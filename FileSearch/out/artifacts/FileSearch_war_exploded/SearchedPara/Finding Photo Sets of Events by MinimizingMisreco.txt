 Nowadays, a large number of photos are flooding our local memory and social photo sharing websites as a result of camera and smart phone X  X  popularization. People often group photos by events. Large storage space brings a torrent of photos for an event. A cover with several photos helps users recognize and recall the event more quickly and much better. What is more, SNS users are more likely to view one event with a few photos shared by their friends rather than all photos. Thus, how to choose photos to form a photo set of an event and improve perceptual quality , which is defined as the accuracy and quickness to recognize an event, becomes a significant problem. With higher perceptual quality, the user can recognize and find a desired ev ent from a huge photo collection more precisely and quickly.
 The aim of our research is to improve the perceptual quality of a photo set. Although our current work is similar to the problem of photo summarization, the purpose of our work is different. It follows that our approach also differs from those used in photo summarization. For example, Sinha et al.[1] tackled the problem of summarizing personal photos from life events. However, such a photo set does not necessarily have high perceptual quality, as their approach does not consider other similar events as which a resulting photo set can be misrecognized. Suppose that a user summarizes photos taken in his/her trip to Japan. By the reason of many temples existing in Japan, the user might take many photos of temples. How ever, one can easily misrecognize the generated summary as  X  X rip to China X  since the summary would include many Asian tem-ples, which are hardly distinguishable by foreigners and even people in those two countries. From the viewpoint of perceptual quality, the photo set should have been generated by taking into account neighbor events (e.g.  X  X rip to China X ) and minimizing possible misrecognitions (e.g. by means of a photo about Japanese castle). Therefore, we analyze relatio nship between events, and put forward a method of preventing user s from misrecognizing a photo set as neighbor events.
We propose three criteria for avoiding possible misrecognitions, namely, sub-event coverage, super-event coverage and membership entropy over sibling events. An algorithm that approximately optimize these criteria is used to generate a photo set with high perceptual quality. Our experimental results showed that our method can achieve high perceptual quality in comparison with a baseline method, while the quality highly depends on queries and the size of photo sets to be generated.

Three contributions of this paper are summarized as follows: 1. We proposed the problem of finding a photo set with high perceptual quality 2. We proposed a method of finding a photo set with high perceptual quality 3. We implemented our approach and conducted experiments by using photos
In the rest of the paper, related wor k is discussed in Section 2. Section 3 defines the problem investigated in this research. Our approach is presented in Section 4, and followed by experimental explanation and results in Section 5. Finally, we draw a conclusion and discuss future work in Section 6. Event representation has been explored in several different study fields for years. As in computer science, there are researches focusing on how to express events in natural language [2]. In multimedia domain, event detection has been popu-lar for both videos and photos. Shen and Fan [3] addressed a challenge of the multimedia field, event detection, by proposing a method for high-level and low-level feature fusion based on collectiv e classification. In recent years, a lot of researches have studied on events that can be predicted from photos. Chen and Roy [4] proposed an approach of detect ing Flickr photos depicting events by analyzing users tags and meta data with the photos. A method of mining most informative features for the event recognition from photo collections is proposed in [5]. However, all these researches addressed a problem of detecting events and clustering photos based on events. They d o not consider the characteristic of events and event representation. In our research, we focus more on how to select photos for representing an event without any misrecognition.

Many of researches on photo summarizati on focused on personal photo collec-tions. Platt, Czerwinski, and Field [6] presented an overview of users photo col-lections generated by an image clustering algorithm, then selected representative images by the most distinctive images. Unsupervised approaches were proposed in [7] for event clustering based on similarity of time and image content. An event-clustering algorithm was develop ed to automatically segment photos into events and sub-events for albuming based on data/time information and color content of the photos [8]. All these resea rches focused only on photos of a certain event, while in our research, photos rel ated to neighbors of an event are taken into consideration and they help to improve the perceptual quality of the result photo set. Many current researches focus on concr ete events, and most of them are used in the context of news or sports. While in this research, we focus more on generic events, which are usual and related to our e veryday life. More importantly, every-one can easily take photos of these events . By referring to some existing research about general event [9], events are defined as ones involves human activities and can be specified with time and location . An event can be represented with some keywords, e.g.  X  X ravel Japan X  and  X  X iking summer X , where terms  X  X ravel X  and  X  X iking X  represent activities, while  X  X apan X  specifies the location and  X  X ummer X  specifies the time.

Note that any term can imply an event in the context of photo, because every term can reflect what a user is doing while taking that photo. For example, term  X  X avender X  is a plant and cannot be regarded as an activity. However, a photo including lavender indicates the activity of viewing lavender. Therefore, every term can represent an event when it is expressed by photos in this research.
The problem we tackle is defined as follows: given an event-related query e  X  E , a photo collection P , and size of an output photo set n , return a photo set S e  X  P e of size n ,where E represents all possible events, and P e is photos related to e from P . The photo collection P is a large set of photos that were taken by different users, while P e can be ones in a personal photo collection for an application of photo summarization or ones taken for event e by many users. Currently, we use latter ones. Users can decide an appropriate size of output depending on their application, such as thumbnails and cover photos for a personal photo library or SNS posts. As we mentioned in the introduction part, the main goal of our research is to find a photo set with high perceptual quality. To this end, we propose a method of minimizing misrecognitions from neighbor events and achieving high perceptual quality accordingly. There are three typ es of misrecognitions when a user looks at a photo set and tries to tell an event from it, and they are mainly caused by three types of neighbor events.

Sub-event misrecognition means that a user misrecognizes a photo set of an event as its sub-event. Event A is a sub-event of event B if A is included in B. As shown in Figure 1(a), event of  X  X rav el X  includes several sub-events, such as  X  X ransport X  (actually it is  X  X ravel transport X , but we removed  X  X ravel X  for simplification),  X  X ightseeing X  and so on. Three photos used in Figure 1(a) are all related to  X  X ransport X  which only co vers a single sub-event of  X  X ravel X . This photo set of size three is easily to be taken as  X  X ravel transport X  by mistake.
Super-event misrecognition is a situation where a user misrecognizes a photo set of an event as its super-event. Super-event is an inverse meaning of sub-event. As seen in the example given b y Figure 1(b), super-events of  X  X ravel in Kyoto X  are  X  X yoto X  (all the events that can happen in Kyoto) and  X  X ravel X . If a photo set only includes photos of Kyoto, people would regard the photo set as  X  X yoto X  rather than  X  X ravel in Kyoto X .

Sibling-event misrecognition indicates a case wher e a photo set is mis-recognized as an event X  X  sibling-event. Event A is a sibling event of event B if A is a sub-event of B X  X  super-event and A share similar contents with B. For example, we can see from Figure 1(c) that a photo set for  X  X onference party X  is also suitable for  X  X irthday party X  which is a sibling event. 4.1 Neighbor Events Generation In order to minimize misrecognition from neighbor events, we need to generate neighbor events for a given event. Every event e consists of a set of keywords, K ated with a set of tags: T e  X  T ,where T represents all the tags. Note that noisy tags, which are not related to content of a photo, such as  X  X ikon X  and  X  X hoto X  have been removed in advance.

There are three types of similarity between two tags: visual similarity, con-text similarity and semantic similarity. Visual similarity of two tags t 1and t 2, VisualSim( t 1 ,t 2), can be obtained by Euclidean D istance between visual features of them[10]. Visual feature of each tag is obtained from global visual features, such as color (RGB and HSV), and local feature with 1000-D bag of visual words. Current research efforts in content-based image retrieval (CBIR) have proved that these common used features could measure visual contents similar-ity between images quite effectively [11]. Context similarity ,ContextSim( t 1 ,t 2), measures whether two tags are similar by considering their neighbor tags [12]. For example,  X  X loud X  and  X  X ky X  are often tagged with the same set of tags, such as  X  X lue, water, tree X , so they are very similar based on tag context. By se-mantic similarity , SemanticSim( t 1 ,t 2), we mean whether two tags has the same meaning and we implement it by using path similarity of wordnet[13].
 Generate Sub-Events. We can specify sub-event by adding one keyword to the original event X  X  keyword set and ones that can be easily get confused with the event will be selected. The adde d tags are expected to be important in the event, and to be visually similar to the event. We first compute tf(term frequency in a photo collection of an event)-idf (inverted photo frequency) of all tags attached to event-related photos P e . A tag is denoted by t and tf-idf( t, e ) represents its importance for e . Then we calculate visual similarity between e and each tag, which is defined by VisualSim( t, e ). Relevance of a tag t to event e is harmonic mean of its tf-idf and visual similarity value: SubRel( t, e )= the redundancy in resulting sub-events. We use context similarity between tags to be diversity metric. Let W e  X  T e be the current sub-event tag set. The strategy is to find tags which have high relevance with e and is most diverse to the current set:
MMRSub( t, e ) = argmax After finding top ten sub-event tags with maximal marginal relevance, we gen-erate sub-events by adding each sub-event tag to the original event X  X  keyword set K e , i.e. Sub( e )= { v | K v = K e  X  X  w } X  w  X  W e } .
 Generating Super-Events. We simply generate super-events by removing each keyword from the original event X  X  keyword set K e , as subsets with one smaller size of keywords usually represent a more general concept than the orig-inal keyword sets. Thus, Sup( e )= { u | K u  X  K e  X | K u | = | K e | X  1 } . For example, super-events of event  X  X ravel Ja pan X  are  X  X ravel X  and  X  X apan X .
 Generating Sibling-Events. An event X  X  sibling events are sub-events of its super-events. However, since we want to find sibling-events that are likely to lead to misrecognition, we change the relevance and diversity metrics when utilizing MMR. For each super-event c of an event e ,theabsentword k is one that generalizes the event, i.e. k = K e  X  K u ( u  X  Sup( e )). For example,  X  X apan X  from  X  X ravel Japan X  makes super-event  X  X ravel X  location non-specified. Sibling-events of  X  X ravel Japan X  under  X  X ravel X  are sub-events of  X  X ravel X  which can specify a location and the added tag should be similar to  X  X apan X  in the context of remaining tags. In addition, the added tag should have short distance with the absent word in regard to visual fea tures. As a result, context similarity and visual similarity between tags are combined for relevance computation, i.e.
Semantic similarity is used for diversity, because tags with the same meaning should be avoided. Similarly, let W u  X  T u be the current sibling-event tag set under one of the super-events u . The target function of MMR algorithm is: MMRSib( t, u, e ) = argmax
With top ten tags with maximal marginal relevance W u , we obtain sibling events under each super-event u , i.e. Sib( e, u )= { v | K v = K u  X  X  w } X  w  X  W u } . 4.2 Sub-event Coverage A photo set which covers only a single or a few sub-events may cause sub-event misrecognitions. So an ideal photo set should cover as many sub-events as possi-ble. By using the example in Figure 1(a), a photo set that contains  X  X ransport X ,  X  X ood X , and  X  X andscape X  would be better to present the event  X  X ravel X  than one that only contains  X  X ransport X .

The sub-event coverage can be measured b y borrowing an idea in search result diversification, which aims to retrieve search results that cover as many topics as possible in response to a given query [14]. The approach used in search result diversification is to estimate the probability that all the topics are covered with at least one search result, and to find a set of search results that maximizes this probability. Analogously, we estimate the p robability that all the sub-events are covered with at least one photo, and to find a set of photos that maximizes this probability. Thus, the sub-event coverage SubCov( S, e )isdefinedasfollows: is the probability that e contains sub-event v as well, and P ( c =1 | s, v )isthe probability that photo s covers sub-event v . We assume a unique distribution for P ( v | e ) due to the lack of prior knowledge for this probability, i.e. P ( v | e )=
Sub( e ) | . An intuitive interpretation of this formula is that SubCov( S, e ) becomes high if at least one of the photos in a photo set S has high probability P ( c = 1 | s, v ) for all the sub-events of e .

Below, we discuss a method of estimating the probability P ( c =1 | s, v ). A basic assumption here is that photo s is likely to cover sub-event v if s is similar to photos of v .Weuse k -nearest neighbor distance k-NND( s, v ), which is the average distance of k -nearest neighbor photos of photo s in photo set P v ,to measure the similarity between a photo and photos of an event. In addition to its simplicity, the computation of the k -nearest neighbor distance is efficient, since k -nearest neighbor search has been exte nsively studied in the literature. We obtain the following formula by taking the inverted distance of k-NND( s, v ) with an exponential function: P ( c =1 | p, e )=exp(  X   X   X  k-NND( s, v )), where  X  is a parameter that controls the shape of this distribution.

In summary, the sub-event coverage SubCov( S, e ) measures how likely a photo set can prevent sub-event misrecognitio ns. A photo set with high sub-event cov-erage is expected to avoid sub-event misr ecognitions, and consequently achieve high perceptual quality. 4.3 Super-Event Coverage A photo set that covers only one or few super-events may cause super-event misrecognitions. To cover all super-events Sup( e )ofevent e , there should be at least one photo related to each super-event in the photo set S . Thus, we use the average of sub-event coverage for all its super-events to get super-event coverage:
Only if all the super-events have high sub-event coverage, super-event coverage becomes high. For example, a photo set with high super-event coverage for event  X  X ravel in Kyoto X  would be one that has high sub-event coverage for both events  X  X ravel X  and  X  X yoto X . 4.4 Membership Entropy over Sibling-Events A photo similar to just a few sibling-event can cause sibling-event misrecogni-tions. Thus, any photo in the output photo set should be similar to sibling-events as evenly as possible or not similar to any sibling event under their shared super-event. In the example of  X  X onference party X  in Figure 1(c), any photo in a photo set should evenly represent all the sibling-events of  X  X onference party X , or be dissimilar to any of the sibling-events such as  X  X irthday party X . Formally, photo s in photo set S for event e should evenly cover sibling-events Sib( e, u )ofevent e in terms of super-event u . This idea can be implemented by using an entropy over sibling-events as proposed in work on query suggestion [15]. Letting P e ( v | s ) be the probability that photo s covers sibling-event v of e , the membership en-tropy of s over sibling-events v  X  Sib( e, u ) under super-event u of e is defined as H by using k -nearest neighbor distance k-NND( s, v ) in the previous section: Here, we used a similar idea to the probability P ( c =1 | s, v )usedinthepre-vious section, i.e. a photo is likely to cover an event if the photo is similar to photos of the event. Note the difference is that the probability P e ( v | s ) follows a multinomial distribution, while the probability P ( c =1 | s, v ) follows a binomial distribution.

The criterion of entropy for super-events of e with respect to sibling-events for a photo is formulated as follows: where Sup( e )isasetofsuper-eventsofevent e ,and  X  H s e,u is the 0-1 normalized version of the entropy H s e,u (i.e.  X  H s e,u = H s e,u / log | Sib( e, u ) | ).
Having calculated the membership entropy for each photo in a photo set, we aggregate these scores by using the following formula: Although it is possible to take the average of SibEnt( s, e ) for each photo in a photo set S , we selected this formula so that MemEnt( S, e )is submodular for efficient photo set generat ion as explained later. 4.5 Photo Set Generation By combining three criteria we introdu ced above, sub-event coverage, super-event coverage and membership entropy over sibling events, we get an objective function f ( S, e ) to be maximized: where  X  ,  X  ,and  X  are parameters that d etermine which criteria to be emphasized.
Our objective now can be reformulated as a problem of finding a photo set of size n for a given event e that maximizes the objective function f ( S, e ). Un-fortunately, it is a NP-hard problem to find an optimal photo set. When photos can belong to multiple photo sets, there may not exist a single ordering of photo sets such that the objective function of f ( S, e ) is maximized for all possible S . The reason is that a set of photos optimal for f ( S ,e ), where | S | = n  X  1, need not be subset of optimal of f ( S, e ), where | S | = n .

As the set function f ( S, e ) is monotonic and submodular (see Appendix), we can apply the greedy algorithm and guarantee the result returns (1  X  1 /e )-approximation of the maximum[16], which often gives a good approximation to the optimum. We start with an empty photo set S , and iteratively add a photo p  X  P e to S that maximizes f ( S  X  X  p } ,e ) until the size of the photo set | S | reaches n . We conducted experiments to demonstrate the effectiveness of our proposed method by using photos crawled from Flickr. Due to two phases in our approach that includes generating neighbor event s and a photo set, they were implemented independently. All data in our experiment was collected from photo sharing social website Flickr, which contained photos taken by different users. We first collected about 1.3 million photos with 500 seed queries from the website to form photo collection P . Photos containing event X  X  keywords are used as P e . 5.1 Generating Neighbor Events In this experiment, we generated neighbor events of 25 events with our proposed method and a simple baseline method. In our method, parameters are set ac-cording to our preliminary experiments:  X  =0 . 7,  X  =0 . 7. As a baseline, we used tf-idf to rank tags and generated sub-events by adding top-ranked tags to a target event. Super-events were produced the same way as in our method, while sibling-events were generated by u sing sub-events extracted by the simple baseline method.
 Table 1 shows some examples generated with our method and baseline method. We can see that neighbor events generated by our methods are closer to reality. Especially our proposed method could generate better sibling-events probably because we considered the absent term of each super-event. On the other hand, baseline method using tf-idf generated many duplicate sibling-events probably due to the lack of considering similarity between tags. 5.2 Generating Photo Set Setup. VisualRank (VR)[17] was used for a baseline method, because it can generate representative photos for a given event due to the fact that it gives high score to photos that are similar to many other photos in a collection. We simply used photos with the highest VR scores as an output photo set.
We used 25 events as inputs and applied five methods to generate photo sets of five types of sizes for each event. The five methods we tested are VisualRank (VR), sub-event coverage only (Sub), super-event coverage only (Sup), member-ship entropy over sibling events only (Sib), and combination of three criteria (ALL) which maximizes value of f in Equation (6). Having conducted prelimi-nary experiments, three parameters in the objective function were set empirically as follows:  X  =0 . 26,  X  =0 . 42,  X  =0 . 32. We used five types of the size of photo sets, i.e. n =1 , 3 , 5 , 10 , 20. The parameter k of k -nearest neighbor was set to 10, and the parameter  X  was set to 25 in this experiment. In total, there are 625 photo set for (event, method, size of photo set) combinations.

To evaluate the perceptual quality o f each photo set, we utilized Lancers 1 ,a crowd sourcing service in Japan. Five users were assigned to each photo set. As we mentioned earlier, the perceptual quality of a photo set is better weighted by the accuracy and quickness of user X  X  perception of an event by looking at a photo set. According to our request, they were required to answer what events they recognized from a photo set in a fe w seconds, which could guarantee the quickness of perception in a relative hig h level. We then quantized the accuracy of perception by judging the agreement b etween the original event keywords and their labels. This comparison was conducted by one of the authors, since this task was neither difficult nor subj ective. The agreement was measured at a three-point scale: mismatch (0), partial match (1), and match (2). Match is given if the label has the same meaning as an event used, while the assessor gave partial match to labels that partially overlap keywords of the event. Results. Figure 2 give photo sets of event  X  X alk dog X  X enerated by  X  X ib X ,  X  X LL X  and  X  X R X  method. As we can see,  X  X R X  gives very similar photos, while fails to cover possible sub-events, such as  X  X alk do g leash X . It also lacks differentiation from sibling-event events like  X  X aise dog X  and  X  X alk stroll X .  X  X ib X  successfully avoid misrecognition from these sibling-events.

Figure 3 shows an overall comparison of results from five methods. The hori-zontal axis is the number of photos in the photo set, and vertical axis is average score we get for average perceptual quality of each size. The overall trend is clear: with more photos in the photo set, the perceptual quality is improved. However, too many photos, such as 10 or 20 photos cannot help with it signif-icantly. A two-way ANOVA shows a significant difference in both the type of p&lt; 0 . 01). Significant interaction was not found: F (16 , 600) = 0 . 217.
Three criteria (Sub, Sup and Sib) show different performances on various sizes. With three or five photos, sub-event coverage is the best probably due to its coverage of good representative cont ents over an event. Nevertheless, sup-event coverage is not as good as other two criteria. Membership entropy over sibling-events exhibits best performance with one photo. This may attribute to the fact that it maximizes an event X  X  diff erence from sibling-events that can cause misunderstanding and users can easily figure out the right event without hesitation. Unfortunately, we find that the combination of three criteria does not reach our expectation. This failure may be the result of following reasons. The parameters of every cr iterion X  X  weight are fixed. While according to our findings, they should vary based on size of photo set since performance of each criterion differs in sizes. M eanwhile, performance of ea ch criterion differs with various events, which indicates the nece ssity of adjusting parameters according to events. We can also find that baseline method outperforms well when there are too many photos (20 photos). The reason may be that it will include diverse photos when the size increases too much. We propose to use a photo set to present an event and utilize event coverage and membership entropy to minimize misrecognition from neighbor events. Three types of misrecognition are summarized, and respectively, three criteria are used to deal with each type. To generate the final photo set, a function combining three criteria is given to be maximized. We compare the performance of VisuaRank and our methods. Results from our experiment prove that our proposed approach can improve perceptual qualit y in different sizes of photo set.

Apparently, there are still a lot of work needed to do in this research. As our definition of event consists of activity, time and place, it is better to make them different when considering relationship between events. Currently, we focus on only the selection of photos to form a photo set, composition of photos and aesthetic factors should be taken into consideration in our future research. Acknowledgments. This work was supported in part by the following projects: Grants-in-Aid for Scientific Research (No. 24240013) from MEXT of Japan, and Microsoft Research CORE Project.

