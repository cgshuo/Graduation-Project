 Classi cation mo deling (a.k.a. sup ervised learning) is an ex-tremely useful analytical technique for developing predictive and forecasting application s. The explosive growth in data warehousing and internet usage has made large amoun ts of data p otentially available for developing classi cation mo d-els. For example, natural language text is widely available in many forms (e.g., electronic mail, news articles, rep orts, and web page contents). Categorization of data is a common activity which can b e automated to a large extent using su-p ervised learning metho ds. Examples of this include routing of electronic mail, satellite image classi catio n, and charac-ter recognition. However, these tasks require lab eled data sets of suciently high quality with adequate instances for training the predictive mo dels. Muc h of the on-line data, particularly the unstructured variety (e.g., text), is unla-b eled. Lab eling is usually a exp ensive manual pro cess done by domain exp erts. Active learning is an approach to solv-ing this problem and works b yiden tifying a subset of the data that needs to b e lab eled and uses this subset to gen-erate classi cation mo dels. W e presen t an activ e learning metho d that uses adaptive resampling in a natural wa yto signi cantl y reduce the size of the required lab eled set and generates a classi cation mo del that achieves the high ac-curacies p ossible with current adaptive resampling metho ds. I.2.6 [ Arti cial Intelligence ]: Learning; I.5.1 [ Pattern Recognition ]: Mo dels; H.2.8 [ Database Managemen t ]: Database Application s| data mining Data mining, machine learning, classi cati on, active learn-ing, adaptive resampling Sup ervised learning metho ds are b eing used to build classi-cation mo dels in various domains like nance, marketing, and healthcare [5]. Classi cation techniques hav ebeende-velop ed within several scienti c discipline s, including statis-tics, pattern recognition, machine learning, neural nets and exp ert systems [30]. The quality and the quantit y of train-ing data used by these sup ervised metho ds is an imp ortant factor in the prediction accuracy of the derived mo dels. In man y application s, getting data with the class lab els is dif-cult and exp ensive since the lab eling is done man ually b y exp erts. A frequently cited example is electronic mail rout-ing based on categories. Training data is usually obtained b yman ually lab eling a n um b er of instances of mail. Another suc h example is categorizing web pages based on con ten t. One approach to solving this problem is to select the data that need to b e lab eled such that a small amoun toflabeled training data suces to build a classi er with sucient ac-curacy. Random sampling is clearly ine ective since the var-ious classes can hav ev ery skewed distribution s in the data and instances of the infrequent classes can get omitted from the random samples. Strati ed sampling [8] is a metho d de-velop ed to address this problem with random samples. The unlab eled data is partitioned based on the attributes of each instance in the data. Sampling is done separately from each partition and can b e biased based on the exp ected diculty in classifying the data in each partition. However, it b e-comes more dicult to generate these partitions for high dimensional data and it is not clear how to e ectively ap-ply this approac h ondatat ypically seen in many real life application s.
 Active learning is a term coined to represent metho ds where the learning algorithm assumes some control over the sub-set of the input space used in the mo deling [9, 10]. In this pap er, active learning will mean learning from unlab eled data, where an oracle can b e queried for lab els of sp eci c instances, with the goal of minimizing the numb er of ora-cle queries required. Active learning has b een prop osed in various forms [2, 10, 11, 12, 17, 23, 24, 27]. W e will discuss in more detail the earlier works in active learning related to the approach used in this pap er.
 One approach to active learning is unc ertainty sampling in which instances in the data that need to b e lab eled are iter-atively identi ed based on some measure that suggests that the predicted lab els for these instances are uncertain. Vari-
Permission to make digital or hard copies of part or all of this work or permission and/or a fee.

KDD 2000, Boston, MA USA  X  ACM 2000 1 -58113 -233 -6/00/0 8 ...$5.00 ous metho ds for measuring uncertain t yha v e b een prop osed. In [22], a single classi er is used that pro duces an estimate of the degree of uncertain t y in its prediction. An iterativ e pro cess then selects some xed n um b er of instances with maxim um estimated uncertain t y for lab eling. The newly lab eled instances are added to the training set and a classi-er generated using this larger training set. This iterativ e pro cess con tin ues un til the training set reac hes a sp eci ed size. This metho d is generalized in [21] b y using t w o clas-si ers, the rst one to determine the degree of uncertain t y and the second one to do the classi catio n. In this w ork, a probabili stic classi er w as c hosen for the rst task based on eciency consideration s and C4.5 rule induction w as c hosen for the second task.
 Another related approac hiscalled Query by Committe e [27, 16]. In one v ersion of the query b y committee approac h t w o classi ers consisten t with the already lab eled training data are randomly c hosen. Instances of the data for whic h the t w oc hosen classi ers disagree are then candidates for lab eling. The emphasis here has b een to pro v e theoretical results ab out this approac h.
 Adaptiv e resampling metho ds are b eing increasingl y used to solv e the classi cation problem in v arious domains with high accuracies [15, 7, 28]. In this pap er, w eusetheterm adaptive r esampling to refer to metho ds lik e b o osting that adaptiv ely resample data biased to w ards the misclassi ed p oin ts in the training set and then com bine the predictions of sev eral classi ers. V arious explanations ha v ebeen put forth for the classi catio n accuracies ac hiev ed b y these tec h-niques [26, 18]. Adaptiv e resampling metho ds lik e b o osting are also useful in selecting r elevant examples ev en though their original goal w as to impro v e the p erformance of w eak learning algorithms [14]. The applicati on of b o osting to se-lectiv e lab eling has b een suggested in [14] without algorith-mic details or exp erimen tal results. A related application of b o osting to select a subset of lab eled instances for nearest neigh b or classi ers has b een explored in [15]. The closest re-lated w ork [1] com bines the Query by Committe e approac h with bagging and b o osting tec hniques. In this pap er w euse a more general form ulation that separates the t w o roles for a classi er in suc h approac hes. This allo ws us to plug in dif-feren t classi ers (includin g an oracle) for one of these roles and gain additional insigh t on factors in uencing the results ac hiev ed. Other di erences b et w een our metho d and [1] re-late to practical asp ects in the applicati on that impact the computational requiremen ts and will b e discussed later in the pap er.
 This pap er applies adaptiv e resampling to the activ e learn-ing task in a direct w a y that will b e describ ed in the next section. The goal is to retain some of the adv an tages of adaptiv e resampling metho ds, e.g., accuracy and robustness of the generated mo dels, and com bine it with a reduction in the required size of the lab eled training set. Comparisons will also b e made b et w een using either one or t w o classi ers in the adaptiv e resampling framew ork [21]. Exp erimen tal re-sults using b enc hmarks from v arious domains are presen ted in the pap er to illustrate the the sizes of the lab eled training sets needed to get adequate classi cati on accuracy . Adaptiv e resampling (e.g., [15, 28]) selects instances from a lab eled training set with the goal of impro ving the classi -cation accuracy . The selection pro cess adapts b y biasing in fa v or of those instances that are misclassi ed b y the ensem-ble of classi ers generated. W e explore a direct application of this framew ork to c ho ose whic h of the unlab eled instances should b e lab eled in an activ e learning task. Since the actual lab els are unkno wn for these instances in an activ e learning task, guessed lab els generated b y a classi er will b e used instead.
 Metho d ALAR (Input: Unlab eled data U, 1 Select an initial subset S
Lab el instances in S 2 F or eac h phase p 3 Guess lab els G for eac h instance in U 4 Use adaptiv e resampling on training set L 5 If not last phase 6 Select subset S 7 Com bine the ensem ble E of classi catio n mo dels end ALAR Figure 1: Description of Activ e Learning using Adaptiv e Resampling (commen ts are italicize d ) Consider a more detailed description of the metho d (ALAR) giv en in Figure 1. It is assumed that apart from the unla-b eled data U pro vided to the metho d, an exp ert is a v ailable to lab el an y selected instance in U. The metho d pro duces as output a classi er C and a selectiv ely lab eled training set L that migh tha v e other uses (e.g., for use b y another classi er).
 Instances are selected from the unlab eled data U for lab el-ing in an iterativ e pro cess. The initial subset S c hosen at random. Instances in S and mo v ed from U to the lab eled training set L (statemen t 1). Additional instances from U will b e lab eled and added to L in phases. In eac h phase, the lab eled training set L is used b y a classi cati on metho d M1 to guess the lab els G for the unlab eled instances in U (statemen t 3). The set L with the instances lab eled so far is used in an adaptiv e resampling framew ork using a classi cati on metho d M2 to generate an ensem ble E of classi cation mo dels (statemen t 4). Man yv ariations for adaptiv e resampling ha v e b een pro-p osed and they di er in the details of w eigh ting function for resampling and the classi cation metho d used. The exp er-imen tal results in this pap er w ere generated using decision trees for the classi cation metho d M2. The resampling w as done using the normalized v ersion of the follo wing w eigh ting function w(i) for eac h instance i in L [28]: where error(i) is the cum ulativ e error for instance i o v er all the classi catio n mo dels in the ensem ble E.
 The ensem ble E of classi cation mo dels is used with the guessed classes G for the unlab eled data to select more in-stances in U for lab eling in the next phase (statemen t 6). In tuitiv ely , the w eigh ts W for selecting an y instance in U for lab eling should b e biased to w ards those whic h are misclassi-ed in the ensem ble E assuming the v alidit y of the guessed class lab els G. In our exp erimen ts, w e use Equation 1 again to compute the w eigh ts W, but with the cum ulativ e error b eing calculated using the guessed class lab els G as refer-ence. A set of instances S sampling using the normalized v ersion of w eigh ts W. T ypically , the iterativ e addition of instances from U to the lab eled set L could con tin ue un til a sp eci ed size of L has b een reac hed or the mo del qualit y impro v emen ts tap er o . The nal classi er C is generated b ycom bining the classi -cation mo dels in the ensem ble E (statemen t7). W e explore a couple of v ariations in the generation of C. In the rst case, all the classi cation mo dels in E are com bined. In the second case, once the lab eled training set L is complete, a new set of classi cation mo dels is generated using adaptiv e resampling with this complete set L (earlier mo dels in E are discarded). The second case corresp onds to using our metho d to gen-erate a lab eled training set L and then using the adaptiv e resampling metho d with L. In our exp erimen ts, w e use un-w eigh ted v oting across the set of classi catio n mo dels b eing com bined to pro duce the nal classi er C [7, 28]. Tw ov ariations of the ALAR metho d will b e considered in the exp erimen ts discussed in the next section. In the rst approac h, refered to as ALAR-v ote-E, w e com bine (using un w eigh ted v oting) the ensem ble of classi cation mo dels E a v ailable in eac h phase for use as the classi cation mo del M1. This approac htak es adv an tage of the rep orted e ec-tiv eness of v oting metho ds (e.g., [15]) in pro viding guessed lab els. In the second approac h, refered to as ALAR-3-nn, t w o distinct classi cation metho ds are utilized. A nearest neigh b or metho d (3-NN) is used for classi cation metho d M1. In b oth approac hes decision trees are used for classi -cation metho d M2. The comparison of the p erformance of these t w o approac hes is in teresting giv en earlier comparisons bet w een one and t w o classi er metho ds (e.g., [21]). Other imp ortan t parameters that can b e v aried in the metho d in Figure 1 are the n um b er of phases, n um ber of poin ts to b e selected for lab eling in eac h phase and the n um b er of rounds of adaptiv e resampling with the training set of eac h phase. The v alues used for these parameters in our exp erimen ts will b e giv en in the next section along with other exp erimen tal details. This section presen ts the results of applying our metho d to b enc hmarks in v arious domains. The rst b enc hmark internet-ads w e will consider is based on an application to iden tify images that are In ternet adv ertisemen ts [6]. An ap-plication to remo v eadv ertisemen ts after iden ti catio n w as ev aluated using this b enc hmark b y its donor in [19]. Three of the 1558 features enco de the geometry of the image. Most of the remaining binary features capture o ccurrences of phrases in the URL, the anc hor text, and text near the anc hor text. In this pap er, only the 2359 records in the b enc hmark with-out an y missing data are used. The original pap er [19] using this data rep orted results using the accuracy measure. The sk ew ed distribution of the t w o classes ad, nonad leads us to use instead the usual information retriev al measures of recall and precision for the more infrequen t class ad . All ex-p erimen ts with this b enc hmark are done using 10-fold cross v alidation.
 In the rst exp erimen tw e will use random sampling to cre-ate training sets of v arious sizes. F or eac h training set cre-ated, t w ot yp es of classi cation mo dels are constructed and ev aluated against the test set. The rst t yp e of mo del is a decision tree constructed using the tree pac k age DMSK [29]. The second t yp e of mo del is created using adaptiv e re-sampling of the training set with 100 DMSK trees. Figure 2 sho ws the results a v eraged o v er ten exp erimen ts for eac h par-tition in the 10-fold cross v alidation. The arithmetic mean of precision and recall is the metric displa y ed. The results obtained for the single tree are comparable to the results presen ted in [19]. The qualit y of precision/recal l degrades substan tiall y for the single tree from 89.4% to 71.3% when the randomly c hosen training set size is reduced b y a factor of ten to 212. On the other hand, adaptiv e resampling with the randomly c hosen subsets (AR-random) is more robust. The precision/reca ll metric for AR-random with the en tire training data is 92.3%, whic h is b etter to b egin with. When the training set is cut in size randomly b y a factor of ten the metric for AR-random degrades to 84.8%. Man y of the ear-lier w orks in activ e learning giv e comparisons with classi ers lik e the single tree case sho wn in Figure 2. Ho w ev er, with the prev alence and success of adaptiv e resampling metho ds no w, it is more in teresting to compare the accuracy of activ e learning metho ds using AR-random as the baseline [1]. The impro v emen t in prediction accuracy b y using the ALAR metho d o v er AR-random is sho wn in Figure 3. The AR-random p erformance curv e is rep eated for comparison. The curv es mark ed ALAR w ere ac hiev ed b y using the ALAR metho d of Figure 1 with the follo wing set of parameters. A total of 4 phases (after the initial addition of S with equal n um b er of instances b eing lab eled in eac h phase. In eac h phase 25 rounds of adaptiv e resampling w as done with the lab eled training set a v ailable at that p oin t. Ho w-ev er, for the last phase after all the additions to the lab eled training set this w as increased to 100 rounds of adaptiv e re-sampling. The com bined classi er w as obtained b yv oting o v er all the 200 trees in the ensem ble. This set of param-eters w as used for all the exp erimen ts in the pap er except when noted otherwise.
 The curv es ALAR-v ote-E and ALAR-3-nn depict the re-sults ac hiev ed b yt w ov ariations of the ALAR metho d. The ALAR-v ote-E curv ew as ac hiev ed b y using the un w eigh ted ma jorit yv ote amongst the ensem ble of mo dels E for classi -cation metho d M1. The ALAR-3-nn curv ew as ac hiev ed b y using 3-NN as the classi cation metho d M1. The results in Figure 3 indicate that there is a v ery sligh t loss of accuracy using ALAR-v ote-E and ALAR-3-nn ev en when the train-ing set size is reduced b y a factor of four. When further reductions are made in the size of the lab eled training set, the accuracy of b oth metho ds (ALAR-v ote-E and ALAR-3-nn) degrades, though it con tin ues to remain b etter than AR-random. F or this b enc hmark, ALAR-v ote-E p erforms sligh tly b etter than ALAR-3-nn for most of the training set size range.
 Another in teresting curv e plotted in Figure 3 is called ALAR-oracle. This curv eis ac hiev ed b y using an oracle for classi-cation metho d M1. Ob viously , this is not a practical solu-tion since the lab els for instances in U will not b e kno wn. Ho w ev er, the ALAR-oracle curv e can b e used to assess the impact of the accuracy of the classi catio n metho ds used for M1 (e.g., 3-NN and v ote-E) on the ALAR metho d. The gap b et w een ALAR-oracle and ALAR-v ote-E/ALAR-3-nn widens as the allo w ed size of the lab eled set is reduced. This is caused in part b y the qualit y of guesses in b oth ALAR-v ote-E and ALAR-3-nn getting w orse as the size of the lab eled set a v ailable to them decreases. All the ALAR results can b e impacted b yc hanging the parameters for the ALAR metho d (e.g., n um b er of phases, n um b er of instances added for lab eling in eac h phase). W eha v e exp erimen ted with these parameters to some exten t, but will use the same set of parameter v alues across all the b enc hmarks. The next b enc hmark w e will consider is satimage from the UCI Rep ository [6]. This b enc hmark con tains sp ectral v al-ues for pixels in a satellite image (36 attributes) and the goal is to predict the soil t yp e (6 classes). The giv en training set has 4435 p oin ts and the test set has 2000 p oin ts. The ALAR metho d w as applied with the same set of parameters as de-scrib ed earlier and the results a v eraged o v er 10 exp erimen ts (on the giv en test set) are plotted in Figure 4. As b efore the AR-random curv e is used as the baseline and the goal for accuracy is that ac hiev ed b y AR-random (a v erage error = 8.54%, = 0.17%) with the en tire training set of size 4435. Both ALAR-v ote-E and ALAR-3-nn ac hiev e comparable ac-curacy with only 2217 lab eled instances. With 2217 lab eled instances ALAR-3-nn ac hiev es a v erage error = 8.83%, = 0.19%, and ALAR-v ote-E ac hiev es a v erage error = 8.67%, = 0.34%. In terestingly , b oth ALAR-3-nn and ALAR-v ote-Eac hiev e accuracy similar to ALAR-oracle for m uc hofthe training set size range.
 The ALAR metho d (refer Figure 1) pro duces a lab eled train-ing set L of the sp eci ed size in addition to the classi er C. W e explored the use of this lab eled training set with this benc hmark. Three di eren t classi ers w ere used to compare three training sets: a ALAR-3-nn generated lab eled set of size 2217, a random subset of size 2217, and the en tire train-ing set of size 4435. The three classi ers w ere 5-NN, adaptiv e resampling using 100 DMSK trees, and a single DMSK tree. T able 1 presen ts the a v erage p ercen tage errors and standard deviation (in paren thesis) o v er ten exp erimen ts. F or this benc hmark, the smaller lab eled set pro duced b y ALAR-3-nn can b e used b y these three classi ers to pro duce fairly accurate mo dels when compared to the results using the en-tire training set. Ho w ev er, further in v estigatio ns are needed to determine whether, in general, the lab eled sets are useful with other classi ers.
 The next b enc hmark is letter-r e c o gnitio n from the UCI Rep os-itory [6]. The 16 attributes capture statistical momen ts and edge coun ts for the english alphab ets in v arious fon ts with the goal of determining the displa y ed alphab et (26 classes). The b enc hmark sp eci es a training set with 16K instances and a test set with 4K instances. The results of applying the ALAR metho d are sho wn in Figure 5. Both ALAR-3-nn and ALAR-v ote-E ac hiev e the accuracy goal with only 8000 lab eled instances.
 The last b enc hmark used is the Mo d-Apte split of the R euters data set a v ailable from [20]. Only the top ten categories are considered. F or eac hofthemw e solv e the binary classi ca-tion problem of b eing in or out of that category .W eused the notion of information gain [31] to select a set of 500 at-tributes for eac h of the ten binary classi catio n problems. This feature selection metho d requires lab els and hence is not applicable for truly unlab eled data [21]. Also, a re-duction in the size of the lab eled set in this exp erimen tal framew ork do es not translate to a corresp onding reduction in the lab eled set needed for the Reuters classi cation prob-lem. Ho w ev er, this exp erimen tal framew ork has b een used in earlier w orks [24]. An in ternally a v ailable decision tree pac k age customized for text applications w as used for this b enc hmark. As is customary with this b enc hmark, w euse the micro-a v erage measure [3], in whic h the confusion ma-trices for the ten categories are added and o v erall precision and recall computed. T en random runs w ere p erformed and the micro-a v erage of the arithmetic mean of recall and pre-cision is giv en in Figure 6. There is only a sligh t degradation in the accuracy with just 960 lab eled instances using either ALAR-v ote-E or ALAR-3-nn metho d. The exp erimen tal results in the previous section indicate that the ALAR-3-nn and ALAR-v ote-E metho ds p erform similarly on those b enc hmarks. Clearly , there is no ev-idence in our exp erimen ts to justify the added computa-tional cost of a separate classi catio n metho d lik e K-NN for M1. ALAR-v ote-E is a more natural and direct w a y to apply adaptiv e resampling to the task of activ e learning when compared to ALAR-3-nn. On some of the b enc hmarks ( internet-ads , r euters ) the ALAR metho d using the oracle do es signi can tly b etter than ALAR-v ote-E, esp ecially for the smaller sizes of the training set. P art of the explanation for this is that the qualit y of the guesses get w orse as the size of the lab eled training set decreases. Ho w ev er, v ariations in the b eha vior across the v arious b enc hmarks require further in v estigation .
 It is hard to directly compare the results obtained using the ALAR metho ds with those obtained b y earlier approac hes to activ e learning. Clearly , the p erformance of an y activ e learning metho d dep ends hea vily on the b enc hmark and its usage. Earlier w orks on activ e learning also rep ort signi -can t reduction in the required size of lab eled training set. Ho w ev er, the baseline target accuracy is c hosen di eren tly in eac hcase. F or example, in [21] the baseline target is subset set set b y the accuracy ac hiev ed b y C4.5 rules on the full la-b eled set. As w eha v e seen in Figure 2 adaptiv e resampling classi cation metho ds can signi can tly impro v e the baseline target o v er single tree classi ers. This has also b een p oin ted out in the w ork in [1] whic h includes b o osted results in the baseline.
 Adaptiv e resampling with trees is a computationall y in ten-siv e pro cess and the ALAR metho d inherits this computa-tional complexit y if decision trees are c hosen for the classi-cation metho d M2. The v alues for the parameters of the ALAR metho d w ere c hosen in our exp erimen ts based on computational complexit y and accuracy considerations. In-stances are c hosen for lab eling and added to the training set in phases. Eac h phase needs to ha v e enough rounds of adaptiv e resampling to train the ensem ble of classi ers ad-equately to the training set for that phase. Adding only one instance in eac h phase as in [1] w ould lead to to o man y phases and to o man y rounds of adaptiv e resampling. Hence, in our exp erimen ts the total n um b er of rounds of adaptiv e resampling, whic h impacts the computational cost, w as c ho-sen to b e comparable to earlier usage (e.g., [15]). Ha ving c hosen this, the n um b er of phases is determined based on trading o ha ving enough rounds p er phase for adaptiv ere-sampling v ersus ha ving enough phases with ne grain con-trol for adding instances for lab eling.
 As men tioned ab o v e, computational considerations lead us to select m ultiple instances for lab eling in eac h phase. This op ens up the issue of ho w these instances are c hosen. One approac hw ould b e to extend the greedy metho d of pic king one instance in [1] to pic king m ultiple instances with the largest w eigh ts (W in Figure 1). Instead, w eha v euseda randomized metho d b y creating a probabili t y function us-ing the selection w eigh ts (Equation 1) and using it to pic k m ultiple instances without replacemen t. The comparison for the b enc hmark satimage is giv en in Figure 7. F or this benc hmark the probabilis tic metho d (ALAR-v ote-E) p er-forms b etter than the greedy metho d (Greedy-E) for smaller training set sizes. A plausible explanation is that pic king m ultiple instances in a greedy fashion ma y b e including more instances that are redundan t for the mo deling. Com bining these metho ds to impro v e the selection pro cess needs to b e explored further.
 In practice, the activ e learning pro cess w ould b e stopp ed b y detecting diminishi ng impro v emen t in the qualit y of the mo dels b eing built. Con v ergence detection has b een studied for the case of random sampling b y estimating the slop e of the learning curv e [25]. The learning curv ema ynotbew ell beha v ed in the activ e learning case making this task more complicated. This also mak es the more general problem of determining a go o d sc hedule for adding lab eled p oin ts harder than the random sampling case [25].
 There are other v ariations of this metho d still to b e ex-plored. Use of simpler classi cation metho ds for M2 will b e explored in future w ork. A related problem with the use of decision trees not addressed in this pap er is that of attribute selection for unlab eled data [21]. Another v ariation to b e ex-plored is in the function (e.g., Equation 1) used for adaptiv e resampling relating imp ortance of selecting an instance to some measure of error. The adaptiv e resampling literature has explored this and the related sub ject of o v er tting an y noisy lab els in the training set [4, 13, 18]. The concern o v er o v er tting of noise lab els is not directly applicable in the activ e learning con text since the error measure is computed using guessed lab els. Dealing with v ast amoun ts of unlab eled data is a gro wing problem in man y domains. W eha v e presen ted a direct w a y of using adaptiv e resampling metho ds for selecting a subset of the instances for lab eling . The exp erimen ts with v ari-ous b enc hmarks indicate that this metho d is successful in signi can tl y reducing the size of the lab eled training set needed without sacri cing the classi cation accuracy when compared with a state-of-the-art metho d lik e adaptiv e re-sampling with trees.
 W ew ould lik e to thank the anon ymous referees for their helpful commen ts. [1] N. Ab e and H. Mamitsuk a. Query learning strategies [2] D. Angluin. Queries and concept learning. Machine [3] C. Apte, F. Damerau, and S. W eiss. Automated [4] E. Bauer and R. Koha vi. An empirical comparison of [5] M. Berry and G. Lino . Data Mining T e chniques: F or [6] C. Blak e, E. Keogh, and C. Merz. UCI rep ository of [7] L. Breiman. Arcing classi ers. The A nnals of [8] W. Co c hran. Sampling T e chniques . John Wiley and [9] D. Cohn, L. A tlas, and R.Ladner. T raining [10] D. Cohn, L. A tlas, and R.Ladner. Impro v ed [11] D. Cohn, Z. Ghahramani, and M. Jordan. Activ e [12] D. Cohn, Z. Ghahramani, and M. Jordan. Activ e [13] T. G. Dietteric h. An exp erimen tal comparison of three [14] Y. F reund. Sifting informativ e examples from a [15] Y. F reund and R. Sc hapire. Exp erimen ts with a new [16] Y. F reund, H. Seung, E. Shamir, and N. Tish b y . [17] Y. F reund, H. Seung, E. Shamir, and N. Tish b y . [18] J. F riedman, T. Hastie, and R. Tibshirani. Additiv e [19] N. Kushmeric k. Learning to remo v ein ternet [20] D. Lewis. Reuters 21578 data set.
 [21] D. Lewis and J. Catlett. Heterogeneous uncertain t y [22] D. Lewis and W. Gale. A sequen tial algorithm for [23] R. Liere and P .T adepalli. Activ e learning with [24] A. McCallum and K. Nigam. Emplo ying em in [25] F. Pro v ost, D. Jensen, and T. Oates. Ecien t [26] R. Sc hapire, Y. F reund, P . Bartlett, and W. Lee. [27] H. Seung, M. Opp er, and H. Somp olinsky . Query b y [28] S. W eiss, C. Apte, F. Damerau, D. Johnson, F. Oles, [29] S. W eiss and N. Indurkh y a. Data-miner soft w are kit [30] S. M. W eiss and C. A. Kulik o wski. Computer Systems [31] Y. Y ang and J. P edersen. A comparitiv e study on
