 short list of interesting rules. Some work has been conducted that finding interesting rules is a very difficult problem, objective is to take the first step to a comprehensive solution to this problem in any domain. 
We present a simple and short process of eliminating a substantial portion of uninteresting association rules in a list outputted by a data-mining algorithm. Instead of trying to establish what is interesting, we look for rules that are not interesting; more specifically, the simple rules whose elimination implies the automatic elimination of many other rules in the list. Thus, our process requires very low-intensity user interaction: in three iterations, a user usually eliminates halve the size of the problem. This elimination is a significant first step since size is the essence of the problem. We present representative results of executions of the algorithm over three real databases: WWW logs, grocery store transactions and adult census data. 1 Introduction As the size of the mined databases increases, the number of rules outputted by data-mining algorithms also increases, and to such an extent that it often overwhelms the users. Users run data-mining algorithms in order to find the knowledge buried within the masses of data [3]. Inundating users with a multitude of patterns discovered in the data is counterproductive. In terms of patterns, a user seeks a short list of interesting-to the user-patterns and that is the list the Knowledge Discovery in Databases (KDD) process should output. To arrive at this list, we need to process the patterns interactions to a few, simple classification questions. We start with the list of rules outputted by the data-mining algorithm. This list is normally very long. If we were to present it for user classification, most rules would be classified as not interesting, indicating that they can be eliminated from the list. We ask a user to classify only a few rules, specifically chosen so that their elimination can bring about the automatic elimination of many other rules. This approach has several benefits: (1) We circum-vent the major difficulty of defining why a certain rule is interesting to a user. (2) We ask only classification questions. The questions are not descriptive in nature and therefore easier and quicker for a user to answer. (3) We make the classification process simpler by having a user classify only very simple rules: a -+ b where both a and b are literals. (4) Every classification a user makes can potentially eliminate an entire family of rules, not only a single rule, meaning that we need to ask fewer questions. (5) We do not require a domain expert to classify the rules; a na X  X ve user can successfully classify most of the rules we present due to their simplicity. For example, in the case of the Israeli grocery store transaction database, one of the first rules brought for classification was (cucumbers) + (tomatoes). Armed with the knowledge that salads are a staple food in Israel, commonly prepared from cucumbers and tomatoes, any user can make this rule classification. 
Thus, the process we present is very low-intensity in both the volume of work expected and the level of interaction required of a user. Our achievements from our user interactions are twofold: first, we incrementally construct a domain knowledge base by gathering the relevant knowledge gained from a user X  X  classifications. The knowledge base is needed for future steps in the process of converging to the list of patterns that are interesting to a domain user. At the same time, we work towards the creation of a concise list of the potentially interesting rules by progressively eliminating rules we learn are not of interest to a user. This elimination process is very fast. Three iterations of our algorithm are usually sufficient to eliminate approximately 30% of the rules. A little over five iterations will often reduce the list to half its original size. 
We stress that in this work we do not attempt to provide a complete solution to the problem of determining, in any domain, precisely which rules are subjectively interesting. The overall problem is currently beyond the scope of a single paper, and still requires a significant cooperative research effort on part of the KDD community. Instead, we present a novel approach that very quickly, using a few simple questions, drastically reduces the size of problem, size being the essence of the problem. This approach also aids us in the construction of a knowledge base. It is the first big step in the formation of a comprehensive solution to this universal base. Many statistically significant rules may be common knowledge even to a na X  X ve user with no domain-specific experience (for example, (pregnant) -+ (woman)). We need to exclude these rules from the list of interesting rules we propose to present to the user. The second category is a broader one, characterizing the entire family of the rule, i.e., any association between the assumption and the consequent. These two categorizations define four possible classifications for each rule: r* = (husband) + (married+) is an example of a rule classified as TNI. The word  X  X usband X  is defined as the male partner in marriage. Any person familiar with this definition (not only a domain expert) can easily deduce that (1) r is a true and not interesting rule, and, (2) any rule specifying when a husband is a married person is not interesting. The first inference is the classification of r as  X  X rue X , a knowledge nugget we can add to our knowledge base. The second inference is the classification of the entire rule X  X  family as not-interesting, indicating that all the rules that have the attribute husband in their assumption and the attribute married in their consequent are to be classified automatically as not-interesting as well (see why in Section 4.3). Note that although a user is required to classify an entire family, it is a very easy classification to make. This classification is perhaps the most confusing one. A user interested in researching married people may classify the rule r:! = (male) + (married)* as NTI, indicating it is not true in general. At the same time, this user may be interested in what qualifications on a male provide a higher confidence that the male is married (for example, (malel X  X owns minivan) + (married)). In this case, the user will choose to have rules that contain the attribute male in the assumption and the attribute married in the consequent be presented to him or her in the future. Since the user determined the rule to be not true r2 is classified as NT1 by this user. A user interested in the conditions for annual income greater than $50,000 classified the rule 7-s as NTNI. This rule was, again, determined to be untrue. The user in this example is not interested in the conditions that determine whether a person is married, and thus classified the family of the rule as not-interesting. In the previous example, this same rule family was classified, by a different user, as interesting. The subjective interests of the different users determine whether the rule is classified as NT1 or NTNI. pass over 52 (low complexity). We do this by calculating the RCSL value of only possibly ancestor rules, those in {~-,~~~~=A~BER,~EA,~EB}. 4.2 User Classification of Best Candidate 
Once selected, the best candidate is presented for user classification along with, if relevant, its support and confidence levels and any user defined objective interestingness criterion that may aid the user in making the classification (list of possible criteria in [6]). We ensure a fast and straightforward classification process by presenting the user with ancestor rules only: a user more readily interprets simple rules than complex ones, and can more easily identify the family of a simple rule. 
The RSCL of the rule is always presented with the best candidate, to be used by a user to determine when to stop the iterative process. More rules will usually be eliminated in the first few iterations of the algorithm than in future iterations. Once the RSCL falls below a given threshold for more than two consecutive iterations, the user is notified. At this time, the user decides whether it is still profitable to continue responding to questions when only a relatively small percent of the rules can be eliminated with each new classification made. 4.3 Processing of User Classification In this section, we detail the processing $l undergoes according to user classification, c, of the ancestor rule, r = a + b, other than the collection and storage of the information in the knowledge base we construct. To aid us in our analysis, we will use Claim 4.1. The claim is presented without its proof due to lack of space. Claim 4.1 Let A, B,C c A and b E A such that A,B,C # 0 and {b} u C = B. Let R be the set of association rules mined by a data mining algorithm with minimum support threshold s and minimum confidence threshold c. If A -+ B E R then A + C E R. 4.3.1 Not-true-Not-interesting classification Labeling T as NTNI implies (see Section 3.3) that T can be deleted from R, and that any rule p = A + B E R such that a E A and b E B can be deleted from R. In other words, we perform R = 0 \ famiZyn(r). Note that we did not eliminate rules of the form a -+ c for c # b. We may have eliminated rules of the form a -+ C where b, c E C. Since the rule a -+ b is not true, the rule a + C contains as much interesting information to a user as the rule a + C \ {b}, which according to Claim 4.1 exists in the original R. Thus, this elimination does not discard any potentially interesting rules to the user. 4.3.2 Not-True-Interesting Classification Labeling T as NT1 indicates (see Section 3.2) that the rule is not true and at the same time expresses a user X  X  interest in famiZys2(r). Let Tl = (a + BJb E B}, and Yz = {A + BJa E A, b E B : A\(a), B\(b) # @}, so that respectively. Patterns were classified by the WebMaster who was our user in this case. 
Figure 2: WWW logs DB results mining a1gorithm rem ter the 20th iteration approximately 16% of the rules remained, showing the fast elimination rate of the al-gorithm. A summary of the number of rules remaining after each of the first 20 iterations can be found in Fig-ure 2, where after the zeroth iteration we have 100% of the rules. Note that in some cases there is no decrease in the number of remaining rules between two iterations. 
Those are the iterations the domain expert classified the best candidate as  X  X nteresting X . Most of the classifica-tions the domain expert provided us were TNI. 
We complied this database from the transactions of an Israeli  X 1 store that sells groceries via tele-I z phone, fax and the Internet. Each [:I one of the 67,470 entries in this P 10 B 30 database describes, using 1,757  X  ;z ket: its contents, money spent on it and where the order was Figure 3: Grocery made. With so many different database results attributes in this database, we expected the mined rules to be more sparse, that is, that the ancestor rules would spawn smaller families. The outcome of the experiment supported our assumption. 
We found that only the first two ancestor rules had large families (with RSCL of over 10%). This brought about a more subdued decrease in the size of the list of rules, de-creasing by approximately 30% after the third iteration, but reaching half its original size only after the fourteenth iteration. This is a good example of how useful the RSCL value is as the it indicates the profitability of continuing the iterative elimination process to the user. Figure 3 summarizes the results of the first 20 iterations of the algorithms run over the set of 3,046 rules mined with support and confidence levels of 3.5%. Our user easily classified the rules we presented for classification, practi-cally all as TNI, reinforcing our comments in Section 1. 
