 Duncan Potts duncanp@cse.unsw.edu.au There are many situations wh en incremental learning is more suitable than a batch processing technique. If the input is a continuous stream of data it may not be tractable to record all o f its history and execute a batch algorithm each time an output is required. For example an agent operating in a real-time environment may need to constantly proces s the latest sensor infor-mation to determine the next action. A large pro-cessing delay may be unacceptable, and some form of incremental learning algor ithm is required that scales linearly with the incoming data.
 In this paper we shall focus on the problem of induc-ing a model of the environment to be used for con-trol, however the methods developed have a potentially much wider applicability. In order to control an agent it is necessary to understand how the world evolves, and how the agent X  X  actions affect this evolution. This knowledge is often obtain ed by constructing a model of the environment. A non-linear stationary model of a continuous dynamic environment can be formulated in continuous time as where z is an n dimensional state vector and u is an m dimensional input (  X  z istherateofchangeof z with re-spect to time) (Slotine &amp; Li, 1991). The problem then becomes one of incrementa lly learning an approxima-tion to the function f using the states experienced by the agent.
 Standard parametric methods for learning f incremen-tally include neural networks, locally weighted learning (LWL) (Atkeson et al., 1997) and radial basis functions (RBFs). For a neural netwo rk it is difficult to deter-mine in advance the numbers of layers and units, and training can be slow and prone to local minima. For both LWL and RBFs the range of input values and approximate curvature of the function is required to determine the number, size and shape of the weight or basis functions. In addition the number of parameters scales exponentially with dimensionality.
 When there is little prior knowledge it may be benefi-cial to consider non-parame tric alternatives where the number of learning parameters is adjusted by the algo-rithm. Schaal and Atkeson (1998) developed a LWL-based algorithm that not only dynamically allocates models as required, but also adjusts the shape of each local weighting function. Enhanced dimensionality re-duction has also been incorporated (Vijayakumar &amp; Schaal, 2000). These algorithms perform well for data with a low intrinsic dimensionality, even if the input data itself has a high number of dimensions. However there are several paramet ers that are hard to specify without trial and error, and the range of inputs and a metric over the input space must be defined in ad-vance.
 A decision tree with a linear model in each leaf (a linear model tree) can also a pproximate a non-linear function. The induction of such trees in a batch man-ner has received significant a ttention in the literature, however the incremental induction of model trees has not been previously addressed.
 The contribution of this paper is to develop incremen-tal methods for growing linear model trees, including a node splitting rule, a stopping rule and a method for pruning. The algorithm is empirically tested in three domains and compared with existing incremen-tal, instance-based and batch methods.
 Section 2 gives a brief overview of linear model trees and Section 3 surveys relat ed work on both the incre-mental induction of classification trees and the batch induction of linear model trees. Section 4 describes the algorithm, Section 5 pres ents the experimental re-sults, and finally we conclude and suggest areas for future work. Learning each component of  X  z in (1) can be formulated as a typical regression problem where f ( x ) is the component of  X  z and x =[ z T u T 1] is a d = n + m +1 dimensional column vector of regres-sors (the constant regressor is added to simplify the notation). The observed values y are corrupted by in-dependent zero-mean Gaussian noise with unknown variance  X  2 . The aim of a regression analysis is to find an approximation  X  f ( x )to f ( x ) that minimises some cost function (e.g. sum of squared errors) over a set of training examples.
 For a linear model tree  X  f ( x ) is a decision tree with a linear model in each leaf. The decision tree partitions the input space and within each leaf where  X   X  is a column vector of d parameters. The linear least squares estimate of the function f ( x )isthevalue of  X   X  that minimises over the N training examples x i ,y i in the leaf. Defin-ing the N  X  1 vector y and the N  X  d matrix X the linear least squares estimate is The residual for each example is the difference between the value y i and the prediction  X  f ( x i ), and the resid-ual sum of squares (RSS) is the minimum value of J (occurring when  X   X  =  X   X  LS ). Both  X   X  LS and RSS can be calculated incrementally using the recursive least squares (RLS) algorithm. The difficulty lies in defin-ing the tree structure itself. 3.1. Incremental Tree Induction Utgoff et al. (1997) consider the incremental induc-tion of classification trees where each leaf determines an element from a finite set of classifications. One of their aims is that the increm ental algorithm generates an identical tree to one built in a batch manner, and therefore that the resultant tree is invariant to the or-der in which the examples are processed. To achieve this all examples must be stored, and although the average incremental updat e is fast, in some cases it can take longer than re-building the entire tree. Our goal, on the other hand, is a fully incremental algo-rithm that is guaranteed to be fast. In addition their learning technique does not extend to model trees be-cause the best split can no longer be determined from a small number of statistics kept in the node. 3.2. Batch Induction of Model Trees The general approach to building trees from a train-ing set is to start at the root and perform top down induction. At each node the training set is recursively partitioned using a splitting rule until the tree is suffi-ciently large. A number of alternative rules have been proposed for the induction of linear model trees. De-note the N examples at a particular node as x i ,y i .A potential split divides these examples into two subsets. Denote the N 1 examples in the first subset x i 1 ,y i 1 , and the N 2 in the second subset x i 2 ,y i 2 . M5 (Quinlan, 1993; Frank et al., 1998) chooses the split that minimises a measure of the standard devi-ation of the y values, and HTL (Torgo, 1997) min-imises the mean square error of the y values, measur-ing error from the average y value. These measures are closely related to those originally used by Breiman et al. (1984) to grow regression trees with a constant value in each leaf. However when linear models are fitted to each leaf, distance to the mean y value is an inappropriate measurement of error and distance to the linear regression plane should be used instead. RETIS (Karalic, 1992) minimises the total RSS over the two subsets where  X  f k ( x ) is the linear least squares estimate for subset k (see Figure 1). The number of potential split values increases with the number of examples (assuming the regressors are drawn from a continuous set), and  X   X  LS must be cal-culated using (3) for the two subsets of examples on each side of every split to mi nimise (4). It therefore quickly becomes intractable to test all potential split values with this method.
 Alexander and Grimshaw (1996) reduce the complex-ity by only considering simple linear models (with a single regressor) in each leaf, but this limits the rep-resentation to surfaces with axis-orthogonal slopes. Malerba et al. (2001) build up a multivariate linear model using a sequence of simple linear regressions which also simplifies the split selection, however splits near the root are therefore only selected on the basis of a few regression components and comprehensibility is lost due to the transformation of regressors. Dobra and Gehrke (2002) determine the split by separating two Gaussian clusters in the regressor attributes en-abling oblique splits to b e found. Li et al. (2000) also find oblique splits using principal Hessian directions, however the procedure is complex and requires inter-action from the user and an iterative process to find the split value.
 These methods are effectiv e in a batch setting where typically an overly large tree is grown initially, and a pruning process is later applied to try and optimise the prediction capability on unseen examples. For an incremental algorithm, h owever, it is desirable to limit the growth of the tree in the first place and avoid any complex pruning procedure. The algorithm must therefore not only determine where to make a split but also when , and the splitting rules considered so far do not help. There is clearly no need to make any split if the examples in a node can all be explained by a sin-gle linear model, however the node should be split if the examples suggest that two separate linear models would give significantly better predictions. Fortunately this problem has also received attention in the statistics community. Both the SUPPORT (Chaudhuri et al., 1994) and GUIDE (Loh, 2002) com-pute the residuals from a linear model and compare the distributions of the regressor values from the two sub-samples associated with the positive and negative residuals. Using statistical tests it is possible to deter-mine the likelihood of the examples occurring under the hypothesis that they were generated from a sin-gle linear model, and therefore a confidence level can be assigned to the split. An incremental algorithm has been developed with the statistical tests used by SUPPORT, however predicti ons are more accurate us-ing an alternative statistica l test based on the residual sums of squares. The details of this test are explained in the next section. Section 4.1 presents the splitting rule used in the in-cremental model tree induction (IMTI) algorithm, and Sections 4.2 and 4.3 describe incremental methods for stopping the growth of the tree and pruning. Section 4.4 explains how smoothing is used to obtain more ac-curate gradient estimates a nd Section 4.5 analyses the complexity of IMTI. 4.1. Splitting Rule The question of whether the two linear models on each side of a potential split give a better estimation of the underlying function f ( x ) than a single linear model can be tested as a hypothesis. The null hypothesis is that the underlying function is linear over the entire node ( H 0 : f ( x )= x T  X  ) while the alternative hypoth-esis is that it is not. Three linear models are fitted to the examples in the node as in Figure 1;  X  f ( x )using all N examples,  X  f 1 ( x )usingthe N 1 examples lying on one side of the split, and  X  f 2 ( x )usingthe N 2 exam-ples on the other side. The residual sums of squares are also calculated for each linear model, and denoted RSS 0 , RSS 1 and RSS 2 respectively. The two smaller linear models will always fit the data at least as well, and RSS 1 +RSS 2  X  RSS 0 . However if the alternative hypothesis is true RSS 1 +RSS 2 will be significantly less than RSS 0 , and this can be tested using the Chow test, a standard statistical test for homogeneity amongst sub-samples (Chow, 1960). Under the null hypothesis it can be shown that the statistic is distributed according to Fisher X  X  F distribution with d and N  X  2 d degrees of freedom ( d is the dimension-ality as defined in Section 2). The candidate split least likely to occur under H 0 should make the best choice, and this corresponds to the F statistic with the smallest associated p -value (probability in the tail of the distribution). This method was used by Sicilano and Mola (1994) to grow linear model trees in a batch setting. Denote the smallest p -value as  X  .Thekey advantage of such a statistical test in an incremental implementation is that if the probability  X  is not small enough to discount H 0 with the desired degree of con-fidence, no split should be made until further evidence is accumulated.
 The intractability of maintaining linear models on each side of every split value has already been noted, there-fore a constant number  X  of candidate split values is defined in advance for each regressor. In each leaf a linear model is maintained on both sides of the  X  ( d  X  1) candidate split values, and  X  is calculated from these models. Table 1 defines the steps needed to decide whether to split a leaf node given a training exam-ple. In our implementation  X  split =0 . 01% and  X  = 10. Therefore a split is only ma de when there is less than a 0.01% chance that the data in the node came from a single linear model. Such a low level reduces the number of incorrect splits when testing many times. Reducing  X  appears to have little effect on the results with the advantage of less computation. 4.2. Stopping Rule To illustrate the need for a stopping rule, assume a lin-ear model tree is being gro wn to approximate a smooth convex function. As more examples are observed, the statistical splitting rule will repeatedly split the leaf nodes of the tree. The tree will grow without bound, fracturing the input space into a large number of linear models that together result in a very good approxima-tion. Setting the confidence limit on the statistical test higher will only slow this process.
 It is, however, often desirable to limit the growth of the tree. The parameter is the difference between the variance estimate using a single linear model and the pooled variance estimate using separate linear models on each side of a can-didate split. As the model tree grows and forms a more accurate approximation,  X  decreases. Splitting is halted if  X  falls below a certain threshold  X  0 (see Table 1).
 An advantage of the tree representation in an incre-mental setting is that  X  0 can be lowered if the approx-imation is not sufficiently accurate. The tree will grow from its leaves to form a more detailed model, and no re-building or internal restructuring is required. 4.3. Pruning A fully incremental algorithm that does not store any training examples cannot perform cross-validation, and therefore many standard pruning techniques are not possible. However if a bad split has been made, it is desirable to identify and prune branches of the tree that are not contributing t o the overall accuracy. In Section 4.1 the p -value associated with the F statis-tic was seen to give the probability that the examples in the node could have come from a single linear model. Hence a high p -value at an internal node indicates that it may be beneficial to prune the node X  X  children. The F statistic (5) is therefore maintained in each inter-nal node, and pruning takes place if the corresponding p -value rises above a certain threshold  X  prune .Inthe experiments  X  prune = 10%. 4.4. Smoothing Although we have focussed on learning an approxima-tion to the function f , what we are really interested in for control purposes is the derivative of f with respect to the state z and input u . A popular method of non-linear control is to linearise the system about a certain operating point ( z = z 0 , u = u 0 ) using the Taylor series expansion  X  z = f ( z 0 , u 0 )+ where the derivatives are evaluated at the operating point. Ignoring the higher order terms (h.o.t.) we obtain the standard equations for a linear system which have been intensively studied in control theory. From these equations we ca n determine the local sta-bility of the system, and control policies to move the state along all possible local trajectories. However the linear model tree lacks continuity, result-ing in poor gradient estimates. Therefore the esti-mates are smoothed using a Gaussian kernel. From the linear model (2) it is clear that the gradient esti-mate in each leaf k is simply the parameter vector  X   X  k , hence the smoothed gradient estimate over all L leaves is  X   X  f ( x )  X  x where w k ( x ) is the Gaussian kernel The centre of the leaf in regressor space is c k ,and the elements of the diagonal matrix D k are the in-verse squares of each leaf width component. The same smoothing process is also applied to the actual func-tion estimates  X  f ( x ) although with less improvement. The value  X  = 16 is used for the smoothing parameter. 4.5. Training Complexity Assuming that the stopping rule has limited the growth of the tree, the time taken to pass each train-ing example down to a single leaf in the tree according to the tests in the intermediate nodes is bounded by the depth of the tree. In the leaf O (  X d )modelsare updated, and each RLS update takes O ( d 2 ). Hence the overall training complexity is O ( N X d 3 )where N is the total number of examples. The algorithm there-fore fulfills our goal of scaling linearly with the number of examples. Also pleasing is the polynomial increase with dimensionality, and the fact that a strict bound can be placed on the worst ca se processing time for a training example (if the tree has stopped growing). The new incremental model tree induction (IMTI) al-gorithm is empirically tested in three domains, and results are compared with four alternative algorithms: 1. A single linear model updated using RLS. 2. The k -nearest neighbour instance-based approxi-3. The incremental adaptive locally weighted learn-4. The batch model tree induction algorithm SUP-The batch algorithm from which the IMTI splitting rule was derived (Sicilano &amp; Mola, 1994) does not scale to the numbers of examples considered here, and there-fore we compare with SUPPO RT which performs bet-ter than both CART (Breiman et al., 1984) and M5 (Frank et al., 1998) on these problems.
 RFWR has since been adapted to improve its dimen-sionality reduction capability (Vijayakumar &amp; Schaal, 2000), however the test dom ains do not contain redun-dant dimensions and the original algorithm, without any ridge regression parameters, is more competitive. IMTI, RFWR and SUPPORT all construct a piecewise linear approximation. Parameters in each algorithm limit the number of linear models, resulting in a cer-tain degree of asymptotic approximation error. These parameters are optimised in each domain to give the best performance while keeping the number of models to within a comparable range.
 The RFWR initial distance metric D 0 is optimised matrix), the penalty  X  is optimised over the set { optimised over the set { 2 . 5 , 5 , 10 , 25 , 50 , 100 , 250 The SUPPORT parameters are MINDAT=30, v =10 and both f and  X  are optimised over the set { 0 . 1 , 0 . 2 , 0 . 3 , 0 . 4 , 0 . 5 } .
 Both 10-NN and RFWR require a metric to be de-fined over the input space. For these algorithms each regressor is scaled to the range (  X  1 , +1) and the met-ric is the standard Euclidean distance. The observed y values are not scaled.
 Training is performed using a single stream of non-repeating examples, such as would be obtained by an agent in the real world. The non-increm ental SUP-PORT algorithm is re-run for each point on the fol-lowing graphs.
 In all domains the measurement noise is (a vector of) independent zero-mean Gaussian noise with variance  X  2 and  X  =0 . 1. Error bars and numerical errors re-ported in tables indicate one unbiased estimate of the standard deviation over 20 trials. 5.1. 2D Test Function Initial tests are performed using the same function as Schaal and Atkeson (1998) Training examples are drawn uniformly from the square  X  1  X  x 1  X  +1 ,  X  1  X  x 2  X  +1. The algorithms are tested using 2000 examples drawn in a similar manner, but without noise. Figure 2 plots the normalised root mean square er-ror (nRMSE) against the number of examples. IMTI uses the stopping parameter  X  0 =10  X  3 .RFWRuses the parameters specified in Schaal and Atkeson (1998) and learning rates set to 250. SUPPORT uses f =0.1 and  X  = 0.4. The single linear model can only achieve nRMSE = 1.0. The graph shows that IMTI accurately learns the function with fewer training examples than RFWR, and surprisingly it s performance is even com-parable to the batch SUPPORT algorithm.
 Table 2 reports the final number of local models built by each algorithm and the number of parameters within each local model. IMTI also uses less models than RFWR. 5.2. Pendulum A pendulum rotating 360  X  around a pivot is a simple non-linear dynamic environm ent with a closed form for the gradient, allowing gradient errors to be examined. The dynamic model of a pendulum can be written where z =[  X   X   X  ] T ,  X  is the pendulum angle, g is gravity, m = l = 1 are the mass and length of the pendulum,  X  =0 . 1 is a drag coefficient and u is the torque applied to the pendulum. Define x =[ z T u ] T and y =  X  z + . Training examples of y , x are drawn uniformly from the input domain  X   X   X   X   X  +  X ,  X  5  X   X   X   X  +5 and  X  5  X  u  X  +5. The algorithms are tested using 5000 examples drawn in a similar manner, but without noise. In order to examine gradient predictions, we define the normalised root mean square gradient error as When the gradient estimat e is correct everywhere nRMSE(Grad) = 0, and when the gradient estimate is zero everywhere nRMSE(Grad) = 1.
 Figure 3 plots the mean (over both  X  z components) nRMSE(Grad) against the number of examples. IMTI uses  X  0 =10  X  3 .RFWRuses D 0 =5 I ,  X  =10  X  7 and learning rates set to 5. Gradients are extracted from RFWR by applying the same weighting kernels to the gradients of each local model that are applied to the predictions themselves. SUPPORT uses f =0.1and  X  = 0.5. It is not possible to obtain gradients from 10-NN. The single linear model achieves nRMSE(Grad) = 0.76. The graph shows that IMTI can learn accu-rate gradients, and can therefore effectively estimate the linear model given by F , G and c in (7) for the pendulum (8).
 Table 3 reports the final number of local models and the number of parameters within each local model. A separate model tree is induced for each component of y and therefore the local IMTI and SUPPORT models are half the size of the local RFWR models. IMTI uses less overall parameter s and forms a more accurate gradient estimate than RFWR. 5.3. Pendulum on a Cart The problem of swinging up a pendulum on a cart demonstrates the behaviour of the algorithm in a more complex domain. The aim is to balance the pendulum in the vertical position by applying a horizontal force to the cart. The physical parameters of the pendu-lum are the same as in the previous section (except  X  = 0), and the cart has a mass of 1. The system is highly non-linear when the pendulum is allowed to rotate through 360  X  . So far we have only considered continuous time models, however the analysis applies equally to models formulated in discrete time. For the cart and pendulum the discrete time model is where z =[ xv X  X  ] T , x (limited to  X  2) and v are the position and velocity of the cart,  X  and  X  are the angle and angular velocity of the pendulum, and u (limited to  X  7) is the force applied to the cart. The system is sampled 20 times per second. It is not possible to determine a closed form for  X  or  X  and therefore the next state of the system is calculated using successive Euler integrations with a time step of 0.01 seconds. Instead of sampling randomly across the state space, the system is initialised at rest with the pendulum hanging vertically downward. A simple control strat-egy was hand-coded to repeatedly swing up the pen-dulum and balance it for a short period using the ob-served state vector y k = z k + . The regressors for y k are the previous state z k  X  1 and action u k  X  1 .The sequence of states generate d is given directly to the learner without changing the order, so that consecutive regressors are very highly correlated. The algorithms are tested using 10,000 examples randomly drawn from a similar sequence, but without noise. Figure 4 plots the mean (over all z components) nRMSE against the number of examples. IMTI uses  X  0 =5  X  10  X  3 , and results are shown both with and without pruning. RFWR uses D 0 =10 I ,  X  =10  X  5 and learning rates set to 50. SUPPORT uses f =0.2 and  X  = 0.5. The single linear model achieves nRMSE = 0.13. Again IMTI learns a more accurate model from fewer examples than RFWR. Pruning slightly improves the prediction accuracy and results in less variation over the different trials.
 Table 4 reports the final number of local models and the number of parameters within each model. It shows that pruning significantly reduces the number of linear models but the variation remains high. In this domain RFWR forms its approximation with over four times as many parameters as the model tree algorithms. This paper describes and evaluates an algorithm that incrementally induces lin ear model trees. The algo-rithm can learn a more accurate approximation of an unknown function from fewer examples than other in-cremental methods, and in addition the induced model can contain less parameters. The learner is even com-parable to a batch algorithm that induces the same type of tree.
 In the algorithm the trade-off between the number of linear models built and the approximation error can easily be controlled using the single parameter  X  0 ,and there are no learning rates to be tuned, thus avoiding a major cause of instability in many gradient descent systems. Other benefits of the algorithm are that no initial knowledge regarding the size of the input do-main is required, and no metric need be defined over this space (as opposed to RFWR which requires knowl-edge of the input domain to set the initial size of the local models, and instance-based methods that require a metric). Pruning, while having little impact in the smaller domains, is seen to reduce the tree size with no detrimental effect on pred iction accuracy in a more complex environment.
 Having developed a method for rapidly learning non-linear models of dynamic en vironments, future work will concentrate on control. Nakanishi et al. (2002) have developed a provably stable adaptive controller based on the representation learnt by RFWR, and per-haps a similar approach can be applied to incremen-tally induced linear model trees.

