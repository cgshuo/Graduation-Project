 Named Entity Recognition (NER) is a well-established task that has immense impor-tance in many Natural Language Processing (NLP) application areas such as Informa-tion Retrieval [Mandl and Womser-Hacker 2005], Information Extraction [Pasca et al. 2006], Machine Translation [Babych and Hartley 2003], Question Answering [Pizzato et al. 2006], and Automatic Summarization [Nobata et al. 2002] etc. The objective of NER is to identify and classify every word/term in a document into some predefined categories such as name, location name, organization name, miscellaneous name (date, time, percentage, and monetary expressions, etc.), and none-of-the-above.
The main approaches to NER can be grouped into three main categories, namely rule-based, machine learning-based, and hybrid approach. Rule-based approaches focus on extracting names using a number o f handcrafted rules. Generally, these systems [Aone et al. 1998; Humphreys et al. 1998; Mikheev et al. 1998, 1999] con-sist of a set of patterns using grammatical (e.g., part of speech), syntactic (e.g., word precedence), and orthographic features (e.g., capitalization) in combination with dic-tionaries. These kinds of systems have better results for restricted domains and are capable of detecting complex entities that are difficult with learning models. However, rule-based systems lack portability and robustness, and furthermore the high cost of maintenance of rules increases even when the data is slightly changed. These types of systems are often domain dependent, language specific, and do not necessarily adapt well to new domains and languages.

Researchers nowadays are popularly using machine-learning approaches for NER because these are easily trainable, adaptable to different domains and languages, and their maintenance is also less expensive. The ML techniques can be grouped into the following three categories: supervised, semi-supervised, and unsupervised. The idea of supervised learning is to study the features of positive and negative example of NE over a large collection of annotated documents and design rules that capture instances of a given type. Some of the representative supervised machine learning approaches used in NER are Hidden Markov Model (HMM) [Bikel et al. 1999; Miller et al. 1998], Maximum Entropy (ME) [Borthwick 1999; Borthwick et al. 1998], De-cision Tree [Bennet et al. 1997; Sekine 1998], and Conditional Random Field (CRF) [Lafferty et al. 2001; McCallum and Li 2003]. The main shortcoming of supervised learning is the requirement of a large annotated corpus, which is very difficult to ob-tain for many resource-constrained languages. The unavailability of such resources and the prohibitive cost of creating them lead to two alternative learning methods: semi-supervised and unsupervised. The term semi-supervised (or, weakly supervised) is relatively recent. The main technique for semi-supervised approach [Collins and Singer 1999; Riloff and Jones 1999; Yangarber et al. 2002] is bootstrapping and in-volves a small degree of supervision, such as a set of seeds, for starting the learning process. The typical approach in unsupervised learning is clustering. For example, one can try to gather NEs from clustered groups based on the similarity of context. There are other unsupervised methods too. Basically, the techniques rely on lexical resources (e.g., WordNet), on lexical patterns and on statistics computed on a large unannotated corpus. The typical unsupervised systems are Alfonseca and Manand-har [1999], Shinyama and Sekine [2004], and Etzioni et al. [2005]. In hybrid systems [Mikheev et al. 1998; Srihari et al. 2002; Yu 2007], the goal is to combine rule-based and machine learning-based methods, and develop new methods using strongest points from each one. Although hybrid approaches can get better results than some other ap-proaches weakness of handcraft rule-based NER surfaces exists when there is a need to change the domain and/or language of data. Besides the above-mentioned works, there are other existing works. The majority of the languages covered include English, most of the European languages, and some of the Asian languages such as Chinese, Japanese, and Korean. India is a multilingual country with great linguistic and cultural diversities. People speak in 22 different official languages that are derived from almost all the dominant linguistic families. However, the works related to NER in Indian languages have started to emerge only very recently. Named Entity (NE) identification in Indian languages is more difficult and challenging compared to others due to a number of facts.  X  Lack of capitalization information, which is an important cue for NE identification in English.  X  Indian names are more diverse in nature and many of these appear in the dictionary as common nouns.  X  Free word order nature of the Indian languages.  X  Resource-constrained environment, that is, non-availability of corpus, annotated corpus, name dictionaries, morphological analyzers, p art of speech (POS) taggers, etc., in the required measure.

Most of the works in the area of NER related to Indian languages cover a few lan-guages such as Bengali, Hindi, and Telugu. An unsupervised approach for NER in Bengali is described in Ekbal and Bandyopadhyay [2007], where they reported two different NER models, one using lexical contextual patterns and the other using lin-guistic features along with the same set of lexical contextual patterns learned from an unlabeled corpus. A HMM-based supervised NER system was reported in Ekbal et al. [2007], where more contextual information was introduced during emission probabil-ities and NE suffixes were used for handling the unknown words. More recent works in the area of Bengali NER are based on CRF [Ekbal et al. 2008], SVM [Ekbal and Bandyopadhyay 2008a], and voting [Ekbal and Bandyopadhyay 2009].

A CRF-based Hindi NER system can be found in Li and McCallum [2004] that uses feature induction to automatically construct the features that most increase the con-ditional likelihood. Other works for Hindi NER can be found in Patel et al. [2009] using rules and in Saha et al. [2008] using a hybrid feature set (linguistic and statis-tical) based ME approach. Srikanth and Murthy [2008] developed an NER system for Telugu and tested it on several datasets from the Eenaadu and Andhra Prabha news-paper corpora for person, location, and organization tags. Gali et al. [Shishtla et al. 2008] developed a CRF-based system for English, Telugu, and Hindi. They suggested that a character n -gram based approach is more effective than word-based models to increase the recall of NER systems. Some more systems on NER in Indian languages, especially in Bengali, Hindi, Telugu, Oriya, and Urdu using different approaches are reported in the IJCNLP-08 Shared Task on NER for South and South East Asian Lan-guages (NERSSEAL) 1 . Other than these languages, a CRF-based Tamil NER system was proposed in Vijayakrishna and Sobha [2008] for the tourism domain. This ap-proach can take care of morphological inflections of NEs and can handle nested tagging with a hierarchical tagset containing 106 tags. Classifier ensemble 2 is a new direction of machine learning. In the literature [Florian et al. 2003; Ekbal and Bandyopadhyay 2009], it has been shown that the combination of multiple classifiers could be more effective compared to any individual one for NER.
The main idea behind classifier ensemble is that ensembles are often much more accurate than the individual classifiers that make them up. Usually the members of an ensemble are generated either by applying a single learning algorithm (i.e., using homogeneous classifiers) [Dietterich 2002] or using different learning algorithms (i.e., using heterogeneous classifiers) over a dataset [Wolpert 1992]. Two basic approaches to combine the outputs of several classifiers are majority voting and weighted voting [Dietterich 2002]. The existing classifier ensemble techniques can be grouped into sub-sampling the training examples such as bagging [Breiman 1996] and boosting [Freund and Schapire 1995a], manipulating the input features [Cherkauer 1996], manipulat-ing the output target such as Error Correct ing Output Codes (ECOC) [Dietterich and Bakiri 1995], and injecting randomness in the learning algorithm [Kolen and Pollack 1991].

A major factor in classifier ensemble is that the individual classifiers should be as diverse as possible. In the well-known ensemble techniques such as bagging and boosting, such diversities are achieved by manipulating the training examples in order to generate multiple hypotheses. The base classifier is trained several times, each time with a different subset of the training examples and thus creating different classifiers. Finally there should be a method to combine the outputs of these sets of classifiers. This method is effective for unstable learning algorithms such as neural networks, decision trees, etc. In the case of bagging, at each run the learning algorithm is trained with a training set that consists of a sample of m training examples drawn randomly with replacement from the original training set of m items. The basic idea behind boosting [Freund and Schapire 1995a] is to train a series of diverse classifiers and to iteratively focus on the hard-to-learn training examples. It is again divided into two steps. In the first step a number of classifiers are generated with various versions of the training samples, and then in the second step the classifiers are combined together to produce a more powerful one.

AdaBoost [Freund and Schapire 1995b], short for Adaptive Boosting, is a very popu-lar machine learning algorithm. This is a meta-algorithm, and can be used in conjunc-tion with many other learning algorithms to improve their performance. AdaBoost is also adaptive in the sense that subsequent classifiers built are tweaked in favor of those instances misclassified by previous classifiers. The main drawback asso-ciated with AdaBoost is that it is sensitive to noisy data and outliers; however, in some problems it can be less susceptible to the overfitting problem than most learning algorithms.

AdaBoost calls a weak classifier repeatedly in a series of rounds t =1 ,..., T .For each call a distribution of weights D t is updated that indicates the importance of exam-ples in the dataset for the classification. On each round, the weight of each incorrectly classified example is increased (or alternatively, the weights of all correctly classified examples are decreased), so that the new classifier focuses more on those examples. In this way the T individual classifiers are formed. These classifiers are then combined together into a single system using some weighted voted approach, where the weight of vote depends on the error rate of the individual classifier.

Stacking [Wolpert 1992] is another important classifier ensemble technique which basically follows a layered architecture. At the very first level, classifiers are trained using the original dataset and each classifier outputs a prediction for each token. Suc-cessive layers receive the predictions of the layer immediately preceding it as an input. Finally at the top level, a single classifier, also called meta-classifier, outputs the final prediction. Again the overall performance depends on the individual classifiers as well as on the effective classifier selection at the second level. Another problem of stacking is how to obtain the right combination of base-level classifiers and the meta-classifier especially in relation to each specific datas et. Error-correcting-co de (ECOC) is another general technique for constructing a good ensemble of classifiers. Here each class is encoded as an L -bit code vector. When the L classifiers are applied to classify a new sample, their predictions are combined into a L -bit string. But it is again very tricky to choose the appropriate codewords L for each class.

Thus, it can be noted that all the existing ensemble techniques should have a way of combining the decisions of a set of classifiers. Existing approaches combine the outputs of all classifiers either by using majority voting or by using weighted voting. The weights of votes depend on the error rate/performance of individual classifiers. But none of the existing techniques quantifies the amount of vote for each output class in each classifier. However, in reality, in an ensemble system all the classifiers are not good at detecting all types of output classes. For example, in case of NER, some classifiers could be most effective at detecting person names whereas some are good to detect location names. In case of weighted voting, weights of voting should vary among the different output classes in each classifier. The weight should be high for that particular output class for which the classifier performs well. Otherwise, the weight should be low for the output class for which its output is not very reliable. So, it is a crucial issue to select the appropriate weights of votes for all the classes per classifier. In this article, we develop a genetic algorithm (GA) based method to find the appropriate weights of votes for each output class in each classifier. The method is explained below with a more general example:
Suppose there are four classifiers C 1 , C 2 , C 3 ,and C 4 ; and three classes cl 1 , cl 2 ,and cl . Let us assume that depending on the training set and the set of features used, classifier C 1 is more efficient to classify the points in class cl 1 . Similarly, depending on the configuration, classifiers C 2 , C 3 ,and C 4 are more efficient in classifying the points is not desirable in almost all real-world problems. In most of the practical applications, the reliabilities of predictions vary among the various classes in any classifier. By the proposed GA-based approach we can determine the appropriate values of  X  s such that  X  on the effectiveness of the classifiers C 1 and C 4 , the proposed GA-based approach will determine these values automatically. Another important note is that GA-based ap-that though C 1 is more confident to classify class cl 1 , it is also eligible to vote for the other classes. The key advantages (or, novelty) of our proposed approach over the ex-isting ensemble techniques are twofold, that is, (i) unlike previous ensembles (such as stacking), our GA-based approach does not require any technique to select the most suitable subset of classifiers from a set of base classifiers. In contrast, our proposed technique does not discard any classifier during ensemble and (ii) rather than assign-ing the same weights to all the classes in a classifier, like any other existing techniques, it effectively finds the proper weights of all the eligible classes depending upon the pre-diction confidence.

The underlying motivations behind our work are as follows. (1) We wanted to develop a new method of combining the outputs of many classifiers. (2) Existing approaches don X  X  quantify the amount of votes for all the classes in (3) Another important motivation of the proposed approach is the use of GA for
The effectiveness of classifier ensemble has been explored in the NLP applications such as noun-phrase segmentation and NER. Carrears et al. [2002] reported an ensem-ble system in the CoNLL-2002 shared task that achieved the the recall, precision, and F -measure values of 81.4%, 81.38%, and 81.39%, respectively, for Spanish and 76.29%, 77.83%, and 77.05%, respectively, for Dutch. They used ECOC for combining different binary classifiers, based on AdaBoost. Wu et al. [2003] presented stacking and voting methods for combining strong classifiers such as boosting, SVM, and TBL in CoNLL-2003 shared task [Tjong Kim Sang and De Meulder 2003]. They obtained the recall, precision, and F -measure of 82.31%, 83.06%, and 82.69%, respectively for the English dataset. Florian et al. [2003] reported a NER system by combining four heterogenous classifiers, namely HMM, ME, transformation-based learning, and robust linear clas-sifier. This system showed the best performance in CoNLL-2003 shared task [Tjong Kim Sang and De Meulder 2003] with the help of unannotated data and an additional NE tagger. In Indian languages, Ekbal and Bandyopadhyay [2009] presented a voted NER system for Bengali by combining three different classifiers such as ME, CRF and SVM. They used word-level and contextual features, gazetteers, post-processing tech-niques, and unlabeled data to improve the performance in each of the classifiers as well as of the overall system. On the other hand, our system (i) is based on a relatively sim-pler set of features, easily derivable for many languages, and (ii) does not use any addi-tional domain dependent resources and/or tools, but still achieves the state-of-the-art performance.

A very preliminary version of the present approach is available at Ekbal and Saha [2010], where only ME was used as a base classifier. But in the current article we use heterogenous classifiers such as ME, CRF, and SVM as the underlying classification techniques, elaborately explain the algorithm with more details, evaluate it for four different Indian languages and English, and compare the performance with the three conventional baseline models as well as other existing techniques. We have also shown the effects of ensemble size and training set size on the overall system performance. In addition, we also develop a single objective optimization based feature selection tech-nique. The classifiers trained with the feature sets identified by the feature selection technique achieve higher performance than the corresponding best individual classi-fier. This feature selection technique is used as another baseline to compare with the proposed classifier ensemble. In this article, we propose a novel technique for classifier ensemble based on GA and evaluate it for NER. We use ME, CRF, and SVM frameworks as the base classi-fiers. Depending on the different combinations of the available features and/or feature templates, several versions of these classifiers are generated. All the classifiers make use of a set of features that are language independent in nature, and can be easily ob-tained for almost all the languages with a little effort. Thereafter, GA is used to search for the appropriate weighted vote based classifier ensemble. Instead of searching for the best performing individual classifiers, our main focus is to investigate the appro-priate weights for voting. We use real encoding. Weights for voting of each classifier for every output classes are encoded in a chro mosome. Mutation and crossover operators are modified accordingly. A new mutation operator is used to handle real encoding. Adaptive mutation and crossover operators are used to accelerate the convergence of GA. We also use elitism.

The proposed approach is evaluated for four resource-poor languages, namely Ben-gali, Hindi, Telugu, and Oriya. In terms of native speakers, Bengali is the fifth popu-lar language in the world, second in India and the national language in Bangladesh. Hindi is the third most spoken language in the world and the national language of In-dia. Telugu and Oriya are the other two popular languages and predominantly spoken in the southern and eastern parts of India, respectively. We manually annotate a por-tion, containing approximately 250,000 wordforms, of the Bengali news corpus [Ekbal and Bandyopadhyay 2008c] with a coarse-grained NE tagset of four tags namely, PER (Person name), LOC (Location name), ORG (Organization name), and MISC (Miscel-laneous name). We also use the IJCNLP-08 NER on South and South East Asian Languages (NERSSEAL) 3 . Shared Task data of around 100K wordforms that were originally annotated with a fine-grained tagset of twelve tags. For Hindi, Telugu, and Oriya, we use the datasets of the NERSSEAL shared task. Evaluation results yield the recall, precision and F -measure values of 92.08%, 92.22%, and 92.15%, respectively for Bengali; 96.07%, 88.63%, and 92.20%, respectively for Hindi; 78.82%, 91.26%, and 84.59%, respectively for Telugu; and 88.56%, 89.98%, and 89.26%, respectively for Oriya. Finally, we evaluate the proposed approach for the CoNLL-2003 shared task [Tjong Kim Sang and De Meulder 2003] English data. Evaluation yields the overall recall, precision, and F -measure values of 88.72%, 88.64%, and 88.68%, respectively. This is comparable to that of the best system [Florian et al. 2003] of CoNLL-2003 shared task. The best system showed the recall, precision, and F -measure values of 88.54%, 88.99%, and 88.76%, respectively, with a classifier-combination experimen-tal framework that used four diverse classifiers. It should be noted that they made use of more complex set of features, gazetteers, and an additional NE tagger. But they did not provide any information about how their system performs without any domain knowledge and/or external resources. In contrast, our proposed algorithm is based on a very simple set of features and does not use any domain knowledge but shows reasonably good performance. Results for all the languages show that the vote-based classifier ensemble identified by GA outperforms all the individual classi-fiers as well as the three conventional baseline ensembles, out of which one is based on traditional majority voting and the other two are based on weighted voting. Comparisons of the proposed method to some existing ensemble techniques such as stacking [Wolpert 1992] and ECOC (Error correcting output code) [Dietterich and Bakiri 1995] are also shown. For Bengali, we have also compared our proposed tech-nique with a QBC (Query by committee) [Seung et al. 1992] based active learning method.

In a part of the article, we also formulate the problem of feature selection in any classifier under the single objective optimization framework. Thereafter, a GA-based technique is used to solve this problem. This is used as another baseline. Experimental results also suggest that our proposed method performs superior to this baseline.
The main contributions and/or advantages of our work are listed below.  X  A new method of classifier ensemble, founded on the principle of single objective optimization technique, is proposed. The proposed technique is based on GA that quantifies the amount of voting weights for each class in each classifier. We tried to establish that such classifier ensemble is capable to increase the classification quality by a large margin compared to the conventional ensemble methods.  X  To the best of our knowledge, use of GA for classifier ensemble is a novel contribu-tion, particularly in the area of NLP and especially for NER.  X  The proposed technique can be replicated for any resource-poor language very easily due to its language independent nature. In the present work, it is evaluated for four resource-poor languages such as Bengali, Hindi, Telugu, and Oriya.  X  The proposed framework is a very general approach. In the present work, we use the proposed approach to solve the problem of NER. But the proposed approach can be effectively used to solve the other types of well-known classification problems such as Part-of-Speech (PoS)-tagging, question-answering, etc.  X  Note, that our work proposes a novel way of combining the available classifiers. Thus, the performance of the existing works (e.g., Ekbal and Bandyopadhyay [2009],
Florian et al. [2003] etc.) can be further improved with our proposed framework.  X  In a part of the article we also formulate the problem of feature selection under the single objective optimization framework, and propose a solution to it using GA. This baseline showed inferior performance compared to the proposed classifier ensemble.
The rest of the paper is organized as follows. The base classifiers are briefly described in Section 2. Section 3 depict sthesetofNEfeaturesthatweuseforNER in four leading Indian languages, namely Bengali, Hindi, Telugu, and Oriya as well as for English. The problem of weighted vote-based classifier ensemble is formulated in Section 4. We discuss our proposed GA-based ensemble technique elaborately in Section 5. Section 6 reports the detailed evaluation results along with necessary dis-cussions for these languages. The single objective optimization based feature selec-tion technique is described in Section 7. Finally, we conclude with the future work roadmaps in Section 8. We use Maximum Entropy (ME), Conditional Random Field (CRF), and Support Vec-tor Machine (SVM) as the base classifiers to construct the ensemble system based on weighted voting. Brief descriptions of these classifiers are presented below. The ME framework estimates probabilities based on the principle of making as few assumptions as possible, other than the constraints imposed. Such constraints are derived from the training data, expressing some relationships between features and outcome. The probability distribution that satisfies the above property is the one with the highest entropy. It is unique, agrees with the maximum likelihood distribution, and has the exponential form ated weight  X  j ,and Z ( h ) is a normalization function.

The problem of NER can be formally stated as follows. Given a sequence of words w ,...,w from a set of tags T , which satisfies where h i is the context for the word w i .

The features are, in general, binary valued functions, which associate a NE tag with various elements of the context. For example,
We use the OpenNLP Java based MaxEnt package 4 for the computation of the values of the parameters  X  j . This allows us to concentrate on selecting the features which best characterize the problem instead of worrying about assigning the relative weights to the features. We use the Generalized Iterative Scaling [Darroch and Ratcliff 1972] algorithm to estimate the MaxEnt parameters. Conditional Random Fields (CRFs) [Lafferty et al. 2001] are undirected graphical mod-els, a special case of which corresponds to conditionally trained probabilistic finite state automata. Being conditionally trained, these CRFs can easily incorporate a large number of arbitrary, non-independent features while still having efficient procedures for non-greedy finite-state inference and training.

CRF is used to calculate the conditional probability of values on designated output nodes given values on other designated input nodes. The conditional probability of a is calculated as ing. The values of the feature functions may range between  X  X  X  ,... +  X  , but typically they are binary. To make all conditional probabilities sum up to 1, we must calculate the normalization factor which as in HMMs, can be obtained efficiently by dynamic programming.

To train a CRF, the objective function to be maximized is the penalized log-likelihood of the state sequences given the observation sequences: mean,  X  2 -variance Gaussian prior over parameters, which facilitates optimization by making the likelihood surface strictly convex. Here, we set parameters  X  to maximize the penalized log-likelihood using Limited-memory BFGS [Sha and Pereira 2003], a quasi-Newton method that is significantly more efficient and which results in only minor changes in accuracy due to changes in  X  .

When applying CRFs to the NER problem, an observation sequence is a token of a sentence or document of text and the state sequence is its corresponding label sequence.
 be 1 when s t  X  1 , s t are certain states and the observation has certain properties. We have used the C ++ based CRF ++ package 5 , a simple, customizable, and open source implementation of CRF for segmenting or labeling sequential data. In the field of NLP, Support Vector Machines (SVMs) [Vapnik 1995] are applied to text categorization and are reported to have achieved high accuracy without falling into over-fitting even though with a large number of words taken as the features [Joachims 1999; Taira and Haruno 1999]. Suppose, we have a set of training data for a two-class the training data and y  X  X  +1 ,  X  1 } is the class to which x i belongs. In their basic form, a SVM learns a linear hyperplane that separates the set of positive examples from the set of negative examples with maximal margin (the margin is defined as the distance of the hyperplane to the nearest of the positive and negative examples). In basic SVMs framework, we try to separate the positive and negative examples by the hyperplane written as SVMs find the  X  X ptimal X  hyperplane (optimal parameter w, b ) which separates the training data into two classes precisely.

The linear separator is defined by two elements: a weight vector w (with one com-ponent for each feature), and a bias b which stands for the distance of the hyperplane to the origin. The classification rule of a SVM is being x the example to be classified. In the linearly separable case, learning the maxi-mal margin hyperplane ( w , b ) can be stated as a convex quadratic optimization prob-lem with a unique solution: minimize || w || , subject to the constraints (one for each training example):
The SVM model has an equivalent dual formulation, characterized by a weight vector  X  and a bias b .Inthiscase,  X  contains one weight for each training vector, indicating the importance of this vector in the solution. Vectors with non null weights are called support vectors. The dual classification rule is The  X  vector can be calculated also as a quadratic optimization problem. Given the optimal  X   X  vector of the dual quadratic optimization problem, the weight vector w  X  that realizes the maximal margin hyperplane is calculated as
The advantage of the dual formulation is that efficient learning of non-linear SVM separators, by introducing kernel functions . Technically, a kernel function calculates a dot product between two vectors that have been (non linearly) mapped into a high dimensional feature space. Since there is no need to perform this mapping explicitly, the training is still feasible although the dimension of the real feature space can be very high or even infinite.

By simply substituting every dot product of x i and x j in dual form with any kernel function K ( x i , x j ), SVMs can handle non-linear hypotheses. Among the many kinds of kernel functions available, we will focus on the d -th polynomial kernel
Use of d -th polynomial kernel function allows us to build an optimal separating hyperplane which takes into account all combination of features up to d .
Support Vector Machines have advantage over conventional statistical learning al-gorithms from the following two aspects: (1) SVMs have high generalization performance independent of dimension of feature (2) SVMs can carry out their learning with all combinations of given features without
We develop our system using SVM [Joachims 1999; Vapnik 1995] which perform classification by constructing an N -dimensional hyperplane that optimally separates data into two categories. We have used YamCha 6 toolkit, an SVM based tool for de-tecting classes in documents and formulating the NER task as a sequential labeling problem. Here, the pairwise multi-class decision method and the polynomial kernel function are used. We use the TinySVM-0.07 7 classifier. The main features for the NER task are identified based on the different possible com-binations of available word and tag contexts. We use the following features for con-structing the various classifiers based on the ME, CRF, and SVM frameworks. Most of these features are language independent in nature and can be easily obtained for almost all the languages. The features are language independent in the sense that these don X  X  need any domain dependent resources and/or language specific rules for their generation. We also define a semantically motivated feature that proved to be very effective to improve the o verall system performance. (1) Context words: These are the preceding and succeeding words of the current word. (2) Word suffix and prefix: Fixed length (say, n ) word suffixes and prefixes are very (3) First word: This is a binary valued feature that checks whether the current token is (4) Length of the word: This binary valued feature checks whether the number of (5) Infrequent word: This is a binary valued feature that checks whether the (6) Last word of sentence: This feature checks whether the word is the last word of a (7) Capitalization: This is a binary valued feature that determines whether the word (8) Part-of-Speech (POS) information: POS information of the current and/or the sur-(9) Chunk information: This is useful for NE identification. Here, this is used only for (10) Digit features: Several digit features are defined depending upon the presence (11) Semantic feature: This feature is semantically motivated. We consider all un-(12) Dynamic NE information: This is the output label(s) of the previous token(s). Suppose, the N number of available classifiers is denoted by C 1 ,..., C N .Let, A = { C i : i =1; N } . Suppose, there are M number of output classes. The weighted vote-based classifier ensemble selection problem is then stated as follows: Find the weights of votes V per classifier which will optimize some functions F i classifier for the j th class. More weight is assigned for that particular class for which the classifier is more confident; whereas the output classes for which the classifier is less confident are given less weight. V ( i , j )  X  [0 , 1] denotes the degree of confidence of the i th classifier for the j th class. These weights are used while combining the outputs of classifiers using weighted voting. Here, F i s are some classification quality measures of the combined weighted vote-based classifier. The particular type of problem like NER has mainly three different kinds of classification quality measures, namely re-call, precision and F -measure. Thus, F  X  X  recall , precision , F -measure } .Herewehave chosen F = F -measure. The proposed GA-based classifier ensemble method is described below. The basic steps of the proposed approach closely follow those of the conventional GA as shown in Figure 1. Genetic Algorithms (GAs) [Goldberg 1989] are randomized search and optimization techniques guided by the principles of evolution and natural genetics, having a large amount of implicit parallelism. GAs perform search in complex, large, and multi-modal landscapes, and provide near-optimal solutions for objective or fitness function of an optimization problem. In GAs, the parameters of the search space are encoded in the form of strings called chromosomes . A collection of such strings is called a population . Initially, a random population is created, which represents different points in the search space. An objective or a fitness function is associated with each string that represents the degree of goodness of the string. Based on the principle of survival of the fittest, a few of the strings are selected and each is assigned a number of copies that go into the mating pool. Biologically inspired operators, such as crossover ,and mutation , are applied on these strings to yield a n ew generation of strings. The process of selection, crossover, and mutation continues for a fixed number of generations or until a termination condition is satisfied. Suppose there are M number of available classifiers and O number of output classes. Then the length of the chromosome is M  X  O . Each chromosome encodes the weights of votes for possible O output classes for each classifier. Please note that chromosome represents the available classifiers along with their weights for each class. It bears the same meaning for all types of models such as ME, CRF, and SVM. As an example, the encoding of a particular chromosome is represented in Figure 2, where M =3 and O = 3 (i.e., a total 9 votes is possible). The chromosome represents the following ensemble: The weights of votes for three different output classes in classifier 1 are 0.59, 0.12, and 0.56, respectively. Similarly, weights of votes for 3 different output classes are 0.09, 0.91, and 0.02, respectively, in classifier 2 and 0.76, 0.5 and 0.21, respectively, in classifier 3.

In the figure, classifiers 1, 2, and 3 could be either of the same type (i.e., ME, CRF, or SVM) or different types (i.e., one/more may be of one category such as CRF and the rest are of different categories) of cla ssification methods. We use real encoding that randomly initializes the entries of each chromosome by a real value (r) between 0 and 1. Here, r = rand () RAND MAX +1 . If the population size is P then all the P number of chromosomes of this population are initialized in the above way. Initially, the F -measure values of all the available classifiers are calculated using three-fold cross validation on the available training data. Then, we execute the fol-lowing steps to compute the fitness value of each chromosome. (1) Suppose there are total M number of classifiers. Let, the overall F -measure values (2) Initially, the training data is divided into three parts. Each classifier is trained (3) The overall F -measure value of this ensemble is calculated for the 1/3 training (4) Steps2and3arerepeated3timesto perform three-fold cross validation. (5) The average F -measure value of this three-fold cross validation is used as the fit-During each successive generation, a proportion of the existing population is selected to generate a new generation. Individual solutions are selected through a fitness-based process where fitter solutions (as measured by a fitness function) are typically more likely to be selected. Certain selection methods rate the fitness of each solution and preferentially select the best solutions.

In this article, we use roulette wheel selection. Here, the fitness function associated with each chromosome is used to associate a probability of selection with each individual chromosome. If f i is the fitness of individual i in the population, its probability of being selected is where N is the number of individuals in the population.

This selection process has resemblance to a roulette wheel in a casino. Usually, a proportion of the wheel is assigned to each of the possible selections based on their fitness value. This could be achieved by dividing the fitness of a selection by the total fitness of all the selections, thereby normalizing them to 1. Then a random selection is made similar to how the roulette wheel is rotated. Thus, in case of roulette wheel selection, chromosomes with higher fitness values are less likely to be eliminated but there is still a chance that they may be. Here, we use the normal single point crossover [Holland 1975]. As an example, let the two chromosomes be P 1: 0.24 0.16 0.54 0.87 0.66 0.76 0.01 0.88 0.21 P 2: 0.12 0.09 0.89 0.71 0.65 0.82 0.69 0.43 0.15
At first a crossover point has to be selected randomly between 1 to 9 (length of the chromosome) by generating some random number between 1 and 9. Let the crossover point, here, be 4. Then after crossover, the two new offsprings are O 1: 0.24 0.16 0.54 0.87 0.65 0.82 0.69 0.43 0.15 (taking the first four positions from P 1 and rest from P 2) O 2: 0.12 0.09 0.89 0.71 0.66 0.76 0.01 0.88 0.21 (taking the first four positions from P 2 and rest from P 1) Crossover probability is selected adaptively as in Srinivas and Patnaik [1994]. Crossover probabilities are computed as follows. Let f max be the maximum fitness value of the current population, f be the average fitness value of the population and f be the larger of the fitness values of the solutions to be crossed. Then the probability of crossover,  X  c ,iscalculatedas  X   X  c = k 3 ,if f Here, as in Srinivas and Patnaik [1994], the values of k 1 and k 3 are kept equal to 1.0. Note that when f max = f ,then f = f max and  X  c will be equal to k 3 . The aim behind this adaptation is to achieve a trade-off between exploration and exploitation in a different manner. The value of  X  c is increased when the better of the two chromosomes to be crossed is itself quite poor. In contrast when it is a good solution,  X  c is low so as to reduce the likelihood of disrupting a good solution by crossover. Each chromosome undergoes mutation with a probability  X  m . The mutation probabil-ity is also selected adaptively for each chromosome as in Srinivas and Patnaik [1994].
The expression for mutation probability,  X  m , is given below:  X   X  m = k 4 if f
Here, values of k 2 and k 4 are kept equal to 0.5. This adaptive mutation helps GA to come out of local optimum. When GA converges to a local optimum, that is, when f local optimum. It will also happen for the global optimum and may result in disruption of the near-optimal solutions. This may distract GA to converge to the global optimum. The  X  c and  X  m will get lower and higher values for high and low fitness solutions, respectively. While the high fitness solutions aid in the convergence of the GA, the low fitness solutions prevent the GA from getting stuck at a local optimum. The use of elitism will also keep the best solution intact. For a solution with the maximum fitness value,  X  c and  X  m are both zero. The best solution in a population is transferred undisrupted into the next generation. Together with the selection mechanism, this may lead to an exponential growth of the solution in the population and may cause premature convergence. To overcome the above stated problem, a default mutation rate (of 0.02) is kept for every solution in the proposed approach.

Here, each position in a chromosome is mutated with probability  X  m in the follow-ing way. The value is replaced with a random variable drawn from a Laplacian dis-Here,  X  is the value at the position which is to be perturbed. The scaling factor  X  is chosen equal to 0 . 1. The old value at the position is replaced with the newly generated value. By generating a random variable using Laplacian distribution, there is a non-zero probability of generating any valid position from any other valid position while probability of generating a value near the old value is more. In this approach, the processes of fitness computation, selection, crossover, and muta-tion are executed for a maximum number of generations. The best string seen up to the last generation provides the solution to the above classifier ensemble problem. Elitism is implemented at each generation by preserving the best string seen up to that gener-ation in a location outside the population. Thus on termination, this location contains the best classifier ensemble. In this section, we present the detailed discussions on the datasets, experimental setup, and evaluation results for all the languages along with necessary discussions. Indian languages are resource-constrain ed in nature. For NER, we use a Bengali news corpus [Ekbal and Bandyopadhyay 2008c] developed from the archive of a leading Bengali newspaper available on the Web. We manually annotate a portion containing approximately 250K wordforms with a coarse-grained NE tagset of four tags namely, PER (Person name), LOC (Location name), ORG (Organization name) and MISC (Mis-cellaneous name). The Miscellaneous name includes date, time, number, percentages, monetary expressions, and measurement expressions. The data is collected mostly from the national, states, sports domains and the various subdomains of districts of the particular newspaper. This annotation was carried out by one of the authors and verified by an expert. We also use the IJCNLP-08 NER on South and South East Asian Languages (NERSSEAL) 12 Shared Task data of around 100,000 wordforms that were originally annotated with a fine-grained tagset of twelve tags. This data is mostly from the agriculture and scientific domains. For Hindi, Telugu and Oriya, we use the datasets obtained from the NERSSEAL shared task. The underlying reason to adopt the finer NE tagset in the shared task was to use the NER system in various NLP applications, particularly in machine translation. The IJCNLP-08 NERSSEAL shared task tagset is shown in Table I. One important aspect of the shared task was to identify and classify the maximal NEs as well as the nested NEs, that is, the con-stituent parts of a larger NE. But, the training data were provided with the type of the maximal NE only. For example, mahatmA gAndhi roDa (Mahatma Gandhi Road) was annotated as location and assigned the tag  X  X EL X  even if mahatmA (Mahatma) and gAndhi (Gandhi) are NE title person (NETP) and person name (NEP), respectively. The task was to identify mahatmA gAndhi roDa as a NE and classify it as NEL. In addition, mahatmA and gAndhi had to be recognized as NEs of categories NETP (Title person) and NEP (Person name), respectively.

In the present work, we consider only the tags that denote person names (NEP), location names (NEL), organization names (NEO), number expressions (NEN), time expressions (NETI), and measurement expressions (NEM). The NEN, NETI, and NEM tags are mapped to the MISC tag that denotes miscellaneous entities. Other tags of the shared task are mapped to the  X  X ther-than-NE X  category denoted by  X  X  X . Hence, the tagset mapping now becomes as shown in Table II.

In order to properly denote the boundaries of NEs, four basic NE tags are fur-ther divided into the format I-TYPE (TYPE  X  PER/LOC/ORG/MISC) which means that the word is inside a NE of type TYPE. Only if two NEs of the same type immedi-ately follow each other, the first word of the second NE will have tag B-TYPE to show that it starts a new NE. For example, the name mahatmA gAndhi [Mahatma Gandhi] is tagged as mahatmA [Mahatma]/I-PER gAndhi [Gandhi]/I-PER. But, the names mahatmA gAndhi [Mahatma Gandhi] rabIndrAnAth thAkur [Rabindranath Tagore] are to be tagged as: mahatmA [Mahatma]/I-PER gAndhi [Gandhi]/I-PER rabIndrAnAth [Rabindranath]/B-PER thAkur [Tagore]/I-PER, if they appear sequen-tially in the text. This is the standard IOB format that was followed in the CoNLL-2003 shared task [Tjong Kim Sang and De Meulder 2003]. In order to report the evaluation results, we randomly select a portion of each dataset as the gold stan-dard test data. Some statistics of training and test datasets for the Indian lan-guages are presented in Table III. For English NER, we use the CoNLL-2003 shared task data. We set the following parameter values for GA: population size = 100, number of gener-ations = 50, probability of mutation and crossover are determined adaptively.
We define three different baseline classifier ensemble techniques as follows. (1) Baseline 1 . In this baseline model, all the individual classifiers are combined to-(2) Baseline 2 . All the individual classifiers are combined with the help of a weighted (3) Baseline 3 . For each classifier, the average F -measure value of each output class
For the purpose of comparison three state-of-the-art ensemble techniques, namely stacking [Wolpert 1992], QBC (Query by committee)[Seung et al. 1992] and ECOC (Er-ror correcting Output Codes) [Dietterich and Bakiri 1995] are executed on the obtained classifiers. In stacking, SVM is used as a meta-classifier for all the languages, namely Bengali, Hindi, Telugu, Oriya, and English.

A QBC-based active learning technique is used for Bengali. We use a portion of the unlabeled Bengali news corpus [Ekbal and Bandyopadhyay 2008c] for active learning. This portion is consisting of 35,000 news documents that contain approximately 10 million wordforms. Here, we form a committee by selecting the two top-performing classifiers from each of ME, CRF, and SVM models (see Section 6.3). The decision ob-tained from this committee is used to improve the performance of the best performing classifier. The available 35,000 documents are divided into 35 equal subsets. Initially, all the available classifiers are trained using the available training data and evaluated with the first subset of unlabeled data. Most uncertain samples of this test data are selected for manual verification by the use r. The user is provided with the surrounding context of previous three and next three words to determine the correct labels of the uncertain samples. After verification, these samples are added to the initial training data. We considered the samples to be uncertain if the output labels of all the classi-fiers do not agree to a single decision. This process is repeated 35 times. Finally, the best individual classifier is retrained using the resultant training data and evaluated with the available test data. We could not employ this technique for other Indian lan-guages due to the non-availability of unlabeled data. For ECOC, initially we generate binary classifiers for each NE class. Binary classifiers are generated using ME, CRF, and SVM for the Indian languages and for English. Thereafter, ECOC [Dietterich and Bakiri 1995] method is applied to solve the multi-class problem. The code matrix is generated exhaustively and minimum Hamming distance-based method is applied to determine the appropriate class label of each test instance. We build a number of different ME, CRF, and SVM models by considering the various combinations of the available NE features and/or feature templates. In this particular work, we construct various classifiers by cons idering the various subsets of the follow-ing set of features: various context window within the previous three and next three (3+3 different features) or four (4+4 different features) characters, POS information of the current and/or surrounding token(s), first word, length, infrequent word, last word in the sentence, several digit features, semantic feature, and dynamic NE information.

A feature vector consisting of the features as described above is extracted for each word in the NE-tagged corpus. Now, we have a training data in the form ( W i , T i ), where, W i is the i th word and its feature vector and T i is its corresponding output class. For CRF, we consider various combinations from the set of feature templates as given and w i +1 ; feature vector consisting of all other features of w i ; and B (bigram feature template) } .

Please note that in CRF, the bigram feature template represents the combination of current and preceding output labels. For Bengali, we generate 152 different models using ME classifier by varying the available features. Some 21 of these classifiers are shown in Table IV. Varying the available features and/or feature templates, we construct many CRF and SVM based classifiers, out of which nine CRF-based and eight SVM-based classifiers are shown in Table IV. 13 The CRF-based model exhibits best performance with the overall recall, precision, and F -measure values of 89.42%, 90.55%, and 89.98%, respectively. Thereafter, we apply our proposed GA-based approach to determine the appropriate classifier ensemble. Overall evaluation results of this ensemble techniques along with the best individual classifier, three different baseline ensembles and some other existing ensemble techniques are reported in Table V. Results show that the overall performance attained by the GA-based clas-sifier ensemble determined by the proposed algorithm performs better than the best performing individual classifier with the increments of 2.66, 1.67, and 2.17 percentage recall, precision, and F -measure points, respectively. The proposed GA-based ensem-ble technique performs reasonably better than three baseline models. It demonstrates the overall performance improvement with the increments of 6.79, 6.05, and 5.00 percentage F -measure points over Baseline 1, Baseline 2, and Baseline 3, respectively. The relatively lower performance in the baseline ensembles is due to the blind combi-nation of all the available classifiers. This fact also points in support of our underlying assumption that quantification of voting for each class in each classifier is very important.

Statistical analysis of variance (ANOVA) [Anderson and Scolve 1978] is performed in order to examine whether the proposed ensemble technique really outperforms the best individual classifier, three baseline ensembles and three other existing ensemble techniques. Our proposed technique is based on GA, a heuristic based search and op-timization technique. The final results provided by GAs largely depend on the seed value of the random variables and values of parameters. Here, we have executed the proposed approach 10 times and the best among these is reported in Table VI. But, the three baselines always provide the same results in every run. This is due to the fact that all the available classifiers are ensembled in the baselines. So for ANOVA analy-sis, we consider ten different runs (in maximum of the cases results are almost same) of GA, whereas the same results are used ten times for three baselines. Thereafter, ANOVA analysis is carried out on these outputs. ANOVA tests show that the differ-ences in mean recall, precision, and F -measure values are statistically significant as p value is less than 0 . 05 in each of the cases. Evaluation results of the ANOVA analy-ses are shown in Table VI. Results reveal that the GA based approach truly performs better than the best individual classifiers, three baseline approaches, and three other ensemble techniques.

Thereafter, the proposed approach is evaluated on Hindi and Telugu datasets. The various classifier combinations are reported in Table VII and Table X for Hindi and Telugu, respectively. We use the same set of features as Bengali. The overall per-formance of the best individual classifier, three baseline ensembles, single objective GA-based ensemble, and the two other existing ensemble techniques are presented in Table VIII and Table XI for Hindi, and Telugu, respectively. For Hindi, CRF model exhibits the best performance whereas SVM model shows the highest performance for Telugu. The proposed GA-based ensemble yields the overall recall, precision and F -measure values as 96.07%, 88.63%, and 92.20%, respectively for Hindi, and 78.82%, 91.26%, and 84.59%, respectively for Telugu. Results show that the overall perfor-mance of the classifier ensemble determined by the proposed algorithm is better than all the other models. For Hindi, it shows the improvement of F -measure values by 2.80%, 17.51%, 8.56%, 7.61%, 2.00%, and 1.57%, respectively, over the best individual classifier, three baseline approaches and two existing ensemble techniques.
Results for Telugu show that the overall performance attained by the GA-based ensemble is reasonably better (an improvement of 1.40%, 13.27%, and 6.89% recall, precision and F -measure values, respectively) than the best individual classifier. We also observe the increments of 3.36, 3.76, and 3.25 percentage F -measure points over Baseline 1, Baseline 2 and Baseline 3, respectively. The proposed algorithm also performs superior with more than 3.83 and 3.21 percentage F -measure values compared to two existing ensemble techniques. Note that unlike Bengali, the baseline models based on majority voting do not perform well in comparison to weighted voting for Hindi and Telugu both. This may be due to the nature of the datasets.
Finally, the proposed system is evaluated for Oriya, one of the popularly spoken lan-guages in the eastern part of India. The various classifier combinations are reported in Table XIII. We train each classifier with t he same set of language independent fea-tures, as used for other languages except POS information. Detailed evaluation results are presented in Table XIV that shows the overall recall, precision, and F -measure val-ues as 88.56%, 89.98%, and 89.26%, respectively. Results also show that the overall performance of the proposed GA-based classifier ensemble is better (an improvement of 2.01%, 1.95%, and 1.97% in recall, precision, and F -measure values, respectively) than the best individual classifier. In comparison to three baseline ensembles, our proposed method performs superior by the margins of 1.63, 1.46, and 0.90 percentage F -measure points, respectively. The proposed GA-based approach also performs superior to two state-of-the-art ensemble techniques, namely stacking and ECOC. Evaluation for all the languages suggest that rather than blindly combining all the available classifiers, it is more effective to find out the appropriate weights of voting for each class in each classifier. Here, we evaluate our proposed technique on the benchmark English dataset of CoNLL 2003 shared task [Tjong Kim Sang and De Meulder 2003]. Initially, the system is tuned on the development data, and then blind evaluation is performed on the test data to report the evaluation results. The CoNLL-2003 shared task English dataset had 203,621, 46,435, and 51,362 tokens for training, development, and test sets, respec-tively. The different classifier combinations obtained by varying the feature sets and/or feature templates in ME, CRF, and SVM (as the underlying classification techniques) are reported in Table XV. The best performance is obtained for the CRF based model that yields the overall recall, precision and F -measure values of 86.16%, 86.47%, and 86.31%, respectively. Overall evaluation results are presented in Table XVI. It shows the overall recall, precision, and F -measure values of 88.72%, 88.64%, and 88.68%, re-spectively, which are better than the best individual classifier, three baseline ensemble techniques and two state-of-the-art ensemble techniques.
 For the purpose of illustration, we experiment with the various ensemble size for Bengali. The results are reported in Table XVII. Note that increasing the ensemble size increases the length of the chromoso me and thereby increases the size of the search space. As an example, for the ensemble size = 50 and number of output classes = 8, total length of the chromosome will be 400. This, in turn, increases the size of the search space. Thus, it is very difficult to find the appropriate weight combinations for each classifier. Results also suggest that increasing the number of classifiers may not always increase the overall performance of the system. If more good performing/complimentary classifiers will be added to the total set of classifiers then the overall system performance may increase. But in general, after a certain size of the classifier ensemble, system performance does not improve with the increase of ensemble size. Table XIII shows that the system achieves the recall, precision, and F -measure values of 87.51%, 89.67%, and 88.57%, respectively, with the ensemble that is formed with the 80 best performin g ME-based classifiers. But if we increase the number of classifiers to either 140 or 152, the performance does not improve. Inclusion of heterogenous classifiers improves the overall performance of the system. Though, the overall performance increases until we reach the size of the ensemble to 169. But, it is also to be noted that greater ensemble size does not deteriorate the overall performance of the system. One possible explanation behind this nature of performance is that the weights of most of the classifiers for maximum number of output classes are automatically set near zero values by the proposed GA-based method.

We also experiment by varying the size of the training set in order to observe their effect on the overall performance. Results a re reported in Table XVIII with the various training sets and evaluating on the same test set. Table XVIII shows that the perfor-mance of the system is proportional with the size of the training set. But the rate of improvements are gradually decreasing per iteration.
 In the experimental results we have compared our approach with three standard base-line techniques along with some existing ensembling techniques, stacking, ECOC, and QBC. We have executed the proposed technique on HP Server running red hat linux enterprize 4 operating system with 6 GB RAM and 250 GB hard disk.

For stacking, baselines and the proposed approach the first step is the same, that is, generating all the base classifiers. Here, we report the time required by the techniques for computing the next step, i.e. in case of stacking the time taken by second level classifier; in case of the proposed method the time taken by the GA based approach; in case of baselines time taken to combine the outputs. For Bengali, stacking method took 82 minutes to train and test the second level SVM classifier. Baseline approaches are the fastest as these need only the time to combine the individual classifiers. These methods took only 2, 3.2, and 4.6 minutes, respectively. Our proposed approach took 30 minutes of time to determine the final result. Again for Hindi the time taken by stacking, three baselines and the proposed approach are 74, 1.5, 2, 2.5, and 28 minutes, respectively. Thus it can be noted that while for stacking the time complexity depends on the classifier used in the second level, our approach is independent of the base classifiers used. This is an advantage of our proposed technique.

QBC involves a lot of computations, and it is the most time-consuming technique among all of our experiments. We have used this technique only for Bengali. Each ME, CRF and SVM classifiers took 72, 91, and 96 minutes, respectively, for training and evaluating with the first set of unlabeled data. The time taken for combining all the decisions was 1.7 minutes. The uncertain samples were selected in 1.2 minutes. All these steps were repeated 35 times. Two users were employed to assign the correct labels to the most uncertain samples, and they spent 2.4 hours on an average for each set of unlabeled documents. Finally, the best individual classifier took 167 minutes in total for training and testing. In contrast, in the experimental settings of our proposed method, the maximum time was spent in generating only the base classifiers. The later stages took less than 30 minutes to generate the final results.

The complexity of the proposed technique also depends on the number of individual base classifiers. With the increase of the number of base classifiers, the complexity of the proposed technique increases. Results show that weighted vote-based classifier ensemble identified by the proposed GA-based technique performs better than the best individual classifier, three different baseline ensemble techniques, and some other state-of-the art ensemble techniques for all the datasets. This is because of the following. (1) It is already established in machine-learning literature that proper ensemble (2) Three baseline ensemble techniques are not able to combine the classifiers (3) The effectiveness of GA in finding out proper weights of voting is another rea-
The second observation also supports the gravity of our underlying hypothesis that proper classifier ensemble selection is, itself, a very crucial problem. Our proposed GA-based approach effectively selects the appropriate weights of voting for each class in each classifier. For Indian languages, all the results show that the proposed algo-rithm performs best for Bengali followed by Hindi, Oriya, and Telugu. The possible reasons could be (i). the ratios of positive (NEs) and negative examples (non-NEs) in the respective training data, that is, 1:9 (Bengali), 1:9.33 (Hindi)., 1:13 (Telugu), and 1:19 (Oriya); (ii) agglutinative nature of Telugu that may possibly require a different feature set; and (iii) presence of less number of NEs in the Oriya dataset. The proposed algorithm shows a general high precision but suffers from relatively low recall values for all these languages. This may be due to the fact that all the datasets are highly imbalanced and hence greatly biased towards the negative categories. Thus, there are not enough NE instances that could be more effective for NE identification. These need to investigate appropriate sampling strategy to make the ratios of positive and negative examples more balanced. We also investigated the effects of training set size and ensemble size on the overall performance of the system. For CoNLL-2003 shared task English dataset, the proposed technique achieves the performance comparable to the state-of-the-art systems. We have developed a single objective optimization based feature selection technique which also showed inferior performance compared to the proposed approach. It will not be fair to compare the performance of our proposed system with that of the previous proposals for Bengali [Ekbal and Bandyopadhyay 2007; Ekbal et al. 2007, 2008; Ekbal and Bandyopadhyay 2008a, 2009], Hindi [Li and McCallum 2004; Patel et al. 2009; Saha et al. 2008] and Telugu [Srikanth and Murthy 2008] as these works use (i) different experimental setup, (ii) different data sets, (iii) more complex set of features, and (iv) domain-dependent knowledge and/or resources. In contrast, our proposed algorithm is based on a relatively small set of features that can be easily obtained for almost all the languages, does not make use of any domain dependent re-sources, and thus can be replicated for any resource-poor language very easily. Though we use the IJCNLP-08 NERSSEAL shared task data, we convert these fine-grained annotated data to the coarse-grained forms. Thus, comparing our proposed system with that of the shared task articles 14 is also out-of-scope. Comparisons of the pro-posed method to some existing ensemble techniques such as stacking [Wolpert 1992] and ECOC [Dietterich and Bakiri 1995] are also shown. In addition to stacking and ECOC, we have also compared our proposed method with a QBC based [Seung et al. 1992] active learning technique for Bengali.

For the benchmark English dataset, our proposed system achieves the performance, comparable to the best performing system [Florian et al. 2003] of CoNLL-2003 shared task [Tjong Kim Sang and De Meulder 2003]. The best system [Florian et al. 2003] at CoNLL-2003 shared task demonstrated the recall, precision, and F -measure values of 88.54%, 88.99%, and 88.76%, respectively. They presented a classifier-combination experimental framework for NER in which four diverse classifiers, namely robust lin-ear classifier, ME, transformation-based learning, and HMM. They made use of a more complex set of features: gazetteer information, in the form of a list of 50,000 cities, 80,000 proper names, and 3,500 organizations. They also used the outputs of other two NE classifiers, trained on a richer tagse t of 32 named categories for improving the system performance. However, they did not report any results on the test set without using any domain knowledge. In contrast, our proposed algorithm (i) makes use of a very simple set of features that can be derived for any language with a little effort, (ii) does not use any domain-dependent resources like the gazetteers etc., and (iii) does not make use of any additional NE taggers, but still achieves state-of-the-art performance, which is below 0.08 F -measure point compared to the best system of CoNLL-2003.
Until now, the best reported results for CoNLL-2003 shared task data are in Lin and Wu [Lin and Wu 2009] that proposed a semi-supervised approach for NER. In addition to word clusters, they used phrase clusters as the features and achieved sig-nificant performance improvement. They proposed an algorithm for clustering tens of millions of phrases and used the resulting clusters as features in discriminative classifiers. They collected 20 million unique queries from an anonymized query log that were found in a 700 billion token Web corpus with a minimum frequency count of 100. Thereafter, they constructed the feature vectors for 20 million phrases us-ing the web data, executed the K -means clustering on the phrases that appeared in the CoNLL training data to obtain K centroids, and assigned each of the 20 million phrases to the nearest centroid of clusters. They used CRF as a base classifier and experimented with 48 various feature templates. They obtained the F -measure value of 90.90%, which is 1.22 points higher than our proposed system. In addition to the above mentioned two systems [Florian et al. 2003; Lin and Wu 2009], we also present the comparative results with some other well-known existing techniques in Table XIX. Suzuki and Isozaki [2008] run a baseline discriminative classifier on unlabeled data to generate pseudo examples, which are then used to train a different type of classifier for the same problem. Later on, they used the automatically labeled corpus to train HMMs. Chieu and Ng [2003] showed how the use of global information, in addition to the local ones, can improve the model performance. Our system also achieves 5.99 points higher F -measure value in comparison to the stacked, voted model proposed by Wu et al. [2003] in the CoNLL-2003 shared task. In a machine learning approach, feature selection is an optimization problem that in-volves choosing an appropriate feature subset. In an ME model, appropriate feature selection is a very crucial problem and also a key issue to improve classifier X  X  perfor-mance. However, it does not provide any method for automatic feature selection and heuristics are usually used for this task. In this section, we report a single objective optimization based feature selection technique based on GA [Goldberg 1989]. This is used as a baseline to compare with the performance of the proposed classifier ensemble technique. The GA-based feature selection technique is described below. If the total number of features is F , then the length of the chromosome is F .Asan example, the encoding of a particular chromosome is represented in Figure 3. Here F = 12 (i.e., total 12 different features are available). The chromosome represents the use of seven features for constructing a classifier (first, third, fourth, seventh, tenth, eleventh, and twelfth features). The entries of each chromosome are randomly initial-ized to either 0 or 1. Here, if the i th position of a chromosome is 0 then it represents that i th feature does not participate in constructing the classifier. Else if it is 1 then the i th feature participates in constructing the classifier.

If the population size is P then all the P number of chromosomes of this population are initialized in the above way. For the fitness computation, the following procedure is executed. (1) Suppose there are N number of features present in a particular chromosome (i.e., (2) Construct a classifier with only these N features. (3) Here, initially the training data is divided into three parts. The above classifier is (4) Now, the overall F -measure value of this classifier for the 1/3 training data is (5) Steps 3 and 4 are repeated three times to perform three-fold cross validation. (6) The average F -measure value of this three-fold cross validation is used as the fit-Here, roulette wheel selection is used to implement the proportional selection strat-egy. For crossover, normal single point crossover [Holland 1975] is used. Crossover probability is selected adaptively as in Srinivas and Patnaik [1994]. Each chromosome undergoes mutation with a probability  X  m . The mutation probability is also selected adaptively for each chromosome as in Srinivas and Patnaik [1994]. Here, mutation op-erator is applied to each entry of the chromosome where the entry is randomly replaced by either 0 or 1.

In this approach, the processes of fitness computation, selection, crossover, and mu-tation are executed for a maximum number of generations. The best string seen up to the last generation provides the solution to the above feature selection problem. Elitism is implemented at each generation by preserving the best string seen up to that generation in a location outside the population. Thus on termination, this loca-tion contains the best feature combination.
 The feature selection technique is evaluated for Bengali, Hindi, and Telugu. Here we have selected best feature combination for ME classifier. But the approach is very general and it can be used with any other classifiers like CRF, SVM etc. We set the following parameter values for GA: population size = 100, number of generations = 50, probability of mutation = 0.2 and probability of crossover = 0.9.

Here, the following features are considered: Context of size five (previous two, cur-rent, and next two) or three (previous, current, and next) words, prefixes of length up to three or four characters (three or four features), suffixes of length up to three or four characters (three or four features), POS information, first word of the sentence, length of the word, infrequent word, position of the word, digitComma, digitPercentage, digit-Dot, digitSlash, digitHyphen, digitFour, digitTwo, semantic feature, and dynamic NE information.
 The GA-based feature selection technique finally selects the features as shown in Table XX for these languages. In the table, meanings of the notations are as follows: C [  X  i , + j ]: context spanning from the previous i th word to the next j th word with the current token at position 0; Pre i and Su f i : prefixes and suffixes of character sequences up to i of the current word, respectively; t i : output class of the current token; and Se M i : Semantic feature of the current token.

The recall, precision, and F -measure values of the best individual classifier trained using the feature set identified by the GA-based approach are 86.32%, 89.02%, and 87.65%, respectively for Bengali. Thereafter, we execute the feature selection algo-rithm for Hindi and Telugu datasets. Evaluation results yield the recall, precision, and F -measure values of 86.01%, 90.92%, and 88.40%, respectively for Hindi and 73.80%, 86.58%, and 79.68%, respectively for Telugu. Overall results of the feature selection technique and the GA-based classifier ensemble are presented in Table XXI. For each of the languages, results show that GA based classifier ensemble performs superior compared to the baseline model developed using the GA-based feature selection ap-proach. But, it is also to be noted that the GA-based feature selection yields better performance in comparison to the heuristics based feature selection of ME model for each of the languages. The GA-based feature selection technique shows the increments of 1.11, 1.99, and 3.04 percentage F -measure points (c.f. M 6 in Table IV, M 6 in Table VII, and M 13 in Table X) over the best individual ME-based classifiers for Bengali, Hindi, and Telugu, respectively.
 In this article, we proposed a novel technique of classifier ensemble for NER. We have used GA to determine the weights of votes for different output classes in each clas-sifier. We hypothesized and experimentally shown that instead of eliminating some classifiers completely, it is better to quantify the amount of votes per classifier for each output class. The proposed approach encodes the weights in its chromosome. Adaptive mutation and crossover probabilities have been used to accelerate the conver-gence of GA. The overall F -measure value of three-fold cross validation on the training data attained by the weighted vote-based classifier ensemble encoded in a particular chromosome has been used as its objective value. We have used ME, CRF, and SVM frameworks as the base classifiers to generate the several different versions of them by varying the available features and/or feature templates. One most interesting and important characteristic of our system is that it makes use of only language inde-pendent features that can be easily derived for almost all the languages without any knowledge of the languages a priori. Thus, our proposed algorithm can be very eas-ily replicated for any language. We evaluated our proposed technique for four leading Indian languages, namely Bengali, Hindi, Telugu, and Oriya, which are all resource-constrained in nature. Experiments show the effectiveness of our proposed approach with the promising results for all the four languages. We also evaluated the approach with the benchmark English datasets of CoNLL-2003 shared task, and it showed the performance comparable to the existing state-of-the-art systems. Results also show that the performance attained by the GA-based ensemble technique is better than the best individual classifier, three baseline ensemble techniques and some existing state-of-the art classifier ensemble techniques. We also showed the effects of ensemble size and training set size on the overall system performance.
 In part of the article, we have also developed a feature selection technique using GA. This is used as a baseline that showed inferior performance compared to the proposed classifier ensemble.

In this article, we have used GA to optimize only one classification quality mea-sure to determine the best classifier ensemble. But sometimes only a single measure may not always capture the quality of an ensembling reliably. For a good ensem-ble, sometimes it may be necessary to opti mize more than one classification quality measures simultaneously. Thus it would be good to use multiobjective optimization (MOO) techniques to solve the classifier ensemble problem. In the future we will use some MOO-based techniques to solve the problem of weighted vote-based classifier ensemble.

