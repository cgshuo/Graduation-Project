 Zak Waters 1( The classification of social interactions occurring among individuals who partic-ipate in an online community is an important research problem. Not all partici-pant contributions have the same value, with some being more thoughtful than others. This problem is particularly important in an educational domain, where online discussions are often being used to support both fully online and blended models of learning [ 7 ]. A substantial body of research aims to foster higher-order thinking among students in online learning communities. One prominent frame-work for approaching this problem is the Community of Inquiry (CoI) model [ 8 ] which describes the important dimensions of learning in online communities, and provides a quantitative coding scheme for their assessment. This coding scheme provides a method for categorising various interactions between partic-ipants within a particular online community, which is traditionally conducted by two human  X  X oders X  who manually label discussion messages for post hoc analysis.
 Despite wide adoption by online education researchers, coding online dis-cussion transcripts is a manual and labor-intensive task, often requiring several coders to dedicate significant amounts of time to code each of the discussion mes-sages. This approach (i) does not enable for a real-time feedback on the quality of learning interactions, and (ii) limits the wider adoption of the CoI framework by educational practitioners. This problem makes the task an ideal candidate for automation, and a number of approaches aimed at automating the process of cod-ing transcripts using machine learning techniques are in development [ 2 , 17 , 22 ]. While these approaches have produced promising results, their text classifica-tion models currently make class predictions on a per-message basis, using only features derived from a single post, without consideration of the context of a post or of the preceding classification sequence. Given that human coders take discussion context into account during the classification process, and that the underlying construct of cognitive presence develops over time [ 7 , 9 ], it seems likely that structural classification features can be used to model context in a similar fashion, and that these might improve classification accuracy. This paper presents the preliminary results of an alternate approach to the automated analysis of online discussions within online learning communities using Conditional Random Fields (CRFs) [ 26 ], which is a novel extension of previous work that aims to automate the text-classification of online discussions using the CoI framework. Our results show that the use of structural features in combination with a CRF model produce a higher classification accuracy than currently available methods. In Sect. 2 , the CoI model is briefly introduced, and examines current approaches of analysing community participants X   X  X ognitive presence X . Related applications of CRFs to online discussions are also reviewed. Section 3 outlines our approach, which aims to improve on existing approaches by combining structural features with a Linear-Chain CRF model. The results of this experiment are presented in Sect. 4 , where they are compared against cur-rent approaches and human accuracies. Structural features and their potential use across a number of contexts and discussion media are discussed in Sect. 5 , along with the limitations of the current study, which form the basis of the future work directions. Finally, the research and key contributions are summarised in Sect. 6 . 2.1 The Community of Inquiry (CoI) Framework Overview. The Community of Inquiry (CoI) framework [ 7 , 8 ] proposes three important dimensions (presences) of inquiry-based online learning: 1. Teaching presence defines the role of instructors before and for the duration 2. Social presence provides insights into the social climate between course 3. Cognitive presence is a central component of the framework and defines for the coding of student discussion messages, which is the main unit of analysis used to assess the level of the three presences. This framework has gained consid-erable attention in the educational research community, with a large number of replication studies and empirical validations (cf. [ 9 , 10 ]). Overall, the CoI frame-work and its coding schemes show sufficient levels of robustness (see Sect. 3.1 for an example) resulting in widespread adoption of the framework in the online education research community [ 10 ].
 munity members, due to its indication of their critical thinking. It is defined as the  X  X xtent to which the participants in any particular configuration of a com-munity of inquiry are able to construct meaning through sustained communica-tion. X  [ 8 , p. 11], and is operationalized through a practical inquiry model which defines the four phases of the inquiry process that occurs during learning [ 8 ]: 1. Triggering : In the first phase, students are faced with some problem or 2. Exploration : This phase is primarily characterized by the exploration X  X oth 3. Integration : After exploring different ideas, students synthesize the relevant 4. Resolution : In the final phase, students apply the newly constructed knowl-Challenges of CoI Framework Adoption. One of the biggest practical chal-lenges in adoption of the CoI framework  X  and other transcript analysis methods X  is that it requires experienced coders and substantial labor-intensive work to code (i.e. categorise) discussion messages for the levels of three presences [ 4 , 17 ]. As such, it is argued that this and similar approaches have had very little practical impact upon current educational practices [ 4 ]. To enable for a more proactive use of the Community of Inquiry framework by the course instructors, there is a need for an automated content analysis of online discussions that would provide instructors with a real-time feedback about student learning activities [ 15 ]. 2.2 Automated Classification of Student Discussion Messages Despite the labor intensive nature of manually coding online discussion messages, human coders that categorise online discussion messages into the phases of cogni-tive presence typically achieve very high intersubjective agreements. Moreover, the high levels of agreement among coders suggests that humans can identify the latent phases of cognitive presence from text-based discussions with relative ease. On the other hand, using machine learning to classify student messages in a similar manner is a challenging task. Where humans construct meaning from text using various inferences and abstractions that manifest as complex higher-order cognitive processes, machine learning approaches require meticu-lously constructed feature spaces, which are representative of the problem task. Kovanovi  X  c et al. [ 17 ] presented an approach to classifying cognitive presence from online discussions, using a Support Vector Machine (SVM) classification model, which achieved classification accuracy of 58.84 %. While the results of this work are promising, the overall performance of this approach is substantially less accurate than what can be achieved by human coders, which provides further evidence of the overall complexity of this task. In this approach, Kovanovi  X  c et al. [ 17 ] made use of lexical features derived from the content of each individ-ual discussion message that are prominent within the literature. These features consisted of various N-grams, POS tags, name entity counts and dependency tuples, as well as intuitive features such as whether a post or reply is the first in a discussion thread. In contrast, human coders may typically utilise contextual information when making their coding decisions, such as the structure the dis-cussion or the sequence in which discussion messages appear. Because of this, it is worth investigating how structural features about a discussion in addition to considering discussion messages in sequence may further improve classification performance.
 Beyond the CoI framework, many studies have acknowledged that accounting for the relationships between individual messages and the latent structure of dis-cussions may improve classification performance for transcript analysis [ 5 , 23 , 25 ]. Specifically, Ravi and Kim [ 23 ] suggests that using features derived from a pre-vious message can be a positive indicator for classification of the next post along in a discussion. Other related work in threaded-discussion classification that seeks to incorporate the structural features of discussions is becoming increas-ingly common [ 6 , 14 , 28 ]. The most common type of structural features utilised include a post X  X  position relative to others in a discussion, whether a post is the first or the last in a thread, how similar a post is as compared to its neighbours, and how many replies a post accrued. For this study, we attempt to account for the latent structure between posts in a discussion by incorporating these features into a Conditional Random Field approach.
 2.3 Conditional Random Fields for Automated Detection We have implemented a Conditional Random Field (CRF) classification model [ 26 ] to annotate posts within a discussion with the phases of cognitive pres-ence. Unlike traditional text classification methods, Conditional Random Fields consider the label sequence of a data set. Because of this, Conditional Random Fields have found numerous applications in natural language processing (NLP) tasks, such as part-of-speech (POS) tagging [ 18 ], document segmentation and summarisation [ 24 ], as well as gene prediction from biological sequence data [ 3 ]. where posts and interactions between participants are sequential in nature. Wang et al. [ 28 ] applied CRFs to discussion forums to learn the reply structure of forum interactions. This was achieved by using rich features that capture both short and long range dependencies within posts of an online discussion such as the lexical content similarity between two neighbouring posts. Similarly, FitzGerald et al. [ 6 ] combined the lexical features of posts with a Linear-Chain CRF to detect high quality comments in blog discussions, such as the word and sentence count of the post. Moreover, FitzGerald et al. [ 6 ] postulates that there exists sequential dependencies between posts in a forum, which emphasises the useful-ness of structural features derived from the entire discussion, as well as lexical features from a single post. To date, CRF classification has not been applied to the problem of automating the detection of Cognitive Presence in online discus-sion transcripts. Here, we show that making this step improves the accuracy of classification when compared with the current best practices. 3.1 Dataset The data used in this study comes from six offerings of a fully-online masters-level research-oriented course in software engineering at a Canadian public university. This is the same dataset as was used in the study by Kovanovi  X  c et al. [ 17 ]which makes for more accurate and direct comparison between the two different clas-sification approaches. In total, the data consists of 1,747 messages produced by 81 students. Each message was coded by two experienced coders who achieved an excellent level of coding agreement of 0.97 Cohen X  X  Kappa, which is a mea-sure commonly used to measure inter-rater reliability between coders using a quantitative categorisation scheme. Table 1 shows the distribution of messages in different phases of cognitive presence. The details of course structure and 3.2 Classifier Implementation For this study, we implemented a Linear-Chain Conditional Random Field (LCCRF) model to predict the phases of cognitive presence occurring in online discussions. This LCCRF was implemented in Java using the Mallet library [ 21 ], which is a widely used open source toolkit for machine learning. This library was extended as needed to suit our experimental requirements. 3.3 Data Preprocessing In this dataset, online discussions form a tree-like hierarchical structure (i.e., each discussion message can receive replies which can also receive replies). This presents a problem; in order to train and test our LCCRF implementation, the structure of the data must be linear, as opposed to the current tree structure. In order to obtain appropriate sequences of data, sub-threads were extracted such that every sequence of posts from the root node to every leaf node in a tree was obtained. To obtain reliable results, these sub-threads must be remerged after classification to produce one classification per message in a discussion; this remerging process in described in Sect. 4.1 . While other CRF models will accept hierarchical structures (e.g., such as Tree-Structured and Hierarchical CRFs), we chose a linear-chain model over other approaches due to the size constraints imposed by the dataset, which had only 84 coded discussion threads in total to use for training and testing a tree-structured model. Breaking these up into linear chains produced more message sequences that could be used to train our linear model.
 In addition to the extraction of linear sequences, the discussion threads in the data set were split into two sets; one for training and testing the CRF model, the other for validation from which our results are derived. These threads were split 70/20/10 % for training, testing and validation, respectively. 3.4 Classification Features Many of the features used for the purpose of this study were extracted using the various functionalities of the Stanford CoreNLP Java library [ 20 ], and are derived from the related work in our literature review. Each post in the discussion is described by a feature vector that attempts to encapsulate both lexical and structural features. In addition to word unigrams, lexical features were derived from the text content of a post itself, and structural features were used to indicate where a post resides in the context of the entire discussion thread. These features are presented below: 1. Entity Count is the number of entities within a post as found by the Stan-2. First Post and Last Post are boolean features that are set to true when a 3. Comment Depth is the number assigned to a post based on its chronological 4. Post Similarity of the previous and next post in a discussion is calculated 5. Word and Sentence counts capture the number of words and sentences 6. Number of Replies to a post, which provides the classifier with the intuition Because our classifier is sequential, these feature vectors are combined to form a feature vector sequence used in Mallet for training and testing our CRF clas-sification model. The aim of this study was to investigate whether classifying posts in sequence, with the addition of structural features improves upon the current approach to identifying cognitive presence in online learning discussions. In order to evaluate the effectiveness of our approach we use Cohen X  X  Kappa, which is a metric often used for judging the reliability of a categorisation scheme. Cohen X  X  Kappa is advantageous as it allows for a genuine comparison between the performance of human coders and our approach. A comparison between this experiment and the approach with the current highest accuracy is described in Table 2 . Before remerging the discussion threads, the CRF model achieved an accu-racy of 67.2 %, and 0.515 and 0.620 precision and recall respectively and a F-measure of 0.562. Because sub-threads were extracted for this experiment (detailed in Sect. 3.3 ), messages found earlier in the discussion threads have been classified multiple times. As a result of this, these accuracies are optimisti-cally high due to multiple correct classifications diluting the overall classification accuracies. This problem was fixed by re-merging the discussion threads back into their original hierarchical form in order using a majority vote mechanism. 4.1 Re-Merging Discussion Threads As mentioned earlier in Sect. 3.3 , every message sequence from a root post to every leaf node in a discussion was extracted to produce an appropriate linear sequence to train the LCCRF. This means that the earlier posts in a discussion may have been classified multiple times. Furthermore, the predicted phase need not necessarily be the same for these multiple classifications; a post that was classified as Triggering in one sequence might be classified as Exploration in the next sequence that it appears in. In order to obtain one classification result for each message in a threaded discussion, the sub-threads were remerged using a majority vote mechanism. This method of remerging posts results in a final accuracy of 64.2 % for the validation set. A large majority of posts that were classified multiple times belonged to the Triggering label, but many of these multiple classifications were correctly identified. Thus, the resulting small drop in performance is representative of the general classification accuracy obtained by the LCCRF. It seems that this implementation performs well at this type of classification task, with an overall precision and recall of 0.630 and 0.504 respectively and a F-measure of 0.559. Moreover, our implementation achieves a Cohen X  X  Kappa value of 0.482, which gives us a comparison with the human coding according to this widely used metric for judging the overall reliability of a coding or categorisation scheme. Table 2 demonstrates that while an improve-ment has been obtained, more work needs to be completed before we can be sure that an automated approach is performing at a level similar to human coders in this task. Our LCCRF approach shows promise for the automated classification of cog-nitive presence in discussions occurring within an online learning community. Moreover, the results of this work show a modest improvement over the work conducted by Kovanovi  X  c et al. [ 17 ], who presented an accuracy of 58.4 % as seen in Table 2 . The key differences in these two approaches is clear: our approach considers discussion messages in sequence, modelled via the CRF, utilising fea-tures that attempt to convey the context of the discussion. In contrast the work presented by Kovanovi  X  c et al. [ 17 ] considers each message separately, relying on primarily lexical features and a SVM.
 this text classification task. Using this approach, the classifier may more appro-priately model the dependencies between messages in online discussions. The structurally oriented feature-set allows for a contrast between posts that would otherwise contain very similar lexical features. By combining these features, the probabilistic CRF implementation appears to better model the dependencies between posts, leading to increased predictive performance. This improvement provides preliminary evidence of how modelling the structure of discussions, and considering discussion posts in sequence may be an important factor in further improving the automated detection of cognitive presence. Further studies using our approach will seek to confirm this theory by exploring alternate features and CRF implementations. 5.1 Limitations and Future Work One key limitation of this work is contextual, our results may be biased towards the single course from which the dataset was derived. Moreover, there are a num-ber of different platforms in which online learning discussions can take place. For example, a learning community using Social Media may be more informal in nature than one conducted in an institutes formal discussion forum. Using a model trained on one community may not produce reliable results for another community. Future research needs to consider data sets from courses in other subject areas and delivery modes (i.e., blended learning). One potential advan-tage of a structural approach is that it may perform more consistently across different datasets. A classification based upon structural features is more likely to prove robust under changed conditions than specific lexical characteristics, and so there is the possibility that the CRF approach will achieve better per-formance at text annotation across multiple discussion groups and fora. Further research and new datasets will be required to investigate whether this claim holds merit.
 investigated as future work. Because this approach uses a linear-chain model, some dependencies between messages in an online discussion may be missed. However, this linear model allows for the implementation of coding practice rules used by various CoI coding schemes, such as  X  X oding up X  X  i.e., when a message has traces of two phases of cognitive presence, it is coded with the higher phase [ 16 ]. Despite this, approaches that might better model dependen-cies across hierarchical structures, such as a tree CRF may further improve on our current accuracy. As seen in Table 1 , the distribution of phases (class labels) in our dataset is largely uneven. This disparity between the individual phases of cognitive presence is seen in the predictive performance of our classifier, where the lowest represented phases are typically classified correctly less often than that of their higher represented counterparts. Unfortunately, collaboration within online learning communities commonly takes this form, where learners typically do not progress to the resolution phase of cognitive presence [ 11 , 12 ]. Future attempts at automation may benefit from a method of accounting for this uneven distribution of class labels.
 In order to replace the current approach to analysing online learning commu-nities with manual hand-coding transcripts, we aim to achieve Cohen X  X  Kappa value of close to 0.80, which indicates an almost perfect agreement among coders according to the Landis and Koch [ 19 ] interpretation of Cohen X  X  Kappa. Our CRF approach achieved a Kappa value of 0.482, which indicates a moderate agreement, but will require further improvement before machine learning tech-niques can replace hand coders. Future work will aim to further improve our classifier X  X  performance. Specifically, we plan to further improve our model by: (i) evaluating our model on another, larger dataset with a more even distribution of phases; (ii) seeking additional features that may improve upon our current accuracies, such as Coh-Metrix [ 13 ] and features derived from the Linguistic Inquiry and Word Count (LIWC) framework [ 27 ] that are commonly used to characterise cognitive processing associated with comprehending and producing text and discourse, and; (iii) better modelling the dependencies between threaded discussions using a Tree-Structured CRF model approach. In this work, we presented a new approach to automating the detection of the four phases of cognitive presence arising in online discussions. By reconceptualis-ing online discussions as a sequence prediction problem, we predicted a sequence of labels (i.e. the phases of cognitive presence) for a sequence of messages. This allowed us to use a linear chain Conditional Random Field model for classifi-cation, which incorporates structural features of online discussions rather than just the lexical features that have previously been applied to solving this prob-lem. This approach to automating the detection of cognitive presence has shown promise, with moderate improvements over alternative approaches with an accu-racy of 64.2 % and a Cohen X  X  Kappa value of 0.482. However, classification accu-racies are not yet high enough to replace the current approach of manually coding transcripts. Further improving this model is a priority for future work where we aim to further evaluate the model on alternative datasets, investigate additional features, and attempt to better model the dependencies between posts using a tree-structured CRF model.

