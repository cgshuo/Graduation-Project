 Scientists often search for document-elements like tables, figures, or algorithm pseudo-codes. Domain scientists and researchers re-port important data, results and algorithms using these document-elements; readers want to compare the reported results with their findings. Some document-element search engines have been pro-posed (especially to search for tables and figures) to make this task easier. While searching for document-elements today, the end-user is presented with the caption of the document-element and a sen-tence in the document text that refers to the document-element. Of-tentimes, the caption and the reference text do not contain enough information to interpret the document-element. In this paper, we present the first set of methods to extract this useful information (synopsis) related to document-elements automatically. We also in-vestigate the problem of choosing the optimum synopsis-size that strikes a balance between information content and size of the gen-erated synopses.
 H.3.3 [ INFORMATION STORAGE AND RETRIEVAL ]: Infor-mation Search and Retrieval; H.5.2 [ INFORMATION INTER-FACES AND PRESENTATION ]: User Interfaces Algorithms, Experimentation.
 classification, document-element, summarization, synopses.
Authors use document-elements for a variety of purposes like reporting and summarizing experimental results (plots, tables), de-scribing a process (flow charts) or presenting an algorithm (pseudo-code). A document-element is defined as an entity, separate from the running text of the document, that either augments or summa-rizes the information contained in the running text. Figures, ta-bles and pseudo-codes for algorithms are the most commonly used Figure 1: A sample figure and its caption. Figure is taken from[1]. document-elements in scientific literature and are sources of valu-able information. Recently, significant efforts have been made to utilize and extract the information present in document-elements. CiteSeerX 1 , a major computer science digital library, has intro-duced a table search feature in addition to normal document search. Likewise, a specialized search engine for biology documents, Bio-Text Search Engine , offers capability to search for figures and tables in the documents[3].

Such special-purpose document-element search engines return a list of document-elements and a snippet constructed from the docu-ment. Often the end-user wants to examine more information than is available in the snippets because he or she can not always inter-pret the information content of document-elements by examining just the snippet as illustrated by Figure 1. Even though the asso-ciated caption and legend help in understanding the information presented in a figure, they hardly provide enough details to fully understand and interpret them.

In this work, we show a way to automatically extract information related to document-elements from the document text. We refer to this extracted information as a synopsis . Availability of a concise and relevant synopsis saves the end-users X  time when they are ex-amining search results to find something that satisfies their infor-mation needs. In Figure 2, we show the synopsis generated by our method for the figure shown in Figure 1. It can be seen that the mes-sage in Figure 1 becomes much clearer with this additional piece of information. Thus, our tool increases the degree of automation of information seeking and improves productivity of end-users.
Extracting a synopsis for a document-element from a digital doc-ument involves filtering information related to the document-element http://www.citeseerx.ist.psu.edu Fig. 3 illustrates the training results of TSVM and PTSVM on Tutorial dataset. The solid line is the final hyperplane found by PTSVM and the dashed line is the final hyperplane found by TSVM. As shown in Fig. 3, the wrong estimation for value of
N is responsible for bad performance of TSVM. This problem is successfully avoided in PTSVM. We can also find out that the training time of PTSVM is much shorter than that of TSVM.
This is mainly due to the fact that TSVM need to successively increase the value of C and calculation has to be done for every Cvalue.
 Figure 2: Information extracted by our method for the figure described in Figure 1. from the rest of the information contained in the document. Solv-ing this problem accurately is easy if we understand the semantics of the text automatically. However, state-of-the-art techniques of natural language processing and statistical text processing still fall short in fully understanding the semantics of text documents. Ad-ditionally, good synopsis generation involves making a judgment call regarding the level of detail that may be useful to an end-user. If we generate a very large synopsis, it will be comprehensive, but the users X  needs of finding information quickly will not be met. If we generate a very short synopsis, the user will not understand the document-elements clearly. We aim at striking a balance between these conflicting needs using automated synopsis-generation meth-ods.

Previous research on document-elements has focused on knowl-edge extraction [5, 4] and developing techniques for document-element search [7, 3]. Futrelle introduces the idea of diagram sum-marization and explores various related issues and problems [2]. However, none of these work addressed the problem of actually summarizing a document-element and to provide related textual in-formation that may help the user in the relevance judgment of a particular table or figure. In the present work we propose a method for extracting document-element related information from digital documents automatically. We adopt machine learning techniques and develop a novel feature set for identifying document-element related sentences. We also propose a simple model for sentence se-lection that tries to strike a balance between the information content and length of the synopsis.
In this section we describe the strategies for automatically identi-fying document-element related information. We treat this problem as a classification task -each sentence is either relevant or non-relevant for a document-element.
The process of synopsis generation starts with the conversion of digital documents (pdf format) into text format followed by sen-tence segmentation which splits up the document text into its con-stituent sentences. The next step in the process involves parsing the document-element captions. Captions contain useful information cues that help understand the content of a document-element. A well-framed caption shows the purpose of the document-element. In order to deal with variations in caption format across different domains and writing styles, we propose the following grammar to distinguish and extract caption sentences from rest of the sentences: The CAPTION non-terminal in this grammar has 4 sub-parts. DOC_EL_TYPE specifies the type of the document element that can be a figure, a table or an algorithm. FIG_TYPE, TABLE_TYPE and ALGO_TYPE refer to the variations of the words  X  X igure X ,  X  X able X  and  X  X lgorithm X  respectively. The DOC_EL_TYPE non-terminal is followed by an integer that represents the document-element number and is used to track the corresponding elements and their reference sentences. The integer is followed by a DE-LIMITER that can again be either  X : X  or  X . X . The final non-terminal TEXT gives a textual description of the element.

Although captions provide some details about the element of in-terest, we have to analyze the running text also in order to get com-plete understanding of the content and context of the document el-ement under consideration [2]. Assuming good writing style, we hope to find at least one explicit reference to a particular document-element that can reveal certain details about the element. To iden-tify such reference sentences, we use a grammar similar to the one used for caption parsing. Note that in the reference sentence, the delimiter will not be present in most cases and the integer will tell us which element this sentence is referencing to.
In this section we describe features that try to capture how well a sentence describes the content and context information of a document-element. 1. Similarity with Caption (CapSYM): This feature utilizes 2. Similarity with Reference Sentence (RefSYM): To utilize 3. Cue Words and Phrases (CP): Certain cue words and phrases
The features described above assume all sentences to be equally important. This assumption, however, is not true as generally when a document-element is referenced in the running text, the nearby sentences also relate to the document-element and become  X  X ontex-tually X  more important than the other sentences. These  X  X earby X  sentences provide the  X  X ontext X  in which a document-element is being described or used. We use the following features to identify and capture these contextually important sentences: 1. IfReference Sentence (IfRefSent): It is a binary feature 2. Paragraph Location (IsInSamePara): It is again a binary 3. Proximity: This feature captures the fact that a sentence
We use Na X ve-Bayes classifier for identifying document-element related sentences. Na X ve-Bayes classifier has been previously used successfully for sentence extraction task for document summariza-tion[6, 10] and is defined as follows:
Let the set of sentences that are related to the document-element d be S d and let S be the set of all sentences in the document Given the features F 1 ,F 2 , ..., F n for sentence s  X  X  , application of Bayes X  rule assuming independent features yields the probability that s also belongs to S d , as follows:
The probabilities P ( F i | s  X  X  d ) and P ( F i ) are not known apriori but they can be estimated by counting occurrences in the training set. This gives a simple Bayesian classification function that assigns a probability score to each sentence in the document. The top-scoring sentences can be identified as related to document-elements. Note that P ( s  X  X  d ) is same for all sentences in the document and is therefore a constant.
After identifying the document-element related sentences, we need to decide how many and what sentences to include in the syn-opsis that will be presented to the user. Presenting all the relevant sentences to the user might have a detrimental effect on the read-ability of the synopsis. A longer synopsis might be comprehensive, but it requires more time to read and understand, thereby defeating the whole purpose of making search results more user-friendly. It is therefore required to determine an optimum synopsis size that balances the trade-off between information content and readability and effectiveness of the synopsis.

In general, the sentence selection problem can be framed as fol-lows: let U k be the Utility measure of sentence s k that tells us whether it is useful to select the sentence or not. Let the score of k th sentence be score k and let all sentences be ranked in decreas-ing order of their scores so that i &lt; j implies score i define the Utility measure U k as:
We include a sentence in the synopsis if and only if its utility is greater than zero. Here Utility of a sentence is determined by two competing factors  X  (a) Relevance of the sentence to the document-element which is measured by the score of the sentence; (b) Penalty incurred by having an additional sentence s k in the synopsis.  X  is the Penalty Parameter that controls the magnitude by which sen-tences are being penalized and thus, determines the length of the synopses.

The final set of selected sentences is arranged in the order in which they appear in the document. Non-consecutive sentences are separated by ellipsis ( ...) tomaintainreadab ility and cohesiveness of the synopsis.
In this section, we evaluate the effectiveness of the proposed method for extracting the document-element related information. For our experiments, we randomly selected 140 document-elements from different Computer Science publications. For each document-element, the relevant sentences were manually identified from the associated document by two human evaluators and were assigned a label 1. All other sentences in the associated document were as-signed a label -1.
The aim of this experiment is to evaluate how well the pro-posed methods are able to identify the document-element related sentences. If the model learned is reasonable, then the sentences with a higher probability score are more relevant than sentences with a lower score. Thus, we get a ranked list of relevant sentences for each document-element. As discussed by Kanungo and Met-zler, R -precision is more appropriate than using precision at a fixed value for sentence selection task because for different &lt;document-element, document&gt; pairs, the value of R is different and ideally, we want to return only these R relevant sentences[8].

We use 5-fold cross validation for evaluation. Table 1 reports the Precision values at N averaged over five validations where N = {1,2,3,4,5} and also the R -precision values. Note that here R is different for different document-elements. It can be observed that the performance of the proposed method is appreciable for the sentence extraction task. High precision values at top ranks indicate that the scores assigned on the basis of learned models are good indicators of the relevance of sentences to document-elements. Table 1: Different precision values for the sentence extraction task.
In this section we evaluate our proposed sentence selection strat-egy to select a subset of top-ranking sentences that should be in-cluded in the final synopsis to be presented to the user. The penalty parameter  X  , as defined in equation 3, controls the length of gen-erated synopses by penalizing the inclusion of additional sentences in the synopses. In order to study the behavior of generated syn-opses with varying  X  , we generated synopses for different values of  X  , varying from 0 to 1, with increments of 0.01. For each value of  X  , we compute the average length of synopses (in number of sen-tences) and F1 measure. The results are summarized in Figure 3. Note that the variation of average length of synopses is shown on a log scale.

From the figure, we observe that the average length of synopses decreases with increasing  X  . For very small values of  X  , almost no penalty is being incurred by inclusion of additional sentences. The model tries to maximize the information content and we end up with pretty long synopses. As we increase  X  , the amount of penalty also increases and the less relevant sentences are being filtered out. For very high values of  X  , the model favors highly concise syn-opses. The F1 measure, which considers both the precision and recall values simultaneously, follow an interesting trend. It first in-creases with increasing  X  , achieves a maximum at  X  =0 . 06 then gradually falls. The F1 values remain stable in the range 0.61  X  0.69 for  X  = 0.05  X  .35. The average synopses length in the same range lies in between 3 . 6 to 9 . 4 . Here, the use of penalty parame-ter  X  provides us with a simple but powerful means of generating variable length synopses as per the user needs. Initially, using a moderate value of  X  (say 0.3), we can provide a concise and highly informative synopsis. Then, if the user wishes to know more about the document-element, synopses generated with lower values of  X  can be presented (using relevant feedback techniques).
The present work identified the problem of generating synopses for document-elements like tables and figures in digital documents. Machine learning techniques are used to identify relevant sentences from the document text using a novel set of features that utilizes content and context information related to document-elements. A simple model is proposed to determine which sentences to include in the final synopsis. The model tries to balance the information content and length of the description so that the generated syn-opses are both effective and useful. Our future work would include developing more features to improve the quality of generated syn-opses and to investigate the use of synopses for improved document search and document summarization.
This material is based upon work supported by the National Sci-ence Foundation under Grant Nos. 0535656 and 0845487.
