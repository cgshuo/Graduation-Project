 Recently, privacy preserving graph publi cation has become a hot research topic and many graph protecting models have been proposed [9,7,3,12,11,13,14,1]. All these models assume there is a trustable centralized data source, which has a complete origi-nal graph G , and can directly generate the privacy preserving graph G from G .
However, in reality, people join different social networks due to different interests or purposes. For example, a person uses Facebook to share his information with his classmates and coworkers. At the same time, he may also build his blog on a blog server to share his interests with others. As a result, his connection information is stored in two social networks. A consequence of t his joining preference is that each social network website only holds partial information (a subgraph) of the complete social network G . We call such a social network website as a data agent. Consider a social graph as shown in Figure 1 where each person has two labels and people are involved in different interactions, the graph can be stored on three data agents, A 1 , A 2 and A 3 separately as shown in Figure 2.

Although people join different networks, it is often necessary to obtain a privacy pre-serving graph generated from the complete graph for criminal investigation [8] or min-ing useful patterns/influential persons [4,8,6]. This requests that the distributed agents should cooperatively generate a privacy preserving graph G . There are three potential approaches to do this (Figure 3).
A Third-Party approach (Figure 3(a)) is to let all the data agents send their local con-tents to a trustable third party agent, where the published graph by integrating all the data. However, since the data of each site is its most valuable asset, no one is willing to share its data with others, finding such a trustable third party data agent is not feasible in the real world. The naive approach (Figure 3 (b)) is to let each data agent generate a pri-vacy preserving graph based on its own content and securely combine them into a large privacy preserving graph 1 . Secure combination means no l ocal content is released dur-ing the process. However, this approach encounters two problems: (1) It results in the low quality of the published data since the gra ph is constructed only based on local in-formation instead of the complete graph; (2) A privacy preserving graph generated only by local information may violate the privacy requirement when globally more connec-tion information is provided considering the connections between nodes [9,13,14,2,1]. The secure combination needs t o delete some connections to ensure the final published graph satisfies the privacy requirement. The refore, the published graph will have incom-plete information. A nother approach (Figure 3(c)) is that each data agent participates in a protocol to produce a privacy preserving graph. The privacy preserving graph is generated just as there virtually exists an agent who has the integrated data. During the computation, except the content derived from the final published graph, the pro-tocol controls no additional local content of a data agent is released. This solution is known as the famous Secure Multi-Party Computation (SMC). SMC deals with a prob-lem where a set of parties with private data wish to jointly compute a function of their data. A lot of SMC protocols have been proposed for different computation problems, but not for privacy preserving graph publishing in a distributed environment. SMC has two requirements: 1) Correctness requireme nt: the computation is performed in a dis-tributed environment just the same as doing it on an agent who holds the integrated data; 2) Security requirement: each data ag ent should not know the local information of other agents even with the intermedi ate results passing through each other.
In this paper, we follow the SMC approach and design a secure protocol SP to al-low the data agents to cooperately generate a graph G based on a recently proposed protection model [1], called S-Clustering. Through clustering methods, S-Clustering publishes a graph G that only contains super nodes ( clusters) where each super node represents multiple nodes in G . We call a published graph which satisfies S-Clustering as the S-Clustering graph. We refer the algorithm which generates the S-Clustering graph in a centralized environment as the cen tralized algorithm. The distributed ver-sion of the centralized algorithm, SP , should work the same as running the centralized algorithm on the complete original graph. For any data agent, SP protects its local information when generating the published graph. We propose novel solutions in SP based on random lock, permutati on, and Millionaire Protocol [10]. 2.1 Graph, Storage Model and Problem Definition An online social network with rich interactions can be represented as a bipartite graph G ( V,I,E ) [1], where each node in V represents an entity in the network and each node in I stands for an interaction between a subset of entities in V . An edge e ( u, i )  X  E ( u  X  V , i  X  I ) means entity u participants in the interaction i . Each entity has an identity and a group of attributes. Without lo ss of generality, each entity X  X  identifier can be represented as a unique id within [1 , | V | ] . The commutative encryption scheme [8] can assign each name a unique number id without releasing the real name values in a distributed environment. In the rest part of this paper, we refer entity u as the same as the entity with id u . Each interaction also has an identity and a set of properties as shown in Figure 1. An interaction can involve more than two entities, such as the interaction  X  X ame3 X . Two entities can also be involved in different interactions at the same time. For example, in Figure 1, v 1 and v 2 participate in  X  X log1 X  and  X  X log2 X  simultaneously.
In a distributed environment, the graph G is distributively stored on l different data agents. That is, each agent A i holds a portion of the graph G i ( V i ,I i ,E i ) such that may be stored on different agents. The G i held by different data agents may overlap, such that the intersection between two graphs stored on different agents might not be an empty set. 2 That is,  X  l i =1 V i =  X  and  X  l i =1 I i =  X  .
In the rest of this paper, we use node to specifically represent an entity in V and use interaction to represent an item in I . When we say two nodes u , v have a connection , it means u and v are involved in a same interaction i in I (In the graph, we have two edges e ( u, i ) and e ( v, i ) ).

We propose a protocol which securely generates a S-Clustering graph [1] for in-teraction based graphs in a distributed environment. S-Clustering [1] assumes that an attacker can know the id, label and any connection information of a node. An attacker uses the information he knows about some users to analyze the published graph in order to learn more about these users. Given a constant k , S-Clustering publishes a clustered graph (S-Clustering graph) which guarantees the following three Privacy objectives : Objective 1: For any node u , an attacker has at most 1 k probability to recognize it. Objective 2: For any interaction i , an attacker has at most 1 k probability to know a node Objective 3: For any two nodes u and v , an attacker has at most 1 k probability to know We assume that all participants joined in the computation, including all data agents and necessary extra servers are semi-honest. The local information beyonds the Privacy objectives of S-Clustering is protected. The problem we solve in this paper is: 1. Input :Agraph G distributed stored on l data agents and a privacy parameter k . 2. Output : A S-Clustering graph G of G under k . 3. Constraints : (a) Correctness: G is computed the same as generating it on an agent 2.2 S-Clustering Model Given a graph G ( V,I,E ) , to satisfy the three privacy objectives, a S-Clustering graph G ( CV,I,CE ) is published, where CV is a super node (cluster) set in which each super node represents a group of entities in V .Weuse c to denote a cluster in CV and | c | to denote the cluster size, which is the number of entities that c represents. For each in G . Figure 4 is a clustered graph of Figure 1.
To guarantee the three privacy objectives, the S-Clustering graph G must satisfy:  X  Each cluster represents at least k entities. This guarantees the Objective (1).  X  The Clustering Safety Condition (CSC) [1]: Definition 1. A division (clustering) of nodes V into clusters satisfies the Clustering Safety Condition (CSC) if for any node v  X  V , v participates in interactions with at most one node in any cluster S  X  V , that is:  X   X  e ( v, i ) ,e ( w, i ) ,e ( v, j ) ,e ( z,j )  X  E : w  X  S  X  z  X  S  X  z = w ;  X   X  e ( v, i ) ,e ( w, i )  X  E : v  X  S  X  w  X  S  X  v = w ; This condition guarantees Objectives (2) and (3).

The CSC requires that any two nodes in a cluster cannot be connected or connect to the same node. Figure 4 is a clustered graph which satisfies CSC . For any two nodes that appear in the same cluster of Figure 4, they do not have a connection or connected to the same third node. For any two nodes u and v , if they satisfy (or do not satisfy) the CSC , we denote this as CSC ( u, v ) (or  X  CSC ( u, v ) ). Similarly, for a cluster c and a node u ,if u satisfies (or does not satisfy) CSC with all the nodes in c , we denote this as CSC ( c, u ) (or  X  CSC ( c, u ) ). 3.1 Overview We proposed SP to generate a S-Clustering graph in a distributed environment as shown in Algorithm 1. We call a computation that satisfies the Security requirement as a Secure Computation. Thus, SP contains four stages such that each stage conducts one Secure Computation in lines 1, 7, 15, and 16, respectively. Stage 1 sorts nodes without releasing any degree information. Stage 2 clusters nodes by correctly checking
Algorithm 1. Clustering with CSC in distributed environment CSC ( c, v ) without releasing any connection information. Stage 3 and Stage 4 gener-ate the interactions on clusters and attributes for clusters respectively without disclos-ing any interaction-node mapping and node-attribute mapping. To summarize, we must avoid the releasing of the following information during computation: (1) Degree infor-mation (from Stage 1); (2) Specific node-attribute mapping (from Stage 4); (3) Specific connection information, including node-interaction mapping and connection between nodes (from Stage 2 &amp; 3); (4) Any  X  CSC result and the computation order of nodes (from Stage 1 &amp; 2).

Next, we introduce our design of SP for each stage in detail. Due to space limitation, we ignore all the proofs. Before presenting SP , we assume each node/interaction has a weight that represents how many duplicated copies of this node/interaction have been stored in the system. We call these weights duplicated weights . Details of the method to generate duplicated weights is shown in Appendix A. 3.2 Stage 1: Secure Sorting Sub-Protocol (SSSP) Protocol Design. In this stage, we sort the nodes without revealing any degree infor-mation and the computation order of nodes (the sorting order of nodes on real id s) information. The basic idea is to do the sorting on permuted id s with their correspond-ing  X  X ocked X  degree values. We use the random number to lock the real degree of each node. That is, we make one agent hold a key ( a random number) and another agent hold the locked degree value (real degree plus this random number). Then, we sort all nodes on permuted id s through the cooperation of these two agents. During the sorting, the agent who has the locked degree values cannot learn any key value and the agent who holds the keys cannot learn any locked valu e. The Secure Sortin g Sub-Prot ocol (SSSP) works as follows (Figure 5): Theorem 1. SSSP sorts all nodes on  X  ( id ) s under the Security requirement. 3.3 Stage 2: Secure Clustering Sub-Protocol (SCSP) Protocol Design. In Stage 2, we need to cluster nodes based on the sorted order L without revealing any connection information.

Since S 1 holds L after Stage 1, in SCSP , we continue to make S 1 generate clusters on  X  ( id ) s. Before S 1 can do clustering on  X  ( id ) s, the connection information between nodes should be mapped on  X  ( id ) s firstly. So, SCSP contains the following three steps: The first two steps map the connection information on  X  ( id ) s(The [0 , 1] character of NMR  X  NMR will be used for securely clustering). The last step does the clustering on the connection information between  X  ( id ) s. During the computation, to satisfy the Security requirement, we make the agent who holds MR , NMR or  X  ( NMR ) cannot get the noised content MR , NMR or  X  ( NMR ) and vice versa.

The first step computes MR and MR securely as follows: After the first step, A l gets a noised matrix MR . For any nodes u and v , MR [ u ][ v ]  X  MR [ u ][ v ] &gt; 0 is equivalent to u and v have a connection. The second step securely computes the matrices NMR and NMR asshowninFigure6:
The third step is to do the clustering on  X  ( id ) s. Before introducing how S 1 conducts the clustering, we prove a property we use in the next computation. For a node u ,we nodes u and v have a connection, E u [ i ]=1 ,otherwise E u [ i ]=0 . For example, node v C , we call E C =(  X  u  X  C E u ) as C  X  X  connection vector . The connection vector has the following property: Theorem 2. For any cluster of nodes C , if there exists a t where E C [ t ] &gt; 1 ,then C does not satisfy CSC ;otherwise, C satisfies the CSC .
 For a cluster of nodes C on  X  ( id ) s, it is obvious E C =  X  u  X  C (  X  ( NMR )[ u ]  X   X  ( NMR )[ u ]) . Based on the property of connection vector, when S 1 needs to check whether v can join a cluster c based on CSC , the protocol works as follows (Figure 7): S 1 does the clustering on L and uses the above method to test CSC . S 1 finally gets the cluster set CV on  X  ( id ) s and passes CV to A 1 . A 1 computes the cluster set on real ids CV =  X   X  1 ( CV ) .
 Theorem 3. SCSP clusters all nodes without violating the Security requirement. 3.4 Stage 3: Secure Edge Generation Sub-Protocol (SESP) Protocol Design. In Stage 3, we generate the inte ractions among clusters. After A 1 gets the cluster set CV on real ids, A 1 reports CV to all A i s one by one. Each A i gen-erates the interactions between clusters and sends the results to A i +1 . Finally A l gets a clustered graph with correct interactions. T he above process only passes the connection information through interactions without the attribute information. Each A i directly sends the attribute of each interaction to A l since all the interactions will be clearly published. Since the interactions between super nodes reported by each A i is a sub-set of the final result, the middle results are already included in the published graph. Therefore the Security requirement is satisfied. 3.5 Stage 4: Secure Label Generation Sub-Protocol (SLSP) Protocol Design. In Stage 4, we generate the node attributes for each cluster without disclosing any specific node-attribute mapping. Suppose there are m attributes for each node. The Secure Label Generation Protocol (SLGP) works as shown in Figure 8. This is similar to Stage 1. Due to page limitation, we ignore the detailed description. Theorem 4. SLSP assigns node attributes to each cluster without violating the Secu-rity requirement.
 Based on the above step by step illustration of Algorithm, we conclude that the whole SP satisfies the Correctness and Security requirements. The intermediate results of one stage do not influence other stages since computation contents are different. Since each stage satisfies the Security requirement, the whole SP also satisfies the Security requirement. To demonstrate the effectiveness of SP pro tocol, we implement a Relaxed Secure Pro-tocol (RSP) which is based on the naive approach (Fig. 3(b)). The brief introduction to the design of RSP is shown in Appendix B. We compare the graph generated We compare the graph generated by RSP and SP . 4.1 Criteria We focus on two aspects to show the benefit of designing a SMC protocol: the infor-mation loss and the utilities. We estimate the information loss of RSP comparing with SP ( SP does not delete any interaction). Assume del is the number of interactions that are deleted by RSP and the original complete graph contains | I | interactions, we use the ratio of deleted interactions ( 100 del | I | % ) to represent the information loss.
Utility is used to estimate the quality of the pub lished graph. For the clustering-based protection models [7,12,1], the utility testing is operated by drawing sample graphs from the published one, measuring the utility of each sample and aggregating utilities across samples. We test the following measures: 1. Degree distribution : Suppose the sorted degree sequence of the original graph G is 2. A group of randomly selected queries : We test three aggregate queries as the same 4.2 Data Set and Distributed Storage ArXiv (arXiv.org). ArXiv(arXiv.org) is an e-print service system in Physics, Computer Science etc. We extract the co-author graphs in Computer Science. Each node denotes an author, and each interaction means a unique coauthor paper. The ArXiv provides 37 categories in Computer Science to search the papers. Since most people work in multi-ple sub-fields and each paper also belongs to mu ltiple sub-fields, the authors of papers in different categories are overlapped and finally form a large graph. We set each au-thor X  X  research field as his/her node label. We divide the 37 categories to 6 sets and store the crawled graph of each category set on one data agent. This can be seen as different data agents maintain the relationship of people in different fields. The integrated graph contains 28868 nodes and 23290 inte ractions. On average, each interaction is involved by 2 . 4 nodes.

We consider the following two distributed storage cases: 1. Real Distributed Case: The 6 subgraphs we crawled in different research fields can 2. Simulated Distributed Case: We manually divide the integrated graph G to6parts 4.3 Result Result on Real Distributed Case We compare the performance of SP and RSP under different privacy parameter k s. Figure 9(a) shows the result of information loss. RSP deletes 13% to 17% interac-tions. This is a fairly significant information loss. The published graph by RSP fails to correctly represent the original graph. Figure 9(b) shows the comparison of degree sequence distance. RSP performs 45% to 80% worse than SP . The published graph by RSP is much worse than SP when estimating by the degree distribution. Figure 9(c) shows the results of queries. In most cases, the RSP performs 10% to 25% worse than SP . In most cases, SP gets a much better graph than RSP .
 Result on Simulated Distributed Case For the Simulated Distributed Case, we set k =5 and compare the performance of SP and RSP with different node overlapping ratio r s. Figure 10(a) shows the number of deleted interactions. Larger r means more overlapping between data agents and more chances to delete an interaction. In most cases, RSP deletes 10% to 20% interactions. Figure 10(b) shows the comparison of degree sequence distance. RSP performs 25% to 45% worse than SP . Figure 9(c) shows the results of queries. In most cases, the RSP performs 5% to 35% worse than SP . SP generates a graph with higher utilities than RSP .

From the testing results, we can find SP exhibits benefits on both information com-pleteness and the u tilities of the published g raphs. Firstly, the RSP deletes roughly 13%-19% interactions, publishing a graph which loses such a large portion of infor-mation is not acceptable. While SP guarantees no information loss in the published graph. Secondly, the utilities of t he graph generated by SP are much better than RSP . It is necessary to design a SMC protocol such as SP for the privacy preserving graph publication problem. Actually, since SP has the same effect as running the state-of-art centralized graph construction algorithm on the complete original graph, the published graph generated by SP can be seen as the best. Two models are proposed to publish a privac y preserving graph: the edge editing based model [9,13,14,2,11] and the clustering based model [7,12,1]. The edge editing based model is to add/delete edges to make the published graph satisfy certain properties ac-cording to the privacy requirements. For example, Liu[9] defined and implemented the k-Degree anonymous model on network structure, with which there exists at least other k  X  1 nodes having the same degree as any node in a published graph. The clustering based model is to cluster  X  X imilar X  nodes into super nodes. Since a clustered graph only contains super nodes, the p robability of re-identifyi ng any user can be bounded to 1 k by making each cluster X  X  size at least k .

Frikken [4] designed a protocol which allows a group of agents to generate an in-tegrated graph. However, the graph generated by this protocol cannot provide the pro-tections against the complex attacks propos ed in recent works [9,7,3,12,11,13,1,14]. Kerschbaum [8] designed a protocol to generate an anonymized graph from multiple data agents. Each edge in the anonymized graph has a digital signature which can help trace where this edge comes from. While, simple removing the identifiers of nodes in a graph cannot resist an attack which aims to re-identify the nodes/links [7]. There-fore, it is essential to investigate protocols that support the stronger protection models [9,7,3,12,11,13,1,14] in a distributed environment. Our work generates the published graph which follows the recently proposed S-Clustering protection model. This model protects nodes and links against the strongest attack which may use any information around nodes. Moreover, our work supports a more flexible graph model while the pro-tocols of Keith [4] and Florian [8] only support the homogeneous graphs. In this paper, we target on the secure multi-party privacy preserving social network publication problem. We design a SMC protocol SP for the latest clustering based graph protection model. SP can securely generate a published graph with the same quality as the one generated in the centralized environment. As far as our knowledge, this is the first work on SMC privacy preserving graph publication against the  X  X tructure attack X . In the future, one interesting direction is to study how to enhance the current solution to handle the malicious or accessory agents. How to design SMC protocols for the editing based graph protection models will be another interesting direction. Acknowledgments. This work is supported in part by Hong Kong RGC grants
