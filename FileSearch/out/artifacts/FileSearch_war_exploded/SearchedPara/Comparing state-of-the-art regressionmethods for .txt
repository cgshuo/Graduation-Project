 a Departamento de Engenharia Inform  X  atica, Faculdade de Engenharia, Universidade do Porto, Porto, Portugal c Departamento de Engenharia Industrial e Gest  X  ao, Faculdade de Engenharia, Universidade do Porto, Porto, Portugal 1. Introduction
Travel time prediction (TTP) for the long-term could be used in order to better plan transportation be done to better plan the deliveries. Typically, at the best, the existing approaches to address this problem use average times by segmenting time empirically: early morning, morning peak period, etc. This approach can be explained, at least partially, by the lack of data on actual times. Some companies that work in this business do not follow regular routes leading to a reduced number of trips per route. Consequently, in such conditions travel time cannot be accurately predicted due to data sparsity. The only known work on long term TTP was developed for a route planner owned by ANWB, a motorist association from the Netherlands [29].

The reason why long term TTP is not used in public transportation companies is different. In the nineties, some companies began the implementation of dispatch systems that allow the monitoring of the fl eet and the archive of respective actual services [46]. Nowadays this kind of systems is used by many public transport providers, specially in developed countries. The use of long term TTP for the planning of public transport companies does not depend on data availability but, instead, on the lack of transport company. They are usually done in the following sequential way [8,14,33]: 1. The network de fi nition: it is, obviously, a planning task for the long/very long term. It comprises 2. The trips de fi nition: it is a medium term task, with an horizon much shorter than the network 3. The de fi nition of the duties of the drivers and buses: they are medium term (several months) tasks.
The sequential nature of this planning process and the complexity of these tasks are, probably, the main reasons for the lack of planning procedures using long-term TTP. All this sequential process is strongly time consuming. Additionally, once the duties are planned changes in travel times can have an effect on these planned duties that is hardly predictable. How to use TTP in the planning of public transport companies is, nowadays, the main question. Is it possible to use more fl exible planning processes in order to reduce the prediction horizon? How short can this horizon be if the planning is done from the yet answers to them. The use of long-term TTP can imply the change of some planning procedures. More study must be done in order to better understand the gains and costs from the use of long-term TTP.
In this paper we address the problem of long term TTP. We believe this is an important study which be) needed. We hope that this paper can give a contribution to increase the knowledge on how to perform TTP for the long term. This paper is an extended version of [40]. This previous paper of 8 pages length was more oriented towards the machine learning process. The present paper describes with much more detail the experiments done and makes the bridge between the business problem and the data mining problem.
 In order to predict long term TTP we have chosen three state-of-the-art regression methods: Projection Pursuit Regression, Support Vector Machines and Random Forests. Since each induction algorithm has a set of parameters we have conducted experiments in order to choose the best set of input parameters for each algorithm. However, the performance of these algorithms also depends on the pre-processing tasks, i.e., tasks that are performed before the training of the model. These tasks change somehow the The three experiments we have done on pre-processing tasks are organized as follows:  X  First experiment: tests different feature subsets;  X  Second experiment: tests different methods for example selection together with the test of different  X  Third experiment: tests different domain values for the variable week day together with the test of
In the following we fi rstly describe the data we have used for these experiments. Then, we present the experimental setup followed by the description of the methods used. The three experiments previously described, are presented. Each one is focused on a different pre-processing task as described in [41]. Finally we discuss the lessons learned from these experiments and point out some research directions in order to take advantage of the existence of long term TTP for the planning of transport services. 2. Description of the data
The experiments described in this paper use data provided by the Sociedade de Transportes Colectivos do Porto, SA (STCP), the largest urban public transport operator in greater Oporto, Portugal. STCP has made, in the last few years, important investments in information systems in order to support the decisions of both top and operational managers. One such effort was the SAEI system, a bus dispatching system for real time control purposes.

The main components of the SAEI include:  X  Automatic vehicle location based upon dead reckoning sensors supplemented by differential GPS  X  Voice and data communication system using TETRA (Trans European Trunked Radio);  X  On-board computer and control head displaying schedule adherence information to drivers, and  X  Automatic passenger counters on front and rear doors of twenty vehicles;  X  Computer-aided dispatch center.

A test version of the SAEI system began to store data on a regular basis in 2003. Sometime later, the to coordinate any problems that might occur. Each dispatcher is responsible for six or seven bus lines. Despite the fact that the SAEI was designed for control purposes, nowadays it is a major source of the data warehouse owned by STCP. The data warehouse is the main source of information for management purposes. The most impressive characteristic of this data warehouse is its very low level analysis. The data from the SAEI system is used in the experiments described in this paper. Since the of the trips (bus voyage from end-point to end-point) was used. Information about passing times at bus time, would have to predict travel time for each road stretch that composes the route (this is known as link-based prediction). However, trip time prediction (also known as route-based prediction) is reported to have less variance [10]. The loss of information (predictions per stretch) is not relevant for this use instead route predictions. However, whatever the prediction problem is (route-based or link-based), the lessons learned from the experiments we describe would be the same.

The variables used in the experiments were obtained by visual inspection [39] and using the advise of the majority of the experiments use only 4 of them. They are: departure time, week day, day of the year we want to predict that is the travel time.

We have used data from January 1st to August 30th to analyse the variables (Table 1) and for the experiments on feature selection (Section 5.1). All the remaining experiments described in this paper use data from January 1st to March 31st of 2004. All data is from route 78-1-1. This route was cancelled in the end of 2006. 3. Experimental setup
The problem we address in this paper is a typical inductive learning regression problem. Inductive learning for regression consists ideally in the inference of a function where f represents the unknown true function.

The algorithm used to obtain the  X  f function is called induction algorithm or learner. The particular used by the algorithm to induce  X  f is the training set. However, in practice, the output of the learned between the predictions of previously unseen instances and their actual travel times. We evaluate this difference using the variation index measure Eq. (3). The reason for using this measure is three-fold, the quadratic measure of the distance (which penalizes the distance more than a linear measure), its transport companies [46,50]. The variation index gives the ratio between a dispersion measure and the average. represents the actual travel time of trip i and  X  y represents the average travel time for the n trips.
We have used a three-day prediction horizon. The reason is that, from the point-of-view of transport realistic planning horizon.

The experimental setup we use is a sliding window with a 30-day time stamp (Fig. 1). This sliding window is used because it is expected that the last days are the ones that can give more information on what will happen three days ahead. The use of a time stamp-based window against a sequence-based set, the average number of trips for each 30-day window is around 9 hundred. Nevertheless, the most adequate window size can and should be studied also because fi xing the number of days is oriented towards constraining the computational complexity instead of improving the accuracy. This problem is discussed in [53]. However, it is not the focus of this research.

All the experiments use the R statistical package [48]. 4. Choosing the regression methods
Before choosing which induction algorithm to use, we must de fi ne which characteristics they should other characteristics may be considered [20]. In any case, for TTP, the predictive capability is the one that shall be optimized. In fact, from the point of view of the goal of this research, the usefulness of could be useful for them are not the ones that are important for the improvement of the prediction X  X  accuracy. An example is the existence of bus lanes. The impact of bus lanes is relevant for business negotiations between the STCP company and the Oporto authorities, namely the town hall, but this choice of the route. Several other variables exist in the same situation.

In [20], arti fi cial neural networks (ANN) [2], Support Vector Machines (SVM) [45] and instance local regression / instance based methods [1,11] are the ones reported to be the most accurate when compared against decision trees [7] and Multivariate Adaptive Regression Splines (MARS) [16]. This evaluation was not based in tests using a known set of problems. It is only a general classi fi cation based on the authors X  experience.

In any case, the main reference for the choice of the induction algorithms to use for TTP was the work test SVM, linear regression [28], decision trees, ANN, MARS, BRUTO (similar to MARS but cannot handle categorical input variables), Multiple Additi ve Regression Trees (MART) [17], Projection Pursuit Regression (PPR) [18] and two decision tree-based ensemble algorithms: Random Forests (RF) [5] and bagging [4]. Globally ANN, SVM, PPR and RF are the best [35].

From the four induction algorithms previously referred, we have selected three of them: SVM, PPR and RF. There is no special reason to select these three since there is no evidence of the advantage of any of the four methods mentioned over the other three from the benchmark. The aim was to reduce the time of the experimental process.
 Besides these algorithms we have also used a baseline method for comparison that is described next. 4.1. A baseline method
In the spirit of a common recommendation on prediction methods [34], we start the experiments using a simpler approach to be used as a baseline method. The goal is, obviously, to obtain the fi rst results for comparison with more sophisticated approaches. The baseline method we use does not perform any learning.
 The main idea of this method is to select the past example most similar to the one we want to predict. However, considering the different behaviour of travel time in different days (for example, weekdays, Sundays, holidays, etc.), we search the most similar example only from days equivalent to the example we want to predict. Consequently, the baseline method has two steps: (1) the fi rst step fi lters data regarded as equivalent to the day we want to predict; and (2) the second one uses the fi ltered data set from which to select the nearest past example.
  X  Day Type = Normal and Week Day = working days (from Monday to Friday);  X  Day Type = Normal and Week Day = Saturdays;  X  Week Day = Sundays;  X  Day Type = bank holiday and Week Day on Monday, Friday;  X  Day Type = bank holiday and Week Day on Tuesday, Thursday;  X  Day Type = bank holiday and Week Day = Wednesday;  X  Day Type = bank holiday and Week Day = Saturdays;  X  Day Type = bridge day;  X  Day Type = tolerance day.
 The equivalent day X  X  groups were de fi ned by visual inspection and using experts knowledge.
The second component uses a distance measure to obtain the nearest neighbor. The selected distance measure is the Heterogeneous Euclidean-Overlap Metric (HEOM) because it is one of the mentioned measures that handle numeric and nominal attributes simultaneously [54]: where and v is the number of input variables (also named attributes), min and the maximum values of attribute a .
The baseline method calculates the HEOM distance between the test instance (the t variable in Eq. (4)) and each element x of the training set that belongs to the same equivalent day. The target value of the instance with the shortest HEOM distance is the prediction of the baseline method.

Using the experimental setup described in Section 3, the variation index obtained with the baseline method was 12.32%. This value will be the reference for comparison along this paper whenever appropriate. 4.2. PPR  X  Projection Pursuit Regression
Projection Pursuit Regression (PPR) is an additive model [20], i.e., it can be decomposed as a sum combination of these. The V dimensional original space is linearly projected and the image of this projection in the univariate f where t is the number of iterations. Its value is obtained on the fl y.

PPR was presented in 1981 [18] and this can perhaps explain the relative lack of use of this promising method. One of the main drawbacks of PPR is its computational cost. For modern-day computers, the i.e., for t arbitrarily large and for an appropriate choice of the f
The algorithm fi rst adds up to max.terms ridge terms f each step until nterms terms are left. max.terms and nterms are two parameters that must tuned. There is Further details on the parameters of PPR can be found in [48].

In all the experiments done with PPR we use max.terms as the number of input variables (in this case, max.terms = 4). For experiments on parameter set selection, nterms  X  X  1 , 2 , 3 , 4 } and optlevel  X  X  0 , 1 , 2 , 3 } .

Furthermore, PPR has a method for smoothing the ridge functions, called smoothers. We assume that different smoothers induce different algorithms. The ppr function from the R-project [48] has three different options for smoothers [48]:  X  The super smoother ( supsmu );  X  The splines ( spline );  X  The Generalized Cross-Validation (GCV) spline ( gcvspline ).

Depending on the smoother there are different parameters that must be tunned. The set of values tested for those input parameters that depend on the smoother is presented in Table 2. 4.3. SVM  X  Support vector machines
Support vector machines (SVM) is a relatively recent family of successful algorithms for both re-gression and classi fi cation. Based on the statistical learning theory (VC theory) developed during the sixties/seventies, it was mainly in the nineties, when Vladimir Vapnik began to work at AT&amp;T Bell Laboratories, that SVM were largely developed. Nowadays SVM is an area of research in its own right with a large number of successful applications. This section follows closely [45].

The basic idea of  X   X  SVM, the most used SVM algorithm, is to learn  X  f such that the error for the as possible. This is achieved using the  X  -insensitive loss function:
The examples that minimize the second part of the loss function, thus implicitly de fi ning the margin, are called support vectors.

For the case of linear functions, the problem can be written as a linear programming one: where w =(  X  are slack variables, and  X  and C are input parameters.  X  is the limit for non-penalized errors and C of  X  f is guaranteed by the fi rst term of the objective function.

After some reformulation, using the dual problem and generalization for the nonlinear case, the problem takes the form: where Kn is a kernel function. This function is of major importance in the SVM algorithm since it allows of problems.
 A more complete overview on support vector regression can be obtained in [45,51].
 for this new formulation, called  X  -SVM, is that  X  -SVM needs to give the desired accuracy of the approximation as an input parameter (the  X  parameter) while in most cases the goal is to obtain a  X  f function as accurate as possible.  X  -SVM automatically minimizes  X  . However, it is not expected that fraction of errors and a lower bound on the fraction of support vectors. An important difference for the than .The  X  -SVM formulation for regression is
In this paper we have adopted this later approach and the kernels used were:  X  linear: Kr ( x  X  Gaussian radial basis function: Kr ( x
SVM are sensitive to the scale used by the numeric variables. In order to avoid this problem, a common approach is to standardize those variables to have zero mean and standard deviation one [20]. This is done by default in the SVM implementation used in the R statistical package.
 While  X  and C are needed whatever the kernel is,  X  is kernel dependent (radial kernel).
The experiments on SVM use the parameters presented in Table 3. The used values were obtained to use. 4.4. RF  X  Random Forests
A Random Forest (RF) is an ensemble of models, i.e., it uses more than one model, instead of just one, for the prediction task. The main idea of ensemble methods is to generate different models in such just one model.

Breiman X  X  Random Forests method [5] uses an algorithm for induction of decision trees [7] which is modi fi ed to incorporate some randomness: the split used at each node is de fi ned a randomly selected one. This strategy based on the manipulation of the learning algorithm is combined with subsampling, since the ensemble is generated using the bagging approach [4]. The strength of the method is the combined use of bootstrap sampling and random feature selection.

RF constructs a pre-de fi ned number of trees (it is one of the input parameters of the method, called ntree ) using a variant of the CART algorithm and averages the results obtained by the set of trees. The Several other input parameters exist but are not relevant for the prediction accuracy [6,31]. They are its result converges as ntree increases. In all the experiments with RF performed here, ntree is set to mtry  X  X  1 , 2 , 3 , 4 } . 5. Experiments
Data can be manipulated in order to increase accuracy and reduce the computational cost, among other bene fi ts. There are three pre-processing tasks: feature selection, example selection and domain values de fi nition. All of them can be used to increase accuracy, while example and feature selection can also be used to address the computational cost issue. In fact, the computational complexity for each of the methods is a function of M , the number of examples in the training set, and V , the number of features/variables:  X  SVM: O ( N 3  X  RF: O (  X  PPR: O ( t  X  V  X  M  X  log( M )) [18] where t is the number of iterations (Section 4.2).
This section follows this order: (1) feature selection; (2) example selection; and (3) domain values de fi nition. In the last two experiments we also test different parameter sets. 5.1. Feature selection
The experiments on feature selection, and only in these ones, use data from January 1st to August 30th of 2004. It would be better to use, at least, one year of data. However, such amount of data was not available when these experiments were done.

Some authors classify the features as relevant or irrelevant according to how the inclusion of these features in the training set improves the results of the prediction task (considering just supervised learning) [26,36]. Even knowing that the feature subset that optimizes accuracy depends on the induction algorithm to be used [30], we will start by removing overall irrelevant features. Using the de fi nition and whose values are generated at random for each example X  [36]. Molina et al. compare some of the most well known algorithms for feature subset selection in order to evaluate some particularities, one of which is irrelevance. The method with best results for detecting irrelevance is Relief. According to algorithms to date X  [15]. One decade has passed but the Relief family of algor ithms is still frequently used for data mining applications [12,21,24,25,32].

The Relief family of algorithms [27] weighs the features according to  X  X owwell their values distinguish between instances that are near to each other X  [42]. Originally the Relief algorithm only addressed the classi fi cation problem. The regression version, called RReliefF, was introduced later.
Our approach for the detection of irrelevant features uses the RReliefF algorithm [42]. This algorithm computes the weights of the input variables, giving a measure of how much each variable  X  X xplains X  the target variable. Its pseudo code is:
Program RReliefF ( R,  X , t, k ) {where R = { R i ,i =1 , 2 ,  X  X  X  ,M } and each R i is an input vector; begin end .

The variable V in the algorithm is the number of input variables of the data set,  X  ( . ) is the target variable, i.e., the travel time, and M is the number of examples in the training set. The parameter t is the number of iterations. Its choice is problem dependent. The larger the t value is, the more stable the weights estimations are. Additionally, the computational cost also increases. Robnik-Sikonja iterations. We use t = 50. The value used for k (the number of nearest examples) was 10, as suggested by the authors. From the several distance functions proposed by the authors, we use one that quadratically increases the cost of the distance: where the values of t interval, as suggested by the authors; and the value d represents the absolute difference of the input variable A for the two examples, I suggested in [19]. However, remembering the experimental setup (Section 3), for 60 days of data, for 0.01 and the minimum, maximum, mean and standard deviation of the RReliefF weight values.
Some comments can be drawn:  X  The low values for day type, entrance fl ow and exit fl ow can be explained by the use of 30 days  X  The low value for Sundays until next pay day can be due to the use of just one seasonal-cycle of this  X  A natural doubt is if a feature with a low percentage of days with a weight larger than 0.01 has,
For the above reasons, the variables week of the year, school break, Sundays until next pay day, entrance fl ow and exit fl ow are classi fi ed as irrelevant.

The following step was to select the feature subset that maximizes accuracy. The used approach takes advantage of the embedded feature selection used in random forests. Taking advantage of RF capacity that removing irrelevant variables, performance keeps stable. The tested subsets are:  X  RedSet: the reduced set, i.e., the set of four variables considered the most important by the experts;  X  RedSet+Meteo: the reduced set with the meteorologic variables;  X  AllRRF-Meteo: all variables excluding the irrelevant and the meteorological ones;  X  AllRRF: all variables excluding the irrelevant ones;  X  All15: all the 15 variables.
 For each of these subsets, all possible values of the mtry parameter are tested.

The best subset is, as expected, All15. However, AllRRF-Meteo uses just 7 variables and obtains a very similar result. Since the meteorological variables are the only ones that are obtained from outside results for AllRRF and AllRRF-Meteo, the difference among the best results for each of these two subsets is around 0.3%. It is important to note that the meteorological variables used as input variables have However, if inspecting the promising subset RedSet+Meteo, three variables (weekday, day type and day predicting travel time three days ahead. The meteorological variables are the ones whose predictions three days ahead are expected to be more erratic. If we use predicted values for the input variables instead of the actual ones, the difference among the results for AllRRF and AllRRF-Meteo is expected to be higher than 0.3%.

The main result of the experiments on feature selection is that the RedSet, with or without meteorolog-5.2. Example selection
The main idea of example selection is to increase accuracy by selecting from the training set just a subset of the examples for the training task.

Two approaches were tested:  X  Equivalentdays (ed): uses the examples from identical past days according to several groups, de fi ned  X  Leaf node (ln): uses the examples that fall in the same leaf node of a CART tree [7] as the current
The idea behind using example selection can be stated in this way: as happens with autoregressive methods [34] the use data from equivalent past periods to predict the unknown future (using typically a weighted average of the past equivalent data), it is expected that by using only similar past data for training, the methods can predict better because there will be less  X  X oise X . Both example selection use improved by using just past trips with similar departure times. The advantage of the leaf node approach is that it is completely independent of the existing expertise on the problem and, consequently, it can easily be adapted to other problems, as discussed later in this section. 5.2.1. Results on example selection The values of the abscissa are represented as follows:  X  For PPR, each parameter set is represented and ordered by n[ nterms index]o[ optlevel index]b[ bass  X  For SVM, each parameter set is represented and ordered by c[ C index]n[  X  index] for the linear  X  For RF, each parameter set is represented and ordered by m[ mtry value].

In Table 6 the best results for each algorithm and for each different method to select the training set best results for each different algorithm are much closer to each other.

Next, we discuss the main results for each of the three methods. We divide this discussion in general comments (that includes discussion on parameter set selection) and on comments about example selection.
 PPR  X  general comments :  X  Results for PPR  X  supsmu have two distinct parts. The fi rst one is easily identi fi able because the  X  The super smoother is the one that gives the best result among the three available smoothers in R. PPR  X  example selection : For PPR, both approaches perform better than the all approach, even if for some parameter sets they perform worse. Anyway, it is clear that both approaches for example selection can ameliorate the accuracy.

SVM  X  general comments : Since the goal is to fi nd the best parameter set for each algorithm, there is range of values tested in those experiments was selected from previous experiments using a larger and wider grid (in particul ar for unbounded parameters). Consequen tly, the results are already conditioned larger  X  is, the larger the number of support vectors is. As the SVM computational complexity is given by O ( N 3 the larger the computational time for training is.

SVM  X  example selection : For SVM, the leaf node approach is the best one. This result is particularly impressive. As previously mentioned,the leafnode approach is notproblemdependentand,consequently, there is an open question: is the leaf node approach promising in other domains? The answer to this question is given in [38]. The leaf node approach is tested in eleven regression data sets [49] just for SVM  X  linear. The regression data sets are not time varying and, consequently, the experimental setup is necessarily different. We use 10-fold cross validation. The leaf node approach increases accuracy in seven data sets, draws in two and loses in the remaining two data sets. These results were obtained with 5% statistical signi fi cance.

RF  X  general comments :  X  Random Forests is a very appealing  X  X ff-the-shelf X  method because parameter selection is easy
RF  X  example selection : Results for RF are not surprising. In fact, the leaf node approach uses a fi lter identical to the one embedded in CART, and the equivalent day approach applies a kind of fi lter implemented by CART, splits the d ata according to a set of rules in order to minimize, with some constraints (such as the minimum number of examples per leaf node), the sum of the variances of the to the use of the CART approach. 5.3. Domain values de fi nition
The choice of domain values can also affect the p redictive ability of a met hod. Therefore, we have also observed how the variation index for the different methods is affected by different choices on the domain values.

Domain values de fi nition can in clude: (1) the choice of the data t ype for each variable; (2) the discretization of continuous variables; or (3) the choice of appropriate values for a symbolic variable. following possible experiments:  X  Some variables, namely, day of the year, week day and week of the year, can be de fi ned as numeric  X  Some continuous variables can be discretized by the use of the integer part when expressed in
Of all these tests, we have only done the one on the data type for the variable week day. The remainder will be explored in future work. Results for SVM using different kernels present the same behavior. the numeric data type for the variable week day when using SVM is not promising.

For RF using numeric or symbolic type for the variable week day yields similar results (Fig. 9) for any value of the mtry parameter.

For PPR (Fig. 10 and [37], Appendix A) results vary erraticly as different parameters are used. For this reason, the same tests were done using the leaf node and the equivalent day approaches for example are in [37], Appendix A. presented in Section 5.2. This happens because in all the experiments on varying parameters, we used the symbolic data type for the variable week day. 6. Analysing results
After the three pre-processing tasks the best result for each algorithm improved. However, the best selection and the use of a symbolic data type for the variable week day. RF is not very sensitive to the different settings tested. The results for PPR were the most erratic ones. The best setting for PPR, whichever the smoother used, was obtained using the equivalent days approach for example selection and the numeric data type for the variable week day.

The statistical validation of these results was done using the Friedman rank test with the statistic derived by Iman and Davenport as described in [13]. We have compared the best predictor of each algorithm, i.e., seven different predictors. The 1788 trips tested were divided in 12 groups according to their time order. The ranks obtained are shown in Table 8. The p value for the null hypothesis of equivalence between the seven predictors is 0.0008. Comparing the six predictors against the baseline
These results show that the study on the best parameter set should be done together with the studies on each of the focusing tasks. This is not the usual procedure, probably due to the large amount of time required by such experiments. However, doing parameter tuning before the focusing tasks does not guarantee the best parameter set. This is applicable whichever the dataset is. 7. Conclusions
The main purpose of this research was to assess th e predictive ability of di fferent methods on long term travel time prediction. We have used three state-of-the-art induction algorithms for the regression problem: Projection Pursuit Regression (PPR), Support Vector Machines (SVM) and Random Forests (RF). We have done an extensive search for the best parameters. Additionally, we have done experiments on the three pre-processing tasks in order to increase accuracy. These tasks are: feature selection, example selection and domain values de fi nition. The main results of all these experiments are:  X  RF is the most appealing method from an off-the-shelf point-of-view. Without any pre-processing
This study assumes that, in order to use this approach in practice, the work described should use data from one year long, at least. This would guarantee a representative sample of the problem. There is no guarantee that, for other routes, the results would be the same. However, we believe that only the parameter tuning would vary. In fact, using always the same features and methods for example selection favors the choice of algorithms that best behave with such approach. However, this problem could be set should be addressed. This could be done using ensemble learning approaches in order to dynamically choose the most promising models [53].

The use of long term TTP in order to enhance transportation services is still very incipient or even unexisting. Processes for gathering data in freight transports must be developed. For public transport companies the problem is diverse. There is already data but the operational processes in companies do not take advantage of it. The study on the use of long term TTP for operational purposes is still very limited. But there is a strong perception that some improvements can be obtained by its use. This is using long term predictive methods, the experiment al proof of their predictive ability above currently employed methods, may foster its wider application in companies.

This paper is organized according to the usual ste ps given by any pr actitioner o n applied supervised learning, namely, choice of the algorithms, tuning parameters and focusing tasks [41]. Despite some of the methods we have used are problem dependent, namely the baseline approach, we believe that supervised learning.
 Acknowledgments
This work is funded by the ERDF through the Programme COMPETE and by the Portuguese Govern-ment through FCT -Foundation for Science and Technology, project ref. PTDC/EIA-EIA/098355/2008. References
