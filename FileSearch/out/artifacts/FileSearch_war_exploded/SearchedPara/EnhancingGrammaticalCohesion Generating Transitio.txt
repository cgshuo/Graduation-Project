 During the last decade, great progress has been made on statistical machine translation (SMT) models . However, these translations still suffer from poor readability , especially translati ons of compound -complex sentence s . One of t he main reason s may be that most existing models co n-centrate more on producing well -translated local sentence fragments , but largely ignore global cohesion between the fragments. Generally, c o-hesion , includ ing lexical and grammatical coh e-sion , contributes much to the understandability and smoothness of a text. 
Recently , research ers have begun address ing the lexical cohesion of SMT (Gong et al., 2011; Xiao et al., 2011; Wong and Kit, 2012 ; Xiong, 2013 ). The se efforts focus mainly on the co -occurrence of lexical items in a similar enviro n-ment . G rammatical cohesion 1 (Halliday and Ha s-san , 1976) in SMT has been little mentioned in previous work . T ranslation s without grammatical cohesion is hard to read , mostly due to loss of cohesive and transitional expression s between two sentence fragments . Thus, generat ing trans i-tional expression s is necess ary for achieving grammatical cohesion. However , it is not easy to produce such transitional expression s in SMT . A s an example , consider the Chinese -to -English translation in Fig ure 1 .

There are 4 sub -sentences separated by co m-ma s in the Chinese sentence. We have tried to translat e the Chinese sentence using many well -known online translators, but find that it is very difficult to generate the target t ransitional e x-pressions , especially when there is no explicit connective word in the source sentence, such as generating  X  and  X  and  X  which  X  in Figure 1.
Fortunately , the functional relations hips b e-tween two neighboring source sub -sentences provide us with a good perspective and the insp i-ration to generate those transitional phrases. Fi g-ure 1 shows that the first and the second Chinese sub -sentences form a parallel relation. Thus, even though there is no distinct connective word at the beginning of the second source sub -sentence, a good translator is still able to insert or generate an  X  and  X  as a connection word to make the target transl ation more cohesive.
 es on the target grammatical cohe sion in SMT to make the translation more understandable, esp e-cially for languages with great difference in li n-guistic structure like Chinese and English. To the best of our knowledge, our work is the first a t-tempt to generate target t ransitional expressions for SMT grammatical cohesion by introduc ing the functional relation ships of source sentence s . In this work, we propose two model s . One is a new translation model that is utilized to gener at e new translation rules combined with the info r-mation of source functional relations hips . The other is a generative transfer model that encou r-ages producing transitional phrases during d e-coding. Our e xperiment al results on Chinese -to -English translation demonstrate that the transl a-tion readability is greatly improved by introdu c-ing the cohesive information .
 fo l lows. In Section 2, we describe the functional relations hips of Chinese compound -complex se n-tence s . In Section 3, we present our models and show how to integrate the models into an SMT system . Our experimental results are reported in Section 4. A survey o f related work is conducted in Section 5, and we conclude our work and ou t-line the future work in Section 6. T o acquir e the functional relations hips of a Ch i-nese compound -complex sentence , Zhou (2004) proposed a well -annotated scheme to build the C ompound -c omplex S entence S tructure ( CSS ) . The structure explicitly show s the minimal s e-mantic span s , called elementary unit s ( eu s ), and also depict s the hierarchical relations among eu s . T here are 11 common types of functional rel a-tions hips 2 annotated in the Tsinghua Chinese Treebank (Zhou, 2004).
 Under the annotation scheme of the Tsinghua Chinese Treebank, the Chinese sentence of e x-ample in Fig ure 1 is represented as the tree shown in Fig ure 2 . In this example, each sub -sentence is an eu . eu 1 and eu 2 are combine d with a parallel relation ship , followed by eu 3 with an adversative relation ship . eu 1, eu 2, and eu 3 form a large semantic span 3 , connected with eu 4 by a consequence relationship. All of the eu s are o r-ganized into various functional relations hips and finally form a hierarchical tree . Fig ure 2 : T he compound -complex sentence s tructure of the Chinese sentence in Fig ure 1.
Formally , g iven a compound -complex se n-tence structure ( CSS) , each node in the CSS can be represented as a tuple
R s e s e s e . R represents the relation ship , which has L children . For each child of R , a pair ( , ) eu s . For example , adversative -[( 1 , 2 ) , ( 3 , 3 )] in Fig ure 2 means that two children are controlled by the relation ship adversative , and the left child con sists of eu 1 and eu 2 , while the right child co n-tains only eu 3 .
 CSS has much in common with Rhetorical Structure ( Mann and Thompson, 1988 ) in En g-lish , which also describe the semantic relation between discourse units. But the Rhetorical S tructure involves much richer relations on the document -level, and little corpus is open for Chinese.

In the follow ing , we will describe in detail how to utilize such CSS information for mode l-ling in SMT. Our purpose is to enhanc e the grammatical coh e-sion by exploiting the source CSS information . Therefore, theoretically , the conditional probabi l-ity of a target translation e s conditioned on the source CSS -based tree f t is given by ( | ) and the final translation s e is obtained with the following formula :
Following Och and Ney (2002), our model is framed as a log -linear model: w here ( , ) the best translation is :
Our model s make use of CSS with two strat e-gies : 1) CSS -based translation model : f ollow ing f ormula (1), we obtain the cohesion information by modi fying the translation rules with their probabilities ( | ) ments between the source CSS -tree and the ta r-get string ; f ormula (3), we introduce a transfer score to e n-courage the decoder to generate transitional words and phrases ; the score is utilized as an a d-ditional feature ( , ) 3.1 CSS -based Translation Model For the exist ing translation models , the entire training process is conducted at the lexical or syntactic level without grammatical ly cohesive information . A s a result, it is difficult to utilize such cohesive information during decoding . I n-stead, we reserve th e cohesive information in the training process by converting the original sourc e sentence in to tag ged -flattened C S S and then pe r-form word alignment and extract the translation rules from the bilingual flattened source CSS and the target string .

As introduced in Section 2, a C S S consists of node s , and a node can be represented as a tuple
R s e s e s e  X  . In this represe n-tation, the relation ship R is the most important factor because different relations hips directly reflect different cohesive expressions. In addition, the children  X  s positions always play a strong role in choosing cohesive expressions because trans i-tional expressions vary for children with diffe r-ent positions . For example, when translating the last child of a parallel relation, we always use word  X  and  X  as the transitional expression seen in Figure 3 , but we w ill not use it for the first child of a parallel relation . Therefore , in the training process we just keep the information of relatio n-s hips and children  X  s positions when converting the source CSS to a tagged -flattened string. of the eu , such as 1 , 2 , 3 ) is somehow sparse in the corpus , we employ the relative position i n-stead . B ( Beginning ) represent s the first child of a relation ship , E ( End ) means the last child of a relation ship , and M ( Middle ) represent s all the middle children. Under this agreement , the original Chinese CSS -based tree will be converted to a new tagged -flattened string . Note the converting e x-ample from Figure 3 (a) to Figure 3(b ) : node pa r-allel -[(1,1), (2,2)] ( see Figure 2) is converted to a flat string. Its first child is represented as &lt; pa r-allel , @B &gt; with the semantic span, while the last child is &lt; parallel , @E&gt; with the corresponding semantic span.

W e t hen perform word alignment on the mod i-fied bilingual sentences , and extract the new translation rules based on the new alignment, as shown in Figure 3(b) to Figure 3(c) . N ow t he n ewly extracted rule  X  &lt;parallel, @E &gt; [X]  X  X  X  ||| and growing [X]  X  is tagged with cohesive i n-formation. Thus, if the similar relation ship para l-lel occurs in the test source sentence, this type of rule is more likely to be chosen to generate the cohesive word  X  and  X  during decoding because it is more discriminati ng than the original rules ( [X]  X  X  X  ||| and growing [X] ). The conditional pro b-abili ties of the new translation rules are calcula t-ed following ( Chiang , 2005 ). 3.2 CSS -based Transfer model In general, according to formula (3), the transl a-tion quality based on the log -linear model is r e-lated tightly with the fea tures chosen . Most tran s-lation systems adopt the features from a transl a-tion model , a language model , and sometimes a reordering model. T o give a bonus to gen erating cohesive expressions during decoding, we have design ed a special additional feature . The add i-tional feature is represented as a probability ca l-culated by a transfer model.

G iven the source CSS information, we want our transfer model to predict the most possible cohesive expressions . F or example, given two semantic span s with a parallel relation ship and many translation candidates , our transfer model is expected to assign higher score s to those with transitional expressions such as  X  and  X  or  X  as well as  X  .

Let expressions observed in the target string. O ur transfer model can be re presented as a conditio n-al probability :
By deriving each node of the CSS, we can obtain a factored formula : w here ij w is the transitional expression produced by the th j child of the th i node of the CSS. the relation ship type of the th i node. For the th child in the th i node, j RP is its relative position ( B, M or E ) introduced in Section 3.1. 
The process of t raining this transfer model and smoothing is similar to the process of train ing a language model. W e obtain the factored transfer probability as follows, w here Following (Bilmes and Kirchhoff, 2003) , the formula (6) are estimated in the same way as a factored language model , which has the a d-vantage of easily incorporating various linguistic information.

Considering that ij w commonly appear s at the beginning of the target translation of a source semantic span such as  X  which ...  X  , namely , the left -frontier phrases, we fo cus only on the left -frontier phrases when training this model . Note that if there exists a target word before a left frontier , and this word is aligned to NULL , we will expand the left frontier to this word . The expan sion process will be repeated until there is no such word. For example, if we take the CSS and the alignment in Figure 3 (a) for training , the left frontier of the second child will be expand ed from  X  growing  X  to  X  and  X  . In addition, taking the tri -gram left -frontier phrase for example , we can obtain a training sample such as ing public , R = parallel , R P = E .

By learning such probabilities for different transitional expressions conditioned on different relation s hips , we are able to capture the inner connection between the source CSS and the pr o-jected target cohesive phrases. Thus , d uring d e-coding , if we add the pro bability generated by the transfer model of ( | ) P CSS w as a feature in f ormula (3) , it will certainly contribute to selec t-ing more cohesive candidates. 3.3 Elementary -Unit Cohesion Constraint As mentioned in Section 3.2 , in the transfer model, the transitional phrases are expected to occur at the left frontier of a projected span o n target side . I n fact, this depends on the assum p-tion that the projected translations of any two disjoint source semantic spans are also disjoint to keep their own semantic integrity . We call this assumption the integrity assumption . This a s-sumption is intuitive and supported by statistics. After a nalyzing 1,007 golden aligned Chinese -English sentence -pairs, we find that approx i-mat e ly 9 0% of the pairs comply with the a s-sum p tion. However, in real automatically aligned noisy data , the ratio of compl ying pairs reduces to 71% 4 . Two projected translations that violate the integrity assumption may mutually overlap, which causes our confusion on where to extract the transitional phrases . In this case, extracted transitional phrases are likely to be wrong .
T o increase the chance of extract ing correct transition al phrases, the alignment results must be modified to reduce the impact of incorrect alignment . W e propose a dynamic cleaning method to en sure that the most expressive trans i-tional phrases fall in the accessible extraction range before training the transfer model. 3.3.1 E UC and non -EUC As we have define d in Section 2, the minimal semantic span is called elementary unit ( eu ). I f the source eu and its projected target span c o m-ply with the integrity assumption , we say that such an eu and its projected span have Eleme n-tary -Unit -Cohesion (EUC). We define EUC formally as follows.

Given two elementary units A eu and B eu , and their projected target span s A ps and B ps bound by the word alignment, the alignment compl ies with EUC only if there is no overlap between A ps and B ps . Otherwise, the alignment is called non -EUC . The common EUC and non -EUC cases are illustrated in Figure 4.
 sum p tion. For the best cases, the elementary units comply with EUC, and thus the semantic spans combined b y elementary units are certainly su bject to the integrity assumption. Fig ure .4 The s chematic diagram of EUC cases and non -EUC case . 3.3.2 A Dynamic Cleaning Method An intuitive method to clean the alignment r e-sults is to drop off the noisy word -to -word links that cause non -EUC. Considering that the dro p-ping process is a post -edit ing method for the original alignment obtained by a state -of -the -art aligner such as GIZA++ , we do no t expect over -delet ing . Therefore, we tend to take a relatively conservative strategy to minimize the deleting operation .

Given a sentence -pair ( f , e ), suppose that f is d ivide d into M eleme n-tary units words , that is , word alignment of ( f , e ) , then the goal is to co n-struct the maximum subset * A A  X  under the condition that * A is the word alignment with the constraint of EU . The search process can be d e-scribed as the pseudo code in Figure 5.

In Figure 5, we scan each target word and each source eu to assign each word to a unique eu u n-der the EUC constraint with the lowest cost. Function cost( , ) nm in line 6 computes the counts of deleted links that force the th n target word to align only to words in the range of the m eu . For example, if the th n target word is source side , while the th i word belongs to and the ( 1) th i  X  and ( 2) th i  X  words b elong to u , then In line 6, Score [ n ][ m ] saves a list of score s , each score computed by adding the current cost( n , m ) with the history score of each list of Score [ n -1 ] .
Before the next iteration , the bad branches are pruned , as seen in line 5. We adopt the following two ways to prune : (1) EUC constraint : if the current link violates EUC alignment , delete it . (2) Keep the hypothesis with a fixed maximum size to avoid too large a searching space. Fig ure 5 . The pseudo code of dynamic cleaning method. 4.1 Experimental Setup T o obtain the CSS s of Chinese sentence s , we use the Chinese pars er proposed in (Tu et al., 2013 a ). Their parser first segment s the compound -complex sentence into a series of elementary units , and then build s structure of the hierarchical relations hips among these elementary units . Their parser was reported to achiev e an F -score for elementary unit segmentation of approx i-mately 0 .89. T he progressive , causal , and cond i-tion terms of functional relation ships can be re c-ognized with precision s of 0.86, 0.8, and 0.7 5, respectively , while others , such as purpose , pa r-allel , and flowing , achieve only 0.5, 0.59 and 0.6 2, respectively . 
The translation experiment s ha ve been co n-ducted in the Chinese -to -English direction. The bilingual training data for translation model and CSS -based transfer model is FBIS corpus with approximately 7.1 million Chinese words and 9.2 million English words . We obtain the word alignment with the grow -diag -final -an d strategy with GIZA++. Before training the CSS -based transfer model, the alignment for transfer model is modified by our dynamic cleaning method . During the cleaning process, the maximum size of hypothesis is limited to 5. A 5 -gram language model is trained with SRILM 5 on the combin a-tion of the Xinhua portion of the English Gig a-word corpus combined with the English part of FBIS . For tuning and testing, we use NIST03 evaluation data as the development set . NIST04/05 /06 , CWMT 08 -D evelopment 6 and CWMT08 -E valuation data are used for testing under the measure metric of BLEU -4 ( Papineni et al. 2002 ) with the shortest length penalty. 
Table 1 shows how the CSS is distributed in all testing sets. According to the statistics in T a-ble 1, we see that CSS is really widely distribu t-ed in the NIST and CWMT corpora, which i m-pl ies that the translation quality may benefit su b-stantially from the CSS information, if it is well considered in SMT. 4.2 Extracted Transitional Expressions Eleven types of Chinese functional relation s hips and their English left -frontier phrases ( tri -gram) learned by our transfer model are given in Table 2. 
The results in Table 2 show that some left -frontier phrases reflect the source functional rel a-tion ship well, especially for those with better precision of relation ship recognition , such as progressive, causal and condition . Conversely , lower precision of relation ship recognition may weaken the learning ability of the trans fer model. For example, noisy left -frontier phrases are eas i-ly generated under relations hips such as parallel and purpose . 4: f or 01 mM  X   X   X  :{ /* scan source U set */ 9:}//end n NIST04 1 , 788 1 , 307 73.1 NIST05 1 , 082 849 78.5 NIST06 1,000 745 74.5 CWMT08 -Dev. 1 , 006 818 81.3 CWMT08 -Eval. 1 , 006 818 81.3 Table 1. The numbers of sentences and the 
CSS ratio s of all sentences. CWMT08 -D ev . is short for CWMT 08 D evelopment data and 
CWMT08 -E val . is CWMT 08 E valuation d a-ta. 4.3 Results on SMT with Different Strategies For this work , we use an in -house decoder to build the SMT base line ; it combines the hiera r-chical phrase -based translation model ( Chiang, 2005 ; Chiang, 200 7) with the BTG ( Wu, 1996 ) reordering model ( Xiong et al. , 2006 ; Zens and Ney , 2006 ; He et al., 2010). 
T o test the effectiveness of the proposed mo d-els, we have compare d the translation quality of different integration strategies. First, we adopt ed only the tagged -flattened rules in the hierarchical translation system. Next, we add ed the log pro b-ability generated by the transfer model as a fe a-ture into the baseline features. The baseline fe a-tures include bi -directional phrase translation probabilities, bi -directional lexical translation probabilities, the BTG re -ordering features, and the language model feature. The tri -gram left -frontier phrase was adopted in th e experiment. Then the prob ability generated by the transfer model with EUC constraint is added . Finally, we incorporate d the tagged -flattened rules and the additional transfer model feature together. 
Table 3 shows the results of these different i n-tegrated strateg ies . In Table 3, almost all BLEU scores are improved , no matter what strategy is used . In p articular , the best performance marked in bold is as high as 1.24, 0. 9 4, and 0.82 BLEU points , respectively , over the baseline system on NIST04, CWMT08 D evelopment , and CWMT08 E valuation data . T he strategy of  X  TFS+ Fla t-tened Rule  X  is the most stable . Meanw hile the  X  Flattened Rule  X  achieve s better performance than  X  TFS  X  . The merits of  X  Flattened Rule  X  are two -fold : 1) In training process, the new word alignment upon modified sentence pairs can align transitional expressions to flattened CSS tags; 2) In decoding process, t he CSS -based rules are more discriminati ng than the original rules , which is more flexible than  X  TFS  X  . From the table, we cannot conclude that the EUC co n-straint will certainly promote translation quality, but the transfer model performs better with the constraint on most testing sets. 4.4 Analysis of Different Effects of Different As mentioned in Section 4.3, we have noted the effectiveness of tri -gram transfer model , which means 2 n  X  in formula (7) . In fact , the length s of common transitional expressions var y from one word to several words . T o evaluate the effects of different n -grams for our proposed transfer mo d-el, we compare d the uni -/bi -/tri -gram transfer model s in SMT , and illustrate the results in Fi g-
Relation L eft -frontier phrases (tri -gram) parallel as well as; at the same; ... progressive but will also; in addition to; ... causal therefore , the; for this reason ; as a condition as long as; only when the ... hypothesis if we do; if it is; if the us; ... alternative regardless of whether; ... purpose it is necessary; explanation t ha t is ,; the first is; first is the; ... adversative however , the ; but it is; ... flowing this is a; which is an; ... consequence so that the; to ensure that ...
 Table 2 . Chinese functional relation s and their corresponding English left -frontier phrases learned by our transfer model. T he noun phrases starting with a definite / indefinite word are fi l-tered because they are unlikely to be the trans i-tional phrases .

Baseline 33.42 31.99 33.88 26.14 23.88 + Flattened Rule 34.54 ** 32.32 34.58 ** 26.79 ** 24.7 0 ** +TFS (without EUC ) 33.9 3 ** 32.04 34.4 0* 26.44 24.5 8** +TFS 33.84 ** 32.63 * 34.15 27.08 ** 24.65 ** +TFS+ Flattened Rule 34.66 ** 32.54 34.52 ** 26.87 ** 24.49 ** ure 6 . In this experiment, the CSS -based transl a-tion rules and the CSS -based transfer model are both incorporated . Considering time and comp u-ting resource s , in the rest of our paper, our anal y-sis is conducted on NIST05 and NIST06. 
W e choose 0, 1, 2 n  X  in this experiment for that the common English transitional expressions are primarily conjunctions , most of which are less than 4 words . Results in Figure 6 show that the uni -gram and tri -gram transitional expre s-sions seem more fitting for our transfer model . One possible reason is that uni -gram or tri -gram conjunctions are more utilized in an English text . In a conjunction expression list proposed by ( Williams, 1983 ) which summa rize s the diffe r-ent kinds of conjunctions based on the work of Halliday and Hassan (1976) , we obtain the stati s-tical results on uni -/bi -/tri -gram expressions , which are about 52.1%/16.9%/23.9% respectiv e-ly. 4.5 Experiments on Big Training Data T o further evaluate the effectiveness of the pr o-posed models, we also conduct ed an experiment on a larger set of bilingual training data from the LDC corpus 7 for translation model and transfer model . The training corpus contains 2.1M se n-tence pairs with approximately 27.7M Chinese words and 31.9M English words. All the other setting s were the same as the SMT experiments of sub -section 4.3 . The final BLEU sc ores on NIST05 and NIST06 are given in Table 4 .

T he results in Table 4 further verify the effe c-tiveness of our proposed models. T he best pe r-formance with bold marking scored as high as 0.8 3 and 0.64 BLEU point s, respectively over the baseline system on NIST05 and NIST06 evalu a-tion data. 4.6 Translation Examples Two S MT examples of Chinese -to -English are given in Table 5 . W e observe that compared to the baseline, our approach has obvious a d-vantages on translating the implicit relations, due to generating translational expressions on target side . Moreover, with the tr ansitional expressions, cohesion of the entire translation improves . N o-tably, the transitional expressions in this work like  X  including, there are, the core of which  X  are not linguistic conjunctions. We would like to call them  X  generalized  X  conjunctions, b ecause they tie semantic fragments together, analogously to linguistic conjunctions. I mprov ing c ohesion for c omplex sentences or discourse translation has attracted much attention in recen t years. Such research efforts can be roughly divided into two groups: 1) research on lexical cohesion, which mainly contribute s to the sel ection of generated target word s ; 2) efforts to improve the grammatical cohesion , such as di s-ambiguation of reference s and connectives . In lexical cohesion work , (Gong et al., 2011; Xiao et al., 2011; Wong and Kit, 2012) buil t di s-course -based models to ensure lexical cohesion or consistency. In (Xiong et al., 2013a), three different features were designed to capture the lexical cohesion for document -level machine translation. (Xiong et al., 2013b) incorporated lexical -chain -based models ( Morris and Hirst, 1991 ) into machine translation. They generated the target lexical chains based on the source 
Figure 6 . Different translation qualities along with different n -gram s for transfer model. 
Baseline 35.2 0 35.52 +Flattened Rule 36.03 ** 36.10 * +TFS 35.56 * 36.04 * +TFS +Flattened Rule 36.02** 36.16** Table 4 . BLEU scores on the large -scale training data. chains via maximum en tropy classifiers, and used the target chains to work on the word sele c-tion.
 matical cohesion . (Marcu et al., 2000) design ed a discourse structu r e transfe r module , but it f o-cused on converting the semantic structure rather than actual translation . ( Tu et al., 2013 b ) provi d-e d a Rhetorical -Structure -Theory -bas ed tree -to -string translation method for complex sentences with explicit relations inspired by ( Marcu et al., 2000 ), but their models work ed only for explicit functional relations, and they were concern ed mainly with the translation integrity of semantic span rather than cohesion . (Mey er and Popescu -Belis, 2012) use d sense -labeled discourse co n-nectives for machine translation from English to French. They add ed the labels assigned to co n-nectives as an additional input to an SMT system, but the ir experimental results show that the i m-provements under the evaluation metric of BLEU were not significant. (Nagard and Koehn, 2010) address es the problems of reference or anaphora resolution inspired by work of Mitkov et al. ( 1995 ).

To the best of our knowledge, our work is the first attempt to exploit the source functional rel a-tion ship to generate the target t ransitional e x-pressions for grammatical cohesion , and we have suc c essfully incorporate d the proposed model s into an SMT system with significant improv e-ment of BLEU metrics. In this paper, w e focus on cap turing cohesi on information to enhance the grammatical cohesion of machine translation . By taking the source CSS into consideration, we build bridge s to connect the source functional relations hips in CSS to ta r-get transitional expressions ; such a process is very similar to human translating.

Our contributions can be summarized as : 1) the new translation rules are more discriminative and sensitive to cohe sive information by conver t-ing the source string in to a CSS -based tagged -flattened string ; 2) the new additional feature s embedded in the log -linear model can encourag e the decoder to produce transi tional expres s ions . T he experimental results show that significant improvements have been achieved on various test data , meanwhile the translations are more cohesive and smooth , which together demo n-strate the effectiveness of our proposed models . 
In the future, we will extend our m ethods to other translation models, such as the syntax -based model , to study how to further improve the performance of SMT systems . Besides, more language pairs with various linguistic structures will be taken into consideration. We would like to thank Jiajun Zhang for provi d-ing the BTG -based hierarchical decoder. The research work has been partially funded by the Natural Science Foundation of China under Grant No. 61333018, the Hi -Tech Research and Development Program ( X 863 X  Program) of China under Grant No. 2012AA011101 , and also the Key Project of Knowledge Innovation Pr o-gram of Chinese A cademy of Sciences under Grant No. KGZD -EW -501 as well.
 R eference Baseline Improved
