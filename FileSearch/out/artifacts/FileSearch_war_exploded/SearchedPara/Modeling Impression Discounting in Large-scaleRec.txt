 Recommender systems have become very important for many on-line activities, such as watching movies, shopping for products, and connecting with friends on social networks. User behavioral anal-ysis and user feedback (both explicit and implicit) modeling are crucial for the improvement of any online recommender system. Widely adopted recommender systems at LinkedIn such as  X  X eo-ple You May Know X  and  X  X ndorsements X  are evolving by analyz-ing user behaviors on impressed recommendation items.

In this paper, we address modeling impression discounting of recommended items, that is, how to model user X  X  no-action feed-back on impressed recommended items. The main contribution-s of this paper include (1) large-scale analysis of impression da-ta from LinkedIn and KDD Cup; (2) novel anti-noise regression techniques, and its application to learn four different impression discounting functions including linear decay, inverse decay, expo-nential decay, and quadratic decay; (3) applying these impression discounting functions to LinkedIn X  X   X  X eople You May Know X  and  X  X ndorsements X  recommender systems.
 H.3.3 [ Information Storage and Retrieval ]: Information Filter-ing; J.4 [ Computer Applications ]: Social and Behavior Sciences Impression discounting; Recommender system
Analyzing and incorporating user feedback on recommended item-s is crucial for evolving any recommender systems, which have be-come important for many online activities and especially for social networks. At LinkedIn, the largest professional network with more than 300 million members, recommender systems play significant role in engaging users, discovering new content, connections, op-portunities, and satisfying users needs. LinkedIn exposes connec-tion or link recommender systems through features such as  X  X eople You May Know X  (PYMK) (Figure 1(a)), which recommends other KDD  X 14 , August 24 -27 2014, New York, NY, USA members to connect with, and skills endorsements, which recom-mends to endorse connections with their skills &amp; expertise to add to their profiles (Figure 1(b)).

Modeling user behavior and incorporating feedback on live rec-ommender systems such as PYMK and Endorsements, which are exposed to millions of users every day, are critical for enhanc-ing these recommender systems. User feedback on recommended items viewed by users or impressions, can be explicit or implicit. User action such as inviting or dismissing a recommended member to connect with is explicit feedback in PYMK. On the other hand, viewing a recommended member or clicking to view the profile of a recommended member, but not inviting to connect, are examples of implicit feedback in PYMK. There has been extensive research on modeling explicit feedback in terms of ratings and acceptance of recommended items [9, 21, 26]. However, modeling certain implic-it feedback such as no action on impressed recommended items for conversion, has been under explored. There has been some work on estimating Click-through rate (CTR) using past impressions [1], but CTR estimation is different from conversion prediction as also argued recently in [5, 17].

Usually a recommender system generates a list of items, ordered by a score, to show to users. We say a recommended item is im-pressed when a user views the item. Acceptance of an impressed recommended item results in conversion. No action from users on impressed recommended items can be because of multitude of rea-sons, for example, a user might be busy with other things, or the recommended item is not relevant or the purpose of the site visit is very different. In the impression discounting problem we aim to maximize conversion of recommended items generated by a rec-ommender system by applying a discounting factor, derived from past impressions, on top of scores generated by the recommender system. There are two basic challenges in the impression discount-ing problem: (1) how can we build an effective model between conversion and various user behaviors from the large amount of past impression data? (2) how can the model be applied to im-prove the performance of existing recommender systems? There are various factors that can be used in modeling the impact of im-pressions, such as, (1) the number of times an item is impressed or recommended to a user, (2) when the item was impressed, and (3) frequency of user visits on the site or user seeing any of the recommended items.

In this work, we present models for discounting impressions of recommended items based on various factors such as the number of impressions and the last time the item was seen. The intuition behind these models is simple; for example, in the case of PYMK, a recommended member that results in a number of impressions, but does not lead to an invitation, should be removed or lowered in the recommended list of members. We performed detailed analy-Figure 1: (a) People You May Know at LinkedIn recommend-s other members to connect with. (b) Suggestions for skills endorsements, a recommender system at LinkedIn to endorse connections for their skills and expertise, which can be added to their profile. sis of past impressions over large amount of tracking data to find correlation between various factors and conversion rate, for exam-ple, invitation rate for PYMK. We learned four different regression models that represent linear decay, inverse decay, exponential de-cay, and quadratic decay. We developed novel anti-noise regres-sion techniques to detect outliers and lower the effect of outliers in learning regression functions. We show empirically that our im-pression discounting models perform significantly better both in offline analysis using past data as well as in online A/B testing. In offline analysis for PYMK, these impression discounting models showupto 31% improvement in invitation rate, and in online A/B test experiments, the model improves invitation rate by up to
The main contributions of this paper are as follows:  X  Perform large scale correlation studies between impression  X  Design effective impression discounting models based on lin- X  Evaluate these regression models on real-world recommenda-
The rest of the paper is organized as follows. Section 2 dis-cusses related work. Section 3 formalizes concept of impressions in the context of recommender systems and details data sets used in this work. Section 4 presents exploratory data analysis to figure out correlations between various user behavior and conversion rate. This section also describes our impression discounting framework, and various discounting functions learned through regression. Sec-tion 4.5.3 describes our anti-noise regression techniques. Section 5 presents experimental results including offline analysis and online A/B testing results. Finally we conclude in Section 6.
The related work of this paper falls mainly under one of the fol-lowing categories.
 Implicit Feedback in CF. User implicit feedback plays an essen-tial role in the recommendation models [2]. Collaborative filtering (CF) is a typical recommendation model, with the advantage of not needing the user/item profiles [9, 10, 21, 26]. Hu et al. [8] studied implicit feedback on CF and proposed a factor model by treating implicit feedback as the indication of positive and negative pref-erence associated with varying confidence levels. Koren [9] dis-covered that incorporating implicit feedback into a neighborhood latent factor model (SVD++) could offer significant improvemen-t. On the application side, a local implicit feedback model mining users X  preferences from the music listening history is proposed in [24]. Moling et al. [15] exploited implicit feedback derived from a user X  X  listening behavior, and modeled radio channel recommen-dation as a sequential decision making problem. Yang et al. [25] proposed Collaborative Competitive Filtering (CCF) to learn user preferences by modeling the choice process with a local competi-tion effect. Gupta et al. [7] modeled user response to an ad cam-paign as a function of both interest match and past exposure, where the interest match is estimated using historical search/browse ac-tivities of the user. All these methods [8, 9, 25, 7] exploit implic-it feedback by integrating historical signals with existing recom-mendation models. In contrast, our impression discounting model serves as an external plugin of the existing recommendation model, which has advantages in modularization.
 CTR Estimation. The estimate of click-through rate (CTR) for online resources such as news articles, Ads or search results is a hot topic, and we categorize the related work into two types: classification-based estimate and regression-based estimate. For the first type, Agichtein et al. [2] showed that incorporating user behavior data can significantly improve the ordering of top result-s in real web search engines, by treating user behaviors as features and using classification to re-rank. Richardson et al. [18] employed logistic regression to predict the CTR for newly created Ads, using features of ads, terms, and advertisers. For the second type, Agar-wal et al. [1] proposed a spatio-temporal model to estimate the first impression CTR of Yahoo! Front Page news articles.

Impression discounting shares some commonalities with the es-timate of CTR: they both try to predict a user X  X  future action. How-ever, they differ in many aspects. First, impression discounting aims to improve the conversion rate of recommendations, which is a different goal from CTR estimate, as a click can happen multiple times and may not result in a conversion action. Second, the exist-ing work on CTR estimation is mainly focused on new items; for example, the first exposure of news articles [1] or Ads [18]. The link between impression history and conversion rate is not covered in existing studies.
 Density-based Approach. Density concepts, first introduced by density-based clustering [6] and recently adapted to social network and media analysis [13, 12], is a traditional way to detect noises. In the context of linear regression, Ristanoski et al. [19] proposed segmenting the input time series into groups and simultaneously optimizing both the average loss of each group and the variance of the loss between groups, to produce a linear model that has low overall error. Chen et al. [4] introduced a nonlinear logistic regres-sion model for classification, and the main idea is to map the data to a feature space based on kernel density estimation. Kernel regres-sion is another relevant approach, which estimates the condition-al expectation of a random variable by non-parametric techniques [11]. However, all these approaches [19, 4, 11] cannot combat the noise in linear regression.
In large-scale recommender systems, user actions, such as im-pressions, are readily captured [23]. Before jumping to the model-ing of impression discounting, we start to extract and formalize the impression data sets in a uniform format, crossing various appli-cation scenarios, including PYMK, Skill Endorsements, and Key-word Search Ads. These impression data sets are typically reflect-ing the interaction between users and popular online recommender systems.
Our study on the daily interaction logs of different recommender systems reveals that there is a common structure behind impression records from different sources. Without the loss of generality, we formalize each impression record as a tuple T with six attributes, as explained below.

Definition 1. (Impression) An impression in the recommender system is modeled as a tuple T with six attributes: where:  X  user is a user ID;  X  item is a recommendation item ID;  X  conversion is a boolean type to describe whether or not user  X  behavior is an observed feature of interaction;  X  t is the time stamp of impression;  X  R is the recommendation score of item to user , which is pro-
As a convention, we use T .x to refer to attribute x in T Conversion. We use the term conversion to indicate that user explicitly accepts the recommendation. A conversion action may differ from a user click. For example, a conversion action in PYMK means that a user does not simply click on the profile page of an-other user, but instead takes action to invite that user. In job rec-ommendations, conversion means that a user actually applies for the job item .
 Behaviors. User interactions with the recommender system typi-cally follow a  X  X ee-think-do X  procedure. The interaction between users and recommender systems has many facets. We aggregate the following user behaviors:  X  LastSeen : the day difference between the last impression and  X  ImpCount : the number of historical impressions before the  X  Position : the offset of item in the recommendation list of  X  UserFreq : the interaction frequency of user in a specific rec-
We use X to represent the set of behaviors and use m to describe the set size, i.e., m = | X | .
 Impression Sequence. Given a large impression data set with each record formatted as tuple T , we can perform a  X  X roup-by X  operation on ( user , item ) to obtain a sequence with the same ( user , item ). This sequence can be ordered by time and denot-ed as seq ( user, item )=( T 1 ,  X  X  X  , T n ) . In a given observation time window, the sequence length is indicated by ImpCount . Espe-cially, if seq ( T .user, T .item ) has the property ImpCount we call it T the first impression.
 Conversion Rate . In most recommender systems, once the con-version is true, item will not be recommended to user again. So conversion = True only possibly occurs once on the tail of a sequence. Thus, the overall conversion rate can be defined as the ratio between the number of impressions with conversion = and the number of all impression sequences. Let S denote the set of impressions. The global conversion rate is computed by
Conversion rate can also be measured on the basis of each behavior set X . We can  X  X roup-by X  all impression sequences on X , and then define the local conversion rate by the formula We normalize conversion rates in this work as only relative changes are important.
To deploy the impression discounting model, we collect two real-world data sets from online recommender systems in LinkedIn and one external public data set from Tencent. In the following section, we describe the salient characteristics of these data sets. LinkedIn PYMK Impressions. PYMK is one of the most pop-ular recommender systems in LinkedIn. The PYMK item is ac-tually another 2nd or higher degree LinkedIn user. We select an observation time with a total of 1.08 billion impressions in tracking data. Out of them, a significant portion of impressions are mul-tiple, which means at least half the impressions were previously presented to the users, but get no invitation action. The relatively long impression sequences in PYMK make it an ideal data set for modeling impression discounting.
 LinkedIn Skill Endorsement Impressions. Skill Endorsement is another popular recommender system to recognize the skills and expertise of 1st-degree connections. We collect impressions track-ing data with 0.19 billion impression tuples, and a small portion of them are multiple. The item in a tuple is the combination of a user and his skill. Because endorsements are only allowed for 1st-degree connections, impression sequences are usually very short and the conversion rate is relatively high, which implies that the skill recommendations are more likely endorsed by connections in the first impression.
 Tencent SearchAds Impressions 1 . SearchAds is a data set made publicly available for KDD Cup 2012 by the Tencent search engine. It contains various ingredients of the interaction between a user and the search engine; for example, user, query, Ad ID, depth, position, etc. In total, this data set has 0.15 billion impression sequences, and the CTR of the Ad at the 1st, 2nd and 3rd position of the search session is 4.8%, 2.7%, and 1.4% respectively. http://www.kddcup2012.org/c/kddcup2012-track2
There are two basic challenges in the impression discounting problem: (1) how can we learn an effective model between the conversion and various user behaviors from the big data? (2) how is the model applied to new impressions and improving the perfor-mance of existing recommender systems? In this section, we intro-duce the impression discounting model, which is learned from the actual impression data sets and integrated as a plugin in the existing large-scale recommender systems.
For convenience of presentation, we introduce the following con-cepts and notations:  X  Behavior List : a list of behaviors that describe the user X  X  in- X  Conversion Rate : the actual conversion rate in data sets is  X  Observation : an observation ( X,y ) is composed by a behav- X  Support of Observation : the support of an observation (  X  Observation Space : the set of all possible observations
As an example in LinkedIn PYMK, assume a common scenario that a user called Alice gets the recommendation for a connection called Bob in September 20 but takes no invitation action. This assumption has two folds of meaning: (1) the recommendation en-gine thinks that Bob has a relatively high recommendation score R to Alice; (2) it is very likely that Alice is not satisfied with the rec-ommendation item Bob. If the recommender system ignores this implicit negative feedback from Alice, most likely Bob will be rec-ommended to Alice again in another day, which only reduces the overall satisfaction of Alice. We believe that this kind of scenar-ios can be easily found in nearly every recommender system, e.g., Ad recommendation, job recommendation and even web search en-gines. Motivated by this example, we design the impression dis-counting framework, which serves as a module in the existing e-cosystem of recommender systems, by taking full consideration of the implicit negative feedback from users. We formalize the im-pression discounting problem as follows.

Problem 1. ( Impression Discounting ). Given a large-scale im-pression data set with each record defined by Definition 1, for each unique ( user, item ) , supposing the historical impression sequence is seq ( user, item )=( T 1 ,  X  X  X  , T n )( n  X  1) and T is the current impression (i.e., T .t &gt; T n .t ), the problem of impression discount-ing on T is to determine a discounting factor d ( 0 &lt;d updates  X T  X  .R = T .R  X  d ;  X  seq ( user, item )=( T 1 ,  X  X  X  , T n , T ) ;  X  seq  X  ( user, item )=( T 1 ,  X  X  X  , T n , T  X  ) ; Figure 2: The impression discounting framework. Our pro-posed impression discounting model only relies on the histori-cal impression records, and can be treated as a plugin for ex-isting recommendation engines. We use the dotted rectangle to circle the newly built recommender system with impression dis-counting, which produces discounted impressions with a higher overall conversion rate. and maximizes where ConveRate  X  and ConveRate are computed by Eq. (1) based on seq  X  ( user, item ) and seq ( user, item ) respectively.
To explain why impression discounting helps improve the over-all conversion rate, we use the following example. Suppose that in a user interaction session, the recommendation engine fetches top 100 recommendation items ranked by T .R and 50 of them will be observed by the user. If without impression discounting, existing recommendation engine will present the top 50 items ranked by T .R to the user. However, since a large portion of item impres-sions are multiple, their historical negative feedback indicates that their conversion rate will be low. Now we consider a newly built recommender system with impression discounting. Since impres-sions are discounted properly by d where d  X  1 , all 100 items will be re-ranked. Ideally, items with less negative feedback will bub-ble up into top 50 list and be exposed to user X  X  observation, which results in a higher overall conversion rate.

We show the impression discounting framework in Figure 2. Ba-sically, we assume that R is already produced by the best-known recommendation method, and the computation of R is not the fo-cus of this paper. Our proposed impression discounting model only relies on the historical impression records in the past observation time window. In other words, impression discounting can work independently with the recommendation engine. Once added as a plugin into the recommender system, impression discounting mod-el will produce a discounting factor d , which penalizes items that not likely gain a conversion action and makes the recommendation list re-ranked. A properly designed impression discounting model will make the overall conversion rate increasing and improve user X  X  satisfaction. The challenge of the impression discounting problem is how to design an effective model that determines the optimal d to re-rank the recommendation list with intuitive explanation. Impression Discounting: Plugin vs. In-Model . There are typical-ly two ways to incorporate impression discounting into an existing recommendation system: serve as an independent plugin or push in the recommendation model. The plugin approach does not change Figure 3: The change of Normalized ConveRate with increas-ing ImpCount on three real-world impression data sets. the existing recommendation model, and the impression discount-ing is performed by multiplying a discounting coefficient d with the recommendation score. In contrast, the in-model approach modi-fies the existing recommendation model by adding more signal-s. For example, supposing the recommendation model is based on classification, the in-model approach will add signals like imp-Count , lastSeen as additional features. The plugin-based approach provides model independence: we can be agnostic as to the under-lying recommendation model, whether it is a sophtiscated similar-ity ranker or simple cooccurance-based collaborative filtering, it is treated as a black box. Thus, impression discounting can be pro-vided  X  X s a service X  for any client application. In this paper, we focus on the plugin-based approach, though these techniques can be adapted to the in-model approach without loss of generality. We have a basic hypothesis for the impression discounting:
Hypothesis 1. Impression T with conversion = false is a negative feedback to the recommendation of item to user .
If this hypothesis is false, the recommender system will always try to recommend items with a longer impression history to gain a higher conversion rate, and these long impression sequence will dominate the recommendation list, preventing new items being dis-played. If this is the case, the discounting factor d  X  1 problem definition will become invalid, as the conversion rate may increase if the impression sequence becomes longer. Thus, if this hypothesis is false, the impression discounting framework will be problematic. To verify this hypothesis on real-world impression data sets, we measure the change of ConveRate with increasing impression sequence length, as shown in Figure 3. As we can see, on all three data sets, ConveRate decreases very fast as increasing ImpCount in the beginning. Later, the decreasing trend becomes steady, and when ImpCount is high (which is rare in observation), there are some turbulences on the tail of the curves due to the data sparsity problem. The impression sequences of the Endorsement data set are very short in length and ConveRate decreases even faster than the other two data sets. In a nutshell, Figure 3 verifies that Hypothesis 1 is true, and also reveals that the discounting fac-tor in the Endorsement data set should be more severe and smaller than the other two data sets. Figure 4: Correlation confidence analysis between ConveRate and two behaviors on PYMK data. Correlation Analysis. It is essential to explore the correlation con-fidence between conversion rate and user behaviors. An effective way to tackle the correlation analysis is using non-parametric s-moothers in a generalized additive model (GAM) [14] to fit the conversion rate. We perform GAM fitting on the PYMK data set and show the correlation analysis between conversion rate and Im-pCount , LastSeen in Figure 4. The narrow intervals in Figure 4(a) and (b) suggest that the curvatures of the correlation are both strong. Moreover, as the interval in Figure 4(a) is even narrower than the in-terval in Figure 4(b), we conclude that ConveRate has a stronger correlation with LastSeen than the correlation with ImpCount .In other words, LastSeen plays a more important role than ImpCount in determining conversion rate. The monotone decreasing trend-s suggest that the correlations are both negative. The correlation analysis for other user behaviors and in Endorsement and SearchAd-s data sets delivers similar messages. We omit the details due to space constraints.
 Discounting Functions. Based on the correlation analysis, we de-fine discounting functions to model the negative relationship be-tween the conversion rate and a specific user behavior. In particular, we introduce the following four kinds of discounting functions:  X  Linear Discounting: f L ( x )=  X  1  X  x +  X  2 ;  X  Inverse Discounting: f I ( x )=  X  1  X  Exponential Discounting: f E ( x )= e  X  1  X  x +  X  2 ;  X  Quadratic Discounting: f Q ( x )=  X  1 ( x  X   X  2 ) 2 +  X 
We use PYMK as the default data set, and show the conversion rate vs. LastSeen and ImpCount in Figure 5. Since the supports of observations for a high LastSeen or ImpCount is really low, the curve tails in Figure 5(a) and (b) become fluctuant, which brings new challenges for curve-fitting, a problem we will study in Sec-tion 4.6. So far, we perform regression and show the root mean square error (RMSE) of different discounting functions to the actu-al observations in Table 1. As we can see, exponential discounting achieves the overall minimal RMSE with the best fitting quality. More evaluation of discounting functions can be found in Section 5. In our impression discounting model, these discounting functions will serve as the atoms in the multiple variable regression process.
Conversion rate is determined by multiple facets of user behav-iors. For example, it is confirmed that ImpCount and LastSeen will Figure 5: The change of normalized conversion rate with increasing LastSeen and ImpCount . We simulate all observations by four discounting functions, and exponential discounting achieves the minimal RMSE. influence the invitation rate in PYMK. To model conversion rate ac-curately, we propose an aggregated discounting model in this paper, which integrates multiple discounting functions into a hybrid mod-el. There are typically two ways to incorporate multiple variables into a model: linear or multiplicative combinations. We explore both of them in this section.
 Workflow. The major workflow of the impression discounting model is presented in Figure 6. Without any prior knowledge, the correlation analysis is a great way to discover the correlation strength and polarity between the conversion rate and a specific user behavior. Correlation analysis also helps determine which dis-counting function fits the observations best by comparing RMSE, and narrows down the search space for the model candidates. Each candidate model will be learned by the regression from the training data set. Finally, we perform a model evaluation for each candidate on the testing data set, and the model with the best performance will be selected as the optimal discounting model for the corresponding recommender system.
 Regression vs. Classification. Classification is a typical machine learning technique for decision making. Since our impression dis-counting framework follows the plugin approach, given that the recommendation score R is obtained from the best-available classi-fication model, it will bring severe redundancy problem if we apply the classification model again on features in impression discount-ing. Besides, compared with the classification, regression can pro-vide a better and more intuitive explanation of impression discount-ing by discounting functions.
The first aggregated discounting model we explore is the linear model. Linear aggregation model combines discounting functions of different user behaviors by a linear function, in the form: where m = | X | and f ( X i ) is any one of discounting functions. Given a specific behavior X i , the correlation analysis will help de-cide which discounting function is the best choice for f ( is the weight for the discounting function and will be learned. It is well known that too many parameters in the linear model will re-sult in over-fitting. Actually, once we select the specific discounting functions, the parameters in Eq. (9) can be reduced greatly. Here is an example with three different behaviors: where  X  = e  X  5 . In general, combing like terms in Eq. (9) can reduce the parameters from the order of 3 m to ( m +1) . These parameters can be learned by standard linear regression packages.
Multiplicative aggregation is another way to combine discount-ing functions, in the form:
Supposing each discounting function has two parameters on aver-age, Eq. (6) has (2 m +1) parameters to learn. We try to reduce the number of parameters, by performing a linearization, in the fol-lowing way:
If f ( X i ) is the exponential discounting, Eq. (7) degrades to a simple linear regression with ( m +1) parameters without accuracy loss. Otherwise, we can discard the constants or lower order terms in discounting functions and obtain an approximated version of Eq. (7) with ( m +1) parameters.
Both linear aggregation and multiplicative aggregation can be linearized as a uniform form shown below where  X  y = X  y in linear aggregation and  X  y =ln X  y in multiplicative aggregation. We set  X  X 0 =1 and when i  X  1 ,wehave  X  X { for multiplicative aggregation. It is trivial to show support support ( X i ) . The selection of  X  X i depends on the kind of dis-counting functions for each behavior in the model. For example, in multiplicative aggregation, if f ( X i ) is the inverse discounting, we have  X  X i =ln X i . Eq. (8) can be written in matrix notation as Once we obtain the aggregated discounting model, the impression discounting factor d for a impression tuple T can be computed by the normalized value of  X  y , which falls in (0 , 1] . That is,
Eq. (9) transforms the aggregated discounting model as a linear regression problem, whose objective function is to minimize the mean squared error, with a form In the practice of model-fitting, we observed a number of cases that the sparsity of observation supports may make the conversion rate go too high or too low. Examples are found on the curve tails in Figure 5(a) and 5(b). If y i deviates from the overall trend of its neighboring observations because of sparsity, the objective func-tion Eq. (11) will suffer a lot because it tries to minimize the d-ifference between the local overall trend and sparse observations. Ideally, it would be perfect if outliers of observations can be re-moved by a well-designed mechanism and the observations with less supports can be penalized in the objective function.
Notice that the naive approach that truncates the curve tail by a threshold on the minimal support of an observation is problematic, because: (1) this will also remove the observations that don X  X  devi-ate a lot from their local overall trends; (2) the threshold is difficult to decide, because on the scale of billions of records, the  X  X parsity X  is a relative concept, where a  X  X parse X  observation may still have millions of supports.
In related work, density-based clustering [6] defines clusters as areas of higher density than the remainder of the data set, and the key idea is that for each node in the cluster, the number of neigh-bors within a radius  X  should exceed a threshold  X  . Density-based clustering has the benefit of distinguishing clusters and outliers in a data space efficiently. Recently, density-based clustering emerged into the social network and media analysis [13, 12] and demon-strated its effectiveness. In impression discounting, we model the density of an observation as the support sum in a small neighbor-hood of this observation. The migration of density concepts to the linear regression is a contribution of this paper. To start, we define  X  -neighborhood of a behavior list X in multiple-variable linear re-gression as follows.

Definition 2. (  X  -neighborhood of a behavior). The  X  -neighborhood of a behavior set X , denoted by N  X  ( X ) , is defined by N { X  X  D | dist ( X,X )  X   X  } .

The shape of  X  -neighborhood is determined by the choice of the distance function dist ( X,X ) . Without the loss of generality, we consider the Euclidean distance is the choice for multi-dimensional feature space, that is
Density-based clustering does not define the concept of  X  X on-nection X  between points. In our anti-noise regression model, as each behavior list X is associated with a response value y , we use connection to describe the relationship between two pairs of obser-vations, as defined below.

Definition 3. (Connection in  X  -neighborhood). Given two d-ifferent observations ( X,y ) and ( X ,y ) , they are connected if dist ( X,X )  X   X  and | y  X  y | X   X  , where  X  is the maximal toler-ance for local deviation.

We compute the density of an observation ( X,y ) as the sum of supports connected with ( X,y ) in the  X  -neighborhood:
Density score will categorize observations into three types:  X  Core Observations : ( X,y ) is a core observation, if the sup- X  Border Observations : ( X,y ) is a border observation, if  X  Outlier Observations : ( X,y ) is an outlier observation, if
Intuitively, outlier observations capture those observations that are unreliable by deviating from the local trends of nearby observa-tions. Basically, all the outlier observations can be discarded before the linear regression. We can tune density parameters {  X ,  X ,  X  control the percentage of outlier observations in the observation s-pace. As a general guideline, {  X ,  X  } is usually fixed for a specific impression data set, and we set 5% as the percentage of outlier ob-servations out of all observations, which can be tuned by  X  .
We explain the intuition of noise detection from the graph per-spective. If we view each observation as a node and a connection between observations as an edge, an observation network will be built. Core observations will be those nodes with a high connectiv-ity to other nodes. Those nodes represent high authority ranking in the network analysis such as PageRank [16]. Outlier observations are those nodes with low degrees and no edges to any high authori-ty nodes, and they usually represent the marginal, isolated or noisy part of the network. Removing these outlier nodes will make the whole network structure more cohesive and accurate to model.
In RMSE shown in Eq. (11), the error between the actual con-version rate y and predicted conversion rate  X  y are weighted equally. However, we argue that for observations with high supports, their errors should be emphasized in the objective function, compared with the observations with a relatively low supports. To achieve the goal, we propose the density weighted regression , which adds a weight v i for each error ( y i  X   X  X i T u ) , with a modified objective function given below
The problem is how to decide v i . One naive solution is using the ratio between the support of an observation and the total supports to weight the corresponding error, that is v  X  i = support The assumption of this solution is that the distribution of support is  X  X mooth X  in X i  X  X  local neighborhood. That is to say, compared with the support of X i  X  X  neighbors, support ( X i ) should not be remarkably too high or too low. However, in real-world data set-s, support ( X i ) is likely not smooth due to the sparsity problem. Instead, we propose an advanced solution, by adopting the density parameter  X  : Notice that X i  X  N  X  ( X i ) . The rationale behind Eq. (15) is that, the supports of all similar observations in the neighborhood of X contributes to the weight of ( X i ,y i ) . In the extreme case, if  X  we have N  X  ( X i )= { X i } and v i degrades to the naive solution. If  X  =  X  and  X  =1 , N  X  ( X i )= D and v i =1 , making Eq. (14) degrades to the unweighted version (Eq. (11)). Typically, we set  X  smaller than 5, making v i as the ratio between the supports of  X  -neighborhood and the total supports. v i is smoother than v highlights the observations with high supports effectively.
Next, we can write Eq. (14) in matrix notation as n  X  RMSE (
Vy  X  VXu ) T ( Vy  X  VXu ) , where V = diag ( v ) . If we take the derivative of n  X  RMSE 2 v with respect to u , we get ( VX VXu ) . By setting the derivative to zero, we solve u by the follow-ing reasoning: where V 2 = diag ( v  X  v ) and  X  is the Hadamard product [22] (a.k.a. entrywise product) for vectors. Eq. (18) can be actually viewed as a kind of locally weighted linear regression problem [20], where V 2 is the weighting matrix.

In the case that the matrix X T V 2 X is singular, we cannot solve  X  u by Eq. (18) by the inverse operation. It is well known that Ridge regression [3] adds an additional matrix  X I to the matrix X linear regression to make it non-singular. In our anti-noise regres-sion model, we can apply a similar technique and estimate where  X  is determined by minimizing RMSE.
Imagining that we have n choices for discounting functions, the number of different aggregation models can be as high as n both linear aggregation and multiplicative aggregation. Although correlation analysis can rule out a large portion of aggregation mod-els by selecting discounting functions with low RMSE, we stil-l need standard evaluation metrics to compare different aggrega-tion models and find the optimal discounting model for the recom-mender system. In this paper, we use the following evaluation met-ric to assess the performance of an aggregated discounting model:  X  Precision at Top k . In the testing data set, given a user ,
In this section, we test the proposed impression discounting mod-el on three real online impression data sets: LinkedIn PYMK, LinkedIn Endorsement and Tencent SearchAds. The data set details are de-scribed in Section 3.2.
Correlation analysis helps determine which discounting function fits the relationship between the conversion rate and a user behavior the best. We perform correlation visualization in both 2-D and 3-D.
The 2-D correlation analysis between the conversion rate and a specific behavior is an effective way to discover the strength and type of relationships between them. Figure 7 shows the conver-sion rate vs. LastSeen , Position and UserFreq on three real data sets. The conversion rate vs. ImpCount has already been shown in Figure 3. In Figure 7(a), we can see conversion rate in PYMK decreases faster with LastSeen than the conversion rate in the En-dorsement data set, which reveals that LastSeen for Endorsement is less important than it for PYMK. LastSeen is not available in SearchAds data set. Figure 7(b) shows the relationships between the conversion rate and offset positions in the recommendation list. Clearly, if an item is ranked lower in the recommendation list, its conversion rate will be lower. Endorsement data set has the steepest decreasing trend, compared with the other two data sets. In Figure 7(c), we show the conversion rate as the increasing of UserFre-q . Surprisingly, we find that the conversion rate increases in both PYMK and Endorsement. The explanation may be that, a higher UserFreq indicates that user is more active in the recommender system, and also more likely to take conversion actions. UserFreq does not play an important role in SearchAds, most likely because users do not have enough stickiness to a general web search engine.
In Figure 8, we perform the 3-D visualization between conver-sion rate and two user behaviors on three data sets respectively. Each ball represents an observation, which is the conversion rate with respect to a specific value of user behaviors. As we can see, on the PYMK data set (Figure 8(a)), ConveRate decreases with both ImpCount and LastSeen . However, on the Endorsement data set (Figure 8(b)), ConveRate is not very sensitive with LastSeen ,as supported by Figure 7(a). Figure 8(b) also shows there are many outlier observations even when ImpCount &lt; 10 , mainly because most impression sequences in Endorsement data set are very short and the sparsity problem becomes very critical. On the SearchAds data set (Figure 8(c)), because LastSeen is not available, we show ConveRate vs. ImpCount and Position , which clearly decreases along both dimensions.
We split each impression data set into training and testing sets, and the impression discounting model is learned from the training (a) Conversion rate vs. LastSeen Figure 7: Conversion rate vs. LastSeen , Position and UserFreq on three real data sets.
 Table 2: The improvement of precision at top k of the impres-sion discounting model on different real-world data sets. The improvement rate is computed based on the precisions at top k without discounting. set. We use precision at top k defined by Eq. (20) on the testing set to evaluate the performance of different aggregated discounting models. The precision improvement of the impression discounting model, compared with the baseline without a discounting model, is shown in Table 2. As we can see, if we integrate more user be-haviors into the impression discounting model, the precision will be improved: the 4-behavior model on both PYMK and Endorse-ment gains at least two times higher precision growth compared with the 2-behavior model. Also, the precision growth on PYMK is obviously higher than the precision growth on Endorsement and SearchAds, because impression sequences in PYMK is distinctly longer than the impression sequences in the other two data sets. As proof, P @5 is obviously higher than P @10 on SearchAds, because a user has 5.8 items on average, and the precision on top 10 items of each user is not an effective evaluation metric. We implemented the impression discounting model in the LinkedIn PYMK recommender system, and the online A/B test results is shown in Table 3. This impression discounting model uses two be-haviors, LastSeen and ImpCount . We fix the ImpCount dimension as the exponential discounting (as it has the minimal RMSE), and try the LastSeen by exponential discounting, inverse discounting, Figure 8: The 3-D visualization between conversion rate and user behaviors on three real data sets.
 Table 3: The A/B test results of precision at top 10 of differ-ent impression discounting models on PYMK data set, with X = ( LastSeen , ImpCount ). and linear discounting respectively. The results show that exponen-tial discounting achieves a slightly better precision improvement, and all the Group B models gain significant improvements by in-corporating impression discounting in recommendations.
In this section, we evaluate the density weighted regression pro-posed in Section 4.5.3. Compared with traditional linear regres-sion, density weighted regression removes the outlier observations and assigns weights to observations based on their supports. Figure 9(a) shows the distribution of observation supports is very skewed and follows power-low distribution. If we treat these observations as unweighted, the squared error of each observation using tradi-tional linear regression is shown in the lower line in Figure 9(b). As we can see, although linear regression minimizes the sum of squared errors by reducing the area under the curve (AUC), squared errors are high when ImpCount is small. Since Figure 9(a) reveals that most observations have small ImpCount , traditional linear re-gression suffers from the problem that the majority of impression sequences have high prediction error.

In contrast, density weighted regression tries to minimize the prediction error of impression sequences. In this experiment, we set  X  =2 ,  X  =0 . 01 and  X  =2 . In the preprocessing, we detect Figure 9: (a) The support of observations with specific Imp-Count in logarithmic scale. (b) The squared error of each obser-vation by traditional linear regression and our anti-noise linear regression. Experiments are performed on PYMK data. and remove 5 observations on the tail. We set the weights by Eq. (15), and the squared errors are shown by the upper line in Figure 9(b). Although the AUC of density weighted regression is larger than the traditional linear regression, the squared errors are mini-mized when ImpCount is small. To evaluate their performance in model-fitting, we instantiate the RMSE in Eq. (14) by
On PYMK data set, we compute the RMSE for traditional linear regression and density weighted regression as 0.1121 and 0.0188 respectively, which indicates density weighted regression performs much better than linear regression when the distribution of obser-vation supports is skewed.
In this paper, we focuse on the impression discounting problem in large-scale recommender systems, in which a user X  X  impressions on historical recommended items are discounted to re-rank the rec-ommendation list. User satisfaction quantified by the conversion rate is expected to be improved due to the re-ranking. To precise-ly capture each facet of user interaction, we build impression dis-counting models by integrating discounting functions of user be-haviors into a linear or multiplicative aggregation model. More-over, to resolve the sparsity problem on observation supports, we propose anti-noise regression model to remove the outlier observa-tions and perform a density weighted regression, which achieves a better prediction quality than the traditional linear regression. The proposed impression discounting framework is evaluated on three real-world data sets from LinkedIn and Tencent. The precision im-provement on these impression data sets supports the effectiveness of our impression discounting model. [1] D. Agarwal, B.-C. Chen, and P. Elango. Spatio-temporal [2] E. Agichtein, E. Brill, and S. T. Dumais. Improving web [3] C. Bishop. Pattern Recognition and Machine Learning . [4] W. Chen, Y. Chen, Y. Mao, and B. Guo. Density-based [5] B. Dalessandro, R. Hook, and C. Perlich. Evaluating and [6] M. Ester, H.-P. Kriegel, J. Sander, and X. Xu. A [7] N. Gupta, A. Das, S. Pandey, and V. K. Narayanan. Factoring [8] Y. Hu, Y. Koren, and C. Volinsky. Collaborative filtering for [9] Y. Koren. Factorization meets the neighborhood: a [10] Y. Koren. Factor in the neighbors: Scalable and accurate [11] S. Kpotufe and V. K. Garg. Adaptivity to local smoothness [12] P. Lee, L. V. S. Lakshmanan, and E. E. Milios. Keysee: [13] P. Lee, L. V. S. Lakshmanan, and E. E. Milios. Incremental [14] X. Lin and D. Zhang. Inference in generalized additive [15] O. Moling, L. Baltrunas, and F. Ricci. Optimal radio channel [16] L. Page, S. Brin, R. Motwani, and T. Winograd. The [17] C. Perlich. Machine learning challenges in targeted [18] M. Richardson, E. Dominowska, and R. Ragno. Predicting [19] G. Ristanoski, W. Liu, and J. Bailey. Time series forecasting [20] D. Ruppert and M. P. Wand. Multivariate locally weighted [21] B. M. Sarwar, G. Karypis, J. A. Konstan, and J. Riedl. [22] G. P. Styan. Hadamard products and multivariate statistical [23] R. Sumbaly, J. Kreps, and S. Shah. The big data ecosystem at [24] D. Yang, T. Chen, W. Zhang, Q. Lu, and Y. Yu. Local [25] S.-H. Yang, B. Long, A. J. Smola, H. Zha, and Z. Zheng. [26] J. Zhang and P. Pu. A recursive prediction algorithm for
