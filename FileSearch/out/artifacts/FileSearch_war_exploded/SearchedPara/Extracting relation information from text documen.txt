 1. Introduction With the dramatic increase in the amount of textual information available in digital archives and the
WWW, there has been growing interest in techniques for automatically extracting information from text doc-uments. Information extraction (IE) is such a technology that IE systems are expected to identify relevant information (usually of pre-defined types) from text documents in a certain domain and put them in a struc-tured format.

According to the scope of the NIST Automatic Content Extraction (ACE) program ( ACE, 2000 X 2005 ), current research in IE has three main objectives: Entity Detection and Tracking (EDT), Relation Detection and Characterization (RDC), and Event Detection and Characterization (EDC). The EDT task entails the detection of entity mentions and chaining them together by identifying their coreference relationships. In
ACE vocabulary, entities are objects, mentions are references to them, and relations are semantic relationships between entities. For example, the ACE EDT 2003 task de-fries five entity types, i.e. persons, organizations, locations, facilities and geo-political entities (GPE: geographically defined regions that indicate a political sions and pronouns. The RDC task detects and classifies implicit and explicit relations tified by the EDT task. For example, we want to determine whether a person is at a location, based on the evidence in the context-Extraction of semantic relationships between entities can be very useful for applica-tions such as question answering, e.g. to answer the query  X  X  X ho is the president of the United States? X  X , and information retrieval, e.g. to expand the query  X  X  X eorge W. Bush X  X  with  X  X  X he president of the United States X  X  via his relationships with the country  X  X  X he United States X  X .

This paper focuses on the ACE RDC task and employs diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using support vector machines (SVM). Our study illustrates that the base phrase chunking information contributes to most of the performance improvement from syntactic aspect while current commonly used features from full parsing do not contribute much, largely due to the fact that most of relations defined in the ACE corpora are within a very short distance. We also demonstrate how semantic information such as WordNet ( Miller, 1990 ) can be used in the feature-based framework. Evaluation on the ACE benchmark corpora shows that effective incorporation of diverse features enables our system out-perform previously best-reported systems. It also shows that our feature-based approach significantly outper-forms tree kernel-based approaches.

The rest of this paper is organized as follows. First, Section 2 presents related work. Then, a brief introduc-4 . Finally, we present experimental setting and results in Section 5 and conclude with some general observa-tions and remarks in relation extraction in Section 6 . 2. Related work The relation extraction task was formulated as a critical part of information extraction at the 7th Message
Understanding Conference ( MUC-7, 1998 ) and is starting to be addressed more and more within the natural language processing and machine learning communities. Representative related works can be classified into three categories according to different approaches they used: generative models ( Miller, Fox, Ramshaw, &amp;
Weischedel, 2000 ), tree kernel-based approaches ( Bunescu &amp; Mooney, 2005; Culotta &amp; Sorensen, 2004; Zel-enko, Aone, &amp; Rochardella, 2003; Zhang, Su, Wang, Zhou, &amp; Tan, 2005 ), and feature-based approaches ( Roth &amp; Yih, 2002; Kambhatla, 2004 &amp; Zhao &amp; Grisman, 2005 ).
Miller et al. (2000) augmented syntactic full parse trees with semantic information corresponding to entities and relations, and built generative models to integrate various tasks such as POS tagging, named entity rec-ognition, template element extraction and relation extraction. The problem is that such integration may impose big challenges such as the need of a large scale annotated corpus. Generative models typically apply some smoothing techniques to integrate different scales of contexts in parameter estimation, e.g. the back-off approach in Miller et al. (2000) .
 Zelenko et al. (2003) proposed extracting relations by computing kernel functions between parse trees.
Culotta and Sorensen (2004) extended this work to estimate kernel functions between augmented dependency trees and achieved the F -measure of 45.8 on the 5 relation types in the ACE RDC 2003 corpus.
Mooney (2005) proposed a shortest path dependency kernel. They argued that the information to model a relationship between two entities can be typically captured by the shortest path between them in the depen-dency graph. It achieved the F -measure of 52.5 on the 5 relation types in the ACE RDC 2003 corpus. Zhang et al. (2005) adopted clustering algorithms in unsupervised relation extraction using tree kernels. Various scales of sub-trees are normally applied in the tree kernel computation.
 Comparably, feature-based approaches achieved much success recently. Roth and Yih (2002) used the SNoW classifier to incorporate various features such as word, part-of-speech and semantic information from
WordNet, and proposed a probabilistic reasoning approach to integrate named entity recognition and relation extraction. Kambhatla (2004) employed maximum entropy models with features derived from word, entity type, mention level, overlap, dependency tree, parse tree, and achieved the F -measure of 52.8 on the 24 relation subtypes in the ACE RDC 2003 corpus. Zhao and Grisman (2005) combined various kinds of knowledge from tokenization, sentence parsing and deep dependency analysis through support vector machines and achieved the F -measure of 70.1 on the 7 relation types of the ACE RDC 2004 corpus. mally incorporate various scales of contexts into the feature vector extensively. These approaches then depend on adopted learning algorithms to weight and combine each feature effectively. For example, an exponential model and a linear model are applied in the maximum entropy models and support vector machines (in the feature-based framework) respectively to combine each feature via the learned weight vector.

Tree kernel-based approaches, such as the ones proposed by Zelenko et al. (2003), Culotta and Sorensen (2004) and Bunescu and Mooney (2005) , are able to explore the implicit feature space without much feature tasks such as the one defined in ACE. Complicated relation extraction tasks may also impose a big challenge to the generative modeling approaches, such as the one used by Miller et al. (2000) which integrates various tasks (including part-of-speech tagging, named entity recognition, template element extraction and relation extraction) in a single model.

This paper will further explore the feature-based approach with a systematic study on the extensive incorporation of diverse lexical, syntactic and semantic information. Compared with others, we separately incorporate the base phrase chunking information, which contributes to most of the performance improve-ment from syntactic aspect. We also show how semantic information like WordNet can be equipped to further improve the performance. Evaluation on the ACE corpora shows that our system outperforms other feature-based systems. It also shows that our system significantly outperforms tree kernel-based systems. 3. Feature-based relation extraction In this paper, relation extraction is recast as a classification problem using a machine learning approach.
Just like most supervised machine learning approaches, our feature-based relation extraction relies on fea-ture-based representation of annotated relation instances. That is, an annotated relation instance is trans-formed into a collection of features f 1 , f 2 , ... , f N training, a classifier learning algorithm uses the annotated relation instances to learn a classifier while, in possible relations.

In this paper, we select support vector machines (SVM) as the classifier since SVM represent the state-of-the-art in the machine learning research community, and there are good implementations of the algorithm available, In our implementation, we use the binary-class SVM Light is a supervised machine learning technique motivated by the statistical learning theory ( Vapnik, 1998 ). Based on the structural risk minimization of the statistical learning theory, SVM seeks an optimal separating hyper-plane to divide the training examples into two classes and make decisions based on support vectors which are selected as the only effective instances in the training set.

Basically, SVM is a binary classifier. Therefore, we must extend SVM to multi-class (e.g. K ) classification such as the ACE RDC task. For efficiency, we apply the one vs. others strategy, which builds K classifiers so as to separate one class from all others, instead of the pairwise strategy, which builds K mined by the class which has the maximal SVM output. By default, we will only apply the simple linear kernel our performance using the polynomial kernel. 4. Features
Semantic relationship between two entities is determined from the context of their entity mentions. In addi-tion, we distinguish the argument order of the two mentions (M1 for the first mention and M2 for the second mention), e.g. M1-Parent-Of-M2 vs. M2-Parent-Of-M1. For each pair of mentions, ical, syntactic and semantic features. Since this paper focuses on the ACE RDC task, we will explain relevant features in the context of the ACE RDC 2003 and 2004 corpora.

Fig. 1 gives an illustration of all the various types of features extracted from a relation instance of type  X  X  X OCIAL.OTHER-PERSONAL X  X  between two entity mentions  X  X 200 domestic partners X  X  and  X  X  X heir own workers X  X  in the sentence  X  X  X o provide benefits to 200 domestic partners of their own workers in New York X  X .
In this paper, eight types of features are employed. Next, we will describe each of them one by one. 4.1. Words
According to their positions, four categories of words are considered: (1) the words of both the mentions; (2) the words between the two mentions; (3) the words before M1; and (4) the words after M2. For the words of both the mentions, we also differentiate the head word is generally much more important and informative. The words between the two mentions are classified into three bins: the first word in between, the last word in between and other words in between. Both the words before M1 and after M2 are classified into two bins: the first word next to the mention and the second word next to the mention. This means that we only consider the two words before M1 and after M2. Since a pro-nominal mention (especially neutral pronoun such as  X  X t X  and  X  X ts X ) contains little information about the sense of the mention, the coreference chain is used to decide its sense. This is done by replacing the pronominal men-tion with the most recent non-pronominal antecedent when determining the word features.
 In details, this category of features includes: WM1: bag-of-words in M1.
 HM1: head word of M1.
 WM2: bag-of-words in M2.
 HM2: head word of M2.
 HM12: combination of HM1 and HM2.
 WBNULL: when no word in between.

WBFL: the only word in between when only one word in between. WBF: first word in between when at least two words in between.
 WBL: last word in between when at least two words in between.
 WBO: other words in between except first and last words when at least three words in between. BM1#1: first word before M1.
 BM1#2: second word before M1.
 AM2#1: first word after M2.

AM2#2: second word after M2. 4.2. Entity type This category of features concerns about the entity types of both the mentions, e.g. which can be PERSON,
ORGANIZATION, FACILITY, LOCATION and GPE in the ACE RDC 2003 task, their entity subtypes and entity classes (defining the kind of reference an entity makes to something in the world) if available: ET12: combination of mention entity types.
 EST12: combination of mention entity subtypes.

EC12: combination of mention entity classes. 4.3. Mention level This category of features considers the entity level of both the mentions, e.g. which can be NAME,
NOMIAL and PRONOUN in the ACE RDC 2003 task, and the more detailed LDC mention types if available: ML12: combination of mention levels.

MT12: combination of LDC mention types. 4.4. Overlap
This category of features includes: #MB: number of other mentions in between. #WB: number of words in between.
 M1 &gt; M2 or M1 &lt; M2: flag indicating whether M2/M1 is included in M1/M2.

Normally, the above overlap features are too general to be effective alone. Therefore, they are also com-bined with other features: (1) ET12(or EST12) + M1 &gt; M2; (2) ET12(or EST12) + M1 &lt; M2; (3)
HM12 + M1 &gt; M2; (4) HM12 + M1 &lt; M2. 4.5. Base phrase chunking
It is well known that chunking plays a critical role in the Template Relation task of the 7th Message Under-standing Conference ( MUC-7, 1998 ). However, the related work mentioned in Section 2 only explored the information embedded in the full parse trees. In this paper, we separate the features of base phrase chunking from those of full parsing. In this way, we can separately evaluate the contributions of base phrase chunking and full parsing. Here, the base phrase chunks are derived from full parse trees using the Perl script by Sabine Buchholz from Tilburg University and the Collins X  parser ( Collins, 1999 ) is employed for full pars-ing. Most of the chunking features concern about the head words of the phrases between the two mentions.
Similar to word features, three categories of phrase heads are considered: (1) the phrase heads in between, which are classified into three bins: the first phrase head in between, the last phrase head in between and other phrase heads in between; (2) the phrase heads before M1, which are classified into two bins: the first phrase head before and the second phrase head before; (3) the phrase heads after M2, which are classified into two bins: the first phrase head after and the second phrase bead after. This means that we only consider the two phrases before M1 and after M2. Moreover, we also consider the phrase path in between: CPHBNULL when no phrase in between.
 CPHBFL: the only phrase head when only one phrase in between.
 CPHBF: first phrase head in between when at least two phrases in between.
 CPHBL: last phrase head in between when at least two phrase heads in between.

CPHBO: other phrase heads in between except first and last phrase heads when at least three phrases in between.
 CPHBM1#1: first phrase head before M1.
 CPHBM1#2: second phrase head before M1.
 CPHAM2#1: first phrase head after M2.
 CPHAM2#2: second phrase head after M2.
 CPP: path of phrase labels connecting the two mentions in the chunking.

CPPH: path of phrase labels connecting the two mentions in the chunking augmented with head words of the phrases in between, if at most two phrases in between. 4.6. Dependency tree
This category of features includes information about the words, part-of-speeches and phrase labels of the words on which the mentions are dependent in the dependency tree derived from the syntactic full parse tree.
The dependency tree is built by using the phrase head information returned by the Collins X  parser and linking the same NP/PP/VP.
 ET1DW1: combination of the entity type and the dependent word for M1.
 H1DW1: combination of the head word and the dependent word for M1.
 ET2DW2: combination of the entity type and the dependent word for M2.
 H2DW2: combination of the head word and the dependent word for M2.
 ET12SameNP: combination of ET12 and whether M1 and M2 included in the same NP.
 ET12SamePP: combination of ET12 and whether M1 and M2 exist in the same PP.

ET12SameVP: combination of ET12 and whether M1 and M2 included in the same VP. 4.7. Parse tree This category of features concerns about the information inherent only in the full parse tree: PTP: path of phrase labels (removing duplicates) connecting M1 and M2 in the parse tree.

PTPH: path of phrase labels (removing duplicates) connecting M1 and M2 in the parse tree augmented with the head word of the top phrase in the path. 4.8. Semantic resources
Semantic information from various resources, such as WordNet, is used to classify important words into different semantic lists according to their indicating relationships. On the one hand, such information can be used to differentiate various relations. On the other hand, it can help resolve the data sparseness problem in relation extraction. 4.8.1. Country name list
This is mainly used to differentiate the relation subtype  X  X  X OLE.Citizen-Of X  in the ACE RDC 2003 task, which defines the relationship between a person and the country of the person X  X  citizenship, from other role relation subtypes, especially  X  X  X OLE.Residence X  X  in the ACE RDC 2003 task, which defines the relationship between a person and the location in which the person lives. For the ACE RDC 2004 task, this country name
GPE (Geo-Political Entities, such as country names and provincial names). Its impact is indirect and mainly due to its effect in resolving the data sparseness problem. Two features are defined to include this information: ET1 Country: the entity type of M1 when M2 is a country name.

CountryET2: the entity type of M2 when M1 is a country name. 4.8.2. Personal relative trigger word list This is mainly used to differentiate the six personal social relation subtypes in the ACE RDC 2003 task:
Parent, Grandparent, Spouse, Sibling, Other-Relative and Other-Personal. This trigger word list is first gath-ered from WordNet by checking whether a word has the semantic class  X  X  X er-son j ... j relative X  X . Then, all the trigger words are semi-automatically 9 classified into different categories according to their related personal social relation subtypes. We also extend the list by collecting the trigger words from the head words of the mentions in the training data according to their indicating relationships. For the ACE RDC 2004 task, this list can be used to differentiate  X  X  X ER-SOC.Family X  X , which defines any familial relationship between two enti-ties, from other personal/social relation subtypes, especially  X  X  X ER-SOC.Business X  X , which defines any profes-sional relationship between two entities. Two features are defined to include this information:
ET1SC2: combination of the entity type of M1 and the semantic class of M2 when M2 triggers a personal social subtype.

SC1ET2: combination of the entity type of M2 and the semantic class of M1 when the first mention triggers a personal social subtype. 5. Experimentation
This paper mainly uses the ACE RDC 2003 corpus provided by LDC to train and evaluate our feature-based relation extraction system for both final and detailed performance. This ACE corpus is gathered from various newspapers, newswire and broadcasts. In this paper, we only model explicit relations because of poor inter-annotator agreement in the annotation of implicit relations and their limited number. Detailed evalua-tion has been also done on the ACE RDC 2004 corpus and shows similar tendency with the ACE RDC 2003 corpus. To avoid redundancy, we will report only the final performance on the ACE RDC 2004 corpus. 5.1. Experimental setting
We mainly use the official ACE RDC 2003 corpus from LDC, which is divided into a training set and a testing set, for both detailed and final evaluation. The training set consists of 674 annotated text documents ( 300 k words) and 9683 instances of relations. During development, 519 documents in the training set are used for training while the remaining 155 (674 519) documents are set aside for fine-tuning the system.
The testing set is held out only for final evaluation. It consists of 97 documents ( 50 k words) and 1386 instances of relations. The ACE RDC 2003 task defines 5 relation types and 24 subtypes between 5 entity types, i.e. person, organization, location, facility and GPE. Table 1 lists the types and subtypes of relations for the ACE RDC 2003 task, along with their frequencies of occurrence in the training set. It shows that this
ACE RDC 2003 corpus suffers from a small amount of annotated data for a few subtypes such as the subtype  X  X  X ounder X  X  under the type  X  X  X OLE X  X . It also shows that the ACE RDC 2003 task defines some difficult sub-types such as the subtypes  X  X  X ased-In X  X ,  X  X  X ocated X  X  and  X  X  X esidence X  X  under the type  X  X  X T X  X , which are difficult even for human experts to differentiate.
 Moreover, we also report our final performance on the ACE RDC 2004 corpus. Compared with the ACE
RDC 2003 task, the ACE RDC 2004 task defines two more entity types, i.e. weapon and vehicle, much more entity subtypes, and different 7 relation types and 23 subtypes between 7 entity types. The ACE RDC 2004 corpus from LDC contains 451 documents and 5702 relation instances. For comparison with Zhao and Gris-man (2005) , we only use the same set of 348 documents in the corpus, which contain 125 k words and 4400 relation instances. Evaluation was done using 5-fold cross-validation.

In this paper, we iterate over all pairs of entity mentions occurring in the same sentence to generate potential relation instances. We also explicitly model the argument order of the two mentions involved.
For example, when comparing mentions m1 and m2, we distinguish between m1-ROLE.Citizen-Of-m2 and m2-ROLE.Citizen-Of-m1. Note that, in the ACE RDC 2003 task, 6 of these 24 relation subtypes are symmet-ric:  X  X  X EAR.Relative-Location X  X ,  X  X  X OCIAL.Associate X  X ,  X  X  X OCIAL. Other-Relative X  X ,  X  X  X OCIAL.Other-Pro-fessional X  X ,  X  X  X OCIAL.Sibling X  X , and  X  X  X OCIAL.Spouse X  X . In this way, we model relation extraction as a multi-class classification task with 43 (24  X  2 6 + 1) classes, two for each relation subtype (except the above 6 symmetric subtypes) and a  X  X  X ONE X  X  class for the case where the two mentions are not related. For the ACE RDC 2004 task, 6 of these 23 relation subtypes are symmetric:  X  X  X HYS.Near X  X ,  X  X  X ER-SOC.Business X  X ,  X  X  X ER-
SOC.Family X  X ,  X  X  X ER-SOC.Other X  X ,  X  X  X MP-ORG.Partner X  X , and  X  X  X MP-ORG.Other X  X . In this way, we model relation extraction as a multi-class classification task with 41 (23  X  2 6 + 1) classes, two for each relation subtype (except the above 6 symmetric subtypes) and a  X  X  X ONE X  X  class for the case where the two mentions are not related. 5.2. Experimental results
In this paper, we only measure the performance of relation extraction on  X  X  X rue X  X  mentions with  X  X  X rue X  X  chaining of coreference (i.e. as annotated by the corpus annotators) in the ACE corpora. Table 2 measures the performance of our relation extraction system over the 24 relation subtypes on the testing set of the
ACE RDC 2003 corpus. It shows that our system achieves best performance of 63.1%/49.5%/55.5 in preci-sion/recall/ F -measure when combining all the diverse lexical, syntactic and semantic features. Therefore, all the features described in Table 2 are employed thereafter in our system since such combination shows best performance. Table 2 also measures the contributions of different features by gradually increasing the feature set in the increasing order of feature complexity. It shows that: Using word features only achieves the performance of 69.2%/23.7%/ 35.3 in precision/recall/ F -measure.
Entity type features are very useful and improve the F -measure by 8.1 units largely due to the recall increase.

The usefulness of mention level features is quite limited. It only improves the F -measure by 0.8 units due to the recall increase.

Incorporating the overlap features gives some balance between precision and recall. It increases the F -mea-sure by 3.6 units with a big precision decrease and a big recall increase.

Chunking features are very useful. It increases the precision/recall/ F -measure by 4.1%/5.6%/5.2 units, respectively.

To our surprise, incorporating the dependency tree and parse tree features only improve the F -measure by 0.6 and 0.4 units, respectively. This may be due to the fact that most of relations in the ACE RDC 2003 corpus are quite local. Table 3 shows that about 70% of relations exist where two mentions are embedded in each other or separated by at most one word, although the context information in the left and right of the two mentions is also useful in relation extraction. While short-distance relations dominate and can be resolved by above simple features, the dependency tree and parse tree features can only take effect in the remaining much less long-distance relations. However, full parsing is always prone to long-distance errors although the Collins X  parser used in our system represents the state-of-the-art in full parsing. Another rea-son may be that current dependency tree and parse tree features extracted in this paper is not effective to reflect the syntactic structure in relation extraction.

Incorporating semantic resources such as the country name list and the personal relative trigger word list further increases the F -measure by 1.5 units largely due to the differentiation of the relation subtype  X  X  X OLE.Citizen-Of X  X  from  X  X  X OLE. Residence X  X  by distinguishing country GPEs from other GPEs. The effect of personal relative trigger words is very limited due to the limited number of testing instances over personal social relation subtypes.
 Table 4 separately measures the performance of different relation types and major subtypes in the ACE
RDC 2003 corpus. It also indicates the number of testing instances, the number of correctly classified instances and the number of wrongly classified instances for each type or subtype. It is not surprising that the perfor-mance on the relation type  X  X  X EAR X  X  is low because it occurs rarely in both the training and testing data. Oth-ers like  X  X  X ART.Subsidary X  X  and  X  X  X OCIAL.Other-Professional X  X  also suffer from their low frequencies of occurrence. It also shows that our system performs best on the subtype  X  X  X OCIAL.Parent X  X  and  X  X  X OLE.Cit-izen-Of X  X . This is largely due to incorporation of two semantic resources, i.e. the country name list and the personal relative trigger word list. Table 4 also indicates the low performance on the relation type  X  X  X T X  X  although it frequently occurs in both the training and testing data. This suggests the difficulty of detecting and classifying the relation type  X  X  X T X  X  and its subtypes.
 Table 5 separates the performance of relation detection from overall performance on the testing set of the
ACE RDC 2003 corpus. It shows that our system achieves the performance of 84.8%/66.7%/74.7 in precision/ recall/ F -measure on relation detection. It also shows that our system achieves overall performance of 77.2%/ 60.7%/68.0 and 63.1%/49.5%/55.5 in precision/recall/ F -measure on the 5 relation types and 24 relation sub-types, respectively. Compared with the best-reported system in Kambhatla (2004) , our system achieves better performance by 3 units in F -measure largely due to its gain in recall. Moreover, we also evaluate our system using the polynomial kernel with degree d = 2. It shows that this can further improve the F -measure by difference in the extraction of 5 relation types. Finally, it also shows that feature-based methods dramatically outperform kernel methods. This suggests that feature-based methods can effectively combine different fea-tures from a variety of sources (e.g. WordNet) that can be brought to bear on relation extraction while current tree kernels developed in Culotta and Sorensen (2004) and Bunescu and Mooney (2005) mainly capture the structured syntactic information and are yet to be effective on the ACE RDC 2003 task.

We also evaluate our final performance in the ACE RDC 2004 corpus using 5-fold cross-validation. Table 6 shows that our system achieves the performance of 87.6%/64.0%/74.0 in precision/recall/ F -measure on rela-tion detection. It also shows that our system achieves overall performance of 81.4%/59.5%/68.7 and 73.8%/ 54.1%/62.4 in precision/recall/ F -measure on the 7 relation types and 23 relation subtypes, respectively. This indicates that the ACE RDC 2004 task is much easier than the ACE RDC 2003 task, especially in the extrac-tion of relation subtypes, largely due to the fine definition of entity subtypes in the ACE RDC 2004 task.
Moreover, we also evaluate our system using the polynomial kernel with degree d = 2. It shows that this can further improve the F -measure by 1.3 units in the extraction of 23 relation subtypes. Compared with the best-reported system in Zhao and Grisman (2005) which applies a complicated composite polynomial ker-interesting to note that our system and Zhao and Grisman (2005) are quite complementary in precision and recall: our system achieves much higher precision and lower recall while Zhao and Grisman (2005) has lower precision and higher precision. This indicates possible performance improvement by integrating them.
Due to the difficulty in building a large annotated corpus, another interesting question is about the adapt-the ACE RDC 2003 corpus while keeping all the training examples of remaining relation subtypes. It shows that the three major relation subtypes can achieve a bit stable performance on different training data sizes ranging from 700 to 1100 training examples. It also shows that further steady improvement can be achieved for the three major relation subtypes after the turning points. This indicates that, as the current largest anno-tated corpus in relation extraction, the ACE RDC 2003 corpus still suffers from the lack of training data, even for major relation subtypes.

Finally, Table 7 shows the distributions of errors in the ACE RDC 2003 corpus. It shows that 73% (627/ 864) of errors results from relation detection and 27% (237/864) of errors results from relation characteriza-tion, among which 17.8% (154/864) of errors are from misclassification across relation types and 9.6% (83/364) of errors are from misclassification of relation subtypes inside the same relation types. This suggests that per-formance improvement on relation detection is critical for the success of relation extraction. 6. Discussion and conclusion
In this paper, we have presented a feature-based approach for relation extraction where diverse lexical, syn-tactic and semantic knowledge are employed. Instead of exploring the full parse tree information directly as previous related work, we incorporate the base phrase chunking information first Evaluation on the ACE
RDC corpora shows that base phrase chunking contributes to most of the performance improvement from syntactic aspect while further incorporation of the parse tree and dependence tree information only slightly improves the performance. This may be due to three reasons: First, most of relations defined in the ACE
RDC task have two mentions being close to each other While short-distance relations dominate and can be resolved by simple features such as word and chunking features, the further dependency tree and parse tree features can only take effect in the remaining much less and more difficult long-distance relations. Second, full parsing is always prone to long-distance parsing errors although the Collins X  parser used in our system achieves the state-of-the-art performance. Therefore, the state-of-art full parsing still needs to be further enhanced to provide accurate enough information, especially PP (Preposition Phrase) attachment. effective way need to be explored to incorporate information embedded in the full parse trees. This means that syntactic structure in relation extraction. However, this also suggests that a cheap and robust solution can be achieved in relation extraction with the near state-of-the-art performance. Besides, we also demonstrate how semantic information such as WordNet, can be used in feature-based relation extraction to further improve the performance.

The effective incorporation of diverse features enables our system outperform previously best-reported sys-tems on the ACE RDC corpora. Although tree kernel-based approaches facilitate the exploration of the impli-cit feature space with the parse tree structure, yet the current technologies are expected to be further advanced to effectively explore the structured syntactic information. Evaluation on the ACE RDC corpora shows that our approach of combining various kinds of evidence can scale better to problems, where we have a lot of relations with a relatively small amount of annotated data. The experiment result also shows that our fea-ture-based approach significantly outperforms the tree kernel-based approaches. However, we find it difficult to further improve the performance in feature-based relation extraction by incorporating more features.
Moreover, our error analysis shows that relation detection is critical in relation extraction. We think that the structured syntactic information may play a critical role in detecting a relation. This indicates that future success in relation extraction largely depends on effectively exploring structured syntactic information. This suggests the urgency in exploring more effective tree kernels in relation extraction in the future.
In the future work, we will focus on research and development in tree kernels. A straightforward way is to 2001 ) and semantic role labeling ( Moschitti, 2004 ), in relation extraction. In the meanwhile, we will explore more semantic knowledge in relation extraction, which has not been covered deeply by current research. Finally, our current work is done when the entity detection and tracking (EDT) task has been perfectly done. Therefore, it would be interesting to see how imperfect EDT affects the performance in relation extraction. References
