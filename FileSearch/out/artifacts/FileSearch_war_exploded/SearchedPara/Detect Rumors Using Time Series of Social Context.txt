 Automatically identifying rumors from online social media especially microblogging websites is an important research issue. Most of existing work for rumor detection focuses on modeling features related to microblog contents, users and propagation patterns, but ignore the importance of the variation of these social context features during the message propagation over time. In this study, we propose a novel ap-proach to capture the temporal characteristics of these fea-tures based on the time series of rumor X  X  lifecycle, for which time series modeling technique is applied to incorporate var-ious social context information. Our experiments using the events in two microblog datasets confirm that the method outperforms state-of-the-ar t rumor detection approaches by large margins. Moreover, our model demonstrates strong performance on detecting rumors at early stage after their initial broadcast.
 H.4 [ Information Systems Applications ]: Miscellaneous Rumor detection; temporal; time series; social context
A rumor is commonly defined as a statement whose truth value is unverifiable or deliberately false [3]. These rumors on microblogging websites, carrying unreal or even malicious information, can bring massive panic and social unrest to our community. For instance, on April 23, 2013, a rumor on Twitter about two explosions in the white house injuring Barack Obama caused the stock market crash in the US 1 . http://www.bbc.com/news/world-us-canada-21508660 c Figure 1: The two sample features changing over time (in hours) demonstrates different patterns in rumors and non-rumors Therefore, automatic rumor detection technique that can quickly identify rumor messages and dynamically monitor the propagation of rumors become very useful.

Existing rumor detection methods typically exploit super-vised machine learning models based on a wide range of fea-tures corresponding to users, contents of messages and their propagation patterns [2, 9, 7, 8, 10, 11]. An obvious limi-tation of these models is that they just consider the overall statistics on the social context information of messages as features, e.g., the total number of retweets, the time length of propagation, etc., and ignore the variation of these fea-tures over time.

To improve the accuracy of detection, we argue that it is of importance not only looking at the overall properties and the properties of individual messages, but also studying the changes or the trends of these properties along the lifecycle of the concerned hypothesis. For example, given two Twit-ter events, one is about  X  X iring squad X  (a rumor) and the other about  X  X ilton is arrested X  (a non-rumor), Figure 1(a) and 1(b) show the variation of proportion of tweets using question marks and first person pronouns using time series, respectively, which are two of the typical features used in previous work. Figure 1(a) implies that the non-rumor tends to use less question marks than the rumor does at the later stage, but according to Figure 1(b), there might be more frequent use of the first person pronoun in the rumor at the early stage. Such variations reflect different characteristics of rumors and non-rumors over time during diffusion.
Kwon et al. [5, 4] recently introduced a time series fit-ting model that shows better detection result based on the temporal properties regarding a single feature  X  tweet vol-ume. However, their temporal model focuses on converting the continuous time series of tweet volume into only 3 fit-ting parameters for capturing the temporal fluctuations of features, which might result in significant information loss given complex time series. Also, it is difficult to extend the number of fitting parameters in their model for further im-proving the fitting effect.

To overcome these shortcomings, we propose a novel time series model called Dynamic Series-Time Structure (DSTS) to capture the variation of a wide spectrum of social context information over time far more than the tweet volume fea-ture. We will study how well the time series of social context features can capture the variation of these features during the spread of event messages, which is supposed to bene-fit the differentiation between rumors and non-rumors. We utilize two datasets containi ng hundreds of events crawled from Twitter and Sina Weibo which are the most popular microblogging websites in English and Chinese, respectively. We build classifiers using the DSTS-based features and the annotated datasets. In our approach, we examine two basic settings: (1) given the complete lifecycle of an event about some specific topic, we decide it is a rumor or not; (2) given the event data at the early stage of propagation, we apply our model for early rumor detection. Experimental results under the two settings demonstrate that our DSTS-based model achieves promising improvements over the state-of-the-art approaches on both datasets.
An event is considered as a set of microblogs related to some specific topic, e.g.,  X  X illary Clinton announces 2016 campaign for president X ,  X  X H370 landing in Nanning X , etc.. The topics can be compiled manually from Twitter [2] or de-rived from Sina X  X  community management center [10], which include verified rumors and non-rumor events (Section 4.1).
We model microblog data as a set of events E = { E i } , and each event E i consists of relevant microblogs { m ij We represent each E i as a D-dimensional vector F D i con-taining social context features regarding the contents, users and diffusion patterns of the relevant microblogs. To make the number of features tractable, we convert the continu-ous time stream of microblogs associated with each event into fixed time intervals. For learning our model, we extract a rich set of features sensitive to time, where not only the overall statistics of social context information but also the variation of individual features based on the time intervals can be captured.

In this section, we will first introduce an approach to discretize time stream for generating time stamps, then a method for capturing the variation of features.
For an event E i ,let timeFirst i and timeLast i be the time when the initial and the last microblog is posted, re-spectively. We convert the creation time of each microblog m ij to a time interval falling into the range from 0 to N , serving as the time stamp of m ij ,where N is the tunable number of time intervals. We determine the length of time interval for E i and the time stamp (TS) for m ij created at time t m ij as follows: where Interval ( . ) is the length of each time interval in the number of time units like minutes, hours or days, and TS ( is the index of time stamp which m ij falls into, taking the value of 0 , 1 ,  X  X  X  ,N . We use hour as time unit in this work.
With all the time stamps of E i , a vector of its social con-text features V ( E i ) can be naturally generated given each time stamp. However, the temporal properties of such infor-mation is subject to continuous change over time, which can-not be captured effectively by just modeling features within individual time intervals. A better approach would be to identify the shapes of time series, which are formed by the relative change between the consecutive intervals, as a sup-plement of the absolute temporal properties.

For this purpose, we propose a Dynamic Series-Time Struc-ture (DSTS), which is used to capture the variation of each feature. In this structure, we not only consider the absolute feature values from the initial time up to each interval, but also incorporate the slopes of features between two consecu-tive intervals. Therefore, the feature vector based on DSTS is represented as: where F D i,t is the feature vector generated from social context features for the microblogs in E i from time 0 to the interval ,and S D i,t is the slopes of features between the and the ( t +1)-th intervals.

We use Z-score to normalize feature values along the time series. The Z-score of a feature from 0 to the t -th interval f t,k is defined as where f k is the mean of the k -th feature and  X  ( f k )isthe standard deviation of the k -th feature over all the time in-tervals, and f t,k is the k -th feature from time 0 to the interval which is obtained by calculating the average or other statistics of the feature over the microblogs falling into that time span (Section 3).
In this section, we will engineer each of the social context features corresponding to f t,k given in Equation 6. Note that f t,k is typically obtained by averaging the original so-cial context feature f k defined on individual microblogs, but chances are there that some features are defined di-rectly on all microblogs from time 0 to the interval t .We present three types of features: content-based, user-based and propagation-based features, some of which are derived from prior work [2, 10, 11] and several others are newly pro-posed. Table 1 describes all these features. For clarity, we give more details on some of the following features.
For the simplicity of presentation, we omit the notation of the event index i here Table 1: Description of features f t,k on microblogs from time 0 to time interval t of an event
LDA-based topic distribution : For all the microblogs in
E , we use a Latent Dirichlet Allocation (LDA) model [1] to obtain a n -topic distribution for each post. For every post m ij of every event E i ,wehave T ( m ij )=( p where p ( z ) ij is the probability of m ij belonging to topic 1 ,  X  X  X  ,n ). Then the topic distributions of all microblogs in the concerned time span of an event are averaged to obtain the n LDA-based topic distribution features. We set n =18 following previous work [10].

Average sentiment score : Similar feature but not the same was used in [2, 10]. Given a sentiment lexicon and an emoticon lexicon, the average sentiment score of microblogs in a time span of event E i is calculated as: where | w pos | ij and | w neg | ij is the number of positive and negative words, respectively, | e pos | ij and | e neg | ij ber of smiling and frowning emoticons, respectively, in mi-croblog m ij ,and | m i | is the number of microblogs in the concerned time span of event E i . For tweets, we use MPQA sentiment lexicon and a set of frequent emoticons collected by ourselves; for Weibo, we used the sentiment lexicon and emoticons described in [10].
For tweets, we used the public dataset released by Castillo et al. [2]. They extracted 288 events using Twitter Moni-tor [6] from tweet feeds in April-September 2010. We fil-tered out events with less than 10 tweets and left 207 pop-http://mpqa.cs.pitt.edu/lexicons/ ular events, in which 110 of them are labeled as rumors. We also collected an additional microblog dataset from Sina Weibo, where the verified rumors came from Sina X  X  commu-nity management center [10] that accepts reports of various misinformation. We kept tho se rumor events with at least 100 posts. This left us 422 rumor events. We injected 500 normal (non-rumor) events, each with more than 100 posts. Sina Weibo API 4 provides interfaces to capture the infor-mation of original and retweeted posts. Table 2 shows the details for our datasets.

We resorted to linear SVM classifier for our model. We made comparison between our DSTS-based SVM model and several strong baselines: (1) DT: The Twitter credibility model using Decision Tree classifier proposed in [2] with the social context features in Table 1 without considering time series ; (2) RF: The Random Forest classifier proposed in [5] using features consisting of the three parameters fit-ting tweet volume curve [5] plus all static features in Table 1; (3) RF-ext: Our extension of the RF model [5] with addi-tional features by adding the fitting parameters of time se-ries of all social context features in Table 1; (4) SVM-RBF: The SVM-based model with RBF kernel proposed in [11] using all features in Table 1 without considering time se-model using content-based, user-based and diffusion-based features, respectively; (6) SV M DSTS all : Our fully configured DSTS model. We did not compare with [10] which used specific propagation structure of Sina Weibo platform while our method is much more general.
 We implemented DT, RF and RF-ext using Weka 5 and SVM models with LibSVM 6 . We conducted 10-fold cross-validation, and used accuracy, precision, recall and F-measure for evaluation. We fixed N =50 on a development set.
Table 3(a) and 3(b) show the performance of different methods. Overall, our system SV M DSTS all , although a linear model, clearly outperforms the baselines that are all based on non-linear models. In terms of accuracy, it improves DT, RF, RF-ext and SVM-RBF by 9.5%, 3.3%, 4.4% and 9.1% respectively on Twitter data, and improves the same by 9.3%, 3.8%, 5.2% and 8.6% respectively on Weibo data. This is because DSTS model could reserve much variation of the rich social context information. DT only uses the static social context features over the entire lifecyle of posts, and RF uses as additional features the three parameters of a model that fits the time series of retweets volume, which may suffer from information loss. Surprisingly, RF-ext per-forms worse than RF, which implies that representing the variation of each feature with the three parameters cannot http://open.weibo.com/wiki/API http://www.cs.waikato.ac.nz/ml/weka/ http://www.csie.ntu.edu.tw/~cjlin/libsvm/ Table 3: Results of comparison with different meth-ods (R: Rumor; N: Non-rumor) capture complex propagation patterns and fitting more fea-tures may accumulate even more information loss. Extend-ing the three fitting parameters is limited by their original model. SVM-RBF is even worse than our DSTS models just using content-based and user-based subsets of features, in-dicating that our time series representation is very effective.
We find that using the subsets of features alone except diffusion-based features is already comparably good as the best baselines. Combining all features gives the best perfor-mance suggesting that they are complementary.
We examine the performance of our model on rumor early detection task that aims to identify rumors in the early stage of propagation. Given a detection deadline, we assume all messages of test events after the deadline are invisible when testing our model. When training the model, the complete lifecyle of training events is assumed observable.
Figure 2 shows the accuracy of our model SV M DSTS all in comparison with the baselines DT, RF, RF-ext and SVM-RBF at different deadlines. At the first few hours, our model does not have obvious advantage because it lacks of sufficient variation of social context. As time goes by, the performance of our model climbs much more rapidly after 5-10 hours while other models do not improve much because DSTS can capture rich variation patterns of features from the time se-ries. Ours model achieves the similar accuracies of baselines at much earlier stage than they need. For example, on Twit-ter, it takes our model around 15 hours to get the highest accuracy of RF, the second best baseline, while RF needs more than 25 hours; on Weibo, our model needs about 20 hours but RF needs nearly 70 hours to achieve the similar performance. This suggests our model is very effective for early detection.
We proposed a novel approach to automatically identify rumors on microblogging websites. We develop a Dynamic Series-Time Structure model which explores the variation of various social context features over time. Experimental re-sults show that our method with the time series of features achieves salient improvement on rumor detection given the complete lifecyle of events as well as at the early stage of dif-fusion. In future work, we plan to investigate unsupervised models using time series for identifying rumors online. This work is partially supported by General Research Fund of Hong Kong (417112), Shenzhen Fundamental Research Program (JCYJ20130401172046450, JCYJ20120613152557576).
