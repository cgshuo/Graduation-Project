 Motivated by the critical importance of connectives in recognizing discourse relations, we present an unsupervised cross-argument inference mechanism to implicit discourse relation recognition. The basic idea is to infer the implicit discourse relation of an argument pair from a large number of comparable argument pairs, which are automatically retrieved from the web in an unsupervised way. In this way, the inference proceeds from explicit relations to implicit ones via connective as bridge. This kind of pair-to-pair inference is based on the assumption that two argument pairs with high content similarity (i.e. comparable argument pairs) should have si milar discourse relationship. Evaluation on PDTB proves the effectiveness of our inference mechanism in implicit relation recognition to the four level-1 relations. It also shows that our mechanism significantly outperforms other alternatives. I.2.7 [ Computing Methodologies ]: Artifical Intelligence  X  Natual Language Processing (Discourse). Algorithms, Measurement, E xperimentation, Languages. Implicit discourse relation, pair-to-pair inference. The task of discourse relation recognition is to automatically predict the internal structure and logical relationship between adjacent text spans (clauses, sentences or paragraphs), such as the ones explored in our paper, Comp arison, Contingency (also called Causal), Temporal and Expansion, as annotated in the Penn Discourse Tree Bank [1] . Thereafter in this paper, we limit the discourse corpus and the discourse relations to PDTB and these four relationships respectiv ely, otherwise specified. &amp; rhetorical question: What can the keyword pair  X  go-Go  X  do for the discourse analysis? (3) Current college students study 24 hours a day, (4) You wanna go? [Implicit=then] Go now. Motivated by the critical importance of connectives in recognizing explicit discourse re lations, this paper proposes a cross-argument inference mechanism to overcome the three major issues in recognizing implicit relations. Here, an argument (abbr., Arg) denotes a text span by the definition of PDTB. The basic idea is to infer the implicit discourse relation of an argument pair from a large number of comparable argument pairs, which are automatically retrieved from the web in an unsupervised way. This kind of pair-to-pair inferen ce is based on the assumption that two argument pairs with high content similarity (i.e. comparable argument pairs) should have simila r discourse relationship. In this way, the inference proceeds from explicit relations to implicit ones via connective as bridges. Example (5) shows two argument pairs meeting the requirements of the cross-argument inference: (5) Arg1: Bush beats McCain, Obviously, above three major issues can be well addressed by our cross-argument inference mechan ism, i.e. through employing connective as bridge to achieve the inference from explicit relations to implicit relations, a voiding the intricate linguistic or rhetorical analysis via direct discourse relation mapping between comparable argument pairs and data sparseness via retrieving comparable argument pairs from the large-scale web data. The rest of the paper is organized as follows. Section 2 overviews related work. Section 3 introduces PDTB. Section 4 describes our cross-argument inference mechanism for implicit discourse relation recognition. Section 5 shows the experiments and discussion. Finally, we concl ude our work in Section 6. Similar to explicit relation recognition, all the existing studies on implicit recognition adopt a superv ised learning framework with focus on exploring various kinds of linguistic features. Pitler and Louis (2009) [4] explored several linguistically informed features, including polarity tag, Le vin verb class, length of verb phrase, modality, context, and lexical features. They worked with Penn Discourse Treebank [1] , the largest available annotated corpora of discourse relations , showing performance increases over a random classification baseline. Lin and Kan (2009) [5] inherited this theme and expended the contextual features by using the dependency patterns and the possible correlations between pair s of discourse relations. Their classifier considered the context of the two arguments, as well as the arguments X  internal cons tituent and dependency parses, showing an accuracy of 40.2% on PDTB. The PDTB is the first corpus to systematically identify and distinguish explicit and implicit di scourse relations, allowing us to concentrate solely on the implicit relations. By definition, an explicit relation is triggered by the presence of a discourse connective which occurs overtly in the text. The discourse connective can essentially be viewed as a discourse-level predicate which takes two clausal arguments. Example 6 shows an explicit Contingency relation triggered by the discourse connective  X  because  X , where the last line shows the relation type and the file ( ID indicates file number) in the PDTB from which the example is drawn. The cor pus recognizes 100 such explicit connectives and contains annotations for 19,458 explicit relations. Implicit relation is inferred by the reader but not marked by an overt discourse connective in the text. In this case, for a pair of adjacent spans, the annotator was asked to provide a connective that best captured the inferred relation. Example (7) shows an implicit relation, where the annotator inferred a Contingency relation and inserted an implicit connective  X  so  X  (i.e., the original text does not include  X  so  X ). There are a total of 16,584 implicit relations annotated in the corpus. (7) Arg1 : You look tired. In addition to discourse relations and their arguments, the PDTB also provides the senses of each relation (Miltsakaki and Livio, 2008). The tagset of senses is orga nized hierarchically into three levels. The top level consists of four major relation classes: Temporal, Contingency, Comparison, and Expansion. For each class, a second level of types is defined to provide finer semantic distinctions. A third level of subtypes is defined for only some types to specify the semantic contribution of each argument. In this paper, we focus on implicit relation recognition to the Level 1 classes, as until recently, the cla sses could be predicted with only 40.2% in accuracy at best (Lin and Kan, 2009) [5] . In this section, we firstly give the framework of our cross-argument inference method, and then approach the issues of comparable argument pair mining, relation sense disambiguation and pseudo-cue filtering. The first is to detect the comparable argument pairs to form the basis of the inference; the second is to disambiguate the relation senses of explicit connectives in the mapping process (e.g. discrimina tion between Contingency and Temporal senses of the connective  X  X ince X ); the third is to shield the inference from the misleading cues caused by the unbalanced distribution of discourse relations (averagely 42.45% Expansion relations but only 12.89% Temporal in PDTB). The cross-argument inference framework predicts the implicit relation for a given relational argum ent pair with four basic steps (see Table 1). To perform the pai r-to-pair inference from explicit relations to implicit ones, the first step only focuses on mining the comparable argument pairs, which have explicit connectives. On the basis, the second and third steps attempt to select the optimal comparable argument pairs to explore the most possible connective (cue word) for the inferred argument pair. The last step implements the relation mapping with the help of the normally well-defined correspondence between relation senses resources, our frequency based conn ective selection will bring in the connectives of more widely distributed relations, to make noises (pseudo-cues) in recognizing sparse relations. Therefore, the connective selection should be supplemented by an additional treatment of pseudo-cue filtering. 
Table 2: Discourse relation dist ribution in explicit/implicit In this paper, we propose a web-driven comparable argument pair mining method for the unsupervised cross-argument inference. It includes two basic steps: the first is to use information retrieval with a regular expression constrained query to roughly search possible comparable argument pairs (candidates); and the second is to select the most similar candidates with the tested argument pairs in content to generate the final comparable corpus. We perform the information retrie val on the search engine Google. The query is generated by the use of two grammars extracted from the tested argument pair: one grammar ( PreGram ) from the prepositive argument, and another ( PosGram ) from the postpositive. And the query follows the regular expression  X  PreGram  X + X  PosGram  X , within which the double quotes and the plus sign are both necessary parts, as shown in Figure 1. A query expressed as  X  X  X + X  X  X  in Google can ensure that all search results (especially snapshots) contain X and Y simultaneously but in different spans. For each tested argument pair, we use all possible combinations of its  X  PreGram  X  and  X  PosGram  X  to generate queries, and use snapshots of top N ( N =500) search results as resources for extracting candidate comparable argument pairs. We select the snapshots but not full texts as the resources because the former provide closers comparable pairs in short texts (averagely 3 to 4 spans), helping to obtain adjacent comparable pairs efficiently. And obviously the adjacent pairs have more useful relations for our inference than estranged pairs. where, P(s) is the probability of sense s acting as the sense of the ambiguous connective in the comparable corpora, P s is the prior probability of s , s div denotes the average divergence between the ambiguous connective and ri gorous connectives of sense s in the cluster tree, and the logarithmic function smoothes the sharp difference of divergences. The sense inference model tends to recommend senses of closer rigorous connectives when the prior probability P s closes to 0.5. Such probability ( P s =0.5) means corresponding relation senses are the most ambiguous, e.g. the 52.17% probability of sense Contingency of connective  X  since  X  in Table 3. On the contrary, when P s is much high (indicating una mbiguous), e.g. the 95.99% probability of Contingency of  X  moreover  X  in Table 3, the model normally can X  X  influence the pre dominant senses of connectives with the help of logarithmic func tion. Therefore, it can facilitate sense ascertainment of very ambiguous connectives in the meanwhile avoid confusing sens es of approximate rigorous connectives. 
Comparison : while (66.07%), But (97.19%), yet (97.03%), still (98.42%), however (99.59%), although (99.70%), though (100.00%) 
Expansion : in fact (92.68), indeed (95.19%), and (96.83%), or (96.94%), instead (97.32%), unless (98.95%), also (99.94), for example (100.00%), in addition (100.00%), moreover (100.00%), for instance (100.00%), separately (100.00%) 
Contingency : since (52.17%), if (95.99%), because (100.00%), so (100.00%), thus (100.00%), as a result (100.00%) 
Temporal : meanwhile (48.70), as (70.26%), when (80.18%), until (87.04%), then (93.24%), once (95.24%), later (98.90%), after (99.65), before (100.00%) More directly, we define connectives with more than 90% prior probability of occurrence in thei r predominant senses as the rigorous connectives, and those less than the probability as ambiguous ones. The sense disambiguation only proceeds when meeting the defined ambiguous conn ectives. We show all explicit connectives that appear more than 50 times in the PDTB, as well as the prior probability in their predominant senses (see Table 3). It can be found only a few connectives (e.g. while, since, meanwhile, etc) need to be di sambiguated, and thus most connectives can be used as ri gorous connectives to support the sense inference. In our Explicit-to-Implicit relation inference, only explicit connectives are used in sense mapping. So we divide explicit connectives of PDTB into rigorous (82 in total 102 explicit connectives) and ambiguous (the rest 20) to perform disambiguation. As discussed in section 4.1, the unbalanced distribution of discourse relations will make our frequency based connective selection easily bring in the connectives of more widely distributed relations, resulting in noisy connectives (pseudo-cues) in sense mapping for sparsely dist ributed relations. For example, the word  X  and  X  is an Expansion connective the most frequently occurring in most linguistic resour ces. However, the spans, which are connected by the connective  X  and  X , don X  X  always have  X  Sneak Filtering (for FTs) : remove original connectives from the samples, and then parse th e samples (Stanford dependency parser 1 is used). In a dependency tree, if a FT has the bridge connecting Arg1 and Arg2, it will be regarded as the true connective and used to predict the slot [implicit=?], else the original connective will be used insusceptibly. See the example of sneak filtering in Figure 3, where after removing the original connective  X  and  X , the only bridge (dependency arc connect two Args) points to the FT  X  lead to  X , which will be used as the true inference cue (Note: when two Args have no FT or have but triggering a clause but not the bridge between the Args, the sneak filtering is unavailable).  X  Sneak Filtering (for CTs) : remove original connectives from the samples, and then pars e the samples. In a dependency tree, if a CT has a direct dependency arc with the word which bridges two text spans, it will be regarded as the true connective, else the original connective will be used insusceptibly. See the example of sneak filtering in Figure 4, where after removing the original connective  X  and  X , the only bridge points to the word  X  go  X , and the CT  X  later  X  has a direct dependency arc with it, according to which, sneak filtering regards th e CT as the true inference cue. Sneak filtering aims to determine whether a latent connective can bridge two arguments instead of an original connective when the two connectives occur in the same sentence. If yes, the latent connective will be used as the true inference cue in our discourse relation recognition scheme. This is under the hypothesis that if a content word (Functional Trigger) or a connective which depends on the content word (Connective Trigger) has reflected the semantic or logistical relation between text spans, the original connective will not trigger the main discourse relation or even just a modal particle. good statistical method to compare with our inference method. And we also reported the performance of Wang et al (2010) X  X  method [3] , which improves the syntactic-feature based discourse relation classification with the tree kernel. We compared it with our method (both being tested on sections 23-24 ) to verify the feasibility of statistical modeling in discourse relation analysis. The performance is evaluated as: This metric is specially used to evaluate individual relation recognition, where an instance is inferred to be a target relation ( positive ) or not ( negative ). When evaluating the accuracy for all relations ( four-way ), the TrueNegative always equals to 0, to generate a whole accuracy (i.e. percentage of correctly inferred instances). Exp. vs. Other. 43.04% 57.95% 58.09% 55.98% Con. vs. Other. 45.53% 68.15% 69.72% 72.51% Com. vs. Other. 69.25% 81.12% 82.39% 85.16%. Tem. vs. Other. 88.29% 95.30% 96.13% 96.86% We firstly inspect the performance of our systems on recognizing an individual relation. Table 6 lists the accuracy for each of the target relations. The worst performance of system 1 illustrates our web-driven approach with comparable corpora mining initially offers rough resources for comparab le relation detection. System 2 optimizes the initial corpora through effective comparable similarity measurement, achie ving substantial improvements on overall target relations (22.62% at best). System 3 further slightly improves System 2 (1.57% at best ). System 4 achieves the optimal four-way performance and considerable improvements on Contingency and Comparison (2.79% at best), but shows a little worse on Expansion than System 3. Contingency Comparison To support the pseudo-cue filtering, we manually collected 165 Functional Triggers (FTs) which are all content words (verbs, adjectives, adverbs) or th eir corresponding phrases. After expanding the triggers according to the hyponymy of WordNet , we finally obtained 396 FTs, including 98 Contingency, 179 Expansion, 51 Comparison and 68 Temporal. We regard the FTs as the key latent connectives . Besides, we expanded the 101 connectives of PDTB by adding 18 new connectives (e.g.  X  than  X ), which all are conjunctions or prepositions and their combinations. When the connectives co-occur in the same sentences, the connectives, which don X  X  connect text spans, will be automatically regarded as la tent Connective Triggers (viz., CTs, see Section 4.3). There are totally 186 FTs and 15 new connectives occurring in PDTB. Ta ble 9 lists 119 of them which occur more than 5 times. We inspected the distributions of Functional Triggers (FTs) respectively in implicit and explicit relations (see Figure 5), by which to validate the feasibility of using the FTs as the cues of our relation inference. Figure 5 shows the FTs more frequently occur in implicit relations than in explicit relations, especially the most frequent FTs give extr emely obvious differences. It to some extent illustrates that when there aren X  X  explicit connectives, the FTs can instead express the discourse relations. implicit argument pairs (in the s ections 23-24 of PDTB v2) which involve FTs and uses the FTs to directly predict relations (by using the sense mapping in Table 9), and other targets maintain the original output of System3. And the baseline 2 detects the comparable argument pairs (in the mined comparable corpora) which involve FTs and uses the FT s to directly predict relations. For System 3, the Rough filtering removes all comparable pairs which involves both original conn ectives and latent connectives (including CTs and FTs). The Agent filtering uses the latent connectives to replace the origin al connectives. Sneak filtering selectively performs the replacement according to the dependencies of the latent connectives (see Section 4.3). It can be found that the three methods of Sneak Filtering all improve the performance of System 3, especially the Sneak which considers both FTs and CTs. And af ter analyzing the experimental data, we found the sneaks should bring in more improvements if the dependency parser is more precise. In contrast, the Agent filtering and the Rough filtering reduce the performance of System 3, especially to directly replace original connectives by latent connectives in Agent filtering brings in much more performance drawback. So compared with discarding some uncertainty, to unlimitedly re place original connectives is at the risk of bringing in more noises. The baseline 1 and 2 show the worst performances. But in fact the baseline 1 should achieve an approximately 31% accuracy because the percentage of the FTs, which connect the argument pairs, is about 31%. This implies some incorrect relation sense ma pping or ambiguous senses of our FTs. Besides, we find the baseline 1 can be improved if we further expand the set of latent connectiv es, e.g. adding the combination of synonyms (e.g.  X ... beauty ... pretty ... X  -Expansion) and that of antonyms (e.g.  X ... love ... hate ... X  -Comparison). Therefore, to improve pseudo-cue identification and filtering, it is necessary to deal with the following issues:  X  To further expand the set of latent connectives;  X  To disambiguate multiple senses of latent connectives;  X  To improve the precision of dependency parser. We compare our best system with that of Wang et al X  X  Tree kernel method [3] and Zhou et al X  X  language model based unsupervised method [13] . Besides, we use the majority relation class (see Table 4) as the baseline, where all instances are classified as Expansion, yielding an accuracy of 50.80%. Table 11 lists the accuracy for all relations (four-way). Our met hod (System 4) shows the best performance, better than Wang et al X  X  and Zhou et al X  X  We have presented the first st udy on using unsupervised method to recognize implicit discourse rela tion, as well as the statistical method of relation sense disambi guation. Unlike prior work, our method bypasses the complicated li nguistic analysis, and performs Explicit-to-Implicit relation mapping by well using comparable corpora in large-scale web data. Results on PDTB show a significant improvement. Our analysis revealed several difficulties in current implicit relation recognition: 1) rhetorical structure is important feature for implicit relation analysis, but the rh etoric analysis itself is a hard work so far; 2) discourse relation recognition involves subjectivity and ambiguity, see instance (10), so it shouldn X  X  proceed without the support of context analysis, however, to search the most relative context will bring in another relation analysis; 3) modal connectives (e.i. connectives act as modal particle) normally make pseudo-cues for implicit relation inference, e.g.  X  X  love you, and [modal particle] I hate you too X  should be Comparison relation (by  X  love  X  and  X  hate  X ) but not Expansion signaled by the modal connective  X  and  X , therefore, to filter modal connectives and instead use latent relation connectives (e.g. love &amp; hate ) to signal relations is very necessary. In future work, we focus on the automatic method of modal particle identification with the help of sentiment analysis, and on the basis to deeply explore the latent connective mining and application in discourse relation recognition. This research is supported by the National Natural Science Foundation of China (No. 60970056, 60970057, 61003152, 90920004), the Special fund project of the Ministry of Education Doctoral Program (2009321110006, 20103201110021), the Natural Science Foundation of Jiangsu Province (No. BK2011282), the Major Project of College Natural Science Foundation of Jiangsu Province (No. 11KIJ520003) and the Natural Science Foundation of Ji angsu Province, Suzhou City (SYG201030). [1] Prasad, R., Dinesh, N., Lee, A., Miltsakaki, E., Robaldo, L., [2] Pitler, E., Raghupathy, M., Me hta, H., Nenkova, A., Lee, A., [3] Wang, W. T., Su, J., and Ta n, C. L. 2010. Kernel Based [4] Pitler, E., Louis, A., and Ne nkova, A. 2009. Automatic sense 
