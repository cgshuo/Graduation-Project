 Michael Minock * 1. Introduction
Although the advantages of interacting with computers in natural language (e.g., Swedish or English) are easy to recount (e.g., humans already know natural language, natural language is capable of expressing nuanced semantics, speech interfaces are eyes-free/hands-free, etc.), in practice such systems have enjoyed only limited success [3,6]. Typically such systems are characterized by being brittle and unpredictable [21]. Slight re-phrasings of successful commands result in failures, users have difficulty comprehending system coverage, etc. Although NLIs to databases have fallen out of focus, many develop-ments over the last 20 years make another pass at the general problem promising (e.g., maturation of relational technology and theory [1], availability of extensive lexical resources [13], high performance theorem provers [25], advances in machine learning, improvements in speech recognition [10], etc.).

One factor that has blocked the uptake of natural language interfaces (NLIs) to databases has been the economics of con-figuring such systems [3,6]. Typically configuration requires high levels of linguistic expertise and long time commitments.
The typical work environment has neither of these in great supply and thus when presented with the choice of building a common forms-based interface versus an NLI, organizations typically opt for forms. Our work seeks to make NLIs a more attractive option by reducing the time and expertise requirements necessary to build them.

Given the limited linguistic expertise possessed by most technical teams, modern approaches to configuring NLIs to stan-dard relational databases come down to one of three approaches: 1. Let authors only lightly name database elements (e.g. relations, attributes, join paths, etc.) and reduce query interpreta-tion to graph match [4,20] . 2. Offer a GUI based tool where an author builds a semantic grammar 3. Use machine learning to induce a semantic grammar from a corpus of natural language query/correct logical interpreta-tion pairs [24,11,7,26,27] .

Since our ultimate goal is the delivery of a high impact NLI system, it should not be surprising that we primarily adopt an authoring approach. That said, aspects of the first approach are deeply integrated into our work and we have laid the foun-dation for an integration of machine learning techniques to achieve highly robust NLIs  X  X n the limit X  after experiencing large volumes of user queries.

There are three main assumptions that underlie C-P HRASE . The first is that standard, off-the-shelf relational databases are sufficiently expressive to back NLIs. The second is that any approach must include a generation component that can accurately paraphrase database queries back to the user in natural language. and gives them a feeling of control, reducing the anxiety of being misunderstood by the system. The third assumption is that  X  X  X nergy stocks down last year up 10% this year X ). Thus analysis components must be robust, seeking out near misses when in-put is less than ideal and the system must be adaptable, making it easy for authors to patch running systems to catch unantic-ipated phrasings. 3
This article looks at the total problem of configuring and evaluating NLIs to databases from the system author X  X  perspec-tive. Although the primary effort goes into configuring the parser and generator to associate phrases with database elements, there are other tricky issues with respect to problems such as spell checking and, more generally the leveraging of additional linguistic resources for enhanced robustness. 1.1. Organization of this article This article is an extension of an earlier conference paper [17] and holds a similar structure, but presents at greater depth.
Section 2 lays the foundation of concepts necessary to understand our approach. This includes a formalization of naming databases elements, queries of the sort we handle and finally some basic material on synchronous context-free grammars enriched with lambda-expressions. Section 3 presents our formal approach to analyzing noun phrases, what we consider to be the primary challenge of NLIs to databases. The treatment is based on a limited derivative of X-bar theory [9] encoded in synchronous context-free grammars [2] augmented with lambda calculus expressions ( k -SCFG). Section 4 presents our GUI-based authoring tool through which an author populates the system with the formal elements described in Sections 2 and 3 . Section 5, which is new in this article, provides a detailed description of the processing steps that C-P respond to user X  X  typed input. Section 6 describes the overall methods of evaluating NLIs to databases and presents a small study confirming that reasonably skilled subjects can effectively use C-P new evaluation metric termed willingness that complements the classic notions of precision and recall . Section 7 compares our approach with other approaches to building NLIs to databases and Section 8 concludes. 2. Foundations
This work rests on relational databases and assumes that authors (and readers) have a knowledge of primary and foreign keys and Codd X  X  tuple calculus. There are many excellent sources covering these concepts, ranging from detailed theoretical treatments [1] to more conceptual undergraduate textbooks. Perhaps due to substantial growth within the database field, many recent textbooks have skipped Codd X  X  tuple calculus. We consider this to be unfortunate with respect to NLIs to dat-too procedural and DATALOG spreads queries over multiple rules in complex ways. The tuple calculus is a compact, declar-ative formalism in which many user queries can be expressed as single formulas. 2.1. Relations, attributes, values, join paths, and namings
While database design may initially involve UML or ER modeling, most on-going work is at the representational level with the underlying relations, views, attributes, tuples and values of the working database. The process of naming associates words or phrases with such database elements. Assume the set of relations R (e.g.
 CITY.NAME 2 A ) and data values V (e.g. X  Chicago  X  2 V ). An additional class of elements that we consider are equi-join paths
J over the underlying schema. Collectively the set of database elements is E = R [ A [ V [ J . Elements are named by associat-ing various words or phrases with them. In Fig. 1 we see elements being named with various phrases. If we consider the set ation of the naming relation may be accomplished by a mix of automated and manual methods, but a substantial amount of it is simply materialized from the underlying database (e.g.  X  X  X hicago X  is a name for the database value  X 
Although relations, attributes and values may be immediately comprehended, equi-join and, more generally, paths of equi-joins, deserve a bit more explanation. These specify conditions commonly appearing in queries that span more than one rela-tion (e.g. CITY.STATE = STATE.NAME ). Normally such joins are formed via foreign key definitions in the underlying schema. So, for example, if the attribute CITY.STATE is a foreign key to the normally the equi-join CITY.STATE = STATE.NAME 2 J . Note that for purposes of naming, order matters. Thus the equi-join
TY.STATE = STATE.NAME is not the same as the equi-join STATE.NAME ence between phrases such as  X  X  X ities in Michigan X  and  X  X  X tates with cities with more than 2 million people X .
We generalize these notions to consider paths of equi-joins as forming multi-table complex joins. For example if we have a table that expresses a binary bordering relation between two states, then
DER.STATE2 = STATE.NAME is such a join path that expresses  X  X ordering X . Of course if one were to instantiate such a join, then it would be important to alias separate variables to state in the first as well as the second equi-join. Formally an equi-join path of length n is the sequence [ R / (1) . A h (1) = R u (1) and # map to attribute identifiers, and u ( i )= / ( i + 1) for 1 less that are built up from primitive foreign key based equi-joins. The naming process enables system authors to attach phrases to such join paths. 2.2. Queries in an extended tuple calculus
Because of the formal difficulties of working directly with SQL expressions, we represent queries as expressions in Codd X  X  tuple calculus . The tuple calculus is a well known syntactic sugar developed over standard first-order logic where variables tion &gt; 10,000,000)}. Tuple calculus may be directly mapped to SQL queries or expressions in first-order logic.
To handle various ranking and aggregation capabilities of SQL, we extend the tuple calculus with several higher-order capabilities. For example to support ranking and thus superlatives, we use higher-order predicates.

Example 1.  X  X  X ities of over 100,000 people in the largest area mid-western state X  { x j City ( x ) ^ x . population &gt; 100,000 ^ The two place predicate LargestByArea is true for the tuple y that has the greatest area that satisfies the supplied formula, mountain tuples.) Each numeric attribute automatically induces such a higher-order superlative predicates. These expres-sions have straightforward mappings to SQL for database systems that robustly support sub-selects.
 Example 2. Example 1 translated to SQL for PostgreSQL.
 SELECT * FROM City AS x WHERE x.population &gt; 100000 AND
We model aggregation and projection as functions that apply to tuple sets. Thus we denote the total area of all states as sum notation, rather than the normal dot notation of standard tuple calculus. 2.3. Semantic grammars in k -SCFG
Following [26], we model our semantic grammars as synchronous context-free grammars [2] augmented with lambda cal-guage yield of the first tree. The requirement of having variables within the semantic formulas necessitates the use of k expressions and in turn (slightly) complicates the notion of what a yield is for the second tree; yields are calculated bottom up and involve the well known alpha conversion and beta reduction operations of lambda calculus.
 Formally, each k -SCFG rule has the form: where A is a single non-terminal symbol and a is a sequence of terminal and non-terminal symbols where the terminals are words or word sequences in natural language. b consists of a sequence of terminals, non-terminals and formal argument functions in as arguments. 4 In such case we shall use the symbol f minal in a corresponds to which in b . The example in the next section gives a more complete characterization of how such k -
SCFG rules are used to translate a natural language input to a formal semantic expression. 3. Focusing on noun phrases
Through earlier and ongoing work [14,16] , we posit that the main analysis task for natural language interfaces to dat-abases is the analysis of noun phrases, often with modifying adjectival phrases, prepositional phrases, relative clauses, and modifying gerund constructions. In fact more experienced users often type just noun phrases to describe the information they would like retrieved. In addition our experience tells us that we can model noun phrases as coordinated pre-modifiers and post-modifiers around head nouns, essentially basing our linguistic formalism on a limited derivative of X-bar theory [9]. In the notation of k -SCFG some of the general rules that guide this process are: QUERY ? h  X  X  list the  X . NP , answer ({ x j NP ( x )}) i NP ? hj PRE j NP , j PRE j ( NP ) i NP ? hj NP 1 j , j NP 1 ji NP 1 ? h NP 1 j POST j , j POST j ( NP 1) i NP 1 ? hj HEAD j , j HEAD ji
The first rule expresses what we call a sentence pattern , of which there are many variants. This particular rule enables terns and rarely do we find users typing expressions not covered by these rules. Of course as we discover new ones, we, as system designers, simply add them in. The last four rules above are more interesting and enable noun phrases such as those in Fig. 2 .

The authoring process provides the lexical entries that define pre-modifiers, heads and post-modifiers of noun phrases for the given database. Assume the following entries are built over our specific geography database: HEAD ? h  X  X  cities  X , k x . City ( x ) i HEAD ? h  X  X  state  X , k x . State ( x ) i
PRE ? h  X  X  big  X , k f . k x . f ( x ) ^ City ( x ) ^ x . population &gt; 100,000 i
POST ? h  X  X  in the  X  NP ,
PRE ? h  X  X  largest  X ,
PRE ? h  X  X  largest  X ,
PRE ? h  X  X  mid western  X , k f . k x . evaluates to the expression answer ( Q ) where Q is the expression in Example 1 , which in turn is automatically translated to the SQL of Example 2 . 4. Our GUI-based authoring tool
We have developed an AJAX-based authoring tool that gives an integrated GUI through which an author may import a schema from any ODBC accessible database and commence what we term the name-tailor-define cycle of authoring an NLI.
Naming actions provide simple text names for the relations, attributes and join paths of the database schema. In short one populates the naming relation ( N ) of Section 2.1. Fig. 3 shows the schema browser in our tool where the user has the option of exploring and naming the various database elements. The attributes and relations with asterisks have already been named, and the user is in the process of naming the join from formed by coupling logical expressions over the database elements, with associated words and phrases from the naming the underlying language, English in our case. They also, depending on matches, may include alternate phrasings obtained through synonym searches using additional lexical resources (e.g. [13]) or stemming routines. Note we posit that naming time, not query time, is the most appropriate time at which to utilize such domain-independent resources and techniques; inevitable erroneous generalizations are better reflected in structures that the author can view, control and correct.
To manage comprehensibility and navigation, lexical rules are gathered into a collection of entries that couple a single elementary conceptual expression with a set of m -patterns (see Fig. 4 ). In the underlying formalism this expresses m lexical rules, but to the author there is one entry with m patterns. Using a theorem prover these entries are sorted into a subsump-tion hierarchy for ease of navigation. See [14,16] for a detailed description of this process. During Tailoring one works with patterns that are associated with parameterized concepts expressed in tuple calculus. For example in Fig. 4 the currently selected entry corresponds to the concept of a state with an area greater than a certain amount. In this case the additional in the reverse direction to paraphrase queries to clarify to users that the system understood (or misunderstood) their ques-tions. See [15] for an in-depth discussion of this paraphrase generation process.

Once a fair bit of structure has been built up, definitions may be performed in which the author creates conceptually more specific entries. Fig. 5 shows an example of an action in which a new concept that corresponds to states with a population over 1 million is defined. One continues with the name-tailor-define process over the lifetime of the interface. Our authoring configuration on an on-going basis.

One final bit of configuration that should be mentioned is the specification of substitutions . Substitutions are domain-spe-
This includes phrases such as  X  X  X n the country X . Since such a phrase is always redundant in the given context, it is important to be able to blot it out and not expect that the parser will be able to meaningfully parse it. 5. Processing Now that we have described the main representations underlying C-P when a user inputs a string. Fig. 7 shows the flow of processing. This figure shows a cascade of operations that transform the user X  X  input string, ultimately into a system response, report of failure or a request for the user to resolve ambiguity. 5.1. Input string to token sequence The input string is the user X  X  raw text string that they type into C-P kens where whitespace is a separator and punctuation symbols (commas, colons, periods, currency symbols, etc.) are always tokens of length 1. Any matching double quotes delimit text that should be interpreted as a single quoted material token . 5.2. Token sequence to tagged token sequence
Given a token sequence, the first process is to apply a spell check. The token sequence is scanned from left to right. A token with quoted material is accepted, as is the largest prefix that is within what we term the domain dictionary . ple if the current token sequence is ( X  population  X  X  X  Des correction. However in the token sequence ( X  X  Des  X  X  X  the the structure that records the assigned tags so that the user may be presented with a  X  X  X id you mean X? X  phrase where X is the original sentence with the spell check applied, exactly as web search engines typically present spelling corrections.
After the tokens have been spell checked, the resulting token sequence is lexically analyzed, resulting in a set of possible tags being associated with tokens or spans of tokens. For example for the token sequence ( X   X  X 
Arbor  X  X  X  ,  X  X  X  please  X ) the sub-sequence ( X  Ann  X  X  X  Arbor the domain dictionary. To enhance robustness all possible taggings will be considered. Thus if the user happened to type in the query  X  X  X ength of the Mississippi River X , then both ( X  X  nized as possible string values (one referring to the STATE.NAME the possibility of sub-sequences spanning a set of tokens, the lexical analysis phase will have to apply over all O ( n quences of a input sequence of length n . In addition, in seeking out valid string values, stemming is performed to find matches. The current stemming method is simply Porter X  X  method.
 There are a plethora of independent processes that can recognize lexical types such as
DATE _ VALUES,URL _ VALUE,QUOTED _ MATERIAL , etc. In principle each recognizer runs independent of the others, although and authored rules that reflect the tags obtained during lexical analysis. These rules are built in a standard way from tags. 5.3. Tagged token sequence to system response
A standard chart parser that performs semantic composition is applied to the tagged token sequence. Each rule has a plau-sibility measure between 0 and 1 and the overall plausibility of a parse is simply the product of these measures for all the rules employed. A tuple calculus expression is obtained for each parse in the chart whose plausibility meets or exceeds a out any redundancies.

Given a set of such resulting tuple calculus expressions, there are two other parameters that then determine the system X  X  highest scoring parse will be added to the set of ambiguous parses that must be resolved by the user.

In the case that there is only one semantically distinct query that meets the immediate application threshold and for which there are no other competing parses within the selection gap, the system converts the query to an equivalent SQL query, evaluates this query over the database to obtain answers. Finally these answers and a paraphrase of the tuple calculus query is presented as a response to the user. In the case of ambiguity, or confirmation, queries are paraphrased via a para-phraser (not shown in diagram) and the user must select, or confirm, one interpretation. Once the user picks their intended interpretation, the system evaluates the query as above. When no parse is above the failure threshold we have the case of utter failure . In such a case the system will have to come up with a suitable message. Although the current C-P does nothing other than report requesting the user to rephrase their query, future work will investigate the best type of re-sponse in such situations and base responses on at least some island parse of the users input string. 6. Evaluation 6.1. Benchmark studies
Benchmark studies rely on a human built  X  X old standard X  of natural language sentence/logical query pairs, possibly ob-tained through wizard-of-Oz studies. The advantage of such benchmarks is that they set a bar on the expressivity and types of queries that a system must be able to handle in a given domain. For example systems incapable of handling negation or ambiguity (for example [20]), would be flagged as inadequate by such benchmarks.

A widely used benchmark for NLIs to databases is the GEOQUERY Corpus provided by Professor Raymond Mooney X  X  group at the University of Texas, Austin. The corpus is based on a series of questions gathered from undergraduate students over an example US geography database originally shipped with a Borland product. In addition to the raw geography data, the corpus consists of natural language queries and equivalent logical formulas in Prolog for 883 queries. There are several other bench-marks available. For example there are the RESTAURANT and JOBS corpora also developed by Mooney X  X  group as well as the COPESTAKE corpus sets very high semantic demands indeed.
 When one conducts a benchmark evaluation for NLIs to databases one can use the familiar notions of precision and recall .
Still their definition is somewhat complicated by the fact that for each query we have three possibilities: (1) the query is we count a query as correctly answered if it is among the interpretations recognized by the system. Given this, # queries=# correctly answered+# incorrectly answered +# unanswered. The standard definitions of precision and recall follow
We introduce an additional metric of what we call willingness .
The intuition behind willingness is that it represents the tendency of a system to actually offer answers to queries. A system that always parses to some, possibly incorrect logical query, would have complete willingness. A system that very often gave the message,  X  X  X orry your request can not be processed X  would in contrast have very low willingness. In classical information and precision which have this relationship. Also of note, recall = precision willingness. 6.2. A small authoring study
Given that many systems have been evaluated using the GEOQUERY Corpus, we decided to see how well our authoring approach would work. Though this study is small, it does at least establish that our authoring system is usable for normal technical operators and does not require specialized linguistic expertise. The subjects were several under-graduate computer science students that had recently taken an introductory relational database course. The subjects were instructed to read the user X  X  manual of the authoring tool and were trained on its use. Training times varied from practically none, to around an hour over a mocked up example student database in no way related to the GEOQUERY Corpus. Not surprisingly the two sub-jects that received the least training did the poorest.

After being trained on the system, subjects were presented with a random  X  X raining set X  of 100 of the GEOQUERY Corpus queries. Subjects were told that they needed to author the system to cover such queries. Among the remaining queries in the corpus, 33 were selected to be in our test set. For these 33 queries correct logical queries were manually constructed in our corpus of the complexity of the GEOQUERY Corpus corpus, a skilled worker will take approximately 2 min per natural lan-guage query to write and test the equivalent logical query.

As our subjects worked to cover the 100 queries of the training set, their configurations were saved off at intervals for future analysis. This continued for a two hour time span. Afterwards we automatically tested the resulting sequences of con-were marked as correct if their parse to logical form was equivalent to the manually constructed correct result. In the rare case of ambiguity (e.g.  X  X  X argest state X ) the answer was marked correct if one of its results was equivalent to the manually shows the resulting precision and willingness measures through time. 6.3. Fielded systems studies through open-sourcing C-P HRASE
Fielded systems studies put an actual system in a real world environment to see how users actually interact with it. The survey paper [19] presents qualitative results for NLI systems deployed in corporate environments up to the mid-1990s. The web opens up many new possibilities for such studies. The advantage of web-based studies is that one may observe a large volume of real user behavior at relatively low cost. The interface may be run from a web-page and user sessions logged for come dominating solutions for particular application niches.  X  X ominating X  means that a significant number of people prefer to use the NLI to access some pertinent information over all of the other common techniques (e.g., forms-based interfaces, hy-per-text navigation, key-word search, point-and-click query builders, formal query languages, etc.). If such a case is found, tion to NLIs to databases.

The disadvantage to fielded system studies is that it requires product level robustness and a keen sense of what is relevant to some segment of the browsing public. For C-P HRASE , we have worked very hard to stabilize the system into near product level robustness. However the system still has a way to go. Additionally although we have informally conducted fielded sys-tem studies through presenting a geography interface for general querying by the public, what is needed is for teams to at-tach C-P HRASE to their databases to see how the system performs in the real world.

The need to stabilize C-P HRASE along with the need to encourage others to conduct fielded system studies over their own under the BSD type license, allowing unrestricted use and adaptation of the system. C-P lines of LISP code plus another 5k lines of code for an AJAX-based authoring interface to author the system over arbitrary relational databases. The complete system with source code may be downloaded at http://code.google.com/p/c-phrase/ . 7. Related work
Due to the public availability of GEOQUERY Corpus, we can compare our initial results to several machine learning ap-proaches [24,11,7,26,27] , an approach based on light annotation [20] and an authoring approach over Microsoft X  X  English-Query product (described in [20]).

Fig. 9 , adapted from [26], displays the precision and recall measures for all the machine learning based systems [24,11,7,26,27] over the GEOQUERY Corpus. We have added results for our authoring study (for the well trained authors) as well as the results reported in [20]. In comparing our results with machine learning approaches, we focus on results ob-the accuracy of k -WASP, the latest and currently best performing system developed by the group at the University of Texas, appears to be slightly under 50% recall with 60 queries in the test set (precision was slightly under 80%, thus in our termi-nology willingness was approximately 60%). In our experiments subjects average around 80% willingness after 120 minutes ples grow to essentially unbounded size. In these cases, machine learning results are much stronger. The asymptotic preci-sion of k -WASP appears to be approximately 91.95% with a recall of 86.59%, yielding, in our terminology an asymptotic willingness of 94%. Another machine learning experiment over a relaxed-CCG approach obtained similar results [27].
Our comparisons with machine learning approaches highlight a bootstrapping weakness that if overcome would probably make machine learning approaches dominant. The weakness is of course the cost of obtaining the corpus of natural lan-guage/logical expression pairs. Mooney talks briefly about an approach to this problem for simulated environments where descriptions in natural language are paired with formal representations of objects and events retained from the simulation [18]. He suggests simulated RoboCup where a commentator describes game events as an interesting test-bed. Our proposed approach, focussed as it is on just NLIs to databases, envisions authors making equality statements between natural language queries. For example one may assert that  X  X  X hat are the states through which the Longest river runs X  means  X  X  X tates with the language question and use this as a basis to induce extra lexical rules that make the NLI more robust. Although our approach always requires some initial bootstrapping before such machine learning can engage, this article has shown that the labor 100% precision and recall for the queries that are issued to the system. This does not address larger issues such as the lim-itations of the underlying formal language nor users querying for information outside the scope of the database.
PRECISE [20] is a system based on light annotation of the database schema that was tested over the GEOQUERY Corpus corpus. PRECISE reduces semantic analysis to a graph matching problem after the schema elements have been named. Inter-estingly the system (as well as [23]) leverages a domain-independent grammar to extract attachment relationships between tokens in the user X  X  requests. The PRECISE work identifies a class of so called semantically tractable queries . Although the group did not publish the actual configuration times, they presumably corresponded to the naming phase and thus were is an impressive result and over very simple databases with a stream of very simple queries this may be adequate. However queries are not semantically tractable and must be rephrased or abandoned.

The PRECISE group reported a side experiment in which a student took over 15 hours to build a GEOQUERY Corpus NLI using Microsoft X  X  EnglishQuery tool. The resulting system achieved rather poor results for such an expensive effort; approx-imately 80% precision and 55% willingness, yielding a recall of approximately 45%. Our limited experience with the Microsoft commercial systems such as Progress Software X  X  E ASY A SK methods the Wolfram Alpha team uses to cover new domains.

It should be noted that historically, transportable systems (e.g., [8]) arose as a proposed solution to the high configuration costs of NLIs to databases. The idea is to use large scale domain-independent grammars, developed in the linguistics com-logical query expressed in the vocabulary of the relations of the actual database. Building an interface over a new database requires supplying a set of domain-specific lexical entries and the specification of translation knowledge, but does not re-quire new linguistic syntax rules to be defined. A serious problem with the transportable approach however, is that it re-quires a deep understanding of the particular logical form employed to specify working and robust translation knowledge to the actual database tables in use. Considering the knowledge and tastes of the average technical worker, one wonders how well this can be supported. This said, some very interesting work has recently taken up the transportable approach for authoring NLIs over OWL and F-logic knowledge-bases [5]. Like this work, that work assumes very little computational linguistics knowledge on the part of the person who builds the natural language interface.

The system DUDE [12] presents an easy to use authoring interface to build dialogue systems. The back-end database is essentially a universal relation with relatively simple slot filling queries, but the authoring method is elegantly direct and results are sufficient for many practical applications. 8. Conclusions nally the system uses X-bar theory [9] inspired semantic grammars encoded in k -SCFG to map user requests to an extended variant of Codd X  X  tuple calculus which in turn is automatically mapped to SQL. The NLI author builds the semantic grammar through a series of naming, tailoring and defining operations within a web-based GUI. The author is shielded from the formal complexity of the underlying grammar and as an added benefit, the given grammar rules may be used in the reverse direc-tion to achieve paraphrases of logical queries (see [15]).

Using the GEOQUERY Corpus corpus, our results are compared with contemporary machine learning results and ap-proaches based on light annotation. Our initial experimental evidence shows quick bootstrapping of the initial interface can be achieved. Future work will focus on more complete evaluation and experimentation with more comprehensive gram-matical frameworks (e.g. CCG [22]), especially under regimes that enable enhanced robustness [27]. Future work will also explore hybrid approaches using initial authoring to bootstrap NLIs, followed by interactive machine learning that, applied in the limit, will edge such NLIs toward 100% precision and recall.

Sapir X  X  proverb  X  X ll grammars leak X  rings especially true in the case of grammars for NLIs to databases. In any operational system a grammar that has been built up to cover a domain will be leaky in the sense that there will be turns of phrase that user X  X  will employ that the system is unable to parse. When a system is unable to understand a user X  X  request, and must respond with some variant of  X  X  X orry, your request can not be understood X , the user, understandably becomes irritated.
We see no solution other than for a human author to closely monitor the NLI, continually patching the system to minimize the occurrences of such failures.

The central hypothesis of this work is that the robustness and usability of NLIs to databases can be enhanced to such a degree so as to overturn Shneiderman X  X  objection [21] that such systems are not  X  X  X omprehensible, predictable and control-lable X . The ultimate confirmation of this hypothesis would be the identification of a useful, though not necessarily broad class of interfaces where closed domain phrasal search of databases dominate all other alternatives (e.g., forms-based inter-faces, hyper-text navigation, key-word search, point-and-click query builders, formal query languages, etc.). Acknowledgements
I would like to acknowledge the hard work of Peter Olofsson and Alexander N X slund for building the AJAX authoring interface. I would like to also acknowledge Philipp Cimiano and Myra Spiliopoulou for a very productive discussion on pre-cision and recall measures for NLIs to databases. Additionally thanks are due to Bart Massey for convincing me to open to acknowledge Bonnie Webber for reminding me to reach back to standard chart parsing.

References
