 Opinion retrieval is a task of growing interest in social life and academic research, which is to find relevant and opinionate documents according to a user X  X  query. One of the key issues is how to combine a document X  X  opin ionate score (the ranking score of to what extent it is subjective or objective) and topic relevance score. Current solutions to document ranking in opinion retrieval are generally ad-hoc linear combination, which is short of theoretical foundation and careful an alysis. In this paper, we focus on lexicon-based opinion retrieva l. A novel generation model that unifies topic-relevance and opinion generation by a quadratic combination is proposed in this pape r. With this model, the relevance-based ranking serves as the weighting factor of the lexicon-based sentiment ranking function, which is essentially different from the popular heuristic linear combination approaches. The effect of different sentiment dictionaries is also discussed. Experimental results on TREC blog datasets show the significant effectiveness of the proposed uni fied model. Improvements of 28.1% and 40.3% have been obtained in terms of MAP and p@10 respectively. The conclusion is not limited to blog environment. Besides the unified generation mode l, another contribution is that Bayesian approach to combining multiple ranking functions is superior to using a linear combina tion. It is also applicable to other result re-ranking applications in similar scenario. H.3.3 [ Information Search and Retrieval ]: Retrieval Models General Terms : Algorithms, Experimentation, Theory Generation model, topic relevan ce, sentiment analysis, opinion retrieval, opinion generation model In recent years, there is a growing interest in finding out people X  X  opinions from web data. In many cases, obtaining subjective attitudes towards some object, person or event is often a stronger request than getting encyclopedia-like descriptions. General opinion retrieval is an important issue in practical activities such as product survey, political opinion polls, advertisement analysis, etc. Some researchers have observed this underrepresented need of information and made attempts towards efficient detection, extraction and summarization of opinions from web data [7, 8, 15]. However, much of the work focused on presenting a comprehensive and detailed analys is of the sentiments expressed in the text, without studying how well each source document can meet the need of the user. In addition, this branch of work seek solutions to a specific data domai n, such as product/movie review websites [7,15] and weblogs [8], so they make use of many field-dependent features such as different aspects of a product, which are not present for other types of text data. The rising prospects of research and implementation on opinion search are opened up by the explos ive amount of use r-centric data available recently. People have been writing about their lives and thoughts more freely than ever on personal blogs, virtual communities and special interest forums. Driven by this trend and its intriguing research values, TREC started a special track on blog data in 2006 with a main ta sk of retrieving personal opinions towards various topics, and it has been the track that has the most participants in 2007. 1 But how to combine opinion score (the ranking score of to what extent it is subjective or objective) with relevance score is a key problem in research. In previous work, there are many examples that the existing methods of document opinion ranking provide no improvements over mere topic-rele vance ranking. [12] Things come better in 2007. But there X  X  still an interesting observation that the topic-relevance result outperforms most opinion-based approaches [26]. Ad-hoc solutions have been adopted to combine relevance ranking and the opin ion detection result, causing performance to suffer from lack of adequate theoretical support. In this paper, we focus on the problem of searching opinions over documents containing personal opinions towards the given query. We start from the general statistics-based information retrieval, following the idea of taking relevance estimation problem as query generation and document generation. Then considering the opinion retrieval background, we induct the new constrain of sentiment expression into the model. With probabilistic derivation, * Supported by the Chinese Nati onal Key Foundation Research &amp; Development Plan (2004CB318108) , Natural Science Foundation (60621062, 60503064, 60736044) and National 863 High Technology Project (2006AA01Z141. we come to a novel generati on model that unifies the topic-relevance model and the opinion generation model by a quadratic interpolation between the docume nt X  X  relevant score and its opinion score, which is popularly us ed in such tasks. With this proposed model, the relevance-base d ranking criterion now serves as the weighting factor for the lexicon-based sentiment ranking function. Experimental results show the significant effectiveness of the proposed unified model. It is reasonable since the relevance score is a reliable indicator of whether opinions, if any, expressed in the document is indeed towards the wanted object. This notion is a novel characteristic of our model because in previous work, the opinion score is always calcul ated independently to the topic-relevance degree. Furthermore, th is process can be viewed as a result re-ranking. Our work demonstrates that in IR and sentiment analysis, a Bayesian approach to combining multiple ranking functions is superior to using a linear combination. It is also applicable to other result re-r anking applications in similar scenario. This opinionate docu ment ranking problem is of fundamental benefits to all opinion -related research issues, in that it can provide high quality results for further feature extraction and user behavior learning. Although the experiments in this paper are conducted on TREC (Text REtreival Conference) blog 06 and 07 data sets, no characteristic of blog data has been used, such as feature extraction, blog spamming filtering, processing on blog feed and comments, etc. In addition, the lexicons used in this work are all domain-independent ones. Hence the conclusion is not limited to blog environment and the proposed approach is applicable to all opinion retrieval tasks on di fferent kinds of resource. The rest of the paper is organized as follows. We first review previous work in section 2. In s ection 3, we present our generation model for opinion retrieval that unifies topic relevance model and sentiment-based opinion generation. Details for estimating model parameters are also discussed in the section. After introducing experiment settings in section 4, we test our generation model with comparative experiments in section 5, together with some further discussions. Finally, we summarize the paper and suggest avenues for future work in section 6. There has long been interest in either the topics discussed or the opinions expressed in web documents. A popular approach to opinion identification is text clas sification [7, 15, 22]. Typically, a sentence classifier is learned from both opinionate and neutral web pages available using language features such as local phrases [15] and domain-specific adjective-noun patterns [7]. In order to calculate an opinion score, the classification result is then combined with topic-relevance sc ore using binary operator [12]. Another line of research on opinionate documents comes from natural language processing and de als with pure text without constraints on the source of opinionate data. The work in general treats opinion detection as a te xt classification problem and use linguistic features to determine the presence and the polarity of opinions [13, 17, 22]. Nevertheless, they either neglect the problem of retrieving valuable doc uments [13, 17], or adopt an detection [22]. It is the first in Hurst and Nigam X  X  work [4] that topicality and polarity are first fused together to form the notion of opinion retrieval, i.e. to find opinions about a given topic. However in that work, the emphasis is on how to judge the presence of such opinions and no ranking strategy is put forward. The first opinion ranking formula is introduced by Eguchi and Lavrenko [2] as the cross entropy of topics and se ntiments under a generation model. The instantiation of this formul a, however, does not perform very well in the following TREC opini on retrieval experiments. No encouraging result has been obtained. Opinion search systems that pe rform well empirically generally adopt a two-stage approach [12]. T opic-relevance search is carried out first by using relevance ranking (e.g. TF*IDF ranking or language modeling). Then heuristic opinion detection is used to re-rank the documents. One major method to identify opinionate content is by matching the documents with a sentiment word dictionary and calculating term frequency [6, 10, 11, 19]. The matching process is often performed multi-times for different dictionaries and different restri ctions on matching. Dictionaries are constructed according to existing lexical categories [6, 10, 19] or the word distribution over the dataset [10, 11, 19]. Matching constraints often concern with the distance between topic terms and opinion terms, which can be thought of as a sliding window. Some require the two types of words to be in the same sentence [10], others set the maximum word allowed between them [19]. After the opinion score is calculat ed, an effective ranking formula is needed to combine multiple sources of information. Most existing approaches use a linear combination of relevance score and opinion score [6, 10, 19]. A ty pical example is shown below. where  X  and  X  are combination parameters, which are often tuned by hand or learned to optimize a target metric such as binary preference [10]. Other alternatives include demoting the ranking of neutral documents [11]. Domain specific information has always been studied by researchers. Mishne [22, 23] propos ed three simple heuristics with improved opinion retrieval performance by using blog-specific properties. Other works make use of many field-dependent features such as different aspe cts of a product or movie [7, 15], which are not present for other types of text data. TREC blog track is also an important research and experimental platform for opinion retrieval. The major goal is to explore the information seeking behavior in the blogosphere, with an emphasis on spam detection, blog structure analysis, etc. Hence submitted work often goes to great lengths to exploit the non-textual nature of a blog post [10, 12]. This approach makes strong assumptions on the problem domain and is difficult to generalize. The opinion retrieval task aims to find the documents that contain relevant opinions according to a user X  X  query. In existing probabilistic-based IR models, relevance is modeled with a binary random variable to estimate  X  X hat is the probability that this document is relevant to this query X . There are two different ways to factor the relevance probability, i.e. query generation and document generation [5]. In order to rank the document by their relevance , the posterior probability p ( d | q ) is generally estimated, which captures how well the document d  X  X its X  the particular query q . According to Bayes formula, where p ( d ) is the prior probability that a document d is relevant to  X  X enerated X  by d . When assuming a uniform document prior, the ranking function is reduced to the likelihood of generating the expected query terms from the document. However, when explicitly s earching for opinions, users X  information need is now restricted to only an opinionate subset of the relevant documents. This subset is characterized by sentiment expressions s towards topic q . Thus the ranking estimation for opinion retrieval changes to p ( d | q , s ). In this paper, for simplicity, when we discuss the lexicon-based sentiment analysis, the latent variable s is assumed to be a pre-constructed bag-of-word sentimen t thesaurus, and all sentiment words s i are uniformly distributed. Then the prior probability that the document d contains relevant opinions to query q is given by where | s | is the number of words in sentiment thesaurus s . When Referring to Equation 2, it is easy to find that Eq.3 is estimation of topic relevance, a nd the remaining shows that given query q , how probably a document d generates a sentiment word s . Then Equation 3 is rewritten as: This is the generation model for opinion retrieval. In this model, I ( d , q ) is the document generation probability to estimate topic sentiment analysis. Essentially it presents a quadra tic relationship between document sentiment and topic relevance, which is naturally induced from the opinion generation process and is proven more effective in our experiments than the popular linear interpolation used in previous work, e.g. where  X  is the linear combination weight. This result is reasonable since th e relevance score is a reliable indicator of whether opinions, if an y, expressed in the document is indeed towards the wanted object. This notion is a novel characteristic of our framework in that previous work calculated p ( d | q , s ) independent of the topic-relevance degree. In the following two sections, we will discuss the two sub-models in the generation opinion retrieval model respectively. document generation. A classic probabilistic model, the Binary Independent Retrieval (BIR) model [5 ], is one of the most famous ones in this branch. The heuris tic ranking function BM25 and its variants have been successfully a pplied in many IR experiments, including TREC (Text Retrieval Conference) evaluation. Hence in this paper, we adopt this BIR-based document generation model, by which the topic relevance score ScoreI given by the ranking function pres ented in [25] can be shown as: where c ( w , d ) is the count of word w in the document d , c ( w , q ) is the count of word w in the query q , N is the total number of documents in the collection, df ( w ) is the number of documen ts that contain word w , | d| is the length of document d , avdl is the average document length, k constants. that given query q , how probably a document d generates a sentiment expression s . This model is on the branch of query generation , in which language model has been shown quite effective in information retrieval during recently years. The sentiment expressions s is a latent variable in our framework which is not inputted in the query but expected to appear in search results. In this work, we assume s to be a bag-of-word sentiment thesaurus, and sentiment words s is uniformly distributed. Hence Different from query generation-based language model in IR, where the number of query terms (| q |) is usually small (less than 100, and in most cases be 1 or 2) , in our opinion generation model, the number of sentiment words (i.e. | s |) is large (generally several thousand), and the sparseness problem is prominent. Hence smoothing has turned out to play an important role for parameter estimation in this proposed model. where p S ( s i | d , q ) is the smoothed probability of a word s probability mass assigned to unseen words, p ( s i collection language model given query q . This unigram model can be est imated using any existing method. As iluustrated in Zhai &amp; Lafferty X  X  study [20], Jelinek-Mercer smoothing is much more effective than the other two when the  X  X ueries X  are long and more verbose. In this proposed opinion generation model, the  X  X ueries X  ar e sentiment words. Therefore, under this similar scenario, we use the MLE estimation, smoothed by Jelinek-Mercer method. According to Jelinek-Mercer smoothing, where  X  is the smoothing parameter, and p ml smoothing to Equation 7 and Equation 8, we get the estimation: We use the co-occurrence of sentiment word s and query word q inside document d within a window W as the ranking measure of p ( s i | d , q ) . Hence the sentiment score of a document d given by the opinion generation model is: Where co ( s i , q | W ) is the frequency of sentiment word s term frequency in the document. Taking the topic-relevance ra nk (Equation 6) and opinion-generation rank (Equation 11), we get the overall ranking function for the unified generation model: Notice that this ranking function is not the precise quantitative estimation of p ( d | q , s ) , because proportion factor 1/| S | in opinion-generation rank is ignored. But this factor has no affect to document ranking and hence this approximation is order-preserving. In this ranking function, we directly use the co-occurrence frequency as the factor to estima te the generation probability p ( s i | d , q ). But as mentioned in secti on 3.3, generally, the number sentiment thesaurus is really larg e, e.g. over several thousand or unbalance, the logarithm norma lization is taken on opinion ranking. By this way, the ranking function turns out to be: The experimental analysis on this logarithm relationship will be made in section 5.3, which shows the effectiveness of this normalization. We test our opinion retrieval model on the TREC Blog06 and Blog07 corpus [12, 26], which is the most authoritative opinion retrieval dataset available up to date. The corpus is collected from 100,649 blogs during a period of two and a half months. We focus on retrieving permalinks from this dataset since human evaluation result is only available for these documents. There are 50 topics (Topic 851~900) from the TREC 2006 blog opinion retrieval task, and 50 topics (Topic 901~950) from TREC blog 2007. Query terms are extracted from the title field using porter stemming and st andard stop words removal. Generally, queries from blog 06 are used for parameter comparison study, including selec tion of sentiment thesaurus, window size, and the effectiven ess of different models. And queries of blog 07 are used as the testing set, where all the parameters have been tuned in bl og 06 data and no modification is made. To make the experiments applicable to real word applications and comparable to TREC evaluations, only short queries are used. The evaluation metrics used are general IR measures, i.e. mean average precision (MAP), R-Precision (R-prec), and precision at top 10 results (p@10). Totally three approaches have been comparative studied in our experiments. (1) General linear combination (Shown as Linear Comb .) the same way as that in the Equation 11. (2) Our proposed generation model with Jelinek-Mercer smoothing (Shown as Generation Model ). See Equation 11. (3) Our proposed generation model with Jelinek-Mercer smoothing and logarithm normalization (Shown as Generation, log ). See Equation 12. For lexicon-based opinion detec tion methods, the selection of opinion thesaurus plays an impor tant role. There are several online public dictionaries from the area of linguistics, such as WordNet [18] and General Inquirer [14]. We follow the general way [6] to select a small seed sentiment words list of WordNet, and then incrementally enlarge the list with synonyms and antonyms. Another option is to rely on a se lf-constructed dictionary. Wilson et al [17] manually selected 8821 words as their sentiment lexicon and it has been used in some othe r works. Esuli and Sebastiani [3] scored each word in WordNet re garding its positive, negative and neutral indications to obtain a Se ntiWordNet lexicon. Words with positive or negative score above a threshold in SentiWordNet are used by some participants of the TREC opinion retrieval task. Furthermore, we seek help from other languages. HowNet [1] is a knowledge database of the Chinese language, and some of the words in the dictionary have properties of positive or negative. We use the English translation of those sentiment words provided by HowNet. For comparison, sentimental words from HowNet, WordNet, General Inquirer and SentiWordN et are used as lexicons respectively. Table 1 shows the detail information on the lists. The retrieval performance under diffe rent sentiment thesauruses is presented in Figure 1. The cr oss-language HowNet dictionary performs better than all other candidates and is quite insensitive to the smoothing parameter. SentiW ordNet and the Intersection thesauri perform next and close to each other. General Inquirer does not perform well and has the worst result. There might be two reasons that l ead to the better performance of using the words from HowNet than using that from WordNet. First, the list generated from WordNet might be lack of diversity since the words come from a limited initial seeds and only synonyms and antonyms are taken into consideration. Second, the English translations of the Chin ese sentiment words are annotated by non-native speakers; hence most of them are common and popular terms, which are generally used in the Web environment. Since the performance of SentiWordNet and HowNet are with no big difference when  X  is higher, and SentiWordNet is open in the Internet, we choose SentiWordNet as the sentiment thesaurus in the following experiments to make the experiments much easier to repeat by other researchers. 
Figure 1 MAP- X  curves with different thesaurus. (Blog 06) It is intuitive that opinion modifiers are less likely to be related to during the opinion term matching process, a proximity window is often used to restrict the valid distance between the sentiment words and topic words. However, no one is sure about how close the two types of words should be to each other and this threshold is often set by hand with various indications. In previous work, window sizes that represent the le ngth of direct modification (e.g. 3 [11]), a sentence [10, 22] (e.g. 10~20), a paragraph (e.g. 30~50 [11]), or the whole document [6] have been used. We test the retrieval performance under these settings respectively to illustrate how this factor could influence the opinion retrieval ability of our model. The result is given in Figure 2. Figure 2. MAP v.s. window size with different  X  . (Blog06) It is clear that the larger the window is, the better the performance is. And this tendency is invariant to different levels of smoothing. The result is reasonable since the distance between a query term and a sentiment word is generally used to demonstrate the opinion relevance to the topic, which has already been taken into consideration in this unified model by the quadratic combination of topic relevance. And in the Web documents, the opinion words may not always been located near the topic words. Therefore, we set the full document as the default window size in the following experiments. Three opinion ranking formulas are tested in our experiment. Their performance is compared in Figure 3. We can see that the generation model is more effective than linear combination especially when mild smoothing is performed. As the value of  X  goes up, desired documents with only a few opinion terms are deprived of the discrimi native ability contained in their opinion expressions, as this part of the probability is discounted to the whole document collection. Generation log model overcomes this problem and gives the best retrieval performance under all values of  X  . This demonstrates the usefulness of our log-smoothing approach in the setting of opinion search. In addition, all three ranking schemes perform e quivalent to or better than the best run at TREC 2006 owing to the careful selection of sentiment thesaurus and window size as discussed above. To further demonstrate the effectiveness of our opinion retrieval model, a comparison of opinion MAP with previous work is given in Table 2. Performance improve ment after opinion re-ranking is shown in Figure 4 in pr ecision-recall curves. Figure 3. MAP-curve for different opinion ranking formulas. 
Figure 4. Precision-recall curves before and after opinion re-Data Blog 06 Blog 07 *: on Blog 07 data, use the same parameters as those on Blog 06 data.  X  =0.6, window=full, thesaurus: SentiWordNet. All our approaches use title X  X nly run. In Figure 5, per topic gain in opinion MAP and p@10 are visualized on blog 07 data set. No tice that no characteristic of blog data has been used in this work, such as feature extraction, blog spamming filtering, processing on blog feed and comments, etc. In terms of MAP, 16 of the 50 topics receive improvement of more than 50%, while only 5 topics result in minor performance loss. Few topics that benefit the most from opinion re-ranking, such as topic 912 (144%) and topic 928 (135%), are those where only a few documents with releva nt opinions are retrieved and ranked lowly in the first stage. Only 4 topics X  performances decrease a little (less than 40%). In terms of p@10, even more significant results ar e given. Three topics get more than 200% improvement, such as topic 946 (+ 900%), and only 6 topics get a little drop on performance. Table 3 gives detailed descriptions of two topics in blog06 and blog07. We can see our re-ranking procedure successfully re-scores almost all the target doc uments into the top 100 results. This proves our formula to be hi ghly accurate in discriminating a few subjective texts from a large amount of factual descriptions. In this work we deal with the problem of opinion search towards general topics. Contrary to previ ous approaches th at view facts retrieval and opinion de tection as two distinct parts to be linearly combined, we proposed a formal probabilistic generation model to unify the topic relevance score and opinion score. A couple of opinion re-ranking formulas are derived using the language modeling approach with smoothi ng, together with logarithm normalization paradigm. Furtherm ore, the effectiveness of different sentiment lexicons and variant distances between sentiment words and query terms are compared and discussed empirically. Experiment shows that bigger windows are better than smaller windows. Accordi ng to the experiments, the proposed model yields much better results on TREC Blog06 and Blog07 dataset. The novelty of our work lies in a probabilistic generation model for opinion retrieval, which is ge neral in motivation and flexible in practice. This work derives a unified model from the quadratic relation between opinion analysis and topic releva nce, which is essentially different from general linear combination. Furthermore, in this work, we do not make any assumption on the nature of blog-structured text. Therefore this approach is expected to be generalized to all kinds of res ources for opinion retrieval task. Future directions on opinion re trieval may go beyond merely document re-ranking. An opinion-or iented index, as well as deeper analysis on the structural information of opinion resources such as blogs and forums could be helpful in understanding the nature of opinion expressing behavi or on web. Another interesting topic is to automatically construct a collection-based sentiment lexicon, which has been a hot re search topic [26], and to induct this lexicon into our generation model. [1] Dong, Z. HowNet. http://www.HowNet.org [2] Eguchi, K. and Lavrenko, V. Sentiment Retrieval using [3] Esuli, A. and Sebastiani, F. Determining the semantic [4] Hurst, M. and Nigam, K. Retrieving Topical Sentiments from [5] Lafferty, J. and Zhai, C. Proba bilistic relevanc e models based [6] Liao, X., Cao, D., Tan, S., Liu, Y., Ding, G., and Cheng X. [7] Liu, B., Hu, M., and Cheng, J. Opinion observer: analyzing [8] Mei, Q., Ling, X., Wondra, M., Su, H., and Zhai, C. Topic [9] Metzler, D., Strohman T., Turtle H., and Croft, W.B. Indri at [10] Mishne, G. Multiple Ranking Strategies for Opinion [11] Oard, D., Elsayed, T., Wang, J., and Wu, Y. TREC-2006 at [12] Ounis, I., de Rijke, M., Macdonald, C., Mishne, G., and [13] Pang, B., et al, T humbs up? Sentiment Classification Using [14] Stone, P., Dunphy, D., Smith, M., and Ogilvie, D. The [15] Tong, R. 2001. An Operationa l System for Detecting and [16] Turtle, H. and Croft, W.B. Evaluation of an Inference [17] Wilson, T., Wiebe, J., and Hoffmann, P. Recognizing [18] WordNet. http://wordnet.princeton.edu/ [19] Yang, K., Yu, N., Valerio, A. , Zhang, H. WIDIT in TREC-[20] Zhai, C. and Lafferty, J. A study of smoothing methods for [21] Zhai, C. A Brief Review of Information Retrieval Models, [22] Zhang, W. and Yu, C. UIC at TREC 2006 Blog Track. [23] Mishne, G. and Glance, N. Leave a Reply: An analysis of [24] Mishne, G. Using blog properties to improve retrieval, In [25] Singhal, A. Modern information retrieval: A brief overview. [26] Macdonald, C. and Ounis, I. Overview of the TREC-2007 
