 1. Introduction Information retrieval can be considered as a problem of inference (van Rijsbergen 1986). It is a process concerned with estimating, given available evidence about things, such as information need and documents, the likelihood (or probability) of relevance of a document need. This can be generalized to include any source of evidence that might be used for IR such as the evidence of different retrieval techniques, different document representation techniques, or different IR systems. 450 HSU AND TAKSA
Information retrieval can be viewed as a process which takes a query (Q) as an input and produces the output which is a list of documents or results (R) (see figure 1(a)). The IR process entails a query formulation (F) or representation and a scheme or system (S) which processes the query formulation in order to obtain results (R) (see figure 1(b)).
W ith the advent of computer science and information technology (in particular, database technology and information retrieval technology), it has become feasible and possible to improve information retrieval system performance by considering multiple formulations and multiple schemes. Figure 2 depicts three such possibilities.

MFSS X  X ultiple formulations single scheme (figure 2(a)), SFMS X  X ingle formulation multiple schemes (figure 2(b)), and MFMS X  X ultiple formulations multiple schemes (figure 2(c)). However, very few of the developments have actually investigated the ef-fect of multiple formulations and/or multiple retrieval schemes on performance. effect of combining multiple representations of information problems on the performance of the INQUERY probabilistic inference network retrieval engine. Although their results improvement in retrieval performance, the INQUERY results (INQC) were substantially combining INQC and the combined Boolean queries as two different sources of evidence. The overall retrieval performance became worse when more weight was given to the Boolean query evidence. However, the performance was improved when fractional weights were given to the combined Boolean queries.

Belkin et al. (1994) and Fox and Shaw (1994) investigated the effect of combination of multiple representations of TREC topics on retrieval performance. Both projects found forming single query. However, they indicated that choosing the best query often results in significant performance differences from combined queries. They also pointed out that COMPARING RANK AND SCORE COMBINATION METHODS 451 in any single run there are always instances of combined queries performing better than the best, and on average combination does better. Belkin et al. (1995) reported on two studies conducted at Rutgers University (Belkin et al. 1994) and at Virginia Tech (Fox and Shaw 1994) that investigated the effect on retrieval performance of combination of mul-tiple representations of TREC-2 topics. When dealing with query combination, the rules used (CombSUM, CombANZ, and CombMNZ) were based on similarity scores between a topic and a document. On the other hand, when dealing with multiple evidences from different schemes (or systems), combinations (MAX, MIN and MED) were based on rank information. Encouraged by the interesting and generally positive results of the two sep-arate studies involving combination of evidences (using similarity scores) or data fusion (using rank information), Belkin et al. (1995) performed two other experiments and had the following observations: Remark 1.1 . (a) When different systems are commensurable, combination using similar-ity scores is better than combination using only ranks; (b) when multiple systems have incompatible scores, a combination method based on ranked outputs rather than the scores directly is the proper method for combination; and (c) although results from the experi-ments for combination of results from different databases are encouraging, it is not clear that such combination is possible among systems that have different methods for computing similarity scores.
 search for proper names. Their experiments (on measures dealing with phonetic similarity, typing errors, and plain string similarity) showed that all three approaches perform sig-nificantly better than a system based on exact-match searches only. They suggested that further improvements are possible by combining different methods. Although they realized that combining two or three different similarity measures seems to be very promising, they indicated that further work for maintaining and searching one or two more methods has to be considered.

Lee (1997) presented the rationale for evidence combination that different runs return similar sets of relevant documents but retrieve different sets of non-relevant documents. tiveness. In particular, he showed experimentally that in some circumstances, using ranks similarity on retrieval effectiveness and found that: Remark 1.2 . Data fusion using rank works better than using similarity scores if the runs in the combination have  X  X ifferent X  rank-similarity curves.

In their study of the problem of predicting, in advance, whether combination (or fusion) of two or more retrieval schemes will be worth doing, Ng and Kantor (1998) identified: performance of the two schemes. 452 HSU AND TAKSA
In a subsequent study, Ng and Kantor (2000) investigated the prediction power of these two variables using symmetrical data fusion and receiver operating characteristic (ROC) as a variable to measure the similarity of performance of the two IR schemes. Although and symmetric data fusion will be effective.

The LC (linear combination) model for fusion of IR systems combines the results lists of multiple IR systems by scoring each document with a weighted sum of the scores from each of the component systems. Vogt and Cottrell (1999) studied the problem of predicting the performance of a combined system. Their analysis supports the following: Remark 1.4 .A nL C model should only be used when the systems involved have high performance, a large overlap of relevant documents, and a small overlap of non-relevant documents.

Previous empirical and experimental results (including those reviewed in this section) still remain unanswered. All these indicate that the problem involves tremendously high complexity and dimensionality. They have become both quantitatively and qualitatively dif-different techniques (or algorithms) to measure the likelihood or probability of relevance of a document to a given query. Moreover, the choices of techniques (or algorithms) rely cated by having a variety of multiple formulations of the information need and a large and multi-faceted collection of documents (see figure 2(a) X (c)). Multiple representations (or hand, the document space consists of not only large and different structured database sys-and different countries.

In this paper, we continue the study of the problem of data fusion (DF) in information using similarity measures to search for proper (relevant) documents in the databases or on the World Wide Web when presented with an information need (a query). On the other hand, even though we include the general MFMS setting (see figure 2(c)), we only consider the case of combining results of search in the same database or search space. In general, we have found: same query by different experts. But they can also be obtained from different (disjoint or COMPARING RANK AND SCORE COMBINATION METHODS 453 non-disjoint) subsets of the same query; and (b) the search can be based on different for-(c)) on the same database (or on the World Wide Web).
 mation gathered by multiple agents (sources, schemes, sensors or systems) into a single representation (or result). Data fusion has been used in pattern recognition where results and defense applications (Hsu et al. 2003, Lyons et al. 2003, Varshney 1997).
The concept of data fusion has been used, as mentioned above, in information retrieval to study the combination of multiple evidences resulting from different query formulations or from different schemes (Belkin et al. 1993, 1994, 1995, Fox and Shaw 1994, Kantor 1998, Lee 1997, Ng and Kantor 1998, 2000, Pfeifer et al. 1996). Many empirical studies have been performed and various results have been obtained. While some of the major issues related to the questions such as why and how multiple evidences should be combined remain unanswered, researchers have come to realize the advantage and benefit of combining multiple evidences.

Our approach aims to study the problem of when DF in IR is worth doing and how fusion should be done. We take the modeling approach, which will encompass several fundamental on Cayley graphs and digraphs (called CG model) with the following characteristics: r the set of n documents to the set of real numbers.

Our model uses a ranked list which consists of a rank function (as a permutation in the of the document). We perform analytical study and simulation of the DF of different kinds using rank vs. score combination and explore further the question of when and why one kind of combination is better than the other. We believe that our model and approach will provide better understanding of the phenomena surrounding the issue of effectiveness of DF in information retrieval.

In Section 2, we describe our data fusion framework which includes a data fusion model lytical result which strongly supports the advantage of using the framework. Experimental results are included in Section 4. More detailed discussions and remarks are summarized in Section 5 which concludes the paper. 454 HSU AND TAKSA 2. Data fusion model and architecture We first review and define some of the notations and terminologies, which will be used equivalent, forms: and where Fo re xample, when  X  is a permutation on the set of numbers { 1, 2, 3, 4, 5, 6 } ,wehave and Often a cycle of length one is ignored without any ambiguity. We also adopt the convention that each permutation is written interchangeably (without confusion) as an ordered list of a graph.
 Definition 2.1 . Let be a finite set of n elements and  X  be a binary operation in . is said to be a group if it satisfies the following properties: (a) for every a , b  X  , a  X  b  X  , (b) for every a , b , c  X  , ( a  X  b )  X  c = a  X  ( b  X  c ), COMPARING RANK AND SCORE COMBINATION METHODS 455 this case, is said to be an Abelian group .
 edge set of G and A as the arc set of D .

We note that the symmetric group S n of order n is a special case of a kind of algebraic readers are referred to the book by Biggs and White (1979).

The symmetric group S n , when imposed a metric, would become a metric space. For ex-define the concepts of a Cayley graph and a Cayley digraph as follows: Definition 2.3 . Let (or )b ea group and S (or S )a generating set which does not include identity element of (or ). Cayley digraph G ( , S )i s the directed graph with c , d  X  , cd  X  1 , dc  X  1  X  S } .

The study of Cayley graphs and digraphs, sometimes under the name Cayley color-group or Cayley diagrams, can be dated to the 1940 X  X . Recent survey and treatments can be found in Biggs and White (1979) and Grammatikakis et al. (2001), Chap. 6.4, and Heydemann (1997). In our applications here, we are more concerned with the case of Cayley graph where = S n , the symmetric group, and S is a generating set with transpositions. Two kinds of S we are most interested in are T 1 and T 2 : and 456 HSU AND TAKSA d cay can be found in Marden (1995). While d k ( needed to bring the  X  order [  X  1 , X  2 ,...., X  n ]tothe  X  order [  X  1 , X  2 ,...., X  n ].
When d k (  X ,  X  ) = 1 , X  and  X  are related to (or incident with) each other by an adjacent ( S
We note that although Cayley distance d cay (  X ,  X  ) and Cayley graph (and Cayley digraph) share the same name  X  X ayley X , they are different in the sense that the former defines a permutations.

In our approach of studying DF in information retrieval, a ranked list consists of a rank numerical subindices to denote the documents, it is easy to confuse document ordering and from [ d 10 ]to [0, 1] = the set of real numbers between and including 0 and 1. and We are now ready to define the concept of a rank/score function.
 Definition 2.4 . The rank/score function f A for the system A is a function from [ n ]to [0 [ n ].
 COMPARING RANK AND SCORE COMBINATION METHODS 457
It follows that f A has the following values when n = 10 in the example above. parameters to measure the performance of the system (or scheme) of the ranked list A . A measures of performance for a system A as follows:
Fo rt wo ranked lists A and B ,w e present two different ways of combining A and B . One uses rank combination and the other uses score combination.
 r A and B using ranks has the rank function r C ( x ) = d with f g ( x ) = s g ( r C ( x )).
We illustrate the above two definitions with the example in figure 3 for a special case n = 10. Note that each of the two rank functions g and s B ( d ).
 and (b). The two examples in figure 4(b) have n = 500 and s = 100. 458 HSU AND TAKSA
Our approach to the study of effectiveness of DF in IR consists of a model of simulation and analysis and an architecture summarized in figure 5. We use the symmetric group S n as our sample space (or sometimes called rank space) with respect to n documents. Since the total number of possible rank data written as permutations is n! which is computationally s f ashion. Ranked lists C and D are rank combinations and score combinations of A and B respectively as defined in Definitions 2.6 and 2.7. By employing different variations of A COMPARING RANK AND SCORE COMBINATION METHODS 459 and B, we hope to be able to extend and generalize our results. In Section 4, we will have e performance of the combination by ranks is always better than that of the combination by score, i.e. P @ q ( C )  X  P @ q ( D ). 3. Analysis of combination methods In this section, we take the general view as stated in Remark 1.6. As such, each evidence and documents with their similarity scores for n distinct documents. Each rank function 460 HSU AND TAKSA r framework described in Section 2 and previous results discussed in Section 1, we are now in Definition 2.5 (see also figure 5). We summarize Remarks 1.1 X 1.6 and ask the following questions: and B , P ( C )  X  P ( D )? 4.1 : r A = e A the identity permutation and r B = random, and Case4.2 : r A = random and r and average precision ( P avg ). Among the many results and phenomena observed from these simulations, we see the following pattern: COMPARING RANK AND SCORE COMBINATION METHODS 461 case when r A = e A and r B = random. In the cases that r A = random and r B = random, %( P avg ( C ) &gt; P avg ( D )) &gt; %( P avg ( C ) &lt; P avg ( D )).
 special cases n = 500 and s = 100): r (1 / 2)[ y  X  + f See Appendix A for proof.

Proof is similar to that of Theorem 1 . 4. Simulation we assume the number of documents to be n = 500 and the highest score given to any rank is s = 100. Hence the total number of possible permutations as rank function is 500!. The rank functions rB X  X  are obtained by a random generation process in Case 4.1. In each simulation, we generate ten thousand (10 k) cases of r B .I n our study, we fix f A to be discrete function defined from [1, 500] to [0, 100] which is monotonically non-increasing, we start with a special case of f B which is a combination of two straight lines with one figure 4(a) has no such points. Since the problem at issue is combining two ranked lists A where r A and r B are both randomly generated in Case 4.2. These two cases are described in more details as follows: 462 HSU AND TAKSA = P avg respectively. In figure 6(a), the tuples at point ( x P @50 ( D ) and P @50 ( C ) P P figure 7(a) X (c).

We note that figures 6 and 7 exhibit certain features which are quite noticeable. One and i = j ), the combination by rank performs better than combination by score in either P @ q or P avg cases as long as q We are also interested in the performance of C and D as compared to those of A and B . The data fusion model and architecture we established in Section 2 in this paper is In this paper, we have shown analytically and experimentally that the graphical relation and P(D). The data generated and exhibited in figures 8 and 9 demonstrated that the two of combinations.
 P = P COMPARING RANK AND SCORE COMBINATION METHODS 463 to 1.0 in step of 0.1 and y = (50, 10) to (450, 90) in steps of (50, 10) and x -coordinate. 5. Discussion and future work In this paper, we have established a framework (see figure 5) for analysis and simulation in the study of data fusion in the information retrieval domain by defining rank function and score function and using the concept of a rank/score function. Every evidence (from ments. Using the concept of a Cayley graph, we consider a rank function r A (of n doc-permutation e .

Recall from Remark 1.6, Definition 2.4 and figure 5, rank function r A and score function s are defined respectively from N to D and from D to R + . Hence the rank/score function function would be f  X  A = s A  X  r  X  X  X  1 (i.e.: f  X  A  X  r  X  A = s A ).
 why and how data fusion (or evidence combination) should be done. We have started with some specific cases when the rank/score function f A = straight line and f B = semi-linear can be any discrete function defined from [1, 500] to [0, 100] which is monotonically non-P (10 k) permutations for each random case, we have found several interesting phenomena. All these analytical and simulation results, summarized in Sections 5.1 and 5.2, strongly in the current study. 464 HSU AND TAKSA 5.1. Combination using rank vs. score from a ranking procedure A which gives the rank function r A and score function s A .Onthe f enables us to characterize different ranking procedures (algorithms or systems), and then to better quantify the differences between them (see Remarks 1.1 and 1.2). Our results in confirmed the observations made by previous researchers and summarized in Remark 1.1 (see Belkin 1994, 1995) and Remark 1.2 (see Lee 1997). Specifically, we have demonstrated performs better than combination using scores under certain conditions. In particular, we have shown analytically in Theorems 1 and 2 that when the difference between r A and r B performance of rank combination is at least as good as that of score combination. 5.2. Effectiveness of combination V arious techniques and experiments have been performed to study the effectiveness of com-Belkin 1993, 1994, 1995, Hsu et al. 2003, Lee 1997, Lyons et al. 2003, Marden, 1995, Ng and Kantor 1998, 2000, Vogt and Cottrell 1999). These include the progressive combination of query formulations and the linear combination (LC) model for fusion of IR system by scoring each document with a weighted sum of the scores from each of the component sys-tems (Vogt and Cottrel 1999) and the study by Ng and Kantor (1998, 2000) which identified two predictive variables: the Kendall distance and the performance ratio (see Remarks 1.3 performance of the two IR schemes A and B . Our simulation results (see figures 9(a) X (c)) are in conformity with those by Ng and Kantor on the performance ratio P l / P h .Wehave ( x  X  , y  X  ) = (50 t, 10 t) and 1  X  t  X  9 (see figures 9(a) X (d)).
 D are combination of A and B using rank and score respectively. As to the Kendall distance d ( r A , r B ), we have not attempted to find such pattern in our simulation. However, the for the effectiveness of combination.
 COMPARING RANK AND SCORE COMBINATION METHODS 465 5.3. Future work We have discussed, in Section 4.1, that when r A = e A and r B = random we have P ( C ) &gt;
P ( D ) (either @50 or on average) (see figures 6(a) X (c)) for most of the cases at point ( y ( x  X  , y  X  )o f intersects where ( y  X  = X  1 &gt;
P avg ( C ) (see figure 7(c)). However, when performance@50 is used, no apparent pattern can be drawn (see figure 7(a) and (b)).

The current study suggests several problems worthy of further study and several issues that require further investigations. We summarize as follows: 466 HSU AND TAKSA (e) We note that framework proposed and results obtained in this paper for information A ppendix A Proof of Theorem 1 We divide the problem into three cases according to the relative positions of i and j with greater than q ) does not make any difference to the performance of C or D . Therefore, we (c) into two subcases: of s B ( x )i sf aster than that of s A ( x ).
 or less than s A ( i )  X  s B ( i ) depending on how big j is.
 COMPARING RANK AND SCORE COMBINATION METHODS 467 array f AB into ascending order to become s g ,wehave and h AB ( j )i s bigger than the other? Definition 2.7. After sorting the array h AB into descending order to become s g ,wehave s r ( x ): d 1 , d 2 , d 3 ,... ..................., d i , d j ,........................., d n r s s s r for the third possibility of Subcase (c) (ii): [ n ]: 1 , 2 , 3 ,... i ,.... i ,..., i + j 2 i + j 2 ,... j ,... j ,......... n r ( x ): ......................., d i ,..., d j ,..................... h
AB ( x ): s ( d ): ............, h AB ( i ) ,............, h AB ( j ) ,.............. r ( x ): ......, r D ( i ) ,..., d i ,.............., d j ,..., r D ( j ) ,...... r completes the proof of the theorem. 468 HSU AND TAKSA
A ppendix B COMPARING RANK AND SCORE COMBINATION METHODS 469 470 HSU AND TAKSA COMPARING RANK AND SCORE COMBINATION METHODS 471 472 HSU AND TAKSA COMPARING RANK AND SCORE COMBINATION METHODS 473 474 HSU AND TAKSA COMPARING RANK AND SCORE COMBINATION METHODS 475 476 HSU AND TAKSA COMPARING RANK AND SCORE COMBINATION METHODS 477 478 HSU AND TAKSA COMPARING RANK AND SCORE COMBINATION METHODS 479 References 480 HSU AND TAKSA
