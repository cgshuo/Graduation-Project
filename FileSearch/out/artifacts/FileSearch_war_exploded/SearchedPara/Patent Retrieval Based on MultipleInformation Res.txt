 The amount of patent information is growing rapidly with an abundant production of digital collection of documents. It is a real challenge to accessing to useful information among this large size dataset. Although patent search engine like Derwent World Patents Index and Google patent search engine have large databases, the search results are not satisfactory. People got very different results when they use different search engines with the same keywords, and they cannot determine which result is more relevant to the keywords. So it is necessary to integrate multiple patent data sources and search methods to improve the performance of patent retrieval.
 retrieval (IR) [ 1  X  3 ] In particular, the pseudo-relevance feedback (PRF) which uses query expansion has been proven to be effective [ 4 , 5 ]. The process of query expansion modi fi ed the original keyword query submitted by the user and it would be better represented the underlying intent of the query. The formulated query is then used as an input to the search engine  X  s ranking algorithm. Thus, the primary goal of query for-mulation is to improve the overall quality of the ranking presented to the user in response to the query. However, the general query expansion method cannot be introduced directly to special tasks, such as patent retrieval. The patent documents, which are constructed by several special text fi elds, are different from Web page documents. These fi elds describe different aspects of patent and have different importance. The traditional expansion methods select candidate terms from the whole document without considering the information from fi elds which are not suitable for work [ 9 , 10 ], we proposed a query expansion method, which used patent text the resource of expansion terms, the performance was improved by introducing the fi eld information to query expansion. However, we only use the pseudo-relevance feedback documents for expansion terms. There are still some external information resources which can be used to improve the retrieval performance. It is highly effective to query expansion by using external information resources [ 11 Learning to rank [ 14 ] has become an important research issue for information retrieval. It is an effective approach to improve the ranking performance. The basic premise for learning to rank method is that there are three types of input spaces, they are pointwise, pairwise, and listwise samples. In this paper, we will apply the learning to rank approach to optimize the combination of information sources to improve the performance of patent retrieval.
 The remainder of our paper is organized as follows. Section 2 reviews some related work. Section 2 explores the impact of different information resources for patent retrieval. Section 3 proposes the learning to rank based query expansion approach on Derwent World Patents Index and Google search engine for patent retrieval. In Sect. 4 , we report the experimental results. Finally, we conclude the paper and discuss future work in Sect. 5 . 2.1 Patent Retrieval In recent years, researchers show growing interests in patent retrieval. Their research mainly focused on exploring methods on query formulation for topics. Keywords was the query to reduce the burden on patent examiners which was advocated by Xue and Croft [ 17 ]. Text mining, bibliographic coupling and citation analysis were also used in patent retrieval [ 18 , 19 ]. Chen and Chiu [ 20 ] developed an IPC-based vector space model for patent retrieval and achieved a higher accuracy than normal patent search engine. Rusinol et al. [ 21 ] presented a fl owchart recognition method for patent image retrieval. Recent work showed that the best retrieval results were obtained when using terms from all the fi elds of the queried patents [ 22 ]. It seems that very effective to improve the patent retrieval. However, there are still few works on exploring the text fi elds to improve query expansion. This paper will use the patent text fi eld information to select candidate terms and improve the results of patent retrieval. We also investigate the capability of text fi eld of patent in improving the performance of retrieval as promising information for query expansion. 2.2 Query Expansion and External Sources Pseudo-relevance feedback (PRF) is an effective automatic query expansion method by reformulating the original query using expansion terms from pseudo-relevant docu-ments. Traditional PRF has been implemented in several retrieval models, such as [ 26 ], and so on. Meanwhile, there are many research work which focus on improving traditional PRF in different ways. For example, using passages instead of documents [ 27 ], using a local context analysis method [ 1 ], using a query-regularized estimation method [ 4 ], using latent concepts [ 3 ], and using a clustered-based re-sampling method for generating pseudo-relevant documents [ 5 ]. These methods follow the basic assumption that the top-ranked documents from an initial search contain useful terms that can help discriminate relevant documents from irrelevant ones.
 Search Engines and Derwent World Patents Index. Google is one of best search engines in the world, which can provide the accurate information for the users according to the their queries, so we also want to use Google to provide the relevant web pages to expand the query terms for patents. The Derwent World Patents Index (or DWPI) is a database containing patent applications and grants from 44 of the world authorities. Compiled in English by editorial staff, the database provides a short abstract detailing the nature and use of the invention described in a patent and is indexed into alphanumeric technology categories to allow retrieval of relevant patent documents by users. Each record in the database de fi nes a patent family, the grouping of patent documentation recorded at the various patent of invention is sought around the world. Each patent family is grouped around a Basic patent, which is usually the fi rst published example of the invention. All subsequent fi lings are referred back to the Basic patent as Equivalent patents. The database has some 20 million  X  inventions  X  , corresponding to ten millions of patents, with almost a million new inventions added each year. Since Derwent database is so effective to the patent research, we will use it as another external information resource to patent query expansion. 2.3 Learning to Rank Learning to rank approaches can be divided into three categorizations, the pointwise approach, the pairwise approach, and the listwise approach. Different approaches model the process of learning to rank in different ways. They de output samples, using different hypotheses and employ different loss functions. This paper will focus on the construction of samples of listwise approach for further anal-ysis. The listwise approach addresses the ranking problem in a natural way. It takes ranking lists as samples in both learning and prediction. The structure of ranking is maintained and ranking measures is incorporated directly into the loss functions. More speci fi cally, the listwise approach takes the labeled query-document list as one instance. LambdaMART [ 28 ] is the boosted tree version of listwise approach of learning to rank, which is based on RankNet. Boosting and LambdaMART have been shown as the best performing learning methods on public data sets. LambdaMART rankers won Track 1 of the 2010 Yahoo Learning To Rank Challenge. It has been proven to be an effective ranking method for merging the ranking features to improve the performance of retrieval. In this paper, we will use this approach to improve the ranking performance of patent retrieval based on multiple query expansion methods and text fi elds. 3.1 Query Expansion Model In this section, we introduce our method for patent query expansion. Our query expansion model includes two Rocchio models, one is the original Rocchio model [ 23 ], and the other is modi fi ed Rocchio model [ 9 ].
 The original Rocchio model is de fi ned as follows: where Q 1 is the expansion query, Q 0 is the original query. R is the pseudo relevance document collection, r is the relevant document. The modi on patent fi elds. In this paper, the model is de fi ned as follows: where Q 2 is the expansion query, Q 0 is the original query. R is the pseudo relevance document collection, r f is the fi eld f of the relevant document r . q We expand the original queries by this formula. 3.2 Information Resources for Patent Retrieval The common information resource for pseudo-relevance feedback is the top ranked documents from the corpus with a given query. Relevance feedback takes the results that are initially returned from a given query to perform a new query. The content of the assessed documents is used to adjust the weights of terms in the original query and/or to add words to the query. So the fi rst resource is the TREC data for patent. A patent document is composed of several fi elds of information, in particular the title, the abstract, the description and the claims. We use these content text objects to improve the quality of expansion terms. The title of patent. The abstract fi eld contains the text of summary or main idea of a patent. The description fi eld consists of the some sentences about different aspects of a patent content. The claims are the boundary associated with a patent, which is assumed to describe its limits. All the information from the fi elds may be related to the relevance, and the terms appear in the different fi elds have different degrees of relevance. So we try to apply the fi elds to weight the terms for query expansions.
 very effective. When the query is submitted to the search engine, the answer is returned in the form of title and abstract texts. The texts and real user search queries are very similar because most title and abstract texts are succinct descriptions of the destination page. The relevant documents for the given query are the second resource of query expansion. The fi elds we use to query expansion from Google are title and abstract. candidates associated with a query is restricted by considering only those anchor texts that point to a short set of top ranked patents from a larger set of top-ranked patents. These patents can provide more effective information for query expansion. The patent and abstract. 3.3 Term Selection for Query Expansion For query expansion, there are two steps: select the pseudo relevance document col-lection R and evaluate the weight of q f .
 resource: TREC patent data set, Google and Derwent World Patents Index. For TREC patent data set, the fi rst step is the pseudo feedback document selection, which applies three ranking methods for top-k documents: TF*IDF, BM25, BM25F.
 quency. There are various ways to determine the exact values of both variables. For term frequency, the simplest choice is to use the raw frequency of a term in a docu-ment, i.e. the number of times that term occurs in a document. where tf t,d is the number of times that term t occurs in document d . n the documents which contain the term t . N is the number of documents in the collection.
 in the order of their probabilities of relevance to the query. A query term is assigned a weight based on its within-document term frequency and within-query frequency. The weighting function used in our experiments is BM25, shown as follows: w is the weight of a query term, N is the number of indexed documents in the col-lection, n is the number of documents containing the term, R is the number of docu-ments known to be relevant to a speci fi c topic, r is the number of relevant documents containing the term, tf is within-document term frequency, q frequency, dl is the length of the document, avdl is the average document length, n the number of query terms, the k i s are tuning constants (which depend on the database and possibly on the nature of the queries and are empirically determined), K equals to k  X  X  1 b  X  X  b dl = avdl  X  , and indicates that its following component is added only once per document, rather than for each term.
 BM25F [ 30 ] is an extension of the BM25 function to a document description over multiple fi elds. A key property of this function is that it is nonlinear. Since BM25F reduces to BM25 when calculated over a single fi eld, we will refer to both functions as BM25F, where F is a speci fi cation of the fi elds contained in the document description. In this paper, we use BM25F as the initial retrieval method for feedback documents, which considers multiple fi elds. BM25F is computed as follows for document d , with a document description over fi elds F , and query q : The sum is over all terms t in query q . It is the Robertson-Sparck-Jones form of inverse document.
 We apply the BM25F approach as the initial retrieval method, and select the documents ranking on top-k positions as the candidate collection for the second step. TF*IDF and BM25 are used as baselines for comparison, which rank the docu-ments for top-k pseudo feedback documents without fi eld information, i.e. taking the whole document as a fi eld.
 The second step is to decompose every pseudo relevant document generated from the fi rst step into several pieces according to the fi elds of patent, while each regarded as an independent short document. We use the BM25 approach to calculate the relevance between the query and the fi eld document. The relevance score can be seen as the importance of fi eld, which we used to weight the also evaluate the importance of each term in the short fi expansion methods, such as TF, TF*IDF, BO1 and BO2 [ 31 ]. This analogy suggests us to use the other urn model for IR to obtain alternative methods of expansion for the query, which is the Bose-Einstein statistics. Note that one possible approximation of the Bose-Einstein statistics is given by the geometric distribution G. The probability P generating the geometric distribution has the same parameter process. P de fi ned as follows: The urn model based on BE can be thus used for measuring the information content of terms in the query expansion process giving us: where F Eq is the frequency of the term and k Eq is de fi where TotFr D is the total number of term tokens in the collection D . We use these expansion methods to evaluate the relevant importance of a term in the patent which combine the weights of fi elds to obtain the fi nal weight of the term in the patent document. The fi nally expanded queries will be used to improve the ranking accuracy. parameters for the patent retrieval method. If there are M optional parameter settings for a method, N ranking methods and K weight evaluation methods, and L information resources, the number of features is M * N * K * L . The experiments focus on the effec-tiveness of different forms of patent retrieval methods on learning a ranking model. 3.4 LambdaMart The performance of patent retrieval system is also evaluated by IR measures such as MAP and NDCG. Learning to rank approaches can de fi ne the ranking loss function such as cross entropy loss according to the relevance judgments. By minimizing the loss, it can learn a ranking model to improve ranking performance directly. The aim of query expansion is also to improve the performance of ranking. Therefore, learning to rank can be used to learn a model for query expansion approaches.
 model, a linear combination of the outputs of a set of regression trees. LambdaMART utilizes gradient boosting to optimize its loss function de LambdaRank. Gradient Boosting produces an ensemble of weak learner to form a strong one. LambdaRank constructs its loss function based on RankNet, whose loss function is a differentiable function of the model parameters based on cross entropy objective function. The k for a given document in the ranking list gets contributions from all other documents under the same query with different labels. The interpreted as a force, which indicates whether the document should move up or move down in this round of optimization and also the distance it will move. The document is the sum of k ij computed by using the formula as below. Loss function C has the same form as RankNet based on a probability function combining the score of each document. LambdaRank modi fi es the gradient with the variation of NDCG through swapping the rank positions of the two documents. LambdaMART uses k as the gradient of loss function and use boosted regression tree as its model to decrease ranking loss in iterations as MART does. In this paper, we mainly utilize the multiple query expansion methods to extract features for ranking model. We expect that it is effective to improve the ranking accuracies of patent retrieval.
 Feature space is constructed by different parameter settings, different ranking methods, and different weight evaluation methods. Overall, there are 18 features, which can be directly used in learning algorithms. The ranking methods include TF*IDF, BM25, and BM25F, and the weight evaluation methods include BO1 and BO2. The example of feature set is shown in Table 1 . Table 1 gives some details of implemen-tation of these features, and for the parameter settings N / M means to extract M expansion terms from N documents. N can be set to be10, 20, and M can be set to be 50, 100, and 150. Ranking methods include BM25, BM25F and TF*IDF. BO1 and BO2 are used as weight evaluation methods. In this section, we show the experimental results of query expansion based on patent fi elds. The TREC-CHEM collection is the experimental data set. We adopt all the topics from TS (Technology Survey) task from TREC-CHEM2010 and TREC-CHEM2011 as our query set. Our research is based on data set of the subtask tech-nology survey. This set contains TS-topics, which is manually created by human experts. Each topic has a description as a natural language expression of information need based on data described in a patent document. The systems should return a set of documents that answer this information need as good as possible. These topics are created to be interesting, so their main priority will be as similar as possible to a genuine information need of an expert searcher. We only use the patent documents in this collection. A patent document is composed of several abstract, description, and claims. These special text fi elds are used to improve the quality of expansion terms. For the information resources from Google and Derwent, we select expansion query terms from the title and abstract validation is used to obtain the average results. The results are evaluated by mean average precision (MAP) and P@n. 4.1 Effectiveness of Query Expansion Based on Patent Fields In this section, we conduct the experiment based on TREC data patent compare the method based on text fi eld for expansion terms (short for TFET) with retrieval methods without query expansion (Original) and the oracle method (use the best feature to rank the documents of test topic of every fold). Table 2 lists the results of these methods.
 original method. Especially for MAP and P@5, the ranking performance of TFET method is much better than Original method, and is similar to the performance of Oracle method in terms of P@5. Results show that query expansion approach based on fi eld information is indeed effective in improving the patent retrieval results. However, TFET is not as good as Oracle method in terms of other evaluation methods. The results of Oracle method come from the best ranking feature of test set of every fold. Therefore, it is feasible to develop a method considering the impact of different ranking features other than using a single ranking feature. Based on these results, the opti-mization of the query expansion based ranking methods for queries could be expected to further improve the retrieval performance. Now our goal is to develop an effective method to construct a ranking model based on different ranking features. 4.2 Effectiveness of Learning to Rank Model In order to take full advantage of all the ranking methods, we introduce a learning to rank model: LambdaMART to learn a ranking model from the ranking features. In this section the TFET and Original methods serve as baseline approaches. We will examine the effectiveness of LambdaMart model whose features are extracted from TREC data sets. Table 3 lists the results of the ranking methods.
 is superior to TFET method in all of the evaluation methods. Moreover, the relative improvement of LambdaMart is even over that of Oracle method for P@5. And in terms of P@20, it also achieves the same results as the Oracle method. As the infor-mation of test set is unknown in the training process and the ranking model is learned take into account the impact of all the ranking features based on text retrieval. It also reveals that the query expansion method based on learning to rank model can improve the ranking performance of patent retrieval. 4.3 Effectiveness of External Information Resources On above experiments, we only use the TREC data sets for query expansion to extract the features for learning to rank approach. In this section, we also apply the Google and Derwent information resources for query expansion in order to obtain the features for the ranking model. From Table 4 , we can see that the LambdaMart ranking model based on TREC data is superior to TFET method in all of terms of evaluation methods. It is also effective to improve the ranking performance by using Google and Derwent information resources. Especially when we use all the features from TREC, Google and Derwent information resources, the ranking model learned from that can achieve the best performance. It seems that it is effective to take the impact of all the information query expansion method based on learning to rank model using multiple information resource can improve the ranking performance of patent retrieval. In this paper, we explored the multiple information resources for query expansion. For TREC topics, we measure the importance of expansion terms on the retrieval performance. Our experiments show that the query expansion method is an effective approach for patent retrieval. Furthermore, we investigate the effectiveness of learning to rank model based on the query expansion ranking features. The experimental results demonstrate that, the ranking model which is based on multiple information resources, can effectively cope with the patent ranking problem. In future work, for the pseudo relevant selection method, we will try other retrieval methods to obtain more relevant documents. For the term ranking model, we plan to explore more term ranking methods for further accuracy of patent retrieval.
 improving query expansion: (1) we examine the effectiveness of different information resources for the patent query expansion; (2) we cast the combination of information sources as an optimization problem that can be solved under a learning to rank framework; (3) we take different query expansion approaches by different resources as features for learning; (4) we apply learning to rank approach with the ranking features to improve the performance of patent retrieval.

