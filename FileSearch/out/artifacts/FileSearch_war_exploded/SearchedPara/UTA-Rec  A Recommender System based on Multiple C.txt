 UTARec, a Recommender System that incorporates Multiple Criteria Analysis methodologies is presented. The system X  X  performance and capability of addressing certain shortfalls of existing Recommender Systems is demonstrated in the case of movie recommendations. UTARec X  X  accuracy is measured in terms of Kendall X  X  tau and ROC curve analysis and is also compared to a Multiple Rating Collaborative Filtering (MRCF) approach. The results indicate th at the proposed Multiple Criteria Analysis methodology can certainly improve the recommendation process by producing highly accurate results, from a user oriented perspective. H.1.2 [ Models and Principles ]: User/Machine Systems  X  Human information processing, Software psychology. H.3.4 [Information Stor age and Retrieval] : Systems and Software  X  Performance evaluation (efficiency and effectiveness) Algorithms, Performance, Reliability, Experimentation, Human Factors. Recommender Systems, Multiple Criteria Analysis, Dissagregation-Aggregation approach, Algorithm Performance Analysis. According to Mulder et al. [12],  X  X nformation overload is the feeling of stress when the information load goes beyond the processing capacity X . They observed that "Whatever people perceive as information overloa d affects decision-making, quality of work, happiness, job satisfac tion, and leads to frustration, stress, and loss of time". Many sy stems and techniques have been developed so far trying to ove rcome the information overload problem. One of the first visionaries that introduced the idea of using software agents to assist people in their computer-based tasks, was Negroponte [13]. Nowada ys, expert systems able to suggest items that a user may be interested in, are known as Recommender Systems and the topic has steadily advanced into a challenging research area of its own in the mid-1990. The term  X  X ecommender System X  (RS) was coined by Resnick and Varian [15], [14], as a generic replacement for  X  X ollaborative filtering X , a phrase proposed earlier by Goldberg et al. [5], for the first RS named Tapestry, a filter-based electronic mail system designed for the intranet at the Xerox Parc Palo Alto Research Centre. The goal of a Recommender System is to reduce information overload, by selecting a subset of items fro m a universal set that maximizes the user X  X  utility, based on user preferences. A more formal definition for a recommendation ' c s follows: where c indicates a user that belongs to the overall set of users C and s is an item of S , the set of all candidate for recommendation items. u(c,s) is the utility function that measures usefulness of item s to user c , : uC S  X  X  X  X  , where  X  is a totally ordered set. Most research works, classify Recommender Systems into three main categories, according to the technique used to provide recommendations. These are: 1) Collaborative Filtering Recommender Systems that try to predict usefulness of items for a particular user based on the items previously rated by other users, 2) Content-based Recommender Systems that utilize users X  past likings to recommend new items and 3) Hybrid Recommender Systems which combine the two aforementioned techniques, or incorporate various statistical and machine learning techniques, in order to overcome certain limitations of each method. Further details on these systems can be found in [2] and a taxonomy of RS X  X  on the internet in [11]. The majority of existing recommender systems obtains an overall numerical rating r ij , as input information for the recommendation algorithm. This overall rating depends only on one single criterion Single-criterion rating systems have proved successful in several applications. However, articles like [10] underlie the pretence of stirring Recommender Systems researchers towards a more user oriented perspective, indicating that people are not truly satisfied by existing Recommender Systems. As clearly stated in [2], Multiple Criteria Analysis methodologies have been extensively studied in Operations Research community [4], not much has been done yet though, in the field of Recommender Systems. The key to more effective personalization services is the ability to develop a system able to understand not only what people like, but why they like it. In other words, the accurate modelling of a users X  value system and thus an effective preference representation schema, will potentially lead to the design of a recommendation algorithm with increased performance. A system can understand how users think about items, by considering the knowledge about the underlying attributes that attract users to choose this particular item and hence recognize preferences, not just patterns, ensuring a more sophisticated understanding of a user. Recently, some works have started employing multi-criteria ratings directly in their Recommender Systems algorithms [1], [9], or indirectly in related to RS X  X  tasks such as User Profiling [8]. Also, in the commercial sector, Yahoo Movies has launched a recommendation service that employs user-specific multi-criteria ratings for each movie. However, to incorporate multi-criteria rating in an existing recommendation process or to design new recommendation techniques, careful consideration is necessary, to achieve maximum accuracy. In Decision Science, the field of Multiple Criteria Decision Analysis (MCDA) is well established and comes into a large variety of theories, methodologies, and techniques [4]. Multiple Criteria Analysis aims to assist a decision maker in choosing the best alternative, when multiple criteria conflict and compete with each other. A common approach states that Multiple Criteria Analysis is a set of methods or models enabling the aggregation of multiple evaluation criteria, to s upport the decision(s) related to a set of actions A. According to the general modeling methodology of decision-making problems as proposed by Roy [16], there are four distinct lev els through which a decision maker is driven to a final decision. of the set of potential actions (alternatives) A and the determination of a problem statement on A according to four reference problem statements (c hoosing, sorting, ranking and describing the actions), each of which does not necessarily preclude the others. assuming that these criteria are non-decreasing value functions, exhaustive and non-redundant. aggregate the marginal preferences on the criteria. and the problem statement of level 1. The word  X  X iding X  in MCDA implies that the decision model representing decision maker X  X  valu e system supports the decision maker, by indicating an optimal according to his/her value system decision. Under this perspective, we face the recommendation process as a decision problem and exploit techniques from Decision Theory and more specifically from the field of MCDA, to accurately model user X  X  preferences. Following this framework, a potential user in a Recommende r System corresponds to the decision maker in a Decision Support System. Both Decision Support Systems and Recommender Sy stems, try to assist the decision maker and user respectively, to identify an optimal decision. This decision may vary, from a simple purchase of an item, to more sophisticated managerial matters. UTARec system is based on a four step methodological framework that exploits and evaluates the MCDA principles, in order to provide accurate and user-oriented recommendations. These steps are analytically described in the following subsections. For the initial step of UTARec system, users have to rate a sample set of items upon specific criteria satisfying the properties of monotonicity, exhaustiveness and non-redundancy. An ideal set for UTARec was found in the Yahoo! Movies Web site (http://movies.yahoo.com) and was us ed to demonstrate system X  X  performance. In this web site users have submitted movie ratings for several movies. These ratings provide information on four criteria in addition to an overall rating. The four criteria upon which each user is asked to rate a movie, are: a) story (C1), b) acting (C2), c) direction (C3) and d) visuals (C4). This set forms a consistent family of criteria according to basic principles of MCDA [16]. To represent and manipulate user rating information, a 7-fold vector with the followi ng attributes was used: [user_id; movie_id; overall; C1; C2; C3; C4]. A 13-fold scale to grade all four criteria and the overall rating was used. In our case, the value labels as given by the users were converted to numerical values, as follows: (A+  X  13, A  X  12, A- X  11, B+  X  10, B  X  9, B- X  8, C+  X  7, C  X  6, C- X  5, D+  X  4, D  X  3, D- X  2, F  X  1). The collected data came from 45 randomly selected movies encoded with a serial number from 1 to 45. The number of movies that each user has rated was filtered to be greater than 7, according to MCDA methodological requirements [18]. All user ratings containing missing values at any of the attributes (criteria or overall rating) were removed. The resulting d ata set included 201 users and a total of 2,694 ratings. It should be noted that the number of movies each user has rated, varies along the users and takes values from 7 to 25. UTARec incorporates the UTA* algorithm to model users X  value system. UTA* is analytically presented in subsection 2.3. The application of this algorithm requires a careful arrangement of the data set. The entire data set as described in 2.1 is separated into two disjoint sets, the training set and the test set. For this division two conjoint conditions are applied. The first ensures that the number of rated movies for each user in the training set is five, while the second condition ensures a maximum dispersion of the overall rating for these set of five movies. As a result, the training set forms a multi-criteria matrix that acts as an input for the UTA* algorithm. This multi-criteria matrix consists of all the criteria values, in addition with the overall rating for the five movies that each user has rated. For the UTA* algorithm to be applied, ranking and not rating of the overall preference is required. Hence, the overall rating for the five movies is transformed into a single ranking order. For example, let us consider user i , with an overall rating r i given by the sequence r =[A+, A, B+, C, F]. This sequence is first converted into characteristic multi-criteria matrix for the UTA* algorithm has the form of Table 1. Table 1. Table captions should be placed above the table Indifference relations are allowed in the ranking order as shown in Table 1, but are not favoured for the input multi-criteria matrix to a great extent, because they would lead to a less accurate value system representation by the model [18]. In case where the number of movies with dissimilar overall rating is less than five, the training set is completed by a random choice of movies that are indifferent to the user. As previously stated, the complete data set is comprised by users that have rated at least seven movies. Five of the most diverse overall rating represent the training set and the rest of these movies are used to validate the prediction performance of UTA*. Therefore, the test set used in the evaluation phase varies from 2 to 18 movies depending on the user. UTARec system employs the UTA* algorithm [18], an improved version of the original UTA (UT ilit X s Additives) method [17], to model user preferences. This al gorithm, adopts the preference disaggregation principle, the philosophy of which, is to assess/ infer preference models from given preferential structures and is shown in Figure 1. To achiev e that, a specific methodological framework is followed and described below.
 Based on the four levels of Roy X  X  general decision-aiding modelling methodology as these are mentioned in the introduction, the movie recommendation problem that is addressed herein belongs to the first problem statement. In this problem statement the goal is to choose a potential action from a set of actions (alternatives) A. Very similarly, the goal of a Recommender System is to choose such an item that the user is more likely to prefer. The modelling process of level 2 must conclude on a consistent family of criteria {g 1 ,g criterion must be a non-decreasing real valued function defined on A, as follows: where * [,] * g g ii is the criterion evaluation scale, the worst and the best level of the i th criterion respectively, g(  X  ) is the evaluation or performance of action  X  on the i g (  X  ) is the vector of performances of action  X  on the n criteria. From the above definitions the following preferential situations can be determined: Thus, having a weak-order preference structure on a set of actions, the problem is to adjust additive value or utility functions based on multiple criteria, in such a way that the resulting structure would be as consiste nt as possible with the initial structure. Generally, the UTA method originally proposed by [17] aims at inferring one or more additive value functions from a given ranking on a reference set A R . The method uses special linear programming techniques to a ssess these functions so that the ranking(s) obtained through these functions on A consistent as possible with the given one. The UTA* algorithm aims at estimating additive utilities of the form: subject to the following constrains: where u i (g i ) i=1,...,m are non decreasing real valued functions, named marginal utility function. Conclusively, the UTA* algorithm may be summarized in the following steps: Step 1: Express the global value of reference actions u[ g (a 1,2,...,m , first in terms of marginal values u i (g i ) , and then in terms of variables w ij according to the formula (6). The transformation of the global value of reference actions into weights values expression is made according to formula (7): Step 2: Introduce two error functions  X  + and  X  -on A for each pair of successive actions in the given ranking the formula (8): Step 3: Solve the linear program (LP): Step 4 (stability analysis): Check the existence of multiple or near optimal solutions of the linear program (9). In case of non uniqueness, find the mean additive value function of those (near) optimal solutions which maximize the objective functions of (10), on the polyhedron of the constraints of the LP (9) bounded by the constraint of (11), where z* is th e optimal value of the LP in step 3 and  X  a very small positive number. By applying the UTA* algorithm to our training data set all the necessary parameters to estimate global utility functions (( )) g U  X  for each movie and user are calculated. Thus, a value is assessed for each alternative (movie) that belongs to the reference set, quantifying its utility to each user and ensuring consistency with his/ her value system. An example of the UTA* algorithm output is shown in Figure 2 for a characteristic user i. In this figure all four marginal utility functions for a specific user are shown. Through these functions, a marginal utility value can be assessed for all criteria and for every performance stated by the users, through which a global utility will quantify user X  X  preference on each alternative. The results attained from step 3 are used as an input for the recommendation process. The total utility of an item is calculated according to equation 4. The test set is used to evaluate UTARec X  X  recommendation efficiency. Suppose we have no information about the overall rating for the movies that belong to the test set. By applying formula 4, in combination with the performances of these movies upon all four criteria, an overall utility score for the specific movie for each user is calculated and compared to the actual score, evaluating accordingly the accuracy of UTARec by performing the validity analysis described in section 3. Figure 2. Criteria Marginal Utility Functions for a characteristic user The output of a recommendation algorithm is usually a list of items that a user is more likely to prefer, compared to an overall set of similar type items. To evaluate the recommendation performance of UTARec system, we first calculate its prediction performance. Different types of m easures have been applied to evaluate the performance of a RS [6]. Evaluating Recommender Systems and their algorithms is inherently difficult and the main reason for this is that different algorithms may give better or worse results on different data se ts. Moreover, there is no global agreement in research society yet on the definition of a successful recommender system. Some works measure their recommendation algorithm performance based on prediction accuracy while other researchers focus on metrics that evaluate user satisfaction. In this work, Kendall X  X  tau is calculated between user and model ranking orders. In addition, to further verify the results, precision and recall measures have been calculated to reveal the classification accuracy of the build up model. For the later to be applied, a grouping of the actual user answers was preceded. As stated is step 1 each user has rated a different number of movies ranging from 7 to 25. The prediction accuracy of UTARec is calculated on the residual set of movies (test set) after the exclusion of the reference set (training set) used in step 3. For the test set we suppose here that there is no information upon the overall rating by the user. The input for step 4 is the significance weights and marginal utility functions as calcu lated is step 3. The output of the test set. Since the algorithm for user preference modelling employs ordinal regression technique s by exploiting the ranking information over user X  X  overall preference, an appropriate metric to evaluate the results of such an algorithm is Kendall X  X  tau, a measure of correlation between two ordinal-level variables. In our revealed by the overall rating for the test set given by the user and the second is the ranking order derived by the utilities values calculated by the model. In order to calculate Kendall X  X  tau for any sample of n observations, there are [n (n-1)/2] possible comparisons of points (x i , y i ) and (x j , y j ). Suppose M number of pairs that are concordant and M D is the number of discordant pairs. The formula for Kendall tau is: Where I Y is the number of equivale nt pairs regarding ranking order Y (user X  X  ranking order) and pairs regarding ranking order Y (model X  X  ranking order). Kendall X  X  tau is a measure of the prediction accuracy of the algorithm and in this sense it is a measure of the precision that our model represents user X  X  preference system. Kendall X  X  tau varies between -1 and 1 with 1 indicating a total agreement of the orders. Figure 3 shows values of Kendall X  X  tau for each user. A mean value of 0.74 was found with 20,4% of user having a Kendall X  X  tau of 1. This result indicates that the two ranking orders compared, the one predicted by UTARec and the real one as stated by the user, are in high agreement. Figure 3. Kendall X  X  tau between user X  X  and UTARec X  X  ranking order per user Receiver Operating Characteristic Analysis (ROC Analysis) is a useful technique for organizing cl assifiers and visualizing their performance. It is related to cost-benefit analysis in decision making and has been widely used in medicine. Recently it has been introduced in machine learning [3]. ROC graphs are two-dimensional graphs in which True Positive rate is plotted versus False Positive. True positive rate is the actual number of positives correctly classified by a model (UTARec in this case) over the total positives. False Po sitive Rate is the result of the number of negatives incorrectly classified, divided by the total negatives. An ROC graph depicts relative trade-offs between true positives and false positives. The diagonal line of an ROC graph represents the case of randomly guessing a class. Furthermore, the Area Under the Curve (AUC) has been shown to be an accurate evaluation measure and is widely used in applications where ranking is crucial. The maximum value for the AUC is 1.0, a point in the upper left corner or coordinate (0,1), thereby indicating a (theoretically) perfect classifier. The best possible prediction method would yield AUC values vary between 0 and 1 but since an AUC of 0.5 represents the pe rformance of a random classifier, values less that 0.5 indicate no di scriminating power of the model. In Figure 4 the ROC graph for UTARec is depicted. The Area Under Curve was found to be 0.81 for 50 cut off points. Figure 4. Receiver Operating Characteristic curve for 50 cut off points For a Recommender System to be considered successful, it must address at least some of the exis ting RS X  X  shortfalls [2],[19]. In the work of [19], the main drawbacks of Recommender systems are analytically discussed. UTARec system can prove helpful in addressing some of these problems. A major issue in Recommender Systems is the quality of recommendations. To increase this quality, fa lse positive results need to be minimized. False positive results arise from th e fact that sometimes, items which are counted as positives and thus recommended are not preferred by the users (false). As shown in the experimental results of ROC curve analysis, UTARec performs especially well in this task. The AUC value of 0.81 among highest values reported for RS X  X  [7]. To furthe r verify this result, precision (defined as the percentage of truly high ratings among those that the model predicted would be high) and recall (the result of dividing the number of correctly predicted high ratings by all the ratings known to be high) were calculated on a cut off point of 0.22. To implement these results, F-measure, which assigns equal weights to both recall and precision, was calculated for each user on the test set. The average F-measure for all users was found 0.88. These values are again among highest reported for collaborative filtering algorithms [7]. Given that the evaluation of a RS is highly dependent on the f unctioning data set, to ensure a consistent comparison of the re sults, a Multirating Collaborative Filtering approach (MRCF) was implemented. In this approach, the same reference set used to model user preferences in the UTARec system was also used to calculate similarity among users. The metric of distance and similarity among users is analytically mentioned in [1]. To measure MRCF X  X  accuracy and compare it to UTARec X  X , the measure of Mean Absolute Error (MAE), a very common accuracy measure in Recommender Systems was calculated for the same test set in both UTARec system and MRCF approach. The comparison was made as follows: First, in the MRCF case, for every user and for the entire set of candidate for recomme ndation movies, a score was calculated as the average rating of current user X  X  neighbours. As neighbours, users with similarity values greater than the average similarity were considered. S econd, in the UTARec case, the overall score of the same movies was calculated as a linear combination of the criteria weights with the performance of these movies on each criterion. For all users the MAE upon all candidate movies was calculated re garding the true overall values as stated by the users. The results are shown in Figure 5. In this MAE is achieved in the case of UTARec system, proving thus its superiority to a classic Multirating Collaborative Filtering approach. Figure 5. Mean Absolute Error for the first 50 users (see input graph for all users) in the case of MRCF (light grey) and UTARec (dark grey). Another very common and important issue in RS X  X  is data matrix sparsity, which finds its origin to the fact that users have generally rated a very limited number of items. In the UTARec algorithm this problem is not apparent, since a minimum number of rated items is required as an input for the UTA* algorithm. This restriction ensures a uniform data distribution at least at the degree of the reference set lengt h. A further main problem in existing recommender systems is scalability. Traditional Recommender Systems, like collaborative filtering type systems, or content based type systems, re quire calculations that grow with both the number of users and the number of items. In UTARec, the training of the algorithm is made by a limited number of data for each user and the results are used to provide recommendations. The algorithm is very fast and since it is independent on other user X  X  opinions, it does not suffer from typical scalability issues of RS X  X  . Further pitfalls of current Recommender Systems like Loss of Neighbour Transitivity or Cold Start Problem, depend on the fact that today X  X  Recommender Systems are  X  X eer oriented X , meaning that are based on the information provided by other users. UTARec, is a one-to-one recommender system, that does not take other users X  opinions under consideration. For this reason, it is not affected by any problems related to collabor ativeness. The Unusual user problem refers to individuals whose opinions are uncommon, meaning that they do not agree or disagree consistently with any group of people. With collaborative filtering systems, these individuals would not easily benefit, since they would rarely receive accurate predictions [19]. This problem is also addressed by UTARec, since UTARec considers and models each user separately. At this point, it is crucial to mention that only a single aspect (the recommendation performance aspect) of the UTARec system is discussed in this study. UTARec system can be also used as a  X  X on-recommender X  tool . According to utility results the system may suggest the user to avoid buying a specific item that he/she wouldn X  X  like and its purchase would result in increased frustration. UTARec is a recommender system that based on user preferences modelling, is capable of recommending favoured to each user items. Through a user-oriented approach, it achieves high accuracy level scores and is thus able to allocate the most preferred to the user items, from a very large available list. It requires a minimum effort by the us er, by asking him/her to rate a small number of reference set ite ms upon certain criteria and to provide a ranking order for those items. Afterwards, the system implements the UTA* algorithm to model user X  X  preference policy and by exploiting this information, it provides accurate, personalized recommendations, addr essing thus, several problems of existing Recommender Systems. UTARec system exploits multi-criteria ratings to better model user X  X  preference behaviour and its results appear promisi ng in terms of prediction and performance analysis. The authors are grateful to Prof. Alexis Tsoukias and to the anonymous referees for their valu able comments. This work is part of the 03ED375 research pr oject, implemente d within the framework of the  X  X einforcement Programme of Human Research Manpower X  (PENED) and co-financed by National and Community Funds (75% from E.U.-European Social Fund and 25% from the Greek Ministry of Development-General Secretariat of Research and Technology). [1] Adomavicius, G. and Kwon, Y. 2007. New Recommendation [2] Adomavicius, G. and Tuzhilin, A. 2005. Towards the Next [3] Fawcett, T. ROC Graphs: Notes and Practical Considerations [4] Figueira, J., Greco, S. and Ehrgott, M. 2005.Multiple criteria [5] Goldberg, D., Nichols, D., Ok i, B. M. and Terry, D. 1992. [6] Herlocker, J. L., Konstan, J. A., Terveen, L. G. and Riedl, J. [7] Huang, Z., Zeng, D. and Chen, H. 2007. A Comparison of [8] Lakiotaki, K., Delias, P., Sakkalis, V. and Matsatsinis, N. F. [9] Matsatsinis, N., Lakiotaki, K. and Delias, P. A System based [10] McNee, S. M., Riedl, J. and Konstan, J. A. Making [11] Montaner, M., Lopez, B. and Rosa, J. L. 2003. A Taxonomy [12] Mulder, I., Poot, H. d., Verwij, C., Janssen, R. and Bijlsma, [13] Negroponte, N. 1969. Toward a Theory of Architecture [14] Resnick, P., Iacovou, N., Such ak, M., Bergstrom, P. and [15] Resnick, P. and Varian, H. R. 1997. Recommender systems. [16] Roy, B. 1985. M X thodologie Multicrit X re d X  X ide  X  la [17] Siskos, Y., Grigoroudis, E. and Matsatsini s, N. 2005.UTA [18] Siskos, Y. and Yannacopoulos , D. 1985. UTASTAR, An [19] Vozalis, E. and Margaritis, K. G. Analysis of Recommender 
