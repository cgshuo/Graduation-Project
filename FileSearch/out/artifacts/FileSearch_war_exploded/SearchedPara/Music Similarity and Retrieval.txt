 This tutorial serves as an introductory course to the field of and state-of-the-art in music information retrieval (MIR) and in particular to music similarity estimation which is an essential component of music retrieval. Apart from explain-ing approaches that estimate similarity based on acoustic properties of an audio signal, we review methods that ex-ploit (mostly textual) meta-data from the Web to build rep-resentations of music then used for similarity calculation. Additionally, topics such as (large-scale) music indexing, in-formation extraction for music, personalization in music re-trieval, and evaluation of MIR systems are addressed. H.5.5 [ Sound and Music Computing ]: Methodologies and techniques; H.3.3 [ Information Search and Retrieval ] music information retrieval, music similarity, music retrieval, content-based MIR, context-based MIR Music is omnipresent in today X  X  society, especially on the Web and in social media, and the amount of music avail-able via streaming services, online stores, and platforms like YouTube has skyrocketed over the last couple of years. Mu-sic information retrieval (MIR) is a research field that aims  X  among other things  X  at making the information contained in ever-growing digital music repositories accessible in an intelligent manner by automatically extracting semantically meaningful information from various representations linked to music entities, such as digital audio files, band Web pages, song lyrics, or tweets on listening activities.

A key approach in MIR is to describe music via com-putational features, which can be broadly categorized into three classes: music content , music context , and user con-text . While music content-based features are derived directly from the audio signal of the music file [1], music context refers to pieces of information that are not encoded in the actual audio file, nevertheless play an important role in hu-man perception of music, such aspects include the meaning of song lyrics, the background of an artist, or even the cover of an album [2]. The user context, in contrast to the other two, includes environmental aspects as well as physical and mental activities of the music listener [3].

The aim of the tutorial is to give a sound and comprehen-sive, nevertheless easy-to-understand, introduction to MIR. First, we review and discuss the ideas behind the three cat-egories of computational features (content, music context, and user context). Then, we focus on approaches for music similarity estimation, in particular approaches that estimate similarity based on acoustic properties of the actual musical signal and approaches that exploit meta-data from the Web. This includes an introduction to the field of Web-based MIR and a detailed description and comparison of data sources of music context (e.g., Web pages, blogs, micro-blogs, social networks, tags, lyrics, playlists). Additionally, topics such as automatic (large-scale) music indexing, information extrac-tion for music, personalization and user adaptation in music retrieval, as well as the challenging task of evaluating MIR systems beyond the traditional IR-related measures and the difficulties entailed by the need for objective quantification are addressed. We further demonstrate applications such as automatic playlist generators, music search engines, music recommender systems, and intelligent interfaces to music, that utilize the methods presented.

The material presented in the tutorial is available online at http://www.cp.jku.at/tutorials/sigir2013.html
The research leading to these results has received funding from the European Union Seventh Framework Programme FP7 / 2007 X 2013 through PHENICX project under grant agreement no. 601166 [1] M. Casey, R. Veltkamp, M. Goto, M. Leman, [2] P. Knees and M. Schedl. A Survey of Music Similarity [3] M. Schedl and P. Knees. Personalization in Multimodal
