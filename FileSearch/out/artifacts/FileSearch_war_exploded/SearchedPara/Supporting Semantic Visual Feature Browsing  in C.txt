 A new shot level video retrieval system that supports semantic visual features (e.g., car, mountain, and fire) browsing is developed to facilitate content-based retrieva l. The video X  X  binary semantic feature vector is utilized to calcula te the score of similarity between two shot keyframes. The score is th en used to browse the  X  X imilar X  keyframes in terms of semantic visual features. H.3.3 [ Information Search and Retrieval ]: Relevance feedback Algorithms, Design Content-based, video browsing, video retrieval, user interface In video retrieval, various br owsing technologies are widely supported to augment text based query search, in particular when exact queries are hard to form. This may be because human beings generalizing or inferring informa tion from limited data, and making relevance decisions. Browsing usually follows a search operation to pinpoint the correct matches. For shot level content-based retrie val (where a shot represents a series of consecutive frames with no sudden transition), temporal neighbor browsing is the most common navigation method [1,2]. Temporal neighbor browsing allows users to navigate around the selected sample shot keyframe (a single frame that is representative of the content of a shot) from a text query returns. Potential relevant shots may appear just before or after the sample one due to the asynchronous of the visual content and its related transcript. One limitation of the temporal neighbor browsing is the limited support for visual objects searching, such as people, car, map, etc.. We propose a video browsing system that supports both temporal neighbor and semantic visual feature browsing. Figure 1 is the main interface of the system. On the top part (part A) a traditional text input field is provided for text-based query. In our system the videos X  transcripts were u tilized for text-based retrieval. 
