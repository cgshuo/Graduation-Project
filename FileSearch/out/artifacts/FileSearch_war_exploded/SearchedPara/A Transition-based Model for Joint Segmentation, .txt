 Microblogs, such as Twitter, SMS and Weibo, has become an important research topic in NLP. Pre-vious work has shown that off-the-shelf NLP tools can perform poorly on microblogs (Foster et al., 2011; Gimpel et al., 2011; Han and Baldwin, 2011). One of the major challenges for microblog processing is the issue of informal words. For ex-ample,  X  X mrw X  has been frequently used in tweets for  X  X omorrow X , causing OOV problems.

Text normalization has been introduced as a pre-processing step for microblog processing, which transforms informal words into their stan-dard forms. Most work in the literature focuses on English microblog normalization, treating it as a noisy channel problem (Pennell and Liu, 2014; Cook and Stevenson, 2009; Yang and Eisenstein, 2013) or a translation problem (Aw et al., 2006; Contractor et al., 2010; Li and Liu, 2012; Zhang et al., 2014c), and training models based on words.
Lack of annotated corpora, text normalization is more challenging for Chinese. Unlike En-glish, Chinese informal words are more difficult to mechanically normalize for two main reasons. First, Chinese does not have word delimiters. Second, Chinese informal words manifest diver-sity, such as abbreviations, neologisms, unconven-tional spellings and phonetic substitutions. Intu-itively, there is mutual dependency between Chi-nese word segmentation and normalization, and therefore two tasks should be solved jointly.
Wang and Kan (2013) proposed a joint model to process word segmentation and informal word detection. However, text normalization was not included in the joint model. Kaji et al (2014) proposed a joint model for word segmentation, POS tagging and normalization for Japanese Mi-croblogs, which was trained on a partially anno-tated microblog corpus. Their method requires special annotation for text normalization, which can be expensive.

In this paper, we propose a joint model for Chi-nese text normalization, word-segmentation and POS tagging, which can be trained using standard segmentation and POS tagging annotation, over-coming the lack of an annotated corpus on Chi-nese microblogs. Our model is based on Zhang and Clark (2010), with an extended set of transi-tion actions to handle joint normalization. In our model, word segmentation and POS tagging are based on normalized text transformed from infor-mal text. Assuming that the majority of informal words can be normalized into formal equivalents (Han et al., 2012; Li and Yarowsky, 2008), we seek standard forms of informal words from an au-tomatically constructed normalization dictionary.
To evaluate our model, we developed an anno-tated corpus of microblog texts. Results show that our model achieves the best performances on three tasks compared with several baseline systems. Text normalization is a relatively new research topic. There are no precise definitions of a text normalization task that are widely accepted by researchers. The task is generally divided into three categories: lexical-level, sentence-level and discourse-level normalization. In this paper we focus on lexical-level normalization, which aims to transform informal words into their standard forms.

Lexical normalization can be regarded as a spelling correction problem. However, researches on spelling correction focus on typographic and cognitive/orthographic errors (Kukich, 1992), while text normalization focuses on lexical vari-ants, such as phonetic substitutions, abbreviation and paraphrases.

Unlike English, for which informal words are detected according to whether they are out of vo-cabulary, Chinese informal words manifest diver-sity. Wang et al. (2013) divided informal words into three types: phonetic substitutions, abbrevi-ations and neologisms. Li and Yarowsky (2008) classified them into four types: homophone, ab-breviation, transliteration and others. Due to vari-ant characteristics, they normalise informal words by training a model per type, leading to increased system complexity.

Research reveals that most lexical variants have an unambiguous standard form (Han et al., 2012; Li and Yarowsky, 2008). The validity of this as-sumption is also empirically assessed on our cor-pus annotation in Section 6.1. Based on this as-sumption, we seek standard forms of informal words from a constructed normalization dictio-nary, avoiding diversity on informal words. 3.1 Transition-based Segmentation We adapt the segmenter of Zhang and Clark (2007) as our baseline segmenter. Given an input sentence x , the baseline segmenter finds a segmen-tation by maximizing: where Gen ( x ) denotes the set of all possible seg-mentations for an input sentence.

Zhang and Clark (2007) proposed a graph-based scoring model, with features based on com-plete words and word sequences. We adapt their method slightly, under a transition-based frame-work (Zhang and Clark, 2011), which gives us a consistent way of defining all models in this paper. Here a transition model is defined as a quadruple M = ( C, T, W, C t ) , where C is a state space, T is a set of transitions, each of which is a function: C  X  C , W is an input sentence c 1 ... c n , C t is a set of terminal states. A model scores the output by scoring the corresponding transition sequence.
As shown in Figure 1, a state is a tuple ST = ( S, Q ) , where S contains partially segmented se-quences, and Q = ( c i , c i +1 , ..., c n ) is the sequence of input characters that have not been processed. When the character c i is processing, the transition system would operate one of two actions that are defined as follows: (1) APP( c i ), removing c i from Q , and append-ing it to the last (partial) word in S . (2) SEP( c i ), removing c i from Q , making the last word in S as completed, and adding c i as a new partial word.

Given the sentence  X   X  \  X   X  ' J (How great work pressure is!) X , the sequences of ac-tion  X  X EP(  X  ), APP( \ ), SEP(  X  ), APP(  X  ), SEP( ' ), SEP( J ), SEP(!) X  can be used to ana-lyze its structure. 3.2 Joint Segmentation and Normalization Our SN model extends the transition-based seg-mentation model. In addition to the actions APP and SEP, the transition system also contains a SEPS action, which substitutes an in formal word on the top of S if it exists in the normalization dic-tionary. Figure 2 gives a normalization transition process for the sentence  X   X  \ - X  ' J (How great work pressure is!) X . During processing the character  X  ' (big) X , the following actions can be applied. (1) APP( X  ' (big) X ), appending  X  ' (big) X  to the beled sequence. (2) SEP( X  ' (big) X ), making the last word  X  - X  (y  X  al  X   X , pear) X  in the informal labeled sequence as a completed word, and adding  X  ' (big) X  as a new partial word. (3) SEPS( X  ' (big) X ,  X   X   X  (y  X  al `  X , pressure) X ), operating the action SEP( X  ' (big) X ), and using Figure 2: Transition actions for joint segmentation and normalization. the standard form  X   X   X  (y  X  al `  X , pressure) X  for the informal word  X  - X  (y  X  al  X   X , pear) X .

Given the sentence  X   X  \ - X  ' J (How great work pressure is!) X , the sequences of ac-tion  X  X EP(  X  ), APP( \ ), SEP( -), APP(  X  ), SEPS( ' ,  X   X  ), SEP( J ), SEP(!) X  can be used to analyze its structure.

Lexical substitution is based on a normalization dictionary whose entries consist of &lt; lexical vari-ant, standard form &gt; pairs. The output is a pair of labeled sequences, containing the informal la-beled sequence and the corresponding formal la-beled sequence. To rank the candidates, both la-beled sequences can be scored. However, lacking annotated corpora on informal texts, we only use the score of formal labeled sequence in our model. The advantage is that we can train our model by using standard corpus only, overcoming the lack of annotated corpora on informal texts. 3.3 Training and Decoding We apply the global training and beam-search de-coding framework of Zhang and Clark (2011). An agenda is used by the decoder to keep the N-best states during the incremental process. Before de-coding starts, the agenda is initialized with the ini-tial state. When a character is processed, existing states are removed from the agenda and extended with all possible actions, and the N-best newly generated states are put back onto the agenda. Af-ter all states have been terminal, the highest-scored state from the agenda is taken as the output. Algorithm 1 shows pseudocode for the decoder. ADDITEM adds a new item into the agenda, N-BEST returns the N highest-scored items from the agenda, and BEST returns the highest-scored item from the agenda. G ET NW ORD returns a possible standard form set of last word, seeking from nor-malization dictionary. APP appends a character to the last word in a state, SEP joins a character as the start of a new word in a state, SEPS oper-ates SEP and replaces the last word by a possible standard form. 3.4 Features In the experiments, we use the segmentation fea-ture templates of Zhang and Clark (2011). These features are effective for segmentation on formal text. However, for text normalization, these fea-tures contain insufficient information. Our exper-iments show that by using Zhang and Clark X  X  fea-tures, the F-Score on normalization is only 0.4207.
Prior work has shown that the language statis-tic information is important for text normalization (Wang et al., 2013; Li and Yarowsky, 2008; Kaji and Kitsuregawa, 2014). As a result, we extract language model features by using word-based lan-guage model learned from a large quantity of stan-dard texts. In particular, 1-gram, 2-gram, 3-gram features are extracted. Every type of n-gram is di-vided into ten probability ranges. For example, if the probability of the word bigram:  X   X   X  -'  X  (high pressure) is in the 2 nd range, the feature is represented as  X  X ord-2-gram=2 X .

In our experiments, language models are trained train a word-based language model, we segmented the corpus using our re-implementation of Zhang and Clark (2010). Results show that language model information not only improves the perfor-mance of text normalization, but also increases the performance of word-segmentation. 4.1 Joint Segmentation and POS Tagging In order to reduce the error propagation of word segmentation, joint models have been applied to some NLP tasks, such as POS tagging (Zhang and Clark, 2010; Kruengkrai et al., 2009) and Parsing (Zhang et al., 2014a; Qian and Liu, 2012; Zhang et al., 2014b).

We take the joint word segmentation and POS tagging model of Zhang and Clark (2010) as the joint baseline. It extends from transition-based segmenter, adding POS arguments to the original actions. In Figure 1, when the current character c i is processing, the transition system for ST would operate as follows : (1) APP( c i ), removing c i from Q , and append-ing it to the last (partial) word in S with the same POS tag, . (2) SEP( c i , pos ), removing c i from Q , making the last word in S as completed, and adding c i as a new partial word with a POS tag  X  pos  X .

Given the sentence  X   X  \  X   X  ' J (How great work pressure is!) X , the sequences of ac-tion  X  X EP(  X  , NN), APP( \ ), SEP(  X  , NN), APP(  X  ), SEP( ' , VA), SEP( J , SP), SEP(!, PU) X  can be used to analyze its structure. 4.2 Joint Segmentation, Normalization and Our joint model extends the model of Zhang and Clark (2010) by adding a SEPS action, which sub-stitutes formal word for last word in S if exists in the dictionary. On the other hand, it can also be regarded as an extension of the joint segmentation and normalization model, adding POS arguments to the original actions.

Using the same example shown in Figure 2, the following three actions can be applied for the char-acter  X  ' big) X : (1) APP( X  ' (big) X ), appending  X  ' (big) X  to the beled sequence, which remain with the same POS tag  X  X N X . (2) SEP( X  ' (big) X , VA), making the last word  X  - X  (y  X  al  X   X , pear) X  in the informal labeled se-quence as a completed word and adding  X  ' (big) X  as a new partial word with a POS tag  X  X A X .
 (3) SEPS( X  ' (big) X , VA,  X   X   X  (y  X  al `  X , pres-sure) X ), operating the action SEP( X  ' (big) X , VA), and using the standard form  X   X   X  (y  X  al `  X , pressure) X  for the informal word  X  - X  (y  X  al  X   X , pear) X .
Given the sentence  X   X  \ - X  ' J (How great work pressure is!) X , the sequences of ac-tion  X  X EP(  X  , NN), APP( \ ), SEP( -, NN), APP(  X  ), SEPS( ' , VA,  X   X  ), SEP( J , SP), SEP(!, PU) X  can be used to analyze its structure.
We use the same training and decoding frame-work as our joint segmentation, normalization and POS tagging model, as described in section 3.3. Although large-scale normalization dictionaries are difficult to obtain, informal/formal relations could be extracted from large-scale web corpora (Li and Yarowsky, 2008), and informal words are mainly derived using fixed word-formation pat-terns. In this paper, we adopt two methods to con-struct a normalization dictionary.

The first method is to extract informal/formal pairs from large-scale text. In general, many infor-mal and formal words co-occur in the same texts or similar contexts. We can find their relations with text patterns. As shown in Table 1, the first example follows the  X  X ormal _  X  informal X  ( X  _  X   X  means  X  X s also referred to as X ) definition pat-tern, while the second example follows the pattern  X  X nformal(formal) X . This gives us a reliable way to seed and bootstrap a list of informal/formal pairs.
We use a bootstrapping algorithm to extract in-formal/formal pairs from large-scale microblogs. First, a small set of example relations are collected manually. Second, using these relations as a seed set, we extract the text patterns, with which we identify more new relations from the data and aug-ment them into the seed set. Table 2 shows the initial text patterns extracted form the examples. The procedure iterates until it cannot identify new relations. There is much noise in the extracted informal/formal pairs. We re-rank them using a similarity-based classifier with weak supervision, with the positive pairs being inserted into dictio-nary.

The second method is to generate new infor-mal/formal pairs using word-formation patterns extracted from informal/formal pairs. Although Chinese informal words manifest diversity, infor-mal words are mainly derived using fixing word-formation methods, such as compounds, phonetic substitutions, abbreviations, acronym, reduplica-tion. We can learn the pattern of informal word-formation from informal/formal pairs. For exam-ple, in informal/formal pair  X   X   X  (m ` eizh  X   X , sis-ter paper)/  X  P (m ` eiz  X   X , sister) X , informal word  X   X   X  (m ` eizh  X   X , sister paper) X  is builded from formal word  X   X  P (m ` eiz  X   X , sister) X  by the pattern  X  P  X   X . Using this pattern, we can generate many new informal/formal pairs, such as  X  I  X  (h ` anzh  X   X , man paper)/ I P (h ` anz  X   X , man) X ,  X  7  X  (n  X  anzh  X   X , man pa-paper)/ YP (s  X  unz  X   X , grandson) X , in which the for-mal words contain character  X  P  X .

In the experiments, we constructed the nor-malization dictionary consisting of 32,787 infor-mal/formal word pairs in total. The dictionary is used to tamper the formal training data for the joint segmentation and normalization systems with 25% of the formal words in the dictionary be-ing replaced with their informal equivalents. Table 3: Frequency distribution and annotation agreement on various types of informal words. 6.1 Microblog Corpus Annotation To evaluate our model, we develop a microblog corpus. Our annotated corpus is collected from platform in China. More than 1,000,000 Chinese posts are crawled using Sina Weibo API. Among these, 4,000 posts were randomly selected. We follow Wang et al. (2012) and apply rules to preprocess the corpus X  X RLs, emoticons,  X  X user-names and Hashtags as pre-segmented words. As a result, we obtain 2,000 sentences as a source of the corpus.

Two human participants annotated the 2,000 sentences by using the tools we developed. The tools can simultaneously annotate word bound-aries, POS and text normalization. We used the CTB scheme for word segmentation and POS tagging. We divided informal words into three types: Phonetic Substitutions, Abbreviation, Para-phrases. In total, we annotated 1,129 informal word-pairs in the 2,000 sentences, which con-tained 658 different informal words.

Table 3 shows the frequency distribution and annotation agreement over three types of informal words in corpus. The Cohen X  X  kappa is 0.95 for informal words annotation, which shows that it is easy for humans to distinguish informal words, and validates our assumption that informal word generally has one formal word equivalent. 6.2 Settings and Measures Our model is trained on the Chinese Treebank tagged and fully bracketed Chinese news corpus. The annotated microblog corpus is randomly di-vided into two parts: 1,000 sentences for develop-ment and 1,000 sentences for test.

The standard F-measure is used to measure the Table 4: Segmentation and normalization results. S;N denotes the pipeline model. SN denotes the joint model. lm denotes language model features. accuracies of word segmentation, POS tagging and text normalization, where the accuracy is F = 2PR/(P+R) . In addition, we use recall rates to evaluate the identification accuracies of formal, in-formal and all words. The recall rate of formal words N-R is defined as the percentage of gold standard output formal words that are correctly segmented, the recall rate of informal words I-R is defined as the percentage of gold-standard out-put informal words that are correctly segmented and the recall rate of all words ALL-R is defined as the percentage of gold standard output words that are correctly segmented. 6.3 Joint Segmentation and Normalization Our development set is used to decide the beam size and the number of training iterations. The best performances on the development set are obtained when the beam size is set to 16 and the number of iterations is set to 32.

Comparison with pipeline We investigate the influence of the language model and analyze the result compared to the baseline. Table 4 shows the results on the development and test sets, where SN model is joint model and S;N is pipeline model. Our SN model performs better on segmentation than pipeline S;N model, demonstrating the effec-tiveness of normalization.

Table 5 shows the accuracies (i.e., recall rate) of formal and informal word identification on the development set. After normalization, the accu-racy of informal word identification has a large improvement, and the accuracy of formal word identification also increases. This shows that for-mal words can be better recognized when infor-mal words are identified correctly. It demonstrates that text normalization is effective for both infor-mal words and formal words.

The effect of language model From Table 4, we observe that the performances increase when using language model features. Particularly, the Table 5: Formal and informal word accuracies on the development test. N-R denotes the recall rate of formal words, I-R denotes the recall rate of in-formal words, ALL-R denotes the recall rate of all words. normalization accuracy improves more signifi-cantly. It indicates that statistical language model knowledge play an important role on text normal-ization. Using language model features, our SN model improves more in the segmentation F-Score compared with the baseline system.

Furthermore, we also find that the language model features are helpful to identifying the for-mal words, as shown in Table 5. The identification accuracy of informal words increases on the SN model, while the accuracy decreases on the S;N model. Due to the relatively low frequency of in-formal words, they score lower on informal text by using the language model information, resulting in incorrect word segmentations. This illustrates that our joint model is more suitable for microblogs than the pipeline method. 6.4 Joint Segmentation, Normalization and We compare the following models on word seg-mentation, text normalization and POS tagging. ST Our re-implementation of Zhang and Clark(2010). We investigate how the joint model contributes to improving accuracy of word seg-mentation and POS tagging in microblog domain.
S;N;T It is a pipe-line method for segmentation, normalization and POS tagging. The segmentation model does not use the features of POS. The nor-malization model uses segmentation information, but not features of POS. The POS tagging model does not need to segmentation.

SN;T It is another pipe-line method that first performs segmentation and normalization, then performs POS tagging. The SN model does not use the features of POS, and the POS tagging model does not need to segmentation.

SNT Our joint segmentation, normalization, and POS tagging model. 6.4.1 Results Table 6 shows the final results on the test set. Pre-vious work has shown that the systems trained on news data give poor accuracies of word segmen-tation and POS tagging in the microblog domain. As shown in Table 6,the F-Score of segmentation and POS tagging is 0.902 and 0.8163 respectively by using the Stanford segmenter and POS tagger.
Comparing ST and SNT, we find that text nor-malization can enhance word segmentation and POS tagging in the microblog. SNT achieved larger improvements over the baseline with lan-guage features, reducing segmentation errors by 12.02% and POS errors by 3.63%.

Another goal of the experiment is to illustrate whether the three tasks benefit from each other. Comparing SN;T to S;N;T shows that the perfor-mance increases by join segmentation and normal-ization. It indicates that segmentation and text normalization benefit from each other. On other hand, our SNT model yields better performance than SN;T. It indicates that POS features are effec-tive for segmentation and text normalization, and hence three tasks benefit from each other.
 The effect of the normalization dictionary The dictionary plays an important role in our model, which reduces the number of OOV words. Intuitively, the performance is higher when the coverage of dictionary is larger. In the experi-ments, the coverage of our dictionary on the devel-opment and tests are 45.8%,48.2% respectively.
To investigate the effect of the dictionary on our model, we manually construct ten dictionar-ies from our development data, with coverage be-tween 10% and 100%. Figure 3 shows the F-score curves of test set on segmentation and POS-tagging for both SNT+lm and ST+lm model by different dictionaries. With the coverage of the dictionaries increasing from 10% to 100%, the F-score generally increases. When the coverage is greater than about 20%, the F-score for joint model is higher than for the baseline model. 6.4.2 Error Analysis We found two major categories of errors. Abbre-viation is sometimes incorrectly normalised, es-pecially an informal word mapping to more than one formal word. For example, informal word  X   X  v  X  mapped to  X   X   X  v X   X  (American idol), which consists of two words:  X   X   X   X  (American) and  X  v X   X  (idol). However, our model cannot normalise the word  X   X  v  X  in the experiment. Figure 3: Results of SNT+lm and ST+lm based on different dictionaries for test set.
 Table 6: Results on the test set. ST denotes the joint segmentation and POS tagging model. S;N;T denotes the pipeline model. SN denotes the joint segmentation and normalization model. SNT de-notes the joint segmentatin. normalization and POS tagging model. lm denotes language model features. Seg-F denotes the F-Score of segmenta-tion. POS-F denotes the F-Score of POS tagging. Nor-F denotes the F-Score of normalization.

Another type of error is phonetic substitutions of numbers, which are sometimes identified incor-rectly. For example.  X 7456 X  is identified as a num-ber in the experiments, but it means  X  {  X   X  (I X  X  so angry). To settle this problem, it needs more context information. 6.5 Results of Lexical Normalization It is interesting to explore how well the joint model can normalize informal words. We compare our results with two existing systems on text normal-ization based on our annotated microblog corpus. (1) WangDT We re-implement Wang et al. (2013), which formalized the task as a classifica-tion problem and proposed rule-based and statisti-cal features to model three plausible channels that explain the connection between formal and infor-mal pairs. We use a single decision tree classifier in the experiment. (2) LYTop1 Li and Yarowsky (2008) formal-ized the task as a ranking problem and proposed a conditional log-linear model to normalization. In the experiment, we select top 1 as the standard form of informal word.

We use the same division with 1000 sentences for training and 1000 for test. The training data is used for both the WangDT and LY. We re-segment the corpus using Stanford tools for the two base-lines. WangDT uses CRF to detection informal words and LYTop1 uses the informal words de-tected using our joint model.

Although it is a little unfair for the two baselines compared with our joint model, which uses the ex-ternal knowledge -normalization dictionary. The experiments can partly reflect some conclusions. Table 7 shows the results of normalization by dif-ferent systems. The performance of our model is the best among the three systems. In particular, the precision in our SNT model improves upon the baselines significantly. The main reason is that our model is based on global features over whole sentences, while the two baselines based on local windows features. There has much work on text normalization. The task is generally treated as a noisy channel prob-lem (Pennell and Liu, 2014; Cook and Steven-son, 2009; Yang and Eisenstein, 2013; Sonmez and Ozgur, 2014) or a translation problem (Aw et al., 2006; Contractor et al., 2010; Li and Liu, 2012; Zhang et al., 2014c). For English, most recent work (Han and Baldwin, 2011; Gouws et al., 2011; Han et al., 2012) uses two-step unsuper-vised approaches to first detect and then normalize informal words. They aim to produce and use in-formal/formal word lexicons and mappings.
 In processing Chinese informal text, Wong and Xia (2008) address the problem of informal words in bulletin board system (BBS) chats by employ-ing pattern matching. Xia et al. (2005) also use SVM-based classification to recognize Chinese in-formal sentences chats. Both methods have their advantages: the learning-based method does bet-ter on recall, while the pattern matching performs better on precision.

Li and Yarowsky (2008) tackle the problem of identifying informal/formal Chinese word pairs by generating candidates from Baidu search engine and ranking using a conditional log-linear model. Zhang et al. (2014c) analyze the phenomena of mixed text in Chinese microblogs, proposing a two-stage method to normalise mixed texts. How-ever, their models employ pipelined words seg-mentation, resulting in reduced performance.
Wang and Kan (2013) propose a joint model to process word segmentation and informal word de-tection. However, text normalization is split to an-other task (Wang et al., 2013). Our joint model process word segmentation, POS tagging and nor-malization simultaneously. Kaji et al. (2014) propose a joint model for word segmentation, POS tagging and normalization for Japanese Mi-croblogs. Their model is trained on a partially an-notated microblog corpus. In contrast, our model can be trained on existing annotated corpora in standard text.

Researchers have recently developed various microblog corpora annotated with rich linguistic information. Gimpel et al. (2011) and Foster et al. (2011) annotate English microblog posts with POS tags. Han and Baldwin (2011) release a mi-croblog corpus annotated with normalized words. Duan et al. (2012) develop a Chinese microblog corpus annotated with segmentation for SIGHAN bakeoff. Wang et al. (2013) release a Chinese mi-croblog corpus for word segmentation and infor-mal word detection. However, there are no mi-croblog corpora annotated Chinese word segmen-tation, POS tags, and normalized sentences.

Our work is alse related to the work of word segmentation (Zhang and Clark, 2007; Zhang et al., 2013; Chen et al., 2015) and joint word seg-mentation and POS-tagging (Jiang et al., 2008; Zhang and Clark, 2010). A comprehensive sur-vey is out of the scope of this paper, but interested readers can refer to Pei et al. (Pei et al., 2014) for a recent literature review of the fields.

To evaluate our model, we develop an annotated microblog corpus with word segmentation, POS tags, and normalization. Furthermore, we train our model by using a standard segmented and POS tagged corpus. We also present a comprehensive evaluation in terms of precision and recall on our microblog test corpus. Such an evaluation has not been conducted in previous work due to the lack of annotated corpora for Chinese microblogs. We proposed a joint model of word segmentation, POS tagging and normalization, in which the three tasks benefit from each other. The model is trained on standard corpora, hence there is no need to re-train it for new microblog corpora. The results demonstrated that the model can improve the per-formance of word segmentation and POS tagging with text normalization on microblogs, and our model can benefit from the language statistical in-formation, which is not suitable to segment word and tag POS directly for microblogs because of the relatively low frequency of informal words.

In our model, lexical substitution is based on a normalization dictionary, which avoids the diversity of informal words, simplifying this problem for real world applications. The codes of the joint model and data set are pub-lished at the website: https://github.com/ qtxcm/JointModelNSP .
 We thank all reviewers for the insightful com-ments. This work is supported by the State Key Program of National Natural Sci-ence Foundation of China (No.61133012), the National Natural Science Foundation of China (No.61373108, 61373056, 61202193), the Key Program of Natural Science Foundation of Hubei, China(No.2012FFA088), the National Philoso-phy Social Science Major Bidding Project of China (No.11&amp;ZD189) and the Singapore Min-istration and Education (MOE) AcRF project T2MOE201301.

