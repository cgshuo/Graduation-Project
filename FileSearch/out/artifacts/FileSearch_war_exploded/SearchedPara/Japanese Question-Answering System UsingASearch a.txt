 TATSUNORI MORI Yokohama National University 1. INTRODUCTION
The technology of question-answering (QA) is widely regarded as an advance-ment on the combination of information retrieval (IR) and information extrac-tion (IE). QA systems do not provide us with the relevant documents; instead, they provide answers to questions. For example, the response of the system to the question  X  X ho is the prime minister of Japan? X  would be  X  X un-ichiro
Koizumi. X  Typical QA systems accept factoid questions X  who , when , where , what , and how (4W1H) X  X nd find answer candidates by IR techniques such as passage retrieval and IE techniques like named entity (NE) recognition [TREC Project 2001; QAC Organizing Committee 2002].

Many researchers have proposed methods to find answers based on the con-sistency between the type of question and type of NE or numeric expression in passages retrieved by an IR system [Breck et al. 1999; Sasaki et al. 2001;
Kazawa et al. 2001; Kazawa and Kato 2000; Oh et al. 2001]. However, the consistency of type itself is not a very strong basis for finding answers, because extracted passages may contain several NEs of the same type. It is possible to in-troduce an NE recognizer with finer-grained taxonomy to address the problem; however, the extracted passages might still have NEs of the same type. Hence, most QA systems consider the context of answer candidates by assigning each answer candidate a matching score that expresses the degree of consistency between the question and the context of the answer candidate. For example, many QA systems adopt the distance (or nearness) between an answer can-didate and keywords in a segment as the matching score. More sophisticated methods have been employed to improve the accuracy of scoring answer can-didates. Harabagiu et al.[2000], Murata et al.[2000], Sasaki et al.[2002], and
Kuwahara et al.[2002] proposed methods that parse each sentence in retrieved passages and construct logical forms to perform sentential matching, inference, and paraphrasing. These methods require time-consuming subprocesses, such as part-of-speech (POS) tagging, parsing, and NE recognition. If all these sub-processes are applied to all retrieved passages, the processing time will be very high and the system will be of no practical use.

In order to address the problem of response time, Prager et al.[2000] proposed a method termed predictive annotation . The system executes time-consuming subprocesses on document databases in advance and annotates the documents with extracted information. However, the method assumes that all the docu-ments are controlled by the system. Therefore, it is not applicable to documents on the WWW. Moreover, some of preprocessors have a slow processing speed. For example, although a Japanese NE recognizer based on support vector machines (SVM) yields accurate results, it is not suitable for exhaustive preprocessing of a large document database exhaustively because it is very slow.

On the other hand, Lee and Lee [2002] adopted lexico X  X emantic patterns to find candidates that are suitable for a question type and to score them. Although the method works very rapidly, it requires a large set of patterns, depending on domains. Since it is based on the result of a morphological analysis scheme of predictive annotation is still required if the amount of text in which answer candidates are searched for is too large for a morphological analyzer to process in an acceptable turnaround time.
 In order to address these problems, we have proposed a method to introduce
A  X  search control in a sentential matching mechanism for a Japanese QA system in order to reduce the turnaround time while maintaining the accuracy of the answers without any preprocessing on documents [Mori et al. 2003]. The system processes the most promising candidate first and delays the processing of other candidates. Thus, we may use accurate but time-consuming analyzers, such as an SVM-based NE recognizer. However, the mean reciprocal rank (MRR) the system is still low (approximately 0.3), as we have reported in Mori et al. [2003].

In this paper, we propose several measures of the degree of sentence matching and a variant of a voting method in order to improve the accuracy. Both of them can be integrated into our system of controlled search. We also examine the effectiveness of the newly introduced techniques at Subtask 1 of NTCIR4
QAC2, which is an evaluation workshop for question-answering systems. 2. SYSTEM OVERVIEW
An overview of the proposed system is shown in Figure 1. It has the following features.

First, several new techniques for sentential matching are introduced in order to improve the accuracy of scoring answer candidates (see Section 3). Second, the A  X  search algorithm with a two-stage scoring function was introduced in our previous work to reduce the turnaround time while maintaining the accuracy of answers, without any preprocessing on document databases. In addition, we propose several approximations of the newly introduced sentential matching score for the two-stage scoring function (see Section 4).

In the rest of this section, we describe each module of the system. 2.1 Question Analyzer
The question analyzer receives a question from a user and extracts the following information: (1) results of the morphological analysis and syntactic parsing, (2) a list of keywords (see also Section 3), (3) the question type, and (4) dependency structures of numerical expressions. Here, we define the term keywords as con-tent words in a given question. The question types, such as are estimated by a set of handcrafted patterns. If the question type is detected as a type of numerical expressions, a numerical expression extractor [Fujihata et al. 2001] is employed. It extracts a triplet ( object , attribute , numeric for each numerical expression in a sentence. For example, it outputs the triplet ( Tokyo Tower , height , 333m ) when the sentence  X  X he height of Tokyo Tower is 333 m. X  is provided (in Japanese). 2.2 Passage Extractor
Since the information related to a question is usually contained in a very small part of the document, the passage extractor segments each document into small passages and selects suitable passages that are related to keywords. In our experiment, we defined one passage as a sequence of three sentences, similar to Murata et al. [2000]. 2.3 Sentential Matcher
The input for this module is a set of sentences in retrieved passages X  retrieved sentences . The module treats each morpheme as an answer candidate and as-signs it a matching score. The matching score represents the fitness of each answer candidate for the answer. Similar to other QA systems, the score is cal-culated using the following two steps: (1) Link the answer candidate AC to an interrogative Q in a question after assuming that it is an answer. (2) Under the above condition, calculate the matching score based on the similarity between the contexts of AC and Q .

We adopt a linear combination of several subscores based on the matching score, as described in Section 3.

The output of this module is a list of n -best morphemes with scores. 2.4 Answer Generation
An answer candidate obtained by the sentential matcher is a morpheme, which may be either a word or a part of a longer compound word. In the latter case, the system finds the compound word including the answer candidate and outputs it. 3. IMPROVING ACCURACY OF JAPANESE SENTENTIAL MATCHER
Present NLP techniques require that there is some tradeoff between the ex-pressiveness of a data structure and robustness of analysis in each processing technique. Thus, we suspect that it would be difficult to develop a QA system having high precision using one monolithic method. For example, the distance scheme, in which the degree of sentential matching is represented as a function of the distance between an answer candidate and keywords of a question sen-tence that appear in a retrieved sentence, is very robust; however, the approx-imation is crude. On the other hand, the matching condition can be expressed in detail by using logical forms; however, it is difficult to extract logical forms robustly and precisely. Consequently, we believe that it is desirable that QA systems should preferably employ multiple complementary methods in order to have robustness as well as a variety of expressiveness.

Therefore, we adopt several off-the-shelf NLP techniques that treat certain different aspects of sentence. We construct a composite matching score shown in Eq. (1), which is a linear combination of the following subscores for an answer candidate AC in the i th retrieved sentence L i with respect to a question sen-tence L q having an interrogative Q : (1) the matching score in terms of 2-grams,
Sb ( AC , L i , L q ), (2) the matching score in terms of keywords, Sk ( AC , L (3) the matching score in terms of dependency relations between an answer candidate and keywords, Sd ( AC , L i , L q ), and (4) the matching score in terms of the question type, St ( AC , L i , L q ).

Sb ( AC , L i , L q ), Sk ( AC , L i , L q ), and Sd ( AC , L the similarity between the context of an interrogative Q in a question sentence
L and that of an answer candidate AC in a retrieved sentence L hand, St ( AC , L i , L q ) is a score for representing the consistency between the answer candidate AC and a question type expressed by the interrogative Q .
In the rest of this section, we first introduce a method called sentence chaining in order to apply sentential matching to a series of sentences. Subsequently, we describe each subscore in Eq. (1). 3.1 Sentence Chaining
The method proposed in the following subsections is for matching one question with one retrieved sentence, because it is difficult to precisely detect intersen-tential dependency. However, the information corresponding to one question may spread over multiple retrieved sentences. We cannot obtain correct an-swers by one-to-one sentential matching in such a situation. Therefore, we propose a method to treat multiple sentences as one sentence. In this method, each parse tree for sentences L 0 , ... , L n in an extracted passage is connected to the parse tree of the succeeding sentence, if the following condition with respect to the question sentence L q is satisfied: where KW ( L i ) is the set of keywords appearing in L when L n has new keywords that do not appear in the sequence of sentences
L , ... , L n  X  1 , and vice versa. Intuitively, when keywords in the question sen-tence are scattered over a series of sentences, we connect the sentences. We term this method as sentence chaining . In sentence chaining, the last ment of L i  X  1 is linked to the BUNSETSU segment with the Japanese topic marker  X  wa  X  X n L i . This follows from the fact that a topic marker expresses old infor-mation and the antecedent should appear in the preceding sentences. In the case where L i does not have a topic marker, the last BUNSETSU is connected to the first BUNSETSU segment of L i .

Figure 2 shows an example of sentence chaining. The keywords of the ques-tion sentence X  Medaka , Gakkou (a part of a song name), and sakushisha (a lyric writer) X  X re distributed over two sentences L 0 and L would like to treat those sentences as one sentence in order to calculate appro-priate scores for answer candidates in the sentences. Equation (2) shows the condition when we treat the sentences as one sentence for score calculation. Since the condition is satisfied in this case, the root node of the parse tree of
L 0 is linked up to the BUNSETSU segment with the topic marker wa in the parse tree of L 1 . 3.2 Matching in Terms of Keywords
The matching score in terms of keywords, Sk , is calculated based on the num-ber of keywords shared by a question and a retrieved sentence. If a matched keyword has the same case marker, 4 an extra score is added.

Equation (3) defines the score Sk ( AC , L i , L q ) for an answer candidate AC in a retrieved sentence L i with respect to a question L q where the function KW case ( L ) returns a set of keyword, case marker pairs in the sentence L . The constants C k and C c are mixing factors in the composite score of (1). c AC is the case marker of the AC . The functions SKW ( AC , L and SKWC ( AC , L i , L q ) return the set of keywords and the set of keyword, case marker pairs shared by the question L q and the retrieved sentence L respectively. Therefore, the first term of Eq. (3) corresponds to the score in terms of the number of keywords shared by a question and retrieved sentence. The second term expresses the extra score that is assigned when shared keywords have the same case markers in both a question and retrieved sentence.
We assume that the function w ( k ) is a weighting function of keyword k , ac-cording to a certain global weighting method. In the worst case, however, we may not use any global term weighting methods because we assume that docu-ments are available only through an external search engine. Therefore, in the rest of this paper, we set the constant value 1 to the value of w ( k ) for any key-word k . If we can use information on a global term weight, such as the inverse document frequency (IDF) available from a search engine, the information may be incorporated as the function w ( k ). 3.3 Matching in Terms of 2-Grams
The matching score in terms of 2-grams is calculated according to the number of character 2-grams shared by a retrieved sentence and a question. where s and e are the character positions of the start and end of an AC in L returns the number of times that x appears in y . The function len ( x ) returns the length in characters of the string x . The binary relation j returns the substring of x that begins at the i th character of x and ends at the j th character. 3.4 Matching in Terms of Dependency Structure
Unfortunately, Japanese parsers are not precise enough to generate complete logical forms. 5 Therefore, we would like to choose only the necessary parts of a syntactic tree in a robust manner. Accordingly, we only use information about the position of an answer candidate relative to keywords in a dependency structure. It is important to note that the distance between two words in a surface expression is not suitable for measuring the distance between two words in Japanese; this is because the order of BUNSETSU segments is relatively flexible.
Here, we propose a new vector representation of a dependency relation in a parse tree. It represents information on the relative position of two words in a dependency relation as a two-dimensional vector in the following manner.
First, we extract a dependency relation between an answer candidate AC and each keyword K i in a retrieved sentence. The relative position of AC to K then represented as a dependency vector DV ( AC , K i ), as shown in Figure 3.
A dependency vector is a two-dimensional vector that represents the relative position between two nodes in a parse tree, i.e., a dependency tree. The first element of the dependency vector DV ( AC , K i ) is the distance between AC and
LCA , the lowest common ancestor of AC and K i . The second element is the distance between K i and LCA . The distance is defined as the number of edges between two nodes. Similarly, we can obtain a dependency vector DV ( Q , K for a question sentence, where Q is an interrogative in the sentence.
Using dependency vectors, we calculate the similarity between dependency structures of two sentences. More precisely, we utilize dependency vectors to measure the similarity between the relative position of an interrogative Q to keywords K 1 , ... , K n in a question sentence and the relative position of an answer candidate AC to the keywords in a retrieved sentence, in terms of how relevant the AC is to the answer of the question. First, the similarity between the dependency relation of a Q to a keyword K i in the question sentence L and that of the AC to K i in the retrieved sentence L measures of the appropriateness of AC . The appropriateness can be represented as a function of the distance between two dependency vectors DV ( Q , K DV ( AC , K i ). In this paper, we adopt Eq. (4) as such a function.
Second, the nearness between an answer candidate and keywords can also be regarded as a measure of the appropriateness of the AC , which can be calculated as the length of the dependency vector. In this paper, we adopt Eq. (5) as such a measure.

Considering these two measures of structural similarity, we define a measure of the degree of matching between the dependency structures of the AC in the retrieved sentence L j and that of Q in the question sentence L
An example of the calculation of Sd 1( AC i , Q , K ) is shown in Figure 4. In this example, we assume that the words  X  shusho  X  (prime minister) and  X  dare  X  (who) in the question sentence L q are one of the keywords K and the target interrogative Q , respectively, and AC 1 , ... , AC 5 are answer candidates. First, dependency vectors for Q and AC i ( i = 1, ... , 5) are derived, after which each value of Sd 1( AC i , Q , K ) is calculated. As a result, we find that AC
BUNSETSU segment including the word  X  Koizumi  X  in the sentence L appropriate answer candidate in this example, in terms of the score function Sd 1( AC i , Q , K ).

The vector representation also makes transformation rules of the de-pendency structure very concise. In Japanese, an interrogative word may appear at not only the same position as the corresponding word in a declar-tion sentence may have a different dependency structure from a declarative sentence, some transformation of questions is necessary to improve the re-call of answers. For example, answers to the question (a) in Figure 5 may be found in declarative sentences corresponding to the question (c). However, the dependency structures of (a) and (c) are different from each other. We need a certain transformation that generates a dependency structure identical to the declarative sentence from a question sentence, as shown in (b) in the figure.

Since in our method, the calculation of the structural similarity between two dependency structures is reduced to the calculation of dependency vectors de-fined in Eq. (6), such a transformation can be represented as a set of simple rewriting rules of dependency vectors. Although the structural transformation raising an interrogative phrase, they are simply expressed as one rewriting op-eration of the dependency vector shown in (d). Finally, we obtain the rewriting rule in Figure 5(e). If the rule is applicable, we calculate the similarity score
Sd 1( AC , Q , K i ) for not only the original dependency vector, but also the rewrit-ten dependency vectors and adopt the larger value as a final score. Although currently we have only five types of rules, as shown in Figures 6, 7, and 8, we can easily add such rules when we find new structures of question sentences and declarative sentences. It should be noted that a transformation of a dependency tree may increase the score of an incorrect answer candidate that happens to have a dependency vector similar to that of the transformed dependency tree.
This may result in a decrease in precision. 3.5 Matching in Terms of Question Type
The matching score St ( AC , L i , L q ) in terms of the question type is calculated as follows. First, a question type is estimated by the type of the interrogative and other clue expressions. According to the question type, one of three semantic type analyses is performed. If the question type is in an entity class such as
PERSON , all retrieved sentences are passed to an NE recognizer to find named entities. The matching score is calculated according to the consistency between the NE type and question type.

Second, when the question type is supported by our numerical expression extractor, such as LENGTH , a set of patterns is used to filter answer candidates that are not numerics or do not have suitable unit expressions. Each retrieved sentence L j with a suitable numeric is then passed to the extractor to obtain matching score for an answer candidate is defined in Eq. (8) based on the simi-larity of surface expression between the triplet ( Obj j , Attr ( Obj q , Attr q , Q ) extracted from a question sentence L where the function shared char ( s 1 , s 2 ) returns the number of characters shared by both strings s 1 and s 2 . Therefore, the function R s represents the similarity of objects and attributes between two triplets in terms of the surface expression. The parameter  X  num (0  X   X  num to which the result of the numerical expression extractor is considered. The constant C num is a mixing factor in Eq. (1).

Third, if the question type belongs to any other simple numeric expression such as DATE , a set of patterns is applied to retrieved sentences to filter out an-swer candidates that are not numerics or do not have suitable unit expressions. 4. A  X  SEARCH ALGORITHM FOR SENTENTIAL MATCHING
It is very inefficient to perform all score calculations uniformly for each answer candidate. Since a single subprocess in sentential matching has dependency on certain other subprocesses, the calculation of the matching score for an answer candidate can be broken down into a series of execution of several subprocesses in the order of the dependency. Therefore, we have proposed a sentential match-ing method with a controlled search, which first processes the most promising answer candidate. The control also works effectively in finding n -best candi-dates.

All subprocesses to be applied to one answer candidate can be represented as a path of the search tree (shown in Figure 9), if we assume the correspondence shown in Table I.

In Figure 9, a node at processing level 1 represents the state of an an-swer candidate whose subscore Sb ( AC , L i , L q ) has been exactly calculated but other subscores have not been calculated. The transition from level 1 to level 2 corresponds to the execution of morphological analysis and the calculation of
Sk ( AC , L i , L q ). In level 2, only the subscores Sb ( AC , L of an answer candidate are exactly calculated. The transition from level 2 to level 3 corresponds to the execution of dependency analysis and calculation of
Sd ( AC , L i , L q ). In level 3, only the subscores Sb ( AC , L and Sd ( AC , L i , L q ) of an answer candidate are exactly calculated. In the fi-nal level, i.e., level 4, all the subprocesses of score calculation are completed.
The transition from level 3 to level 4 corresponds to the execution of the NE recognition or numerical dependency analysis.

In the A  X  search, the estimated score  X  S ( AC , n ) of an answer candidate AC at processing level n is represented as the following summation of the exact (real) score S 1 ( AC , n ) obtained until level n and the score an estimated score for the rest of the subprocesses. where we omit L i and L q for conciseness. The candidate with the highest score will be processed in the next turn. In order to find the best answer, the estimated score has to satisfy the following condition:
If this condition is not satisfied, it is not guaranteed that the search will find the optimal solution. In such a situation, the search is called  X  X  search X  instead of  X  X   X  search. X  It should be noted that our heuristic function does not represent a cost, which is widely used in search problems; instead, it represents a score. The optimal solution is the one with the highest value. Accordingly, the heuristic score function  X  S 2 ( AC , n ) must never underestimate the score of moving from a particular state to the goal state. If we use an underestimating heuristic score, the score of the optimal solution may be lower than it really is and lower than the estimated scores of some other solutions. Therefore, the algorithm may choose a suboptimal solution over the optimal one. On the other hand, if we use an overestimating heuristic, it may cause expansion of nodes that are not optimal; however, as the real score of that path becomes known, a truly optimal path will become preferred.

One of the simplest methods to estimate the score of a candidate is to adopt the maximum value of possible scores. Using this estimation, the best answer can always be obtained because condition (11) is satisfied. However, the estima-tion cannot effectively prune hopeless candidates because the estimated scores of many candidates remain high. Thus, we introduce a more precise approxi-mation of the score in the next step and revise the estimated score follows: where  X  S a 2 ( AC , n ) is a more precise approximation of the score for the next step, and  X  S b 2 ( AC , n ) is the sum of maximum scores of steps in the rest of the path.
If the approximation score  X  S a 2 ( AC , n ) for the next step can be calculated with some small additional cost, we can prune the candidates with low possibility in earlier stages.
 5. APPROXIMATED SCORES OF SENTENTIAL MATCHING
In this section, we discuss methods of calculating approximated scores for matching subscores in Section 3. 5.1 Approximated Score of Keyword Matching
Once keywords and their postpositional particles in a question are extracted by the question analyzer, we need a morphological analysis to judge whether or not a retrieved sentence includes each keyword and its postpositional particle. The calculation of an approximated score must be performed at a lower cost than morphological analysis. Therefore, we adopt a simple string match to judge whether or not the string of each keyword occurs in the string of a retrieved sentence. This approximation satisfies condition (11). 6 5.2 Approximated Score of Matching of Dependency Structure
In order to calculate the matching score Sd ( AC , L j , L ture given by Eq. (6), we need not only the dependency vectors DV ( Q , K question sentence L q but also the dependency vectors DV ( AC , K sentence L j . However, it is difficult to precisely estimate dependency structures without parsing. Thus, we use the information on (1) occurrence of keywords, (2) boundaries of BUNSETSU segments, and (3) cases of BUNSETSU can be derived from the result of POS tagging along with the dependency vec-tors DV ( Q , K i )of L q , which have already been obtained by question analysis.
The approximation consists of the following two stages. 5.2.1 First Approximation. The first approximation is performed before morphological analysis. The approximated score of Sd ( AC , L by calculating the right-hand side of Eq. (6) under the assumption that all keyword strings in the retrieved sentence L j are in complete matching with respect to the question sentence L q . A keyword K i is said to be in complete matching when the keyword satisfies the following relationship:
In other words, in the above approximation, we suppose that the unknown dependency vector DV ( AC , K i ) of a retrieved sentence L dependency vector DV ( Q , K i ) of a question sentence L by this method satisfies condition (11). 5.2.2 Second Approximation. The second approximation is based on the estimation of boundaries of the BUNSETSU segment after morphological analysis.
Using the boundaries, we can also estimate the number of BUNSETSU between an answer candidate AC and a keyword K i as well as the case marker of each BUNSETSU segment. This information can be used to refine the first ap-proximation as follows.
 Relative position of AC to K i . In Japanese sentences, a have a dependency relation only with one of other BUNSETSU appear after it.
 is satisfied, it is obvious that the keyword K i is not in complete matching: where pos r ( X ) is the position of the morpheme X in a retrieved sentence.
In this case, the first approximation is obviously an overestimation, and we can revise the score. The revision is performed as follows: (1) enumerate all dependency structures that are possible under the constraint of the relative position of AC to K i in the retrieved sentence L j , (2) calculate the scores
Sd ( AC , L j , L q ) of all enumerated dependency structures by using Eq. (6), and (3) find the best score, which is a revised estimation of Sd ( AC , L
Number of BUNSETSU segments n B between AC and K i . If the following re-lationship is satisfied, it is obvious that the keyword K matching.

In such a case, we can also revise the score by determining another estimation of the dependency relation with the second best score in the same manner as steps (1), (2), and (3) described in the section  X  X elative Position of AC to
K i . X  The estimated score does not satisfy condition (11), because of possible errors in BUNSETSU segmentation.

The cases of BUNSETSU segments . Matching score for case markers can be es-timated according to the candidate of case marker assumed in the segmentation. The estimated score does not satisfy condition (11), because of possible errors in the BUNSETSU segmentation and the estimation of cases. 5.3 Approximated Score of Matching of Question Type 5.3.1 Named Entity. Each score of the following answer candidates is given based on the following result of morphological analysis: (1) Candidates whose detailed POS information is consistent with the question type. didates that consist of KATAKANA characters or alphabets (because they are pos-sibly loanwords).

Since named entities that do not satisfy the above conditions exist, the esti-mated score does not satisfy condition (11). 5.3.2 Numerical Expression. The numerical expression extractor is ap-plied to each answer candidate that matches one of the patterns correspond-ing to a question type. Thus, each of those candidates is assigned the score that is calculated on the assumption that the triplet of the candidate com-pletely matches that of the question. This approximation satisfies condition (11). 6. PSEUDO VOTING METHOD IN SEARCH SCHEME Many existing QA systems exploit global information on answer candidates.
In particular, redundancy is the most basic and important information. For example, there are previous studies that boost the score for answer candidates that occur multiple times in documents [Clarke et al. 2001; Xu et al. 2003]. This is known as the voting method . Web search engines are also utilized to obtain redundancy information, such as the number of hits of the answer candidates on the Web [Magnini et al. 2002].

On the other hand, we cannot exploit the voting method directly in our scheme of searching answers, because it quits searching after n -best answers are found. Therefore, we introduce an approximation of the voting method, termed pseudo voting , as follows. Our method continues searching for an-swers until n different answer candidates are found in case n -best answers are found. In other words, n different answer candidates reach the goal state, where all of subscores are actually calculated. Therefore, the system may find other answer candidates that have the same surface expression as one of the answer candidates that have already reached the goal state. Conse-quently, we can partially use the frequency information of answer candidates by recording all that have reached the goal state in the search process. Here, we define the pseudo voting score S v ( AC , L q ) for an answer candidate AC as follows: where Ans List is the list of answer candidates that have reached the goal state. 7. EXPERIMENTAL RESULT
In this section, we describe the experimental results obtained from Subtask 1 of NTCIR4 QAC2. NTCIR QAC is a series of evaluation workshops dealing with
Japanese question answering, organized by the National Institute of Informat-ics, Japan. The last workshop, called NTCIR4 QAC2, was held in June 2004 [Fukumoto et al. 2004]. The test collection of NTCIR4 QAC2 Subtask 1 consists of 195 questions prepared by QAC2 task organizers. For each question, the participating systems were expected to extract five (exact) answer candidates from the document set. The performance of the systems was evaluated using the MRR. 8 We conducted the following experiments under the conditions shown in
Table II with the test collection of QAC2 Subtask 1. 9 We also used 200 questions of QAC1 Formal Run [Fukumoto et al. 2002] in order to develop the system.
Each passage in the experiments consists of a series of three sentences. 7.1 Experiment 1: Evaluation of Performance with Respect to System Parameters
Since there are several system parameters, we would like to examine the rela-tionship between the setting of the system parameters and performance includ-ing accuracy and turnaround time. In this experiment, we examine the MRR and turnaround time by varying the values of the system parameters shown in Table III.

The result is shown in Figure 10. We have plotted two lines for the turnaround time. The first is the turnaround time that includes the processing time of an external search engine, while the second excludes the processing time of an external search engine. 7.2 Experiment 2: Evaluation of Effectiveness of Proposed Matching Techniques
With regard to the scoring method for answer candidates, the main contri-bution of this study lies in (1) matching of the dependency structure defined by Sd ( AC , L i , L q ) in Eq. (6), (2) sentence chaining described in Section 3.1, and (3) pseudo voting method described in Section 6. In order to evaluate the effectiveness of these matching techniques, we prepared systems in which one function is suppressed, and examined (1) their accuracy on the basis of
MRR, (2) the average precision of the first answer candidate, and (3) the ratio of the number of questions whose answers are found within the top five answer candidates. As a baseline, we also prepared a system that uses a naive scoring function based on the distance between an answer candi-date and a keyword, as many existing QA systems do. We may regard such types of scoring methods as an approximation to the matching for the de-pendency structure and sentence chaining. The baseline adopts the scoring
Sd ( AC , L i , L q ) for the dependency structure, but does not use the pseudo voting method: where the function Dist ( AC , k ) returns the distance between AC and k , that is, the number of morphemes between AC and k plus one.

The result of comparison is shown in Figure 11, where the parameter setting is a = 5/d = 250/ppd = 5/p = 50, which achieves the best performance in the experiment described in Section 7.1.

We also conducted the Wilcoxon matched pairs signed rank sum test to check the statistically significant difference between the system with all features and other systems in terms of the reciprocal rank. First of all, the proposed method is statistically significantly superior to the baseline ( p Regarding the improvement in each matching technique, the sentence chaining statistically significantly improves the reciprocal rank ( p other methods do not. 7.3 Experiment 3: Evaluation of Effectiveness of Proposed Search Control
We compare the following systems in terms of the MRR value and the average processing time to search one or five (different) answer candidates. No control . A system with no search control.

A  X  (Max. only) . A system with A  X  search controlled by only the maximum scores.

A  X  (Approx. + Max.) . A system with the proposed A  X  search control, which is controlled by approximated scores and maximum scores.

The result is shown in Figure 12, where the parameter setting is a 5/d = 250/ppd = 5/p = 50. 7.4 Experiment 4: Comparison of A  X  Search Control with Other Controls
We also compare systems based on the following search control methods in order to examine the effectiveness of A  X  search control in our scheme. A  X  . The proposed A  X  search control.
 SP A . A search control based on  X  X ype-A X  simple pruning.
 SP B . A search control based on  X  X ype-B X  simple pruning.

The systems SP A and SP B retain answer candidates whose scores exceed a certain threshold after each matching stage, and prune the other candidates. For n -best answers, the system SP A , based on Type-A pruning, selects the n -best candidates from the remaining candidates in the final stage. On the other hand, the system , based on Type-B pruning, selects the best (one) candidate in the final stage and then, restarts the search from the first stage for the second best candidate, etc., by maintaining the list of all candidates. 10 The threshold is assigned as a ratio of the score of the candidate to the maximum score of all remaining candidates. The ratios are selected so as to make the average processing time of each system comparable with that of the others. The result of the comparison is shown in Figure 13, where the parameter setting is a = 5/p = 50.

We also conducted the Wilcoxon matched-pairs signed rank sum test to check the statistically significant difference between the proposed method and other search controls in terms of the reciprocal rank. The result shows that there is no statistically significant difference between the proposed method and other search controls. 8. DISCUSSION
With regard to the parameter setting in Experiment 1, Figure 10 shows the correlation between the accuracy and number of documents to be retrieved. In general, the larger the parameter  X  X , X  the higher is the accuracy. We should pay attention to the fact that the MRR at d = 400 is slightly degraded in comparison with that at d = 250. One of the reasons is that the probability that sentences in unrelated documents have higher score increases as the number of documents increases. The parameter  X  X , X  which is the number of passages to be considered, shows the same tendency as the parameter  X  X . X  In the case of the parameter  X  X , X  which denotes the number of answers to be searched for, the setting of a almost same as that of a = 5. This implies that the pseudo voting method may work well even if the number of answers to be searched for is not much larger than the necessary number of answers. From the viewpoint of both accuracy and turnaround time, the setting a = 5/d = 250/ppd = 5/p = experiment, at least for the QAC2 Formal Run. At this setting, MRR is 0.516 and the average turnaround time is 16.1 s (excluding the processing time of an external search engine).

In Figure 11 of Experiment 2, we observe that each proposed matching tech-nique has an effect on improving accuracy. In particular, the sentence chain-ing method described in Section 3.1 is statistically significant. Regarding the matching of dependency structures, the score based on the  X  X ifference X  between dependency vectors is also useful, along with the score based on the  X  X um X  of dependency vectors; the latter score is superior to the former one. This implies that the distance between a keyword and an answer candidate is not a unique measure to represent the goodness of matching. This fact is also supported by the low MRR of the baseline system (distance only) in Figure 11, which adopts a naive scoring function based on the distance between keywords and an an-swer candidate. Moreover, the pseudo voting method and transformation rules also have an effect, to some degree, although the ratio of the number of ques-tions whose answers are found within the top five answer candidates is slightly degraded when the transformation rules are used.

Figure 12 of Experiment 3 shows that the proposed system [A (Approx. + Max.)] is 12.0 times (for one candidate) and 5.8 times (for five dif-ferent candidates) faster than a system with no search control. The proposed system is also 2.1 times (for one candidate) and 1.7 times (for five candidates) faster than the system controlled by only maximum scores. The ratio of the processing time to search for only the first candidates is greater than that to search up to the fifth candidate.

In the case of MRR values, our algorithm is not guaranteed to find the optimal solution because the calculation of some subscores may not satisfy condition (11). However, Figure 12 empirically shows that the MRR value of the proposed method is not lower than that of the strategy  X  A  X  (Max. only), X  which satisfies the condition and is guaranteed to find the optimal solution. value of the strategy  X  X o control X  may appear to be strange. This is because of an undesirable effect of the voting method. In the setting of the strategy  X  X o control, X  the system calculates the scores for all answer candidates in all retrieved passages, that is, 150 sentences in the experiment. However, the set of passages may contain not only sentences relevant to a question but also irrelevant sentences. An answer candidate whose surface expression appears many times in comparison to other answer candidates may have a higher score by voting, even if its original score is not so high. We need some threshold values of the score to eliminate unpromising answer candidates. On the other hand, in the strategies based on the A  X  search, pseudo voting is applied only to n -best answers and it reranks them appropriately.

As shown in Figure 13, the proposed system achieves a higher MRR value than other systems based on simple pruning when the average processing time is the same as that of other systems, although the difference is not sta-tistically significant. We can also find that the difference is larger when we search for a smaller number of answer candidates. It shows that the simple pruning methods cannot reduce the processing cost as effectively as the A search. 9. CONCLUSION In this paper, we introduced several techniques to a QA system based on the
A search in order to improve the accuracy of finding answers. Based on the experiments in NTCIR4 QAC2 Subtask 1, we confirmed that the system using those techniques achieves a higher MRR than the systems in which one of the techniques is suppressed. The MRR value of the system is 0.516 when we tune the parameters.

From the viewpoint of computational cost, the absolute average processing time should be reduced to a greater extent, although our controlled search suc-cessfully manages the tradeoff between computational cost and accuracy. One of the reasons is that the main part of the experimental system is implemented in Perl, which is a script language. The reimplementation in other program-ming languages that generate native code would be effective. Introduction of a caching mechanism to reuse the result of subprocesses would also achieve good results, because some subprocesses, such as the NE recognizer we used in this study, are very time consuming. In our future work, we would like to explore these challenges. We express our gratitude to Masahiro Shiga, Tomoharu Ohta, Katsuyuki
Fujihata, and Ryutaro Kumon, who developed the earlier versions of the sys-tem. We are also grateful to the task organizers of NTCIR4 QAC2 and people who manage the NTCIR workshops. We would like to especially thank Mainichi
Shimbun and Yomiuri Shimbun for permitting us to use the documents for research. Finally, we would like to thank the anonymous reviewers for their helpful comments.

