 Marta Rukoz  X  Maude Manouvrier  X  Genevi` eve Jomier Abstract This article presents the -distance, a family of distances between images re-cursively decomposed into segments and represented by multi-level feature vectors. Such a from an image segmentation process. It handles positional information of image features (e.g. color, texture or shape). -distance is the generalized form of dissimilarity measures between tween nodes, distances between trees or visual similarity between images can be computed families: two families of distances between tree structures, called and S -distance ( S for Segment ), and a family of visual distances between images, called V -distance ( V for Visual ). The V -distance visually compares two images using their tree representation and the other two distances compare the tree structures resulting from image segmentation. Moreover, we show how existing distances between multi-level feature vectors appear to be particular cases of the -distance.
 Keywords Image database . Distance between quad/quin or nona-trees of images . Similarity of image segments . Content-based image retrieval 1. Introduction Content-Based Image Retrieval (CBIR) consists in retrieving images similar to a query image from an image database. Usually, in CBIR systems (Antani et al., 2004; Kherfi et al., 2004; Smeulders et al., 2000), the query is an image of the database and the query result is an ordered set of similar images rather than a set of images that exactly match the query image. content such as color (Smith, 2002; Stehling et al., 2002), texture (Manjunath et al., 2002; Rubner et al., 2001) or shape (Chakrabarti et al., 2000; Kimia, 2002). The similarity measure depends on user X  X  criteria and on the representation of image features (Li et al., 2002). In 1999; Rubner et al., 2001) such that proximity in the multi-dimensional space reflects the similarity of the images. A feature vector of the query image is computed and all the images of the database, whose feature vectors satisfy the similarity criterion, are presented as the query result (Albuz et al., 2000).

Each image feature may have several representations (Li et al., 2002), i.e. several nu-merical representations of their descriptors, also called signatures. Generally, images are characterized by global signatures (e.g. the color histogram of the entire image). However, as explained by Shyu et al. (1998), global characterization alone cannot ensure satisfactory retrieval results for many application areas, for example in the medical domain. Moreover, global signatures ignore spatial relationship between pixels or regions (group of pixels). A simple example is represented in Fig. 1. Using a global color signature and thus ignoring the To overcome this limitation, several approaches (Ahmad et al., 2003; Albuz et al., 2000; 2000; Lin et al., 2001; Lu et al., 1994; Luo et al., 2003; Malki et al., 1999; Remias et al., 1997) recursively decompose images into equal-sized segments and represent each image by a data structure, based on quadtree (Samet, 1984) or on related tree structures, quin or nodes store the features of each corresponding image segment. The root node stores the global et al., 1994; Manouvrier et al., 2005): each image is compared with the query image using their global signature and if they are similar enough (according to a given threshold and to a similarity metric), then the corresponding image segments are compared, and so on, level by level. For example, using such multi-level signatures with images of Fig. 1, two sets of similar images are retrieved: the first one containing the first four images and the second one containing the last two images. A multi-level feature vector can be also used to compute pattern search which consists in retrieving images from the database having segments similar to the segments selected by the user in a query image.

All the aforementioned approaches measure the image similarity using a distance between multi-level feature vectors. All the distances used in these approaches could be generalized. exists. In this article, we present -distance, a generalization of distances between images represented by multi-level feature vectors. -distance is defined as a linear combination of distances between tree nodes. Using different parameters to compute -distance, different precisely, two families of distances between tree structures, called and S -distance ( S for Segment ), and a family of visual distances between images, called V -distance ( V for Visual ), appear. The V -distance family visually compares two images, other two distance families compare the tree structures resulting from an image segmentation process.
 -based distance families T , S and V . Section 5 shows several experimental results. Section 6 compares the proposed distances with other approaches. Finally, Section 7 draws some conclusions. 2. Basic concepts Several content-based image retrieval approaches (Ahmad et al., 2003; Albuz et al., 2000; 2000; Lin et al., 2001; Lu et al., 1994; Luo et al., 2003; Malki et al., 1999; Remias et al., 1997) deal with the same image search process. Firstly, the images from the database are recursively decomposed into several equal-sized segments. The number of resulting image segments could be fixed (see Section 2.1) or produced by an image segmentation process (see Section 2.2). Secondly, each image is represented by a tree storing the feature vectors computed using a distance between image trees. To be comparable, two images must have homologous segments (or homologous nodes in their corresponding tree representation), i.e. segments with the same location in both images (or nodes with the same location in both trees). This section presents how images could be recursively decomposed and represented by such a tree structure. 2.1. Recursive image partition An image could be recursively decomposed into equal-sized segments. Using a quadtree de-composition (Samet, 1984), an image is recursively decomposed into four non-overlapping segments. Figure 2(a) shows an example. The first segment (identified by numeral 0) repre-sents the entire image. At level 1, the image is decomposed into four segments (identified by 00, 01, 02 or 03), following the North-West (NW), North-East (NE), South-West (SW) and South-East (SE) directions. If the decomposition is stopped after two iterations, level 2 contains 16 image segments. This kind of decomposition is used in Ahmad et al. (2003), Using a quin-tree, an image is recursively decomposed into five overlapping segments. This kind of decomposition is used in Park et al. (2000). Using a nona-tree decomposition, the nona-tree decomposition of the Lena image. If the decomposition is stopped after two In Remias et al. (1997), Sheikholeslami et al. (1999) and Wang W et al. (2003), a nona-tree is used for content-based image retrieval.

Several types of decomposition can be mixed. For example, Luo et al. (2003) combine a nona and a quadtree decompositions: level 1 of the image decomposition contains nine segments whereas the second level results from a quadtree decomposition containing only 16 sub-segments. 2.2. Image segmentation by recursive decomposition The aforementioned image decomposition could be used to segment images according to a given split criterion. For example, in Fig. 3, the black-and-white Lena image, on the left of Figure 3, is segmented using a quadtree decomposition (a quin or nona-tree decomposition could have been be used). In this example, the segmentation of an image segment is stopped when the color homogeneity is equal to 90%. This kind of image segmentation can also be used for colored image. A color image can be represented by several color layers, each layer split criterion examples of such decomposition-based segmentation are texture homogeneity (Sheikholeslami et al., 1999), shape approximation (Chakrabarti et al., 2000) or a maximal number of feature points in each image segment (Ahmad et al., 2003). The decomposition type (quad, quin or nona) must be the same for all the images of the database, in order to be able to compare the images. However, depending on the split criterion, the number of the resulting segments per image and the number of levels per tree are indeterminate and are not the same for all the images. Moreover, this kind of image representation should be improved if it is preceded by image registration techniques (Gottesfeld Brown, 1992). 2.3. Multi-level feature vectors Image segments resulting from an image partition (see Section 2.1) or an image segmentation is a leaf when its corresponding image segment conforms to the split criterion; otherwise the node is internal or non-terminal. The tree resulting from the image segmentation is unbal-anced. Figure 5 presents an example of four quadtrees representing the color segmentation of the four first synthetic images of Fig. 4. To make explanations clear, we use a specially simple case of synthetic binary images where the split criterion which stops the subdivision of an image segment is homogeneity according to the pixel color, black or white. Moreover, in the following, to simplify the figures, only quadtrees are represented. Nevertheless, all figures and explanations can obviously be extended to any recursive image decomposition.
Depending on the image representation, internal nodes of trees can store different kinds of quadtree (see underlined values in Fig. 5). In Ahmad et al. (2003), images have a symbolic representation and are recursively decomposed into a spatial arrangement of feature points in
Several approaches (Climer et al., 2002; Gupta et al., 1997; Jomier et al., 2005; Kim et al., 2000; Lin et al., 2001; Lu et al., 1994; Luo et al., 2003; Malki et al., 1999; Wang Z et al., 2003) represent each image by a tree having a fixed number of levels (usually a full a combination of color and texture captured via histograms (Malki et al., 1999) or several each quadtree node contains the color histogram of the corresponding image segment. For instance, the histogram labeled 00 corresponds to 00 segment, given by the first subdivision of the image. Histograms stored in each child node (labeled 000 to 003) of quadtree node 00 correspond to the four sub-segments of segment 00 (at the top of the right side in Fig. 6).
In the following, we call such a tree structure (based on image segmentation or using a distance between images represented by multi-level feature vectors. 3. Distances between multi-level feature vectors This section presents the -distance, a generalized distance between multi-level feature vec-trees resulting from a fixed and arbitrary image partition. In this article, we extend the -extension allows to define several -based distance families (presented in Section 4). Sec-tion 3.1 defines distances between tree nodes used in -distance. Finally, a general formal definition of -distance is given in Section 3.2 and specific cases of -distance are presented in Section 3.3. Table 1 (pp. 7) summarizes the notation symbols used in this article. 3.1. Distances between homologous tree nodes We define a distance between tree nodes. Let  X  ( i ,  X   X  [0 , 1], between homologous nodes n ( n  X  N ) in trees i and j . For instance, denotes the normalized distance between homologous nodes labeled 033 in trees i and j .
The  X  -distance can be chosen among any existing distance (Di Ges  X  u et al., 1999; Rubner et al., 2001) computed between the image features contained by tree nodes. The choice of depends on the value stored in each tree node. If images are represented by multi-level color histograms (see Fig. 6), then  X  can be chosen among any distance between color histograms X  see in Smith (2002) and Stehling et al. (2002) for more details about these distances. When the visual features of the image segments are represented by d -dimensional vectors (stored in the corresponding tree nodes),  X  can be any distance of the Minkowski L distance between two feature vectors u = ( u 1 , u 2 ,... homologous segments n of images i and j , it computes the distance between the feature vector contained in each homologous nodes n .

As explained above, when two homologous nodes n are both leaf or internal, is leaf in the other one, say j , three alternatives appear: 1. all children of the internal node n in tree i ,  X  ( i , j node n , exist in tree i but do not exist in tree j ( n is a leaf in tree j ).  X  (1 , 3 , 033) = 1. Moreover,  X  (1 , 3 , 033 x ) = 1, with x do not exist in tree 3. 2. The value of the internal node n of tree i can be computed by aggregation of values coming stored in the internal node n is used to compute a lower bound of the distance between both corresponding sub-trees rooted by n in trees i and j (the sub-tree rooted by n is a leaf in tree j ). Let  X  be this lower bound.
 with  X  = L 1 , the well known  X  X ity-block X  distance:  X  (1 3. Leaf node n in tree j can be artificially replaced by a sub-tree: we call this operation specialization , in contrast to the case of the previous item 2. The leaf node n of tree j becomes internal during the distance computation, having four, five or nine children ac-cording to the split criterion and depending on the tree structure (quad, quin or nona-tree).
After this specialization, both sub-trees rooted by node n in trees i and j have the same structure; all internal nodes have the same location in both subtrees and all leaf nodes have the same location in both subtrees. Thus,  X  ( i , j , n ) internal nodes n are not taken into account. The  X  -distance can be computed between all homologous children of node n which exist in tree i and are artificially created in tree j .
For example in Fig. 5, if during the computation of  X  ( i ternal in quadtree 3, having four black leaf children, then ogous nodes 003 are internal).  X  (1 , 3 , 0330) =  X  (1 , 3 three nodes are white in tree 1, whereas they are black in tree 3) but (homologous nodes 0333 are black in both trees). 3.2. General definition of -distance -distance is a normalized distance between images represented by multi-level features: the smaller the -distance between the multi-level feature vectors is, the closer or the more similar the images are. The definition of -distance is general and allows to distinguish families of distances between multi-level feature vectors.

The -distance between two images i and j , represented by multi-level feature vectors, is defined as a sum of normalized  X  -distances between homologous nodes n in trees i and j , weighted by w n , w n  X  0: trees i and j .
  X  j , as defined in Section 3.1  X  w n is the weight of tree node n in the -distance computation. The choice of weights depends on the user needs. For example, if several image segments do not have to appear in the -distance computation, then they must be associated with computation must take into account the image segment surface, then each weight be proportional to the surface represented by segment n in relation to the surface of the entire image. Weights w n allow to define particular cases of -distance.  X 
W is the sum of all weights w n : W = -distance is normalized by the denominator W (at least one zero):  X  [0 , 1]. Below we only consider normalized distances.
 Remark 1. As  X  n  X  N ,  X  ( i , j , n )  X  0, ( i , j ) = 0 if and only if  X  ( i , j , n ) = 0 and ( i , j ) = 1 if and only if  X  n  X  N w n is a metric distance because it is a linear combination of metric distances between homol-(1) ( i , i ) = 0 (reflexivity) because  X  n  X  N ,  X  ( i , (2) ( i , j ) = ( j , i ) (symmetry) because  X  n  X  N ,  X  ( i (3) ( i , i )  X  ( i , j ) + ( j , i ) (triangle inequality) because as 3.3. Specific cases of -distance According to the choice of weights w n and/or the choice of the become a ( ) -distance, taking into account only nodes appearing from the root level to a 3.3.2 and 3.3.3), or a pattern distance, called p -distance (see Section 3.3.4). The exact value of the -distance between two sub-trees is obtained by an exhaustive com-parison of both sub-trees. It can be progressively approximated by comparing both sub-trees et al., 2003) -see in Manouvrier et al. (2005) for more details about multi-level filtering. ( ) ( i , j ) is defined as the -distance between multi-level feature vectors i and j , where for all nodes n ( n  X  N ) appearing from root level (level 0) to a level , for all nodes n appearing in a deeper level ( &gt; ), w n is computed without taking into account details after a certain point, i.e. the information contained in lower-level tree nodes.

For any given level  X  1 in two multi-level feature vectors of images i and j : N ( k ) is the set of node identifiers appearing at level k . account only both tree roots, i.e. the feature vectors stored in the root nodes of the image trees i and j . ( ) -distance is an increasing function of : For any given level  X  1 in multi-level feature vectors: can be used to approximate -distance. This approximate feature vector could be computed from statistical methods (e.g. color moment). In these cases, -distance can be approximated by associating w n  X  0 with all nodes n appearing at level and by associating null weights ( w n = 0) with the other nodes.
 by the following formula: In this formula, nodes n appear at level in both trees of images i and j ( n is interesting when the choice of weights w n preserves the inequality: ( ) ( i , j )  X  ( + 1) ( i , j ). When the images of the database are segmented (see Section 2.2), and then are represented and v j n allows to compute a lower bound of the distance between subtrees rooted by node n node n in trees i and j (see Item 2 in Section 3.1). For instance using L defined by the following formula: The previous formula is interesting when the choice of weights For example, in Fig. 5, each internal node n of quadtree i has a value, said quadtree with the same number of levels, v i n  X  [0 , 1]). For leaf node n , is black, and v i n = 0 when its color is white. For internal nodes 033, 03 and 0, one child of node 003 is black in quadtree 1), v 1 03 = 1 the 16 possible nodes of a two-levels full quadtree), and are represented underlined in Fig. 5. If  X  = L 1 , then:  X   X  (1 , 3 , 033) =| 1 / 4  X  1 |= 3 / 4. 3.3.4. p -distance Let p be a pattern being composed of segments selected by the user among the segments possible to compute the distance between homologous patterns p in two images by giving values w n = 0 only for tree nodes representing the pattern p . Let between image trees i and j , where for all nodes n representing pattern p , w n = 0 for the other tree nodes. When pattern p contains only one image segment n , then ( i , j ) =  X  ( i , j , n ).
 available for each segment of pattern p , independently from any other segment. To avoid one representing a geometric transformation of the initial one. For example, in Malki et al. from a translation of the bounding box (see ( e ) in Fig. 7). 4. -based distance families According to the weights w n and the choice of the  X  -distance, several families of distances particular, we call T a distance between two tree structures without using leaf node values X  values X  X ee Section 4.2. Another distance, called V , allows to visually compare two images using only distances between the leaf nodes of their trees X  X ee Section 4.3. As described in Section 3.3, distances T , S or V could be computed level by level (defining distances ( T p , S p and V p ) could be defined. 4.1. T -distance of one image, according to two different split criteria, matches.
 Let T -distance be this family of distances. Two images i and j have a zero (
T in both trees, likewise leaf nodes are in the same location in both trees. For example images 1 and 7 in Fig. 4 have a zero T -distance ( T (1 , 7) = 0), because image 7 is the complement of image 1 then both trees have the same structure (quadtree of image 1 is represented in Fig. 5).
 To compute a T -distance between images, both images must be segmented (see Section 2.2) and not arbitrary decomposed into a full-balanced tree (otherwise T -distance computation between two image multi-level feature vectors i and j , distance has only two possible values:  X  the same value) in trees i and j .  X  n exists only in one tree and does not exist in the other one.
 Because, the value of the leaves are not considered, defining a lower bound of meaningless. However T -distance can be computed level by level, using a For example, if in Fig. 5 all weights w n are equal  X  n  X  N quadtrees 1 and 3 differ in five nodes (the subtree rooted by 033):  X  (1 , 3 , 033 x ) = 1, with x  X  X  0 , 1 , 2 , 3 } . On the other hand, the 1 to 3 is: T (1) (1 , 3) = 0, because the difference between both quadtree structures appears 1 and 3 do not have the same type (both internal or both leaf) up to level 2.
During the T -distance computation, the values of the leaves are not considered, thus two images having a zero T -distance can be visually completely different (for instance images 1 values. 4.2. S -distance S ( i , j ) = 0, when both membres of all couples of homologous nodes have the same type (internal or leaf) and the same value in both trees. During two image multi-level feature vectors i and j , the  X  -distance has several possible values:  X   X  ( i , j , n ) = 0 when homologous nodes n are both internal or both leaves with the same value in trees i and j .  X  other tree or when a node n exists only in one tree and not in the other one.  X  values of homologous nodes n .
 As in the previous family distance, any weight w n can be chosen. When when weights w n are equal  X  n  X  N , S ( i , j ) corresponds to the proportion of homologous nodes having different values in the multi-level feature vectors of images i and j .
This paragraph presents several examples of the S -distance computation. In these exam-nodes values are only taken into account when S -distance is computed. The between images 1 and 7 of Fig. 4, whose T -distance is zero (image 7 is the complement of image 1), is: S (1 , 7) = 10 / 13. Indeed, internal nodes have a (they are located at the same position in both trees); (with  X  = L 1 ). The S -distance between images 1 and 2 of Fig. 5 is:  X  (1 , 2 , 0330) = 1. The other homologous nodes have the same values or are both internal in both quadtrees:  X  (1 , 2 , 0) =  X  (1 , 2 , 0 x ) =  X  (1  X  (1 into account leaf node values) appears only at level 3. However, using the approximate values of internal nodes appearing at level 2, with  X  = L 1 : S (2) (1
Several approaches, presented and compared in Manouvrier et al. (2002), propose to store similar images organized in quadtrees. Their main goal is to reduce the memory space used by image quadtrees by sharing common parts between quadtrees. As a consequence, the S -distance can be used in these approaches to organize the images in a hierarchy: an S ( i node values between their trees is X  X ee in Manouvrier et al. (2002) for more details. However, two images i and j with two very different multi-level feature vectors, i.e. may appear visually similar: for example, using the split criterion of color homogeneity, a totally white image and a white image with only one black pixel. Image 5 and 6 in Fig. 4 node which is a white leaf. Thus, it is useful to define a visual distance distance based on -distance. 4.3. V -distance We call V -distance the family of distances between images represented by multi-level feature vectors, based on the perceptual features of image visual content. The computation of the V -distance between trees i and j requires their T -distance being zero (i.e. both trees having the same structure -T ( i , j ) = 0). Therefore, when images are segmented and their trees are unbalanced, it requires homogenizing the structure of both quadtrees i and j , either by generalization or by specialization of nodes (see Section 3.1). The computation of takes only into account the  X  -distances between leaf nodes; nodes n (internal node have the same location in both quadtrees i and j because
To visually compare images i and j , weights w n associated with leaf nodes n should be proportional to the surface of the corresponding image segments n . Thus, entire image is 1 (see examples below). The deeper the position of node n in the multi-level feature vector, the smaller the value of the weight w n .
 For example, images 5 and 6 in Fig. 4 have a V -distance equal to: the black region of image 6 represents 1/256 of the entire image surface. On the other hand, the V -distance between images 1 and 7 is: V (1 , 7) = 1, because image 7 is the complement of image 1. The V -distance between image quadtrees 1 and 2 is: (1 / 64) = 1 / 64 because  X  (1 , 2 , 0330) = 1 (other  X  distances are equal to zero) and 4 3 . The V -distance between segment 033 in images 1 and 2 is: only node 0330 differs between sub-quadtrees 1 and 2 rooted by node 033.

To compute the V -distance between images 1 and 3, both quadtrees 1 and 3 must have the same structure: node 033 in quadtree 3 must be divided up to level 3 (into four black node children) during the distance computation. Thus V (1 , 3)  X  (1 , 3 , 0332))  X  (1 / 64) = 3 / 64 = 0 . 05 (because  X  (1 images 1 and 3 up to level 2, is: V (2) (1 , 3) =| 1  X  1 / subtree is 1/4) and nodes of level 2 represent 1/16 of the image surface. 5. Experimental results This section is organized in the following way. In order to better understand the different uses of -distance, Section 5.1 presents several experimental results based on segmented images. In Section 5.2, -distance between images represented by full-balanced multi-level feature vectors are compared with a color distance based on global signature. The following experimental results are limited to images represented by quadtrees. However, they could be extended to any related structures (e.g. quin or nona-trees). 5.1. Different uses of -distance This subsection presents several experimental results showing how the different -distance families, presented in Section 4, can be used. In order to better understand those different families, we have developed a prototype implementing the proposed -distances. It is written in C ++ programming language on a Linux platform and is based on PANDORE processing library.
 images, from National Oceanic and Atmospheric Administration (NOAA) Photo Library and from the Content Based Image REtrieval System (CIRES). are represented in Fig. 10. To conduct experiments, we have considered a contrast-based quadtree decomposition, i.e. a quadtree node is a leaf when the difference between the higher otherwise the node is internal. Each quadtree node (internal and leaf) contains an average color value corresponding to the average luminance of the image segment. The between quadtree nodes computes the normalized difference between node values (  X  n  X  N , w n = 1 for the T and S -distances, and w n = 4  X  ( n appearing at level ) for the V -distance.

Figure 9 shows experimental results on the synthetic images of Fig. 4 compared with the query image q of Fig. 8. As shown in this figure, quadtrees of q and quadtrees of images 1, 2, 7 and 8 have the same structure ( T ( q , i ) = 0 with i is more different between image q and images 7 and 8 ( S ( q between image q and the two first images ( S ( q , i ) &lt; framed by a dotted line rectangle in the third line). Moreover, the visual distance image q and images 7 and 8 tends to 1 whereas it is below 0 differs totally from the quadtree of the query image q ( T 7and8( V ( q , 5) &lt; V ( q , 7) &lt; V ( q , 8) X  X ee in line 5).
 Differences between images could appear at several levels. For example, is equal between image q and images 1, 2 and 4 (see underlined distances). On the other hand, the S -distance between those images differs when the distance computation takes into account the quadtree levels which are below level 2: S ( q corresponds to the black quadrants of the query image q (corresponding to quadrants 00, 030, 0330 and 0333), then the results of V p -distance computation show that: image 4 con-tains exactly the same black pattern ( V p ( q , 4) = 0 X  X ee distances framed by a dotted line rectangles in the last line), images 1 to 3 contains a similar pattern ( i
Figure 10 presents the different similarity ranks between several pairs of real colored images, using the different -distance families, T , S and query images. The first line represents the result images. Each cell of the matrix contains three values, each one corresponding to the letter of the distance used ( by the rank of the image in the query result. For example, value second column means that image 2 is the fifth image of the result set when the query image is image 1 and when the T -distance is used.

The image ranks depend on the -distance used. For example, when the query image is image 1, the first image returned by the query is image 4 for the the image 7 for both S and V -distances. When the query image is image 3, the first returned image is always the same (i.e. image 4) for all the distances. As shown in Fig. 10, the rank of image 4 is always one for all the query images, when the to the contrast-criterion used to the image decomposition, the the tree structure (i.e. the localization of the homogeneous regions). Using the (i.e. comparing the tree structure and the value of tree nodes), the rank of image 4 does not change when the query image is image 7. On the other hand, when the query image is image 6, the first returned image, using both S and V -distance is image 7. 5.2. Comparing the S -distances with a color distance based on global signature When images are represented by full-balanced multi-level feature vectors (see Section 2.3) and internal nodes store values, only V -distance or S -distance are meaningful, whereas balanced multi-level feature vectors, using the S -distance-based CBIR prototype of Jomier et al. (2005), are presented in this subsection. This prototype has been implemented in Java, using the DBMS Oracle 9.i, so that the content-based query could be easily written in SQL. External Java procedures compute the S -distances. The experimental database contains a mixture between 2120 fine-art images 4 and 155 butterfly images. is decomposed into 21 segments, using a quadtree-based decomposition. Each segment is represented by a nine-dimensional feature vector representing the first three color moments. Each tree node stores the feature vector of the corresponding image segment. Figures 11(b) and (c) present two query examples showing that The query image is on the left X  X ee in Figure 11(a). It appears in the first position in both Figure 11(b) presents the result image obtained using a color distance based on the global the height returned images. Moreover, three fine-art images appear in the result at different ranks (ranks 2, 4 and 6). On the other hand, the result is better when the distance is only computed between the first four image segments (i.e. computing in Fig. 11(c). In this case, only butterfly images are returned. Moreover, the three images the importance of the weight choice and the image registration.

Figure 12 shows recall and precision values obtained using different image classes. Several to an original image. Other images may correspond to an original image after a rotation. About 12 images of the database have been processed, resulting from approximatively 10 processed images for each original one. A class of images contains an original image and all the images resulting from image processing operations applied to this original image. For each class, we compare the results obtained using a distance between global signatures (called without S ) and using the S -distance (called with result images are similar to the query image without taking into account the color location (even rotated images are considered similar to the query image). The second kind of query is of the query, then rotated images are not considered similar to the query image. As shown on the top of Fig. 12 for  X  X lobal search criterion, X  computing a result in better recall or better precision values than without any depending on the image classes. However, the average value of as shown on the bottom of Fig. 12, for  X  X attern search criterion X  (then taking into account the color location in the images), computing S -distance always gives equal or better recall and precision results. 6. Related work Multi-level feature vectors are used in several Content-Based Image Retrieval approaches (Ahmad et al., 2003; Albuz et al., 2000; De Natale et al., 2001; Gupta et al., 1997; Jomier 1999; Remias et al., 1997) in order to capture the spatial composition of features (color, texture, shape) in images. Using well-chosen values of weights obtained several existing similarity measures from the -distance. Table 2 summarizes these particular cases of the -distance.

For instance, De Natale et al. (2001) characterize each image segment by its dominant color (i.e. the color with the higher percentage of occurrences inside the image segment). The image segments result from a quadtree decomposition where the maximum and the minimum block sizes are fixed: quadtrees are unbalanced. To compare the segmented images of the database, these authors propose a similarity combining a Quadtree Structure Similarity (QSS) and a Quadtree Color Similarity (QCS). The proposed similarity QSS is evaluated through the number of changes needed to be performed in order to make one image quadtree equivalent to another one. The distance between two images i and j , obtained by computing 1  X  QSS ( i , j ), is similar to a T -distance with w nodes n = 00. The similarity QCS is computed after homogenizing the structure of both of all homologous leaf nodes. The distance between to two images i and j , obtained by computing 1  X  QCS ( i , j ), corresponds to a V -distance with  X  ( i , j , n ) &gt; 0 for the other nodes n = 00.

Ahmad et al. (2003) characterize images by a set of feature points and organized them by unbalanced quadtrees whose leaf nodes contain at least one feature point. The quadtrees of all the images of the database are compared with the query image quadtree using a distance between the proportion of feature points stored in each node n . Each weight to the proportion of feature points in the sub-quadtree rooted by n in comparison with the total number of feature points in the entire quadtree. In Jomier et al. (2000) and Manouvrier to optimize the storage of similar image clusters.
 by a full fixed-depth balanced quadtree. Depending on the approach, each node of the balanced quadtree contains a color histogram, an average color vector or a nine-dimensional based on the first three color moments, characterizing the colors of the corresponding segment in the image. The distance between images, used in Lu et al. (1994) and Lin et al. (2001), is a V ( ) -like distance where w n is a surface coefficient equal to 4 distance between each color vector stored in homologous nodes n appearing at level . The distance is computed by comparing the image quadtrees level by level: The top-level color vectors are first compared. If they match using some threshold value, the next level will be levels provide a better discrimination power. Moreover, in the DISIMA Image DBMS Oria et al. (2001), sub-image queries can be answered using selected portions of the multi-scale color histograms. This kind of distance can be defined using a (2003), a V ( ) and a V p distances are used to visually compare images represented by nona-trees storing the mean and the covariance color of the corresponding image segments. As explained in Section 5.2, distances S , S p and S ( ) are used in Jomier et al. (2005).
Malki et al. (1999) also represent each image by a full fixed-depth balanced quadtree. This approach allows performing segment queries. Image signatures are computed systematically on each image segment (and stored in quadtree nodes) and a dedicated similarity measure is computed allowing retrieving images with similar segments. For performing such a query, the user has to select several segment at a chosen level in a query image. A minimum bounding box of all the selected image segments is defined (see Fig. 7). Each image of the database is then compared to the initial query image and the query images obtained after a translation of the bounding box containing the image segments selected by the user. Each image segment corresponding to a quadtree node is associated with a high dimensional feature vector. The size, thus all nodes n representing the selected segments have the same value of weights w n are zero for the other nodes n which do no represent the image segments selected by the user. Remias et al. (1997) also use a V p image segment selected by the user among all image segments resulting from a nona-tree representation of the images and where  X  is a texture-based distance.

In Kim et al. (2000), a shape is divided into four sub-regions by two principal axes cor-responding to the two eigenvectors at the center of mass of the shape. Each sub-region is subdivided into four sub-regions in the same way. The sub-division process is repeated a pre-determined number of times. A fixed-depth balanced quadtree representation with its nodes corresponding to regions of the shape is derived from the above process. Four parameters, invariant to translation, rotation and scale, are computed for the corresponding regions of each node while two parameters are extracted from the root node. The shape descriptor is represented as a vector of all parameters (reading the quadtree following a breadth first or-der). The similarity distance used to compare two shapes is a L -distance between quadtree nodes, and where w n is equal for all nodes n . 7. Conclusion This article has presented the -distance, a generalization of similarity distances defined on images recursively decomposed into segments and represented by a tree structure (quad, quin tree-based distances proposed by Ahmad et al. (2003), De Natale et al. (2001), Kim et al. et al. (1997) appear as particular cases of distance ; (2) It allows to define new distances between images. Moreover, the proposed distances can be computed using any split criterion of image trees and storing any value in the tree nodes (color value, color histogram, texture representation, signature, matrix of pixels and so on.). Thus, depending on values stored in et al., 1999; Li et al., 2002; Rubner et al., 2001) based on image features (color, texture, or shape) can be used to compare homologous nodes. The  X  -distance between homologous tree nodes may be chosen among measures based on color image retrieval techniques (Smith, dissimilarity measures (Rubner et al., 2001).

As explained in Sections 3.1 and 3.3.4, depending on the feature vectors stored in tree segment independently of each other. To overcome this limitation, the query image could be modified to represent several geometric transformations of the initial query image. For our experimental results (see in Section 5.2), the -distance must be used when the spatial position of features is an important criterion for the image similarity.

The -distance is more time-consuming than any global distances between global feature vectors: the time used is proportional to the number of image segments resulting from the image decomposition. To accelerate query evaluation, index structures can be used to filter images using the first level of their trees (if the root nodes contain an approximate value of their rooted tree) before comparing the other levels. As explained by Lin et al. (2001), but no false dismissals. Then entire tree comparisons are only done for the images contained (2001) or a quadtree-like structure in Jomier et al. (2005).

We are working on several issues. First, the -distance is proposed in this paper to compare images decomposed in trees using a split criterion. This proposition can be generalized in representing the -distance between two images i and j organized in trees according to a to fix the right weights w n and to choose the  X  -distance between image segments, depending on the query they want and on the images of their database. At the end, this prototype could also be used to compare similar approaches (Ahmad et al., 2003; Albuz et al., 2000; De Malki et al., 1999) by implementing their common characteristics. Indeed, until now, it is difficult to really compare the performances of these approaches because their prototypes are not always accessible and are generally based on different frameworks. This article, by generalizing the distances used, gives the first bricks to develop such a prototype. References
