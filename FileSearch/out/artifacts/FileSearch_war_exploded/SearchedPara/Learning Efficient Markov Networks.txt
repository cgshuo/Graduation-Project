 Markov networks (also known as Markov random fields, etc.) ar e an attractive class of joint prob-ability models because of their generality and flexibility. However, this generality comes at a cost. Inference in Markov networks is intractable [25], and appro ximate inference schemes can be un-reliable, and often require much hand-crafting. Weight lea rning has no closed-form solution, and requires convex optimization. Computing the gradient for o ptimization in turn requires inference. Structure learning  X  the problem of finding the features of th e Markov network  X  is also intractable [15], and has weight learning and inference as subroutines.
 Intractable inference and weight optimization can be avoid ed if we restrict ourselves to decomposable Markov networks [22]. A decomposable model can be expressed as a product of distributions over Markov network can be converted into a decomposable one by tr iangulation (adding edges until every Goldman [13] proposed a method for learning Markov networks without numeric optimization based limiting the applicability of this method. More recently, a series of papers have proposed methods complexity of inference (and typically of learning) is expo nential in the treewidth, only models of wide applicability.
 Fortunately, low treewidth is an overly strong condition. M odels can have high treewidth and still allow tractable inference and closed-form weight learning from a reasonable number of samples, by exploiting context-specific independence [6] and determin ism [7]. Both of these result in clique dis-tributions that can be compactly expressed even if the cliqu es are large. In this paper we propose a pendence and determinism [7, 26, 11] have a common structure : they search for partial assignments to variables that decompose the remaining variables into in dependent subsets, and recurse on these problem into smaller (nearly) independent subproblems, an d stops when the data does not warrant further decomposition.
 Decomposable models can be expressed as both Markov network s and Bayesian networks, and state-of-the-art Bayesian network learners extensively exploit context-specific independence [9]. How-ever, they typically still learn intractable models. Lowd a nd Domingos [18] learned tractable high-treewidth Bayesian networks by penalizing inference compl exity along with model complexity in a standard Bayesian network learner. Our approach can learn exponentially more compact models by exploiting the additional flexibility of Markov networks , where features can overlap in arbitrary ways. It can greatly speed up learning relative to standard M arkov network learners because it avoids weight optimization and inference, while Lowd and Domingos  X  algorithm is much slower than stan-dard Bayesian network learning (where, given complete data , weight optimization and inference are already unnecessary). Perhaps most significantly, it is als o more fundamental in that it is based on identifying what makes inference tractable and directly ex ploiting it, potentially leading to a much Lowd and Domingos X  algorithm lacks.
 We provide both theoretical guarantees and empirical evide nce for our approach. First, we provide underlying distribution. These results rely on exhaustive search over features up to length k . (The treewidth of the resulting model can still be as large as the n umber of variables.) We then propose greedy heuristics for more efficient learning, and show empi rically that the Markov networks learned in this way are more accurate than thin junction trees as well as networks learned using the algorithm in practice translates into more accurate query answers). We make this assumption for simplicity of exposition; our an alysis extends trivially to multi-valued variables.
 We begin with some necessary definitions. An atomic feature o r literal is an assignment of a value to a variable. x denotes the assignment x = 1 while  X  x denotes x = 0 (note that the distinction between an atomic feature x and the variable which is also denoted by x is usually clear from context). A features or literals, e.g., x be assigned the value 0 . Often, given a feature F , we will abuse notation and write V ( F ) as F . A Markov network or a log-linear model is defined as a set of pai rs ( F and w where V is a truth-assignment to all variables V =  X  F , and 0 otherwise, and Z is the normalization constant, often called the partition function . Next, we define junction trees. Let C = { C (a)  X  m contained in C D i.e.,  X  C one. The set S The space complexity of representing a junction tree is O ( P m Our goal is to exploit context-specific and deterministic de pendencies that is not explicitly repre-sented in junction trees. Representations that do this incl ude arithmetic circuits [10] and AND/OR graphs [11]. We will use a more convenient form for our purpos es, which we call feature graphs . In-ference in feature graphs is linear in the size of the graph. F or readers familiar with AND/OR graphs [11], a feature tree (or graph) is simply an AND/OR tree (or gr aph) with OR nodes corresponding to features and AND nodes corresponding to feature assignment s.
 D
EFINITION 2. A feature tree denoted by S T is a rooted-tree that consists of alternating levels of feature nodes or F-nodes and feature assignment nodes or A-n odes. Each F-node F is labeled by a feature F and has two child A-nodes labeled by 0 and 1 , corresponding to the true and the false assignments of F respectively. Each A-node A has k  X  0 child F-nodes that satisfy the following requirement. Let {F of all variables involved in the features associated with F { 1 , . . . , k } , i 6 = j, D ( F A ,i )  X  D ( F A ,j ) =  X  .
 Semantically, each F-node represents conditioning while e ach A-node represents partitioning of the variables into conditionally-independent subsets. The sp ace complexity of representing a feature tree is the number of its A-nodes. A feature graph denoted by S trees of a feature tree S any model that can be represented using a junction tree havin g treewidth k can also be represented exponentially smaller than a junction tree because it can ca pture context-specific independence [6]. A feature tree can be easily converted to a Markov network. Th e corresponding Markov network has The following example demonstrates the relationship betwe en a feature tree, a Markov network and a junction tree.
 E
XAMPLE 1. Figure 1(a) shows a feature tree. Figure 1(b) shows the Marko v network corresponding for the Markov network given in 1(b). Notice that because the feature tree uses context-specific 64 potential values while the feature tree given in Figure 1(a) requires only 10 A-nodes. without loss of generality, because a feature graph can be co nstructed by caching information and merging identical nodes, while learning (constructing) a f eature tree. The distribution represented by a feature tree S details see [11]). We assume that each leaf A-node A A-node A and each F-node F , we associate a value denoted by v ( A ) and v ( F ) respectively. We compute these values recursively as follows from the leaves to the root. The value of all A-nodes is constraint M ( A an internal F-node is the sum of the values of the child A-node s. The value of an internal A-node A (the division takes care of double counting). Let v ( F described above. Let V be an assignment to all variables V of the feature tree, then: where v initialized instead to w ( A from the root to A Algorithm 1 : LMIP: Low Mutual Information Partitioning We propose a feature-based structure learning algorithm th at searches for a feature that divides the configuration space into subspaces. We will assume that the s elected feature or its negation divides the (remaining) variables into conditionally independent partitions (we don X  X  require this assumption In practice, the notion of conditional independence is too s trong. Therefore, as in previous work For this we use the LMIP subroutine (see Algorithm 1), a varia nt of Chechetka and Guestrin X  X  [8] LTCI algorithm that outputs a partitioning of V . The runtime guarantees of LMIP follow from those of LTCI and correctness guarantees follow in an analogous fa shion. In general, estimating mutual information between sets of random variables has time and sa mple complexity exponential in the number of variables considered. However, we can be more effic ient as we show below. We start with a required definition.
 D
EFINITION 3. Given a feature assignment F , a distribution P ( V ) is ( j,  X , F ) -coverable if there exists a set of cliques C such that for every C ( j,  X , F = 1) -coverable.
 L
EMMA 1. Let A  X  V . Suppose there exists a distribution on V that is ( j,  X , F ) -coverable and | V | (2  X  +  X  ) .
 Lemma 1 immediately leads to the following lemma: L partitioning of V into disjoint subsets { Q 1)  X  ) .
 We summarize the time and space complexity of LMIP in the foll owing lemma.
 L
EMMA 3. The time and space complexity of LMIP is O ( n cardinality q .
 Note that our actual algorithm will use a subroutine that est imates mutual information from data, and the time complexity of this routine will be described in t he section on sample complexity and probabilistic performance guarantees.
 Algorithm 2 : LEM: Learning Efficient Markov Networks Next, we present our structure learning algorithm called LE M (see Algorithm 2) which utilizes the LMIP subroutine to learn feature trees from data. The algori thm has probabilistic performance guar-antees if we make some assumptions on the type of the distribu tion. We present these guarantees in sible features of length k constructible from V . Recall that given a feature assignment F , the LMIP sub-routine partitions the variables into (approximately ) conditionally independent components. It of the model, we should try to balance the trade-off between i ncreasing the number of partitions and maintaining partition size uniformity (namely, we would wa nt the partition sizes to be almost equal). The following score function achieves this objective. Let Q = { Q then the score of Q is given by: Score ( Q ) = 1 inference complexity.
 After selecting a feature G , the algorithm creates a F-node corresponding to G and two child A-nodes corresponding to the true and the false assignments of G . Then, corresponding to each element of Q interesting special case is when either | Q In this case, no partitioning of V exists for either or both the value assignments of G and therefore the remaining variables. In practice, because of the expone ntial dependence on | V | , we would want this condition to hold only when a few variables remain. To ob tain guarantees, however, we need stronger conditions to be satisfied. We describe these guara ntees next. 3.1 Theoretical Guarantees To derive performance guarantees and to guarantee polynomi al complexity, we make some funda-coverable, then the LMIP sub-routine is guaranteed to retur n at least a two-way partitioning of V . didate features that satisfy this property. Therefore, we want this coverab ility requirement to hold not only recursively but also for each candidate feature (at each recursive call). The following two definitions and Theorem 1 capture this intuition.
 D ment F of F , such that | V ( F ) |  X  m , P ( V ) is ( j,  X , F ) -coverable and for any partitioning S of satisfy the ( j,  X , m, G  X  F ) assumption.
 D isfies the nested context independence condition for (  X , w ) if  X  i, S tion on V conditioned on the satisfaction of G T
HEOREM 1. Given a distribution P ( V ) that satisfies the ( j,  X , m, true ) -assumption and a perfect mutual information oracle I , LEM( V , S , I , k , j + 1 ,  X  ) returns a feature tree S feature of S 3.1.1 Sample Complexity and Probabilistic Performance Gua rantees The foregoing analysis relies on a perfect, deterministic m utual information subroutine I . In real-ity, all we have is sample data and probabilistic mutual info rmation subroutines. As the following theorem shows, we can get estimates of I ( A, B | F ) with accuracy  X   X  and probability 1  X   X  with a L
EMMA 4. (Hoffgen [14]) The entropy of a probability distribution ov er 2 k + 2 discrete vari-ables with domain size R can be estimated with accuracy  X  with probability at least 1  X   X  using strengthen our assumptions, as we define below.
 D
EFINITION 6. If P ( V ) satisfies the ( j,  X , m, true ) -assumption and a set of sample data H drawn from the distribution is such that for any G less than some constant fraction c of the subset of H that satisfies G the c -strengthened ( j,  X , m, true ) assumption .
 T
HEOREM 2 ( Probabilistic performance guarantees ) . Let P ( V ) be a distribution that sat-c -strengthened ( j,  X , m, true ) assumption from which we draw S samples of size T = ( j + 1 ,  X  +  X  ) returns a feature tree, the leaves of which satisfy the nest ed context independence condition for (  X , j  X  (  X  +  X )) , with probability 1  X   X  . When implemented naively, Algorithm 2 may be computationall y infeasible. The most expensive step in LEM is the LMIP sub-routine which is called O ( n k ) times at each A-node of the feature graph. Given a max set size of q , LMIP requires running Queyranne X  X  algorithm [23] (comple xity is not available in practice and one has to compute I ( X, V \ X | F ) from data. In our implementation, we used Moore and Lee X  X  AD-trees [19] to pre-compute and cach e the sufficient statistics (counts), in advance, so that at each step, I ( X, V \ X | F ) can be computed efficiently. A second improvement subset of a connected component Q  X  Q because merging all Q entirely problematic for our approach because we may still b e able to induce large treewidth models by taking advantage of context specific independence, as dep icted in Figure 1.
 To further improve the performance of our algorithm, we fix q to 3 and use a greedy heuristic to LMIP k  X  n times instead of O ( n k ) times, but does not have any guarantees. It starts with a set of atomic features (i.e., just the variables in the domain), runs LMIP on each, and selects the (best) loosely based on the greedy approach of Della Pietra et al.[1 2]. We also use a balance heuristic to reduce the size of the model learned; which imposes a form of r egularization constraint and biases similar scores, we select a feature F such that the difference between the scores of F = 0 and F = 1 of remaining variables is smaller than 5 . This is because even though a feature may not partition the set of variables, it may still partition the data, thereby re ducing complexity. We evaluated LEM on one synthetic data set and four real world ones. Figure 2(f) lists the five data sets and the number of atomic features in each. The synthetic domain consists of samples from the Alarm Bayesian network [3]. From the UCI machine learning re pository [5], we used the Adult and MSNBC anonymous Web data domains. Temperature and Traffic ar e sensor network data sets and were used in Checketka and Guestrin [8].
 et al.[12] (henceforth, called the DL scheme), the L1 approa ch of Ravikumar et al. [24] and the lazy thin-junction tree algorithm (LPACJT) of Chechetka an d Guestrin [8]. We used the following value of  X  used. We suggest using any reasonably small value  X  0 . 1 . The LPACJT implementation available from the authors requires entropies (computed fr om the data) as input. We were unable to compute the entropies in the required format because they us e a propriety software that we did not have access to, and therefore we use the results provided by t he authors for the temperature, traffic and alarm domains. We were unable to run LPACJT on the other tw o domains. We altered the DL algorithm to only evaluate candidate features that match at least one example. This simple extension vastly reduces the number of candidate features and greatly improves the algorithm X  X  efficiency. For implementing DL, we use pseudo-likelihood [4] as a scoring f unction and optimized it via the limited-memory BFGS algorithm [17]. For implementing L1, we used the OWL-QN software package of Andrew and Gao [1]. The neighborhood structures for L1 can be merged in two ways (logical-OR or regularization, we tried penalty = { 1, 2, 5, 10, 20, 25, 50, 100, 200, 500, 1000 } and used a tuning set to pick the one that gave the best results. We used a time-b ound of 24 hrs for each algorithm. For each domain, we evaluated the algorithms on training set sizes varying from 100 to 10000. We performed a five-fold train-test split. For the sensor netwo rks, traffic and alarm domains, we use the test set sizes provided in Chechtka and Guestrin [8]. For the MSNBC and Adult domains, we selected a test set consisting of 58265 and 7327 examples res pectively. We evaluate the performance based on average-log-likelihood of the test data, given the learned model. The log-likelihood of the test data was computed exactly for the models output by LPACJ T and LEM, because inference is tractable in these models. The size of the feature graphs lea rned by LEM ranged from O ( n 2 ) to O ( n 3 ) , comparable to those generated by LPACJT. Exact inference o n the learned feature graphs log-likelihood approximately using loopy Belief propagat ion [20].
 Figure 2 summarizes the results for the five domains. LEM sign ificantly outperforms L1 on all the domains except the Alarm dataset. It is better than the greed y DL scheme on three out of the five domains while it is always better than LPACJT. Figure 2(f) sh ows the timing results for LEM, DL and L1. L1 is substantially faster than DL and LEM. DL is the sl owest scheme. We have presented an algorithm for learning a class of high-t reewidth Markov networks that admit tractable inference and closed-form parameter learning. T his class is much richer than thin junction trees because it exploits context-specific independence an d determinism. We showed that our algo-we move further away from the root), is itself representable by a polynomial-sized feature graph and in which the maximum feature-size at each node is bounded by k . We believe that our new theoretical insights further the understanding of structure learning i n Markov networks, especially those having high treewidth. In addition to the theoretical guarantees, we showed that our algorithm has good performance in practice, usually having higher test-set li kelihood than other competing approaches. Although learning may be slow, inference always has quick an d predictable runtime, which is linear dependent datasets.
 Acknowledgements This research was partly funded by ARO grant W911NF-08-1-024 2, AFRL contract FA8750-09-C-0181, DARPA contracts FA8750-05-2-0283, FA8750-07-D-018 5, HR0011-06-C-0025, HR0011-07-C-0060 and NBCH-D030010, NSF grants IIS-0534881 and IIS-08 03481, and ONR grant N00014-08-1-0670. The views and conclusions contained in this docu ment are those of the authors and should ARO, DARPA, NSF, ONR, or the United States Government.
