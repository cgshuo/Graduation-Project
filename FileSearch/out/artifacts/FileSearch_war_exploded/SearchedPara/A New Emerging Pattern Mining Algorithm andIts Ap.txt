 The main goal of a supervised classification algorithm is to build a model based on a representative sample of the problem classes [1]. This model can be used to predict the class of new objects or to gain understanding of the problem domain. In many cases, the result of the classific ation is not enough; the user could need to understand the classification model and the classification results, mostly if the classification disagrees with the expected results.

Many accurate classifiers, like Neural Networks [2] or Support Vector Ma-chines [3], are unable to explain their classification results in terms understand-able by an application expert. Emerging Pattern classifiers, on the other hand, build accurate and easy to understand models. An emerging pattern is a com-bination of feature values that appears mostly in a single class. This way, an emerging pattern can capture useful cont rasts among the problem classes [4], which can be used to predict the class of unseen objects.

Emerging pattern classifiers are very valuable tools to solve real problems in fields like Bioinformatics [5], streaming data analysis [6], and intruder detec-tion [7].

Current methods for finding Emerging Patterns in a database have two main drawbacks:  X  Global discretization of numerical attributes, which could seriously degrade  X  High sensitivity to the support threshold value, which makes very hard for In this paper, we introduce the Crisp Emerging Pattern Mining (CEPM), a novel algorithm to find emerging patterns, which does not apply global discretiza-tion of numerical attributes. CEPM extrac ts patterns using a special procedure, from a collection of C4.5 decision trees. T o find a representative collection of patterns, our algorithm uses a novel ob ject weighting scheme. CEPM applies local discretization, using only such attribute values appearing in the objects on each tree node. Additionally, CEPM finds an accurate estimation of the min-imal support threshold, testing differe nt values decrementally. It starts from a high enough value and ends when the thres hold attains the expected abstention ratio. CEPM returns a set of emerging patterns with the highest support value associated with the lowest e xpected abstention ratio.

The rest of the paper is organized as fo llows: Section 2 presents a brief revi-sion about classification using emerging patterns, Section 3 introduces the new algorithm for mining emerging patterns without global discretization, Section 4 presents the algorithm to estimate the minimal support threshold, Section 5 shows the experimental results, and S ection 6 presents ou r conclusions. A pattern is an expression, defined in a language, which describes a collection of objects; the amount of objects des cribed by a pattern is the pattern support . In a supervised classification problem, we say that a pattern is emerging if its support increases significantly from one class to the others [4]. Emerging patterns (EPs) are usually expressed as combinations of feature values, like ( Color = green, Sex = male, Age = 23) or as logical properties, like [ Color = green ]  X  [ Sex = male ]  X  [ Age &gt; 23].

Most algorithms for emerging pattern mining have the goal of finding the patterns that satisfy a desired property: being supported by a single class, min-imality over subset inclusion, or tolerance to noisy objects. These algorithms have the following general steps: 1. Selection of the minimal support threshold  X  2. Global discretization of numerical attributes 3. Representation of the transformed objects using a particular structure 4. Traversing the structure to find emerging patterns 5. Pattern filtering Using this traditional algorithm has two important drawbacks: 1. Global discretization of numerical attributes could drastically degrade the 2. High sensitivity to the support threshold value. The accuracy of the classifier In this section, we introduce CEPM, a new emerging pattern mining algorithm with local discretization of numerical features. CEPM extracts patterns from a collection of C4.5 decision trees [11] , using a special pattern mining proce-dure during the tree induction. To guarantee that CEPM finds a representative collection of patterns, it uses a n ovel object weighting scheme.

The tree induction procedure has the following characteristics:  X  Candidate splits are binary. Nominal attributes use properties like [ Feature  X  If a node has less than  X  objects, it is not further split because it cannot  X  To select the best split, our algorithm evaluates the weighted information During the tree induction, every tree node that (A) has at least  X  objects in a class, and (B) has at most one object in the complement of that class, generates a new emerging pattern. Each pattern consists in the conjunction of the properties fromthenodetotheroot.

Additionally, CEPM extracts patterns while evaluating the splits, even if a split does not have the highest gain; any tree node that fulfills (A) and (B) generates an emerging pattern. For example, Fig. 1 shows two candidate splits, using different properties. Although the first one has the highest information gain, the second contains the emerging pattern ( Age &lt; 20). So, this pattern is extracted although the split is discarded.

CEPM iteratively induces several decisi on trees, updating the object weights after each induction. The algorithm updates the weights using (2). where  X  Support o is the sum of the support of such patterns contained in o .Ifa  X  averageSupport is the average support of the patterns in the database, which We can describe CEPM using the following pseudocode: 1. Initialize object weights to 1 2. Induce the first decision tree with the initial weights and extract the first 3. Calculate the average support, used in weight recalculation 4. Repeat while a new pattern is added in the last iteration 5. Return mined patterns It is worth to mention that CEPM returns a set of the most general emerging patterns with support greater or equal to  X  . A pattern P is more general than a pattern Q if the set of objects described by Q is strictly contained in those described by P , considering all the objects in the universe. Additionally, CEPM returns the abstention ratio, which is the ratio of objects that are not covered by the resultant patterns.

The CEPM based classifier, named CEPMC, uses the following decision rule: to assign an object to the class with maximum value of the total votes given by the patterns contained in the object. Every pattern contained in the object votes for its own class with its total support. If no pattern supports the object or there is a tie in the votes, the classifier refuses to classify the object. Selecting the minimal support threshold for an emerging pattern classifier is a difficult task; a classifier using patterns with higher  X  values, is a more accurate classifier, but could reject to classify mo re objects. On the contrary, a classifier using patterns with lower  X  values might contain many useless patterns, which could degrade the class ification accuracy.

The algorithm proposed for calculating the minimal support value infers the initial support ( M axSupport ) and the minimal expected abstention rate ( MinAbstRate ). Then, it tests support values, starting from  X  = M axSupport , until a  X  value produces an abstention rate lower than MinAbstRate .Thevalue of  X  is decremented using a calculated Step = M axSupport/ 10, because if M axSupport is high, decrementing  X  by1couldbetoocostly.

Some important remarks: 1. M axSupport is inferred based on two criteria. If it is higher than the op-2. MinAbstRate is inferred using  X  = 2, so it measures the minimal expected To compare the performance of the CEPMC classifier, we carried out some ex-periments over 22 databases from the UCI Repository of Machine Learning [12]. We selected six state-of-the-art classifiers: Nearest Neighbors [13], Bagging and Boosting [14], Random Forest [15], C4.5 [11] and Support Vector Machines [3]. For each classifier, we used the Weka 3.6.1 implementation [16] with its default parameters. We also tested SJEP [8], whi ch is one of the most accurate emerging pattern based classifiers, using the minimal support threshold suggested by their authors.

We performed 10-fold cross validation, averaging the results. In both SJEP and CEPMC we reported abstentions as errors. In these objects, the classifier is unable to assign a class; returning the majority or a random class could hide these undesirable cases. In Table 1, we can find the accuracy results, in percent.
Experimental results show that SJEP has low accuracy values in some da-tabases, compared to other classifiers. In those databases, most numerical at-tributes were discretized into a categorical attribute with a single value, so they were useless for mining patterns. C EPMC has higher accu racies than SJEP in most databases. It also has the highest average accuracy from all tested classifiers.

In order to determine if the differences in accuracy are statistically signifi-cant, we performed a pairwise compari son between our classifier and the oth-ers. Each cell in Table 2 contains the number of databases where our classi-fier Win/Lose/Tie to each other classi fier. We detect ties using a two-tailed T-Test [17] with significance of 0.05. The pairwise comparison shows that, in the tested databases, CEPMC is more accurate than other understandable classifiers, while being competitive with Nearest Neighbors and Support Vector Machines classifiers.

The model built by CEPMC is very easy to understand in terms of the problem domain, unlike Nearest Neighbors and Support Vector Machines models. Each class is described as a collection of discriminative properties, as you can see in the example appearing in Table 3. In this paper, we introduced CEPM, a new algorithm for mining Emerging Pat-terns. It uses local discretization of numerical values for solving the global dis-cretization drawback of previous emerging pattern classifiers. CEPM extracts patterns from a collection of decision tr ees, using a special extraction proce-dure during the tree induction. To obtain a collection of representative patterns, CEPM uses a novel object weighting schem e. Furthermore, this paper proposes an algorithm for accurately estimate the minimal support threshold.
Experimental results show that CEPMC, a classifier based on CEPM, is more accurate than one of the most accurate emerging pattern classifiers in the ma-jority of tested databases. A pairwise comparison reveals that CEPMC is more accurate than other understandable classifiers, and as accurate as Nearest Neigh-bors and Support Vector Machines, while the model built by CEPMC for clas-sification is easy to understand in terms of the problem domain.

In the future, we will work on speeding up the algorithm to estimate the minimal support threshold, which is the slowest component of the current algorithm. This work is partly supported by the National Council of Science and Technology of M  X  exico under the project CB-2008-01-106443 and grant 25275.

