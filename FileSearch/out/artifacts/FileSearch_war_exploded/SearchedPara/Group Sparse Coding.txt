 frequency in the document collection [1].
 scales [6].
 sentations are not that robust with respect to descriptor va riability. reconstruction error and the  X  used to efficiently represent each visual descriptor of each image [13]. same image without much additional regularization cost.
 category, thus including an indirect discriminative signa l in code construction. through the sparse encoding step.
 optimization. Finally, Sec. 5 presents experimental resul ts on a well-known image database. v , is denoted G operations on a single group, we use G for the group in discussion and denote by x that express each x reconstruction or compact encoding is governed through a re gularization parameter  X  . {G sum of group encoding objectives and the mixed norm of the dic tionary. optimization problem: The reconstruction matrix A = {  X  specifying the contribution of d mixed  X  eter  X  that balances reconstruction quality (the first term) and re construction complexity. index r , omitting fixed arguments of the objective, and denoting by c depend on  X  We next show how to find the optimum  X  term of the objective. Its partial derivatives with respect to each  X  i Let us make the following abbreviation for a given index r , It is clear that if following sub-gradient condition for optimality, Since  X  r otherwise  X  r set of values { + optimal solution has a non-zero norm, k  X  regularization term is At the optimum this vector must be zero, so after rearranging terms we obtain Therefore, the vector  X   X  scaling parameter s which implies that  X  . Namely, the term 1  X   X / k  X  + k must be positive, thus, we get that  X  otherwise  X  constitute the group. To do so we simply take the p -norm of each  X  vector. Since we use mixed-norms which are sparsity promoti ng, in particular the  X  the resulting vector is likely to be sparse, as we show experi mentally in Section 6. above method, it could be easily generalized to work with Mer cer kernels instead. with low predictive power. To achieve this goal, we will appl y  X  representation of groups.
 Let G = {G where the single group objective Q ( A lations. Define the following auxiliary variables: Then, we can express d gradient with respect to each d d Similarly to the way we solved for  X  following iterate for d where, as above, we incorporated the case d ever the norm of the residual vector u regularization parameter. There are around 2500 training images, 2500 validation imag es and 5000 test images in total.  X  comparable to SIFT and results in similar performance.
 words towards the zero vector implies dictionary sparsity.
 This scheme yielded an initial dictionary of size 7873. the dictionary obtained by both  X  hierarchical k -means is also shown.
 classes to produce the mean average precision shown in our gr aphs. hyperparameters are varied to control the overall dictiona ry size. For the  X  different dictionary size was obtained by tuning  X  while setting  X  = 0 . For the  X  zero, so that it could be comparable to the standard  X  when the dictionary is allowed to be very large, the pure  X  regularization performed better than the  X  than the pure  X  dictionary sizes by varying  X  .
 In Figure 2 we compare the mean average precisions of  X  size of each image as encoded using the trained dictionary ob tained by both  X  image or by class. The baseline system using hierarchical k -means is also shown. Figure 3: Comparison of the dictionary words used to reconst ruct the same image. A pure  X  was used on the left, while a mixed  X  the number of times each dictionary word was used in the recon struction of the image. the  X  regularization performed even worse than hierarchical k -means for small image sizes Figure 3 compares the usage of dictionary words to encode the same image, either using  X  left) or  X  (a row in the plot) was used in the reconstruction of the image . Clearly,  X  coding process. As expected, with  X  words that are used. applications or online settings.
 discrimination which appears to help under space or time con straints. We would like to thanks John Duchi for numerous discussions a nd suggestions.
