 This is a short summary of the author X  X  thesis on  X  X orrela-tion Clustering X  (Ludwig-Maximilians-Universit  X at M  X unchen, Germany, 2008). The complete thesis is available at http://edoc.ub.uni-muenchen.de/8736/ . While clustering in general is a rather dignified problem, mainly in about the last decade new approaches have been proposed to cope with new challenges provided by modern capabilities of automatic data generation and acquisition in more and more applications producing a vast amount of high dimensional data. These data need to be analyzed by data mining methods in order to gain the full potentials from the gathered information. However, high dimensional data pose different challenges for clustering algorithms that require specialized solutions. In particular, in high dimensional data traditional similarity measures as used in conventional clus-tering algorithms are often not meaningful. This problem and related phenomena triggered adaptations of clustering approaches to the nature of high dimensional data. Com-mon approaches are known as subspace clustering, projected clustering, pattern-based clustering, or correlation cluster-ing. 1 This area of research has been a highly active one in the recent years with a plethora of proposed algorithms but, in our opinion, lacking of a systematic problem analy-sis. Thus, a comparison of proposed algorithms is difficult both, theoretically and practically.
 The family of axis-parallel subspace and projected cluster-ing algorithms assumes that data objects belonging to the same cluster are near by each other in Euclidean space but allows to assess the corresponding distance of objects w.r.t. subsets of the attributes due to the problem of increasingly poor separation of near and far points in higher dimensional data and the problem of irrelevant attributes. Pattern-based approaches often disregard the assumption that a cluster consists of objects that are near by each other in the Eu-clidean space or some Euclidean subspace and, instead, aim at collecting objects following a similar behavioral pattern over a subset of attributes. These patterns relate to simple strict pairwise linear positive correlations among the con-
Note, though, that the term  X  X orrelation clustering X  has been used for a quite different problem within the machine learning community. gorithms. So far, no efficient all-round-algorithm has been proposed and it seems unlikely to get one. It is not even clear whether such a solution would be desirable. Another open question, as pointed out in this systematic part, is the evaluation of different approaches. Since any approach uses its own assumptions and heuristics (and often even defines the objective in a different way), a comprehensive and fair experimental evaluation of a reasonable set of representa-tives for the different classes of solutions is not only missing so far but seems also a very demanding and complex task. Contributions to the category of correlation clustering algo-rithms are presented in Parts III X  X . Part III collects adap-tations of the density-based paradigm using PCA as a prim-itive to grasp correlated attributes and derive the corre-sponding arbitrarily oriented subspace. The first adaptation is the algorithm 4C (Chapter 8). A more robust, more effi-cient and more effective variant for flat correlation clustering is COPAC (Chapter 9). Hierarchical correlation clustering has been tackled by the approaches HiCO (Chapter 10) and ERiC (Chapter 11). For all correlation clustering algorithms based on PCA on a local selection of points, a framework to enhance the suitability of the selected set and the robustness of the applied PCA has been discussed in Chapter 12. Nevertheless, as discussed in Part IV, there remain weak points of all these density-based approaches applying PCA on a local selection of representative points (see Chapter 13). They rely on the so called locality assumption which is in view of high dimensional data rather na  X  X ve, as has also been discussed in Part II. Thus, as a global approach to cor-relation clustering, the algorithm CASH has been proposed and discussed in Chapter 14.
 None of the existing correlation clustering algorithms derives a quantitative and qualitative model for each correlation cluster. Such a model helps to gain the full practical poten-tials from correlation cluster analysis. Part V describes an original approach to derive quantitative information on the linear dependencies within correlation clusters. As discussed in Chapter 15, this step is not readily available for correla-tion clustering so far. The concepts for deriving quantita-tive and qualitative correlation clustering models described in Chapter 16 are independent of the clustering approach and can thus be applied as a post-processing step to any correlation clustering algorithm. The broad experimental evaluation demonstrates the beneficial impact of the pro-posed method on several applications of significant practical importance. It has been exemplified how the method can be used in conjunction with a suitable clustering algorithm to gain valuable and important knowledge about complex re-lationships in real-world data. Furthermore, as sample ap-plications of the approach, Chapter 17 sketches how these quantitative models can be used to predict the probability distribution that an object is created by these models, and Chapter 18 describes an adaptation of the approach to the outlier detection problem.
 The final Part VI summarizes the contributions and results of the thesis (Chapter 19), and points out some open ques-tions and possible directions for future work (Chapter 20). The results of Part II were presented as tutorial at ICDM  X 07, PAKDD  X 08, KDD  X 08, and VLDB  X 08 [11], and have been published in an updated version in [12]. The algorithms de-
