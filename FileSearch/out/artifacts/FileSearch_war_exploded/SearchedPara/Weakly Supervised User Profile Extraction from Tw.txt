 The overwhelming popularity of online social me-dia creates an opportunity to display given as-pects of oneself. Users X  profile information in information in a structured data format, making it amenable to automatic processing. This includes, for example, users X  jobs and education, and pro-vides a useful source of information for applica-Table 1: Examples of Twitter message clues for user profile inference. line advertising, computational social science and more.

Although profiles exist in an easy-to-use, struc-tured data format, they are often sparsely popu-lated; users rarely fully complete their online pro-files. Additionally, some social networking ser-vices such as Twitter don X  X  support this type of structured profile data. It is therefore difficult to obtain a reasonably comprehensive profile of a user, or a reasonably complete facet of information (say, education level) for a class of users. While many users do not explicitly list all their personal information in their online profile, their user gen-erated content often contains strong evidence to suggest many types of user attributes, for example education, spouse, and employment (See Table 1). Can one use such information to infer more de-tails? In particular, can one exploit indirect clues from an unstructured data source like Twitter to obtain rich, structured user profiles?
In this paper we demonstrate that it is feasi-ble to automatically extract Facebook-style pro-files directly from users X  tweets, thus making user profile data available in a structured format for upstream applications. We view user profile inference as a structured prediction task where both text and network information are incorpo-rated. Concretely, we cast user profile predic-tion as binary relation extraction (Brin, 1999), e.g., S POUSE (User i , User j ), E DUCATION (User i , Entity j ) and E MPLOYER (User i , Entity j ). Inspired by the concept of distant supervision, we collect training tweets by matching attribute ground truth from an outside  X  X nowledge base X  such as Face-book or Google Plus.

One contribution of the work presented here is the creation of the first large-scale dataset on three general Twitter user profile domains (i.e., E DUCA -TION , J OB , S POUSE ). Experiments demonstrate that by simultaneously harnessing both text fea-tures and network information, our approach is able to make accurate user profile predictions. We are optimistic that our approach can easily be ap-plied to further user attributes such as HOBBIES ing data can be obtained by matching ground truth retrieved from multiple types of online social me-dia such as Facebook, Google Plus, or LinkedIn. Our contributions are as follows:  X  We cast user profile prediction as an informa- X  We present a large-scale dataset for this task  X  We demonstrate the benefit of jointly rea- X  We experimentally demonstrate the effective-
The remainder of this paper is organized as fol-lows: We summarize related work in Section 2. The creation of our dataset is described in Section 3. The details of our model are presented in Sec-tion 4. We present experimental results in Section 5 and conclude in Section 6. While user profile inference from social media has received considerable attention (Al Zamal et al., 2012; Rao and Yarowsky, 2010; Rao et al., 2010; Rao et al., 2011), most previous work has treated this as a classification task where the goal is to pre-dict unary predicates describing attributes of the user. Examples include gender (Ciot et al., 2013; Liu and Ruths, 2013; Liu et al., 2012), age (Rao et al., 2010), or political polarity (Pennacchiotti and Popescu, 2011; Conover et al., 2011).

A significant challenge that has limited previous efforts in this area is the lack of available training data. For example, researchers obtain training data by employing workers from Amazon Mechanical Turk to manually identify users X  gender from pro-file pictures (Ciot et al., 2013). This approach is appropriate for attributes such as gender with a small numbers of possible values (e.g., male or fe-male ), for which the values can be directly iden-tified. However for attributes such as spouse or education there are many possible values, making it impossible to manually search for gold standard answers within a large number of tweets which may or may not contain sufficient evidence.

Also related is the Twitter user timeline extrac-tion algorithm of Li and Cardie (2013). This work is not focused on user attribute extraction, how-ever.
 Distant Supervision Distant supervision, also known as weak supervision, is a method for learn-ing to extract relations from text using ground truth from an existing database as a source of supervision. Rather than relying on mention-level annotations, which are expensive and time consuming to generate, distant supervision lever-ages readily available structured data sources as a weak source of supervision for relation ex-traction from related text corpora (Craven et al., 1999). For example, suppose r ( e 1 ,e 2 ) = IsIn ( Paris,France ) is a ground tuple in the database and s =  X  X aris is the capital of France X  contains synonyms for both  X  X aris X  and  X  X rance X , then we assume that s may express the fact r ( e 1 ,e 2 ) in some way and can be used as pos-itive training examples. In addition to the wide use in text entity relation extraction (Mintz et al., 2009; Ritter et al., 2013; Hoffmann et al., 2011; Surdeanu et al., 2012; Takamatsu et al., 2012), distant supervision has been applied to multiple Figure 1: Illustration of Goolge Plus  X  X nowledge base X . fields such as protein relation extraction (Craven et al., 1999; Ravikumar et al., 2012), event extrac-tion from Twitter (Benson et al., 2011), sentiment analysis (Go et al., 2009) and Wikipedia infobox generation (Wu and Weld, 2007).
 Homophily Online social media offers a rich source of network information. McPherson et al. (2001) discovered that people sharing more attributes such as background or hobby have a higher chance of becoming friends in social media. This property, known as HOMOPHILY (summarized by the proverb  X  X irds of a feather flock together X ) (Al Zamal et al., 2012) has been widely applied to community detection (Yang and Leskovec, 2013) and friend recommendation (Guy et al., 2010) on social media. In the user attribute extraction literature, researchers have considered neighborhood context to boost inference accuracy (Pennacchiotti and Popescu, 2011; Al Zamal et al., 2012), where information about the degree of their connectivity to their pre-labeled users is included in the feature vectors. A related algorithm by Mis-love et al. (2010) crawled Facebook profiles of 4,000 Rice University students and alumni and in-ferred attributes such as major and year of ma-triculation purely based on network information. Mislove X  X  work does not consider the users X  text stream, however. As we demonstrate below, rely-ing solely on network information is not enough to enable inference about attributes. We now describe the generation of our distantly supervised training dataset in detail. We make use of Google Plus and Freebase to obtain ground facts and extract positive/negative bags of post-ings from users X  twitter streams according to the ground facts.
 Figure 2: Example of fetching tweets containing entity USC mention from Miranda Cosgrove (an American actress and singer-songwriter) X  X  twitter stream.
 Education/Job We first used the Google Plus of users whose profiles contain both their educa-Then, we fetched tweets containing the mention of the education/job entity from each correspondent (shown in Figure 2) and used them to construct positive bags of tweets expressing the associated attribute, namely E DUCATION (User i , Entity j ), or E is employed for alias recognition, to match terms such as  X  X arvard University X ,  X  X arvard X ,  X  X ar-vard U X  to a single The remainder of each corre-sponding user X  X  entire Twitter feed is used as neg-
We expanded our dataset from the seed users according to network information provided by Google Plus and Twitter. Concretely, we crawled circle information of users in the seed set from both their Twitter and Google Plus accounts and performed a matching to pick out shared users between one X  X  Twitter follower list and Google Plus Circle. This process assures friend identity and avoids the problem of name ambiguity when matching accounts across websites. Among candi-date users, those who explicitly display Job or Ed-ucation information on Google Plus are preserved. We then gathered positive and negative data as de-scribed above.

Dataset statistics are presented in Table 2. Our education dataset contains 7,208 users, 6,295 of which are connected to others in the network. The positive training set for the E DUCATION is com-prised of 134,060 tweets.
 Spouse Facebook is the only type of social me-dia where spouse information is commonly dis-played. However, only a tiny amount of individ-ual information is publicly accessible from Face-spouse relation at large scale, we turned to Free-ered instances of the / PEOPLE / PERSON / SPOUSE relation. Positive/negative training tweets are ob-tained in the same way as was previously de-scribed for E DUCATION and J OB . It is worth noting that our Spouse dataset is not perfect, as individuals retrieved from Freebase are mostly celebrities, and thus it X  X  not clear whether this group of people are representative of the general population.

S POUSE is an exception to the  X  X o-mophily X  effect. But it exhibits another unique property, known as, REFLEXIVITY : fact IsSpouseOf ( e 1 ,e 2 ) and IsSpouseOf ( e 2 ,e 1 ) will hold or not hold at the same time. Given train-ing data expressing the tuple IsSpouseOf ( e 1 ,e 2 ) from user e 1  X  X  twitter stream, we also gather user e  X  X  tweet collection, and fetch tweets with the mention of e 1 . We augment negative training data from e 2 as in the case of Education and Job. Our Spouse dataset contains 1,636 users, where there are 554 couples (1108 users). Note that the number of positive entities (3,121) is greater than the number of users as (1) one user can have multiple spouses at different periods of time (2) multiple entities may point to the same individual, e.g., BarackObama, Barack Obama and Barack. We now describe our approach to predicting user profile attributes. 4.1 Notation Message X: Each user i  X  [1 ,I ] is associ-ated with his Twitter ID and his tweet corpus X i . X i is comprised of a collection of tweets X of tweets user i published. Tweet Collection L e i : L e i denotes the collection of postings containing the mention of entity e from user i . L e i  X  X i .
 each entity e  X  X i , there is a boolean variable z k i,e indicating whether entity e expresses attribute k of user i . Each posting x  X  L e i is associated with at-tribute indicator z k i,x indicating whether posting x expresses attribute k of user i . z k i,e and z k i,x are observed during training and latent during testing. Neighbor set F k i : F k i denotes the neighbor set of user i . For Education ( k = 0) and Job ( k = 1) , i denotes the group of users within the network that are in friend relation with user i . For Spouse attribute, F k i denote current user X  X  spouse. 4.2 Model The distant supervision assumes that if entity e corresponds to an attribute for user i , at least one posting from user i  X  X  Twitter stream containing a mention of e might express that attribute. For user-level attribute prediction, we adopt the following two strategies: (1) G LOBAL directly makes aggregate (entity) level prediction for z k i,e , where features for all tweets from L e i are aggregated to one vector for training and testing, following Mintz et al. (2009). (2) L OCAL makes local tweet-level predictions for each tweet z e i,x , x  X  L k i in the first place, mak-ing the stronger assumption that all mentions of an entity in the users X  profile are expressing the asso-then made from the deterministic OR operators.
The rest of this paper describes G LOBAL in de-tail. The model and parameters with LOCAL are identical to those in G LOBAL except that LOCAL encode a tweet-level feature vector rather than an aggregate one. They are therefore excluded for brevity. For each attribute k , we use a model that factorizes the joint distribution as product of two distributions that separately characterize text fea-tures and network information as follows: Text Factor We use  X  text ( z k e ,X i ) to capture the text related features which offer attribute clues:
 X  The feature vector  X  text ( z k i,e ,X i ) encodes the fol-lowing standard general features:  X  Entity-level: whether begins with capital let- X  Token-level: for each token t  X  e , word iden- X  Conjunctive features for a window of k  X  Tweet-level: All tokens in the correspondent
In addition to general features, we employ attribute-specific features, such as whether the en-tity matches a bag of words observed in the list of universities, colleges and high schools for Edu-cation attribute, whether it matches terms in a list of companies for Job attribute 12 . Lists of universi-ties and companies are taken from knowledge base Neighbor Factor For Job and Education, we bias friends to have a larger possibility to share the same attribute.  X  Neigh ( z k i,e ,F k i ) captures such influence from friends within the network: Features we explore include the whether entity e is also the correspondent attribute with neighbor user j , i.e., I ( z e Input : Tweet Collection { X i } , Neighbor set Initialization :  X  for each user i : features End Initialization while not convergence :  X  for each user i : end while : Figure 3: Inference for NEIGH -LATENT setting.
For Spouse, we set F spouse neighbor factor can be rewritten as: It characterizes whether current user C i to be the spouse of user e (if e corresponds to a Twitter user). We expect clues about whether C i being en-tity e  X  X  spouse from e  X  X  Twitter corpus will in turn facilitate the spouse inference procedure of user i .  X 
Neigh ( C i ,X e ) encodes I ( C i  X  S e ) , I ( C i 6 X  S Features we explore also include whether C i  X  X  twitter ID appears in e  X  X  corpus. 4.3 Training We separately trained three classifiers regarding the three attributes. All variables are observed during training; we therefore take a feature-based approach to learning structure prediction models inspired by structure compilation (Liang et al., 2008). In our setting, a subset of the features (those based on network information) are com-puted based on predictions that will need to be made at test time, but are observed during train-ing. This simplified approach to learning avoids expensive inference; at test time, however, we still need to jointly predict the best attribute values for friends as is described in section 4.4. 4.4 Inference Job and Education Our inference algorithm for Job/Education is performed on two settings, depending on whether neighbor information is observed ( NEIGH -OBSERVED ) or latent ( NEIGH -LATENT ). Real world applications, where network information can be partly retrieved from all types of social networks, can always falls in between.
Inference in the NEIGH -OBSERVED setting is trivial; for each entity e  X  G i , we simply predict it X  X  candidate attribute values using Equ.6.
For NEIGH -LATENT setting, attributes for each node along the network are treated latent and user attribute prediction depends on attributes of his neighbors. The objective function for joint infer-ence would be difficult to optimize exactly, and algorithms for doing so would be unlikely to scale to network of the size we consider. Instead, we use a sieve-based greedy search approach to inference (shown in Figure 3) inspired by recent work on coreference resolution (Raghunathan et al., 2010). Attributes are initialized using only text features, maximizing  X  text ( e,X i ) , and ignoring network information. Then for each user we iteratively re-estimate their profile given both their text features and network features (computed based on the cur-rent predictions made for their friends) which pro-vide additional evidence.

In this way, highly confident predictions will be made strictly from text in the first round, then the network can either support or contradict low con-fidence predictions as more decisions are made. This process continues until no changes are made at which point the algorithm terminates. We em-pirically found it to work well in practice. We ex-pect that NEIGH -OBSERVED performs better than NEIGH -LATENT since the former benefits from gold network information.
 Spouse For Spouse inference, if candidate entity e has no correspondent twitter account, we directly determine z k i,e = argmax z 0  X ( z 0 ,X i ) from text by maximizing text factor, as we did for Educa-tion and Job. Then we iteratively update z k given by the rest variables until convergence. In this Section, we present our experimental re-sults in detail.

Table 3: Affinity values for Education and Job. 5.1 Preprocessing and Experiment Setup Each tweet posting is tokenized using Twitter NLP tool introduced by Noah X  X  Ark 14 with # and @ separated following tokens. We assume that at-tribute values should be either name entities or terms following @ and # . Name entities are ex-tracted using Ritter et al. X  X  NER system (2011). Consecutive tokens with the same named entity tag are chunked (Mintz et al., 2009). Part-of-speech tags are assigned based on Owoputi et al X  X  tweet POS system (Owoputi et al., 2013).

Data is divided in halves. The first is used as training data and the other as testing data. 5.2 Friends with Same Attribute Our network intuition is that users are much more likely to be friends with other users who share at-tributes, when compared to users who have no at-tributes in common. In order to statistically show this, we report the value of AFFINITY defined by Mislove et al (2010), which is used to quantita-tively evaluate the degree of HOMOPHILY in the network. AFFINITY is the ratio of the fraction of links between attribute (k)-sharing users ( S k ), rel-ative to what is expected if attributes are randomly assigned in the network ( E k ).
 where T k m denotes the number of users with m value for attribute k and U k = shows the affinity value of the Education and Job. As we can see, the property of HOMOPHILY in-deed exists among users in the social network with respect to Education and Job attribute, as signifi-cant affinity is observed. In particular, the affinity value for Education is 74.3, implying that users connected by a link in the network are 74.3 times more likely affiliated in the same school than as expected if education attributes are randomly as-signed. It is interesting to note that Education ex-hibits a much stronger HOMOPHILY property than Job. Such affinity demonstrates that our approach that tries to take advantage of network information for attribute prediction of holds promise. 5.3 Evaluation and Discussion We evaluate settings described in Section 4.2 i.e., GLOBAL setting, where user-level attribute is pre-dicted directly from jointly feature space and LO -CAL setting where user-level prediction is made based on tweet-level prediction along with differ-ent inference approaches described in Section 4.4, garding whether neighbor information is observed or latent.
 Baselines We implement the following base-lines for comparison and use identical processing techniques for each approach for fairness.  X  Only-Text: A simplified version of our algo-rithm where network/neighbor influence is ig-nored. Classifier is trained and tested only based on text features.  X  NELL: For Job and Education, candidate is se-lected as attribute value once it matches bag of words in the list of universities or companies borrowed from NELL. For Education, the list is extended by alias identification based on Free-base. For Job, we also fetch the name abbrevia-tion and Job attribute.
 For each setting from each approach, we report the (P)recision, (R)ecall and (F)1-score. For LO -CAL setting, we report the performance for both entity-level prediction ( E ntity) and posting-level prediction ( T weet). Results for Education, Job and Spouse from different approaches appear in Table 4, 5 and 6 respectively.
 Local or Global For horizontal comparison, we observe that GLOBAL obtains a higher Precision score but a lower Recall than LOCAL ( ENTITY ). This can be explained by the fact that LOCAL ( U ) sets z k i,e = 1 once one posting x  X  L e i is identified as attribute related, while GLOBAL tend to be more meticulous by considering the conjunctive feature space from all postings.
 Homophile effect In agreement with our ex-pectation, NEIGH -OBSERVED performs better than NEIGH -LATENT since erroneous predictions in NEIGH -LATENT setting will have negative in-fluence on further prediction during the greedy search process. Both NEIGH -OBSERVED and NEIGH -LATENT where network information is harnessed, perform better than Only-Text , which the prediction is made independently on user X  X  text features. The improvement of NEIGH -OBSERVED over Only-Text is 22 . 7% and 6 . 4% regarding F-1 score for Education and Job respectively, which further illustrate the usefulness of making use of Homophile effect for attribute inference on online social media. It is also interesting to note the im-provement much more significant in Education in-ference than Job inference. This is in accord with what we find in Section 5.2, where education net-work exhibits stronger HOMOPHILE property than Job network, enabling a significant benefit for ed-ucation inference, but limited for job inference.
Spouse prediction also benefits from neighbor-ing effect and the improvement is about 12% for LOCAL ( ENTITY ) setting. Unlike Education and Job prediction, for which in NEIGH -OBSERVED setting all neighboring variables are observed, net-work variables are hidden during spouse predic-tion. By considering network information, the model benefits from evident clues offered by tweet corpus of user e  X  X  spouse when making prediction for e , but also suffers when erroneous decision are made and then used for downstream predictions. NELL Baseline Notably, NELL achieves high-est Recall score for Education inference. It is also worth noting that most of education men-tions that NELL fails to retrieve are those in-volve irregular spellings, such as HarvardUniv and Cornell U, which means Recall score for NELL baseline would be even higher if these irregular spellings are recognized in a more sophisticated system. The reason for such high recall is that as our ground truths are obtained from Google plus, the users from which are mostly affiliated with de-cent schools found in NELL dictionary. However, the high recall from NELL is sacrificed at preci-sion, as users can mention school entities in many of situations, such as paying a visit or reporting some relevant news. NELL will erroneously clas-sify these cases as attribute mentions.

NELL does not work out for Job, with a fairly poor 0.0156 F1 score for LOCAL ( ENTITY ) and 0.163 for LOCAL ( TWEET ). Poor precision is ex-pected for as users can mention firm entity in a great many of situations. The recall score for NELL in job inference is also quite low as job related entities exhibit a greater diversity of men-tions, many of which are not covered by the NELL dictionary.
 Vertical Comparison: Education, Job and Spouse Job prediction turned out to be much more difficult than Education, as shown in Ta-bles 4 and 5. Explanations are as follows: (1) Job contains a much greater diversity of mentions than Education. Education inference can benefit a lot from the dictionary relevant feature which Job may not. (2) Education mentions are usually asso-ciated with clear evidence such as homework, ex-ams, studies, cafeteria or books, while situations are much more complicated for job as vocabular-ies are usually specific for different types of jobs. (3) The boundary between a user working in and a fun for a specific operation is usually ambigu-ous. For example, a Google engineer may con-stantly update information about outcome prod-ucts of Google, so does a big fun. If the aforemen-tioned engineer barely tweets about working con-ditions or colleagues (which might still be ambigu-ous), his tweet collection, which contains many of mentions about outcomes of Google product, will be significantly similar to tweets published by a Google fun. Such nuisance can be partly solved by the consideration of network information, but not totally.

The relatively high F1 score for spouse predic-tion is largely caused by the great many of non-individual related entities in the dataset, the iden-tification of which would be relatively simpler. A deeper look at the result shows that the classifier frequently makes wrong decisions for entities such as userID and name entities. Significant as some spouse relevant features are, such as love, hus-band, child, in most circumstances, spouse men-tions are extremely hard to recognize. For exam-ple, in tweets  X  X heck this out, @alancross, it X  X  awesome bit.ly/1bnjYHh . X  or  X  X appy Birth-day @alancross ! X . alancross can reasonably be any option among current user X  X  friend, colleague, parents, child or spouse. Repeated mentions add no confidence. Although we can identify alan-cross as spouse attribute once it jointly appear with other strong spouse indicators, they are still many cases where they never co-appear. How to integrate more useful side information for spouse recognition constitutes our future work. In this paper, we propose a framework for user at-tribute inference on Twitter. We construct the pub-licly available dataset based on distant supervision and experiment our model on three useful user profile attributes, i.e., Education, Job and Spouse. Our model takes advantage of network informa-tion on social network. We will keep updating the dataset as more data is collected.

One direction of our future work involves ex-ploring more general categories of user profile at-tributes, such as interested books, movies, home-town, religion and so on. Facebook would an ideal ground truth knowledge base. Another direc-tion involves incorporating richer feature space for better inference performance, such as multi-media sources (i.e. pictures and video). A special thanks is owned to Dr. Julian McAuley and Prof. Jure Leskovec from Stanford University for the Google+ circle/network crawler, without which the network analysis would not have been conducted. This work was supported in part by DARPA under award FA8750-13-2-0005.

