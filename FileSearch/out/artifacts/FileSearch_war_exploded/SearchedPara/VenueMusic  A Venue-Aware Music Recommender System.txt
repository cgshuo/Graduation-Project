 Users X  music preferences can be greatly influenced by their location and environment nearby. In this demonstration, we present an intelligent music recommender system, called VenueMusic, to automatically identify suitable music for various popular venues in our daily lives. VenueMusic enjoys a set of nice features: i) music concept sequence generation scheme and Location-aware Topic Model (LTM) are pro-posed to map the characteristics of venues and music into a latent semantic space, where suitability of music for a venue can be directly measured, ii) a smart interface enabling user to smoothly interact with VenueMusic, and iii) high quality music playlist. The demonstration will show several inter-esting use-cases of VenueMusic, and illustrate its superiority on recommending music based on where user presents. H.3.3 [ Information Search and Retrieval ]: Query for-mulation, Search process; H.5.5 [ Sound and Music Com-puting ]: Systems Music Recommendation, Context-Aware, Topic Model
Mobile devices have increasingly become significant medi-ums for enjoying music anywhere and anytime. It is well known that users X  music preferences can be greatly influ-enced by where they are and surrounding environment. There-fore, how to leverage venue related information is a key is-sue towards effective location based music recommendation. Different venues usually have different atmosphere and am-bience. Accordingly, different music contents are suitable for different venues in general. For example, energetic mu-sic is popular in gym, while love songs fit a romantic restau-rant well. Recent physiological study [3] shows that human judges the suitability of a music for a place based on various music semantics (e.g., genre and mood). However, it is very difficult to apply low level acoustic features to explicitly de-scribe those semantics due to the well-known  X  X emantic gap X . Besides, the acoustic contents of music belonging to same or similar concepts could be highly diverse [4]. In the demon-stration, we present an intelligent music recommender sys-tem, called VenueMusic, to automatically identify suitable music for various popular venues in our daily lives [2]. To-wards this goal, a novel topic model called Location-aware Topic Model (LTM) is proposed to measure the suitability of music for venues in a latent semantic space. Besides, music concept sequence generation scheme is developed to represent each track as a set of music concepts. The demon-stration also focuses on a few interesting use-cases, and il-lustrates the superiority of VenueMusic on recommendation accuracy and robustness at various venues.
VenueMusic X  X  architecture comprises two major compo-nents: (1) Music Concept Sequence Generation (MCSG) and (2) Location-aware Topic Model (LTM). Main func-tionality of MCSG is to detect music concepts (e.g., in-strument , genre , and mood ) to represent audio contents of the music tracks. Figure 1 illustrates the detail architecture of VenueMusic. Specifically, when receiving a music track, VenueMusic partitions it into multiple short segments, from which different concepts (i.e., genres and moods) are ex-tracted based on their audio contents using automatic con-cept detectors (trained based on concept-labeled data). To improve the quality of the detected concepts for a segment, concepts with low detected probabilities or causing rare con-cept co-occurrence patterns are removed via Infrequent Con-cept Pattern Filtering (ICPF). For a track, its music concept sequence is the concatenation of the concepts of all segments. Serving as the second component, LTM extracts the latent topics from location-labeled music tracks and uses them to represent the characteristics of the location and the music content with the probabilistic distributions of the mined top-ics. When the new tracks (unlabeled-tracks) are available, we fit them into the model by fixing the topics and ob-tain their topic distributions. Through characterizing the location and music tracks by probability distributions of the same topics, the suitability score of a music track m for a venue v is estimated using Kullback-Leibler (KL) distance as, In the demonstration, we show a few nice features of the VenueMusic including good usability, effectiveness and ro-bustness.
VenueMusic has a simple but effective interface alongside with intelligent recommendation engine at backend. The design of the interface is to facilitate the easy use of the system, and the intelligent backend enables flexible recom-mendation to satisfy different music needs and personal pref-erences. The demo will focus on several nice characteristics of VenueMusic X  X  user interface.
In order to validate the effectiveness and robustness of the system, a user study was conducted using large scale test collection including 10,000 songs. In the test, the system was applied to recommend suitable music tracks to eight common venues (as shown in Table 1) and compared with several competitors. Due to the space limitations, the results of three competitors are presented:
Totally 29 music concepts (5 moods, 12 genres and 12 in-struments) are used in the experiments. 7 human subjects are recruited to evaluate the recommendation results of each method. The evaluation procedure is the same to the user study in [1]. Table 1 presents the mean P@20 of all sub-jects over the eight venues. The comparisons with ABCF and CBCF demonstrate the superiority of using semantic topic representations for venues and music; and the com-parison with CLTM verify the usefulness of using ICPF in the generation of music concept sequences for music tracks. VenueMusic outperforms the competitors across the eight venues significantly and consistently , which demonstrates its effectiveness and robustness on location-aware music recom-mendation.
 Table 1: Precision@20 comparison over different venues.
This research is supported by Singapore Ministry of Ed-ucation under Academic Research Fund Tier-2 (MOE Ref: MOE2013-T2-2-156) and the Microsoft Research Grant (FY14-RES-OPP-048).
