 This is the f rst study of crowdsourcing Pareto-optimal object f nd-ing over partial orders and by pairwise comparisons, which has ap-plications in public opinion collection, group decision making, and information exploration. Departing from prior studies on crowd-sourcing skyline and ranking queries, it considers the case where objects do not have explicit attributes and preference relations on objects are strict partial orders. The partial orders are derived by ag-gregating crowdsourcers X  responses to pairwise comparison ques-tions. The goal is to f nd all Pareto-optimal objects by the fewest possible questions. It employs an iterative question-selection frame-work. Guided by the principle of eagerly identifying non-Pareto optimal objects, the framework only chooses candidate questions which must satisfy three conditions. This design is both suff cient and eff cient, as it is proven to f nd a short terminal question se-quence. The framework is further steered by two ideas X  X acro-ordering and micro-ordering. By different micro-ordering heuristic-s, the framework is instantiated into several algorithms with varying power in pruning questions. Experiment results using both real crowdsourcing marketplace and simulations exhibited not only or-ders of magnitude reductions in questions when compared with a brute-force approach, but also close-to-optimal performance from the most eff cient instantiation.
The growth of user engagement and functionality in crowdsourc-ing platforms has made computationally challenging tasks unprece-dentedly convenient. The subject of our study is one such task X  crowdsourcing Pareto-optimal object f nding . Consider a set of objects O and a set of criteria C for comparing the objects. An object x  X  O is Pareto-optimal if and only if x is not dominated by any other object. Object y dominates x (denoted y  X  x ) if and only if x is not better than y by any criterion and y is better than x by at least one criterion, i.e.,  X  c  X  C : x  X  c y and  X  c  X  C : If x and y do not dominate each other (i.e., x  X  y and y  X  x ), we denote it by x  X  y . The preference (better-than) relation denoted  X  c ) for each c  X  C is a binary relation subsumed by is better than (preferred over) y with regard to criterion if ( c . We say x and y are indifferent regarding c (denoted x  X  ( x , y ) /  X  P c  X  ( y , x ) /  X  P c . We consider the setting where each strict partial order , i.e., P c is irref exive (  X  x : ( sitive (  X  x , y : ( x , y )  X  P c  X  ( y , z )  X  P c  X  ( x imply asymmetry (  X  x , y : ( x , y )  X  P c  X  ( y , x ) /  X  P that such def nition of better-than relation has been widely used in modeling preferences (e.g., [20, 13, 28]), and the def nition of Pareto-optimal objects follows the concept of Pareto composition of preference relations in [13].
 Novelty Pareto-optimal queries resembles skyline queries [5]. However, except for [23, 4, 17], previous studies on preference and skyline queries do not use the crowd; they focus on query processing on existing data. On the contrary, we examine how to obtain suff cient data from the crowd for determining Pareto-optimal objects. Furthermore, our work differs in several radical ways, as summarized in Table 1 and explained below.  X 
The preference relation for a criterion is not governed by explicit scores or values on object attributes (e.g., sizes of houses, prices of hotels), while prior studies (except [4, 17]) assumed explicit attribute representation. For many comparison criteria, it is diff -cult to model objects by explicit attributes, not to mention asking people to provide such values or scores; people X  X  preferences are rather based on complex, subtle perceptions, as Examples 1 and 2 shall demonstrate. The concept def nitions deliberately do not admit notations for attribute or object equivalence.  X 
Due to the above reason, we request crowdsourcers to perform pairwise comparisons instead of directly providing attribute val-ues or scores. On the contrary, [23] assumes explicit attribute representation and thereby answers skyline queries by asking the crowd to provide missing attribute values. Pairwise comparison is extensively studied in social choice and welfare, preferences, and voting. It is known that people are more comfortable and conf -dent with comparing objects than directly scoring them, since it is easier, faster, and less error-prone [30].  X 
The crowd X  X  preference relations are modeled as strict partial or-ders, as opposed to total orders. This is not only a direct effect of using pairwise comparisons instead of numeric scores or explicit attribute values, but also a ref ection of the psychological nature of human X  X  preferences [20, 13], since it is not always natural to enforce a total order. Most studies on skyline queries assume total orders, except for [11, 28, 29, 32] which consider partial orders.
Several recent studies used crowdsourcing to compare objects for answering ranking, top-k and group-by queries. Crowd-BT [12] ranks objects by crowdsourcing pairwise object comparisons. Poly-chronopoulos et al. [25] f nd top-k items in an itemset by asking human workers to rank small subsets of items. Davidson et al. [15] evaluate top-k and group-by queries by asking the crowd to answer
Figure 1: Finding Pareto-optimal movies by story , music , acting . type questions (whether two objects belong to the same group) and value questions (ordering two objects). They do not consider multi-ple attributes in modeling objects, while skyline and Pareto-optimal objects are def ned in a space of multiple attributes. They assume total orders instead of partial orders.

To recap, ours is so far the only work on crowdsourcing Pareto-optimal object f nding over partial orders, and we reported in the extended version of this paper [4] the f rst study of crowdsourc-ing Pareto-optimal queries by pairwise comparisons and without explicit attribute representation.

Motivating Applications Pareto-optimal object f nding lend-s itself to applications in several areas, including public opinion collection, group decision making, and information exploration, exemplif ed by the following motivating examples.
 Example 1 (Collecting Public Opinion and Group Decision Mak-ing) . Consider a set of movies O = { a,b,c,d,e,f } and a set of crite-ria C = { story, music, acting } (denoted by s , m , a in the ensuing discussion). Fig.1a shows the individual preference relations (i.e., strict partial orders), one per criterion. Each strict partial order is graphically represented as a directed acyclic graph (DAG), more specif cally a Hasse diagram. The existence of a simple path from x to y in the DAG means x is better than (preferred to) y by the corresponding criterion. For example, ( a , e )  X  P m ( a is better than e by music . ( b , d ) /  X  P s and ( d , b Figure 2: A question that asks to compare two movies by sto ry . The partial orders def ne the dominance relation between objects. For instance, movie c dominates d ( c  X  d ), because c is preferred than d on story and music and they are indifferent on acting , i.e., c  X  s d , c  X  m d , and c  X  a d ; a and b do not dominate each other ( a  X  b ), since b  X  s a , a  X  m b and b  X  a a . Based on the three partial orders, b is the only Pareto-optimal object, since no other objects dominate it and every other object is dominated by some object.
Note that tasks such as the above one may be used in both under-standing the public X  X  preference (i.e., the preference relations are collected from a large, anonymous crowd) and making decisions for a target group (i.e., the preference relations are from a small group of people).
 Example 2 (In formation Exploration) . Consider a photography en-thusiast, Amy , who is drown in a large number of photos she has taken and wants to select a subset of the better ones. She resorts to crowdsourcing for the task, as it has been exploited by many for similar tasks such as photo tagging, location/face identif cation, sorting photos by (guessed) date, and so on. Particularly, she would like to choose Pareto-optimal photos with regard to color , sharp-ness and landscape .

By def nition, the crux of f nding Pareto-optimal objects lies in o btaining the preference relations, i.e., the strict partial orders on individual criteria. Through crowdsourcing, the preference rela-tions are derived by aggregating the crowd X  X  responses to pairwise comparison tasks. Each such comparison between objects x and y by criterion c is a question, denoted x ? c y , which has three possible outcomes X  x  X  c y , y  X  c x , and x  X  c y , based on the crowd X  X  answers. An example is as follows.
 Example 3 (Deriving Preference Relations from Pairwise Com-parisons by the Crowd) . Fig.1b shows the hypothetical results of all 15 pairwise comparisons between the 6 movies in Example 1, by criterion s = story . The outcomes of all comparisons form the crowd X  X  preference relation on story (the leftmost DAG in Fig.1a). Fig.2 is the screenshot of a question form designed for one such comparison. A crowdsourcer, when facing this question, would make a choice among the three possible answers or skip a question if they do not have enough conf dence or knowledge to answer it. Fig.1b shows how many crowdsourcers have selected each answer. For instance, for question a ? s f , three people preferred movie a , one person preferred f , and one person is indifferent. By aggre-gating these answers, it is derived that a is better than f with regard to story , since 60% of the crowdsourcers who responded to the question chose this answer. For question b ? s c , th e result is b since neither b  X  s c nor b  X  s c received enough votes. (Assuming a threshold  X  =60% , i.e., either b  X  s c or b  X  s c should have at least 60% of votes, in order to not declare b  X  s c .)
It is important to point out that, in the aforementioned appli-ca tions, there is an intrinsic lack of the notion of  X  X round truth X . Since objects are not explicitly represented by attribute values, the partial orders are purely ref ections of crowdsourcers X  opinions. For this reason, we shall not investigate if crowdsourcers can obtain answers close to  X  X round truth X , which does not exist. This also means that our techniques may get different answers when using different crowdsourcers or even the same crowdsourcers at different times, because people X  X  opinions alter.

Algorithmic Framework Our goal is to f nd all Pareto-optimal objects with as few questions as possible. A brute-force approach will obtain complete preference relations via pairwise comparison-s of all object pairs by every criterion. However, without such exhaustive comparisons, incomplete knowledge collected from a small set of questions may suff ce in discerning all Pareto-optimal objects. Toward this end, it may appear that we can take advantage of the transitivity of object dominance X  X  cost-saving property of-ten exploited in skyline query algorithms (e.g., [5]) to exclude dom-inated objects from participating in any future comparison once they are detected. But, as also discussed in [13], object dominance in our case is not transitive (Property 1), due to the lack of explicit attribute representation. Hence, the aforementioned cost-saving technique is inapplicable.

Aiming at Pareto-optimal object f nding by a short sequence of questions, we introduce a general, iterative algorithm framework (Sec.3). Each iteration goes through four steps X  question selec-tion , outcome derivation , contradiction resolution , and termination s outcome is determined based on crowdsourcers X  answers. On unusual occasions, if the outcome presents a contradiction to the obtained outcomes of other questions, it is changed to the closest outcome such that the contradiction is resolved. Based on the tran-sitive closure of the outcomes to the questions so far, the objects O are partitioned into three sets X  O  X  (objects that must be Pareto-optimal), O  X  (objects that must be non-Pareto optimal), and (objects whose Pareto-optimality cannot be fully discerned by the incomplete knowledge so far). When O ? becomes empty, O  X  contains all Pareto-optimal objects and the algorithm terminates. The question sequence so far is thus a terminal sequence .
There are a vast number of terminal sequences. Our goal is to f nd one that is as short as possible. We observe that, for a non-Pareto optimal object, knowing that it is dominated by at least one object is suff cient, and we do not need to f nd all its dom-inating objects. It follows that we do not really care about the dominance relation between non-Pareto optimal objects and we can skip their comparisons. Hence, the overriding principle of our question selection strategy is to identify non-Pareto optimal object-s as early as possible. Guided by this principle, the framework only chooses from candidate questions which must satisfy three conditions (Sec.3.1). This design is suff cient, as we prove that an empty candidate question set implies a terminal sequence, and vice versa (Proporty 2). The design is also eff cient, as we further prove that, if a question sequence contains non-candidate questions, there exists a shorter or equally long sequence with only candidate questions that produces the same O  X  , matching the principle of eagerly f nding non-Pareto optimal objects (Theorem 1). Moreover, by the aforementioned principle, the framework selects in every iteration such a candidate question x ? c y that x is more likely to be dominated by y . The selection is steered by two ideas X  macro-ordering and micro-ordering . By using different micro-ordering heuristics, the framework is instantiated into several algorithms with varying power in pruning questions (Sec.4). We also derive a lower bound on the number of questions required for f nding all Pareto-optimal objects (Theorem 2).

In summary, this paper makes the following contributions:  X 
This is the f rst work on crowdsourcing Pareto-optimal object f nd-ing over partial orders and by pairwise comparisons. We def ne preference relations based on pairwise comparisons and we aim to f nd all Pareto-optimal objects by fewest possible comparisons.  X 
We propose a general, iterative algorithm framework (Sec.3) which follows the strategy of choosing only candidate questions that must satisfy three conditions. We prove important properties that establish the advantage of the strategy (Sec.3.1).  X 
We design macro-ordering and micro-ordering heuristics for f nd-ing a short terminal question sequence. Based on the heuristic-s, the generic framework is instantiated into several algorithms ( RandomQ , RandomP , FRQ ) with varying eff ciency. We also derive a non-trivial lower bound on the number of required pair-wise comparison questions. (Sec.4)  X 
We carried out experiments using both simulations and real crowd-sourcing marketplace to compare the amount of comparisons by different instantiations of the framework under varying problem sizes. The results demonstrate the effectiveness of selecting only candidate questions, macro-ordering, and micro-ordering. When these ideas are stacked together, they use orders of magnitude less comparisons than a brute-force approach. The results reveal that
FRQ is nearly optimal and the lower bound is practically tight, since FRQ gets very close to the lower bound. (Sec.5)
Besides [12], there were multiple studies on ranking objects by pairwise comparisons, which date back to decades ago as aggregat-ing the preferences of multiple agents has always been a fundamen-tal problem in social choice and welfare [14, 3]. The more recent studies can be categorized into three types: 1) Approaches such as [21, 26, 31] predict users X  object ranking by completing a user-object scoring matrix. Their predictions take into account users X  similarities in pairwise comparisons, resembling collaborative f l-tering [16]. They thus do not consider explicit attribute representa-tion for objects. 2) Approaches such as [7, 9, 8] infer query-specif c (instead of user-specif c) ranked results to web search queries. Fol-lowing the paradigm of learning-to-rank [22], they rank a query X  X  result documents according to pairwise result comparisons of other queries. The documents are modeled by explicit ranking features. 3) Approaches such as [6, 19, 1, 2, 24] are similar to [12] as they use pairwise comparisons to infer a single ranked list that is neither user-specif c nor query-specif c. Among them, [19] is special in that it also applies learning-to-rank and requires explicit feature representation. Different from our work, none of these studies is about Pareto-optimal objects, since they all assume a total order among objects; those using learning-to-rank require explicit feature representation, while the rest do not consider multiple attributes. Moreover, except [19, 1, 2], they all assume comparison results are already obtained before their algorithms kick in. In contrast, we aim at minimizing the pairwise comparison questions to ask in f nding Pareto-optimal objects.
By the def nition of Pareto-optimal objects, the key to f nding such objects is to obtain the preference relations, i.e., the strict partial orders on individual criteria. Toward this end, the most basic operation is to perform pai rwise comparison  X  X iven a pair of objects x and y and a criterion c , determine whether one is better than the other (i.e., ( x , y )  X  P c or ( y , x )  X  P indifferent (i.e., ( x , y ) /  X  P c  X  ( y , x ) /  X  P c ).
The problem of crowdsourcing Pareto-optimal object f nding is thus essentially crowdsourcing pairwise comparisons. Each com-parison task between x and y by criterion c is presented to the crowd as a question q (denoted x ? c y ). The outcome to the question (denoted rlt ( q ) ) is aggregated from the crowd X  X  answers. Giv-en a set of questions, the outcomes thus contain an (incomplete) knowledge of the crowd X  X  preference relations for various criteria. Fig.2 illustrates the screenshot of one such question (comparing two movies by story ) used in our empirical evaluation. We note that there are other viable designs of question, e.g., only allowing specif c question design.

Given n objects and r criteria, a brute-force approach will per-form pairwise comparisons on all object pairs by every criterion, which leads to r n ( n  X  1) / 2 comparisons. The corresponding ques-tion outcomes amount to the complete underlying preference rela-tions. The quadratic nature of the brute-force approach renders it wasteful. The bad news is that, in the worst case, we cannot do better than it. To understand this, consider the scenario where all objects are indifferent by every criterion. If any comparison x is skipped, we cannot determine if x and y are indifferent or if one dominates another.

In practice, though, the outlook is much brighter. Since we look for only Pareto-optimal objects, it is an overkill to obtain com-plete preference relations. Specif cally, for a Pareto-optimal object, knowing it is not dominated by any object is suff cient, and we do not need to f nd all the objects dominated by it; for a non-Pareto optimal object, knowing it is dominated by at least one object is suff cient, and we do not need to f nd all its dominating objects. Hence, without exhausting all possible comparisons, incomplete knowledge on preference relations collected from a set of questions may suff ce in fully discerning all Pareto-optimal objects.
Our objective is to f nd all Pareto-optimal objects with as few questions as possible. By pursuing this goal, we are applying a very simple cost model X  X he cost of a solution only depends on its num-ber of questions. Although the cost of a task in a crowdsourcing en-vironment may depend on monetary cost, latency and other factors, the number of questions is a generic, platform-independent cost measure and arguably proportionally correlates with the real cost. Therefore, we assume a sequential execution model which asks the crowd an ordered sequence of questions Q = h q 1 , ..., q asks q i +1 after rlt ( q i ) is obtained. Thereby, we do not consider asking multiple questions concurrently. In practice, such a parallel-execution framework will lead to shorter latency but more ques-tions (which may imply higher monetary cost) than our sequential-execution framework. One interesting direction of future work is to adapt our algorithms to a parallel framework and investigate the tradeoffs between latency and cost. Furthermore, in discussion of our approach, the focus shall be on how to f nd a short question se-quence instead of the algorithms X  complexity, since the time taken by crowdsourcers to answer questions will dominate the algorithms X  execution time.

To f nd a short sequence, we design a general algorithm frame-work, as displayed in Fig.3. Alg.1 shows the framework X  X  pseudo-code. Its execution is iterative. Each iteration goes through four steps X  question selection , outcome derivation , contradiction reso-lution , and terminationtest . In the i -th iteration, a question is selected and presented to the crowd. The question outcome rlt ( q i ) is derived from the crowd X  X  aggregated answers. On unusu-Algorithm 1: The general framework Input : O : the set of objects al occasions, if the outcome presents a contradiction to the obt ained outcomes of other questions so far, it is changed to the closest outcome to resolve contradiction. By computing R + ( Q i ) sitive closure of R ( Q i )  X  X he obtained outcomes to questions so far h q , . . . , q i i , the outcomes to certain questions are derived and such questions will never be asked. Based on R + ( Q i ) , if every object is determined to be either Pareto-optimal or non-Pareto optimal without uncertainty, the algorithm terminates.

Below, we discuss outcome derivation and termination test. Sec.3.1 examines the framework X  X  key step X  X uestion selection, and Sec.3.2 discusses contradiction resolution.
 Outcome derivation Given a question x ? c y , its outcome must be aggregated from multiple crowdsourcers, in order to reach a reliable result with conf dence. Particularly, one of three mutually-exclusive outcomes is determined based on k crowdsourcers X  an-swers to the question: rlt ( x ? c y ) = where  X  is such a predef ned threshold that  X &gt; 50% , # number of crowdsourcers (out of k ) preferring x over y on criterion c , and # y is the number of crowdsourcers preferring y over x on c . Fig.1b shows the outcomes of all 15 questions according to Equation (1) for comparing movies by story using k =5 and  X  =60% . Other conceivable def nitions may be used in determining the outcome of x ? c y . For example, the outcome may be def ned as the choice (out of the three possible choices) that receives the most votes from the crowd. The ensuing discussion is agnostic to the specif c def nition.

The current framework does not consider different levels of con-f dence on question outcomes. The conf dence on the outcome of a question may be represented as a probability value based on the distribution of crowdsourcers X  responses. An interesting direction for future work is to f nd Pareto-optimal objects in probabilistic sense. The conf dence may also ref ect the crowdsourcers X  quality and credibility [18]. Termination test In e ach iteration, Alg.1 partitions the objects into three sets by their Pareto-optimality based on the transitive clo-sure of question outcomes so far. If every object X  X  Pareto-optimality has been determined without uncertainty, the algorithm terminates. Details are as follows.
 Def nition 1 (Transitive Closure of Outcomes) . Given a set of ques-tions Q = h q 1 , ..., q n i , the transitive closure of their outcomes { rlt ( q 1 ) , ..., rlt ( q n ) } is R + ( Q )= { x  X  c y | ( x  X  c y  X  R ( Q ))  X  (  X  w 1 ,w 2 ,...,w m : w 1 = x , w m : w
In essence, the transitive closure dictates x  X  c z wit hout asking the question x ? c z , if the existing outcomes R ( Q ) (and recursive-ly the transitive closure R + ( Q ) ) contains both x  X  c Based on R + ( Q ) , the objects O can be partitioned into three sets: O  X  = { x  X  O |  X  y  X  O : (  X  c  X  C : x  X  c y  X  R + ( Q ))  X  (  X  c  X  C : x  X  c y  X  R + ( Q )) } ; O  X  = { x  X  O |  X  y  X  O : (  X  c  X  C : y  X  c x  X  R + ( Q )  X   X  R + ( Q ))  X  (  X  c  X  C : y  X  c x  X  R + ( Q )) } ; O ? = O \ ( O  X   X  O  X  ) .
 O  X  contains objects that must be Pareto-optimal, O  X  contains ob-jects that cannot possibly be Pareto-optimal, and O ? contains ob-jects for which the incomplete knowledge R + ( Q ) is insuff cient for discerning their Pareto-optimality. The objects in O ? out to be Pareto-optimal after more comparison questions. If the set O ? for a question sequence Q is empty, O  X  contains all Pareto-optimal objects and the algorithm terminates. We call such a terminal sequence , def ned below.
 Def nition 2 (Terminal Sequence) . A question sequence Q is a terminal sequence if and only if, based on R + ( Q ) , O ?
Given objects O and criteria C , there can be a huge number of terminal sequences. Our goal is to f nd a sequence as short as possible. As Fig.3 and Alg.1 show, the framework is an iterative procedure of object partitioning based on question outcomes. It can also be viewed as the process of moving objects from O O  X  and O  X  . Once an object is moved to O  X  or O  X  , it cannot be moved again. With regard to this process, we make two important observations, as follows.  X 
In order to declare an object x not Pareto-optimal, it is suff cient to just know x is dominated by another object . It immediately follows that we do not really care about the dominance relation-ship between objects in O  X  and thus can skip the comparisons between such objects. Once we know x  X  O ? is dominated by another object, it cannot be Pareto-optimal and is immediately moved to O  X  . Quickly moving objects into O  X  can allow us skipping many comparisons between objects in O  X  .  X 
In order to declare an object x Pareto-optimal, it is necessary to know that no object can dominate x . This means we may need to compare x with all other objects including non Pareto-optimal ob-jects. As an extreme example, x may be dominated by only a non-
Pareto optimal object y but not by any other object (not even the objects dominating y ). This is because object dominance based on preference relations is intransitive, which is formally stated in Property 1. The intransitivity of preference relation formed by Pareto composition of strict partial orders was discussed in [13].
Property 1 (Intransitivity of Object Dominance) . Object domi-nance based on the preference relations over a set of criteria is not transitive. Specif cally, if x  X  y and y  X  z , it is not necessarily true that x  X  z . In other words, it is possible that x  X  z or even z We show the intransitivity of object dominance by an example.
Co n sider objects O = { x,y,z } , criteria C = { c 1 , c erence relations in Fig.4. Three dominance relationships violate
Figure 4: Intransitivity of object dominance: x  X  y , y  X  tra nsitivity: (i) x  X  y (based on x  X  c (based on y  X  c z  X  c 2 x , z  X  c 3 x ). As another example, in Fig.1a, b  X  b  X  m c , b  X  a c , where s = story , m = music , a = acting ) and c ince c  X  s a , c  X  m a , c  X  a a ), but a  X  b (since b  X  s where transitivity does not hold.

Differently, transitivity of object dominance holds in skyline anal-ysis [5]. The contradiction is due to the lack of explicit attribute representation X  X n our case two objects may be considered equal-ly good on a criterion if they are indifferent, while in skyline analysis they are equally good regarding an attribute if they bear identical values. Skyline query algorithms exploit the transitivity of object dominance to reduce execution cost, because an object can be immediately excluded from further comparison once it is found dominated by any other object. However, due to Property 1, we cannot leverage such pruning anymore.

Based on these observations, the overriding principle of our ques-tion selection strategy (Alg.2) is to identify non-Pareto optimal objects as early as possible. At every iteration of the framework (Alg.1), we choose to compare x and y by criterion c (i.e., ask ques-tion x ? c y ) where x ? c y belongs to candidate questions . Such candi-date questions must satisfy three conditions (Def nition 3). There can be many candidate questions. In choosing the next question, by the aforementioned principle, we select such x ? c y that x is more likely to be dominated by y . More specif cally, we design two or-dering heuristics X  macro-ordering and micro-ordering . Given the three object partitions O  X  , O  X  and O ? , the macro-ordering idea is simply that we choose x from O ? (required by one of the conditions on candidate questions) and y from O  X   X  O ? (if possible) or (otherwise). The reason is that it is less likely for an object in dominate x . Micro-ordering further orders all candidate questions satisfying the macro-ordering heuristic. In Sec.4, we instantiate the framework into a variety of solutions with varying power in pruning questions, by using different micro-ordering heuristics. Def nition 3 (Candidate Question) . Given Q , the set of asked ques-tions so far, x ? c y is a candidate question if and only if it satisf es the following conditions: (i) The outcome of x ? c y is unknown yet, i.e., rlt ( x ? (ii) x must belong to O ? ; (iii) Based on R + ( Q ) , the possibility of y  X  x must not be ruled Algorithm 2: Que stion selection We denote the set of candidate questions by Q can . Thus, = { x ? c y | rlt ( x ? c y ) /  X  R + ( Q )  X  x  X  O ?  X  (  X  c R + ( Q )) } .

If no candidate question exists, the question sequence Q is a t erminal sequence. The reverse statement is also true, i.e., upon a terminal sequence, there is no candidate question left. This is formalized in the following property.
 Property 2. Q can =  X  if and only if O ? =  X  .
 Proof. The proof is omitted due to space limitations and can be found in the technical report [4].

Questions violating the three conditions may also lead to termi -nal sequences. However, choosing only candidate questions match-es our objective of quickly identifying non-Pareto optimal objects. Below we justify the conditions.

Condition (i): This is straightforward. If R ( Q ) or its transitive closure already contains the outcome of x ? c y , we do not ask the same question again.

Condition (ii): This condition essentially dictates that at least one of the two objects in comparison is from O ? . (If only one of them belongs to O ? , we make it x .) Given a pair x and y , if neither is from O ? , there are three scenarios X (1) x  X  O  X  , (2) x  X  O  X  , y  X  O  X  or x  X  O  X  , y  X  O  X  , (3) x  X  O  X  , know an object is in O  X  or O  X  , its membership in such a set will never change. Hence, we are not interested in knowing the dominance relationship between objects from O  X  and O  X  only. In all these three scenarios, comparing x and y is only useful for indi-rectly determining (by transitive closure) the outcome of comparing other objects. Intuitively speaking, such indirect pruning is not as eff cient as direct pruning.

Condition (iii): This condition requires that, when x ? c sen, we cannot rule out the possibility of y dominating x . Other-wise, if y cannot possibly dominate x , the outcome of x ? help prune x . Note that, in such a case, comparing x and y by help prune y , if y still belongs to O ? and x may dominate y . Such possibility is not neglected and is covered by a different representa-tion of the same question X  y ? c x , i.e., swapping the positions of x and y in checking the three conditions. If it is determined x and y cannot dominate each other, then their further comparison is only useful for indirectly determining the outcome of comparing other objects. Due to the same reason explained for condition (ii), such indirect pruning is less eff cient.

The following simple Property 3 helps to determine whether y is possible: If x is better than y by any criterion, then we can already rule out the possibility of y  X  x , without knowing the outcome of their comparison by every criterion. This allows us to skip further comparisons between them. Its correctness is straightforward based on the def nition of object dominance.
 Property 3 (Non-Dominance Property) . At any given moment, suppose the set of asked questions is Q . Consider two objects x and y for which the comparison outcome is not known for every criterion, i.e.,  X  c such that rlt ( x ? c y ) /  X  R + ( Q ) mined that y  X  x if  X  c  X  C such that x  X  c y  X  R + ( Q )
In justifying the three conditions in def ning candidate questi on-s, we intuitively explained that indirect pruning is less eff cient X  if it is known that x does not belong to O ? or y cannot possi-bly dominate x , we will not ask question x ? c y . We now justi-fy this strategy theoretically and precisely. Consider a question sequence Q = h q 1 , . . . , q n i . We use O  X  ( Q ) , O denote object partitions according to R + ( Q ) . For any question the subsequence comprised of its preceding questions is denoted Q it was chosen (i.e., after R ( Q i  X  1 ) was obtained), we say it is a non-candidate . The following Theorem 1 states that, if a question sequence contains non-candidate questions, we can replace it by a shorter or equally long sequence without non-candidate questions that produces the same set of dominated objects O  X  . Recall that the key to our framework is to recognize dominated objects and move them into O  X  as early as possible. Hence, the new sequence will likely lead to less cost when the algorithm terminates. Theorem 1. If Q contains non-candidate questions, there exists | Q  X  |  X  | Q | and O  X  ( Q  X  ) = O  X  ( Q ) .
 Proof. We prove by demonstrating how to transform Q into such a Q it and, when necessary, replace several questions. The decisions and choices are partitioned into three mutually exclusive scenarios, which correspond to violations of the three conditions in Def ni-tion 3. The detailed proof is omitted due to space limitations and can be found in the technical report [4].
A preference relation can be more accurately derived, if more input is collected from the crowd. However, under practical con-straints on budget and time, the limited responses from the crowd ( k answers per question) may present two types of contradicting preferences. (i) Suppose rlt ( x ? c y )= x  X  c y and rlt ( y ? c z )= derived, i.e., they belong to R ( Q ) . They together imply x since a preference relation must be transitive. Therefore the ques-tion x ? c z will not be asked. If the crowd is nevertheless asked to further compare x and z , the result rlt ( x ? c z ) might be possibly z  X  c x , which presents a contradiction. (ii) Suppose rlt ( x ? c y )= x  X  c y and rlt ( y ? c z )= derived from the crowd. If the crowd is asked to further compare x and z , the result rlt ( x ? c z ) might be possibly z  X  c y  X  c z and z  X  c x together imply y  X  c x , which contradicts with x (A symmetric case is rlt ( x ? c y )= x  X  c y , rlt ( y ? crowd might respond with rlt ( x ? c z )= x  X  c z , which also leads to contradiction with x  X  c y . The following discussion applies to this symmetric case, which is thus not mentioned again.)
In practice, such contradictions are uncommon. This is easy to understand intuitively X  X s long as the underlying preference rela-tion is transitive, collective wisdom of the crowds will ref ect it. We can f nd evidence of it in [27, 10], which conf rmed that preference judgments of relevance in document retrieval are transitive.
Nevertheless, contradictions still occur. Type (i) contradictions can be prevented by enforcing the following simple Rule 1 to as-sume transitivity and thus skip certain questions. They will never get into the derived preference relations. In fact, in calculating transitive closure (Def nition 1) and def ning candidate questions (Sec.3.1), we already apply this rule.
 Rule 1 (Contradiction Prevention by Skipping Questions) . Given objects x, y, z and a criterion c , if rlt ( x ? c y )= x y  X  c z , we assume rlt ( x ? c z )= x  X  c z and thus will not ask the crowd to further compare x and z by criterion c .

To resolve type (ii) contradictions, we enforce the following s im-ple Rule 2.
 Rule 2 (Contradiction Resolution by Choosing Outcomes) . Con-sider objects x, y, z and a criterion c . Suppose rlt ( x and rlt ( y ? c z )= y  X  c z are obtained from the crowd. If z  X  c x is obtained from the crowd afterwards, we replace the out-come of this question by x  X  c z . (Note that we do not replace it by x  X  c z , since z  X  c x is closer to x  X  c z .)
At every iteration of Alg.1, we choose a question x ? c y from the set of candidate questions. By macro-ordering, when available, the question selection strategy (Alg.2) chooses a candidate question in which y /  X  O  X  , i.e., it chooses from Q 1 can . Otherwise, it chooses from Q 2 can . The size of Q 1 can and Q 2 can can be large. Micro-ordering is for choosing from the many candidates. As discussed in Sec.3, in order to f nd a short question sequence, the overriding principle of our question selection strategy is to identify non-Pareto optimal objects as early as possible. Guided by this principle, this section discusses several micro-ordering strategies. Since the strate-gies are the same for Q 1 can and Q 2 can , we will simply use the term  X  X andidate questions X  without distinction between Q 1 can
RandomQ , as its name suggests, simply selects a random candi-date question. Table 2 shows an execution of the general framework under RandomQ for Example 1. For each iteration i , the table shows the question outcome rlt ( q i ) . Following the question form x ? c y in Def nition 3, the object  X  x  X  in a question is underlined when we present the question outcome. The column  X  X erived results X  dis-plays derived question outcomes by transitive closure (e.g., a dominance (e.g., b  X  d after q 20 ). The table also shows the object partitions ( O  X  , O ? and O  X  ) when the execution starts and when the partitions are changed after an iteration. Multiple iterations may be presented together if other columns are the same for them.
As Table 2 shows, this particular execution under RandomQ requires 30 questions. When the execution terminates, it f nds the only Pareto-optimal object b . This simplest micro-ordering strate-gy already avoids many questions in the brute-force approach. The example clearly demonstrates the benef ts of choosing candidate questions only and applying macro-strategy.
RandomP randomly selects a pair of objects x and y and keeps asking questions to compare them ( x ? c y or y ? c x ) until no such candidate question remains, upon which it randomly picks another pair of objects. This strategy echoes our principle of eagerly identi-fying non-Pareto optimal objects. To declare an object x non-Pareto optimal, we must identify another object y such that y dominates x . If we directly compare x and y , it requires comparing them by every criterion in C in order to make sure y  X  x . By skipping questions according to transitive closure, we do not need to directly compare them by every criterion. However, Property 4 below states that we still need at least | C | questions involving x  X  X ome are direct com-parisons with y , others are comparisons with other objects which indirectly lead to outcomes of comparisons with y . When there is a candidate question x ? c y , it means y may dominate x . The fewer criteria remain for comparing them, the more likely y will dominate x . Hence, by keeping comparing the same object pair, RandomP aims at f nding more non-Pareto objects by less questions. Property 4. Given a set of criteria C and an object x  X  O | C | pairwise comparison questions involving x are required in order to f nd another object y such that y  X  x .
 Proof. The proof is omitted due to space limitations and can be found in the technical report [4].
 Table 3 illustrates an execution of Ran domP for Example 1. The initial two questions are between c and f . Afterwards, it is concluded that c  X  f by Property 3. Therefore, RandomP moves on to ask 3 questions between a and e . In total, the execution requires 28 questions. Although it is shorter than Table 2 by only questions due to the small size of the example, it clearly moves objects into O  X  more quickly. (In Table 2, O  X  is empty until the 20 th question. In Table 3, O  X  already has 3 objects after 20 questions.) The experiment results in Sec.5 exhibit signif cant performance gain of RandomP over RandomQ on larger data. Similar to RandomP , once a pair of objects x and y are chosen, FRQ keeps asking questions between x and y until there is no such candidate questions. Different from RandomP , instead of randomly picking a pair of objects, FRQ always chooses a pair with the fewest remaining questions. There may be multiple such pairs. To break ties, FRQ chooses such a pair that x has dominated the fewest other objects and y has dominated the most other objects. Furthermore, in comparing x and y , FRQ orders their remaining questions (and thus criteria) by how likely x is worse than y on the criteria. Below we explain this strategy in more detail. Selecting Object Pair Consider a question sequence Q i so far and FRQ is to select the next question Q i +1 . We use C x,y denote the set of criteria c suc h that x ? c y is a candidate question, i.e., C x,y = { c  X  C | x ? c y  X  Q 1 can } . (We assume Q Otherwise, FRQ chooses from Q 2 can in the same way; cf. Alg.2.) By Def nition 3, the outcomes of these questions are unknown, i.e., question (whose outcome is unknown) between x and y is a candi-date question, then all remaining questions between them are candi-date questions. FRQ chooses a pair with the fewest remaining can-didate questions, i.e., a pair belonging to S 1 =arg min (
The reason to choose such a pair is intuitive. It requires at least | C x,y | candidate questions to determine y  X  x . (The proof would be similar to that of Property 4.) Therefore, min ( x,y ) minimum number of candidate questions to further ask, in order to determine that an object is dominated, i.e., non-Pareto optimal. Thus, a pair in S 1 may lead to a dominated object by the fewest questions, matching our goal of identifying non-Pareto optimal ob-jects as soon as possible.

We further justify this strategy in a probabilistic sense. For y to be realized, it is necessary that none of the remaining ques-tions has an outcome x  X  c y , i.e.,  X  c  X  C x,y : rlt ( x Make the simplistic assumption that every question x ? c y has an equal probability p of not having outcome x  X  c y , i.e., tion outcomes, the probability of satisfying the aforementioned nec-essary condition is p | C x,y | . By taking a pair belonging to have the largest probability of f nding a dominated object. We note that, for y  X  x to be realized, in addition to the above neces-sary condition, another condition must be satisf ed X  X f  X  c y  X  c x  X  R + ( Q i ) , the outcome of at least one remaining question should be y  X  c x , i.e.,  X  c  X  C x,y : rlt ( x ? c y )= y probability-based analysis does not consider this extra requirement. Breaking Ties There can be multiple object pairs with the fewest remaining questions, i.e., | S 1 | &gt; 1 . To break ties, FRQ chooses such an x that has dominated the fewest other objects, since it is more likely to be dominated. If there are still ties, FRQ further chooses such a y that has dominated the most other objects, since it is more likely to dominate x . More formally, FRQ chooses a pair belonging to S 2 = { ( x,y )  X  S 1 |  X  ( x X ,y X  )  X  S 1 such that ( d ( x X  )= d ( x )  X  d ( y X  ) &gt;d ( y )) } , where the function number of objects so far dominated by an object, i.e.,  X  x |{ y | x  X  y based on R + ( Q i ) }| . This heuristic follows the principle of detecting non-Pareto optimal objects as early as possible. Note that S 2 may still contain multiple object pairs. In such a case, FRQ chooses an arbitrary pair.
 Selecting Comparison Criterion Once a pair ( x,y ) is chosen, FRQ has to select a criterion for the next question. FRQ orders the remaining criteria C x,y based on the heuristic that the sooner it understands y  X  x will not happen, the lower cost it pays. As discussed before, | C x,y | questions are required in order to conclude that y  X  x ; on the other hand, only one question (if asked f rst) can be enough for ruling it out. Consider the case that x is better than y by only one remaining criterion, i.e.,  X  c  X  C x,y : rlt ( x  X  c  X  C x,y , c  X  6 = c : rlt ( x ? c  X  y )= x  X  c  X  y . If FRQ asks x other remaining questions, it takes | C x,y | questions to understand y does not dominate x ; but if x ? c y is asked f rst, no more questions are necessary, because there will be no more candidate questions in the form of x ? c y .

Therefore, FRQ orders the criteria C x,y by a scoring function that ref ects the likelihood of x  X  X  superiority than y by the corre-sponding criteria. More specif cally, for each c  X  C x,y , its score is r ( x,y ) = r c ( y )+ r  X  c ( y )  X  r  X  X  c ( y )  X  ( r c ( x r ( y ) = |{ z | z  X  c y  X  R + ( Q i ) }| , r  X  c ( y )= |{ z is the number of objects preferred over y by criterion c , is the number of objects equally good (or bad) as y by c , and r c ( y ) is the number of objects to which y is preferred with regard to c . FRQ asks the remaining questions in decreasing order of the corresponding criteria X  X  scores. This way, it may f nd such a question that rlt ( x ? c y )= x  X  c y earlier than later.
Table 4 presents the framework X  X  execution for Example 1, by applying the FRQ policy. In addition to the same columns in Tables 2 and 3, Table 4 also includes an extra column to show, at each iteration, the chosen object pair for the next question ( x,y ) and the set of remaining comparison criteria between them ( The criteria in C x,y are ordered by the aforementioned ranking function r ( ) . At the beginning of the execution, the object pair is arbitrarily chosen and the criteria are arbitrarily ordered. In the example, we assume a ? s b is chosen as the f rst question. After q , FRQ can derive that a  X  b . Hence, there is no more candidate question between them and FRQ chooses the next pair ( a,c ). Three questions are asked for comparing them. At the end of q 5 object pairs have the fewest remaining questions. By breaking ties, ( b,c ) is chosen as the next pair, since only c has dominated any object so far. The remaining criteria C b,c are ordered as because r a ( b,c ) &gt;r s ( b,c ) and r a ( b,c ) &gt;r sequence terminates after 17 questions, much shorter than the and 28 questions by RandomQ and RandomP , respectively.
To conclude the discussion on micro-ordering, we derive a lower bound on the number of questions required for f nding all Pareto-optimal objects (Theorem 2). The experiment results in Sec.5 re-veal that FRQ is nearly optimal and the lower bound is practically tight, since the number of questions used by FRQ is very close to the lower bound.
 Theorem 2. Given objects O and criteria C , to f nd all Pareto-optimal objects in O , at least ( | O | X  k )  X | C | +( k  X  1)  X  2 comparison questions are necessary, where k is the number of Pareto-optimal objects in O .
 Proof. The proof is omitted due to space limitations and can be found in the technical report [4].
We d esigned and conducted experiments to compare the eff cien-cy of different instantiations of the general framework under vary-ing problem sizes. Our experiments used both a real crowdsourcing marketplace and simulations based on a real dataset.
Figure 5: No. of Pareto-optimal objects. Varying | O | and
We studied the eff ciency and scalability of various instantiations of the general framework. Given the large number of questions required for such a study, we cannot afford using a real crowdsourc-ing marketplace. Hence, we performed the following simulation. Each object is an NBA player in a particular year. The objects are compared by 10 criteria, i.e., performance categories such as points , rebounds , assists , etc. We simulated the corresponding 10 preference relations based on the players X  real performance in individual years, as follows. Consider a performance category and two objects x =(player1, year1) and y =(player2, year2). x . player1 X  X  per-game performance on category c in year1 (similarly for y . c ). Values in each category c are normalized into the range [0 , 1] , where 0 and 1 correspond to the minimal and maximal val-ues in c , respectively. Suppose x . c&gt; y . c . We generated a uniform random number v in [ 0 , 1 ]. If v&lt; 1  X  e  X  ( x.c  X  y.c ) , we set x otherwise we set x  X  c y . This way, we introduced a perturbation into the preference relations in order to make sure they are partial order-s, as opposed to directly using real performance statistics (which would imply total orders). Fig.5 shows that the number of Pareto-optimal objects increases by the sizes of both object set are randomly selected) and criteria set C (the f rst | C | the aforementioned 10 criteria).
 Effectiveness of candidate questions and macro-ordering To verify the effectiveness of candidate questions and macro-ordering, we compared f ve methods X  BruteForce ,  X  X Q X  X O ,  X  X Q+MO , +CQ X  X O , and +CQ+MO . The notation +/ X  before CQ and MO indicates whether a method only selects candidate questions ( CQ )
Figure 7: No. of questions by different micro-ordering heuristics. and whether it applies the macro-ordering strategy ( MO ), respec-tively. In all these f ve methods, qualifying questions are randomly selected, i.e., no particular micro-ordering heuristics are applied. For instance, +CQ+MO selects only candidate questions and ap-plies macro-ordering. Hence, it is equivalent to RandomQ . Fig.6 shows the numbers of required pairwise comparisons (in logarith-mic scale) for each method, varying by object set size ( | O | 500 to 10 , 000 for | C | =4 and | C | =10 ) and criterion set size ( from 3 to 10 for | O | =3 , 000 and | O | =10 , 000 ). The f gure clearly demonstrates the effectiveness of both CQ and MO , as taking out either feature leads to signif cantly worse performance than Ran-domQ . Particularly, the gap between +CQ X  X O and  X  X Q+MO suggests that choosing only candidate questions has more funda-mental impact than macro-ordering. If neither is applied (i.e.,  X  CQ X  X O ), the performance is equally poor as that of BruteForce . (  X  X Q X  X O uses slightly less questions than BruteForce , since it can terminate before exhausting all questions. However, the dif-ference is negligible for practical purpose, as their curves overlap under logarithmic scale.) Effectiveness of micro-ordering Fig.7 presents the numbers of pairwise comparisons required by dif-ferent micro-ordering heuristics ( RandomQ , i.e., +CQ+MO , Ran-domP , FRQ ) and LowerBound (cf. Theorem 2) under varying sizes of the object set ( | O | from 500 to 10 , 000 for | C | =4 | C | =10 ) and the criteria set ( | C | from 3 to 10 for | O | =10 , 000 ). In all these instantiations of the general framework, CQ and MO are applied. The results are averaged across 30 cutions. All these methods outperformed BruteForce by orders of magnitude. ( BruteForce is not shown in Fig.7 since it is off scale, but its number can be calculated by equation | C | X | O | X  ( | O |  X  1) / 2 .) For instance, for 5 , 000 objects and 4 criteria, the ratio of pairwise comparisons required by even the naive RandomQ to that used by BruteForce is already as low as 0 . 0048 . This clearly shows the effectiveness of CQ and MO , as discussed for Fig.6. The ratios for RandomP and FRQ are further several times smaller ( 0 . 00094 and 0 . 00048 , respectively). The big gain by FRQ justi-f es the strategy of choosing object pairs with the fewest remain-ing questions. Especially, FRQ has nearly optimal performance, because it gets very close to LowerBound in Fig.7. The small Figure 8: No. of questions by different micro-ordering heurist ics. | C | = 3 , varying | O | . gap between FRQ and LowerBound also indicates that the lower bound is practically tight. The f gure further suggests excellent scalability of FRQ as its number of questions grows almost linearly by both | C | and | O | .
We also studied the performance of the proposed algorithms us-ing the popular crowdsourcing marketplace Amazon Mechanical Turk (AMT). The task is to compare 100 photos of our institu-tion with regard to color , sharpness and landscape . To obtain the ground-truth data, all 14 , 850 possible pairwise questions were par-titioned into 1 , 650 tasks, each containing 9 questions on a criterion. An AMT crowdsourcer is allowed to perform a task only if they have responded to at least 100 HITs (Human Intelligence Tasks) before with at least 90% approval rate. Furthermore, we imple-mented basic quality control by including 2 additional validation questions in each task that expect certain answers. For instance, one such question asks the crowd to compare a colorful photo and a dull photo by criterion color . A crowdsourcer X  X  responses in a task are discarded if their response to a validation question deviates from our expectation. ( 236 crowdsourcers failed on this.) The parameters in Equation (1) were set to be k =5 and  X  =0 . 6 in total (1 , 650  X  5+236)  X  (9+2) = 93 , 346 pairwise comparisons were performed by AMT crowdsourcers. We paid 1 cent for each comparison and therefore spent close to $1,000 in total.
The responses to all possible questions provide the ground-truth data. An algorithm execution only needs the responses to a sub-set of the questions. We randomly selected a subset of photos ( | O | from 10 to 100 ) and applied various algorithms to f nd Pareto-optimal photos. Figure 8 shows, for varying | O | , the number of questions (in logarithmic scale) required by each micro-ordering strategy. To account for the randomness in RandomP and Ran-domQ , we repeated these two algorithms, respectively, 30 and we reported the average numbers of questions. Conf rming the results in Figure 7, FRQ was close to the theoretical lower bound, performing better than the other two methods, and RandomP out-performed RandomQ .
This is the f rst study on using crowdsourcing to f nd Pareto-optimal objects when objects do not have explicit attributes and preference relations are strict partial orders. The partial orders are obtained by pairwise comparison questions to the crowd. It intro-duces an iterative question-selection framework that is instantiated into different methods by exploiting the ideas of candidate question-s, macro-ordering and micro-ordering. Experiment were conducted by simulations on large object sets and by using a real crowdsourc-ing marketplace. The results exhibited not only orders of magni-tude reductions in questions against a brute-force approach, but also close-to-optimal performance from the most eff cient method.
