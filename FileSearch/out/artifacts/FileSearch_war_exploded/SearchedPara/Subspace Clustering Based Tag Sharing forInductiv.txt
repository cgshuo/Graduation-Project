 Annotating images with tags is useful for indexing and re-trieving images. However, many available annotation data include missing or inaccurate annotations. In this paper, we propose an image annotation framework which sequen-tially performs tag completion and refinement. We utilize the subspace property of data via sparse subspace clustering for tag completion. Then we propose a novel matrix com-pletion model for tag refinement, integrating visual correla-tion, semantic correlation and the novelly studied property of complex errors. The proposed method outperforms the state-of-the-art approaches on multiple benchmark datasets even when they contain certain levels of annotation noise. image annotation; subspace clustering; matrix completion; complex errors
It is useful to annotate images with textual tags for the purpose of image indexing and retrieval. To annotate proper tags, one need to bridge the gap between low level visual features of an image and corresponding high level semantic information [16]. Since manual annotation is labor intensive, automatic annotation has aroused much attention. Many machine learning based approaches have been developed.
Currently many image annotation data have been col-lected from crowdsourcing services [21, 12], providing large amount of data for training while being noisy due to an-notation errors. Annotation errors are usually complex and mainly come in two forms: missing tags and inaccurate tags. Most image annotation approaches solely focus on one of those two, either trying to impute the missing tags (tag com-pletion/tag assignment) [11] or correcting inaccurate tags (tag refinement) [22, 8, 16]. Other existing methods fail to model the complex errors properly. They either treat them in the same way [24], ignoring the complex property of the  X  Corresponding author.
 errors, or rigidly assign fixed weights to different kinds of er-rors [11], having no adaptability when working on different datasets with different levels of annotation errors.
In this paper, we propose a framework called Subspace clustering and Matrix completion with Complex errors (SM-C). Since current tag refinement methods suffer from the extreme sparsity problem [20], SMC performs tag comple-tion and refinement sequentially. During tag completion, SMC tries to introduce many additional proper tags to im-ages via exploring subspace property in the image collection. We then adapt the inductive matrix completion [13] model to perform the following tag refinement procedure, utilizing side information such as the correlation between visual fea-tures and their corresponding tags (visual correlation), cor-relation between the semantic information of tags (semantic correlation) and the complex errors.

The main contributions of this paper include:
We denote the observed tag matrix as O  X  { 0 , 1 } N i  X  N where each row corresponds to one image, each column cor-responds to one textual tag, and N i and N t denote the num-ber of images and tags, respectively. O ij takes value 1 only if image i is annotated with tag j and 0 otherwise.
We are targeting at modifying the values in matrix O by matrix completion methods to perform image annotation. After the matrix completion procedure, if the value of O ij changes from nonzero (zero) to zero (nonzero), we say that the algorithm removes (adds) tag j from (to) image i . Meth-ods based on matrix completion are robust and efficient since they only operate on the tag matrix, avoiding error propa-gation from image segmentation.

However, in many cases O is so sparse that some columns have at most one known entries and some rows have no known entries at all, making existing methods not applicable [20]. In order to overcome such extreme sparsity, we first perform tag completion to make O denser, creating a better condition for the following tag refinement procedure. More specifically, we perform subspace clustering over images and share tags within subspaces.

For tag refinement, existing methods usually depends heav-ily on image segmentation and visual feature extraction ac-curacies [1]. However, image segmentation and feature ex-traction procedures always contain a lot of noises, which affect the following annotation procedure severely. Mean-while, recent matrix completion based methods [10, 8, 9] stand out due to their robustness and efficiency, since these algorithms avoid the image segmentation procedure. Our proposed framework is called Subspace clustering and Matrix completion with Complex errors (SMC), because it utilizes the subspace property of image collections (Sec-tion 2.2) and addresses the complex errors and side infor-mation in an inductive matrix completion model for tag re-finement (Section 2.3).
It is reasonable to assume that images belonging to differ-ent categories are approximately sampled from a mixture of several low-dimensional subspaces. The membership of the data points to the subspaces is unobserved, leading to the challenging problem of subspace clustering. Here the goal is to cluster data into k clusters with each cluster correspond-ing to a subspace.

One of the state-of-the-art method is the sparse subspace clustering (SSC) model [5]. The idea behind SSC is to ex-press a data point as a linear (or affine) combination of neighboring data points. The neighbors can be any other points in the data set. While every point is a combination of all other data points, SSC seeks for the sparsest represen-tation among all the candidates by minimizing the number of nonzero coefficients [6].

We denote the set of images, represented as visual feature vectors, as V = [ v 1 , v 2 ,..., v n ]. Assuming that they are drawn from a union of k subspaces. Each column of V can be represented by a linear combination of the bases in a  X  X ictionary X . SSC uses the matrix V itself as the dictionary while explicitly considering noise: each z i being the representation of v i and E is the error matrix. This problem can be solved efficiently using modern sparse optimization algorithms, such as linearized alternat-ing direction methods [17].

Given a sparse representation for each data point, we can define the affinity matrix as A = | Z | + | Z &gt; | . Subspaces are then obtained by applying spectral clustering to the Lapla-cian matrix of A [5].
We improve the search based neighbor voting algorithm proposed in [18] to share tags in each cluster separately. We rank all the tags for the cluster, taking tag frequency, tag co-occurrence and local frequency into consideration. The elements of tag matrix after tag sharing are no longer binary but take values in [0 , 1], representing the confidence level between each image-tag pair.
The tag completion procedure makes the tag matrix much denser and thus avoids the extreme sparsity problem. Then we can refine the tag matrix. In our framework we novelly adapt the inductive matrix completion model (IMC) [13] for tag refinement, due to its scalability and capability of incorporating various kinds of side information.
Let v i  X  R f i denote the f i -dimensional feature vector of image i and t j  X  R f t denote the f t -dimensional feature vec-N i images, where the i -th row is the image feature vector v where the i -th row is the tag feature t &gt; i .

For image annotation, we assume that the tag matrix can be approximated by applying visual feature vectors and tag feature vectors associated with its row and column entries onto an underlying low-rank matrix M , i.e. O  X  VMT &gt; , rank r N i ,N t . The goal is to solve the following problem: A common choice for the loss function is the squared loss. The low-rank constraint on PQ &gt; makes (3) NP-hard. A standard relaxation is to use the trace norm, i.e. sum of singular values. Minimizing the trace-norm of M = PQ &gt; optimization problem we use in this work is therefore: We want to get the refined tag matrix  X  O = VPQ &gt; from the original tag matrix O . Here we represent the i th row of  X  O as  X  O i , corresponding to the refined tag vector of image i . Thus we can measure the correlation between image i and image j in two ways: 1) similarity between image features v i and v j , 2) similarity between refined tag vectors  X  O i and  X  O j . Since visually similar images often belong to similar themes and thus are annotated with similar tags, these two kinds of similarities should be correlated.
Such visual correlation can be enforced by solving the fol-lowing optimization where k  X  O i  X   X  O j k 2 measures the similarity between tag vec-tors  X  O i and  X  O j and g ij measures the similarity between visual features v i and v j . In this work, we adopt cosine similarity, i.e. g ij = cos( v i , v j ). The formulation forces tag vectors with large similarities also have large similarity in their corresponding visual features and vice versa.
The formulation can be rewritten as min where L v = diag( G1 )  X  G is the Graph Laplacian [3] of the similarity matrix G = ( g ij ).
Similarly, we can also enforce semantic correlation be-tween tags. Since each column of the matrix  X  O represents the feature of a tag, we can measure the correlation between two tags using the similarity between their corresponding column vectors of  X  O . Meanwhile, semantic similarity be-tween two tags can be measured using word vectors. These two kinds of similarities should be correlated as well.
We can enforce the semantic correlation by solving the following optimization, in a similar form as (6): min where L s = diag( H1 )  X  H is the Graph Laplacian of the sim-ilarity matrix H = ( h ij ), with each element h ij = cos( t
We utilize DeCAF 6 [4] to extract 4 , 096-dimensional visual features for each image, which have high level information. Meanwhile, we adopt pre-trained word embedding vectors (word2vec) [19] to construct 300-dimensional features for each tag, trying to capture semantic information.
As we have mentioned, annotation errors come in two forms: missing tags and inaccurate tags. Since human be-ings are relatively reasonable, the user-provided tags are rea-sonably accurate to certain level [24]. Users might miss one or several proper tags among the few related tags, but may become less probable to add one or several inaccurate tags from the massive unrelated tag sets [12]. In other words, if an image is not originally annotated with a tag, it is more likely that they really have no relation at all. Thus the errors are mainly composed of inaccurate tags rather than missing tags. And we should pay more attention to denoise the inaccurate tags rather than completing the missing ones.
To model the complex structure of errors, we improve the matrix completion model by putting less weights on the u-nannotated positions: min where  X  represents the positions where the images are o-riginally not annotated. U is a projection operator and  X  acts as a weighting parameter which changes adaptively in different datasets according to their noise levels.
Existing methods never model these two kinds of errors separately. They simply model the errors as Laplacian noise [24] or Gaussian noise [22]. To our knowledge, our model is the first to model the missing errors and inaccurate er-rors separately. The model can further adapt to different datasets according to their noise levels.
Based on the components regarding low-rankness, visu-al correlation, semantic correlation and complex errors, we formulate the objective function as follows:  X  By solving P and Q we can then construct the refined tag matrix  X  O = VPQ &gt; T &gt; and use it for refined annotation.
We set the regularization terms of visual correlation and semantic correlation with the same weight  X  2 for simplicity. This simplification does not harm performance, as we find during preliminary experiments.

This objective function is non-convex. To solve the opti-mization problem, we adapt the solver for low-rank empiri-cal risk minimization for multi-label learning (LEML) [23], which naturally fits for the settings of large-scale multi-label learning with missing labels. The solver uses alternating minimization (fix P and solve for Q and vice versa) to up-date the variables. When either P or Q is fixed, the result-ing subproblem in one variable ( Q or P ) can be solved using iterative conjugate gradient procedure.
We evaluate our proposed SMC framework on two bench-mark datasets: Labelme [21] and MIRFlickr-25K [12]. Ta-ble 1 demonstrates the detailed statistics. These two dataset-s, especially MIRFlickr-25K, are rather noisy, with a number of the tags being misspelled or meaningless. Hence, a pre-processing procedure is performed. We match each tag with entries in the Wikipedia thesaurus and only retain the tags in accordance with Wikipedia.

We compare our method with the state-of-the-art meth-ods, including matrix completion-based models (i.e. LRES [24], TCMR [8], RKML [9]), search-based models (i.e. JEC [18], TagProp [11], and TagRelevance [15]), mixture mod-els (i.e. CMRM [14] and MBRM [7]) and co-regularized learning model (FastTag [2]). The tag refinement procedure by itself, denoted as SMC IMC, is also compared to veri-fy the benefit from the tag completion procedure. We tune the parameters on the validation set of the two datasets separately for every method in comparison. Note that the weighting parameter  X  we tune changes from 0 . 4 (Labelme) to 0 . 7 (MIRFlickr-25K), confirming that as the data become more and more noisy, we should pay more attention to the noisy tags and less on missing tags.

We measure all the methods in terms of average preci-sion @ N ( AP @ N ) and average recall @ N ( AR @ N ). In the top N completed tags, precision @ N is to measure the ratio of correct tags and recall @ N is to measure the ratio of miss-ing ground-truth tags, both averaged over all test images.
Table 2 and Table 3 show performance comparisons on the two datasets, respectively.

We can observe that: 1) Generally, methods achieve bet-ter performance on Labelme, since tags in MIRFlickr-25K are more noisy. 2) Methods based on matrix completion, such as SMC, LRES and TCMR, usually achieve the best performances. 3) Our SMC framework shows increasing ad-vantage to LRES as the data become more and more noisy, justifying our assumption and model on the noises. 4) SM-Table 2: Performance Comparison on Labelme Table 3: Performance Comparison on MIRFlickr-25K C nearly outperforms all the other algorithms in all cases. 5) Performance comparison between SMC and SMC IMC demonstrate the remarkable benefit of tag completion for tag refinement. 6) Performance on MIRFlickr-25K in some sense provides an evidence for the robustness of SMC.
In this work we present an effective framework for image annotation by performing tag completion and tag refinement sequentially. Our method first clusters images using sparse subspace clustering and shares tags using a neighbor voting algorithm, then refines tags by adapting inductive matrix completion while novelly utilizing visual and semantic infor-mation. Experiments show the effectiveness of our frame-work and suggest that tag refinement can benefit a lot from performing tag completion first.
 Zhouchen Lin is supported by National Basic Research Pro-gram of China (973 Program) (grant no. 2015CB352502), National Natural Science Foundation (NSF) of China (grant nos. 61272341 and 61231002), and Microsoft Research Asia Collaborative Research Program. [1] G. Carneiro, A. Chan, P. Moreno, and N. Vasconcelos. [2] M. Chen, A. Zheng, and K. Weinberger. Fast image [3] F. Chung. Spectral graph theory . 1997. [4] J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, [5] E. Elhamifar and R. Vidal. Sparse subspace clustering. [6] E. Elhamifar and R. Vidal. Clustering disjoint [7] S. Feng, R. Manmatha, and V. Lavrenko. Multiple [8] Z. Feng, S. Feng, R. Jin, and A. Jain. Image tag [9] Z. Feng, R. Jin, and A. Jain. Large-scale image [10] A. Goldberg, B. Recht, J. Xu, R. Nowak, and X. Zhu. [11] M. Guillaumin, T. Mensink, J. Verbeek, and [12] M. Huiskes and M. Lew. The MIR Flickr retrieval [13] P. Jain and I. Dhillon. Provable inductive matrix [14] J. Jeon, V. Lavrenko, and R. Manmatha. Automatic [15] X. Li, C. Snoek, and M. Worring. Learning social tag [16] X. Li, T. Uricchio, L. Ballan, M. Bertini, C. G. Snoek, [17] Z. Lin, R. Liu, and Z. Su. Linearized alternating [18] A. Makadia, V. Pavlovic, and S. Kumar. A new [19] T. Mikolov, K. Chen, G. Corrado, and J. Dean. [20] N. Natarajan and I. Dhillon. Inductive matrix [21] B. Russell, A. Torralba, K. Murphy, and W. Freeman. [22] L. Wu, R. Jin, and A. Jain. Tag completion for image [23] H. Yu, P. Jain, P. Kar, and I. Dhillon. Large-scale [24] G. Zhu, S. Yan, and Y. Ma. Image tag refinement
