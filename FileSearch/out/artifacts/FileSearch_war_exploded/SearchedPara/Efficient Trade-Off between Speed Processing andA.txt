 A data stream is an ordered, continuous sequence of timestamped data elements [8]. The information naturally occurs in the form of a sequence of data values; examples include sensor data, Internet traffic, financial tickers, transaction logs, etc. The poten-tially infinite nature of data streams and their high arrival rate imply an inability to store a data stream in its entirety and restrict queri es and algorithms to process the data of a stream on the fly in a one pass fashion (i.e: without a prior data storage). In order to be processed in real time, queries must be specified before the beginning of streams. These queries run continuously over a period of time and incrementally return new results as new data arrive. The inability to store a comp lete stream suggests the use of approxi-mate summary structures, referred to in the literature as synopses [9] or digests [3]. By definition, a summary is an incomplete representation of the historical data of a stream. Summarizing online data streams has been larg ely studied with several techniques like sketching, sampling, building hist ograms, and wavelets [2] [7] [11].

In this paper, we investigate using both sampling and clustering processes to make historical summaries on data streams. The sampling method is known to be fast and efficient for answering important classes of queries, but this technique does not give good results for historical queries [4]. The clustering process enables to maintain a good performance for queries applied on distant past. By taking advantages of the sampling and the clustering processes, we show in this paper that we can make a summary of the whole data stream. Through our performance measurements, we show that the data kept using our algorithm, allow us to have good results for queries that cover a very distant past.

In this paper, we are interested in querying the whole data stream specially, the historical part of the stream. We study the multi-dimensional and numerical data stream produced by a source  X  X  X . Each data stream can be viewed as a sequence of and t i is the time when the reading element was produced by the source  X  X  X . We assume that the elements come under increasing timestamps. The study of delay in the arrival of elements can be managed by our approach but it is not the purpose of this paper.
We are interested in aggregating the stream values within a time interval [6]. This where Agg represents an aggregate operation (sum, count, etc.) and [ t start ,t end ] are the bounds of the time period over which the aggregate is calculated. The aggregate operation is computed over the data stream X  X  summary.

We present the Reservoir Hybrid (RH) approach in order to build historical sum-maries of data streams. It is a two stage summary: initially the summary is in the form of samples then, the elements of these samples evolve to make part of a cluster sum-mary. This proposal offers a good compromise in terms of accuracy and run-time. In this section, we briefly describe the Clu Stream and StreamSamp approaches which are used to create the RH approach for summarizing data streams.
 CluStream [1] is based on clustering of quantitative data but it can provide a structure particularly suited for the data stream summary. The objective is to build a summary as evolutionary micro-clusters including snapshots which are stored regularly. Aggarwal was inspired by the BIRCH algorithm [12] using the CFV structure (Cluster Feature Vector) to represent clusters and expands on this concept by adding temporal features. The CFV structure maintains statistical da ta that summarize all the elements of micro-clusters.

CluStream proceeds in two steps: the first one is the building of a data summary after the initialization of k micro-clusters (using the k-means algorithm). This step consists on the micro-clusters creation and mainte nance. When a new stream element enters the Clustream process, its distance to the centr oid of each micro-cluster is calculated and then assigned to the nearest micro-cluster. The CFV of this cluster is updated without storing the belonging of this element to the cluster. The second step is characterized by post-analysis which can be applied to the stored snapshots. At each clock time, the algorithm takes a snapshot and saves it according to a pyramidal time frame 1 .This consists of storing on disk the CFV of all micro-clusters. For post-analysis purposes CFVs allow the subtraction of two snapshots. Approximation of results for statistical queries can be computed over the pre-specified time horizon.

CluStream keeps representative snapshot s even for old stream elements. This allows the monitoring of the data stream over time. However, one weakness of the algorithm is that the process of distance calculations is expensive. A second limitation consists of the high number of parameters which depend on the nature of the stream and the arrival speed of elements.
 StreamSamp [5] is based on sampling a data stream. It was developed to overcome the limitations of CluStream. It combines a memory-based reduction method which is random sampling and a time-based reduction system which is tilted windows 2 .The algorithm proceeds in two steps: the first one is the building of data summary by sam-pling and re-sampling stream elements. Upon arrival, the data are sampled in a purely random way with a fixed sampling rate,  X  , and placed in samples of size T .When T is reached StreamSamp, stores on the disk the s ample elements and its starting and ending timestamps of constitution. The weight 1 is attributed to this sample. As it is impossible to keep all samples, when L samples of size T are filled, StreamSamp merges the two oldest samples following the tilted windows system. The weight of the resultant sample (created by random re-sampling) is multiplied by 2 . It is a recursive operation. The sec-ond step allows the exploitation and analysis of the created summary. It consists of the exploration of the summary retained for a given period. The algorithm starts by con-stituting the final sample by concatenating elements having different weights to restore the flow of that period. Each element in t his period is associated to its weight. StreamSamp has the advantage of being fast on designing the data stream summary. However, its performance degrades over tim e because old elements increase in weight for a given sample size. Therefore, if a sam ple contains recent elements (much lower weight) and some old elements, the latter will increase the errors in the results of query answers. The RH approach is presented as a trade-of f between processing speed and accuracy in summarized data streams. The basic idea of this algorithm is that the elements from the data stream are first sent into StreamSamp to be processed. When the samples are no longer representative in terms of the two criteria detailed below, the sample elements are sent to CluStream. Depending on the chronological order, these elements are sent to the reservoir before sending to CluStream. Since it involves CluStream, only numerical data can be considered. 3.1 Representativeness of Samples The representativeness of a sample is associat ed to two criteria: (i) the variance criterion features of the two processes: the random sampling for StreamSamp and the updating evolutionary micro-clusters for CluStream. In order to preserve a summary with good quality, we have to maintain a good quality for these two processes. The first criterion is checked for each attribute while the second one is checked considering all attributes together. The main idea is to transit from the StreamSamp process to CluStream based on a simultaneous check of these two criteria.
 Variance Criterion. One of the steps in the StreamSamp process is random re-sampling. In this step, two samples E 1 and E 2 , both of size N and covering respec-is created by randomly drawing N elements from E 1 and E 2 and covering the period [ t itors random re-sampling and measures the  X  X uality X  of the resulting sample. Definition 1. A sample has a good quality if it can generate, from stored data, an ap-proximate response to aggregate queries such as mean, variance, etc.

We aim to control the quality of the sample resulting from the merger of independent samples E 1 and E 2 . We note that these samples have the same weight. The sample X  X  quality is checked by controlling the accuracy of aggregate estimators. In this paper, we check the accuracy of the mean estimator noted x . However, we could make this criterion more severe by controlling the quality of all used aggregates (mean, median, sum, etc). The goal of this criterion is to set a statistical bound on the mean estimator. Since a sample and random sampling are used, we know that with a confidence of 95%, we have the inequality: We r e E 1 and E 2 are the two samples that have to be merged and 9 x is the estimator of the mean.
 The variance Var ( 9 x ( E 1  X  E 2 )) is estimated according to t he following formula : Where n is the sample size and N is the size of the involved population
To ensure that merger quality is satisfied, we define a threshold B (user defined parameter) that the error estimator must not exceed. The criterion is expressed using the inequality : However, even if the criterion is met, we do not decide to merge, unless the second criterion, about the position of the centroids is checked.
 Position Criterion of the Centroids. While the first criterion concerns the StreamSamp process, the position criterion of the centroids is related to the CluStream process. The random re-sampling process leads to a deteri oration on the quality of the built summary. This may cause a considerable change on the position of the centroids which will be calculated on the remaining samples. Consequently, the accuracy on the position of the centroids deteriorates. Therefore, like the first criterion, a minimum precision on the centroids position must be maintained by establishing a threshold over the distance between the centroids.

Unlike the classical approach of CluStr eam in which the algorithm processes the whole stream, in our CluStream version, the algorithm will only processes a sampled stream.

In order to maintain this accuracy, we ch eck the centroid X  X  precision at each re-sampling step. We calculate the distance between the centroid ( G ) (calculated from the samples to be merged ( E 1 and E 2 )) and the centroid ( G ) (calculated from the estimated sample ( E 3 )). This distance must be below a threshold D . Otherwise, the required pre-cision is no longer respected.
 Where is a user defined parameter fixed followi ng the evolution of the centroids, and
If one of these two criteria is no longer respected, the two corresponding samples will be handled by CluStream. 3.2 Insertion of the Samples in CluStream The insertion of elements in CluStream depends on two parameters: (1) the weight of elements and, (2) the chronological insertion. (1) To maintain the representativeness of the elements, the weight must be taken into consideration. Two strategies can be applied for the insertion of elements into CluS-tream: (i) each element i is inserted w i times ( w i is the weight of the element i )or (ii) each element is multiplied by its weight and inserted once in the nearest micro-cluster. CluStream uses the Euclidean distance. It is not based on the correlation be-tween attributes (i.e. Mahanalobis distance [10]). The two strategies offer the same results. Consequently, each element is ins erted once because the first strategy needs O ( p  X   X   X  w i ) times to insert an element i into the nearest micro-cluster (with p the number of micro-clusters and  X  the time needed to calculate the distance between an element and a micro-cluster). (2) In CluStream, Aggarwal added a temporal extension to the classical form of CFV. In order to reflect the evolution of the stream data over a time period, it is necessary to insert elements in chronological order. Thus, during their move from StreamSamp to CluStream, data elements have to be processed according to the order of their respec-tive timestamps: samples with higher weights must be moved away before the lower weighted samples.

Following the chronological order some samples have to be moved to CluStream only because they are older than another sam ples, although they still respect the merge criteria. The early transmission of sample s from StreamSamp to CluStream leads to the following important drawbacks:  X  Unnecessary waste of accuracy, especially for classification tasks.  X  Unnecessary waste of time as the clustering process of CluStream is slower than  X  StreamSamp empties quickly and once emptied we lose the performance of this To overcome these drawbacks, a buffer (referred to in the sequel as the reservoir )is introduced between StreamSamp and CluStream. As StreamSa mp processes data faster than CluStream, the basic idea behind our proposal is to keep data in the StreamSamp process as long as possible, i.e: as long as the representativeness criteria are respected. The reservoir structure is filled with samples that: (i) do not satisfy the representative-ness criteria and hence can not remain in the StreamSamp process; and (ii) can not be moved yet to the CluStream process because there are older samples which are still in the StreamSamp process. These samples ar e moved from the reservoir to CluStream when the storage space allocat ed is reached. The data tran sfer between StreamSamp, the reservoir and CluStream is based on two rules.
 Rule for transmission to the reservoir. Let E 1 , E 2 be the two oldest samples of a weight i in the StreamSamp process. Assume that L (the maximum number of samples of weight i ) is reached and that E 1 and E 2 cannot be merged. In such case, we check an eventual merger between E 2 and E 3 (the third oldest sample of weight i ). If this merger is possible, only E 1 is sent to the reservoir, and the samples E 2 and E 3 are merged. Otherwise, samples E 1 and E 2 are sent to the reservoir. As we cannot indefinitely send samples to the reservoir, we need to vacuum it dynamically by sending elements to CluStream.
 Rule for transmission to the CluStream process. Once the reservoir is filled, the  X  oldest samples are sent to the CluStream process (  X  is a user defined parameter). These  X  samples are jointly extracted from the StreamSamp process and from the reservoir. They are sent to CluStream in chronological order from the oldest to the newest. The storage space allocated for the reservoir is not predefined. Rather, as illustrated by the following formula, a global space is shar ed between the StreamSamp summary and the dynamic reservoir.
 Res : Reservoir, HSpace : total space allowed for the hybrid approach, SSamples :Sam-ples in StreamSamp. Such a sharing mechanism allows a flexible management of the storage space. This is an important featur e of our approach as the storage space re-quired by StreamSamp from one hand and the reservoir from the other hand, highly data-dependent on the quality of the built samples. Indeed, if the merger X  X  criteria are often satisfied, StreamSamp needs mor e space than the reservoir as few sam-ples are sent to the reservoir. In the opposite case, the reservoir needs more storage space.
 We aim at assessing the performance of our algorithm and comparing it with CluS-tream and StreamSamp used on their own. To m ake the comparison fair, all algorithms use the same amount of memory to store their summaries. The algorithm parameters are presented in table 1. Real data sets KDD98 3 and CoverType 4 are used to evaluate the performance of the algorithms. In these evaluations, we are interested in the robustness and efficiency of algorithms for estimating queries which are evaluated over a time pe-riod that grows old over time. Thereby, we study the aging period [0-10000] at different timestamps ( t 10000 ,t 20000 ,etc. ). We repeat the StreamSamp and the RH approach 100 times because they include th e sampling step. The result corresponds to the mean of these drawings.

For reasons of limited space, we just presen t in this section the results for median as querying task and classification as data mining task. Furthermore, other kinds of analysis tasks have been applied (e.g. Mean, clustering) and present good results for the Reservoir Hybrid approach. Note that we also compared these algorithms with the classical Hybrid Approach (without using a reservoir), in order to study the impact of reservoir in the construction of the summary. 4.1 Median Evaluation We study the performances of the different approaches on median estimation. The estimated error is calculate d according to its ranking values: error = The Real Rank is calculated over the original dataset (5000 in our case) while, the Esti-mated Rank is calculated over the resulted summary and the Window Size represents the number of elements studied for the median calculation(10000 in our case). The value of the estimated rank depends on the algorithm used to design the summary: 1. With StreamSamp, the estimated rank is easily calculated b ecause the sampling 2. With the CluStream algorithm, stream el ements are absorbed inside the micro-3. Using the RH approach or the classical Hybrid approach, it is possible to have As shown in figure 1(a), the relative media n error calculated on StreamSamp increases with the aging period [0-10000]. This error is calculated once on CluStream given that it keeps two snapshots. The RH approach adopts a similar behavior to StreamSamp for the recent periods. Then, when the quality of summary deteriorates it converges to an accuracy close to the CluStream behavior. T his approach provides better performance than either summarizing approaches can prov ide separately and provides greater accu-racy in estimating the median than the classical Hybrid approach. 4.2 Classification Evaluation We evaluate the performances of the gener ated models using the different summa-rizing algorithms. The models are constructed over the fixed period [0-10000] using the CoverType dataset. This dataset contains 7 labels, however, predicting 7 labels is difficult. To achieve this, we transform the data set to 2 labels: most frequent label (a majority), and all others. We compare the performance of the generated models with the reference which is constructed on the origin al dataset ([0-10000] in this task). The better algorithm had to develop a prediction model close to the reference. The classification evaluation is done on three steps: 1. Extraction of the summary on the period [0-10000]: 2. Construction of the model: The C4.5 algorithm is used on the extracted summaries 3. Evaluation of the model: Models are evaluated using the training/test method. As shown in figure 1(b), we compared the derived models constructed by algorithms to the reference model (without summarizing operations). StreamSamp built the closest model for recent periods because it used the r eal data unlike CluStream which uses data generated from micro-clusters. The classical Hybrid approach and the RH approach present better results in mo re recent periods since they used data from StreamSamp. For very distant past periods, the RH approach performances stabilize over time and presents the best results while, the Str eamSamp performances continue to degrade. 4.3 Runtime Evaluation In a data stream context, the runtime execution is a very important feature of processing stream data. We take account the global elapsed time for the data stream processing. We are not interested in the aging period [0-10000] but rather by the cumulative time for processing the whole data stream. As shown in figure 2(a) (logarithmic scale), Stream-Samp provides the best performance and C luStream the worst one. The runtime per-formance of the RH approach remained betw een those of StreamSamp and CluStream. They are close to the StreamSamp X  X  performance but still much faster than CluStream (more than 10 times faster than CluStream ). StreamSamp algorithm uses only merg-ing and sampling tasks. CluStream is the s lowest because of updating operations of the CFV structures and the distance calculation between centroids.

The use of the reservoir provides a benefi t in speed processing. The performance of the RH approach are better than the classical Hybrid approach and much better than CluStream. Furthermore, using the reservoir strategy, we avoid the heavy initialization step (Runtime evaluation Zoom in figure 2(b)). 4.4 Conclusion Summarizing data streams is a difficult problem as we need to take into account two antagonistic problems: (i) the representati veness off kept data and hence, the accuracy of queries results; and (ii) the speed processi ng which is crucial in a data stream context. In this paper, we have developed an efficient method called Reservoir Hybrid Approach (RH approach) for summarizing data stream. W e present the results for median and clas-sification task, however, other kinds of queries (e.g. mean), and data mining tasks (e.g. clustering) was evaluated. All the evaluation results show that the RH approach solves the two antagonistic problems and provides best results. It provides a better speed-accuracy trade-off than existing approaches. The use of a reservoir makes summary building speed close to StreamSamp perform ances with an accuracy close to CluStream for distant past periods.

Future work includes the design of a query language allowing the exact querying of current data as well as the approximate querying of historical data.

