 Hua Wang huawangcs@gmail.com Feiping Nie feipingnie@gmail.com Heng Huang heng@uta.edu Many problems in machine learning involve data sets with multiple views where observations are represented by multiple sources of features. Because different data sources contain different and partly independent infor-mation, the multi-view learning is beneficial by reduc-ing the noise, as well as by improving statistical sig-nificance and leveraging the interactions and correla-tions between data sources to obtain more refined and higher-level information, which is also known as data fusion or data integration. Much progress has been made over the last ten years in developing effective multi-view semi-supervised ( e.g. co-training (Ghani, 2002) and co-EM (Brefeld &amp; Scheffer, 2004)) and un-supervised learning ( e.g. multi-view clustering (Bickel &amp; Scheffer, 2004)) algorithms. These methods typ-ically utilize multiple redundant views to effectively learn from unlabeled data by mutually training a set of classifiers defined in each view, with the assumption that the multi-view features given the class are con-ditionally independent. However, in most real-world applications, the independence assumption of the fea-ture sets is not well satisfied, such that these methods may not effectively work (Belkin et al., 2006). From machine learning point of view, different repre-sentations of the same set of objects could give rise to different kernel functions, thus the Multiple Kernel Learning (MKL) approaches (Yu et al., 2010; Suykens et al., 2002; Kloft et al.; Ye et al., 2008a; Lanckriet et al., 2004a; Bach et al., 2004; Sonnenburg et al., 2006) have recently become very popular, because they can easily combine information from multiple views. In general, MKL attempts to form an ensemble of ker-nels to yield a good fit for a certain application. It has been proven that MKL can offer some needed flexibil-ity and well manipulate the case that involves multiple, heterogeneous data sources.
 A core assumption in MKL, as well as many existing graph based multi-view learning methods (Cai et al., 2011; Kumar et al., 2011), is that all features in the same data source are considered as equally impor-tant and given the same weight in data fusion, i.e ., one weight is learned for one kernel matrix or graph. However, one can expect that the feature-wise impor-tance to different learning tasks can vary significantly. To capture the view-wise relationships among data sources without ignoring the feature-wise importance within each data source, we propose a novel multi-view learning framework via the sparse regularizations to emphasize structured sparsity from both group and multi-task points of views.
 In sparsity learning, the sparse representations are typically achieved by imposing non-smooth sparsity-inducing regularization terms. From the sparsity orga-nization perspective of view, we have two types of spar-sity: 1) The flat sparsity is often achieved by  X  0 -norm or  X  1 -norm regularizer or trace norm in matrix/tensor completion. 2) The structured sparsity is usually ob-tained via different sparsity-inducing norms such as  X  2 , 1 -norm (Obozinski et al., 2010),  X   X  , 1 -norm (Quat-toni et al., 2009), and group  X  1 -norm (Yuan &amp; Lin, 2006), and many others (Wang et al., 2011; 2012a;c;d). In this paper, we propose a novel multi-view feature learning and data clustering framework that integrates all features of different views and uses joint struc-tured sparsity-inducing norms to learn a weight for each feature and provide a more flexible method for model selection. The group  X  1 -norm regularization learns the group-wise features importance of one view on each cluster (task) and the  X  2 , 1 -norm regularization explores the feature-wise importance for multiple clus-ters (tasks). Our new model is designed for multi-view data clustering, which can also be naturally extended to deal with classification tasks when prior labeling knowledge is available. Because our final objective comprises two non-smooth sparsity-inducing norms, the current related optimization methods cannot be efficiently applied. We derive a new efficient algorithm with rigorous theoretical proof on its convergence. We apply our new multi-view learning framework to five broadly used multi-view data sets. Promising results in extensive experiments have validated our new ap-proaches in a number of real-world applications. In this section, we will first systematically propose a novel multi-view learning model for exploring the un-supervised heterogeneous data fusion and clustering, followed by a new efficient iterative algorithm to solve the formulated highly non-smooth objective with a rig-orous proof of its convergence. Then we extend the proposed multi-view learning framework to deal with supervised classification tasks.
 Notations. In this paper, we write matrices as bold uppercase letters and vectors as bold lowercase letters. Given a matrix W = [ w ij ], we denote its i -th row as w i and its j -th column as w j . 2.1. Joint Structured Sparsity-Inducing Norms In the setting of clustering, given n data samples { x  X  tures from a total of k views and each view j has d j features such that d = view clustering is to partition { x i } n i =1 into c clusters by exploiting the information stored in all k different views of the input data.
 Although the traditional K -means clustering or spec-tral clustering objectives can be extended for multi-view clustering, similar to MKL, such multi-view clus-tering objectives still only learn one weight for all fea-tures from the same type (due to the objectives X  nat-ural limitation). Thus, we need do clustering from another point of view. Previous work (Nie et al., 2009) showed the following regression-like clustering objective, which is equivalent to the Discriminative K -means (Ye et al., 2008b), obtains better results than K -means or spectral clustering methods: where b  X  X  X  c  X  1 is the intercept vector, 1 n is n  X  1 constant vector of all 1 X  X , F = [ f 1 ,  X  X  X  , f n ] T  X  X  X  n is the cluster indicator matrix, and f i  X  X  X  c is the cluster indicator vector for data point x i with f ij indicating how likely x i belongs to the j -th clus-ter. Upon solution, we learn the d  X  c parameter matrix W , which includes the weights of each fea-ture for c different clusters. In multi-view clustering, W = [ w 1 1 ,  X  X  X  , w 1 c ;  X  X  X  ,  X  X  X  ,  X  X  X  ; w k 1 ,  X  X  X  where, as illustrated in Figure 1, w q p  X  X  X  d q indicates the weights of all features in the q -th view with re-spect to the p -th cluster. Although Eq. (1) learns the weight for each feature to capture the feature-wise importance, more importantly we need design proper regularizers to include the interrelations among multi-view features.
 In heterogeneous data fusion, from a multi-view view-point, the features of a specific view can be more or less discriminative for different clusters (groups of data objects). For instance, in image clustering, the color features substantially increase the detection of stop signs while they are almost irrelevant for find-ing cars in images. To address this, we use group  X  1 -norm ( G 1 -norm) for regularization, which is defined as  X  W  X  G and illustrated in Figure 1. Thus, and our objective can be written as: Because the group  X  1 -norm uses  X  2 -norm within each view and  X  1 -norm between views, it enforces the spar-sity between different views, i.e. if one view of features are not discriminative for certain group of objects, the objective in Eq. (2) will assign zeros (in ideal case, usually they are very small values) to them for corre-sponding clusters; otherwise, their weights are large. Crucially, this group  X  1 -norm regularizer captures the global relationships between views.
 However, in certain cases, even if most features in one view are not discriminative for a group of objects, a small number of features in the same view can still be highly discriminative. From multi-task learning per-spective of view, such important features should be shared by all clusters. Thus, we add an additional  X  2 , 1 -norm regularizer into Eq. (2) as following: The  X  2 , 1 -norm has been widely used in multi-task fea-ture learning (Argyriou et al., 2008; Obozinski et al., 2010). Because the  X  2 , 1 -norm regularizer imposes the sparsity between all features and non-sparsity between clusters, the features that are discriminative for all clusters will get large weights.
 Our regularization items consider the heterogeneous features from both view-wise and individual view-points. Figure 1 visualizes the matrix W T as a demon-stration, in which the elements with deep orange color have large values. The group  X  1 -norm emphasizes the view-wise weights learning corresponding to each cluster and the  X  2 , 1 -norm accentuates the individual weight learning across multiple clusters. Through the joint sparsity-inducing norms, for each task (cluster), many features (not all of them) in the discriminative views and a small number of features (may not be none) in the non-discriminative views will learn large weights as the important and discriminative features. 2.2. Optimization Algorithm Because the objective in Eq. (3) comprises two non-smooth regularization terms of G 1 -norm and  X  2 , 1 -norm, it is difficult to solve in general. Thus we derive an alternative iterative algorithm to solve the prob-lem, which employs the iteratively re-weighted method (Gorodnitsky &amp; Rao, 1997) to deal with the non-smooth regularization terms.
 First, when W and b are fixed, we need to solve the following problem: Due to the orthonormal constraint, Eq. (4) is not easy to solve. We prove the following theorem for generic matrices, which provides the solution to Eq. (4) in a closed form.
 Theorem 1 Given any matrix A  X  X  X  n  X  c ( c  X  n ) and its singular value decomposition (SVD) A = UV T ( U  X  X  X  n  X  n , V  X  X  X  c  X  c ), the solution of the follow-ing optimization problem: ( P 1 ) min B T B = I  X  A  X  B  X  2 is given by B = U [ I ; 0 ] V T ( I is the identity matrix with size c , 0  X  X  X  ( n  X  c )  X  c is a matrix with all zeros). Proof : When A is fixed, it can be verified that the problem ( P 1 ) is equivalent to the following prob-tr ( tr ( Z ) = and  X  ii and z ii are the ( i, i )-th entry of and Z , respectively. Note that ZZ T = I , thus z ii  X  1. On the other hand,  X  ii  X  0 as  X  ii is singular value of A . Therefore, tr and when z ii = 1 (1  X  i  X  c ), the equality holds. That is to say, tr Z = [ I , 0 T ]. Recall that Z = V T B T U , the solu-B = UZ T V T = U [ I ; 0 ] V T . Theorem 1 is proved. Using Theorem 1, letting SVD of X T W + 1 n b T = UV T , the solution to Eq. (4) is F = U [ I ; 0 ] V T . Next, when F is fixed, taking the derivative of the objective with respect to b and w i (1  X  i  X  c ), and setting it to zero, we obtain b = F T 1 n /n (because the data are centered) and have 1 :
XX T w i  X  X ( f i  X  b i ) +  X  1 D i w i +  X  2 ~ Dw i = 0 , (5) where b i is an n  X  1 vector in which all elements are the i -th element of b , D i (1  X  i  X  c ) is a block diagonal matrix with the j -th diagonal block as 1 is an identity matrix with size of d j , w j i is the j -th segment of w i and includes the weights of features in j -th view. ~ D is a diagonal matrix with the i -th diagonal Note that D i (1  X  i  X  c ) and ~ D are dependent on W and thus are also unknown variables. We propose an iterative algorithm to solve this problem, which is described in Algorithm 1.
 Algorithm 1 An efficient iterative algorithm to solve the optimization problem in Eq. (3).

Input : X = [ x 1 , x 2 , ..., x n ]  X  X  X  d  X  n . 1. Let t = 1. Initialize F t by K -means clus-tering and then initialize W t and b t by solving while not converge do end while Output : W t  X  X  X  d  X  c , b t , F = [ f 1 , f 2 , ..., f n ] Computational analysis. In Algorithm 1, step 2 solves a SVD problem. Because in typical cluster-ing tasks, the number of clusters d is usually not very large, step 2 can be computed efficiently by many off-the-shelf numerical packages. Step 3 is computation-ally trivial. In step 4, instead of computing the matrix inverse with cubic complexity, we can solve a system of linear equations with quadratic complexity to ob-tain ( w t +1 ) i . When sufficient computational resources are available and parallel computing is implemented, both SVD and linear equations, thereby the whole al-gorithm, can be solved with desired efficiency. Convergence analysis. The following theorem guar-antees the convergence of Algorithm 1.
 Theorem 2 Algorithm 1 decreases the objective value of Eq. (3) in each iteration.
 Proof : In each iteration t of Algorithm 1, according to Step 2, we know that According to Steps 3 and 4, we know that W Thus, we can derive: +  X  1  X  X T W +  X  1  X  X T W +  X  1 Substituting ~ D and D by definitions, we obtain:
L
L where L t = || X T W t + 1 n b T t  X  F t || 2 F . Because it can be easily verified that for function f ( x ) = x  X  x 2 2  X  any x  X  =  X   X  X  X  , f ( x )  X  f (  X  ) holds, we can derive that and
Adding Eqs. (9-12) on both sides (note Eq. (11) is repeated for 1  X  i  X  c ), we have
L
L Therefore, the algorithm decreases the objective value in each iteration.
 Upon convergence, W t , b t , D i t (1  X  i  X  c ) and ~ D t will satisfy the Eq. (6), i.e ., the K.K.T. conditions is satisfied, which indicates the algorithm converges to a local solution of the problem.
 Clustering Rules. Given the input data X , we can compute the projection matrix W and the cluster in-dication matrix F by Algorithm 1. Upon solution, we cluster the data samples { x i } n i =1 by performing K -means clustering on F . 2.3. Extension to Supervised Classi cation The proposed clustering framework can also be extended to a supervised multi-view classification method. Suppose the data samples are labeled into c classes, which are represented by a class indication matrix Y = [ y 1 ,  X  X  X  , y n ] T , such that y ij = 1 if data point x i belongs to the j -th class, y ij = 0 otherwise. Then we can perform supervised multi-view classifica-tion by simply replacing F in our objective in Eq. (3) by Y . Because Y is fixed upon the labeling knowledge, Step 2 in Algorithm 1 is skipped and b = Y T 1 n /n . Upon solution, we can classify an unseen data point by arg max j The extended supervised classification method is ad-vantageous for the following reasons. First, similar to the proposed method for clustering, the new classifi-cation method explicitly computes the feature weight coefficients W for both each type of features and each feature within one single type. As a result, com-pared to the MKL methods, our new classification method has the capability to identify both useful fea-ture types (views) and relevant individual features. Therefore, the features are properly weighted at two levels of granularity upon their relevance to the seman-tic classes of interest, which could lead to improved classification results. Second, because no SVD is in-volved in the algorithm for classification task, the com-putational complexity is approximately linear when sufficient computational resources are available and parallel computing is implemented, i.e ., our method scales well to large-scale data and is suitable for prac-tical use to solve real-world problems. In this section, we experimentally evaluate the pro-posed multi-view learning framework in both cluster-ing and classifications tasks on five broadly used multi-view data sets, including three image data sets, one Protein data set and one Multi-Lingual (ML) Text analysis data set. Each data set has a certain number of types of features (views), whose details are described as following and summarized in Table 1.
 Image annotation. To minimize the gap between the low-level visual features and high-level semantic concepts, an image can be abstracted by a variety of different descriptors, and each type of these descriptors naturally forms up a view of the images of interest. We evaluate our new multi-view learning framework on the following three broadly used benchmark data sets, including NUS-WIDE-Object data set 2 , Ani-mal data set 3 and MSRC-v1 data set 4 . Protein categorization. Protein can be character-ized from different aspects, each of which can be seen as a view. The Berkeley genomic data set 5 (Lanckriet et al., 2004b) is used in our studies.
 Multi-lingual document analysis. With the ad-vances of machine translation techniques, one can eas-ily get different translations for one document (Pret-tenhofer &amp; Stein, 2010), and the translation in each language can be considered as a view. We apply our new multi-view learning framework on the multi-lingual (ML) text data set 6 for document analysis. 3.1. Improved Multi-View Clustering In this subsection, we first evaluate the multi-view clustering capability of the proposed method. Experimental setup. Following (Cai et al., 2011), as a baseline, we apply the spectral clustering (SC) algorithm (Ng et al., 2001) on every data set using each single type of features. Besides, we also apply SC on the concatenation of all the features in differ-ent types, which is equivalent to assume that all the feature types are of the same importance and does not distinguish the feature relevance within a feature type. For SC, we need to build a graph from the input data. Following (He et al., 2005), we construct the nearest-neighbor graph, where the neighborhood size for the graph construction is set as optimal by searching the grid of { 1 , 2 , . . . , 10 } .
 We compare our method against two most recent multi-view clustering methods: the Multi-Modal Spec-tral Clustering (MMSC) method (Cai et al., 2011) and Co-regularized Multi-view Spectral Clustering (CMSC) method (Kumar et al., 2011), which have demonstrated state-of-the-art clustering performance on multi-view data. We implement the compared methods following the original works and set the pa-rameters as optimal by performing cross validations in our preliminary experiments using the ground truth data labels. For our method, we fine tune the pa-rameters  X  1 and  X  2 in Eq. (3) by searching the grid of { 10  X  5 , 10  X  4 , . . . , 10 4 , 10 5 We implement four versions of the proposed method to evaluate the effectiveness of its component terms in multi-view learning. First, we implement our method by only using the first term of Eq. (3) and denote it as  X  X oss only X , which is equivalent to use linear regression to perform the clustering on the concatenation of all the features from different types. Second, we imple-ment our method by only imposing the group  X  1 -norm regularization and denote it as  X  G 1 -norm X , which, sim-ilar to MKL, only takes into account type-wise rele-vance but not feature-wise relevance. Third, we imple-ment our method by only imposing the  X  2 , 1 -norm reg-ularization and denote it as  X   X  2 , 1 -norm X , which thus is reduced a typical multi-task feature selection method and only takes into account feature-wise relevance. Fi-nally, we implement the full version of the proposed method as defined in Eq. (3).
 Comparison results. Because the clustering results of compared methods are dependent on the initial val-ues, we repeat each experiment on each setting for 50 times and report the average performance. The com-parison results measured by clustering accuracy and normalized mutual information are reported in Table 2 and Table 3 respectively.
 A first glance at the experimental results in Table 2 and Table 3 shows that the three multi-view cluster-ing methods, including ours, are generally better than SC on each individual data view, which validate the usefulness of data integration in clustering. In addi-tion, the three multi-view methods also outperform SC on the concatenation of all features, which is reason-able in that multi-view methods learn proper weights for different views (and features by our method) upon their relevance to the data clusters while the simple features concatenation does not has such capability. Moreover, for the three compared multi-view cluster-ing methods, our method is always better by a large margin. This observation is consistent with our theo-retical analysis in that both MMSC and CMSC only learn the weights at feature type level, while ignoring the relevance of each individual features, especially for those in low-weight feature types. In contrast, our method is particularly designed to take into account the feature weighting at the two levels of granularity, which is confirmed to be effective in data clustering by all the experimental results reported in Table 2 and 3. Finally, the full version of our new method outper-forms all its three degenerate versions, which demon-strate the correctness of our objective and the useful-ness of its two regularization terms that capture both the global and local aspects of feature relevances. Analysis of learned view relevance and feature relevance. Besides the clustering performance com-parison, we examine the feature weight matrix W learned from Eq. (3) with some details, because the most important advantage of our new method over other competing multi-view learning methods lies in its capability for simultaneous view selection and in-dividual feature selection. First, for example, for MSRC-v1 data set we notice that the overall spar-sity of the learned coefficient matrix W is 22.1%. In contrast, for the image cluster related to the  X  X ut-door X  concept, the sparsity of  X  X olor moment X  fea-ture type is about 59.7% and the relative weights of the Color/SIFT/LBP/HOG/GIST/CENTRIST are about 1/0.81/0.63/0.35/0.86/0.42, which clearly shows that the color features and GIST features are of the most significant importance when we deter-mine whether an image belongs to the  X  X utdoor X  class. This observation perfectly agrees with our common sense and empirically justifies the correct-ness the proposed method in terms of view se-lection. Second, although the relative weights of the Color/SIFT/LBP/HOG/GIST/CENTRIST fea-tures for the image cluster related to the  X  X ar X  concept are about 1/1.12/0.60/0.33/0.46/0.68, two HOG fea-tures have considerably high relative weights of 0.27% and 0.26%. Such high relative weights, compared to the average relative weights of all non-zero features of 0.12%, indicates the high discriminative power of these two HOG features, although the overall importance of HOG features is the lowest compared to the other 5 types of image features. This result concretely con-firms that our new method is able to select the useful individual features from feature groups with very weak influences. In summary, empirical results validate the proposed method for its capability to learn both view-wise and individual feature-wise relevances. 3.2. Improved Multi-View Classi cation Now we evaluate the supervised extension of the pro-posed method in multi-view classification.
 We apply SVM on each individual type of features and the concatenation of all types of features of the experi-mental data sets as baselines. We compare our method against several most recent multiple kernel learning (MKL) methods that are able to make use of multiple types of data: (1) SVM  X   X  MKL method (Sonnen-burg et al., 2006), (2) SVM  X  1 MKL (Lanckriet et al., 2004a), (3) SVM  X  2 MKL method (Kloft et al.), (4) least square (LSSVM)  X   X  MKL method (Ye et al., 2008a), (5) LSSVM  X  1 MKL method (Suykens et al., 2002) and (6) LSSVM  X  2 MKL method (Yu et al., 2010). Same as before, four versions of our method are implemented and evaluated.
 We conduct standard 5-fold cross-validation and re-port the average results. For each of the 5 trials, within the training data, an internal 5-fold cross-validation is performed to fine tune the parameters. The param-eters of our method (  X  1 and  X  2 in Eq. (3)) are opti-mized in the range of the SVM method and MKL methods, one Gaussian kernel is constructed for each type of features ( i.e ., K ( x i , x j ) = exp eters  X  are fine tuned in the same range used in our method. We implement the compared MKL methods using the codes published by (Yu et al., 2010). Follow-ing (Yu et al., 2010), in LSSVM  X   X  and  X  2 methods, the regularization parameter  X  is estimated jointly as the kernel coefficient of an identity matrix; in LSSVM  X  method,  X  is set to 1; in all other SVM approaches, the C parameter of the box constraint is fine tuned in the same range used for our method. We use LIBSVM-software package to implement SVM in all our exper-iments. The classification performances measured by average classification accuracies of all compared meth-ods on the five data sets are reported in Table 4. Table 4 shows that our method consistently outper-forms all other compared methods, which demonstrate the effectiveness of our method in supervised multi-view classification. In addition, the methods that use multiple data sources are generally better than SVM using each one single type of data. This confirms the usefulness of data integration in supervised multi-view learning. Moreover, the results that our method is al-ways better than the MKL methods, though both of them take advantage of data from multiple different sources, are consistent with our theoretical analysis. That is, our method not only assigns proper weight to each type of data, but also considers the relevances of the features inside each individual type of data. In con-trast, the MKL methods only address the former while not being able to take into account the latter. These important observations, again, concretely demonstrate the advantages of the proposed multi-view learning framework in classification tasks. Finally, the full ver-sion of the proposed method is clearly superior to its degenerate versions, which prove the necessity of the both regularization terms of the proposed method in multi-view learning. In this paper, we proposed a novel multi-view learn-ing model to efficiently learn the weights of individ-ual feature on different clusters when all heterogenous features are integrated. The joint sparsity-inducing norms are utilized to impose the structured sparsity on the learned weight (parameter) matrix from both local and global multi-view viewpoints. Compared to existing state-of-the-art multi-view clustering methods approaches, our new methods capture the importance of local features and achieve better performance in both unsupervised and supervised multi-view learning tasks.
 Corresponding Author: Heng Huang (heng@uta.edu) This work was partially supported by NSF CCF-0830780, CCF-0917274, DMS-0915228, IIS-1117965.
