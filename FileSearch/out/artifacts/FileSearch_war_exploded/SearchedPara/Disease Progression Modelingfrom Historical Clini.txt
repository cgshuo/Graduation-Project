 This paper considers the problem of modeling disease pro-gression from historical clinic al databases, with the ultimate objective of stratifying patients into groups with clearly dis-tinguishable prognoses or suitability for different treatment strategies. To meet this objective, we describe a procedure that first fits clinical variables measured over time to a dis-ease progression model. The resulting parameter estimates are then used as the basis for a stepwise clustering procedure to stratify patients into groups with distinct survival charac-teristics. As a practical illustration, we apply this procedure to survival prediction, using a liver transplant database from the National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK).
 J.3 [ Life and Medical Sciences ]: Health; I.6.5 [ Simulation and Modeling ]: Model Development Algorithms Disease progression modeling, cluster analysis, NIDDK liver transplant database, logistic model, censoring
One of the central challenges in clinical medicine is the problem of choosing the best treatment for an individual patient with a particular disease. Since the pattern of dis-ease progression, the optimum treatment, and the outcome of disease are all consequences of the individual patient X  X  genes, lifestyle, and environment, it stands to reason that disease progression, treatment response, and outcome are correlated with one another. This observation raises the possibility of studying patterns of disease progression as a means of guiding treatments and predicting outcomes. This paper describes our efforts to develop a specialized data-mining tool 1 for the analysis of disease progression patterns in support of these objectives. In this description, a clinical variable is defined as a measurable patient characteristic like the serum concentration of hemoglobin, and the term feature refers to one of four canonical model parameters a , b , m ,or  X , computed as described in Sec. 3 from the time-evolution of a specified clinical variable for a specific patient. These features form the basis for cluster analysis, generating pa-tient clusters that are evaluated using a novel heuristic based on survival analysis, described in Sec. 5. The end result of our analysis is a stratification of patients into groups on the basis of disease progression model parameters, where these groups exhibit distinct survival characteristics.

The rest of this paper describes our analysis procedure, which consists of the following six steps: 1. For each patient, obtain best-fit disease progression 2. Generate a set of preliminary clusterings for each clin-3. Based on these preliminary results, select the one best 4. Add each non-selected clinical variable to the selected 5. Optimize the feature weights for all clinical variables 6. If none of the new  X   X  S w values computed in Step 5 are
Patent appl. no. WO2005013071,  X  X nformation Process-ing Method and System for Synchronization of Biomedical Data, X  A. Hochberg and M. Liebman, ProSanos Corp. Figure 1: Plot of total bilirubin concentration at each protocol time point for one patient.
 In what follows, Sec. 2 describes a liver transplant database used in the application example presented here, Sec. 3 de-scribes the development of disease progression models on which patient clusterings are based, Sec. 4 describes the mechanics of this clustering, Sec. 5 describes the survival-based heuristic used to evaluate patient clusterings, Sec. 6 describes the initial determination and subsequent optimiza-tion of feature selection weights, and Sec. 7 summarizes the liver transplant application results.
Many of the key ideas presented in this paper are il-lustrated nicely by the NIDDK liver transplant database, which summarizes a seven year prospective study of 1563 liver transplant candidates [9]. This database consists of 88 individual datasets, linked by common key variables. We consider Dataset CI, the short-term follow-up dataset sum-marizing post-transplant patient data at 8 Protocol Time Points (Days 1 and 3, and Weeks 1 through 6), and Dataset CO, the long-term follow-up dataset summarizing patient data at 6 additional Protocol Time Points (Month 4 and Years 1 through 5). Here, we use the one-year follow-up data (Weeks 2 through 6, Month 4, and Year 1) to predict long-term follow-up results (Years 2 through 5). Since the peri-operative period immediat ely following the transplant (Days 1 and 3 and Week 1) involves many complicated tran-sient phenomena, it is excluded from our analysis.
Fig. 1 shows the logarithm of total bilirubin concentra-tion versus time for a representative patient from Datasets CI and CO. The two dashed vertical lines in this figure sep-arate the peri-operative phase, the one-year follow-up pe-riod, and the long-term follow-up period defined above. An unusually high serum concentration of bilirubin can be an indication of certain liver disorders [3, p. 369], but here indi-cates transient injury to the organ from the transplantation process. For this patient, no measurement is available at the final time point because the study ended before the date of this patient X  X  five-year follow-up visit. This form of missing data is called censoring , an extremely common phenomenon in clinical databases discussed further in Sec. 5.
The disease progression models considered here are ap-propriate to clinical variables that evolve monotonically with time, typically (although not always) from  X  X ealthy X  to  X  X is-eased. X  While this assumption is not universally valid, it is valid for chronic, progressive diseases. Consequently, we adopt the approach described in this paper to cases like renal disease, diabetes, or Alzheimer X  X  disease where this mono-tonicity assumption is reasonable. As a specific example, note that the log total bilirubin data shown in Fig. 1 evolves monotonically, provided we exclude the peri-operative data.
An important aspect of disease progression modeling is that we rarely observe the comp lete course of a disease over time. That is, the observed clinical variables for an indi-vidual patient are often censored at one or both ends. To address this issue, we fit observed clinical responses to one of five possible models, shown in Fig. 2. We adopt the logis-tic model to describe the complete evolution of the affected clinical variable y with time: This model predicts that y ( t ) evolves from the value y ( t ) a for times t&lt;&lt; X  to the value y ( t ) b for times t&gt;&gt; X  . The parameter  X  represents the time at which the response y ( t ) reaches the mean intermediate value ( a + b ) / 2, and the parameter  X  determines how long the patient remains in the transition between the initial region y ( t ) a and the final region y ( t ) b .

To account for the possibility of censoring, we consider the following five variations of the logistic model, each based on different censoring assumptions: 1. for uncensored cases, we adopt the full logistic model 2. if only the initial phase ( t&lt;&lt; X  ) or only the final phase 3. when only the transition phase ( |  X  ( t  X   X  ) | &lt;&lt; 1) is 4. when only the initial and early transition phases are 5. when only the final and late transition phases are ob-Figure 2: Illustrations of the five disease progression model types considered here.
 Table 1: Mapping between the parameters of the five disease progression models considered here and the canonical parameter vector { a, b, m,  X  } .
 More specifically, for each patient and each clinical variable considered, we fit all five models and select the one that gives the best fit, penalized for complexity. The parameters describing the selected model are then mapped into a set of four canonical parameters { a, b, m,  X  } according to Table 1. In the expressions appearing in this table, t 1 denotes the time of the earliest data observation used, t n denotes the time of the latest data observation used, and y  X  is the average y ( t ) value over all patients and all times considered. For the last two model types, the value of  X  is determined from the data for all patients, while the parameters  X  ,  X  , and t 0 are estimated for each individual patient.
Once disease progression models have been fit, each pa-tient is characterized by his or her associated canonical dis-ease progression model parameters, { a, b, m,  X  } ,onesetfor each clinical variable considered. Patient clustering then proceeds in a stepwise manner starting with a single variable and adding one variable at a time until no further improve-ment in the clustering is seen, as determined by the cluster separation measure  X   X  S described in Sec. 5. The following paragraphs describe the mechanics common to every stage of this stepwise clustering process.

Given a set of p candidate variables, the associated canon-ical disease progression model parameters are combined into afeaturevector v i of dimension P =4 p for each patient: where a i,j is the canonical a -parameter estimated from the i th clinical variable for patient j ,with b i,j , m i,j and  X  defined analogously. Patients are then clustered on the ba-sis of these feature vectors using an extension of the Par-titioning Around Medoids (PAM) algorithm described by Kaufman and Rousseeuw [7], based on their extension for large datasets (CLARA). Specifically, like CLARA, the algo-rithm used here selects random subsamples from the original dataset, applies the PAM algorithm to cluster this subset, and then updates the resulting clusters to incorporate the remaining data objects in the dataset that were not included in the original subsample.

The PAM algorithm groups a collection of N data ob-jects into a specified number k of clusters by first identify-ing a set of k representative data objects and then assign-ing each of the other data objects to the cluster defined by the nearest representative object. A detailed description of this algorithm is given by Kaufman and Rousseeuw [7, Ch. 2]. The basis for both initially selecting representative data objects and subsequently assigning data objects to clusters is an N  X  N symmetric matrix of dissimilarities d ij which must satisfy the following conditions for all data objects i and j : nonnegativity ( d ij  X  0), symmetry ( d ij = d ji self-similarity ( d ii = 0). One advantage of the PAM algo-rithm is that it accepts any dissimilarity matrix satisfying these constraints as an input. This feature is important here since it permits us to use the customized dissimilarity mea-sure described below. Additional advantages of the PAM algorithm over other, possibly better-known algorithms like k -means include an improved outlier resistance, an insensi-tivity to the ordering of data objects in the original dataset [7, p. 114], and the fact that each cluster can be uniquely associated with a data object from the original dataset.
The dissimilarity measure used here is a modified Maha-lanobis distance between feature vectors that accounts for the uncertainty in estimated parameter values. First, the individual feature vectors are normalized to multivariate z -scores: where  X  v is the average of the feature vectors v j over all pa-tients j ,and D is a diagonal matrix of standard deviations for each feature. These standard deviations and the covari-ance matrices  X  i required in Eq. (6) below are computed from the parameter covariance matrix obtained from the dis-ease progression model fits, together with knowledge of the appropriate parameter transformation defined in Table 1.
The dissimilarity d ij between patients i and j is Here,  X  i is the covariance matrix for the { a, b, m,  X  } rameters estimated for patient i ,thesuperscript  X  denotes the Moore-Penrose generalized inverse [2], and  X  ij is a di-agonal feature selection weight matrix discussed in the next paragraph. Note that (1 / 2)( X   X  i + X   X  j ) represents the best ap-proximation to a common inverse covariance matrix for the two patients, allowing for the possibility that one or both of the matrices  X  i and  X  j may be singular (e.g., due to limited data availability). The essential idea is to down-weight the contribution of model parameters whose values cannot be accurately estimated from the available data.
 The diagonal P  X  P weight matrix  X  ij is given by: where W is the feature weight matrix discussed in Sec. 6 and Q ij is an P  X  P diagonal matrix whose diagonal entries are either 1 or 0. Specifically, if either patient i or patient j is best characterized by a constant model for a given variable, the corresponding m and  X  parameters are undefined. The diagonal elements of Q ij corresponding to these undefined parameters are set to zero, w hile those corresponding to well-defined model parameters are set to 1.
In the liver transplant example considered here, the goal of clustering patients is to predict long-term transplant sur-vival. Consequently, we propose a novel cluster quality mea-sure based on survival analysis [6, Ch. 29] to evaluate pa-tient clusterings. In particular, a good clustering in the context of this application is one that exhibits a wide varia-tion of survival characteristics between clusters. A standard approach to survival analysis is via Kaplan-Meier curves, which are described next and then used to define the sepa-ration score  X   X  S , a simple heuristic for assessing the quality of patient clusterings.

The analysis of times to a failure event, such as transplant failure or death, is complicated by the presence of censored data (e.g., from patients still alive with a functioning graft at the end of the study period, like the case seen in Fig. 1). We can represent a sample of censored survival data as a sequence { t i } of times, together with a { 0 , 1 } -sequence where  X  i =1if t i represents a failure (death or transplant failure) and  X  i =0if t i represents a censored time (i.e., if it is known that the actual failure time is greater than t Kaplan-Meier survival analysis is based on the assumption that the recorded survival times t i are samples of some pos-itive random variable T with cumulative distribution func-tion F ( t ) and density function f ( t ). The survival function S ( t ) is defined as the probability that the observed survival time T is greater than t , i.e. S ( t )= P { T&gt;t } =1  X  Kaplan-Meier survival analysis constructs an estimate  X  S ( t ) of the survival curve S ( t ) that is easily computed from the available censored data [6, Ch. 29].

Specifically, let u 1 &lt;u 2 &lt; ... &lt; u k be the distinct values in the sequence { t i } , recognizing that repeated values com-monly arise. For each u j ,let r j denote the number of pa-tients still at risk at time u j ; that is, the number of patients i for whom t i &gt;u j or t i = u j and  X  i =0. Let d j denote the number of failures at time u j . The Kaplan-Meier estimate of the value of the survival curve S ( t ) is defined as:
To use survival analysis as a tool for evaluating patient clusterings, we first construct separate Kaplan-Meier curves for each patient cluster. The separation score  X   X  S is then defined as the magnitude | S i ( t 0 )  X  S j ( t 0 ) | of the difference between survival curve values for the best separated curves S ( t )and S j ( t ) at a specified reference time t 0 . For the liver transplant example considered here, we are interested in the long-term survival period from 1 year (52 weeks) to 5 years (260 weeks), so we choose t 0 = 150 weeks, the approximate midpoint of this interval, as our reference time.

Cluster analysis frequently generates a few very small clus-ters [1], and the pair of best separated clusters at time t the application considered here often includes one or two of these nonrepresentative clusters. Since our primary inter-est is in identifying disease progression characteristics that predictably distinguish the survival characteristics of large groups of patients, we require that the patient clusters used in defining the separation score  X   X  S be representative clus-ters , whose size exceeds a specified threshold s .Theresults presented here take this threshold value to be 40 patients. While this choice is somewhat arbitrary, it seems to give reasonable results for the example considered here; more systematic alternatives are discussed briefly in Sec. 8.
A typical family of Kaplan-Meier survival curves is shown in Fig. 3, based on k = 10 clusters obtained as described in Sec. 7. Each curve gives an estimate of the fraction S ( t ) of the patients in a specific cluster who survived up to time t . The vertical line at t = 150 weeks identifies the reference time t 0 used in computing the separation score  X   X 
S defined above. For this example, the separation score  X   X  S =0 . 32 is the distance between the two heavy lines in Fig. 3. Note that there is a curve lying below the lower heavy line, corresponding to a survival curve for a cluster containing fewer than 40 patients. This curve was not used in computing  X   X  S since this cluster is non-representative.
It is known that extraneous fea tures can seriously degrade clustering results [4, 8], motivating both the stepwise clinical variable selection used in Steps 4 through 6 of the procedure outlined in Sec. 1 and the feature weight matrix W appear-ing in Eq. (7). Here, these feature weights are binary, serv-ing to either select a particular feature (if W ii =1)oromit it (if W ii = 0); as noted in Sec. 8, we are also exploring the use of continuous feature weights.
 The feature weights defining the P  X  P diagonal matrix W appearing in Eq. (7) are initially determined as follows. For each clinical variable, the canonical model parameters a , b , m , and  X  are considered in turn, restricting attention to those patients for which the parameter is well-defined. The corresponding parameter values are partitioned into deciles and patients are grouped into ten clusters according to these decile values. The Kaplan-Meier survival curves discussed in Sec. 5 are then constructed for each patient cluster. As in Sec. 5, a  X  X ood X  feature is one for which these ten sur-vival curves are well-separated. Therefore, the differences between these curves are tested for significance using the S-plus procedure survdiff [6, p. 326], which tests the null hypothesis that all curves are drawn from the same distri-bution against the alternative hypothesis that they are not.
If these Kaplan-Meier survival curves differ at the 5% significance level, the corresponding feature (i.e., canonical model parameter a , b , m , or  X ) is given a weight of 1. If Figure 3: Kaplan-Meier survival curves for the 10 patient groups obtained from a clustering of the log(AST) data using the weights listed in Table 2. some (but not all) of these four canonical parameters do not meet this significance criterion, their associated weights are set to zero. If none of the four canonical parameters asso-ciated with a given variable are individually significant, all weights are set to 1 since there is no basis for emphasizing any subset of the model parameters over the rest.

The advantages of this feature weighting procedure are il-lustrated in Table 2, which summarizes the separation scores  X   X  S computed for each of five individual clinical variables. The unweighted separation scores  X   X  S u were obtained by clustering patients into k = 10 groups as described in Sec. 4, based on the indicated clinical variable with all weights W ii = 1. The four columns designated a , b , m ,and X  X n Table 2 list the binary weights obtained for each of these pa-rameters by the procedure descr ibed in the preceeding para-graph. In cases where these parameters were not all equal to 1, patients were re-clustered into k = 10 new groups, again using the procedure described in Sec. 4 but with the binary feature weights given in Table 2. Kaplan-Meier sur-vival curves were then constructed for each of these patient clusters and the corresponding separation score  X   X  S w was computed as described in Sec. 5. Comparing the  X   X  S u and  X   X 
S w values listed in Table 2, it is clear that the elimination of individually non-significant model parameters substan-tially improves the separation scores obtained for the first four of these five clinical variables. Also, of particular rele-vance for the stepwise clustering procedure described here, note that the weighted separation scores induce a different ranking on these variables than the unweighted scores do; for example, Potassium ranks first among these variables according to  X   X  S u but last according to  X   X  S w .
The optimization of these feature weights in Step 4 of the procedure outlined in Sec. 1 is accomplished by setting
No. Variable  X   X  S u abm  X  X  X   X  S w Table 2: Unweighted separation scores  X   X  S u ,feature weights for a , b , m ,and  X  , and weighted separation scores  X   X  S w for five liver transplant variables. each nonzero weight to zero, one at a time, re-clustering the patients as described in Sec. 4, and comparing the result-ing  X   X  S w values. If the new  X   X  S w value is larger than the original one, the corresponding feature weight is set to zero; otherwise, the feature weight is unmodified.
To illustrate the general procedure just described, we ap-ply it here to the NIDDK liver transplant database, con-structing a model of disease progression in the first year post-transplant and using it to predict long-term survival. Altogether, 34 real-valued clinical variables appear in both Dataset CI, the short-term follow-up dataset, and Dataset CO, the long-term follow-up dataset. On the basis of both data quality issues (in particular, high fractions of missing data for some variables) and clinical relevance, we reduced this set to 10 candidate clinical variables. Also, in cases where log transformations improved the distributional char-acter of a clinical variable (assessed in terms of distributional asymmetry measures and numbers of outliers), we included the log of the clinical variable instead of the variable itself.
In the example considered here, there are four different events that can be used to define a patient X  X  end time for survival analysis: 1) the patient X  X  transplant may fail, result-ing in a retransplant; 2) the patient may die due to compli-cations of his or her liver transplant; 3) the patient may die of causes unrelated to the transplant; or 4) the patient may be lost to follow-up either due to the end of the study or drop-out. In this analysis we treat the first three end-points as failures (  X  i = 1) and the last endpoint as censored (  X  i = 0). Where a patient underwent a second transplant the date of the second transplant was used as the failure date of the first. Since patients with prior liver transplants exhibit significant immunological and physiological changes, only first liver transplants were considered here. Where a patient was lost to follow-up, the date of the last follow-up visit was used to determine the censored survival time. All times in the analysis are in weeks. To be included in the analysis, a patient was required to have at least three values for each of the ten clinical variables considered, to have an endpoint as defined above, and to have a transplant survival time of at least one year. A total of 684 patients met all of these inclusion criteria.

The best results obtained for any one clinical variable was that based on log-transformed AST values with the weights shown in Table 2. To improve this result, the other nine Figure 4: Kaplan-Meier survival curves for the 10 patient groups obtained from a clustering of the variables log(AST), log (AP), and log (HCT). clinical variables were added one at a time, re-clustered and evaluated to find the best two-variable clustering. The clin-ical variable pair with the highest  X   X  S value was log (AST) with log (AP), giving  X   X  S =0 . 34. Continuing this process and optimizing the feature weights, the combination of b and m parameters for log (AST) and log (AP), with the b pa-rameter for hematocrit (HCT) produced a  X   X  S value of 0 . 42. Since no combination of four variables produced a larger  X  value, this result was chosen as the final patient clustering. The Kaplan-Meier estimated survival curves for the clusters obtained from this best three-variable model are shown in Fig. 4. It is interesting to note that these three variables re-flect three different aspects of liver physiology. Specifically, AST is elevated when there is damage to the liver tissue itself; AP is elevated more specifically in cases where there is obstruction of bile flow from the liver; HCT is a measure-ment of red-blood-cell production which indirectly reflects a number of metabolic processes in the liver.
This paper has considered the problem of clustering pa-tients on the basis of disease progression, as inferred from the time-evolution of measurable clinical variables. In order to predict outcomes and guide treatments (e.g., assign more ag-gressive treatments to patients with poorer prognoses), the main objective of this analytical approach is to distinguish groups with different survival characteristics. To meet this objective, we have developed a procedure that involves first, fitting the time evolution of measurable clinical variables to disease progression models for each patient, then combin-ing the resulting model parameters into feature vectors that characterize each patient, and finally clustering patients on the basis of these feature vectors. The procedure is an it-erative one where variable and feature selection decisions are based on a heuristic separation measure  X   X  S described in Sec. 5 that characterizes the difference between Kaplan-Meier survival curves constructed for the patients in each cluster. The objective is to obtain large clusters of patients with clearly distinct survival characteristics. An application of this procedure to the characterization of transplant sur-vival for patients included in the NIDDK liver transplant dataset was briefly described in Sec. 7.

While space limitations do not permit detailed discussions of these points, important issues that we are examining fur-ther include the selection of the number of patient clusters k using a permutation-based reference strategy [8], the use of continuous feature weights W ii taking values in the interval [0 , 1] instead of binary feature selection weights, and the ex-ploration of refinements of  X   X  S to automatically downweight contributions from very small clusters. One such alternative is the following, where size n i of cluster C i for i =1 , 2 ,...,k :  X   X  S = 2 It follows from the arithmetic-geometric mean inequality [5, p. 17] that the term in parenthesis is at most 1, achieving this value only if n i = n j . Hence, the double sum consists of k ( k  X  1) / 2 terms each lying between 0 and 1, so  X   X  between 0 (if all survival curves are identical) and 1 (achiev-able only for k = 2 with two equal-sized patient clusters of maximum possible separation). The primary advantage of  X   X  S is that it avoids the specification of a minium repre-sentative cluster size required for the separation score  X  Another alternative we are exploring is the use of balanced clustering procedures like those described by Banerjee and Ghosh [1], which generate fewer very small clusters. [1] A. Banerjee and J. Ghosh. On scaling up balanced [2] A. Ben-Israel and T. Greville. Generalized Inverses: [3] A. T. Blei. Liver and biliary tract. In Laboratory [4] A. Gordon. Classification . Chapman and Hall/CRC, [5] G. Hardy, J. Littlewood, and G. Polya. Inequalities . [6] Insightful-Corp. S-PLUS 6 Guide to Statistics Vol. 2 . [7] L. Kaufman and P. J. Rousseeuw. Finding Groups in [8] R. K. Pearson, T. Zylkin, J. S. Schwaber, and G. E. [9] Y. Wei, K. Detre, and J. Everhart. The NIDDK liver
