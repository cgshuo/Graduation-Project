 Faezeh Tafazzoli, Reza Safabakhsh n 1. Introduction
In recent years, human recognition with high reliability has gained considerable importance in different applications such as access control and visual surveillance. Research has shown that this goal may be reached through biometrics. A biometric is a measure taken from a living person, which is essentially universal, unique, permanent and collectable ( Jain et al., 1999 ). This measure can be based on physiological characteristics such as fingerprints, or some aspects of human behavior such as hand-writing ( Cunado et al., 2003 ). Physiological biometrics have been receiving more attention so far and include face, iris, retina, fingerprints, hand geometry, and voice patterns. Among all possibilities, gait is the newest ( Jain et al., 1999 ).
Humans can recognize friends and acquaintances by the way they walk. Psychological studies support the notion that gait can be perceived by human vision as a set of unique patterns ( Johannson, 1973 ). That is why the study of this universal and complex human activity has generated a lot of interest in various fields, especially in computer vision. It is challenging, however, to find discriminative gait features in markerless motion sequences.
Many established biometrics are obscured in various person identification applications. The face may be at low resolution or hidden with make-up or glasses, the palm could be obscured or hands may be cut off, and the ears might be covered by hair. But people need to walk; and their manner of walking is usually observable and more difficult to obscure or disguise. This feature introduces gait as a biometric. An outstanding advantage of gait is its potential for being noticeable over long distances, in contrast to other biometrics which may need high resolution images taken from a close distance. Besides, it is difficult to conceal or imitate the motions of an individual X  X  walking. Perhaps, what makes gait an attractive biometric is its non-invasiveness, which does not involve any notification or contact with the subject.

Despite all privileges, there are limits to the use of gait. For instance, footwear, clothing or object carrying can affect it. In addition, physical conditions such as pregnancy, leg or foot injuries, or even drunkenness can change the manner of walking. Like most biometrics, gait will instinctively change with age. But a good biometric system should be able to understand the basic features of the biometric, regardless of the presence of such factors. However, representing a method to study gait as a potential biometric under limited conditions would be an initial step towards materializing a general gait recognition method.
This research investigates the potential discriminatory cap-ability of the gait signatures obtained from different parts of the body such as legs and arms. The subject is modeled based on anatomical proportions and recognition is carried out through the K -nearest neighbor classifier and Fourier components of the joint angles. Special attention is paid to the movement of arms in conjunction with the movement of legs.

The rest of this paper is organized as follows: Section 2 presents current approaches to gait recognition by computer vision techniques. In order to better understand the nature of gait, an overview of the terminology and biomechanics of a person X  X  motion is given from medical literature in Section 3. Section 4 presents the proposed algorithm. Experimental results are given in Section 5, and Section 6 concludes the paper.
 2. Previous work
Existing methods for gait recognition can be divided into two main categories: model-free and model-based approaches. Model-free approaches attempt to extract a gait description without resolving the body pose, and, hence, avoid the most complex part of this problem. These approaches typically use the subject X  X  silhouette and its features ( Phillips et al., 2002 ). The main advantages of these methods, compared to model-based ap-proaches, are their simplicity and speed. However, these approaches are essentially data-driven, and, thus, the recognition rate is limited by the input data quality and noise. Occlusion and variation in clothing also affect the silhouette dynamics. Phillips et al. (2002) measured the correlation between the probe silhouette image sequences and those in a dataset, while Collins et al. (2002) applied template matching to selected key frames.
Different image features are used to identify the spatial and temporal variations of human gait, such as silhouette self-similarity ( BenAbdelkader et al., 2004 ), moments of optical flow ( Little and Boyd, 1998 ), width of the outer contour of a silhouette ( Kale et al., 2003 ), and generalized symmetry operators ( Hayfron-Acquah et al., 2003 ).

Model-based approaches incorporate knowledge of the shape and dynamics of human gait into the feature extraction process, constraining the expected shape and motion of the subject to a known set of possible alternatives, which helps these approaches overcome weaknesses of the previous category. Here, gait dynamics are directly extracted by determining the joint positions, rather than inferring dynamics from other measures.
However, constructing a suitable model is the main difficulty and even the source of error in these approaches. This is because applying sufficiently complex features to incorporate individual variation across the population may lead to complex models with many free parameters. However, with gait features closely related to the walking mechanics, model-based approaches have a high potential for robust feature extraction. Human-like structures are proposed in this process. Cunado et al. (2003) modeled the thighs as interlinked pendulums and used the Fourier series to extract their angular movements. Bobick and Johnson (2001) used the act of walking to derive body parameters which described the subject X  X  body and stride. Yam et al. (2004) developed a model-based system to describe the two legs and to handle walking as well as running. This was based on evidence gathering and anatomical constraints. Zhang et al. (2007) was concerned with the change in the orientation of human limbs. Given distances normalized by the height of thorax, he represented the body posture by a set of distance measurements and the inclination of its parts.

Model-based methods seem to be more attractive and promising; but they have to deal with the complexity of models and model extraction, which is not a trivial task. 3. Biomechanics of walking
Studies and observations made regarding human identification has revealed that  X  X  X  given person will perform his or her walking pattern in a fairly repeatable and characteristic way; sufficiently unique that it is possible to recognize a person at a distance by his gait X  X  ( Winter, 1990 ). As a matter of fact, walking uses a repetitious sequence of limb motions moving the body forward while simultaneously maintaining stability. As the body moves forward, one limb serves as a source of support while the other progresses to a new support site. The limbs then reverse their roles. A single sequence of events by one limb is called a gait cycle ( Zhang et al., 2007 ). Each gait cycle is divided into two periods: a stance and a swing. Stance is used to describe the period during which the foot is on the ground and is subdivided into three intervals according to the sequence of floor contacts for both limbs. Swing is the period in which the foot is on the air. Both the start and end of stance involve a period of bilateral foot contact with the ground (double stance), while the middle portion has a period of single limb contact (single stance). The duration of a single limb support for one limb equals the swing of the other.
The relative distribution of the periods of gait within a gait cycle is 60% for the stance and 40% for the swing ( Zhang et al., 2007 ); but the precise duration of these intervals within the gait cycle varies with a person X  X  walking velocity.

The whole process of walking begins with the heel strike of one foot (initial contact) (right foot for example), followed by flexion of ankle to bring that foot flat on the ground, which causes the transmittal of body weight onto it (loading response). Then the left leg swings through in front of the right leg as the right heel lifts off the ground (mid stance). As the body weight moves onto the left foot (terminal stance), the supporting right knee flexes. The remainder of the right foot, which is now behind (pre-swing), lifts off the ground (initial swing) ending the stance phase with toe-off (terminal swing) ( Cunado et al., 2003 ). Fig. 1 illustrates the described sequence.

The motion between successive points of contacts of the same foot is called Stride ; and the motion among consecutive heel strikes of opposite feet is a Step ( Cunado et al., 2003 ). It is obvious that a complete gait cycle includes two steps. Thus, human gait is a form of periodic motion, especially when one walks laterally, and can be predicted in a cycle. The motion period and gait frequency are the time taken by a step and the number of steps taken per second, respectively ( Cunado et al., 2003 ).
Medical research has shown the uniqueness of gait, consider-ing all movements ( Zhang et al., 2007 ) and using markers to represent the observed movement in the form of 3D trajectories that translate into kinematic variables such as body movements and joint angles ( Yoo et al., 2002 ). But using markers needs intrusive and expensive specialized hardware and requires contact with the subject, which violates the most important privilege of this biometric. However, extracting all moving patterns would be impossible or even unnecessary. For instance, measuring pelvic and thorax rotations will be difficult even from an overhead view. The pelvic can be covered due to the type of clothing and ankle rotation extraction may be difficult in normal resolutions ( Cunado et al., 2003; Kale et al., 2003 ). These problems make such features inappropriate for a computer vision-based automated system, as they require markers attached to the subject, and, hence, most current approaches are limited to use rotation patterns of hip and knee. These patterns, which can be simply extracted, have a considerable discrimination capability based on medical studies ( Nixon and Carter, 2006 ). Based on clinical results, the normal hip rotation pattern is characterized by one period of extension (while the trunk moves forward over the supporting limb), and one period of flexion (in preparation for the swing phase), in every gait cycle.

Figs. 2 (a) and (b) show the mean and standard deviations given by medical data from anatomical markers in limb segments ( Winter, 1990 ) for joint angles of the thigh and knee motion during a single gait cycle.

Minimizing the extent that the body X  X  center of gravity is displaced from the line of progression is the main mechanism for reducing the muscular effort of walking. The dependence on described reciprocal bipedal locomotion presents some situations during each stride. As the left and right limbs alternate their support roles, the body must shift laterally from one side to the other. The limbs also change their vertical alignment between double and single supports, thus causing the pelvic and, therefore, the body to be moved up-and downwards. The magnitude of the horizontal and vertical displacement is approximately 2.3 cm in each direction ( Spencer, 2005 ). We will ignore these displace-ments in modeling for the purpose of simplicity. 4. The proposed method
We use the properties of the human body in order to reduce the computational requirements and limit the search space of the model. Based on the literature on anatomy ( Winter, 1990 ), we have created an initial mean shape model which consists of three main regions. The size of each region is estimated as a percentage of the body height ( H ). The result is used as an initialization to a detailed version of the model which separately extracts motion patterns out of each region.

A velocity filtering algorithm is employed to determine the bulk motion of the person regardless of the shape parameters. Using this motion information, we form a global temporal accumulation describing the person X  X  average shape over the gait sequence. This accumulation is used to robustly estimate the size and shape of the person X  X  body segments, using ellipses for head and torso, and two pairs of lines for each leg, applying anatomical constraints to reduce matching errors. Gait phase and frequency are estimated simply based on characteristics of the silhouette through the total sequence. The motion pattern of articulated parts is extracted via analyzing the variations of their angles with vertical axis.
Based on physiological research results, most of the walking dynamics take place in the sagittal plane, or the plane which vertically bisects the human body ( Zhang et al., 2007 ). Thus, our approach assumes a single subject moving at a constant speed, fronto-parallel against a static background. However, this approach can be generalized to more practical situations. 4.1. Shape model estimation
As mentioned earlier, the process of model construction and fitting is divided into two phases. In the first phase, a shape model is estimated. The motion model is then constructed based on the estimated model in the second phase. The input frames should be pre-processed using a kernel regression method ( Takeda et al., 2007 ) to recover the noiseless high-frequency information corrupted by limitations of the imaging system. This is followed by Sobel edge detection and background subtraction. The method used here for foreground segmentation is based on using the minimum graph cut method proposed in Howe and Deschamps (2006) , which results in a more reliable silhouette especially around the borders in noisy images. This approach uses informa-tion which would be discarded by thresholding in traditional methods, to construct a graph incorporating all the differences measured between the current frame and the background model. Links in this graph reflect the connectivity of the pixels in the image, allowing each pixel to affect those in its local neighbor-hood. Segmenting the graph using a standard graph-cut algorithm produces a foreground X  X ackground segmentation that can correct local errors without causing larger global distortions ( Howe and Deschamps, 2006 ). Therefore, we will have cleaner silhouettes to use in subsequent phases. Using the estimated edges and silhouettes, we will be able to extract edges of the moving objects. Typical results of the above phases are shown in Fig. 3 for an input instance.

Using a velocity filtering algorithm ( Wagg and Nixon, 2003 ), it is possible to determine object moti on independent of shape, based on
A  X  i , j  X  X  where A v is the accumulation for velocity v (in pixels per frame), I the image intensity function at frame n , i and j are coordinate indices and N isthenumberofframesinthegaitsequence( Wagg and
Nixon, 2003 ). This algorithm sorts the objects in the scene according to their velocity and starting posi tion, producing an accumulation for each possible object velocity. At the correct accumulation velocity for an object, edges from each frame will accumulate to a single area, producing an average shape. Hence, the highest peak in the plot of maximal intensity versus velocity indicates the object X  X  velocity. This procedure holds true when the person is the most significant moving object in the scene; otherwise, we must apply some knowledge of the person X  X  shape to distinguish it from other objects. The computed temporal accumulation will prepare a basis for the shape model to be built upon. Parameters that do not change during a gait cycle, which we will call static parameters, can be determined through this model. These parameters comprise approximate body segment sizes, velocities and period of walking.
The shape model consists of three major segments dedicated to head, torso and leg regions. We can estimate the model by dividing the bounding box of the temporal accumulation measured through the subject X  X  velocity, based on the mean anatomical proportions presented in Winter (1990) . The final model and relative sizes are shown in Fig. 4 . This model has only three free parameters; the height of the body ( H ) and the center of mass coordinates.

The last static parameter to be estimated is the period of walking. As mentioned before, the motion of a person X  X  limb during normal gait creates a complex periodic pattern, composed of many different components which can be approximately modeled by a single sinusoid. The gait frequency and phase are particularly useful components since they describe this motion to a large extent and can be easily extracted without resolving limb dynamics. In simple terms, the gait frequency describes the speed at which the subject moves his legs, and the phase describes the legs X  starting pose. We have chosen simple features of the silhouette such as variation of its width as the measure of period calculation to decrease computational overhead. That is why we chose a more precise method for foreground segmentation to retrieve better borders in order to be able to achieve smoother periodic signals. 4.2. Motion model estimation
The second stage of model construction is dedicated to the posterior model, which is initialized based on the prior model described in the previous section, and determines dynamic parameters. Dynamic parameters are the second group of model parameters which vary through the gait cycle, and are extracted directly from the model. The three regions of the initial model are replaced with four major segments at this stage. These parts include head, torso, legs and arms.

Since the first two segments have the least motion during walking, they are less important than the articulated parts. As a result, we will model them more generally using an ellipse-fitting algorithm ( Fitzgibbon et al., 1999 ). This will provide features such as dimension and orientation values of these two parts which will be used during the recognition phase. Since the fitting is applied to the temporal accumulation, optimizing it for each frame is done via the center of mass motion, as we have assumed these parts to have just horizontal displacements. 4.2.1. Extracting leg angles
The leg shape is lost during the accumulation process due to articulation of the leg joints. Therefore, an improved estimate is necessary since the mean anatomical proportions are not appropriate for certain types of clothing. In addition, as the main dynamic recognition features are going to be extracted from these articulated parts, we need to have a more reliable model. This model consists of two line segments for the upper and lower leg regions. Ultimately, analysis of rotation patterns of these lines during gait cycle will create a part of the final feature vector.
Most previous methods have used algorithms like line Hough transform to detect these lines. But apparently, this approach has some disadvantages. As each peak in the Hough space indicates the presence of a linear structure at the corresponding position and angle, we have to know the expected orientation and width of a leg to constrain the Hough space. This forces us to use clinical data to find a local estimate of that leg. This approach will increase the number of errors in situations where the legs are too close to each other or the input data possesses low resolution and
Hough transform is unable to detect the correct lines, even considering exact pre-assumptions.

So we have chosen to use active contour models to find precise borders of each leg. The basic idea in active contour models or snakes is to evolve a curve, subject to constraints from a given image, in order to detect objects in that image. For instance, starting with a curve around the object to be detected, the curve moves towards its interior normal and has to stop on the boundary of the object. Here, we have used a combination of such algorithms to achieve the best result. Therefore, the active contour model proposed in Li et al. (2007) , which can segment images based on intensity homogeneity, is used first. Its basic idea is to avail a kernel function to define a local binary fitting energy in a deviating formulation, so that the local intensity information can be embedded into a region-based active contour model. This model does not utilize the image gradients and so has better performance for images with weak object boundaries. Thereupon, the following function should be minimized for each point in a selected region: E x  X  C , f 1  X  x  X  , f 2  X  x  X  X  X  l 1 where in ( C ) and out ( C ) indicate regions inside and outside contour
C , respectively; K is a kernel function with localization property, and f 1 ( x ) and f 2 ( x ) are two numbers that fit image intensities near point x . Since we need to extract accurate borders of each leg, we refine the extracted contour using the method described in Malladi et al. (1995) , with the current contour as the initial one.
The main privilege of this algorithm is its ability to deal with the shapes with significant protrusions, and this is why we use it here. The main reason for using the two methods in the stated order is that the second approach has a high computational cost and is unable to detect borders in images with weak edges or holes. The first approach, on the other hand, converges in far fewer iterations, and prepares a more reliable initial value for the next stage to decrease the computational requirements. In each iteration, a convolution should be computed which makes the complexity of the algorithm O ( p log( nm )) in each step, where p is the number of pixels of each frame, and the kernel size is n by m , and m , n o 10. The time complexity of the second method is O ( p /2) using the previous stage X  X  initialization in each time step.
After determining the contour of the leg region, we are able to extract the skeleton of the reconstructed silhouette from the estimated contours using a thinning algorithm ( Zhang and Suen, 1984 ), by removing all contour points of the picture except those points that belong to the skeleton.

Then we divide the measured skeleton to sub-regions based on the situation of the legs to find the best fitting line. This medial axis is converted into two or four segments, above and below the knee location. The ordinary least squares (OLS) regression theory relies on the assumption that the explanatory variables are measured without errors. It is obvious that this assumption is often proved false when randomness exists in the regressors due to measurement errors or other underlying volatilities. Actually, this approach minimizes the squared vertical (in estimate of Y on X ) distance from the points to the regression line. OLS is suitable when only one of the two variables is random. Therefore, as the direction of regression needs to be changed during the whole gait sequence, we will use the orthogonal least square regression to take the middle ground by minimizing the orthogonal distance from the observed data points to the regression line ( Leng et al., 2007 ). In simple terms, orthogonal regression is suitable when the error variances are equal. This way, we will get the rotation spectrum of each segment. The main advantage of this approach is that in cases of severe noise, semi-occlusion of legs, failure of any of previous phases, etc., in which the process is unable to extract the best model, the neighborhood data will be used instead. This makes the approach more robust to missing data and occlusion. The process of leg extraction described above is presented in Fig. 5 for two poses of the leg during walking. 4.2.2. Extracting the arm angles
Hands have not been modeled or considered as a part of feature vector in most of the existing approaches. The main drawback is the possibility of carrying objects by the subject, and also ambiguity of hand identification because of its color and texture or occlusion with the bust. But here, we aim to study the importance of the motion of this articulated part and its effect on recognition rate.

We have chosen a simple characteristic of normal human walking as the basis. One of the unique properties of walking is bilateral symmetry; that is, when one walks or runs, the left arm and right leg interchange direction of swing with the right arm and left leg, and vice versa, with a phase shift of half a period ( Yam et al., 2004 ).

Considering this trait, we will be able to use line Hough transform without the previous difficulties. Since the legs were modeled in each frame in the former stage, the resulting angles and approximate position will be utilized to constrain the Hough space. Actually, the swing amplitude of the arms during normal walking is observed to be much larger than that of the legs. Thus, we have calculated these angles based on a linear relation of both hip and shin angles: y  X  t  X  X  a y H  X  t  X  X  b y K  X  t  X  X  3  X  where y H and y K indicate hip and knee rotation angles in each frame respectively, and a and b are two coefficients which are set based on different poses of leg and shin. The estimated value with a tentative range is used in line Hough transform, along with the approximate position of elbow and shoulder, based on the anatomical proportions. 5. Experimental results
The above algorithm is applied to the Georgia Tech (GT) database ( Bobick and Johnson, 2001 ), which consists of 268 sequences from 20 subjects (6 female/14 male). These sequences are collected under two viewing conditions: side view and angle view (45 1 ). For each subject and angle condition, there are 6 trials. Data collection is done indoors and outdoors. Considering these conditions, we use the indoors data, where lighting is at a constant level and subjects move with approximately constant velocity in front of a plain static background. The sequences are taken at different time intervals and the subject X  X  distance to the camera is changing. This data subset consists of 108 sequences (6 sequences for 18 subjects). Each video sequence is stored in digital video (DV) format, encoded in color PAL format at a resolution of 320 240 pixels, recorded at a rate of 29.97 frames per second. Each sequence typically consists of 80 X 120 frames, or around 3 full gait cycles. Figs. 6 and 7 show the extracted model superimposed over the original frames for sequences side0001m01 and side0006m01, for every 10 frames.

The inclination of the thigh and knee has been precisely found in the majority of frames. The best results are seen in frames where the legs are most distant. As the distance decreases, we may observe some problems, especially in the hip region.
However, this digression can be overlooked, as it will not considerably affect the total joint rotation. Also, it seems that some frames include inclination, where the position of thigh or shin is out of leg boundaries. This reflects just an inaccuracy in the estimation of the horizontal displacement of the leg region, as it was only based on the motion of the center of mass, rather than an error to the motion model.

As we assumed the fronto-para llel movement, one of the hands will be completely or partially occluded during walking. So we model only the hand which is closer to the camera. The same situation pertains for the legs, but we have tried to consider both legs in most frames even if just a part of the occluded leg is observable. Nevertheless, only one of the legs is adequate for recognition, because the opposite one has the same movement pattern with a p /2 phase offset. This information, in essence, is exploited in order to recover the missing data of the current semi-visible part. In other words, to handle the side effects of occlusion, we have used the knowledge of neighboring frames to predict the approximate pose of the segment, co nsidering the periodic nature of walking. This information, as stated before, is used in situations where neighborhood frames are corrupted by severe noise, semi-occlusion or failure of any of the phases. For occlusion of each of the two parts of the leg, the details of that segment are reconstructed through the information of that part in the current pose in previous cycles or the one with stated phase offset. Meanwhile, all aspects of the visible part, such as flexion and phase, should be taken into account simultaneously to retrieve the most useful data.
Comparing the rotational patterns of the hip and the knee given in Fig. 8 with the normal patterns displayed in Fig. 2 , we can see that the proposed model has created the same structure, so the simple solution for handling self-occlusion has been lucrative in rebating such noises.

In Fig. 6 , it is apparent that the arms X  inclination is estimated more acuratly than the legs X . This is because of its good initialization that allows the Hough transform to detect lines in a more limited space.

Comparing Figs. 6 and 7, we can observe differences in patterns of walking for different people from both sexes. In Fig. 7 ,the subject has more moderate motions, which produces rotation patterns with smaller amplitude. This is true about the arms as well, since they have less variations compared to the subject X  X  legs.
However, arm movements highly depend on the walking velocity, as the hands move more strongly with increasing speed. We have normalized the produced spectrums with the subject X  X  velocity to make the algorithm robust to speed changes. In addition, we have considered the parameters related to the body segments as a part of our feature vector. These parameters include each segment X  X  dimension and orientation. Since the measured dimensions depend on the subject X  X  distance from the camera, we normalize them with the person X  X  approximate height.

For recognition, we have used the frequency information of each rotation spectrum using Fourier analysis. This information includes phase-weighted Fourier magnitudes which is shown to have better discriminatory performance over the magnitude ( Cunado et al., 2003 ). In this case, the subjects are recognized not only by flexion, but also by the time when it occurs. The final feature vector comprises two types of elements: static and dynamic. Dimensions and angles of head and torso, along with the period of walking, person X  X  approximate body height and velocity form the first group. The last two components of these features are utilized to make the algorithm robust to speed and distance changes, and are not considered in the recognition. The second group consists of phase-weighted Fourier magnitudes of hip, knee and arm rotation spectrums.

For evaluation purposes, the database is divided into five trainig sequences and one test sequence for each person. The measure for each test sequence was compared against those of the trainig sequence. The k -nearest neighbor rule was used to classify the differences in different feature vectors for k  X  1to k  X  3. Two experiments are accomplished to analyze the effect of considering arm rotaion frequency components as a part of the final feature vector. So we have evaluated the algorithm considering the static and the leg-region related features in
Experiment 1, and all of the features including dynamic features of the arm in Experiment 2. Table 1 summarizes the correct classification rate (CCR) for these groups.

We have performed several more experiments to analyze the effect of image noise and the complexity of the background on the method. As mentioned in Section 4.1, an adaptive kernel regression method is applied to denoise the input image (for instace, film grain removal) to improve the performance of the algorithm in a wide range of cases. Therefore, in this experiment, the input frames are made noisy with Gaussian noise. The output results of the denoised image and related silhouette are displayed in Fig. 9 . As shown in the second image, the algorithm has been successful in removing the noise and reconstructing the input image, but the outcome is not as lucid as the raw image. However, the algorithm has been able to extract an accaptable silhouette, but the accuracy decreases due to the participation of less plain edges in the leg angle derivation. The final classification rate is still notable though ( Table 2 ).

In the next experiment, we tested the algorithm on video sequences with more complex backgrounds. These are part of the outdoor data of the GT database. Here, the subjects still move fronto-parallel to the camera with approximately constant speed, but as we have no control on lighting conditions, images contain shadows in most sequences. The related variations are seen in the extracted silhouette, which makes the temporal accumulation much less accurate. This problem leads to wrong initialization of the mean shape model which gives our static features. Since the source of light is behind the subject in the utilized sequences, we are able to omit the unwanted regions in each image. The results of a sample sequence are displayed in Fig. 10 . The final CCR for the above experiments is presented in Table 2 .

The results of classification show an improved performance compared to the existing approaches. This even gets better in case of adding rotation properties of arms as a feature (Experiment 2).
Actually, fair comparisons are made if the implementation conditions and the used databases are identical. Bobick uses the
GT database and the static body and stride parameters of subjects ( Bobick and Johnson, 2001 ). In his work, two sets of parameters are presented and the within and between discrimination power of each set are analyzed. He reports a CCR of 91% for the indoor side view images where the people are far from the camera and 94% where the people are much closer.

The approach introduced by Tanawongsuwan and Bobick (2001) uses only the trajectories of the lower body joint angles in the GT database. This method has reached a CCR of 73% on 106 time-normalized signals. The approach has gained accurate results through the use of markers, but the classification rate is a demonstration of the deficiency of features. We similarly examined the proposed algorithm by considering just the dynamic features in the feature vector. The system was able to correctly classify in 75.5% of instances, which is remarkable since no marker was used. The main overhead in time complexity of the above approach is the DTW algorithm applied to align joint angle trajectory in an animation application, which has O ( n m ).
Parameters n and m represent the length of the sequences utilized for alignment ( Keogh, 2005 ).

Wagg uses hierarchies of shape and motion and global temporal accumulation to robustly estimate the size and shape of the person X  X  body segments ( Wagg and Nixon, 2003 ). He estimates the dominant gait frequency via a measurement of the edge strength about the lower leg region over time. Leg motion is estimated by fitting prototype gait curves collected from a clinical gait study to the subject X  X  gait frequency and hip rotational amplitude. This approach achieved a CCR of 84% for indoor sequences of the Southampton HiD database. It, in addition, attained the time complexity of O ( p n ), which principally belonged to the pre-processing stage, containing color to grey-scale conversion, edge detection and background subtraction, along with temporal accumulation, finding the velocity of the subject and reducing the image sequence to a single summary image ((number of velocity quanta) (mean number of edge pixels per frame) (number of frames)).

Finally, Ning uses a hierarchical search strategy in a divide-and-conquer fashion based on the tree-like structure of the human body model to decompose the parameter space. This is done so that locating the human global position and estimating each joint angle can be done separately. A kinematics-based algorithm is utilized to recursively refine the joint angles. To measure the matching error, a pose evaluation function combin-ing both the boundary and the region information is applied.
Experimental results on both indoor and outdoor images have gained a CCR of 87.5% on the NLPR database ( Ning et al., 2004 ).
This method, has gained the time complexity of O ( n m k )in which n is the projection area of each body part, m is the number of body parts, and k is the number of iterations, where usually m  X  10 and k o 100.

The proposed algorithm, on the contrary, faces the time complexity of O ( n ), O ( p n ), O (2 n ), O ( p log(nm) n ), O (( p / 2) n ) and O ( n ) for different stages of foreground segmentation, velocity filtering, ellipse fitting, two steps of using active contours, skeletonization and Hough transform, respectively. This makes the whole complexity of the method an order of O ( p n ), where p is the number of pixels and n is the number of frames in a sequence. The above comparisions with the proposed algorithm are summarized in Table 3 .

However, as we mentioned earlier, the difficulty with using arms as a part of the model is in cases where the subject is carrying something and the hands are not in normal position. In such cases, the algorithm which uses this feature fails. Hence, it is better to test the person X  X  condition via an algorithm for object carriage detection as in Haritaoglu et al. (1999) , and then choose the appropriate subset of features. 6. Conclusions
We have described a method for extracting the gait signatures and kinematic features for analyzing and identifying the gait motion, guided by the known anatomy. A 2D model is used to represent the human body and trajectory-based kinematic features, extracted from the image sequences in two stages. First, a shape model based on anatomical proportions is utilized to gain an overall picture of the body, upon which the main motion model is built. This model is fitted on temporal accumulation of the subject to estimate a main initial parameter which is the approximate height of the subject. The dynamic properties of the subject X  X  locomotion are computed based on the rotation angle variation of three articulated parts of the body: hip, knee and arm. Leg region properties are estimated using a combination of two active contour models from which a medial axis of the silhouette is extracted. Moreover, analysis of the arm movements is added to describe their role in the method X  X  discrimination ability, using bilateral symmetry characteristics of human walking. Frequency domain gait signatures and body segments properties are used for classification.

We have shown that one can reliably locate joint angles for the purpose of gait analysis by applying this approach to the GT database and achieving a recognition rate of 94.5% and 93.1%, with and without the arm orientation features, respectively.
Experimental results show promising performance in both experiments compared to other similar methods. However, applying the technique to a larger database will better indicate the performance of the method. Also, the effect of footwear or loose clothing on the classification rate needs to be studied.
Besides, imagery with multiple moving people will require a more complicated strategy to extract the model parameters.

In our future work, we will generalize the method to other imaging viewpoints and further analyze the above features for constructing a model capable of operating in real-world applications. References
