 Classification is to predict possible labels on unlabeled instance given a set of labeled training instances. Traditionally, it is assumed that each instance is as-sociated with only one label. However, an instance often has multiple labels simultaneously in practice [1,2]. For example, a report about religion could also be viewed as a politics report. Classification for this kind of instance is called multi-label learning. Nowadays, multi-l abel learning is receiving more and more concerns, and becoming an important topic.

Various methods have been developed for multi-label learning, and these methods mainly fall into two categories [2]: (1) algorithm adaptation, which extends traditional single-label models so that they can deal with multi-label instances directly. Several adapted traditional models include Bayesian method, AdaBoost, decision tree, associative rules, k -NN, etc. [3,4,5,6,7]. (2) problem transformation, which converts a multi-label problem into one or several single-label problems. Thus traditional single-label classifiers can be used directly with-out modification. Recently, many methods have been proposed to learn label dependency as a way of increasing learning performance [1,2,8,9,10,11,12]. How-ever, most of them do not give an explicit description of label dependency. For example, classifier chain, a model proposed recently [9], links the labels into a chain randomly and assumes that each l abel is dependent on all its preceding labels in the chain. However, each lab el may be independent with its preceding labels while dependent on its following labels since they are linked randomly. Moreover, more complex dependency such as a tree or DAG-like hierarchical structure of labels often exists in prac tice, thus more appropriate models are needed to describe them.

Hence, we propose one kind of novel method for aforementioned issues. We quantify the dependencies of pairwise labels firstly, building a complete undi-rected graph that takes the labels as the set of vertices and the dependent val-ues as edges. A tree is then derived to depict the dependency explicitly, so the unrelated labels can be removed for each label and the dependency model is generalized into a tree model. Furthermo re, we also use ensemble technique to build multiple trees to capture the dependency more accurately. The experimen-tal results would show our proposed method is competitive and could further enhance learning perform ance on most of datasets.

The remainder of this paper is organized as follows: We review the related works in section 2. A formal definition of multi-label learning is given in section 3. In section 4, we describe and analyze our proposed methods in detail. Section 5 is devoted to the experiment design and result analysis. The last section concludes this paper and gives some potential issues with further research. Many methods have been proposed to cope with multi-label learning by exploit-ing label X  X  dependencies. According to the order of dependency be learned, these methods mainly fall into following categories. (1) No label dependency is learned. Basic BR (Binary Relevance) method decomposed one multi-label problem into multiple independent binary classifi-cation problems, one for each label [2]. Boutell et al. used BR for scene classi-fication [13]. Zhang et al. proposed ML-KNN, a lazy method based on BR [7]. Tsoumakas et al. proposed HOMER to deal with a large number of labels [14]. (2) Learning the dependencies of pairwis e labels. Hullermeier et al. proposed the RPC method that learned the pairwise preferences and then ranked the labels [15]. Furnkranz et al. extended the RPC by introducing a virtual label [16]. Madjarov et al. proposed a two stage architecture to reduce the computational complexity of the pair-wise methods [17]. (3) Learning the dependencies within multiple labels. Basic LP (Label Power-set) method treated the whole set of labels as a new single label and learned dependencies within all them [2]. Tsoumakas et al. proposed the RA k EL d method that divided the label set into disjoint subsets of size k randomly [18]. Stacking-base method was proposed to aggregate binary predictions to form meta-instances [19]. Read proposed the PS, which decomposed the instance X  X  la-bels until a threshold was met [8]. Read et al. proposed the CC (Classifier Chain) algorithm to link the labels into a chain randomly [9]. Dembcynski et al. pro-posed PCC, a probabilistic framework that solved the multi-label classification in terms of risk minimization [10].

A number of models have also been used to depict the labels dependencies explicitly, which include multi-dimensional Bayesian network, conditional depen-dency networks, conditional random fields [11,20,21,22,23]. Dembczynski et al. formally explained the difference between the conditional dependency and un-conditional dependency [24]. Similar with these methods, our proposed method uses the tree to learn the label dependency explicitly. the difference is that we simply ignore the feature set in the proces sofconstructingatr ee, whereas others [11] build the models conditioned on the feature set. Let X be the instance space, and L =( l 1 ,l 2 ,...,l m ) be a set of labels. Given a instance, and C k  X  L is a subset of L denoting x k  X  X  true labels, the target of multi-label learning is to build a classifier: f : X  X  2 L , that is a mapping from the instance space to a set of label subset, where 2 L is the power set of L . C k can also be represented by a Boolean vector ( b k 1 ,b k 2 ,...,b km ), where b kj =1
Let x  X  X be an unlabeled instance, y =( y 1 ,y 2 ,...,y m )beitsBoolean vector of predicted labels, we can also m ake prediction by calculating the joint conditional probability P ( y | x ). For each label l k ,let Parent ( l k )denotetheset of labels that label l k is dependent on, Parent ( y k ) is the corresponding Boolean counterpart. Hence P ( y | x ) can be transformed as Eq.(1).
 where y k denotes the k th label. Hence we can get the label vector X  X  posterior probability by calculating each label X  X  posterior probability respectively, so the transformation of Eq.(1) is a kind of problem transformation. A key issue is how to exactly find the set of dependent labels for each label in order to calculate the posterior probability more accurately. As mentioned above, to eliminate weak dependencies in CC model, and fit the real data more accurately, we propose a new algorithm named as LDTS (Learning dependency from Tree Structure of Labels) in this section.
LDTS firstly measures the dependency for each pairwise labels l i and l j ,no-tated as dependency ( l i ,l j ), thus an undirected complete graph G ( L, E )iscon-structed, where the label set L denotes the vertices, and E = { dependency ( l i ,l j ): l  X  L, l label, a maximum spanning tree is then derived using Prim algorithm, and each label is assumed to be dependent on its an cestor labels. A dataset is then created for each label and their dependent labels are added into the feature set, so we could utilize these dependency since the classifiers is trained based on the new feature set. The whole training process is outlined in Algorithm 1.
 Algorithm 1. The process of training LDTS classifier
At step 1, mutual information is used to compute the dependencies of pairwise labels. Its definition is shown as follows [25].
 where X and Y are two variables, x and y are their all possible values.
The labels is organized using a tree for t wo purposes. Firstly, the properties of maximum spanning tree ensure that each label is more dependent on its ancestor labels than other labels, since they have greater mutual information value. Hence it could eliminate weak dep endency further by assuming each label is only dependent on its ancestor labels. When generating the graph and tree of labels, we simply assume that label dependency is independent with the feature set and only consider the mutual influence among the labels, this is one kind of the unconditional dependency described in [24]. Secondly, various kinds of dependencies including tree hierarchy and DAG of dependency may exist within labels. Therefore, we expect the performance could be improved, especially on the datasets in which the labels are organized into a tree indeed.

It is also should be noted that the main purpose of our method is to find more accurate label dependency, and it does not impose a hierarchy on labels since labels have the same parent or in different paths could exist simultaneously. This is different from the hierarchical classification that impose a strict label hierarchy. Although the randomness in not eliminated fully, we do reduce it to only select the strong dependency randomly. One possible issue is that a full graph of labels needs to be learned with the computational complexity O ( n 2 ), the efficiency needs further improvemen t to cater for a large number of labels.
When classifying an unlabeled instance x , each label l i can not be predicted until its dependent labels are all predicted. Hence the labels should be predicted from the root of the tree and then its children recursively until all the leaves are reached. The detailed process is depicted in Algorithm 2. For each label, the labels dependencies are considered since its prediction is based on the feature set and the predictions of its dependent labels.
 Algorithm 2. The process of classification using LDTS classifier
When generating the directed tree in LDTS, the root node is selected ran-domly. However, selecting a different label will result in a different tree and thus generating different dependent labels for each label. Another issue is the label dependency could not be utilized fully, since the dependency of pairwise labels l ,l j calculated here is mutual and useful equally to each other. One possibility is that a label may also depend on its children labels, but the directed tree does not allow for this situation. To address such issues, the ensemble learning is used to generate multiple LDTS classifiers iteratively. In each iteration, the classifier is trained on a sampling of the original dataset, and the root label is reselected randomly. Hence each iteration will get a different label tree and combining them will reduce the influence of the root X  X  randomness and take full advantage of the label dependency. We call this extended method ELDTS(Ensemble of LDTS). The detail process is depicted in Algor ithm 3. Given an unlabeled instance x , all predictions of these classifiers will be aggregated into a final result by voting simply.
 Algorithm 3. The process of training ELDTS classifier
All above are the description and analysis of our proposed algorithms. Com-parison with other state-of-the-art algorithms and further analysis will be given in the following section. 5.1 The Description of Datasets We take several datasets from multiple domains for the experiments, and table 1 depicts them in detail.

Several statistics as follows have been used to characterize these datasets. (1) Label cardinality: LC = 1 n n i =1 | C i | . It calculates the average number of labels for each instance, where | C i | isthenumberoftruelabelsofthe i th instance. (2) Label density: LD = 1 n n i =1 cardinality by m , the size of original label set.
 (3) Distinct label sets: DLS( D )= |{ C | X  ( x, C )  X  D }| . It counts the number of distinct label sets that appear in the dataset.

Seen from table 1, these datasets cover many domains including text catego-rization, scene classification, emotion analysis, biology etc.. It should be noted that there are no label hierarchies in these datasets and we use them to examine whether our methods could find more strong label dependency and gain bet-ter performance. More detail description can be found on the official website of Mulan 1 . 5.2 Evaluation Criteria In order to evaluate the algorithm performance, the criteria should be specified. stance, and C i  X  L is its true labels. Given a classifier f andaninstance x i , Y i denotes the predicted labels for x i , while rank ( x i )or rank i denotes the pre-dicted rank of labels, and rank ( x i ,l ) denotes the label l  X  X  position in the rank. All the criteria we used are as follows. (1) Hamming loss: It is proposed by Schapire and Singer [4].
 The operator number of misclassified labels for an instance. (2) Accuracy: It calculates the ratio bet ween the intersection and union of the predicted set of labels and the true set of labels for the instances on average. (3) One-error: It calculates how many times that top-ranked label is not a true label of the instance.
 where  X  ( x )=1if l is a true label of the instance, otherwise  X  ( x )=0. (4) Ranking loss: It expresses the number of times when the irrelevant labels are ranked before the true labels.
 R-Loss= (5) Average precision: This measurement calculates the average fraction of labels ranked above a particular label l  X  C i , which are all also in C i .
These criteria evaluate the different aspects of these methods. While Hamming loss and accuracy do not consider the relation between different predictions, the other 3 criteria take such a relation into considerations, since they are based on the ranking of the probabilities predicted for all labels. Because our methods are intended to get a more accurate probability for each label by finding more strong labels dependencies, thus for each label, it should be predicted more accurately and the true labels should be given greater possibilities. Therefore, we expect that our method could gain better performance under Hamming loss and ranking loss, since Hamming loss examines the predictions of all labels independently and ranking loss focuses on whether the true labels are given greater probabilities than other labels. For other 3 criteri a, our method may be effective, but they are not what our method optimize for. 5.3 Algorithms and Settings The algorithms used for comparison are listed in table 2 with their abbreviations respectively. To examine the effect of label dependency, BR algorithm is used as a baseline since it does not consider the label dependency, then we compare our proposed LDTS and ELDTS with CC and ECC methods to see their effectiveness after eliminating weak dependencies. RA k EL d and RA k EL are also used for comparison as other ways of learning label dependency.

The experiments are divided into two parts, according to the two purposes mentioned in section 4. One part is on the five aforementioned datasets without label hierarchy to see whether our method can find more strong dependency and thus gain better performance, the other part is on the dataset rcv1v2, a dataset in which there exists a tree hierarchy of labels, to see its performance when a tree structure is learned. S ince only one tree exists in rcv1v2, we do not use the ensemble method on it.

AllalgorithmsareimplementedontheMulanframework[26],anopenplat-form for multi-label learning. The parameter values are chosen as those used in the paper [9]. For the RA k EL, we set the k = m 2 .FortheRA k EL d ,wesetthe k = 3. For the ensemble algorithms, the number of iterations is 10, and for each iteration, 67% of the original dataset is sampled with replacement to form the training dataset. SMO, a support vector machine classifier implemented in Weka [27], is used as the base classifier. All algorithms are executed 5 times using 10-fold cross validation on all datasets ex pect rcv1v2 with different random seeds 1, 3, 5, 7, 11, respectively, and the final results are the averaged values. For the rcv1v2, only 100 attributes are kept, and 10-fold cross validation is used only one time since it has a huge amount of instances and attributes. 5.4 Experimental Results and Analysis Based on above setup, we get the final results and the following tables display them in detail. The bold result indicates the best one, and result with the black dot  X   X   X  indicates our proposed algorithm is better than itself indicated algorithm.
As shown from table 3 to table 7, our proposed LDTS method performs better on the majority of datasets evaluated by the criteria. It is superior to CC on 3 datasets under the Hamming loss, accuracy, one-error, and ranking loss, but inferior under other metrics. LDTS algorithm does not improve all the time or the improvement is not significant. The possible reason is that although LDTS algorithm could learn the dependency further, it still ignore lots of useful de-pendency since it only considers unidirectional dependency of pairwise labels, especially when the labels are dependent mutually. We expect that ensemble learning that combines different trees can further utilize the label dependency , since the dependent direction between pairwise labels is changed in a different tree by choosing a different root.

To validate above assumption, we also use ensemble learning on these algo-rithms and compare them each other. Also shown from table 3 to table 7, our proposed ELDTS has a substantial improvement after the employing ensemble learning. Under all 5 criteria, ELDTS is superior to ECC on most datasets. These results show that through learning multiple label trees by ensemble learning, the influence of the root label X  X  randomness could be mitigated, and the label de-pendencies are learned more effectively. Although ECC algorithm also changed the order of labels, it could not make sure that only the strong dependency is considered each time, since it X  X  totally random when determining the dependent relationship within labels.

It can be observed that the proposed algorithms do not perform well on two datasets medical and scene . Seen from the table 1, these two datasets have very small label cardinality, which means there tend to be less label dependency in them and overemphasis on label dependency may not be preferable. Thus the algorithms we propose are more suitable for the datasets that there are indeed strong label dependency in them.

The results gotten on rcv1v2, a dataset with tree structure of labels, are also given in table 8. We can clearly see that our proposed LDTS method is superior under Hamming loss and ranking loss, the criteria it optimize for. Therefore, it has been proven that our method is more effective when there is complex dependency within labels.
 In this paper, one kind of novel approaches are proposed to exploit the label depen-dency. Specifically, the dependency degree of pairwise labels is calculated firstly and then a tree is build to represent the dependency structure of labels. The meth-ods assume that the dependencies only exist between each label and its ancestor labels, resulting in reducing the influence of weak dependency. At the same time, they also generalize the label dependency into a tree model. Furthermore, we utilize ensemble learning to learn and aggregate multiple label trees to reflect the labels dependencies fully. The experimental results show that the algorithms we proposed perform better, especially after boosted by the ensemble learning.

One potential problem is that using mutual information to measure the de-pendency will give equal values to both of the labels, which assumes that the dependency for pairwise labels is mutual and equal for each other. However, the label dependency could be directed possibly and this assumption is often vio-lated in reality. Hence how to measure the directed label dependency should be one of the next directions. Additionally, how to generalize the tree structure of labels further to graph or forest structure is another issue in the future work.
