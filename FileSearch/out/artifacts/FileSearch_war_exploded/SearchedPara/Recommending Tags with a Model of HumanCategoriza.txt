 When interacting with social tagging systems, humans exercise complex processes of categorization that have been the topic of much research in cognitive science. In this paper we present a recommender approach for social tags derived from ALCOVE, a model of human category learning. The basic architecture is a sim-ple three-layers connectionist model. The input layer encodes pat-terns of semantic features of a user-specific resource, such as la-tent topics elicited through Latent Dirichlet Allocation (LDA) or available external categories. The hidden layer categorizes the re-source by matching the encoded pattern against already learned ex-emplar patterns. The latter are composed of unique feature patterns and associated tag distributions. Finally, the output layer samples tags from the associated tag distributions to verbalize the preced-ing categorization process. We have evaluated this approach on a real-world folksonomy gathered from Wikipedia bookmarks in Delicious. In the experiment our approach outperformed LDA, a well-established algorithm. We attribute this to the fact that our ap-proach processes semantic information (either latent topics or ex-ternal categories) across the three different layers. With this paper, we demonstrate that a theoretically guided design of algorithms not only holds potential for improving existing recommendation mech-anisms, but it also allows us to derive more generalizable insights about how human information interaction on the Web is determined by both semantic and verbal processes.
 H.2.8 [ Database Management ]: Database Applications X  Data min-ing ; H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Information filtering personalized tag recommendations; LDA; human categorization; Wikipedia; Delicious
There is now broad agreement that in order to support users in tagging resources on the Web, a good understanding of the mech-anisms that underlie human tagging behavior is advantageous [4, 6]. Based on models of information theory [6] and human memory theory [4] generative models of social tagging have been developed providing much insight into the emergence of the data observed in social tagging systems. The generative models implement cogni-tive assumptions about human information processing and provide computational models that predict a tag distribution. Comparing the theoretical to the empirical tag distribution then allows making claims about the validity of the underlying cognitive assumptions. A stricter test of theoretical claims can be provided by controlled experiments as these allow for testing causal relationships more di-rectly. Such studies have been conducted, for instance, by Fu et al. [4] to test the semantic imitation model of social tagging, by Cress et al. [3] to test a social variant of information foraging theory, as well as by our own group to find evidence for a dual-process mem-ory mechanism [22]. These studies, on the other hand, have limi-tations as they need to necessarily control the setting in which they are conducted. To generalize findings from these lab settings to naturally occurring tagging behavior, the models need to be tested in real-life settings. In this paper, we have devised a recommender mechanism which implements some basic mechanisms of human categorization that is assumed to take place in social tagging envi-ronments. When contrasting predicted with observed tag choices, this provides validation of the underlying model. Additionally, this approach allows several algorithms and their underlying models to be compared to each other.

The contributions of the paper are threefold: (1) We present a novel tag recommendation mechanism that is based on psycholin-guistic models of categorization and speech production, (2) We demonstrate that such a recommendation mechanism performs sig-nificantly better than a standard tag recommendation approach such as LDA, and (3) We demonstrate that a theoretically guided design of a recommender complements data-driven approaches in that it allows for learning something about how humans process informa-tion in sensemaking tasks on the Web.
The remainder of the paper is structured as follows: In Section 2 we discuss related work and in Section 3 we present our new ap-proach. In Section 4 we shortly introduce our experiments and the used dataset. Section 5 presents the results of our study. Section 6 concludes the paper and discusses our findings in light of the ben-efits of connecting data-driven and theory-driven research for rec-ommender systems research. Finally, Section 7 outlines future re-search directions.
In contrast to the research on generative models of social tag-ging mentioned above, recommender systems research has taken a more pragmatist stance, such as helping users discover useful re-sources on the Web, or improving the overall tag consistency. One of those approaches that have been very successful in predicting and recommending tags for Web resources has been collaborative filtering [7]. The first work describing such a mechanism for the domain of collaborative tagging systems is the work of Xu et al. [25] who introduce a simple tag co-occurrance approach to rec-ommend tags to a user. Sigurbjornsson et al. [24] developed a similar approach and showed for the photo tagging system Flickr that it is  X  X ssential to take the co-occurance values of the candi-date tags into account when aggregating the intermediate results in a ranked list of recommended tags X . Hotho et al. [9] presented an algorithm called FolkRank which uses the structure of folk-sonomies for searching and ranking. These rankings can also be used to recommend tags, resources and users or to build commu-nities of interest from the folksonomy. In [10] Jaschke et al. ex-tended FolkRank to design a graph-based tag recommendation al-gorithm on top of it and compared it to collaborative filtering based on users, where they achieved better recall and precision values. Another interesting contribution to tag recommender systems was made by Lipczak and Milios [18] who introduced a novel scalable and adoptable system, which can recommend tags based on the re-source X  X  title and content and the user X  X  profile and which allows to learn new tags efficiently. Rendle et al. introduced a factorization model PITF (Pairwise Interaction Tensor Factorization) with linear runtime for both learning and recommending tags [21]. Similarly to the work of Lipczak and Milios [18] they addressed the prob-lem of the cubic runtime of Tensor Factorization approaches which have been shown to outperform for instance other tag recommender algorithms such as FolkRank, collaborative filtering, etc. One of the first extensive studies of the tag prediction problem from the rule-mining perspective was performed by Heyman et al. [8], who achieved high-precision results in a number of experiments using tags from the social tagging system Delicious. In a follow-up, Krestel et al. [13]. tested the use of recommending tags in LDA and showed that it delivered significantly better results than the as-sociation rules. In [12], they enhanced the performance of LDA by combining it with simple language models based on the most frequent tags of the users and the resources in the bookmarks.
Although these methods of finding algorithms to accurately pre-dict historical user-interaction data are rather efficient, they often lack theoretical background in the cognitive processes that lead to the data that is being predicted. By applying formal models of human semantic memory, the new recommender presented in the next section complements the above-mentioned recommender sys-tems and integrates current cognitive science results into the rec-ommender systems for social tagging. Figure 1: Basic architecture of 3Layers (Note that only two of the six exemplars at the hidden layer are illustrated com-pletely).
Our theoretical focus is on formal memory models explaining word (re-)productions and hence, psycholinguistic processes that we deem to be in play during tag assignments and tag imitations. A number of prominent memory models assume word productions to proceed in different steps on distinct levels of memory. For in-stance, the Fuzzy Trace Theory (FTT, [2]) postulates an activation of a gist-trace in response to a stimulus, e.g. a Web-resource or a set of associated tags, which contains semantic aspects (concepts, relations, patterns) of the stimulus. The gist-trace in turn recon-structs several, semantically related word forms verbalizing the ac-tivated gist. By means of a Markov model derived from FTT, [22] showed that a substantial amount of tag productions can indeed be predicted by a two-step memory retrieval involving both gist-based and verbal processes.

Similarly to FTT, the psycholinguistic theory of Levelt et al. [16] distinguishes between three processes during the production of words: 1) Categorization (resulting in a message or gist to be articulated), 2) Formalization (accessing the mental lexicon to ac-tivate word forms corresponding to the categorization) and 3) Ar-ticulation (selecting and producing appropriate word forms). The recommender presented here is called 3Layers and is in line with this proposed translation of latent structures into words. We as-sume a set of tagged resources, which are at the same time assigned to a category. These categories (hereinafter called "semantic fea-tures") are either given a-priori (e.g. because a page is categorized to a wikipedia category) or are derived as LDA topics [5] from the tag assignments. The recommender starts with categorizing a user-specific resource by encoding and processing semantic features true for the user and/or resource, then formalizes the categorization by identifying tag distributions associated with the resource X  X  semantic features and finally, articulates tags by sampling the most appropri-ate tags from the identified tag distributions. 3Layers is based on ALCOVE [14, 15], a formal model of hu-man category learning. The basic architecture is a feed-forward connectionist network consisting of three layers of nodes realizing a top-down pattern completion process by means of straightforward equations. In response to semantic information on the input layer (two patterns of LDA-topics or external categories, one characteriz-ing a user and one a specific resource), the hidden layer categorizes and formalizes the resource by calculating the input X  X  similarity to already stored exemplars that are unique topic (or category) pat-terns and associated tag distributions. Finally, the output layer ar-ticulates the preceding categorization and formalization processes by sampling tags from the tag distributions of the identified, similar exemplars.

On the input layer, there are two input vectors representing se-mantic features that are true for the user u, a in u , and the resource r, a in r . Within each vector, each of the N nodes represents a sin-gle semantic feature f i (in our case a topic identified by LDA or a category). Its activation (denoted a in i ) indicates the extent to which that feature applies to the user, a in iu , and resource in question, a iu is given by where c ( f i ,u ) represents the counted frequency of the semantic feature in the user X  X  personomy (i.e., her or his bookmark collec-tion). Correspondingly, a in ir represents the association of the se-mantic feature to the resource and is estimated in a similar way from the counted frequency of the feature f i in all bookmarks of the resource r, c ( f i ,r ) . The activations across the N input nodes con-stitute the vectors a in u = ( a in 1 u ,a in 2 u ,...,a in ,a
Nr ). In Figure 1, the left semantic feature pattern at the input layer corresponds to the input vector a in u = ( . 04 ,. 24 ,...,. 01 ,. 00) indicating that, for instance, the topics/categories 1 and 2 have the relative frequencies . 04 and . 24 , respectively, across the user personomy.

The nodes on the hidden layer store information about exem-plars e j extracted from the training set, that is all previous tag as-signments of that user. Figure 1 illustrates two such exemplars ( and e 8 ) that are composed of unique, semantic feature patterns, = ( h j 1 ,h j 2 ,...,h jN ) , and associative weights w tj maintained between each of all m tags t and the unique feature pat-tern h j and are illustrated in form of diagrams plotting the weights against the tags. The estimates of each h ji in h j are calculated in a similar way as the activation of each input feature (either a ir ), and the associative weight w tj encodes the relative frequency of each tag t in e i and is estimated as where c ( t, e j ) is the counted frequency of tag t in exemplar
Step 1 in Figure 1 is based on a simple pattern matching process and results in probability estimates of each exemplar. To perform it, we firstly calculate the distance of a given exemplar e j the cosine similarity measure and subtracting the result from 1, i.e.,
Correspondingly, d r j is calculated by subtracting the similarity between a in r and h j from 1. The distances are linearly combined to a single distance, which is then transformed to an activation (or similarity) estimate a hid j falling exponentially with the distance be-tween the hidden node and the input [23], and yielding a probability estimate for e j :
For example, the Figure 1 schematically illustrates that e ceives higher activation than e 8 (illustrated by the black-and grey-filled rhombic form, respectively) since e 6  X  X  topic pattern more similar to both input vectors a in u and a in r than tern h 8 .

We then form response strengths for each of the tags, t out step 2 (see Figure 1), each hidden node X  X  activation a hid plied by the corresponding tags X  associative weights, i.e., and in step 3, these products are summed over all hidden nodes, given by where each t out x is a realization of a discrete random variable since P m
In a last step 4, we make use of this probability distribution to simulate the user X  X  tag assignments by drawing y random numbers and mapping them into events, i.e. t out x . Finally, the observed count of tag t x in the simulation, c ( t x ) , determines its ranking for being recommended. If the parameter l specifies the number of tags to be selected, the subset of tags to be recommended RecT ags is given by
In order to evaluate our approach, we compared it with a popular tag recommendation approach based on Latent Dirichlet Allocation [12, 13].

Latent Dirichlet Allocation (LDA) is a probability model that helps to find latent topics for documents where each topic is de-scribed by words in these documents [13]. This can be formalized as follows: Here P ( t i | d ) is the probability of the i th word for a document d and P ( t i | z i = j ) is the probability of t i within the topic P ( z i = j | d ) is the probability of using a word from topic document. In LDA the number of latent topics Z has to be chosen in advance, which defines the level of specialization of the topics.
When using LDA for tag recommendation, documents are re-sources which are described by tags. This means that each resource, or more specified each bookmark of a resource, can also be repre-sented with the top tags of topics identified by LDA.
 We implemented the LDA tag recommendation algorithm with Figure 2: Recall/precision plots for LDA with 24 topics, LDA with 500 topics, 3Layers with Wikipedia categories and 3 Lay-ers with LDA tags on 1 -10 recommended tags. calculated the probability of a tag tP ( t | r, u ) based on a given user uP ( t | u ) and based on a given resource rP ( t | r ) and combined these two values based on the smoothing technique described by Krestel and Frankhauser [12]. This ensures that the two probabili-ties are weighted according to their importance and that no tag gets a probability value of 0.
For our experimentation we used a large-scale social tagging [26]. It was crawled between 2003 and March 2011 and contains nearly 340 million bookmarks, 119 million unique resources, 15 million unique tags and 2 million unique users. To obtain a dataset where all resources are categorized and freely available, we parsed lion bookmarks, 386 thousand unique resources, 361 thousand tags, 304 thousand unique users and 4.9 million tag assignments. This focus on the Wikipedia domain gives us not only the possibility to test our approach with external knowledge such as category infor-mation, but also increases the reproducibility of our experiments. In order to get a dense fraction of the dataset we used a ing technique as proposed by Batagelj and Zaversnik [1]. The final dataset we used for our experiments was a p-core pruned dataset at level 14 and contained 49,691 bookmarks, 2,003 unique resources, 1685 unique tags, 1,968 unique users and 194,584 tag assignments.
In order to extend the resources in our dataset with semantic fea-tures that can be used as external knowledge for the input layer of our approach, we fetched the category information of the Wikipedia categories are very specific, we only focused on the 24 Wikipedia top-level categories for each article obtained from the Wikipedia category-taxonomy that we created according to [19].
To evaluate the performance of our tag recommender approach we used a 80/20 split to randomly generate 20 different training and test sets. The bookmarks in a training set were used as the input for the algorithms to predict the tags of the bookmarks in the corresponding test set [13].

As evaluation metrics we used different well-established metrics for tag recommendations in order to obtain the performance of our Figure 3: F1-score values for LDA with 24 topics, LDA with 500 topics, 3Layers with Wikipedia categories and 3Layers with LDA tags on 1 -10 recommended tags. approach compared to LDA [10, 17]. All these metrics are reported for different numbers of recommended tags (1 -10) and as an aver-age over our 20 training and test sets.

Recall is calculated as the number of correctly recommended tags divided by the number of relevant tags, where t u denotes the list of recommended tags and T u the list of relevant tags of a book-mark of user u . This is averaged on all known bookmarks U
Precision is calculated as the number of correctly recommended tags divided by the number of recommended tags.
 F1-score combines precision and recall into one score [17].
Mean reciprocal rank (MRR) is the sum of the reciprocal ranks of all relevant tags in the list of the recommended tags. This means that a higher MRR is achieved if the relevant tags occur at the be-ginning of the recommended tag list [20].

Mean average precision (MAP) is an extension of the precision metric that also looks on the ranking of the recommended tags. It is described in the formula below where B n is 1 if the recommended tag at position n is relevant [20].

In this section we present the results of our approach compared to LDA based on the previously mentioned evaluation metrics and the Wikipedia dataset.

As reported in Section 4, the number of latent topics for LDA has to be set in advance. When generating recommendations for 24 (corresponding to the number of top-level categories in Wikipedia), 100, 250, 500, 750 and 1000 topics based on 10 recommended tags, Table 1: MRR and MAP values with standard deviations for LDA with 24 topics, LDA with 500 topics, 3Layers with Wikipedia categories and 3Layers with LDA tags on 10 recom-mended tags. we found that 500 topics produced the best results (MRR = .862 and MAP = .345). We therefore configured our 3Layers approach with two different data sources for its input layer, (i) Wikipedia X  X  24 top-level categories as described in Section 4.1 and (ii) tags based on LDA with 24 (corresponding to the 24 Wikipedia categories) and 500 topics. For the second configuration we used the top 10 tags identified by LDA for each bookmark in the training set.
Figure 2 shows the recall/precision plot for LDA with 24 top-ics, LDA with 500 topics, 3Layers with Wikipedia categories and 3Layers with LDA tags calculated for 500 topics on 1 -10 recom-mended tags. LDA with 24 topics is used here as a simple baseline based on the number of top-level categories in Wikipedia. Fur-thermore, Figure 3 also shows the F1-score values for these algo-rithms on 1 -10 recommended tags. It can bee seen that both 3Lay-ers approaches outperform LDA on all values where the maximum values are reached for recall@10 = .758, precision@1 = .646 and F1-score@4 = .426 for 3Layers with LDA tags identified for 500 topics.

The MRR and MAP values with standard deviations are shown in Table 1 for all the algorithms on 10 recommended tags. Also on these metrics the two 3Layers approaches outperforms LDA on all values. The maximum values are reached by 3Layers with LDA tags based on 500 topics for MRR = 1.200 and MAP = .549 (visu-alized in bold). These estimates clearly imply that independent of the measure the probability estimates vary with the conditions, i.e. the tag recommenders, in a constant ordering.
 To check for statistical significance we performed two one-way ANOVAs on MRR and MAP for 10 recommended tags with Al-gorithm as a between-subjects factor. The statistical prerequisites of normal distribution and equal variances were met. The results of both ANOVAs are shown in Table 2 and are well in line with the de-scriptive pattern of Table 1. In particular, the overall difference be-tween the four recommenders proved highly significant and yielded the large effect sizes of  X  2 MRR = .997 and  X  2 MAP = .998. Addi-tionally, pairwise comparisons conducted by means of the Tukey X  X  HSD test corresponded to the ordering described above. First, the difference between the two best performing recommenders, i.e. 3Lay-ers -LDA 500 and 3Layers -Categories (MRR: q = 55.38, p &lt; .001; MAP: q = 64.56, p &lt; .001), second, the difference between 3Lay-ers -Categories and LDA 500 (MRR: q = 21.73, p &lt; .001; MAP: = 28.05, p &lt; .001) and third, the difference between LDA 500 and LDA 24 (MRR: q = 71.88, p &lt; .001; MAP: q = 97.29, p &lt; .001) all proved large and highly significant.
In this paper we have presented and evaluated 3Layers , a model of human categorization implemented in form of a tag recommender. The model takes into account semantic information about a user-specific bookmark, which is either a set of available Wikipedia cat-egories or a set of topics derived by LDA. The semantic information is further processed in a connectionist network of three layers that Table 2: Summary of one-way ANOVA for MRR and MAP on 10 recommended tags with Algorithm as the between-subjects factor. mimics the user X  X  categorization and formalization of the bookmark to predict the user X  X  tag assignments. We think this has introduced some new perspectives into recommender systems research for so-cial tagging environments.

Our experiments show that the 3Layers -model holds potential of realizing a strongly performing recommender system. In partic-ular, 3Layers -LDA that utilizes LDA-topics as input significantly outperforms the LDA-recommender introduced by [13]. The same applies to 3Layers -Categories, which makes use of Wikipedia cate-gories and therefore, operates independently of the LDA-approach.
Of course, several limitations of these results need to be ad-dressed. As we have only tested the performance in one data set, generalizability to other cases needs to be demonstrated. Also with-out a doubt, there is nowadays a much larger set of recommender algorithms available than we could take into account in our study.
We take the results as a promising outcome. First of all, the processing of semantic categories (either explicitly given, or la-tent) can alleviate the cold start problem that other approaches are suffering from (such as Collaborative Filtering or those based on popularity, for instance). Reliance on these categories should also improve the robustness as the algorithm does not only depend on word-level imitation but takes into account shared semantic inter-pretations (e.g. [4]).

Additionally, our approach significantly enhances the LDA-rec-ommender [13, 12] by further operating on the identified latent topic patterns. We attribute the latter result to the calculation steps of formalization where prior tag distributions are weighted accord-ing to the preceding categorization steps. The result is a distri-bution at the output layer exhibiting fewer ties and allowing for a more accurate selection of relevant tags. Therefore, our approach provides an appropriate theoretical framework and an effective rec-ommender that integrates top-down and bottom-up generated data.
Our approach therefore should transfer well to other related Web interaction paradigms where both top down classification systems and bottom-up categorization co-exist. For example, Web cura-tion is a recent trend in which Web users can create collections of resources and share these collections with others. These usually employ mechanisms of social bookmarking and tagging, but also employ classification systems to which collections are assigned.
With Web interaction paradigms changing quickly, a purely data-driven strategy has its limitations, as the data sets produced within them may differ considerably. It is then more difficult to under-stand, why certain approaches perform very well in certain datasets, but not very well in others. The reason is that datasets are products of very complex processes [6] and they depend on a number of factors that the models would need to take into account. While the datasets will look different, many of the fundamental processes that underlie the interaction in these new environments (such as human categorization or language production) will be very similar. Hence, the danger of a predominantly data-driven research strategy is that with every new paradigm, we have to start from zero as the ear-lier algorithms are not directly transferable. With the current work, we have demonstrated how a connection between a data-driven and theory-driven approach can be realized when the algorithms imple-ment well-founded theories of cognitive science.
In future work we will address the previously mentioned issues by testing the recommender mechanism in other tagging datasets as well as with other Web interaction paradigms, such as Web cura-tion. Additionally, we will compare 3Layers  X  performance to other well-established approaches, such as FolkRank [9] or Collaborative Filtering [25]. A distinctive benefit of our theory-driven approach in designing tag recommendation mechanisms is that it opens up fruitful directions for future research. For instance, we hypothe-size that our approach relates to the distinction of categorizers and describers that was introduced in [11] to explain different tagging motivations. We suspect that 3Layers will especially work well for the categorizers who draw on a more refined system on personal categories when assigning tags.
 Acknowledgments: The authors would like to thank Andreas Hotho for his constructive comments on this work. This work is partially funded by the Know-Center and the EU FP7 under the Learning Layers project (http://www.learning-layers.eu). [1] V. Batagelj and M. Zaver  X  nik. Generalized cores. arXiv [2] C. Brainerd and V. Reyna. Recollective and nonrecollective [3] U. Cress, C. Held, and J. Kimmerle. The collective [4] W.-T. Fu, T. Kannampallil, R. Kang, and J. He. Semantic [5] T. L. Griffiths, M. Steyvers, J. B. Tenenbaum, et al. Topics in [6] H. Halpin, V. Robu, and H. Shepherd. The complex [7] J. L. Herlocker, J. A. Konstan, L. G. Terveen, and J. T. Riedl. [8] P. Heymann, D. Ramage, and H. Garcia-Molina. Social tag [9] A. Hotho, R. J X schke, C. Schmitz, and G. Stumme.
 [10] R. J X schke, L. Marinho, A. Hotho, L. Schmidt-Thieme, and [11] C. K X rner, R. Kern, H.-P. Grahsl, and M. Strohmaier. Of [12] R. Krestel and P. Fankhauser. Language models and topic [13] R. Krestel, P. Fankhauser, and W. Nejdl. Latent dirichlet [14] J. K. Kruschke et al. Alcove: An exemplar-based [15] M. D. Lee and D. J. Navarro. Extending the alcove model of [16] W. J. Levelt. A theory of lexical access in speech production. [17] M. Lipczak. Hybrid Tag Recommendation in Collaborative [18] M. Lipczak and E. Milios. Learning in efficient tag [19] D. Milne and I. H. Witten. Learning to link with wikipedia. [20] M. Rawashdeh, H.-N. Kim, J. M. Alja X  X m, and A. El Saddik. [21] S. Rendle and L. Schmidt-Thieme. Pairwise interaction [22] P. Seitlinger and T. Ley. Implicit imitation in social tagging: [23] R. N. Shepard et al. Toward a universal law of generalization [24] B. Sigurbj X rnsson and R. van Zwol. Flickr tag [25] Z. Xu, Y. Fu, J. Mao, and D. Su. Towards the semantic web: [26] A. Zubiaga, V. Fresno, R. Mart X nez, and A. P. Garc X a-Plaza.
