 Although business process modeling has become widely adopted and intensively researched in the last decade, we still know quite little about the concrete act of sense-making while a human inspects a model. At least, prior research has identified various factors that have an influence on how well a process model is understood. These fac-tors mainly relate to the representation of the model, for instance its size, its complex-modeling expertise or familiarity with a particular modeling language [1], [2], [3], [4]. Most of these factors can be traced back to theories such as cognitive load theory. 
What is striking in this context is the fact that the comprehension performance of a particular person in interpreting a specific model can be quite diverging. While it has been demonstrated that comprehension tasks vary in their degree of difficulty [5], concurrency, exclusiveness) has not worked well to separate easy from difficult comprehension tasks [6]. Beyond that, such a distinction does not help in explaining the striking importance of the degree of structuredness for comprehension. The notion of structuredness measures if a model is built using nested blocks of matching join and split connectors [7], [8]. 
In this paper we address the gap of research on the factors that influence the com-prehension tasks. We approach this topic from the perspective of both the process model and the comprehension tasks together, which provides us with a basis for de-fining the notion of a so-called Relevant Region and its components, the Relevant Model Elements. In order to evaluate the significance of this notion, we use an eye-tracking experiment with expert process modelers. Our results confirm the relevance of this notion, which has implications for future model comprehension experiments and for improving model comprehension in practice. 
The paper is structured as follows. Section 2 discusses the background of our re-search. We summarize findings in this area and standard ways of measuring compre-hension performance. This provides us with the basis to define the notion of a Rele-vant Region. Section 3 presents our research design. We formalize our expectations in terms of four hypotheses. Then, we present the experimental design for investigating these hypotheses, and the experimental setup. Section 4 presents the results of the experiment. We summarize the demographics of the participants. Furthermore, we utilize correlational analysis to inspect the hypotheses, and logistic regression to pre-dict the probability of a correct answer based on the Relevant Region metrics. Section 5 discusses our findings in the light of related work, before Section 6 concludes. In this section, we discuss the background of our research. First, we revisit the foun-dations of process model comprehension performance. Then, we describe novel direc-tions for the definition of comprehension task. 2.1 Process Model Comprehension Performance Model comprehension is an important facet that is closely associated with a more general notion of model quality. According to semiotic theory and its adoptions to model quality, a reader of a model has to understand the syntax and the semantics of a model correctly in order to be able to draw correct pragmatic conclusions from it [9]. Comprehension of a model cannot be directly observed. Therefore, comprehension performance is typically approached by pr oviding tasks to a model reader that can only be solved correctly when the model is well understood. The range of potential tasks types includes cloze tests, problem solving tasks, or speed of answering questions [10]. More specifically, in the area of process model comprehension, inter-pretation tasks relating to the formal behavior are typically used to operationalize comprehension [4], [11]. Such interpretation tasks can be constructed by presenting a process model to a model reader and asking how a specific pair of activities is related from a behavioral point of view (being concurrent, exclusive or ordered). The correct solutions can be automatically checked based on the formal semantics of the model [12]. 
Fig. 1 shows the example of a process model which was part of the BPMN Selftest (more details are available at http://granturi.ubbcluj.ro/decision_mining/docs/BPMN-Selftest-Material.pdf). People could participate in this self-test by running through a series of process model comprehension questions on a website. In relation to the model shown in the figure, it is interesting to note that user characteristics and model characteristics alone are hardly able to ex plain the comprehension performance. For instance, the comprehension task can Z and AA be executed in the same case (yes/no) was answered correctly by 65.6% of 430 participants, while the same partici-pants had 72.2% correct answers for the task After O has been executed, and the de-fault path is taken at the next gateway, then Z must always be executed (yes/no). Since we randomly sampled the questions, we can rule out fatigue as a distorting factor. This sampling was organized in such a way that participants never got tasks on the same model directly after one another to avoid memorizing bias. Furthermore, the second question is 13 words longer than the first one, which should imply a higher burden in terms of cognitive load. Still, on the aggregate level it was easier for partic-might serve as factors of model comprehension. 2.2 Model Comprehension and the Notion of a Relevant Region The idea of defining new metrics in relation to model comprehension relies on the observation that not the whole model has to be studied for providing a correct solution to a comprehension task. If we consider the second task referring to O and Z , we find that we can easily find a path from O to Z with only four gateways and one activity in between. In contrast to that, the relationship between Z and AA is much more difficult to assess. To this end, we have to inspect the model in a backward mode from the two activities up to the gateway from which both paths to Z and AA originate. Here, this is the split gateway (labeled 36) in the very left part of the model. If nodes 36, 39 and 50 were exclusive choice gateways (XOR-splits), the answer would be no . As we ob-serve an AND-split, the correct answer is yes . The challenge in finding this solution is that a considerably larger share of the mode l has to be inspected as for the task on O and Z . From the AND-split to AA , we have to traverse the model via A , C , H , and K ; better results for the second question introduces in the previous sub-section. The generalized. 
In line with this observation, we formalize a notion of Relevant Region as a poten-tial factor of model comprehension. This formalization is based on the definition of a process model, its notion of path, and the notion of a dominator (cf. [13]). A process model is defined as a tuple  X  X , X , X  X  X  X   X  X  with N being the set of nodes and the arcs defined as  X  X   X  X   X  . The set of nodes is partitioned into mutually disjoint sets as  X  X   X   X , X   X   X  X  X  X  referring to start and end events, activities and gateways. The function  X  X  X  X , X  X , X  X  X  X  X   X : X  maps gateways to corresponding label types AND, OR, and XOR. A path  X   X   X   X   X  is a non-empty sequence of nodes  X   X   X ,...,  X  such y , if and only if for all paths from the start event  X   X  X  it holds that  X  X   X  X  X  X  X   X  . The dominating node  X  X  X   X   X , X   X   X   X  is that node that is both a dominator to x and y , and which has no other dominators on its paths to x and y (cf. the notion of start join single-entry node of a fragment is a dominating node for all pairs of nodes within this fragment. 
Based on these notions, we can establish the definition of a Relevant Region  X  X   X  X  X , X , X  X  X  X  such that Consider the example of Fig. 1 where each node is numbered for easy reference. Giv-en a comprehension task as Can R and W show up in the same case? (yes/no) , we observe that R and W share a dominating node  X  X   X  X , X  X  X  X  X   X  X  , which is the AND-gateway directly before them. Accordingly,  X  X   X   X  X , X , X   X   X   X   X , X , X   X  X   X  . By inspecting the elements and connections in th is area, we find the correct answer is yes . 
The significance of this notion of a Relevant Region can be investigated from two angles. First, with a focus on process model comprehension results, it can be checked in comprehension performance. Second, it can be approached by mapping the comprehension process onto the process model. The latter can be facilitated using eye-tracking. Indeed, eye-tracking has been recently proposed as a technique for investigating the cognitive process of model comprehension on a more fine-granular level as compared to existing approaches which consider task results only [15], [16]. depicted in the model. Looking at model elem ents is highly correlated with the indi-vidual X  X  thinking process [17]. Eye-tracking equipment helps to create a record of the elements the subject X  X  eyes fixated upon. Other interesting data extracted using this method is the fixation sequence and fixation times of the different elements. Fixation means that a person X  X  eyes are aimed at some object, therefore he investigates it. Fixa-tion sequence is the order of the items a person looks at. Fixation time is the period of time over which the subject X  X  eyes are directed at the object. In our eye-tracking expe-riment, subjects look at process models. Therefore, a fixation occurs when the subject his brain to capture the meaning of the visual stimulus [18], [19], [20]. The eye-tracking software calculates fixation time as the length of time the eye velocity was below both the saccade velocity criterion an d the drift distance criterion. Saccades are fast rotations of the eyes that occur several times each second and are commanded automatically by the brain (without getting awareness) [20]. Saccades show up when the subject X  X  attention shifts from one point on the screen to another. Using recorded fixation sequences, we can define the set of elements that a subject has looked at, as the notion of a Scan Path  X  X   X  X  . This Scan Path, SP , is the set of nodes of a process model that get a fixation from the subject X  X  eyes. 
Based on both the notion of a Scan Path SP and concepts from information retriev-al, we can discuss the appropriateness of the Relevant Regions RR concept. The area of information retrieval focuses on evaluating techniques that provide a number of results from a given search space. This perspective can be directly related to our re-search problem. The standard notions of precision, recall and f-measure can be adapted accordingly [21]. Simply put, precision is the percentage of relevant items from all retrieved items while recall is the percentage of relevant retrieved items from all relevant items. The f-measure is the harmonic mean of precision and recall. Given a process model and a subject that fixates some of the model elements in order to answer a comprehension question, we can identify the corresponding Relevant Region RR. Together with the actually observed Scan Path, we get Scan Path Precision (SPP), Scan Path Recall SPR, and Scan Path f-measure (SPF): Based on these concepts, we have defined the foundations to empirically test the sig-nificance of the notion of a Relevant Region. This section introduces the experimental setup. We first define the researched hypotheses, and then give an overview of the methodology employed to validate them. At the core of our approach lays the notion of Relevant Region introduced in the previous section and the experiments involving tracking the subject X  X  fixations on (looks at) the elements of the model (eye-tracking). H1 : The Relevant Region elements are fixated a longer time than other model ele-ments by the subjects that provided the corr ect answer to the comprehension question; H2 : More elements of the Relevant Region are fixated than other model elements by the subjects that provided the correct answer to the comprehension question; H3 : The higher the percentage of time spent fixating the Relevant Region elements, the more likely is a correct answer; H4 : The higher the share of Relevant Region elements a person fixates (scan-path recall and/or f-measure), the more likely is a correct answer. In order to prove our hypotheses we follow different approaches. First, we gather experimental eye-tracking data from live experiments. Then, for H1 and H2 we do a statistical correlation analysis of the data. For H3 and H4, we model a logistic regres-sion for estimating the probability of giving the (binary) correct answer. As a follow-up to H3 and H4 we try to discover a model that will predict the probability of provid-ing a correct answer to a comprehension question. 3.1 Participants Previous research showed expertise plays an important role in process model compre-hension [4]. Therefore, we decided to use only experts as subjects for our experi-ments. There were several experimental sessions stretched between August 2012 and November 2012 with a total of 26 process model experts recruited both from acade-mia and industry. Academia experts included in those sessions were selected from the Babes-Bolyai University in Cluj-Napoca (UBB), the Wirtschaftsuniversit X t Wien (WU) and from the Technical University in Eindhoven (TUE). Sessions including industry experts were organized during the 4th International Workshop on BPMN held in Vienna. This selection of subjects covers multiple backgrounds: subjects from UBB and from industry have no focus on a specific process modeling notation, sub-jects from WU are more familiar with BPMN while subjects from TUE use mainly Petri Nets. Given the expertise level, each subject was (highly) qualified to answer the comprehension questions. To evaluate the level of expertise, each subject was asked to fill-in a self-evaluation questionnaire as the one used in [4]. 
The evaluated variables are: Models read in the last year (MR) which ranges from 0 to maximum 100, Models created in the last year (MC), Familiarity with under-standing and using BPMN (FAM) which ranges from 1 (very much) to 7 (none), Modeling years (MY) and the number of months since using BPMN (MBPMN). The synthetic data giving the lowest value/highest value/mean/standard_deviation is introduced in Table 1. 
As can be seen from Table 1, the total level of expertise is high given that, the av-erage number of months the subjects used BPMN is 36, they are familiar with the notation (2.6 on a scale from 1 to 7) and have read an average of 61 process models. Variable Cluj-Napoca Vienna Eindhoven Total 3.2 Measured Variables The independent variables measured based on the eye-tracking output data are divided according to the two inve stigated dimensions:  X  the number of elements in the Relevant Region fixated by the subject. To correlate the number of RR elements fixated with the total number of elements fixated we calculate scan-path precision (SPP), scan-path recall (SPR), scan-path F-measure (SPF), and scan-path F2-measure (SPF2);  X  the fraction of the model investigation time spent fixating each Relevant Region element (Time In Region  X  TIR). This variable is calculated as the time spent fixating one model element in RR over the total time spent fixating all model elements. 
The dependent variable is Outcome. It is a binary variable that shows if the subject provided the correct (1) or the incorrect answer (0) to the comprehension question. 3.3 Experiment Implementation Details The experiment was performed in seven steps as follows: a) Hardware set-up . For experimenting we used a fixed-head eye-tracking system produced by Arrington Research (http://www.arringtonresearch.com/headfixed.html). Some pictures taken during the experiments that show the hardware setup are available at: http://granturi.ubbcluj.ro/decision_mining/experimente-en.html; b) Calibration . This is an essential step that influences data accuracy. Calibration means mapping eye vectors (left and right) to a position on the screen. For the experiments, we calibrated a number of 42 points to balance between high fidelity (more calibration points is better) and time (more calibration points require a longer calibration period in which the subject might become tired and/or bored). c) Calibration confirmation . This step give assurance over the calibration quality; d) Show BPMN model and ask comprehension question . Recording eye movements starts when the model is displayed on screen and a comprehension question is asked; e) Record question answer . The subject says out loud the answer to the compre-hension question. All answers are Boolean (True or False). The eye movements recording stops once the answer is given; f) Slip correction . After each question, a quick re-calibration (slip-correction) is performed. The basic idea is to compensate the subject X  X  minor head movements (e.g. while speaking out loud the answer). g) Skip to the next question . Typically, we repeated steps c) through f) for each of the six comprehension questions. In rare cases (under 10%), once a full calibration succeeded, there was a need to also repeat step b) later in the experiment. The experiment used a set of 5 models. Each has a structured and an unstructured version (the material can be downloaded from http://granturi.ubbcluj.ro/decision _mining/experimente.html). We asked a set of 6 questions covering those models (the two questions using the same model were placed first and last). All 26 subjects were given the basic treatment (2 comprehension questions from structured models and 4 from the unstructured ones). Three subjects were also given, in a different day, the alternate treatment (i.e. were asked the same questions but on the  X  X ther X  model). None of the alternate treatment subjects reported a memory effect. 3.4 Experimental Data To better understand the data outputted by the eye-tracking system we will use first a small running example. The output of the experiment is a data file as shown in Fig. 2 includes the timestamp (ATT), the elapsed time between eye movements (ADT), the X and Y coordinates of the pupil (ALX and ALY), which region of interest the eye coordinates are placed in (ARI), pupil width (APW), height (APH), the quality of the pupil detection (AQU) and how much time the eye didn X  X  move, in seconds, (AFX). The log also records events like eyes fixa ting a ROI, Fixations, Drifts and Saccades, individually for each eye (A or B). 
The data stored in the file introduced in Fig. 2 enables the post-hoc replay over the Fig. 3. It is explicitly depicting the behavior of an expert while answering the question  X  X an R and W be executed for the same case? X . 
In order to ease the analysis we make some assumptions. First, the sequence of fix-ations is not important. Second, we abstract from the count of the number of fixations for one element and use just the total time a ROI is fixated. Instead, we keep the ag-gregate value (e.g. that the user fixated ROI 23 for 1.58 seconds). In this way, we convert the log in Fig. 4A to the synthetic data in Fig. 4B. There are some risks that threat the validity of results and may limit our conclusions: -eye-tracking hardware and software imprecision . It is inherent to any device and is due to the hardware limitations (e.g. video recording speed) and/or to the algo-differences between the exact coordinate fixated by the subject and the one recorded in the log. To mitigate this risk we used models with enough distance between ele-ments and we defined ROIs slightly larger than the actual model element. -de-calibration during experiment . This is a serious risk which leads to the rejec-tion of the entire observation. We used fixed-head eye-tracking system (i.e. the user X  X  head is fixed in the chin and nose areas) but still, head movements will cause coordinate outside the screen area). To mitigate this risk we did a post-hoc visual examination of each eye-movie and rejected those that obviously been de-calibrated. The percentage of rejected observations was 10.35% of all traces (18 out of 174). -personal biological features . For most humans, one eye is dominant focusing first on the model element while the other eye lags behind. Therefore, the eyes cases in which one eye focuses on one model element while the other focuses on an adjacent one for a brief moment. To mitigate this risk we recorded both eyes indepen-dently. Then, we calculated the subject X  X  scan-path as the union of ROIs visited by both eyes. One way of examining the experimental data is to strictly evaluate the percentage of correct answers to each comprehension questio n. The share of correct answers is in the same range as for the prior experiments with the same questions without eye-we investigated an evenly distributed number of structured (e.g. model no 30, 50) and unstructured ones (e.g. 19, 29, 39). Some of the results are introduced in Table 2. As one can note, for a question we recorded a large number of incorrect answers. Correct (no.) 18 18 17 6 16 14 Incorrect (no.) 5 6 2 10 0 9 Correct (%) 78.26% 66.67% 89.47% 37.5% 100% 60.87% 
Table 3 introduces a sample of the aggregated data for the model in Fig. 1. From the total valid observations, 10 observations were set aside for validation purposes. Therefore the data file contains a numbe r of 146 observations, where each observation represents a comprehension questions answered by one subject. The data file is avail-able at: http://granturi.ubbcluj.ro/decision_mining/loguri-en.html. In Table 3, one can see that Subject 1 spent about half of his time evaluating RR elements, fixated all the RR elements (i.e. recall is 1) but the fixated RR elements were a small sub-set of all the model elements fixated (i.e. precision is 0.19). However, Subject 1 gave the cor-rect answer to the comprehension question. Subject 2 fits better our hypothesis that the correct answer was given because he spent most of his time fixating RR elements, fixated all RR elements, and just a small number of model elements outside the RR. Subject 25 contradicts our hypothesis because he gave the incorrect answer despite fixating all RR elements and spending most of his time looking at RR. 
In order to validate H1 and H2 we will use the series for the variables in the exam-ple. The sample data summary is introduced in Table 4. We first perform a simple correlation analysis of the dependent variable Outcome with the independent va-riables SPP, SPR, SPF, SPF2 and TIR. The result, introduced in Table 5, shows that there is some limited correlation between the variables. Variable F F2 SPP SPR TIR ANOVA F-ratio 28,247 29.650 17.290 21.446 17.964 ANOVA Significance P&lt;0.001 P&lt;0.001 P&lt;0.001 P&lt;0.001 P&lt;0.001 
The ANOVA test in Table 5 shows there is a significant difference in the distribu-tion of the independent variable for correct and incorrect answers. We also performed simple regression analysis (last row of Table 5) to find out if the independent va-riables are associated with the dependent variable Outcome. The ANOVA analysis, the simple correlation and the simple regression analysis in Table 6 shows there is strong evidence that the null hypothesis can be rejected for all independent variables and that, indeed, a higher number of RR elements fixated and the time spent fixating them is connected with a tendency towards giving a correct answer. 
To evaluate H3 and H4 we performed a) multivariate regression analysis; b) logistic regression to estimate the probability of the binary choice stored as the Output variable; and c) ROC curve and AUC analysis for modeling the influence of independent variables over the probability of giving the correct answer. 
Multivariate regression analysis results show that a regression model using SPP (precision) and SPR (recall) explains the outcome variable (correct answer yes/no). We should also stress that positive coefficients for SPP, SPR and TIR implies a ten-dency to increase probability of a correct answer with a larger number of RR elements examined or more time taken to examine them. This is in line with our hypothesis. However, a model involving both dimensions (SPP and/or SPR plus TIR) does not explain the outcome. Interestingly, multiple regression analysis shows the F-measure is slightly better than F2 measure in a model also involving TIR. 
The coefficients for the Nagelkerke X  X  R 2 and R 2 -adjusted coefficients comparing multiple models are introduced in Table 9 showing that a considerable share of variance is explained by the independent variables. This analysis also shows that variations in the Outcome variable are best explained by the SPP  X  SPR model. 
The logistic regression analysis (in Table 10 and Table 11) shows that giving the correct or incorrect answer to the compre hension question can be predicted by: a) Precision and Recall; and b) Recall and TIR. The other combinations of independent variables are not producing statistically relevant forecasts. 
For predicting the probability of giving the correct answer, we used the logistic regression equation based on the coefficients in Table 11. We try to provide a state-ment like  X  X or a particular combination of SPR y SPR  X  [0, 1] and TIR y TIR  X  [1, 100%], there is a z% probability of giving the correct answer to the comprehension question X . Some examples of this statement are depicted in Table 12. The results can be interpreted as the effect of the risk factors that only a part of the model elements are fixated for an insufficient time to give the correct answer to the comprehension question. 
For validating our outputs, we followed a machine learning approach using a train-ing set. We considered the SPR-TIR pairs (Table 12) to calculate the probability of a correct answer. We used as reference the 50% threshold (therefore if the prediction was a correct answer with 45% probability we expected an incorrect answer). Then, we manually evaluated the 10 observations set aside from the whole data set, along-side the actual answers given by the subjects. We calculated the prediction precision as the number of true positives over the sum of true positives and false positives. The prediction precision yielded a satisfying 70%. Therefore, we argue that our approach is generalizable and can be used to predict whether experts will provide correct an-swers to process model based comprehension questions. We have approached an actively researched field in the last few years (process model understanding) with an emerging technique for direct observation (eye-tracking). Therefore, we build on previous knowledge from both areas. Main related issues in process model understanding approaches were already presented in the first section of the paper [2], [3], [4], [5], [6], [9], [10], [11], [12], [13]. Most research in eye-tracking is focused related to the areas of psychology, medical research, marketing research and human-computer interaction [19], [20], [23]. The last two areas are linked with information systems because they focus on subjects like advertising, package design, interface design, etc. Most work in information systems is linked to web usability related issues. For the eye-tracking experimental design we used [20], and [23] as references. For eye-tracking data analysis we used [24] as a reference. 
Eye-tracking research directly applied to process modeling context is discussed in [15]. Currently, a team of researchers at the University of Innsbruck [16] focus on the process of process modeling and try to combine eye-tracking analysis with previous results on how process models are created. This is obviously approaching a different issue than our research. Somewhat connected to our current goals (but closer to our future goals) is the work-in-progress performed by the same group and introduced in [25]. The approach is to correlate the ment al effort with the accuracy of a process model related task, but the results still rely on statistics built on indirect observations. 
Eye-tracking was used before to evaluate the difference between novices and ex-perts performing some task. In [23] visualizing scan-path differences between expert and novice aircraft inspectors is used as an example, where the expert scan-path is recommended to be followed by the novices to increase their performance. In our experiments we used only experts, but this approach opens up a new implementation opportunity for our findings. model comprehension. We formally defined the notion of a Relevant Region and a Scan-Path, as well as precision and recall metrics based on both. We hypothesize those are connected with the way a subject inspects a process model, and eventually with the performance in giving correct answers. We conducted an experiment using eye-tracking equipment involving 26 expert modelers yielding data on 6 tasks for each of them. Our statistical analysis not only confirms the significance of the hypotheses, but also highlights the predictive power of defined independent variables. 
Some limitations of our research are: a) the focus on model structure understand-ing; and b) that we investigate understanding of a part of the model. To focus on structure we eliminated task labels, and it could be argued that those could play a role in model understanding. But, on one hand, correctly understanding labels is highly subjective. On the other hand, failing to understand the model structure will directly result in poor performance. To address the second limitation, we argue that  X  X ivide et impera X  strategy can be used in model understanding. Therefore same approach as in our comprehension questions can be applied first to understanding small parts of the model and later to piecing together those parts. 
In future research we aim to further investigate the process of model comprehen-sion based on eye-tracking. One direction is to investigate the notion of structuredness in more detail due to its importance for process model comprehension reported in prior research. Also, we will focus on giving a quantitative measure to the difference between novice and expert process modelers when it comes to model comprehension. Our approach can also be used to determine the influence of task (comprehension question) difficulty on the cognitive process of a process model reader. And last, but not least, given a large number of investigated subjects it should be possible to mine some cognitive model exploration patterns (a process of examining a process model) that will ensure a greater probability of understanding the model. Acknowledgement. This research was supported by Human Resources Development Operational Program through the project Transnational Network of Integrated Postdoctoral Research in the Field of Science Communication, Capacity Building (Post-doctoral School) and Scholarship Program (CommScie) POSDRU/89/1.5/S/63663. 
