 Mobile networks enable users to post on social media ser-vices (e.g., Twitter) from anywhere. The activities of mobile users involve three major entities: user, post, and location. The interaction of these entities is the key to answer ques-tions such as w ho will post a message w here and on w hat topic? In this paper, we address the problem of profiling mobile users by modeling their activities, i.e., we explore topic modeling considering the spatial and textual aspects of user posts, and predict future user locations. We propose the first ST ( S patial T opic) model to capture the correla-tion between users X  movements and between user interests and the function of locations. We employ the sparse coding technique which greatly speeds up the learning process. We perform experiments on two real life data sets from Twitter and Yelp. Through comprehensive experiments, we demon-strate that our proposed model consistently improves the average precision@1,5,10,15,20 for location recommendation by at least 50% (Twitter) and 300% (Yelp) against existing state-of-the-art recommendation algorithms and geographi-cal topic models.
 H.2 [ Database Management ]: Database Applications-Data Mining Algorithms, Design, Measurement, Experimentation Spatial Topic Model, Mobile Users, Location Recommenda-tion
With the rapid growth of mobile network users, the way users consume Web 2.0 is changing substantially. Mobile networks enable users to post on social media services (e.g., Twitter or Yelp) from anywhere. This new phenomenon led to the emergence of a new line of research to mine the behavior of social media users taking into account the spatial aspects of their engagement with online social media.
The activities of mobile users can typically be represented as follows: a user appears at a certain location (with a pair of latitude and longitude coordinates), and leaves a post (e.g., tweet or review) which is likely semantically related to the user and/or the location. These activities involve three major entities: user, post, and location. The interaction of these entities is the key to answer questions such as w ho will post a message w here and on w hat topic? In this paper, we address the problem of profiling mobile users by modeling their activities, i.e., we explore topic modeling considering the spatial and textual aspects of user posts, and predict future user locations.

Several works in the literature have addressed some of the above aspects. In recommender systems, [20, 2, 13] have proposed probabilistic matrix factorization models mining latent user and location preferences to predict user loca-tions, but they totally ignore one of the key components: user posts. Another line of works [18, 21] has focused on user posts and proposed topic models to analyze geograph-ical topics. Most recently, Hong et. al. [10] proposed a geographical topic model to capture language patterns of different regions and different users. Note that the users X  distributions over regions are assumed to be independent from each other.

We observe that user movements sometimes correlate if two users have similar lifestyle or living routine. For exam-ple, many students from New York University live in the same neighborhood near the campus, and their movement trajectories correlate to each other. They may go to the same restaurants, coffee shops and grocery stores. There-fore, we argue that considering the movements of different users independently as in [10] is not the best way, and that we can predict a user X  X  movement more accurately taking into account the movements of similar users. This idea un-derlies the paradigm of collaborative filtering.

A second observation is that user interest affects user movement not at the  X  X yntactic X  level of 2-dimensional co-ordinates but at the  X  X emantic X  level of places with a certain function. Existing spatial topic models with 2-dimensional coordinates do not distinguish the following two scenarios: 1) two users appear in the same location, like a hockey themed bar, and 2) two users appear in two different loca-tions that are adjacent to each other, where one is a hockey themed bar and the other one is a facial salon. Intuitively, mal e users who are interested in sports often go to sport bars and watch games, while female users often go to facial sa-lons. Two users in the first scenario share the same interest, while two users have totally different interests in the second scenario. As a result, without considering the fact that user movements are influenced not only by the coordinates of a location but also by its function, the predictive ability of the model will be greatly reduced.

Motivated by the above observations, this paper explores the following two questions: 1. How are user movements correlated to each other? 2. How does user interest affect user movement at the We propose a spatial topic model, called ST ( S patial T opic), that takes the correlation of users X  movements, and the correlation of user movement and user interest into ac-count. As in existing models, a post is represented as an unordered collection of words (a bag-of-words assumption) associated with user and location, which are all considered as observed random variables. Different from existing works [18, 21, 10], a location in this paper is defined as a place with a semantic functionality and with its 2D coordinates. A set of latent random variables is also defined, i.e., regions and topics are latent, and each post is assigned to a region and a topic. We assume that each location is assigned to one and only one region, and its coordinates are generated by a 2-dimensional Gaussian distribution. For example, in New York City, regions could be areas that corresponded to com-munity districts, such as Manhattan, Brooklyn, and Queens etc. Different from existing models, in order to generate a location of a post by a particular user, the model considers the user X  X  interest and the locations of  X  X imilar X  users. We develop a MCEM (Monte Carlo Expectation Maximization) method to learn the latent random variables and parameters that maximize the likelihood of the observed random vari-ables, and the sparse coding technique is used to improve the efficiency of the learning method.
 We perform experiments on two real life data sets from Twitter and Yelp. All posts (tweets and reviews) in the data sets are annotated with corresponding users and locations. We evaluate the effectiveness of our proposed model and of state-of-the-art models in terms of accuracy of location prediction, i.e., given a post and its author, we recommend top-k locations to the user.

The major contributions of this paper are as follows:
In this section, we briefly review related work. There are three lines of related work, which are geographical topic modeling, location recommendation, and user movement anal-ysis.

Geographical Topic Modeling . Topic modeling is a classic task to enable text analysis at a semantic level. A topic model assumes that each document in a given data set is associated with a topic distribution, and each topic with a word distribution. The most representative models are PLSA [9] and LDA [1]. Recently, there are many works [19, 18, 21, 10] in the area of geographical topic modeling, which detect geographical regions and topics from documents that are associated with locations.

Yin et al. [21] and Eisenstein et al. [7] propose similar models, where the coordinates in each document are drawn from a 2D Gaussian distribution and the region is drawn from a Multinomial distribution over all regions.
Recently, Hong et al. [10] propose a model, called GT (Geographical Topic), assuming that each user has a distri-bution over all regions, i.e., users tend to appear in a small subset of all regions, and each user has a distribution over all topics, i.e., users tend to have different interests on different topics. They conduct extensive experiments on a large scale Twitter data set and their model achieves better location prediction performance than existing models.

Although all the above works discover regions and ge-ographical topics, they do not consider the correlation of users X  movements. Additionally, they assume that users X  in-terests influence users X  regional preferences directly but in-fluence users X  locations only indirectly. Finally, these models ignore the functionality of locations, which greatly reduces the predictive ability of the model as will be shown in our experiments.

Location Recommendation . In the classic framework of recommender systems, we have a user-item matrix and each element in the matrix represents the user X  X  rating of that item. To put it in the context of location recommen-dation, locations can be viewed as items, and binary user item ratings can represent whether a user has visited the corresponding locations. Particularly, the user-location ma-trix can be computed by the user and location latent factors through MF (Matrix Factorization) techniques [11, 12]. Re-cent works [20, 22, 2, 13] extend PMF (Probabilistic Matrix Factorization) [16] for location recommendation by consid-ering the distance between users and locations, i.e., closer locations are recommended with higher probabilities.
The authors of [2] have proposed a MF model considering geographical influence for POI (Point-Of-Interest) recom-mendation in location-based social networks. Their model detects multiple centers for each user based on their history of locations, and each center has 2-dimensional coordinates. Motivated by the effect of geographical influence, the prob-ability of recommending a location is inversely proportional to the distance between the location and the nearest user center. Similarly, a recent work [13] has proposed GLDA (Geo Latent Dirichlet Allocation) to capture users X  location preferences by combining LDA and geographical influence.
Note that all these methods ignore the text of posts which is an essential component in our problem definition.
User Movement Analysis . Some works [8, 3, 4, 5] have been studying user movements in location-based social net-works. Since most user posts are not associated with coor-dinates, these works address the following problem: given a set of geo-tagged posts from many users, learn a model of re-gion specific words, and apply this model to predict the user location of un-tagged posts based on their content. This is different from the problem in this paper, which is to predict the location of posts by users with many geographical posts. Cheng et al. [3, 4] develop probabilistic methods to identify local words in tweets, and they predict user locations based on the local words in their tweets. Similarly, [8] proposes a Multinomial Naive Bayes model to predict the Twitter user profile X  X  location at the granularity of the city level. [5] studies the problem of modeling human mobility in so-cial networks, and one of their interesting findings is that users tend to move within a small number of regions, e.g., around their home and office. Another interesting finding is that a user X  X  movement trajectory correlates to that of their friends. Furthermore, a recent work [15] presents a prob-abilistic model incorporating social networks and achieves better performance for tweet location prediction. This type of work focuses on the impact of social networks on user movements, while we do not use social networks.
In this section, we first introduce the problem definition and then present our proposed ST ( S patial T opic) model.
On social media sites, such as Twitter or Yelp, a large number of users generate content. These user generated posts can consist of personal information, news, comments or reviews. We are in particular interested in the text and location of the posts. More precisely, we assume that a post has the following attributes: text, author, and location. An example of publicly available tweets is as follows: This tweet states that a Twitter user from San Jose, Cali-fornia compliments the coffee at a coffee shop, where  X 37.38, -121.90 X  are the latitude and longitude coordinates, and  X 0befbacea94beb06 X  is the unique label of the coffee shop.
We assume that all the documents are authored by a user from a fixed set of size U and all the words are from a fixed vocabulary of size V . We associate each user with a set of posts, and the number of posts of user u is denoted as D u . Each post is represented by a set of words (the number of its words is denoted as N u,d ), and a pair of latitude and longitude coordinates. For convenience, we consider X  X weet X ,  X  X eview X ,  X  X ost X  and  X  X ocument X  as synonyms in this paper. Formally, a document d is defined by d = { w ,u,i } , where w,u,i represents set of (index of) words, the index of user and location respectively. l i represents the coordinates of location i . A document collection D is defined as a set of documents from all users. We assume that there is a set of latent topics and a set of latent regions in the document collection D . Each document d is assigned to one of the topics z d and regions r d . We use Z and R to denote the number of topics and number of regions, respectively. A semantically coherent topic in the document collection D is associated with a probability distribution over all words in the vocabulary, and a probability distribution over all lo-cations. A region has a geographical center, and it is com-prised of a set of documents, which are coherent in topics and close to the center geographically. We assume that different users show different distributions over topics and regions. All notations described above are listed in Table 1.
Variable Interpretation w u,d, n n th word of the d t h document posted by the u th i u,d location index of the d th do cument posted by the u th l i latitude and longitude coordinates of the i th lo cation z u,d topic assignment of the d th do cument posted by the r u,d region assignment of the d th do cument posted by the Z number of topics R number of regions U number of users I number of locations D u number of documents of user u N u,d number of words in document d of user u V size of the vocabulary
Based on the above definitions, we formalize our research pro blem as follows:
Problem 1 (Spatial topic modeling). Given a doc-ument collection D , and numbers Z of topics and R of re-gions, the task is to model and extract a set of topics and a set of regions.
To address our research problem, we introduce the ST model. Figure 1 shows the graphical model of ST.

We fi rst introduce the notations of our model and listed in Table 1. Our input data, i.e., words and locations, are modeled as observed random variables, shown as shaded cir-cles in Figure 1, and we use w u,d,n and i u,d to denote them. l is a pair of latitude and longitude real values of i th l oca-tion. Similar to existing models as in [21, 10], the topic and region index of documents are considered as latent random variables, which are denoted as z u,d and r u,d respectively. Users are associated with topic and region distributions, i.e.,  X  user and  X  user , from which the topics and regions of posts are sampled. Topics are associated with word distributions  X  topic . Given the sampled topic, words are drawn from the word distribution of that topic. The background distribu-tions of words, topics, and regions are denoted as  X  0 ,  X  0 , and  X  0 . All parameters are listed in Table 2.

Variable Interpretation  X   X  u topic distribution of the u th us er  X   X  z word distribution of the z th to pic  X   X  u region distribution of the u th us er  X   X  z location distribution of the z th to pic  X  r region mean location of the r th re gion  X  r region location covariance of the r th re gion
An important change from existing models is that instead of g enerating the coordinates of posts, ST generates the in-dex of the location of posts. Another major change is that, to model the impact of user interest on user movement, ST assumes that the location depends not only on the region but also on the topic. Consequently, it adds a location dis-tribution  X  topic for each topic. Existing models assume that the 2D Gaussian distribution with center  X  and covariance  X  of the sampled region governs the choice of locations vis-ited, i.e., the closer a location to the center, the higher the probability of visiting that location, and ST has the same as-sumption. Additionally, ST assumes that another important reason why the user visits the location can be attributed to the user interests. Since locations with different functions can have very similar coordinates, this assumption is much more meaningful when considering  X  X emantic X  locations.
Particularly, users have different topic distributions, and topics have different location distributions, so that the de-pendency between user interests and user locations is trans-ferred through the topic. ST captures the correlation be-tween movements of different users, such that users who have similar movements share the same topics. Note that the top-ics serve a similar role as the latent factors in MF (Matrix Factorization). Different from the existing MF methods [2, 13], ST associates a word distribution with a topic so that it can describe the latent user and location factors. Intuitively, collaborative filtering assumes that locations A and B should both have high probabilities in location distributions of some topic(s) in our case if many users frequently co-occur in both A and B. Location A and B do not necessarily have the same functionality. However, ST further assumes that locations with high probabilities for the same topic should be cohe-sive in their functions, e.g., a topic with high probabilities for words like  X  X offee X ,  X  X ava X , and X  X ocha X  should have high probability only for coffee shops. This design enables ST to detect users with similar interests and locations with simi-lar functions, and enables ST to better deal with X  X old start X  users, i.e., users who have very few posts, since the words of their few posts are more informative than their locations.
Next, we describe the generative process of the ST model for a single document d .
For each document, the ST model generates the location and words consecutively. To generate a location, the model first samples a region from the set of regions. To generate a region r , we use a multinomial distribution as follows: region distribution of user u . To simplify the notations, we 2). This approach employs the sparse coding technique in-troduced in the SAGE (Sparse Additive Generative) model [6]. The major advantage of SAGE is that it does not require additional latent X  X witching X  X ariables when the model needs to take multiple factors into account. For example, in order to model topics, based on the background word distribution, for each topic SAGE models the difference in log-frequencies from the background word distribution instead of the log-frequencies themselves.

Each location i is drawn depending on its corresponding region r and corresponding topic z . Given the sampled topic z and sampled region r , ST draws the location i u,d as follows: where p ( i |  X  0 +  X  topic z ) =  X  z,i is shown in Equation 6, and p ( l i |  X  r ,  X  r ) = N ( l i | r, X ,  X ), which is the PDF of the Mul-tivariate Gaussian distribution. This is the product of the probability of drawing the coordinates of the location from the 2D Gaussian distribution  X  r ,  X  r of that region, and the probability of drawing the index of the location from the location distribution  X  topic z of that topic.

Similarly, for generating the topic and word index, the model uses a multinomial distribution considering the back-ground and user topic distributions together, and the back-ground and topic word distributions together, respectively as follows: are shown in Equation 6. p ( z , r , w , i |  X ) = p ( z |  X  0 ,  X  user )  X  p ( r |  X  )  X  p ( i | r , z , X ,  X  , X  0 , X  topic )  X  Q  X  , X 
Our goal is to learn parameters that maximize the marginal log-likelihood of the observed random variables i , w . The marginalization is performed with respect to the latent ran-dom variables z , r , and it is hard to be maximized directly. Therefore, we apply the MCEM (Monte Carlo Expectation Maximization) algorithm to maximize the complete data likelihood p ( z , r , w , i |  X ) in Equation 5 (see Figure 2), where
According to the MCEM method, we sample the latent variables r , z in the E step and maximize the parameters  X  in the M step. To sample a single variable r u,d given all other variables fixed, we use Equation 7. After r is sampled, we sample z u,d similarly according to Equation 8. p ( r u,d | z , r  X  u ,d , w , i ,  X ) p ( z u,d | z  X  u,d , r , w , i ,  X ) Figure 3: The sampling formulas for latent variables r,z in the ST model
In the M step, fixing all the latent variables r , z that are sampled in the E step, we maximize the log likelihood of Equation 5 with respect to the parameters  X . For variables  X  and  X , to obtain the maximum likelihood estimate, we take the derivative of its log likelihood with respect to  X  and  X  r , and set it to zero. Only one term in Equation 5 contains  X  r , so we use Equation 9 to update  X  r , where I ( . ) is an identity function, i.e. one where r u,d equals to r and zero otherwise, and d ( r ) represents the number of documents assigned to region r .  X  r denotes the mean coordinates of locations of the documents assigned to region r in the E step. We use Equation 10 to update the parameter  X  r .  X 
To update the other parameters, we use the gradient de-scent learning algorithm PSSG (Projected Scaled Sub-Gradient) [17], which is designed to solve optimization problems with L1 regularization on the parameters. More importantly, PSSG is scalable because it uses the quasi-Newton strategy with line search that is robust to common functions. Ac-cording to the limited-memory BFGS [14] updates for the quasi-Newton method, the partial derivative functions of the 11 and 12, where d ( u,r ) represents the number of documents assigned to region r by user u , and d ( u ) represents the num-ber of documents by user u .
Similarly, we get derivative functions for the remaining parameters, which are omitted because of the page limit.
The ST model can be employed for location recommenda-tion as follows. Given a document with a user, our task is to recommend top-k  X  X ew  X  locations, i.e., the locations that the user has not visited in the training data set, which that user will visit. More precisely, given the words and author of a document d , the probability that author u visits location i is computed as in Equation 13: p ( i | w ,  X )  X  We rank the locations in descending order of p ( i | w ,  X ).
In this section, we experimentally evaluate the effective-ness of the ST (Spatial Topic) model, and we compare it against some baseline methods, one of the state-of-the-art location recommendation methods [13], and one of the state-of-the-art geographical topic models [10]. We report our experimental results on Twitter and Yelp data sets, using the top-k average precision of location recommendation for measuring the quality.
We report our experimental results on a Twitter data set resentative city in the US: NYC (New York City), where all tweets contain a location label and geographical coordi-nates. To determine the coordinates of the location, we use the mean of the coordinates of all tweets associated with a location. Hence each location corresponds to a unique mean coordinate, and each tweet of that location has the same coordinates. Another data set is from Yelp, and it is pub-data set, each review has a location (being reviewed) that is associated with a unique pair of latitude and longitude coordinates. Note that Twitter users often check in at the same location multiple times, while Yelp users write reviews for a location only once.

In the pre-processing steps, texts are processed by tok-enizing on whitespace and punctuations, while we remove the URLs starting with  X  X ttp X  and user names starting with  X  X  X . Then we remove all texts with non-latin characters, followed by removing stop words, and the words with occur-rences less than 100. To reduce noise, we remove both users and locations with less than 10 posts. Some statistics about the data sets are presented in Table 3.
 Table 3: Statistics of data sets from New York City on Twitter and Phoenix on Yelp.
Note that our data sets are much larger than the ones use d in [13]. Another related work [10] uses data sets from all over the world, while our data sets are at the city level. From this point of view, the size of these two data sets is comparable or larger than the ones in [10].
In our data sets, we randomly select 70% of observed data for each user as the training data, and the remaining 30% as the test data. We focus on the task of location recommen-dation for users based on each document, which is by far the most commonly used performance measure for spatial topic model in the literature [20, 2, 13]. In particular, we train models in the training data set, and recommend the locations based on posts by users in the test data set.
Evaluation Metric . Precision@k (top-k average preci-sion) is used to evaluate the methods as follows. The top-k precision for a test post is 1 k if i ts location is among the top-k recommendations, and zero otherwise. The precision@k is the average top-k precision over all test posts.

Comparison Partners . In our experiments, we evalu-ate the following comparison partners, which all model (can predict) either the coordinates or index of locations: 2 ht t ps://www.yelp.com/dataset challenge/ Note that there are other existing models [19, 18, 21] pro-posed for geographical topic modeling. We do not compare against them because the GT model proposed in [10] is a generalization of the existing models, and it performs bet-ter than the existing models in terms of location prediction in the experiments of [10]. We do not compare against [2], since it is similar to GLDA, which is the most recent work [13] on location recommendation.
For location recommendation, Figure 4(a) and 4(b) show the precision@1,5,10,15,20 results of the comparison part-ners in the Twitter and Yelp data sets. Note that the num-ber of topics and regions is set to 30 and 20. We observe that our ST model consistently and drastically outperforms all other models on both data sets. Compared to the state-of-the-art methods, GLDA and GT, in the areas of recom-mender systems and geographical topic modeling, ST im-proves the precision@20 by 50% (Twitter) and 300% (Yelp), and the gain is even higher for smaller values of k. This indi-cates that modeling the user interests and the correlation of user movements can help improve the accuracy of location recommendation.

We also observe that the precision difference between ST and other models on Yelp is much larger than on Twitter. We argue that this is because 1) the posts on Yelp are much longer than on Twitter; 2) the words used on Yelp are more formal than on Twitter. As a result, it is easier to capture the user interests on Yelp than on Twitter.

We further analyze the contributions of different compo-nents in ST, by comparing the performance of ST and its simplified versions: ST loc , ST coo , and ST loc + coo . We observe that modeling the index (semantics) of locations in ST loc much more precise than modeling the coordinates of loca-tions in ST coo . Comparing ST and ST loc + coo , we see that the user interests expressed in the posts indeed enable more ac-curate location recommendation. Furthermore, we observe that ST loc + coo clearly outperforms ST coo , demonstrating the contribution of exploiting the correlation of user movements. set to 30.

To analyze the impact of the input parameters, we show the precision@10 of the comparison partners for different numbers of regions (see Figure 5(a) and 5(b)) and topics (see Figure 6(a) and 6(b)). The results for precision@1,5,15,20 are similar to the results for precision@10. We observe that ST consistently outperforms the other comparison partners for all number of regions and topics. Furthermore, as the number of regions increases, the precision@10 of ST and GT increases and reaches a peak at first, and it plateaus when the number of regions reaches 10 or 20. Similarly, as the number of topics increases, the precision of ST increases. Some models, such as PMF , GLDA and ST loc , do not take the number of regions as their input, so that their precision is constant in Figure 5. Overall, the results of ST are relatively robust to the choice of the input parameters.
In this paper, we address the problem of spatial topic modeling in online social media, such as Twitter and Yelp, for user-generated content with location. Previous work has explored topic models and recommendation algorithms that model either user and location, or user and post, but they do not consider all of them together. We propose the first spatial model to capture spatial and textual aspects of posts, as well as user profiles in a single topic model, called Spa-tial Topic (ST) model. ST exploits the interdependencies between user movements, and between user interests and user movements. More specifically, ST is based on the intu-ition that 1) users X  movements correlate with each other; 2) users X  interests affect the movements of users. We argue that taking the correlation of users X  movements, and the correla-tion of user movement and user interest into account enables a more accurate discovery of relevant regions and topics. We present the graphical model of ST and a corresponding method of parameter learning. We perform an experimen-tal evaluation on Twitter and Yelp data sets from New York City and Phoenix. We compare ST against a state-of-the-art geographical topic model and a state-of-the-art recommen-dation method in terms of location recommendation. Our set to 20. experiments demonstrate drastically improved performance in location recommendation.

An interesting direction for future work is to integrate other aspects that may impact user locations, i.e. ratings and time, into the spatial topic model. Open questions are in particular how ratings of locations attract users, as well as if and how time (hour, day, week, year) influences user locations. [1] D. M. Blei, A. Ng, and M. Jordan. Latent dirichlet [2] C. Cheng, H. Yang, I. King, and M. R. Lyu. Fused [3] Z. Cheng, J. Caverlee, and K. Lee. You are where you [4] Z. Cheng, J. Caverlee, K. Lee, and D. Z. Sui. [5] E. Cho, S. A. Myers, and J. Leskovec. Friendship and [6] J. Eisenstein, A. Ahmed, and E. P. Xing. Sparse [7] J. Eisenstein, B. O X  X onnor, N. A. Smith, and E. P. [8] B. Hecht, L. Hong, B. Suh, and E. H. Chi. Tweets [9] T. Hofmann. Probilistic latent semantic analysis. In [10] L. Hong, A. Ahmed, S. Gurumurthy, A. J. Smola, and [11] Y. Koren. Factorization meets the neighborhood: a [12] Y. Koren, R. Bell, and C. Volinsky. Matrix [13] T. Kurashima, T. Iwata, T. Hoshide, N. Takaya, and [14] D. C. Liu, J. Nocedal, D. C. Liu, and J. Nocedal. On [15] A. Sadilek, H. Kautz, and J. P. Bigham. Finding your [16] R. Salakhutdinov and M. Andriy. Probabilistic matrix [17] M. Schmidt, A. Niculescu-Mizil, and K. Murphy. [18] S. Sizov. Geofolk: latent spatial semantics in web 2.0 [19] C. Wang, J. Wang, X. Xie, and W.-Y. Ma. Mining [20] M. Ye, P. Yin, and W.-C. Lee. Location [21] Z. Yin, L. Cao, J. Han, C. Zhai, and T. Huang. [22] V. W. Zheng, Y. Zheng, X. Xie, and Q. Yang.

