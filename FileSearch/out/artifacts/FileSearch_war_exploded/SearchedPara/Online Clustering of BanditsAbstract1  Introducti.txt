 DiSTA, University of Insubria, Italy DiSTA, University of Insubria, Italy Amazon Development Center Germany, Germany (Work done when the author was PhD student at Univeristy of Mi lan) Presenting personalized content to users is nowdays a cru-cial functionality for many online recommendation ser-vices. Due to the ever-changing set of available options, these services have to exhibit strong adaptation capabil-ities when trying to match users X  preferences. Coarsely speaking, the underlying systems repeatedly learn a map-ping between available content and users, the mapping be-ing based on context information (that is, sets of features) which is typically extracted from both users and contents. The need to focus on content that raises the users X  inter-est, combined with the need of exploring new content so as to globally improve users X  experience, generates a well-known exploration-exploitation dilemma, which is com-monly formalized as a multi-armed bandit problem (e.g., ( Lai &amp; Robbins , 1985 ; Auer et al. , 2001 ; Audibert et al. , 2009 ; Caron et al. , 2012 )). In particular, the contextual bandit methods (e.g., ( Auer , 2002 ; Langford &amp; Zhang , 2007 ; Li et al. , 2010 ; Chu et al. , 2011 ; Bogers , 2010 ; Abbasi-Yadkori et al. , 2011 ; Crammer &amp; Gentile , 2011 ; Krause &amp; Ong , 2011 ; Seldin et al. , 2011 ; Yue et al. , 2012 ; Djolonga et al. , 2013 ), and references therein) have rapidly become a reference algorithmic technique for implement-ing adaptive recommender systems.
 Within the above scenarios, the widespread adoption of online social networks, where users are engaged in technology-mediated social interactions (making product endorsement and word-of-mouth advertising a common practice), raises further challenges and opportunities to content recommendation systems: On one hand, because of the mutual influence among friends, acquaintances, busi-ness partners, etc., users having strong ties are more likel y to exhibit similar interests, and therefore similar behavi or. On the other hand, the nature and scale of such interactions calls for adaptive algorithmic solutions which are also com -putationally affordable.
 Incorporating social components into bandit algorithms ca n lead to a dramatic increase in the quality of recommen-dations. For instance, we may want to serve content to a group of users by taking advantage of an underlying net-work of social relationships among them. These social rela-tionships can either be explicitly encoded in a graph, where adjacent nodes/users are deemed similar to one another, or implicitly contained in the data, and given as the outcome of an inference process that recognizes similarities acros s users based on their past behavior. Examples of the first approach are the recent works ( Buccapatnam et al. , 2013 ; Delporte et al. , 2013 ; Cesa-Bianchi et al. , 2013 ), where a social network structure over the users is assumed to be given that reflects actual interest similarities among users  X  see also ( Caron &amp; Bhagat , 2013 ; Valko et al. , 2014 ) for recent usage of social information to tackle the so-called  X  X old-start X  problem. Examples of the second approach are the more traditional collaborative-filtering (e.g., ( Schafer et al. , 1999 )), content-based filtering, and hybrid approaches (e.g. ( Burke , 2005 )).
 Both approaches have important drawbacks hindering their practical deployment. One obvious drawback of the  X  X x-plicit network X  approach is that the social network infor-mation may be misleading (see, e.g., the experimental ev-idence reported by ( Delporte et al. , 2013 )), or simply un-available. Moreover, even in the case when this information is indeed available and useful, the algorithmic strategies to implement the needed feedback sharing mechanisms might lead to severe scaling issues ( Cesa-Bianchi et al. , 2013 ), es-pecially when the number of targeted users is large. A stan-dard drawback of the  X  X mplicit network X  approach of tra-ditional recommender systems is that in many practically relevant scenarios (e.g., web-based), content universe an d popularity often undergo dramatic changes, making these approaches difficult to apply.
 In such settings, most notably in the relevant case when the involved users are many, it is often possible to iden-tify a few subgroups or communities within which users share similar interests ( Rashid et al. , 2006 ; Buscher et al. , 2012 ), thereby greatly facilitating the targeting of users by means of group recommendations. Hence the system need not learn a different model for each user of the service, but just a single model for each group.
 In this paper, we carry out 1 a theoretical and experimen-tal investigation of adaptive clustering algorithms for li near (contextual) bandits under the assumption that we have to serve content to a set of n users organized into m &lt;&lt; n groups (or clusters ) such that users within each group tend to provide similar feedback to content recommendations. We give a O ( stochastically linear setting for payoffs where, importan tly, the hidden constants in the big-oh depend on m , rather than n , as well as on the geometry of the user models within the different clusters. The main idea of our algorithm is to use confidence balls of the users X  models to both esti-mate user similarity, and to share feedback across (deemed similar) users. The algorithm adaptively interpolates be-tween the case when we have a single instance of a contex-tual bandit algorithm making the same predictions for all users and the case when we have n -many instances provid-ing fully personalized recommendations. We show that our algorithm can be implemented efficiently (the large n sce-nario being of special concern here) by means of off-the-shelf data-structures relying on random graphs. Finally, w e test our algorithm on medium-size synthetic and real-world datasets, often reporting a significant increase in predict ion performance over known state-of-the-art methods for ban-dit problems. We assume the user behavior similarity is encoded as an unknown clustering of the users. Specifically, let V = { 1 , . . . , n } represent the set of n users. Then V can be par-titioned into a small number m of clusters V 1 , V 2 , . . . , V with m &lt;&lt; n , such that users lying in the same cluster share similar behavior and users lying in different cluster s have different behavior. The actual partition of V (includ-ing the number of clusters m ) and the common user behav-ior within each cluster are unknown to the learner, and have to be inferred on the fly.
 Learning proceeds in a sequential fashion: At each round t = 1 , 2 , . . . , the learner receives a user index i t  X  V together with a set of context vectors C i t = { x t, 1 , x t, 2 , . . . , x t,c t }  X  R d . The learner then selects some  X  x t = x t,k t  X  C i t to recommend to user i t , and ob-serves some payoff a t  X  R , which is a function of both i and the recommended  X  x t . The following assumptions are made on how index i t , set C i t , and payoff a t are gener-ated in round t . Index i t represents the user to be served by the system, and we assume i t is selected uniformly at random 2 from V . Once i t is selected, the number of con-text vectors c t in C i t is generated arbitrarily as a function of past indices i 1 , . . . , i t  X  1 , payoffs a 1 , . . . , a C is generated i.i.d. (conditioned on i t , c t and all past indices i , . . . , i t  X  1 , payoffs a 1 , . . . , a t  X  1 , and sets C from a random process on the surface of the unit sphere, whose process matrix E [ XX  X  ] is full rank, with mini-mal eigenvalue  X  &gt; 0 . Further assumptions on the pro-cess matrix E [ XX  X  ] are made later on. Finally, payoffs are generated by noisy versions of unknown linear func-tions of the context vectors. That is, we assume each clus-ter V j , j = 1 , . . . , m , hosts an unknown parameter vector u j  X  R d which is common to each user i  X  V j . Then the payoff value a i ( x ) associated with user i and context vector x  X  R d is given by the random variable where j ( i )  X  { 1 , 2 , . . . , m } is the index of the clus-ter that node i belongs to, and  X  j ( i ) ( x ) is a condition-ally zero-mean and bounded variance noise term. Specif-ically, denoting by E t [  X  ] the conditional expectation that for any fixed j  X  X  1 , . . . , m } and x  X  R d , the variable  X  ( x ) is such that E t [  X  j ( x ) | x ] = 0 and V t  X  j ( x ) | x  X   X  , where V t [  X  ] is a shorthand for the conditional vari-ance V  X  ( i 1 , C i variable at argument. So we clearly have E t [ a i ( x ) | x ] = u expected payoff observed at user i for context vector x . In the special case when the noise  X  j ( i ) ( x ) is a bounded random variable taking values in the range [  X  1 , 1] , this im-plies  X  2  X  1 . We will make throughout the assumption that a i ( x )  X  [  X  1 , 1] for all i  X  V and x . Notice that this implies  X  1  X  u  X  j ( i ) x  X  1 for all i  X  V and x . Finally, we assume well-separatedness among the clusters, in that r of the learner at time t as We are aimed at bounding with high probability (over the  X  bound we would like to obtain (we call it the reference bound) is one where the clustering structure of V (i.e., the partition of V into V 1 , . . . , V m ) is known to the algo-rithm ahead of time, and we simply view each one of the m clusters as an independent bandit problem. In this case, a standard contextual bandit analysis ( Auer , 2002 ; Chu et al. , 2011 ; Abbasi-Yadkori et al. , 2011 ) shows that, as T grows large, the cumulative regret high probability as 3 For simplicity, we shall assume that || u j || = 1 for all j = 1 , . . . , m . Now, a more careful analysis exploiting our assumption about the randomness of i t (see the sup-plementary material) reveals that one can replace the term contributed by each bandit j by a term of the form  X  erence bound becomes Observe the dependence of this bound on the size of clus-ters V j . The worst-case scenario is when we have m clus-ters of the same size n m , resulting in the bound At the other extreme lies the easy case when we have a single big cluster and many small ones. For instance, | V 1 | = n  X  m + 1 , and | V 2 | = | V 3 | = . . . | V m | = 1 , for m &lt;&lt; n , gives A relevant geometric parameter of the set of u j is the sum of distances SD ( u j ) of a given vector u j w.r.t. the set of vectors u 1 , . . . , u m , which we define as SD ( u j P  X  =1 || u j  X  u  X  || . If it is known that SD ( u j ) is small for all j , one can modify the abovementioned independent bandit algorithm, by letting the bandits share signals, as i s done, e.g., in ( Cesa-Bianchi et al. , 2013 ). This allows one to exploit the vicinity of the u j vectors, and roughly replace 1+ mutual distances || u j  X  u j  X  || among cluster vectors. How-ever, this improvement is obtained at the cost of a substan-tial increase of running time ( Cesa-Bianchi et al. , 2013 ). In our analysis (Theorem 1 in Section 3 ), we would like to leverage both the geometry of the clusters, as encoded by vectors u j , and the relative size | V j | of the clusters, with no prior knowledge of m (or  X  ), and without too much extra computational burden. Our algorithm, called Cluster of Bandits (CLUB), is de-scribed in Figure 1 . In order to describe the algorithm we find it convenient to re-parameterize the problem de-scribed in Section 2 , and introduce n parameter vectors u , u 2 , . . . , u n , one per node, where nodes within the same cluster V j share the same vector. An illustrative example is given in Figure 2 .
 The algorithm maintains at time t an estimate w i,t for vec-tor u i associated with user i  X  V . Vectors w i,t are up-dated based on the payoff signals, similar to a standard linear bandit algorithm (e.g., ( Chu et al. , 2011 )) operating on the context vectors contained in C i t . Every user i in V hosts a linear bandit algorithm like the one described in ( Cesa-Bianchi et al. , 2013 ). One can see that the pro-totype vector w i,t is the result of a standard linear least-squares approximation to the corresponding unknown pa-rameter vector u i . In particular, w i,t  X  1 is defined through the inverse correlation matrix M  X  1 i,t  X  1 , and the additively-updated vector b i,t  X  1 . Matrices M i,t are initialized to the d  X  d identity matrix, and vectors b i,t are initialized to the d -dimensional zero vector. In addition, the algorithm maintains at time t an undirected graph G t = ( V, E t ) whose nodes are precisely the users in V . The algo-rithm starts off from the complete graph, and progressively erases edges based on the evolution of vectors w i,t . The graph is intended to encode the current partition of V by means of the connected components of G t . We denote by  X  V nected components of G t . Initially, we have m 1 = 1 and  X  V 1 , 1 = V . The clusters called the current clusters) are indeed meant to estimate the the underlying or true clusters.
 At each time t = 1 , 2 , . . . , the algorithm receives the index i of the user to serve, and the associated context vectors x t, 1 , . . . , x t,c t (the set C i t ), and must select one among them. In doing so, the algorithm first determines which cluster (among  X  V 1 , 1 ,  X  V 2 ,t , . . . ,  X  V m t ,t ) node i call this cluster  X  V b j tor  X  w b j and computing the least squares approximation as if all nodes i  X   X  V b j vector  X  w b j ticular, The quantity CB b j dence bound in the approximation of  X  w b j combination of vectors u i , i  X   X  V b j tary material for details.
 Once this selection is done and the associated payoff a t is observed, the algorithm uses the selected vector  X  x t updating M i t ,t  X  1 to M i t ,t via a rank-one adjustment, and for turning vector b i t ,t  X  1 to b i t ,t via an additive update whose learning rate is precisely a t . Notice that the up-date is only performed at node i t , since for all other i 6 = i we have w i,t = w i,t  X  1 . However, this update at i t will also implicitly update the aggregate weight vector  X  w b j associated with cluster  X  V b j pen to belong to in the next round. Finally, the cluster structure is possibly modified. At this point CLUB com-pares, for all existing edges ( i t ,  X  )  X  E t , the distance || w i nificantly large (and w i t ,t  X  1 and w  X ,t  X  1 are good approx-imations to the respective underlying vectors u i t and u then this is a good indication that u i t 6 = u  X  (i.e., that node i and node  X  cannot belong to the same true cluster), so that edge ( i t ,  X  ) gets deleted. The new graph G t +1 , and the in-duced partitioning clusters  X  V 1 ,t +1 ,  X  V 2 ,t +1 , . . . , are then computed, and a new round begins. 3.1. Implementation In implementing the algorithm in Figure 1 , the reader should bear in mind that we are expecting n (the num-ber of users) to be quite large, d (the number of features of each item) to be relatively small, and m (the number of true clusters) to be very small compared to n . With this in mind, the algorithm can be implemented by stor-ing a least-squares estimator w i,t  X  1 at each node i  X  V , an aggregate least squares estimator  X  w b j which is able to perform decremental dynamic connectiv-ity. Fast implementations of such data-structures are thos e studied by ( Thorup , 1997 ; Kapron et al. , 2013 ) (see also the research thread referenced therein). One can show (see the supplementary material) that in T rounds we have an overall (expected) running time
O T d 2 + Notice that the above is n  X  poly (log n ) , if so is | E addition, if T is large compared to n and d , the average running time per round becomes O ( d 2 + d  X  poly (log n )) . As for memory requirements, this implementation takes O ( n d 2 + m d 2 + | E 1 | ) = O ( n d 2 + | E 1 | ) . Again, this is n  X  poly (log n ) if so is | E 1 | .
 3.2. Regret Analysis Our analysis relies on the high probability analysis con-tained in ( Abbasi-Yadkori et al. , 2011 ) (Theorems 1 and 2 therein). The analysis (Theorem 1 below) is carried out in the case when the initial graph G 1 is the complete graph. However, if the true clusters are sufficiently large, then we can show (see Remark 4 ) that a formal statement can be made even if we start off from sparser random graphs, with substantial time and memory savings.
 The analysis actually refers to a version of the algo-rithm where the confidence bound functions CB j,t  X  1 (  X  ) and f CB i,t  X  1 in Figure 1 are replaced by their  X  X heoreti-which are defined as follows. Set for brevity A  X  ( T,  X  )= where ( x ) + = max { x, 0 } , x  X  R . Then, for j = 1 , . . . , m t , being | X | the determinant of the matrix at argument, and, for i  X  V , Recall the difference between true clusters V 1 , . . . , V rithm at time t . Consistent with this difference, we let G = ( V, E ) be the true underlying graph, made up of the m disjoint cliques over the sets of nodes V 1 , . . . , V m G t = ( V, E t ) be the one kept by the algorithm  X  see again Figure 2 for an illustration of how the algorithm works. The following is the main theoretical result of this paper, 5 additional conditions are needed on the process X generat-ing the context vectors.
 Theorem 1. Let the CLUB algorithm of Figure 1 be run on the initial complete graph G 1 = ( V, E 1 ) , whose nodes V = { 1 , . . . , n } can be partitioned into m clusters V , . . . , V m where, for each j = 1 , . . . , m , nodes within cluster V j host the same vector u j , with || u j || = 1 for j = 1 , . . . , m , and || u j  X  u j  X  ||  X   X  &gt; 0 for any j 6 = j Denote by v j = | V j | the cardinality of cluster V j . Let the j,t (  X  ) function in Figure 1 be replaced by the TCB j,t function defined in ( 3 ), and f CB i,t be replaced by g TCB fined in ( 4 ). In both TCB j,t and g TCB i,t , let  X  therein be replaced by  X / 10 . 5 . Let, at each round t , context vec-ditioned on i t , c t and all past indices i 1 , . . . , i offs a 1 , . . . , a t  X  1 , and sets C i 1 , . . . , C i process X such that || X || = 1 , E [ XX  X  ] is full rank, with minimal eigenvalue  X  &gt; 0 . Moreover, for any fixed unit vector z  X  R d , let the random variable ( z  X  X ) 2 be (conditionally) sub-Gaussian with variance parameter  X  Then with probability at least 1  X   X  the cumulative regret satisfies as T grows large. In the above, the e O -notation hides log(1 / X  ) , log m , log n , and log T factors.
 Remark 1. A close look at the cumulative regret bound presented in Theorem 1 reveals that this bound is made up of three main terms: The first term is of the form This term is constant with T , and essentially accounts for the transient regime due to the convergence of the minimal eigenvalues of  X  M j,t and M i,t to the corresponding minimal eigenvalue  X  of E [ XX  X  ] . The second term is of the form This term is again constant with T , but it depends through E [ SD ( u i t )] on the geometric properties of the set of u well as on the way such u j interact with the cluster sizes v . Specifically, Hence this term is small if, say, among the m clusters, a few of them together cover almost all nodes in V (this is a typical situation in practice) and, in addition, the corre -sponding u j are close to one another. This term accounts for the hardness of learning the true underlying clustering through edge pruning. We also have an inverse dependence on  X  2 , which is likely due to an artifact of our analysis. Re-call that  X  is not known to our algorithm. Finally, the third term is the one characterizing the asymptotic behavior of our algorithm as T  X   X  , its form being just ( 5 ). It is in-structive to compare this term to the reference bound ( 1 ) obtained by assuming prior knowledge of the cluster struc-ture. Broadly speaking, ( 5 ) has an extra replaces a factor Remark 2. The reader should observe that a similar al-gorithm as CLUB can be designed that starts off from the empty graph instead, and progressively draws edges (thereby merging connected components and associated aggregate vectors) as soon as two nodes host individ-ual vectors w i,t which are close enough to one an-other. This would have the advantage to lean on even faster data-structures for maintaining disjoint sets (e.g ., ( Cormen et al. , 1990 )[Ch. 22]), but has also the significant drawback of requiring prior knowledge of the separation parameter  X  . In fact, it would not be possible to connect two previously unconnected nodes without knowing some-thing about this parameter. A regret analysis similar to the one in Theorem 1 exists, though our current understanding is that the cumulative regret would depend linearly on instead of a large number of true clusters, rather than a small number. Remark 3. A data-dependent variant of the CLUB algo-rithm can be designed and analyzed which relies on data-dependent clusterability assumptions of the set of users with respect to a set of context vectors. These data-dependent assumptions allow us to work in a fixed design setting for the sequence of context vectors x t,k , and re-move the sub-Gaussian and full-rank hypotheses regarding E [ XX  X  ] . On the other hand, they also require that the power of the adversary generating context vectors be suit-ably restricted. See the supplementary material for detail s. Remark 4. Last but not least, we would like to stress that the same analysis contained in Theorem 1 extends to the case when we start off from a p -random Erdos-Renyi initial graph G 1 = ( V, E 1 ) , where p is the independent probabil-ity that two nodes are connected by an edge in G 1 . Trans-lated into our context, a classical result on random graphs due to ( Karger , 1994 ) reads as follows. Lemma 1. Given V = { 1 , . . . , n } , let V 1 , . . . , V partition of V , where | V j |  X  s for all j = 1 , . . . , m . Let G 1 = ( V, E 1 ) be a p -random Erdos-Renyi graph with p  X  random draw of edges), all m subgraphs induced by true clusters V 1 , . . . , V m on G 1 are connected in G 1 . For instance, if | V j | =  X  n m , j = 1 , . . . , m , for some constant  X   X  (0 , 1) , then it suffices to have | E 1 | = O m n log( n/ X  )  X  . Under these assumptions, if the initial graph G 1 is such a random graph, it is easy to show that Theorem 1 still holds. As mentioned in Section 3.1 (Eq. ( 2 ) therein), the striking advantage of beginning with a sparse r connected graph than the complete graph is computational, since we need not handle anymore a (possibly huge) data-structure having n 2 -many items. In our experiments, de-scribed next, we set p = 3 log n n , so as to be reasonably confident that G 1 is (at the very least) connected. We tested our algorithm on both artificial and freely avail-able real-world datasets against standard bandit baseline s. 4.1. Datasets Artificial datasets. We firstly generated synthetic datasets, so as to have a more controlled experimental setting. We tested the relative performance of the algorithms along different axes: number of underlying clusters, balanced-ness of cluster sizes, and amount of payoff noise. We set c t = 10 for all t = 1 , . . . , T , with time horizon T = 5 , 000 + 50 , 000 , d = 25 , and n = 500 . For each cluster V j of users, we created a random unit norm vec-tor u j  X  R d . All d -dimensional context vectors x t,k have then been generated uniformly at random on the surface of the Euclidean ball. The payoff value associated with clus-ter vector u j and context vector x t,k has been generated by perturbing the inner product u  X  j x t,k through an addi-tive white noise term  X  drawn uniformly at random across the interval [  X   X ,  X  ] . It is the value of  X  that determines the amount of payoff noise. The two remaining parameters are the number of clusters m and the clusters X  relative size. We assigned to cluster V j a number of users | V j | calculated as 7 | V so that z = 0 corresponds to equally-sized clusters, and z = 3 yields highly unbalanced cluster sizes. Finally, the sequence of served users i t is generated uniformly at ran-dom over the n users.
 LastFM &amp; Delicious datasets. These datasets are ex-tracted from the music streaming service Last.fm and the social bookmarking web service Delicious. The LastFM dataset contains n = 1 , 892 nodes, and 17 , 632 items (artists). This dataset contains information about the lis -tened artists, and we used this information to create pay-offs: if a user listened to an artist at least once the payoff is 1 , otherwise the payoff is 0 . Delicious is a dataset with n = 1 , 861 users, and 69 , 226 items (URLs). The payoffs were created using the information about the bookmarked URLs for each user: the payoff is 1 if the user bookmarked the URL, otherwise the payoff is 0 . 8 These two datasets are inherently different: on Delicious, payoffs depend on user s more strongly than on LastFM, that is, there are more popu-lar artists whom everybody listens to than popular websites which everybody bookmarks. LastFM is a  X  X ew hits X  sce-nario, while Delicious is a  X  X any niches X  scenario, making a big difference in recommendation practice. Preprocess-ing was carried out by closely following previous experi-mental settings, like the one in ( Cesa-Bianchi et al. , 2013 ). In particular, we only retained the first 25 principal com-ponents of the context vectors resulting from a tf-idf rep-resentation of the available items, so that on both datasets d = 25 . We generated random context sets C i c = 25 for all t by selecting index i t at random over the n users, then picking 24 vectors at random from the available items, and one among those with nonzero payoff for user i . 9 We repeated this process T = 5 , 000 + 50 , 000 times for the two datasets.
 Yahoo dataset. We extracted two datasets from the one adopted by the  X  X CML 2012 Exploration and Exploitation 3 Challenge X  10 for news article recommendation. Each user is represented by a 136-dimensional binary feature vector, and we took this feature vector as a proxy for the identity of the user. We operated on the first week of data. Af-ter removing  X  X mpty X  users, 11 this gave rise to a dataset of 8 , 362 , 905 records, corresponding to n = 713 , 862 distinct users. The overall number of distinct news items turned out to be 323 , c t changing from round to round, with a maximum of 51 , and a median of 41 . The news items have no features, hence they have been represented as d -dimensional versors , with d = 323 . Payoff values a t are either 0 or 1 depending on whether the logged web system which these data refer to has observed a positive (click) or negative (no-click) feedback from the user in round t . We then extracted the two datasets  X 5k users X  and  X 18k users X  by filtering out users that have occurred less than 100 times and less than 50 times, respectively. Since the system X  X  rec-ommendation need not coincide with the recommendation issued by the algorithms we tested, we could only retain the records on which the two recommendations were in-deed the same. Because records are discarded on the fly, the actual number of retained records changes across algo-rithms, but it is about 50 , 000 for the  X 5k users X  version and about 70 , 000 for the  X 18k users X  version. 4.2. Algorithms We compared CLUB with two main competitors: LinUCB-ONE and LinUCB-IND. Both competitors are mem-bers of the LinUCB family of algorithms ( Auer , 2002 ; Chu et al. , 2011 ; Li et al. , 2010 ; Abbasi-Yadkori et al. , 2011 ; Cesa-Bianchi et al. , 2013 ). LinUCB-ONE allocates a single instance of LinUCB across all users (thereby mak-ing the same prediction for all users), whereas LinUCB-IND ( X  X inUCB INDependent X ) allocates an independent instance of LinUCB to each user, thereby making predic-tions in a fully personalised fashion. Moreover, on the synthetic experiments, we added two idealized baselines: a GOBLIN-like algorithm ( Cesa-Bianchi et al. , 2013 ) fed with a Laplacian matrix encoding the true underlying graph G , and a CLAIRVOYANT algorithm that knows the true clusters a priori, and runs one instance of LinUCB per clus-ter . Notice that an experimental comparison to multitask-like algorithms, like GOBLIN, or to the idealized algorithm that knows all clusters beforehand, can only be done on the artificial datasets, not in the real-world case where no cluster information is available. On the Yahoo dataset, we tested the featureless version of the LinUCB-like algorith m in ( Cesa-Bianchi et al. , 2013 ), which is essentially a ver-sion of the UCB1 algorithm of ( Auer et al. , 2001 ). The cor-responding ONE and IND versions are denoted by UCB-ONE and UCB-IND, respectively. On this dataset, we also tried a single instance of UCB-V ( Audibert et al. , 2009 ) across all users, the winner of the abovementioned ICML Challenge. Finally, all algorithms have also been compared to the trivial baseline (denoted by RAN) that picks the item within C i t fully at random.
 As for parameter tuning, CLUB was run with p = 3 log n n , so as to be reasonably confident that the initial graph is at least connected. In fact, after each generation of the graph, we checked for its connectedness, and repeated the process until the graph happened to be connected. 12 All algorithms (but RAN) require parameter tuning: an exploration-exploitation tradeoff parameter which is com -mon to all algorithms (in Figure 1 , this is the  X  param-eter), and the edge deletion parameter  X  2 in CLUB. On the synthetic datasets, as well as on the LastFM and De-licious datasets, we tuned these parameters by picking the best setting (as measured by cumulative regret) after the first t 0 = 5 , 000 rounds, and then sticked to those values for the remaining T  X  t 0 = 50 , 000 rounds. It is these 50 , 000 rounds that our plots refer to. On the Yahoo dataset, this optimal tuning was done within the first t 0 = 100 , 000 records, corresponding to a number of retained records be-tween 4 , 350 and 4 , 450 across different algorithms. 4.3. Results Our results are summarized in 13 Figures 3 , 4 , and 5 . On the synthetic datasets (Figure 3 ) and the LastFM and Delicious datasets (Figure 4 ) we measured the ratio of the cumulative regret of the algorithm to the cumulative regret of the ran-dom predictor RAN (so that the lower the better). On the synthetic datasets, we did so under combinations of num-ber of clusters, payoff noise, and cluster size balancednes s. On the Yahoo dataset (Figure 5 ), because the only available payoffs are those associated with the items recommended in the logs, we instead measured the Clickthrough Rate (CTR), i.e., the fraction of times we get a t = 1 out of the number of retained records so far (so the higher the better). This experimental setting is in line with previous ones (e.g ., ( Li et al. , 2010 )) and, by the way data have been prepared, gives rise to a reliable estimation of actual CTR behavior under the tested experimental conditions ( Li et al. , 2011 ). Based on the experimental results, some trends can be spotted: On the synthetic datasets , CLUB always out-performs its uninformed competitors LinUCB-IND and LinUCB-ONE, the gap getting larger as we either decrease the number of underlying clusters or we make the clusters sizes more and more unbalanced. Moreover, CLUB can clearly interpolate between these two competitors taking, in a sense, the best of both. On the other hand (and unsurpris-ingly), the informed competitors GOBLIN and CLEAR-VOYANT outperform all uninformed ones. On the  X  X ew hits X  scenario of LastFM, CLUB is again outperform-ing both of its competitors. However, this is not happen-ing in the  X  X any niches X  case delivered by the Delicious dataset, where CLUB is clearly outperformed by LinUCB-IND. The proposed alternative of CLUB that starts from an empty graph (Remark 2 ) might be an effective alternative in this case. On the Yahoo datasets we extracted, CLUB tends to outperform its competitors, when measured by CTR curves, thereby showing that clustering users solely based on past behavior can be beneficial. In general, CLUB seems to benefit from situations where it is not immediately clear which is the winner between the two extreme solu-tions (Lin)UCB-ONE and (Lin)UCB-IND, and an adaptive interpolation between these two is needed.
 We would like to thank the anonymous reviewers for their helpful and constructive comments. Also, the first and the second author acknowledge the support from Ama-zon AWS Award in Education Machine Learning Research Grant.
 Abbasi-Yadkori, Y., P  X  al, D., and Szepesv  X  ari, C. Improved algorithms for linear stochastic bandits. Proc. NIPS , 2011.
 Audibert, J.-Y., Munos, R., and Szepesv  X  ari, C.
Exploration-exploitation tradeoff using variance es-timates in multi-armed bandits. Theoretical Computer Science , 410(19):1876 X 1902, 2009.
 Auer, P. Using confidence bounds for exploration-exploitation trade-offs. Journal of Machine Learning Re-search , 3:397 X 422, 2002.
 Auer, P., Cesa-Bianchi, N., and Fischer, P. Finite-time ana l-ysis of the multiarmed bandit problem. Machine Learn-ing , 2001.
 Bogers, T. Movie recommendation using random walks over the contextual graph. In CARS X 10: Proc. 2nd Work-shop on Context-Aware Recommender Systems , 2010. Buccapatnam, S., Eryilmaz, A., and Shroff, N.B. Multi-armed bandits in the presence of side observations in so-cial networks. In Proc. 52nd IEEE Conference on Deci-sion and Control , 2013.
 Burke, R. Hybrid systems for personalized recommenda-tions. In Proc. of the 2003 ITWP , pp. 133 X 152, 2005. Buscher, G., White, R. W., Dumais, S., and Huang, J.
Large-scale analysis of individual and task differences in search result page examination strategies. In Proc. 5th ACM WSDM , pp. 373 X 382, 2012.
 Caron, S. and Bhagat, S. Mixing bandits: A recipe for im-proved cold-start recommendations in a social network.
In SNA-KDD, 7th Workshop on Social Network Mining and Analysis , 2013.
 Caron, S., Kveton, B., Lelarge, M., and Bhagat, S. Lever-aging side observations in stochastic bandits. In Proc. UAI , pp. 142 X 151, 2012.
 Cesa-Bianchi, N., Gentile, C., and Zappella, G. A gang of bandits. In Proc. NIPS , 2013.
 Chu, W., Li, L., Reyzin, L., and Schapire, R. E. Contextual bandits with linear payoff functions. In Proc. AISTATS , 2011.
 Cormen, T.H., Leiserson, C.E., and Rivest, R.L. Introduc-tion to Algorithms . McGraw Hill, 1990.
 Crammer, K. and Gentile, C. Multiclass classification with bandit feedback using adaptive regularization. In Proc. ICML , 2011.
 Delporte, J., Karatzoglou, A., Matuszczyk, T., and Canu, S.
Socially enabled preference learning from implicit feed-back data. In Proc. ECML/PKDD , pp. 145 X 160, 2013. Djolonga, J., Krause, A., and Cevher, V. High-dimensional gaussian process bandits. In NIPS , pp. 1025 X 1033, 2013. Kapron, Bruce M., King, Valerie, and Mountjoy, Ben. Dy-namic graph connectivity in polylogarithmic worst case time. In Proc. SODA , pp. 1131 X 1142, 2013.
 Karger, D. R. Random sampling in cut, flow, and network design problems. In Proc. STOC , 1994.
 Krause, A. and Ong, C.S. Contextual gaussian process ban-dit optimization. In Proc. 25th NIPS , 2011.
 Lai, T. and Robbins, H. Asymptotically efficient adaptive allocation rules. Advances in Applied Mathematics , 6: 4 X 22, 1985.
 Langford, J. and Zhang, T. The epoch-greedy algorithm for contextual multi-armed bandits. In Proc. NIPS , 2007. Li, L., Chu, W., Langford, J., and Schapire, R. E. A contextual-bandit approach to personalized news article recommendation. In Proc. WWW , pp. 661 X 670, 2010. Li, L., Chu, W., Langford, J., and Wang, X. Unbiased of-fline evaluation of contextual-bandit-based news article recommendation algorithms. In Proc. WSDM , 2011.
 Rashid, A. M., Lam, S.K., Karypis, G., and Riedl, J.
Clustknn: a highly scalable hybrid model-&amp; memory-based cf algorithm. In Proc. WebKDD-06, KDD Work-shop on Web Mining and Web Usage Analysis , 2006. Schafer, J.B., Konstan, J.A., and Riedl, J. Recommender systems in e-commerce. In Proc. EC , pp. 158 X 166, 1999. Seldin, Y., Auer, P., Laviolette, F., Shawe-Taylor, J., and Ortner, R. Pac-bayesian analysis of contextual bandits. In NIPS , pp. 1683 X 1691, 2011.
 Thorup, M. Decremental dynamic connectivity. In Proc. SODA , pp. 305 X 313, 1997.
 Valko, M., Munos, R., Kveton, B., and Koc  X  ak, T. Spectral
Bandits for Smooth Graph Functions. In 31th Interna-tional Conference on Machine Learning , 2014.
 Yue, Y., Hong, S. A., and Guestrin, C. Hierarchical ex-ploration for accelerating contextual bandits. In ICML ,
