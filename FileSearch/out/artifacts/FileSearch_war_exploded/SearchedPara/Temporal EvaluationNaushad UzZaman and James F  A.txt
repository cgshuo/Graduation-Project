 The recent emergence of language processing a p plications like question answering, information extraction, and document summarization has mot i vated the need for temporally -aware systems. This, along with the availability of the temporal annot a tion scheme TimeML (Pustejovsky et al., 2003) , a te m porally annotated corpus , Tim e Bank (Pustejovsky et al., 2003) and the te mporal evalu a tion cha l lenges TempEval -1 (Verhagen et al., 2007) and Te m pEval -2 (Pustejovsky and Verhagen, 2010) , has led to an explosion of r e search on temporal information pro c essing (TIP).
Prior evaluation methods (TempEval -1, 2) for different TIP subtasks have borrow ed prec i sion and recall measures from the information r e t rieval comm u nity. This has two pro b lems: First , systems express temporal relations in different, yet equiv a lent, ways. Co n sider a scenario where the reference annot a tion contains e 1 &lt;e 2 and e 2 &lt;e the system identifies the relation e 1 &lt;e 3 . The traditional evalu a tion metric will fail to identify e &lt;e 3 as a co r rect relation, which is a logical consequence of the re f erence annotation. Second, traditional evaluation s tell us how well a system perform s in a partic u lar task, but not the overall performance . For example, in TempEval -2 there were 6 subtasks (event e x traction, temporal expression extraction and 4 su b tasks on identifying temporal relations). Thus , different system s perform best is different su b task s , but we can X  X  compare overall performance of system s . 
We use temporal closure to identify equivalent temporal relations and produce a single score that measures the temporal awareness of each system. We use Tim e graph (Miller and Schubert, 1990) for computing temporal closure, which makes our sy s tem scalable and computa tionally inexpe n sive . To calculate the inter -annotator agreement between annotators in the temporal annotation task, some researchers have used semantic matc h ing to reward distinct but equivalent temporal relations. Such techniques can equal ly well be applied to system evaluation.

Setzer et al. (2003) use temporal closure to r e ward equivalent but distinct relations. Co n sider the example in Figure 1 (due to Tannier and Muller, 2008) . Consider graph K as the reference annot a tion graph, and S 1 , S 2 and S 3 as output s of differen t sy s tems. The bold edges a re the extracted rel a tions and the dotted edges a re derived . The traditional matching approach will fail to verify B&lt;D is a co r rect relation in S 2 , since there is no explicit edge between B and D in reference annotation (K). But a metric using temporal closure would cr e ate all implicit edges and be able to r e ward B&lt;D edge in S 2 . 
Setzer et al. X  X  approach works for this particular case, but as pointed by Tannier and Muller ( 2008) , it gives the same impo r tance to all relations, whereas some relations are not as crucial as others. For example, with K again as the reference annot a tion, S 2 and S 3 both identify two correct rel a tions, so both should have a 100% precision, but in terms of rec all, S 3 identified 2 explicit relations and S 2 ident i fied one explicit and one implicit rel a tion. With Setzer at al. X  X  technique, both S 2 and S 3 will get the same score, which is not accurate . Tannier and Muller handle this problem by fin d ing the core 2 rel ations. For recall, they consider the refe r ence core relations found in the system core rel a tions and for prec i sion they consider the system core rel a tion s found in the reference core relations. They noted that core relations do not contain all inform a tion pr o vided by closed graphs . H ence their measure is only an approx i mation of what should be assessed. Consider the pr e vious example again. If we are eval u ating graph S 2 , they will fail to verify that B&lt;D is a co r rect edge. 
We have shown that both of these existing evaluation mechanism reward relations based on s e mantic matching, but still fail in specific cases. We also use temporal closure to reward equivalent but distinct relations. Ho w ever, we do not compare against the temporal clo sure of reference annot a tion and sy s tem output, like Setzer et al., but we use the temp o ral cl o sure to verify if a temporal relation can be derived or not. Our prec i sion and recall is defined as: 
The harmonic mean of precision and recall, i.e. fscore, will give a n evaluation of the temp o ral awareness of the system. As an example, c onsider again the examples in Figure 1, with K as reference annotation . S 1 and S 3 clearly have 100% pr ecision , and S 2 also get s 100% precision, since the B&lt;D edge can be ver i fied through the temporal cl o sure graph of K. Note, our r e call measure doesn X  X  reward the B&lt;D edge of S 2 , but it is counted for prec i sion. S 1 and S both get a recall of 2/3, since 2 edges can be ver i fied in the reference te m poral closure graph. This scheme is similar to the MUC -6 scoring for coreference (Vilain et al., 1995) . Their scoring e s timate d the minimal number of missing links ne c essary to complete co -ref erence chain in order to make it match the h u man annot a tion. Here in both S 1 and S 3 , we are missing one edge to match with the re f e rence annotation; hence 2/3 is the appropriate score. Precision, recall and fscore for all these sy s tem output are shown in T a ble 1. Our proposed approach is easy to impl e ment with an existing temporal closure implementation. We preferred Timegraph (Miller and Schubert, 1990) over Allen X  X  interval closure algorithm (A l len, 1983) because Timegraph has been shown to be more scalable 3 to larger pro b lems (Yampratoom and Allen, 1993) . Furthermore, the additional e x pressive power of interval disjun c tion in Allen (1983) does not appear to play a signif i cant role in temporal extra c tions from text.

A Timegraph G = (T, E) is an acyclic directed graph in which T is the set of vertices (nodes) and E is the set of edges (links). It is partitioned into chains, which are defined as sets of poi nts in a li n ear order. Links between points in the same chain are in -chain links and links between points in di f ferent chains are cross -chain links . Each point has a numeric pseudo -time , which is arbitrary except that it maintains the ordering relationship b e tween the points on the same chain. Chain and pseudo -time information are ca l culated when the point is first entered into the Timegraph. Determining rel a tionship b e tween any two points in the same chain can be done in constant time simply by co m paring t he pseudo -times, rather than follo w ing the in -chain links. On the other hand, relationship b e tween points in di f ferent chain s can be found with a search in cross -chain links, which is dependent on the number of edges (i.e. number of chains and number of cr oss -chain links) . A m e tagraph keeps track of the cross -chain links effectively by mai n taining a metanode for each chain, and using a cross -chain links between metanodes. More d e tails about Timegraph can be found in Miller and Sch u bert (1990) and Tau gher ( 1983) .

Timegraph only supports simple point rel a tions (&lt;, =,  X  ), but we need to evaluate systems based on TimeML, which is based on interval algebra. However, single (i.e., non -disjunctive) interval r e lations can be easily co n verted to point rel a tio ns 4 .

For efficiency, we want to minimize the nu m ber of chains constructed by Timegraph , since with more chains our search in Timegraph will take more time. If we arbitrarily choose TimeML TLINKs (temporal links) and add them we will create some extra chain s . To avoid this, we start with a node and traverse through its neighbors in a sy s tematic fashion trying to add in chain order. This approach decreases number of nodes+edges by 2.3% in complete TimeBank corpus, which eve n tually affects searching in Timegra ph. 
Next addition is to optimize Timegraph co n struction. For each relation we have to make sure all constraints are met. The easiest and best way to approach this is to consider all relations t o gether. For example, for interval relation X includes Y, the point relation constraints are: x1&lt;y1, x1&lt;y2, x2&gt;y1, x2&gt;y2, x1&lt;x2 and y1&lt;y2. We want to co n sider all constraints together as, x1 Timegraph. In Table 2, we show TimeML rel a tions and equivalent Allen X  X  relation 5 , th en equivalent representation in point algebra and finally point algebra represented as a chain, which makes adding relations in Timegraph much easier with fewer chains. These additions make Timegraph more effective for TimeML co r pus. Our proposed evaluation metric has some very good properties, which makes it very suitable as a standard metric. This section presents a few e m pirical tests to show the usefu l ness of our metric.

Our precision and recall goes with the same spirit with traditional precision and recall, as a r e sult, performance decreases with the decrease of info r mation. Specifically, i. if we remove relations from the reference a n notation and then compare that against the full re f erence annotation, then recall decrease s linearly. Shown in Figure 2. ii. if we introduce noise by adding new rel a tions, then precision decreas es linearly (Figure 3). iii. if we introduce noise by changing existing relations then fscore d e creases linearly (Figure 4). iv. if we remove temporal entities ( such as events or temporal expressions), performance d e creases more for entities that are temporal ly relat ed to more entities. This means, if the system fails to extract important temporal entities then the pe r formance will d e crease more (Figure 5). 
Temporal entities related with a maximum nu m ber of e n tities are removed first. It is evident from the graph that performance decreased more for r e moving impo r tant entitie s (first few entities). 
These properties explain that our final fscore captures how well a system extract s events, temp o ral expressions and temporal rel a tions. Therefore this single score captures all the scores of six su b tasks in TempEval -2, making it ve ry convenient and straightforward to compare different sy s tems. 
Our implementation using Timegraph is also scalable. We ran our Timegraph construction alg o rithm on the complete TimeBank corpus and found that Timegraph construction time i n creases linearly with the increase of number of nodes and edges (= # of cross -chain links and # of chains) (Figure 6). 
The largest document , with 235 temporal rel a tions (around 900 nodes+edges in Timegraph) only take s 0.22 seconds in a laptop co m puter with 4GB RAM and 2. 26 GHz Core 2 Duo proce s sor. 
We also confirmed that the number of nodes + edges in Timegraph also incr ease s lin e arly with number of temporal relations in TimeBank doc u ments . , i.e. our Timegraph construction time co r relates with the # of relations in TimeBank doc u ments (Figure 7).

Searching in Timegraph, which we need for temporal evaluation, also depends on number of nodes and edges, hence number of TimeBank rel a tions. We ran a temporal evaluation on Tim e Bank corpus using the same document as system output. The operation included creating two Tim e graphs and searching in the Timegraph. As e x pected, the searc h ing time also increases linearly against the number of relations and is computationally ine x pensive (Figure 8). We proposed a temporal evaluation that considers semantically similar but distinct temporal relations and consequently gives a si n gle score, which could be used for identifying the temporal awareness of a system. Our approach is easy to implement, intu i tive and accurate. We implemented it using Tim e graph for handling temporal closure in TimeML derived corpora, which makes our implement a tion scalable and co mputationally inexpensive. James F. Allen. 1983. Maintaining knowledge about temporal intervals. Communications of the ACM 26 , 832 -843.
 S. Miller and L. Schubert. 1990. Time revisited. Computational Intelligence 6 , 108 -118.
 J. Pustejovsky, P. Hanks, R. Sauri, A. See, R. Gaizauskas, A. Setzer, D. Radev, B. Sundheim, D. Day, L. Ferro and M. Lazo. 2003. The TIMEBANK corpus. Proceedings of the Corpus Linguistics, 647  X  656.
 James Pustejovsky, Jos M. Castao, Robert Ingria, Roser Sa uri, Robert J. Gaizauskas, Andrea 
Setzer, Graham Katz and Dragomir R. Radev. 2003. TimeML: Robust Specication of Event and Temporal Expressions in Text. . Proceedings of the New Directions in Question Answering.
 James Pustejovsky and Marc Verhagen. 2010. 
S emEval -2010 task 13: evaluating events, time expressions, and temporal relations (TempEval -2). Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions.
 A Setzer, R Gaizauskas and M Hepple. 2003. 
Using semantic inferen ces for temporal annotation comparison. Proceedings of the Fourth International Workshop on Inference in Computational Semantics (ICOS -4), 25 -26.
 X Tannier and P Muller. 2008. Evaluation Metrics for Automatic Temporal Annotation of Texts. Proceedings of th e Proceedings of the Sixth International Language Resources and Evaluation (LREC'08).
 J. Taugher. 1983. An efficient representation for time information. Department of Computer Science . Edmonton, Canada: University of Alberta.
 Marc Verhagen, Robert Gaizaus kas, Frank Schilder, Mark Hepple, Graham Katz and James Pustejovsky. 2007. SemEval -2007 Task 15: TempEval Temporal Relation Identification. 
Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval 2007).
 Marc Vilain, John Burger, John Aberdeen, Dennis 
Connolly and Lynette Hirschman. 1995. A model -theoretic coreference scoring scheme. 
Proceedings of the MUC6  X 95: Proceedings of the 6th conference on Message understanding.
 Ed Yampratoom and James F. Allen. 1993. Performance of Temporal R easoning Systems. TRAINS Technical Note 93 -1 . Rochester, NY: 
University of Rochester.
