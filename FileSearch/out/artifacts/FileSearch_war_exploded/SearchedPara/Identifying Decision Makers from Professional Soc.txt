 Sales professionals help organizations win clients for prod-ucts and services. Generating new clients starts with iden-tifying the right decision makers at the target organization. For the past decade, online professional networks have col-lected tremendous amount of data on people X  X  identity, their network and behavior data of buyers and sellers building re-lationships with each other for a variety of use-cases. Sales professionals are increasingly relying on these networks to research, identify and reach out to potential prospects, but it is often hard to find the right people effectively and effi-ciently. In this paper we present LDMS, the LinkedIn Deci-sion Maker Score, to quantify the ability of making a sales decision for each of the 400M+ LinkedIn members. It is the key data-driven technology underlying Sales Navigator, a proprietary LinkedIn product that is designed for sales professionals. We will specifically discuss the modeling chal-lenges of LDMS, and present two graph-based approaches to tackle this problem by leveraging the professional network data at LinkedIn. Both approaches are able to leverage both the graph information and the contextual information on the vertices, deal with small amount of labels on the graph, and handle heterogeneous graphs among different types of ver-tices. We will show some offline evaluations of LDMS on historical data, and also discuss its online usage in multiple applications in live production systems as well as future use cases within the LinkedIn ecosystem.
 Decision Makers, Social Network Mining, Graph Mining
As a crucial part of any for-profit organizations, sales pro-fessionals help to win customers for products and services. For B2B selling, 1 their job typically starts from identifying
Business to Business Selling, https://en.wikipedia.org/ wiki/Business-to-business the right decision makers at the client organizations. This process is often called prospecting or lead generation . The ability to do this well is arguably the most important skill set that any successful sales professional need to have [6, 10, 12].

As we have entered into the social era, sales profession-als started to pay more attention to developing relationships with potential clients as part of the sales process. This is often referred to as social selling , and includes components such as social prospecting, personal branding, employee ad-vocacy, and social relationship management. 2 Among these components, social prospecting involves monitoring and search-ing social networks for signs of customer interest, immediate buying intent, or qualified prospect status based on indus-try, role, geography, etc. It X  X  the entry point of identifying potential clients in the modern sales process.

Nowadays, social prospecting often takes place via social networks such as LinkedIn, Twitter and Facebook. Sales professionals are increasingly checking on member X  X  profile, social connections, and blogs/updates on these social net-works. However, they often find it hard to identify prospects they are interested in, despite the large amount of data avail-able in various sources. They need intelligent data tools to help them find the target clients effectively and efficiently. In this paper we present LDMS, the LinkedIn Decision Maker Score, to capture the fundamental notion of decision makers in the sales context by leveraging the professional members data on LinkedIn. The goal of LDMS is to consol-idate all member X  X  profile data with social graphs data and calculate a score for each of the 400M+ LinkedIn members, quantifying his or her ability of make or influence a sales de-cision. We will specifically discuss the modeling challenges of developing LDMS, and present two approaches to tackle the problem, a graph summarization approach and a bipar-tite graph learning approach. Both approaches are able to leverage both the graph information and the contextual in-formation on the vertices, deal with small amount of labels on the graph, and handle heterogeneous graphs among dif-ferent types of vertices. These methods are discussed in the LDMS context, but they can be applied to many other rank-ing or influence extraction problems on social networks or graphs in general. We will show performance of both ap-proaches on LinkedIn data, and also discuss how LDMS is currently used in LinkedIn production systems.

The rest of the paper is organized as follows. In Section 2 we cover the related work on graph-based learning methods for influential node discovery, and in Section 3 we present https://en.wikipedia.org/wiki/Social selling the overview of the problem and the general setup. Then in Section 4 we present two learning approaches to tackle this challenging problem, and in Section 5 we show some experimental results on some offline data. Finally we dis-cuss applications of LDMS within the LinkedIn ecosystem in Section 6, and conclude the paper in Section 7.
There has been a rich literature on identifying important or influential nodes in a network, both in an unsupervised setting and a semi-supervised setting. We briefly describe some of the work in this section, and also discuss the impor-tance of decision maker identification for sales use cases.
The identification of decision makers can be viewed as finding the most important nodes in a graph. If treated as an unlabeled problem, the most popular graph-based algo-rithms are PageRank [2] and HITS [11], both in the context of web page ranking. PageRank is an iterative algorithm be-hind Google search engine, in which the rank of a web page is the probability that a random surfer would visit that page starting from a random page. HITS, on the other hand, tries to answer the question of how authoritative a given web page is. The model assumes that there exist authority pages and pages that link to many related authorities, referred to as hubs, interconnected by a mutually reinforcing relationship.
Several algorithms have been proposed to enhance PageR-ank and HITS. Haveliwala et al. [8] presented different ap-proaches to personalize PageRank. TrustRank [7] was pro-posed for spam detection using a seed of expert-verified trusted pages. BrowseRank [14] also incorporates the time component by taking into account how much time users spend on a web site. It uses continuous time Markov process instead of the discrete time Markov process that PageRank uses. An application of PageRank-based algorithm for iden-tifying trendsetters was presented by Trumper et al. [18]. They identify the trendsetters in information networks by using temporal attributes of nodes and edges, and rank users based on their ability to promote new ideas which will be adopted by many other users later.
Instead of only considering the link structure of the net-work, several papers also investigated how to incorporate contextual attributes of the nodes into learning and ranking. Topic-sensitive PageRank [9] pre-computes a set of biased PageRank vectors using a set of representative topics. It then uses these to generate query-specific importance scores at query time. Richardson et al. [17] proposed an intel-ligent surfer which is a query-dependent, content-sensitive version of PageRank. The surfer probabilistically hops from page to page, depending on the content of the page and the query terms the user is searching. TwitterRank [19] ranks users by taking into account the topical similarity be-tween users based on their tweets besides the graph infor-mation. The random surfer performs a topic-specific walk and then the overall influence is measured by aggregating the topic-specific TwitterRank over all the topics. Pal et al. [16] identified authorities in Twitter by performing prob-abilistic clustering over the feature space and then rank the users inside the cluster, under the assumption that features follow a Gaussian distribution.
Several work explored the bipartite graphical structure to identify important nodes. The majority of them have been developed in the context of co-authorship and cita-tion networks. Zhou et al. [23] proposed an approach to combine two random walks, one as intra-class walk between same-type entities (authors or documents) and the other as inter-class walk across the two sides of the bipartite graph. The random surfer has a certain probability of taking intra-or inter-class steps at any vertex. Meng et al. [15] devel-oped a rule-based method which iteratively ranks authors and publications following a mutual-reinforcement strategy until convergence. There has also been work on influence mining on a heterogeneous graph by Liu et al. [13], using both the link information and the textual content. They proposed a generative graphical model to find the topic-level direct influence and subsequently the indirect influence be-tween nodes.
Another work stream on graphs is to start from a small set of labeled vertices, and leverage the graphical structure to propagate the labels to other unlabeled vertices. The main assumption is that similar vertices are more likely to have the same label. Following these principles, approaches for undirected graphs have been developed [24, 20], as well as a HITS-inspired algorithm for directed graphs [21] and a method motivated by PageRank to identify the unknown labels in a directed graph [22].
Many books and articles have discussed the specific skills a sales professional should have. A crucial one among them is to identify real decision makers and to present their products or services to them [4, 6, 10, 12]. However there has not been many work in the data mining community that aims to help sales professionals tackle this problem (see a recent paper in [5]).

For the decision maker identification problem in our con-text, we cannot simply run a PageRank or HITS type algo-rithm to identify the important nodes. Such algorithms typ-ically find influential or popular people on our network (such as celebrities), not necessarily the people who can make sales decisions. We require some labels to guide the algorithms, hence need to combine the labels with the graph structure. Also we will need to deal with heterogeneous graphs within our professional network. With this in mind, the approaches we propose in this paper are able to leverage both the graph information and the contextual information, deal with small amount of labels on the graph, and handle heterogeneous graphs among different types of vertices. We believe they will have positive impact in many sales use cases and other application areas beyond the context we discuss in this pa-per.
In this section we give a high-level overview of the so-cial network environment in our context, and discuss mech-anisms to obtain ground truth and features for developing LDMS. Although the context is within LinkedIn ecosystem, many of the attributes and insights apply to other social network settings. top that are tailored to the specific sales professional user.
LinkedIn is the largest professional social network in the world with more than 400M members to date. Most sales professionals have already started using LinkedIn to research, identify, and reach out to potential clients. With a premium subscription, they can view members X  profiles, follow them, get introduced to connect to them, send private messages (called inMails ) to them, etc.

LinkedIn also has a proprietary product called Sales Nav-igator, which is designed specifically for sales professionals. It combines LinkedIn X  X  network data, relevant news sources, and the accounts, leads, and preferences set by the sales professionals to produce customized recommendations and insights. See Figure 1 for two screen shots of Sales Navigator on sales-focused search and lead recommendation on com-pany page. Both of them are currently leveraging LDMS in live production systems. We will discuss these specific applications in more detail in Section 6.
In this work, we focus on identifying decision makers in the professional social networks within the LinkedIn ecosystem. The decision makers in our context are people who can make or influence a sales decision. Note that we are not interested in influence within the social graph, but rather within the sales context. That X  X  why we are leveraging social data from both the LinkedIn.com and LinkedIn Sales Navigator. Both platforms share certain data elements (e.g., member profiles, connections), but Sales Navigator has its own characteristics (see Figure 1(a)): Our goal is to learn a scoring function to assign a LinkedIn Decision Maker Score to each of the 400M+ LinkedIn mem-bers. We intentionally make the score global , in that every member has one score regardless of what his or her indus-try, company, or function is. In other words, we do not aim to develop a specialized score for members within each in-dustry, each company, or each function. This has broader usage for our context, and can be used within a special set-ting if needed. One can, for instance, use the score to refine search ranking such that higher-scored members are shown at the top. We can also sort members by this score for a given company to measure decision-making power within the company. Both use cases will be discussed further in Section 6.
One challenge in the LDMS offline training is the unavail-ability of the actual ground truth. In other words, we do not have definitive answer on who is and who is not a decision maker. We also do not have access to our customer X  X  CRM (i.e., customer relationship management) data to know ex-actly who made or influenced a buying decision. Therefore, we seek to use a surrogate ground truth from LinkedIn data. In this section we describe the definition details and the ra-tionale behind it.
When a sales professional is interested in a particular indi-vidual on LinkedIn, here are the major signals we can collect depending on how he or she expresses interest: Going from Profile View to inMail , the sales professional is getting more serious about this individual. He or she also needs to do more work with the interaction -from simply viewing a LinkedIn profile to carefully drafting a message. Since the inMail signal is the most effective way of reach-ing out through the LinkedIn and Sales Navigator platform, in the LDMS training pipeline we chose the number of in-Mails from distinct sales professionals within a specified time frame , denoted as N in ( x,T ) for member x in time frame T , to be the signal for ground truth definition. The higher this number, the more likely the recipient is truly a prospect. Note that we only count inMails from one sales professional once for each recipient.
Inbound inMails alone is not sufficient to identify key de-cision makers for sales use-case as this leads to a lot of false positives. For example, on LinkedIn platform, recruiters also receive high number of inbound inmails. Not surprisingly, they also send out a lot of inMails to prospective candi-dates. On the contrary, decision makers tend to receive disproportionately more inbound inMails when compared to the amount of inMails that they send out themselves. Additionally, since our motivation is to compute Decision Maker Score across organizations so in our ground truth we discount for organization X  X  popularity amongst sales pro-fessionals. Therefore we considered the following discount factors: Figure 2: Sparsity of different graph signals. At the per-company level, we show the number of (a) inMail signals and (b) Profile View signals the top-ranked people (from 100th to 2000th) received from sales professionals within the calendar year of 2015. The box plots averaged all companies with more than 5000 employees based on LinkedIn data. On the y-axis we highlight the scale difference of the two box plots instead of the actual number. It can be seen that Profile View signals are  X  50 folds larger than inMail signals. Furthermore, across various time-window we see large changes in the absolute number of inMails that individuals get. There-fore to add robustness to our ground-truth, we consider per-centiles within the company for these two discount factors instead of the actual discount values. The final ground truth definition for member x in time frame T is:
GT ( x,T ) = N in ( x,T )  X  Perc ( D 1 ( x,T ))  X  Perc ( D where Perc denotes the percentile which takes value between 0 (0%) and 1 (100%).
One may wonder why not simply use this ground truth definition as the LDMS score (hence no need for supervised learning!). The reason is data sparsity . Very few LinkedIn members have ever received an inMail from a sales profes-sional. Figure 2 also shows, at a per-company level, how many inMails and Profile Views top-ranked people received within a 12-month period. It can be seen that other signals, Profile Views in this case, do not suffer as much from spar-sity problem. Therefore, to robustly rank a broader set of member base, we need to identify other non-sparse signals that correlate with the ground truth.
In the LDMS offline training pipeline we considered var-ious information about the member and the social graphs from LinkedIn.com and Sales Navigator. The following are the high-level categories: All graph edges have a time stamp associated with it, and for some graphs there might be multiple edges between two nodes (e.g. Profile View Graph ). There are other social graphs within the LinkedIn ecosystem, such as the Follower Graph, Endorsement Graph, etc. We currently do not use them but the framework is easy to extend to these addi-tional graphs. Also note that we make an explicit distinc-tion among various graphs on LinkedIn instead of blending all the actions into one graph. In Section 5.3 we will ex-plore why this is helpful. We also want to emphasize that these heterogeneous graphs cover different types of graphs we normally see in social networks and include undirected, uni-directional and bipartitie graphs.
Given the aforementioned ground truth and feature groups, in this section we introduce two algorithms for LDMS train-ing, mainly based on how we encode the graph information into the learning process. The graph summarization ap-proach summarizes each graph into specific features, and then adapts state-of-the-art supervised learning algorithms. The bipartite graph learning approach leverages the graph-ical structure explicitly and presents a novel graph prop-agation algorithm. Though we focus our algorithmic de-scriptions within the LinkedIn context, the approaches are general and should be applicable to other applications.
In this approach we cast the problem to a classification problem, i.e., we are training a classifier to categorize each member to be a decision maker (+1) or not (-1). The key here is how to leverage various social graphs for classifier training on top of the member-profile-based features. In the following we discuss the details for three different types of graphs. Since all the graphs evolve with time, we fix a specific time frame for each graph.

For undirected graphs (e.g., Connection Graph ), we ex-tract the following information from the graph for each mem-ber: For non-bipartite, directed graphs (e.g., Profile View Graph , Invitation Graph , inMail Graph ), we compute the following information from the graph for each member: For the bipartite directed graph (e.g., Lead Saves ) between members and sales professionals, we only compute the Sales-In feature.

One key insight from this graph summarization approach is that the ratio features are more relevant to distinguish good and not-so-good decision makers, as good decision mak-ers tend to have more in-bound interest (which can be profile views, lead saves, inMails, etc.) and less out-bound signals.
For supervised learning, we created binary labels based on the ground truth values, and combined all the graph-based features with the member-profile-based features. We can use any classification algorithm for training  X  for compari-son in this paper we used elastic net classifier [25], which is a combination of L2 and L1 regularization. From our expe-rience it was shown to be more flexible and can strike the right balance between goodness-of-fit and sparsity. One may also adapt Learning-To-Rank methods to learn the overall ranking of the members based on LDMS ground truth.
One issue the graph summarization approach does not take into account is the quality or competency of sales pro-fessionals. In the graph features computed from each of the graphs, we effectively weigh each sales professional equally. This may not be ideal as the signal, say a Profile View, from a novice sales professional should carry much less weight compared to that from an experienced and active sales pro-fessional. In this subsection we formulate this as a bipartite graph learning problem which explicitly takes into account the LDMS for a member and the competency assessment for a sales professional, which we call the LinkedIn Sales Competency Score (LSCS). The motivation is that when we compute the LDMS score for a member, the incoming sig-nals from the sales professionals should be weighted by their respective LSCS score. Likewise we can also take into ac-count members X  LDMS score when updating the LSCS score for a sales professional.

Formally, let X = { x i } and Z = { z j } be two disjoint sets of nodes in the network. With a slight abuse of notation we use x i and z j to denote both the nodes in the network as well as the contextual feature vectors they represent. We assume there are K bipartite graphs between nodes X and Z . For the k -th graph G k = ( V k ,E k ), we have vertices V k = X  X  X  , and edges E k = { e k ( ij ) : x i  X  X ,z j  X  Z} . We allow the edges to be undirected ( e k ( ij ) ), uni-directional ( e the uni-directional edges to describe the approach but it can take all three types of edges.

For the bipartite graph construction we assume X  X  X  =  X  . In our context X can be the members, and Z the sales professionals. Since sales professionals are also members, in our context they have a representation on both sides.
Let p i be the p -score for x i , and q j be the q -score for z These, in our context, can be LDMS for members and LSCS for sales professionals. We define the following models for p and q j : Here f (  X  ) and g (  X  ) denote non-linear transformation func-tions from the continuous space to [0 , 1]. We assume they are both sigmoid functions in this paper. w pc and w qc are the weight vectors for all constant (individual) features of x z that are not based on the bipartite graphs. In our context these features include profile-based features such as title, po-sition and seniority. Note that they are multi-dimensional and can be of different length for x and z . w pk and w are the weights for graph G k and they measure how graph G k contributes to the overall model regardless of index i or j . t ( j,i ) is a pre-defined transformation function for pairs ( z ,x i ). In the simplest case it can be the count of signals z sent to x i in the given time frame.

This model can be seen as a generalization of many ex-isting supervised learning and graph-based methods. With q  X  1, the model goes back to standard supervised learning with summarization features from the bipartite graphs, as we discussed in Section 4.1. If K = 1 and we have no con-stant features, i.e., x i  X  z j  X  0, the model is an extension of the label propagation approach [24], where any label (of p is first propagated to the other side of the bipartite graph (to q j  X  X ), and then propagated back (to update all p i  X  X ). If we remove the ground truth labels and make this an un-supervised learning problem, the model is an extension of the well-known HITS algorithm [11] to bipartite graphs, in which p i and q j can be thought of as the authority and hub scores, respectively.

For learning, we are given ground truth labels for the p -score, and need to estimate W = { w pc , { w pk } ,w qc , { w (with parameter regularizations). Instead of directly opti-mizing the problem which is non-convex, in this paper we present an iterative approach and introduce an intertwined elastic net solver to solve the problem. The iterative al-gorithm is shown in Algorithm 1. As a starting point we initialize the q -score by fixing w qc  X  w qk  X  1. Then we solve an optimization problem for w pc and w pk by fixing q scores. This can be done exactly the same way as what we discussed in Section 4.1. After that we propagate p i and q scores throughout the entire network by iterating equations (2) and (1), with fixed model parameters W . Note that the unlabeled x i  X  X  within X will also get propagated p i scores. We iterate until we reach a stable state of p i and q j scores across the entire network. Then we repeat the process of optimizing p i and q j separately for the respective parame-ters, and propagating the labels through the network with the learned parameters. In Step 6 where we optimize the q scores, since we do not have ground truth labels for q j  X  X , we take a heuristic approach and label the top 20% percentile as +1 and bottom 20% percentile as  X  1. From our experiments we see the results and convergence rate are not sensitive to the specific percentile choice. The algorithm typically con-verges within 20 iterations from our experience.
 Algorithm 1 The Bipartite Graph Learning algorithm 1: Initialization: w pc = w qc = 1 ,w pk = w qk = 1 ,  X  k . 2: Compute q j using (2),  X  j . 3: ( Optimization ) Solve elastic net problem in (1) for w 4: ( Propagation ) Iterate (2) and (1) till convergence with 5: repeat 6: ( Optimization ) Solve (2) for w qc and w qk ,  X  k . 7: ( Optimization ) Solve (1) for w pc and w pk ,  X  k . 8: ( Propagation ) Iterate (2) and (1) till convergence 9: until convergence For the results we show in this paper, we collected all LinkedIn network data over the calendar year of 2015. The ground truth was defined based on Section 3.3 with this time frame, and all the feature groups defined in Section 3.4 were captured for this time frame. There were around 400M members in the pipeline, and the total number of signals (e.g., profile views) for most of the graphs is in the hun-dreds of millions. For learning and parameter estimation, we leveraged our internal Hadoop infrastructure at LinkedIn for distributed learning.
For offline evaluation we randomly split the LinkedIn mem-ber base into training (70%) and testing (30%). Based on the ground truth definition in Section 3.3, we assign a (+1/0/-1) label to each member based on two pre-selected thresholds T + and T  X  : For the graph summarization approach, we ignored the mem-bers who have label 0 to remove noisy data. For bipartite graph learning approach, we only used members with labels (+1 /  X  1) in each round of elastic net training for LDMS (Step 7 in Algorithm 1), but let the labels propagate to the other members throughout the iterations (in all propagation steps).
For offline evaluation we need to compare the ranked list of decision makers from the algorithm with that from the ground truth definition. We are more interested in the rela-tive ranking of members rather than the absolute predictive scores. Therefore we chose NDCG (normalized discounted cumulative gain) and Kendall X  X   X  with our own adaptions.
NDCG is widely used in the Learning-To-Rank literature [1, 3] to measure ranking performance. For a ranked list and position k , NDCG @ k is the ratio of DCG @ k to the ideal DCG @ k , where the latter is obtained had the list been sorted by the ground truth label. DCG @ k is formally given by: which captures the importance of finding the correct order-ing among the top ranked decision makers. Since the ranked list is very long in our case, we chose various k position from 10 all the way to 1 , 000 , 000. Note that we have only one very long ranked list to evaluate, unlike the typical search sce-nario that multiple search sessions contribute to the NDCG metric. The gain function rel ( r ) is defined by binning the ground truth label into different buckets.

Kendall X  X   X  is a standard way of measuring correlation, which has also been extensively used in the literature of identifying the most influential people [15, 16, 19] in order to compare the ranking lists of different algorithms. Formally, it is defined as: at position k , where # pairs represents the number of pairs. A pair of members are concordant if they are ranked the same way in the predictive algorithm and the ground truth, and are discordant if they are not. Note that unlike NDCG which is between 0 and 1,  X  ( k ) is between -1 (i.e., perfect disagreement) and 1 (i.e., perfect agreement). One key dif-ference of Kendall X  X   X  from NDCG is that in Kendall X  X   X  each member pair has the same weight as opposed to a dis-counted weighting scheme in NDCG. In our experiments we compute  X  ( k ) for k between 10 and 10,000 to measure the metrics at different scales.
The performance of the two approaches described in Sec-tions 4.1 and 4.2 is shown in Table 1 and Table 2. First of all, both approaches performed very well for the LDMS ranking problem. Between these two methods, we can see that the bipartite graph learning approach outperformed the graph summarization approach in terms of NDCG for all list sizes. For Kendall X  X   X  , the results show that the graph summa-rization approach had better Kendall X  X   X  than the bipartite graph learning method for small list sizes (10  X  500), but was inferior to bipartite graph learning method for large list sizes (1 , 000  X  10 , 000). As we are more interested in how the model would perform with a reasonably large amount of member base for the decision maker ranking, the bipartite graph learning approach is superior overall. Also keep in mind that even a small improvement in these two metrics will typically lead to significant improvement in downstream applications. We will cover one such case in Section 6.
One reason why the improvement tended to be small is that the inMail graph features are more important from both approaches due to the fact that the ground truth defi-nition also leveraged the inMail information. The additional improvements over the graph summarization approach from the bipartite graph learning approach is significant in that it shows a bootstrap from the basic graph summaries with the help of the LSCS score for the sales professionals will lead to a better ranking result overall. We also get the side-benefit of having a ranking among the sales professionals, which by itself has many downstream applications. The details of this are beyond the scope of this paper.
In Tables 1 and 2, we used all the social graphs we have introduced in Section 3.4. In this subsection we evaluate how much each social graph contributes to the overall per-formance on top of the inMail graph. In Figure 3, we com-pare NDCG and Kendall X  X   X  results for the following graph configurations: We can see that in the majority of the cases the addition of more graphs helps improve the performance when K is reasonably large. This agrees with our intuition that consid-ering more social graphs leads to a better ranking of LDMS among decision makers, and also stronger signal for the strength of the relationship between a decision maker and a sales professional. The additional social graphs not only
Kendall X  X  tau resolved the sparsity problem we mentioned in Section 3.3.3, but also improved the overall performance.
Last but certainly not the least, we plot the histograms of the LDMS score for members and LSCS scores for sales professionals in Figures 4 for the bipartite graph learning approach. The LDMS score for the graph summarization approach follow a similar pattern. We want to highlight that the two scores behave in a totally different way. LDMS scores follow a power law distribution, where the majority of people have scores close to 0. This agrees with our intuition that decision makers are a small percentages of the member base. On the other hand, LSCS scores follow a normal distri-bution, with the majority of sales professionals around 0 . 5. This indicates that the majority of sales professionals per-form neutrally, with some distinguished and some not very experienced. This is also intuitive and can be supported by various reports [4, 6].
One key component of social prospecting is to identify people with influence in the sales process. This is one of the core components of the LinkedIn Sales Navigator prod-uct. We discuss some of the applications of LDMS in this section, all of which are currently running live on the Sales Navigator product. On the offline side, the aforementioned offline training algorithms are computed weekly on our in-ternal Hadoop infrastructure. Once it is completed, both versions of the LDMS scores are pushed to a key-value store for online consumption.
Search is one of the key building blocks of Sales Naviga-tor. We have integrated the LDMS score into Sales Nav-igator Search to allow the users to find decision makers faster, which differentiates Sales Navigator search to the LinkedIn.com search (see Figure 1(a)). We first investi-gated the integration performance offline using the NDCG metric, for which we wanted to test whether the LDMS-enabled search ranking is better than the baseline model (which was already fine-tuned with years of effort). Note this is the NDCG metric on search rankings, not on LDMS ranking as we presented in Section 5. The baseline NDCG performance was 67.3%, LDMS score from the graph sum-marization approach yielded 68.6%, and the LDMS from the bipartite graph learning approach yielded 69.8%. This seem-ingly small improvement on offline NDCG turns out to have a significant impact on online search metrics. Compared to the baseline search metrics, the A/B test for the graph sum-marization approach has shown 4.5% improvement on lead saves from search, which is the key metric for Sales Navi-gator search. The A/B test for the bipartite graph learning over the graph summarization approach has shown an addi-tional 10.6% improvement on lead saves from search. These metric improvements are the key drivers of improving the Sales Navigator ecosystem.
Lead recommendation module in Sales Navigator recom-mends potential leads to the user based on the decision making power those individuals have and the user X  X  past activities on LinkedIn and Sales Navigator, such as profile views, lead saves, and the specified sales preferences. See Figure 1(b) for lead recommendation module on the com-pany page. In the simplest implementation, it is extracted from the top decision makers for the specific company and then filtered by the users activities and their sales prefer-ences. This is a new module that was recently launched, and was made available because of the LDMS score. This is also one of the differentiating factors of the Sales Navigator company page compared to LinkedIn.com. So far we are seeing that this module has the largest user engagement on the company page.
Another LDMS application is on the Sales Navigator In-sights module, which is a feed system that aims to keep the users informed about latest updates on leads and com-panies they care about. This includs job changes, article shares, mentions in the news, company updates, etc. LDMS is leveraged to boost rankings of those updates from key decision makers. In this paper we presented LDMS, the LinkedIn Decision Maker Score, to capture the ability to make or influence a buying decision for each of the 400M+ LinkedIn member. We proposed two learning approaches to tackle this problem, which are able to leverage both the graph information and the contextual information on the vertices, deal with small amount of labels on the graph, and handle heterogeneous graphs among different types of vertices. Although the ap-proaches were presented in the LinkedIn context, they are general methods and can be applied to other social network settings.

Within LinkedIn Sales Navigator, this score is used in re-fining search ranking, improving lead recommendations and providing additional insights about decision maker activity on LinkedIn. More broadly for LinkedIn, we are building upon this work to do more holistic optimization to improve overall LinkedIn experience for key decision makers across all enterprise products. [1] S. Boyd, C. Cortes, M. Mohri, and A. Radovanovic. [2] S. Brin and L. Page. The anatomy of a large-scale [3] O. Chapelle and Y. Chang. Yahoo! learning to rank [4] T. Connor. 91 Mistakes Smart Salespeople Make . [5] B. A. Duncan and C. P. Elkan. Probabilistic modeling [6] J. J. Fox. Secrets of Great Rainmakers: The Keys to [7] Z. Gy  X  ongyi, H. Garcia-Molina, and J. Pedersen. [8] T. Haveliwala, S. Kamvar, and G. Jeh. An analytical [9] T. H. Haveliwala. Topic-sensitive pagerank. In [10] A. B. Karl Schmidt, Brent Adamson. Making the [11] J. M. Kleinberg. Authoritative sources in a [12] D. Kurlan. Top 4 reasons salespeople struggle to reach [13] L. Liu, J. Tang, J. Han, M. Jiang, and S. Yang. [14] Y. Liu, B. Gao, T.-Y. Liu, Y. Zhang, Z. Ma, S. He, [15] Q. Meng and P. J. Kennedy. Discovering influential [16] A. Pal and S. Counts. Identifying topical authorities [17] M. Richardson and P. Domingos. The intelligent [18] D. Saez-Trumper, G. Comarela, V. Almeida, [19] J. Weng, E.-P. Lim, J. Jiang, and Q. He. Twitterrank: [20] D. Zhou, O. Bousquet, T. N. Lal, J. Weston, and [21] D. Zhou, T. Hofmann, and B. Sch  X  olkopf.
 [22] D. Zhou, J. Huang, and B. Sch  X  olkopf. Learning from [23] D. Zhou, S. Orshanskiy, H. Zha, C. L. Giles, et al. [24] X. Zhu, Z. Ghahramani, and J. Lafferty.
 [25] H. Zou and T. Hastie. Regularization and variable 67(2):301 X 320, 2005.
