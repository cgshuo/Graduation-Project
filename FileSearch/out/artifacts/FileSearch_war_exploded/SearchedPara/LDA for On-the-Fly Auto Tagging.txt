 In this paper, we propose a method for automatic tagging sparse and short textual resources. In the presence of a new resource, our method creates an ad hoc corpus of related re-sources, then applies Latent Dirichlet Allocation (LDA) to elicit latent topics for the resource and the associated cor-pus. This is done in order to automatically tag the resource based on the most likely tags derived from the latent topics identified. We evaluate our method, using an o ffl ine analy-sis on publicly available BibSonomy dataset and an online study, showing its e ff ectiveness.

Tagging has proven to be an intuitive and flexible Web 2.0 mechanism to enhance the users X  X  online experience. Tags are capable of facilitating search, easing navigation (e.g., tag clouds), improving personalization in collaborative tag recommendations and across disparate media types.

An important prerequisite for realizing the benefit of tags, is that a resource actually has at least one tag associated with it. When a resource has no associated tags or users, a collaborative tagging recommender can not provide a rec-ommendation  X  the cold start problem.

One of the methods used to address the cold start problem is automatic tagging. State of the art work in this area re-lies upon latent data models to make explicit, some hidden, underlying  X  X ontext X .

We propose  X   X  TaggingLDA : an approach in which an un-tagged item is annotated by exploiting the content from sim-ilar resources found outside the boundaries of a single site.
Consider a folksonomy as a four-tuple, F := ( U, T, R, Y )[7], where:
The set of all tags that user u  X  U has assigned to resource r  X  R is defined as T ( u, r ):= { t  X  T | ( u, t, r )  X  Y } and the set of all posts of the folksonomy as P := { ( u, T ( u, r ) ,r ) | u  X  U, r  X  R, T ( u, r ) =  X  } .

The goal of automatic tagging consists of automatically annotating a given resource r  X  R ,withasetoftags T ( SY S, r )  X  T , where SY S  X  U is a special user representing the sys-tem. Consider the scenario of a Web 2.0 Social Information System that analyses news headlines from RSS feeds and from micro blogging data streams. The system automati-cally annotates resources to improve navigation, searching, and serendipitous discovery of related resources.

As we see in Figure 1, the system is provided whith just the title of some breaking news article, or an entity(e.g, per-sons, product names, places, etc.) identified in a microblog-ging post or tweet 1 : Will New Internet Domain Names Change http://twitter.com/ the Web? . This is a novel resource, not present in the sys-tem X  X  database and without tag annotations. Using an In-ternet search engine we retrieve the titles and snippets of similar resources, and together with the title of the resource, we build a corpus from which a LDA-based method will ex-tract a list of tags to recommend.
Latent Dirichlet Allocation (LDA) [2] is a generative prob-abilistic model for collections of discrete data such as text corpora. The basic idea is that documents are represented as random mixtures over latent topics, where each topic is characterized by a distribution over terms.

Each document is generated by picking a distribution over topics, and given this distribution, picking the topic of each specific term. Then, terms are generated given their top-ics. We consider that the documents correspond to resources r  X  R . When a new resource without tags, needs to be an-notated automatically by the system, i.e., by user SY S  X  U , we can exploit r  X  X  textual content information or metadata to first, associate it to a collection of  X  X imilar X  resources, i.e., a specific corpus for the resource, and then discover the la-tent topics that generate them.
We use the probability distribution assigned by LDA on to the latent topics identified, which indicates the contribution of each topic to the overall collection, to guide our selection of tags from the most relevant topics. Furthermore, LDA also assigns a probability distribution over the terms within a latent topic. We exploit this distribution to rank the terms in a particular topic and use the top ones as candidate tags for annotations.

A LDA model is created on-the-fly for the resource and the associated similar documents, and it is discarded after the list of tag annotations is inferred.
The concrete realization of  X  -TaggingLDA used in our ex-periments is implemented in Java. The corpus builder (Fig-ure 2) is based on the search results obtained by querying Yahoo! X  X  open search web services platform (BOSS) 2 . The ti-tles and short text summaries (snippets) of the top-10 results returned are used to create ten di ff erent textual documents. The final ad hoc corpus for the resource consists of these and the textual content of the resource. Then, by applying http://developer.yahoo.com/search/boss/ LDA on this corpus we extract the desired number of latent topics, and from them, the needed tags are inferred.
We use the LDA with Gibbs sampling implementation provided by the Machine Learning for Language Toolkit (MALLET) [10].
To evaluate the efectiveness of our approach, the problem of automatic tagging is cast as a recommender system task.
We evaluate our  X  -TaggingLDA method on a BibSonomy dataset from [3]. This dataset is almost a complete dump of BibSonomy, i.e., all users, resources (publication references and bookmarks) and tags publicly available until December 31 st , 2008. All tags are lowercased and a cleansing process was applied to the data.

The characteristics of the dataset are:
There are two kind of resources: bookmarks and bibtex records . To use as textual resources we extract the url and description available from bookmarks and the follow-ing fields from bibtex entries: author, editor, title, abstract, journal, booktitle, notes and description.
We compare the performance of our method against two baselines. The first one ( baselineM P ), relies on the most specific tags of a resource. For a given user u  X  U ,agiven resource r  X  R , and some n  X  N the top-n most popular tags by resource are given by: where, Y t,r := Y  X  ( U  X  { t }  X  { r } ), for t  X  T and r  X  R , which corresponds to the frequency of tag assignments on r having the tag t . When resources have just a few number or zero tag assignments, we complement the set with the most popular tags of the folksonomy : where, Y t is the set of all tag assigments having tag t  X  T , and is defined as Y t := Y  X  ( U  X  { t }  X  R ).

The second baseline corresponds to a LDA-based tag rec-ommender introduced in [9] and evaluated on the same datasets and splits as ours in [8], the values of their evaluation on the corresponding test splits are reported here as baseline and are identified as baselineLDA .
For the evaluation, we used the test data splits provided also by [3]. For a given user u  X  U and a given resource r  X  R , the test data consists of a set of posts without tag assignments, i.e., P test := { ( u, S, r ) | u  X  U, r  X  R, S =  X  } . The system has to compute the set of tags for this posts S = T ( u, r ) to complete the tag assignments. Some statistics about the test data splits are presented as follows:
In the evaluation, the list of recommedations consist of five di ff erent tags, i.e., | T ( u, r ) | = 5. The number of iterations of the underlying LDA algorithm is set to 100.

As performance measures we use precision and recall and f1-measure (f1m) which are standard in such scenarios [4] for each post ( u, T ( u, r ) ,r ) as defined above. We then average these values over all posts in the given set and compute the f1-measure:
We deployed our implementation as a recommender sys-tem on the BibSonomy recommedation framework according the guidelines described in [3, 6].

The online evaluation took place from July 27 th ,2009, until September 1 st , 2009. More than 200 users received recommendations. The recommendations consisted of a list of 5 tags. The number of posts for we delivered tag recom-mendations is 11,102. For the online evaluation, we set the LDA parameter to produce two general topics and fixed the number of iterations to 50.
The behavior of our method varying the number of top-ics( | Z | = 2, 4, 8, 16, 32) is shown in Figure 3a. As can be seen in the figure, performance decreases with the LDA topic size. A solution with few topics typically will generally re-sult in broad topics whereas a solution with too many topics will result in uninterpretable topics that pick out idiosyn-cratic tags. The results, on the datasets explored, suggest that such broad topics have higher chance to produce tags general enough to explain the limited document collection, leading to a higher recall and precision.
The prediction quality of  X  -TaggingLDA with two gen-eral topics is clearly superior to the one of the baselines (Table 1, Figure 3b) achieving a f1m@5= 15 . 43% (i.e., f1m evaluating 5 tags) . Given the high number of unseen re-sources in this dataset, a solution based on relational infor-mation only, such as the most popular tags by resource, is ex-pected not to perform well, in this case, the baselineMP just achieves a of f1m@5= 3 . 5%. Surprisingly, the LDA baseline method just achieves a f1m@5 of only 9.8%. This can be ex-plained on how this method represents the resources of the system. Each resource is considered as a bag of tags , without exploiting any content feature. A LDA model is built using the whole corpus of available resources, i.e., bag of tags, in the training set, the model is then applied on test resources to infer the tag recommendations. For unseen resources, i.e., without tags, the method fails to produce a suitable repre-sentation and performs suboptimal in this, more realistic, sparse dataset.
In the online setting, the average time period the recom-mender needs for delivering a list of tag recommendations is 1630.58 milliseconds 3 The results obtained during the online evaluation are shown in Table 2:
In this work, we present an approach to addressing the dynamics associated with online environments, where novel items appear rapidly, using probabilistic topic models, in specific, Latent Dirichlet Allocation. We show the ability of our method,  X  -TaggingLDA , to enrich sparse and limited textual information by means of exploiting the resource re-dundancy and latent topic overlap between similar resources found in an auxiliary domain.

We empirically evaluate, both o ffl ine and online, the e ff ec-tiveness of our approach addressing the cold start problem on a collaborative tagging recommender scenario.

The online deployment of our method demostrates its ef-ficiency and scalability delivering high quality recommenda-tions in real time, without requiring any expensive o ffl ine model computation or updates. We believe that our ap-proach would be ideally suited as part of a complementary solution for bootstrapping Web 2.0 social information sys-tems.

As future work we intend to evaluate how the tags we sug-gest can help with regard to recommending resources to the users. We plan to evaluate our approach on items that are not textual like photos, video, music and other multimedia resources using the metadata. Early results in this direction suggest this to be challenging not only given the sparseness
The results presented in this work ignore any possible time-outs in the process. of such metadata, but the di ffi culty with which topics can be found, even after the enrichment from an auxillary domain.
Latent data models have been used to expose some hidden stucture or  X  X ontext X  to suggest tags for enhanced informa-tion access and collaborative tag recommendations. By con-text we refer to some meaningful aggregation of resources such as: association rules [5] or user/system defined clus-ters[1, 12]. In each of these cases, properties of aggregated resources increase overlap, which can be exploited to derive tag information about the resource on the Web.

Latent approaches treat the automatic suggestion of tags by relying upon dimensionality reduction: such as Latent Dirichet Allocation. In [9, 8] resources annotated by many users and thus having a relatively stable and complete tag set are exploited to overcome the cold start problem. They build an LDA model from tags which have been previously assigned by users. In this way, a resource in the system is represented with tags from topics discovered by LDA. For a new resource with few or no annotations, they expand the latent topic representation with the top tags of each latent topic. The work of [11] external knowledge from a large, so called X  X niversal Dataset X  X s used to address textual sparseness in the classification of short segments of text such as chat messages, or news feeds. They learn a LDA topic model from both a small set of labeled training data and the universal dataset. The model is then exploited to discover a set of latent topics which are subsequently used as the target in a multi-class classifier for the original sparse text.
In contrast to model based systems, instance based ap-proaches do the association between users and annotations on-the-fly. For example, in Cross-Tagging [13], information accesses is enhanced for a non-folksonomy user, such as a music blogger, by exploiting the tag assertions made by (sim-ilar) users of folksonomies. The overlap between the mention of tracks in music a blog and the tracks in LastFM is de-termined. The user-resource-tag triples are modeled with a tensor; exploiting the underlying latent semantic structure in the tensor to form multi-way correlations between users, tags, and resources.
 Acknowledgments: This work was funded in part by the Programme Al  X  an, the European Union Programme of High Level Scholarships for Latin America, scholarship no. (E07D400591SV) and the the EU Project FP7 -248984.
