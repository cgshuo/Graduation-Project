 Collin F. Baker Abstract This paper will focus on recent and near-term future developments at FrameNet (FN) and the interoperability issues they raise. We begin by discussing the current state of the Berkeley FN database including major changes in the data format for the latest data release. We then briefly review two recent local projects,  X  X  X apid Vanguarding X  X , which has created a new interface for the frame and lexical unit definition process based on the Word Sketch Engine of Kilgarriff et al. ( 2004 ), and  X  X  X eyond the Core X  X , which has developed tools for annotating constructions, and created a sample  X  X  X onstruction X  X  of especially  X  X  X nteresting X  X  constructions which are neither simply lexical nor easy for the standard parsers to parse. We also cover two current collaborations, FN X  X  part in the development of the manually annotated subcorpus of the American National Corpus, and a pilot study on aligning WordNet and FrameNet, to exploit the complementary strengths of these quite different resources. We discuss FN-related research on Spanish, Japanese, German (SALSA), Chinese and other languages, and the language-independence of frames, along with interesting FN-related work by others, and a sketch of a large group of image-schematic frames which are now being added to FN. We close with some ideas about how FrameNet can be opened up, to allow broader participation in the development process without losing precision and coherence, including a small-scale study on acquiring data for FN using Amazon X  X  Mechanical Turk crowd-sourcing system.
 Keywords FrameNet Frame semantics Lexical semantics interoperability WordNet Lexicon Corpus Semantic role Thematic role Lexical resource Crowdsourcing 1 The FrameNet database FrameNet (hereafter FN) is a lexicon of English which is intended to be both human-and machine-readable, based on the theory of frame semantics (Fillmore 1982 ), which asserts that the meanings of many words are best understood in terms of an entire situation and the participants and props involved in it; the situation is called a frame , and the participant roles are called frame elements (FEs) . The link between a lemma and a frame is a lexical unit ( LU ), which is roughly equivalent to a word sense in a conventional dictionary, or to a WordNet (WN) sense (although these three types of resource are designed on different principles and so make different choices about dividing senses). Words of all parts of speech can evoke frames, although the FN database contains mainly nouns, verbs, and adjectives; frames can represent events, relations, states, and even entities. Many frames contain LUs of several parts of speech.

Instances of the lexical units are manually annotated, marking the frame evoking expression ( FEE ), which may be more than a single word, and the occurrence (or in some cases, non-occurrence 1 of frame elements in each sentence. Then reports are generated showing all the possible valences of each lexical unit.

The FrameNet database, as of July 20, 2012, contained 1,043 lexical semantic frames, covering 12,601 lexical units, or roughly 12 lexical units per frame. The frames are linked to each other with a variety of frame relations, including several types of inheritance, and a further 116 non-lexical frames have been created to fill out the frame hierarchy. The lexical frames contain 10,077 frame elements (FEs), or about 10 per frame. 2 There are 193,846 annotated instances of lexical units (LUs) in the database. Roughly 85 % of these are  X  X  X exicographic X  X  annotation, in which only one LU is annotated per sentence, and roughly 20 sentences have been annotated for each LU, selected so as to show the full range of valences for the LU. The other 14 % of the instances are in running text which is annotated for all the LUs in each sentence, called  X  X  X ull-text X  X  annotation. The sentences for the lexicographic annotation are drawn from the British National Corpus and the American National Corpus (Ide et al. 2002 ); those for full-text annotation are drawn from several sources, including the American National Corpus, the nuclear threat initiative website ( http://www.nti.org ), and newspaper texts. The database is stored in MySQL, with annotation carried out using a Java GUI client connecting via an application server implemented in JBOSS.
The frames are linked to each other with a variety of frame relations, which allow us to:  X  Create frames at different levels of generality and express the relation between  X  Represent complex events involving more than one frame, via subevent and  X  Represent other regular patterns of relations between frames, such as Causative-
Multiple inheritance is common in FN; for example, the Attack frame inherits from the Intentionally affect frame, meaning that it represents the action of a sentient agent on a patient, with the intention of affecting the patient. But it also has a using relation from the Hostile encounter frame, meaning that it is an action that takes place between two opposing sides in a conflict. There are accompanying FE-to-FE relations for each frame relation as shown by the dotted lines in Fig. 1 :
In this case, the Attack frame has FEs A SSAILANT and V ICTIM ; the A SSAILANT is bound to the A GENT and the V ICTIM to the P ATIENT of the Intentionally_affect frame via Inheritance; the A SSAILANT and V ICTIM are also bound to the FEs S IDE 1 and S IDE 2 of Hostile_encounter via Using. Collectively, these relations constitute a repre-sentation of the notion that an attack is an intentional action performed by an agent on one side of a conflict on a patient on the other side of the conflict; clearly this is not the whole meaning of the concept of attack, but it is a fairly precise specification of a useful part of it.

For each FE instantiated, in addition to the FE label itself, two coterminous labels are also added to the text, giving the phrase type in which the FE is realized (NP, PP, etc.) and the grammatical function (a.k.a grammatical relation) between the FE and the FEE. Then various reports are generated from this data; one of them, the lexical entry report, includes a manually-entered definition of the LU and shows all the possible syntactic-semantic combinations ( valences ) of each lexical unit, based on the annotated triples of FE, phrase type and grammatical function. The examples which are manually annotated for lexicographic purposes are deliberately selected to exemplify all the lexicographically relevant patterns of FE realization, but not alternations which apply to very broad classes of lexemes. For example, FN annotators try to exemplify the dative alternation, since this is a lexically specific property differing between even semantically similar verbs (e.g. give and donate ), but there is no effort to include passive examples in the annotation of every transitive verb, since virtually all of them can occur in passive form. 3 We assume that a good NLP system should be able to recognize passive VPs and the regular changes in grammatical relations that go with them. In this respect, FN lexicographic annotation is different from corpus-based annotation from other projects; some common variants are underrepresented in FN, while some relatively rare valence patterns are exemplified at least once or twice, even in a set of only 15 or 20 examples. The full-text annotation portion of FN is much closer to other corpus-based projects in that it reflects the frequency of words in running text, although it tends to have more detailed annotation of predictors (of all parts of speech). 1.1 Importing text The importation of sentences into the database involves first converting the raw text into XML, then inserting it into the appropriate tables. Since the requirements for lexicographic annotation and full-text annotation are different, these processes involve different steps, although some of the tools used are the same.

We have encountered several low-level encoding issues: we began work with an early version of the BNC and continue to use it for lexicographic work, which results in some problems with incompatibility that we have not completely solved. The original encoding of the BNC was SGML, rather than XML, and ISO-8859-1 rather than Unicode. When retrieving example sentences for lexicographic annotation, we retrieve them with the BNC (CLAWS) POS tags and in ISO-8859-1 encoding. This was causing problems, as we attempt to convert everything to Unicode. We have recently been able to clean up most of these problems and to convert our database to UTF-8 Unicode; a collaborator at DAC, Inc., Peter David, has assisted this work by matching sentences from the FN database with those in the current, UTF-8 compliant, commercial release of the BNC.
 The full texts come from a variety of sources. Those from the first release of the ANC were in UTF-16; we converted these to UTF-8 for importing, since our MySQL database and several other pieces of software are set up for UTF-8. There are, however, a small proportion of non-Unicode characters in some of the ANC texts; so far there have been so few of these that we have been correcting them by hand, but we hope to find a more reliable way of dealing with them automatically. The current version of the ANC is in UTF-8, which is becoming the standard encoding for many purposes. 1.2 Data release 1.5 We set up a new reporting and data release system a few years ago, and put out Release 1.5 in the fall of 2010. The previous data release (R 1.3) contained both XML and HTML copies of all the data files, so that they would be both machine-and human-readable; we were also producing versions of the XML with and without part of speech (POS) labels. Since there are more than 10,000 lexical units, each with its own file, with 1 HTML and 2 XML files for each, this involved more than 30,000 files, which required a long time to generate and had to be kept in sync across the different formats. We also produced different versions of the HTML for use on the public website, for internal use, and for the data distribution.
 The new system creates just one XML format for all uses; a set of new XSL/ Javascript scripts allows the XML to be viewed by standard browsers. Even the top-level index files for selecting frames, lexical units, and full texts are in XML with corresponding XSL scripts. One advantage is that the process of exporting the release data is much simpler; another advantage is that we can build considerable functionality into the scripts, so that browsing the data and navigating among the various reports is fully available to anyone who downloads the data release, including interactive browsing of the valance tables and full-text annotation. We have also moved from DTDs to XML schemas for definition and validation of the XML syntax. Another important change is the licensing terms. Previous releases were distributed under a FrameNet-specific license, which required commercial users to pay a fee, but allowed unlimited non-commercial use. Release 1.5 is released under a Creative Commons attribution-only license, meaning that there will be no fee for any users, commercial or non-commercial. Since the change in licensing, we have noticed many more requests for the data for commercial purposes; we suspect that previous releases were often being used for commercial purposes without our knowledge.

Many users of the FN data been using it for inferencing or computing entailments, e.g. Burchardt et al. ( 2009 ); Baumgartner and Burchardt ( 2004 ), and several have analyzed shortcomings of FN X  X  logical structure and suggested improvements e.g. Ovchinnikova et al. ( 2010 ), Shen and Lapata ( 2007 ). We hope that FN will prove useful in such efforts and welcome such suggestions, and will attempt to provide the FN data in forms suitable for use in inferencing. In Release 1.3, we also distributed an OWL representation of the frames and frame relations; we also distributed software to convert the XML files into OWL. For Release 1.5, we hope to produce an OWL representation that is closer to the FN XML data. Colleagues at U Trento are also offering to produce a Prolog version of the FN data. A full  X  X  X ntologization X  X  of FrameNet would also require links to a real ontology, such as SUMO (cf. Scheffczyk et al. 2010 ) or DOLCE (Gangemi et al. 2010 ). FrameNet, remains, however, a project grounded in language, and, given a choice between logical consistency and being true to the linguistic facts, FN will tend to do the latter. 1.3 FN frame elements and  X  X  X tandard X  X  semantic/thematic/theta roles FN data users and visitors to our website often ask  X  X  X hat is the relation between the 9,000 ? FEs in the FrameNet database and the eight or ten case roles of Fillmore X  X  early work, e.g. Fillmore ( 1968 )? X  X  The answer is that almost all of the FEs are connected through a series of FE-to-FE links that go along the frame-to-frame hierarchy to high-level frames, such as Event , Action , Intentionally_act , Motion , etc. 4 The FEs in these high-level frames are named A GENT ,T HEME ,S OURCE ,P ATH , G However, this requires traversing the links to find out what case role a given FE belongs to X  X nd there are some FEs that are not linked to high-level frames for all the FEs, such as the Similarity frame, home to LUs such as like .a and resemble .v. Similarity inherits from the frames Gradable_attributes and Reciprocality , but neither of those will supply anything like the traditional case roles, as they are simply not applicable in the Similarity frame. The decision not to link the FEs of Similarity to higher-level FEs is simply a recognition of this fact. 2 Recent projects at ICSI 2.1  X  X  X apid vanguarding X  X  The FrameNet team has completed a project to build new software for the  X  X  X anguarding X  X  portion of our work, that is, the process of defining new frames and their frame elements and determining what lexical units they are evoked by. This can be a very time-consuming process, involving repeated searches of the corpus for each lexical unit. The new tools, modeled on the Word Sketch Engine developed by Adam Kilgarriff and associates (Kilgarriff et al. 2004 ), help to eliminate duplication of effort and allow decisions about an entire group of homonyms or all the senses of a polysemous lemma to be made simultaneously. 2.2 Syntactic constructions  X  X  X eyond the Core X  X  According to the theory of construction grammar, there is only one kind of linguistic object that constitutes what speakers of a language have to learn: the construction, a pairing of a form and a meaning (i.e. a Saussurean sign ). Various degrees of specificity are possible on each side of the construction. The lexical units of FN are simply constructions whose form pole is one or more word-forms, and whose meaning pole is partially represented as a specific semantic frame. In the case of other, non-lexical constructions, such as the subject-predicate construction and the genitive construction, the syntax of the form side is clear, but the meaning evoked is extremely vague.

Many of the  X  X  X nteresting X  X  constructions are partially, but not entirely, lexical and are precisely what cause conventional parsers to fail or give incomplete analyses of sentences such as the following: (1) I can X  X  stand to see, let alone touch, boa constrictors. [This sense of stand requires a modal ( can or could in a negative polarity context).
Let alone functions as a conjunction, but with very specific semantic constraints on the pieces that it joins; this is combined with a Right-node Raising construction. (cf. Fillmore et al. 1988 )] (2) The gifted have a duty to help the less fortunate. ( The ? Adj forms a noun meaning  X  X  X eople who have this quality X  X .) (3) What X  X  this scratch doing on the table top?
The scratch isn X  X  doing anything, and the construction as a whole carries an implication that there X  X  something odd or wrong about the situation (Kay and Fillmore 1999 ).

We have completed a pilot project to document non-lexical constructions, just as the current FrameNet documents the lexical constructions. This means manually annotating examples drawn from corpora, using a set of construction elements ( CEs ), analogously to annotation with frame elements. The FN annotation software has been extended for this purpose, new tables have been added to the database, and a set of XML reports analogous to those for frame annotation will be produced. The intent is to create a  X  X  X onstruction X  X  and a gold standard set of annotation data which can be used to train automatic recognizers for all sorts of constructions, including the  X  X  X nteresting ones X  X  (in other words, to produce construction-aware parsers). Roughly 75 constructions were described in the pilot study, and most were documented by annotating representative examples drawn from corpora or the web. Some of these also evoke frames already described in FN, and so are annotated with regard to both their syntax and their frame semantics; the combination of frame and construction information produces a more complete representation of a sentence.
A particular area of research is constructions related to rates of various kinds, such as ten dollars an hour , 30 m.p.g ., 10 m ./ s 2 , and 1.3 hectares per family . The standard parsers simply analyze such phrases as two adjacent NPs, yet they are clearly members of a family of quite regular constructions based on the underlying notion of a fraction with a numerator and a denominator; an important subtype are expressions of speed, where the denominator is a time expression (cf. recent work by Power and Williams ( 2012 ) on fractions as numerical approximations). Although constructions in general are language specific, it is possible investigate constructions in different languages used to express similar concepts, as in Hasegawa et al. ( 2010 ), a comparative study of constructions for measurement and comparison in English and Japanese. 2.3 FN-WN collaboration: aligning WordNet and FrameNet Many people have noted that WordNet has extensive lexical coverage, but minimal syntactic valence information, whereas FrameNet has a rather limited lexicon, but quite detailed valence information about those lexical units. It seems that there should be a way to align or combine them to produce a new resource with the strengths of both.
Staff at WordNet and FrameNet performed a pilot study of what such an alignment would look like, but since the two lexica were created for quite different purposes and have totally different data structures, the interoperability problems are manifold. WordNet (hereafter WN) is composed of separate hierarchies for each part of speech, with nodes comprising sets of lexemes which are synonymous in certain contexts ( synsets ). In FrameNet, the frames comprise sets of lexical units which may be of different parts of speech, and the frames themselves are the primary locus of the semantics, with the individual LUs as subtypes of the semantics of the frame.
Since WN and FN both contain sets of lemmas grouped by their senses, it is tempting to simply align WN synsets and FN frames. This is at best misleading, since there is no claim that all the LUs in a frame are synonymous, only that they are related to the same sort of event, relation, state, or entity (and share the same number and types of participants). For example, WN has an antonym relation between the verbs praise and criticize ; in FN, both praise and criticize are in the Judgment_communication frame, although criticize is marked with a semantic type label  X  X  X egative_judgment X  X , and praise with  X  X  X ositive_judgment X  X . On the other hand, some types of word-to-word relations in WN are parallel to frame-to-frame relations in FN. For example, in WN the verb pay has give as a hypernym; in FN pay occurs in the Commerce_pay frame, which inherits from the Giving frame, which includes the LU give .

As part of a collaboration with Prof. Christiane Fellbaum of WordNet (WN), we studied in detail several dozen lemmas of medium polysemy in FN and WN, trying to decide, in an ideal world, how many senses they would have in each database and to what extent they would differ. For example, the adjective quiet has six senses in WordNet 3.0, in the following synsets (slightly abridged): 1. quiet : (characterized by an absence or near absence of agitation or activity; 2. quiet : (free of noise or uproar; or making little if any sound;  X  X  X  quiet audience 3. quiet, restrained : (not showy or obtrusive;  X  X  X lothes in quiet good taste X  X ) 4. hushed, muted, subdued, quiet : (in a softened tone;  X  X  X ushed voices X  X ;  X  X  X  quiet 5. placid, quiet, still, tranquil, smooth, unruffled  X  (of a body of water) free from 6. quiet : (of the sun) characterized by a low level of surface phenomena like
Initially, FN had quiet .a in two frames: (1) Volubility , which includes big mouth.n, brusque.a, chatterbox.n, chatty.a, (2) Prominence , along with blatant.a, conspicuous.a, eye-catching.a, flashy.a, of quiet that deal with a low degree of perceptual salience, not constrained to acoustic perception, go into the Prominence frame. The uses (not clearly represented in the WN list) that deal with being quieted, as in I was asked to keep quiet on that sensitive subject , go into the Volubility frame. However, we also decided to create a new frame Sound_level , inheriting from the frame Measur-able_attributes , for the sound perception sense of quiet (as in the WN example  X  X  X  quiet audience at the concert X  X ). A more detailed discussion of WordNet-FrameNet alignment as applied to annotating full texts can be found in Fellbaum and Baker ( 2008 ).

The creation of practical alignments of lexical resources was one of the key requests emerging from a workshop on  X  X  X pgrading FrameNet X  X  held on May 1, 2010, funded by an NSF planning grant (0855271). Since only a small portion of any alignment can be done manually in as much detail as the examples given above, attention is being focused on semi-automatic alignment. Several systems have been built for WN-FN alignment and discussed in conference papers, two of which have made the resulting data freely available: Tonelli and Pighin ( 2009 ) have built a system based mainly on comparing WN glosses with FN frame and LU definitions; unfortunately, in order to connect the WN side with MultiWordNet, so that they could project their results to Italian, they had to align FN Release 1.3 with WN version 1.6, which is many years out of date. Ferra  X  ndez et al. ( 2010 ) have created a system which utilizes the relational structure of the semantic  X  X  X eighborhoods X  X  around the lemmas on each side to determine similarity of senses; their results on precision and recall on a small manually-aligned gold standard are slightly better than those of Tonelli and Pighin ( 2009 ).

It should be understood that it would be pointless to attempt to duplicate in FN the rich hierarchy of nouns which already exists in WN. For example, the hierarchy of animals in WN contains a very detailed taxonomy which provides valuable information for making inferences, but the frame semantics of all animals is rather similar, so it would not be useful to proliferate frames in this domain. Instead, it may be possible to use some very general  X  X  X overing X  X  frames to guide semantic parsing. For example in the phrase a fledgling wood thrush , we would like to be able to recognize fledgling as indicating the maturation stage, and wood thrush as a compound denoting a subtype of thrush. The FE Maturation_stage might be part of a very general frame applying to all animals. 6 3 Current projects at ICSI 3.1 FN-MASC collaboration FrameNet served as a subcontractor in the creation of the multiply annotated subcorpus [MASC, Ide et al. ( 2010 ); Passonneau et al. ( 2012 )] of the American National Corpus. A portion of the MASC is being handled by the usual FN full-text annotation method, importing the documents one by one and annotating every FEE.
Other sentences are being annotated by a variant of the lexicographic annotation method in which the FN team annotate roughly 100 sentences for each lemma, creating whatever frames or LUs are needed in the process. 7 This differs from the usual FN practice of progressing frame by frame, and is closer the the traditional lexicographer X  X  approach of defining all the sense of one headword before moving on to the next. It also means that the frequencies of the annotated senses will be closer to their frequencies in running text.

A number of interoperability issues have had to be solved for this task. For example, the FN annotation software is set up such that, during the import process, all punctuation is separated from the words it occurs with by inserting a space. This very basic kind of tokenization simplifies a lot of manual annotation steps. But it also causes the pointers from the FN labels to the text to be offset from the original text positions by a few bytes here and there, depending on where the punctuation appears. The ANC staff have had to post-process the FN data to remove the offsets in order to integrate the FN data into the MASC. Eventually, it may be necessary to rewrite the FN annotation software so that it will not depend on space-separated tokens, but will use the stand-off tokenization of the ANC. This would also have advantages for enclitic pronouns in languages like Spanish, not to mention languages normally written without spaces between words, such as Chinese and Japanese. 8 In the course of this project, we have used the GATE NLP system to test the speed and accuracy of various components of our pipeline, but we are not using GATE to do the importing interactively.

We completed all the senses (LUs) of roughly 110 lemmas (nouns, verbs and adjectives) by the end of this project. Some of the lemmas being annotated had already been studied in the WN-FN alignment pilot, and the data from this project allows direct comparisons, between the FrameNet annotations and the WordNet sense (synset) annotations of the same sentences, which were created at Vassar and Columbia; see Passonneau et al. ( 2012 ), and (de Melo et al. 2012 ) for preliminary results of this research.

We also hope to use existing automatic semantic role labeling (ASRL) systems created by other researchers to label larger amounts of MASC/ANC text. The first publicly available ASRL system was Shalmaneser (Erk and Pado  X  ( 2006 ), http://www.coli.uni-saarland.de/projects/salsa/shal ), created by Katrin Erk and Sebastian Pado  X  of the SALSA project (discussed below). It comes with pre-trained parameter sets for English and German; the English training was accomplished by first converting the FN annotation XML (LU XML files) to SALSA/TIGER XML.
 This was followed by the LTH system developed at Lund University for SemEval 2007 (Johansson and Nugues 2007 ) and the SEMAPHOR system of Das et al. ( 2010 ), the most accurate ASRL currently available to us.
The different ASRL systems use different data formats (both for input and output), so some conversion scripts will need to be written to allow us to compare their outputs. The intention is to find cases in which the different systems disagree (or about which they have low confidence in labeling) and to select similar sentences for supplemental annotation, using a version of active learning. We also hope that these two types of semantic annotation (WN and FN) can be used as training data for each other. The FrameNet software has already been modified to allow annotators to browse some ASRL output within the annotation tool, without actually adding it to the FN database. 3.2 Decisive analytics collaboration In January, 2011, the FrameNet team began a collaboration with Decisive Analytics Corporation, working on analyzing texts related to events on the battlefield in Iraq and Afghanistan. Many of the texts have to do with improvised explosive devices (IEDs), ambushes, searching for enemy troops, etc. and we have created a number of frames for events and entities in this domain. Some of the texts are filled with military abbreviations and jargon; in many cases, these are formally defined terms, but others are specialized uses of everyday words, such as Clear the table vs. Clear the area . Both can be treated as instances of the Emptying frame; in both cases the unexpressed T HEME FE can be understood from the context, but the first context suggests dirty dishes as a filler, while the second suggests enemy combatants and/or civilians. Some of more technical terms can be recognized by standard named entity recognition (NER) systems. 3.3 Siemens research collaboration In the autumn of 2011, FrameNet started a short-term pilot collaboration with Siemens Corporate Research, US, to do frame semantic annotation of texts in the medical domain. We are hopeful that Siemens can handle the technical terminology using NER and UMLS categories, while FN can annotate some of the  X  X  X rdinary X  X  expressions that link them, expressing relations such as causation, temporal sequence, elaboration, etc. The combination should lead to a better understanding of the texts than either approach alone. 4 FrameNets across languages Although FrameNet is building a lexicon of English, created in the US, the theory of frame semantics has always presupposed that many frames should be more or less language-independent [Boas ( 2009 )], and the ways in which other languages divide up the world are often taken into account in resolving difficult issues. We are fortunate to have had short-and long-term visitors from many countries, quite a few of whom have been inspired to start similar projects for other languages, and thus become collaborators in the development of a multilingual frame semantics. Some of these are reviewed briefly here; for conciseness, we give URLs of websites containing bibliographies, rather than many references to papers.

The SALSA project , based at Saarland University and DFKI, and under the direction of Prof. Manfred Pinkal, has manually annotated the verbs in German texts, using their own, very graphical annotation software (Erk et al. 2003 ), but still applying the FN semantic frames and FEs so far as possible. ( http://www.coli. uni-saarland.de/projects/salsa )
The text is from the TIGER corpus, a parsed and manually corrected newswire corpus. Where they found no appropriate English frame, they created a  X  X  X roto-frame X  X  (something like PropBank) and simply called the FEs  X  X  X E1 X  X ,  X  X  X E2 X  X , etc. They put out their first data release in the spring of 2008, and have received funding for a second stage of development. The SALSA/TIGER XML format is quite different from any Berkeley FN XML format, as it is closely tied to a parse tree, which must be present for each sentence. In this respect also, their work is like PropBank, since they are depending on the correctness of the parses in a TreeBank which has already been carefully manually validated (and which they themselves helped validate).
 Spanish FrameNet ,( http://gemini.uab.es:9080/SFNsite ), based at Universidad Auto  X  noma de Barcelona, under the direction of Prof. Carlos Subirats, is a lexico-graphic project which follows very closely the model of Berkeley FrameNet, using the same type of database and annotation software. They are even keeping up with version changes in the annotation software. The only software changes they had to make were to a small set of methods that attempts to guess the phrase type and grammatical function of phrases that have been annotated as FEs, since Spanish has different parts of speech and phrase types; these changes have been brought back into the FN software distribution.

Spanish FN is extracting example sentences from their own corpus and formatting them in XML so that they can be imported by the same tools that import English sentences. They were also able to seed their tables of lexemes and word-forms from an existing Spanish lexicon, which greatly speeded up getting started on a lexicon. The Berkeley FrameNet lexicon was seeded in the same way from the CELEX lexicon, giving us roughly 40,000 lexemes whose word-forms we don X  X  have to type in.

As with the SALSA project, the SFN team have found that some LUs in Spanish don X  X  seem to fit into any of the English frames. Unlike SALSA, they are creating new frames and modifying existing frames as they go along, using the FN tools for this purpose. They are also using the FN report software to produce HTML and XML versions of their data, which was made public via their website in June, 2008.
As this data is identical in XML format to the Berkeley FN data, it has been comparatively easy for another of our collaborators, Prof. Hiroaki Sato of Senshu University, Kawasaki, Japan to extend his FrameSQL website ( http://sato.fm. senshu-u.ac.jp/fn2_13/notes/index.html ) to produce comparisons of English and Spanish data, aligned according to a combination of frame identity across languages and translation equivalence between LUs.

Japanese FrameNet ( http://jfn.st.hc.keio.ac.jp/index.html ): This project is the work of a group of scholars at Keio University and University of Tokyo, headed by Prof. Kyoko Ohara. They are using a modified version of the FN software to do annotation, but the changes seem to have been more extensive than for Spanish, because of the greater difference of the Japanese writing system from English. One minor change was to add a separate annotation layer for particles; this proved quite easy, requiring only a new record in a couple of database tables.
 Chinese FrameNet is headed by Profs. Liu Kaiying and Li Ru of Shanxi University Computer Science Department, and a number of graduate students and post-graduates. They began work in 2004, and have built their own annotation software, but are using FrameNet frames to a great extent, concentrating on texts in the domain of tourism within China. As of April, 2010 they had covered 304 frames (roughly 18 of which were created specifically for Chinese), comprising 3,152 LUs, with 20,322 annotated sentences. They are experimenting with ASRL, both rule-based and using Conditional Random Fields (Li et al. 2010 ).

FrameNet Brazil is a new project started in Minas Gerais, Brazil, as part of a collaboration agreement with ICSI ( http://www.framenetbr.ufjf.br ). Prof. Subirats has visited the prospective team members and advised them of his experience in initializing the FN database for a new language; Dr. Tiago Torrent, a member of the FrameNet Brazil team, has visited ICSI and FrameNet team members Michael Ellsworth and Miriam Petruck have taught an intensive course on FrameNet and frame semantics at UFJF. They have created their own corpus and annotation software and have already released some data.

Swedish Framenet : A team at Gothenburg University headed by Lars Borin is building Swedish FrameNet ?? ( http://spraakbanken.gu.se/eng/swefn ), with the intention of covering at least 50,000 LUs following the principles of the Berkeley FN project. This is part of a larger project building a unified set of freely available lexical resources for Swedish.

Italian FrameNet : There is also a new effort to build an Italian FrameNet under the direction of Prof. Alessandro Lenci at the University of Pisa, using techniques very similar to Spanish FrameNet, i.e. annotating with the current Berkeley FN software, but creating in-house a process for importing lexicographic example sentences. They have a copy of the FN database and the software running, have populated the appropriate tables with Italian lexemes and word-forms, and a master X  X  student, Martina Johnson, is works on annotating LUs in the perception domain.

A FN database for Slovenian has also been set up at ICSI (Lo  X  nneker-Rodman et al. 2008 ), and researchers have planned FrameNets in German (separate from but using the results of SALSA), Hebrew (Petruck 2009 ), Hindi, Korean, Uyghur, etc. All of these cross-linguistic FN projects raise the underlying question of how similar the frames of one language are to those of another; our initial impression is that a large portion of frames are indeed substantially the same across many languages, as suggested by the discussion above, although certain systematic differences between languages are also found, which typically require either new frames or additional frame elements in existing frames (Ellsworth et al. 2006 ; Ohara et al. 2006 ; Lo  X  nneker-Rodman and Baker 2009 ).

Some of these projects are exploiting the partial language-independence of the frames, to extend FrameNet to other languages automatically, by projecting the English frames and annotation onto either the lexicon or text or both in the target language, based on parallel corpora and dictionaries; studies of this sort have been done on projecting to German and French (Pado  X  2007 ), Swedish (Johansson and Nugues 2006 ; Borin et al. 2010 ), and Chinese (Chen and Fung 2004 ). While inherently less accurate than manually created FrameNets, this approach can sometimes quickly create a FrameNet in another language for at least some core domains. 5 Toward a more collaborative FN In the long run, it is becoming clear that progress on the FN lexicon will continue to be slow if we continue to depend solely on expert manual annotation. We are investigating various ways of allowing a larger community of people to be involved in the day-to-day work of FrameNet. This is a delicate matter, as we want as wide participation as possible, but we do not want anything to be added which is not coherent with existing data and in accord with the annotation policy.

We want to make it possible for different people to participate in different ways, according to their interests and abilities. This will probably mean that the final decision about what new frames are made and what LUs go in them will come from Berkeley, but that users of the data and the software will be able to influence the direction of development, bring in texts for annotation, and actually do a lot of the annotation work. Exactly how this will be accomplished is under study; we are looking at a variety of models, including the Open Mind project ( http://www. openmind.org ), several data-collection on-line games (e.g. Chamberlain et al. ( 2008 ), a game for collecting coreference annotations), Wikipedia, and the Stanford Encyclopedia of Philosophy ( http://plato.stanford.edu ).
 One model that has been very popular lately is crowd-sourcing, especially, using Amazon.com X  X   X  X  X echanical Turk X  X  (AMT) ( http://www.mturk.com ), to facilitate paying many untrained people (a small amount) for categorization or annotation data; in fact, an entire workshop was held at NAACL 2010 on using AMT to gather linguistic data (Callison-Burch and Dredze 2010 ). Some of this enthusiasm may stem from Snow et al. ( 2008 ) who reported good results on a variety of linguistic data collection tasks; their very positive results on word sense disambiguation, however, were based on a study of a single word, president .n whose sense divisions are relatively clear.

We have recently been testing crowdsourcing for gathering data for FN. We ultimately hope to collect data for annotation in this way, but before one can annotate, one needs to discriminate among different senses of words, so our first experiments have been on word sense discrimination for several polysemous words (chosen from the MASC and WN-FN tasks), using both AMT and another commercial crowd-sourcing system, CrowdFlower ( http://crowdflower.com ). We have been trying to gather responses on items involving some fairly subtle dis-tinctions, such as four of the senses of rip .v distinguished in FN:
However, our results to date have suggested that, while untrained workers can make some of these distinctions, others are quite difficult. For example, we would hope that, unless the sentence explicitly includes a resultative such as to pieces , in two or up , the Damaging sense would be preferred to the Cause to fragment sense, since Damaging does not entail Cause to fragment, but workers often seemed to assume the Cause to fragment reading for sentences out of context. (See Hong and Baker ( 2011 ) for more details.) We also would like to foster greater cooperation in the development of FrameNets in new languages, and to encourage specialists in particular domains to undertake work on the frames and LUs in those areas. As part of our efforts to encourage greater participation, we have restructured the project website and linked to an external social networking site. 6 Conclusion As the FrameNet project has developed over the years, we have repeatedly had to decide between making the effort to update legacy software and data or to start from scratch in some area. We have also been involved in a variety of collaborations, both lexicographic and computational linguistic. Each of these steps has raised specific issues of compatibility, standardization, and interoperability. In this respect, we are not that different from many other projects. In some cases, we may have made mistakes from which others may learn. We are convinced that the NLP field needs standards of cooperation that are higher than the  X  X  X owest common denominator X  X , that facilitate future collaborations, rather than just solve immediate problems. It remains to be seen how this can come about, whether by adoption of formal standards, such as those of the ISO TC 37 SC 4, or by adoption of software systems which enforce protocols, such as GATE and UIMA, or by other means. References
