
Consider spatial data consisting of a set of binary fea-tures taking values over a collection of spatial extents (grid cells). We propose a method that simultaneously nds spa-tial corr elation and featur e co-occurr ence patterns, with-out any par ameter s. In particular , we employ the Minimum Description Length (MDL) principle coupled with a natu-ral way of compr essing regions. This denes what  X good X  means: a featur e co-occurr ence pattern is good, if it helps us better compr ess the set of locations for these featur es. Con ver sely , a spatial corr elation is good, if it helps us bet-ter compr ess the set of featur es in the corr esponding region. Our appr oac h is scalable for lar ge datasets (both number of locations and of featur es). We evaluate our method on both real and synthetic datasets.
In this paper we deal with the problem of nding spa-tial correlation patterns and feature co-occurrence patterns, simultaneously and automatically . For example, consider environmental data where spatial locations correspond to patches (cells in a rectangular grid) and features correspond to species presence information. For each patch and species pair , the observ ed value is either one or zero, depending on whether the particular species was observ ed or not at that patch. In this case, feature co-occurrence patterns would correspond to species co-habitation and spatial correlation patterns would correspond to natural habitats for species groups. Combining the two will generate homogeneous re-gions characterised by a set of species that live in those re-gions. We wish to nd  X good X  patterns of this form simul-taneously and automatically .

Spatial data in this form (binary features over a set of locations) occur naturally in several settings, e.g.: In all these settings, we would lik e to disco ver meaning-ful feature co-occurrence and spatial correlation patterns. Existing methods either disco ver one of the two types of patterns in isolation, or require the user to specify certain parameters or thresholds.

We vie w the problem from the perspecti ve of succinctly summarizing (i.e., compressing) the data, and we emplo y the Minimum Description Length (MDL) principle to auto-mate the process. We group locations and features simul-taneously : feature co-occurrence patterns help us compress spatial correlation patterns better , and vice versa. Further -more, for location groups, we incorporate spatial afnity by compressing regions in a natural way.

Section 2 presents some of the background, in the con-text of our problem. Section 3 builds upon this background, leading to the proposed approach described in Section 4. Section 5 presents experiments that illustrate the results of our approach. Section 6 surv eys related work. Finally , in Section 7 we conclude.
In this section we introduce some background, in the conte xt of the problem we wish to solv e. In subsequent sections we explain how we adapt these techniques for our purposes.
In this section we give a brief overvie w of a practical for -mulation of the minimum description length (MDL) princi-ple. For further information see, e.g., [5, 8]. Intuiti vely , the main idea behind MDL is the follo wing: Let us as-sume that we have a family M of models with varying de-grees of comple xity . More comple x models M 2 M involv e more parameters but, given these parameters (i.e., the model M 2 M ), we can describe the observ ed data more concisely .
As a simple, concrete example, consider a binary se-ple model M ( 1 ) might consist of specifying the number h of heads. Given this model M ( 1 ) f h = n g , we can encode H ( ) is the Shannon entrop y function. Ho we ver, in order to be fair , we should also include the number L ( M ( 1 ) bits to transmit the fraction h = n , which can be done using log ? n bits for the denominator and d log ( n + 1 ) e bits for the numerator h 2 f 0 ; 1 ; : : : ; n g , for a total of L log ? n + d log ( n + 1 ) e bits.
 Denition 1 (Code length and description complexity) L (
D j M ( 1 ) ) is code length for D, given the model M ( 1 L ( M ( 1 ) ) is the model description comple xity and L (
D ; M ( 1 ) ) : = L ( D j M ( 1 ) ) + L ( M ( 1 ) ) is the total code length .

A slightly more comple x model might consist of seg-menting the sequence in two pieces of length n 1 1 and n 2 = n n 1 and describing each one independently . Let h 1 and h 2 be the number of heads in each segment. Then, to describe the model M ( 2 ) f h 1 = n 1 ; h 2 = n 2 g , we need L (
M ( 2 ) ) : = log ? n + d log n e + d log ( n n 1 ) e + d 1 ) e + d log ( n 2 + 1 ) e bits. Given this information, we can describe the sequence using L ( D j M ( 2 ) ) : = n 1 H ( n H ( h 2 = n 2 ) bits.

No w, assume that our family of models is M : = f
M ( 1 ) ; M ( 2 ) g and we wish to choose the  X best X  one for a particular sequence D . We will examine two sequences of length n = 16, both with 8 zeros and 8 ones, to illustrate the intuition.
 Let D 1 : = f 0 ; 1 ; 0 ; 1 ; ; 0 ; 1 g , with alternating values. We have L ( D 1 j M ( 1 ) 1 ) = 16 H ( 1 = 2 ) = 16 and L log ? 16 + d log ( 16 + 1 ) e = 10 + 5 = 15. Ho we ver, for M ( the best choice is n 1 = 15, with L ( D 1 j M ( 2 ) 1 ) 15 and L ( 16 + 15 = 31 and L ( D 1 ; M ( 2 ) 1 ) 15 + 19 = 34. Thus, based on total code length, the simpler model is better 1 . The more comple x model may give us a lower code length, but that benet is not enough to overcome the increase in descrip-tion comple xity: D 1 does not exhibit a pattern that can be exploited by a two-se gment model to describe the data.
Let D 2 : = f 0 ; ; 0 ; 1 ; ; 1 g with all similar values con-tiguous. We have again L ( D 2 j M ( 1 ) 2 ) = 16 and L (
Figure 1. Quadtree compression: The map on the left has 4 4 = 16 cells (pix els), eac h ha v X  ing one of three possib le values. The result X  ing quadtree has 10 leaf nodes, again eac h ha ving one of three possib le values. 15. But, for M ( 2 ) 2 the best choice is n 1 = n 2 = 8 so that L ( total code lengths are L ( D 2 ; M ( 1 ) L ( length, the two-se gment model is better . Intuiti vely , it is clear that D 2 exhibits a pattern that can help reduce the total code length. This intuiti ve fact is precisely captured by the total code length.

In fact, this simple example is prototypical of the group-ings we will consider later . More generally , we could consider a family M : = f M ( k ) j 1 k n g of k -se gment models and apply the same principles. Furthermore, the datasets we will consider are two-dimensional matri-ces D : = [ d ( i ; j )] , instead of one-dimensional sequences. In Section 3.2 we address both of these issues. To complicate matters even further , one of the dimensions of D has a spa-tial location associated with it. Section 4 presents data de-scription models that also incorporate this information.
In fact, choosing the appropriate family of models is non-trivial. Roughly speaking, at one extreme we have the sin-gleton family of  X just the raw data,  X  which cannot describe any patterns. At the other extreme, we have  X all Turing ma-chine programs that produce the data as output,  X  which can describe the most intricate patterns, but mak e model selec-tion intractable. Striking the right balance is a challenge. In this paper , we address it for the case of spatial data.
A quadtree is a data structure that can be used to ef-ciently inde x contiguous regions of variable size in a grid. It has been used successfully in image coding and has the ben-et of small overhead and very efcient construction [28]. Figure 1 sho ws a simple example. Each internal node in a quadtree corresponds to a partitioning of a rectangular re-gion into four quadrants. The leaf nodes of a quadtree rep-resent rectangular groups of cells and have a value p asso-ciated them, where p is the group ID. In the follo wing we briey describe quadtree codelengths. Structur e. The structure of a quadtree uniquely corre-sponds to a partitioning of the grid. For example, the parti-tioning into three regions in Figure 1 on the left corresponds to the structure on the right. This partitioning is chosen in a way that respects spatial correlations. The structure can be described easily by performing a tra versal of the tree and transmitting a zero for non-leaf nodes and a one for leaf nodes. The tra versal order is not signicant; we choose depth-rst order (see Figure 1).
 Values. Quadtree structure con veys information about the partition boundaries (thick grid lines in Figure 1). These capture all correlations: in effect, we have reduced the orig-inal set of equal-sized cells to a (smaller) set of variable-sized, square cells (each one corresponding to a leaf node in the quadtree). Since the correlations have already been tak en into account, we may assume that the leaf node values are independent. Therefore, the cost to transmit the values is equal to the total number of leaf nodes, multiplied by the entrop y of the leaf value distrib ution.
 Lemma 1 (Quadtr ee codelength) Let T be a quadtr ee with m 0 leaf nodes, of whic h m 0 p have value p, wher e 1 p k. Then, the number of internal nodes is d m 0 = 3 e 1 . Structur e information can be transmitted using one bit per node (leaf/non-leaf) and values can be transmitted using en-tropy coding . Ther efor e, the corr esponding total codelength is This has a straightforw ard but important consequence: Lemma 2 The codelength L ( T ) for a quadtr ee T can be computed in constant time , if we know the distrib ution of leaf node values.
 In other words, for a full quadtree (i.e., one where each node has either zero or four descendants), if we kno w m 0 and m for 1 p k , we can compute the cost in closed form, us-ing Lemma 1. Note that the quadtree does not have to be perfect (i.e., all lea ves do not have to be at the same level). When a node is reassigned a dif ferent value, region consoli-dations may occur (i.e., pruning of lea ves with same value). Updating m 0 and m 0 p will require time proportional to the number of consolidations, which are typically localized. In the worst case, the time will be O ( log m ) if pruning cascades up to the root node.
In this section we formalize the problem and prepare the ground for introducing our approach in Section 4.
Assume we are given m cells on an evenly-spaced grid (e.g., eld patches in biological data) and n features (e.g., species). For each pair ( i ; j ) , 1 i m and 1 j n , we are also given a binary observ ation (e.g., species pres-ence/absence at each cell).

We want to group both cells and features, thus also im-plicitly forming groups of observ ations (each such group corresponding to an intersection of cell and feature groups). The two main requirements are: 1. Spatial afnity: Groups of cells should exhibit spatial 2. Homogeneity: The implicit groups of observ ations The problem and our proposed solution can be easily ex-tended to a collection of cate gorical features (i.e., taking more than two values, from a nite set of possible values) per cell.
Let D = [ d ( i ; j )] denote a m n ( m ; n 1) binary data matrix. A bi-gr ouping is a simultaneous grouping of the m rows and n columns into k and ` disjoint row and column groups, respecti vely . Formally , let denote the assignments of rows to row groups and columns to column groups, respecti vely . The pair f Q X ; Q Y g grouping.

Based on the observ ation that a good compression of the matrix implies a good, concise grouping, both k , ` as well as the assignments Q X ; Q Y can be determined by optimizing the description cost of the matrix. Let
R p : = Q 1 X p ; C q : = Q 1 Y q ; 1 p k ; 1 q ` be the set of rows and columns assigned to row group p and column group q , with sizes m p : = j R p j and n q : respecti vely . Then, let be the sub-matrix of D dened by the intersection of row group p and column group q . The total codelength L ( D ) L ( D ; Q X ; Q Y ; k ; ` ) for transmitting D is expressed as
For the rst part of Eq. 3.2 , elements within each D p are assumed to be dra wn independently , so that
L ( D p ; q j Q X ; Q Y ; k ; ` ) = d log ( j D p ; q j + 1 where r p D is analogous to the coin toss sequence models described in Section 2.1 . Finally ,
For the second part of Eq. 3.2 , row and column groupings are assumed to be independent, hence Finally , a uniform prior is assigned to the number of groups, as well as to each possible grouping given the number of groups, i.e., and similarly for the column groups.

Using Stirling' s approximation ln n ! n ln n n and the fact that  X  i m i = m , we can easily deri ve the bound L (
Q X j k ) = log m Therefore, we have the follo wing: Lemma 3 The codelength for transmitting an arbitr ary m-to-k mapping Q X , wher e m p symbols from the rang e are mapped into eac h value p ; 1 p k, is appr oximately
The set of all cells may form an arbitrary , comple x shape, rather than a square with a side that is a power of two. Ho w-ever, we wish to penalize only the comple xity of interior cell
Figure 2. Quadtree compression to discount the comple xity of the enc losing region' s shape; onl y the comple xity of cell group shapes within the map' s boundaries matter s. group boundaries. The shape of boundaries on the edges (e.g., coastline) of the map should not affect the cost.
For example, assume that our dataset consists of the three black cells in Figure 2(a). If all three cells belong to the same group and we encode this information na X vely , then we get a quadtree with ve nodes (Figure 2(c)). Ho we ver, the comple xity of the resulting quadtree is only due to the fact that the bottom-left is  X non-e xistent.  X 
If we kno w the shape of the entire map a priori , we can encode the same information using 1 bit, as sho wn in Figure 2(d). In essence, both transmitter and recei ver agree upon a set of  X existing X  cell locations (or , equi valently , a prior quadtree corresponding to the map description). This information should not be accounted for in the total code-length, as it is x ed for a given dataset. Given this infor -mation, all cells groups in the transmitted quadtree (e.g., group of both light and dark gray in Figure 2(d)) should be inter sected with the set of existing cells (e.g., black in Figure 2(a)) to get the actual cells belonging to each group (e.g., only dark gray in Figure 2(d)).

Since the  X non-e xistent X  locations are kno wn to both par -ties, we do not need to tak e them into account for the leaf value codelength, which is still m 0 H ( m 0 1 = m 0 ; : : : ; (see Lemma 1), where m 0 p is the number of quadtree lea ves having value p (1 p k ) and m 0 =  X  k p the tree-structure codelength we need to include the num-ber m 0 0 of nodes corresponding to non-e xistent locations (e.g., white in Figure 2(c)). Thus, the structure codelength is d 4 ( m 0 + m 0 0 ) = 3 e 1.
In the pre vious sections we have gradually introduced the necessary concepts that lead up to our nal goal: com-ing up with a simple but powerful description for binary data, which also incorporates spatial information and which allo ws us to automatically group both cells as well as fea-tures, without any user -specied parameters.

In order to exploit dependencies due to spatial afnity , we can pursue two alternati ves: 1. Relax the assumption that the values within each D p 2. Assign a non-uniform prior to the space of possi-We choose the latter , since our goal is to nd cell groups that exhibit spatial coherence. In the former alternati ve, spatial afnity does not decide how we form the groups; it only comes into play after the groupings have been decided. The second alternati ve fortunately leads to efcient algorithms. Each time we consider changing the group of a cell, we have to examine how this change affects the total cost. As we shall see, this test can be performed very quickly .
In particular , we choose to modify the term L ( Q X j k ) us assume that the dataset has m = 16 cells, forming a 4 4 square (see Figure 1), and that cells are placed into k = groups (light gray , dark gray and black in the gure). In-stead of transmitting Q X as an arbitrary m -to-k mapping (see Section 3.2 ), we can transmit the image of m = 16 pix els (cells), each one having one of k = 3 values. The length (in bits) of the quadtree for this image is precisely our choice of L ( Q X j k ) (compare Lemmas 1 and 3).

By using the quadtree codelength, we essentially penal-ize cell group region comple xity . The number of groups is factored into the cost indirectly , since more groups typically imply higher region comple xity .
For concreteness, let us consider the case of patch loca-tions and species presence features. The intuiti ve interpre-tation of cell and feature groups is the follo wing: The patterns we nd essentially summarise species and cells into families and habitats. The summaries are chosen so that the original data are compressed in the best way. Given the simultaneous summaries, we wish to mak e the intersection of families and habitats as uniform as possible: a particu-lar family should either be mostly present or mostly absent from a particular habitat. This criterion jointly decides the
Figure 3. In this simple example (16 cells and 2 species, i.e ., 32 binar y values total), if we require groupings to obe y spatial afnity , we obtain the shor test description of the dataset (locations and species) if we place all cells in one group. An y fur ther subdivision onl y adds to the total description comple xity (due to cell group region shapes). species of a family and the cells of a habitat. Ho we ver, our quad-tree model comple xity favours habitats that are spa-tially contiguous without overly complicated boundaries.
The group search algorithms are presented in subsection 4.2 . Intuiti vely , we alternati vely re-group cells and features, always reducing the total codelength. Example. A simple example is sho wn in Figure 3. We choose this example as an extreme case, to clarify the trade-offs between feature and spatial afnity . Experiments based on this boundary case are presented in section 5. Assume we have two species, located on a square map in a check er-board pattern (i.e., odd cells have only species A and even cells only species B). Consider the two alternati ves (we omit the number of bits to transmit species groups, which is the same in both cases): Therefore, our approach prefers to place all cells in one group. The interpretation is that  X both species A and B oc-cup y the same locations, with presence in r 1 cells.  X  Indeed, if we chose to perfectly separate the species instead, the cell group boundaries become overly comple x without any spatial afnity . Furthermore, if the number of species was dif ferent, the tipping point in the trade-of f be-tween cell group comple xity and species group  X impurity X  would also change. This is intuiti vely desirable, since de-scribing exceptions in lar ger species groups is inherently more comple x. Algo rithm I NNER : Start with an arbitrary bi-grouping ( Q 0 X ; Q 0 Y ) of the matrix D into k row groups and ` column groups. Subsequently , at each iteration t perform the follo wing steps: 1. For this step, we will hold column assignments, i.e., 2. Similar to step 1, but sw apping group labels of 3. If there is no decrease in total cost L ( D ) , stop. Other -
Figure 4. Ro w and column grouping, given the number of row and column groups.
Finding a global optimum of the total codelength is com-putationally very expensi ve. Therefore, we tak e the usual course of emplo ying a greedy local search (as in, e.g., stan-dard k -means [13] or in [4]). At each step we mak e a local mo ve that always reduces the objecti ve function L ( D ) search for cell and feature groups is done in two levels: If k and ` were kno wn in adv ance, then one could use only I
NNER to nd the best grouping. These mo ves guide the search towards a local minimum. In practice, this strate gy is very effecti ve. We can also perform a small number of restarts from dif ferent points in the search space (e.g., by randomly permuting rows and columns of D ) and keep the best result, in terms of total codelength L ( D ) .
For each row (i.e., cell) sw ap, we need to evaluate the change in quadtree codelength, which tak es O ( log m ) time Algo rithm O UTER : Start with k 0 = ` 0 = 1 and at each iteration T : 1. Try to increase the number of row groups, holding the 2. Apply algorithm I NNER with initial bi-grouping 3. If there is no decrease in total cost, stop and return 4 X 6. Similar to steps 1 X 3, but trying to increase column
Figure 5. Algorithm to nd number of row and column groups. in the worst case (where m is the number of cells). Ho we ver, in practice, the effects of a single sw ap in quadtree structure tend to be local.
 Complexity . Algorithm I NNER is linear in the number nnz of non-zeros in D . More precisely , the comple xity is O ( nnz ( k + ` ) + n log m ) T = O ( nnz ( k + ` + log m ) where T is the number of iterations (in practice, about 10 X  15 iterations suf ce). We mak e the reasonable assump-tion that nnz &gt; n + m . The n log m term corresponds to the quad-tree update for each row sw ap. In algorithm O UTER , we increase the total number k + ` of groups by one at each iteration, so the overall comple xity of the search is O (( k + ` ) 2 nnz + ( k + ` ) n log m ) , which is is linear with respect to the dominating term, nnz .
In this section we discuss the results our method pro-duces on a number of datasets, both synthetic (to illustrate the intuition) and real. We implemented our algorithms in Matlab 6.5. In order to evaluate the spatial coherence of the cell groups, we plot the spatial extents of each group (e.g., see also [29]). In each case we compare against non-spatial bi-grouping (as presented in Section 3.2 ). This non-spatial approach produces cell groups of quality similar to or better than, e.g., straight k -means (with plain Euclidean distances on the feature bit vectors) which we also tried.
 SaltP epper . This is essentially the example in Section 4.1 , with two features in a chessboard pattern. For the experiment, the map size is 32 32 cells, so the size (a) Non-spatial grouping (b) Spatial grouping of D is 1024 2. The spatial approach places all cells in the same group, whereas the non-spatial approach creates two row and two column groups. The total codelengths are (for a detailed explanation, see Section 4.1 ): NoisyRegions. This dataset consists of three features (say , species) on a 32 32 grid, so the size of D is 1024 3. The grid is divided into three rectangles. Intuiti vely , each rectangle is a habitat that contains mostly one of the three species. Ho we ver, some of the cells contain  X stray species X  in the follo wing way: at 3% of the cells chosen at random, we placed a wrong, randomly chosen species. Figure 6 sho ws the groupings of each approach. The spatial ap-proach favours more spatially coherent cell groups, even though the y may contain some of the stray species, because that reduces the total codelength. Thus, it captures the  X true habitats X  almost perfectly (except for a few cells, since the algorithms nd a local minimum of the codelength). Birds. This dataset consists of presence information for 219 Finnish bird species over 3813 10Km 10Km patches which cover Finland. The 3813 219 binary matrix con-tains 33.8% non-zeros (281,953 entries out of 835,047).
First, the cell groups in Figure 7(b) clearly exhibit a higher degree of spatial afnity than those in Figure 7(a). In fact, the grouping in Figure 7(b) captures the boreal veg-etation zones in Finland: the light blue and green regions correspond to the south boreal, yello w to the mid boreal and red to the north boreal vegetation zone.

With resepct to the species groups, the method success-fully captures statistical outliers and biases in the data. For example, ospr ey is placed in a singleton group. The data for this species was recei ved from a special study , where a big effort was made to seek nests. Similarly , blac k-thr oar ed diver is placed in a singleton group, most lik ely because of its good detectability from lar ge distances. Rustic bunting has highly specialized habitat requirements (mire forests) and is also not grouped with any other species.

Figure 7. Finnish bir d habitats; our appr oac h produces muc h more spatiall y coherent cell groups (see , e.g., red, purple and light blue) and captures the boreal veg etation zones.
In  X traditional X  clustering we seek to group only the rows of D , typically based on some notion of distance or similar -ity. The most popular approach is k -means (see, e.g., [13]). There are several interesting variants, which aim at im-pro ving clustering quality (e.g., k -harmonic means [30] and spherical k -means [7]) or determining k based on some cri-terion (e.g., X-means [23] and G-means [10]). Besides these, there are man y other recent clustering algorithms that use an altogether dif ferent approach, e.g., CURE [9], BIRCH [31], Chameleon [16] and DENCLUE [14] (see also [11]). The LIMBO algorithm [2] uses a related, infor -mation theoretic approach for clustering cate gorical data.
The problem of nding spatially coherent groupings is related to image segmentation; see, e.g., [29]. Other more general models and techniques that could be adapted to this problem are, e.g., [3, 19, 24]. Ho we ver, all deal only with spatial correlations and cannot be directly used for simulta-neously disco vering feature co-occurrences.

Pre vailing graph partitioning methods are METIS [17] and spectral partitioning [22]. Related is also the work on conjuncti ve clustering [21] and community detection [25]. Ho we ver, these techniques also require some user -specied parameters and, more importantly , do not deal with spa-tial data. Information theoretic coclustering [6] is related, but focuses on lossy compression of contingenc y tables, with distortion implicitly specied by pro viding the num-ber of row and column clusters. In contrast, we emplo y MDL and a lossless compression scheme for binary matri-ces which also incorporates spatial information. The more recent work on cross-associations [4] is also parameter -free, but it cannot handle spatial information. Finally , Keogh et al. [18] propose parameter -free methods for classic data mining tasks (i.e., clustering, anomaly detection, classica-tion) based on standard compression tools.

Frequent itemset mining brought a revolution [1] with a lot of follo w-up work [11, 12]. These techniques have also been extended for mining spatial collocation pat-terns [20, 27, 32, 15]. Ho we ver, all these approaches re-quire the user to specify a support and/or other parameters (e.g., signicance, condence, etc).
We propose a method to automatically disco ver spatial correlation and feature co-occurrence patterns. In particu-lar: Our method easily extends to other natural spatial hierar -chies, when available (e.g., city block, neighbourhood, city , county , state, country), as well as to cate gorical feature val-ues. Finally , we emplo y fast algorithms that are practically linear in the number of non-zero entries.

