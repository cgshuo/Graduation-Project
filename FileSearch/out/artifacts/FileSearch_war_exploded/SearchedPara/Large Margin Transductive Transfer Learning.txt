 Recently there has been increasing interest in the problem of transfer learning, in which the typical assumption that training and testing data are drawn from identical distri-butions is relaxed. We specifically address the problem of transductive transfer learning in which we have access to la-beled training data and unlabeled testing data potentially drawn from different, yet related distributions, and the goal is to leverage the labeled training data to learn a classifier to correctly predict data from the testing distribution. We have derived efficient algorithms for transductive transfer learning based on a novel viewpoint and the Support Vector Machine (SVM) paradigm, of a large margin hyperplane classifier in a feature space. We show that our method can out-perform some recent state-of-the-art approaches for transfer learning on several data sets, with the added benefits of model and data separation and the potential to leverage existing work on support vector machines.
 Categories and Subject Descriptors: H.2.8 [Database Applications]: Data Mining; I.5 [Pattern Recognition]: Mod-els  X  Statistical General Terms: Algorithms Keywords: Transfer learning, large margin classifier, trans-ductive learning, kernel method
Constructing mining and learning algorithms for data that may not be identically and independently distributed ( i.i.d. ) is one of the emergent research topics in data mining and machine learning [2, 5, 14, 21, 30, 31, 35, 37, 39]. Non-i.i.d. data occur naturally in applications such as cross-language text mining, bioinformatics, distributed sensor networks and sensor-based security [29], social network studies, low qual-ity data mining [41], and ones found in multi-task learn-ing [25]. The key challenge of these applications is that accurately-labeled task-specific data are scarce while task-relevant data are abundant. Lea rning with non-i.i.d. data in such scenarios helps build accurate models by leveraging relevant data to perform new learning tasks, identifying the true connections among samples and their labels, and ex-pediting the knowledge discovery process by simplifying the expensive data collection process.

Transfer learning aims to learn classification models with training and testing data sampled from possibly different distributions. The common assumption in transfer learning is that the training and testing data sets share a certain level of commonality and identifying such common structures is of key importance. For data that have well-separated struc-tures, exploring the common cluster structure of training and testing sets is a widely used technique [14, 37]. Instance based methods assume a common relationship between the class label and samples and use weighting or sampling strate-gies to correct differences between training and testing dis-tributions [5, 21, 35]. In feature based methods, shared fea-ture structure is lea rned in order to transfer knowledge in training data to testing data [30, 31]. In addition, Xue et al. used a hierarchical Bayesian model and developed a ma-trix stick-breaking process to learn shared prior information across a group of related tasks [39]. From a multi-task learn-ing framework, if we assume that the testing data is coming from a new task and that the new task belongs to a pa-rameterized task family, we can learn the structure of such a parameterized task family and use that information for transfer learning, as demonstrated in the zero-data learning algorithm [25].

In this paper, we explore a research direction motivated by manifold regularization which assumes that data distribute on a low dimensional manifold embedded in a high dimen-sional space [3]. The learning task is to find a low complexity decision function that well separates the data and that varies smoothly on the manifold. Following the same intuition, we approach the non-i.i.d. data learning problem by learning a decision function with low empirical error, regularized by the complexity of the function and the difference between training and testing data distributions, evaluated against the decision function. The idea is to in effect find a man-ifold for which the training and testing data distributions are brought together so that the labeled training data can be used to learn a model for the testing data. In particular, we aim to obtain a linear classifier, in a reproducing kernel Hilbert space, such that it achieves a trade-off between the large margin class separation and the minimization of train-ing and testing distribution discrepancy, as projected along Figure 1: Decision boundaries for the standard sup-port vector classifier (black) and our method (red) on a simple generated 2-D transfer learning prob-lem. This example is discussed in detail in Section 5. the linear classifier. Our hypothesis is that unlabeled test-ing data reveal information about testing data distribution and help build accurate classification models. Though large margin classifiers have been investigated in similar contexts including semi-supervised learning and transductive learn-ing [3, 23, 36], applying large margin classifiers to transfer learning by incorporating a regularization component mea-suring the distances between training and testing data is new and worth a careful investigation.

We illustrate our hypothesis in Figure 1 where we show an artificial data set in a 2D space where training and test-ing data sets have different distributions. As shown in the figure, the support vector machine builds a decision bound-ary that fits the training data well. Clearly the decision boundary is not the optimal one as evaluated on the testing data set. Clustering based methods are widely used in de-signing transfer learning algorithms. In this example, there is no obvious clustering structure for the positive and neg-ative samples and clustering based techniques will not be very helpful. Yet another class of widely used methods is ones that are based on feature extraction and feature selec-tion. These methods will not be very useful since in this case we only have two features and both of them are important. The key observation, as illustrated in this example, is that we need to integrate feature weighting (in order to handle distribution mismatches between training and testing sam-ples) and model selection in a unified framework.
The major advantage of adopting the regularized empir-ical error minimization paradigm such as the SVM is the potential to exploit many algorithms designed specifically for SVMs with only slight modifications, if any. For exam-ple, there have been fast algorithms designed for handling large data sets [19, 24], anomaly detection with one-class SVM, and multi-class SVM for multi-category classification. Other advantages are the rigorous mathematical foundation such as the Representer Theorem, global optimization with polynomial running time using convex optimization, and ge-ometric interpretations through generalized singular value decomposition. We discuss these properties of SVM based transfer learning in detail in the Algorithmic study section.
In supervised learning, we aim to derive ( X  X earn X ) a map-ping for a sample x  X  X  to an output y  X  X  . Towards that end we collect a set of n training samples D s = {{ x 1 ,y { x n ,y n }} sampled from X X Y following a (unknown) prob-ability distribution Pr ( x, y ). We also have a set of m test-ing samples D t = { z 1 ,..., z m } sampled from X following a (unknown) probability distribution Pr ( x, y ), where the cor-responding outputs from Y are unavailable, or hidden ,and must be predicted. We assume that D s are i.i.d. sampled according to the distribution Pr ( x, y )and D t are i.i.d. sam-pled according to the distribution Pr ( x, y ). In standard su-pervised learning, we assume that Pr ( x, y )= Pr ( x, y ). The problem of large margin transductive transfer learning is to learn a classifier that accurately predicts the outputs (class labels) for the unlabeled testing data set when Pr ( x, y )and Pr ( x, y ) are different.
There are two main approaches to transfer learning that have been considered, inductive transfer learning, where a small number of labeled test data are used along with labeled training data [1], and transductive transfer learning, where a significant number of unlabeled testing samples are used along with the labeled training data. In this paper we focus on transductive transfer learning.

A common approach to transfer learning is a model-based approach in which the different distributions are incorpo-rated in a model, e.g. through domain specific priors [11] or through a model with general and domain-specific com-ponents [12]. Several approaches have also been developed for transductive transfer learning which consider the local structure of the unlabeled data, utilizing some unsupervised learning methods, such as clustering [14] or co-clustering [37]. Our approach is most similar to feature-based ap-proaches to transfer learning, which include such approaches as weighting features to find feature subsets [31] or feature subspaces [26, 28] that generalize well across distributions. The difference is that we do so in a regularization framework, which aims to avoid over fitting and minimize the generaliza-tion error. Another approach that is similar to ours is that of Bickel et al. [7]. They address the problem of covariate shift through a likelihood model approach that takes into ac-count the discrepancy between train and test distributions. However their method results in a logistic regression based classifier from a non-convex problem, whereas our approach results in an SVM classifier from a convex problem.
At the heart of our approac h is the goal of finding a fea-ture transform such that the distance between the testing and training data distributions, based on some distribution distance measure, is minimized, while at the same time max-imizing a class distance or classification performance crite-rion for the training data. There has also been work de-scribing how to measure the distance between distributions. A key idea is that the distance between two distributions can be measured with respect to how well they can be sep-arated, given some function class. For instance, Ben-David et al. [4] used as an example the class of hyperplane clas-sifiers and showed that the performance of the hyperplane classifier that could best separate the data could provide a good method for measuring distribution distance for differ-ent data representations. Along these same lines, Gretton et al. [18] showed that for a specific function class, the mea-sure simplifies to a form that can be easily computed, the distance between the two means of the distributions, result-ing in the maximum mean discrepancy (MMD) measure, which we use in this paper. The particular form of this measurement makes it easier to incorporate into optimiza-tion problems, and so we chose this formulation to estimate distribution distances.

All the methods cited previously, including transfer learn-ing, are closely related to multi-task learning and may be viewed as a special case of semi-supervised learning where unlabeled data is used to enhance the learning of a decision function. The difference is that in transfer learning, there is an assumed bias between training and testing samples. A recent review of semi-supervised learning may be found in [10, 40]. A discussion of possible sample bias, in a multi-task learning framework, may be found in [21, 33].
Here we briefly discuss the formulation of the standard support vector machine (SVM), since it forms the basis for our transductive transfer support vector machine. Given ( x 1 ,y 1 ) ,..., ( x n ,y n )  X  X  X { X  1 } the supervised binary clas-sification learning task is to learn a function f  X  ( x ) for any x  X  X  that correctly predicts its corresponding class label y ; of particular interest is generalization accuracy the accu-racy of the function on predicting unseen future data. For hyperplane classifiers such as the SVM, the decision func-tion is given by the function f  X  ( x )=sign( f ( x )+ b ), where f ( x )= w T x ,and w controls the orientation of the hyper-plane, and b the offset. For the separable case, in which the two classes of data can be separated by a hyperplane, the SVM method tries to find the hyperplane with the maxi-mum margin of separation, where the margin is the distance to the hyperplane of a point closest to the hyperplane. For the non-separable case, the SVM method tries to identify the hyperplane with the maximal margin with slack vari-ables called the soft-margin. It can be shown that selecting the hyperplane with the largest margin minimizes a bound on expected generalization error [36].

The binary soft-margin SVM formulation aims to learn a decision function f specified below: where K ( x, x ): X X X X  R is a kernel function which defines an inner product (dot product) between samples in X , H K is the set of functions in the kernel space, || f || 2 is the L 2 norm of the function f ,and C is a regularization coefficient. V measures the fitness of the function in terms of predicting the class labels for training samples and is called a risk function. The hinge loss function is a commonly used risk function in the form of V =(1  X  y i f ( x i )) + and x if x  X  0 and zero otherwise.

If the decision function f is a linear function represented by a vector w , equation 1 can be represented as:
Where an unregularized bias term b is included and  X  ( x i is the kernel feature vector of x i . Following common termi-nology (e.g. [32]) we refer to this as the 1-norm soft margin SVM, and if squared slack variables are penalized instead, i.e. C n i =1 2 i , the 2-norm soft margin SVM.
For our formulation, it is necessary to choose a conve-nient distribution distance measure. One popular distribu-tion  X  X istance X  measure is the Kullback-Leibler divergence, based on entropy calculations. However for our approach we need a nonparametric method suitable for a reproduc-ing kernel Hilbert space (RKHS) that is both efficient to compute and relatively easy to incorporate into optimiza-tion problems while still allowing accurate distance mea-surement. One method that has recently been shown to be both efficient and effective for estimating the distance between two distributions in a reproducing kernel Hilbert space is the maximum mean discrepancy (MMD) measure [18]. The measure derives from computing the distribution distance by finding the function from a given class of func-tions that can best separate the two distributions, with the function class restricted to a unit ball in the RKHS. Addi-tionally the particular form of this measure fits quite well into our support vector formulation, as shown in Section 4. Here we briefly overview the MMD measure for estimating the distance between two distributions. Given a set of n training samples D s = {{ x 1 ,y 1 } ,..., { x n ,y n }} and a set of m testing samples D t = { z 1 ,..., z m } . The (squared) maxi-mum mean discrepancy distance of the training and testing distributions is given by the following formula:
The MMD measure has also recently been used in the con-text of transfer learning, e.g. for kernel learning [28].
Our general approach is as follows. We want to find a feature transform that minimizes the between-distribution distance, but at the same time maximizes the performance of a classifier on data from the training distribution. The latter criterion could also be considered a distribution dis-tance measure (along the lines of [4]) in this case the distance between the distributions of the classes of the training data distribution. Thus in essence our general transfer learning approach is described with Equation 4. f =argmin where Pr is the distribution of the training samples, Pr the distribution of the testing samples, d f,K ( Pr,Pr )isa distance measure of the two distributions, as evaluated against the decision function f and the kernel function K .  X  controls the trade-off between the three components in the objective function. Other symbols such as C, V, H K are the same as explained in Equation 1.

Following convention, we only consider linear decision func-tions f in the format f ( x )= w T  X  ( x )where w is the direction vector of f . Also following convention, we introduce an un-regularized bias term, b , so that the final function is given by f ( x )+ b and the label is assigned as sign( f ( x )+ b ).
Oneapproachwetaketomeasurethedistancebetween two distributions is to estimate how well the two distribu-tions are separated as explo red in the maximum mean dis-crepancy distance [18], mentioned previously. We define the projected maximum mean discrepancy distance measure ,us-ing a set of training samples D s = {{ x 1 ,y 1 } ,..., { and a set of m testing samples D t = { z 1 ,..., z m } below. Here we take the squared projected maximum mean dis-crepancy measure for our distribution distance measure, to estimate the distribution distance under a given projection w :  X  2 1
With the given decision and distance functions, we can rewrite Equation 4 in vector format below: min . 1 2 || w || 2 + C s . t . i  X  0 ,y i ( w T  X  ( x i )+ b )  X  1  X  i  X  i =1 , ..., n where d f,K ( Pr,Pr ) 2 is estimated using Equation 5.
The major difficulty in solving Equation 6 is that w is a vector in the Hilbert space defined by the kernel function K and hence may have infinite dimensionality. The Represen-ter Theorem, which states that any vector w that minimizes Equation 6 should be a linear combination of the kernel fea-ture vectors of the training and testing samples, provides a useful remedy. where  X  i and  X  j are coefficients and w is the vector that optimizes Equation 6. For simplicity, we denote  X  ( S )= (  X  ( s 1 ) ,..., X  ( s n + m )) = (  X  ( x 1 ) ,..., X  ( x n ..., X  ( z m )) is a list of kernel feature vectors for training and testing samples and  X  =(  X  1 ,..., X  n , X  1 ,..., X  m ) T is a ( n + m ) column vector. Hence we have w =  X  ( S )  X  .

The key observation of the Representer Theorem is that if w has a component that is not in the span of column vectors in  X  ( S ), that component must be orthogonal to the linear space spanned by the training and testing samples. In that case, the value of f , evaluated on training and testing samples will remain unchanged but the L 2 norm of f will increase [3]. The details of the formal proof in this case can be found in the appendix. With the Representer Theorem, we state our algorithm for large margin transductive transfer learning below.
With the Representer Theorem, we learn the decision bound-ary without explicitly learning the vector w . Wehavethe following observations. where  X  is a ( n + m )by( n + m ) positive semi-definite ma-trix and  X  i,j = K (  X  ( s i ) , X  ( s j )). Our projected distribution distance measure can then be expressed as: =  X  T  X   X  where  X  is a ( n + m )  X  ( n + m ) symmetric positive semi-definite matrix. K Train is the ( n + m )  X  n kernel matrix for the training data, K Test the ( n + m )  X  m kernel matrix for the testing data, and [1] k  X  l is a k  X  l matrix of all ones.
With these two equations, Equation 6 is expressed using  X  in the following way: where K i =  X  ( S ) T  X  ( x i )isan( n + m )columnvector.
It is easy to show that the optimization problem of Equa-tion 10 has an objective with a quadratic form of  X  and is a standard convex quadratic program, and hence can be solved using quadratic program solvers.
We can view the problem of Equation 10 as performing regression in the Hilbert space with a hinge loss function and parameters  X  . Thus we propose adding an L 2 penalty to the  X  parameters to shrink the selection of the data points used for the classifier and to add numerical stability to the algorithm in practical implementations -particularly with large matrices this can correct for slight negative eigenvalues from calculating  X . Thus our final objective to minimize is: where I is the ( n + m )  X  ( n + m ) identity matrix. In our experiments we found that generally a moderate amount of such L 2 regularization improved performance.
Below we show a special case with linear kernels and a fea-ture weighting as opposed to a projection for measuring the distribution distance and demonstrate that in this case our algorithm can be viewed as a processing technique, follow-ing by a regular SVM model construction. We arrive at this simplification if we consider the target projection w as rep-resenting a linear feature weighting transform W = diag ( w ) that does not project a data point but re-weights it, and measure the MMD with respect to the feature weighting in-troduced for a given w and the resulting W . With linear kernels, w is a vector in the original feature space, rather than in the kernel feature space, and the MMD measure under this linear transform is given by equation 12.
We can rearrange the MMD measure to sum across each feature: where p is the dimensionality of x and Q is a p  X  p diagonal [1 ,p ].

Plugging this back into our 1-norm soft-margin SVM for-mulation, we can combine the MMD 2 term with the maxi-mum margin term, resulting in the objective: where I is a p  X  p identity matrix and Q =  X Q + 1 2 I .
We could derive a similar quadratic programming for com-puting w but it is unnecessary. The problem presented in Equation 14 can be solved using a pre-processing step, fol-lowed by any off-the-shelf SVM solver. To see this, notice that since Q is diagonal it can be expressed as U T U with U = Q 1 2 so that w T Q w becomes w T U T Uw =( Uw ) T ( Uw ). Thus by defining w = Uw and re-scaling the data by 1 /U (i.e. x i = x i (1 /U )), we obtain the standard SVM prob-lem. To obtain w from the solution w  X  we simply divided by U . Note that we can incoporate nonlinearity in this case through basis expansion; we simply define the feature f j agiven x as the output of the kernel function between x and the data instance (from the training and testing sets) s , j  X  X  1 ,...,n + m } .
In the previous sections, we discussed the SVM with 1-norm soft margin for transductive transfer learning. In this section, we introduce a similar formalization for 2-norm soft margin transductive transfer learning that is equivalent for the case of the standard SVM, in which we fix the hyperplane norm || w || and find the hyperplane direction that gives maxi-mum separation, measured by  X  . This formalization reveals a geometric interpretation for the regularization. We dis-cuss the geometric interpretation using a technique known as generalized singular value decomposition (GSVD).
The 2-norm transductive transfer learning is an optimiza-tion problem specified below: With the Representer Theorem we have w =  X  T  X  ( S )where  X  ( S )=(  X  ( x 1 ) ,..., X  ( x n ) , X  ( z 1 ) ,..., X  ( z m
Using the expression of MMD from Equation 9 and the L 2 norm of w in Equation 8, we have the following optimization problem:
The Lagrangian of Equation 16 is L ( w, b,  X ,  X ,  X ,  X  0 )=  X   X .

Clearly, if the value of  X  0 is known, the Lagrangian is a quadratic programming problem for  X  . The difficulty here is that we have to optimize two variables  X  0 and  X  .Inreg-ular SVM with 2-norm soft margin, the optimal value of  X  0 can be determined analytically once we know  X  and the op-timization problem adopts the quadratic programming for-mat. In transductive transfer learning, we do not have this convenience anymore. However, we may use a technique called generalized singular value decomposition to show the effect of the distribution distance measure  X  in the optimiza-tion.
 For the kernel matrix  X  we obtain a matrix  X  c such that K = X  T c  X  c . Similarly for the kernel matrix  X  we obtain a matrix  X  d such that K = X  T d  X  d . Given two square-matrix  X  c and  X  d with the same size, if we apply the generalized singular value decomposition we have  X  c = U  X  1 RQ T and  X  d = V  X  2 RQ T where U, Q are orthogonal matrices and R is an upper-triangular matrix. Then we have the following formula: M  X  1 is a shrinkage operator, penalizing smaller generalized singular values and the penalization is controlled by the two parameters  X  0 and  X  .
Here we give a synthetic 2D example to illustrate our ap-proach. The training data distribution is shown as the green dots or squares (for the negative class) and the black plus symbols (as the positive class), generated by sampling from Gaussians for each feature with  X  2 =1,centeredat(0 ,  X  2) and (2 , 0) respectively. The testing distribution is generated in a similar fashion, designed to be similar to the train-ing distribution particularly along one dimension, with the negative class, depicted with upside-down red triangles gen-erated from a Gaussian distribution centered at (0 , 2) and the positive class, depicted as blue circles, generated with a Gaussian centered at (2 , 0).

The transductive support vector machine is a widely used method that handled to some extent the possible difference between training and testing data sets. The transductive SVM tries to minimize the decision function norm and the errors on both the training and testing data, taking the un-known labels as variables of the optimization problem, so that these labels must be solved for along with the decision function. One of the key disadvantages of the transductive SVM is that the underlying optimization problem is an NP-hard problem and hence an iterative approximation has been used to solve it, which can take a very long time to finish. Our formalization of the transductive transfer SVM utilizes a quadratic programming optimization which is guaranteed to identify the global minimum in worst-case polynomial time.

The results for three versions of the support vector classi-fier are shown in Figure 2. The first is the standard support vector machine (green line), which performs the worst, ob-taining an accuracy of . 60, the second is the transductive SVM [23] (magenta line). The accuracy here improves to . 72. Finally, the results of our transductive transfer SVM with a 1-norm soft margin are shown and the linear feature-weighting simplification (LMFW -red line), which tries to take into account the distance between the testing and train-ing distributions. In this case it achieves the best accuracy, . 84, and comes closest to finding the underlying ideal sepa-ration for a linear transform, a vertical line between the two classes. Figure 2: Performance of different support vector classifiers on a simple generated 2-D transfer learn-ing problem.

The next example we give is for a nonlinear classification task. Here data of the negative class are generated around the origin by sampling 100 points from a Gaussian distri-bution that is stretched in one dimension and shrunken in the other, for the training data it is stretched along the x axis, and for the test data along the x 1 axis. The positive class is then generated in each case by randomly sampling points from a uniform distribution in the box region around the negative class distributions. Points that are less than a fixed threshold when evaluated in the Gaussian function for the negative data distribution are discarded, and points are sampled until 100 are obtained. For all three methods we use default parameters of  X  =0 . 5fortheRBFkernelwidth and regularization parameter C = 1. The resulting clas-sification boundaries learned by each of the three methods are shown in Figure 1, this time for our large-margin pro-jection algorithm (LMPROJ). Our algorithm again achieves superior performance.
Here we evaluate our methods using collections of real-world data. We use data from four different classification tasks, forming a combined total of 24 transfer learning data sets. Three of these tasks are commonly used in the liter-ature and are related to text classification (work that used all or some of these data sets include [37, 14, 26, 28]). We include a fourth data set for tra nsfer learning, related to protein-chemical interaction prediction.

Besides baseline methods of the standard support vector machine (SVM) and the transductive support vector ma-chine (TSVM), we choose for comparison two recent state-of-the-art algorithms from KDD X 08 that showed impressive results, out-performing baseline methods and some previous transfer learning methods in their experiments. The first comparison method is the Cross Domain Spectral Classi-fier (CDSC) [26] (out-performing the methods of [37] and [33] in their experiments). We implemented their method in Matlab, directly following the algorithm as presented in the paper. The second is the Locally-Weighted Ensemble (LWE) classifier of [14]. We used the same three meth-ods that they used in their experiments for the ensemble, namely the Winnow algorithm from the SNoW Learning Architecture [8], a logistic regression algorithm from the BBR package [15] and the LIBSVM implementation of a support vector machine classifier [9]. We obtained parts of the code for their algorithm from an author X  X  website http://ews.uiuc.edu/~jinggao3/kdd08transfer.htm and implemented the rest following the algorithm in their paper.
We obtained three pre-proce ssed text classification data sets from the paper [14] for our experimental study: the Reuters data sets, 20 newsgroups text classification data sets, and the spam filtering data sets. We follow the sam-pling strategy in [26] to sample 500 instances each from the testing and training distribution to form our training and testingdatasets.

We confirmed the correctness of our implementation by obtaining similar results to the performance reported in the respective papers (in some cases slightly more and in some cases slightly less accuracy). The methods we compared to did not list the type of normalization used, so we tried three different ways to normalize the non-binary features, no normalization, [0 , 1] normalization using both the train-ing and testing data, and [0 , 1] normalization separately on the training and testing data. Interestingly, the performance of all the methods except LWE improved slightly using nor-malization, since normalization may interrupt the clustering structure in a data set. The difference between the second and the third normalization methods is negligible and hence we only report results on [0 , 1] normalization separately on the training and testing data.

From our methods, we tested both the large-margin pro-jection approach as described in Section 4.2 and Equation 10 and the large margin feature-weighting approach as de-scribed in Section 4.3. We denote the two approaches as LMPROJ and LMFW, respectively. We tested these two approaches as well as the basic SVM using a linear kernel and a cosine similarity measure, K ( x, y )=( x T y ) / ( the same similarity measure used by the CDSC method and commonly used in text mining. We only show results us-ing the cosine similarity since they were slightly better than with the linear kernel. We used Matlab and a convex solver, CVX [16, 17], to solve the quadratic programs of the LM-PROJ methods. For transductive transfer learning no la-beled testing data can be used in the training, and since the testing and training distributions are different there is no easy way to use typical model selection approaches such as cross-validation to select appropriate parameters [14]. Thus we give the best performance for each method over a range of parameters, for the LWE and CDSC methods we center this range around the best performing parameters reported in their respective papers. Because of this, the base line SVM method and the transductive SVM method have higher ac-curacy as compared to those reported in the literature when default parameter values are used. We also perform detailed parameter sensitivity analysis to show how the performance is affected by each of the parameters in our method.
To compare the performance of the different methods, the first evaluation criterion we use is the F1 score, which is commonly used in information retrieval tasks such as docu-ment classification. The F1 score is the harmonic mean of the precision ( P )andrecall( R ): 2 PR P + R ,where P is given by + fp and R by tp tp + fn . tp denotes the number of true pos-itive predictions, fp the number of false positives, fn false negatives, and tn true negatives. The F1 score is particu-larly appropriate for the spam filtering and chemical-protein interaction prediction data sets where predicting the positive class, the existence of spam and chemical-protein interaction respectively, is of particular interest. The second criterion we present results for is accuracy, commonly used to evalu-ate classification performance in general. Accuracy is given
A brief description of each data set and its set-up is given here. Table 3 in the Appendix summarizes the data sets and gives the indexes by which we will refer to each in our results. For example, data set 10 is an email spam filtering data set where the training data set is a set of public messages and the testing data set is the set of emails collected from a specific user. These data sets both represent text categorization tasks, Reuters is made up of news articles with 5 top-level cat-egories, among which, Orgs , Places ,and People are the largest, and the 20 Newsgroups data set contains 20 news-group categories each with approximately 1000 documents. For these text categorization data, in each case the goal is to correctly discriminate between articles at the top level, e.g.  X  X ci X  articles vs.  X  X alk X  articles, using different sets of sub-categories within each top-category for training and testing, e.g. sci.electronics and sci.med vs. talk.politics.misc and talk.religion.misc for training and sci.crypt and sci.space vs. talk.politics.guns and talk.politics.mideast for testing. For more details about the sub-categories, see [37]. Each set of sub-categories represents a different domain in which dif-ferent words will be more common. Features are given by converting the documents into bag-of-word representations which are then transformed into feature vectors using term frequency, details to this procedure can also be found in [37].
For this task, there is a large quantity of public email messages available, but an individual X  X  emails are generally kept private, and these messages will have different word distributions. The goal is to us e the publicly available email messages to learn to detect spam messages, and transfer this
Figure 3: Prediction F1 score on all 24 data sets learning to individual users X  email messages. There are three different users with associated email messages. The features for this data set are also made using term frequency from bag-of-word representations for the messages, details can be found in [6].
For this data set, we test the ability of the algorithms to transfer learning across protein families for protein-chemical interaction prediction. The goal is to be able to use the known protein-chemical interactions for a given protein fam-ily to help predict which chemicals the proteins of another protein family will interact with, for which no interaction in-formation is known. We obtained a data set from Jacob et al. [22] which includes all chemicals and their G protein-coupled receptor (GPCR) targets, built from an exhaustive search of the GPCR ligand database GLIDA [27]. The data set con-tains 80 GPCR proteins across 5 protein families, 2687 com-pounds, and a total of 4051 protein-chemical interactions. One family we discard since it has too few proteins and in-teractions. For the proteins we extracted features using the signature molecular descriptors [13], for the chemicals we used a frequent subgraph feature representation approach [20, 34], and we used a threshold on the feature frequencies to obtain about 100 features each. We then built the feature vector for a given protein-chemical pair by taking the tensor product between the protein and chemical feature vectors.
For each protein family we then built a data set by sam-pling 500 pairs of proteins from the family and chemicals that are known to interact (or took all available interac-tions for a given family if there were less than 500). Since we had no  X  X egative interaction X  data we randomly sampled the same number of protein-chemical pairs among the pro-teins of the given family and the chemicals for which there was no known interaction, the assumption being that the positive interactions are scarce. We then constructed 12 transfer learning tasks by using each protein family in turn as the training domain and each other protein family for the testing domain. The break-down of the protein families is shown in Table 3 in the Appendix.
First, we show an overall comparison of our method with the two state-of-the-art methods we compared with as well as the baseline of a SVM classifier with a cosine similar-ity kernel and the off-the-shelf transductive SVM. For easy visualization we show a plot of the F1 scores in Figure 3 with the data set index on the x-axis and the F1 score on the y-axis for the different methods, only showing here our method LMPROJ with the cosine similarity kernel (though the LMFW method was comparable, as seen in Tables 1 and 2) marked by blue circles, the LWE method marked by upside-down purple triangles, the CDSC method marked by green crosses, transductive SVM (TSVM) by a dashed orange line, and traditional SVM by the dotted black line. The results for accuracy are reported in Tables 1 and 2.
In Figure 3, we observe that there is a general agreement of all 5 different methods that we compared in the first 12 data sets. The chemical-protein interaction data sets are harder and there is a large performance gap between dif-ferent methods. Specifically comparing different methods, the base-line SVM works almost always the worst. This is not surprising since we know there are differences between training and testing samples and ignoring such differences usually does not lead to optimal modeling.

The cross-domain spectral classifier method (CDSC) has competitive performance, as compared to other methods. For some reasons that we do not fully understand, we ob-serve a large performance variation of the CDSC method across different data sets. The locally weighted ensemble method (LWE) and the transductive SVM (TSVM) method have competitive performance in the first 12 data sets but they do not perform very well in the chemical-protein data sets. The results may suggest that the chemical-protein in-teraction data do not follow the clustering assumption well.
We observe that the LMPROJ method delivers stable re-sults across the 24 data sets. For both accuracy and F1 score LMPROJ achieves the best score in 11 out of 24 data sets and is competitive with the best methods for the majority of the other data sets. It obtains the best score more times than any of the other methods.

We also note that we obtained somewhat better results for the SVM and TSVM methods than typically reported in the literature (e.g. [14, 26]) on the same data sets that we use. This is because in our study instead of selecting a default parameter or allowing an internal cross-validation on the training data to be performed, to allow a fair comparison with the transfer learning approaches we reported the best results over a set of parameters for the baseline methods.
Next we give parameter sensitivity results in Figure 4, for the accuracy criterion and the three parameters  X  ,  X  and C . For each plot, two parameters are fixed at the best values while the third parameter is varied to generate the plots. Here we show representative results for a couple of data sets, the 2nd Reuters data set -a text data set, and the second chemical-protein interaction data set. In the last three subfigures we also show the sensitivity results for the three parameters averaged over all 24 data sets. While the base accuracy was different for different data sets, the gen-eral trends are captured by averaging the results together. In general we see that as we suspected larger values of  X  tend to improve performance; as  X  is increased, the perfor-mance increases from the base standard SVM performance, and levels off to a maximum for a wide range of parameters. The results for  X  2 show that in general the L 2 regulariza-tion slightly improves performance up to moderate amounts, but past a certain point, i.e. too much regularization, the (a) Chem.-Prot. (2) - X  (d) Reuters (2) - X  (g) All (Avg.) - X  performance deteriorates. Also the performance is relatively insensitive to C for a wide range of values.

Finally the full results including a comparison of all the methods tested in terms of accuracy are given in Table 1 and Table 2.
We have addressed the problem of transductive transfer learning using regularization with the goal of maximizing a classification margin while at the same time minimizing a distance between training and testing distributions. With extensive experimental study we demonstrated the effective-ness of our approach, comparing it with some recent state-of-the-art methods. Our results demonstrate the effectiveness of this viewpoint of using regularization to find a decision function that brings the training and testing distributions together so that the training data can be effectively utilized.
One key idea for future work is incorporate an L 1 penalty on  X  of the projection method to encourage a sparse solu-tion. Also, an open problem for transductive transfer learn-ing in general is how to perform parameter selection, since no labeled testing data is available. Another area of fu-ture work is to experiment with different loss functions for our large-margin classifier, in particular, a truncated hinge-loss function (e.g. [38]), to avoid situations where errors on the training data effectively prevent the transfer to the test domain. Finally, from our results we have seen that two schools of thought for considering transfer learning prob-lems, one which tries to match the structure of the testing data and the other which tries to find some type of trans-form/embedding that brings the testing and training data together, seem to some extent to provide complementary re-sults. Forming a hybrid method could potentially result in a more powerful classifier. This work has been partially supported by ONR award # N00014-07-1-1042 and an NSF Graduate Research Fellow-ship (for BQ). [1] R. K. Ando, T. Zhang, and P. Bartlett. A framework [2] A. Arnold, R. Nallapati, and W. W. Cohen. Exploiting [3] M. Belkin, P. Niyogi, V. Sindhwani, and P. Bartlett. [4] S. Ben-David, J. Blitzer, K. Crammer, and F. Pereira. [5] S. Bickel, C. Sawade, , and T. Scheffer. Transfer [6] S. Bickel. Ecml-pkdd discovery challenge 2006 [7] S. Bickel, M. Br  X  uckner, and T. Scheffer.
 [8] A. Carlson, C. Cumby, J. Rosen, N. Rizzolo, and [9] C.-C. Chang and C.-J. Lin. LIBSVM: a library for [10] O. Chapelle, B. Sch  X  olkopf, and A. Zien, editors. [11] C. Chelba and A. Acero. Adaptation of maximum [12] H. Daum  X  e III and D. Marcu. Domain adaptation for [13] J.-L. Faulon, M. Misra, S. Martin, K. Sale, and [14] J. Gao, W. Fan, J. Jiang, and J. Han. Knowledge [15] A. Genkin, D. D. Lewis, and D. Madigan. BBR: [16] M. Grant and S. Boyd. CVX: Matlab software for [17] M. Grant and S. Boyd. Graph implementations for [18] A. Gretton, K. M. Borgwardt, M. Rasch, [19] C. Hsieh, K. Chang, C. Lin, S. Keerthi, and [20] J. Huan, W. Wang, and J. Prins. Efficient mining of [21] J. Huang, A. Smola, A. Gretton, K. M. Borgwardt, [22] L. Jacob, B. Hoffmann, V. Stoven, and J.-P. Vert. [23] T. Joachims. Transductive inference for text [24] T. Joachims. Training linear svms in linear time. In [25] H. Larochelle, D. Erhan, and Y. Bengio. Zero-data [26] X. Ling, W. Dai, G. Xue, Q. Yang, and Y. Yu. [27] Y. Okuno, J. Yang, K. Taneishi, H. Yabuuchi, and [28] S. J. Pan, J. T. Kwok, and Q. YangPan. Transfer [29] B. Quanz and C. Tsatsoulis. Determining object [30] R. Raina, A. Battle, H. Lee, B. Packer, and A. Y. Ng. [31] S. Satpal and S. Sarawagi. Domain adaptation of [32] J. Shawe-Taylor and N. Cristianini. Kernel methods [33] H. Shimodaira. Improving predictive inference under [34] A. Smalter, J. Huan, and G. Lushington.
 [35] M. Sugiyama, S. Nakajima, H. Kashima, P. V. [36] V. Vapnik. Statistical Learning Theory . John Wiley [37] Q. Y. Wenyuan Dai, Gui-Rong Xue and Y. Yu.
 [38] Y. Wu and Y. Liu. Robust truncated hinge loss [39] Y. Xue, D. Dunson, and L. Carin. The matrix [40] X. Zhu. Semi-supervised learning literature survey. [41] X. Zhu, T. M. Khoshgoftaar, I. Davidson, and
The major difficulty in solving Equation 6 is that w is a vector in the Hilbert space defined by the kernel function K and hence may have infinite dimensionality. Fortunately we have the following theorem, known as the Representer Theorem, which states that w is always a linear combination of  X  ( x i )and  X  ( z j )where x i in D s and z j in D t .Belowwe prove that the Representer Theorem is correct in our case.
Theorem 10.1. The vector w that minimizes the Equa-tion 6 can be represented as where  X  i and  X  j are coefficients.
 Proof. We prove the theorem by showing contradiction. Let w 1 = the Equation 6 where w  X  /  X  span (  X  ( x i ) , X  ( z j )). And let w 0 = w 1  X  w  X  be the projection of w 1 in the linear space of span (  X  ( x i ) , X  ( z j )). Then we have
And || w 1 || 2 = || w 0 || 2 + || w  X  || 2  X || w 0 || 2 .Ifwecompare w 1 and w 0 , we claim that the hinge loss function values are exactly the same and the MMD regularizer values are exactly the same. The only difference is that the norm of w 1 is larger than w 0 . This claim contradicts the original assumption that w 1 optimizes Equation 6. Hence w  X  =0.
