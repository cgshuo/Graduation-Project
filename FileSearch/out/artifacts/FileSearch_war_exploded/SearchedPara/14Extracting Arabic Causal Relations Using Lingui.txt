 JAWAD SADEK and FARID MEZIANE , University of Salford Most studies on semantic analysis of texts focused on the detection of Causal relations since they are fundamental to many Natural Language Processing (NLP) applica-tions such as Text Generation (TG), in which causality is a typical way of generating knowledge and providing explanation [Kaplan and Berry-Rogghe 1991; Jackson 1989]. Furthermore, Modern Information Retrieval (IR) researchers have concentrated their efforts on developing more efficient search engines by expanding the lexical approach to a semantic level, including Causal relations [Zadeh 2006; Puente et al. 2011]. Ques-tion Answering (QA) systems also highly benefit from an in depth mining of causation. Consider the sentence  X  X because the car broke down,] 1 [Sarah was late for school] 2  X  which contains a Causal relation that holds between Slots 1 and 2. We can then provide Slot 1 as a candidate answer for the  X  X hy was Sarah late? X  [Girju and Moldovan 2002; Pechsiri and Kawtrakul 2007].

There are two main approaches for constructing syntactic linguistic patterns: rule-based approaches (also referred to as hand-crafted patterns) [Joskowsicz et al. 1989; Carcia 1997; Khoo et al. 2000; Low et al. 2001] and machine-learning approaches, which aim to automatically construct syntactic patterns that may encode causation [Girju 2003; Beamer et al. 2007; Rink et al. 2010; Do et al. 2011]. The later studies exploited the electronic knowledge resources available for the languages involved, for example, large annotated corpora, WordNet, dictionaries, Wikipedia, and so on.
The Arabic language, so far, lacks mature knowledge base resources upon which machine-learning algorithms heavily rely. Recently, Leeds Arabic Discourse Treebank (LADTB) 1 has been presented as an Arabic corpus annotated with discourse relations. However, this corpus contains approximately 500 sentences annotated with a Causal relation, which is a very small set to provide proper training and justify the use of a machine-learning approach. Furthermore, the syntactical patterns of the Arabic relations are relatively larger compared to the size of the available training corpus.
In this research, Arabic texts were analyzed to observe the behavior of the connectives that indicate Causal relations. However, capturing the syntactical arrangement of many of the causative connectors is a challenging task. Consider, for example, the lemma  X  , X  which can be represented by a variety of syntactical forms. In fact, more than 150 occurrences of this connector in different sample documents were investigated in order to generate the patterns group that can accurately identify cause and effect information associated with the set of words belong to the lemma  X  . X  Table I shows samples of the generic structure for sentences involving the lemma  X  . X 
The approach adopted in this study makes use of a set of hand-crafted linguistic patterns indicating the presence of the targeted relations defined by the researchers. In this work, we use the expression Causal as a superclass term in which each refers to a number of relations that belong to the same category. In this context, when the term Causal is used, we refer to the relation (Causal, Result, and Purpose). The direct application of this research is to enhance the performance of a QA system attempting to answer  X  X hy X  and  X  X ow to X  questions [Sadek et al. 2012] and is limited to texts written in Modern Standard Arabic (MSA). Our contributions are to propose a Pattern Recognizer model that employs a set of linguistic patterns identified based on a combi-nation of cue words and part-of-speech labels that tend to appear in sentences of the Causal type. In addition, we introduce three separate algorithms that would let the model deal with the justification particles that may indicate causation. Causation is a textual relationship that relates two situations. The Causal relation event is understood as a consequence of the first. Some studies touched on the topic of causation in Arabic literature while discussing other language phenomena [Sarig 1995; Kammensjo 2010; Al-Jarrah 2011]. However, only few Arabic linguists have devoted their work to study the function of connectives that indicate causation within sentences. Haskour [1990] has extensively surveyed Causal relations in the written Arabic litera-ture. She argued that causation from the perspective of grammarians can be classified into two main categories. The first one is (verbal causality) , which can be captured by the presence of nominal clauses for example, [ (Accusatives of purpose)-(Cognate accusative)] or by causality connectors such as [ (there-fore), (because) and (for)] even though these connectors may in some cases signal different relations other than causation. The second category is (context-based causality) that can be inferred by the reader using general knowl-edge without locating any of the previous indicators. This category includes various Arabic stylistic structures that express causality implicitly such as [ (resump-tion), (condition), (exception)]. This classification is similar to that proposed by Blancol et al. [2008], who made the following distinctions for Causal relations in the English language.  X 
Marked or Unmarked: In the case that a Causal relation can be indicated by a specific to a volcano eruption X ; the other case is unmarked relation , for example,  X  X e careful!
It X  X  unstable. X   X 
Ambiguous or Unambiguous: Unambiguous connectors are those that always indi-cate Causal relations in text like (because). On the other hand, they are con-sidered ambiguous if they are associated with multiple relations. For example, the connector may express causation in some cases in the sense of  X  X ecause, since, as X  while in other cases it refers to the Temporal relation indicating motion towards and at the same time arrival at an object, as in sentence (1). It also operates like other copulative particles in the sense of  X  X ven X  with no independent influence upon the following noun, but rather remains under the same influence of the preceding noun, as in sentence (2). (1) (2)  X  on the other side, a relation is considered to be implicit if any of its elements is missing. Implicit relations are frequently used in rhetorical expressions, especially in novels, poetry, and the holly Quran. Consider, for example, the following sentence: stone with your stick, and there gushed forth forms it twelve springs. X  2 In this sen-tence, the action of striking the stone, which was the result of the appearance of wate  X  X e stroked, so it exploded  X  X as not explicitly stated. The definition of implicit relations in Arabic has been controversial among linguists and has raised many interpretation and acceptance issues. It is not the aim of this study to add to these controversies, but we will restrict our study to the extraction of explicit relations indicated by ambiguous/unambiguous markers. Altenberg X  X  [1984] typology of causal linkage , which covers linking words and describes which clause or phrase is the cause and which is the effect , was of great importance for extracting Causal relations in English. Unfortunately, such a list does not exist in the Arabic language.

Discourse connectives such as  X   X  have an important linking function, linking two clauses. Arabic grammarians considered these items to be function words and they referred to them by the term  X  . X  which means  X  X ools. X  In their study, traditional Arabic grammarians provided comprehensive descriptions of these linguis-tic devices, classifying them as a grammatical class whose members operate within sentence boundaries [Kammensjo 2010; Hatim 1997].

In order to locate the elements that signal causation, we surveyed all causative con-nectors from the perspective of grammarians mentioned in Haskour [1990] and the verbs that are synonymous with the verb  X   X  (cause), for instance,  X  . X  Likewise, we studied the grammatical particles presented in Mughi al-labib [Haskour 2009] that indicate causation. We also investigated Arabic discourse in order to deter-mine the items that are commonly used in modern Arabic texts to indicate causation, such as the word  X  . X  The method adopted in this study is similar to the pattern-matching and slot-filling in IE [Cardie 1997; Cowie and Lehnert 1996]. It applies a set of predefined linguis-tic patterns to a natural language text in order to match particular types of relation and extract cause X  X ffect information. The patterns were generated by analyzing a data collection extracted from a large untagged Arabic corpus called arabiCorpus 3 . This corpus is nonvocalized, which makes it representative of real-world Arabic texts; furthermore, it is available online for exploration. The corpus consists of a variety of resources classified into five main categories: Newspapers, Modern Literature, Nonfic-tion, Egyptian Colloquial, and Premodern. It also provides useful searching tools that help in the study of lexical items and their syntactical categories in the sentences in which the link words under scrutiny appear. Furthermore, it has a number of filters that allow the search of specific words, including or excluding suffixes, such as looking up a word with pronoun endings. The search results are also supported with statis-tics and numbers of occurrences. We selected the Newspapers category, as it covers a wide variety of topics. This category represents a dataset containing approximately 135 million words of articles published between 1996 and 2010 in different Arabic countries. We initially constructed our set of patterns using a series of different kinds of tokens separated by spaces. The tokens were made easy to understand so that the set can be readily modified and extended with new patterns. For the pattern-matching process, a separate algorithm would convert each pattern in the set into sequences of literal characters and special symbols, namely, regular expressions that obey the conventions used by the JAVA programming language. Tokens used to formulate the patterns contain the following items:  X 
Particular word: This type of token searches the input sentence for any word that has the same characters as the token under scrutiny. For example, the words  X   X  and  X   X  in pattern P (1).  X  words, phrases, and particles. For instance, the subpattern &amp;This in pattern P (1) refers to a list of definite demonstrative nouns ( ).  X 
Part-of-Speech tag: Indicated in patterns by uppercase characters. Each tag repre-sents a certain syntactic category assigned to each word in the input sentence such as the definite noun tag DTNN in pattern P (1). Part-of-speech (POS) tagging was obtained from the Stanford tagger system. The POS tagger X  X  developers reported that it works rapidly with per-token accuracies of slightly over 97% [Toutanova et al. 2003].  X 
Slot: This token reflects the adjacent words that represent the cause or the effect part  X 
Symbol: Instructs the Pattern Recognizer model to take specific action during the pattern-matching procedure. These symbols could be one of the following: P (1) R (&amp;C) [C] AND + + &amp;This (DTNN) ++ VBD [E] &amp;.
 P(2)XC$Awww C As the discourse connectives are functional linguistic devices that acquire meaning from context, the constructed patterns should be adapted to cover various phrasings of sentences and syntactical structures. The pattern development process went through several steps of reasoning methods [Khoo et al. 1998]. Inductive and deductive phases were assembled into a single circular one so that the patterns continually cycle between both until we ended up developing a set of approximately 700 general patterns.  X  Inductive Phase: This is the initial step of the development process, which involves making specific observations from a sample of sentences containing Causal relations. This phase consists of detecting regularities and features that indicate the presence of a Causal relation, which led us to formulate some tentative patterns specifying cause and effect slots. For example, pattern P (3) was constructed from sentence (3) specifying that the words preceding ( ) represent the effect slot while the words following ( ) represent the cause . (3)  X  X ASA postponed the landing of the space shuttle Atlantis yesterday due to bad weather. X  P (3) R (&amp;C) [E] AND +[C]&amp;.  X 
Deductive Phase: Involves exploring the patterns that have been formulated in the previous step by testing them against text fragments extracted from the corpus. Each text fragment contained an occurrence of the causative unit addressed by the pattern and a  X  X indow X  of 10 words before and 10 words after this occurrence. The Arabic writer, however, prefers the use of regrouped and large grammatical chunks. Hence, in many cases, a longer  X  X indow X  needed to be investigated. Three types of errors may be returned upon conducting the patterns test in the deductive phase. Each kind of error was handled by performing another inductive step. Errors found can be classified as here: 1. Undetected relation: This error occurs when the constructed patterns are unable to locate the presence of a Causal relation in a text fragment. To fix this error, more patterns need to be added so that the missing relation can be identified. In some cases, it may be better to modify a pattern to cover all the absent relations by omitting some one. For example, pattern P (3) that was previously constructed to identify the Causal relation in sentence (3) would obviously miss the Casual relation presented in sentence (4) because of omitting one feature of pattern P (3), which is the word  X  . X  For that, we created pattern P (4), which is able to retrieve the missed relation. (4)  X  X he government has recently paid great attention to the development of agriculture to achieve food security X  P (4) R (&amp;C) [E] AND [C] &amp;. 2. Irrelevant relation: This is linked to the situation when the constructed patterns improperly recognize a relation as a Causal one. For this kind of error, we need to narrow down the scope of these patterns from the more general into the more specific by adding more constrains to them. Another way to amend this fault is to add a new pattern associated with the void value to exclude the expression that causes the error. For instance, the word  X   X  in sentence (5) distinctly expresses causality, thus pattern P (5) would correctly indicate the presence of a Causal relation. However, the occurrence of the word  X   X  in sentences (6) and (7) acts as cataphoric and anaphoric references that refer to other elements in the two sentences. This function can be identified by the definite noun following the causative connectors for sentence (6) or due to the connector position X  X t the end of the sentence X  X n sentence (7). In both instances, new patterns P (4) and P (5) of a void value should be constructed in order to indicate irrelevant relations. It is important to note that sentence (6) still contains a Causal relation signaled by the causation faa as will be discussed later in Section 4.2. (5)  X  X ust can obstruct the ventilation areas of a computer, leading to a rise of tempera-ture; therefore you must protect against dust. X  (6)  X  X ead the drug leaflet carefully before taking it since that drug may not be adequate for your illness. X  (7)  X  X he team leader did not disclose his intention to dismiss some of the team members, but his behavior points that out. X  P(5)R(&amp;C)[C] [E] &amp;.
 P(6)XC DTNN C P(7)XC &amp;. 3. Misidentify slots: In some cases, even though a relevant relation is correctly ex-defect is to reorder the patterns in a way that more specific patterns have the priority over the more general ones. For example, pattern P (5) is unable to correctly fill the pattern, such as pattern P (8), needs to be created and inserted before pattern P (5). (8)  X  X he Goods Trade Balance has some flaws; therefore , projects that rely on public services have been established by the government. X  P (8) R (&amp;C) [C] (AND) [E] &amp;.

Examples of the linguistic patterns for identifying the Causal relations signalled by the word  X   X  are given in Table II.

Algorithm 1 describes the actions taken to convert the patterns formulated in this study into their equivalent regular expressions. The algorithm replaces each of the pattern tokens with the appropriate string in order to match the POS tagger output. The tagger produces a sequence of tagged words, each of which has the form word / tag . For example, line 3 locates all POS tags in a pattern and substitutes each with a string the  X  +  X  operator in order to match one or more occurrences of any Arabic letter. Then, the targeted POS tag  X /tag X  is bound to the string, followed by another word boundary  X  \ b X . In lines 12 through 28, the algorithm replaces the symbols that represent Arabic word templates with actual Arabic letters. Finally, the algorithm omits all special symbols and maps all Arabic characters in a pattern with the equivalent encoding character UTF-16. Applying Algorithm 1 to pattern P (9) generates the converted pattern P (10).
 P (9) R (C) AND [C] VBD++ [E] &amp;.
 / \ w+ \ b \ s)+ \ b \ w+/VBD \ s( \ b \ w+/ \ w+ \ b \ s)+( \ b \ W/PUNC|CD|SYM \ b) The justification particles are those types of letters that are prefixed to a certain word to indicate causation and explanation in sentences. This set of particles includes purpose lam ( ), causation faa ( )and causation baa ( ). However, these particles are highly ambiguous since they hold a wide range of functions and purposes other than causation. Therefore, linguistic patterns cannot be employed for the detection of the syntactical rules that govern them, each of which requires specific actions and procedures to be considered.

The issue here is that to precisely recognize the justification role of these particles requires an accurate syntactic parser, which has not been used in this study. Hence, we proposed three algorithms that aim to make a judgment on whether a word starting with any of these particles implies a justification function. The algorithms may not be accurately capable of signifying the justification role of the aforementioned particles, but they effectively work with very little computational expense. Purpose lam is one of the most complicated particles in the Arabic language, as it expresses many meanings; some grammarians counted more than 30 different purposes for it. For instance, lam of denial ( )asin ( X  X halid was not a man to drink milk X ) and lam of possession ( ) when it indicates the right of property, as in ( X  X hmad had a large car X ). However, our concern here of the agent. Lam at- X  X aleel may also indicate the purpose for which, or the reason why, a thing is done. In this context, the Arab grammarians take lam at- X  X aleel to function similarly to ( )or( ) [Wright et al. 1896].
 The procedure we propose to recognize lam at- X  X aleel is outlined in Algorithm 2. It accepts as input a word ( W ) prefixed with the particle lam along with the tagged sentence that the word belongs to and a list of stop words. As output it returns a true value if the word X  X  context suggests a justification role and false otherwise. In the first line, the algorithm checks if the word X  X  length including the lam character is less than four letters, in which case the word is a particle such as  X  . X  ALGORITHM 1: Converting a Linguistic Pattern into Regular Expression String It also checks if the word is contained in the stop-words list; if yes, it yields a false result. In lines 5 through 8, the algorithm inspects the POS tag assigned to the word; and preposition), the algorithm returns false. Then, the algorithm treats the case of double lam . It examines whether the syntactic category of the word following ( W) is a preposition; if not, a false value will be returned. The double lam in sentence (9) is an example of a false case. In line 1,3 the algorithm returns true if ( W) matches any form of the verbs category. The next step tests if ( W) has the template ( ); at this point, we exclude the cases when lam prefixes  X  X oun of preeminence X  as in sentence (10). The condition in line 17 eliminates the words that denote plural nouns to both genders. In line 19, the ( W) is reduced to its stem before it is checked against a set of nominal templates. Those templates refer to  X  X resent participle X  and some forms of  X  X roken plural/irregular plural X  ;if( W) belongs to any of the former templates, the algorithm returns false. In lines 21 through 24, the algorithm considers the case when ( W ) length is more than four characters and starting with the ( ) letter. otherwise, it returns false. This way, we exclude the following forms of nouns:  X  X oun of place X  such as the one in sentence (11),  X  X oun of time X  and  X  X oun of instrument X  as in sentence (12). However, if a word of the previous forms contains (13). Finally, in the case that the aforementioned if statements were not applicable, the algorithm returns a true value, recognizing ( W) as a justification indicator. (9)  X  X s for the housing issue, the government has confirmed that it is considering a com-prehensive study in this regard. X  (10)  X  X he delegation has eventually arrived at the airport after waiting for more than ten hours. X  (11)  X  X he Ministry of Health allowed the dairy factory to resume its operations. X  (12)  X  X he author mentioned that many of his works were subject to censorship. X  (13)  X  X inisters of Environment will hold a meeting next month to discuss ways of reducing the emissions of pollutants. X  ALGORITHM 2: Determining the Potential Justification Function of lam role and many semantic properties. The illustrative examples stated in this discussion were taken from Saeed and Fareh [2006]. One of the particle  X  faa  X  roles is to signal a consequential relationship between two elements or events occurring consecutively and in the order indicated in the sentence. For example, ( X  X halid stood up, then Ahmad X ). Also,  X  faa  X  has an adversative function, in which it expresses a con-trast between two clauses, the second of which stands in adversative relation with the preceding. The following example illustrates this function: ( X  X y friend invited me to visit him, but I turned down his invitation X ). In addition, it contributes to indicating causation between two parts of a sentence. Consider the two examples in sentences (14) and (15). (14)  X  X hmad loved theatre and so he excelled in it. X  (15)  X  X o not cry because crying is weakness. X 
Several newspaper articles from the arabiCorpus were surveyed in order to identify grammatical and syntactical characteristics that help recognize the cases in which the particle  X  faa  X  functions as a causative conjunction. Consequently, we came up with the set of rules formulated in Algorithm 3.
 ALGORITHM 3: Determining the Potential Causation Function of the Particle  X  faa  X  Another particle that poses many difficulties is the particle baa . Grammarians denote various uses of baa [Wright et al. 1896]. One use of this particle is  X   X  to express time and place, for example,  X   X  ( X  X e travelled two days before me X ). Another use for baa is to indicate adhesion  X   X  X sin X   X  ( X  X ecause worms stick to the fruit X ). It can also be used to form negation expressions, as in  X   X  ( X  X  don X  X  know X ). Moreover, it expresses the reason, cause, or explanation, such as the particle baa . (16)  X  X od will grant him patience through the salutary power of prayer to him. X  (17)  X  X  wrote with the pen. X  ALGORITHM 4: Determining the Potential Causation Function of the Particle baa . It is a common trait of natural languages that a text involves a sequence of events that lead up to some final effect; this causal chain results in combining relations. Let us consider the three events subsumed in text (18); we notice that event 1 in slot I causes event 2 in slot II to form the Causal relation C1 X  X 1. Similarly, event 2 causes event 3 in slot III, creating the Causal relation C2 X  X 2. However, event 1 is also responsible for the result occurring in event 3. Accordingly, a new Causal relation, that is, C3 X  X 3, is created where event 1 and event 2 are joined together to constitute the cause part of the new relation, and event 3 constitutes the effect part. The following formula illustrates this rule of relations combination.
 model by a large margin, improving the overall recall by 33% for Health texts and 26% for Science &amp; Technology texts. However, employing the justification particle al-gorithms caused the rise of the number of instances in which the Pattern Recognizer mistakenly indicated the presence of Causal relations. Accordingly, the overall pre-cision degraded by 15% for the Health texts and 17% for the Science &amp; Technology texts. The main reason for this is, unsurprisingly, the number of errors accounted by the justification particle algorithms. Indeed, as mentioned earlier, these particles are ambiguous tools and can play different roles other than causation indicators.
On examining the relations set that the Pattern Recognizer failed to identify in stage 2, that is, incorporating the linguistic patterns and justification particle algorithms, we found out that 30 relations of the set (67%) were missed because of some particular kinds of linking words that were not included in the list of patterns. Some of these given in Text (19).

The other set of relations (15 relations), which the Pattern Recognizer was unable to discover, was due to unexpected sentence construction. This group covers 33% of the missed relations. An example is the Causal relation in sentence (20). This type of relation is indicated implicitly and inferred from the world knowledge needed to identify such relations. (19)  X  X But the secret, which is hidden from most women, especially those with olive com-plexion or Arab complexion, is that all of these products and treatments have short-term effects] C [unless we become aware that the Gulf sunlight spoils most of such treatments.] E (20)  X  X There are also the alternative therapies which, sometimes, work as a good substitute for chemical therapies,] C [and some of these therapies have become acceptable in the medical community] E  X  Early attempts at detection of causation made use of hand-coded and domain-specific knowledge bases. In the COATIS system [Carcia 1997], a model was built for causal knowledge acquisition by locating Causal relations between two expressions of actions in French texts. The model was created by doing manual classification of indicator verbs in technical domains. It applies the strategy of Contextual Exploration, which decides if the located indicator is likely to express a Causal relation, as well as to identify the argument of relations. In order to confirm the presence of a Causal relation in a sentence, the system takes into account the context in which the located indicators appear. This involves considering relevant information in texts such as morphologic and morpho-syntactic (the occurrence of an infinitive verb preceding or following the indicator). The author reported to have reached a precision rate of 85%.

Another attempt was presented by Khoo et al. [2000] in which English linguistic pat-terns were identified to extract cause X  X ffect templates that were explicitly expressed within sentences in a database of abstracts of medical journal articles and conference papers. They developed a parser to convert sentences and causality patterns into con-ceptual graphs that reflect the syntactic structure of the target relation. The graphs representing the patterns were then matched against the graphs representing the sen-tences to locate the presence of Causal relations and to fill the cause X  X ffect template with the textual parts that match each slot. They obtained an accuracy of 0.41 and 0.48 for extracting the cause and the effect slots, respectively A semiautomatic approach was proposed by Girju and Moldovan [2002] to identify Casual relations using lexico-syntactic patterns. It was called semiautomatic since the patterns were extracted automatically, whereas the process of pattern ranking and validating was performed manually. They first explored WordNet for pairs of noun phrases; then, a list of verb expressions was constructed by searching collections of documents for each pair located. Finally, several semantic constraints were applied on NP1 , NP2 ,and Verbs for ranking the patterns and validating the verbs. The authors focused their work on extracting patterns with the form &lt; NP1 verb NP2 &gt; which is, as the authors stated, the most frequent intrasentential form that indicates causation. The patterns were tested on the TREC-9 2000 collection of texts; two human subjects were asked to judge whether the relations returned by the system are Causal ones. The average accuracy obtained was 65.6%.

Machine-learning techniques were employed by a number of studies for automati-cally harvesting causal patterns. An example of these studies is the one presented by Blancol et al. [2008], in which the authors concentrated their work on the syntactic pattern [VP rel C], [rel C, VP] when performing pattern classification. They stated that this pattern comprises more than half of the causations found in the TREC5 corpus. Where the C symbol in the pattern stands for causation, VP stands for a verb phrase and rel for a relator (preposition or conjunction) that was restricted to the occurrences algorithm was trained to learn to discriminate whether or not a pattern referred to causation using a set of lexical, syntactic, and semantic features extracted mainly from WordNet. For example: Relator (A relator can encode a causation always or sometimes); Relator left and right Modifiers (adverb + after almost always signals a temporal rela-tion, not a causation, as + preposition can hardly signal a causation); Semantic Class a temporal relation not a causation); Verb Tense Cause and Effect Verb (if the relator passive, then it is more likely to express causation. Conducting the testing phase, the system obtained an F measure of 0.89 for cause and 0.91 for not-cause cases. However, the authors pinpointed that  X  X he model is only able to classify correctly the causations signalled by the relators because and since . X 
Support vector machines (SVM) were used by Beamer et al. [2007] as a learning model. The first model incorporated 18 lexico-syntactic and semantic features, and was trained on the dataset provided by SemEval 2007 Task 4; it achieved an accuracy of 77.5% in identifying cause X  X ffect noun pairs. The last model was trained over annotated texts of the Wall Street Journal and obtained a recall of 79.7% and precision of 24.4% in the causal relation identification task.

Prasad and Joshi [2008] tried to find out to what extent discovering Causal relations in texts would cover  X  why  X  questions. They made use of the annotated Penn Discourse TreeBank (PDTB) corpus as a resource of discourse relations. This corpus contains an-notations of explicit and implicit discourse relations held between two abstract objects in texts such as events, facts, and propositions. They selected QA pairs related to three of the PDTB corpus. The results obtained showed that 71% of the collected questions were correlated with one of the Causal relations.

More recently, a less supervised algorithm was proposed by Ittoo and Bouma [2011] by exploiting Wikipedia as a raw knowledge base. In the pattern acquisition phase, all sentences extracted from Wikipedia are converted into lexico-syntactic patterns, each of which represents a pair of events connected by a semantic relation. In the causal pattern extraction phase, a supervised algorithm decides which of these patterns encode causality. The pairs of events denoting Causal relations are then used to learn are kept. The acquired patterns were applied to specialized documents collected from customer service responses on medical equipment in order to evaluate their efficiency. With this approach, the researchers achieved high scores with a precision of 76.5% and recall of 82%. The automatic detection of semantic information in Arabic texts is rather a complex task because of the morphological variation, agglutination phenomenon, and irregu-lar syntactic forms that allow flexibility to swap any word category position in any sentence. Furthermore, the syntactical patterns of the Causal relations are relatively large compared to the size of the available training corpus. We addressed these chal-lenges by developing an analytical model that employs a set of around 700 linguistic patterns targeting intrasentential relationships, capturing statements of cause X  X ffect information. This model is enhanced with three algorithms to discover the Causal role that may be indicated by the justification particles. The Pattern Recognizer model was evaluated on eleven articles taken from Health and Science &amp; Technology domains. With the participation of human judges, a total of 240 Causal relations were manually identified. The linguistic patterns were then applied together with the justification particle algorithms. Under this condition, the results showed that about 81% of the re-lations that were picked out by the subjects could be correctly identified and extracted by our model. Furthermore, of the instances that the model identified as Causal re-lations, about 78% were correct. The majority of the incorrect instances were picked out by one of the justification particle algorithms, as they were highly ambiguous. Ignoring these particles and applying only the linguistic patterns improves precision by 16%. However, this improvement comes at the cost of the recall measure, which causes a reduction of 29%, demonstrating that this type of particle plays a key role as intrasentential indicator.

Utilizing a full syntactical parser and performing word sense disambiguation, espe-the precision measure. If a syntactical parser and lexical resources such as WordNet are used, the linguistic patterns can be made much simpler and fewer patterns need to be used. This will definitely come at the cost of computational complexity. Some promising work has been done in this direction [Abouenour et al. 2013; Green and Manning 2010].

The extracted linguistic patterns reflect strong relation indicators and constitute a useful feature in the future for systems adopting machine-learning techniques in acquiring patterns that signal causation.

This study made use of discourse connectives as indicators of the presence of Causal relations. However, Causal relation can also be expressed using some types of verbs. Such types are called causative verbs, which means that they induce causal elements. For example, the two transitive verbs ( X  X enerate X ) and ( X  X ill X ) can be paraphrased using the intransitive words  X  X ie X  and  X  X appen, X  respectively, as  X  X o cause to die X  and  X  X o cause to happen. X  Writers have different views on how to distinguish causal verbs from other transitive verbs that are not causal. Gonsalves [1986] pointed out that the in the causation by his acts. As an extension to this work, we plan to explore the use of causal verbs in the Arabic literature.

