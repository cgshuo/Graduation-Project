 accompanied by the generation of tremendous web contents. Web users are shifting from data cons umers to data producers. As a result, topic detection and tracking without taking users X  interests into account is not enough. This pa per presents a statistical model that can detect interpretable trends and topics from document streams, where each trend (short fo r trending story) corresponds to a series of continuing events or a storyline. A topic is represented by a cluster of words frequently co-occurred. A trend can contain multiple topics and a topic can be shared by different trends. In addition, by leveraging a Recurrent Chinese Restaurant Process (RCRP), the number of trends in our model can be determined automatically without human interv ention, so that our model can better generalize to unseen data. Furthermor e, our proposed model incorporates user interest to fully simulate the generation process of web contents, which offers the opportunity for personalized recommendation in online social media. Experiments on three different datasets indicated that our proposed model can capture meaningful topics and trends, mon itor rise and fall of detected trends, outperform baseline approach in terms of perplexity on held-out dataset, and improve th e result of user participation prediction by leveraging users X  interests to different trends. H.2.8 [ Database Management ]: Database Applications  X  Data Mining Algorithms, Experimentation Topic, Trend, User Interest, Evolution, Modeling. Different from the age of Web 1.0, nowadays web contents are mainly generated by web users. To catch the pulse of a rapidly changing world, it is critical to model the evolution of topics and users X  interests over time in a streaming fashion. Therefore, given a document corpus, the goal of this work is proposing a model to discover trending stories and their representative vocabularies, to detect topics and their evoluti ons, to classify each individual document to a trending story, and to understand web users X  interests toward the identified trending stories. This will bring great opportunities for news/blo g recommendation, personalized search, and marketing. From a statistical point of view, a topic is a cluster of words frequently co-occurred. For instance, news articles about  X  X uropean sovereign debt crisis X  might contain topics such as finance, trading, election and fore ign relationship. Similarly, news articles about  X  X ithdrawal of U.S. military force X  might involve topics such as election, foreign relationship, military and homeland security. In this paper, we consider  X  X uropean sovereign debt crisis X  and  X  X ithdrawal of U.S. military force X  in the examples above as two trending stories ( trend for short ). Different trending stories can share one or more topics. Specifically, a trend can be a series of continuous events or a evidenced in many online social media sites, users X  interests play an important role to the generation of web contents. Users interested in a specific trend have more motivation to contribute their opinions, observations or thoughts to online social media sites. Therefore, we consider user interests in this paper as their and user interest, figure 1 below shows three different trends (trend I, trend II and trend III). For each trend, we plot its volume (y-axis) over 4 consecutive time intervals (x-axis). Each trend may contain different topics indicated by different colors. A topic can be shared by different trends. In addition, in different time interval, the portion of a given topic inside a trend can be different to their interests to this trend within each time interval. Most of the existing works regarding topic detection and tracking employed either generative a pproaches or clustering-based techniques. These methods retrieve d topics as bags of words and captured the potential relationships between topics according to their word-based similarities, e.g. using KL-Divergence to quantify topic similarities when each topic was represented by a distribution of words [9, 11]. However, the topic evolution result obtained by these approaches is ha rd to interpret, as each ongoing trend might contain multiple topics and each topic can be shared by many different trends. For instance, 2012 NCAA tournament and 2012 UEFA Champions League are two completely different trends, although the news artic les about NCAA tournament and the news articles about UEFA Champions League share several common topics such as Sports, Commercial Promotion and Security. By merely knowing the rise or fall of a specific topic, for example security topic, without knowing which trend the topic belongs to, readers will find it difficult to capture the major trending stories. Some most re cent works tried to address this problem by introducing the concept of  X  X rend X  X 9] (or  X  X tory X  [1]). Generally speaking, Kawamae intr oduced a trend class variable into his Trend Analysis Model (TAM), where each document belongs to a trend and each trend has a probability distribution over topics and words. Unfortunately, the number of trends in TAM is fixed over time and needs to be predefined, which might be difficult in real-world applic ation. Furthermore, to our best knowledge, none of the existing topic detection and tracking works has incorporated dynamic user interests into their models. Different from the previous works which extracted topics from dynamic trends and topics from us er-generated contents in online social media. As a result, user interests must be taken into consideration. In addition, incor porating user interests into topic model might help the model to be tter generalize to unseen data. Figure 1. Illustration Exampl e of Concepts about Trend, In this paper, we propose a new pr obabilistic genera tive model to simulate the generation process of both web contents and users X  participations in a unified frame work. In our model, we use a latent variable to represent the trend label of each document which has benefits including: a) a document corpus can be well organized and navigated easily as documents within a corpus are classified according to their trend label; b) a detected trend can roughly represent a storyline or a series of continuous events which increases its interpretability; c) the word distribution of a given trend shows the signature terms of this trend which, to some extent, can be used to label a trend; d) each word can be generated by a background topic, a trend-specific background topic or one of the general topics shared by the whole corpus. In addition, our proposed model can determine the appropriate number of trends automatically in a document corpus by incorporating a RCRP. Last but not least, compared to existing works, another distinct feature of our model is that us ers X  participations are modeled simultaneously during the generati on process. It provides the recommendation, personalized search etc. In the next section, we review some existing works about topic detection and tracking. We pay part icular attention to two models, RCRP and TAM, which motivate our model and serve as baseline in the experiment section. In the past decade, topic modeli ng has attracted many research efforts from both academia and i ndustry. A topic consists of a cluster of words frequently co-occurred. Given a corpus, a topic model can distinguish words with different semantic meanings and extract hidden topics. Hofmann [8] proposed the PLSI model given the assumption that each docu ment contains different topics proposed the LDA model which used a Dirichlet prior to solve the over-fitting problem which makes the model more flexible. As further extensions, Rosen-Zvi et al. proposed the author-topic model [13], and McCallum et al . proposed the author-recipient-topic-model [10]. Recently, Liu et al. [18] developed a Bayesian hierarchical approach to perform topic modeling and author community discovery in a unifie d framework. However, all these works only investigated static topi cs or users without considering their evolutions. Beyond static topi c modeling, other researchers of Topic Detection and Tracking (TDT) exte nd topic modeling to take into account of their evolutions. Some researchers studied TDT problem by using gene rative models. In Mei and Zhai X  X  work [11], text streams were partitioned into intervals. They employed a probabilistic mixture model to infer topics within each interval and discovered their evoluti onary transitions using KL-divergence. Wang and McCallum [17] proposed a Topic-Over-Time model (TOT) to generate t opics. Each generated topic was associated with a cont inuous distribution over time. AlSumait et al presented an online version LDA model which automatically captures the thematic patterns and identifies emerging topics of text stream[3]. Similarly, Bl ei and Lafferty [5] designed a Dynamic Topic Model (DTM) by us ing Gaussian time series and logistic normal topic proportion m odels. Qi et al proposed to make use of citations to extr act evolutionary relationships between topics [6]. However, n one of these TDT models takes user information into consideration which is critical for modeling user-generated contents in online communities. Lin et al. [7] proposed to model topic evolution along with the burstiness of user interest. However, they modeled topics using a PLSI-like approach which suffered from the over-fitting problem. Other than using generative mode ls, some other research works rely on clustering approach to de tect evolving topics. Each cluster corresponds to a set of documents with a focused theme. Morinaga and Yamanishi [12] treated documents as an incoming stream and then used a finite mi xture model to cluster documents by maximizing their posterior pr obability. They al so applied the theory of dynamic model selec tion to detect emerging topics indicated by changes of th e mixture model. Schult and Spiliopoulou [14] proposed to use clustering approach to identify emerging and persistent taxonomy or ontology for documents. Shahaf et al introduced a novel method and a set of measurements to construct an information map, namely as metro map, to capture the connections of articles and provide structured summaries of information[15]. Recently, Ahmed and Xing extended the Chinese Restaurant Process to Recurrent Chinese Restaurant Process which can be used for evolutionary clustering for document corpus [2]. Concretely, the RCRP is formally defined as:  X  where  X   X , X  is a parameter of a likelihood function  X  X  X  be illustrated by a RCRP metaphor. Assuming that customers entered a restaurant in a given day are not allowed to stay beyond this day, at the end of day  X 1 X  , the owner of the restaurant records on each table the dish se rved on this table and the number of customers who shared it. When the i th customer  X   X   X  X  X  X  has  X   X , X   X   X   X  customers at day t before  X   X   X  X  X  X  of customers who sit on this table at day  X 1 X  . Alternatively, he can pick an empty table that nobody is sitting on at day  X  but  X   X , X  X  X  customers sit on at day  X 1 X  with probability Finally, he can pick an empty new table with probability RCRP here since it is used as an importa nt component in our proposed model later. Recently, Ahmed et al. proposed a new model, namely Storyline, which extended the traditional LDA model by incorporating the RCRP [1]. Storyline model combines the power of evolutionary clustering and topic modeling. Th erefore it can simultaneously group articles into storylines a nd identify prevalent topics. The Storyline model has distinctive di fferences to our proposed model in several aspects: 1) Our model captures user interests toward detected trends while Storyline completely neglect user information; 2) Compared to St oryline, our model uses a switch variable to control topic selecti on; 3) The generation process of topics in Storyline model an d our proposed model are also substantially different. Last but not least, Kawamae proposed a Trend Analysis Model (TAM) wh ich extends the TOT model and introduces a latten trend class variable into each document [9]. As shown in Figure 2, in TAM, each document is assigned to a trend,  X  , according to a multinomial distribution  X  . Given a trend based on a multinomial distribution  X   X  . At the same time, a switch variable  X   X  is sampled. According to the value of  X  be generated based on either a background topic, a trend-related background topic or one of Z topics. By introducing the concept  X  X rend X  into the model, some words can be generated directly from the trend class rather than from topics, which helps to model the generation process of the corpus more precisely. Further, relationships between trend and t opic are also modeled. However, TAM model has a few limitations as follows: 1) the number of trend is difficult to predefine for practical problems, 2) the model is unsuitable for processing documen t stream and 3) valuable user information in online social media is completely neglected. In this section, we introduce our Topic-User-Trend model (TUT) to detect evolving topics and tren ds, and discover users X  interests. This model depicts the generation process of web contents and user participations in a unified framework. By estimating this model, we can identify the major trends discussed by users in online social media, learn the t opical structure of web contents, and understand users X  interest s to the detected trends.  X  ,  X   X  All users , the user u  X  ,  X   X   X  ,  X   X   X  ,  X   X   X   X  is a concentration parameter  X , X , X , X , X  parameters of Dirichlet priors  X   X  the multinomial distribution of words specific to topic z  X   X  the multinomial distribution of users specific to trend e  X   X  the multinomial distribution of topics specific to trend e  X   X  the multinomial distribution of words specific to trend e  X   X  the multinomial distribution of switch variables specific  X   X   X , X  X  X , X , X  number of word tokens assigned to switch x = 0/1/2 in M  X , X  number of times that word w is assigned to topic z N  X , X  number of times that word w is assigned to trend e  X   X , X  number of times that topic z is assigned to trend e C  X , X  number of times that user u is assigned to trend e Topic-User-Trend model (TUT) is designed based on a real generation process of content terms and users. In online social media, we consider each document (e.g. a thread, a post, or a participants. In addition, it X  X  the trend itself, rather than the topics, that encourages the participation of users. For instance, although threads of NCAA tournament a nd threads of UEFA Champions League share common topics such as Sports, Commercial Promotion and Security, college ba sketball fans may participate more in the threads related to 2012 NCAA basketball tournament rather than the threads related to 2012 UEFA Champions League. In this work, we divide a time axis into several non-overlapping time intervals. Within each time interval, when a new document arrives, we first model the genera tion process of its trend label by a RCRP. Once the trend label of this new document is determined, users X  interests play an important role to decide whom this new document will attract. In additio n, depending on the trend label of this document, we model the ge neration process of its content terms by a variation of LDA model. Specifically, we assume that the generation of each content term is influenced by one of the three factors: 1) a general background topic, 2) a trend-specific background topic (e.g. 2012 NCAA basketball tournament or 2008 U.S. Presidential Election). and 3) topi cs shared by the whole corpus (e.g. economy topic, sport topic or military topic). Terms that are topic-unrelated but widely exist in the corpus have a higher chance coming from the general background topic. In addition, each trend may contain some signature terms serving as the trend-specific background term s. At last, similar to LDA model, the entire corpus shares a mixture of |Z| different topics. We adopt a switch variable to co ntrol the influence of these three number of topics, |Z|, is predefin ed and fixed while the number of trends is theoreticall y countable infinity in our model. Different trends can share common topics. Our proposed model is shown in Figure 3. The meanings of notations in Fig. 3 are listed in Table 1. As shown in Fig. 3(a), TUT model is a time-dependent model. Each component represents the generation process of documents in a time interval. Fig. 3(b) shows the detail of the TUT model in the  X   X  X  X  time interval. Within time interval t, the trend label  X  distribution over users (  X   X  and a new distribution over words (  X   X  trend. Otherwise, the existing  X   X   X |  X  | equal to the number of users pa rticipated in document d, the user list of d is generated by repeating the sampling process  X | times based on a trend-user distribution  X   X  drawn either from the general background topic or the trend-specific background topic or one of |Z| topics shared by the whole corpus. As mentioned, a switch variable  X   X  multinomial distribution for word  X   X  process. If  X   X  topic. If  X   X  topic,  X   X   X  distribution  X   X  topic. Overall, the generation process of users and words in the TUT model can be described as follows: For each time interval  X  from 1 to  X  : 1. Draw 1+|Z| multinomial distributions  X   X  from prior  X  , one for each topic (a general background topic and Z topics) 2. Draw |D| multinomial distribution  X   X  from prior  X  , one for each document 3. Draw |E| multinomial distributions  X   X  ,  X   X  and  X   X   X  X  X   X , X  respectively, one for each existing trend For each document  X  of time interval  X  : Several methods have been developed to estimate the latent variables in a probabilistic graphical model. Among them, Gibbs sampling often yields relatively simple algorithm for high-dimensional data model. In th e Gibbs sampling schema, Markov chain is constructed for simula ting the generation processes of terms and users. The transition between successive states in the Markov chain is achieved by repeatedly sampling topic and trend for each observed term and us er based on its conditional probability. We first provide the joint distribution and then derive conditional probabilities for trend label and topics respectively in section 3.2.1 and 3.2.2. time interval and O  X  to denote all observations of the t interval including words and users. Instead of finding a global optimization of  X  X   X   X   X  X  X  X   X  , given the whole observation sequence  X  O  X  ,O  X  ,...,O  X   X  , our goal is to find greedy optimization configuration as did in [16]. Specif ically, we assume that we only observe O  X  X  X  O  X  X  X   X  . We want to maximize the posterior probability Pr  X  X   X  | X   X  X  X   X  ,O  X  X  X  ,O  X   X  , where  X  optimal hidden variables estimate d for time interval t-1. The justification is that, instead of observing the whole observation assume that the data comes in a stream fashion and we update the model sequentially. In the inference process, we need to first calculate the conditional distributions. As shown in the previous subsection, the joint distribution of the documents of time t is computed as:  X   X  X  X  X  X  X  X  Pr  X   X   X   X , X , X , X , X , X , X , X , X , |  X   X  X  X   X , X , X , X , X , X ,  X   X  X   X   X   X  X   X  X r  X   X  X   X  X  X Pr  X   X  X  X  where  X  X  X  X  X  X  X  X  X  X   X  X  X  . In the joint distribution above, multinomials (  X  X , X , X , X , X  can be adapted by the conjugate priors (  X  X   X , X , X , X  and then integrated out eventually. The conjugate priors can be predefined in this work. Therefore, we only need to steps. The first step is to sample the trend label,  X   X   X  d of time period d,  X Pr X   X   X   X ...| X  X  . The second step is to sample the switch variable and the topic for each individual word in a document: Pr  X   X   X  X  X  X   X 0 | ...  X  ,Pr  X   X   X  X  X  X   X  X 1 X   X   X  ... X  X   X  ,Pr  X   X  . Details of the derivation of Gibbs sampling for TUT is given below. For each document, we use the chain rule to obtain the conditional distribution to sample its trend label  X   X   X  . The sampling equation is defined as:  X  X  Pr  X   X   X ...| X  X   X  X   X   X  assigned to trend e, except in document d. Similarly,  X  represents the number of times that topic z is assigned to trend e, except in document d; N  X , X  X  X  represents the number of times that word w is assigned to trend e, except in document d. The terms within the first square bracket m easure the posterior probability of observing users in document d given the trend label  X  measures the posterior probabilit y of observing topics and trend-specific background words respectively given  X   X   X   X  X  behind the curly bracket denote the probability of assigning document d to trend e by following the RCRP [2]. When time t = 1 which means historical trend information is unavailable, the top half of the term is used (  X  &gt; 1, the second half of the term is used (  X  belonging to a new trend and  X   X  X  X , X  an existing trend e) By using the chain rule again, for each word token, the posterior probability of adding word  X   X  is derived as: Pr  X   X   X  X  X  X   X 0 | ...  X   X  where the first term measures th e probability of having the switch variable equals to 0, and the second term measures the probability of generating  X   X  Similarly, the posterior probability of adding word  X  document d to trend  X  is derived as: Pr  X   X   X  X  X  X   X  X 1 X   X   X  ... X  X   X   X  where the first term measures th e probability of having the switch variable equals to 1, and the second term measures the probability of generating  X   X  Similarly, the posterior probability of adding word  X  document d to topic  X  is defined as: Pr  X   X   X  X  X  X   X , X  X   X  X  X  X   X 2 | ...  X   X  where the first term measures th e probability of having the switch variable equals to 2, the second term measures the probability of selecting topic k in trend e, and the third term measures the probability of generating  X   X  Once the sampling processes converge based on the conditional distributions derived in sections 3.2.1 and 3.2.2, we can estimate the five parameters usi ng the following equations: In the previous section we in troduced the TUT model, a new statistical model for topic and tr end tracking and user interest discovery. In this section, we evaluate the effectiveness of our model with experiments on three diffe rent datasets. First of all, we conducted a qualitative analysis on the topics and trends detected by our model. Secondly, we compared our model to the Trend Analysis Model [9] on several different datasets by using perplexity and rate of convergen ce as measurements. Finally, we built a recommendation model to test if the trend-user distribution is effective to predict user participation. Data 1 ( DBLP Dataset ): We implemented a XML parser to extract bibliography data from DBLP. Our dataset contains 10 years (2001-2010) of research papers in conference proceedings including CIKM, KDD, WWW and SIGIR. Each document in this dataset corresponds to a publicati on where title, author list and year of publication were extracted to form the content, user list and timestamp respectively. We preprocessed the data by removing stop words, stemming, and filtering low frequency words and authors. Concretely, we obtained a total set of 4,631 documents and 1,627 users. We considered one year as the time interval. The training set includes documents from 2001 to 2009 and the test set consists of documents from 2010. Data 2 ( Digg Dataset ): Digg (digg.com) is a social news website where users can post news, make comments, or vote up/down other users X  posts/comme nts. In this experiment, we selected the 5 most popular news sources in Digg: CNN, BBC, NPR, The Washington Post, and Yahoo! News. We then built our dataset by using Digg open API to collect all posts as well as their comments from these five news sources during the period between March 1 2011 and May 31 st 2011. Each post and all of its comments were aggregated as a document in this dataset. Contents from both a post and its comments were combined to be the content of a document. The post initiator and all commenters were extracted to be a user list. The same pre-proc essing used for DBLP dataset was then applied. Accordingly, we obtained a total set of 9,894 documents and 2,356 users. We considered a week as the time interval. The training set includes the documents from March 1 2011 to May 15 th 2011 and the test set consists of the documents from May 16 th 2011 to May 31 st 2011. Data 3 ( MySpace Dataset ): MySpace is one of the popular social networking sites which offers its registered users to start a new thread to discuss several topics or participate in a thread created by other users and make comments. In this study, we used a public data set available for workshop CAW 2.0 (http://caw2.barcelonamedia.org/ ). The original MySpace dataset provided by the workshop consists of threads from three different sub-forums: campus life, news &amp; politics and movies. In our experiment, we used threads fro m news &amp; politics sub-forum and movies sub-forum. The same pre-processing used for DBLP dataset was then applied. We transformed the original dataset to an input format of our model. E ach thread and its comments were aggregated as a document in our dataset. Contents from both an initial post and its comments were combined as the content of a document. The post initiator and all commenters were extracted to be the user list. Accordingly, we obtained a total set of 3,886 documents and 1,373 users. The time range of our processed dataset spans from October 2007 to November 2008. Therefore, we considered a month as the time interval. The training set includes the documents from Oc tober 2007 to September 2008 and the test set consists of the documents from October 2008 to November 2008. In the first experiment, we conducted a qualitative analysis on the MySpace dataset to investigate the quality of the topics and trends detected by our proposed model. In order to produce a small example fitting this paper X  X  size, we chose the number of topic |Z|= 50. We empirically set  X 1 X  and let  X   X , X 0.1  X   X , X 0.1 X  X 0.5,  X ,0.1  X   X , X 0.1  X   X 0.2 and  X   X   X 0.7 . Table 2 shows an illustrative example of 10 different topics extracted from MySpace dataset of August 2008 by our proposed model. The top 10 words with the largest topic-word association were presented for each topic in table 2. The top 10 words in each topic in table 2 show clearly what each topic is about and how the topics are differentiated. For instance, topic 6 is about taxation and 
Afghanistan 0.0207 employment. Topic 11 is about military. Topic 39 is about finance and topic 14 is about campaign. We further analyzed the detected trends by selecting three trends as examples and listing top 5 topi cs with the largest trend-topic association for each trend, as showed in table 3. These three trends were manually labeled by human annotator according to the content of the threads assigning to them and their top topic list. These three detected trends are: 2008 Georgia-Russia Crisis, 2008 Mortgage and Credit Crisis and 2008 U.S. Presidential Election. As shown in table 3, some topics were shared by these three trends. We highlighted a topic in blue if it was shared by two trends and highlighted a topic in red if it was shared by three trends. For example, from table 3, we noticed that topic 14 (campaign topic), was shared by all three trends. From our understanding, trend A (2008 Georgia-Russia Crisis) happened around the same time as trend C (2008 U.S. Presiden tial Election). At that moment, presidential candid ates X  attitude toward this crisis was critical to exhibit their experience and capability of dealing with foreign affair, which explains why threads of trend A involved in campaign topic. Sim ilarly, 2008 Mortgage and Credit Crisis continued to worsen from March 2008, when the U.S. Government freed up $200 billion to support Fannie Mae and Freddie Mac mortgage giants, to September 2008, when Lehman Brothers investment bank declared bankruptcy and the U.S. Government bailed out AIG. As a result, threads of trend B (2008 Mortgage and Credit Crisis) una voidably involved campaign topic which showed the American X  X  hope for a new president to remedy the economic problems. Similarly, threads of trend C (2008 U.S. Presidential Election) shared topic 6 (taxation and employment) and topic 39 (finance) with trend B (2008 Mortgage and Credit Crisis), which is also reasonable because possible solutions to the Mortgage and Credit Crisis were very hot topic during the 2008 U.S. Presidential Election. To sum up, without modeling trends and their associated topics (as in the traditional topic modeling works), it is difficult for us to a gain comprehensive view of each trend and find out the connections among them through their common topics. In addition, we measured the volume of threads in each trend in one year period and visualized their accumulated volume in Figure 4. X-axis in figure 4 represents timeline and y-axis of figure 4 indicates the accumulated percentage of volume of the whole dataset. Concretely, 2008 U.S. Presidential Election was the most eye-catching event which attracted lots of threads in MySpace between Oct 2007 and Oct 2008. This campaign involved several different issues including taxation, employment, finance, counter-terro rism, military and more. We observed two peaks of trend C (green area). The first peak happened around February 2008 which can be expl ained by the primaries and caucuses, especially on the Supe r Tuesday, 5 February 2008. The second peak happened when the Election Day was getting closer. Similarly, for the trend of 2008 Mortgage and Credit Crisis, its volume was close to zero before 2008 but became substantially larger since January 2008. As we know, the Mortgage and Credit Crisis continued to worsen since UBS reported an $18 billion write-down due to its exposure to th e American real estate market in January 2008 and Fannie Mac reported $3.55 billion loss for the fourth quarter of 2007 in February 2008. The increase of trend B X  X  volume also can be explained by the fact that the crisis became even worse and the U.S. Congress gave final message to multi-billion-dollar program and tried to address the crisis in July 2008. Further, trend A kept going upward which indicated the Georgia-Russia crisis was getting more and more intense, especially when the South Ossetia War broke out on 7 August, 2008. Trend Popular Topic List A. 2008 Georgia-Russia Crisis 0,3,26, 14, 40 B. 2008 Mortgage and Credit Crisis 6,32, 14,39,49 C. 2008 U.S. Presidential Election 40, 14, 6,39,11 Figure 4. Accumulated Volume of Trends in MySpace Dataset In this section, we used perple xity as an evaluation metric to investigate the performance of ou r proposed model in 3 different datasets. For each dataset, we trained the model in its training set and computed its perplexity in th e test dataset. Trend Analysis Model (TAM) [9] is employed as a benchmark. The major differences between TUT and TAM are: 1) TUT can automatically decide the number of trends while TAM needs human intervention to predefine the number of trends; 2) TAM is unsuitable for processing document streaming; and 3) TUT models the generation proce sses of contents and user participations in a unified fram ework while TAM neglects all user information. Perplexity is a standard measur e for evaluating the generalization performance of a probabilistic model. The value of perplexity reflects the ability of a model to generalize to unseen data. Specifically, in our case, perplexity reflects the ability of a model to predict words for unseen documents. The perplexity is monotonically decreasing in the likel ihood of the test data, and is algebraically equivalent to the i nverse of the geometric mean per-word likelihood. A lower perplexity score indicates better generalization performance. We follow [9] and define the perplexity score for a test set  X   X  X  X  X  X  as: where In the equation above,  X   X , X  represents the probability of observing switch variable equals to  X  in document d,  X   X , X  probability of observing word  X  given topic  X  ,  X  the probability of observing word  X  given trend  X  represents the probability of observing topic  X  given trend  X  probabilities  X   X  X  X , X  ,  X   X , X  ,  X   X  trend in the training set) are le arned from the training set, and  X  set) are estimated by a Gibbs sa mpling process on the test set. As mentioned in the literature review, TAM needs human intervention to predefine its number of trends |C|. However, in real world application, it X  X  nontrivial to find out the optimal |C|. In addition, our proposed model can automatically decide the number of trends in a dataset wit hout human intervention. In this sub-section, we first studied the performance of TUT on Digg dataset . For TUT model, we set  X 1 X  ,  X   X , X 0.1  X , X 0.1 X   X , X 0.1 X ,| X |/50  X   X , X 0.1  X   X 0.2 and  X   X   X 0.7 . The experiment results were shown in figure 5. It X  X  important to note that both TAM and TUT have fixed number of topics which needs to be predefined. Therefore, the x-axis in Figure 5 represents different represents the perplexity score in test set. TAM(5) denotes a TAM model with predefined number of trend |C|=5. TAM(10) denotes a TAM with |C|=10 and TAM(20) denotes a TAM with |C|=20. The number of trends determined automatically by TUT is around 11 (average number of 5 repeating experiments), so that we only tested TAM with |C| equaling to 5, 10 and 20. Figure 5 shows that TUT model achieved the lowest perplexity score across all settings of topic number comparing to TAM. We also observed that in TAM the perplexity score roughly increased with the value of |C| while TUT performed relativ ely stable. Last but not least, even though TAM(10) has a very close trend number to TUT in Digg dataset, TUT still outperformed TAM(10). Figure 5. Perplexities over different # of topics for TUT and Furthermore, we compared the cha nge of perplexity over iteration number during Gibbs sampling process. The results are shown in Figure 6. We set the number of topics, |Z|, to be 100 based on the following considerations: 1) all four models achieved decent performances when |Z| = 100; and 2) when |Z| = 100, it simplifies the result for clear visualization. From this figure, we observed that all these models are able to converge quickly. But given a perplexity score comparing to TAM(5), TAM(10) and TAM(20) 
Figure 6. Perplexities over the number of iterations for TUT model and TAM model with different # of trend in Data 2 Additionally, we compared the performance of TUT and TAM in the other two datasets. We repeated each model in each setting for five times and reported the av erage number. The experiment results were summarized in Figur e 7 and Figure 8 respectively. For DBLP dataset, we predefined the number of trends for TAM to be 5, 10 and 20 respectively, because the average number of trends identified by our proposed m odel in test set equals to 11.5. We set  X 1 X  ,  X , X 0.1 X ,| X |/ X 50  X , X 0.1  X , X 0.1 X   X   X , X 0.1  X  0.2 and  X   X   X 0.7 . Similarly, we predefined the number of trends for TAM in MySpace dataset to be 5, 10 and 20 respectively since the average number of trends identified by our proposed model in MySpace X  X  test set equals to 20.25. We set  X 0.1 X  ,  X  X  X  X 0.1,  X   X , X 0.1 X ,| X |/ X 50  X ,0.1  X   X , X 0.1  X   X 0.2 and  X   X   X 0.7 . From both Fig. 7 and Fig. 8, we observed that our proposed TUT model consistently outperformed TAM in all settings of trend number and topic number. In additi on, the perplexity scores of TUT were relatively stable comp aring to TAM. As we know, the number of trends should be different in different time interval, but we predefined and fixed the number of trends for TAM according to the result of TUT, which might bring difficulties for TAM to generalize to the test dataset. However, even though TAM(10) has a very close number of trends to TUT in DBLP dataset, TUT still outperformed TAM(10). The same applies to TAM(20) in MySpace dataset. One possible expl anation is that, modeling user participation, to some extent, might help TUT model to better generalize to the unseen dataset. Figure 7. Perplexities over different number of topics for TUT Figure 8. Perplexities over different number of topics for TUT Modeling user interest is critical for news/blog recommendation and personalized search. One of the important outputs of TUT model is trend-user distributions, which can be considered as users X  interests toward each detected trend. In this experiment, we evaluated the usefulness of the user interests to boost ranking for potential participant prediction. The experiment was conducted in Digg dataset . Generally speaking, we first trained a recommendation model based on the Digg dataset X  training set. Then, for each document in its test set, we randomly removed 80% of the users and only withheld the other 20%. We then used the recommendation model to predict users and compared the result to the ground truth (the removed users). We first used a na X ve ranking method as a baseline approach and then boosted the baseline by the user interests dete cted by our proposed model. Our goal is to show that, even though with a straightforward combination method, the detected user interests can boost the na X ve ranking approach substantially. constructed a bipartite grap h based on the user-document relationships observed in the training dataset. The bipartite graph consists of nodes and edges. Each node represents either a Digg user or a document posted in Digg.com. All nodes representing users are on the left hand side while all nodes representing documents are on the right hand side. Each edge of the bipartite graph connects a user to a doc ument which means that a user similarity between user  X  and  X  is defined by the Jaccard Index as: user  X  participated. In this way, we calculated the similarity between every two users in the training set. Given a new document  X  in the test set and its 20% of withheld users,  X  ranked all other users, excluding those in  X   X  X   X  X   X  where  X   X  represents a bipartite graph. The rationale of this na X ve raking is This na X ve ranking method relying on user similarity will serve as the baseline approach in this experiment. On the other hand, for our boosted ranking method , based on the trend-user distributions  X  that we obtained from the training set, we know which trends a user will be interested. By applying a trained TUT model to the test set, it automatically assign each document in the test set to a trend  X  . Since we already know users X  interests toward each trend , X   X   X   X  X  X  X   X , X   X ,  X , X   X ,..., training set, the boosted ranking for user  X   X  then redefined as: where Pr X  X   X  X  X   X   X   X   X   X  X   X  , X   X  interest to trend e  X  and w denotes the weight to combine the baseline approach and user interests. The experiment setup is as follow s: 1) Using the training set, we constructed a user-thread bipartite graph and calculated user similarities; 2) Based on the user similarities computed in step 1, we applied the baseline ranking method to predict users for each document in the test set (results from the first two steps were used as baseline); 3) Using the training set again, we trained our TUT model to discover users X  interests to trends; 4) We applied the trained TUT model to assign a trend label to each document in the trend label from step 4 and also users X  interests to each trend from step 3, we applied our boosted ranking method to predict its potential participants. We employed Precision@K as the evaluation measure in this experiment. Specifically , by using Precision@K, we consider the top-K list resulted by a recommendation method. Let m denotes the number of users that co-exist in the top-K list and the ground truth list of a document, Precision@k equals to  X   X   X  . The higher the value, the better the perform ance of a recommendation method is. We empirically set weight w to 0.5. As shown in Table 4, our boosted ranking method consistently outperformed the na X ve ranking from K=5 to K=30. The highlighted red figures within parentheses indicate the percenta ge of improvement of boosted rank comparing to the baseline approach. Na X ve Ranking Boosted Ranking In this paper, we proposed a Topi c-User-Trend Model to simulate the generation process of user-generated web contents. By incorporating a latent variable  X  X rend X  and using RCRP to enable our model to decide automatica lly the appropriate number of trends in a document corpus and also taking users X  interests into account, our proposed model is able to model the generation process of web contents in a more meaningful way. At the same time, our model achieves a better generalization performance than the TAM model in multiple test datasets. Besides, the user interests learned by our proposed model can be utilized for document recommendation, which substantially improved the performance of the na X ve ranking method which relies on user similarity only. Thus far, our proposed model only considers users participated in a given document without taking their interactions into consideration. In the future work, we will incorporate the generation process of user relation ships into our model. Moreover, we will further explore other o pportunities to make use of the trend-user association for recommendation problems. [1] Ahmed, A., Ho, Q., Eisenstein, J., Xing, E., Smola, A. J. and [2] Ahmed, A. and Xing, E. 2008. Dynamic non-parametric [3] AlSumait, L., Barbara, D. and Domeniconi, C. 2008. On-line [4] Blei, D., Ng, A. and Jordan , M. 2003. Late nt dirichlet [5] Blei, D. M. and Lafferty, J. D. 2006. Dynamic topic models. [6] He, Q., Chen, B., Pei, J., Qiu, B., Mitra, P. and Giles, L. [7] Hearst, M. A. and Pedersen, J. O. 1996. Reexamining the [8] Hofmann, T. 1999. Probabilistic latent semantic indexing. [9] Kawamae, N. 2011. Trend analysis model: trend consists of [10] McCallum, A., Corrada-Emmanue l, A. and Wang, X. 2005. [11] Mei, Q. and Zhai, C. 2005. Di scovering evolutionary theme [12] Morinaga, S. and Yamanishi, K. 2004. Tracking dynamics of [13] Rosen-Zvi, M., Griffiths, T., Steyvers, M. and Smyth, P. [14] Schult, R . and Spiliopoulou, M. 2006. Discovering emerging [15] Shahaf, D., Guestrin, C. and Horvitz, E. 2012. Trains of [16] Sun, Y., Tang, J., Han, J., Gupta, M. and Zhao, B. 2010. [17] Wang, X. and McCallum, A. 2006. Topics over time: a non-[18] Zeng, H.-J., He, Q.-C., Chen, Z., Ma, W.-Y. and Ma, J. 2004. 
