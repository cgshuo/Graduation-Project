 1. Introduction
The approach search engines (SEs) follow in order to collect and rank data has drastically changed during the last three years.
From a link and popularity-based ranking scheme, Google, Bing and Yahoo! SEs nowadays try to capture user experience and consider this as a major factor affecting their ranking mechanisms.
Obviously, Search Engine Optimization (SEO) methods also have to be updated in order to cope with the changes in the search engine ranking strategy. The ultimate SEO goal is to provide the basic policy to optimize websites, in order for the latter to succeed in higher and better related rankings in the search engines, as well as better targeted traf fi c, both in volume and depth.

Due to the nature of the web, there will always be some SEO technique that will prove effective with respect to ranking in search engines; after all, search engines do not have the ability to generate popular content, only to recognize it with the use of certain factors and promote it. Given that an SEO approach identi fi es these factors, it strives to  X  exploit  X  them as much as possible. Up until recently these factors were only based on machine-generated characteristics; now,
Google has switched its focus towards the quality of content to the users, and considers it as a vital characteristic on the evaluation process of a given website ( Koningstein, 2012; Lamping and Pearson, 2011 ). Based on its recent patents, Google also states its intention to capture user experience. Agarwal et al. (2013) have described the methodology Google employs in order to provide personalized con-tent to users according to predictions based on previously captured user behavior.

It is common knowledge that SEs employ crawlers that parse the web and reveal them the link structure of the web. Apart from text, tags and links to URLs, crawlers have evolved into mechan-isms that gather content from javascript, fl ash, frames and links to fi les, also. This type of content is largely available in Web 2.0 sites, where social media provide a wealth of user-related experiences and preferences of web content.

On the other hand, one should mention that Berners-Lee et al. (2001) vision of a Semantic Web is fi nally starting to fl the effort to organize the web on its content, semantic mark-ups have been de fi ned. SE crawlers are now also responsible for recognizing all the SE types of semantic markups, analyzing them down to their semantic triples ( Sintek and Decker, 2002 ) and retrieving their content. The level of use of semantic structured data differs according to the domain of the website. It is obvious that all this content coming from web 1.0, 2.0 and 3.0 sites, along with user experience factors, is retrieved, stored and indexed by the crawlers.

Upon a given query, the search engine returns the most relevant documents ranked by importance, which corresponds to SE popularity. And this popularity is different for each SE; it is determined through complex algorithms that employ a plethora of criteria or ranking factors constantly changing over the last decade. 1 Most search engines provide web content developers with guidelines in order to be SE-technical detail, but they all include the same basics for SEO: (a) focus should be given on the creation of unique, qualitative and fresh content, (b) content should target the users and not search engines, (c) proper link architecture and strategy should exist to help SEs to navigate, discover and index content, (d) keywords should be used and placed properly in the text and tags of a webpage, (e) robots.txt should be de fi ned in order to interact correctly with a website and, fi nally, (e) social media components are useful for the promotion of a content's popularity.

Though these guidelines are open, the exact ranking mechan-isms algorithms of the search engines are not published. As a result, one has to guess the SE ranking strategy by reading patents and analyzing their result pages. Additionally, it is essential to consider that there are differences in the trends in webpage and semantic characteristics in different domains. We argue that the search engine ranking factors could present signi fi cant differences in the level of their in fl uence considering the domain of interest.
Moreover, due to this lack of transparency by the SEs, there have been attempts by organizations and companies to create custom-made metrics that evaluate a website's presence around web and search engines from various perspectives. One of the most promi-nent companies in SEO fi eld is Moz 5 (former SEOmoz) that has created metrics regarding the authority, trust and other attributes of a website. These metrics have been widely used around the web by users in order to assess the progress of websites and present high level of interest in their analysis. They are not transparent, though, therefore analysis of the Moz metrics can be performed only by analysis of web documents' scores on them.
 To this end, we present our mechanism LSHrank (Latent Semantic
Headless rank), emphasizing on the ability to extract webpage and semantic characteristics out of web documents. LSHrank is a headl-ess crawler, that extends our previous work, LDArank ( Mavridis and
Symeonidis, 2012 ). Despite LDArank's promising results, it approached the fi eld of semantics only by performing content analysis. In order to obtain a more holistic view of the fi eld, LSHrank builds upon LDArank 's schema, ranks the results based on various SEO metrics, generates optimal content out of the semantic analysis on the corresponding web documents ( Mavridis and Symeonidis, 2014 ), introduces the recognition of webpage and semantic characteristics, and explores their in fl uence as ranking signals.

The aim of this work is the identi fi cation of the different in fl uence of various characteristics on the ranking schemas of SEs between two different domains. Our hypothesis is that semantic data have emerged as signi fi cant ranking factors, yet they display different level of in fl uence according to the domain examined. We argue that search engines in their attempt to integrate semantics in their mechanisms, present small scale, yet signi fi cant, differences.
Moreover, we assume that the Moz metrics are in fl uenced by more characteristics, including semantic related data and domain choice, than their of fi cial descriptions state. LSHrank de fi nes a procedure in order to test our hypotheses and to explore the level of integration of semantic characteristics in results from different domains.
The remainder of this paper is organized as follows: Section 2 discusses state-of-the-art with respect to the ranking factors of search engines in a Web 2.0 and Web 3.0 context, while Section 3 presents the architecture of our crawler LSHrank , with focus on its procedure of analyzing the result pages of search engines to extract conclusions regarding their ranking schemas. Section 4 performs a thorough set of experiments with different SEs on different domains (and domain types) in order to recognize the various levels of in fl uence of the webpage and semantic charac-teristics as search engines ranking signals. Section 5 discusses the experiments run against the Moz ranking metrics in order to explore their factors of in fl uence. Finally, Section 6 outlines future directions and concludes the paper. 2. Related work/background theory
Given the constant evolution of the web and the respective continuous attempt by the major SEs to grasp this evolution on their SERPs (Search Engine Result Pages), factors that affect ranking in search engines, as well as the degree of in fl factors have constantly change. The following sections discuss the state-of-the-art on search engine optimization, crawling techni-ques and the ranking factors, under the prism of user experience, in a social and semantic web context. 2.1. Search engine ranking factors 2.1.1. Ranking factors survey
The transformation of the Web from a read medium to a read/ write (Web 2.0) and the read/write/infer (Web 3.0) one, has led to the enhancement of SE ranking with new ranking factors, making others obsolete. Nevertheless, according to a bi-annual survey performed by Moz, 6 some factors are considered as de-facto standards and strongly in fl uence SE ranking ( Fig. 1 ). What is interesting to see is the importance of domain-related metrics and how they gain popularity.

Early 2011 Google 7 announced its fi rst Panda Update. Through this, Google increases focus on domains and considers the domain-level metrics to be equally important to page-level ones.
The basic idea behind the Google Panda Updates is that quality raters have been providing information on what they like in order to incorporate this intelligence in their machine learning process and as a result into the SE results. Consequently, Google ranks websites based on user experience and the design of a website. In that sense, Panda is much more than an algorithm update; it could be considered as a platform that provides alternative ways to understand the web.

Moreover, Google has been publishing bi-monthly updates that cover a variety of issues, namely how page quality is calculated, what is the rank of  X  trusted sources  X  , what link-scheme detection mechan-ism to follow, even how Exact-Match Domains are treated to changes on anchor-text scoring, freshness and richer snippets creation. 2.1.2. Correlation of ranking factors
Fig. 2 depicts the spearman correlation coef fi cient of all the critical factors to SE rankings, including social media-based factors, based on data from analyses performed by Moz, 8 Searchmetrics and The Open Algorithm. 10 It is important to mention that the three-way classi fi cation of the values of the spearman correlation into small ( r s 4 0 : 1), medium ( r s 4 0 : 3) and large ( r 2009 ) does not apply in the fi eld of search engines' rankings, since a plethora of factors are considered into the ranking schemas of the search engines.

Apart from the typical ones, one should pay attention to the following metrics: i. Moz mozRank is a logarithmic scaled 10-point measure of ii. Moz Page Authority is a metric on how high a given webpage is iii. Moz Domain Authority is a metric similar to Moz Domain iv. Moz mozTrust quanti fi es the trustworthiness of a webpage to all the other webpages on the web. It builds upon an algorithm originally developed by Yahoo! search engineers (similar to the trust algorithms used by Google and Bing search engineers). v. LDA stands for Latent Dirichlet Allocation , a probabilistic tech-nique widely applied in text summarization. It was fi rst published by Blei et al. (2003) and has appeared as an interesting ranking factor, given its capability to analyze web page content.

All the above metrics are calculated on the Mozscape, 11 which is a database index by Moz comprising 776 billion links, 119 billion URLs, 172 million RDs.

Based on Fig. 2 , it is also obvious that semantic signals are of increasing in fl uence. Additionally, the number of external and internal links display high correlation with the SEs.
 On the other hand, user experience starts to play a pivotal role.
To this end, Google has announced the  X  Penguin  X  X  webspam updates 12 that focus on over-optimization and adjust a number of spam factors including keyword stuf fi ng. Page layout algorithm improvements have been published, the use of knowledge graph has been initiated, the DMCA (Digital Millennium Copyright Act) penalty 13 was put into practice; all these con fi rm Google's goal towards SERPs that focus on page quality and are as close as possible to the human experience and feel of a webpage. 2.2. New era SE crawling and browsing
During the last years, headless browsing (web browser without a visual interface) is uptaken by search engines, in the place of search engine robots, in order to capture the semantics of web documents. This trend has unlocked the potential of headless browsing in the quest to rank webpages. 2.2.1. Crawling
Every major engine has been trying to crawl enriched data (not only text) in order to be able to obtain as much info as possible about the documents that the users are provided with; this way a clearer view upon the document it crawls can be gained.
Maykov and Chellapilla (2007) indicated that Microsoft's craw-ler Bingbot is practically a browser, since it interacts with the documents that it crawls by constructing their Document Object
Model (DOM) (claim 12) and by providing speci fi c responses to webpage scripts. Li et al. (2011) describe the basics of the mechanism Microsoft uses in order to recognize media elements in websites and to rank them based on their  X  dominance  X  that Microsoft parses media elements and has already de fi mechanism to incorporate them in its ranking mechanism.
Prabhakar et al. (2009) describe how Yahoo! has created a mechanism that executes scripts, inserts information into forms automatically and it is connected with a web browser and a crawler.

Finally, Malpani et al. (2012) discuss Google's headless brows-ing mechanism that attempts to rank non-text content items by creating labels related to them according to corresponding web-pages. This approach is further analyzed by Gokturk et al. (2007) , who describe a mechanism to analyze images and extract human-added information, beyond plain anchor text. 2.2.2. Headless browsing use cases
Headless browsing has been employed by Patton et al. (2012) in order to capture the number of user publications and to provide accurate measures of his/her scienti fi c impact. This approach was deemed useful in order to parse JavaScript and PDF fi les, which are usually left out by mainstream crawlers. Hoehl and Lewis (2011) have also employed headless browsing in order to analyze the difference of the user experience between mobile-and desktop-oriented websites.

There is indication that Google has been executing JavaScript and this could be re-enforced by Halevy et al. (2006) who pre-sented a method to acquire content from web-based forms. In addition to the above, EGNOR (2006) describes how Google analyses the positive and negative characteristics of a webpage
DOM and discusses the method under which a browser could process more effectively the CSS and JavaScript transformations of a webpage, in order to improve the visual analysis of a document.
Dean et al. (2010) also describe how Google has considered user experience as a very important factor for its SERPs and con Google's Page Layout above the fold update. 14
Evidence that search engines do use headless browsing comes by introspecting on the Google  X  webmasters help  X  section. The use of Instant Previews in its result pages provide with a  X  graphic representation of the web-page, generally highlighting the relevant sections based on the search query  X  . Instant Previews, though, are based on Googlebot and  X  the preview generator renders Javascript, AJAX, CSS3, frames, iframes and Flash  X  (as it is underlined in the
Google Instant Previews FAQ section 15 ); AJAX by default is content loaded by JavaScript when an action takes place after a page is loaded.

Nichols et al. (2008) also suggested that headless browsing should be used in order to implement their proposed mechanism to deploy mobile applications that were generated according to existing web-sites, insert custom JavaScript code into them and scale their architecture.

Headless browsing has been also used for the emulation of execution of JavaScript and for the extraction of Social media features by Eshete et al. (2013) , in their design of a mechanism to detect malicious webpages. Finally, Snellman et al. (2011) has shown that headless web browsers can be automated in order to simulate users and to test the prototype imple mentation of a framework that identi fi es the problems of Rich Internet Applications. 2.3. Semantics of web content
Based on our earlier research ( Mavridis and Symeonidis, 2012 ), we have argued that semantic analysis is important in SEO. The majority of the approaches have focused on the link structure and due the new route of search engines to a more content regulated approach to rank webpages in the SERPs, the use of content analysis has appeared to be highly important. Practically, semantic analysis can be broken down to semantic authorship, semantic markups and content analysis. Authors argue that content analysis is also signi fi cant for webpage ranking and its potential is explored within the context of this work. 2.3.1. Semantic authorship on engines The work of Minogue et al. (2009) stresses the importance of Authorship in SERPs rankings (Search Engine Result Pages) in
Google. Google  X  has provided functionality where Authorship tags are used in order to connect a website and its content with the identity of an  X  author  X  ,  X  publisher  X  or simple user.
MinogueandTuckerprovideuswitharankingmechanismcalled  X 
Agent Rank  X  .Theterm  X  agent  X  is used to refer to the identity of an individual that interacts actively with any kind of content around theweb.InAgentRank,analgorithm fi rst calculates the query independent ranking of an agent and then a modi fi ed version of the algorithm is used to de fi ne the query dependent. The ranking is determined based on the content of the documents that are related to an agent and could even differ depending on the topic de classi fi cation of search terms into categories.

It is clearly mentioned that this mechanism will in fl uence the search engine results by creating a numerical score that expresses the reputation of a certain agent. The logic behind the ranking algorithm of Agent Rank is stated to be similar to Page et al. (1999) which has been Google's main ranking component that uses web link structure and ranks webpages based on the fact that an important webpage is linked by other important webpages. In similar fashion, if content that is signed by an agent is referenced by other important agents it should be important. Details on the ranking mechanism of authorship and authors are analyzed by
Si et al. (2012) , without mentioning the term  X  Agent Rank several factors are described related to the quality and quantity of the content an author produces and of the comments and endorsements he/she receives.

In speci fi c, the authority score for an individual is analyzed in detail. The authority score resembles the agent ranking score and a plethora of factors that may de fi ne it are mentioned. The factors include the relevance of the content that is created to prior content of other individuals, the originality of it in its respective semantic area, the coverage of the content on the topic that is related to, the richness of it and the level of connection to recent events.

Google has experimentally presented a tool called Ripples, which graphically presents the sharing of a post or URL through users, and an API mechanism called Activities, 17 which provides an insight on the information that you could have for a certain individual through his/her Google account, and both reveal a small portion of what it kind of info could be stored and used in the back-end mechanism of Google and what characteristics related to the content of an author could be taken into consideration.
In general, semantic authorship has evolved as one of the basic characteristics that SEs have started to integrate into their docu-ment ranking mechanisms. 2.3.2. Semantic markups
Most common current markup formats are microformats, RDFa and microdata. XML (Schema) 18 ( Thompson, 2004 ), RDF 19 and Guha, 2000 ), DAML  X  OIL 20 ( Horrocks, 2002 )havebeenthe original formats that have been created.

Shah et al. (2002) have claimed that the use of semantic markup along with the indexing mechanisms will result in improved performance on information retrieval. They proposed a model that could be used in various points in a search engine or a question-answer model; the indexing phase, the query processing phase or even in the evaluation of the results of a query. The major search engines Google, Yahoo!, Bing and Yandex, have been trying to capture the evolution of Semantic Web and they have created the Schema.org 21 initiative that provides a simple markup voca-bulary for microdata in HTML5. The purpose is to de fi ne a common markup line among them that all the websites would follow for their structure.

Google in order to provide the public with an insight on their view on semantic markups has published two online tools related to structured semantic data,  X  Structured Data Testing Tool  X 
Structured Data Markup Helper  X  . 23 The former has as its purpose to verify the semantic data that Google recognizes and the latter, is a tool through which a web user has the opportunity to submit the exact place of semantic data in a speci fi ed website along with semantic information about the content. The tools' functionalities display Google's interest on semantic markups and data, which has been further outlined with the creation of Knowledge Graph. The Knowledge Graph is an attempt by Google to enhance its results by including semantic structured data in their SERPs and providing the user to retrieve more information without naviga-tion around the web.

Another signi fi cant semantic protocol has been Open Graph which has been created and mainly used by Facebook and has as its target to provide a webpage the option to be linked and enriched in a social graph in a simple way and is based on RDFa ( Adida and Birbeck, 2008 ). Facebook has provided with an API order to use Open Graph on it. Twitter has also introduced recently Twitter Cards 27 which is a mechanism to represent Tweets around the web and has a markup tag protocol that corresponds partially to Open Graph Protocol.

Stolz and Hepp (2013) proposed a framework in order to extract semantic data from all the various Semantic vocabularies into RSS or Atom feeds. In speci fi c, the vocabularies that were considered are Schema.org, GoodRelations ( Hepp, 2008 ) (an ontology that provides vocabulary mainly for products and services in the business and FOAF ( Brickley and Miller, 2010 ) (a social-oriented vocabulary aiming to connect people and information using a dictionary to describe what people talk about and what actions they perform). Breslin et al. (2005) de fi ned SIOC (Semantically-Interlinked Online Communities), an ontology mapped to FOAF and RSS and aims to describeinformationsharedinonlinecommunitiesthroughclasses and their properties. IETF (Internet Engineering Task Force) have developed vCard ( Consortium et al., 1998 ) which is a data speci tion that attempts to represent individuals and information related to them and Halpin et al. (2010) hadproposedthemappingofvCardto RDF/OWL in order to enable it to be used in the Semantic Web.
The framework by Stolz and Hepp (2013) also included SIOC and vCard along with the previously referenced vocabularies and based their approach on using RDF data. RDFa ( Adida and Birbeck, 2008 )was used in custom alternative named Viral RDFa in order to provide with a connection of the feeds with the original content and its meta-information. Their approach uses SPARQL and is characterized by features that were not included in other popular ones such as Yahoo Pipes 28 and DERI pipes 29 ( Le-Phuoc et al., 2009 )andprovideswitha simplistic framework for using RDF data for web development.
There is a high level of complexity in the area due to the various vocabularies and the different approaches that have been suggested. Frameworks that simplify the use of these vocabularies and the extraction and the manipulation of the info of semantic data will lead web into its semantic format. There has been evolution on structured data and the effect of the several semantic structured data on the ranking of websites on engines has to be explored. 2.4. LSHrank novelties in comparison to LDArank
There has been a lack of research on analyzing the effect of integrating semantic structured data on the ranking mechanisms of search engines due to the fact that it has begun very recently. Users have been stated as the clear targets of the major search engines and the signals related to the delivery of better semantically recognized webpages are currently a priority for search engine mechanisms. To this end, we have extended our previous mechanism,
LDArank and created LSHrank (Latent Semantic Headless rank) .In summary, LDARank extracts web documents from query results from the major search engines and employs state-of-the-art metrics for the evaluation of webpages. Extending work on
LDARank , LSHrank is a mechanism that employs headless browsing in order to recognize the content of a webpage, the webpage and semantic characteristics of it in detail.
 Furthermore, LSHrank considers Twitter as source of content.
Jansen et al. (2009) have concluded that Twitter is a key applica-tion in determining and capturing the public's attention and acts as an  X  ElectronicWord of Mouth  X  . Furthermore, Java et al. (2007) have shown that people use Twitter in order to exchange informa-tion and comment on several topics. Google Authorship has also revealed Google's goal towards SERPs that include Social media signals. Minogue et al. (2009) address the signi fi cance of Author-ship in SERP rankings Google. Social Media's in fl uence in SEs and Web is an essential trend to be captured.

In parallel, through Latent Direchlet Allocation LSHrank identi-fi es the most important topics related to a query and produces optimal content. Analysis of the effect of semantic content analysis in SEO is provided in our complementary paper ( Mavridis and Symeonidis, 2014 ) and is not the focus of this work.

Within the context of this paper, LSHrank is discussed with respect to its benchmarking properties and focus is given on the analysis of the parameters that affect SE rankings, through the prism of SEO. We argue that incorporating semantic characteristics has started to show its in fl uence on the ranking of SEs. Moreover, we present a methodology, through statistics, to compare the differences on ranking signals between the SEs and different domains of interest.

The architecture of the LSHrank framework, with focus on the extraction of webpage and semantic characteristics, is provided next. 3. The LSHrank architecture
The overall LSHrank approach is described by the steps fol-lowed; these are depicted in Fig. 3 .

At step A, LSHrank performs queries to search engines (A1) and retrieves the search results from them (A2). Then our mechanism ranks the results (A3) according to various SEO-related metrics.
Headless browsing (step B) is employed on the webpages that correspond to the results for thorough examination and informa-tion extraction out of the web documents. LSHrank analyzes them by capturing several webpage and semantic characteristics.
At step B, webpage characteristics (B1), such as the number of links, are captured. In parallel, semantic markup related character-istics (B2) are considered by LSHrank . In step C, content out of the web documents (C1) is extracted. It is also enhanced with the inclusion of Twitter information (C2). LDA ( Blei et al., 2003 )is employed for the Semantic Analysis of the content extracted (C3). In the last step, NGD (Normalized Google Distance) ( Cilibrasi and
Vitanyi, 2007 ) is used for the creation and selection process of new queries (D1).

LSHrank is a generic crawling evaluation mechanism that allows for a number of SEs to be employed, while the granularity of the analysis and the evaluation metrics can also be de fi ned at user will. Focus of the paper is on the evaluation of SE rankings with respect to various evaluation metrics and not on the ef fi the LDA mechanism. As already discussed, the analysis of step C and D is provided in ( Mavridis and Symeonidis, 2014 ). A focused analysis of steps A and B of LSHrank 's architecture follows. 3.1. Queries to search engines  X  steps A1,A2 The LSHrank con fi guration parameters are displayed in Table 1 .
The table is split in two sections: (a) input related parameters and (b) internal parameters related to the search engine(s) and the crawling mechanism. The LDA related parameters denoted in gray are included in section (a): only for completeness reasons.
In order to initialize LSHrank, one should determine a set of queries (step A). During the fi rst iteration the queries are de fi andcanbeenhancedwiththehelpofakeywordtoollikeGoogle
AdWords. 30 Google custom search API, 31 Yahoo! BOSS API 32
Search API via Azure Marketplace 33 are employed in order to perform number of m results returned by the APIs is de fi ned at LSHrank initiation set and the resultset RS o engine 4  X  r _ o ... ; r _ o engine 4 m (  X  engine  X  is Y for Yahoo!, B for Bing and G for
Google) is extracted in JSON format ( Crockford, 2006 ). Json-simple the employed parser in order to analyze the results and to extract the corresponding URLs. 3.2. Evaluation and selection of top results -step A3
The evaluation of the top  X  results  X  Rtop  X f rt 1 ; rt 2 performed against the following metrics:
Simple ranking  X  SR  X  : selection of the top  X  SR results according to their rank, where  X   X  m n 3.

Visibility score  X  ViS  X  : selection of the top  X  ViS results according to their rank, after integrating the rankings of the three search engines, where  X   X  m n 3 duplicate results.

Moz Page Authority ( PA ): selection of the top  X  PA results for each search engine, where  X   X  m or based on threshold option on the score of PA .

Moz Domain Authority  X  DA  X  : selection of the top  X  DA results for each search engine, where  X   X  m or based on threshold option on the score of DA .

Moz mozRank  X  MR  X  : selection of the top  X  MR results for each search engine, where  X   X  m or based on threshold option on the score of MR .

Moz subdomain mozRank  X  sMR  X  : selection of the top  X  sMR for each search engine, where  X   X  m or based on threshold option on the score of sMR .
 The values of MR , PA , DA , sMR arecalculatedthroughtheMoz Mozscape free API. 35 The mechanism would have been more complete if it included the mozTrust and External mozRank metrics, which are however available only through the Moz Mozscape paid API, distributed under a certain cost. Nevertheless, LSHrank follows an expandable architecture, thus their incorporation is seamless if they are available. The values of the above SEOmoz metrics are extracted in JSON format and the google-gson parser 36 is used for the analysis of the JSON fi les. 3.3. Extraction of webpage and semantic characteristics through Headless browsing  X  step B
The web documents are analyzed thoroughly employing Head-less browsing in step B. Webpage and semantic markup related statistics are extracted. Further details regarding step B of LSHrank webpage and semantic characteristics on the SEs ranking schemas.
The URLs that are included in Rtop are submitted to the headless browsing procedure which is performed with the use of JxBrowser. Browsing is performed along with thorough DOM (Document Object Model) analysis in order to extract all information from each docu-ment. It provides full DOM access through a Java API in order to access advanced browser options such as Javascript access and execution and access to frames. In the occasions that JxBrowser fails, we employ the JSOUP 38 html parser that has proven a reliable and effective alternative.

Statistics are kept regarding the human non-text readable con-tent that is parsed by the headless browser. Next, the analysis of the webpage and semantic statistics calculated follows.
 3.3.1. Extraction of Webpage statistics  X  step B1
Search engine rankings have displayed in fl uence by basic webpage characteristics since their inception. The link structure of the web has been used by search engines, since the early stages of their inception, to crawl and rank web documents. Several search engine metrics such as Pagerank ( Page et al., 1999 ) have considered links to be essential.
Thus, it is signi fi cant to include them in the group of possible ranking factors. The amounts of internal links ( Li ) and redirect-external links
Moreover, the amount of iframes ( Nf ), the number of embedded videos ( Ne )andthenumberofscripts( Ns ) are calculated in an attempt to explore their in fl uence as webpage characteristics on search engines' ranking schemas.

The webpage characteristics that are taken into consideration are displayed in part a of Table 2 . The symbol represents the number of a characteristic. 3.3.2. Extraction of semantic markup related statistics  X 
Various semantic related statistics are extracted in order to recognize the level of in fl uence of semantics on the rankings of search engines. Semantic markups are expressed mainly by the number of semantic triples ( Str ), therefore, its calcul-ation is essential. Furthermore, the number of rel microfomat uses ( Nr ) and microformats ( Mf ) could be signi fi cant factors of in fl uence considering the wide use of them in the fi eld of Semantic Web.

In a similar fashion, the emergence of schema.org and semantic authorship in the fi eld of semantic web are signi fi cant; therefore, the number of schema.org instances ( Sch and the number of semantic authorities ( Sa ) are calculated.

Part b of Table 2 consists of the semantic characteristics that are taken into consideration. The symbol represents the number of a characteristic.
 3.4. LSHrank ' s architecture in total LSHrank extends our previous work, LDARank ( Mavridis and
Symeonidis, 2012 ). In summary, LDARank collects query results from the major search engines and employs state-of-the-art metrics for the evaluation of webpages. Extending our work on
LDARank , LSHrank employs headless browsing of webpages in order to capture several webpage, semantic or not, characteristics.
Practically, our mechanism attempts to recognize the use of various webpage and semantic characteristics on actual SERPs and explore their effect on the majors SEs' rankings.

It is imperative to mention that, in parallel, LSHrank performs semantic analysis through Latent Dirichlet Allocation on web docu-ments and produces optimal content. The robustness and ef
LSHrank 's semantic analysis steps against other related approaches is provided in another work ( Mavridis and Symeonidis, 2014 ). Never-theless, the total activity diagram of LSHrank is displayed in Fig. 5 in order to provide with an overview of its functionality.
The following section presents the experiments run to explore our approach on comparing two domains regarding their search engine ranking factors. 4. Experiments and results on SE rankings
In this section, the experiments conducted in order to recog-nize the effect of several webpage and semantic characteristics on the major search engine ranking mechanisms are discussed. The existence of differences among the domains chosen and the major SEs is identi fi ed through the set of experiments.

The goal is to recognize the relation of webpage and semantic characteristics with the search engines' rankings and identify the differences of their in fl uence as ranking factors according to the choice of domain examined. Our aim is to solidify our argument that semantic characteristics could enhance the rankings of a speci fi c webpage considering its respective domain. 4.1. Experiment setup
In order to provide evidence on the value of webpage and semantic characteristics in SE rankings, we applied the mechanism on two domains: software engineering and sports .The fi rst domain was selected due to the fact that semantics in websites discussing software engineering are very ambiguous and, thus, not easy to identify.
Additionally, one should mention that this domain was pre-viously selected for the evaluation of the LDArank mechanism ( Mavridis and Symeonidis, 2012 ). The second domain was selected exactly because of its wealth in social/semantic content. Moreover, both domains were selected for the evaluation of the procedure of
LSHrank regarding the generation of optimal content through semantic analysis of web documents ( Mavridis and Symeonidis, 2014 ). Thus both domains provide an appropriate benchmark for evaluating LSHrank performance.

Given that our focus is not on the LDA part of the mechanism, the LDA-related parameter values are based on the previous LDArank and LSHrank experiments (as well as for comparison reasons); obviously, other parameter values could be de fi LSHrank initiation, based on the user hypothesis to be tested.
To this end, two sets of terms were considered for the analysis: (a) a set comprising eight widely used software engineering terms and (b) a set comprising eight widely used sports terms related to basketball, football, soccer and hockey coupled with word in order to direct SEs to websites with web 2.0 and web 3.0 content.
 Table 3 provides the terms de fi ned:
Table 4 includes the settings of the experiments. The LSHrank internal parameters have been depicted in Table 1 .

The values of iLim , cwl and the 6 different combinations of tw derive from the LDA settings in our work on LSHrank's content semantic analysis component ( Mavridis and Symeonidis, 2014 ) and are provided for completeness reasons.

For the webpages analyzed in the experimental section, several metrics are calculated as displayed in Table 2 . For the analysis of the results gathered, focused statistical analysis is performed; Table 5 depicts the approaches followed along with their objective.
Initially, for every metric captured, basic statistics are presented (mean, standard deviation). Detailed analysis of the ranking schemas of Google , Bing and Yahoo! follows. Furthermore, exploration of the differences between the domains and the SEs mechanism is sought.
Mann  X  Whitney U testing ( Mann and Whitney, 1947 )isperformed for identifying the differences on the webpage and semantic characteristics.

Spearman's correlation coef fi cient ( Spearman, 1904 )isemployed for the recognition of effect of the various ranking factors in each domain for each SE. Spearman corr elation analysis is performed on both the webpage and semantic characteristics. The results are provided next. 4.2. Search engines ' ranking schemas analysis
In the remainder of this section, metrics calculated and discussed against the Bing (B), Google (G) and Yahoo! (Y) engine results.
Initially, some statistics regarding the amount of webpages parsed are provided. A general view of the SEs and the several character-istics around the web through some basic statistics follows. 4.2.1. Basic statistical analysis for website characteristics
It is important to outline that LSHrank cannot not extract characteristics from textual unstructured data such as .pdf or . doc. Regarding non-textual unstructured such as videos or images,
LSHrank is able to parse them but there are no characteristics to extract.

At fi rst, basic statistics regarding the search engines and the webpage characteristics in both domains are provided. Part of a
Table 6 displays the mean and standard deviation of the metrics related to webpage characteristics for both domains.

As we can see there are differences in the metrics regarding the webpage characteristics both between the domains and between the search engines. Further exploration is necessary in order to recognize if these differences are signi fi cant. The basic statistical analysis regarding the semantic characteristics follows. 4.2.2. Basic statistical analysis for semantic characteristics
Basic statistics regarding the semantic characteristics captured from both domains are provided. Part b of Table 6 displays the mean and standard deviation of them for each SE.

There are interesting differences in between the domains due the fact that the sports related webpages are up-to-date with the web trends and the term blog has been included in the corre-sponding queries (see Table 3 ). As we can also see, SEs portray difference in the semantic metrics and this could originate from the level of integration of semantics in their own schemas. As stated about the webpage characteristics, further exploration is necessary in order to recognize if the differences in the semantic characteristics are signi fi cant. The analysis of the differences between the domains follows. 4.2.3.  X  Sports  X  vs  X  Software Engineering  X  in general
It is important to recognize whether there is signi fi cant differ-ence in the attribute values we have calculated due to the different domains. Data retrieved are not normally distributed; this is why we employ the Mann  X  Whitney ( Mann and Whitney, 1947 ) approach in order to measure the signi fi cance of the domain of queries they belong to. The Mann  X  Whitney signi fi cance U and Z are computed and consequently the effect size r is calculated, where N is the total number of instances we check for the union of groups.

The Mann  X  Whitney U test is a non-parametric test used as an alternative to t-test in non-normal data and tests the mean values of two samples. The Asymptotic Signi fi cance ( Asymp. Sig )standsforthe p -value and, if it is below 0.05, it corresponds to a signi attribute. In case the value of the Monte Carlo ( MC Sig. )iscloseto
Asymp. Sig , it denotes a really signi fi cant attribute. Values of 0 : 5 4 j r j 4 0 : 3 denote a medium effect, 0 : 8 4 j r j 4 0 these are general rules and search engines are in fl uenced by a vast amount of factors, we do not compare j r j against these values.
In our case, all attributes have Asymp. Sig. and MC Sig. equal to 0.000 except for Ne , with values 0.060 and 0.059 respectively. There-fore, the values of Asymp. Sig. and MC Sig. are omitted and since Ne does not portray signi fi cant difference, it is excluded from the rest of the analysis. The results of the Mann  X  Whitney test are displayed in Table 7 .

From the results of the test, it is clear that the type of the domain has a signi fi cant effect on both webpage and semantic characteristics captured by our model. It is a clear indication that there are different trends and structures in the websites according the domain they belong to. The difference between the two domains is mostly in fl uenced by the scripts ( Ns ) and the total number of links ( Lt ), yet the semantic characteristics such as the microformats ( Mf )present relatively high level of in fl uence on the difference.
The existence of differences between the domains has been proved. It is imperative to compare the domains, for each search engine in separate, in order to examine their differences in detail. 4.2.4. Difference of  X  Sports  X  vs  X  Software engineering Engine
It is important to examine the two domains considering the fact that the search engine could alter the effect of the several char-acteristics as difference signals. Table 8 compares the two domains examined in terms of means of the attributes measured.

It is very interesting to see that all attributes except number of schema.org entities ( Sch ) in Bing have higher values in related queries than in  X  software engineering  X  ones in every search engine. This could be an indication that Bing is in more by schema.org in the  X  software engineering  X  domain. Further exploration of the relation of the Bing rankings and Sch could provide an insight on the issue.

The higher number of webpage characteristics has to do with the fact that the sports related webpages include more content and more links to other web documents by their nature compared to software engineering webpages. The existence of higher values regarding the semantic characteristics in sports related webpages, as stated before, could originate from the fact that sports related webpages are more up-to-date with the web trends and term blog is included in their corresponding queries (see Table 3 ).
Therefore, in order to form a more clear and concrete picture for the differences on the domain choice, separate analysis for each SE is going to be provided. 4.2.5. Signi fi cance of difference between domains
In order to recognize the signi fi cance of the domain choice in each search engine, Mann  X  Whitney U tests were performed for each search engine separately. Table 9 displays the results of the analysis. All attributes for all search engines have Asymp. Sig. and MC Sig. equal to 0.000, therefore these variables are omitted from the table. As before, we include in the analysis the effect size r , where N is the total number of instances we check for the union of groups. Values of 0 : 5 4 j r j 4 0 : 3 denote a medium effect, 0 2009 ). As stated, since these are general rules and search engines are in fl uenced by a vast amount of factors, we do not compare r against these values.

The domain type seems to show signi fi cant difference in all attributes. Considering the values of the effect size r , it mainly affects Google , then Bing and last but not least Yahoo!
It is interesting that in each SE the webpage characteristic which contributes to the difference between the domains the most is the number of scripts Ns . This could originate to the fact that the  X  sports  X  webpages tend to include more media elements, such as video or photo galleries, embedded in scripts, in comparison to  X  software engineering  X  webpages. In further examination of the webpage characteristics, the total number of links ( Lt ) is the next more in fl uential characteristic, in terms of effect size on the difference, for both Bing and Google, but not for Yahoo! .
On the semantic characteristics, the microformats Mf contribute the most to the difference between the domains for every SE. It could be stated that the usage of semantic structured data is a signal of difference between the two domains, that the search engines have started to consider in their attempt to parse web documents in detail.
Google displays the higher values of effect size of the all the semantic characteristics except Nga , in which the effect size is slightly more for Yahoo! This could be an indication of Google recognizing the semantics in the content of web documents in order to associate it with certain domains.

Exploring the values of r on the semantic characteristics the SEs display a similar trend on the characteristics that in fl difference between the domains. In general, one could argue that the domain type is a factor that in fl uences all the webpage and semantic characteristics that LSHrank considers . Nevertheless, it is necessary to explore the similarities and the signi fi cant differences of the SEs; the comparison of them follows. 4.2.6. Comparison of search engines
Within the context of our work we have assumed that search engines would display difference in the values of the attributes that
LSHrank measures due to their inherent differences. On the other hand, the SEs have a similar trend on the factors that in differences between the domains. In this section, a comparison of Bing ,
Google and Yahoo! results on each domain is performed in order to withdraw insights regarding their possible differences and similarities.
Comparison of search engines in sports : As already discussed, data are non-normally distributed; thus we perform Kruskal Wallis testing ( Kruskal and Wallis, 1952 ) to explore whether differences between the search engines are signi fi cant (similar to Mann
Whitney U testing, Kruskal  X  Wallis analysis is a non-parametric test that can be applied to 3 or more groups). A difference is signi when the Asymptotic Signi fi cance ( Asymp. Sig. ) o 0.05 . As already stated, the signi fi cance is stronger if the values of the Asymp. Sig. and the Monte Carlo Signi fi cance ( MC Sig. ) are close.
The attributes that differ signi fi cantly between the SEs are: internal links (Li), reltags (Nr) and microformats (Mf) . The SEs display most of their differences in the webpage characteristics; in the semantic aspect only rel microformats ( Nr ) and microfor-mats ( Mf )have Asymp. Sig below 0.05.

The test performed above de fi nes which relations are signi however it does not provide insight on which SE combination generates the signi fi cance in the differences ( Bing vs Google, Google vs Yahoo!, Yahoo! vs Bing ). In order to obtain this information, we also perform Mann  X  Whitney testing and report as signi fi cant the differ-ences with Asymptotic Signi fi cance Asymp. Sig. below 0.0167. The value 0.0167 equals 0.05 (the usual signi fi cance limit) divided by 3, which is the number of groups, in order to avoid Type I error Field, 2009 ). The couples that are signi fi cantly different are denoted by * on the value of Asymp. Sig. Theeffectsizeisdenotedwith r .Valuesof 0 : 5 4 j r j 4 0 : 3 denote a medium effect, 0 : 8 4 j r j 4 0 size and if j r j 4 0 : 8averylargeeffect( Field, 2009 ). As stated, since these are general rules and search engines are in fl uenced by a vast amount of factors, we do not compare r against these values.
Based on the results of the tests the following couples could be characterized as signi fi cantly different for each attribute: Iframes (Nf) : Bing vs Yahoo!, Google vs Yahoo!, Scripts (Ns) : Bing vs Google, Bing vs Yahoo!, Google vs Yahoo!, Total number of links (Lt) : Bing vs Yahoo!, Google vs Yahoo! Number of redirect/external links (Lr) : Google vs Yahoo! Number of internal links (Li) : Bing vs Google, Bing vs Yahoo!, Google vs Yahoo! Number of reltags (Nr) : Google vs Yahoo!, Bing vs Yahoo! Number of microformats (Mf ): Google vs Yahoo!
One may easily notice that the Yahoo! search engine performs in a much different way in the  X  sports  X  domain than Google and Bing .Itis imperative to outline that despite that all the SEs have been based on the link structure of a website in order to capture it, they present differences in the internal links. It is an indication that they follow different logic in this aspect. Regarding, the external links which SEs have been using in order to crawl different domains around the web, Google and Yahoo! have the signi fi difference. This implies that Google and Yahoo! have a different view on the importance of the external links on their mechanisms.
Furthermore, as already stated, in the semantic characteristics captured from  X  sports  X  webpage, the SEs did not have signi differences except in rel microformats ( Nr )andtotalamountof microformats ( Mf ). In speci fi c, according to the results of the Mann
Whitney tests, Yahoo! seems to value rel microformats ( Nr )in different fashion than the rest of SEs, which do not display signi difference. As for the number of microformats ( Mf ), Google and Yahoo! differ. It is apparent that the Google and Bing differ from Yahoo! in the way they incorporate microformats as a whole in their mechanisms .
Additionally, should one refer back to Table 6 , the following could be stressed with respect to the attributes with signi differences among the SEs in the  X  sports  X  domain:
Iframes (Nf) : it is low in all engines. Google has a bit higher average.

Scripts (Ns) number : Google has 32.5% more than Yahoo! and 10.3% more than Bing in average.

Total number of links (Lt) : Google has 3.1% more than Bing and 5.6% than Yahoo!.

Number of redirect links (Lr) : Bing has 3% more than Google and 32.1% than Yahoo!.

Number of internal links (Li) : Google has 35.4% more than Bing and 64.3% than Yahoo!.

Number of reltags (Nr) : Google has 7% more than Bing and 16.5% than Yahoo!.

Number of microformats (Mf) : Google has 6.9% more than Bing and 15.75% than Yahoo!.

Since it has been stated that the domain in fl uences the results of the metrics captured, the analysis of the SEs in the  X  software engineering  X  domain follows. Comparison of search engines in the  X  software engineering  X  domain Considering the same approach as in the  X  sports  X  domain, Kruskal Wallis testing is performed. As before, signi fi cance is denoted when the Asymptotic Signi ( Asymp. Sig. ) o 0 : 05 and its difference with the Monte Carlo
Signi fi cance ( MC sig ) metric is low. Values of 0 : 5 4 a medium effect, 0 : 8 4 j r j 4 0 : 5 a large effect size and if j r j very large effect ( Field, 2009 ). As stated, since these are general rules and search engines are in fl uenced by a vast amount of factors, we do not compare r against these values.

Based on the results of the test, the attributes that differ between SEs are: iframes (Nf), scripts (Ns), Number of links (Li), redirect links (Lr) and internal links (Li). The SEs differ in the  X  software engineering  X  domain in all the webpage characteristics and not in any semantic attribute. Therefore, it could be stated that the SEs in the domain of Software Engineering portray similar use of the semantic characteristics in their mechanisms .

In order to recognize the signi fi cantly different couples of SEs on the webpage characteristics, Mann  X  Whitney test is employed.
Considering the fact that Type I error ( Field, 2009 ) should not occur, Asymp : Sig o 0 : 05 = 3  X  0 : 0167. The effect size is denoted with r and couples with signi fi cant difference are denoted by * on the value of Asymp. Sig. Values of 0 : 5 4 j r j 4 0 : medium effect, 0 : 8 4 j r j 4 0 : 5 a large effect size and if j r j very large effect ( Field, 2009 ). As stated, since these are general rules and search engines are in fl uenced by a vast amount of factors, we do not compare r against these values.

From the results of the Mann  X  Whitney tests the following couples could be characterized as signi fi cantly different for each attribute: Iframes (Nf) : Bing vs Google, Bing vs Yahoo! Scripts (Ns) : Bing vs Yahoo! Total number of links (Lt) : Bing vs Yahoo! Number of redirect links (Lr) : none Number of internal links (Li) : Google vs Yahoo! One may easily notice that, regarding the webpage characteristics, Google resembles in some parts both Bing and Yahoo! Engines (or vice verca), which are very different between them. Bing and Yahoo! differ on the number of iframes Nf , the number of scripts Ns and the total number of links Lt .

Additionally, should one refer back to Table 6 , the following could be stressed with respect to the attributes with signi fi cant differences between the search engines in the  X  software engineering  X 
Iframes (Nf) : it is low in all engines. Google has a bit higher average.

Scripts (Ns) : in Bing it is higher than the other engines. Bing has 8.6% more than Google and 12.5% more than Yahoo! in average.
Total number of links (Ns) : Bing has 6.4% more links than Yahoo! and 11.5% than Google
Number of redirect links (Lr) : Bing has 13.5% more redirect links than Google and 5.3% than Yahoo!
Number of internal links (Li) : Bing has 3.8% more internal links than Google and 11.8% than Yahoo!
In general, about the  X  software engineering  X  domain, Bing por-trays a higher number in the majority of the webpage characteristics, with Google to present similarities and Yahoo! to differ . On the opposite, they are not characterized by signi fi cant differences in the semantic characteristics around the web. 4.2.7. Signi fi cant attributes
In this step, the relation of the rank of the search engines and the various characteristics is sought. As already stated, our data do not follow a normal distribution. Therefore, Spearman ( Spearman, 1904 ) rank correlation coef fi cient ( r s ) is employed for our goal. Spearman (1904) correlation is a non-parametric rank statistic and it is used in order to identify whether there is relation between each one of the metrics and the rank of the search engines. It is chosen over Pearson correlation, which assumes normal distribu-tion, and over Kendall (1938) , which is more suitable for small data sets with large number of tied ranks ( Field, 2009 ). Table 10 discusses the results for the two domains. Sig. stands for signi cance and 0 : 01 4 Sig : is denoted with ** (highly signi 0 : 05 4 Sig : 4 0 : 01 is denoted with *(signi fi cant).

It is apparent from Table 10 that several different factors in fl uence the ranking of SEs. The negative values of the correlation correspond to the fact that as the value of the characteristic becomes lower, the rank goes from 1 to 20. The following points could be stated regarding the values of the Spearman correlation:
For different domains we have different factors that affect the search engines and different level in fl uence of each factor. In speci fi c, Google is in fl uenced by semantic triples ( Str ), number of rel microformats uses ( Nr ) and microformats ( Mf )in software engineering domain and by scripts ( Ns ), semantic authorities ( Nga ) and internal links ( Li )in sports . This implies that the domain of a webpage/website is a factor of in fl uence on the ranking signals that the major search engines consider.
Authorities (Nga) show correlation in Google and Yahoo! in the sports domain, where the websites are sport-related news' websites and the authorship tends to be more used from journalists/authors.

Authorities (Nga) are more valued by Yahoo! (correlated in both domains we have examined).

The fact that the correlation of the authorities ( Nga ) is positive means that while the number of authorities goes up and the rank goes down. This could be an indication of spam detection techniques by Google and Yahoo! for cases where multiple authorships are placed as an attempt to achieve higher rank-ings. Nevertheless, the small number of authorities used in average could be the reason behind the positive correlation and, therefore, it could be a false indication as ranking factor.
Internal links (Li) show high correlation to rankings for both domains for all SEs, except for Google on the Sports domain. It is a clear sign that the link architecture of a webpage/website remains a valuable for the operation of the search engines.
Scripts (Ns ) have shown correlation for Google rankings in the sports domain. The fact that they display positive correlation for
Google in  X  software engineering  X  (higher amount of scripts, lower rank) could be an indication of Google's attempt to detect spam (Panda and Penguin Updates) and to penalize webpages with hidden links in the javascript.

Semantic triples (Str) , which is the main expression of semantic structured data, have high correlation to both Bing and Google rankings in the  X  Software Engineering domain  X  . Higher Str numbers leads to higher ranking. This validates our argument that SEs (in this case Bing and Google ) do take into account semantic data.

Rel microformats (Nr) and Microformats (Mf) have shown negative correlation to both Bing and Google rankings in the  X  software engineering  X  domain. This is another proof that SEs use Semantic Web data in their algorithms. The proof of usage of semantic data by the major search engines could promote the use of structured data on the web for the creation of a more properly organized and ef fi cient web user experience.
Yahoo! rankings are not correlated to any kind of semantic data other than the authorities ( Nga ), with the possibility, as already stated, to be a false signal due to the low amount of authorities. 4.2.8. General comments about search engines ranking schemas
From the analysis above, insightful conclusions regarding the SEs' ranking schemas have been extracted. The results have solidi argument that the choice of domain in fl uences the factors that search engines value. In general, Sports related webpages display higher averages in the values of each attribute captured for every SE than software engineering websites. Semantic characteristics have emerged as possible ranking factors to a certain extent and the results indicate that SEs consider Semantic Web into their mechan-isms. Google and Bing have shown signi fi cant level of similarity in both the  X  sports  X  and  X  software engineering  X  queries, while also having signi fi cant differences with Yahoo! .
 The SEO fi eld is not only in fl uenced by SEs' characteristics.
Other metrics have emerged as adequate evaluation measures. To this end, an analysis of Moz's metrics follows in order to explore whether they display different behavior according to the domain examined and recognize the attributes that in fl uence them. 5. Experiments and results on Moz metrics
In this section we will discuss the in fl uence of the several attributes on the different scores of Moz metrics. The existence of differences among the metrics' description is identi fi ed through the set of experiments.

The goal is to recognize the rel ation of webpage and semantic characteristics with the SEs ranking and to solidify our argument that certain they could lead a given webpage, for queries related to its respective domain(s), to higher rank ings in search engine result pages.
As already discussed, this work focuses on the exploration of the effect of webpage and semantic factors on SEs and not the content semantic analysis, through LDA, part of LSHrank . Other parameters could be de fi ned in LSHrank initiation for another hypothesis to be tested (content-related).

In order to explore this in fl uence, experiments were performed on 13,705 webpages in the two domains examined previously,  X  sports  X  and  X  software engineering  X  , with the same terms as input.
Analysis of the 13,705 webpages is provided in Table 11 and is in fl uenced by the LSHrank procedures on semantic analysis of content regarding the iteration limit of the mechanism ( iLim ), the production of new queries and the convergence limit of the content ( cwl ). The ef fi ciency of this part of LSHrank, as already stated, is out of the context of this work and is presented in another paper ( Mavridis and Symeonidis, 2014 ).

As before, Spearman correlation was employed as the metric for the comparisons. Table 12 provides with the value of the Spearman mR , PA , DA and smR . Important factors are considered the ones with signi fi cance (Sig.) below 0.05. As before, 0 : 01 Z Sig (highly signi fi cant), 0 : 05 4 Sig : 4 0 : 01 is denoted with *(signi 5.1. MozRank analysis
MozRank is mostly in fl uenced by the number of internal links (Li) , which has shown the largest correlation scores in Spearman.
Higher MozRank score corresponds to higher number of internal links. It must be pointed out that MozRank shows a slight negative correlation for the redirect/external links (Lr) . This practically proves the logic behind MozRank  X  mR  X  is based on the link architecture of a website . MozRank also seems to grow, as the number of schema.org  X  Sch  X  , reltags  X  Nr  X  , microformats  X  Mf  X  and number of semantic triples goes down; this is quite interesting since they practically express the Semantic Web . The number of authorities (Nga) also presents a slight negative in fl uence on mR .It could be stated that MozRank  X  mR  X  is a link popularity score in fl uenced by the links in a given webpage and its score considers Semantic characteristics as additional factors. 5.2. Page Authority analysis
Page Authority presents highly signi fi cant correlation with every webpage and semantic characteristic measured except the number of authorities ( Nga ), which is considered signi fi Examining the r s scores, it could be stated that PA is mostly in fl uenced by the number of internal links  X  Li  X  , the number of redirect links  X  Lr  X  , and the total number of links  X  Lt  X  . The high correlation identi fi ed implies that PA potentially tries to determine the authority of a page according to its links. The higher the number of links, internal links and redirect links, the higher the Page Authority. The number of iframes ( Nf ) and the number of scripts ( Ns ) also in fl uence the score of Page Authority in same fashion but their effect is smaller. The effect of the semantic characteristics is relatively low, therefore, they cannot be declared as important in fl uence factors of PA. Nevertheless, the fact that rel microformats ( Nr ) present positive correlation and microformats in total ( Mf ) negative is insightful about possible consideration of them by PA . In all the other metrics, Nr and Mf present similar pattern. 5.3. Domain Authority analysis
Domain Authority is mostly in fl uenced by reltags  X  Nr  X  ,total microformats  X  Mf  X  and semantic triples  X  Str  X  .The larger their number, that the number of authorities  X  Nga  X  displays negative correlation with the score. It could be an indication that a large amount of semantic authorities in fl uence negatively DA , possibly attempting to detect spam techniques such as using multiple Google  X  author pro fi les in a given website. In general, DA is in fl uenced by both webpage and semantic characteristics and could be a relatively complete metric of evaluation of a website. 5.4. subDomain MozRank analysis
Subdomain MozRank ( smR )ismostlyin fl uenced by the number semantic triples  X  Str  X  and total microformats  X  Mf  X  . Subdomain
MozRank ( smR ) presents no signi fi cant in fl uence by the number of internal links Li ,whichisincontrastwith mR .Thisdifferencecould derive from the fact that mR is a webpage metric and smR adomain metric. Moreover, it is very insightful that a metric described to be in fl uenced by the link architecture, di splays positive correlation with semantic characteristics when mR displays negative. The only semantic characteristic wi th negative correlation in smR is number of authorities  X  Nga  X  , and as already stated, it could be an attempt to detect spam techniques related to multiple author pro fi les or a false signal due to the small amount of number of authorities. 5.5. Moz metrics comparison The number of internal links ( Li ) has great in fl uence on mR and
PA , which correspond to the page-level evaluation and much less on DA and zero on smR , which represent the domain-level evalua-that shows that it is based mostly on the internal link structure.
The total number of links ( Lt ) shows positive correlation with all the metrics.

On the domain level metrics, the number of all the semantic web metrics show greater level of correlation and prove that the web takes into account semantic data. The number of authorities  X  Nga  X  is the only semantic web metric that shows negative correlation against all the Moz metrics and especially against the domain level ones .

Schema.org uses  X  Sch  X  have negative correlation in page level metrics, very small positive with DA and important positive in smR . This fact proves the difference between the metrics. Last but not least, Page authority  X  PA  X  is the only metric that is in by the number of scripts  X  Ns  X  .

The Moz metrics have correlation with several characteristics and semantic attributes are taken into account. It will be interest-ing to explore if the domain in fl uences which factors display correlation with the Moz metrics. 5.5.1. In fl uence of domain on Moz metrics
In this section we are going to examine the in fl uence of the domains of sports and software engineering on the Moz metrics.
Table 13 examines the in fl uence of domain choice on the Moz metrics by presenting the Spearman correlation scores for both of them. Important factors are considered the ones with signi (Sig.) below 0.05. As before, 0 : 01 Z Sig : is denoted with ** (highly signi fi cant), 0 : 05 4 Sig : 4 0 : 01 is denoted with *(signi Links present in fl uence with MozRank, as seen in part of a
Table 13 inthesamelevelbothin sports -related and in software engineering domains, but schema.org (Sch) , rel microformats (Nr) , semantic triples (Str) and total number of microformats (Mf) in
MozRank (mR) negatively only in sports -related domain. The char-acteristics that MozRank (mR) correlates with are in fl uenced by the choice of domain. Furthermore, the semantic characteristics in negatively mozRank in the sports-domain. One could state that
MozRank (mR) is a webpage popularity metric that is based on the link architecture, yet depending on the domain, it could be in by semantic characteristics.

In a similar manner, part b of Table 13 discusses the in fl the domain choice on Page Authority. The webpage characteristics, number of links (Lt,Li,Lr) , iframes (Nf) , embedded videos ( Ne ) and number of scripts (Ns) in fl uence in similar fashion PA in both domains. On the other hand, the semantic related variables in ence more and in some cases only Software Engineering domain , which is in contrast with MR where the opposite was observed. In further detail, it is interesting the PA is in fl uenced positively by Nr only in the Software Engineering domain. (PA) is a metric of authority for a speci fi c webpage and the factors it considers are altered depending on the domain.
 Part c of Table 13 discusses the effect of domain type on
Domain Authority. On the  X  sports  X  domain reltags (Nr) and micro-formats (Mf) are the most important metrics and on  X  software engineering  X  semantic triples (Str) . The external links (Lr) in more in the  X  software engineering  X  and the internal links (Li) in the sports domain. Interestingly, Schema.org entities (Sch) present small, yet signi fi cant, correlation with DA only for the related webpages. Domain Authority seems to be in fl uenced differently by the webpage and semantic characteristics according to the domain examined.

Last but not least, part d of Table 13 displays the difference that sMR has due to the domain of the website. Subdomain mozRank in the Software Engineering domain is in fl uenced only by rel microformats (Nr) and microformats (Mf) with positive correlation and by the number of authorities (Nga) with negative. These characteristics in fl uence smR also in the sports domain in similar manner. Further-more, the number of schema.org (Sch) ,semantictriples (Str) ,links the domain in fl uences the factors which smR takes into consideration.
The analysis above provided us with an insight on the several factors that in fl uence the Moz metrics that are considered to have high level of credibility on the SEO fi eld. The domain has been found to alter signi fi cantly every Moz metric and the majority of the correlations extracted provide us with useful insights about the nature of metrics, which could not be determined by the description of them. 6. Conclusion and future work
Based on our basic argument that contemporary SEs strive to capture user experience and have started employing metrics that take semantic data into account, we have built LSHrank ,amechanismthat attempts to deliver high quality SEO based on LDA techniques and state-of-the-art SE metrics. This paper concludes the fi rst design phase, where we perform a thorough analysis on the factors that affect SE rankings and focus on the existence of Web 2.0 and Web 3.0 content, as well as the factors that are considered as important in several Moz metrics. From the analysis performed it is obvious that the domain of queries affects both the webpage and the semantic attributes that in fl uence the ranking score in search engines. Moreover, search engines exhibit similar behavior in some aspects and are signi fi in other. Bing and Google have many common points ,while Yahoo! differs signi fi cantly. All the SEs still consider link structure as an important characteristic of the web. On the semantic aspect, Bing and Google display more in fl uence by semantic web related metrics while
Yahoo! 's ranking schema shows correlation only to semantic authorities (Nga) and no other semantic structured data.

Concluding, we have gained an insight on the internal of the ranking mechanisms of search engines and the experiments run has also provided us with the opportunity to withdraw conclusions regarding the metrics of Moz, which are highly used in the
SEO. We have solidi fi ed our argument that the domain in the characteristics that are considered as factors of importance from both the major search engines and Moz. LSHrank has proven to a tool that enables the extraction of conclusions for the search engine ranking schemas. The next step, will be to employ LSHrank on several domains in order to withdraw more concrete conclusions and to explore the level that semantic structured data have started to be considered as ranking signals by the major search engines. Last but not least, LSHrank could improve by the inclusion of more semantic markup related characteristics and achieve a more detailed view of how search engines incorporate the semantic web in their ranking mechanisms. Potential proof of semantic characteristics as ranking signals in multiple and diverse domains could enable
LSHrank to be a tool that promotes the use of structured data and aims for enhanced quality of semantics in the web.
 References
