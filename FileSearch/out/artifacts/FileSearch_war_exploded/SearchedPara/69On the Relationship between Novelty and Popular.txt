 DAVID CARMEL and HAGGAI ROITMAN, IBM Research Haifa Recent years have witnessed a tremendous increase in the amount of user-generated content (UGC) available on the Web. Many social media (Web 2.0) applications have emerged to provide an open stage for users to contribute content and to publicly share their ideas and opinions with others. The most notable source for UGC on the web nowadays is the Blogosphere , where blogging web services such as Blogger 1 ,and ReadWriteWeb 2 have become popular media for personal content publication. More recently, microblogging services, such as Twitter 3 , let users publish short comments about breaking world news as well as daily updates about themselves. Other notable sources are collaborative services such as Wikipedia 4 and YouTube 5 , where UGC is collaboratively contributed by the community (articles on Wikipedia and video uploads on YouTube), and triggers public discussions around. Collaborative bookmarking services such as Delicious 6 and Digg 7 are additional sources of UGC, allowing users to annotate content published on the Web.

As the popularity of social media services increases, identifying UGC with high  X  X uality X  becomes more difficult due to the enormous amount of new content that is continually published on those sites. Typically, due to the large amounts of data, only a small fraction of new posts are expected to gain popularity. Consequently, only a few posts will be read, commented, or rated by others, while most of the posts will be ignored. Mishne and Glance [2006] revealed that only 15% of the blog posts are commented on, with an average of two comments per post. They note that the number of comments per post follows a power-law distribution, with a small number of posts containing a high number of comments, and a long tail of posts with only a few or no comments. Therefore, it is extremely important for blog services to be able to identify those sporadic  X  X ood X  posts to be recommended for their users.

The quality of UGC is usually measured in several dimensions such as the author X  X  reputation, objectivity, and reliability, as well as content relevancy, completeness, and accuracy [Chai et al. 2009]. The most successful indicators for UGC quality are the amount of user feedback and the number of citations the content has [Hsu et al. 2009; Mishne and Glance 2006; Tsagkias et al. 2009]. These approaches usually rely on explicit and publicly available feedback such as comments, ratings, recommendations, and tagging [Hsu et al. 2009; Tsagkias et al. 2009], as well as implicit feedback such as click-through data [Lerman and Hogg 2010; Szabo and Huberman 2010]. In addition, following the successful link analysis techniques for measuring web site authority, the user X  X   X  X uthority X  can also be inferred by link analysis. Estimating the author X  X  au-thority in the Blogosphere has been intensively studied recently [Agarwal et al. 2008; Kempe et al. 2003; Song et al. 2007]. Content-based features such as writing style and missing spelling errors can additionally be used for quality analysis [Agichtein et al. 2008; Hasan Dalip et al. 2009].

User feedback is indeed very valuable for identifying high quality content. However, there still remains a fundamental gap in evaluation of UGC quality when no feedback is available, especially for freshly published content. When user feedback does not ex-ist, evaluation approaches are mostly based on the author X  X  reputation, as reflected by the popularity of the author X  X  previous content contributions [Hsu et al. 2009; Tsagkias et al. 2009]. However, such methods are strongly biased to popular contributors in the past, and underestimate fresh content published by unfamiliar contributors. In this work we deal with the task of predicting UGC popularity, as reflected by the amount of expected user feedback, focusing on new content (post) that has not yet re-ceived feedback. We address a new dimension for content quality evaluation based on measuring the novelty of the published content and demonstrate how the novelty of a new post plays an important role in affecting its popularity. More specifically, we study three dimensions of novelty types. The first type, termed contemporaneous novelty , models the relative novelty embedded in new post with respect to contemporary con-tent generated by others in the same time period. We hypothesize that non-novel posts are less popular since they fail to explore new valuable information for their readers.
The second type of novelty, termed self novelty , models the relative novelty em-bedded in new UGC with respect to the user X  X  own contribution history. Self novelty measures the novelty of a new post with respect to previous contributions published on the same source. We show that self-novelty also contributes to content popularity, probably due to the fact that authors who repeat themselves and fail to innovate, lose their readers over time.

The third novelty type, termed discussion novelty , relates to the novelty of the com-ments associated by readers with respect to the post X  X  original content. The comments are compared to their associated post for measuring the amount of information they add to the post. For example, controversial and provocative posts are expected to have high discussion novelty. In order to predict the discussion novelty, before the post has been commented, we measure the average discussion novelty of comments to previous posts published by the same author. The assumption behind this measure is that a new post, contributed by an author with a history of high discussion novelty, is also likely to initiate a stimulating online discussion that will affect the post X  X  popularity.
The novelty-based features we have described do not require existing user feedback; therefore, they can enhance existing popularity estimation techniques for new posts, which are currently based primarily on the author X  X  reputation and on textual anal-ysis. Furthermore, the contemporaneous novelty feature can even be used to predict the popularity of new posts provided by unfamiliar contributors with no history at all. Such an estimation of fresh content quality, prior to the availability of any user feed-back, is of extreme importance. For example, the success of commercial marketing campaigns in the blogosphere strongly depends on identifying those blog posts that are expected to a have high potential for reaching large audiences and influencing their readers. This is also true for search systems that look for high quality new items that are relevant to their user needs, and for recommendation services, which recom-mend interesting posts to their customers. Most existing blogging services recommend a short list of high-quality blog posts on their main page. This list is usually composed of the latest top-rated and commented posts, as well as new posts of authors who con-tributed popular posts in the past. Given the ability to predict the expected number of comments for new posts will enable better identification of high quality posts in advance, when no feedback is available yet. It will also allow those recommendation tools to identify interesting posts immediately after publication, independently of their future recognition by the society. Using two real-world datasets of blogs and academic papers, we demonstrate the ef-fectiveness of the novelty measures described in this work in assisting with the task of estimating the number of comments expected for new posts. For the blog data, we show that the novelty-based features significantly improve the prediction accuracy, especially for posts published on blogs with short history. For such blogs the novelty-based features are extremely important in the absence of previous data. The improve-ment in prediction accuracy is less impressive (but still significant) for posts published by authors with a long publication history. This is expected because a long history provides enough evidence for the blog X  X  popularity, hence novelty-based features are less significant for prediction. Similarly, in the academic papers domain, we obtain significant improvement in accuracy of the citation number prediction as a result of using the new novelty-based features.

Novelty by itself is not sufficient to gain popularity. Novel content that is not rel-evant or interesting will not receive the public attention. Moreover, spammers can easily pretend novelty, for instance, by adding randomness into their posts [Mishne et al. 2005]. Our results indeed show that novelty-based features are not enough to predict popularity, however they can significantly enhance the prediction of post pop-ularity when combined with other valuable features such as content quality and the author X  X  reputation.

The rest of this article is organized as follows. In Section 2 we provide general background and review several works that address the task of estimating content pop-ularity. In Section 3 we describe the new novelty-based features and implementation details. In Section 4 and Section 5 we illustrate the effectiveness of these features in the blog domain and the academic papers domain. Section 6 concludes our work and discusses future directions. Several recent works studied the reasons why users contribute content and participate in online discussions. Nardi et al. [2004] conducted an ethnographic investigation about the reasons that drive bloggers  X  X o document their lives, provide commentary and opinions, express deeply felt emotions, articulate ideas through writing, and form and maintain community forums X .

Cha et al. [2007] analyzed the popularity distribution of user-generated videos and its evolution on YouTube. De Choudhury et al. [2009] further studied what drives in-dividuals to participate in online conversations on YouTube. They developed a model, based on mixed random walk, that was used to estimate the interestingness of con-versations that emerged around YouTube videos. They found that users tend to par-ticipate in conversations that have  X  X nteresting themes, X  and are commented on by familiar users with high social impact.

A parallel body of studies, yet indirectly related to the scope of our article, is fo-cused on the spread of information in the blogoshpere [Gruhl et al. 2004; Kumar et al. 2005], and the influence of one author on others in social media sites [Agarwal et al. 2008; Kempe et al. 2003; Song et al. 2007]. Song et al. [2007] modeled influence using InfluenceRank , a measure that considers novel information diffusion between differ-ent users. According to this model, influencers are those that initiate novel ideas in the blogosphere, which are then cited by many others. Similar to our work, this work also measures novelty as an important feature for identifying influencers. How-ever, it is mostly based on citation analysis and thus is not effective for analyzing new content contributions. Moreover, Song et al. [2007] did not consider other pos-sible novelty features, such as self-novelty, as a factor that can assist in estimating  X  X nterestingness. X 
Chai et al. [2009] provide a comprehensive survey on various content quality characteristics that were already considered in the literature, which can be used to estimate the quality of social media content. The set of features can be categorized into two main classes: the author X  X  features (reputation, objectivity) and the content-based features (amount of user feedback, relevancy, completeness, accuracy, understand-ability, consistency). Several works tried to use similar features to predict the quality of UGC and its popularity [Agichtein et al. 2008; Hasan Dalip et al. 2009; Hsu et al. 2009; Khabiri et al. 2009; Mishne and Glance 2006; Tsagkias et al. 2009]. Mishne and Glance [2006] showed that blog popularity is highly correlated with the volume of blog comments. Agichtein et al. [2008] measured the quality of questions and answers in Yahoo! Answers using a classifier trained on several structural, textual, and community-based features. Hasan Dalip et al. [2009] estimated the quality of Wikipedia articles by training a classifier on several textual, revisional, and structural features extracted from the articles X  content.
 More recently, Khabiri et al. [2009] studied the popularity factor of Digg comments. They showed that popular comments were those contributed by users with a good reputation (i.e., active users with history of highly ranked comments), and those with high textual quality. These authors further attempted to predict the popularity of Digg comments using support-vector regression over these features [Hsu et al. 2009]. Tsagkias et al. [2009] addressed a similar prediction task for online news and classified articles as such with low or high potential to be commented, using similar features to those in Hsu et al. [2009]. Szabo and Huberman [2010] and Lerman and Hogg [2010] further used click-though data to enhance the popularity prediction of Digg news. Focusing on a similar prediction task [Hsu et al. 2009; Lerman and Hogg 2010; Szabo and Huberman 2010; Tsagkias et al. 2009], this article extends our preliminary study in [Carmel et al. 2010] and shows how novelty factors can assist in predicting the expected volume of comments for a new UGC, in the absence of user feedback. Novelty detection has been the focus of several IR tasks [Allan et al. 2003; Soboroff and Harman 2005]. Most detection approaches are based on measuring the dissim-ilarity between new content to previously published content. We follow the same approach, however, we measure novelty by the normalized compression distance ( NCD ) [Cilibrasi and Vit  X  anyi 2005], which assesses the similarity between a pair of strings by measuring the improvement achieved by compressing one string using the information found in the other string.

Predicting the number of expected comments for a given UGC has some characteris-tics in common with predicting the volume of academic paper citations. This task was studied intensively in the 2003 KDD Cup [Gehrke et al. 2003]. Furthermore, Castillo et al. [2007] estimated the number of expected citations based on the paper authors X  reputations. Dietz et al. [2007] also considered the paper content and the topic flows between papers using an extension of the LDA model. In this article we further demon-strate how the novelty features developed for the UGC comment prediction task are beneficial for predicting the volume of academic paper citations.
 A related task in the music domain was recently studied by Bischoff et al. [2009]. This work introduced a new method for predicting the potential of music tracks to become hits. Instead of relying directly on the intrinsic characteristics of the tracks, it uses data mined from music social network sites and the existing relationships be-tween tracks, artists, and albums. Following the results of our work, it will be inter-esting to explore the relations between novelty and music popularity. To the best of our knowledge, this question has not been researched yet and should be furthered investigated. We start this section with some definitions and then derive several novelty-based fea-tures for a given post, whose popularity we predict in a later section. Let U = { u 1 , u 2 ,..., u n } be a set of n sources of UGC, where each source u  X  U is modeled as a stream of user contributed content updates, termed hereinafter as posts . Such content is usually contributed by the same author, or a community of authors who post updates on the same source, for instance, a blog on the same topic. Let p u denote a single post published on source u . We assume each post p u hasatimestamp t ( p u ) that captures its publication time.

Each post can further have zero to many comments from its readers. 8 We denote the sequence of comments to a post p u by C ( p u )= { c 1 ,..., c k } , where each comment c has its own publication time t ( c i ). Obviously, the publication time for any comment c  X  C ( p
We now define three sets that will be used later on to derive the proposed novelty-based features. Figure 1 provides an illustration of the three sets, where a single new post is illustrated at the bottom left (gray rectangle).

Definition 3.1 ( Self-novelty set ). Given a post p u , we define SN ( p u , T )tobetheset of all posts that were published on the same source u previous to post p u ,withina given time window T . Formally: The self-novelty set is illustrated by the left (black) rectangle region in Figure 1. Definition 3.2 ( Contemporaneous-novelty set ). Given a post p u , and a time window T , we define CN ( p u , T )tobethesetofallposts p u that were contemporary published with post p u on other sources within the time window T . Formally: The contemporaneous-novelty set determines all posts that were published on other sources, contemporary with post p u in a given time window. This set of posts is illus-trated by the bottom (blue) rectangle region in Figure 1.
Definition 3.3 ( Discussion-novelty set ). Given a post p u , a sequence of comments to the post C ( p u ), and a timestamp t , we define DN ( p u , t )tobethesetofallcommentsto post p u that were submitted up to time t . Formally: The discussion novelty set for a given post is magnified on the upper left corner in Figure 1. We measure the novelty of a single source-post over three contextual dimensions, which we hypothesize as contributing to predicting its popularity. Many novelty mea-sures have been proposed over the years; most are based on measuring dissimilarity of the new content from previously published content [Allan et al. 2003; Soboroff and Harman 2005]. In this work we utilize a distance measure that is derived from infor-mation theory, known as the normalized compression distance (NCD), suggested (and was given a formal justification) by [Cilibrasi and Vit  X  anyi 2005].
 Given a compressor M and two strings x and y ,the NCD is defined as: where M ( x ), M ( y )and M ( xy ) are the bitwise sizes of the resulting sequences when using M to compress x , y , and the concatenation of x and y , respectively. In this work, we used the 7ZA-compression algorithm [Salomon 2004] as our choice for M ,duetoits ability to utilize a large buffer that is well suited for large text.

NCD estimates the distance between two text strings by measuring the improve-ment achieved by compressing one string using the information found in the other string. It has been proved to serve as an approximation of Kolmogorov complexity [Cilibrasi and Vit  X  anyi 2005]. NCD was shown in previous studies to be efficient in identifying distances between different types of information items, including music [Cilibrasi et al. 2004], authors [Amitay et al. 2007], and languages [Benedetto et al. 2002]. We now suggest several novelty-based features for predicting UGC popularity. This set of features can be further used along with more traditional features [Chai et al. 2009]. We measure novelty along three contextual dimensions, coined self novelty, contemporaneous novelty, and discussion novelty. 3.3.1. Self Novelty. This measure models the relative novelty embedded in new UGC with respect to the user X  X  own contribution history. Self novelty measures the novelty of a new post with respect to previous posts published on the same source. We hy-pothesize that self-novelty contributes to post popularity, probably due to the fact that authors who fail to innovate and to  X  X urprise X  their readers, lose their popularity over time.

Given a post p u of some source u  X  U , and a time window T s ;let SN ( p u , T s )bethe corresponding self-novelty set according to Definition 3.1. The self-novelty of post p u with respect to SN ( p u , T s ) is given by: tion of all post contents in the SN set.
 3.3.2. Contemporaneous Novelty. This measure evaluates the novel contribution of a single source-post with respect to other posts submitted in the same time period. We hypothesize that non-novel source-posts are less popular as they fail to explore new valuable information for their readers.

Given a post p u of some source u  X  U ,andatimewindow T c ;let CN ( p u , T c )bethe corresponding contemporaneous-novelty set according to Definition 3.2. The contem-poraneous novelty of post p u with respect to CN ( p u , T c ) is given by: 3.3.3. Discussion Novelty. This measures relates to the novelty of the comments as-sociated by readers with previous posts on the same source. The comments of each previous post are compared to the original post content to measure their novelty in terms of the amount of information they add to the original post. The intuition behind this measure is that a post on a source that is commented with comments that add new content to its own content (e.g., more details on the original post X  X  topic, new point of views, sentiments, etc.), results with a high discussion novelty. Therefore, such a post is more likely to initiate an interesting fruitful discussion that will affect the post X  X  popularity.
 posts in u prior to p u . The discussion novelty of p u is measured by the average novelty of comments on previous posts on the same source. More formally: where | b | represents the number of previous posts on u ,and concat ( DN ( p u , t ( p u ))) is the concatenation of all comments to post p u that were given prior to publication time of p u .

Finally, it is important to note that the amount of source post history that can be kept depends on the underline application capabilities. For example, most blog sys-tems nowadays keep the whole history of their UGC. The size of source post history may be controlled by tuning the number of previous posts considered for the discussion novelty calculation in our model. Furthermore, efficient techniques for maintaining fresh UGC source post histories with bounded size may be employed [Roitman et al. 2008].

The following sections provide experimental results that validate the usage of the novelty-based features to predict the post popularity, as indicated by the number of its expected comments. In Section 4 we focus on the task of predicting the number of comments for a blog post. In Section 5 we study the prediction of number of citations for academic papers. We collected data from an internal IBM blogging system [Huh et al. 2007]. We obtained a total of 42,502 blog posts written by 4,416 unique bloggers. Figure 2(a) demonstrates a power-law distribution of the number of posts per blog in our dataset with a power factor k =  X  1 . 74 ( R 2 =0 . 89).

We extracted several features from each blog post to be used by the popularity pre-dictor. These features include the post X  X  raw text, the time and date of its publication, the number of comments it received as well as the comments X  raw text and publication time, the number of tags the post was tagged with as well as its average rating value. We further measured (average and standard deviation) the relative activity (relative publication rate) of the blog X  X  author. Table I provides the full list of features that we used, including the new proposed novelty-based features described in Section 3. We measured blog post X  X  popularity as the total number of comments it received until the time we obtained the dataset, as in [Hsu et al. 2009; Mishne and Glance 2006; Tsagkias et al. 2009]. The number of comments per blog post in our dataset is power-lawed (similar to what was shown in [Mishne and Glance 2006]) and is demonstrated in Figure 2(b) with a power factor k =  X  2 . 55 ( R 2 =0 . 95).

Our goal is to predict whether a new blog post would receive a total of N or more comments in the future, by learning a predictor that is based on the features described in Table I. We tested two classifiers for prediction: a Linear Regression and a Decision Tree. The goal of the classifier is to separate blog posts with N or more comments from all other posts. Given a new blog post, the predictor will then classify it into either of the two classes. Both classifiers were trained using the given blog data. Tenfold cross validation was used to reduce the chance of overfitting.

The accuracy of prediction was measured by the area under the corresponding ROC curve. The ROC curve shows how well items with N or more comments can be identi-fied, by plotting the true positive classification rate as a function of the false positive rate, that is, the fraction of correctly identified blog posts versus the fraction of posts that would incorrectly be labeled as having N or more comments.

Since both classifiers predict the number of comments per post directly, they can ad-ditionally be evaluated by the Spearman X  X - X  regression coefficient that measures pre-diction quality by the correlation between the ranking of the posts according to their  X  X rue X  number of comments and the ranking of the posts according to their predicted number of comments. Therefore, we evaluate the predictors by the area under the ROC curve, when used as binary predictors, and by the rank correlation (Spearman X  X - X  ), when used as multiple value predictors. The linear regression classifier gave superior performance for this task, thus we provide an analysis of its results in the following text. In the first set of experiments, we analyzed the contribution of the proposed novelty-based features over the remaining features to the accuracy of the prediction (see Table I). We split the training blogs into three groups according to the length of their posting history: short (with 1 X 5 posts), moderate (with 6 X 10 posts) and long (with 11+ posts). We learned three predictors for each set: the first one with only the novelty-based features, the second with only the traditional blog and post features, and the third with all features together. The predictor X  X  task was to identify posts with at least 10 comments. For the novelty-based features we set T s (the self-novelty time window) to 120 days, and T c (the contemporaneous-novelty time window) to 10 days. Figure 3 shows the area under the ROC curve for the linear regression classifier in the three settings.

As the figure illustrates, considering only the novelty-based features for prediction leads to poor prediction accuracy, and the best strategy is to combine all features together. The proposed novelty-based features add significant gain to the overall per-formance of the predictors. This is most evident for blogs with short history: the novelty-based features add approximately 7% to the prediction accuracy, as measured by ROC, and 14% to the rank correlation, for blogs with five or fewer posts. The con-tribution of the novelty-based features for blogs with moderate and long histories is smaller but still significant. This reduction in gain is expected because a long history provides enough evidence for the blog X  X  popularity, hence novelty-based features are less significant for prediction.

The results clearly reveal that novelty-based features are indeed valuable for pre-dicting blog post popularity, especially for blogs with a short history, according to the two evaluation metrics. In the following we take a deeper look into the prediction task. Having successfully verified the effectiveness of using the proposed novelty-based fea-tures together with the baseline features, we now analyze the performance of the linear regression classifier for different parameter settings.

In the first experiment we studied the effect of the window size used by the novelty-based features on prediction quality. Recall that, in order to obtain the self-novelty and contemporaneous novelty features, we must first determine the time windows for which we derive the SN and CN sets respectively. We trained the linear regression classifier, using all features and all data (with tenfold cross validation), for different threshold values and different window sizes. Figure 4 shows the ROC area obtained by the classifier, for predicting at least N comments, while increasing T s window size (in days) and a fixed window size T c = 10 days. We can observe that the area tends to saturate at around 120 days for every value of N that we tested, and any improvement thereafter is relatively small. This indicates that the effective horizon for blog posts is approximately 4 months, with longer horizons adding relatively little information. The effect of T c was also examined in a similar manner, and was found to reach a plateau at T c = 10 days. Its overall effect on the ROC area was negligible.

Table II shows for each threshold value ( N ), the fraction of blog posts with at least this number of comments, and the area under the ROC curve that the linear regression predictor reached. Note that for N  X  1 the predictor also predicts no comments at all. Interestingly, it is easier to identify blog posts with many expected comments than to distinguish between blog posts with no comments to those posts that will have at least one comment (as is also evident from Figure 4). We attribute this to the fact that most blog posts that receive many comments tend to come from blogs that have a persistent following over time, thus are easier to be identified.

When applying the linear regression predictor as multiple value predictor, the rank correlation between the actual and predicted rankings (according to the actual number of comments and the predicted number of comments) in this setting was  X  =0 . 28 ( p &lt; 10  X  4 ).

Figure 5 further shows the ROC curves obtained by the predictor using the same parameters setting and threshold values of Table II. Different points on the ROC curve represent different thresholds for deciding if a blog post will receive N or more posts. The curves are relatively smooth, indicating that there are no specific groups of blogs that are easier (or more difficult) to identify.
 Finally, we identified the most influential features used by the predictor by normaliz-ing each feature to zero mean and unit variance, and ranking the weights learned by the predictor (for N = 5) in decreasing order of absolute magnitude. Using this method, the most influential features (in decreasing order of importance) were: (1) discussion-novelty, (2) self novelty, (3) average number of comments to previous posts, and (4) standard deviation of discussion-novelty.
 The influential features were all positively correlated with the comment count. We estimated the relative contribution of each of these features by building a predictor with the most influential feature, the two most influential features, etc. The area un-der the ROC curve, for different threshold values, and the rank correlation, is given in Table III. According to this table, even when using a single feature, it is easier to iden-tify posts that will receive many (more than 10) comments, compared to identifying posts that will receive no comments. Furthermore, the average number of comments to previous posts is mostly influential for identifying blog posts that will receive 10 or more comments, and self-novelty also contributes to this prediction task. This is in line with our previous observation on the relative ease of identifying such posts (see Section 4.3) that mostly belong to blogs with long history. Note also the improvement in rank correlation when self novelty is added to the features set. This again provides evidence to the value of adding the novelty-based features for the prediction task. In contrast, contemporaneous novelty is not one of the most influential features in the blog domain. However, in the following we will show the dominance of this feature for popularity prediction in the academic papers domain. We now further demonstrate how the novelty-based predictor can be used for the task of citation prediction for academic papers. We first describe the papers dataset that we used. We then show that the number of citations to a given paper is correlated with the number of paper X  X  bookmarks, demonstrating that using paper citations for popularity measurement is indeed valid. Finally, we describe how the novelty-based predictor can be used for this task. Our dataset consists of all papers published in SIGIR between 1991 and 2002. We chose this dataset because it represents the publications made by a single academic community, and that enough time has passed since the publication of the last paper in the collection to allow reasonable exposure time. This dataset consists of 710 papers. Since we tracked publication histories of authors, we only used papers of authors who had published more than one paper in that data period. This resulted in 499 papers published by 663 authors. We measured the number of citations made to a paper, as provided by Google Scholar at the end of 2009. The number of papers per author and the number of citations per paper in our dataset have power-law distribution with respectively.

An alternative measure for paper popularity might be the number of times a paper was bookmarked by readers, in a bookmarking website such as CiteULike, 9 which allows its users to bookmark academic articles. For the 499 papers considered in this study, we tested this relationship and found a Spearman correlation of 0 . 44 ( p &lt; 10  X  10 )) between the number of citations a paper has and the number of times it was bookmarked in CiteULike. This relatively high correlation lends strength to our assumption that paper popularity can be measured by the number of its citations.
For each paper, we extracted similar features to the ones described in Table I. The first set of features includes the average and standard deviation of the number of ci-tations for previously published papers by the same author, the number of unique au-thors who cited papers by the same author, and the paper length. If there are several coauthors for a paper, we took the maximum, minimum, and average of the attributes for each author.

Given a paper and time windows T s and T c we then calculated the paper X  X  self-novelty and contemporaneous-novelty features. It is worth noting that for papers we did not measure the discussion-novelty since paper citations are not accompanied with text compared to blog post comments. 10 Similarly to the blog domain, we attempted to predict if the number of citations of a paper will be N or more. Because of the relatively short time span of the data, we set T s = 5 years and T c = 1 year. We tested the two classifiers for prediction: Linear Regression and a Decision Tree. The classifiers were trained using all data; ten-fold cross validation was used to reduce the chance of overfitting. In this case, the decision tree predictor gave superior performance for this task, and thus we provide an analysis of its results below.

In the first set of experiments, we analyzed the contribution of the new proposed novelty-based features over the remaining features for prediction. Table IV shows the ROC area (for predicting 10 or more citations) and the rank correlation of the decision tree classifier, when trained with (1) novelty-based features, (2) traditional features, and (3) all features.

Similarly to the results in the blog domain, the novelty-based features contribute significantly to the prediction accuracy of the expected number of citations, and the best performance is obtained when all features are used for prediction.

Table V shows different thresholds at which the decision tree predictor was evalu-ated, as well as the resulting area under the ROC curve, while setting T s = 5 years and T c = 1 years. We can observe from the table that, overall, we obtain similar results to those in the blog domain, with relatively high prediction accuracy for the number of citations. We can also see that prediction accuracy increases with N , that is, it is easier to identify papers with many citations than to identify papers with no citations.
Figure 6 shows the ROC curves obtained using the decision tree predictor, with the same thresholds as in Table V.

The ROC curves are not  X  X mooth X  as the ROC curves in the blog domain, probably due to data sparseness in this domain.

Finally, we identified the most influential features for citation prediction by per-forming sequential forward feature selection [Duda et al. 2001]. Table VI lists the most influential features, in decreasing order. As this table shows, contemporaneous novelty is the most influential factor for paper citations. This is in contrast to the blog domain where this feature is not found among the top influential features. Interest-ingly, it is also negatively correlated with citation count, that is, high contemporaneous novelty indicates low citation count. The number of papers published by the authors and self novelty are the second and third most influential features. This means that papers that are similar to other contemporaneous papers, and are published by prolific authors, are most likely to be cited by peers. The additional improvement in prediction beyond the first three features is small (less than 1% improvement). This work studies the relationship between novelty and popularity of user-generated content. Our results show that people are more likely to gain public attention by pub-lishing novel content. Attractive posts are those that are novel with respect to previous content published by the same author, as well as novel with respect to contemporane-ous published content, at least in some domains. In addition, stimulating posts that are able to trigger online discussion have high potential to become popular.
By measuring the three novelty dimensions of a blog post, we demonstrated how the novelty-based features can contribute to the task of predicting the number of com-ments to the post, which reflects its popularity. We also demonstrated how the same novelty-based features can assist in predicting the citation volume of academic papers. Interestingly, in contrast to the blog domain, contemporaneous-novelty was found to be negatively correlated with the paper X  X  citation count. This result suggests that in order to gain popularity, academic articles should not be radically different from other articles published in the same time period. In other words, popular articles are those that address issues of current interest to the community.

The datasets we used in this work are free of spam that is prevalent in user-generated content, especially in blog domains [Agichtein et al. 2008]. Spam, in the context of this work, can harden the identification of good quality UGC, as spammers can easily pretend novelty by  X  X njecting X  some randomness into their posts [Mishne et al. 2005]. We leave the separation of spam from novel content for future work.
Furthermore, we note that the overall prediction accuracy of our predictors is not very high, even when using the novelty-based features, probably due to the high com-plexity of the popularity prediction task. While novelty-based features significantly contribute to the prediction accuracy, it seems that high quality prediction of post pop-ularity is still an open challenge and deserves further exploration for more valuable features for that prediction task.

The positive correlation between content X  X  novelty and popularity might be seem obvious, as good content is expected to be novel. However, this is the first study, to the best of our knowledge, that this relationship has been examined and verified system-atically, in the context of the blogosphere and academic writing.

Our work can be extended in several directions. First, we note that there might be more effective ways of calculating novelty. A comparable study is required to investigate the applicability of different novelty measures for the task of popularity prediction. Second, we observe that in the blogosphere, self-novelty seems to dominate contemporaneous-novelty with respect to its importance for popularity prediction; for scientific papers, we observe the opposite trend. Therefore, it might be interesting to explore in more depth the differences and relationships between the two. Furthermore, following the discrepancy between the two domains studied in this article, it would be interesting to study UGC popularity in other domains such as social media (e.g., Facebook, Twitter) and Q/A (e.g., Yahoo! Answers, Quora). Finally, we wish to examine new novelty measures and their relationship with popularity in more domains (e.g., audio-visual content) for which such novelty measures can be captured. Furthermore, it would be interesting to examine novelty-measures which also consider content semantics.

