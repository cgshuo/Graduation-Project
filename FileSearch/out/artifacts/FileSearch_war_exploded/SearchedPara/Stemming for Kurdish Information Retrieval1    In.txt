 Stemming is a common form of language processing in most information retrieval (IR) systems. Stemming is the process of reducing a word to its stem or root form. It allows documents in which a term is expressed using a different morphological form from the query, to be found and matched.

Although experiments with English data show mixed results [9,11,14], retrieval per-formance for morphologically more comple x languages (e.g., Hungarian, Czech and Bulgarian [17], German [20,3], Dutch and I talian [20], and Arabic [33]) has benefited consistently and significantly from stemming.

The Kurdish language is an Indo-European language spoken in Turkey, Iran, Iraq and Syria. Despite having a large number of speakers, Kurdish is considered a less-resourced language for which  X  X mong other basic tools X  no stemmer has been devel-oped. Apart from the resource-scarcity problem, diversity  X  X n both dialect and writing systems X  is another primary challenge in Kurdish language processing. In fact, Kurdish is considered a bi-standard language [7,10]: the Sorani dialect written in an Arabic-based alphabet and the Kurmanji dialect written in a Latin-based alphabet. The features distinguishing these two dialects are phonological, lexical, and morphological.
This paper reports on our efforts in building stemmers for the two main dialects of the Kurdish language and investigate their effectiveness on Kurdish IR. The main contributions of this work are:  X  we build Jedar , a rule-based stemmer for both Sorani Kurdish and Kurmanji  X  we implement GRAS  X  X  state-of-the-art statistical stemming technique X  and apply  X  we conduct a comprehensive experimental study to compare the effectiveness of  X  we carry out a detailed analysis of the results to obtain insights about the behavior Additionally, our source codes for the Jedar and GRAS implementations along with the list of Kurmanji and Sorani suffixes use d in our experiments a re freely accessible and can be obtained from [12]. We hope that making these resources publicly available, would bolster further research on Kurdish IR.
 bit of background on stemming in IR and also on the Kurdish language and dialects. Then in Section 3 we present the Kurdish suffixes and show how we used them to build Jedar, our rule-based stemmer. In Sectio n 4, we briefly explain the GRAS statistical stemming algorithm [22] as well as our implementation of this algorithm. The details of our experimental study and analysis are reported in Section 5. Finally, we conclude the paper in Section 6. In this section we first give an overview of stemming in IR and then briefly introduce the Kurdish language and dialects. 2.1 Stemming for Information Retrieval In an IR system, stemming is used to reduce variant word forms to common roots, and thereby improve the ability of the system to match query and document vocabulary. The variety in word forms comes from both inflectional and derivational morphology [32]. Inflection characterizes the changes in wor d form that accompany case, gender, number, tense, person, mood, or voice. Derivational analysis reduces surface forms to the base form from which they were derived, and inc ludes changes in the part of speech [11].
All stemming algorithms can be roughly classified as rule-based (a.k.a affix remov-ing) or statistical. Below we give a b rief overview of each of these classes. Rule-Based Stemmers. Rule-based stemmers apply a set of transformation rules to each word, trying to strip its suffixes 1 . Two of the most popular algorithms in English IR, the Lovins stemmer and the Porter stemmer, are based on suffix removal.
Lovins X  paper [15] was the first published description of a stemmer. It defines 294 endings, each linked to one of the 29 conditions, and the 35 transformation rules. For a word being stemmed, an ending with a sa tisfying condition is found and removed. The algorithm is fast but misses certain endings.

Porter X  X  algorithm [23] defines five successively applied steps of word transforma-tion. Each step consists of set of rules. The algorithm is concise (about 60 rules) and efficient. The main flaws and errors are we ll-known and can mostly be corrected with a dictionary. The idea of Porter algorithm was later generalized into a stemmers frame-work called Snowball [24].

The major drawback of the rule-based approach is its dependency on a priory knowl-edge of the concerned language X  X  morphology.
 Statistical Stemmers. In contrast to the rule-based stemmers, statistical stemmers are language-independent and only require a c orpus or a lexicon. In following we briefly summarize three important statistical stemmers.

The authors of the YASS stemmer [18] viewed stemming as a clustering problem in which the resulting clusters are considered as equivalence classes and their centroids as stems. Based on their implementation and experiments, they conclude that YASS X  per-formance is comparable to rule-based stemmers like Porter or Lovins for English. For more morphologically-complex languages suc h as Bengali and French, YASS provides substantially improved performance as compared to using no stemming [18] .
Bacchin et al. [1] described a probabilistic model which relies on the mutual rein-forcement relationship between stems and suffixes. Once the prefix and suffix scores are computed over a subset of documents from the corpus, the algorithm estimates the most probable split (into stem and suffix p air) for each word in the full corpus. A set of experiments with several languages pr oduced equally good results as those produced by rule-based stemmers [1].

The main disadvantage of the aforementi oned statistical stemming algorithms is that they are computationally expensive. In c ontrast, the recently-proposed GRAS algo-rithm [22] has been shown to be an efficient alternative. In experiments with seven languages of very different language families and varying morphological complexity, the authors showed that GRAS outperforms rule-based stemmers, three statistical meth-ods (including YASS [18]), and the baseline strategy that did not use stemming.
Hence, we consider GRAS as the state-of-the-art solution for statistical stemming and use it in our experiments. We will describe the GRAS algorithm in more details later in Section 4. 2.2 The Kurdish Language and Dialects Kurdish belongs to the Indo-Iranian family of Indo-European languages. Its closest better-known relative is Persian. Kurdish is spoken by 20 to 30 million people [8,10] in Kurdistan, a large geographical area spanning the intersections of Turkey, Iran, Iraq, Kurdish is a dialect-rich language, however, in this paper we focus on Sorani and Kurmanji which are the two closely-related and widely-spoken dialects of the Kurdish language [8]. Together, they account for more than 75% of native Kurdish speakers [31].
As summarized below, these two dialects differ not only in some linguistics aspects, but also in their writing systems.
 Morphological Differences. Some of the important morphological differences are [16,8]:  X  Kurmanji is more conservative in retaining both gender (feminine:masculine) and  X  the definiteness suffix -aka appears only in Sorani,  X  in the past-tense transitive verbs, Kurmanji has full ergative alignment but Sorani, Scriptural Differences. Due to geopolitical reasons, each of the two dialects uses its own writing system: Sorani is almost-exclusively written in an Arabic-based alphabet and Kurmanji is almost-exclusively written in a Latin-based alphabet. Figure 1 shows the two standard alphabets and the mappings between them [5].
As we will explain in Section 3, these differences have direct implications on design-ing Kurdish stemmers. In the following, we first present the main Kurdish suffixes and then introduce our rule-based suffix-removing stemmer. 3.1 Main Suffixes in Kurdish Kurdish has a complex morphology [26,29,5] and one of the main driving factors behind this complexity is the wide use of inflectional and derivational suffixes [6]. In general, Sorani and Kurmanji share a large proportion of suffixes. However, there is a small, but very important, set of Sorani-specific suffixes. Below, we elaborate more on each of these two groups.
 Common Suffixes. An essential subset of common suffixes between Sorani and Kur-manji is depicted in Figure 2. The complete set can be downloaded from [12]. It should be noted that for some pairs, the Sorani and the Kurmanji strings are not complete transliteration-equivalents (based on the char-level mappings of Figure 1). The left side of Figure 2 (part a) contains the common noun suffixes. A few important remarks re-garding this list are:  X  the Izafe Construction is a shared feature of several Western Iranian languages [25].  X  the impact of case in Kurmanji is also evident in the plural noun marker [30], for  X  in the Kurmanji writing system, if suffixing results in two consecutive vowels, an
The right side of Figure 2 (part b) represents the common verb suffixes. There are two important notes here:  X  in Sorani and Kurmanji while conjugating a verb in past or present tense, per- X  Kurdish resembles most Iranian languages in the fact that it possesses only a limited Sorani-Specific Suffixes. Compared to Kurmanji, Sorani has a richer set of suffixes. A small, but nonetheless very crucial, set of Sorani-specific suffixes is listed in Fig-ure 3. As described below, the existence of these suffixes is due to Sorani X  X  inherent morphological properties as well as its script and system of writing:  X  Sorani uses the pronominal suffixes to take over the functions of the cases (see Sec- X  the definite markers ( aka and akaan for singular and plural nouns, respec- X  there is a general tendency in Sorani X  X  writing system to join suffixes to their pre-3.2 Jedar In this section we introduce Jedar 2 , the first rule-based stemmer for the Kurdish lan-guage. Kurdish stems are often followed by multiple suffixes, hence, Jedar adopts a re-cursive approach to handle nested suffixes. Moreover, we have devised two techniques to decrease Jedar X  X  over-stemming error 3 . The first technique  X  X dopted from [15] X  is to prevent over-stemming by setting a minimum stem length parameter, denoted by L .
The second technique is to exploit the inherent suffixing properties of the Kurdish language. Below, we give a brief description of some of these properties:  X  the nominal suffixes appear in a certain pre-defined order. To demonstrate this order, we analyze the example word ktewakaanishtaandaa  X  X in] your books too X  which consists of a stem ( ktew  X  X ook X ) and four different suffixes:  X  in any given word, only one instance of each suffix type can appear. For ex-ample, although the word klinekaka  X  X he clinic X  contains both the indefinite marker ( ek ) and the definite marker ( aka ), only the second one is a valid suf-fix and the first one should be left untouched. One important exception to this rule is MPMs/possessive pronouns (Figure 3a), which have identical representations but dif-ferent roles.  X  under some circumstances, the minimum length constraint can be relaxed. For ex-ample if a word ends in boo  X  X as X , this string can be removed, as it is solely used to build the past perfect form of the verbs.

Jedar has been implemented as a single Java class (for both Sorani and Kurmanji) that takes a list of dialect-specific suffixes as i nput. For each input word, Jedar recursively removes the best matching suffix, taking into account a set of rules including those explained above. As explained in Section 2.1, the GRAph-based Stemming (GRAS) algorithm has been shown to outperform a number of other existing statistical stemmers. Hence we chose this algorithm to compare with Jedar. The GRAS algorithm, in essence, consists of three steps [22]: Step 1: Frequent Suffix Pair Identification. GRAS starts with a lexicon, a list of the distinct words of the concerned language (usually extracted from a corpus). The words in this lexicon are partitioned into a number of groups such that each pair of words drawn from a group has a common prefix of length at least  X  , a pre-defined threshold. Within each group, all possible word pairs are e numerated and suffix pairs are extracted. For example, since the word pair ( w 1 = p || s 1 ,w 2 = p || s 2 ) share a common prefix p , frequency of each suffix pair is computed an d the non-frequent pairs (fewer occurrences than  X  , a cutoff threshold) are discarded.
 Step 2: Graph Construction. Having built a list of frequent suffix pairs, this list is then used to construct a weighted undirected graph G =( V,E ) as follows. Each word in the lexicon is represented by a vertex in G . In this graph, the edge weight, w ( u, v ) , is the frequency of the suffix pair induced by the word pair represented by u and v . Needless to say, if w ( u, v ) &lt; X  , there is no edge between u and v .
 Step 3: Graph Decomposition. Once the graph G is constructed, the next step is to decompose it. The decomposition algorithm first chooses a pivotal node (say p ) from the remaining vertices, such that its degree is maximized. Next, it considers the vertices adjacent to the pivotal node p one-by-one and measures the cohesion between p and v using the formula: The value of cohesion lies between 0 and 1 . If the cohesion value exceeds a certain threshold (  X  ), the vertex v is assumed to be morphologically related with the pivot p and is put in the same class as p . Otherwise, the edge ( p, v ) is deleted immediately to mark that p and v are not related.

As highlighted by the authors, the choices of the three main parameters  X  X amely the minimum length of the common prefix  X  , the suffix frequency cutoff  X  , and the cohesion threshold  X   X  are important for the performance of the algorithm. Although they provide some clues, but as shown later, more precise values can be found empirically.
The original implementation of GRAS is unfortunately not open source. Therefore, we built our own implementation from scratch by closely following the descriptions given in [22]. Our Java implementation of the GRAS algorithm (along with Jedar X  X  implementation) can be obtained from [12]. In our experiments, we used Pewan, a publicly-available Kurdish test collection [13] which contains two separate text corpora (one Sorani one Kurmanji) and a set of queries available in both dialects. The main properties of the Pewan collection are summarized in Table 1.

For the IR engine, we chose MG4J [19], an open-source Java retrieval system which has been shown [4,6] to be the best performing system for Kurdish IR among a number of systems.

In the following, we first report on the sensitivity analysis that we carried out to fine-tune Jedar X  X  and GRAS X  parameters. Then we provide more insights about the outcomes through a detailed analysis of the results. 5.1 Parameter Tuning In these experiments we vary the stemming parameters and compare the results based on Mean Average Precision (MAP) values. Additionally, we also report the size of the resulting lexicon, that is the total number of distinct strings in Pewan after applying stemming. Jedar X  X  Parameter. We performed a sensitivity analysis on Jedar by varying the mini-mum stem length parameter, L , from 3 to 6 (according to Lovins [15], any useful stem often consists of at least three or four characters).

The results are shown in Table 2. In this table, Baseline denotes the case in which no stemming was applied. Based on these numbers, two important conclusions can be drawn: (i) our rule-based stemming solution generally improves the retrieval perfor-mance, (ii) for both Sorani and Kurm anji, the best result is achieved for L =3 (the gains are 25% and 35% respectively).
 GRAS X  Parameters. One of the important steps in building statistical stemmers is find the best of set of values for the parameters [28]. For GRAS, although the authors provide some general hints in [22] (i.e.,  X  to be the average word length for the lan-guage concerned,  X  =4 and  X  =0 . 8 ), but we decided to run a set of experiments to empirically identify the best vales for the these parameters.

From the computational complexity perspective,  X  is the most important parameter, as it directly affects the complexity of the graph decomposition step. In our experi-ments, we varied the value of  X  from 3 to 7 (Sorani X  X  average word length is 5 . 6 ;for Kurmanji it is 4 . 8 [5]). Moreover, since running the algorithm with  X  =3 and  X  =4 on the full version of our Sorani lexicon (generated from all documents in Pewan X  X  So-rani corpus) exhausted our computational resources, for these cases we used reduced lexicons (generated from 10% and 25% of the documents, accordingly).

The results of this study is shown in Table 3. We would like to note that in the interest of space and due to its inferior performance, the results for  X  =7 are not included in this table.

Based on these numbers, the following observations can be made: (i) our implemen-tation of the GRAS statistical stemmer generally improves the retrieval performance, (ii) while for Kurmanji the best outcome is achieved for (  X  =3 , X  =2 , X  =0 . 7 ), Sorani X  X  peak is reached at (  X  =4 , X  =6 , X  =0 . 9 ). 5.2 Analysis The MAP measure is useful to compare the overall performance of different IR systems. In order to better understand the behavior of these systems, a detailed analysis of the results is required. To this end, in the following we present a drill-down comparison of Jedar X  X  and GRAS X  outputs at their best-performing configuration.
 Detailed Comparison. Figure 4 depicts the precision cu rves at the standard 11 recall points. It clearly demonstrates the facts t hat (i) both Jedar and GRAS improve the IR performance at all recall levels, (ii) the g ains from Jedar and GRAS are comparable. Given GRAS X  reasonable computational cos t and its language-indepe ndent nature, this can mean that GRAS is the favorable option.
 Query-Level Analysis. We also carried out a query-level examination of the results and identified three distinct groups among the queries. Below, we enumerate these groups and present an example for each one:  X  GRAS outperforming Jedar : for example for Q 21 in the Sorani experiments, while  X  Jedar outperforming GRAS : for instance in the Sorani version of Q 22 , GRAS puts Precision  X  Stemming unhelpful : e.g., for query Q 10 in the Kurmanji experiments, both stem-In this paper we presented Jedar, the first rule-based stemmer for Sorani Kurdish and Kurmanji Kurdish. We also introduced our implementation of GRAS [22], a recent proposal for statistical stemming. After fine-tuning their parameters, these stemmers were used to empirically study the eff ectiveness stemming for Kurdish IR.
Our results show that: (i) both Jedar an d GRAS can significantly improve the per-formance of Kurdish IR systems, (ii) the rule-based approach and the the statistical stemmer approach perform comparably well, (iii) overall, the shorter stem lengths (i.e., 3,4) seem to be more effective.

In future, we plan to propose solutions to fix some of the systematic stemming er-rors that we highlighted in the analysis section (e.g., over-stemming and mishandling of named entities). Comparing the performance of these stemmers against N-grams is another avenue for future work.

