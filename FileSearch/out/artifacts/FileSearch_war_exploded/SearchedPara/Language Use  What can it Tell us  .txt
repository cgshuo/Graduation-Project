 Extracting explicitly stated information has been ple, for the text Mushaima'a, head of the opposi-tion Haq movement , an ACE system extracts the relation LeaderOf(Mushaima'a, HaqMovement). In  X  When was Mozart born?  X , for which the answer is contained in one or a few extracted text phrases. text, but has focused primarily on text known to be rich in opinions (product reviews, editorials) and delves into only one aspect of implicit meaning. informal group discussion from language uses (LU), even if those roles are not explicitly stated ; for example, using the communication during a meeting, identify the leader of a group. This paper provides a snapshot of preliminary, ongoing re-search in predicting two classes of language use : Establish-Credibility and Attempt-To-Persuade . Technical challenges include dealing with the facts that those LUs are rare and subjective and that hu-man judgments have low agreement. detects those two LUs in English and Arabic. Our results are that (1) annotation at the message (tur n) level provides training data useful for predicting rare phenomena at the discussion level while re-ducing the requirement for turn-level predictions t o be accurate; (2)weighing subjective judgments overcomes the need for high annotator consistency. Because the phenomena are rare, always predicting the absence of a LU is a very high baseline. For English, the system beats those baselines. For Ara-bic, more work is required, since only 10-20% of the amount of training data exists so far. A language use refers to an aspect of the social intention of how a communicator uses language. The information that supports a decision about an implicit social action or role is likely to be dist rib-uted over more than one turn in a dialog; therefore , a language use is defined, annotated, and predicted across a thread in the dialog. Because our current work uses discussion forums, threads provide a natural, explicit unit of analysis. Our current wor k studies two language uses. tries to convince other participants to change thei r beliefs or actions over the course of a thread. Typ i-cally, there is at least some resistance on the par t of the posters being persuaded. To distinguish be-tween actual persuasion and discussions that in-volve differing opinions, a poster needs to engage in multiple persuasion posts (turns) to be consid-ered exhibiting the LU. tempts to increase their standing within the group. This can be evidenced with any of several moves, e.g., explicit statements of authority, demonstrati on expertise through knowledge, providing verifiable information (e.g., from a trusted source or citing confirmable facts), or providing a justified opinio n (e.g., a logical argument or personal experience). There were two significant challenges: (a) sparsity of the LUs, and (b) inter-annotator agreement. To address the sparsity of data, we tried to automati-cally select data that was likely to contain conten t of interest. Data selection focused on the number of messages and posters in a thread, as well as the frequency of known indicators like quotations. (withheld). Despite these efforts, the LUs of inter -est were rare, especially in Arabic. guideline development, annotation, evaluation of agreement, and revision of guidelines. Elsewhere, similar, iterative annotation processes have yielde d significant improvements in agreement for word sense and coreference (Hovy et al., 2006). While LUs were annotated for a poster over the full thread, annotators also marked specific messages in the thread for presence of evidence of the lan-guage use. Table 1 includes annotator consistency at both the evidence (message) and LU level. nificantly lower than we have seen in other lan-guage processing tasks. Discussions suggested that disagreement did not come from a misunderstand-ing of the task but was the result of differing int ui-tions about difficult-to-define labels. In the following two sections, we describe how the eval-uation framework and system development pro-ceeded despite low levels of consistency. Task. The task is to predict for every participant in a given thread, whether the participant exhibits Attempt-to-Persuade and/or Establish-Credibility. If there is insufficient evidence of an LU for a pa r-ticipant, then the LU value for that poster is nega -tive. The external evaluation measured LU predictions. Internally we measured predictions of message-level evidence as well.
 Google Groups and LiveJournal have been anno-tated for Attempt-to-Persuade, and 103 threads for Attempt-to-Establish-Credibility. For Arabic, threads were annotated for both tasks. Counts of annotated messages appear in Table 1.
 tempting to resolve annotation disagreement by the standard adjudication process was too time-consuming. Instead, the evaluation scheme, similar to the pyramid scheme used for summarization evaluation, assigns scores to each example based on its level of agreement among the annotators. Specifically, each example is assigned positive and negative scores, p = n + / N and n = n -/ N , where n + is the number of annotators that annotate the example as positive, and n -for the negative. N is the total number of annotators. A system that outputs posi-tive on the example results in p correct and n incor-rect. The system gets p incorrect and n correct for predicting negative. Partial accuracy and F-measure can then be computed.
 Each example x i is associated with positive and outputs positive for example x i and 0 for negative. The partial accuracy, recall, precision, and F-measure can be computed by: when there is disagreement between annotators. To achieve accuracy and F scores on a scale of 100, pA and pF are normalized using the maximum achievable scores with respect to the data. Our architecture is shown in Figure 1. We process a thread in three stages: (1) linguistic analysis o f each message (post) to yield features, (2) Predic-tion of message-level properties using an SVM on the extracted features, and (3) Simple rules that predict language uses over the thread. Engine extracts features which are designed to cap-ture different aspects of the posts. The features i n-clude simple features that can be extracted from the surface text of the posts and the structure of the posts within the threads. These may correlate di-rectly or indirectly correlate to the language uses . In addition, more syntactic and semantic-driven features are also used. These can indicate the spe-cific purpose of the sentences; specifically target -ing directives, imperatives, or shows authority. Th e following is a partial list of features which are u sed both in isolation and in combination with each oth-er. tence length; number of names, pronouns, and dis-tinct entities; number of sentences, URLs (links), paragraphs and out-of-vocabulary words; special styles (bold, italics, stereotypical punctuation e. g. !!!! ), depth in thread, and presence of a quotatio n. argument structure including the main verb, sub-ject, object, indirect object, adverbial modifier, modal modifier, and negation, imperative verbs, injection words, subjective words, and mentions of attack events. level (Section 3), an SVM predicts if the post con-tains evidence for an LU. The motivation for this level is (1) Posts provide a compact unit with reli -ably extractable, specific, explicit features. (2) There is more training data at the post level. (3) Pointing to posts offers a more clear justification for the predictions. (4) In our experiments, errors here do not seem to percolate to the thread level. In fact, accuracy at the message level is not directly predictive of accuracy at the thread level. to-Persuade and Establish-Credibility LUs, we wrote a few rules to predict LUs over threads, giv-en the predictions at the message level. For in-stance, if the number of messages with evidence for persuasion is greater than 2 from a given parti c-ipant, then the system predicts AttemptToPer-suade. Phase 3 is by design somewhat robust to errors in Phase 2. To predict that a poster is exhi b-iting the Attempt-to-Persuade LU, the system need not find every piece of evidence that the LU is pre -sent, but rather just needs to find sufficient evi-dence for identifying the LU. an SVM that optimizes F-measure (Joachims, 2005). Because annotation disagreement is a major challenge, we experimented with various ways to account for (and make use of) noisy, dual annotat-ed text. Initially, we resolved the disagreement au -tomatically, i.e. removing examples with disagreement; treating an example as negative if any annotator marked the example negative; and treating an example as positive if any annotator marked the example as positive. An alternative (and more principled) approach is to incorporate positive and negative scores for each example into the optimization procedure. Because each example was annotated by the same number of annotators (2 in this case), we are able to treat each annotator X  s decision as an independent example without aug-menting the SVM optimization process. that performed best on the leave-one-thread-out cross validation results (Table 23 and Table 34 ). Counts of threads appear in Section 4. We compare our system X  X  performance (S) with two simple baselines. Baseline-A (A) always predicts absent for the LU/evidence. Baseline-P (P) predicts posi-tive (present) for all messages/LUs. Table 4Table 3 shows results for predicting message level evi-dence of an LU (Phase 2). Table 5Table 4 shows performance on the task of predicting an LU for each poster. mance in Arabic than English--not surprising con-sidering 5-10-fold difference in training examples. Additionally, Arabic messages are much shorter, and the phenomena is even more rare (as illustrated by the high npA, accuracy, of the A baseline). A 90.9 86.7 0.0 0.0 87.7 90.2 0.0 0.0 P 12.1 27.0 23.8 48.2 18.0 21.5 33.7 41.1 S 94.6 88.3 76.8 38.8 95.1 92.4 80.0 36.0 from an external evaluation on held out data. Un-like our dataset, each example in the external eval -uation dataset was annotated by 3 annotators. The results are similar to our internal experiment. A 96.2 98.4 0.0 0.0 93.6 94.0 93.6 0.0 P 13.1 4.2 27.6 11.7 11.1 10.1 11.1 22.2 S 96.5 94.6 75.1 59.1 97.7 92.5 97.7 24.7 Research in authorship profiling (Chung &amp; Penne-baker, 2007; Argamon et al, in press; and Abbasi and Chen, 2005) has identified traits, such as sta-tus, sex, age, gender, and native language. Models and predictions in this field have primarily used simple word-based features, e.g. occurrence and frequency of function words. cial roles develop in online communities (Fisher, e t al., 2006), and have attempted to categorize these roles in multiple ways (Golder and Donath 2004; Turner et al. , 2005). Welser et al. (2007) have in-vestigated the feasibility of detecting such roles automatically using posting frequency (but not the content of the messages). implicit nature of the text. Work on perspective and sentiment analysis frequently uses a corpus known to be rich in sentiment such as reviews or editorials (e.g. (Hardisty, 2010), (Somasundaran&amp; Weibe, 2009). The MPQA corpus (Weibe, 2005) annotates polarity for sentences in newswire, but the focus of this corpus is at the sentence level. Both the MPQA corpus and the various corpora of editorials and reviews have tended towards more formal, edited, non-conversational text. Our work in contrast, specifically targets interactive discu s-sions in an informal setting. Work outside of com-putational linguistics that has looked at persuasio n has tended to examine language in a persuasive context (e.g. sales, advertising, or negotiations). (2010) investigates language uses over informal dialogue. Their work focuses on chat transcripts in an experimental setting designed to be rich in the phenomena of interest. Like our work, their predic-tions operate over the conversation, and not a sin-gle utterance. The specific language uses in their work (topic/task control, involvement, and disa-greement) are different than those discussed here. Our work also differs in the data type of interest. We work with threaded online discussions in which the phenomena in question are rare. Our annotators and system must distinguish between the language use and text that is opinionated with-out an intention to persuade or establish credibili ty. statistical &amp; rule-based approach to detecting prop -erties not explicitly stated, but evident from lan-guage use. Annotation at the message (turn) level provided training data useful for predicting rare phenomena at the discussion level while reducing the need for turn-level predictions to be accurate. Weighing subjective judgments overcame the need for high annotator consistency. For English, the system beats both baselines with respect to accura-cy and F, despite the fact that because the phenom-ena are rare, always predicting the absence of a language use is a high baseline. For Arabic, more work is required, particularly since only 10-20% of the amount of training data exists so far. purpose behind the words of a message. Future work will explore incorporating LU predictions to predict the social roles played by the participants in a thread, for example using persuasion and credi-bility to establish which participants in a discus-sion are serving as informal leaders. 
