 the second case the optimization domain is a continuous set. An important example of a continuous finding the minimum energy folding of the corresponding prot ein [1].
 However, this is often beyond computational capacity: the o ptimization domain of the traveling salesman problem with 100 cities contains more than 10 155 possible tours. An efficient algorithm to solve the traveling salesman and many similar problems ha s not yet been found and such prob-methods for finding good approximate solutions in hard discr ete optimization problems which defy random search based on the Metropolis-Hastings algorithm, such that the distribution of the ele-ments of the domain visited during the search converges to an equilibrium distribution concentrated around the global optimizers. Convergence and finite-time p erformance of simulated annealing on finite domains has been evaluated in many works, e.g. [7, 8, 9, 10].
 search and in general converge to local optimizers; with the notable exception of convex criteria where convergence to the unique global optimizer occurs [11 ]. Simulated annealing performs a global search and can be easily implemented on continuous do mains. Hence it can be considered a powerful complement to local methods. In this paper, we int roduce for the first time rigorous guarantees on the finite-time performance of simulated anne aling on continuous domains. We will of confidence, find an approximate solution to the problem of o ptimizing a function of continuous steps. Rigorous guarantees on the finite-time performance o f simulated annealing in the optimiza-ity, e.g. [12, 13, 14, 15].
 tribution, of the Metropolis-Hastings algorithm and Marko v Chain Monte Carlo (MCMC) methods, which has been one of the main achievements of recent researc h in statistics [18, 19, 20, 21]. troduce a general formulation of the simulated annealing me thod which allows one to derive new The Metropolis-Hastings algorithm and the general family o f MCMC methods have many degrees of freedom. The choice and comparison of specific algorithms goes beyond the scope of the paper. method and fix the notation. In Convergence we recall the reasons why finite-time guarantees for simulated annealing on continuous domains have not been obt ained before. In Finite-time guaran-tees we present the main result of the paper. In Conclusions we state our findings and conclude the paper. The original formulation of simulated annealing was inspir ed by the analogy between the stochastic by the evolution of the state of an inhomogeneous Markov chai n. The state of the chain evolves according to the Metropolis-Hastings algorithm in order to simulate the Boltzmann distribution of thermodynamic equilibrium. The Boltzmann distribution is simulated for a decreasing sequence of global minimizers [7].
 ing can be generalized straightforwardly to a continuous do main because the Metropolis-Hastings algorithm can be used with almost no differences on discrete and continuous domains The main densities. On a continuous domain, Markov transition kerne ls in which the distribution of the el-ements visited by the chain converges to an equilibrium dist ribution with the desired density can be constructed using the Metropolis-Hastings algorithm an d the general family of MCMC methods [22].
 different type of equilibrium distribution in place of Bolt zmann distributions. 1.1 Our setting that  X  is a bounded set.
 librium distribution, i.e.  X  ( J ) ( d X  )  X  [ U (  X  ) +  X  ] J  X  equilibrium densities are always strictly positive, even i f U takes zero values on some elements of the domain. The offset  X  is chosen by the user and we show later that our results allow o ne to inhomogeneous chain has equilibrium distribution  X  ( J k ) where { J ule X . The cooling schedule is a non-decreasing sequence of p ositive numbers according to which the equilibrium distribution become increasingly sharpen ed during the evolution of the chain. We use  X  P this dependence explicit in the notation.
 involving random variables, the value U (  X  ) may be the expected value U (  X  ) = R g ( x,  X  ) p of some function g which depends on both the optimization variable  X  , and on some random vari-able x which has probability density p too much computation, or because no analytical expression f or p must perform stochastic simulations in order to obtain samp les of x for a given  X  , hence obtain of aircraft routing [24]. In the particular case that p ministic and expected-value criteria. The MCMC method deve loped by M  X  uller [25, 26] allows one J is restricted to integer values. The rationale of simulated annealing is as follows: if the te mperature is kept constant, say J then the distribution of the state of the chain P the cooling schedule J to shows that, under conditions on the cooling schedule and the Markov transition kernels, the distri-bution of the state of the chain P  X   X  ) as k  X   X  [12, 13, 14, 15]. Convergence to the zero-temperature distr ibution implies that asymptotically the state of the chain eventually coincides with a global optimizer with probability one.
 nealing algorithms on a continuous domain is that usually, i n an optimization problem defined over according to the distributions P the set of global optimizers is of non-null measure with resp ect to the reference counting measure [7, 8, 9, 10].
 continuous domain and for a set of global optimizers of measu re zero, the target zero-temperature this situation, although the distribution of the state of th e chain P to of convergence to the target distribution cannot even be defi ned (weak convergence), see [12, The-orem 3.3]. This is the reason that until now there have been no guarantees on the performance of simulated annealing on a continuous domain after a finite num ber of computations: by adopting the convergence in infinite time to a global optimizer.
 port is the total variation norm k annealing on a continuous domain the distribution of the sta te of the chain P tinuous with respect to the Lebesgue measure (i.e.  X  measure also according to P  X  assumptions of continuity and differentiability of U [12, 13, 14, 15]. In general, optimization algorithms for problems defined on continuous variables can only find ap-proximate solutions in finite time [27]. Given an element  X  of a continuous domain how can we assess how good it is as an approximate solution to an optimiz ation problem? Here we introduce the concept of approximate global optimizer to answer this question. The definition is given for a maximization problem in a continuous but bounded domain. W e use two parameters: the value imprecision  X  (greater than or equal to 0) and the residual domain  X  (between 0 and 1) which to-gether determine the level of approximation. We say that  X  is an approximate global optimizer of U with value imprecision  X  and residual domain  X  if the function U takes values strictly greater than formal definition is as follows.
 Definition 1 Let U :  X   X  R be an optimization criterion where  X   X  R N is bounded. Let  X  denote the standard Lebesgue measure. Let  X   X  0 and  X   X  [0 , 1] be given numbers. Then  X  is an approximate global optimizer of U with value imprecision  X  and residual domain  X  if  X  U (  X   X  ) &gt; U (  X  ) +  X  } X   X   X  Leb (  X  ) .
 supremum of U .
 gardless of what the criterion U is: if  X  and  X  have non-zero values then the set of approximate global optimizers always has non-zero Lebesgue measure. It follows that the probability that the imate global optimizer.
 formal guarantees on the finite-time performance of optimiz ation methods based on a stochastic search of the domain is already apparent in the work of Vidyas agar [17, 28]. Vidyasagar [17, 28] pected value criteria based on uniform independent samplin g of the domain. Notably, the number of independent samples required to guarantee some desired a ccuracy and confidence turns out to be polynomial in the values of the desired imprecision, residu al domain and confidence. Although the which exist without the need for any particular assumption o n the optimization criterion.  X   X  any optimization criterion U on a bounded domain. The only minor requirement is that U takes values in [0 , 1] .
 Theorem 1 Let U :  X   X  [0 , 1] be an optimization criterion where  X   X  R N is bounded. Let J  X  1 and  X  &gt; 0 be given numbers. Let  X  be a multivariate random variable with distribution  X  domain  X   X  holds with probability at least  X  .
 Proof. See Appendix A.
 continuous with respect to the Lebesgue measure. Hence, the distance k P distribution of the state of the chain P is a well studied problem. The theory provides simple condit ions under which one derives upper bounds on the distance to the target distribution which are k nown at each step of the chain and decrease monotonically to zero as the number of steps of the c hain grows. The theory has been developed mainly for homogeneous chains [18, 19, 20, 21].
 Markov chain can in fact be formed by a finite sequence of homog eneous chains (i.e. the cooling schedule { J this allows one to apply the theory of homogeneous MCMC metho ds to study the convergence of P ulated annealing algorithm allows one to obtain upper bound s on k P metrically to zero as k  X  X  X  , without the need for any additional assumption on U [18, 19, 20, 21]. Theorem 2 Let the notation and assumptions of Theorem 1 hold. Let  X  the state of the inhomogeneous chain of a simulated annealin g algorithm with target distribution  X  residual domain  X   X  holds with probability at least  X   X  X  P The proof of the theorem follows directly from the definition of the total variation norm. number of steps is an approximate global optimizer with the d esired approximation level. For given J ; while the distance k P number of steps.
 approximation and confidence, is that it will decrease the nu mber of steps required to achieve the desired reduction of k P We have introduced a new formulation of simulated annealing which admits rigorous finite-time notion of approximate global optimizer. Then, we have shown that simulated annealing is guaranteed bounded domain with the only minor requirement that it takes values between 0 and 1. MCMC methods on continuous domains can be used [18, 19, 20, 21 ].
 shown that approximate optimizers with desired accuracy an d confidence can be obtained with a number of uniform independent samples of the domain which is polynomial in the accuracy and expected to be equally or more efficient than uniform indepen dent sampling.
 Acknowledgments Work supported by EPSRC, Grant EP/C014006/1, and by the Euro pean Commission under projects HYGEIA FP6-NEST-4995 and iFly FP6-TREN-037180. We thank S. Brooks, M. Vidyasagar and D. M. Wolpert for discussions and useful comments on the pape r.
 Let  X   X   X  (0 , 1] and  X   X  (0 , 1] be given numbers. Let U measure such that  X  the probability that  X  belongs to the set {  X   X   X  :  X  that the quantity  X  have  X  Moreover, and taking the contrapositive one obtains Therefore {  X   X   X  : U We now derive a lower bound on  X  ( J ) {  X   X   X  : U A  X   X  := {  X   X   X  : U  X  (  X  ) &lt; y  X   X  } and  X  B  X  y } [30, p.162]. Hence, the definition of y Hence,  X  Notice that  X  Since {  X   X   X  : U the proof is complete.
 U have which is proven by noticing that  X  [ U and U (  X  )  X  [0 , 1] . Hence {  X   X   X   X  :  X  U Therefore  X  Q  X ,  X   X  := {  X   X   X   X  : U (  X   X  ) &gt; U (  X  ) +  X   X  } We obtain Hence we can conclude that and the second part of the proof is complete.
 the statement  X   X  is an approximate global optimizer of U with value imprecision  X   X  and residual a bijective relation to  X   X  [ 1+  X  obtained by expressing  X  as a function of desired  X   X  =  X  and  X   X  =  X  .

