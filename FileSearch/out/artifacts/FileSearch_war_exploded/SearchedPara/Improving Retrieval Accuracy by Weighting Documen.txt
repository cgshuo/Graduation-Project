 For enterprise search, there exists a relationship between work task and document type that can be used to refine search results [3]. In this poster, we adapt the popular Okapi BM25 scoring function to weight term frequency based on the relevance of a document type to a work task. Also, we use click frequency for each task-type pair to estimate a re-alistic weight. Using the W3C collection from the TREC Enterprise track for evaluations, our approach leads to sig-nificant improvements on search precision.
 H.3.3 [ Information Storage and Retrieval ]: Search pro-cess Performance, Human Factors Enterprise Search, Clickthrough Data
Recently, Robertson et al. [4] introduced a modified ver-sion of Okapi BM25 to incorporate weights into different fields of a structured document. The intuition is to consider structured documents and rank them according to the im-portance of each structure. Although the modified Okapi BM25 was intended for weighting fields of a structured doc-ument, it can be used to weight another useful piece of in-formation of a document: document type . This poster also introduces an approach to use clickthrough data to estimate a realistic weight for each work task-document type pair.
Previous research [3] has shown that there exists a rela-tionship between work task and document type (or genre) in an enterprise search environment. A document genre is a class of documents, grouped together based on similar sub-ject, form, and content. For our purpose, we would consider document type . A document type defines the source of a document (i.e., WWW pages, emails, discussion threads, etc). If a user X  X  work task is known to a retrieval system, retrieval accuracy can be improved by returning documents from those relevant types and ranking them higher in the result list. Therefore, document type is an important factor to consider in the retrieval process.

Clickthrough data is a history about user-submitted queries and user-selected documents on the corresponding search result page. Although clickthrough data does not provide direct indication on document relevance, it provides useful hints for determining which document (or type of documents) is relevant to a user X  X  need. Many different approaches of utilizing clickthrough data to improve re-trieval performance have previously been proposed (e.g. [1]). In this poster, we take a simpler approach of utilizing clickthrough data in the retrieval process.

In our approach, clickthrough data are grouped together based on different task-type pairs. To determine the weight for each task-type pair, we consider the click frequency of the document type when the work task was given. For example, given a work task, if type A is clicked more frequently than type B, then type A X  X  weight would be larger than type B X  X . Depending on the document X  X  type and on the given work task, we apply the corresponding weight to the modified BM25 to compute the relevance score.
The extended version of Okapi BM25 outputs a relevance score for each document by computing a linear combina-tion of term frequencies and field weights. For query terms Q , Q 2 , ..., Q n , the weighted BM25 relevance score of a doc-ument D is
S where | D | is the length of D , and avgdl is the average docu-ment length. k 1 (= 1 . 2) and b (= 0 . 75) are free parameters. w
Q i is the inverse document frequency weight. f  X  D,Q i is the weighted term frequency of Q i . It is a combination of its unweighted frequency f D,Q i and the corresponding weight w . Suppose that there are N different fields to be weighted,
For our purpose, document type is the only field that would be weighted. If work task is known, a search sys-tem can use the corresponding set of weights for document types to calculate relevance scores.
 To determine a realistic estimate of the weight for each document type, we consider click frequency for each docu-ment type and work task. Each weight should have these properties:
Given a work task, assume cf T represents click frequency of a document type T . A rough model for estimating each weight can be formulated as where | T | is the number of types, | C | is the total number of clicks, and S (= 1 . 5) is a smoothing parameter.
First, if cf T is zero, then w T  X  1 (assume S is relatively small). Second, equation 3 is linear, thus, w T increases monotonically as click frequency increases. Finally, if a particular document type dominates the clicks, cf T would equal to | C | , which means w T would have a value close to | T | + 1. Hence, the weight increases to an asymtotic maxi-mum. Equation 3 satisfies all properties listed above.
Given the weight of each document type for a specific work task, the weighted term frequency is
For our experiments, we employ the W3C collection used in the TREC 2006 Enterprise track [2]. The W3C collection contains 331,037 documents with a total uncompressed size of 5.7 gigabytes. These documents are categorized into six different types: mailing lists, public CVS repository, publ ic Web pages, wiki pages, personal pages for the W3C team, and other pages.

The evaluation is limited by the nature of the TREC En-terprise track. Since the queries were used by the expert search task in TREC Enterprise track, they were created with the objective of finding an expert for a particular topic . Thus, there is only one work task X  expert search task X  corresponding to these queries. Our objective is to find relevant document type(s) for the expert search task and rank documents from this type higher to improve search precisions.

We utilized the clickthrough data that were used during the creation of the evaluation topics. The problem is that some clicked-on documents were also listed in the qrels file. It is inappropriate to train our models using these click-through data and then evaluate our models using the topics and the qrels file. Therefore, we removed them from our experiments and used only the ones where the clicked-on document is not identified in the qrels file.

Table 1 shows that BM25+CF increases search precision at 5 documents from 0.6286 to 0.7469, a 19% improvement. Our model is statistically significant over BM25 for precisi on at 5 and 10 documents.

Table 2 shows the number of documents retrieved in each document type for all query topics. The BM25 model mainly Table 2: Number of Documents Retrieved for Each Document Type. retrieved documents from public Web pages and mailing lists, along with a small amount of documents from the other 4 types. However, BM25+CF retrieved the major-ity of its documents from mailing lists. Therefore, for the expert search task, mailing lists is a more relevance docu-ment type and retrieval performance can be improved by placing more weights on its documents.
We have proposed a fundamental approach for weighting document types and estimating the appropriate weight for each document type using click frequency. Click frequency is an indication of users X  judgments on each type for the work task. Thus, it is a helpful source for estimating the weights. Our model incorporates these weights to determine a weighted term frequency, which is then used to compute relevance scores. In our experiments, the model improves P@5 by 19%, compared to a BM25 baseline. The improve-ment is statistically significant according to a paired t-te st (confidence level: 95%). [1] E. Agichtein, E. Brill, and S. Dumais. Improving web [2] N. Craswell, I. Soboroff, and A. de Vries. Overview of [3] L. Freund, E. Toms, and C. L. A. Clarke. Modeling [4] S. Robertson, H. Zaragoza, and M. Taylor. Simple
