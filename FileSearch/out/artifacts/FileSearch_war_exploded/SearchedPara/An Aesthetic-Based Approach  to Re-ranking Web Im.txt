 Previous works on Web image search focused mainly on retrieving relevant images to users X  queries. Most of them used textual information associated with the images such as filenames, anchor texts, tags and surrounding texts. A few exploited image content to filter out noisy images in search results. [7] presented a reliable measure of image similarity to re-rank image search results returned from Google Image. Despite the continuous improvement of relevance in image search, users are still not fully satis-fied with the top-ranked Web images in terms of image quality 1 . For example, Fig. 1 shows the top-3 image results returned from Google Image 2 with respect to the query good exposure but does not set the tone well. Although the three images are all rele-vant to the query topic, they are not good enough in image quality. 
To recommend users images with both high relevancy and quality, a popular solu-tion adopted by current search engines is to provide some simple filters, which utilize information such as image resolutions or sizes, types of image content (e.g., news, faces, photos, clip arts, line drawings, etc) , image colors (e.g., full color or black and white) and types of image-file formats (e.g., jpeg and png). Such options indeed pre-vent users from reaching certain types of low-quality images. Unfortunately, many low-quality Web images will still be returned like those in Fig. 1 due to the simplicity of the options provided. 
Searching relevant images with high quality is not only helpful for users in satis-re-rank the images returned from search engines based on their visual quality. We use textual information associated with a Web image because it often gives no de-paper, we propose an approach to re-rank the images, which learns a regression mod-el. A set of novel image features are presented. Together with conventional ones, our features could significantly improve the ranking accuracy in five real data sets; in-cludes images from Google Image, Flickr 3 , INRIA Holiday datasets 4 , Photo.net 5 , and DPChallenge 6 . The experimental results show the feasibility of the proposed approach in searching aesthetically-pleasing Web-image search results for users. 
The contributions of this work are as follows. We not only adopt conventional im-age features such as color and texture in our approach, but also introduce a set of new features, which have been shown their effectiveness in extensive experiments. More-over, we apply our approach to re-ranking Web images according to their quality. Different from previous work on image-quality classification or assessment that con-ducted experiments in a small scale, we evaluated our approach on Web images, whose topics are more diverse and whose content is more dynamic. The experimental results show that our approach is robust across different image categories. There existed many studies that used image content to improve the performance of image search results returned from Google Image. Although image content has shown its usability in improving Web image search, most of previous work only concerned the relevance issue, instead of the quality issue. 
Regarding image quality, most of previous work paid attention to image-quality classification, which identifies whether an image has good or bad quality [8,10,11,15]. [8] aimed at distinguishing high quality professional photos from low quality snapshots. [10] extracted the subject region from a photo, and then formulated various high-level semantic features based on this subject and background division. [11] proposed a fusion method integrating query relevance and image aesthetics at the same time. [15] developed several discriminative features to classify images accord-ing to whether they are taken by experienced photographers. Although the problem of image quality classification can be applied to image quality ranking, previous work focused mainly on image low-level features and evaluated in a specific dataset. Our work also presents new features, which are extracted based on closest training exam-ples given by experts and have been proven their effectiveness in determining image quality in extensive experiments. Moreover, we attempt to re-rank images on the Web with diverse topics and dynamic content. We not only manually generate quality data. The experimental results show the feasibility of the proposed approach under various datasets. 
There are some works tending to make images look better by image processing techniques. [3] presented a useful method that enhances the harmony among the col-colors. [12] presented an algorithm for removing motion blur from a single image. These works all tried to enhance the quality of images. Some features measuring im-age quality are related to our work. However, in this paper, our goal is not to enhance the quality of given images. We want to improve the ranking list of Web images ac-cording to their aesthetic quality. 3.1 Image Re-ranking Based on Quality Given a ranking list  X  X  X  X  X   X   X ,  X   X ,  X   X ,...,  X   X  with top-k image search results returned from an image search engine, the goal of this paper is to learn a regression function  X  X  X : X  , mapping each image in L to a real value. The regressed value stands for the quality an image I i has. With the permutation  X  given by the function r , the original ranking list L varies between -2 and 2; -2 means the worst quality while 2 means the best quality.  X  X   X  coming from image search engines and some photography community sites are la-to regression model r to predict the quality of each image  X  X  X   X   X  , which will be used to re-rank L as L X  . As some images in L X  are probably very similar, to maximize the diversity of L X  , we remove duplicated images. Specifically, if the similarity between two images topmost images in L X  are shown to users. In this paper, we apply support vector regres-sion (SVR) to learn r ; other alternatives can also be adopted for calculation. 3.2 Image Features objective . The factors of this set are about basic photographic techniques such as fo-cus (Q1) and exposure (Q2). For example, photographers should take care of shutter speed, aperture and lighting to make an appropriate exposure. Inappropriate exposure will lower the contrast of images and looks awful. Tripod is needed during long expo-sure shots; otherwise, the images would have high blurriness caused by handshake. and taste are quite different from one to another, four major common rules that have been accepted by experienced photographers are adopted here, including simplicity (Q3), realism (Q4), color harmonization (Q5), and composition (Q6). For simplicity, professional photographers usually make their photos simple, so that the objects from images are obviously presented to people. A high quality image should make its sub-wide range of techniques to make their photos  X  X urreal X  like adjusting camera settings, taking shots from a different view angle, and choosing specific times of the day, e.g. morning or dusk. However, non-photographers usually let their photos  X  X eal X . That is, they take photos as they see. Figure 3(b) gives an example of realism. We propose four types of image features: basic photography (measuring Q1 and Q2), color distribution (measuring Q2~Q5), composition (measuring Q3 and Q6), and retrieval features (measuring Q1~Q6). Some of them have been used in the literature; The features of  X  X etrieval X ,  X  X tandard deviation of hue X  and  X  X orizontal balance X  fea-tures are novel. 3.2.1 Basic Photography Features The features are designed to detect if a photo is taken with accurate focus and appro-priate exposure. Blurriness : If an image is out-of-focus, it becomes more blur. We employ the blurri-ness features proposed in [14]. First, the image I i is converted from spatial domain to frequency domain by Fast Fourier Transform (FFT). Then we have: obtain blurriness value, in which lower means more blur. Contrast : This is a measurement of appropriate exposure, i.e., whether an image is taken with wrong shutter time or diaphragm. The photometric exposure is given by: be too low. There are many ways to define an image X  X  contrast. We obtain an image X  X  contrast by computing the entropy of its histogram under grey scale with the follow-ing formula: Noise : We observe some images contain noises, which is caused by CCD (Charge-Coupled Device) in digital cameras with high ISO configuration and low environment simple noise detector to detect noises from camera CCD or jpeg artifacts. Bilateral filtering [13] is well-known for its ability of removing noises. We, therefore, compare the images before and after performing bilateral filtering (BF) to get the noise area in an image. 5x5 bilateral filter and set threshold  X  to 1. 3.2.2 Color Distribution Features This set of features is designed to detect how well the color distribution or toning an image is. Color Harmonization : Color harmonization is used to measure the quality of color which is calculated by:  X  harmonic templates and  X  is the orientation for m . Based on this feature, we can detect how harmonious an image is. Hue, Saturation and Value (HSV) : For each pixel of an image, we can convert it ( v ) for each pixel j in image I i , we compute their average for I i : v ( p j ), respectively. HSV is related to the exposure. If a photo taker controls the expo-sure well, the hue of sky will be close to blue instead of white or gray. Under or over exposure makes the saturation of an image become lower. And exposure also effects value. Hue and saturation are all about the realism issue for image quality. Figure 3(c) gives some examples. Color Size : The feature is to calculate how many different colors (in RGB color space) appearing in an image and to measur e the image X  X  simplicity. Only the colors with frequency more than  X  are counted (  X  =3 in our experiment). If an image is full of noise, then its color size grows significantly. Sometimes users cannot easily find main objects if an image has too many different colors. Standard Deviation of Hue : The feature detecting the changing of colors is to meas-ure the simplicity of an image, and can be computed by: Hue Count : This feature captures the simplicity of an image. We cluster hues of an image to 18 bins and count the number of different bins: Figure 3(d) shows the effect of color size, standard deviation of hue, and hue count on image quality. Largest Area : Images with a large area having the same color (hue) have more prob-ability to achieve high quality. This is because the subject of such image is quite clear. This is also why photographers sometimes convert their photos into mono color space to avoid noises caused by colors. Figure 3(e) gives an example. We calculate largest area by: 3.2.3 Composition The features are used to detect whether objects within an image have appropriate sizes and locations. Region of Interest (ROI) : The size of the main object for an image should not be too large or too small. The size of ROIs can help us detect it. We adopt the attention mod-el developed by Itti et al. [6] to find the areas with higher visual attention, where we combine two Gaussian functions whose centers are at 1/3 and 2/3, respectively, to simulate the influence of the rule of thirds in photograph composition. An object should avoid to appear at center or the border. The best position is 1/3. Horizontal Balance : We can take the absolute arctangent between the longest line in an image and the horizon to see if an image is horizontal balanced. Horizontal balance is important for high-qu ality images since not-balanced horizon lines usually make viewers feel uncomfortable. Figure 3(f) gives an example. Edge Distributions : [8] computed the spatial distribution of the high frequency edges of an image to capture its simplicity. We implement this feature by Canny X  X  approach to edge detection [1] and count the 2D stand deviation of edges in an image: 3.2.4 Image Retrieval Features image retrieval (CBIR) technique to extract so-called retrieval features. Our idea is quite simple: an image visually-similar to high-quality images has more chance to be a high-when each adopted feature is varied. Such r is very sensitive to the details of the distri-bution for each feature. In practice, it is very difficult to fetch perfect distribution for the features are quite robust and reasonably effective for training and prediction. The retrieval features can be calculated as: quality) and X is the way to compute the image similarity. Because we can apply any similarity measure to the retrieval features, four different measurements, including conventional color-texture, basic photography, composition and tone (i.e., color dis-color-texture-based retrieval feature makes use of HSV color histograms and Gabor filters with various orientations and scales as its feature space. The basic-based, com-position-based, and tone-based retrieval features adopt the features described in Sec-tion 3.2.1, 3.2.2, and 3.2.3, respectively, as their feature spaces for similarity compu-tation. In our experiment, we use top 10 ranked images, i.e., 10-nearest neighbors, to predict image quality. 4.1 Datasets There is no existing benchmark for this work, so we collect 5 image datasets from some photo community web sites and image search engines. For each dataset, 70% of the images are used for training, and the remaining 30% are for testing. The 5 datasets Photo.net is a web community for photographers. Photographers can upload their own photos and give ratings (scaled from 1 to 7) to others X  photos. There are two types of ratings for each image: aesthetics and originality. We take their aesthetic ratings and randomly choose photos with &gt; 20 ratings and their standard deviation is less than 1.0. The original idea behind DPChallenge is to teach users to be better photographers by giving each other different 'challenges'. For example, one challenge is about  X  X hurch X , which asks people to photograph a church from any religion and show its beauty, grandeur or simplicity. Similar to photo.net, photographers in DPChallenge can upl-oad their photos and rate others X  photos with a rating scale from 1 to 10. DPChallenge doesn X  X  limit the types of ratings. Sometimes users may not rate photos from the aes-thetic viewpoint. To relieve this problem, we only take 750 top-ranked images and 750 bottom-ranked images from the total 3682 images as our data. The INRIA Holi-days dataset is designed for the evaluation of image search. The dataset contains a set of personal photos taken on holidays. There are also some other images taken on pur-changes, blurring, etc. Hence, the dataset covers different image quality. In our expe-riment, 3 experienced photographers are asked to rate these photos with the rating scale from -2 to 2. For Web images, we collect them from Google Image and Flickr by 30 manually-constructed queries like a pple, building, cat, Tokyo Tower, and sum-mer. For each query, top 100 images returned from each are collected. Dead links are discarded. Type filters provided by Google Image are applied to prevent from some noise like clip art images. 4.2 Evaluation Metrics There evaluation metrics are adopted in this paper, including NDCG, Kendall X  X  tau, and ERR. We slightly modify it to measure the performance of image ranking based same and -1 if one is the reverse of the other. Here we compare our rankings to ideal rankings by Kendall X  X  tau. ERR (Expected Reciprocal Rank) [2] is defined as the ex-high quality image for our purpose).  X   X  X  X   X   X   X   X   X   X   X  X  X  X  X  X  X  X   X  X   X  X  X  X  X   X  X  X  X   X   X   X  X  X  X  . 4.3 Ranking Performance In this experiment, we rank all of the images for each dataset. Since the quality score for each image in the datasets has been labeled by either the website or our expe-rienced photographers (the scores are varied from -2 to 2 for INRIA Holidays, Google Image and Flickr datasets, 1 to 7 for Photo.net, and 1 to 10 for DPChallenge), we can use NDCG, Kendall X  X  tau, and ERR to examine the performance of our ranking re-sults. Table 2 shows the experimental results, where the Web datasets are those col-Basic (Section 3.2.1), color (Section 3.2.2), composition (Section 3.2.3), image re-basic+color+composition+retrieval (all) represent the proposed approach based on individual features, the combination of conventional image features (ba-sic+color+composition, which is adopted by previous work) and all of the features (including the proposed new features). The composition features cannot deal with complicated images well (e.g., photos with complicated backgrounds) because it is difficult for us to correctly detect ROIs. Such errors will propagate in the following processes of image-quality prediction and final ranking. That X  X  the reason why the composition features have bad performance in the Web, Photo.net and DPChallenge datasets. Most of the features are, therefore, effec-mance can be further improved especially for the ERR in Web dataset. This implies that the image retrieval features are useful for promoting high-quality images to satis-fy users. The concept of the retrieval features is close to that of the k -nearest neighbor tends to have good quality. From Kendall X  X  tau, we can see our rankings are slightly correlated with the ideal ranking, but achieve higher NDCG. It means even our ap-proach can X  X  produce perfect rankings but still rank high-quality images in the top. 4.4 Feature Analysis This section analyzes the effectiveness of different features on image-quality predic-tion. We use F-score [4], which is a simple metric measuring the discrimination of two sets of real numbers. Given a set of training vectors  X   X   X ,..., X 1 X , , if the num-ber of positive and negative instances are  X   X  and  X   X  , respectively, then the F-score of the i  X  X  feature is defined as: is the i  X  X  feature of the k  X  X  negative instance. The larger the F-score is, the more likely this feature is more discriminative. The F-score of each individual feature for different datasets is listed in Fig. 4 (a). To examine if different features have di fferent impacts on image-quality prediction for different types of images, we manually classify our image datasets into five cate-gories, including landscape, building, night, object and indoor. positive and negative. For the Web and INRIA dataset, we can use the sign of the aver-age ratings to separate them. But for the others, it is not easy to pick a threshold as these ratings are all positive numbers (photo.net: 1~7, DPChallenge: 1~10). We cut these data by the average of average ratings but it still seems not a very good choice. That is also  X  X  X  X   X  X  X  X  X  X  X  . Also some of the basic and tone features have relative high F-score like blur, contrast, and saturation. The composition features seem not so discriminative. The poss-tions in computation and insufficient training data. Finding nearest neighbors often has high time complexity. The retrieval features require sufficient training data. types. The result is reasonable since the possibility of noise appearance is independent Consider different image types. We find the most discriminative features for the land-scape images are horizontal balance, edge distribution, saturation and contrast. For the area. For the night images, the most effective features are size of ROI, horizontal bal-ance, color harmonization, hue, std. of hue, and blur. For the object images, they are color size, saturation and contrast. For the indoor images, they are size of ROI, edge distributions, value, color size and contrast. Blurriness is especially good for the night images because lots of these images are taken under long exposure and would cause motion blur when no tripod is used. 4.5 Comparison to Web-Image Search Engines To compare the re-ranked results and the original ranking lists given by Google Image and Flickr, we test our method on each query of the 30 queries that we manually con-struct (as mentioned in Section 4.1). In the experiment, we use Google Image and Flickr as our base search engines, and re-rank top 100 images returned from Google Image and Flickr. Table 3 shows that after re-ranking, high-quality images are ranked higher. Only top 100 images retrieved from Google Image and Flickr are re-ranked, and in most case these images are all relevant to queries. Figure 5 gives an example of using  X  X uilding X  as a query to re-rank the images returned from Google Image and Flickr in June, 2010, where high-quality images are re-ranked higher. We have proposed an approach to re-ranking images based on quality with supervised learning and its feasibility in Web-image s earch. Our approach can also be adapted to other applications, including photo album management systems, personalized photo recommendations, etc. For future work, it is possible to include more image features in the ranking algorithm as to improve upon the results and to integrate our approach to the video domain. 
