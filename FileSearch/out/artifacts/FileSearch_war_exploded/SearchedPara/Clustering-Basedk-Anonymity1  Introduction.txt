 Privacy leakage is one of major concerns when publishing data for statistical process or data analysis. In general, organizations need to release data that may contain sensitive information for the purposes of facilitating useful data analysis or research. For example, patients X  medical records may be released by a hospital to aid the medical study. Records in Table 1 (called the microdata) is an example of patients X  records published by hospitals. Note that attribute Disease contains sensitive information of patients. Hence, data publishers must ensure that no adversaries can accurately infer the disease of any patient. One straightforward approach to achieve this goal is excluding unique identifier attributes, such as Name from the table, which however is not sufficient for protecting privacy leakage under linking-attack [1, 2]. For example, the combination of Age and Zipcode can be potentially used to identify an individual in Table 1, and has been called a quasi-identifier (QI for shor t)[1] in literatures. I f an adversary has the background knowledge about Bob, that is: Age=20 and Zipcode=30, then by joining the background knowledge to Table 1, he can accurately infer Bob X  X  disease, that is bronchitis.

To protect privacy against re-identifyin g individuals by joining multiple public data sources, k -anonymity ( k  X  2) was proposed, which requires that each record in a table is indistinguishable from at least k  X  1 other records with respect to certain quasi-identifiers. Generally, to achieve k -anonymity, generalization [1 X 3] is a popular methodology of privacy preservation for preventing linking attacks. Enough degree of generalization will hide a record in a crowd with at least k records with the same QI-values, thereby achieving k -anonymity. Table 2 demon-strates a generalized version of Table 1 (e.g., the Zip 30 of Bob, for instance, has been generalized to an interval [25, 30]). The generalization results in 3 equiva-lence classes, as indicated by their group-IDs. Each equivalence class is referred to as a QI-group. As a result, given Table 2, even if an adversary has the exact QI-values of Bob, s/he still can not exactly figure out the tuple of Bob from the first QI-group. 1.1 Motivation Although generalization-based algorithms have successfully achieved the privacy protection objective, as another k ey issue in data anonymization utility still needs to be carefully addr essed. Great efforts have been dedicated to develop-ing algorithms that improve utility of anonymized data while ensuring enough privacy-preservation. One of the direct measures of the utility of the generalized data is information loss. In order to make the anonymized data as useful as possible for certain applications, it is required to reduce the information loss as much as possible. In general, the less total information loss leads to better utility, which reflects its usefulness as one of the steps in exploratory data analysis.
Clustering [4] is a method commonly used to automatically partition a data set into many groups. As an example of clustering is depicted in Figure 1-3. The input points are shown in Figure 1, and the steps to the desired clusters are shown in Figure 2 and Figure 3. Here, points belonging to the same cluster are given the same color.

Then, we may wonder: Can we significantly improve the utility while pre-serving k -anonymity by clustering-based approaches ? The answer depends on whether it is possible to partition microdata into clusters with less information loss while still ensuring k -anonymity. Intuitively, data points within a cluster are more similar to each other than they are to a point belonging to a different cluster.

The above observation motivates us to devise a new solution to improve the data utility of clustering-based solutions. As an example, we illustrate the details to generalize Table 1 by our approach. Let gen be a generalization function that takes as input a set of tuples and returns a generalized domain. Firstly, Table 1 is divided into 2 clusters, denoted by red and blue in Figure 2, respectively. Then, the cluster denoted by blue is furt her divided into 2 cluster, denoted by black and green color in Figure 3. Finally, tuples with same color are general-ized as a QI-group, that is, tuple Andy and Bob consists of the first QI-group, and assign gen( { Andy, Bob } )= [20  X  20] , [25  X  30] to the first QI-group. Sim-ilarly, { Jane,Alex } , { Mary, Lily, Lucy } make the second and third QI-group. Eventually, table 2 is the final result by our approach.

In this paper, we mainly focused on the basic k -anonymity model due to the following reasons: (i) k -anonymity is a fundamental model for privacy protection, which has received wide attent ion in the literatures; (ii) k -anonymity has been employed in many real applications such as location-based services [5, 6], where there are no additional (sensitive) attributes; (iii) There is no algorithm that is suitable for so many privacy metrics such as l -diversity[7], t -Closeness [8], but algorithms for k -anonymity are simple yet effective, and can be further adopted for other privacy metrics. Apart from the k -anonymity model, we also consider the scenarios with stronger a dversaries, extending our approach to l -diversity(Section 4)
The rest of the paper is organized as follows. In Section 2, we give the defini-tions of basic concept and the problem w ill be addressed in this paper. In Section 3, we present the details of our generalization algorithm. Section 4 discusses the extension of our methodology for l -diversity. We review the previously related research in Section 5. In Section 6, we experimentally evaluate the efficiency and effectiveness of our techniques. Fina lly, the paper is concluded in Section 7. Let T be a microdata table that contains the private information of a set of individuals and has d QI-attributes A 1 , ..., A d , and a sensitive attribute A s .We consider that A s is numerical, and every QI-attribute A i (1  X  i  X  d )canbe either numerical or categorical. All attributes have finite and positive domains. For each tuple t  X  T,t.A i (1  X  i  X  d ) denotes its value on A i ,and t.A s represents its SA value. 2.1 Basic Concept A quasi-identifier QI = { A 1 ,A 2 ,  X  X  X  ,A d } X  X  A 1 ,A 2 ,  X  X  X  ,A n } is a minimal set of attributes, which can be joined with external information in order to reveal the personal identity of individual records.

A partition P consists of several subsets G i (1  X  i  X  m )of T , such that each tuple in T belongs to exactly one subset and T = G i as a QI-group. 2.2 K -means Clustering K -means clustering [4] is a method commonly used to automatically partition adatasetinto K groups. It proceeds by selecting K initial cluster centers and then iteratively refining them as follows: Step 1. Each tuple t i is assigned to its closest cluster center.

Step 2. Each cluster center C j is updated to be the mean of its constituent The algorithm converges when there is no further change in assignment of tu-ples to clusters. In this work, we initialize the clusters using instances picked at random from the data set. The data sets w e used are composed solely of either numeric features or categorical features. For both numeric and categorical fea-tures, we adopt the normalized certainty penalty(see the definition 1) to measure the distance.

The final issue is how to choose K . To keep the algorithm simple in this paper, we consider binary partitioning, that is, K is fixed as 2. 2.3 Problem Definition Some methods have been developed to measure the information loss in anonymiza-tion. In this paper, we adopt the norma lized certainty penalty to measure the information loss.
 Definition 1 (Normalized Certainty Penalty [9]). Suppose a table T is anonymized to T  X  . In the domain of each attribute in T , suppose there exists a global order on all possible values in the domain. If a tuple t in T  X  has range [ x ,y i ] on attribute A i (1  X  i  X  d ) , then the normalized certainty penalty in t on A i is NCP A i ( t )= tuple t , the normalized certainty penalty in t is NCP ( t )= d i w i  X  NCP A i ( t ) , where w i is the weight of attribute A i . The normalized certainty penalty in T is Now, we are ready to give the formal definition about the problem that will be addressed in this paper. Information loss is an unfortunate consequence of data anonymization. We aim to generate a utility-friendly version anonymizaiton for a microdata such that the privacy can be guaranteed by k -anonymity and the information loss quantified by NCP is minimized. Now, we are ready to give the formal definition about the problem that will be addressed in this paper. (Limited by space, all proofs are omitted.) Definition 2 (Problem Definition). Given a table T and an integer k , anonymize it by clustering to be T  X  such that T  X  is k -anonymity and the to-tal information loss is minimized measured by NCP .
 Theorem 1. (Complexity) The problem of optimal clustering-based anonymiza-tion is NP-hard under the metric NCP . In this section, we will present the details of our clustering-based anonymization approach. The key of our algorithm is to divide all tuples into more compact clusters efficiently and correctly. We n ow proceed to a discussion of our modifi-cations to the K -means algorithm.

To keep the algorithm simple, we consider binary clustering. That is, in each round, we partition a set of tuples into two subsets by clustering. In order to reduce the total information loss, we will cluster the microdata following the idea: distribute tuples sharing the same or quite similar QI-attributes into the same cluster . We adopt the NCP to measure the distance. The detailed partitioning procedure is presented in Figure 4. Initially, S contains T itself (line 1); then, each G  X  S is divided into two generalizable subsets G 1 and G 2 such that G
The size of the two subsets should  X  k , otherwise adjustment is needed (line 8). Without loss of generality, assume that G 1 &lt;k , we need to borrow k  X  X  G 1 | tuples from G 2 to make sure that G 1 has a cardinality  X  k .

The tries to converges will cost unaccepta ble time, to acceler ate the partition-ing, the attempts to cluster G are tried r times and tuples of G are randomly shuffled for each time (line 4). Our exp erimental results show that most of G can be partitioned into two sub-tables by up to k = 15 tries. The algorithm stops when no sub-tables in S can be further partitioned.

By the Lemma in the paper [9, 10] that the optimal k -anonymity partitioning of microdata does not contain groups of more than 2 k  X  1 records, we have that the partitioning algorithm will terminate when the size of all groups is between k and 2 k  X  1. If at least one group contains a cardinality more than 2 k  X  1, the partitioning algorithm will continue.
 In the above procedure, the way that we partition G into two subsets G 1 and G 2 is influential on the information loss of the resulting solution. In the first round, we randomly choose two tuples t 1 ,t 2 as the center points C 1 ,C 2 ,and then insert them G 1 and G 2 separately. Then, we distribute each tuple w  X  G : for each tuple w , we compute  X  1 = NCP ( C 1  X  w )and  X  2 = NCP ( G 2  X  w ), and add tuple w to the group that leads to lower penalty (line 7). If  X  1 =  X  2 , assign the tuple to the group who has lower cardinality. After successfully partitioning G , remove the tuples t 1 and t 2 from G 1  X  X  t 1 } and G 2  X  X  t 2 } . At the later each round, the center points C i are conducted as follows: C i = t  X  G i t | G is, for each attribute A j (1  X  j  X  d ), C i .A j = t  X  G i t.A j | G
After the each partition, if the current partition is better than previous tries, record the partition result G 1 ,G 2 and the total sum of NCP ( G 1 )and NCP ( G 2 ). That is, we pick the one that that minimizes the sum of NCP ( G 1 )and NCP ( G 2 ) as the final partition among the r partitions(line 9). Each round of G can be accomplished in O( r  X  ( | G | X  (6 +  X  ))) expected time, where  X  is the cost of evaluating loss. The computation cost is theoretically bounded in Theorem 2. Theorem 2. For microdata T , the clustering-based algorithm can be accom-|
T | is the cardinality of microdata T .
 In this section, we discuss how we can apply clustering-based anonymization for other privacy principles. In particular, we focus on l -diversity, described in Definition 3.
 Definition 3 ( l -diversity[7]). A generalized table T  X  is l -diversity if each QI-group QI i  X  T  X  satisfies the following condition: let v be the most frequent A s value in QI i ,and c i ( v ) be the number of tuples t  X  QI i ,then c i ( v ) | QI To generalize a table through clustering-based anonymization, we partition a table into sub-tables T i which satisfy l -diversity: after each round of the above partitioning, if both ( G 1 and G 2 )) satisfy l -diversity, we remove G from S ,and add G 1 ,G 2 to S ;otherwise G is retained in S . Then for each subset T i  X  S , we conduct the splitting algorithm (see Figure 5) to produce the final l -diverse partitions.

The principle l -diversity demands that: the number of the most frequent A s value in each QI-group QI i can X  X  exceed | QI i | l . Motivated by this, we arrange the tuples to a list ordered by its A s values, then distribute the tuples in L into QI i (1  X  i  X  g ) a round-robin fashion. The resulting splitting is guaranteed to be l -diversity, which is stated in Theorem 3. (If table T with sensitive attribute A s satisfies max l -diversity.) Theorem 3. If table T with sensitive attribute A s satisfies max { c ( v ): v  X  partition produced by our splitting algorithm fulfills l -diversity. In this section, previous related work will be surveyed. Existing generalization algorithms can be further divided into heuristic-based and theoretical-based ap-proaches. Generally, appropriate heuristics are general so that they can be used in many anonymization models. To reduce information loss, efficient greedy so-lutions following certain heuristics have been proposed [9 X 13] to obtain a near optimal solution. Generally, these heuristics are general enough to be used in many anonymization models. Incognito [14] provides a practical framework for implementing full-domain generalization, borrowing ideas from frequent item set mining, while [10] presents a framework mapping the multi-dimensional quasi-identifiers to 1-Dimensional(1-D) space. For 1-D quasi-identifiers, an algorithm of O ( K  X  N ) time complexity for optimal solution is also developed. It is discovered that k -anonymizing a data set is strikingly similar to building a spatial index over the data set, so that classical spatial indexing techniques can be used for anonymization [15]. To achieve k -anonymity, Mondrian [16] takes a partitioning approach reminiscent of KD-trees.

The idea of non-homogeneous generalization was first introduced in [17], which studies techniques with a guarantee that an adversary cannot associate a gener-alized tuple to less than K individuals, but suffering additional types of attack. Authors of paper [13] proposed a randomization method that prevents such type of attack and showed that k -anonymity is not compromised by it, but its par-titioning algorithm is only a special of the top-down algorithm presented in [9]. The model of the paper [13, 17], the size of QI-groups is fixed as 1.
The algorithms mentioned above work well on practical data sets, but do not have attractive asymptotical performance in the worst case. This motivates studies on the theoretical aspects of k -anonymity [16, 18]. Most of these works show that the problem of optimal k -anonymity is NP-hard even a simple quality metric is employed.
 In this section, we will experimentally evaluate the effectiveness and efficiency of the proposed techniques. Specifically, we will show that by our technique (presented in Section 3) have significantly improved the utility of the anonymized data with quite small computation cost.
 Towards this purpose, two widely-used real databases sets: SAL and IN-COME(downloadable from http://ipums.org) with 500k and 600k tuples, respec-tively, will be used in following experiments. Each tuple describes the personal information of an American. The two data sets are summarized in Table 3.
In the following experiments, we compare our cluster-based anonymity algo-rithm (denoted by CB) with the existing state-of-the-art technique: the non-homogeneous generalization [13](NH for short). (The fast algorithm [10] was cited and compared with NH in the paper [13], therefore, we omit the details of the fast algorithm.)
In order to explore the influence of dimensionality, we create two sets of micro-data tables from SAL and INCOME. The first set has 4 tables, denoted as SAL-3,  X  X  X  , SAL-6, respectively. Each SAL-d (3  X  d  X  6) has the first d attributes in Table 3 as its QI-attributes and Occupation as its sensitive attribute(SA). For example, SAL-4 is 5-Dimensional, and contains QI-attributes: Age, Gender, and Education, Marital. The second set also has 4 tables INC-3,  X  X  X  ,INC-6,where each INC-d (3  X  d  X  6) has the first d attributes as QI-attributes and income as the SA.

In the experiments, we investigate the influence of the following parameters on information loss of our approach: (i) value of k in k -anonymity; (ii)number of attributes d in the QI-attributes; (iii)number of tuples n . Table 4 summarizes the parameters of our experiments, a s well as their values examined. Default values are in bold font . Data sets with different cardinalities n are also generated by randomly sampling n tuples from the full SAL-d or INC-d (3  X  d  X  6). All experiments are conducted on a PC with 1.9 GHz AMD Dual Core CPU and 1 gigabytes memory. All the algorithms are implemented with VC++ 2008.

We measure the information loss of the generalized tables using GCP, which is first used in [10]. Note that GCP essentially is equivalent to NCP with only a difference of constant number d  X  N . Specifically, under the same partition P of table T , GCP ( T )= NCP ( T ) d  X  N ( d is the size of QI-attributes), when all the weights are set to 1.0. 6.1 Privacy Level K In order to study the influence of k on data utility, we observe the evolution of GCP that has been widely used to measure the information loss of the general-ized tables by varying k from 50 to 250 with the increment of 50. In all following experiments, without explicit statements, default values in Table 4 will be used for all other parameters. The results on SAL-d and INC-d (3  X  d  X  6) data are shown in Figure 6 (a)-6(h). From the results, we can clearly see that information loss of CB sustains a big improvement over NH, for the tested data except the on SAL-3. Another advantage of our model over NH is that the utility achieved by our model is less sensitive to domain size than NH. From the figures, we can see that data sets generated by NH has a lower GCP on SAL-d than that on INC-d (4  X  d  X  7) due to the fact that domain size of SAL is smaller than that of INC. Such a fact implies that the information loss of NH is positively correlated to the domain size. However, in our model, domain size of different data set has less influence on the information loss of the anonymized data.
 Results of this experiment also suggest that for almost all tested data sets the GCP of these algorithms grows linearly with k . This can be reasonably explained since larger k will lead to more generalized QI-groups, which inevitably will sacrifice data utility. NH performs well when the dimensionality of QI-Attributes is low and the domain size is small, see the experiment results in the paper[13]. 6.2 QI-Attributes Dimensionality d Experiments of this subsection is designed to show the relation between the information loss of these algorithms and data dimensions d . In general, the in-formation loss will increase with d , since data sparsity or more specifically the data space characterized by a set of attributes expone ntially increases with the number of attributes in the set, i,e, dimensions of the table. Figure 7(a) and 7(b) compare the information loss of the anonymization generated by the these four methods with respect to different values of d on SAL-d and INC-d , respectively. It is clear that the anonymization gener ated by the cluster-based method has a lower global certainty penalty compared to that of NH. The advantage of CB is obvious, and such an advantage of CB can be consistently achieved when d lies between 4 to 6. 6.3 Cardinality of Data Set n In this subsection, we investigate the influence of the the table size n on infor-mation loss. The results of experiments on two data sets SAL-7 and INC-7 are shown in Figure 8(a) and 8(b), respect ively. We can see that the information loss of these methods on both two data sets decreases with the growth of n .This observation can be attributed to the fact that when the table size increases more tuples will share the same or quite similar QI-attributes. As a result, it is easier for the partitioning strategies to find very similar tuples to generalize. Similar to previously experimental results, ou r method is the clear winner since infor-mation loss of CB is significantly small than that of NH, which is consistently observed for various database size. 6.4 Efficiency Finally, we evaluate the overhead of performing anonymization. Figure 9(a) and 9(b) show the computation cost of the these anonymization methods on two data sets, respectively. We compare CB with NH when evaluating computational cost. The running time of tow algorithms increases linearly when n grows from 100k to 500k, which is expected since more tuples that need to be anonymized will cost longer time to finish the anonymization procedure. The NH method is more efficient. Comparison results show that the advantages of our method in anonymization quality do not come for free. However, in the worst case, our algorithm can be finished in 500 seconds, w hich is acceptable. In most real appli-cations quality is more important than running time, which justifies the strategy to sacrifice certain degree of time performance to achieve higher data utility. Summary. Above results clearly show that clustering-based anonymization achieves less information loss than the non-homogeneous anonymization (NH) in cases where the dimensionality of QI-attribute d&gt; 3 . NH has a good perfor-mance when the domain size is small, and the dimensionality of QI-Attributes is low. This is due to its greedy partitioning algorithm. As privacy becomes a more and more serious concern in applications involving microdata, good anonymization is of significance. In this paper, we propose an algorithm which is based on clustering to produce a utility-friendly anonymized version of microdata. Our extensive performance study shows that our methods outperform the non-homogeneous technique where the size of QI-attribute is larger than 3.
 Acknowledgement. This work was supported in part by the National Nat-ural Science Foundation of Ch ina (NO.6090303, NO .60902097, NO.60973047), the Natural Science Foundation of Zhejiang Province of China under Grant No. Y1091189 and No.Y1090571, the Research Fund for the Doctoral Program of Higher Education(No. 20090072120056), the Special Fund for Information De-velopment of Shanghai (No. 200901015), the National High-Tech Research and Development Plan of China (No. 2008AA04Z106), the Project of Science and Technology Commission of Shanghai Municipality (NO.08DZ1122300), and the Major Scientific &amp; Technology Specific Programs of Zhejiang Province for Key Industrial Project(No.2011C11042).

