 We address the problem of event extraction (EE): identifying event triggers of specified types and their arguments in text. Triggers are often single verbs or normalizations that evoke some events of interest while arguments are the entities participating into such events. This is an important and challeng-ing task of information extraction in natural lan-guage processing (NLP), as the same event might be present in various expressions, and an expression might expresses different events in different con-texts.

There are two main approaches to EE: (i) the joint approach that predicts event triggers and arguments for sentences simultaneously as a structured predic-tion problem, and (ii) the pipelined approach that first performs trigger prediction and then identifies arguments in separate stages.

The most successful joint system for EE (Li et al., 2013) is based on the structured perceptron al-gorithm with a large set of local and global fea-discrete structures that are intuitively helpful for EE using the NLP toolkits (e.g., part of speech tags, de-pendency and constituent tags). The advantages of such a joint system are twofold: (i) mitigating the er-ror propagation from the upstream component (trig-ger identification) to the downstream classifier (ar-gument identification), and (ii) benefiting from the the inter-dependencies among event triggers and ar-gument roles via global features. For example, con-sider the following sentence (taken from Li et al. (2013)) in the ACE 2005 dataset:
In Baghdad, a cameraman died when an Ameri-can tank fired on the Palestine hotel.

In this sentence, died and fired are the event trig-gers for the events of types Die and Attack , respec-tively. In the pipelined approach, it is often simple for the argument classifiers to realize that camera-man is the Target argument of the Die event due to the proximity between cameraman and died in the sentence. However, as cameraman is far away from fired , the argument classifiers in the pipelined ap-proach might fail to recognize cameraman as the Target argument for the event Attack with their lo-cal features. The joint approach can overcome this issue by relying on the global features to encode the fact that a Victim argument for the Die event is often the Target argument for the Attack event in the same sentence.

Despite the advantages presented above, the joint system by Li et al. (2013) suffers from the lack of generalization over the unseen words/features and the inability to extract the underlying structures for EE (due to its discrete representation from the hand-crafted feature set) (Nguyen and Grishman, 2015b; Chen et al., 2015).

The most successful pipelined system for EE to date (Chen et al., 2015) addresses these drawbacks of the joint system by Li et al. (2013) via dy-namic multi-pooling convolutional neural networks (DMCNN). In this system, words are represented by the continuous representations (Bengio et al., 2003; Turian et al., 2010; Mikolov et al., 2013a) and fea-tures are automatically learnt from data by the DM-CNN, thereby alleviating the unseen word/feature problem and extracting more effective features for the given dataset. However, as the system by Chen et al. (2015) is pipelined, it still suffers from the inherent limitations of error propagation and failure to exploit the inter-dependencies between event trig-gers and argument roles (Li et al., 2013). Finally, we notice that the discrete features, shown to be helpful in the previous studies for EE (Li et al., 2013), are not considered in Chen et al. (2015).

Guided by these characteristics of the EE sys-tems by Li et al. (2013) and Chen et al. (2015), in this work, we propose to solve the EE problem with the joint approach via recurrent neural net-works (RNNs) (Hochreiter and Schmidhuber, 1997; Cho et al., 2014) augmented with the discrete fea-tures, thus inheriting all the benefits from both sys-tems as well as overcoming their inherent issues. To the best of our knowledge, this is the first work to employ neural networks to do joint EE.

Our model involves two RNNs that run over the sentences in both forward and reverse directions to learn a richer representation for the sentences. This representation is then utilized to predict event trig-gers and argument roles jointly. In order to capture the inter-dependencies between triggers and argu-ment roles, we introduce memory vectors/matrices to store the prediction information during the course of labeling the sentences.

We systematically explore various memory vec-tor/matrices as well as different methods to learn word representations for the joint model. The ex-perimental results show that our system achieves the state-of-the-art performance on the widely used ACE 2005 dataset. We focus on the EE task of the Automatic Context as something that happens or leads to some change of state. We employ the following terminology:  X  Event mention : a phrase or sentence in which  X  Event trigger : the main word that most clearly  X  Event argument : an entity mention, temporal
ACE annotates 8 types and 33 subtypes (e.g., At-tack , Die , Start-Position ) for event mentions that also correspond to the types and subtypes of the event triggers. Each event subtype has its own set of roles to be filled by the event arguments. For in-stance, the roles for the Die event include Place , Vic-tim and Time . The total number of roles for all the event subtypes is 36.

Given an English text document, an event extrac-tion system needs to recognize event triggers with specific subtypes and their corresponding arguments with the roles for each sentence. Following the pre-vious work (Liao and Grishman, 2011; Li et al., 2013; Chen et al., 2015), we assume that the argu-ment candidates (i.e, the entity mentions, temporal expressions and values) are provided (by the ACE annotation) to the event extraction systems. We formalize the EE task as follow. Let W = w 1 w 2 ...w n be a sentence where n is the sentence length and w i is the i -th token. Also, let E = e ,e 2 ,...,e k be the entity mentions 3 in this sen-tence ( k is the number of the entity mentions and can be zero). Each entity mention comes with the offsets of the head and the entity type. We further assume that i 1 ,i 2 ,...,i k be the indexes of the last words of the mention heads for e 1 ,e 2 ,...,e k , respectively.
In EE, for every token w i in the sentence, we need to predict the event subtype (if any) for it. If w i is a trigger word for some event of interest, we then need to predict the roles (if any) that each entity mention e j plays in such event.

The joint model for event extraction in this work consists of two phases: (i) the encoding phase that applies recurrent neural networks to induce a more abstract representation of the sentence, and (ii) the prediction phase that uses the new representation to perform event trigger and argument role identi-fication simultaneously for W . Figure 1 shows an overview of the model. 3.1 Encoding 3.1.1 Sentence Encoding
In the encoding phase, we first transform each to-ken w i into a real-valued vector x i using the con-catenation of the following three vectors: 1. The word embedding vector of w i : This is ob-tained by looking up a pre-trained word embedding table D (Collobert and Weston, 2008; Turian et al., 2010; Mikolov et al., 2013a). 2. The real-valued embedding vector for the en-tity type of w i : This vector is motivated from the prior work (Nguyen and Grishman, 2015b) and gen-erated by looking up the entity type embedding table (initialized randomly) for the entity type of w i . Note that we also employ the BIO annotation schema to assign entity type labels to each token in the sen-tences using the heads of the entity mentions as do Nguyen and Grishman (2015b). 3. The binary vector whose dimensions corre-spond to the possible relations between words in the dependency trees. The value at each dimension of this vector is set to 1 only if there exists one edge of the corresponding relation connected to w i in the dependency tree of W . This vector represents the dependency features that are shown to be helpful in the previous research (Li et al., 2013).

Note that we do not use the relative position fea-tures, unlike the prior work on neural networks for EE (Nguyen and Grishman, 2015b; Chen et al., 2015). The reason is we predict the whole sentences for triggers and argument roles jointly, thus having no fixed positions for anchoring in the sentences.
The transformation from the token w i to the vector x i essentially converts the input sentence W into a sequence of real-valued vectors X = ( x 1 ,x 2 ,...,x n ) , to be used by recurrent neural net-works to learn a more effective representation. 3.1.2 Recurrent Neural Networks
Consider the input sequence X = ( x 1 ,x 2 ,...,x n ) . At each step i , we compute the hidden vector  X  i based on the current input vector x i and the previous hidden vector  X  i  X  1 , using the non-linear transformation function  X  :  X  i =  X ( x i , X  i  X  1 ) . This recurrent compu-tation is done over X to generate the hidden vector sequence (  X  1 , X  2 ,..., X  n ) , denoted by  X  X  X  X  RNN ( x 1 ,x 2 ,...,x n ) = (  X  1 , X  2 ,..., X  n ) .
An important characteristics of the recurrent mechanism is that it adaptively accumulates the context information from position 1 to i into the hidden vector  X  i , making  X  i a rich representa-tion. However,  X  i is not sufficient for the event trigger and argument predictions at position i as such predictions might need to rely on the con-text information in the future (i.e, from position i to n ). In order to address this issue, we run a second RNN in the reverse direction from X n to X 1 to generate the second hidden vector sequence:  X  X  X  X  which  X  0 i summarizes the context information from position n to i . Eventually, we obtain the new representation ( h 1 ,h 2 ,...,h n ) for X by concate-nating the hidden vectors in (  X  1 , X  2 ,..., X  n ) and sentially encapsulates the context information over the whole sentence (from 1 to n ) with a greater fo-cus on position i .

Regarding the non-linear function, the simplest form of  X  in the literature considers it as a one-layer feed-forward neural network. Unfortunately, this function is prone to the  X  vanishing gradient  X  prob-lem (Bengio et al., 1994), making it challenging to train RNNs properly. This problem can be alleviated by long-short term memory units (LSTM) (Hochre-iter and Schmidhuber, 1997; Gers, 2001). In this work, we use a variant of LSTM; called the Gated Recurrent Units (GRU) from Cho et al. (2014). GRU has been shown to achieve comparable perfor-mance (Chung et al., 2014; J  X  ozefowicz et al., 2015). 3.2 Prediction In order to jointly predict triggers and argument roles for W , we maintain a binary memory vector G vector/matrices are set to zeros initially ( i = 0 ) and updated during the prediction process for W .
Given the bidirectional representation h ,h 2 ,...,h n in the encoding phase and the initialized memory vector/matrices, the joint predic-tion procedure loops over n tokens in the sentence (from 1 to n ). At each time step i , we perform the following three stages in order: (i) trigger prediction for w i . (ii) argument role prediction for all the entity men-(iii) compute G trg
The output of this process would be the pre-dicted trigger subtype t i for w i , the predicted ar-gument roles a i 1 ,a i 2 ,...,a ik and the memory vec-tor/matrices G trg step. Note that t i should be the event subtype if w i is a trigger word for some event of interest, or  X  Other  X  in the other cases. a ij , in constrast, should be the argument role of the entity mention e j with respect to w i if w i is a trigger word and e j is an argument of the corresponding event, otherwise a ij is set to  X  Other  X  ( j = 1 to k ). 3.2.1 Trigger Prediction
In the trigger prediction stage for the current to-ken w i , we first compute the feature representation vector R trg lowing three vectors:  X  h i : the hidden vector to encapsulate the global
The representation vector R trg with a softmax layer in the end to compute the prob-ability distribution P trg types: P trg a trigger subtype. Finally, we compute the predicted type t i for w i by: t i = argmax t ( P trg 3.2.2 Argument Role Prediction
In the argument role prediction stage, we first check if the predicted trigger subtype t i in the previ-ous stage is  X  Other  X  or not. If yes, we can simply set a ij to  X  Other  X  for all j = 1 to k and go to the next stage immediately. Otherwise, we loop over the en-tity mentions e 1 ,e 2 ,...,e k . For each entity mention e with the head index of i j , we predict the argument role a ij with respect to the trigger word w i using the following procedure.

First, we generate the feature representation vec-vectors:  X  h i and h i  X  B ij : the hidden vector for the binary feature
In the next step, we again use a feed-forward neural network F arg with a soft-max layer in the end to transform R arg [ h ability distribution P trg roles: P arg a is an argument role. Eventually, the predicted argument role for w i and e j is a ij = argmax a ( P arg
Note that the binary vector V ij enriches the fea-ture representation R arg the discrete structures discovered in the prior work on feature analysis for EE (Li et al., 2013). These features include the shortest dependency paths, the entity types, subtypes, etc. 3.2.3 The Memory Vector/Matrices
An important characteristics of EE is the exis-tence of the dependencies between trigger labels and argument roles within the same sentences (Li et al., 2013). In this work, we encode these dependen-cies into the memory vectors/matrices G trg G the trigger and argument prediction explicitly (as shown in the representation vectors R trg above). We classify the dependencies into the fol-lowing three categories: 1. The dependencies among trigger subtypes : are captured by the memory vectors G trg { 0 , 1 } n T for i = 0 ,...,n , and n T is the number of the possible trigger subtypes). At time i , G trg dicates which event subtypes have been recognized before i . We obtain G trg prediction output t i at time i : G trg A motivation for such dependencies is that if a Die event appears somewhere in the sentences, the possibility for the later occurrence of an Attack event would be likely. 2. The dependencies among argument roles : are encoded by the memory matrix G arg { 0 , 1 } k  X  n A for i = 0 ,...,n , and n A is the number of the possible argument roles). At time i , G arg marizes the argument roles that the entity mentions has played with some event in the past. In particular, G some event before time i . G arg G at time i : G arg 3. The dependencies between argument roles and trigger subtypes : are encoded by the memory have been identified as arguments for which event subtypes before. In particular, G arg/trg only if e j has been detected as an argument for some event of subtype t before i . G arg/trg G G G 3.3 Training Denote the given trigger subtypes and argument roles for W in the training time as T = t  X  1 ,t  X  2 ,...,t  X  imizing the joint negative log-likelihood function C for triggers and argument roles: where I is the indicator function.

We apply the stochastic gradient descent algo-rithm with mini-batches and the AdaDelta update rule (Zeiler, 2012). The gradients are computed us-ing back-propagation. During training, besides the weight matrices, we also optimize the word and en-tity type embedding tables to achieve the optimal states. Finally, we rescale the weights whose Frobe-nius norms exceed a hyperparameter (Kim, 2014; Nguyen and Grishman, 2015a). Following the prior work (Nguyen and Grishman, 2015b; Chen et al., 2015), we pre-train word em-beddings from a large corpus and employ them to initialize the word embedding table. One of the models to train word embeddings have been pro-posed in Mikolov et al. (2013a; 2013b) that intro-duce two log-linear models, i.e the continuous bag-of-words model (CBOW) and the continuous skip-gram model (SKIP-GRAM). The CBOW model at-tempts to predict the current word based on the av-erage of the context word vectors while the SKIP-GRAM model aims to predict the surrounding words in a sentence given the current word. In this work, besides the CBOW and SKIP-GRAM models, we examine a concatenation-based variant of CBOW (C-CBOW) to train word embeddings and compare the three models to understand their effectiveness for EE. The objective of C-CBOW is to predict the tar-get word using the concatenation of the vectors of the words surrounding it . 5.1 Resources, Parameters and Dataset For all the experiments below, in the encoding phase, we use 50 dimensions for the entity type em-beddings, 300 dimensions for the word embeddings and 300 units in the hidden layers for the RNNs.
Regarding the prediction phase, we employ the context window of 2 for the local features, and the feed-forward neural networks with one hidden layer for F trg , F arg and F binary (the size of the hidden lay-ers are 600, 600 and 300 respectively).

Finally, for training, we use the mini-batch size = 50 and the parameter for the Frobenius norms = 3.
These parameter values are either inherited from the prior research (Nguyen and Grishman, 2015b; Chen et al., 2015) or selected according to the vali-dation data.
 We pre-train the word embeddings from the English Gigaword corpus utilizing the word2vec lowing Baroni et al. (2014), we employ the context window of 5, the subsampling of the frequent words set to 1 e -05 and 10 negative samples.
 We evaluate the model with the ACE 2005 corpus. For the purpose of comparison, we use the same data split as the previous work (Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013; Nguyen and Grishman, 2015b; Chen et al., 2015). This data split includes 40 newswire articles (672 sentences) for the test set, 30 other documents (836 sentences) for the development set and 529 remaining docu-ments (14,849 sentences) for the training set. Also, we follow the criteria of the previous work (Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013; Chen et al., 2015) to judge the correctness of the predicted event mentions. 5.2 Memory Vector/Matrices This section evaluates the effectiveness of the mem-ory vector and matrices presented in Section 3.2.3. In particular, we test the joint model on different cases where the memory vector for triggers G trg and are included or excluded from the model. As there are 4 different ways to combine G arg/trg and G arg for or not for trigger labeling, we have 8 systems for comparison in total. Table 1 reports the identifica-tion and classification performance (F1 scores) for triggers and argument roles on the development set. Note that we are using the word embeddings trained with the C-CBOW technique in this section.
 Table 1: Performance of the Memory Vector/Matrices
We observe that the memory vector G trg is not helpful for the joint model as it worsens both trig-ger and argument role performance (considering the same choice of the memory matrices G arg/trg and the row with G arg/trg + G arg ).

The clearest trend is that G arg/trg is very effective in improving the performance of argument labeling. This is true in both the inclusion and exclusion of other hand, have negative effect on this task. Finally, ger labeling performance in general (except in the case where G t , G arg/trg and G arg are all applied).
These observations suggest that the dependencies among trigger subtypes and among argument roles are not strong enough to be helpful for the joint model in this dataset. This is in contrast to the de-pendencies between argument roles and trigger sub-types that improve the joint model significantly.
The best system corresponds to the application of the memory matrix G arg/trg and will be used in all the experiments below. 5.3 Word Embedding Evaluation We investigate different techniques to obtain the pre-trained word embeddings for initialization in the joint model of EE. Table 2 presents the performance (for both triggers and argument roles) on the devel-opment set when the CBOW, SKIP-GRAM and C-CBOW techniques are utilized to obtain word em-beddings from the same corpus. We also report the performance of the joint model when it is initialized with the Word2Vec word embeddings from Mikolov et al. (2013a; 2013b) (trained with the Skip-gram model on Google News) (WORD2VEC). Finally, for comparison, the performance of the random word embeddings (RANDOM) is also included. All of these word embeddings are updated during the training of the model.
 Table 2: Performance of the Word Embedding Tech-The first observation from the table is that RAN-DOM is not good enough to initialize the word em-beddings for joint EE and we need to borrow some pre-trained word embeddings for this purpose. Sec-ond, SKIP-GRAM, WORD2VEC and CBOW have comparable performance on trigger labeling while the argument labeling performance of SKIP-GRAM and WORD2VEC is much better than that of CBOW for the joint EE model. Third and most importantly, among the compared word embeddings, it is clear that C-CBOW significantly outperforms all the oth-ers. We believe that the better performance of C-CBOW stems from its concatenation of the multi-ple context word vectors, thus providing more infor-mation to learn better word embeddings than SKIP-GRAM and WORD2VEC. In addition, the concate-Model Trigger Trigger Identification Argument Argument nation mechanism essentially helps to assign differ-ent weights to different context words, thereby be-ing more flexible than CBOW that applies a single weight for all the context words.

From now on, for consistency, C-CBOW would be utilized in all the following experiments. 5.4 Comparison to the State of the art The state-of-the-art systems for EE on the ACE 2005 dataset have been the pipelined system with dy-namic multi-pooling convolutional neural networks by Chen et al. (2015) ( DMCNN ) and the joint sys-tem with structured prediction and various discrete local and global features by Li et al. (2013) ( Li X  X  structure ).

Note that the pipelined system in Chen et al. (2015) is also the best-reported system based on neural networks for EE. Table 3 compares these state-of-the-art systems with the joint RNN-based model in this work (denoted by JRNN ). For com-pleteness, we also report the performance of the fol-lowing representative systems: 1) Li X  X  baseline : This is the pipelined system with local features by Li et al. (2013). 2) Liao X  X  cross event : is the system by Liao and Grishman (2010) with the document-level informa-tion. 3) Hong X  X  cross-entity (Hong et al., 2011): This system exploits the cross-entity inference, and is also the best-reported pipelined system with discrete features in the literature.

From the table, we see that JRNN achieves the best F1 scores (for both trigger and argument la-beling) among all of the compared models. This is significant with the argument role labeling per-formance (an improvement of 1.9% over the best-reported model DMCNN in Chen et al. (2015)), and demonstrates the benefit of the joint model with RNNs and memory features in this work. In ad-dition, as JRNN significantly outperforms the joint model with discrete features in Li et al. (2013) (an improvement of 1.8% and 2.7% for trigger and ar-gument role labeling respectively), we can confirm the effectiveness of RNNs to learn effective feature representations for EE. 5.5 Sentences with Multiple Events In order to further prove the effectiveness of JRNN, especially for those sentences with multiple events, we divide the test data into two parts according to the number of events in the sentences (i.e, single event and multiple events) and evaluate the perfor-mance separately, following Chen et al. (2015). Ta-ble 4 shows the performance (F1 scores) of JRNN, DMCNN and two other baseline systems, named Embeddings+T and CNN in Chen et al. (2015). Embeddings+T uses word embeddings and the tra-ditional sentence-level features in (Li et al., 2013) while CNN is similar to DMCNN, except that it ap-plies the standard pooling mechanism instead of the dynamic multi-pooling method (Chen et al., 2015).
The most important observation from the table is that JRNN significantly outperforms all the other methods with large margins when the input sen-tences contain more than one events (i.e, the row la-beled with 1/N in the table). In particular, JRNN is 13.9% better than DMCNN on trigger labeling while the corresponding improvement for argument role labeling is 6.5%, thereby further suggesting the benefit of JRNN with the memory features. Regard-Stage Model 1/1 1/N all Trigger CNN 72.5 43.1 66.3 Argument CNN 51.6 36.6 48.9 Table 4: System Performance on Single Event Sentences ing the performance on the single event sentences, JRNN is still the best system on trigger labeling al-though it is worse than DMCNN on argument role labeling. This can be partly explained by the fact that DMCNN includes the position embedding fea-in JRNN is not functioning in this single event case. Early research on event extraction has primarily fo-cused on local sentence-level representations in a pipelined architecture (Grishman et al., 2005; Ahn, 2006). After that, higher level features has been in-vestigated to improve the performance (Ji and Gr-ishman, 2008; Gupta and Ji, 2009; Patwardhan and Riloff, 2009; Liao and Grishman, 2010; Liao and Grishman, 2011; Hong et al., 2011; McClosky et al., 2011; Huang and Riloff, 2012; Li et al., 2013). Be-sides, some recent research has proposed joint mod-els for EE, including the methods based on Markov Logic Networks (Riedel et al., 2009; Poon and Van-derwende, 2010; Venugopal et al., 2014), structured perceptron (Li et al., 2013; Li et al., 2014b), and dual decomposition (Riedel et al. (2009; 2011a; 2011b)).
The application of neural networks to EE is very recent. In particular, Nguyen and Grishman (2015b) study domain adaptation and event detection via CNNs while Chen et al. (2015) apply dynamic multi-pooling CNNs for EE in a pipelined frame-work. However, none of these work utilizes RNNs to perform joint EE as we do in this work. We present a joint model to do EE based on bidirec-tional RNN to overcome the limitation of the previ-ous models for this task. We introduce the memory matrix that can effectively capture the dependencies between argument roles and trigger subtypes. We demonstrate that the concatenation-based variant of the CBOW word embeddings is very helpful for the joint model. The proposed joint model is empiri-cally shown to be effective on the sentences with multiple events as well as yields the state-of-the-art performance on the ACE 2005 dataset. In the fu-ture, we plan to apply this joint model on the event argument extraction task of the KBP evaluation as well as extend it to other joint tasks such as mention detection together with relation extraction etc.
