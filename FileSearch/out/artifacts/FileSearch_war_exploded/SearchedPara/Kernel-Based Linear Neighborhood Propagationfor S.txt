 Jinhui Tang 1 , , Xian-Sheng Hua 2 , Yan Song 1 , Guo-Jun Qi 1 , and Xiuqing Wu 1 Automatic annotation (or we may call it high-level feature extraction) of video and video segments is essential for enabling semantic-level video search. As man-ually annotating large video archive is labor-intensive and time-consuming, many automatic approaches are proposed for this issue. Generally, these methods build statistical models from manually pre-labe led samples, and then assign the labels for the unlabeled ones using these models. This process has a major obstacle: the labeled data is limited so that the distribution of the labeled data typically does not well represent the distribution of the entire dataset (include labeled and unlabeled), which usually leads to inaccurate annotation results.
Semi-supervised learning, which attempts to learn from both labeled and un-labeled data, is a promising approach to deal with the above obstacle. Many works on this topic are reported in literature of machine learning community [1]. And some of them have been applied to video or image annotation [2,3,4].
The key point of semi-supervised learning is the consistency assumption [5]: nearby samples in the feature space or samples on the same structure (also referred to as a cluster or a manifold) are likely to have the same label. This assumption considers both the local smoothness and the structure smoothness of the semantic distribution.

There are close relations between the consistency assumption and nonlin-ear dimensionality reduction schemes [6,7,10] since intrinsically they follow the same idea of reducing the global coordinate system of the dataset to a lower-dimensional one while pres erving the local distribution structure. Recently, a method called Local Neighborhood Propagation (LNP) [8,9] is proposed to com-bine these two strategies. LNP borrows the basic assumption of Local Linear Embedding (LLE) [6,10] that each sample can be reconstructed by its neigh-boring samples linearly, and further assumes that the label of the sample can be reconstructed by the labels of its neighboring samples using the same co-efficients. This method potentially assumes that the mapping from the feature to label is linear in a local area (to be detailed in Section 2). However, if the semantic super-plane has a high curvature in this area, LNP will fail. In other words, if the labels of the samples in the local area distribute complexly in the feature space, this linear assumption is no t appropriate. Therefore this method is not suitable to tackle the video semantic annotation problem, since typically the semantic distribution of video segm ents, which are collected from different sources and span a large time interval, is very complex in the feature space.
In this paper, we propose a novel method for automatic video annotation named Kernel based Local Neighborhood Propagation (Kernel LNP), which also combines the consistency assumption and LLE but is applied in a nonlinear kernel-mapped space. This method is able to handle more complex situation since it holds both the advantages of LNP and kernel methods, through mapping the input feature space to a nonlinear kernel-mapped feature space. The experiments conducted on the TRECVID [13] data set demonstrate that Kernel LNP is more appropriate than LNP for complex applications and can obtain a more accurate result for video high-lev el feature extraction.
 The rest of this paper is organized as fo llows. In Section 2, we briefly introduce LNP and analyze its limitation; and the proposed Kernel LNP for the video semantic annotation problem is detaile d in Section 3. Experiments are introduced in Section 4, followed by the conclusion remarks and future work in Section 5. In this section, we briefly introduce LNP and analyze its limitation. LNP is based on the assumption that the label of each sample can be reconstructed linearly by its neighbors X  labels, and the coeffici ents of reconstructing the label is the same as the ones for reconstructing the feature vector of the sample. This can be formulated as where N ( x i ) is the neighbors of sample x i ,and f i is the label of x i .
Define the mapping from the feature to label as f : x i  X  f i , we can obtain: and Combine (2) and (3), we have
Equation (4) indicates that the mapping from the feature to label is linear in a local area. Furthermore, from the viewpoint of LLE, LNP assumes that the semantic is a 1-D manifold embedded in the feature space. Local linear assump-tion or 1-D manifold assumption is not able to handle the data with complex semantic distribution. If the semantic super-plane has a high curvature in the local area, this assumption is not appropriate. So this method cannot tackle the video semantic annotation problem since the semantics of video segments often have very complex distributions. We call this drawback limitation of local linear assumption on the distribution of semantics . To tackle the aforementioned limitation of LNP, in Kernel LNP, we map the features to a kernel-mapped space and then try to obtain the reconstruction coefficients in this nonlinear space. Ke rnel LNP also assumes that the label of each sample can be reconstructed linearly by its neighbors X  labels, but the reconstruction coeffici ents are obtained in the nonlinear mapped space. our application) in R d (feature space with d -dimensional features). X = L U , y  X  X  1 , 0 } (1 i l )and U = { x to the task of high-level feature extraction in TRECVID [13], the objective here is to rank the remaining unlabeled samples, so we will assign real values (between 0 and 1) to the samples as labels instead of  X 0 X  or  X 1 X .

Considering a kernel mapping  X  (  X  ) operating from input space X to a mapped space  X  : the kernel matrix K of dot products can be represented as (RBF) is adopted in our experiments.

We find the k nearest neighbors N (  X  i )ofevery  X  ( x i )  X   X  using the following distance (for concision, we use  X  i to substitute  X  ( x i )): Please note this formula shows that the distance can be obtained directly from the kernel matrix instead of the mapping function  X  (  X  ).

According to the assumption of LLE, x i can be linearly reco nstructed from its neighbors. Using the kernel mapping , the coefficients obtained in the mapped space can reconstruct the labels bette r than the coefficients obtained in the original feature space. To compute the op timal reconstructi on coefficients, the reconstruction error of  X  i is defined as: w obtain the optimal coefficients for  X  i by solving the optimization problem: Introduce a  X  X ocal X  Gram matrix of  X  i in the kernel-mapped space here: where  X  i is a matrix formed by the mapped feature vectors for the k nearest neighbors of i -th sample,  X  1  X  X sa k -dimensional column v ector with each entry equals to 1,and g ipq = k ii  X  k ip  X  k iq + k pq is the entry in matrix G i ( k  X  k ). Please note here the subscripts p and q do not mean g ipq is the element in p -th row and q -th column (1 p, q n ) in the matrix, but it is obtained according to the positions of  X  p and  X  q in  X  i . For example, if  X  p is the r -thcolumnand  X  q is the s -th column in  X  i (1 r, s k ), g ipq is of the element in r -th row and s -thcolumnof G i . In some unusual cases, this Gram matrix may be singular or nearly singular. So it must be added a small multiple of the identity matrix for regularization [10].

Similar to the distance measure (see equation (6)), we can see that the Gram matrix in (9) also can be calculated directly from the kernel matrix instead of the mapping function. Therefore, in the entire computing procedure, the mapping function actually is not explicitly required.

This obtained Gram matrix is symmetric and semi-positive definite. We can use the Lagrange multiplier to enforce the constraint j w ij =1fortheop-timization problem in (8). According to the inverse Gram matrix, the optimal reconstruction coefficients vector w  X  i for i -th sample can be obtained as:
It is intuitive that the obtained reconstr uction coefficients reflect the intrinsic local semantic structure of the samples in the mapped space. These coefficients will be applied to reconstruct the unlabeled samples X  labels (which are real values instead of  X 0 X  or  X 1 X ), that is, to estimate the prediction function f .Inorderto obtain the optimal f , we define the following cost function where f i is the label of sample x i .

Minimizing this cost will optimally reconstruct the labels of all unlabeled samples from the counterparts of their neighbors. And from the view of label propagation, minimizing this cost results in iterative label information propaga-tions from labeled samples to other samp les according to the linear neighborhood structure in the nonlinear mapped space. Formally, this optimization objective is represented as
It has the same form as the optimization problem in [8], where three methods were proposed to solve it: Lagrangian method, eigen-decomposition method [11] and the method similar to anisotropic diffusion [12]. Since the video data set typically is very large (e.g., TRECVID 2005 dataset has about 126,000 sub-shots), it is difficult to storage the similarity matrix and compute its inversion or eigenvalues. To avoid handling large matrix, we adopt the third method. Therefore, we just need to record a small amount of neighbors of each sample, as well as the distances between the sampl e and its neighbors. This is actually an information propagation process from the label of each sample to its neighbors. The main procedure of the above algorithm is summarized as followed: a. Using the RBF as the kernel, compute the kernel matrix K =( k ij ) 1 i,j n with respect to X ( K is a sparse matrix as there are many entries equal to 0); b. Find the k nearest neighbors of each sample  X  i in  X  using the distance measure in (6); c. Compute the Gram matrix G i according to (9), then w  X  i can be computed according to (10); d. Predict the unlabeled samples X  real-value labels by solving the optimization problem in (12). e. Rank the unlabeled samples accord ing the labels obtained in step d. In the following experiments, we use the video data set of the TRECVID05 cor-pus, which is consisted of about 170 hours of TV news videos from 13 different programs in English, Arabic and Chinese [13]. After automatic shot boundary detection, the development (DEV) set contains 43907 shots, and the evalua-tion (EVAL) set contains 45766 shots. Some shots are further segmented into sub-shots, and there are 61901 and 64256 sub-shots for DEV and EVAL set respectively.

The high-level feature extraction task is to detect the presence or absence of 10 predetermined benchmark con cepts in each shot of the EVAL set. The 10 semantic concepts are walking running, explosion fire, maps, flag-US, build-ing, waterscape waterfront, mountain, prisoner, sports and car with concept IDs 1038  X  1047. Some key-frame examples for these concepts are shown in Fig.1. For each concept, systems are required to return ranked-lists of up to 2000 shots, and system performance is measured via non-interpolated mean average preci-sion (MAP), a standard metric for document retrieval.

The low level features we used here are 225-D block-wise color moments, which are extracted over 5  X  5 fixed grid partitions, each block is described using a 9-D feature.

Using the Kernel LNP method, the 64256 sub-shots are labeled as f ( subshot i ), and the sub-shots in the same shot are merged using the  X  X ax X  rule: Then the shots can be ranked according to f ( shot m ).

We compared Kernel LNP with LNP and S VM, and the experimental results are shown in Fig.2. The evaluations are accomplished when all the parameters are tuned to be nearly optimal by cross validations. Comparing these results, we can see that Kernel LNP significantly outperforms LNP for video high-level feature extraction, except that the result of prisoner is a little worse. The main reason is that prisoner is too difficult to be detected and the results of all ap-proaches are nearly random. Kernel LNP outperforms SVM for detecting maps , flag-US , waterscape waterfront , mountain , prisoner and sports , and remarkably outperforms the results named Median [14] (i.e., the average results of all the participants in TRECVID05). The MAP of Kernel LNP is 0.2303, which has an improvement of 4.7% and 64.2% over SVM and LNP, respectively. These comparisons demonstrate that Kernel LNP is more appropriate than LNP and is effective for semantic video annotation. We have analyzed the linear limitation of local semantics for LNP on ranking data with complex distribution, and proposed an improved method named Ker-nel LNP, in which a nonlinear kernel-mapped space is introduced for reconstruc-tion coefficients optimization. The experiments conducted on the TRECVID dataset demonstrate that the proposed method is more appropriate for the data with complex distribution and is effective for the semantic video annotation task. However, this method needs a complex cross validation procedure to obtain an optimal set of parameters. Our next-step work will be focused on reducing com-putation cost brought by this procedure.

