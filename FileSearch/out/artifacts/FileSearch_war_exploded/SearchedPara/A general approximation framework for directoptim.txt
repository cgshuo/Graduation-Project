 Abstract Recently direct optimization of information retrieval (IR) measures has become a new trend in learning to rank. In this paper, we propose a general framework for direct framework, which can be used to optimize most IR measures, addresses the task by approximating the IR measures and optimizing the approximated surrogate functions. framework. We take average precision (AP) and normalized discounted cumulated gains (NDCG) as examples to demonstrate how to realize the proposed framework. Experiments on benchmark datasets show that the algorithms deduced from our framework are very effective when compared to existing methods. The empirical results also agree well with the theoretical results obtained in the paper.
 Keywords Learning to rank Direct optimization of IR measures Position function approximation Truncation function approximation Accuracy analysis 1 Introduction In this paper, we consider the direction optimization of IR measures in learning to rank. 2008 ).

Several methods that directly optimize IR measures have been developed. In general, they can be grouped into two categories. The methods in the first category introduce upper other category approximate the IR measures using some smooth functions and conduct optimization on the surrogate objective functions (Guiver and Snelson 2008 ; Taylor et al. 2008 ).

Previous studies have shown that the approach of directly optimizing IR measures can achieve high performances when compared to the other approaches (Chapelle et al. 2007 ; because IR measures are explicitly considered in the direct optimization approach. How-ever, there are still some open problems regarding the approach, as shown below.
First, although there seems to be some relationship between the surrogate functions and the corresponding IR measures, the relationship has not been sufficiently studied. This is a critical issue, because it is necessary to know whether optimizing the surrogate functions can indeed optimize the corresponding IR measures.

Second, some of the proposed surrogate functions are not easy to optimize. Complicated techniques have to be employed for the optimization. For example, both SVM map (Yue et al. 2007 ) and SVM ndcg (Chapelle et al. 2007 ) use Structured SVM to optimize the surrogate objective functions. However, the optimization technologies (e.g., the con-struction of the joint feature map and the way of finding the most violated constraints) are measure-specific, and thus it is not trivial to extend them to new measures.
In this work, we propose a general direct optimization framework, which can effectively address the aforementioned problems. The framework can accurately approximate any position-based IR measure, and then transform the optimization of an IR measure to that of an approximated surrogate function.

The key idea of our proposed framework is as follows. The difficulty in directly opti-mizing IR measures lies in that the measures are position based, and thus non-continuous and non-differentiable with respect to the score outputted by the ranking function. If we can accurately approximate the positions of documents by a continuous and differentiable function of the scores of the documents, then we will be able to approximate any position mation of a position based IR measure can be obtained and thus high test performance in ranking can be achieved.

Taking average precision (AP) and normalized discounted cumulated gains (NDCG) as examples, we show that it is easy to derive learning algorithms (ApproxAP and Approx-NDCG) to optimize the surrogate functions in the proposed framework. Experimental results show that the derived algorithms can outperform existing algorithms.
The main contributions of this work include two aspects: 2. We show that it is easy to derive algorithms to optimize position based IR measures The remainder of this paper is as follows. We start with a review on existing methods in Sect. 2 . Section 3 sets up a general framework to approximate and optimize IR measures, and shows two examples of using this framework. Theoretical analysis on approximation accuracy is given in Sect. 4 . Experimental results are presented in Sect. 5 . We conclude the paper and discuss future directions in the last section. 2 Related work 2.1 Learning to rank for information retrieval The key problem for document retrieval is ranking, specifically, how to create the ranking model (function) that can sort documents based on their relevance to the given query. It is a common practice in IR to tune the parameters of a ranking model using some labeled data ertson and Hull 2000 ) and LMIR (Language Models for Information Retrieval) (Zhai and Lafferty 2001 ) all have parameters to tune. As the ranking models become more sophis-ticated (more features are used) and more labeled data become available, how to tune or train ranking models turns out to be a challenging issue.

The learning to rank technology can successfully leverage multiple features for ranking, and can automatically tune the parameters in ranking models based on a large volume of training data. This technology has been gaining increasing attention from both the research community and the industry in the past several years. The setting of learning to rank, when applied to document retrieval and web search, is as follows. Assume that there is a corpus of documents. In training, a number of queries are provided; each query is associated with a set of documents with relevance judgments. Each query-document pair is represented by a feature vector. A ranking function is then created using the training data, such that the model can precisely predict the ranked lists in the training data by appropriately combing the features. In retrieval (i.e., testing), given a new query, the ranking function is used to create a ranked list for the documents associated with the query.

Many learning to rank methods have been proposed and applied to different IR applications.

One approach in previous work takes document pairs as instances and reduces the problem of ranking to that of classification on the orders of document pairs. It then applies existing classification techniques to ranking. The methods include Ranking SVM (Herbrich et al. 1999 ; Joachims 2002 ), RankBoost (Freund et al. 2003 ), RankNet (Burges et al. 2005 ). Ranking SVM solves the problem of pairwise classification using Support Vector Machines, RankBoost using the boosting techniques, and RankNet using Neural Networks. See also Tsai et al. ( 2007 ), Zheng et al. ( 2007 ) for other pairwise methods.
Another approach regards ranking lists as instances and conducts learning on the lists of documents. For instance, Cao et al. proposed using a permutation probability model in the rank learning and employing a listwise ranking algorithm called ListNet (Cao et al. 2007 ). algorithms and derived a new algorithm based on Maximum Likelihood Estimation called methods. 2.2 Direct optimization of IR measures Recently, a new approach, direct optimization of IR measures, has attracted much attention in learning to rank. The basic idea of the direct optimization approach is to find an optimal ranking function by directly maximizing some IR measures such as AP (Voorhees and approach seems more straightforward and appealing, because what is used in evaluation is zation of IR measures.

One group of algorithms tries to optimize objective functions that are bounds of the IR measures. For example, SVM map (Yue et al. 2007 ) optimizes an upper bound of (1 -AP) in the predicted rankings. Specifically, a joint feature map is constructed for each possible ranking, and Structured SVM is used to iteratively optimize the most violated constraint (the way of finding the most violated constraint depends on the property of AP). The idea of SVM map is further extended to optimize other IR evaluation measures, and the corre-sponding algorithms include SVM ndcg (Chapelle et al. 2007 ) and SVM mrr (Chakrabarti et al. 2008 ). In these new algorithms, different joint feature maps and different ways of finding the most-violated constraints are proposed. AdaRank (Xu and Li 2007 ) minimizes an exponential loss function which can upper bound either (1 -AP) or (1 -NDCG) using boosting methods. It repeatedly constructs weak rankers on the basis of re-weighted training queries and finally linearly combines the weak rankers for making ranking pre-dictions. Two sub methods have been proposed in (Xu and Li 2007 ). AdaRank.MAP utilizes AP to measure the goodness of a weak ranker, and AdaRank.NDCG utilizes NDCG to measure the goodness of a weak ranker.

Another group of algorithms manages to smooth the IR measures with easy-to-optimize assumes the ranking score of a document to be governed by a Gaussian distribution, and then derives a rank distribution of the document in an iterative manner. Based on the rank distributions of all the documents associated with a query, SoftRank computes the expectation of NDCG as the objective function for learning to rank. The gradient descent method is used to learn the ranking function.

According to previous studies, direct optimization algorithms can achieve higher per-2008 ; Xu and Li 2007 ; Xu et al. 2008 ; Yue et al. 2007 ). However, there are still some open issues as shown below. 1. The relationships between the surrogate functions and the corresponding IR measures 2. Some of the proposed surrogate functions are not easy to optimize. Existing methods 3 A general approximation framework In this section, we propose a general framework for direct optimization of IR measures. The framework is applicable to any position based IR measure, and is theoretically justifiable.

In the framework, we take the approach of approximating the IR measures. The framework consists of four steps: 1. Reformulating an IR measure from  X  X ndexed by positions X  to  X  X ndexed by documents X  . 4. Applying a global optimization technique to optimize the approximated measure
For ease of description, we give some notations here. Suppose that X is a set of documents associated with a query, and x is an element in X . A ranking model f outputs a score s x for each x : where h denotes the parameter of f . A ranked list p can be obtained by sorting the documents thus achieve different ranking performances in terms of the IR measure. Further, we use
We first give a brief introduction to several popular IR measures used in learning to rank, and then take some measures as examples to introduce the four steps of the framework. 3.1 Review on IR measures To evaluate the effectiveness of a ranking model, many IR measures have been proposed. Here we give a brief introduction to several popular ones which are widely used in learning to rank. See also (Moffat and Zobel 2008 ) for other measures.

Precision@ k (Voorhees et al. 2005 ) is a measure for evaluating top k positions of a ranked list using two levels (relevant and irrelevant) of relevance judgment: relevant and zero otherwise.
 Average Precision (AP) (Voorhees et al. 2005 ) is defined on the basis of Precision: where | D ? | denotes the number of relevant documents with respect to the query. Given the ranked list for a query, we can compute an AP for this query. Then MAP is defined as the mean of AP over a set of queries.

While Precision@ k and AP consider only two levels of relevance judgments, Nor-for multiple levels of relevance judgments. NDCG@ k evaluates top k positions of a ranked list using multiple levels (labels) of relevance judgment. It is defined as below, where N k is a constant depending on a query to make the maximum value of NDCG@ k of the query is 1.

By considering all the n documents associated with a query, we can attain NDCG@ n , which is referred to as NDCG for short in this paper if without confusion.
 3.2 Step 1 : Measure reformulation Most of the IR measures, for example, Precision@ k , AP and NDCG are position based. Specifically, the summations in the definitions of IR measures are taken over positions, as can be seen in ( 1 ) X ( 4 ). Unfortunately, the position of a document may change during the training process, which makes the optimization of the IR measures difficult. To deal with the problem, we reformulate IR measures using the indexes of documents.
 When indexed by documents, Precision@ k in ( 1 ) can be re-written as below, positions.
 With documents as indexes, AP in ( 2 ) can be re-written as follows, Combining ( 5 ) and ( 6 ) yields ranked before document y .

Similarly, when indexed by documents, ( 3 ) of NDCG@ k can be re-written as the following, query, and r ( x ) = 4 means that the document is highly relevant to the query. Note that NDCG (more accurately NDCG@ n ) does not need a truncation function, them are non-continuous and non-differentiable. We will discuss how to approximate them separately in the next two subsections. 3.3 Step 2 : Position function approximation The position function can be represented as a function of ranking scores,
That is, positions can be regarded as outputs of functions of ranking scores. Due to the indicator function in it, the position function is non-continuous and non-differentiable.
We propose approximating the indicator function 1 { s x , y \ 0} using a logistic function (which is continuous and differentiable): where a [ 0 is a scaling constant.

In this way, the position function is correspondingly approximated and becomes con-tinuous and differentiable (denoted as ^ p  X  x  X  ), as shown below.
Table 1 shows an example of the above position approximation process. We can see that the approximation is very accurate in this case.

Now we can obtain the approximation of NDCG by simply replacing p ( x )in( 9 ) with ^ p  X  x  X  ; 3.4 Step 3 : Truncation function approximation As can be seen in Sect. 3.2 , some measures have truncation functions in their definitions, such as Precision@ k , AP, and NDCG@ k . These measures need further approximations on the truncation functions. We will introduce in this subsection how it can be achieved. Some other measures including NDCG do not have truncation functions; In this case, the tech-niques introduced below can be skipped.
 logistic function once again, in which b [ 0 is a scaling constant.

Thus, we obtain the approximation of AP as follows,
Similarly, we can also approximate the truncation function 1 { p ( x ) B k }in( 8 )as Here we add 0.5 to change B to \ . Note that we use 0.5 instead of other values such as 0.1 approximation error in the worse case. That is,
With ( 16 ), one can approximate measures like Precision@ k and NDCG@ k . Here we omit the details. 3.5 Step 4 : Surrogate function optimization With the aforementioned approximation technique, the surrogate objective functions (e.g., c AP and d NDCG) become continuous and differentiable with respect to the parameter h in the ranking model, and many optimization algorithms can be used to maximize them. Measure specific optimization techniques are no longer needed.

However, considering that the original IR measures contain a lot of local optima, the approximations of them will also contain local optima. Therefore, one should better choose those global optimization methods such as random restart (Hu et al. 1994 ) and simulated annealing (Kirkpatrick et al. 1983 ) in order to avoid being trapped to local optima. Note that there are also some alternative ways of dealing with the issue of local optimum. For Ranking SVM) to obtain an initial guess of the ranking model. Then use it as the starting point for the optimization of the approximated IR measure.

In this work, we choose to use the random restart technology (Hu et al. 1994 )asan example. That is, we first use a gradient descent method to find a local optimum of the optimum.

Since AP and NDCG are widely used for evaluation in learning to rank, we take them as examples to show how to perform the optimization, and call the corresponding algorithms ApproxAP and ApproxNDCG respectively. The details about the derivation of gradients of c AP and d NDCG can be found in Appendix sections  X  X  Gradient of ApproxNDCG  X  X  and  X  X  Gradient of ApproxAP  X  X . According to the derivations, the complexity of computing the training process is shown in Algorithm 1.
 3.6 Comparison with previous methods SoftRank (Taylor et al. 2008 ) also approximates the IR measure using a smooth function. When comparing the proposed framework to SoftRank, we can find the following differences. 1. Our framework approximates IR measures by approximating document positions, 3. We propose a general framework, which can be used to optimize any position based 4. Our approach has a solid theoretical justification on the accuracy of the approximation 4 Theoretical analysis of the framework As mentioned in Sect. 1 , the relationships between the surrogate objective functions and relation between the surrogate functions obtained by our framework and the IR measures can be well justified. In this section, we will study this issue. 4.1 Accuracy of position function approximation The approximation of positions is a basic component in our framework. In order to approximate an IR measure, we need to approximate positions first; in order to analyze the accuracy of approximation of IR measures, we need to analyze the accuracy of approxi-mation of positions first.
 unique ranked list by sorting. This would bring uncertainty to IR measures. For the sake of clarity, in this paper, we assume that
The following theorem shows that the position approximation in ( 12 ) can achieve very high accuracy. The proof can be found in the appendix.
 Theorem 1 Given a document collection X with n documents in it, for V a [ 0, ( 12 ) can approximate the true position with the following accuracy ,
This theorem tells us that when d x and a are large, the approximation will be very accurate. For example, A corollary of Theorem 1 is given below: Corollary 1 Given a document collection X with n documents in it, for V a [ 0, ( 12 ) can approximate the true position with an accuracy as below .
For the example in Table 1 , we have an accurate approximation: One may argue that the bounds in ( 19 ) and ( 20 ) are not very meaningful when n is large. Note that the denominator is in the exponential order of parameter a and the numerator is not-too-large a , one can always make the bound tight enough. For example in ( 21 ), if n increases from 5 to 1000, we can still get a very tight bound by simply increasing a from 100 to 200: 4.2 Accuracy of IR measure approximation The following theorems quantify the errors in the approximations of MAP and NDCG. The proof can be found in the Appendix.
 Theorem 2 If the error e of position approximation in ( 20 ) is smaller than 0.5, then we have
The theorem indicates that when e is small and b is large, the approximation of AP can be very accurate. In the extreme case, we have lim e ! 0 ; b !1 c AP  X  AP : For the example in approximation is very accurate in this case.
 Theorem 3 The approximation error of d NDCG can be bounded as
This theorem indicates that when e is small, the approximation of NDCG can be very accurate. In the extreme case, we have lim e ! 0 d NDCG  X  NDCG : For the example in Table 1 , we have j d NDCG NDCG j \ e 2ln2 0 : 00085 : That is, the NDCG approximation is very accurate in this case.

From these two examples (AP and NDCG), one can see that the surrogate functions obtained by the proposed framework can be very accurate approximations to the IR measures. 4.3 Justification of accurate approximation As shown in the previous subsection, the surrogate objective function we obtained can be very close to the original IR measure. One may argue whether such an accurate approx-imation really has benefit for learning the ranking model. To answer such questions, we have the following discussions.

If an algorithm can directly optimize an IR measure on the training set, then the learned training set. Note that in statistical machine learning, the training performance is computed as an average on the training set, while the test performance is measured as an expectation training performance will converge to the test performance (i.e., the average will converge to the expectation when the number of samples is infinite). Therefore, directly optimizing mance in terms of the same IR measure.
 Furthermore, it is easy to understand that if the surrogate measures are very close to the IR measures (i.e., the approximations are very accurate), the optimization of the surrogate measures will also lead to high performances of IR measures on training set. Again, if the measures.

One possible issue with regards to the accurate approximation of IR measures is that the more accurate the approximation is, the more complex the surrogate function will be. This is because the IR measure itself is very complex (as a function of the ranking model), and contains a lot of local optima. In this case, the optimization of the surrogate function is desired good performance. This is why we propose using global optimization techniques in our framework.

Due to space restrictions, we have only given some high level discussions here. More details can be found in Qin et al. ( 2008a ). 5 Experimental results We conducted a set of experiments to test the effectiveness of the proposed framework. 5.1 Datasets We used LETOR datasets (Liu et al. 2007 ) in our experiments. LETOR is a benchmark collection for the research on learning to rank for information retrieval. It has been widely Guiver and Snelson 2008 ; Qin et al. 2008b ; Xu et al. 2008 ; Zhou et al. 2008 ). The first version of LETOR was released in April 2007 and used in the SIGIR 2007 workshop on research.microsoft.com/users/LR4IR-2008/ ). The third version of LETOR, namely LETOR 3.0, was released in December 2008. 1 We used three datasets in LETOR 3.0 to test our algorithms: TD2003, TD2004 and OHSUMED. The statistics of the three datasets are shown in Table 2 . The datasets can be downloaded from LEOTR website ( http://www.research.microsoft.com/ * letor ). The TD2003 and TD2004 datasets were used to test ApproxAP and the OHSUMED dataset was used to test ApproxNDCG, since the first two datasets contain two-level relevance judg-ments and the third one contains three-level relevance judgments.

We note that most baseline algorithms in LETOR used linear ranking models. For fair comparison, we also used linear ranking model for ApproxAP and ApproxNDCG in the experiments, although our algorithms can also make use of other kinds of ranking models. 5.2 On the approximation of IR measures We first evaluated the accuracy of the approximations of AP and NDCG.

As seen in Sect. 3.4 , there are two parameters in c AP ; a and b . We first fixed b = 10 and set three different values for a . Then, we applied the ApproxAP algorithm to the TD2004 dataset with these three different parameters. Figure 1 a shows the error q in the training process defined as the training query set, and | Q | is the number of queries in the training set. which is more than 95%. Furthermore, as the increase of a , the approximation becomes more accurate: the accuracy is higher than 98% when a = 100.

We then fixed a = 100 and tried different values of b . Figure 1 b shows the error q with approximation also improves.
 Figure 2 shows the error q  X  1 j Q j ferent a values. We can get similar observations.

All these results verify the correctness of the discussions in Sect. 4.2 , and indicate that the approximation of IR measures using our proposed method can achieve high accuracy. 5.3 On the performance of ApproxAP We adopted the five fold cross validation as suggested in LETOR for both TD2003 and TD2004 datasets. For each fold, we used the training set to learn the ranking model, use the validation set to select hyper parameters a and b in the ApproxAP algorithm, and use the test set to report the ranking performance. The detailed process is as follows: (a) we first chose a set of a values {50, 100, 150, 200, 250, 300} and a set of b values {1, (b) we set d = 0.001, g = 0.01, K = 10 in Algorithm 1. That is, we made 10 random (c) for each combination of a and b , we learned a ranking model with 10 random restarts (d) we tested the performance of each model on the validation set and selected the model (e) we tested the performance of the final model on the test set.

As baselines, we used AdaRank.MAP and SVM map , which directly optimize AP. We also compared with Ranking SVM and ListNet, two state-of-the-art algorithms that do not SVM map , Ranking SVM, and ListNet directly from LETOR official website ( http:// hyper parameters of these algorithms have been carefully tuned and the validation set has been used for model selection. In this regard, the experimental settings for our methods and these baselines are the same, which ensures a fair comparison among them.
 As can be seen from Table 3 , ApproxAP performs better than AdaRank.MAP and SVM map on both datasets. For example on TD2003, ApproxAP gets more than 15% relative improvement over SVM map and more than 20% relative improvement over Ada-Rank.MAP. Since ApproxAP only uses a simple gradient method for the optimization (as compared to the structured SVM and Boosting used in the two baselines), the current result clearly shows the advantage of using the proposed method for direct optimization, and we foresee that with the use of more advanced optimization techniques, the performance of ApproxAP could be further improved.

Furthermore, ApproxAP is better than Ranking SVM and ListNet on TD2003 and gets similar result as Ranking SVM and ListNet on TD2004. We also find that AdaRank.MAP and SVM map are not as good as Ranking SVM and ListNet. We hypothesize the reason as follows. AdaRank.MAP and SVM map optimize the upper bound of AP and it is not clear whether the bound is tight. If the bound is very loose, optimization of the bound cannot always lead to the optimization of AP, and so they may not perform well on some datasets. This is in accordance with the discussions in He and Liu ( 2008 ). 5.4 On the performance of ApproxNDCG We used a similar strategy to select the hyper parameters a for ApproxNDCG to that for ApproxAP. We chose the same set of a values {50, 100, 150, 200, 250, 300} and the same value of d , g and K . But we used NDCG@ n for model selection instead of MAP on the validation set.

We compared ApproxNDCG with AdaRank.NDCG and SoftRank, which directly optimize NDCG. We also compared with Ranking SVM and ListNet. We cited the results of AdaRank.NDCG, Ranking SVM and ListNet from LETOR official website validation set has been used for model selection. There is a hyper parameter r in SoftRank. We tuned the parameter and used validation set to select the best value. That is, the same experimental strategy was applied to all the algorithms here for fair comparisons. Table 4 shows average NDCG at positions 1, 3, 5 and 10 for the five algorithms on the OHSUMED dataset. For position 1, ApproxNDCG gets 0.08 NDCG gain over Ranking SVM, which is about 16% relative improvement; it also gets more than 0.04 NDCG gain over AdaRank.NDCG and SoftRank, which is about 8% relative improvement. Improve-ments can also be observed at other positions. Overall, ApproxNDCG achieves the highest accuracy. The performances in terms of NDCG@ n of AdaRank.NDCG, SoftRank, Ranking SVM, ListNet and ApproxNDCG are 0.6640, 0.6623, 0.6457, 0.6600 and 0.6680 respectively. Again ApproxNDCG is the best one. Note that since NDCG@ n considers all rithms. This verifies the effectiveness of our proposed method. 5.5 Discussions In this sub section, we will make some deep investigations on the algorithms derived from our proposed framework. 5.5.1 Approximation accuracy versus optimization feasibility As mentioned in Sect. 4.3 , the larger the hyper-parameters ( a and b ) are, the more accurate surrogate functions is.

Table 5 shows the training performance in terms of NDCG@5 of ApproxNDCG on fold 1 of the OHSUMED dataset with respect to different a and K values. As can be seen, with only one random restart ( K = 1), a = 300 does not get better training performance than a = 50 and a = 100. This is because a larger value of a makes the objective function more difficult to maximize. As we increase the number of random restarts to 100, we see that a = 300 gets the best training accuracy, a = 100 the second, and a = 50 the third.
From this table, we conclude that larger value of a indeed makes the objective more difficult to maximize; to learn a better ranking model for large a , more random restarts are similar observations for ApproxAP. The details are omitted here. 5.5.2 Comparison with SoftRank In Sect. 3.6 , we have performed some analysis on the comparison with SoftRank, which belongs to the same sub category of the direct optimization approach as our methods. Here we make some experimental studies, including training performance and time complexity.
After tuning the hyper parameter of SoftRank, it achieved its best training performance in terms of NDCG@5 on fold 1 of OHSUMED as 0.4940. Comparing the results in SoftRank. From Tables 4 and 5 , we get that ApproxNDCG achieved better ranking accuracy than SoftRank on both training and testing sets.

Furthermore, we also logged the running time in the experiments. Table 6 shows the information of ApproxNDCG and SoftRank on fold 1 of the OHSUMED dataset. As can be seen, ApproxNDCG is much faster than SoftRank. 6 Conclusions and future work measures. The key part of the framework is to approximate the positions of documents by logistic functions of their scores. There are several advantages of this framework: (1) the techniques can be directly applied to the optimization and the optimization process itself is measure independent; (3) it is easy to conduct analysis on the accuracy of the approach and high approximation accuracy can be achieved by setting appropriate parameters.
We have taken AP and NDCG as examples to show how to approximate IR measures within the proposed framework, how to analyze the accuracy of the approximation, and how to derive effective learning algorithms to optimize the approximated functions. Experiments on public benchmark datasets have verified the correctness of the theoretical analysis and have proved the effectiveness of our algorithms.

There are still some issues that need to be further studied. 1. The approximated measures are not convex, and there may be many local optima in 2. We have used linear ranking models in the experiments. Our algorithms can be Appendix: Approximation accuracy analysis In the appendix, we give proofs of the major theorems in this paper. (I) Proof of Theorem 1 Proof Note that If we can prove that for any document y 2X ; then we can have
Now we prove the inequality ( 25 ). We consider s x , y [ 0 and s x , y \ 0 separately.  X  For s x , y [ 0, from ( 18 ) we have Then, Note that 1 { s x , y \ 0} = 0 when s x , y [ 0. Hence, for s x , y [ 0,  X  For s x , y \ 0, from ( 18 ) we have Note that 1 { s x , y \ 0} = 1 when s x , y \ 0. Hence, for s x , y \ 0, Combining the two cases we end up with ( 25 ). According to ( 26 ), Theorem 1 is correct. (II) Proof of Theorem 2 We prove Theorem 2 about the accuracy of precision approximation.
 Proof For simplicity, we denote From ( 7 ) and ( 15 ), we have Similar to the derivation of ( 25 ), we can get Combining ( 28 ) and ( 29 ), we get Then
Substitute ( 30 ) and ( 32 ) into ( 27 ), we get Since | D ? | C 1, hence Proof of Theorem 3 Proof From ( 9 ) and ( 13 ), we obtain Considering that log 2  X  1  X  ^ p  X  x  X  X  [ 1 ; we have Then ( 33 ) becomes According to the definition of NDCG, we always have NDCG B 1. Hence, Appendix: Gradient derivation (I) Gradient of ApproxNDCG We show how to derive the gradient for ApproxNDCG.
 According to the chain rule, we obtain Further, Substituting ( 36 ) and ( 37 ) into ( 35 ), we get the gradient for ApproxNDCG. example, for linear function, we have o f  X  x ; h  X  o h  X  x : (II) Gradient of ApproxAP We next show how to derive the gradient for ApproxAP.

According to the chain rule, we obtain where
Again by the chain rule, we have gradient for ApproxAP.
 References
