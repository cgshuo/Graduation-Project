 The aim of this work is to survey and reflect on the various ways visualization and data mining can be integrated to achieve effective knowledge discovery by involving the best of human and machine capabilities. Following a bottom-up bibliographic research approach, the article categorizes the observed techniques in classes, highlighting current trends, gaps, and potential future directions for research. In particular it looks at strengths and weaknesses of information visu alization (infovis) and data mining, and for which purposes researchers in infovis use data mining techniques and reversely how researchers in data mining employ infovis techniques. The article then proposes, on the basis of the extracted patterns, a series of potential extensions not found in literature. Finally, we use this information to analyze the discovery process by comparing the analysis steps from the perspective of information visu alization and data mining. The comparison brings to light new perspectives on how mining and visualization can best employ hum an and machine strengths. This activity leads to a series of reflections and research questions that can help to further advance the science of visual analytics.
 Visualization, Data Mining, Vi sual Data Mining, Knowledge Discovery, Visual Analytics. While information visualization (infovis) targets the visual representation of large-scale da ta collections to help people understand and analyze informati on, data mining, on the other hand, aims at extracting hidden patterns and models from data, automatically or semi-automatically. In its most extreme representation, infovis can be seen as a human-centered approach to knowledge discovery, whereas data mining is generally purely machin e-driven, using computational tools to extract automatically models or patterns out of data, to devise information and ultimately knowledge. Interactive Machine Learning (or Interactive Data Mining) [1][2] is an area of research where the integration of human and machine capabilities is advocated, beyond the scope of visual data analysis, as a way to build bette r computational models out of data. It suggests and promotes an approach where the user can interactively influence the decisions taken by learning algorithms and make refinements where needed. Visual analytics is a new interdisciplinary domain that integrates several domains like: interactive vi sualization, statistics and data mining, human factors, to focus on analytical reasoning facilitated by interactive visual interfaces [3]. Often, it is presented as the combination of infovis techniques with data mining capabilities to make it more powerful and interactive. According to Keim et al., visual analytics is more than just visualization and can rather be seen as an integrated approach combining visualization, human factors and data analysis [4]. At the time of writing, we reali ze that regardless several efforts exist to define what visual anal ytics is on a higher level (above all the Visual Analytics Agenda [3]), we still lack a detailed analysis of: 1) how currently the existing techniques integrate and to what extent; 2) what other kinds of integrations might be achieved. The purpose of this work is to start shedding some light on these issues. To this end, we have performed a literature review of papers from premier conferences in data mining and information visualization, extracting those in which some form of integration exists. The analysis permitte d to categorize the observed techniques in classes. For each class we provide a description of the main observed patterns, a nd then we discuss potential extensions we deem feasible and important to realize. The analysis follows by a comparison of the analytical processes as they happen in data mining and in visualization. This comparison, together with the knowledge gain ed in the literature review, permits to clarify some commonalities and differences between the automatic and visual approaches. We believe this kind of reasoning can help framing the problem of automatic and interactive analysis and better understand the role of the human and the machine. Given the nature of our discussion we might seem to suggest that visualization and data mining ar e always two competing methods to address the same problem and th at some form of integration is always desirable. But, this is not the message we want to convey here. Rather we want to draw a picture of what can happen, and should happen, when we focus our attention on only those cases where an overlap exists and inte gration is desirable; without discussing in any details when this is desirable. The paper is organized as follo ws. Section 2 introduces some terminology to clarify the meaning of some words that often appear when talking about automatic or interactive data analysis. Section 3 introduces the literature review and its methodology. Section 4 illustrates the result of the review describing the patterns we found. Section 5 descri bes the extensions we propose. Section 6 dissects commonalities and differences between the analysis processes and provide s some reflections on further research in data mining and visua lization. Section 7 elaborates on the reflections and introduces the idea of defining visual analytics problems. Finally, Section 8 disc usses the limitations of this work, and thus provides ideas for its future extension, and Section 9 closes the paper with conclusions. The common goal of information vi sualization (infovis) and data mining is to extract knowledge from raw data, through visualization techniques and auto matic computational analysis respectively. In the rest of this article, we both use the terms infovis and visualization when speaking about the first approach, and indifferently about data mini ng or automatic data analysis when speaking about the second. Before going further in our inspection of the integration of the two approaches, we thought useful to agree on the definition of basic concepts such as data, information, knowledge, model, pattern and hypothesis and on how they are linked in the knowledge discovery process. Some definitions below are inspired from a mix of sources (e.g. www.infovis-wiki.net, Oxford E nglish Dictionary) and from our own thoughts. The way they rela te in the knowledge discovery process is our own interpretation and as such can be further discussed. In the context of knowledge discovery , raw data are the lowest level of abstraction; data refers to a collection of facts usually collected by observations, measures or experiments. It is called abstract data in infovis, since it refers to data that have no inherent spatial structure enabling further mapping to any geometry. From data, models and patterns can be extracted, either automatically using data mining techniques or by humans using their conceptual, perceptual or vi sual skills respectively. The use of human intuition to come up with observations about the data is generally called insight , i.e., the act or outcome of grasping the inward or of perceiving in an intuitive manner. Patterns and models are not nece ssarily linked, even though some authors consider them as synonyms. A pattern is made of recurring events or objects that repeat in a predictable manner. A model is a mathematical representation of a system phenomena, or processes. It is basically a simplified abstract view of the complex reality. One way to distinguish models and patterns is the following: patterns are directly attached to data or a sub-set of data; whereas models are more conceptual and are extra information that cannot necessarily be observed visually in the data. Further, the observation of some patterns can result in a model and inversely, the simula tion of a model can result in a pattern. Hypotheses are human artifacts a nd are derived from models and patterns. A hypothesis consists either of a suggested explanation for an observable phenomenon or of a reasoned proposal predicting a possible causal correlation among multiple phenomena. A validated hypothesis becomes information that can be communicated. Finally, information reaches the solid state of knowledge when it is crystallized , i.e., it reaches the most compact description possible for a set of data relative to some task without removing information critical to its execution. We started our analysis with a literature review in order to ground our reasoning on observed facts and limit the degree of subjectivity. We followed a mixed approach in which bottom-up and top-down analyses have been mixed to let the data speak for themselves and suggest new ideas or use the literature to investigate our assumptions or formulated hypotheses. We included in the literature papers from major conferences in information visualization, data mining, knowledge discovery and visual analytics. In the current state of our analysis the papers have been selected from the whole set of proceedings of: ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD) , IEEE International Conference on Data Mining (ICDM) and the IEEE Symposium on Information Visualization (InfoVis). We selected infovis candidate papers searching in the IEEE Explore 1 library using keywords like:  X  X ata mining X ,  X  X lustering X ,  X  X lassificati on X , etc. Reversely, in data mining conferences we looked for keywords like:  X  X isualization X ,  X  X nteraction X , etc. Manual skimmi ng followed paper extraction to remove spurious papers. The final set of retained papers counts 48 items. Table 1 shows the distribution of the retained papers according to the paper source and the classification of papers presented below. The whole list of reviewed papers with attached notes and categories can be found at the following address: http://diuf.unifr.ch/people/bertinie/ivdm-review . We used various dimensions in order to classify the chosen papers: the knowledge discovery step it supports, whether it is interactive or not, the major mi ning and visualization techniques used, etc. In particular, in regards to the aim of this paper, we classified the paper according to four major categories indicating which approach drives the research: http://ieeexplore.ieee.org/  X  Computationally enhanced Visualization (V++) contains  X  Visually enhanced Mining (M++) contains techniques in  X  Integrated Visualization and Mining (VM) contains Since the focus of this paper is on how visualization and mining can cooperate in knowledge disc overy, in the paper we do not discuss other categories we have built during the process where a very predominant role of mining or visualization was present. More specifically, we did not take into account the pure visualization category containing techniques based exclusively on visualization, without any type of algorithmic support, or the pure mining category, making no use of visualization techniques. This category pertains to techniques in which visualization is the primary data analysis means and automatic computation (that is the  X ++ X  in the name) provides additional features to make the tool more effective. In other words, when the  X ++ X  part is removed it becomes a  X  X ure X  visualization technique. The techniques collected in our literature review are organized around three main patterns (Projec tion, Data Reduction, Pattern Disclosure) that represent differe nt benefits brought by automatic computation to the information visualization process. Projection . Automatic analysis methods often take place in the inner workings of visualizati on, by creating a mapping between data items and their graphical objects X  position on the screen. They all share the idea that the position assumed by a data point on the screen is not the result of a direct and fixed mapping rule between some data dimensions and screen coordinates, but rather of a more complex computation th at takes into account all data dimensions and cases. Ward refers to this kind of placement techniques as  X  X erived Data Placement Strategies X  in his glyph placement taxonomy [5]. The most traditional technique in this class is Multidimensional Scaling (MDS). Figure 1 shows an example of MDS taken from [6], where a fast MDS visualization algorithm is proposed. Figure 1 -Multidimensional Sc aling. Example of projection technique (extracted from [6]). But in literature it is possible to find many variations and alternatives like graph drawing algorithms and other complex spatialization techniques. Intelligent Data Reduction . Data reduction is another area where computation can support visualiza tion. Visualization has very well known scalability problems that limit the number of data cases or dimensions that can be shown at once. Automatic methods can reduce data complex ity, with controlled information loss, and at the same time allow for a more efficient use of screen space. Pattern matching techniques can replace data overviews with visualizations of selected data cases that match a user-defined query. Sampling can reduce the number of data cases with controlled information loss. Feat ure selection can reduce data dimensionality by retaining subsets that carry the large majority of useful information contained in the data (and thus are most likely to show interesting pattern s). Figure 2 shows an example of dimension filtering as proposed in [7] Figure 2 -Dimension filtering. Example of data reduction technique (extracted from [7]). Patterns Disclosure . In several visualization techniques the effectiveness with which useful patterns can be extracted depends on how the visualization is configured. Automatic methods can help configure the visualization in a way that significant features pop-out from the screen. Axes-reor dering in parallel coordinates is one instance of such case [8]. Similarly, in visualizations where the degree of freedom in visual configuration is limited, pattern detection algorithms can help make visual patterns more prominent and thus readily visible. For instance, Vizster [9] (in Figure 3) organizes the nodes of a social network graph around automatically detected clusters enclosed within colored areas. Johansson et al. in [10] describe an enhanced version of Parallel Coordinates where clustering a nd a series of user-controlled transfer functions help the user reveal complex structures that would be hard, if not impossi ble, to capture otherwise. 
Figure 3 -Graph clustering in Vizster. Example of pattern This category pertains to techniques in which data mining is the primary data analysis means and visualization (that is the  X ++ X  in the name) provides an advanced interactive interface to present the results. In other words, when the  X ++ X  part is removed it becomes a  X  X ure X  data mining technique. The techniques collected in our literature review can be organized around two major patterns (Model Presentation and Pattern Exploration &amp; Filtering) that repr esent different benefits brought by visualization to data mining. Model Presentation. Visualization is used to facilitate the interpretation of the model extracted by the mining technique. According to the method used, th e ease with which the model is interpreted can vary. Some models naturally lend themselves to visual abstraction (e.g., dendrogram in hierarchical clustering) whereas some others require mo re sophisticated designs (e.g., neural networks or support vect or machines) because a natural metaphor simply does not exist. One example of model visualization is  X  X omograms X  [11] (Figure 4), where the output of a classification or regression algor ithm (e.g., SVM) is presented in a way to understand the relations hip between dimensions and target variable. Figure 5 -Sequential Patterns visualization. Example of patterns exploration and filtering (extracted from [12]). Beyond model interpretation, visua lization also works as a way to visually convey the level of trust a user can assign to the model or parts of it. Interactions associated to the visualization permits to  X  X lay X  with the model allowing for a deeper understanding of the model and its underlying data. Patterns Exploration and Filtering. Some mining methods generate, in place of descriptive or predictive models, complex and numerous patterns which are difficult to summarize in a compact representation (e.g., association rules). In this case, visualization often adopts tec hniques similar to plain data visualization and the pattern s are managed like raw data. Visualization here helps gaining an overview of the distribution of these patterns and making sense of their nature. Interactive filtering and direct manipulation tools have a prominent role, in that finding the interesting patte rn out of numerous uninteresting ones is the key goal. An example is the output obtained from sequential temporal patterns, as shown in Figure 5, where numerous time patterns are presen ted to understand how topics change in a stream of news [12]. This category combines visualization and mining approaches. None of them predominate over the other and ideally they are combined in a synergic way. In the literature we found two kinds of integration strategies that we describe below. The two approaches described below illustrate the two extremes to integrate mining and visualization. White-Box Integration. In this kind of integration the human and the machine cooperate during the model building process in a way that intermediary decisions in the algorithm can be taken either by the user or the machine. This kind of systems is quite rare. There are examples of cooperative construction of classification trees, like the one presented in [13], where the user steers the construction process and at any stage can ask the computer to make one step in his or her place like splitting a node or expanding a sub-tree. These sy stems show the highest degree of collaboration between the user and the machine and go beyond the creation of accurate models. They help building trust and understanding, because the whole pro cess is visible, and also they permit to directly exploit the user X  X  domain knowledge in the model construction process. One not able example of this process is the one described in [13] (F igure 6), where the intermediary steps of a decision tree algorithm can be taken interactively or automatically. Figure 6 -Collaborative decision tree construction. Example of white-box integration (extracted from [13]). Black-Box Integration (feedback loop). Integration between mining and visualization can also happen indirectly using the algorithm as a black box, but giving the user the possibility to  X  X lay X  with parameters in a tight visual loop environment, where changes in the parameters are automatically reflected in the visualization. In this way the connection between parameters and model, even if not explicit, can be intuitively understood. Alternatively, the same integration can be obtained in a sort of  X  X elevance feedback X  fashion, where the system generates a set of alternative solutions and the user instructs the system on which are the most interesting ones and gives hints on how to generate a new set. An example of this kind of integration is in [14] where  X  X racketing X  is used to show alternative solutions of a subspace clustering algorithm simultaneously (Figure 7). Figure 7 -Bracketing technique is subspace clustering. Example of black-box technique s (extracted from [14]). Figure 8 -In current enhanced infovis systems (V++), data analysis is mostly used at the beginning of the KDD process and reversely, in enhanced data analysis systems (M++), visualization is principa lly used at the end. Table 2, at the end of Section 5, summarizes the observed integrations of visualization a nd data analysis in data mining systems, as described above, and suggested novel integrations as described in the next section. The previous section listed the ma jor traits we found in current visual analytics systems, through our literature survey. As presented in the previous section and illustrated in Figure 8, the integration patterns in enhanced visualization or enhanced mining systems is stereotyped. On one ha nd, data analysis is used by infovis practitioners at the beginning of the KDD process to project and reduce data, and di sclose patterns. Reversely, visualization is mostly used by data analysis practitioners at the end of the process to present visually a model or to explore and filter the patterns they find. In the following we propose to enhance the respective contributions of data analysis a nd visualization to better cover the full KDD spectrum, towards a tighter integration. All the automatic data analysis methods described in section 4.1 share the common goal of helping the user more easily extract information from the visualization. But, if we take into account the broader picture of data analysis and analytical reasoning, we see that automatic techniques could also be employed to go beyond simple pattern detection, a nd intervene at later stages of the knowledge discovery process. Below we list some of the functions that we believe would be beneficial to information visualization. Visual Model Building. One limitation of current visualization systems is their inability to go beyond simple pattern detection and frame the problem around a sc hema to enable higher level reasoning and hypothesis generation. Ideally, the user should be able to find connections among the extracted patterns to build higher level hypotheses and comple x models. This is another area where data mining has an advantag e over visualization in that in the large majority of the existing methods a specific conceptual model is inherent in the technique. Classification and regression , for instance, imply a functional model: an instantiation of the set of predictive variables produces a target value. Clustering implies a grouping model, where data is aggregated in groups of items that share similar properties. Rules imply an inductive model where if-then associations are used . This kind of mental scaffold is usually absent in visualization, or better it is formed only in the user X  X  mind. But there X  X  no inhe rent reason why future systems might not be provided with visual modeling tools that permit, on the one hand to keep the level of flexibility of visualization tools, on the other hand to structure the visualization around a specific model building paradigm. Two rare examples of systems that go towards this direction are PaintingClass [15] and the Perception Bases Classification (PBC) system [16] in which classification can be carried out interactively by means of purely visual systems. Verification and Refinement. One notable feature of automatic data mining over data visualization is its ability to communicate not only patterns and models but also the level of trust a user can assign to the extracted knowledge. Similar functions are usually not present in standard visuali zation tools and surprisingly little research as been carried out towards this direction so far. Automatic algorithms could be run on extracted patterns to help the user assess their quality once they are detected. To date, the only systems we are aware of where a similar idea has been implemented are [17][18], where respectively data abstraction quality is measured and progressive automatic refinement of visual clusters is performed. Another related area of investiga tion is the use of the traditional split in training data and test data used in supervised learning as a novel paradigm to use in data visu alization. There is no reason in principle not to use the same technique in information visualization to allow for verifica tion of extracted patterns. Some few studies on sampling for data visualization slightly touch on this issue [19][20] but none of them focuses on the use of sampling or data segmentati on for verification purposes. Prediction. Worthy of special remark is also the almost complete absence of predictive modeling in visualization, as highlighted by Amar and Stasko in their analysis of  X  X nalytic gaps X  in information visualization [21]. While it is fairly simple to isolate data segments and spot correlations, even in multidimensional spaces, current information visualization tools lack the right affordances and interactive tools to structure a problem around prediction. Questions like:  X  X hi ch data dimensions have the highest predictive power? X ,  X  X hat combination of data values are needed to obtain a target result? X  are not commonly in the scope of traditional visualization tools. Many real world problems are based on prediction, like the ones involved in marketing campaigns or financial projecti ons, and there is no reason to believe that visualization cannot play a far larger role in this domain. Visualization applied to data mi ning output, as shown in section 4.2, provides great benefits in terms of model interpretation and trust-building. We believe that visualization, however, can provide additional benefits that have not been fully exploited so far, and enable users to intervene in earlier stages of the knowledge discovery process. Visualizing the Parameter Space and Alternatives. One of the characteristic features of da ta mining is its capability of generating different results and models by manipulating a limited set of parameters. This is common to all methods and can be seen as both an advantage and a limitation. It is an advantage in that the necessary flexibility is given to create alternatives and adapt to different analytic goals. But, it is also a big limitation in terms of interaction, in that setting th e parameters of a mining algorithm is often perceived by the user as an  X  X soteric X  activity in which the relation between actions and resu lts is not evident. Even more problematic, when alternative models are constructed, is extremely complicated to compare them in the space of a single user interface. Visualization in our opinion has the power to bridge these gaps by: 1) providing means to more directly represent the connection between parameters and results; 2) allowing for visualization structures that permit the comparison of alternative results. Parameter space visualization is, to the best of our knowledge, a totally unexplored and yet extremely needed research area. Ideally, by visualizing the parameter space it would be possible not only to understand the connection between parameter values and outcome but also to explore the  X  X ensitivity X  of certain parameters and their interaction. Comparison of alternative results is also related and interesting in that visualization has the power to provide the right tools to compare alternative visual abstractions; as demonstrated for instance by the success of the systems presented at the InfoVis 2003 contest on Pair Wise Comparison of Trees [22]. One system in our literature review partially supports this kind of comparison by generating different alternative results of a subspace clustering algorithm [14]. The user can see the results obtained through the variation of various parameters and choose the most interesting ones among the set of available results. But, unfortunately, the concept is not researched in depth or further generalized.
 Model-Data Linking. The models that mining algorithms create out of data are higher level data abstractions that permits to summarize complex relations out of large data. If from the one hand these abstractions facilitate data analysis and reduce the complexity of the original problem space, from the other hand the abstraction process creates a semantic gap. The abstractions often make it difficult to interpret the observed relations in terms of the original data space and the observed objects in terms of the application area. Most systems in our literature survey provide model representation, but very rarely they permit to drill down to the data level to link an observed relation to its underlying data. In some cases such a lack of connection between model and data can create relevant limitations in model understanding and trust building, and visualization is the ri ght tool to bridge this gap. One example is data clustering. Besi des the large provision of visual and interactive techniques to repres ent clustering results, it is very rare to find systems where the linkage between extracted clusters and data instances is made explic it by the visualization. And this is somewhat surprising in that th e goal of data clustering is not only to partition data in a set of homogeneous groups but also, and potentially more important, to characterize them in a way that their content can be described in terms of few data dimensions and values. A better connection be tween model and raw data is then useful also to spot relevant outliers, which can often triggers new analyses and lines of thought . Without such a capability the analyst is forced to base his reasoning only on abstractions, thus limiting the opportunities for serendi pitous discoveries and trust building. One notable example where such connection is implemented is the Hierarchical Clustering Explorer [23], where at each time the user can easily drill down form th e clustering tree up to a single data item in the original data table. V++ Projection M++ Model Presentation VM White-Box Integration Table 2  X  Summary of observed and suggested integrations of Having analyzed a wide spectrum of integrations between automatic and interactive methods as summarized in Table 2, we believe that one of the most in teresting and promising direction for future research is to achieve a full mixed-initiative KDD process where the human and the machine cooperate at the same level. As shown in Figure 9, w ith the suggested contributions presented in this article, visuali zation and data analysis, and as such humans and machines respectively, can both contribute throughout the whole KDD process. Humans and machines are complementary, and visualization and data mining should make use of the specificities of each. Humans are intuitive and have remarkable interpretation skills involving the analysis context and accumulated domain knowledge. They are good at getting the  X  X ig picture X  and at performing high level reasoning towards knowledge. Machines on the other hand are fast and reliable at computing data, and are less prone to errors. While humans are good at choosing modeling strategies through visualization, the machine is good at computing large amounts of data for projecting and reducing da ta. Machines can disclose and highlight all the patterns found automatically over data, humans can assign a meaning to them and keep only the most interesting ones, according to their knowledge of the data and its domain. Furthermore, human and machine can collaborate to build models, either coming from mining models or alternatively derived by humans through their perceptive and cognitive systems. At this stage visualization techniques can be particularly useful to bridge the gap between data and the ex tracted models. Finally, data mining techniques can be useful to support the validation of observed model or knowledge that humans can ultimately refine through interaction. To date, the only system that comes closer to the idea of a mixed-initiative KDD process is the one we mentioned above in White-Box Integration [13], where a decision tree can be constructed by alternating steps of human-based decisions and machine-based algorithmic steps. Visualizing Parameter Space &amp;
Alternatives Refinement Figure 9  X  With the suggested contributions presented in this article, visualization and data analysis both contribute throughout the whole KDD process. Figure 10 -Comparing mining and visualization analytic processes. Visualization and data mining are currently alternative methods to transform data into knowledge. Having said that, a legitimate question stands: are they just different recipes to cope with the same problems or do they differ in any substantial manner? We believe that answering this que stion is becoming of increasing importance as we attempt to get the most out of the two disciplines and create successful integrations like the one advocated in Visual Analytics. In Figure 10 we provide an extremely simplified model of the visualization (bottom) and mini ng (top) processes to put into relation the steps that transform data into knowledge. We have two main set of proce sses that we deem important to compare: from data to models and from models to hypotheses generation. From data to models In mining, data are transformed into a computational model through a mining process , whereas in visualization they are transformed into a visual model through a visual mapping process . The comparison of these two steps can lead to interesting questions and insight s. For instance, both mining and mapping require the definition of a schema (visual or functional) around which data is modeled. The definition of such a schema has a strong relationship with th e mental model the users have perspective they use in understanding the data. In visualization such a schema is notoriously flexible and can easily lead to the exploration of different views on data. Such flexibility is not common in automatic systems, where parameter setting is a quite cumbersome activity. Therefore one research question to explore is:  X  how can we transfer such flexibility into the mining process so that it becomes easier to explore alternative solutions?  X  On the other side, the mining process is notoriously robust and equipped with reliable methods to verify the quality and trustworthiness of the outcome. Therefore another pertinent question is:  X  how can we transfer such robustness and verification capabilities into visualization?  X  The integrations suggested in the previous section point to some potential solutions, but it is evident that there is a whole space of possibilities to explore. From models to hypotheses Continuing on our comparison between the two processes, we see that in mining the main user mental activity involved is the interpretation of the extracted model, whereas in visualization the main user X  X  activity concerns the visual extraction of data patterns from the screen. The output of a mining algorithm is some kind of formal abstraction of data; therefore it is necessary to provide an interface to understand the model, its relation to data, and its validity. Here its worth to point out that traditional data mining is often presented as simply not having an interface, but this is hardly true. Mining systems are not without an interface, they just provide simple and minimalistic interfaces, like results organized in a tabular fashion. The question therefore is not necessarily how to  X  X ttach X  and interface to a mining system, but rather how to make it more effective through visualization. From the visualization design point of view it is important to recognize the shift of mental activity from understanding and interpretation of a computational model to the extraction of visual patterns. One main question here is:  X  how can we provide effective visualizations to interpret, understand, and verify computational models?  X  Even if it is reasonable to believe that what we learned from data visualization will be easily applied to model visualization design, it X  X  important to recognize that model visualization is far less develope d and that new requirements or design challenges may emerge. For this reason, another relevant research question is:  X  is model visualization fundamentally different from data visualization in terms of visual metaphors, interaction techniques, and design solutions?  X  Finally, as we have noted in th e previous sections, the pattern extraction activity in the visualization process can be aided by automatic procedures as those found in the mining process. One last research question is therefore:  X  how can automatic data analysis support users more easily extract relevant and accurate patterns out of data?  X  So far, we have only discusse d one direction of the human-machine interface, that is, from the machine to the human. The opposite direction is often neglected but it is equally important because it permits to close the inte raction feedback loop. It is in fact the possibility to iterate over alternate phases of human perception and understanding of the current state and human actions to change state and devise alternatives that fuel the discovery and learning process both in mining and visualization. On a higher level this is also how the Sensemaking Theory describes how people make sense of information. As Pirolli and Card note in [24], the sense ma king process revolves around  X  X ne set of activities that cycle around finding information and another that cycles around making sense of the information X . Figure 11  X  The feedback loop in Knowledge Discovery. The grey boxes represent the two major stages at which humans can intervene . (*1) A model can be either computational or visual. (*2) Users tune parameters of the visualization or of the computational model, until they confirm their hypothesis.
 In our literature review, almost half of the papers do not propose or describe means to interact with the system and as such to intervene on the knowledge discovery process. In the 55 papers reviewed, the major interaction techniques found can be grouped in two categories depending on th e knowledge discovery step at which users can intervene, i.e., pre or post model creation, to change the schema or manipulate it respectively as illustrated on Figure 5. Changing the schema. Both in visualization and in data mining at any stage the user can decide to change the schema. In visualization changing the sche ma means changing the visual mapping in a way that data can be seen under a new perspective. In data mining it means reframing the problem so that it is represented under a new model; as when, for instance, moving the analysis from the generation of rule s to finding data clusters. This kind of activities is often neglected and yet it is very important because as the user X  X  mental model changes the tools must adapt in a way to reflect this change. The goodness of a data analysis system should be measured also in terms of this flexibility. This need of reframing problems unde r different schemes uncover a relevant gap in current tools. One of the biggest challenges in visualization is to find an appropria te visualization for the task at hand. Despite numerous efforts towa rds this direction, especially at the early stage of information visualization (e.g., in Jock MacKinlay X  X  work [25]), current tools offer very limited support. Automatic or semi-automatic me thods should be employed to help users find appropriate vi sual mappings or yet suggest possible alternatives. Manipulating and tuning the schema. Another user X  X  option to create alternative views or models is to change parameters within the context of a given schema. In visualization this is normally achieved by manipulating a view though interactions like: dynamic filtering, axes reordering, zoom &amp; pan, etc. In data mining it involves some form of pa rameter tuning, as when using different distance functions or num ber of desired groups in data clustering. This last function is of special interest in that visualization can be a powerful means to help users tune up their mining models. As we have alr eady discussed in Section 5 in  X  X isualizing Alternatives X , the us e of powerful visualization and interaction schemes could greatly improve the state of current tools. Of special interest is the study of efficient techniques that permit to understand how a model changes when one or more parameters change. In current t ools it is almost impossible to achieve this level of interaction. Not only the large majority of parameters are difficult to interpret but also the user is forced to go through a series of  X  X lind X  trial-and-error steps where the user changes some parameters, waits for the construction of the new model, evaluates the result and iterates over until he or she is satisfied. The work we have described here stems from the assumption that the fingerprint of Visual Analytics is the integration of automatic and interactive data analysis. Our belief is that this approach has the potential of not only uncovering new research directions but also of defining the very nature of Visual Analytics. Regarding this last point, however, we acknowledge that a whole set of new research approaches are needed. Instead of surveying the complementarities between data mining and infovis techniques, like we did in this survey, another useful approach would consist in studying the type of problems or applications which are best addressed by da ta mining or by visualization alone. In other words, not all problems are Visual Analytics problems and it is necessary to understand when Visual Analytics should not be used, as pointed out by Daniel Keim in [26]. Therefore our community is confr onted with tough questions like:  X  Are the problems addressed by dat a mining of a different class than problems addressed by infovis?  X  and  X  If they are different, why are they different?  X  or  X  When it is not advisable to use a Visual Analytics solution to a given problem?  X  Standard data mining problems are generally clearly defined, e.g. categorize data, find clusters, etc. Infovis techniques on the other hand support exploration and communication. The tasks supported by visualization are cl early open-ended and cannot be reduced to a single problem solving task. Rather than supporting problem solving, visual analy tics systems could rather support practitioners in understanding the nature of the data and in better defining the problem to be solved. We suggest that in the future, the community tries to categorize problems for which data mining is perfectly suited, and reversely problems for which using visua lization, and thus involving humans, is mandatory. This could, hopefully, lead towards the definition of new contests in wh ich both infovis and data mining practitioners can compete. Despite our effort to produce a meaningful literature survey and to extract useful indication out of it, we believe it is important to highlight and acknowledge some limitations of this work. The literature we have analyzed, though useful, is far from being a full survey. We decided to use a number of papers that could be analyzed in a relative short time by the two authors. It can be considered a large enough sample to draw meaningful trends, explore potential extensions, and highlight pertinent research questions. As a consequence we decided not to draw any statistics out of our study. The literature contains some hand-made categorizations that could have been used to further categorize the techniques and depict some additional trends out of it. We postpone this task to later works. Finally, it X  X  important to take into account that a large part of this paper is the product of subjectiv e indications stemming from what we believed worth to extract from the literature. Nonetheless, we believe that our analysis and guidelines can highlight hidden patterns and stimulate further resear ch on important issues in this cross-disciplinary topic. We plan to advance this work after having received sufficient feedback from the community. We want to explore in more details the problem of better de fining Visual Analytics. In particular, we want to investigate in more depth the characterization of visual anal ytics problems and understand what differentiates a visual analytic s problem from other types of problems. We have presented a literature review on the role of visualization and data mining in the knowledge discovery process. From the review we have generated a seri es of classes through which we have categorized the collected papers: the knowledge discovery step it supports, whether it is interactive or not, the major mining and visualization techniques used, et c. In particular, in regards to the aim of this paper, we classified the paper according to three major categories indicating which approach drives the knowledge discovery: computationally enha nced visualization systems, visually enhanced data mining syst ems, and integrated visual and mining systems. This categorization highlight s some observed patterns and suggests potential extensions wh ich are not present in the considered literature. For instance, in order to enhance the standard visualization process, we believe data mining techniques could support visual model buildi ng to go beyond simple pattern detection. Further, mi ning techniques could be also used to verify and assess the quality of patterns de tected by users. Reversely, visualization could enhance the da ta mining process to visualize modeling alternatives, and to understand modeling results through a better model-data linking and presentation. In addition to these suggestions, the article provides a series of higher level reflections on the analysis process as it happens in visualization and data mining. These reflections suggest new perspective on the role of visualization and mining in the data analysis process and potential areas of investigation towards a better integration of both. In particular, this study suggests improving the human machine interaction through a better consideration of the feedback loop so that users can intervene at different levels of the knowledge discovery process, to change and manipulate the schema respectively. [1] J.A. Fails and J. Olsen,  X  X nteractive machine learning, X  IUI [2] M. Ware, E. Frank, G. Holm es, M. Hall, and I.H. Witten, [3] J.J. Thomas and K.A. Cook, Illuminating the path: The [4] D.A. Keim, F. Mansmann, J. Schneidewind, J. Thomas, [5] M.O. Ward,  X  X  taxonomy of glyph placement strategies [6] A. Morrison, G. Ross, and M. Chalmers,  X  X ast [7] P. Yang,  X  X nteractive Hier archical Dimension Ordering, [8] W. Peng, M.O. Ward, and E.A. Rundensteiner,  X  X lutter [9] J. Heer and D. Boyd,  X  X izster: Visualizing online social [10] J. Johansson, P. Ljung, M. Jern, and M. Cooper, [11] A. Jakulin, M. Mo X ina, J. De m X ar, I. Bratko, and B. Zupan, [12] Pak Chung Wong, W. Cowley, H. Foote, E. Jurrus, and J. [13] M. Ankerst, M. Ester, and H. Kriegel,  X  X owards an [14] E. M X ller, I. Assent, R. Kr ieger, T. Jansen, and T. Seidl, [15] S.T. Teoh and K. Ma,  X  X aintingClass: interactive [16] M. Ankerst, C. Elsen, M. Ester, and H. Kriegel,  X  X isual [17] Q. Cui and J. Yang,  X  X eas uring Data Abstraction Quality [18] D. Yang, Z. Xie, E.A. Rundensteiner, and M.O. Ward, [19] G. Ellis and A. Dix,  X  X ensity control through random [20] E. Bertini and G. Santucci,  X  X ive chance a chance: [21] R.A. Amar, J.T. Stasko,  X  X nowledge Precepts for Design [22] C. Plaisant, J. Fekete, and G. Grinstein,  X  X romoting [23] J. Seo and B. Shneid erman,  X  X  Rank-by-Feature [24] P. Pirolli and S. Card,  X  X he sensemaking process and [25] J. Mackinlay,  X  X utomating the design of graphical [26] D. Keim,  X  X isual Analytics: Combining Automated 
