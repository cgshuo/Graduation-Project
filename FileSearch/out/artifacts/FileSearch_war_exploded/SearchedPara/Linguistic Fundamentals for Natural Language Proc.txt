
Emily M. Bender (University of Washington) Morgan &amp; Claypool (Synthesis Lectures on Human Language Technologies, edited by
Graeme Hirst, volume 20), 2013, xvii+166 pp; paperbound, ISBN 978-1-62705-011-1, $40.00; e-book, ISBN 978-1-62705-012-8, $30.00 or by subscription Reviewed by Chris Dyer Carnegie Mellon University
The phenomenal success of machine learnin g in engineering natural language applica-tions has led to a curious situation: Natural language processing practitioners who were trained in the last 15 to 20 years may have established a quite successful career in this area with only a haphazard knowledge of the science of natural languages. The premise of the new volume by Emily M. Bender is that greater awareness of linguistics will enable continued technical progress, particularly as language applications are required to perform more intelligent pr ocessing in more languages. survey of the morphological and syntactic means by which different languages ex-press meaning, anchored by clear and effective examples from typologically diverse languages. Eschewing theorizing to stay close to data permits a remarkably wide range of linguistic phenomena to be covered, and it is this that is the book X  X  greatest strength.
However, in a few places, a seemingly arbitr ary theoretical perspective is assumed rather more tacitly than one might hope, with few hints as to alternative analyses (e.g., see the following remarks about parts of speech in Chapter 6). Furthermore, a bit more theoretical scaffolding could have mad e the presentation more succinct in places (e.g., Chapter 7 X  X  excellent discussion of heads, arguments, and adjuncts could have been more precise with a basic logical calcul us). Finally, although theoretical squabbles can be off-putting to outsiders, theoretical d iversity can have practical benefits, partic-ularly in a field as omnivorous as NLP. For example, while theorists might disagree about whether morphophonology is best modeled with systems of rewrite rules (e.g., SPE) or constraint satisfaction (e.g., Optimality Theory) (Chomsky and Halle 1968;
Prince and Smolensky 2004), each suggests a distinct computational instantiation with different challenges and opportunities. Fo r such reasons, more discussion of theory would not have been unwelcome. This sligh t objection aside, the book is an excellent introduction to the diversity of linguisti c representations that NLP must eventually contend with.
 phology; the second, syntax), spread over 100 numbered topics.
 ogy and syntax from bag-of-words models. It lays out the premise that knowledge of linguistic structure can guide engineers in profitable directions by facilitating error analysis and feature engineering. The notio n of bounded variation is introduced: the idea that while languages exhibit diversit y in how they pair sound and meaning, this variation is subject to limits, and that different languages can have similarities due to areal, genetic, and typological relatedne ss. A brief survey of the genetic taxonomy of the world X  X  languages is given and the number of speakers they have X  X s well as the striking difference in distributions of the languages in the NLP literature.
 internal structure of words and how they are realized in text and speech. Simple
English examples motivate the discussion, but more exotic nonconcatenative processes in Semitic languages and infixation examples from Lakhota emphasize phenomena that may be unfamiliar to those with experience only with Indo-European languages. The conventional tripartite distinction of root s and derivational and inflectional affixes is presented to organize the kinds of meaning/fu nction changes characteristic of morpho-logical processes, although co mpounding and cliticization X  X hich fit less neatly into this taxonomy X  X re also discussed. Because syntax and semantics were only briefly mentioned in the Introduction, the extensive forward references to the related material in the later chapters were quite helpful for c larifying terms, making the e-book version particularly convenient.
 that different languages encode with morphology. Phenomena covered include func-tions applying to the verbal domain, inclu ding tense, mood, and aspect, negation, evidentiality; the nominal domain, includi ng person, number, a nd gender, ca se, defi-niteness, and possession; and various common agreement processes.
 focus on how syntax is used to combine w ords to form an unbounded number of sentences whose meaning is determined compositionally. Chapter 5 introduces the dis-tinction between grammaticality of sentenc es and how syntactic structure determines their meanings, and Chapter 6 introduces parts of speech as clusters of distributional regularities of words and phrases in grammatical sentences. The fact that discussion of grammaticality proceeds almost exclusively in terms of POS X  X  familiar construct to anyone working in NLP, but one that looks quite different in many theories of syntax (Steedman 2000; Stabler 1997) X  X s a shortcoming.
 phrases that relate to each other either as arguments (which semantically complete the meaning of a predicate) or adjunction (which introduces additional predicates).
Diagnostics for distinguishing heads and dependents as well as arguments and adjuncts are given, together with clear examples of their application, and common mistakes (e.g., using optionality as a test of argumenthood or assuming that only verbs can select arguments) are covered. A particularly useful part of this chapter is a discussion of lexical resources (FrameNet, ProbBank) and how they relate to the concepts being discussed.
 entirely successful attempts to create universa l inventories of thematic roles, ultimately demonstrating that syntactic roles are less idiosyncratic (at least within single lan-guages), and capture many generalizations useful for semantic analysis. A discussion of cross-linguistic properties of subjects a nd the distinction between core and oblique arguments follows. Three important sections discuss the subtle and often confusing dis-tinctions between syntactic and semantic arguments with effective examples. Although most of this chapter focuses on English examp les, various morphological strategies for marking grammatical functions is discussed. 154 that can introduce divergences between syntactic and semantic relationships. Because such divergences underlie many constructi ons with considerable value in NLP (e.g., wh-questions in English) and directly cha llenge the simplifying assumption of trans-parency between syntax and semantics, it is fortunate that this section goes into con-siderable detail, covering phenomena includi ng passivization, dative shift, expletives, raising, control, and various kinds of long distance movement, as well as a good discussion of phenomena found in other languages, such as causative morphology and discontinuous constituents.
 tational resources (morphological analyzer s, parsers, typological atlases) that encode linguistic knowledge.

NLP researchers orient themselves with respect to phenomena they will encounter as their applications push into new languages and strive for deeper automated un-derstanding of language. The tension betw een the science of linguistics and natural language engineering and the resulting missed opportunities has been remarked upon in these pages recently (Wintner 2009), and we should applaud this successful effort to find common ground.
 References
