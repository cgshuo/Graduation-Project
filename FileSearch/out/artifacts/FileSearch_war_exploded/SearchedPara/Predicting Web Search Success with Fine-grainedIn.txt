 Detecting and predicting searcher success is essential for automati-cally evaluating and improving Web search engine performance. In the past, Web searcher behavior data, such as result clickthrough, dwell time, and query reformulation sequences, have been success-fully used for a variety of tasks, including prediction of success in a search session. However, the effectiveness of the previous ap-proaches has been limited, as they tend to ignore how searchers actually view and interact with the visited pages. We show that fine-grained interactions, such as mouse cursor movements and scrolling, provide additional clues for better predicting success of a search session as a whole. To this end, we identify patterns of ex-amination and interaction behavior that correspond to search suc-cess, and design a new Fine-grained Session Behavior (FSB) model to capture these patterns. Our experimental results show that FSB is significantly more effective than the state-of-the-art approaches that do not use these additional interaction data.
 H.3.3 [ Information Systems ]: Information Storage and Retrieval Design, Experimentation, Human Factors success prediction, search session, mouse cursor analysis
Detecting and predicting searcher success is essential for au-tomatically evaluating and improving Web search engine perfor-mance at scale [7]. Furthermore, real-time intervention and assis-tance could be provided if lack of success could be predicted earlier in the search session [2, 6].

While previous research has made great use of search behav-ior data such as result clickthrough, dwell time and sequences of searches [7, 2, 6, 1] for predicting searcher success, the effective-ness of the existing models is largely limited as they are agnostic about how users actually view and interact with the visited pages. For example, seeing a search session with a high result clickthrough rate, existing methods would typically consider that the searcher is very likely to be successful in her search. However, the click-through information should be coupled with time information to have a better understanding of the search success  X  for example, a shorter time before click may be indicative of higher confidence in the perceived relevance about the search result while shorter time spent on the landing page might suggest that the searcher found out that the document was actually not relevant.

Yet, the dwell time does not provide a full picture  X  spending a long time on a landing page might suggest that the searcher was struggling and could not find the relevant information if she was actually scanning instead of reading during the stay [5]. Some-times, spending shorter time on a landing page might suggest that the searcher was actually successful if she quickly found the needed information. Similarly, spending some time carefully reading a re-sult snippet before clicking on it is different from quickly scanning the whole search result page within the similar amount of time  X  in the latter case, the user appears to be less satisfied with the re-turned results and is less likely to be successful. Based on the time information alone, such search sessions might be considered suc-cessful and thus the search engine would not be able to improve on them; or, in an on-line setting, the search engine would not pro-vide additional help when the searcher is struggling and becoming frustrated. Figure 1: Example mouse cursor heat maps: (a) -search result page in a successful search session; (b) -search result page in a unsuccessful search session. ments and scrolling behavior on a Web page have shown to be valu-able signals in inferring viewing behavior (e.g., [12, 4, 10]) and searcher preferences (e.g., [9, 5, 8, 13]). In this paper, we pro-pose to model these richer observations to improve the estimation of searcher success. Figure 1 shows the mouse cursor heat maps overlaid on the visited search engine result pages from a success-ful and an unsuccessful search sessions respectively. As we can see, the mouse cursor positions in the unsuccessful session (Figure 1(b)) are more spread-out than in the successful session (Figure 1(a)) and spread to the lower part of the result page, suggesting that when the searcher examines multiple search results (especially the lower-ranked ones) before click, she is more likely to be unsuccessful in finding the needed information. Most closely related to our work, Guo and Agichtein [5] found that the fine-grained post-click be-havior correspond to different viewing patterns and are indicative of document relevance. Complementary to previous efforts, this paper is the first to study the association between the Web search success and the fine-grained behavior such as cursor movements, and the first to develop a predictive model, FSB, that jointly mod-els the session-level behavior patterns on both search engine result pages and pages on the search trails [14]. As the rest of the paper demonstrates, FSB achieves significant improvements for predict-ing search success over the state-of-the-art methods. In this section, we describe our proposed Fine-grained Session Behavior (FSB) features to capture the page examination patterns that could be indicative of search success. In addition, we also include features from the queries, clicks and dwell time. The brief descriptions about some of the FSB features along their correlation with the success labels (Section 4.1) are reported in Tables 1, 2, and 3 and expanded below. Note that the features in the fine-grained interaction groups, namely, cursor and scroll, are first computed for each page view and then aggregated over the entire search session. These two groups can be further divided into pre-click and post-click sub feature groups, corresponding to behavior on the search engine result pages and the behavior on the pages in the search trail. Additional details about the full list of features in the cursor and scroll groups will be available online due to the space constraints. Table 1: Coarse-grained behavior feature descriptions and Pearson X  X  correlations with success ratings (** indicates statis-tical significance at p &lt; .01 level; * indicates statistical signifi-cance at p &lt; .05 level).
 Query Features Query features derived from the query string it-self, include the query length in words and characters, average number of characters of query terms, the number of submitted queries, SERP views, and unique queries. Intuitively, the longer the query, the more likely the task is difficult and the searcher ends up unsuc-cessful. On a session-level, the larger the number of queries users have to submit the more likely that the user is struggling. Notice the subtle difference between submitting a query and viewing a SERP  X  one query might correspond to multiple SERP views. The former can be captured from server-side logs while the latter can only be obtained with a client-side instrumentation.
 Click Features Click features include the number of clicks and clickthrough rate (over queries and SERPs). Clickthrough gener-ally is an indicator of success as searchers click on a document when they think that the document can satisfy their information needs. However, a large number of clicks, especially when paired with an even larger number of submitted queries, might indicate that the clicked documents are actually not relevant and the search goal is unsuccessful. Here, the clickthrough rate may provide ad-ditional evidence about search success.
 Time-related Features We consider both the time users spend on the SERP and the pages on the search trail. In the literature [3, 7, 5], the former is referred as  X  X eliberation time X  while the latter is referred as  X  X well time X . Usually, these measurements of time are defined as the intervals, in seconds, between the time the page is loaded and the time the searcher leaves the page. To aggregate the time information across multiple page views in the session, we follow previous research [7, 6] and compute the total time span during the session, averaging time spent on different types of pages, and the ratio of clicks that result in SAT (dwell time  X  30 seconds) and DSAT (dwell time  X  10 seconds) [3].
 Table 2: Sample fine-grained cursor feature descriptions and Pearson X  X  correlations with success ratings (** indicates statis-tical significance at p &lt; .01 level; * indicates statistical signifi-cance at p &lt; .05 level).

Recently, fine-grained interactions such as mouse cursor move-Cursor Movement Features As suggested in the previous section, characteristics of cursor movements such as speed and range could indicate the searcher X  X  reading behavior, and consequently the suc-cess of the search goal. For example, on a landing page, low speeds may indicate that the searcher was carefully  X  X eading X , while a long vertical range may indicate that the searcher found the document relevant and was willing to explore. We measure the number and frequency of the cursor movements, distance, speed, and the range the mouse cursor travels in pixels (both overall, and its horizontal and vertical components), as well as the minima and maxima of horizontal and vertical cursor coordinates.
 Table 3: Sample fine-grained scroll feature descriptions and Pearson X  X  correlations with success ratings (** indicates statis-tical significance at p &lt; .01 level; * indicates statistical signifi-cance at p &lt; .05 level).
 Vertical Scrolling Features In addition to modeling the overall amount of scrolling, we also model the frequency and speed of scrolling behavior, as well as the overall scroll distance and range in pixels, following [5]. The intuition behind is to capture the searcher X  X  examination patterns. For example, high frequency and speed of scrolling may indicate that the searcher was  X  X canning X  or skipping parts of the document, while a moderate range of scrolling with low speeds may indicate that the searcher was  X  X eading X . Aggregation of Interaction Features We explore different strate-gies in aggregating the page-level features, including computing the mean, median, minimum, and maximum of all the page views and counting the number of page views that meet some specific requirements. The four statistics are more generic treatments of aggregation, with the mean or average more frequently used, me-dian more robust to outliers, and minimum and maximum capture the extreme behavior. The threshold-based counting aggregation is more customized towards individual features, which may result in more effective predictors when appropriately applied. This ap-proach may require a deeper understanding of each individual fea-ture to define meaningful thresholds. We will discuss the different strategies in more depth in Section 4.1 and compare their effective-ness.

Note that aggregation over an entire section might be problem-atic when a search session consists of multiple sub-goals, in which case the searcher behavior may exhibit larger variations. To ad-dress this issue, search goal boundary detection algorithms (e.g., [11, 7]) can be applied to ensure aggregation is over single search goal. Alternatively, one may also consider aggregation over each search trail [14], which may also reduce the variance that comes from different types of pages. In this paper, our aggregation is on a single search goal as each session in our dataset consists of one single search goal (Section 3). While further improvement may be possible (e.g., through trail-level aggregation), as we show later, this goal-based aggregation formalism already results in effective models (Section 4).
The data set we used for our experiments, which has hundreds of search tasks and explicit relevance judgements of visited Web pages, is from a user study conducted by researchers at the Uni-versity of Massachusetts [2]. The usage data of the participants was tracked, containing the URLs the searchers visited, the fine-grained interactions with the browsed pages, such as clicks, cursor movements, and scrolling, the time-stamp of each page view and interaction was also recorded. The search tasks in the user study were designed to be representative of Web search and difficult to solve with a search engine (i.e., the answer was not easily found on a single page). This is particularly valuable as these more difficult and long-tailed search tasks are the main challenge for the state-of-the-art search engines, and an accurate success prediction algorithm would enable search engines to evaluate and improve performance in these search tasks at a large scale.

The original dataset is publicly available online 1 . Similarly, the processed data and source code for this paper is available at http: //ir.mathcs.emory.edu/data/CIKM2012/ . Next, we de-scribe the details of the user study and the collected data (additional information can be found along with the original dataset). Explicit Judgements: Each time the participants completed a search task, they were asked the degree to which their information need of the task was satisfied during the entire search session on a five point scale ( X 1 X  indicates the search session  X  X id not satisfy the informa-tion need in any way X  and  X 5 X  indicates that the search session  X  X ompletely satisfied the information need X ).

We used this self-reported explicit judgement as our ground truth for search success. A total of 211 search tasks were completed and provided feedbacks from 30 participants, with 463 queries submit-ted and 711 pages visited.
In this section, we describe and discuss our experimental results and findings. We start with analyzing the association between each individual session feature and the explicit success judgements, and then move on to our results on success prediction, where we eval-uate each individual feature group and some combinations of the different feature groups.
We now discuss the association between each individual session feature and the explicit success judgements. Specifically, we com-puted Pearson X  X  Correlation for each feature and conducted statis-tical significant testing. The results are summarized in Tables 1, 2 and 3. We organize the discussions by feature groups and com-pare alternative session-level aggregation strategies and sources of evidence (e.g., pre-click vs. post-click) when appropriate. Query, Click, Time As we can see from Table 1, the average query length is negatively correlated with the session length, though not significant, while the number of submitted queries exhibits much stronger negative correlation of -0.522, confirming our intuition that the longer the queries the user had to submit and the larger http://ciir.cs.umass.edu/~hfeild/downloads. html the number of queries, the more likely that the user was struggling and more likely to fail.

The number of clicks turns out to be negatively correlated with search success, which may seem counter-intuitive as clickthrough is typically considered as a signal of finding relevant information. One explanation is that the large number of clicks may come from the large number of queries. Indeed, divided over the number of queries, the clickthrough rate measures results in positive correla-tions, with the ratio computed over SERP views much more signif-icant. This suggests benefits of client-side instrumentation.
As for the time measures, it turns out that the overall time span of a session exhibits the most significant correlation of -0.473, which makes sense as it characterizes the session length as the number of queries and clicks do. Somewhat surprisingly, the average dwell time on landing pages is negatively correlated with search success. One explanation is that as the task difficulty increases, users need to spend on average longer time to find the information on a page. The SAT and DSAT clickthrough rates, in contrast, match our in-tuitions and exhibit positive and negative correlations with success. However, the correlations are not significant, which may also be ex-plained by the fact that the search tasks in our dataset are relatively more challenging.
 Cursor Movements The analysis of this feature group is given in Table 2. For the simplicity of discussion, we only focus on an-alyzing the most discriminative feature of this group  X  maximum y coordinates and compare the different aggregation functions on this feature as well as two different sources of evidence, namely the pre-click behavior on search engine result pages (SERP) and the post-click behavior on the search trail pages.

For the SERPs, the averaging function for cursor ( avg_ymax_s ) appears to be most effective, which is substantially stronger than the deliberation time counterpart of cursor avg_time_s (Table 1). Interestingly, the minimum aggregation function ( min_ymax_s ) re-sults in a significant positive correlation of 0.163. Note that very small maximum y coordinate suggests abandonment of search re-sults and the minimum aggregation function of maximum y coor-dinate to some extent quantifies the likelihood of abandonment.
For the search trail pages, the averaging function ( avg_ymax_t ) only results in a moderate significant positive correlation of 0.179, which is stronger than its dwell time counter-part ( avg_time_s ) with a negative insignificant correlation of only -0.107 as shown in Ta-ble 1. Interestingly, the averaging function does not seem to be the most effective for the search trail pages. Instead, median function appears to be the most effective statistic, likely due to its robust-ness to outliers and larger variance. The best aggregation function for this feature turns out to be counting with meaningful thresholds. For example, the number of  X  X AT X  page views, whose maximum y coordinate is on or above 800 pixels ( num_high_ymax_t ), exhibits a substantially stronger correlation of 0.361. The gain is signifi-cant compared to its dwell time based counterpart ( satr_t ), whose correlation is only an insignificant 0.09. Similarly, the number DSAT page views, whose maximum y coordinate below 400 pix-els( num_high_ymax_t ) exhibits stronger correlation than its dwell time counterpart ( dsatr_t ). These observations match the finding in [5] that post-click cursor features such as maximum y coor-dinates have stronger association with relevance as compared to dwell time. However, as we haven seen, careful selection of the session-level aggregation functions could have significant impacts on the predictive power of such a page-level feature.
 Vertical Scrolling The analysis of this feature group is given in Ta-ble 3. Similar to the cursor feature group, we focus only on analyz-ing the most discriminative feature of this group  X  the scroll speed, to illustrate the differences in the various aggregation options as well as the patterns in pre-click and post-click pages. Overall, the correlations of different aggregations of sources of evidence all re-sult in negative correlations for scroll speed, while the correlations are stronger for SERPs than trail pages. This may be explained by the larger variance in the types of trail pages  X  some of which may be shorter and do not require scrolling. As a result, scrolling may be more sparse and less reliable than the cursor features such as maximum y coordinate, as suggested by the overall weaker as-sociations for search trail pages. In contrast, the correlations for scroll speeds on SERPs are much stronger with mean and maxi-mum aggregation functions, resulting in significant correlations of -0.318 and -0.331, which is likely attributable to the relative fixed layout of search engine result pages, where user behavior tend to have smaller variance.
Now we report our results and findings in predicting search suc-cess explicitly judged by the users using the different groups of features (Section 2). We formulate the success prediction prob-lem as classification, and consider a search session with explicit success judgements (Section 3) equal to or larger than 4 as suc-cessful and unsuccessful otherwise. This definition of search suc-cess corresponds to the Q + R +  X  A + V ? type of success according to the Query-Result-Answer-Verification (QRAV) model proposed by Ageev et al. [1], where a participant was satisfied with her search session and believed that she found an correct answer, without a verification whether the submitted answer was actually accurate.
The underlying success prediction algorithm used was logistic regression, which is a widely used generalized linear model for classification [2, 6], where the predictors can take different forms, such as continuous, discrete, dichotomous, or a mix of these. The response variable, in our case, whether the search goal was suc-cessful or unsuccessful , is not a linear function of the predictors but a logit transformation of their linear combination. Logistic re-gression has the advantages of simple implementation, good inter-pretability, and time-efficiency in training at scale.

For training and testing, we used 10-fold cross-validation with 100 randomized experimental runs. We evaluated our full model FSB 2 , its four single feature group components: query , click , time , and cursor . We also evaluated the cursor_serp and cursor_trail sub-groups, which are based on the cursor feature group computed for the SERPs and trail pages respectively. Two baselines consid-ered are a na X ve Majority Baseline ( MB ) that always guesses the majority class successful and a state-of-the-art baseline QCT model trained on the Query, Click and Time feature groups. Feature group ablation analysis was also conducted by removing the single fea-ture groups one at a time. Finally, we compare the three selected aggregation functions, namely, average ( avg ), median ( med ), and the threshold based counting function ( thres ). We report accuracy and weighted averages of Precision, Recall, and F1-measure over the two search success classes.
 Single Feature Groups : The results are summarized in Table 4. The differences between different methods are statistically signif-icant at .05 level under paired t-test except the difference between cursor_serp and QCT and the difference between cursor_trail and click . As we can see, our full model FSB significantly outperforms the two baselines as well as all the single feature groups. The cur-sor group performs the best among all the single feature groups and is the only single feature group that outperforms both of the two
Some features such as the scroll group are excluded in feature selection. Details are available online. baselines. The remaining single feature groups outperform the MB baseline but underperform the QCT baseline. Among the two cur-sor subgroups, the cursor_serp group is significantly more predic-tive than the cursor_trail group, which may be due to the more se-vere data sparsity and larger variance lies in the different search trail pages compared to the SERPs. Nevertheless, the combined feature group cursor significantly outperforms each of the two sources of evidence individually, suggesting the two are complementary. Table 4: Accuracy, Precision, Recall and F1-measure for the full FSB model, the single feature groups, and the QCT, MB baselines. The percentage of improvement over the QCT base-line is reported for the F1-measure.
 Feature Group Ablation : The results are summarized in Table 5. The differences between the full model FSB and all the feature ab-lation methods are significant at .05 level under paired t-test except for FSB-query , suggesting all the feature groups except the query group contribute significantly to the full model even when other feature groups are presented. The largest decrease comes from re-moving the cursor feature group. Interestingly, even though cur-sor_serp seems to contribute more than the cursor_trail subgroup, the contributions from both of the two subgroups are statistically significant as supported by the fact that FSB-cursor significantly underperforms FSB-cursor_serp and FSB-cursor_trail .
 Table 5: Accuracy, Precision, Recall and F1-measure for fea-ture group ablation. The difference compared to the FSB full model is reported for the F1-measure.
 Aggregation Functions : The results are summarized in Table 6. The differences between different methods are statistically signif-icant at .05 level under paired t-test. As we can see, all the single aggregation functions underperform the full FSB model that uti-lizes all the three functions. Among the individual functions, FSB (thres) performs the best, followed by FSB (med) and FSB (avg) , showing the importance in selecting the aggregation functions.
In this paper we introduce a new model for representing the searchers X  fine-grained session behavior (FSB) that captures not only information about the queries, clicks and time, but also fine-Table 6: Accuracy, Precision, Recall and F1-measure for indi-vidual aggregation functions. The difference compared to the FSB full model is reported for the F1-measure. grained interactions both before and after clicking on a search re-sult, such as cursor movements. To our knowledge, FSB is the first successful attempt to exploit and aggregate such  X  X ow-level X  behav-ioral signals on the session-level, aiming to predict search success.
Our experimental results show that these behavioral signals in-deed correlate with searchers X  explicit judgements of search suc-cess, and provide additional valuable information beyond queries, clicks and the amount of time users spend on the pages in a search session. We found that the different sources of evidence (i.e. be-havior before and after a click) carry valuable complementary in-formation about search success and that the feature aggregation choice was crucial. In combination, these signals enable FSB to exhibit significant improvement of predicting search success over the state-of-the-art methods.
 ACKNOWLEDGMENTS This work was supported by the National Science Foundation grant IIS-1018321. The authors also thank Henry Feild for sharing the user study data.
