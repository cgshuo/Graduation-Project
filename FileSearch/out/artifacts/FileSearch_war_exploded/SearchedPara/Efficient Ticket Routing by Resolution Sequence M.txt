 IT problem management calls for quick identification of re-solvers to reported problems. The efficiency of this pro-cess highly depends on ticket routing X  X ransferring problem ticket among various expert groups in search of the right re-solver to the ticket. To achieve efficient ticket routing, wise decision needs to be made at each step of ticket transfer to determine which expert group is likely to be, or to lead to the resolver.

In this paper, we address the possibility of improving ticket routing efficiency by mining ticket resolution sequences alone, without accessing ticket content. To demonstrate this possibility, a Markov model is developed to statistically cap-ture the right decisions that have been made toward problem resolution, where the order of the Markov model is care-fully chosen according to the conditional entropy obtained from ticket data. We also design a search algorithm, called Variable-order Multiple active State search (VMS), that gen-erates ticket transfer recommendations based on our model. The proposed framework is evaluated on a large set of real-world problem tickets. The results demonstrate that VMS significantly improves human decisions: Problem resolvers can often be identified with fewer ticket transfers. H2.8[ Database Applications ]: data mining Algorithm, Design Markov model, Sequence mining, Workflow mining and op-timization
Problem management is a key task in managing today X  X  enterprise computing environment, a multi-billion-dollar busi-ness. Its goal is to quickly resolve the reported problems, e.g., hardware failures, software bugs, application errors, etc., hence minimize the disruptions caused to business oper-ations. Problem management is typically conducted by the helpdesk and IT support staff members of an enterprise. The process of problem management is reflected by the workflows of problem tickets. A ticket is opened as soon as a problem is reported. Then, it is routed among various expert groups until the root cause of the problem is identified by a resolver group . Finally, the resolver group solves the problem and closes the ticket. Table 1 shows a sample ticket workflow, in which the ticket was routed among multiple groups before it was solved. The efficiency of identifying the problem re-solver depends on ticket routing, which decides, if the group currently holding the ticket cannot solve the problem, which group the ticket should be transferred to next.
 Today, ticket routing is usually driven by expert decisions. It is not uncommon that due to human error or inexperience a ticket is mistakenly transferred to a group that cannot solve the problem, which might lead to a long and ineffi-cient routing sequence. In such cases, not only resources are wasted, but also it would take longer time to close tickets, causing customer dissatisfaction.

In this paper, we propose a mechanism that can improve the overall efficiency of ticket routing, measured by the Mean number of Steps To Resolve (MSTR) the tickets. The first question is what information in ticket data can be used to improve MSTR. Typically, a problem ticket contains two types of information: (1) ticket content that includes prob-lem description and diagnostic data, (2) resolution sequence that shows how it was routed before it reached the resolver group. In the sample ticket shown in Table 1, the entries compose the ticket content, while the extracted group names
SMRDX , SSDSISAP , ASWWCUST , SSSAPHWOA form its resolution sequence. Our study in this paper focuses on the resolu-tion sequences only. As shown later, mining the resolution sequences alone can significantly improve the efficiency of ticket routing and identify resolver groups more quickly  X  a surprisingly encouraging discovery.

Our strategy is to mine resolution sequences of solved tick-ets, which could guide the routing decisions for new tickets. With in-depth analysis, we find that in many cases, long res-olution sequences were results of a few local mis-routing deci-sions, while the majority of the local ticket transfer decisions were logically correct. Intuitively, for a specific type of prob-lems, these local ticket transfer decisions reflect the func-tional relationships between expert groups. For instance, if group A often transfers AIX tickets to group B , this implies if A cannot resolve an AIX problem, B is very likely to be able to solve it. Based on this intuition, we build a model to capture these relationships by mining transfer decisions recorded in the solved tickets. The model is then applied to guide future ticket transfer toward correct decisions. Our method is based on Markov models (or Markov chains). Let each Markov state represents a group, the transition probabilities between these states capture the local deci-sions, i.e. the likelihood of a group to be a transfer target, given the previous groups that have processed the ticket. There are several challenges in applying Markov model in this problem. For instances, what kind of group transitions should be used to build the model? Shall we use the tran-sitions from the previous groups to the resolver group, or use all intermediate group transitions? What should be the optimal order of the derived Markov model? How should the model be used to guide ticket transfer? In our study, we investigate these issues and design a search algorithm that generates good ticket routing recommendations based on the learned models.

In summary, our contributions in this paper include:
The remainder of this paper is organized as follows. We first formulate the problem in Section 2. Then we present the proposed Markov model that captures the ticket trans-fer decisions in Section 3, and algorithms that search for resolver groups based on the derived model in Section 4. In Section 5, we evaluate the effectiveness and robustness of the proposed approach. The related works are reviewed in Sec-tion 6. Finally, Section 7 concludes the paper and discusses future directions of this study.
A problem ticket can be represented by a tuple with two components, (  X , G ( k ) ), where  X  is the ticket content and G k ) is the routing sequence. A ticket is routed to find the group that can potentially solve the problem. Let G = { g 1 ,g 2 ,...,g n } be the set of all expert groups. The routing sequence of a ticket can be written as G ( k ) = g (1) ,g ( g i )  X  X  ), in which a ticket is first issued to g (1) , then trans-ferred in the order of g (2) ,g (3) ,...,g ( k ) .A step in G ticket transfer from one group to another. A ticket (  X , G is open if none of the groups in G ( k ) can resolve it. Corre-spondingly, a ticket is closed if the last group in G ( k g ) , solved the problem, and in this case, the routing se-quence is called a resolution sequence .

Given m ticket resolution sequences { G i } i =1 ,...,m ,wemea-sure the efficiency of a ticket routing system using the Mean number of Steps To Resolve (MSTR): Since the more steps involved in ticket resolution, the longer delay it will cause for the ticket to be closed, our goal is to minimize Eq. (1).

We approach this problem by mining the ticket resolution sequences G ( k ) and address the following question: Is it possible to reduce MSTR by mining ticket resolution sequence G ( k ) alone without accessing ticket content  X  ? As we show later in the paper, although seemingly counter-intuitive, the answer is positive. Why? Because if two tick-ets share the similar resolution processes in the past, likely they are related to similar problems. As a result, they might share the similar resolution routes toward the end!
Formally, given a ticket resolution history database, D S {
G 1 ,G 2 ,...,G n } , we develop a framework to mine the res-olution sequences in D S and make routing recommendation on open tickets in a testing ticket dataset T S in order to minimize their MSTRs. For tickets in T S , our system is only provided with initial routing information, i.e., the first group that the ticket was assigned to by the helpdesk.
In this section, we introduce the Markov model that we use to capture the ticket transfer decisions embedded in ticket resolution sequences.
Markov models are widely use d to capture the temporal dependencies between the states of a system. A process is considered Markovian if at any time point, the probability of the process in the current state is solely dependent on its previous states. Given such property, Markov model fits naturally with our problem here. In our problem setting, each group can be modeled as a state. Assume there are N expert groups, G = { g i } ,i  X  X  1 , 2 ,...,N } ,towhicha ticket can be transferred. A k th-order Markov model gives the probability of the ticket being transferred to group g the next step, P ( g = g i | G ( k ) ) ,g i  X  X  .

In ticket routing, decisions are often based on past group transfers irrespective of the order of transfer. In other words, the decision maker typically looks at all history updates generated by the past groups, rather than in which order these updates were generated. This observation indicates that, if we use S ( k ) to denote the set of groups in G P ( g = g i | S ( k ) ) ,g i  X  X  . Therefore, unless otherwise stated, we will refer to this generalized model as our Markov model (in some literatures, this is called quasi-Markov model [13]).
Using historical ticket resolution sequences, we can find the number of instances with a set of group transfers, S ( denoted as N ( S ( k ) ), as well as the number of instances that a ticket is transferred to group g i after being processed by S k ) , denoted as N ( g i ,S ( k ) ). We can estimate P ( g
P ( g i | S ( k ) )= N ( g i ,S ( k ) ) /N ( S ( k ) )if N ( S ( S ( k ) ,g i ) is called a recognizable group transfer pattern , which is related to sequential patterns [2] except that it does not have minimum frequency requirement. Note that if the same group transfer pattern o ccurred multiple times in a sin-gle ticket, we only count it once in N ( S ( k ) )and N ( g This is to avoid the bias caused by repeated group transfers in a single ticket.
An open problem is whether we should build the model using (1) only the transfer patterns ending with the resolver group, or (2) all transfer patterns including the intermediate transfer steps. For example, for a resolution sequence A , B , C , approach (1) only considers the transfer patterns ending with the resolver group C when building the model, i.e. A , C , B , C ,and A , B , C ; while approach (2) considers all transfer patterns, which additionally include A , B .
In approach (1), we define I (  X , g i )=1ifgroup g i can solve problem  X  , and 0 otherwise. Let P ( I (  X , g i ) | g (1) be the probability that problem  X  cannot be solved by groups g (1) ,g (2) ,...g ( k ) ,butcanbesolvedby g i .Inthiscase, Eq. (2) is evaluated as
In approach (2), we use all intermediate transfer steps in ticket resolution sequences to build the model. We define J (  X , g i ) = 1 if the problem  X  should go through group g (i.e., the problem can be either solved or correctly routed by g ), and 0 otherwise. Then, Eq. (2) is evaluated as
The intuition of Eq. (4) is that although unwise decisions do exist in the training data, most of the ticket transfer de-cisions were helpful in identifying the right resolver groups. If our model accurately captures these decisions, when a new ticket emerges, our model will statistically point out the right direction of ticket routing.

As verified in the experimental study presented in Sec-tion 5, approach (2) has two advantages compared with ap-proach (1). First, in some cases, it is necessary to transfer tickets to certain non-resolver or intermediate groups. These groups are typically the  X  X istributor X  of the tickets who have a good knowledge of how to match tickets with the exper-tise of a subset of groups. If group g i is a distributor group, the approach (2) will be able to capture it, as P ( g i | would tend to be greater than the transition probabilities to other groups. Second, in cases where no enough ticket data is available to build robust probabilities from Eq. (3), using Eq. (4) instead can result in more training instances, hence can potentially avoid overfitting. In the following discus-sion, unless otherwise stated, we will use Eq. (4) to derive our model.
The order of a Markov model determines how many past states are considered to predict the future state of the pro-cess. To determine the  X  X ptimal X  order of a Markov model, we consider the conditional entropy of the training data.
In information theory, conditional entropy quantifies the remaining uncertainty of a random variable given the value of a second random variable [4, 8]. In our problem setting, we evaluate the entropy of the next group g conditioned on a given set of past groups S ( k ) , which is denoted as H ( g H ( g | S ( k ) )=  X  Here,wedefinelog0=0,as P ( g | S ( k ) ) could be 0. G k stands for all k -group combinations selected from the set of all the groups G .

The conditional entropy H ( g | S ( k ) )is0ifthenextgroup can be fully predicted by the past k groups S ( k ) , and equals H ( g ) if the next group g is independent of the past group transfers. Obviously, H ( g | S ( k ) ) is a function of the Markov order k . By evaluating the value of H ( g | S ( k ) ), we can de-termine the  X  X ptimal X  value of k for our Markov model.
Table 2 shows the conditional entropy as the Markov order k varies from 1 to 4, for the Markov models learned from 6 different ticket datasets. As one can see, the conditional entropy can be improved by increasing the Markov order. This suggests that in practice, it is better to make ticket transfer decision based on a longer history.

Although increasing Markov order generally leads to bet-ter predictability, it also increases the complexity of our model, especially when we apply it to online ticket trans-fer recommendations (to be discussed in the next Section). Therefore, we need to find a right tradeoff for k .Weob-serve in Table 2 that when k is increased beyond a certain threshold, the improvement of predictability becomes small. In our study, we empirically set a threshold  X  =0 . 015 to de-termine the optimal value of k , denoted as k opt . Specifically, we consider k opt = k if k is the smallest value that satisfies
Note that in practice, the optimal order may not be usable Figure 1: Number of recognizable group transfer patterns vs. Markov order for AIX problems due to the limited size of the training dataset. To demon-strate this, we plot in Fig. 1 the number of recognizable group transfer patterns with r espect to varied Markov orders for tickets collected from the AIX problem category during 3 months(Jan.2006 -Mar.2006). It is clear that with the increase of Markov order, fewer transfer patterns become available, which may decrease the applicability of the model.
To tackle this, in a k opt -th order Markov model, to mea-sure the probability of selecting group g we consider the past k opt groups. If the past k opt group pattern occurs too infrequently in the training dataset (thus the probability be-comes statistically unreliable), we will decrease k to k opt k opt  X  2, and so on until the occurrences of the recognizable k -group patterns become sufficient. In our experiment, we empirically set 20 as the thresh old of infrequent patterns.
As shown in Section 3, our Markov model captures the likelihood that a ticket would be transferred to a group, given the past group transfer information. The next issue is how to use it to make effective ticket routing recommenda-tions, so that a new ticket can be transferred to its resolver group as quickly as possible. Note that the right resolver group for a ticket is unknown at the beginning of ticket routing. What we know is the initial group that a problem ticket was assigned to.

Based on the initial assignment information, we study three algorithms that guide ticket routing by searching for the potential resolver group using the constructed Markov model. These three algorithms fall into two categories: the first two use 1st-order Markov models, while the third one exploits higher, variable-order models.
The first algorithm, called First-order Memoryless search (FM), searches for resolver groups based on a first-order Markov model, i.e., k = 1 in Eq. (2). In this algorithm, ticket transfer decision is solely based on the current group. That is, given the current group g ( l ) , the algorithm selects the next group g  X  ,where
Consider the first-order Markov model as a graph, where each node represents a group, and an edge between nodes represents possible ticket transfer. For a new problem ticket, starting from the node representing the initial group, the al-gorithm traverses the graph and searches for the resolver group in a way similar to depth-first search. At each step, it chooses the next node with the highest transition prob-ability. The search progresse s until it finds the resolver, or reaches a node without any unvisited neighbor nodes. In the latter case, FM returns to the most recently visited node whose neighbor nodes have not been fully explored. Here, we assume a ticket should not visit the same group twice. Example 1: Fig. 2(a) shows a sample 1st-order Markov model, where the value on each edge is the transfer proba-bility between groups, estimated by Eq. (2).
 Suppose an incoming ticket is initially assigned to group A and the expected solver group is F .WeperformanFM search in Fig. 2(a). Starting from group A , there are four possible next groups { C, D, E, G } with transfer probabili-cannot solve the problem, the algorithm selects the group with the highest transition probability 0.5 as the next group, i.e., group C . Following similar steps, the ticket is then transferred to groups B , H , I , J , until it reaches the re-solver group F . The search path of this algorithm is marked by thick lines in the figure. The groups that are involved in ticket transfer are shadowed, with a number in paren-theses denoting the transfer order in the process. With FM X  X  recommendation, 7 groups are involved in this case: A  X  C  X  B  X  H  X  I  X  J  X  F .

A potential drawback of the FM algorithm is that it only relies on the current state to make group transfer decisions. In some cases, such decisions may not lead to the best ticket transfer direction toward the resolver group. In Example 1, after C fails to resolve the ticket the search should explore group D rather than B for better efficiency.

To overcome the disadvantage of the FM algorithm, we should choose the next group based on the transition prob-abilities from one of the past states. The intuition is that ticket transfer decision should be made based on not only the knowledge of the current group, but also the problem analysis of the past groups. Therefore, if a group transfer decision is based upon one of the past states instead of the current state, it potentially avoids the incorrect  X  X ocal X  de-cisions made by the FM algorithm. Note that the model built here is still first-order, but based on one of the past states. We name this algorithm First-order Multiple active State search (FMS).

To implement this algorithm, we keep track of a visited group set L v , which includes the groups visited so far, and a candidate group set , L c , which consists of the unvisited neighbors of all groups in L v . At each step, the algorithm checks all visited groups g ( l )  X  L v and candidate groups g  X  L c , and selects the next group that maximizes the first-order transition probability, i.e., If g  X  is not the resolver group, the algorithm will update L v and L c accordingly. It iterates until the resolver group is found.
 Example 2: Let us revisit Example 1 using the FMS al-gorithm. The ticket transfer steps suggested by FMS are illustrated in Fig. 2(b). Initially, L v = { A } and L { C, D, E, G } . The algorithm first selects group C .Now,the L v becomes { A, C } and L c becomes { B, D, E, G } .Next, the algorithm selects D based on past group A ,becausethe transition probability, P ( D | A ), is the largest given both past groups in L v and all candidate groups in L c . The iteration
Table 3: 2nd-order transition prob. for Fig. 2(c) continues until group F is selected after the algorithm vis-ited group E . Therefore, the route suggested by FMS is A  X  C  X  D  X  E  X  F , which is shorter than the one sug-gested by FM in Example 1.

Intuitively, FMS should outperform FM, as it can avoid tracing along a wrong direction when navigating the first-order Markov model for group transfer. In the above exam-ple, it is obviously beneficial to try another direction that is more likely to be correct, i.e., group D ,after C fails.
Both algorithms introduced so far make ticket transfer recommendations based on 1st-order Markov model. It is possible to improve prediction accuracy further by using a higher order Markov model. Therefore, we introduce the third algorithm, called Variable-order Multiple active State search (VMS).

Similar to FMS, VMS also maintains a visited set, L v , and a candidate set, L c . It selects a group from L c in each iteration and expands L v , until the resolver group is found. Different from FMS, VMS first checks all available transfer have been visited in the past. Then, it selects the next group g  X  that maximizes the transfer probability from S ( Example 3: Let us apply the VMS algorithm to Example 1. Suppose we can use either 1st-or 2nd-order Markov model, with the 2nd-order transition probabilities listed in Table 3. The VMS algorithm works as follows. Starting from the initial L v = { A } , since only the 1st-order model is available at this time, the algorithm transfers the ticket to group C and updates L v to { A, C } .

Now the algorithm has the choices of using either 1st-or 2nd-order Markov model. We find that the highest condi-tional probability in the 2nd-order model, P ( E | A, C )=0 . 6, is greater than that in the 1st-order model, P ( D | A )=0 . 45. So the algorithm chooses E as the next group, since the 2nd-order model predicts with higher confidence. In Fig. 2(c), we use dashed thick line to represent this transfer. From group E , P ( F | E ) = 0.75 is the highest conditional prob-ability among all candidate groups in L c ,evencompared to 2nd-order probabilities, hence F is selected next. Thus, the VMS algorithm finally reaches the resolver group F in 4steps: A  X  C  X  E  X  F .
 Algorithm 1 VMS( g s ) initial group: g s 1: initialize L v = { g s } ; L c =NeighborNodes { g s } 2: while L c is not empty do 3: remove g  X  from L c which satisfies Eq. (9); 4: add g  X  to L v ; 5: if g  X  is the resolver group then 6: success, return g  X  ; 7: end if 8: add NeighborNodes( g  X  )-L v to L c ; 9: end while
A formal description of VMS is given in Algorithm 1. By considering more than one group visited in the past, the VMS algorithm compares all historical group transfer pat-terns, and finds the one with the highest confidence.
It is worth noting that VMS may not always use a higher-order model for two reasons. First, for a new ticket, a full-fledged higher-order Markov model may not be available due to the limited size of training dataset. In some cases, we reduce the order until a recognizable group transfer pattern is found. Second, in some cases a lower order conditional probability can be a stronger indicator than a higher-order one and therefore is more favorable to be used. For instance, in Fig. 2(c), if the current group is I , the 1st-order model indicates that the next group must be J (with probability 1), despite what past groups have been visited. That is why we propose VMS that considers variable orders in determining ticket transfer. Compared with FM and FMS, VMS achieves higher prediction accuracy, as verified by experiments. The VMS algorithm is the one we recommend to use in practice.
In this section, we report our experiments on evaluating the effectiveness and robustness of the proposed framework. The evaluation is based on 1.4 million problem tickets col-lected from IBM X  X  problem management system over a 1-year period from Jan 1, 2006 to Dec 31, 2006. These tickets were classified into 553 problem categories 1 , e.g., AIX , DB2 , Windows , etc. On average, 50  X  900 groups (both resolvers and non-resolvers) were involved in solving the tickets of each problem category.

In our study, we partition the dataset into training and testing sets for each problem category. Using the training set, we first build the Markov models presented in Section 3. Then for each ticket in the testing set, given the initial group assignment, we apply the search algorithms introduced in Section 4. To evaluate the effectiveness of our system, we compare the resolution sequences of the testing tickets with the ones recommended by our system. Our experiments will demonstrate: 1. Effectiveness: We show that all three search algorithms,
FM, FMS, and VMS, can significantly improve ticket routing. Specifically, VMS outperforms the other two algorithms and is able to reduce the MSTR from 3.94 (based on human decisions) to 2.58 on average. We also validate our assumption that using intermediate transfer steps in model training is beneficial. 2. Robustness: We test the sensitivity of our approach, with respect to the size of training set, the time-variability of tickets, and the variety of problem categories. The results show that our solution consistently achieves good performance. 3. Case Study: We use a real ticket example to illustrate the details of how a ticket routing system can benefit from our solution. Figure 3: Effectiveness of FM, FMS, and VMS
We first describe the performance of our algorithms on a randomly chosen problem category, AIX .Wederivethe Markov models as discussed using the resolution sequences extracted from 6 , 695 tickets, and then apply the FM, FMS, and VMS algorithms to the rest of 2 , 634 tickets.
Fig. 3 shows the MSTR comparison between the orig-inal ticket routing and the routing recommended by our algorithms. The x -axis is the original number of transfer steps recorded in the testing dataset, while the y -axis shows the MSTR resulted from FM, FMS, and VMS, respectively. Note that all three algorithms can be applied based on either Eq. (3) or Eq. (4). Due to space limitation, we only provide
When a ticket is first opened, the helpdesk assigns a pa-rameter that indicates which problem domain it falls into. the results of VMS using Eq. (3) (denoted as VMS( I )) and VMS using Eq. (4) (denoted as VMS( J )). As shown in the figure, among all three algorithms, VMS performs the best. Furthermore, VMS( J ) outperforms VMS( I ), which is well explained in Section 3. Figure 4: # of routing steps: Original vs. VMS
Fig. 4 shows the detailed distribution (plotted in 3D) of the improvement achieved by VMS in the same experimen-tal setting as Fig. 3. The x -axis is the number of transfer steps based on human decisions, the y -axis is the number of transfer steps from VMS, and z -axisisthenumberoftick-ets in different x -y combinations. As shown in the figure, VMS improves the most in those cases where human deci-sions led to excessively long resolution sequences ( &gt; 3). We also note that by following the recommendations from VMS, most of the tickets that originally took 2-3 steps to resolve stay the way they were, only a small portion of them fol-low a longer resolution sequence. In practice, these tickets are the ones that are relatively straightforward to resolve. We argue that the recommendations from VMS are unlikely to mislead human decisions in these cases. Those originally long resolution sequences represent tickets that were diffi-cult for human experts to make correct routing decisions. It is these tickets that cause most customer dissatisfaction. The fact that VMS can significantly improve the routing ef-ficiency in these cases makes it a good solution to routing recommendation.
 Category Original VMS MSTR (% off) ADSM 5.37 3.23 37.99% AIX 4.89 2.78 43.15% BIOS 4.49 2.94 34.52% DB2 4.78 2.57 46.23% WINDOWS 3.93 2.86 27.23% All Categories 3.94 2.58 34.52% Table 4: MSTR for different problem categories
Table 4 shows the average MSTR for testing tickets from five categories and the average MSTR for all 553 problem categories. The fourth column is the improvement gained by VMS. It clearly indicates on average, VMS improves the transfer efficiency.

In Fig. 3, the fact that VMS( J ) outperforms VMS( I )in-dicates that our assumption that intermediate transfer steps are useful in model training is valid. We further validate this assumption as follows. We build our model using training sets that contain resolution sequences with different lengths. Figure 5: Consistency of the performance of VMS with different types of training sequences If our assumption is incorrect, the result based on shorter resolution sequences should be better than that based on longer ones, because shorter resolution sequences contain less intermediate transfer steps.

Specifically, we build 4 models, T 1 through T 4 ,using10 months of AIX tickets. We use resolution sequences of length 2 as the training set for T 1 , sequences of length 3 for T 2 , sequences of length 4 to 9 for T 3 , and sequences of length 10 or more for T 4 . The number of sequences in each training set is around 1,500. Then we use tickets closed in the next 2 months as the testing set. The effectiveness of each model is plotted in Fig. 5. It is clear that the MSTRs of these models are similar, despite the fact that they were trained by resolution sequences of different lengths. This confirms that our assumption is indeed valid.

As for runtime, for each problem category, resolution se-quence mining can be done in less than 1 second, and the throughput of ticket routing is less than 1 ms per ticket, demonstrating that our solution is computationally efficient.
Our next experiment aims at demonstrating the robust-ness of the VMS algorithm. Specifically, we test its sensi-tivity to a variety of factors including (1) the size of the training set, (2) time-variability of ticket data, and (3) the variety of problem categories.

We first study the robustness of our approach against the size of training set. Specifically, we use 3, 4, 5, or 6-month training sets, as described in Table 5, to build the Markov models for VMS.

A comparison of MSTRs is conducted for each training set configuration. As shown in Fig. 6(a), the performance improvement resulted from VMS is consistent across all 4 training sets, while the result slightly improves as the size of the training set increases. This indicates that our algorithm is robust as long as a reasonably large training set is used. When the training set expands, our model is able to recog-nize more group transfer patterns. As a result, higher-order models will be available and subsequently leveraged by the VMS algorithm to improve the accuracy of predicting trans-fer target.

Next, we evaluate the effectiveness of our approach over time. In this evaluation, a sliding time window is applied to train the model (see Table 5), i.e., the data collected in the most recent 6 months is used as the training set and the resulting model is applied to the tickets reported in the following month. Fig. 6(b) shows that the effectiveness of our approach is also consistent over time.

The last experiment is to study the effectiveness of our approach across different problem categories. We again con-struct Markov models using a 6-month training set and ap-ply it to the tickets reported in the following month. We repeated this test for 10 problem categories. Fig. 6(c) plots the detailed comparison results for 3 different problem cat-egories: AIX , DB2 ,and BIOS . We observe that, as partially shown in Figure 6(c), the reduction in ticket transfer steps is consistent across all problem categories.
To better illustrate why our approach improves ticket rout-ing, we present a case study based on a real ticket resolu-tion sequence. The sample problem ticket is described in Table 6, which shows that 12 routing steps by 10 different expert groups were involved in resolving this ticket.
Fig. 7 depicts a fragment of the Markov model obtained from the related tickets in the training set (all in the DB2 problem category), with each node representing an expert group and the edge thickness representing the likelihood of transferring tickets between two groups. With VMS, only 3 groups is contacted to resolve the ticket: SMRDX , SSDSISAP , SSSAPHWOA (marked black in Fig. 7).

In the log, the ticket actually took 12 transfers to iden-tify the resolver group SSSAPHWOA because two local deci-sions were made incorrectly, which transfer the ticket from SSDSISAP to DRINAIXSP (the 2nd transfer in Table 6) and from SSMRDX to ASWWCUST (the 7th transfer in Table 6). As a consequence, these wrong decisions lead to other wrong transfers (shadowed nodes in Fig. 7). Our model shows that statistically, a ticket transferred to DRINAIXSP will be fur-ther transferred to SSOSOGSAP if DRINAIXSP cannot resolve it. It seems that once transferred in a wrong direction, the ticket would not be easily routed back to the correct path.
By examining the problem status descriptions in Table 6, we find that in the process of resolving this ticket, different groups were trying to test different modules of a DB2 sys-tem, and finally came to a conclusion that DB2B needs to be recycled. What VMS recommended was that if SMRDX and SSDSISAP have tried but could not solve the problem, the most efficient solution is to have SSSAPHWOA with higher probabilities than others to work on it and in this case, to recycle DB2B directly. This intuitively explains why our solution leads to more efficient ticket routing.
Figure 7: Markov Model (partial) in Case Study
Process and workflow mining have been extensively stud-ied in computer science and business research. For instance, Agrawal et al. [1] introduced an algorithm that extracts pro-cess models from event logs. Aalst et al. [21] studied the same problem in terms of Petri net. Rozinat and Aalst [17] also studied the event dependencies and applied decision trees for analyzing decision choices in business processes.
The problem of sequential pattern mining in transactions was first illustrated by Agrawal and Srikant [2]. Various combinatorial algorithms such as SPADE [22], PREFIX [16], and SPAM [3] were developed for efficient mining in large sequence databases. In addition to combinatorial solutions, probabilistic sequence mining was also proposed [6, 7, 9, 10, 11, 19]. For instance, Cook et al. [6] tried to use neural network and Markovian approaches for mining software en-gineering processes. Similarly, Mannila et al. [14, 13] also used a Markovian approach to extract patterns in sequen-tial events. A more comprehensive probabilistic model was proposed in [19]. Note that although our Markov model is conceptually similar to those of [17, 14, 13], we made signifi-cant extensions to capture the data statistics. Furthermore, most of the previous studies were focused on discovering statistical patterns/models from event logs, while this work proposed a novel approach to apply the discovered models to effectively support decision making.

In web usage mining, association rules and sequential pat-terns are utilized to ease users X  access and improve the web-site design [5, 15, 20]. Kohavi et al. [12] discussed lessons and challenges from mining click stream data. In these ap-plications, since it is difficult to tell the target web page that a user was looking for from a sequence of click-through activities, the developed model is hard to evaluate. In con-trast, ticket resolution sequences do not have this issue; each sequence has a well-defined resolver group. Therefore, the model we built can be evaluated accurately. We believe res-olution sequence data provides us a good platform to exper-iment and demonstrate the usage and the effectiveness of sequence mining.
In this paper, we explore the potential of mining reso-lution sequences to improve the efficiency of ticket rout-ing. We develop a Markov model to statistically capture the ticket transfer decisions embedded in ticket resolution sequences. Using the developed model, we then design an algorithm to generate effective ticket routing recommenda-tions. Through extensive experiments, we demonstrate that our approach can greatly improve the efficiency of ticket routing, especially in those cases where human experts tend to make wrong decisions and result in long resolution se-quences. We also show that our model is robust to the size, time-variability and the problem categories of the training data sets.

The approach studied in this paper is solely based on min-ing ticket resolution sequences. Continuing this study, we plan to extend the current model with text mining tech-niques, and develop a system being able to take advantage of both resolution sequences and ticket content for better routing performance. [1] R. Agrawal, D. Gunopulos, and F. Leymann. Mining [2] R. Agrawal and R. Srikant. Mining sequential [3] J. Ayres, J. Gehrke, T. Yiu, and J. Flannick. [4] C. Chatfield. Statistical inference regarding Markov [5] M. Chen, J. Park, and P. Yu. Data mining for path [6] J. Cook and A. Wolf. Discovering models of software [7] J. Cook and A. Wolf. Event-based detection of [8] L. Finesso, C.-C. Liu, and P. Narayan. The optimal [9] W. Gaaloul, S. Alaoui, K. Ba  X   X na, and C. Godart. [10] W. Gaaloul, S. Bhiri, and C. Godart. Discovering [11] W. Gaaloul and C. Godart. Mining workflow recovery [12] R. Kohavi, L. Mason, and Z. Zheng. Lessons and [13] H. Mannila and D. Rusakov. Decomposition of event [14] H. Mannila, H. Toivonen, and A. Verkamo. Discovery [15] B. Mobasher, N. Jain, E. Han, and J. Srivastava. Web [16] J. Pei, J. Han, B. Mortazavi-Asl, H. Pinto, Q. Chen, [17] A. Rozinat and W. van der Aalst. Decision mining in [18] Q. Shao, Y. Chen, S. Tao, X. Yan, and N. Anerousis. [19] R. Silva, J. Zhang, and J. G. Shanahan. Probablistic [20] J. Srivastava, R. Cooley, M. Deshpande, and P. Tan. [21] W. van der Aalst, T. Weijters, and L. Maruster. [22] M. Zaki. SPADE: An efficient algorithm for mining
