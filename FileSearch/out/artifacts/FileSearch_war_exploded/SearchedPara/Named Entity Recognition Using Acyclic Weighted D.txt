 As NEs (Named Entities) such as organization X  X  names, person X  X  names and location X  X  names contain more informative information, NE recognition is the fundamental for efficient information access. Generally, the NE recognition methods are divided into two kinds; rule-based methods and statistical methods. The rule-based methods use regular-expression-like patterns and NE dictionaries [6]. If the NE dictionaries are so much massive and the patterns are generated by referring to a large corpus, the performances of the rule-based methods will be good. However, it is well known that managing a lot of rules is very difficult and the cost for the initial implementation is high. Meanwhile, the statistical methods collect statistical knowledge from corpus and determine NE categories based on the statistical knowledge. The statistical methods can be divided into two kinds according to their learning methods; supervised learning methods and unsupervised learning methods. The supervised learning methods perform well, but the performances of the supervised learning methods depend on the size of NE tagged training data. If the size of NE tagged training data is small, most of supervised learning methods will raise the sparse data problems. On the other hand, the unsupervised learning methods do not require NE tagged training data, but the performances of the unsupervised learning methods are much less than those of the supervised learning methods. Recent researches have been focused on improving the accuracy of NE recognition based on some supervised learning models such as DT (Decision Tree) [7], MEM (Maximum Entropy Model) [2], HMM (Hidden Markov Model) [1], and CRF (Conditional Random Field) [3]. However, these approaches still need a large amount of NE tagged training corpus. To reduce the time-consuming tasks of training data construction, we propose a semi-supervised statistical method which combines a supervised factor (i.e. looking up a NE dictionary) with an unsupervised factor (i.e. training based on a large raw corpus). 
This paper is organized as follows. In Section 2, we propose a NE recognition system based on a semi-supervised learning method. In Section 3, we explain experimental results. Finally, we draw some conclusions in Section 4. The proposed system consists of a knowledge acquisition module and a NE recognition module. Using a conventional POS (Part-Of-Speech) tagger and a NE dictionary, the knowledge acquisition module, first, naively extracts NE candidates from a raw corpus and assigns all possible categories to the NE candidates. To location X  X  names, organization X  X  names) from an on-line yellow page and semi-automatically classified the PLO entities into 50 subcategories by using an on-line encyclopedia. As a result, the NE dictionary includes 53 kinds of named entities that are annotated with their categories. Then, the knowledge acquisition module calculates all possible co-occurrence similarities between NE candidates and adjacent content words although the NE tagged corpus includes many errors. When sentences are input, the NE recognition module simply finds all possible NE candidates from the input sentences by using the same method with the knowledge acquisition module. Then, the NE recognition module filters out inadequate NE candidates and classifies each unfiltered NE candidate into one among 53 categories using the co-occurrence similarities that are already calculated by the knowledge acquisition module. 2.1 NE Dictionary Construction To construct the NE dictionary, we collect 489,212 PLO entities (400,438 person X  X  names, 46,776 location X  X  names and 41,998 organization X  X  names) from an on-line yellow page. Then, we automatically assign subcategories to the PLO entities by using the genera of lemmas in an on-line encyclopedia (http://100.naver.com). Most encyclopedias describe lemmas with genera and specific differences. A genus is a difference from other members of its category. For example, the lemma,  X  X oo island X . In such case, the genus of  X  X oo island X  is  X  X sland X , and the specific difference is  X  X hich belongs to one of districts in Jeju island X . Based on these characteristics of encyclopedias, we manually construct a ma pping table with genus words and their categories, as shown in Table 1. 
Genus (in Korean) Category By looking up the mapping table, we automatically assigned subcategories to each PLO entity. If a PLO entity does not exist in the encyclopedia or the genus of a PLO entity does not exist in the mapping table, we do not assign a subcategory to the PLO entity. Then, we manually correct misclassified entities. 2.2 Co-occurrence Similarity Acquisition To calculate co-occurrence similarities between NEs and adjacent content words, the knowledge acquisition module extracts all NE candidates from a raw corpus and assigns all possible categories to the NE candidates by using a POS tagger and the NE Korean daily newspapers; http://www.chosun.com, 2,698,196 raw sentences from 1996 to 1997) as a training corpus. 
Then, the knowledge acquisition module calculates all possible co-occurrence similarities between NE candidates and content words, as shown in Equation (1). content word or a NE category. f ( X ) is the frequency of X in the training corpus, and words, Equation (1) will return the co-occurrence similarity between the two content words. If X is a content word and Y is a NE category, Equation (1) will return the co-occurrence similarity between the content word and the NE category. Finally, the knowledge acquisition module constructs a co-occurrence similarity matrix by gathering all possible co-occurrence similarities, as shown in Fig. 2. 
In Fig. 2, n and m are the number of content words and the number of NE f(w n ) . c j is the j th NE category, where NE categories are arranged in descending order of frequencies f(c 1 )  X  ...  X  f(c j )  X  ...  X  f(c m ) . 2.3 NE Detection When a sentence is input, the NE recognition module first extracts noun phrases 1 from the sentence by using the POS tagger and some heuristics. Then, the NE recognition module naively assigns all possible NE categories to the noun phrases by looking up candidates are not fake but real by searching the optimal path on an AWD (Acyclic Weighted Digraph). In this paper, an AWD consists of two sets, V and E , where V is a finite nonempty set of vertices which represent NE categories or content words, and E is a set of vertex pairs that are co nnected with directed arcs from the i th vertex to the i+1 th vertex in a sequence of NE categories or content words. Fig. 3 shows an example of the AWD for detecting real NEs. 
To find the optimal pass on the AWD, we modify the Viterbi algorithm [8] that is well-known as the best searching algorithm using dynamic programming. Actually, the Viterbi algorithm uses the transition probabilities multiplied by observation probabilities in HMM. However, the NE recognition module cannot directly calculate the observation probabilities and transition probabilities because the training corpus is similarities between adjacent vertices. Although our assumptions include some flaws, we believe that the transition probabilities will be similar to co-occurrence similarities obtained from a large training corpus. Based on these assumptions, the NE recognition module obtains the co-occurrence similarities between adjacent vertices by looking up the co-occurrence similarity matrix and uses the co-occurrence similarities as the transition probabilities. Then, the NE recognition module determines the optimal pass on the AWD by using the modified Viterbi algorithm. If a NE candidate consists of a multi-word phrase like  X   X  X  X   X  X  X  X  (Samsung apartment) X  in Fig. 3, the NE recognition module calculates co-occurrence similarities of each word in the multi-word phrase and selects the maximum value as the co-occurrence similarity of the multi-word phrase, as shown in Equation (2). In other words, the co-occurrence similarity of  X  X TART &amp;  X  X  X   X  X  X  X  (Samsung apartment) X  is the maximum one among the co-occurrence similarities,  X  X TART &amp;  X  X  X  (Samsung) X  and  X  X TART &amp;  X  X  X  X  (apartment) X . vertex that consists of n words. 2.4 NE Categorization After detecting real NEs, the NE recogn ition module assigns categories to the real categorization. For example, if  X   X  X  X   X  X  X  X  (Samsung Apartment) X  is detected as a real NE in Fig. 3, the NE recognition module will remove the two lexical forms of vertices  X   X  X  X  (Samsung) X  and  X   X  X  X  X  (apartment) X  on the AWD, as shown in Fig. 4. 
Then, the NE recognition module finds the optimal pass on the modified AWD by using the same method with the NE detection. Finally, the NE recognition module assigns proper categories to real NEs by tracing the optimal pass. 3.1 Data Sets MUC (Message Understanding Conference) has provided on ongoing forum for However, MUC does not provide any test collections to eval uate a Korean NE recognition system. Therefore, to evaluate the performance of the proposed system, we built a Korean test collection in a telebanking domain. The test collection consists of 1,769 sentences that include 380 person X  X  names, 173 location X  X  names, and 238 organization X  X  names. In this paper, we defined 53 NE categories (PLO categories and 50 their subcategories), but we could not evaluate performances on classification of the 53 NE categories because we did not comp letely construct the test collection yet. Therefore, we evaluated the performances on classification of only the PLO categories (i.e. person X  X  names, location X  X  names, and organization X  X  names). Although the preliminary experiments are incomplete and coarse, we think that the preliminary experiments have some meaning because our goal is to recognize NE categories without fully-annotated training corpus. We are trying to supplement and expand the Korean test collection and will completely evaluate performances of the proposed system in the future. 3.2 Performance Evaluation To evaluate performance of the proposed system, we used the F1-measure, as shown in Equation (3). In Equation (3), p is the precision that means proportion of correct ones out of returned NE categories, and r is the recall rate that means proportion of returned NE categories out of classification targets. 
Table 2 shows the performance of the proposed system. As shown in Table 2, the performance is 81.32% on average F1-measure which is 9.28% higher than the baseline system that used only NE dictionary. The performance for Organization is relatively good, while the performance for Location is poor. The difference is caused by biased training; the proposed system is actually tuned to Organization categories b ecause the training data, the articles of Chosun-Ilbo, holds probably more organization X  X  names than location X  X  names. We proposed a NE recognition system using a semi-supervised statistical method. In training time, the proposed system extracts all possible NE candidates by looking up the NE dictionary that is semi-automatically constructed. Then, the proposed system constructs a matrix that includes co-occurrence similarities between NE candidates and adjacent content words. In running time, the proposed system generates AWDs based on the co-occurrence similarity matrix. Then, the NE recognition system detects NE candidates and assigns proper categories to the NE candidates using Viterbi searching on the AWDs. In the preliminary experiments on PLO (Person, Location, and Organization) recognition, the proposed system showed 81.32% on average F1-measure. Based on the experimental results, we think that the proposed system may be a good solution to reduce the time-consuming tasks of training data construction because it does not require a large amount of NE tagged training corpus. Acknowledgement. This research (paper) was performed for the Intelligent Robotics Development Program, one of the 21st Century Frontier R&amp;D Programs funded by the Ministry of Commerce, Industry and Energy of Korea. It was also partially supported by Kangwon Institute of Telecommunications and Information (KITI). 
