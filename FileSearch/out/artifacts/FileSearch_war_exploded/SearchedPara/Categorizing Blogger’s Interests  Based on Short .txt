 Blogs have become an important medium for people to express opinions and share information on the web. Predicting the interests of bloggers can be bene ficial for information retrieval and knowledge discovery in the bl ogosphere. In this paper, we propose a two-layer classification model to categorize the interests of bloggers based on a se t of short snippets collected from their blog posts. Experiment s were conducted on a list of bloggers collected from blog directories, with their snippets collected from Google Blog Search . The results show that the proposed method is robust to errors in the lower level and achieve satisfactory performance in cate gorizing blogger X  X  interests. I.5.2 [ Pattern Reorganization ]: Design Methodology-Classifier design and evaluation .
 General Terms Algorithms, Experiment ation, Performance. Keywords Blogger, interests, categorization As an important form of onlin e publishing for common internet users, blogs have emerged as a dynamic and diversified medium for information creation, distri bution and accumulation. Bloggers who are interested in certain domains maintain blog sites to publish news, opinions and ideas about the domains of their interest. Identifying and categorizi ng the interests of bloggers can be valuable for information re trieval and knowledge discovery from blogs. The blog posts published by bloggers provide important clues for predicting their interests. However, direct categorization of all the texts written by a blogger cannot produce accurate prediction. This is mainly due to two reas ons. First, blog articles are written in an informal erratic style. Bl oggers sometimes even invent new words and grammars to express themselves idiosyncratically. Second, bloggers do not confine themselves to one topic [2]. Therefore, the mixture of all the posts by a blogger is a multi-topic and noisy text document that is difficult to classify. To address these challenges, we propose a two-layer classification model to categorize blogger X  X  interest s. In the first layer, a text classifier is trained to predict the probability of a blog post belonging to a domain category. Although the classification of individual post is not perfect, the categorizations of multiple posts of a blogger provide important information to predict the overall interests of that blogger. In the second layer, we derive features from the set of categorization probabilities of the posts written by a blogger. Those features are used to categorize the interests of the blogger. By incorporating the membership information of blog posts regarding all the categories, the second layer classifiers are able to learn the topical corre lations among these categories. We experiment with the proposed model using a collection of bloggers compiled from blog direct ories, with blog post snippet retrieved from Google Blog Search. As we expected, classification of short snippets in the first layer is not very accurate. But the features derived from the set of probabilities for all the snippets are meaningful and useful for predicting the overall interests of bloggers. Cate gorization of bloggers X  interests achieves F1 measure of 0.845 by microaveraging over all the categories. In this paper, we use short sn ippets of a blogger X  X  posts to characterize their interests. Using the snippets eliminates the need to download the full web page. Snippets are also faster to process than full page, enabling real time processing, which is especially critical for web applications. For each blogger b , we collect a set of most recent blog posts written by b , denoted as snippet ) ( first few sentences of a blog pos t, containing about 40 words. Ssss = is the set of snippets collected for blogger The goal is to categorize the interests of b into one or multiple classes, drawn from a set of classes, {} The proposed technique addresses this task with a two-layer classification model. In the first layer, the classifiers produce a probability estimate (|) the probability that snippet s i belongs to category c layer, we derive features from the categorization probabilities for all the snippets written by blogger b and use these features to predict the interests of b. To build text classifiers of sni ppets, we take the stemmed content words of snippets as features, with stop words removed. For each category c j , we selected the most predictive 2000 stemmed words according to Information Gain [6]. To categorize the snippets, we use the sequential minimal model (SMO) [3], which has been shown to be efficient and effective for text classification. The output of SVM is fit to a sigmoid model to derive a proper probability estimate of membership [4]. We create a SVM for each category c j . Snippet s i is processed by each SVM with a sigmoid model, resulting in an m-value vector, where the j th feature is the probability that snippet s category c j .(note that the categories are not mutually exclusive.) Categorizations of a blogger X  X  snippets (equation 1) provide important clues about a blogger X  X  in terests. Features are derived from the categorization of snippets to train classifiers of bloggers. (|) pc s for b i S s  X  . The set of probability estimates is E j shows how much a blogger writes about category c histogram. For each category c j , we divide the [0, 1] range into K intervals and compute the K -element distribution of snippets in S according to (|) distribution for the j th category j snippets in S b with (|) d is computed by Equation 3. dSssSpcs We also calculate the mean and variance of (|) mean and variance form a group of features D characterize how much blogger b writes about category c However, knowing that a blogge r wrote some articles about category c j is not enough to predict that she is interested in c This is because of the multi-topic nature of blogs [2]. To characterize a blogger X  X  interests, we use all the features derived for all of the categories. A blogger b is encoded as the union of D To categorize bloggers X  interests, we train the second layer of classifiers using the derived features shown in (5). We experimented with a number of machine learning algorithms, including SMO [3], nearest neighbor [1], and neural network with one hidden layer. Our experiment shows that the neural network achieves the highest F1 measure. For our experiments, we co llected 4,428 blog sites from BlogCatalog and the blog section of Yahoo directory. The sites politics , religion and technology in the blog directories. In our experiment, we assume that each blog site is owned by a single blogger. We labeled each blogger w ith the categories assigned to their blog sites in the blog directories. Blog snippets for the bloggers were collected using Google Blog Search. We queried the blog search engine with the URL of each blog site and collected the most recent 30 (or less) results for each blogger. The title and the search result summary returned by the search engine are used together as the snippe t. Altogether we collected 86,598 blog post snippets for the 4,428 bloggers. In our experiment on the proposed two-layer classifica tion model, we needed twos separate datasets for classifi es in each layer. We randomly divided the bloggers into two halv es. The snippets retrieved for the first half of bloggers were used to train the first layer classifiers for blog snippets. Usi ng the snippet classifiers, we evaluate the second layer classifiers for bloggers on the second half of bloggers using 10-fold cross-validation. We implemented the two-layer classification model describe above using the Weka package [5]. To evaluate the classifiers in each layer, we used the conventional precision, recall and F1 measures. We computed the micro-averaged values for the three measures, which combines the performance of individual categories, weighted by the number of instances in the categories. snippets classification 0.717 0.416 0.526 blogger classification 0.870 0.822 0.845 As shown in table 1, the classification of the first layer classifiers of short snippets is not very accurate. However, in the second layer classification of blogger X  X  in terests, the classifiers achieved micro-level F1 of 0.845 with neur al networks of one hidden layer with 8 nodes. The experiment shows that the second layer words, although the first layer X  X  accu racy is low, it is sufficient for making predictions in the second layer. In this paper, we propose a tw o-layer classification model for categorizing blogger X  X  interests ba sed on short snippets of their blog posts. In the first layer, we predict the probability of a snippets belonging to each category. In the second layer, we derive features from the set of probabilities for snippets written by a blogger and use those features to categorize the blogger X  X  interests. Although short and noisy blog post snippets are hard to classify, the two-layer classifica tion model has been shown to be robust to the errors made in the lower level and achieve satisfactory performance in cate gorizing blogger X  X  interests. [1] Martin, B. 1995.  X  X nstance-Based learning: Nearest Neighbor [2] Pew Internet and the American Life Project. 2006 [3] Platt, J. 1998.  X  X achines using Sequential Minimal [4] Platt, J. C. 1999.  X  X robabilities fo r SV machines X . In A. Smola, [5] Witten, I. H. and Frank, E. 2005 "Data Mining: Practical [6] Yang, Y., Pedersen J.P. 1997.  X  X  Comparative Study on 
