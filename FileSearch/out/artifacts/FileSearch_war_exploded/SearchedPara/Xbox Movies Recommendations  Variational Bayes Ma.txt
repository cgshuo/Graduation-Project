 We present a matrix factorization model inspired by chal-lenges we encountered while working on the Xbox movies recommendation system. The item catalog in a recommender system is typically equipped with meta-data features in the form of labels. However, only part of these features are in-formative or useful with regard to collaborative filtering. By incorporating a novel sparsity prior on feature parameters, the model automatically discerns and utilizes informative features while simultaneously pruning non-informative fea-tures.

The model is designed for binary feedback, which is com-mon in many real-world systems where numeric rating data is scarce or non-existent. However, the overall framework is applicable to any likelihood function. Model parameters are estimated with a Variational Bayes inference algorithm, which is robust to over-fitting and does not require cross-validation and fine tuning of regularization coefficients. The efficacy of our method is illustrated on a sample from the Xbox movies dataset as well as on the publicly available MovieLens dataset. In both cases, the proposed solution provides superior predictive accuracy, especially for long-tail items. We then demonstrate the feature selection capabili-ties and compare against the common case of simple Gaus-sian priors. Finally, we show that even without features, our model performs better than a baseline model trained with the popular stochastic gradient descent approach. H.3.3 [ Information Search and Retrieval ]: Information Filtering Recommender System, Feature Selection
The item catalog in a recommender system is often equipped with many meta-data features in the form of labels, tags, or a  X  X ag-of-words X . These features consist of a word or a short phrase describing the item. For example, for movies we may have features such as Funny , Martial Arts ,and Os-car Winner . Some of these features are highly informative with regard to the recommendation task, but many others are redundant or irrelevant. We therefore present a matrix factorization (MF) model with an embedded feature selec-tion mechanism which on the one hand identifies and utilizes informative features, and on the other hand ignores and sup-presses non-informative features. This approach is success-fully used to enhance movies recommendations in the Xbox marketplace, serving more than 50 million users [11, 15].
Feature selection algorithms typically belong to one of three categories: wrapper methods, filter methods, or em-bedded methods. Wrapper methods evaluate subsets of fea-tures by training a model with each subset and scoring on a held-out set. This approach is independent of the prediction algorithm in use, but scales poorly for large commercial sys-tems with many features. Filter methods use heuristic mea-sures such as Mutual Information or Pearson Correlation to score features based on their informative power with regard to the prediction target (e.g. in the context of recommen-dation system see [19]). These methods are more scalable than wrapper methods as they do not require training many models. However, they are highly dependent on the specific heuristic metric used to score the features, and there is no structured approach or clear guidelines for preferring one metric over the other. The proposed solution in this work belongs to the last category  X  embedded methods. These are a family of algorithms in which feature selection is per-formed during model construction. Embedded methods are not based on cross-validation and therefore scale well with data size. The features are chosen based on their relative usefulness and informative power with regard to the predic-tion task at hand (not based on some external heuristic).
In this paper we present MF-EFS  X  Matrix Factorization with Embedded Feature Selection .MF-EFSisamatrixfac-torization model aided by item features in the form of la-bels. The features are notably used to improve accuracy by mitigating the  X  X old-start X  problem in items 1 . As explained next, not all features are informative in a recommendation task. MF-EFS automatically discerns and utilizes the infor-mative features while  X  X gnoring X  the non-informative ones by encouraging sparsity and setting non-relevant parame-ters to near zero values. In this paper we do not assume the presence of numeric ratings; it is a setting shared by most real-world re commender systems. MF-EFS is a binary
User features can be introduced in an equivalent way. model based only on like / dislike observations, or implicit usage patters such as watch / didn X  X  watch or buy / didn X  X  buy . However, its feature selection framework is general and can be extended to numeric ratings as well as other types of data.

This paper makes several contributions: Firstly, we pro-pose a novel model that can utilize features to improve long-tail accuracy. It is especially effective in systems with a large catalog, many long-tail items and many features. The al-gorithm is unique in its sparsity encouraging property and can easily cope with many non-informative features. Sec-ondly, the training is based on Variational Bayes inference that is less prone to over-fitting and does not require cross-validation [10]. While we are not first to present a Vari-ational Bayes MF model [13, 16, 17], MF-EFS is different than these previous works. Variational Bayes inference tech-niques are still relatively new in our field, and we hope the reader will benefit from the discussion and comparison to more traditional training methods. Finally, we highlight real-world challenges that arose while working on the Xbox recommender system. We present  X  X orking X  solutions that may benefit applied scientists and academics who are de-signing similar systems.
Many previous studies dealt with combining content data with collaborative-filtering (CF) data. A substantial body of work deals with hybrid models and the reader is referred to [5] for a survey of these methods. Notably, Basilico et al. proposed a unified approach that integrates user-item ratings as well as content-based data into a single feature domain [2]. A different direction was taken by [6], where the items X  taxonomy was used to improve accuracy in predicting music ratings. Our solution differs from these approaches in its embedded feature selection, its Variational Bayes infer-ence, its use of binary data, and its real world application and scale.

The X  X ag-of-words X  representation for item meta-data was studied by [1] and later in [22]. Both works combine an MF model with a Latent Dirichlet Allocation (LDA) model. In essence, these are multi-task models where the LDA compo-nent learns a structure on the item-to-feature relations by assigning latent topics to each of the items. Common pa-rameters are used to explain both the user-to-item patterns as well as the item-to-feature patterns. In general, this ap-proach can improve accuracy in the long-tail. However, it is a delicate practice that may eventually hurt the overall accuracy, as the multi-task nature of the model forces the common parameters to find a fine balance between the two goals of the system.

This work is dedicated to improving a CF based recom-mender; the modeling of features is therefore merely a means to an end. Another key difference from [1] and [22] is that we assume a small number of features per item that may not suffice for learning topic mixtures on the items. Fur-thermore, we assume that the features are noisy and many are non-informative with regard to the CF task. Our model therefore needs to be robust to these features, and still take full advantage of the few informative features.

We reserve special indexing for distinguishing users from items: for users m ,andforitems n . We assume a model with Figure 1: A graphical model of MF-EFS with N users, M items and K features.
 M users and N items, and binary observations (e.g.  X  X ike X  ,  X  X islike X  ). We denote by r mn =1thefactthatuser m liked item n ,andby r mn = 0 otherwise. We denote by D def = { r mn } a dataset of such ratings, and use  X ( m ) { n : r mn  X  X } to index a user X  X  rated items, and similarly  X ( n ) def = { m : r mn  X  X } to index an item X  X  raters (users).
We distinguish vectors and matrices from scalars by using bold letters. We capitalize when denoting matrices and use minuscule letters for vectors, e.g. X is a matrix, x is a vector and x and X are scalars. As explained above, every item in our model is associated with a set of features in the form of descriptive labels. We assume a dictionary of k =1 ...K labels and denote by L n the set of labels describing item n ,andby | L n | the size of the set L n .Wedenoteby L = {
L n } N n =1 all items X  label sets. Finally, we denote by f expectation of f over some distribution q .
Many MF models strive to optimize some specific objec-tive function like the root mean squared error (RMSE) [12], hinge loss [18], or ranking-based objective functions [21]. This is often the best approach in competitions such as the Netflix Prize [3], where algorithms are evaluated on a single metric like RMSE. At Xbox, however, we are additionally interested in gaining a broader understanding of users X  tastes when watching movies on their Xbox consoles. We therefore turn to probabilistic generative models which model the data while striving to explain it.

We assume that user m  X  X  rating of item n is generated by the linear combination of latent user and item trait vectors. The latent user and item vectors are denoted by x m  X  R D and y n  X  R D respectively, with D being the dimensionality of the model. We additionally assume that the user and the item have latent biases, b m  X  R and b n  X  R . The odds of a user liking or disliking an item is modeled by where subscripts m and n are dropped as they are clear from the context, b denotes the sum of both of the biases b = b m + b n , and the function  X  denotes the logistic sigmoid  X  ( a )=1 / (1 + e  X  a ).

Each item n has a set of feature labels L n . We believe apriori that some (but not necessarily all) of an item X  X  features k  X  L n are informative in determining its latent vector y n , and their effect is modeled by letting y n depend on them hierarchically . We therefore assume a latent vector f  X  R D for each feature label k =1 ,...,K , and place a hierarchical Gaussian prior on each y n with p ( y n |{ f k } ,L n , X  y )= N y n ; 1 | where  X  y is a precision parameter. The division by | L n sures that the prior variance of p ( y n |  X  y ), when marginalized over { f k } k  X  L n , does not grow or shrink with | L n we do not have different degrees of certainty about y n on the basis of it being tagged with more or less features.
The generative model is shown in Figure 1, and requires additional priors for the user vectors and for the biases. We let these be centered Gaussian distributions: p ( x m )= N ( x m ; 0 , X   X  1 x I )and p ( b m )= N ( b m ;0 , X   X  1 ub sions of the Gaussian distributions are governed by parame-ters  X  x ,  X  ub ,and  X  ib for the user trait vectors and biases, and the item biases respectively. To infer the various precision parameters  X  , we place a conjugate Gamma hyperprior on each of  X  x , X  y , X  ib , X  ub . For example, for  X  x we have: The rate and shape parameters of the hyperprior were set to a = b =0 . 1, giving a hyperprior on the  X   X  X  with mean 1 and a variance of 10.
The prior density on each feature vector f k is governed by its own precision parameter  X  k . Namely, for each vector f we have: p ( f k |  X  k )= N ( f k ; 0 , X  There are therefore K precision parameters  X  k , each takes its own conjugate Gamma hyperprior G (  X  k ;  X ,  X  ).
This particular setting is designed to give raise to a spar-sity prior on the features that encourages the model to dis-cern informative features from non-informative ones. When we marginalize out  X  k , we obtain the effective prior distribu-p ( f k |  X ,  X  )= p ( f k |  X  k ) p (  X  k |  X ,  X  )d  X  k where the D -dimensional t -distribution has a zero mean,  X  = 2  X  degrees of freedom, and a scale matrix  X  =  X   X  I .The marginalization in (2) is explained in the Appendix.
The multivariate t -distribution is a generalization of the well known univariate Student X  X  t -distribution. It serves as an effective prior on the f k vectors; the effective prior mean remains zero, and the f k vectors are still regularized based on their norms f k f k . However, for small degrees of freedom  X  this distribution exhibits very heavy tails (compared to a Figure 2: Contours of the probability mass of the effective prior for two feature vectors (f 1 and f 2 ): p ( f 1 ,f 2 |  X  =0 . 01 , X  =0 . 01) . For the sake of the visual-ization, the feature vectors here are one-dimensional ( D =1 ). The heavy tails originating from the under-laying t -distributions are clearly seen along the axes. As the number of features is higher, this effect re-sults in a concentration of probability mass along the corners which encourages sparse solutions.
 Gaussian). The density in (2) is isotropic, but with heavy tails. However, unlike a product of Gaussians, the product of these densities doesn X  X  have spherical contours, and the resulting probability mass is not isotropically spread. Hence, that are axis-aligned, i.e. where f k is around zero for many feature indexes k (see Figure 2).
 This effect is similar to L 1 regularization, albeit on a Bayesian hierarchical probabilistic model. The rate param-eter  X  of the features hyperprior determines the degrees of freedom of the t -distribution. In MF-EFS, we set  X  and the shape parameter  X  to  X  =  X  =0 . 01, giving a hyperprior on the  X  k  X  X  with mean 1 and variance of 100.
We collectively denote the model X  X  parameters by and hyperparameters by H = { a, b,  X ,  X  } .Thejointdensity of an observed dataset D , given the hyperprior parameters H and item feature sets L is p (  X  , D|L , H )=  X   X   X   X G (  X  x ; a, b ) G (  X  y ; a, b ) G (  X  ub ; a, b ) G (  X  We note that the MF-EFS model presented here can be triv-ially extended to also incorporate user features, but these are omitted for clarity.

We now appeal to Bayes X  theorem to infer the posterior density of  X  , A direct computation of this posterior distribution is hard. Hence, in the following section we approximate p (  X  |D , with a surrogate distribution q (  X  ) from a simpler family. We seek a distribution q (  X  ) that will minimize the Kullback-Leibler divergence from the true posterior to q (  X  ):
D KL q (  X  ) p (  X  |D , L , H ) def = q (  X  )log q (  X  ) This divergence can be rewritten in terms of the model X  X  log likelihood and the variational free energy F [ q (  X  )] (see [4]),
D KL q (  X  ) p (  X  |D , L , H ) + F [ q (  X  )] = log p ( D|L From the expression in (6) and the non-negativity of the Kullback-Leibler divergence, we concur two things: we can minimize (5) by maximizing F [ q (  X  )] with respect to our choice of q ,and F additionally serves as a lower bound to the model X  X  log marginal likelihood.
The joint density in (3) includes Gaussian priors which are not conjugate with respect to the sigmoid link function used in our likelihood (1). In order to facilitate approximate inference, the sigmoids are replaced by a  X  X quared exponen-tial X  form, which is conjugate to a Gaussian prior. Hence we lower-bound the sigmoids in (3) by employing the logistic or Jaakkola-Jordan bound [9]. We introduce an additional vari-ational parameter  X  mn on each observation r mn and bound the sigmoids in (3) as follows (dropping subscripts m and n , and using h def = x y + b ): moid functions in p (  X  , D|L , H )toget p  X  (  X  , D|L , H we now have log p ( D|L , H )  X F [ q (  X  )] where F  X  [ q (  X  )] is our new objective to be maximized. We note that the above bound now additionally relies on the variational parameters  X  = {  X  mn } , which are adjusted along with q (  X  ) to maximize F  X  [ q (  X  )]. The following section dis-cusses the approximating family q (  X  ), and the maximization of
We estimate each component of x , y ,and f ,aswellasthe biases with Gaussian densities. As an example, q ( x md )= N ( x md ; x md , var ( x md )). We further approximate the  X   X  X  with Gamma densities, and let q (  X  ) fully factorize with: One might also choose q ( x m ) as a full multivariate Gaussian, instead of a diagonal one; it gives a richer approximating family, but requires that a D  X  D covariance be kept in memory for each user (or item).

Optimization of F  X  proceeds by coordinate ascent in the function space of the variational distributions. Namely, we compute functional derivatives  X  F  X  / X  X  with respect to each distribution q in (8). Equating the derivatives to zero, to-gether with a Lagrange multiplier constraint to make q inte-grate to one, we get the update steps for each q in (8). We iteratively update the q  X  X , where each update increases our objective F  X  .As F  X  is bounded, the optimization is guaran-teed to converge. In what follows, we describe these update steps in terms of the sufficient statistics of each distribution.
Before describing the update of q ( x md )for d =1 ,...,D , an update is given if the factor was a richer, full covariance Gaussian  X  q ( x m ), instead of a fully factorized one. Equating  X 
F  X  / X   X  q ( x m )tozerogivesamultivariate  X  q ( x m )withpre-cision matrix P m and mean-times-precision vector  X  m P m of  X  These define the natural parameters in terms of their suffi-cient statistics. Note that (9) has no dependence on other user parameters x m , and updating all user parameters is an embarrassingly parallel computation.

For the fully factorized case, single-variable updates like (9) would have to be repeated D times, once for each q ( x This involves D loops over n  X   X ( m ). Instead, a sim-pler technique allows us to estimate all q ( x md ) in bulk by computation: Each of the q ( x md ) X  X  are recovered from the statistics of q ( x md ) based on  X  m and P m are The following sections only present the updates for (interme-diate) full Gaussian factors, after which the above procedure can be employed to efficiently find the factorized parameters.
The natural parameters of  X  q ( y n ), from which each q ( y is recovered, are where P n and  X  n P n indicate its precision matrix and mean-times-precision vector.

The mean vector therefore has two contributions, statis-tics from the relevant user vectors x m , and a sum of the rel-evant feature vectors f k .Evenif X ( n ) is empty, cold items with no usage still have non-trivial solutions based on their features. Again, updating all the item vectors is an embar-rassingly parallel operation.
The natural parameters of  X  q ( f k ), from which each q ( f is recovered, are where P k and  X  k P k again indicate its precision matrix and mean-times-precision vector. Here, Y k denotes the set of all items having feature k ,and L n /k areallthefeaturesin L n except k .
Both q ( b m )and q ( b n ) are Gaussian distributions, and as their update steps are symmetric, only the sufficient statis-tics of q ( b m ) are given. They are with  X  b m and  X  2 b m denoting the mean and variance of q ( b
The precision hyperpriors are all approximated with Gamma distributions. For the sake of brevity only the update step  X  k = D 2 +  X  , and its rate parameter is  X  k =
The updates in (9) and (10) rely on the variational pa-rameters  X  mn . The current maximum of F  X  with respect to them are computed and discarded as needed, with We refer the reader to [4, 9] for a deeper discussion of the Jaakkola-Jordan bound.
Unlike more familiar algorithms that compute a point es-timate of some objective function, the advantage of Varia-tional Bayesian inference is in its posterior approximation, which aims to approximate the whole posterior density. In this framework, when making predictions we take an expec-tation over all possible parameter values which often leads to better overall accuracy. This is especially true when not aiming to optimize any one single metric (such as root mean squared error), or when the metric is too complex to be op-timized directly. The posterior distribution models param-eter uncertainty, which makes Variational Bayes less prone to under-fitting and over-fitting without the need for an ex-haustive cross-validation process.

When predicting whether a user will like an item, we av-erage over the posterior density with p ( r =1 |D , L , H p ( r =1 |  X  ) p (  X  |D , L , H )d  X  . This is made tractable by ap-proximating the true marginal density with an average over q (  X  ), where p ( r =1 |D , L , H )  X  p ( r =1 |  X  ) q (  X  )d other words, where the random variable h def = x m y n + b m + b n is approxi-mated with a Gaussian based on its first two moments under q , i.e. Finally, the logistic Gaussian integral in (11) is approxi-mated with which follows from MacKay [14].
We evaluate using two different datasets. The first is a sample taken from Xbox movies 2 containing approximately 100 million binary ratings to more than 15K movies made by 5.8 million users. The binary ratings come from a pro-cessed dataset based on a mixture of explicit and implicit user inputs such as movies purchases, explicit ratings, the not interested button, etc. Each movie is associated with a list of 20-30 labels (features) from a dictionary of 1,000 labels. These labels describe movie attributes such as genre, plot, time-period, praise, etc.
 The second dataset is based on the publicly available Movie-Lens 10M dataset 3 . We used it to construct a binary like /dislike dataset as follows: First, we took only positive ratings of 4 stars or higher. After filtering we were left with 5,005,684 ratings by 69,878 users to 10,677 movies. We than added fictitious negative ratings by sampling items and adding them to the dataset. For every user we sampled the same number of negative ratings as the number of positive http://marketplace.xbox.com/en-US/Movies http://www.grouplens.org/node/73 Table 1: Mean Percentile Rank (MPR) of the pro-posed model with features ( MF-EFS )andwithout features ( NoFeatures ) against a baseline trained with Stochastic Gradient Descent ( SGD ). ratings she already had. The items for the negative rat-ings were sampled in proportion to their popularity. This dataset construction process follows from KDD Cup X 11 [7]. The popularity sampling was chosen to discourage trivial solutions where biases are learned instead of personalization patterns. The movies in the MovieLens 10M dataset are as-sociated with 3-5 labels from a dictionary of 20 genre labels.
In both datasets, we created test-sets by randomly select-ing and hiding 10% of the positive ratings. These ratings come from items the user liked or consumed. We measure performance in terms of Mean Percentile Rank (MPR), a common metric in studies of implicit feedback datasets [8, 20]. For every user item pair ( m, n )inthetest-set,werank all items not in m  X  X  history and compute the percentile rank PR mn of item n using this ranking: where I [  X  ] is the indicator function,  X ( m ) are the items in m  X  X  history, and p mn is the probability that user m likes item n according to (11). The MPR metric is computed by averaging the percentile ranks ( PR mn )overalltestexam-ples. Accordingly, MPR values closer to zero indicate better rankings.
 We compared against a regression MF baseline utilizing Stochastic Gradient Descent (SGD) such as in [12]. In the following analysis, we dub this baseline SGD .Inordertoiso-late the contribution of the features in MF-EFS, we trained two versions of our model  X  one with ratings and features data and one with ratings only (without the features). We dubbed these two variants MF-EFS and NoFeatures respec-tively. Effectively, the NoFeatures variant amounts to a simple MF model similar to the SGD model but with Varia-tional Bayes inference instead of stochastic gradient descent. All the models are trained with D = 50.

Table 1 summarizes the results of our evaluation. On both datasets MF-EFS performed best. Notably, the two variants of our algorithm are better than the SGD baseline. The difference between the NoFeatures model and the SGD model is attributed to the Variational Bayes inference which is more accurate than the point estimates of the SGD algo-rithm. The difference between MF-EFS and NoFeatures is attributed to the ability of the proposed model to utilize the informative content of the features.

In Figure 3, we further investigate these results by plot-ting MPR vs. the item support (the number of ratings per item). The advantage of MF-EFS over NoFeatures is clearly evident for items with low item-support ( X  X old-items X ). We attribute this advantage to the features data that is utilized only in MF-EFS . The two variants seem to perform equally on items with higher support. Figure 4: Item support distribution of Xbox Movies and MovieLens datasets. The Xbox Movies dataset is larger and its distribution is more skewed.
 The Xbox Movies dataset is much larger than the Movie-Lens dataset and the item support distribution is more skewed (see Figure 4). It is therefore more susceptible to under-fitting and over-fitting by the SGD model. As discussed above, Variational Bayes algorithms are more robust to these effects. This explains the relative advantage of both variants of our model over SGD in the Xbox Movies dataset for items with high support. It also explains the relative advantage of NoFeatures over SGD for cold items in that dataset. In order to investigate the feature selection mechanism of MF-EFS we trained another variant of the model in which the traits X  precision parameters (the  X  k  X  X ) are held fixed and not updated. This model therefore lacks the sparsity encour-aging property of the multivariate t -distribution in MF-EFS . Instead it employs simple Gaussian priors on the feature vec-tors which are the probabilistic equivalent to the common L regularization. In the following, we dub this variant Gaus-sianPrior .

As explained in Section 2.1, the sparsity constraint is held on the feature vector norms. Figure 5, depicts the histograms of the mean feature-vector norms in the Xbox Movies dataset. The sparsity in MF-EFS compared to Gaus-sianPrior is eminent in the general shift of the histogram towards mean zero norms, as well as in the larger number of high norm features (the two rightmost bins).

Figure 6 depicts an insightful visualization of the mean feature vectors in an MF-EFS model trained with dimen-sionality D = 2. A small number of features have a high norm vector, while the vast majority of the features have near zero norms. This is a direct result of the feature se-lection mechanism of our algorithm. The high norm fea-tures are the  X  X nformative X  features as found by MF-EFS . We added text labels to these features. The most informa-tive feature according to the algorithm is the label Kids . This is expected, as this label encodes clear information on the audience that may like the movie.

The vectors in an MF model span a latent space in which the angular direction of a vector encodes information on the  X  X aste X . Item vectors and feature vectors in the same direc-tion belong to items that fit a similar type of users. Indeed, we see in the same direction of the Kids vector other vectors that indicate children X  X  content, e.g. Pets , Semi-Fantastic , Adventures , etc. Interestingly, in the opposite direction we find features that indicate adult content such as Profanity , Drugs/Alcohol , Erotic , etc. We therefore identify a mean-ingful axis in this latent space which roughly spans between the upper right corner and lower left corner  X  the upper right direction indicates children movies and the opposite direction indicates adult movies.

Another meaningful axis in Figure 6 roughly spans or-thogonal to the first one  X  between the lower right corner and towards the upper left corner. The lower right direction indicates more  X  X ophisticated X  taste with features such as Foreign , Experimental and New Wave . To the opposite of these features we see features belonging to the Horror genre such as Horror , Scary and Serial Killer . The fact that these two groups are placed opposite to each other indicates a neg-ative correlation between the audiences of these two types of movies.
We presented a novel probabilistic Matrix Factorization model with Embedded Feature Selection (MF-EFS) for Xbox Movies. The model utilizes items X  meta-data in the form of label features to enhance accuracy in the long tail. We as-sume that only a subset of these features is informative with regard to collaborative-filtering. Our model therefore per-forms embedded feature selection that ignores non-informative features while fully utilizing informative features. We com-pared against a traditional baseline trained by minimizing root mean squared error and demonstrate superior results for Xbox Movies as well as on the publicly available Mevie-Lens dataset. Finally, we note that MF-EFS can be trivially extended to incorporate also user features.
The authors thank Nir Nice and the rest of Xbox Rec-ommendations for their invaluable input, management, and stellar engineering skills. Figure 5: A histogram of the feature-vector norms. The x-axis depicts the mean feature vector norm, and the y-axis is the frequency. The sparsity encour-aging effect of the MF-EFS model over the Gaus-sianPrior model is eminent in the general shift to-wards mean zero norms, as well as in the larger num-ber of high norm features (the two rightmost bins). [1] D. Agarwal and B.-C. Chen. fLDA: matrix [2] J. Basilico and T. Hofmann. Unifying collaborative [3] J. Bennett and S. Lanning. The netflix prize. In Proc. [4] C.M.Bishop. Pattern Recognition and Machine Figure 6: A visualization of the mean feature-vectors in Xbox Movies trained with a D =2 dimen-sional MF-EFS model. The sparsity is evident by the concentration of near zero feature vector norms. We added text labels to the smaller number of  X  X n-formative X  features  X  those with a high norm.
 [5] R. D. Burke. Hybrid recommender systems: Survey [6] G. Dror, N. Koenigstein, and Y. Koren. Yahoo! music [7] G. Dror, N. Koenigstein, Y. Koren, and M. Weimer. [8] Y. F. Hu, Y. Koren, and C. Volinsky. Collaborative [9] T. Jaakkola and M. Jordan. A variational approach to [10] M. Jordan, Z. Ghahramani, T. Jaakkola, and L. Saul. [11] N. Koenigstein, N. Nice, U. Paquet, and N. Schleyen. [12] Y. Koren, R. M. Bell, and C. Volinsky. Matrix [13] Y. J. Lim and Y. W. Teh. Variational Bayesian [14] D. J. C. MacKay. The evidence framework applied to [15] N. Nice et al. Feature embedding in matrix [16] U. Paquet and N. Koenigstein. One-class collaborative [17] U. Paquet, B. Thomson, and O. Winther. A [18] J. D. M. Rennie and N. Srebro. Fast maximum margin [19] R. Ronen, N. Koenigstein, E. Ziklik, and N. Nice. [20] H. Steck. Training and testing of recommender [21] G. Tak  X  acs and D. Tikk. Alternating least squares for [22] C. Wang and D. M. Blei. Collaborative topic modeling We marginalized over  X  k and get p ( f k |  X ,  X  ) as follows: p ( f k |  X ,  X  )= p ( f k |  X  k ) p (  X  k |  X ,  X  )d  X  k =  X  k =  X  We employ the substitution t = f k f k 2 +  X   X  k to get: p ( f k |  X ,  X  )= = = where Hence, p ( f k |  X ,  X  ) = Multi-t  X  ( f k |  X  ,  X  )isa D dimensional t-distribution with location vector  X  , scale matrix  X  and  X  degrees of freedom.
