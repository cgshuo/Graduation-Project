 University of Pennsylvania usyed@cis.upenn.edu should surface depending on the temporal context.
 engine receives [10].
 observed click behavior of users to decide which search resu lts to display. shift in intent occurs as an event .
 novel solution that learns from unlabeled contexts and user click activity. regret bound is handling events that happen during the  X  X hec king X  phase. algorithm is (under certain mild assumptions) at most O ( k + d of events, d n any bandit algorithm that ignores context suffers regret  X ( k and d techniques. single result i A bandit algorithm A chooses i its regret : R ( A ) , E h P T competing against the best result on every round.
 We call an event any round t where p  X (  X  events, such as bursts in query reformulation, average age o f retrieved document, etc. We assume that our bandit algorithm receives a context x a function f  X  X  , in some known concept class F , such that f ( x t , and f ( x bandit algorithm must choose a result i all previously displayed results and received clicks, plus all contexts up to round t . we assume there exists a minimum shift  X  we have p stationary inference problem.
 most O ( n round and has regret at most O ( k p nT log( nT )) for arbitrary p EXP 3. S on T is substantially stronger.
 an optimal result i  X  identity of the optimal result.
 including a dynamic linear growth curve model.
 but rather to predict shifts in intent.
 actually displayed. For us, this assumption is clearly inap propriate. as a meta-algorithm which uses the following two components : classifier and bandit . In each round, classifier inputs a context x Since both classifier and bandit make predictions (about events and arms, respectively), fo r term  X  X rediction X  for classifier .
 t L is a parameter. Each adapting phase j ends as soon as classifier predicts  X  X ositive X ; the round t when this happens is round t phase j , let ( G + i be the most recent full phase before j , we set l is false , the labeled sample ( x receives true -labeled samples. Pseudocode for BWC is given in Algorithm 1. an incorrect prediction should result in G + and j is a phase after it. However, to ensure that the estimates G far from it, we insert a full testing phase every other phase.
 Algorithm 1 BWC Algorithm 1: Given: Parameter L , a ( L,  X  S ) -testable bandit , and a safe classifier . 2: for phase j = 1 , 2 , . . . do 3: Initialize bandit . Let t j be current round. 4: if j is odd then 5: for round t = t j . . . t j + L do 6: Select arm i t according to bandit . 7: Observe p t ( i t ) and update bandit . 8: Let i be the most recent full phase before j . 9: If G + 10: else 11: for round t = t j , t j + 1 , . . . do 12: Select arm i t according to bandit . 13: Observe p t ( i t ) and update bandit ; pass context x t to classifier . 14: if classifier predicts  X  X ositive X  then 15: Terminate inner for loop.
 x if We make the following two assumptions. First, classifier is safe for a given concept class: are at least  X  -suboptimal.
 For correctness, we require bandit to be ( L,  X  Likewise, for correctness we need classifier to be safe; we quantify its performance via the in each round t , classifier receives a context x where the maximum is taken over all event oracles f  X  X  and all possible sequences { x simply, the FP-complexity of classifier is the maximum number of consecutive false positives it can make when given correctly labeled examples.
 cause incorrect feedback to classifier .
 arms, k events and minimum shift  X  nents classifier and bandit such that for this problem instance, classifier is safe, and bandit is ( L,  X  is where d is the FP-complexity of the classifier and R number can potentially be much smaller than k . a classifier whose FP-complexity is bounded in terms of the fo llowing property of F : Definition 1. Define the safe function S of S
F ( { x 1 , . . . , x t  X  1 } ) So if N contains only true negatives, then S gests that S SafeCl outputs a positive prediction if and only if x /  X  S discarded. Clearly, SafeCl is a safe classifer.
 In the full version [20], we show that the FP-complexity of SafeCl is at most the diameter d analogous property for S (probably the most commonly-used concept class in machine l earning), then S hull of the examples in N , extended in all directions by a  X  .
 By using SafeCl as our classifier, we introduce d unless it depends strongly on the number of rounds T . R ( L )  X  O (min( n  X  log L, may be of independent interest. The ( L,  X  ) -testability is then an easy corollary. and let  X ( u ) = p  X   X  p ( u ) be the  X  X uboptimality X  of arm u . For round t , let average of arm u , and let n meaning is that | p ( u )  X  to re-write the index as I early failure probability we will re-define the confidence ra dius as r for some parameter t original analysis of UCB 1 in [2] carries over; we omit the details. given round t let v be our estimate of  X ( u ) . We express the  X  X uality X  of this estimate as follows: Theorem 2. Consider the stochastic n -armed bandits problem. Suppose algorithm UCB 1 (6 , t been played for t steps, and t + t u we have where  X  ( t ) = O ( p n Specifically, if  X  ( t ) &lt; 1 Let us convert UCB 1 (6 , T ) into an ( L,  X  ) -testable algorithm, as long as L  X   X ( n round best guess ( G + Theorem 2. The proof is in the full version [20]. algorithm from Section 4, we obtain the following numerical guarantee. Theorem 3. Consider an instance S of the eventful bandit problem with with number of rounds T , n arms and k events, minimum shift  X  eter d Consider the BWC algorithm with parameter L and components classifier and bandit rithmic regret when an event oracle f is not contained in the concept class F . Theorem 4. Consider the eventful bandit problem with number of rounds T , two arms, minimum shift  X  regret R Theorem 5 proves that in Theorem 3, linear dependence on k + d dependence on k + d diameter d arms, k events, minimum shift  X  values of k  X  1 , n  X  3 , and  X   X  (0 , 1 minimum suboptimality  X (1) such that regret R data.
 to higher dimensional feature spaces.
 certain thresholds.
 dramatically worse and thus we have not included it in the figu re. the number of features grows. by the end.
 shifting events, i.e., each query X  X  intent is not shifting a ll the time. roughly 1K, 10K, 12K and 6K respectively.
 Number of Features: Finally, we comment on the performance of our approach as the number of deviation was 355, 1K, 5K, 4K for ORA , BWC , UCB 1 and EXP 3. S , respectively. live traffic.
 Acknowledgements. We thank Rakesh Agrawal, Alan Halverson, Krishnaram Kentha padi, Robert Kleinberg, Robert Schapire and Yogi Sharma for their helpfu l comments and suggestions. References
