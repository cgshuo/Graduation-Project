 With the progress of multimedia techniques and computer networks, we are faced with more and more digital images. Undoubtedly, in order to make a perfect use of the inter-esting information implied in the disordered data, there should be some image retrieval techniques which can search and access the corresponding images in time. At the same trieval techniques which depend on manual annotations can X  X  meet users X  increasing needs. Thus content-based image retrieval (CBIR) emerges as the times require. 
In CBIR, we usually construct a feature database using the extracted features at first, and transform an image object in the original image database into a correspond-transformed into the nearest neighbor searching of high dimensional data points in feature databases. For a large scaled image database, the corresponding feature database is also large. must be needed to support the searching and improve the performance of it. Most traditional indexing methods degrade when the dimension of target data exceeds 5, even being outperformed by linear scan, which is the well known  X  X urse of dimen-sionality X . Originating from it, this paper makes an analysis and a comparison of current typical indexing techniques in CB IR, summarizes the problems in them, and points out the direction in the future development. 
The remainders of the paper are as the followings. Section 2 reviews existing in-dexing researches from five aspects. Section 3 gives the performance analyses of those indexing structures and uncovers the problems. As the conclusion of the whole paper, section 4 directs the development of indexing techniques in CBIR. The basic function of an indexing structure is to organize feature vectors, manage the procedure of searching and speed up the final querying. An important difference be-tween multimedia indexing structures and those general structures is that the former is confronted with the influence of curse of dimensionality. To solve this problem, there emerge many methods applied in various situations. We classify those methods into five categories, which are multidimensional indexing method, dimension reduction method, approximate nearest neighbor method, multiple space-filling curves method and filter-based method. 2.1 Multidimensional Indexing Method (MIM) MIM works by partitioning the data space, clustering data according to partitions, and using the partitions to prune the search space for querying. While MIM generally performs well at low dimensional data spaces, their performances degrade rapidly with the increasing of dimensionality, even being outperformed by linear scan. The most successful MIM is the tree-based indexing structure. Those methods group the data points in the database into clusters using some strategies at first, then they repre-organized by corresponding tree structure. During a searching, these bounding objects will provide the lower bound from points in clusters to the query object. Actually, the object, so the bounding object is the approximation of a corresponding cluster. 
Furthermore, MIM can be divided into two classes, one is derived from the K-D-space along a pre-defined hyperplane regardless of the data distribution. The regions space. Instead, the latter uses data-partitioning according to the data distribution, and there may be some overlapping after this partitioning. Besides these two approaches, there also exist some other techniques with a combination of multiple methods. 
The R-tree structure and its variants are most commonly used for spatial data, and they are also the early attempts to high dimensional data indexing. Guttman proposed the concept of R-tree in 1984 [1] . It is the generalization of the B+-tree to high dimen-sional spaces, which represents the data by the minimal bounding rectangles(MBRs). Some experiments show that the performance of R-tree degrades when the dimension of data exceeds 5. 
SS-tree [2] is similar with the R-tree, except that it uses the minimal bounding spheres(MBSs). Though the use of spheres reduces the overlapping of regions and overlapping in high dimensional spaces. MBRs and MBSs associated with that node, thus it reduces region overlap among sibling nodes. This structure is better than both the R*-tree and the SS-tree. lap-free split algorithm, which is based on the split history of the tree. Second, where the overlap-free split algorithm would lead to an unbalanced directory, the X-tree The X-tree outperforms both the R*-tree and the TV-tree [6] . combines the low fanout from the K-D-tree with the advantage that the R-tree has in not covering empty. This structure is slightly better than the X-tree. 
The pyramid technique [8] which is proposed by Berchtold uses a special partitioning sion reduction allowing the use of efficient uni-dimensional index structures to store and search data. The pyramid technique divides the data space into 2D pyramids whose apexes lie at the center point. In a second step, each pyramid is cut into several nique associates each high dimensional point to a single value, which is the distance from the point to the top of the pyramid, according to a specific dimension. This value not good for the nearest neighbor searching, instead it is proper for range querying 1 . 
After this, Chakrabarti proposed Hybrid-tree [9] . It combines the advantages from space-partitioning structures and data-partitioning structures. The Hybrid-tree splits a dimension. This method allows overlapping re gions as data-partitioning structures do. This structure outperforms both the SR-tree and the hB-tree. mensional data that introduces the notion of relative approximation. The basic idea of the A-tree is the use of virtual bounding rectangles to approximate minimum bound-ing rectangles or objects. Thus, on one node of the tree we have information about the exact position of the region MBR and an approximation of the relative position of its sons. The A-tree outperforms the VA-File [11] and the SR-tree. 
As for the above mentioned MIMs, there is not a fixed taxis among them. More-over, when the data dimension is relatively high, all of them degrade rapidly, which is a common shortcoming among them. 2.2 Nearest Neighbor Method of feature vectors are not that of images, so we can X  X  guarantee to have exact results even using exact searching. For reasons of it, researchers propose many methods based on the approximate nearest neighbor (ANN) searching to solve the curse of within a given error bound  X  instead of retrieving exact k NNs. Given a query point q and distance error  X  &gt;0, a point p is a (1+  X  )-ANN of q such that for any other database point p X , (1 ) ' qp qp  X   X  X  X +  X  . The dimension reduction and multiple space-filling neighbor approach. 2.3 Dimension Reduction Method mensionality. This approach first condenses most of information in a dataset to a few dimensions by applying the singular value decomposition (SVD), the discrete cosine transform (DCT), or the discrete wavelet transform(DWT). Then it applies traditional multidimensional indexing schemes to the processed data. The QBIC system uses the primary component analysis (PCA) to reduce the 20-dimension shape feature based on the moment to form the indexing of images. Furthermore, the Fastmap algo-rithm [13] proposed by Faloutsos and Lin is also a typical dimension reduction method. multimedia databases. 
In 2002, Yu proposed iMinMax(  X  ) [14] , which maps points in high-dimensional spaces to single-dimensional values determined by their maximum or minimum val-ues among all dimensions. By varying the tuning  X  X nob X ,  X  , users can obtain different sets. The transformed data can then be indexed using existing single-dimensional indexing structures such as the B+-tree. iMinMax is mainly developed to address much more running time to obtain higher accuracy. In range queries, this method outperforms both the VA-file and the pyramid technique. 2.4 Multiple Space-Filling Curves Method The multiple space-filling curves approach orders the d-dimensional space in many mapping from R d  X  R 1 . This mapping gives a linear ordering of all points in the data set. Therefore, when a query point is mapped to the space-filling curve, one can per-data space. However, due to the nature of the R d  X  R 1 mapping, some near neighbors these points are not overlooked, multiple space-filling curves are used, based on dif-ferent mappings from R d  X  R 1 . Thus the efficiency obtained from approximate nearest neighbor searching will be greatly reduced. 2.5 Filter-Based Method The filter-based approach overcomes the dimensionality curse by filtering the vectors so that only a small fraction of them must be visited during a search. It can be realized by various ways. 
Clustering, classification and latent semantic analysis are all commonly used filter methods. Besides, we can narrow the search range using some simple structured attri-butions in relational databases. ing this formula, we won X  X  omit the right solutions. And this method can be used in all retrieval techniques the distance measures of which are metrics. 
In image searching based on the color histogram, we can use a particular filter method. Since the basic idea of this searching is to compute the distances from each images in the database to the query object and regard the distance as the correspond-ing histogram distance, the computation can be simplified by reducing the number of the bins or selecting a subset of the image database only. 
More idiographic, the VA-File and its variants are all belonging to this kind of method in contrast to the approximate nearest neighbor searching. equally full. Let b be the sum of all b i , i.e. sets. Then the data space is divided into 2 b hyperrectangular cells, each of which can be bit-string of the cell into which it falls. In addition to the basic vector data and the ap-proximations, only the boundary points along each dimension must be stored. Depend-ing upon the accuracy of the dada points and the number of bits chosen, the approxima-tion file is 4 to 8 times smaller than the orig inal vector file. Thus, storage overhead ratio Though the VA-File provides a solution to the dimensionality curse and outperforms the sequential scan and most MIMs in high dimensions, it has some drawbacks. The major drawbacks lies in two aspects. One is that more bits are needed for the approximations in proportion to the dimensionality to enhance the filtering power. The other is that the filtering power decreases severely for clustered data, such as image data. 
Berchtold proposed IQ-tree in 2000 [15] . This tree has a three-level structure. The first is a flat directory consisting of minimum bounding rectangles, the second level contains the approximations and the third level contains real points. As a significant development the density of data. This structure outperforms both the X-tree and the VA-File. 
As another perfect improvement, Guang-Ho Cha proposed GC-tree in 2002 [16] . Dif-ferent from the IQ-tree, the GC-tree maintains the hierarchical directory correspond-ing to the partition hierarchy. other variants based on the VA-File. Aiming at skewed data distribution, Manjunath dimension [17] . Then it partitions each dimension independently based on the model parameters. Ferhatosmanoglu also proposed VA+-File to deal with ununiform data sets in 2000 [18] . This method removes the relativities among dimensions using Kar-hunen-Loeve transform at first. Then it makes an unbalanced assignment according to each dimension X  X  energy after the transform. Besides, Guang-Ho Cha proposed the local polar coordinate file(LPC-File) [19] . The basic idea is to enhance the discrimina-tory power of the approximation by adding polar coordinate information of the vector to the approximation. From the above summarizations, we can conclude that each structure has its advan-only give some comparison results based on certain given conditions and some simi-lar structures to some extent. 
Reference Comparison results Conditions and comments 
Anyway, researchers have proposed many methods to solve the curse of dimen-sionality. Some of them have certain improvements, and obtains faster searching studying high dimensional data indexing. And there also exist some problems to be solved. They can be summarized as the followings. (1) Most of the indexing structures degrade rapidly when the dimension of data ex-ceeds 10. (2) During the partitioning of high dimensional data, there always exist some as-are usually far from the real data sets. (3) Most of the structures can X  X  support the dynamic update of data sets, or the ove-rhead is high. (4) The computation complexity of most structures, especially the high dimension-al indexing structures, is very high. (5) Most of the indexing structures can deal with only fixed dimension data. (6) Generally speaking, a newly proposed indexing scheme is aiming at only one or one class of existing scheme, without the considering of the efficient combina-tion with various schemes. (7) To improve the efficiency of CBIR, most work focus on the improvement of indexing structures, but few of them focuses on the improvement of searching algo-rithms. 
Besides the research results shown in the above sections, the comparisons of some other typical indexing structures can be seen in table1. Till now, we have summarized current researches of indexing techniques in CBIR, compared the performance of them and pointed out the existing problems. 
Due to the high dimensionality, complexity and dynamic of multimedia data fea-the following main requirements. (1) The overlap among data regions using the indexing structure should be mini-(2) The indexing structure can deal with various types of queries, including range (3) The indexing structure can track the dynamic changes of a database effi-(4) The indexing structure should be scalable. Besides, it should support the man-(5) The indexing structure should be independent of the order of input data. the research in this domain in progress. By far, there are various methods proposed by many researchers. Those methods do solve some problems in some particular applica-tions to some extent [26,27] . Since the evaluation of indexing schemes are relied on the performance of corresponding searching algorithms, and various applications have various searching algorithms, we don X  X  have a common model to evaluate existing indexing structures by far, which is also an open problem in this research field. 
On the other hand, the combination with various indexing techniques to form a new indexing structure is also an inevitable trend in the improvement of indexing schemes in CBIR. 
Furthermore, from the summarization ahead we can see that most of the researches focus on the construction of the optimal indexing structure, but few of them commit themselves to the introduction of parallel searching algorithms to improve the per-formance of searching. However, we would obtain much better results with the com-bination of a proper indexing scheme and a parallel searching algorithm than only using certain indexing structure. So it is also another important research branch in the future. 
