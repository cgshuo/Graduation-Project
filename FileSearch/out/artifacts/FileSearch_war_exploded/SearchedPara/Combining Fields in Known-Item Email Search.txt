 Emails are examples of structured documents with various fields. These fields can be exploited to enhance the retrieval effectiveness of an Information Retrieval (IR) system that searches mailing list archives. In recent experiments of the TRE C2005 Enterprise track, various fields were applied to varying degrees of success by the participants. In this work, using a field-based weighting model, we investigate the re-trieval performance attainable by each field, and examine when fields evidence should be combined or not.
 Categories and Subject Descriptors: H.3.3 [Informa-tion Storage and Retrieval]: Information Search and Re-trieval General Terms: Performance, Experimentation Keywords: Email, retrieval, fields, structure, metadata.
In a known-item task (KI), there is only one relevant doc-ument that must be ranked as early as possible by the re-trieval system. The evaluation measure in a KI task is Mean Reciprocal Rank (MRR), which rewards retrieval systems that rank the target documentas early as possible. In TREC 2005, the Enterprise track (TREC-Ent) had a known-item task for email search, using an archive of mailing lists emails of the World Wide Web Consortium (W3C).

Emails are composed of two parts: the written message of the email, and various header fields such as subject and sender information. These fields may bring evidence of dif-ferent importance, which can be taken into account to en-hance retrieval performance. We use a field-based weighting model to combine the fields evidence of emails. A research problem is to determine which fields to apply and combine in retrieval. Our objectives are two-fold: Firstly, to deter-mine how useful each separate field is for retrieval purposes. Secondly, to find indications of when the combination of two fieldsiseffective.
In the W3 Ccollection, there are six fields that we apply, namely Subject, Sender, mailing List name, message Text, and finally the Unquoted and Quoted parts of the message text.

As the W3 Ccollection is in the form of a small Web crawl we additionally apply Body (which contains all the email Table 1: Average Length of each field ( avg l f ), and performance in MRR when used separately for re-trieval. Train/Test denotes when the system is trained using the training topics, and Test/Test de-notes when trained using the test topics. Note that the TREC 2005 best performing official run had MRR 0.621, while the median was 0.4545. All runs were statistically different from the best run in each column at p&lt; 0 . 05 . between both trainings. The All field, which contains the most evidence, performs signficantly better than all other fields (Signed Rank test, p&lt; 0 . 05). Interestingly, there are fields that achieve an MRR of 0.4 to 0.5, namely Subject, Title and Anchor text (Atext), even though these do not contain the actual message text of the email. As each of these fields contains the subject of the email, we can infer that the subject is useful for retrieval, and alone can out-perform the median run of the submitted runs on this task.
When considering the fields containing the message text of the email, i.e. All, Body, Text and Unquoted, we can see that the additional evidence present in the All and Body fields increases the performance over the Text field. How-ever, the Quoted text field is of little retrieval value, and re-moving Quoted text from the Text, i.e. the Unquoted field, increases retrieval performance (from MRR 0.401 to 0.424 and 0.437 to 0.448). Finally, the Sender and List fields are not useful for retrieval for these topics, perhaps due to the lack of personal involvement of the topic creators in W3C.
In this section, we investigate applying pairs of fields using the PL2F weighting model (Eq. (1)). The objective is to show when two fields should be combined. Table 2 presents the performance of pairs of fields. Note that some related pairs of fields are omitted, e.g. Text and Unquoted, because the Unquoted field is entirely contained in the Text field.
From the table, we can see that several combinations of fields achieve a good MRR, including some that outperform the best official run of TREC-Ent 2005 (run uogEDates12T: MRR 0.621). In general, a field containing the unquotedtext of the email, and one containing the subject must be used to achieve a high MRR.

Moreover, it is possible to deduce when fields are similar or independent. For instance, although the Atext and Sub-ject fields perform relatively well in Table 1, combining them (as in Table 2) does not improve on the retrieval effective-ness of either alone. This indeed suggests that they contain similar evidence, which matches what we know about these two fields (they both contain terms from the subject of the emails). The combination of Atext and Title exhibits similar properties. In contrast, applying fieldsthat contain indepen-
