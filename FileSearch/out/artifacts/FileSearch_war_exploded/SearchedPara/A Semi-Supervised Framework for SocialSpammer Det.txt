 post phishing URLs, malwares, pornography information and lots of advertise-ments. In order to spread these spam messages to more users, they pretend to be legitimate that post messages mixed by normal and spam information and follow a lot of legitimate users expecting to acquire more in-links. Moreover, similar to link farming on the Web, social spammers often exchange reciprocal links with other spammers[ 5 ] so that they look like more  X  X eputable X , which makes social spammer detection more and more challenging.
 ferent features and train a classifier using labeled data to detect spam [ 11 ]. How-ever, since a social networks like Twitter has huge amount of users, it is impossi-ble to label abundant training data. This makes supervised learning algorithms impractical. Meanwhile, some researchers proposed unsupervised strategies such as ranking models [ 5 , 18 ] and community methods [ 4 , 14 , 19 ] that can automat-ically filter spam messages or accounts based on social relationship. However, this kind of methods often have high false positive rate [ 14 ] and are not robust compared with supervised methods.
 social spammers(SSSD), which take advantages of both supervised learning and unsupervised learning algorithm, and overcomes their difficulties. The framework iteratively trains a classifier by exploring social graph. First, we extract features inspired by previous studies [ 11 , 17 ] and learn an original classifier f with a small number of initial labeled users. Second, we use these labeled data as seeds to propagate trust and distrust on the social graph according to users X  social rela-tionships. Third, we use the classifier f to label top ranked users and select most confident users as new training data. Last we retrain the classifier. We repeat the above steps until the classifier cannot be refined any more. Experimental results show that our framework can be effectively detect social spammers in the condition of lacking sufficient labeled data.
 The whole framework is presented in Section 3. Section 4 shows the performance of our framework and we conclude this paper in Section 5. Social spam detection has been actively studied in recent years. Heymann et al. firstly made a survey of approaches and future challenges about defeating spam in social networks [ 7 ] and then different detection methods were proposed later. model to detect spammers. Benevenuto et.al [ 3 ] discussed video spammers by extracting some features in YouTube. Lee et.al [ 11 ] statistically analyzed features of spam profiles on social networks and apply machine learning methods to detect spammers. Other researches [ 1 , 2 , 13 , 15 ] similarly extracted different features for spam and trained a supervised model in different social network systems. Yang et.al [ 17 ] proposed more comprehensive features and analyzed the robust of dif-ferent features. Recently, Zhu et.al [ 21 ] and Hu et.al [ 8 , 9 ] used optimization G =( V, E ), where V is a set of vertices for users and E is a set of relationships between users. e ( v i ,v j )  X  E denotes node i points to node j , which specially like Twitter means user i follows user j .
 labeled data, and y i  X  X  +1 ,  X  1 } is the label of user i (+1 denotes the spam user). Generally, the problem of social spam detection is to train a classifier f using labeled data L , and predict whether a user in unlabeled data U  X  L is a spammer or not. In the real situation, n , which means labeled data is far less than unlabeled data with the limited resources.
 is shown in Fig. 1 . Firstly, it starts with a small labeled users set and trains an original classifier; Secondly, it uses the labeled seeds to rank all unlabeled users in social graph; Thirdly, it chooses the confident users as new labeled data; Fourthly, it retrains the classifier. The framework iteratively run the above steps until the classifier could not be refined any further. 3.2 Identifying Spammer Features Features are very important to build a classification model, which have been well studied to identify spammers. Inspired by [ 11 , 17 ], we consider four categories of features: user profiles, user contents, user graph features and user neighbors, defined as followings:  X  Profile features . These features can be extracted from user profiles. The  X  Content features . Content features are extracted from tweets. We calculate  X  Graph features . Graph features are extracted from the social graph G .  X  Neighbor features . We also collect information of their following neigh-with log filter and normalization, which is represented by a vector u i . All detailed features are listed in Table 1 . With the features and labeled data, we can train a classification model f using some learning algorithms like SVM, Naive Bayes and so on. Later, we can apply the model f to predict the label y i of user i , y = f ( u i ).
 where  X  is a decay factor 3 , q represents all followings accounts of user v , indegree ( q ) is the number of followers of user q ,and s ( v ) is the normalized indicator function for spam seeds set S  X  that s ( v )=1 / | S  X  | if v  X  S  X  and s ( v )=0if v/  X  S  X  . To separate spammers more significantly, we define the final distrust score[ 16 ]as d = d  X  t . 3.4 Sampling Initial Labeled Data Note that the selection of seeds is an important issue because ranking models are sensitive to these initial seeds and may be biased if run with unreasonable seeds. In general ,we would like to select the most useful users to label as the initial data, who can spread more information in graph and identify other users. to label, and PageRank is applied for spammers seeds to label. Intuitively legit-imate users with high Inverse PageRank ranking scores have more out-links and can propagate much trust to its neighbors, while spammers with high PageRank ranking scores can propagate much distrust. We select the initial labeled data set L from these users to train the original classifier and also use them as the initial seeds of the ranking schemes. 3.5 Semi-Supervised Social Spammer Detection In this subsection, we describe our Semi-Supervised Spammer Detection (SSSD) framework in details. The main purpose of the framework is to iteratively learn an optimized classifier using enlarged training data set starting from a small labeled data set.
 because of limited time and labor resources, while there are abundant unlabeled data with a lot of social relationship information, which is the motivation of the framework. The proposed framework exploits the large number of social relationships of unlabeled data with the ranking model and select the most confident users as new labeled data to retrain the classifier iteratively. The details of the detection framework are presented in Algorithm 1 .
 labeled data set L as input.  X L is the training data set in the current iteration and  X L is the new training set in the next iteration. e and e are the upper bound of the classification error rate in the current iteration and the next itera-tion, respectively. Then, we learn the initial classification model f using learning algorithm c and labeled data L .
 function that initializes seeds set S + and S  X  with users in labeled data set L and new labeled set  X L . After assigning S + and S  X  , we run the ranking scheme SocialTDRank which calculates trust and distrust scores of each user, t and d . itself, while our framework consider both the social relationships and classifier, introducing the ranking model to jointly select new training set from unlabeled data. 4.1 Dataset To empirically study the social spammer detection framework, we use the UDI-Twitter dataset [ 12 ], a subset of Twitter containing 50 million tweets for 140 thousand users and 284 million following relationships collected at May 2011. Then we extract all features listed in Table 1 of 140 thousand users based on their profiles and tweets content.
 the following rules: i)Posting at least one malicious or phishing URLs, ii)Posting much pornographic information or many URLs directed to pornographic web-sites, iii)Posting a lot of advertisements or URLs directed to online shopping websites for promotion. For the first rule, we use Google Safe Browsing 4 , a widely used blacklist, to detect the malicious or phishing URLs. For next two rules, we manually scan the tweets content of all sampled accounts and click the URLs to judge whether they are pornographic information or advertisements. We invite 50 volunteers to identify the spammers by majority vote. At last, we have extracted 2527 spammers from 140,000 users and sampled 11282 legitimate users as our dataset, shown as Table 2 4.2 Experiment Setup In this subsection, we introduce the details about the experimental settings. To simulate the problem of lacking sufficient labeled data, we use just only a few data as the original labeled data. First, we discuss how the initial data affect the SSSD model with different size of initial labeled set and different seeds selection strategy. Second, we compare the performance of SSSD with supervised models. In supervised models, we use 5-fold cross validation, while in SSSD , we select 2400 users as its original labeled data and randomly test 20% unlabeled data. Precision, Recall, F1-score and Accuracy are used as the performance metrics. All the metrics are mainly measured for spammers. studies, UML features[ 11 ], EEND features[ 17 ] and our selected features shown in Table 1 . The results of Precision and Recall are presented in Fig. 3 and Fig. 4 , where the item Original means that the classifier only is trained by the original data without SSSD . In general, high precision indicates that most of predicted spammers are correct and only a few legitimate users are wrongly classified as spammers. Table 3 and Table 4 show the F1-score and Accuracy.
 the results are definitely optimized by running SSSD compared with the original model. These results prove that SSSD have exploited the large number of social network information of unlabeled data, and selected useful new labeled data for refining the model. From the results, SSSD performs almost as same as supervised models and even better using some classifies and features with less labeled data. For example, when we use SVM on our feature set, we get 0.942 F1-score and 0.982 Accuracy, which is higher than the supervised original model. Furthermore, we notice that our features is better than other feature schemes. original data with mining the social graph. SVM performs the best among dif-ferent classifiers in our framework, So we suggest SVM as the final classification model for our data set.
 performance of model from less labeled data, which also can be generalized on different classifies and more new features.

