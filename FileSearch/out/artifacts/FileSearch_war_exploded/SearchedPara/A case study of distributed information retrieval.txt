 1.Introduction
The number of documents available on the Web is increasing daily, from several thousands in 1993 to more than 4 billion indexed by Google (2004) in 2004. There are several challenges faced by Web
Information Retrieval (IR) systems in this highly dynamic environment. One major challenge is how to effi-ciently locate the desired information into all available data. Recent research in Web IR has led to the development of highly effective search engines that allow users to locate relevant or useful documents. A second challenge at the system level is how to design retrieval engines that can process a massive number of documents, while handling a considerable number of queries simultaneously.
 appropriate to turn to the Distributed Information Retrieval (DIR) approach for the storage and search processing.

In a distributed search environment, there are usually two basic strategies for distributing the inverted
One strategy is to partition the document collection so that each query server is responsible for a disjoint other option is to partition based on the index terms so that each query server stores inverted lists corre-the local inverted file organisation uses system resources effectively, provides good query throughput in most cases and is more resilient to failures.

From the collection point of view, a distributed information retrieval system could follow a single-col-documents is indexed and distributed as a whole. In a multi-collection model, the whole collection of doc-uments is divided into sub-collections that are indexed independently, where each sub-collection could have the most relevant sub-collections and the results are merged considering that different rankings schemes could have been used.
 This work is a case study of different architectures for a distributed information retrieval system. The
SPIRIT collection (94,552,870 documents and 1 terabyte (TB) of text) ( Jones et al., 2002 ) is used for the simulation of the distributed IR system. We partition the collection of documents using a local inverted file strategy, and we test the response times for different configurations. Although the obtained timings and conclusions should be independent of the system used. In this way, we intend to provide a guide to SPIRIT.

Theimprovementsintheperformanceofasingle-collectionmodelareexaminedinadistributedandrep-licated system. Moreover, the effects of a multi-collection model are tested through a clustered system. tem and compare its performance with a replicated system in order to measure the effect of changes in the query topics through time.

We start by presenting the related work in Section 2. In Section 3, we describe our simulation model, starting with the analytical model for a basic, not distributed, IR system. Next, a generic collec-tion model is described and the key components of a distributed IR system are analysed. In Section 4, we describe the simulations performed for the different architectures: distributed, replicated and clus-tered system, and the results obtained. Finally, the main conclusions and the future work are presented in Section 5. 2.Relatedwork
Related work for distributed IR systems includes the evaluation of the architecture performance, data partitioning, caching and multiprocessor systems. However, the work on architecture performance is the most directly related to this paper.

Harman,Mccoy,Toense,andCandela(1997) showedthefeasibilityof adistributedIRsystem, bydevel-oping a prototype architecture and performing user testing. However, they used a very small text collection (less than 1 GB data), and did not analyse efficiency issues.

Burkowski (1990) described a simulation study which measures the retrieval performance of a distri-buted IR system, using also a small collection. The performed experiments explore two strategies for dis-tributing the workload across the servers. The first strategy distributes the collection among all servers uniformly. In the second strategy, the servers are divided into two groups: query evaluation and document retrieval. Burkowski concluded that the second strategy could provide better response times than the uni-form approach under certain conditions, although the uniform strategy would perform generally better.
Lin and Zhou (1993) implemented a distributed IR system on a network of workstations, showing large speedup improvements due to parallelisation. The implemented retrieval model uses a variation of the sig-nature file scheme to encode documents and to map the signature file across the network.
Coevreur et al. (1994) analysed the performance of searching large text collections (more than 100 GB data) on parallel systems. They used simulation models to investigate three different hardware architectures (a mainframe system, a collection of RISC processors and a special purpose machine architecture) and searchalgorithms.Thefocusoftheirworkwastoanalysethetradeoffbetweenperformanceandcost,where the mainframe configuration was found to be the most effective.

Hawking (1997) designed and implemented a parallel IR system on a collection of workstations doing experiments with a maximum of 64 workstations. The basic architecture of the implemented system uses a central process to check for user commands and broadcast them to the servers in each workstation. The central process also merges the partial results before sending the final answer set to the user. Cahoon and McKinley (1996) described the result of simulated experiments on the distributed IN-
QUERY architecture. Using the observed behaviour for a mono-server implementation, they estimated the performance figures for adistributed implementation, proving it to be scalable. They experimentedwith collections up to 128 GB using a variety of workloads, and investigated how different system parameters couldaffecttheperformanceandscalabilityofadistributedIRsystem,usingupto128servers.Theirresults showthatwithasimpledistributedarchitecture,thesystemmaintains scalableperformanceathigherwork-loads.

Lu andMcKinley (2000) analysed the effects of partial collection replication to improve the performance in a collection of 1 TB, simulating up to 33 servers. They concluded that the performance of partial repli-cation with a connection broker exceeds that of a client-side caching or server-side caching.
The previous work for distributing the inverted index over a collection of servers is focused on the local
Tomasic &amp; Garcia-Molina, 1993 ), showing that the local inverted file is a more balanced strategy and a good query throughput could be achieved in most cases.

Our work is focused on the simulation and performance evaluation of several distributed architectures using a massive cluster of workstations (up to 4096) and identifying the limitations of each model. This work is especially related to Cahoon and McKinley (1996) and Ribeiro-Neto and Barbosa (1998) , but it are used in our system (without the reduction in the answer set provided by the conjunctive operations).
Second, a simple analytical model is developed initially for a single-collection/single-server environment the results of the analytical model are tested using the TREC WT10g collection and the set of the topic-relevance queries from TREC10 ( Hawking &amp; Craswell, 2001 ). Next, we model a document collection of 1 TB and a set of queries, in order to obtain more generic results. 3.Simulationmodel
To explore the performance of different architectures for a distributed IR system, we implemented a dis-crete event-oriented simulator using the JavaSim simulation environment ( Little, 2001 ).
The simulation model defined in this work is divided into three parts. Initially an analytical model has been developed for the simulation of a simple IR system based on the WT10g collection and the queries lection model is defined to simulate, in general, the behaviour of any collection of documents and in par-ticular, a new collection composed of 94 million documents and 1 TB of text. Finally, the basic IR model is extended to a distributed IR model defining the behaviour of a local area network of computers and mod-elling the tasks of the query brokers and the query servers. 3.1. Analytical model
In this section, we describe a simplified analytical model for the querying process in the IR system de-scribed in ( Plachouras et al., 2002 ), using the WT10gcollection andthe set of queries used for TREC10(see tors that determine the query processing performance for the studied IR system.

A series of experiments were carried out to identify and estimate the basic variables and critical para-meters of the analytical model. The notation for these variables and parameters is provided next: q i vector of keywords for the i th query k i number of keywords in query q i d k number of documents of the inverted list for keyword k r i number of results obtained in query q i tc 1 first coefficient for the time to compare two identifiers and swap them (merging process) tc 2 second coefficient for the time to compare two identifiers and swap them (sorting process) ti initialisation time, including memory allocation and output display ts average seek time for a single disk tr average time to read and process the information about one document in aninverted list (seek time t i total time (in ms) to complete the processing of query q
Once the query server receives the query vector q i for processing, it reads from disk the inverted lists associated with the k i keywords, whose length is given by d to form the answer set whose length is given by r i . The coefficients tc the time to merge and sort the results. Ribeiro-Neto and Barbosa (1998) have modelled this process using a linear relationship, but from our experiments, a logarithmic model seems to fit more accurately as the num-ber of results increases. Hence, the time to merge and sort n results ( tc ) is calculated as:
Theprocessingofaqueryisdividedintofourphases:aninitialisationphase(P the inverted lists from disk and processing the weights (P results (P 4 ). Therefore, the processing time for a query q oftheestimationbyprocessingthetopic-relevancequeriesfrom TREC10 X  X WebtrackwitharealIRsystem ( Plachouras et al., 2002 ). In this way, we obtain the exact number of results for each query and the exact number of documents associated with each of the inverted lists retrieved by the system.
Tocompare the accuracy of our analytical modelwiththe realIRsystem,wemeasuredtherequiredtime to process, on a single computer, the queries 501 X 550 used for the TREC10 topic-relevance task with the
WT10gcollection. This computer had2AMD Athlonprocessors at1.4 GHz and2GB RAM.The process-ing time of the same 50 queries was also evaluated for the proposed analytical model. Both Mann X  X hitney and Kolmogorov X  X mirnov two sample tests confirm the correspondence between the real and predicted processing times, with p -values of 0.956 and 1.0, respectively. In Fig. 1 , we show the cumulative response times for the real system and our analytical model. 3.2. The spirit collection model
In a simulation study, the documents and queries can be represented using two different techniques. One Garcia-Molina, 1993 ).

The former is more realistic and it allows the comparison between the simulation model and the real sys-of synthetic data provides more flexibility for studying a wider range of configurations.
As a consequence, the basic analytical model defined for the WT10g collection will be extended to work with synthetic databases and queries. The objective is to simulate the so-called SPIRIT collection, com-posed of approximately 94 million Web documents and 1 TB of text, although no queries and relevant assessments exist for the moment ( Jones et al., 2002 ). We divide this collection in 72 sub-collections and we use the statistical information (vocabulary size, document size, etc.) of one of them to model the whole collection. 3.2.1. Document model
For the document model, we first study the main parameters of one of the sub-collections, and using this the considered parameters.

The first column describes the parameters that represent a database of documents. The database consists of a collection of D documents. Each document is generated by a sequence of W independent and identi-cally distributed words. Each word is uniquely identified by an integer w in the range 1 6 w 6 T , where
T = j V j . The probability distribution F describes the probability that any word appears and, for conven-ience, is arranged in decreasing order of probability.

The second column of the table represents our base case scenario and the values are obtained from one fraction of the SPIRIT collection. To define a specific probability distribution Z ted to the rank/occurrence plot of the vocabulary, and then normalised to a probability distribution. Fig. 2 shows the log X  X og graph of a linear and quadratic model fit to some of the 500,000 most frequent words.
The X axis represents the words in the vocabulary, ranked by the number of occurrences in decreasing order. The Y axis represents the number of occurrences of each word.

A regression analysis was performed and confirmed that the quadratic model fits the real distribution ( R =0.99770)betterthanthelinearmodel,whichcorrespondstotheZipf X  X law( R =0.98122).Thequadratic match the actual distribution better.

Given the quadratic fit curve, the form of the probability distribution Z Garcia-Molina, 1993 ): The third column of Table 1 shows the estimated values of the parameters for the whole SPIRIT collection.
The number of documents in the collection is 94,552,870. The average number of words per document is supposed to remain stable. Therefore, the same value as the base case is chosen.

The size of the vocabulary of a collection of documents is supposed to match the Heaps law ( Heaps, 1978 ), which states that the vocabulary size of a collection of documents with n terms is given by: where K and b are two parameters that depend on the collection. To estimate these parameters, the values of V and n were measured at several points during the indexing process of the sub-collection, and a regres-sion analysis was performed. Fig. 3 shows the log X  X og graph of the real values and a linear model fit, prov-ing a strong linear relationship ( R =0.999). The estimated values for the parameters are: K =4.60363 and b =0.6776.

Therefore, to estimate the size of the vocabulary of the whole collection, the Heaps law is used for the 94 million documents and 456 words per document, obtaining an approximation of 73,689,638 unique terms for the whole collection.

Finally, a different probability distribution is provided for the whole collection. Given the quadratic fit curve previously described, a new normalisation constant is defined for the new vocabulary size: 3.2.2. Query model between 1 and 4 terms per query, based on the terms used in the TREC10 topic-relevance queries. In Table 2 , we present a description of each parameter and the corresponding values we used for the simulations.
There is little published data on the probability distribution Q . Tomasic and Garcia-Molina (1993) as-sume the uniform term distribution with the fraction parameter for the query model. However, Jeong and
Omiecinski (1995) model Q , assuming that the probability of a term occurring in a query is proportional to that term X  X  frequency in the collection. These two different query models are named uniform query model and skewed query model, respectively.
 The probability distributions Q ( t ) for the two query models are: Uniform Query Model: Skewed Query Model: of choosing a word of low rank increases. Words of low rank occur frequently in the documents of the col-introduced to avoid the effect of the first words in the rank, i.e. stopwords, which increase excessively the number of results obtained. As s increases, more words from the top rank are considered to be stop-words, and therefore are not used as query terms.

At certain points in the simulation, we will need to know the expected size of an inverted list for a query term and the expected size of an answer set for a given query. Let us assume a query with terms t whole collection Documents = D , but in a distributed environment, Documents corresponds to the number of documents covered by each of the distributed indices. Therefore, the number of documents of an in-verted list for term t i will be ( Tomasic &amp; Garcia-Molina, 1993 ):
Consequently, the expected size of the answer set for a query with terms t query) is:
In order to test the accuracy of the described SPIRIT document collection, a simulation was performed to configured empirically to retrieve, on average, the same number of documents as the real set of queries (approximately, 150,000 documents per query, 9% of the collection), for both query models. For the uni-form query model, the values used were: u =0.0009 and s =0.00005; for the skewed query model, the values realistic portion of the vocabulary, trying to avoid uncommon terms.
 The comparison of the response times of both query models and the analytical model is shown in Fig. 4 .
Here, it is clear that the simulations using the query models produce on average similar response times as thebaseline.Althoughthefluctuationsoftherealqueriesare notpresent inthe querymodels(probablydue to the uniform selection of the terms per query in our query models), these models can be considered as quite accurate for the average response times.

On the other hand, there is no clear difference between the response times for the uniform query model and the skewed query model. However, the effect of the parameters u and s on the words potentially used in the queries is quite important. The uniform query model is limited to only 2463 different words, while the skewed model could use more than 28,000 different words from the vocabulary. Note that in both cases, we used a vocabulary of 2,898,203 terms to retrieve on average 150,000 documents per query. skewed model is considered to represent better the real queries. 3.3. Distributed model
In a distributed IR system, the queries are stored in a global queue, which is controlled by one or more central brokers . Each broker will take one query and, depending on the implemented index organisation Barbosa, 1998 ).

In this work, we do not evaluate the impact of the query arrivals on the performance of an interactive system. We assume that the system is operating in batch mode and that there are always enough queries to fill a minimum-size query processing queue. Initially, following the TREC practice, we assume that this queue has a size equal to 50, i.e. a batch of 50 queries is processed for each experiment.
Moreover, this work is focused on a local index organisation (see Fig. 5 ). In this organisation, a broker takes a query out of the queue and sends it to all query servers in the network. Each query server then pro-number of documents from the top of the ranking and returns them to the broker. The broker collects all the local answer sets and combines them into a global and final ranked set of documents. Once a broker finishes with one query, it is ready to process the next one from the queue. If more brokers are available, then more than one query could be sent to the query servers, which will process them sequentially.
This process is repeated until the user queries queue is emptied. The total response time starts when the first query is taken from the queue and finishes when the last query has been processed.
The analytical model previously described is now extended to support the definition of a distributed IR system, with local index organisation. Some new parameters are defined: d k , j number of documents of the inverted list for keyword k on query server j r i , j number of results obtained for query q i on query server j tr max maximum number of top ranked documents returned as the local answer set (1000 by default) tr i , j number of documents from the top ranking in query q t i , j total time (in ms) to complete the processing of query q rq i , j time to receive the query q i for the query server j ra i , j time to receive the local answer set for query q i from the query server j
As a consequence, the time for the query server j to process the query q
The parameters d k , j and r i , j are estimated using the collection model described in the previous sec-tion.

As soon as the broker has received all the local results from all the query servers, it must combine them to obtain the final answer set. Therefore, the total processing time for query q directly depend on the network load of each moment. Therefore, it is necessary to capture the behaviour of the network to represent accurately the response times of a distributed IR system.

In our case, the system will contain a single LA Nthat will be simulated by a single FCFS infinite length queue. This LA Nwill manage all the messages sent by the brokers to the query servers and the answers from the query servers to the brokers. The service time for a request is calculated by the equation:
In Table 3 , we describe the parameters used in the simulation of the network and show their correspond-ing values. The above RequestLength parameter depends on the type of message sent. If a query is sent to the query servers, the value of the QuerySize parameter will be used. If the local answer set for query q sent from query server j to the broker, then the length of the packet will be: tr 4.Simulationresults
This section describes the results of several experiments, in which we used the simulation model de-scribed in the previous section. The objective is to investigate different approaches for the distribution and replication of the collection using a cluster of query servers, and compare the performance between the different configurations.

All the simulations are based on the 1 TB SPIRIT collection model. We model the queries with the ske-wed query model and, following a worst case scenario, we assume that each query would approximately retrieve 8.4 million documents (about 9% of the whole collection). A batch of 50 queries is used to test are run, and the average values for the execution times are calculated for each query.

The experiments are designed to test the performance of different architectures that distribute or repli-replications are analysed and then, we examine possible configurations of a clustered system (based on an asymmetric distribution and replications).
 4.1. Distributed system
In this set of experiments, the collection of documents is distributed using the local index organisation IR system with 1, 2, 3 and 4 brokers respectively. The results are displayed in Fig. 6 .
The best performance is obtained when the query servers are continuously processing queries, without any idle period while waiting for new queries. If only one broker is used, the query servers will have long idle periods, especially as the number of query servers increases. As a consequence, the processing time in the broker for each query also increases (see Fig. 6 ).

The optimal performance is achieved when two or more brokers are used. In fact, with less than 512 query servers, two brokers are able to provide queries to the servers, continuously and, therefore, the per-formance of the system is maximised. However, there is still a bottleneck with 768 or 1024 query servers, with inactivity periods that will reduce the throughput. Three brokers will provide the maximum through-put, and no further benefit is obtained if we increase the number of brokers.

The bottleneck in the brokers is due to the number of local answer sets received from all the query serv-servers, aseachserver storesasmaller invertedindex. Ontheotherhand,thebrokerswill receivemorelocal while waiting for new queries from the brokers. In fact, if the number of query servers is high enough, the performance will start deteriorating at a certain point, independently of the number of brokers used.
The load on the brokers could be lowered in two ways. The first one is to reduce the number of docu-ments included in the local answer sets by the brokers, with a possible repercussion on the precision and recall of the system, which must be analysed. The second way is to reduce the number of local lists received and reduce the answer sets gradually.

In a system with three brokers, the throughput tends to be stabilised around 0.64 queries/s with 512 query servers, with minor improvements as the number of servers increases (0.66 queries/s with 1024 query servers).

Working with an optimal configuration of three brokers, Table 4 provides an estimation of the expected time in minutes to process 50 queries with a distributed IR system, using from 1 to 1024 query servers. 4.2. Replicated system
A replicated system is composed of one or more distributed IR systems. Each distributed system indexes the whole collection, and all the distributed systems that have been replicated, have the same number of with only one replica.

In a replicated system, the brokers must decide initially which replica will process the query, and then broadcast the query to all the query servers in the replica. The objective of the selection of the replicas is to balance the load through all the replicas to obtain an optimal performance for the whole system.
In our case, a round robin policy is used to distribute the queries to the replicas. Each broker will select a different initial replica and for each following query the next replica is selected.

Firstly, we analyse the optimal number of brokers required in a generic replicated system. To study this, we simulated a set of replicated systems, changing the number of brokers used. A summary of the results is provided in Table 5 .

Initially, a system with two replications is simulated, using a variable number of brokers. With only four brokers, there is a reduction in the performance, following the pattern of the basic distributed system with two brokers (decreasing with 768 or 1024 hosts per replica). Using five brokers, a nearly optimal throughput is achieved. A further increase in the number of brokers will only slightly improve the perform-ance (and simultaneously, the network load).

The case of the systems with three and four replications is quite similar. With six and eight brokers respectively, there is a decrease in the performance for more than 512 hosts, reproducing the behaviour of one unique distributed system. As in the previous case, one more broker is sufficient to avoid the bot-tleneck and serve properly all the query servers.

Generally, for the simulated configurations, the number of brokers necessary to achieve near optimal performance for a generic replicated system, with R replicas, is given by: 2 R +1. With 2 R brokers, there isstill abottleneck whenthe number ofqueryservers ishigh,andthis extrabroker will reduce the idletimes inthehosts.Ifmorebrokersareaddedonlyslightimprovementscanbeachieved,especially withmorethan 256 query servers. If the number of replications is further increased, more extra brokers would be necessary to maintain throughput at the same levels.

Another important point in the replicated systems is the relation between the throughput and the num-ber of replicas. If a basic distributed system has a throughput of T queries/min, then the theoretically maximum throughput for a system with R replicas will be T R .

Thisisconsistent withtheresultsobtainedin Table5 ,andespeciallywhentherearefewerthan128query order to improve the throughput up to the optimal theoretical value.

In addition, it is important to stress that if more than 256 (or 512 for some cases) query servers are used per replica, the performance of the system decreases rapidly (see shaded areas of Table 5 ).
Fig. 7 shows the throughput of each replicated system (configured with the optimal number of brokers) less than 1000, the performance improves with each new replica added. However, if the number of query fact, a system with 4 replicas of 1024 query servers has a lower throughput than a system with 4 replicas of 64 servers each.

This decrease in performance is due to the network. Each replica adds more hosts to the network, which is used intensively to send the results back to the brokers. As a consequence, the network latency greatly increases with each new replica added (see Fig. 8 ), making the network a bottleneck for the whole system. age. However, in a system with four replicas and 1024 query servers per replica, the time each byte needs to reachitsdestinationincreases10times.Hence,allthemessagessentthroughthenetworkarehighlydelayed producing inactivity periods on both query servers and brokers.

The effect of this bottleneck could be reduced in three different (and independent) ways. First, we can reduce the number of results included in the local answer sets sent from the query servers, although this sets using compression techniques. Third, we employ different network configurations. In this work, we have only simulated a basic 100 Mbps LAN, although several improvements could be achieved with more complex configurations, using switches, routers and other network technologies apart from Ethernet, i.e. ATM or Gigabit Ethernet.

In the next section, we explore the benefits obtained with the second option. The remaining solutions require a deeper analysis and will be considered in future experiments. 4.2.1. Compression to reduce network congestion The described network congestion is mainly due to the answers sent by the query servers to the brokers.
Nearly all query servers of each replica will send their local results at the same time and above all, the amount of information sent is quite high.

As described in Section 3.3, each server will send a maximum of tr 1000) and the information about each document is codified using DocAnswerSize bytes (currently, 8 bytes). lica), the broker will receive 8000 Kbytes of answers for each query.

To study the benefits of reducing the information sent from the query servers to the brokers, a basic distributed model (without replication) was simulated, compressing the local answer sets (no compression and decompression times were considered). This experiment is also equivalent to a reduction in the size of the local answer sets, although this could affect the retrieval effectiveness of the IR system. We have made the hypothetical assumption that the local answer sets could be compressed to: 75%, 50%, 25% and 10%. Table 6 describes the expected latency of the network and the new achieved throughput, as the information sent to the brokers is being compressed. The study is centred on 256 or more query servers.
On the contrary to what we were expecting, the average time to send one byte does not decrease signif-icantly as the compression ratio is increasing. The same seems to happen to the throughput obtained in the system: there is a slight improvement as the data are being compressed, but not relevant. In fact, with a compression ratio of 10% (sending 800 bytes, instead of 8000), the throughput improves by less than 2.5%.

The same tests were repeated for the replicated systems and the results are displayed in Fig. 9 . The stron-ger line represents the throughput of the replicated systems with a 10% of compression, while the thinner line is the baseline (no compression). As was described previously, there is no significant improvement in a of the compression is more important, avoiding the reduction in the performance with a high number of hosts. In these three cases, the performance of the baseline systems decreased when more than 1000 servers were simulated. However, the compression of the local answer sets to 10%, resulted in higher throughput.
In fact, the behaviour of each of the replicated systems is analogous to a distributed system, with the per-formance increasing proportionally to the number of replicas defined.

These results underline the importance of the volume of information sent from the query servers to the brokers. In a distributed system, the network is not the bottleneck (at least, with the number of hosts sim-ulated) and therefore, there is little improvement in the throughput even by reducing up to a 10% the vol-ume of information. However, on a larger system, where the network is the bottleneck, this reduction is lightening the load of the network and permits the system to achieve its best performance. 4.3. Clustered system
A clustered system is divided into groups of computers, where each group operates as an autonomous distributed and replicated IR system. Each cluster can be composed of a different number of query servers.
We assume that each cluster is responsible for one disjoint part of the whole collection of documents, and each cluster could use distribution and replication to store its respective index.

The brokers are global for the whole IR system. First, a broker must determine the appropriate cluster for each query and then, it should broadcast the query to the selected clustered system. If the cluster sup-round robin policy, as described previously).

Different commercial Web IR systems claim to use a clustered system adapted to the distributions of the distribution of queries, and how the changes of this distribution will affect the performance. Intheworkby Spinketal.(2002) ,asetofrealqueriesofWebusersiscategorisedinto11differenttopics.
Moreover, the variations in the percentage of queries for each topic are analysed in three different years: 2001, 1999 and 1997. Table 7 provides a summary of the 11 topics and the percentage of queries through the different years. In the simulated systems, once a query is generated, it is automatically assigned to a average to fit the size of the clusters.

In these experiments, we assume that each topic is indexed in a different cluster. The collection is divided into 11 sub-collections with an inverted file of approximately the same size, that is 8.5 million documents and, therefore, the 11 defined clusters will index the same number of documents, although using a different the same optimal throughput curve.

The base sub-collection of 8.5 million documents has been distributed over N query servers, where N =1, an optimal configuration of two brokers. The throughput values are displayed in Table 8 .
Two different configurations have been tested for the clustered system. The first one has 128 query serv-ers and the second one has 1024 query servers. Each cluster is assigned a number of query servers propor-tional to the percentage of queries that it is expected to receive (see Table 7 ).

The clustered systems are configured according to the most recent distribution of the topics, correspond-each topic, respectively. The first number corresponds to the number of distributed query servers, and the second one stands for the number of replicas in each cluster (the excepted throughput for each topic con-of the query servers have been chosen analogously in both configurations, trying to maximise the replica-tions for the most popular topics.

For the first configuration, the baseline is a replicated IR system, with 4 replications of 32 query servers each. On the other hand, the baseline for the second configuration is a replicated system with 4 replicas of 256 query servers each.

Fig. 10 presents the box diagram for the response time for the first 100 queries processed by the tested 1997. Obviously, the performance of a replicated IR system does not depend on the type of queries (the baseline is independent of this factor), and the response times for the clustered system with 128 servers are labeled  X  X  Config 1-2001  X  X ,  X  X  Config 1-1999  X  X  and  X  X  Config 1-1997  X  X , respectively.
The first clear conclusion is that the clustered system does not outperform a replicated system. The rep-licated system will process one query in 4682 ms, while the clustered system optimally configured for the 2001 queries will just process one query in 7806 ms (approximately the same performance as a system with two replicas of 64 servers). On the contrary, the clustered system reduces greatly the network load with 0.0008 ms/byte, versus the replicated system with 0.0044 ms/byte.

On the other hand, the clustered system seems sensitive to the changes in the topics of the queries through time. For the queries of the year 1999, the performance is nearly the same, 8068 ms per query, while for the queries from 1997 the performance drops to 9212 ms per query. In fact, the higher differences for the topic distributions are between the years 2001 and 1997 (see Table 7 ).
 fact, the baseline also happens to have some atypical data but very near the confidence interval, due to the distribution of the queries over many servers. In a clustered system, with a reduced amount of hosts per cluster, some heavy queries will produce higher response times. This is more notable when the topics of the queries are changed (1997 queries), because the smaller clusters may have to cope with a higher number of queries than initially expected.

In the second configuration, the clustered system and the replicated system have processed the queries matching the 2001, 1999 and 1997 distributions. The response times for the clustered system with 1024 shows the box diagram for the response time for the first 100 queries processed for all these systems. In this case, the clustered system outperforms the baseline, for all query distributions, through the years.
The replicated system requires 3313 ms per query, while the clustered system for the 2001 queries will proc-ess one query in 2665 ms on average. Regarding the network load, while the replicated system needs, on average, 0.112 ms to send one byte, the clustered system uses only 0.007 ms per byte, on average.
Thisconfigurationisalsosensitivetothechangesinthetopics ofthequeries,buttoasmallerdegree.For the queries from 1999, the performance is slightly better, 2630 ms per query, but for the queries from 1997, the performance drops to 2938 ms per query (still outperforming the baseline).

In this configuration, the increase in the number of query servers reduces the size of the local indexes same time, the different clusters can support more easily the changes in the query topics through the time.
In this configuration, for the 1997 queries, the performance decreases by 9%, while with 128 query servers the throughput decreased by 14%. 5.Conclusions
In this paper, we have described different architectures for a distributed IR system, analysing the optimal design(i.e.numberofbrokers)andestimatingthemaximumperformanceachievedwithmultipleconfigurations (from1upto4096queryservers).Wehavestudiedtheperformanceofadistributed,replicatedandclustered system, and we have established the bottlenecks and limitations of each possible configuration. Our work extends previous works with respect to both the size of the collection and the number of query servers sim-ulated, and confirms some of the previous findings in the literature (see Section 2).

Indeed, we have identified two main bottlenecks in a distributed and replicated IR system: the brokers and the network. The load on the brokers is mainly due to the number of local answer sets to be sorted (characteristic of a distributed system), as it was also shown by Cahoon and McKinley (1996) . Therefore, the load can be improved by reducing the number of documents included in the local answer sets by all the query servers, which could affect precision and recall. Another way is to reduce the number of local lists sent to the brokers, by designing more complex and elaborate distributed protocols.

The network bottleneck is due to the large number of query servers and the continuous data interchange with the brokers, especially in a replicated IR system. The network load could be alleviated by reducing the number of bytes sent over the network or by using different network configurations and technologies. The networktrafficcanbelimitedbyreducing thenumberofresultsineachlocal answerset(withtheadditional compressing the local answer sets up to a 10%. In this case, the network load was substantially reduced and therefore, the performance obtained by the replicated system was nearly optimal, as described in Fig. 9 .
Moreover, it is important to recall that we have modeled the network as a single LAN. This could have an impact on the obtained performance measures. In the future, we intend to use a more realistic network model for our distributed IR system.

Theanalysisoftheclustered systemsindicatesthatthebestthroughput ofthesesystemsisachievedwhen a large number of query servers is used, i.e. greater than 1000 in total. In this case, the clustered system outperforms the replicated one. A clustered system will reduce the network load substantially, as only a work load increases (and the throughput improvements are slowed) as the number of servers increases.
While in a clustered system the processing times in the clustered query servers could be slightly higher, the local answers will reach faster the broker, and the brokers will receive fewer answers, thus processing the final results more efficiently.

However, the clustered systems must be configured a priori, depending on the distribution of the queries accordingly.

We also plan to study different solutions for the brokers and network bottlenecks, as well as their impact on the retrieval performance. Moreover, these results could be used to extend a basic centralised IR system to a distributed one, and then analyse the correspondence between the expected and the actual perform-ance. In general, we believe that the results in this paper are useful to any group interested in handling a very large collection like SPIRIT, or building a large-scale search engine.
 Acknowledgments The work of the first author has been partially supported by the Comisio  X  n Interminis-terial de Ciencia y Tecnolog X   X  a (CICYT) of the Spanish government, under project TIC2001-0547 and by the Fundacio  X  n Caixa
Galicia (Beca curso 2002/2003 para Estudios de Postgrado en Universidades y en Centros de Investigacio  X  n de Excelencia Acade  X  mica).

The work of the second and third authors is funded by a UK Engineering and Physical Sciences Re-search Council (EPSRC) project grant, number GR/R90543/01. The project funds the development of the Terrier Information Retrieval framework (url: http://ir.dcs.gla.ac.uk/terrier ).
We would like to thank Mark Sanderson and Hideo Joho for giving us access to the 1 TB dataset used for the SPIRIT Project. We would also like to thank Prof. David Harper for his important comments and suggestions.
 References
