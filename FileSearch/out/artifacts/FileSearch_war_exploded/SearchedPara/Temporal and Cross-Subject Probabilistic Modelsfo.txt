 In functional Magnetic Resonance Imaging, or fMRI , an MR scanner measures a physiological sig-signal [12]. Functional scans can be taken during a task of in terest, such as the subject viewing images or reading text, thus providing a glimpse of how brain activity changes in response to cer-tain stimuli and tasks. An fMRI session produces scans of the brain volume across time, obtaining BOLD measurements from thousands of small sub-volumes, or voxels at each time step.
 Much of the current fMRI research focuses on the goal of ident ifying brain regions activated in response to some task or stimulus (e.g., [7]). The fMRI signa l is typically averaged over many repeated stimulus presentations, multiple time points and even different subjects, in order to find data, in effect demonstrating the ability to  X  X ead X  informa tion from the scans. For instance, Tong functional scans of visual cortex, and Mitchell et al. [13] s uccessfully applied machine learning techniques to a predict a variety of stimuli, such as the sema ntic category of words presented to a subject. Such prediction work has demonstrated that, despi te the relatively low spatial resolution of fMRI, functional data contains surprisingly reliable an d detailed signal [9, 6, 13], even on time scales as short as a few seconds. Going beyond identifying th e location of responsive regions, these models begin to demonstrate how the brain encodes states and stimuli [3], often capturing di stributed patterns of activation across multiple brain regions simul taneously. This line of research could also eventually provide a mechanism for accurately tracking cog nitive processes in a non-invasive way. Another recent innovation is the use of long and rich stimuli in fMRI experiments, such as a com-mercial movie [8], rather than the traditional controlled, repeating simple stimuli. These experiments present more difficulty in analysis, but more closely mirror natural stimulation of the brain, which may evoke different brain activity patterns from tradition al experiments.
 The recent Pittsburgh Brain Activity Interpretation Competition [2] (PBAIC), featured both the use experiences given functional MRI sessions. Functional sca ns from three subjects were taken while the subjects watched three video segments. Thus, during the scan, subjects were exposed to rich stimuli including rapidly changing images of people, meani ngful sounds such as dialog and music, and even emotional stimuli, all overlapping in time. Each su bject also re-viewed each movie multiple times, to rate over a dozen characteristics of the videos ove r time, such as Amusement , presence of Faces or Body Parts , Language , and Music . Given this data set, the goal was to predict these real-valued subjective ratings for each subject based only on the fMRI scans.
 In this paper, we present an approach to the PBAIC problem, ba sed on the application of machine learning methods within the framework of probabilistic gra phical models. The structured probabilis-tic framework allowed us to represent many relevant relatio nships in the data, including evolution of course the relationship between voxels and ratings. We also explored novel feature selection meth-favor of jointly selecting nearby voxels.
 We demonstrate the performance of our model by training from a subset of the movie sessions and the 2006 PBAIC out of forty entries. We demonstrated very goo d performance in predicting many of the ratings, suggesting that probabilistic modeling for the fMRI domain is a promising approach. An analysis of our learned models, in particular our feature selection results, also provides some insight into the regions of the brain activated by different stimuli and states. Our system for prediction from fMRI data is based on a dynamic , undirected graphical probabilistic model, which defines a large structured conditional Gaussia n over time and subjects. The backbone of the model is a conditional linear Gaussian model, capturi ng the dependence of ratings on voxel measurements. We then extend the basic model to incorporate dependencies between labels across time and between subjects.
 point t , we have a collection of ratings R inherent in the BOLD signal response [4]. For each s and t , we also have the voxel activities V Both voxels and ratings are continuous variables. For mathe matical convenience, we recenter the data such that all variables (ratings and voxels) have mean 0 .
 Each rating R that subject X  X  brain as features. We can express R the dependence of the rating on the voxels is time-invariant , so that the same parameters w  X  number of voxels. In Sec. 3.1 we explore a variety of feature s election and regularization methods relevant to this problem.
 The linear regression model forms a component in a larger mod el that accounts for dependencies among labels across time and across subjects. This model tak es the form of a (dynamic) Gaussian Markov Random Field (GMRF) [15, 11]. A GMRF is an undirected g raphical probabilistic model that expresses a multi-dimensional joint Gaussian distrib ution in a reduced parameter space by mak-ing use of conditional independences. Specifically, we empl oy a standard representation of a GMRF derived from the inverse covariance matrix, or precision matrix Q =  X   X  1 of the underlying Gaus-sian distribution: For X = ( X written as P ( X )  X  exp(  X  1 representation, as Q ( i, j ) = 0 exactly when X corresponding to the absence of an edge between X In our setting, we want to express a conditional linear Gauss ian of the ratings given the voxels. A distribution P ( X | Y ) can also be parametrized using the joint precision matrix: where E Our particular GMRF is a joint probabilistic model that enco mpasses, for a particular rating type j , the value of the rating R assumes a stationary distribution, so that both node and edg e potentials are invariant across time. This means that several entries in the full precision matrix Q are tied to a single free parameter. We will treat each rating type separately. Thus, the variabl es in the model are: all of the voxel measurements V R a joint distribution over the rating variables, conditional on all of the voxel measurements. Thus, there will be no free parameters corresponding to the voxel n odes due to the use of a conditional model, while rating nodes R Each rating node R the same time slice. The set of voxels can vary for different r atings or subjects, but is consistent j includes edges between each rating R and R encode the dependencies between the ratings of different su bjects, in a way that does not assume have an edge between R Overall, our model encodes the following conditional distr ibution:
P ( R ( j, ) | V ( , )) = maximize the conditional likelihood of the observed rating s given the observed voxel measurements, highly noisy, high-dimensional voxel activation distribu tion. We split parameter learning into two phases, first learning the dependence of ratings on voxels, a nd then learning the parameters between rating nodes. The entire joint precision matrix over all vox els and ratings would be prohibitively large for our learning procedure, and this approximation wa s computationally much more efficient. then modify our graph, replacing the very large set of voxel n odes with a new, much smaller set of nodes representing the linear combinations of the voxel act ivations which we just learned. Using the reduced graph, we learn a much smaller precision matrix. We d escribe each of these steps below. 3.1 From Voxels to Ratings To learn the dependencies of ratings on voxels for a single su bject s , we find parameters w using linear regression, which optimize However, to deal with the high dimensionality of the feature space relative to the number of training can be viewed as a spatially-based prior over w in the objective for each rating using a simple feature selec tion method  X  we compute the Pearson The number of voxels to select is a setting which we tuned, for each rating type individually, using five-fold cross-validation on the training set. We chose to u se the same number of voxels across subjects, which is more restrictive but increases the amoun t of data available for cross-validation. Even following this feature selection process, we often sti ll have a large number (perhaps hundreds) of relevant voxels as features, and these features are quite noisy. We therefore employ additional regularization over the parameters associated with these v oxels. We explored both L (Lasso) regularization, corresponding to a Gaussian and a L aplacian prior respectively. Introducing both types of regularization, we end up with a log-likelihoo d objective of the form: Finally, we introduce a novel form of regularization, inten ded to model spatial regularities. Brain activity associated with some types of stimuli, such as lang uage, is believed to be localized to some number of coherent regions, each of which contains multiple activated voxels. We therefore want to from noise. We therefore define a robust  X  X inge-loss X -like d istance function for voxels. Letting k v We now introduce an additional regularization term into the objective Eq. (3). This term can offset the L larization term is applied to the absolute values of the voxe l weights, hence allowing nearby voxels to have opposite effects on the rating; we do observe such cas es in our learned model. Note that, according to our definition, the spatial prior uses simple Eu clidean distance in the brain. This is cortex. A promising extension of this idea would be to apply a geodesic version of distance instead, measuring distance over gray matter only. 3.2 Training the Joint Model We now describe the use of regression parameters, as learned in Sec. 3.1, to reduce the size of our joint precision matrix, and learn the final parameters inclu ding the inter-rating edge weights. Given w we remove the voxel nodes V w s ( j ) T V s ( , t ) only have to find a single parameter Q model, there is a direct relationship between optimization in the reduced formulation and optimiz-ing using the original formulation. Assuming w the optimal Q voxel ( s, j, l ) in the full form would be proportional to Q the reduced form. This does not guarantee that our two phase learning results in globally op timal parameter settings, but simply that given w The joint optimization of Q ing to the reduced conditional likelihood. The reduced form of Eq. (1) simply replaces the final terms containing Q voxel ( s, j, ) with: The final objective is computationally feasible due to the re duced parameter space. The log likeli-positive semi-definite to ensure a legal Gaussian distribut ion. Thus, we can solve the problem with semi-definite programming using a standard convex optimiza tion package [1]. Last, we combine all learned parameters from both steps, repeated across time st eps, for the final joint model. 3.3 Prediction Prediction of unseen ratings given new fMRI scans can be obta ined through probabilistic inference on the models learned for each rating type. We incorporate th e observed voxel data from all three subjects as observed values in our GMRF, which induces a Gaus sian posterior over the joint set of ratings. We only need to predict the most likely assignment t o ratings, which is the mean (or mode) of this Gaussian posterior. The mean can be easily computed u sing coordinate ascent over the log likelihood of our joint Gaussian model. More precisely, we i terate over the nodes (recall there is one node for each subject at each time step), and update its me an to the most likely value given the current estimated means of its neighbors in the GMRF. Let Q all nodes over time and subject, constructed from Q Then for each node k and neighbors N  X  points, given the functional data from scans during a new mov ie. As described, the fMRI data collected for the PBAIC included fMRI scans of three different subjects, and three sessions each. In each of the sessions, a subject vi ewed a movie approximately 20 min-utes in length, constructed from clips of the Home Improvement sitcom. All three subjects watched the same movies  X  referred to as Movie1 , Movie2 and Movie3 . The scans produced volumes with approximately 30 , 000 brain voxels, each approximately 3.28mm by 3.28mm by 3.5mm, with one volume produced every 1.75 seconds. Subsequently, the subj ect watched the movie again multiple times (not during an fMRI session), and rated a variety of cha racteristics at time intervals corre-sponding to the fMRI volume rate. Before use in prediction, t he rating sequences were convolved with a standard hemodynamic response function [4]. The core ratings used in the competition were Amusement , Attention , Arousal , Body Parts , Environmental Sounds , Faces , Food , Language , Laughter , Motion , Music , Sadness , and Tools . Since the ratings are continuous values, compe-tition scoring was based on the correlation (for frames wher e the movie is playing) of predicted Figure 2: (a) Average correlation of predicted ratings and t rue ratings, for simple models, the full (c) Effect of varying the number of voxels used for Language, Amusement, and BodyParts. consistency, we adhere to the use of correlation as our perfo rmance metric.
 To train our model, we use the fMRI measurements along with al l ratings from all subjects X  sessions for some set of movies, holding out other movies for testing. We chose to use an entire held out the prediction task. The training set is used both to learn th e model parameters and for the cross-ratings for the held out test movies for all subjects, from fM RI data alone. Our GMRF model shows significant improvement over simpler models on the predicti on task, and a version of this model was used in our submission to the PBAIC. We also evaluate the resu lts of our feature selection steps, examining which regions of the brain are used for each rating prediction. 4.1 Rating Prediction For our own evaluation outside of the competition, given tha t we did not have access to Movie3 viewing Movie1 , and then made predictions using the scans from all subjects for Movie2 . The pre-dictions made by the dynamic GMRF model were highly correlat ed with the true ratings. The best for both Language and Faces was above 0 . 7 , and we achieved correlations of above 0 . 5 on 19 of the 39 core tasks (three subjects time 13 ratings).
 To evaluate the contribution of various components of our mo del, we also tested simpler versions, beginning with a regularized linear regression model. We al so constructed two simplified versions of our GMRF, one which includes edges between subjects but no t time interactions, and conversely one which includes time interactions but removed subject ed ges. Finally, we tested our full GMRF model, plus our GMRF model along with the spatial prior. As sh own in Fig. 2(a), both the time de-combined model, which includes both time and subject edges, demonstrates significant improvement over including either alone. We also see that the addition of a spatial prior (using cross-validation to select which ratings to apply it to), results in a small add itional improvement, which we explore further in Sec. 4.2. Performance on each of the rating types i ndividually is shown in Fig. 2(b) for of rating type accuracy for the different models is surprisi ngly consistent.
 used our joint GMRF model, but had not developed the spatial p rior presented here. We trained the model using data from Movie1 and Movie2 and the corresponding ratings from all three subjects. We submitted predictions for the unseen Movie3 predictions. Around 40 groups made final submissions. first place group, Olivetti et al. [14], employed recurrent n eural networks with mutual information  X  they applied regularized linear models with smoothing acr oss time, spatially nearby voxels and averaging across subjects. Some groups employed machine le arning techniques such as Support Vector Regression, while others focused on defined Regions o f Interest as features in prediction. 4.2 Voxel Selection and Regularization We also examined the results of feature selection and regula rization, looking at the location of vox-els used for each rating, and the differences resulting from various techniques. Starting with the approximately 30 , 000 brain voxels per subject, we apply our feature selection tec hniques, using cross-validation on training sessions to determine the num ber of voxels used to predict each rating. The optimal number did vary significantly by rating, as the gr aph of performance in Fig. 2(c) demon-the Language rating does well with several hundred voxels, and Amusement uses an intermediate number. This may reflect the actual size and number of brain re gions activated by such stimuli, but likely also reflects voxel noise and the difficulty of the indi vidual predictions.
 Visualization demonstrates that our selected voxels often occur in regions known to be responsive areas known to respond to motion in the visual field (Fig. 3(a) ). Likewise, many voxels selected for Language occur in regions linked to language processing (Fig. 4(b)). However, many other the intermixed and correlated stimuli in the videos. For ins tance, the ratings Language and Faces for subject 1 in Movie1 have correlation 0 . 68 , and we observed that the voxels selected for Faces and Language overlapped significantly. Voxels in the language centers of the brain improve the prediction of Faces since the two stimuli are causally related, but it might be pr eferable to capture this correlation by adding edges between the rating nodes of our GMRF. Interestingly, there was some consistency in voxel selection between subjects, even though our model did not incorporate cross-subject voxel selection. Comparing Faces voxels for Subject 3 Fig. 3(b), to voxels for Subject 2 Fig. 4(a), we see that the respective voxels do come from sim ilar regions. This provides further evidence that the feature selection methods are finding real patterns in the fMRI data. improved in cross-validation trials for all subjects  X  Motion , Language , and Faces . Comparison coherent groups of voxels. Note the total number of voxels selected does not rise in general. As shown in Fig. 4(a), the voxels for Faces for subject 3 include a relevant group of voxels even without Similar results for Language are shown for subject 1. Arousal prediction was actually hurt by This work, and the other PBAIC entries, demonstrated that a w ide range of subjective experiences can be predicted from fMRI data collected during subjects X  e xposure to rich stimuli. Our proba-bilistic model in particular demonstrated the value of time -series and multi-subject data, as the use of edges representing correlations across time and correla tions between subjects each improved the (a) Faces, Subject 2 (b) Language, Subject 1 ularization and the use of a spatially-based prior, reliabl e prediction was possible using individual voxels as features. Although voxels were selected from the w hole brain, many of the voxels selected as features in our model were located in brain regions known t o be activated by relevant stimuli. One natural extension to our work would include the addition of interactions between distinct rating types, such as Language and Faces, which are likely to be corr elated. This may improve predictions, and could also result in more targeted voxel selection for ea ch rating. More broadly, though, the PBAIC experiments provided an extremely rich data set, incl uding complex spatial and temporal interactions among brain voxels and among features of the st imuli. There are many aspects of this data we have yet to explore, including modeling the relation ships between the voxels themselves direction would be to determine which temporal aspects of th e semantic ratings are best encoded by brain activity  X  for instance it is possible that brain activ ity may respond more strongly to changes in some stimuli rather than simply stimulus presence. Such i nvestigations could provide further insight into brain activity in response to complex stimuli i n addition to improving our ability to make accurate predictions from fMRI data.
 Acknowledgments This work was supported by NSF grant DBI-0345474.

