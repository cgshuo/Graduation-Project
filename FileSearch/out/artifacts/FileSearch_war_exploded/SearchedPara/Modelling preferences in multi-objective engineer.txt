 1. Introduction
System design is a complex task when design parameters have to meet a combined number of specifications or objectives which are usually conflicting. System design can be understood as the search for the best compromise among all the required specifica-tions. This challenge is called multi-objective optimization (MOO). The solution to a MOO problem is normally not unique since the best solution for all objectives does not exist. There is a set of good solutions referred to as non-dominated solutions (none is better for all objectives) that define the Pareto set and the
Pareto front (objective values for Pareto set solutions). Several techniques have been developed to obtain the Pareto set and front ( Coello et al., 2002; Coit et al., 2006 ), and they are usually obtained before a decision making procedure. This is a subjective and non-trivial task that depends on designer preferences and is normally based on Pareto front values. Even though decision maker (DM) procedures focus on helping designers in this task, the most common practice when solving MOO problems is the optimization of a single objective formed by a weighted sum of objectives. The weights selection is an iterative and trial-and-error procedure, and once they are selected, the solution obtained does not guarantee the best compromise among the specifications because of the infinite number of solutions that exist for a MOO problem.
 preferences, or acknowledge target values for specifications and values expressing the relative importance of one objective over others. Most of these methods have parameters in the form of coefficients, exponents, constraints, etc., which express the DM X  X  wishes. Some common proposals to incorporate a priori prefer-ences in the searching algorithms include ( Marler and Arora, 2004 ): designer X  X  experience of the problem and expert knowledge about the required specifications. Preferences for each objective are specified in a flexible and natural way, by means of the so-called class functions and range of preferences. The optimization process becomes more transparent for the designer, who only needs to compute the objectives and define the range of preference for each objective, and so leading the search process to the best solution in terms of the designer X  X  preferences.

This paper is organized as follows. Section 2 reviews the physical programming method and summarizes the most im-portant concepts associated with this methodology. Section 3 describes the new method, called global physical programming (GPP), as an evolution of the original PP, and specifies how to calculate preference functions with a simpler formulation and how to rewrite the MMO problem to a non-linear programming (NLP) problem. Finally, Section 4 presents three engineering applications to illustrate the benefits of the proposed methodol-ogy. Conclusions are presented in Section 5. 2. Physical programming synopsis
Physical programming (PP) ( Messac, 1996 ) is very suitable for multi-objective engineering design since it formulates design objectives in an understandable and intuitive language for designers. PP is a MOO technique that includes information available about the problem in the optimization phase, and enables an engineer to express preferences relative to each objective function with more detail than by simply saying  X  X inimize X ,  X  X aximize X ,  X  X reater than X ,  X  X ess than X ,  X  X qual to X  and so on. Initially, PP translates the designer X  X  knowledge into classes with previously defined ranges. These preference functions reveal the DM X  X  wishes using physical units for each of the objectives in the MOO problem. From this point of view, the problem is moved to a different space where all the variables are independent of the original MOO problem. Later, a single objective optimization problem is built on these preference functions and solved using any non-linear programming optimization technique. The final result is a solution that is very close, if it is possible, to the solution required by the DM.

PP has been successfully applied to many different engineering design problems. From structural design of airplane wings ( Messac and Hattis, 1996 ), or propeller design ( Chen et al., 2000 ), to robust feedback control ( Martinez et al., 2006 ), and production planning ( Messac et al., 2002 ). This variety of applications shows the value of the PP method.

In general, the PP method determines the best parameter vector x that satisfies an objective set g i ( x ), ( i  X  1, priori knowledge of the designer X  X  preferences. Within the PP procedure the designer expresses preferences with respect to each objective using eight different classes (four soft and four hard), depending on the sharpness of the preference. Soft classes are labeled as: Class-1S: Smaller is better (minimization).
 Class-2S: Larger is better (maximization).
 Class-3S: Value is better.

Class-4S: Range is better. and the hard classes are a direct translation of the problem X  X  equality and inequality constraints.

For each i th objective with a soft class selected, the designer has to establish six ranges of preferences: highly desirable (HD), desirable (D), tolerable (T), undesirable (U), highly undesirable (HU), and unacceptable (UNA). Fig. 1 a shows this classification, by means of g i k values for a generic Class-1S objective. Notice that extreme values of g i k are specified by the designer in the same physical units as the objective. This helps to quantify the preferences associated with the objective g i ( x ).

Once the parameters have been properly selected (e.g. class type and range definition), the class functions g i  X  g i calculated (see Fig. 1 ). Since each class function g i  X  g normalized objective of g i ( x ), it is possible to state a single objective optimization problem, whose solution x  X  argmin represents the optimal design parameters of the multi-objective optimization problem with n sc objectives or design specifications.
The class functions are calculated satisfying several mathe-matical properties, thus making the optimization technique work more efficiently. Nevertheless, to match these properties it is necessary to build an expensive and iterative algorithm. The right algorithm execution and its subsequent adjustment enable all the g ( x ) objectives that have the same class function image g extreme points. This fact responds to an heuristic rule called the OVO-rule (one vs. others) ( Messac et al., 1996 ). The OVO-rule is an implicit intra-criterion that specifies preferences for one objective with respect to the others, and it guarantees the worst objective minimization with respect to the best minimization. Thanks to this algorithm, for each objective the designer only has to choose the class and g i k values to establish the range of preferences (tolerable, desirable, etc.). The algorithm then builds the right curvatures in an overall way while considering all the objectives at the same time. 3. Global physical programming (GPP)
As mentioned in the previous section, the curvature of the class functions is calculated with an expensive and iterative algorithm that preserves mathematical properties such as derivativity, convexity, etc. Their construction is conditioned to the use of gradient-based methods (such as SQP) for solving the problem optimization. However, in spite of efforts to preserve convexity between objectives g i ( x ) and class functions, the aggregate function (1) in the transformed single objective problem could be a constrained, non-linear, and multimodal function. This fact is due to the relations between the design parameters x and the objectives g i ( x ). Evolutionary algorithms have shown their behaviour as global optimizers. Therefore, if an evolutive optimization method, such as GAs, is selected to solve an optimization problem, the class function curvature does not matter. This fact permits us to modify the procedure to construct class functions in a very simple way; but keeping the essence of the PP method. Similar simplifications have been developed in
Martinez et al. (2008a, b) , where the class functions are piecewise exponential or linear functions; but without strictly fulfilling the OVO-rule.
 The construction of these new class functions is based on:
The best result for each objective must be translated into the solution of a minimization problem.

The limits of each preference range must present the same image in the class function for all objectives of the MOO problem. The goal is that the same preference in each objective will have the same image in all class functions. Hence, each preference range will weigh the same in the single aggregate objective to optimize.

Let N objs be the number of design objectives that the problem comprises and let N be the number of preference ranges that the designer wants to manage for the whole multi-objective problem.
The images a k at the range boundaries 2 g i k can be calculated as  X  0  X  2  X   X  a k 1 N objs  X  1 o k r N  X  X  4  X 
Notice that these values are equal for all the class functions defined, preserving the OVO rule as an implicit intra-criterion that specifies preferences for one objective function with respect to the others. Therefore, the preference intervals defined for each objective g i ( x ) always produce the same D a k image change in their associated class function.

In the following subsections a new definition for class functions, as polynomials in g i ( x ), is developed. 3.1. Class 1S function calculation
For the i th objective g i ( x ), N  X  1 extreme range points, g used by the designer to quantify the preferences associated with the design objective. Note that g i k values have the same physical units as the related objective. With this operation, each objective function will be divided into N intervals with an associated preference. The extreme points g i k will be specified in ascending value, expressing greater preference for the first values and lower represents the best value for the design objective. This point may, or may not, be reached by the final solution.
 if g k 1 i o g i  X  x  X  r g k i then f k  X  x  X  X  a k 1  X  D a k g i  X  x  X  g defined as ( Fig. 1 b) 3.2. Class 2S function calculation defined in the opposite direction to function 1S. Therefore, points g i k will be specified in ascending value too, but expressing lower preference for the first values and greater preference for the later values.
 takes the form as 3.3. Class 3S function calculation are specified: let g i 0 be this ideal value, hence N left and right ranges are defined with the values g i kL (left) and g i kR ranges represent a 1S function. Therefore, the 3S class function is given by 3.4. Class 4S function calculation objective is expressed by the designer. Thus, the extreme points right (class 1S) ranges are defined: n  X  x  X  X  3.5. New aggregated function and its optimization with genetic algorithms
Once the class functions for each design objective have been calculated, the MOO problem can be stated as a constrained optimization problem: min s : t : h j  X  x  X  Z 0 x m p r x p r x M p  X  10  X  where x A R p are the vector design variables, N objs is the number of by adding all the class function images, with all of them equally weighted. Furthermore, because of its normalizing role, each term in the sum is independent of the physical units it comes from.
The problem stated in (10) is, in general, a non-linear and multimodal optimization problem, therefore, to solve it, it is necessary to use a suitable optimi zation technique. Good quality solutions could not be found due to the use of an iterative numerical optimization method  X  which needs initial conditions and the possible presence of local minima in the aggregated function. For this reason, a global optimization technique is used as a substitute for the non-linear programming optimization originally used in the
PP method. Since genetic algor ithms (GAs) are generic search methods, they are used to solve the non-linear programming (NLP) problem stated in (10). There a re several variations in the GA implementation: various gene codifications, various implementa-tions of the genetic operators and constraint handlings, etc. In this work, the GA implementation presen ts the following characteristics: Real value coding is used ( Michalewicz, 1996 ).

Selection is made by the operator known as stochastic universal sampling ( SUS )( Baker, 1987 ).
 The intermediate recombination operator ( M  X  uhlenbein and
Schlierkamp-Voosen, 1993 ) is used for crossover and per-formed with a probability P c .

Mutation operation is performed with a probability P m and normal distribution (with standard deviation set to 20% of the search space range).

There are several approaches regarding constraint handling methods used with GA ( Coello, 2002 ), and most of them use penalty functions. This mechanism adds a penalty term which transforms the constrained problem to an unconstrained problem, splitting the feasible solutions from the unfeasible solutions. In this work, the proposed constraint handling method described in Deb (2000) is applied, where penalty parameters are not needed because solutions are never compared in terms of both objective function and constraint violation information. The following fitness function, where infeasible solutions are only compared on their constraint violation, is therefore used: F  X  x  X  X  where /S denotes the absolute value of the operand if it is negative, and zero if it is positive, and J max is the worst feasible aggregated function value (10) in the population. In the case of an entire unfeasible population, J max is set to zero. The GA will then evolve to solutions closer to the feasible zone, since the fitness F ( x ) punishes gradually according to the degree of constraint violation. 4. Engineering applications
To illustrate the value of the proposed method, three different engineering applications are presented in this section. In the application examples, the number of preference ranges N  X  5 and able and highly undesirable ) have been adopted from the PP method. However, the GPP can be used with any value of N .
For all the examples, the GPP parameters are set to N  X  5, ini  X  0 : 25, and n  X  2. Also, the parameters of the implemented GA 4 are set to: number of generations  X  150, population size N  X  1000, P c  X  0.8 and P m  X  0.1. 4.1. Example 1: sandwich beam
The problem proposed in Messac (1996) , consists of a pinned X  pinned sandwich beam that supports a motor ( Fig. 3 ). A vibratory disturbance (at v Hz) is imparted from the motor onto the beam which is of length L , width b , and symmetrical about its midplane. The design parameters are x  X  X  d 1 d 2 d 3 bL
And the design objective functions, g i ( x ), are (1) Fundamental frequency of the beam (Hz): (2) Cost ($): (3) Beam width (m): g 3 ( x )  X  b . (4) Beam length (m): g 4 ( x )  X  L . (5) Beam mass (kg): g 5  X  x  X  X  M  X  m L . (6) Beam semi-height (m): g 6 ( x )  X  d 3 . (7) Width of layer 1 (m): g 7 ( x )  X  d 1 . (8) Width of layer 2 (m): g 8 ( x )  X  d 21  X  d 2 -d 1 . (9) Width of layer 3 (m): g 9 ( x )  X  d 32  X  d 3 -d 2 where E i , c i and r i are Young X  X  modulus, cost per unit volume and mass density, for each type of material i A  X  123 .
 Let vibration v  X  10Hz and the materials are defined in Table 1 .
In this example and for comparison purposes with the original PP method, the designer X  X  subjective preferences as expressed in
Messac (1996) and described in Table 2 are used. This table provides the numerical values that fit the ranges of differing desirability for each objective. Notice that beam X  X  surface maximization (class 2S) is required while the rest of specifications are minimized (1S). The design results generated by the original PP method, x PP , and by the proposed method x are x
PP  X  X  0 : 299 0 : 309 0 : 345 0 : 681 3 : 999 x GPP  X  X  0 : 328 0 : 338 0 : 360 0 : 595 3 : 991
Comparison of both results is shown in Table 3 where it can be observed that the GPP solution is better in one objective (cost c ).
Furthermore, note that initial values for design parameters x are not needed when GPP is used. 4.2. Example 2: three-bar truss of bar truss design is presented. Fig. 3 describes a three-bar truss broadly used as a benchmark to define the best solutions based on given specifications. The truss parameters proposed in Martinez et al. (2007) have been used, and therefore, the vector of the design variables corresponds to the sections of the bars ( x  X  a a 3 ) with constraints a iu  X  2cm 2 (maximum section) and a cm 2 (minimum section) for all of the variables. The rest of the parameters for the truss are: L  X  1m; y  X  45 3 ; a  X  30 3 ; F kN; E  X  200e9Pa (Young X  X  modulus); r  X  X  7850 7400 7625 kg/m (density of each bar) and maximum stress accepted in each bar s  X  200e6Pa.
 (1) Price at factory ($): where K  X  15$/kg, and v are the volume of each bar (cm 3 ). The second term is the manufacturing cost, where
C (2) Displacement of node P (cm): g 2  X  x  X  X  d  X  0 : 25 d 1  X  0 : 75 d 2 where deformations d 1 and d 2 are calculated as "#  X  a 2  X  a 1 sin 3 y  X  a 3 sin 3 a  X  a 1 sin 2 y cos y  X  a 3 sin 2 a cos a  X  a 1 sin y cos 2 y  X  a 3 sin a cos 2 a  X  17  X 
The reaction forces per surface unit in each bar, N j / a by
N a  X 
N a  X 
N a  X 
Since they are constrained by the maximum stress accepted, s , the constraints included in the problem formulation are j N
To analyze the method X  X  potentiality and its useful assistance in engineering design, several scenarios are presented. Rather than engaging in tweaking weights, the designer can instead explore the consequences of the various physically meaningful preference choices. Both objectives are to be minimized. For this reason, both class 1S functions have been selected. Initially, preferences are stated for each objective ( Table 4 ) and later, their class functions ( Fig. 4 ) are computed according to (5). With these preference choices, the search process will be guided to find prices under $50. The mechanical engineer knows, based on his own experience, that displacements above 0.1cm would be highly undesirable . However, the results shown in Table 6 (more than $150 is highly undesirable ) show that there is no feasible solution for these preferences. At this moment, the designer has information about the exigency of his selection; and therefore, some slackening of preference is needed. Table 5 shows this new preference set and Fig. 5 shows the newly calculated class functions. The new solution shown in Table 6 is more realistic according to the designer X  X  wishes ($98 being a tolerable price).

Regarding parameter n , a discrete solution for the multi-objective optimization problem (Pareto frontier) was obtained using the e v MOGA algorithm ( Herrero et al., 2007 ). Fig. 6 shows that all the solutions calculated by varying n belong to this frontier. The GPP method is therefore forced to search solutions that are nearer to the extremes of the range and always produce non-dominated solutions. 5 4.3. Example 3: predictive controller design
Finally, a controller tuning example for the forward speed control of a helicopter is presented. For a sampling time of 0.6s, the discrete transfer function between rotor angle and forward speed is given by ( Maciejowski, 2002 ) G  X  z 1  X  X  B  X  z 1  X  A  X  z 1  X   X  kz with k  X  6.472. An uncertainty of 7 20 % for parameter k will be assumed during the controller parameter tuning.

Since it represents an unstable and non-minimum phase process, a generalized predictive controller (GPC) ( Clarke et al., 1987 ) will be used to control the system. The GPC has been shown to be an effective way of controlling single-input single-output discrete processes and its formulation uses the following CARIMA stochastic model: y  X  k  X  X  B  X  z 1  X  A  X  z 1  X  u  X  k 1  X  X  T  X  z 1  X  D A  X  z 1  X  x  X  k  X  represents disturbance, z 1 is the backward shift operator, D is the difference operator (1 z 1 ), and T  X  z 1  X  X  X  1  X  t polynomial filter.
 good practical sense: using the model, it predicts the behaviour of the output as a function of future control increments and minimizes a cost index for these increments . For each sample time, the control law is obtained by minimizing the following cost index: J  X  D u  X  X  where N  X  N 2 N 1 +1 is the prediction horizon, N u is the control horizon, a  X  is the prediction error weighting factor, l time k + i .
 adjustable parameters that affect closed-loop performance. In this example, the design parameters under consideration are x  X  X  N 1 N 2 N u a l t f n the conflicting design objectives g i ( x ), that describe the closed loop performance: (1) Settling time at 7 2 % (s): g 1 ( x )  X  t est nom . (2) Rising time from 10% to 90% (s): g 2 ( x )  X  t rise nom (3) Overshoot (%): g 3  X  x  X  X  d nom . (4) Worst case settling time (s) for k 7 20 % : g 4 ( x )  X  t (5) Worst case overshoot (%) for k 7 20 % : g 5  X  x  X  X  d max (6) Control action standard deviation (deg) 6 : g 6  X  x  X  X  (7) Control action increment deviation (deg): g 7  X  x  X  X  s subject to the following constraints h j ( x ): (2) Maximum control action : u max A  X  22 deg. (3) Maximum control action increment : D u max A  X  0 : 50 : 5 deg.
To show how the GPP method can be used as an engineering tool, two different design scenarios have been stated. Each corresponds to two very different flight modes, in which two different dynamic control performances are needed:
Scenario 1: To fly forward, the control engineer looks for fast responses and overshoots of under 10 % are permitted. The lower the value of the objectives g i ( x ), the better the performance of the controller, so class 1S functions are selected.

Scenario 2: To fly sideways, responses with settling times of around 17s and with low overshoots are needed. In order to attain the desired settling time, a 4S class function is used for objectives g 1 ( x ) and g 4 ( x ). The requirements for overshoot are fixed with choices for g 3 ( x ) and g 5 ( x ) below 2% ( highly undesirable ).

It is possible to define the preference sets of Table 7 which show the control engineer choices for both flight modes. The search space is bounded by N 1 A  X  1 , 30 , N 2 A  X  2 , 30 , N
A  X  0 : 001 , 10 , l A  X  0 : 001 , 20 , tf A  X  0 : 01 , 0 : 99 and n shows the solutions the GPP methods offer. For all solutions, the constraint related with the closed loop stability is fulfilled.
In the scenario 1 results ( Fig. 7 a), notice how the typical trade-off between overshoot and settling time is considerable. Tolerable times are obtained with highly desirable overshoots with the nominal model. However, undesirable values for these objectives appear when the controller is tested with the perturbed model. If the control engineer is not satisfied, he might make his preference choices more attainable. In scenario 2 results ( Fig. 7 b), it is shown that it is easier to control the process with a soft and cautious control policy. For this reason, the GPP method puts the control effort parameter at its upper limit. 5. Conclusions
This paper describes a methodology to incorporate a priori preferences in a multi-objective optimization context. Details about its implementation with GAs have been presented with several engineering applications oriented to engineering design problems.

A method called global physical programming (GPP) is presented, where the philosophy of physical programming (PP) has been used. Two components have been totally modified: the construction of the class functions has been made simpler; and the optimizer has been replaced by a GA that avoids local minima problems. The preference method offers a problem formulation that reflects real-life engineering design. The linguistic terms, such as tolerable, highly desirable, etc., have been deliberately introduced to bring imprecision to the design process and make the decision making phase easier. Furthermore, the time-consuming and trial-and-error procedure of weight selection without a clear meaning has been moved to the selection of preference ranges that have the same units as the objective functions. Rather than engaging in tweaking weights, the designer can instead explore the consequences of the various physically meaningful preference choices. Thus the designer, after examining the results, may decide to explore other possibilities.
 References output (km/h)
U (deg)  X  U (deg) output (km/h)
U (deg)  X  U (deg) output (km/h) output (km/h)
