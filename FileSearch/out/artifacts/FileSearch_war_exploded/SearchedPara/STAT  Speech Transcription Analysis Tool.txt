 The theoretical and practical value of studying human accented speech is of interest to language teachers, linguists, and computational linguists. It is also part of the research program behind the Speech Accent Archive ( http://accent.gmu.edu ) housed at George Mason University. The Archive is a growing database of English speech varieties that contains more than 1, 100 samples of native and non -native speakers reading from the same English paragraph. The non -native speakers of Engli sh come from more than 250 language bac k-grounds and include a variety of different levels of English speech abilities . The native samples de m-onstrate the various dialects of English speech from around the world. All samples include ph o-netic transcriptions, phonological generalizations, dem ographic and geographic information . For comparison purposes, t he Archive also includes phonetic sound inventories from more than 200 world languages so that researchers can perform various contrastive analyses and accented speech studies . teners can immediately and automatically notice that speakers are different. For example, Chinese speakers of English sound different from French speakers of English. The Speech Accent A rchive stores and presents data that s pecifie s and codifie s these speech differences at the phonetic segment level. Trained human linguists compare a standard speech sample with phonetically transcribed speech sampl es from each (non -standard or non -native) speaker and distill from this analys is a set of phonological speech patterns (PSPs) for each speaker. Essentially, the task is to discover the precise factors or features responsible for humans to categorize say, a Vietnamese speaker of English differently from a so -called standard English speaker. While such analyses are theoretically and practically valuable, the process of comparing two phonetically transcribed speech samples requires explicit training, is time -consuming, and is difficult to update. As an exam ple of how we manually derive the PSPs for a non -native English speaker, we begin by comparing the narrow phonetic transcription of a  X  X tandard X  North American English sample (1), with a representative non -native speaker of English (here a Vietnamese speak er (2)): Each of these phonetic transcriptions are co n-structed by 3 to 4 trained linguists, and disagre e-ments are settled by consensus. As is the case with all such transcriptions, they remain works in pr o-gress. T wo of these trained linguists do a pencil and paper word -by -word comparison of the two transcriptions in (1) and (2). Their analysis of th e data may find the following PSPs listed in (3): This is just a partial list. Some speakers may have more, and some speakers may have less. But the essential claim here is that each speaker X  X  English accent is the sum of their PSPs. manual process. Foremost among them is the cost and time to train linguists to perform uniform PSP analyses. A nalysts must know what to look for  X  they must decide what is important and what should be ignored. This brings us to the second drawback of manual analysis: the lack of a quick and parameterized method of comparison.
 ditional but un cat a logued PSPs, or if they need to simply search for a defined subset of PSPs, add i-tional manual analyses are necessary. A third pro b-lem appears in the proper selection of one arbitrary standard  X  X ase X  sample for the compari sons. A t times researchers may want to compare non -natives with American English native samples, and at other times they may need to c ompare non -natives with British, or other varieties of native English. This requires multiple manual compar i-sons, and they take human time and energy. F i-nally, as men tioned above, narrow phonetic transcriptions may need to be modified as collab o-rators join the analysis. But when these are changed, they necessitate concomitant change in the register of PSPs. these problems, but also opens up new research possibilities. We have develop ed a computational tool that will automatically compare two phonetically -transcribed speech samples and generate a set of PSPs describing the speech differences . Automa t-ing the comparison process will be of great use to the archive and to any speech scientist who tra n-scribes and analyzes spoken language. It will allow fast and pointed comparisons of any two phonet i-call y transcribed speech samples. Instead of si m-ply comparing a  X  X tandard X  North American native speaker and a non -native speaker, it will be quite simple to perform many accent comparisons, i n-cluding those between a native British English speaker and a non -n ative speaker. It will also be possible to quickly and easily derive a composite result. That is, after a number of analyses, we can determine what a typical Russian speaker of En g-lish will do with his vowels and consonants. This promises to be a great e mpirical improvement over the pronouncements that are currently offered in the appendices of various ESL teacher -training textbooks. has direct use in matters of linguistic assessment. It will be useful in the fields of ESL pronunciation assessment (Anderson -Hsieh, Johnson, and Kohler, 1992). These kinds of assessments will naturally lead to a theory of weighted PSPs . method of checking human transcription accuracy and thereby facilitates better methods of phonetic transcription (Cucchiarini, 1996; Shriberg, Hinke, &amp; Trost -Steffen, 1987). factor diagnostic to guide research in spectr o-graphic speech analysis. And because speech re c-ognition and speaker identification programs must ultimately deal with different accented speech, the results from the STAT analyses will contribute to this work (Bartkova &amp; Jouvet, 2007; Deshpande, Chikkerur, &amp; Govindaraju, 2005). Linguists who transcribe speech into a phonetic representation may use a tool such as PRAAT, to play the audio source file and a text editor to input the transcription. The result is normally a Unicode text file that has an IPA transcription of the audio file. STAT provides linguists with an easy way to play back an audio source file and share it with other linguists. A key feature that STAT provides in addition to transcription tools is a mechanism to manage a corpus of phonetic transcriptions. Once a corpus of phonetic transcriptions is created , li n-guists can use STAT X  X  phonological speech pattern analysis tools to describe differences between di f-ferent speakers X  accents.
 components. Users interact with the system pr i-ma r ily via a web interface. All user interfaces are implemented with Ruby on Rails and various JavaScript libraries. Backend processes and alg o-rithms are implemented in Java . An open source web application bundle including the front -end web interfaces and backend libraries will be made available as an open source library suitable for use in other applications in the future. We believe that the transcription alignment and speech pattern analysis components of STAT make it a unique tool for linguists studying speech processes . 4.1 Language Management The language management component of STAT provides basic transcribed audio corpus manag e-ment. This module allows a user to define a new speaker source language , e.g. Japanese, and specify attribute s of the language, e.g. a phonetic inve n-tory. All transcriptions are then associated with a speaker source language. STAT offers robust search capabilities that allow a linguist to search by things such as speaker demographics, phonetic i n-ventories, phonol ogical speech processes, and speech quality assessments. 4.2 Transcription Management Whenever a transcription is to be made by li n-guists , a new transcription record is created, ass o-ciated with a source language, and the audio file is attached to the transcription record. Once the audio file has been made available , linguists are able to use a web interface to play the audio recording and create phonetic transcriptions. The transcription management interface then allows a senior linguist to adjudicate differences between transcriptions and select an authoritative transcription. 4.3 Transcription Alignme nt and Analysis Once an authoritative transcription for a speaker has been created a linguist can then compare the transcription with the previously transcribed speech of another speaker. This alignment process is the core of the system. The first stage of the comparison is to create a word and phone level alignment between the two transcriptions. The alignment is performed by our special implement a-tion of Kondrak X  X  phonetic alignment algorithm (Kondrak, 2000). The output from this part of the system is a c omplete phone -to -phone to alignment of two transcriptions . Fig ure 1 s hows an example alignment with PSPs that a linguist is able to make adjustments to or mark correct. After alignment a linguist can perform an assessment of the speaker X  X  speech abilities and make other notes.
 different languages and research needs, the settings for the phonemic cluster parser, phoneme distance measures, and alignment algorithm coefficient can be easily changed inside of STAT . Linguists can also control the set of constraints used for the phonological speech patterns analysis . 4.4 Phonological Speech Pattern Analysis Once the transcription alignment has been co m-pleted , the phonological speech pattern analysis can begin. This anal ysis evaluates all phonetic di f-ferences between the two transcriptions under analysis. These differences are then processed by our algorithm and used to determine unique phonological speech patterns. All potential phonological speech patterns are returned to the linguist for verification. As the system encounters and stores more and more phonological speech pattern analyses for a particular language , general descriptions are made about peoples X  accents from a particular language background . Ou r initial design of STAT uses manually dete r-mined weights of phonological features used to align transcriptions and determine phonological speech processes . In the next major release of STAT we intend to integrate automated methods to propose weight settin gs based on language sele c-tions.
 spe c trographic analysis mechanism that will allow for the transcriptions to be time synchronized with the original speech sample. After this we will be investigating the integratio n of several speaker a c-cent identification algorithms. We will also be i n-vestigating applications of this tool to help speech pathologists in the identification and assessment of disordered speech patterns.
