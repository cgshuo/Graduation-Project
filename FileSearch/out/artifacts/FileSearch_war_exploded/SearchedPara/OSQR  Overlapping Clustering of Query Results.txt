 Categories and Subject Descriptors: H.3 [Information Storage and Retrieval]: Information Search and Retrieval-Clustering General Terms: Algorithms, Design, Experimentation Keywords: SQL, Database, Chaining Effect, Context
Query Result Clustering is the operation of grouping the rows in a relational query result into meaningful clusters. This clustering gives the user a higher-level view of the dat a and can be used for easier navigation of the result [3].
A unique feature of query result clustering is the addi-tional availability of the underlying database from which the query result was picked up. Generic categorical data clustering algorithms (see Berkhin [2] for a recent survey) spend substantial time and effort mining information from the given data in order to obtain better cluster quality. Sin ce these algorithms assume an isolated setup, they cannot take advantage of this underlying database in order to obtain more meaningful clusters. In this paper, we propose OSQR , a novel approach for query result clustering that effectivel y uses additional information from the underlying database to generate meaningful overlapping clusters. OSQR also as-sociates with each cluster a set of terms that characterize the cluster with respect to the entire underlying database. Moreover, OSQR automatically determines the appropriate number of clusters for the query result being considered.
Given a SQL query as input, OSQR explores the query X  X  result as well as neighboring tables 2 containing related in-formation, and identifies a set of terms (hereafter called th e query X  X  context ) that are most relevant to the given query; each term in this set is also associated with a weight quanti-fying its relevance. Next, OSQR exploits the term weights, and the association of the rows in the query result with the respective terms to define an asymmetric distance function between the terms. This distance function is then used in a
Currently at Georgia Institute of Technology, Atlanta, GA
OSQR (pronounced  X  X scar X ) stands for Overlapping cluS-tering of Query Results .
Tables reachable from the tables appearing in the query result through foreign keys.
 novel way to group multiple terms together; this grouping, in turn, induces a clustering of the query result rows in a natural manner.

The context computation algorithm, called SCORE , is borrowed from our earlier work [6]. The asymmetric dis-tance function and the novel clustering algorithm based on the same are contributions of this paper.
 Query Context Computation [6]. Consider a query Q on a table R , 3 and let Q ( R ) denote its result. SCORE mea-sures Q  X  X   X  X ocus X  on a term t  X  A , 4 where A  X  cols ( Q ), as A straightforward algorithm to compute the context of Q from Q ( R ) is to rank the terms in Q ( R ) on the basis of T W and pick the top N terms, where N is a user de-fined parameter. Instead, SCORE further explores tables beyond Q ( R ) by  X  X ugmenting X  Q by joining it with addi-tional tables in the database. As a first step, SCORE re-moves all the projection constraints in Q . SCORE then ex-ploits available foreign-key dependencies to iteratively aug-ment this initial query with additional tables in a greedy manner. Specifically, the algorithm maintains the set S of candidate foreign-key columns in the query as augmented so far (call this the augmented query AQ ). In each itera-tion, the algorithm picks F  X  S with the maximum CW ( F ) (where CW ( F ) = max t  X  F T W ( F, t )) and augments AQ as AQ = AQ  X   X  1 R F , where R F is the table referenced by F . The loop exits when no more candidate foreign keys exist, or when M augmentations have already been performed, where M is a user-defined parameter. The algorithm returns: (1) the final augmented query AQ , (2) the context T containing the N terms present in AQ  X  X  result with maximum T W , and (3) for each term t  X  T , (a) the column A t  X  cols ( AQ ) that t is contained in, and (b) the weight w t (= T W ( A t , t )). Initial Query Result Clusters. With each term t  X  T , OSQR associates the cluster C t =  X  cols ( Q ) (  X  A t The rows in Q ( R ) that are not associated with any term t  X  T are termed  X  X utliers X ; these rows are not processed any further. This gives us an overlapping clustering of Q ( R ) with T clusters, each with a well defined context (the asso-ciated term  X  T ). This clustering clearly has high intra-cluster similarity; however, it needs to be refined to achiev e high inter-cluster dissimilarity as well.
 Refining the Clusters. OSQR refines the clustering ob-
While this discussion is limited to single-table queries fo r sake of clearer exposition, the extension of the ideas to the multi-table query case is not hard.
We abuse notation in this paper, with t  X  A meaning |  X 
A = t ( Q ( R )) | &gt; 0. tained as above by merging similar clusters. Suppose there exists a distance function d ( u, v ) that quantifies the (lack of) affinity between the terms u, v  X  T , and let C  X  T = { S T, 1  X  i  X  n } be the optimum clustering of T with re-spect to this distance function. Then, it is easy to see that the optimum clustering of the query results (with re-spect to the inter-cluster dissimilarity criterion) is giv en by C  X  = { C S | C S =  X  t  X  S C t , S  X  C  X  T } , with S  X  C  X  context associated with the cluster C S . In view of this re-duction, in the rest of this section we address the problem of optimally clustering the set T .
 Distance Function. The clustering problem addressed here differs from traditional clustering in an important way : unlike traditional clustering scenarios, each datapoint ( i.e. each term  X  T ) is associated with a cluster of query result rows and a weight. OSQR effectively exploits these two asso-ciated entities, and defines the distance d ( u, v ) between the terms u, v  X  T is defined as d ( u, v ) = w v | C u  X  C v where C u and C v are the clusters associated with the terms u and v respectively.
 Naive Clustering Approach. In OSQR, we opt for the agglomerative single-link approach [5, 2], primarily due t o its efficiency and simplicity of implementation. However, it is well known [5] that single-link algorithms suffer from the chaining effect , wherein a  X  X ridge X  of terms can lead to merging of unrelated clusters, potentially resulting in an un-natural clustering with high intra-cluster dissimilarity . We now describe how OSQR resolves this problem by making the distance function asymmetric.
 Controlling the Chaining Effect. OSQR exploits the term weights, which give the  X  X mportance X  of a given term relative to other terms, to eliminate unwanted merge se-quences of clusters. Informally, we consider a sequence of merges undesirable if it involves a term of less importance facilitating the presence of terms of greater importance in the same cluster, irrespective of their distance.

Formally, let t 1 (= t  X  ) , t 2 , . . . , t k (= t  X  X  ) be a chain of k terms connecting two distinct terms t  X  and t  X  X  . This chain is termed bad iff min 1  X  i  X  k w t i &lt; min( w t  X  , w there exists a term in the chain with weight strictly less than the weight of both t  X  and t  X  X  . A sequence of merges is undesirable iff it is along a bad chain. We contend that the agglomerative single-link algorithm will lead to a bet-ter clustering if it is able to avoid these undesirable merge sequences.
 OSQR X  X  Asymmetric Distance Function. OSQR avoids undesirable merge sequences by considering the distances a s asymmetric , taking into account the relative weights of the terms involved. Specifically, the distance ~ d ( u, v ) from u to v , where u, v  X  T , is defined as d ( u, v ) if w u  X  w v , and  X  oth-erwise. This distance function is extended to clusters as: ( 1) ~ d ( { u } , { v } ) = ~ d ( u, v ), (2) ~ d ( C, { v } ) = min and (3) ~ d ( C, C 1  X  C 2 ) = min( ~ d ( C, C 1 ) , ~ d ( C, C T and C, C 1 , C 2 are distinct clusters of the terms in T , and ( C ) = { u | u  X  C, w u = max t  X  C w t } .
 OSQR X  X  Term Clustering Algorithm. The clustering algorithm is an agglomerative single-link algorithm, as ea r-lier; however, it now uses the above asymmetric distance function instead of the symmetric distance function. Speci f-ically, the algorithm first puts each term in its own cluster, and then iteratively merges the pair of clusters C  X  , C  X  X  that ~ d ( C  X  , C  X  X  ) is minimum, until a stopping condition is met. (See the extended version of this paper [1] for details. ) Correctness. In the extended version of this paper [1], it is proved that this algorithm is complete , i.e. it avoids merge sequences along bad chains. It is further shown that the algorithm is safe , i.e. it does not avoid merge sequences along chains that do not contain a bad chain as a subchain. Implementation. The agglomerative single-link algorithm using the symmetric distance function d can be efficiently implemented by first constructing a weighted undirected graph with node set T and edge set { ( u, v ) | u, v  X  T } with the weight of the edge ( u, v ) taken as d ( u, v ), find-ing its minimum spanning tree (MST) and then forming clusters based on the edges of the MST [5]. Due to the asymmetry in the distance function ~ d introduced above, this undirected MST-based approach no longer works. In the extended version of this paper [1], we show that the fol-lowing algorithm works instead. The new algorithm first constructs a weighted directed graph with node set T and edge set { ( u, v ) | u, v  X  T, w u  X  w v } with the weight of the edge ( u, v ) taken as ~ d ( u, v ), finds its min-cost branching [4] (i.e. a directed MST) and forms clusters based on the edges of this min-cost branching.
 Experimental Results. In the extended version of this paper [1], we show that OSQR determines high quality clus-ters of the query result with a very reasonable overhead. On a benchmark based on the Open Music Directory data (http://www.musicmoz.org), we demonstrate that the tra-ditional single-link clustering results in a few very large , redundant clusters due to the chaining effect; in contrast, OSQR generates compact, non-redundant clusters.
In this paper, we proposed a novel approach to query re-sult clustering. The proposed solution generates a meaning -ful clustering by factoring in additional information avai lable in the underlying database. The solution has several featur es that are not present in prior categorical data clustering wo rk: it generates overlapping clusters, automatically determi nes the appropriate number of clusters, and associates a descri p-tive  X  X ontext X  with each generated cluster. Moreover, it us es agglomerative single-link clustering for efficiency, and at the same time controls the  X  X haining effect X  by using an asym-metric distance function. We showed how the algorithm can be implemented efficiently by using a minimum-cost branch-ing based approach. Our experimental results [1] show that OSQR achieves high quality clusterings at reasonable cost.
