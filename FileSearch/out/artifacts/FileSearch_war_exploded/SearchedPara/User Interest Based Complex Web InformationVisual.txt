 It has become very difficult for end users to get their desired information quickly and accurately from the gigantic World Wide Web. Research attempts to help the users manage and control the information over the internet by presenting user-focused information [4] [6] [11]. However, the existing technology is not ade-quate enough to provide visual maps users expect to guide their web experience. As a consequence, the next research cha llenge is to provide focused informa-tion to the end users for quick and easy understanding of the web information and its pattern. To provide an easy way to explore information according to the need of user, techniques of informatio n retrieval and visualization have been introduced [7]. Information visualization presents the abstract data to amplify human cognition and unfold the hidden relationships among the data. The pur-pose of information visualization is not only to create interesting pictures for the users but also to communicate information clearly and effectively [3] [7].
A web graph, which represents the web information with its internal con-nectivity revealed, is a very useful way to visualize various aspects of the web information. Nevertheless, a huge web graph is less likely to create a good im-pression for the end user compared to a relatively smaller one with information relevant to the user X  X  interests. Therefore, reducing the size of the web graph is very important from the end user viewpoint. Filtering and clustering techniques from different aspects such as structure, context, have been applied on the web graph to reduce the size. Besides the structure and content based clustering techniques, compromise the direct user X  X  needs is expected for personalized visu-alization. First of all, users are different and their needs vary. Most of the work accomplished for personalization of web data is done for a group of people who can be addressed as similar minded [13]. But it is not obvious that every user of a specific group behaves similarly all th e time. Secondly, short term interests or preferences of a particula ruserchangeovertimeorindifferentcontext.

To provide the above personalization in web information visualization, we propose to model every user separately. Instead of providing information di-rectly in the traditional way, we introduce user profile driven clustering for web information personalization. We strongly believe that this can classify the web information into several categories and yield an improved visualization for the end user as the information is clustered according to the individual X  X  interest. The rest of the paper is organized as follo ws: Section 2 presen ts related works; Section 3 describes the proposed architecture for personalized visualization; Sec-tion 4 presents the experiment; and finally, Section 5 concludes the paper. Work has been done in different directions to make the representation of web information more effective to the end users. Some work deals with information searching through search engines [14] [1], i.e., on search results. For personal-ization, researchers consider the user search preference learned from the click history or browsing history [9]; history of similar minded users [13]; location metadata of the user for personalized search [2]; and other personalizing page ranking techniques [11]. In the case of navigating in the web space, clustering techniques plays important roles for reducing the complexity of the web graph. Structure based clustering can be found in the works of Huang et al. [6] and Rattigan et al. [12]. They provide structu re based clustering techniques to re-duce the web graph size. Graph clustering approaches like these only consider the structural aspect of the graph without considering the content of the docu-ments. Besides structure, Gao [4] integrates content in the process of clustering. She first clusters using structure and then clusters using content only on the sub-clusters created in the first phase. As a consequence, this two-phased clustering heavily depends on the structure. Inclusion of structure in the visualization cre-ates scopes for non-similar documents to be linked and hence put in the same cluster. Our work avoids this possibility by considering only content based sim-ilarities while relating documents. In contrast to previous research approaches, this work is personalized as we consider the user X  X  point of view.
 Our proposed system to resolve the issue o f personalized visualization uses data from user profile as preliminary knowledge-base to assist in filtering, cluster-ing and hence final visualization. While the user uses the system, the system automatically updates the existing user profile or creates a new one where ap-propriate to reflect user X  X  latest focusing trends. Finding appropriate scope for involving the user profiles in the system is very crucial for a personalized system. Scopes of the user profiles for personalized searching from electronic information space have been documented in [10]. In our system, after collecting information, we include the user profile while analysing the web information, i.e., in filtering &amp; clustering, and finally we visualize the information.

Figure 1 depicts the architecture of the system for personalization of informa-tion visualization. The key modules of this model are: i) Result Analyser module (composed of Data Collection, Filtering and ii) Visualization module is responsible for visualizing the web graph to pro-iii) Feedback Analyser module gets the user interaction data from the vi-iv) Profiler module gets the updates from Feedback Analyser module and 3.1 Data Collection and Filtering The first component of our architecture is the web crawler which collects infor-mation to represent URLs by their corresponding keywords for the initial web graph. To ensure quick processing and get adequate &amp; useful information, our web crawler does not revisit the faulty, unreachable pages and pages containing very less information rather discards them. We filter out all other html tags, any data except text such as image, audio and video to keep page information simple. Once crawling is finished, we have the original text data for further processing. We convert the words to their base forms(for example:  X  X unning X  to  X  X un X ) to get the actual frequencies of words and remove stop words from the content.
After filtering the stop words, we have set of words, still big in size, to represent a URL. To reduce the size, we apply well known TF-IDF to get the terms of every URL weighted and then sort the m. We take a fixed percentage of top weightedtermsaskeywordstomakef urther steps time &amp; cost effective.
Now we have a set of documents in the corpus to be visualized by the web graph. Every document is composed of a set of ( Keyword,Weight )pairs.All the distinct keywords of these documents form the total set of keywords. At this point, it is very easy to define the documents as vectors of weighted keywords. where t ij is the weight j  X  th keyword where 1 &lt; = j&lt; = n and n is the number of total distinct keywords in the corpus.

We calculate the edges connecting the nodes for the initial graph based on the content similarity of the nodes. If we con sider two documents, the more keywords they have common, the more they are co nnected. The similarity between them is computed by cosine similarity 1 . If the similarity score CSim ( d y ,d z )isgreater than a threshold value  X  then we create an edge between the documents d y and d . Finally, we have an undirected initial graph for next processing. 3.2 User Profiling To optimize retrieval accuracy, we clear ly need to model the user accurately and personalize the information retrieval according to each individual user, which is a difficult task. It is even harder for a user to precisely describe what the infor-mation need is. Unfortunately, in the real world applications, users are usually reluctant to spend time inputting additional personalized information which can provide relevant examples for feedback.
 Representation of user profiles has been classified into three categories in [5]. The simplest one to represent and maintain is keyword-based user profile where the keywords are either automatically extracted from the web documents during a user X  X  visit or through direct input by the user. Each keyword can represent a topic of interest and weight can be associated with it to represent the degree of interest. The other two categories are semantic network profile which deals to address the polysemy problem and concept based user profile which consists of concepts &amp; reveals the relatio nship between the concepts.

In our system architecture, we adopt the keyword based user profiles for sim-plicity to represent a user. So the user p rofile consists of a set of weighted key-words, i.e., ( Keyword,Weight ) pairs. User profiles are maintained in two phases by the  X  X rofiler X  component. In the creat ion phase, the user data are collected directly from the user via a user interface. Here the user is allowed to answer some predefined questions for the creation of basic user profile. After collect-ing the basic data from the user, the system will collect more user data from the internet according to the user X  X  authorization. The maintaining or updating phase occurs mostly whenever the user u ses the system. Profiler updates the preferences based on user interaction da ta passed from the Feedback Analyser. 3.3 Clustering We want to cluster the total corpus into different clusters where the documents will be clustered by biased similarity values based on the user profile. We modify the document vectors computed in sectio n 3.1 to represent both user interests and main topics of the document. For this we need to replace the existing doc-ument terms with the keywords of t he user profile where appropriate.
We update the total number of keywords of the corpus by adding the user profile keywords in the keyword set. If the number of new distinct keywords is m , the total number of keywords becomes ( n + m ). Now, we can write the modified
We calculate the T i ( n + j ) ;where1 &lt;j&lt; = m ; in the following way. We mea-sure the similarity value of c j ,where c j is a keyword from user profile, with each keyword of the d i . We use one of the wordNet similarity measures for this purpose. There are six similarity measures applied on wordNet, three measures including Lin [8] are based on information content of the least common sub-sumer(LCS). Lin yields slightly higher correlation with human judgements than others, which actuates us to use it instead of others.

If c j is similar to document keyword k il ;where1 &lt;l&lt; = n ; meaning that ( SIM ( k l ,c j )  X  T il ) &gt; X  , we consider that document d i is containing keyword c j instead of the original document keyword. So, we remove the k il by making the weight T il as 0. We repeat it for every c j of user profile for each d i .Asa particular c j can be similar with multiple keywords of a document by different values, we take the maximum similarity value as the weight of that c j .
Hence, the new vector to represent a document, d i , reflects the user interests and the topics of the original content as well. We apply k-means algorithm for clustering, where the number k and initial means are calculated from the  X  X osine similarity X  values of the document vectors. We select d i as an initial mean if the degree of d i is greater than the sum of the average degree of the web graph and a predefined threshold. 3.4 Visualization and Feedback Analysis For displaying the final view to the user, we have developed the visualization component based on popular JGraph 2 framework. The visualization interface has three panes. The pane on the left side of the interface produces tree view of the web graph clusters. In the middle of the interface the web graph is displayed. To distinguish between the cluster an d the URL nodes we use rectangular and oval shapes, respectively. Beside navigating, we have also added browser support for the user to visit the web pages in the right pane. The user can-zoom in/out; re-arrange the web graph by drag and drop; delete an inappropriate node or cluster; and create new clusters.

As the user interacts with the visualization interface, it sends the browsing, click and arrangement information generated from the actions accomplished by the user to the feedback analyser component. Browsing feature is the primary contributing feature in profile updating. When user browses a page, the keywords with their weights along with the dwelling time are sent to the feedback analyser module, which updates the weights of existing interests and adds the new ones. While adding the new interests in the user profile, the interest and corresponding weight-value to be added are shown to the user for any amendment. In this section, we provide an experimental example. It begins with showing a simple web graph. For this example we analyse a university web site and set the crawl style property as BFS whose termination is set to 1. We get 19 nodes while crawling and name them acco rding to their appearance number in the crawler. We get the sets of keywords for representing the nodes after applying techniques from 3.1, which are shown in Table 1. Figure 2a shows the original web graph. We get two clusters and eight other nodes which is shown in Figure 2b after applying content based clustering described in [4].

We also have two user profiles constr ucted earlier based on two different users. We consider one user profile, UP a , represents an international student who looks for opportunity of postgraduate studies in computer science related fields whether the other, UP b , is of a local student focusing on undergraduate studies in business, particularly interested in  X  X awthorn X  campus. The corre-sponding user profiles are given in Table 2a as ( Interest,Weight )pairs.
First, we take the user profile UP a and generate the clusters based on the methodology described in section 3.3. We g et three clusters and eight unclustered nodes. Second, applying the same process on the initial graph for the user profile UP b , we get four clusters and seven unclustered nodes as well. Table 2b shows how the nodes are assigned in the clusters for all three cases. With no user profile applied, the two clusters are calculated based on their content similarity. Three and four clusters have been constructed for the user profiles UP a &amp; UP b and are shown in Figure 3a &amp; 3b respectively. From these two visualization it is noticed that clustering has been heavily influenced by the user profiles. Rather displaying the same web graph of Figure 2b, our system shows the web information to different users in different ways according to their interests. This paper demonstrates that the user interest profiles can be used to improve the visualization of complex web information. Based on the experimental re-sult, it is noticed that the g enerated clusters reflect the user interests effectively meaning that the web graph is personalized. Further studies need to be done to design domain specific ontology to get the web information in a structured way and ontology for the user profile as well. Then a combination of both ontologies in the system architecture will be investigated.

