 Entity disambiguation is an important step in many infor-mation retrieval applications. This paper proposes new re-search for entity disambiguation with the focus of name dis-ambiguation in digital libraries. In particular, pairwise sim-ilarity is first learned for publications that share the same author name string (ANS) and then a novel Hierarchical Agglomerative Clustering approach with Adaptive Stopping Criterion (HACASC) is proposed to adaptively cluster a set of publications that share a same ANS to individual clus-ters of publications with different author identities. The HACASC approach utilizes a mixture of kernel ridge regres-sions to intelligently determine the threshold in clustering. This obtains more appropriate clustering granularity than non-adaptive stopping criterion. We conduct a large scale empirical study with a dataset of more than 2 million pub-lication record pairs to demonstrate the advantage of the proposed HACASC approach.
 H.3.7 [ Information Storage and Retrieval ]: Digital Li-braries; H.3.3 [ Information Storage and Retrieval ]: In-formation Search and Retrieval X  Clustering Author Disambiguation, Clustering
The entity resolution problem consists of two subprob-lems: disambiguation and reference identi cation . In the former problem the task is to distinguish references that share the same author name string (ANS) and yet refer to different author identities. For example, there are 13 differ-ent author identities sharing the ANS Ashish Garg in DBLP (the Nov. 2012 version) and 7 different authors with the ANS Stefan Richter. The reference identification task de-termines the set of different ANSs that may be used to refer to the same author identity. For example, Fernando Casade-vall, Fernando Casadevall Palacio, Fernando J. Casadevall refer to the same author identity in DBLP. This paper fo-cuses on the disambiguation problem.

Author name disambiguation is an important research problem for bibliographic (Web) databases (e.g., DBLP, Cite-Seer, MEDLINE). While substantial efforts are made to clean these repositories by semi-automatic means (which of-tentimes goes unrecognized: for instance, DBLP support group utilizes sophisticated heuristic rules to identify am-biguous author names, which are then manually validated [11]), their efforts cannot keep pace with the volume of data ingested in these repositories: These databases are largely constructed by periodically crawling the online pro-ceedings of conferences, workshops and journals. Case in point, DBLP version March 2012 has 671 distinct ambiguous ANSs which are (confidently) disambiguated by the DBLP support group to refer to 2,013 different author identities. A total of 29,103 publications belong to these authors in DBLP. The Nov. 2012 version of DBLP has 143 new am-biguous ANSs that are (confidently) disambiguated, i.e., a 21.3% increase from the previous version. Notice that 88,916 new ANSs and 178,806 new publication records were added to DBLP in Nov. 2012, which were not in DBLP in March 2012. This problem is not unique to DBLP. In MEDLINE, on average 8 different author identities are associated with each ambiguous ANS and 2/3 of the author identities are associated with an ambiguous ANS [13]. This clearly points out that, at such a data ingestion rate, the (admirable) ef-forts of the curators of DBLP, as well as those of its sister bibliographic repositories, cannot keep pace unless assisted by reliable automated tools.

This paper proposes a novel solution for the author dis-ambiguation problem. Our solution consists of two steps. First, we estimate pairwise similarity between publications sharing the same ANS using Logistic Regression. Second, we use a Hierarchical Agglomerative Clustering (HAC) al-gorithm to cluster the publications to real author identities. The stopping criterion in HAC is adaptively learned from supervised information.

Our contributions in this paper are:  X  Propose a novel method for author disambiguation based  X  Conduct a comprehensive large scale empirical study us-
The paper is organized as follows. Section 2 gives a brief overview of the related work. Section 3 describes our pro-p osed solution and Section 4 shows the experimental results. The paper concludes with Section 5.
There is a rich body of work on the disambiguation prob-lem in general and on the author name disambiguation prob-lem in particular. These problems are part of the more gen-eral problem of entity resolution (also referred to as record linkage, reference reconciliation, etc.). Several surveys [6, 8] give a thorough presentation on the work on the entity reso-lution problem. Due to the space limitation, we only review some research work most related to the paper.

A number of solutions have been proposed for the dis-ambiguation problem: unsupervised clustering solutions [13, 14], supervised clustering methods based on naive Bayes and support vector machines [9], graph-based mining, such as, co-authorship graph [7, 12, 2] and entity-relationship graph mining [10], hidden Markov fields [16], and link analysis be-tween publication records using random walks [15].
Our work distinguishes from previous researches on disam-biguation problem as we focus on learning adaptive stopping criterion during the clustering process for identifying indi-vidual author identities. [2] proposed blocking and boost-rapping approach with HAC, but did not elaborate the stop-ping criterion in clustering. The novel HACASC approach intelligently learns adaptive stopping criterion in clustering, which substantially improves the performance of author dis-ambiguation.
This section first presents a formal definition to the author disambiguation task, and then describes the new method for author disambiguation. The method consists of two main phases. The first phase models the probability that a pub-lication pair sharing an ANS is written by the same author identity. This probability is used as a similarity metric be-tween publications in the second phase, where HACASC is utilized to generate clusters of individual author identities.
The mathematical definition of the author disambigua-tion task is as follows. Let N = { n 1 ,n 2 ,  X  X  X  ,n N } set of ambiguous ANSs, and E = { e 1 ,e 2 ,  X  X  X  ,e M } be the set of real author identities. Each ambiguous ANS n i  X  N is associated with a set of publications P n i . For a paper p , denote Au ( p ) = { r 1 ,r 2 ,  X  X  X } as the set of author refer-ences in the author list of p , En ( r ) denotes the real au-thor identity of r , and Nm ( r ) denotes the ANS of r appear-ing in the author list. For each author identity e  X  E, let Nm ( e ) be its ANS. The disambiguation problem thus be-comes: for each ambiguous ANS n i , find a partition C n i { c if j  X  = k , such that,  X  j  X  X  1 ,  X  X  X  ,k n i } ,  X  e  X  E ,Nm ( e ) = n ,  X  p  X  c j n i ,  X  r  X  Au ( p ) ,En ( r ) = e . For example, let n  X  N be an ambiguous ANS and P n = { p 1 ,p 2 ,p 3 } the set of publications where n appears. Hence, we have au-thor references r 1  X  Au ( p 1 ) ,r 2  X  Au ( p 2 ), and r such that Nm ( r 1 ) = Nm ( r 2 ) = Nm ( r 3 ) = n . Suppose that En ( r 1 ) = En ( r 2 ) and En ( r 3 )  X  = En ( r 1 ) ,En ( r r refer to the same author identity, which is different from the author identity referred to by r 3 . The author disam-biguation task is to cluster P n into two clusters { p 1 ,p { p 3 } so that the sets of publications in each cluster correctly indicate the identity of author references r 1 ,r 2 and r
Let p 1 and p 2 be two publications such that r 1  X  Au ( p 1) ,r 2 Au ( p 2), Nm ( r 1) = Nm ( r 2) = n . To provide a similarity metric for the clustering, the pairwise probability Pr ( En ( r 1) = En ( r 2) | p 1 ,p 2) is modeled as a Logistic Regression(LR), i.e. where  X  ( x ) = (1 + exp (  X  x ))  X  1 is the sigmod function and  X  ( n,p 1 ,p 2) is the feature vector extracted from p 1 and p 2 w.r.t n , which reflects the  X  X imilarity X  between the two pa-pers for sharing the same real author identity with the ANS n . w is the weight vector indicating the importance of each feature. We will discuss the features used here later in Sec-tion 4.2. The learning process of the LR problem is through gradient decent. In particular, the BFGS pseudo Newton method [4] is used to solve this optimization problem.
Here we describe the HACASC method for clustering the publications P n that share an ANS n . There are two is-sues for this clustering task: first, the number of real author identities that share this ANS is not given, hence the num-ber of clusters is not pre-determined; second, given only the similarity between publications, without a feature vector for each publication, it is hard to compute cluster centers. To overcome the first issue, the natural choice is to use HAC. HAC starts by treating each node as a cluster by itself, and then iteratively merges the closest pair of clusters until some stopping criterion is met. To overcome the second issue, we utilize the following similarity measure between clusters:
Sim ( c p n ,c q n ) = 1 | where Pr ( En ( r 1) = En ( r 2) | p 1 ,p 2) is provided by the pairwise similarity modeling (Section 3.2).

An important problem when using the HAC algorithm is how to specify the stopping criterion. A simple choice may be to find a single fixed threshold via training and apply it to future data. Suppose N is partitioned into training set ANSs N
T r  X  N, and testing set ANSs N T e  X  N, N T r  X  N T e =  X  With the ground truth of the training set, the best thresh-old t n , for all n  X  N T r can be found. Then a single fixed threshold may be determined using these best thresholds in training set(see Section 4.3.2). But using a single fixed threshold for all different ANSs is not optimal. Therefore, this paper proposes new research for adaptively finding the desired thresholds for different ANSs in HAC as a regression problem, i.e. t n = f ( n,P n ). In this regression model, the input sample is a HAC problem with ANS n and related pub-lications P n , and the target t n is the best threshold for this HAC problem. With a regression model, the stopping crite-rion of a HAC problem can be intelligently learned from the optimal stopping thresholds of training samples with known ground truth (i.e., real author identities).

In particular, the regression function f is defined as a mixture of kernel ridge regressions: p ublication title 1 S im cos tf idf ( t 1 ,t 2) 4 S im c o-authorship 2 C A 1 ( p 1 ,p 2) ,log ( CA 1 ( p 1 ,p 2)) T able 1: Features(  X  ( n,p 1 ,p 2) ) for pairwise similarity modeling. \dim." stands for feature dimensions. where Z indicates the hidden group, Pr ( Z = h | n,P n ) is the gate function for assigning a HAC task to a hidden group, and with K (  X  ,  X  ) as the kernel function. Soft-max function is used for Pr ( Z = h | n,P n ) and Radial Basis Function (RBF) [5] kernel for K (  X  ,  X  ).
 To learn the mixture of kernel ridge regressions model, the Expectation-Maximization (EM) method is applied. In the E-step, the posterior probability is estimated as follows: Pr ( Z = h | n,P n ) = ) where  X  ( n,P n ) is the feature vector, which will be dis-cussed later in Section 4.3.1. N (  X | t n , X  l ) is the probability density function of the normal distribution with the best threshold t n as mean and variance  X  l . Here the error term error = t n  X  f ( n,P n ) is assumed to follow some zero-mean normal distribution.

In the M-step, the parameters to be estimated are w = { w 1 ,  X  X  X  ,w H } for the gate functions,  X  = {  X  1 ,  X  X  X  , X  the kernel ridge regression models in each hidden group and the error term variance  X  = {  X  1 ,  X  X  X  , X  H } . The statistics for updating the parameters are: w h = argmax w h  X  where Z n i = D h is the diagonal matrix with Pr ( Z = h | n i ,P n i ) as the i diagonal element, K is the kernel matrix of training samples, T is the vector of the best thresholds of all training samples, and  X  is the regularization parameter for kernel ridge re-gression. All the estimations are in closed form except for w . Again, the BFGS method is used for this optimization problem and another regularization parameter  X   X  is used to avoid over-fitting. Both regularization parameters,  X  for re-gression model and  X   X  for gate function are obtained by cross validation in training set.
The goal of the experimental section is to show the ad-vantage of learning adaptive thresholds in the proposed HA-CASC method. We evaluate the proposed HACASC against the baseline, which uses HAC with a single fixed threshold. T able 2: Performance of LR for the pairwise simi-larity modeling We perform our experiments on a subset of DBLP called DBLP No te dataset. It is compiled from DBLP March 2012. It consists of all those ANSs in DBLP with the property that each of them is shared by at least two distinct author identi-ties and each of the author identities has an affiliation note. We consider the presence of affiliation notes as a strong indi-cator that the author identities are X  X nequivocally X  X dentified by the DBLP support group for those ANSs. DBLP N ote consists of 692 ambiguous ANSs, of which 354 ANSs are used for training and 338 ANSs are used for testing. By pairing up the publications of the authors in DBLP N ote that share the same ANS, there are 1,109,733 pairs from 15,394 publi-cations in the training set and 1,027,641 pairs from 14,578 publications in the testing set.
We report here the experimental results for the first phase of our approach. Recall that a LR model is built to model the pairwise similarity between publications sharing an ANS.
Table 1 shows the features used for the LR model. Two name-based features ( IDF p ( F ) ,IDF p ( L )) calculate the In-verse Document Frequency(IDF) of the first(last) names of the given ANSs against all publications in the whole DBLP, ( IDF n ( F ) ,IDF n ( L )) compute IDF for the first(last) names One title-based feature uses cosine similarity with TF-IDF features ( Sim cos tf idf ) of publication titles and another four use Latent Dirichlet Allocation (LDA) [3] features ( Sim cos LD A instead. To compute the LDA features, a LDA model is first built using all the publication titles in the training set. It is then applied to publication titles. The estimated topic as-signment probabilities of the titles are denoted as the LDA features of the titles. LDA models with hidden group sizes 10 , 30 , 50 and 80 are used to generate the four features.
For co-authorship features, the level-1 and level-2 co-authorship similarity are defined as follows: CA i ( p 1 ,p 2 ,n ) = where i  X  X  1 , 2 } , and Co 1 ( p 1 ,p 2 ,n ) is the set of ANSs appearing in both p 1 and p 2 besides n , Co 2 ( p 1 ,p 2 ,n ) is the set of ANSs that appear in p 1( p 2) and has co-authorship with some ANS in p 2( p 1) besides n . Here the co-authorship is based on ambiguous ANSs, not real author identities, so it is not the accurate co-authorship.

Finally, a venue feature is computed using cosine similar-ity and TF-IDF features; the year feature is computed as the absolute value of the difference of the publication years.
Table 2 shows the precision, recall and F1 score of the learned LR model. The metrics here are computed by taken the pairwise similarity modeling as a classification problem. A threshold is selected in training set to truncate the simi-larity into a binary number which is then compared to the ground truth of whether a pair shares the same author iden-tity. Notice that this is only a pairwise result, and may contain conflicts. E.g. the model may predict that both { p 1 ,p 2 } and { p 2 ,p 3 } share the same author identity e , but { p 1 ,p 3 } does not.
In the experiments for HACASC, we first describe the features used for the HACASC, then compare the perfor-mance between usage of adaptive threshold and a single fixed threshold. Table 4 shows the features used for the HACASC, where S = { Pr ( En ( r 1) = En ( r 2) | p 1 ,p 2) | p 1 ,p 2  X  { name features are the same as in LR. The pairwise similarity features show the average of the pairwise similarity between the publications sharing the same ANS. The node volume features show the density of the complete graph consisting of related publications and their similarities.
Here we evaluate the proposed HACASC method against a baseline and a theoretical upper bound. The baseline uses a single threshold as a weighted sum of the best thresholds in the training set, with the sizes of HAC problems ( | P as weights. The theoretical upper bound is the performance using the best threshold gained from ground truth for each ANS. The evaluation metric includes F1 score and Normal-ized Mutual Information (NMI) [1]. Unlike the result in pairwise modeling, the F1 score is derived from the cluster-ing result here, hence the transitive conflicts mentioned in Section 4.2.2 do not apply here. The NMI is used to evaluate the performance from the information-theoretic interpreta-tion of clustering, while F1 score evaluates the performance from the pairwise perspective of clustering, as series of de-cisions. The NMI is computed as a weighted (with the sizes of HAC as weights) sum of the NMIs of each of the HAC problems w.r.t. the correct clustering results (given by the ground truth). Table 3 shows the clustering performance. The RBF kernel used in HACASC has one scale parameter, tuned using cross-validation. The number of hidden groups is 5, which in our experiments performs much better than &lt; 5 groups and similar to &gt; 5 groups.

It can be seen from Table 3 that the HACASC generates a better F1 and much better NMI score in testing set com-pared to the baseline. To confirm this, a right-tailed t-test is applied for both F1 and NMI with statistical significance 99 . 9% (  X  = 0 . 1%). The resulting p -value is 3 . 81  X  F1 score and 1 . 97  X  10  X  32 for NMI, indicating substantial ad-vantage of HACASC against the baseline. The upper bound performances show very good pairwise results (over 90% F1 score), which mean that the pairwise modeling does a good job in ranking the publication pairs, but the thresholds are very different for different HAC problems. T able 4: Features (  X  ( n,P n ) ) for the regression in HA-CASC
This paper proposes a HACASC method to intelligently determine the threshold in a HAC process for the author disambiguation problem. This method utilizes Logistic Regression to model the pairwise publication similarity, and the mixture of kernel ridge regressions to model the adaptive thresholds for the stopping criteria of the HAC problems. Our experiments in DBLP No te dataset show substantial advantage of HACASC against the baseline, in both classification and information-theoretic perspective. There is still a large difference between the performance of the upper bound and HACASC. One possible improvement is to incorporate the supervised information with the unsupervised information, such as within cluster distance and between cluster distance, to determine the stopping criterion, which may result in a more effective model. ported by NSF research grants IIS-0746830, CNS-1012208, IIS-1017837 and IIS-0916614. It is also partially supported by the Center for Science of Information (CSoI), an NSF Science and Technology Center, under grant agreement CCF-0939370.
