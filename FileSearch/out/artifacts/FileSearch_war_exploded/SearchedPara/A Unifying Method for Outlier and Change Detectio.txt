 As there is a growing number of emerging applications of data streams, mining of data streams is becoming increasingly important. Recent research indicates that online detection and change detection are often derived from respective problems and are addressed independently. Both statistical methods and fuzzy approaches have been employed to solve these two issues, such as methods based on regression analysis, hidden Markov model (HMM), hierarchical Bayesian model and fuzzy clustering, fuzzy entropy principle [7], etc. 
However, the outliers and change points often exist simultaneously in real data streams. It X  X  necessary to design a unifying method to detect the outliers and change points simultaneously. Thus, in this paper, we explore the relationship between outlier modeled as a time series with some probabilistic structure, both outliers and changes can be defined by the variation of statistical regularity, and the only difference is the variation kind. In [4], a unifying framework for mining outliers and changes was developed this work into a one-stage framework based on the forward and backward predictions. However, these two methods need pre-selected parametric models, and the parameters must be estimated adaptively in real time implementation. These will methods. 
In this paper, we propose a nonparametric unifying method for online mining small forward and backward conditional density, while a change is a point with small forward conditional density and large backward conditional density. In order to functions based on the forward and backward prediction errors. Unlike parametric approaches, all predictions are estimated us ing the local polynomial fitting technique [6] which does not need parameter estimation, but approximates the predictions by fitting a polynomial using the local data around the testing point. This nonparametric method provides many advantages. For example, there X  X  no need to determine the series, which is difficult for parametric methods. 
Approaches proposed in the previous litera ture often try to give an exact partition among outliers, changes, and normal points. However, exact answers from data this paper, fuzzy partition and decision approaches are used to alarm possible outliers and changes. The magnitude of the possibility is visualized by the values of membership functions based on which people can make their own decisions. Thus, we outliers and changes. 
The rest of the paper is organized as follows: In Section 2, we formulate the change point. We give a brief introduction to the local polynomial fitting technique in Section 3, and present the unifying nonparametric outlier and change detection method in Section 4. Simulation results on several data sets are provided in Section 5 and a section of conclusion follows. In this section, we will formulate the problem of outlier and change detection from the intuitive, it is far from easy to define them. One natural description is that an outlier is suggests something common between outlier and change. The holistic regularity varies at both outlier and change point, and only the type of the variation is different. Therefore, detection of outliers and changes is to find the variations of the regularity conditional probability distribution can be incrementally learned from the data stream every time a datum t x is input. That means we can learn the statistical regularity of the data stream adaptively and find the variations. 
We model the real data stream { } t x as a local stationary time-series. Here, each t x is conditional density . Then, the formal definition of outlier and change point is given as only interested in the sudden changes. 
Now, some criterions should be selected to measure the possibility of being an outlier and a change point. In many previous literature, parametric time-series model parametric approaches [4], [5]. One is based on logarithmic loss: point 1 t  X  . Another one is based on quadratic loss: conditional density function as follows: 
However, the estimation for the parametric conditional density function is based on parametric modeling and enough data. In online data mining, only limited data are available for parametric modeling. Thus the modeling biases may arise with high probability and the detection accuracy will be degraded. Moreover, many data in applications exhibit nonlinear features that require nonlinear models to describe. However, beyond the linear parametric models, there are infinitely many nonlinear forms that can be explored. This would be a daunting task for any analysts to try one forward conditional density, which can not distinguish between the outliers and changes. Thus, in this paper, we propose two novel score functions based on the effective nonparametric approach, the local polynomial fitting, to calculate the predictions. Local polynomial fitting is a widely used nonparametric technique. It possesses {( , ) : 1, , } tt
XY t N = " that can be regarded as a realization from a stationary time function in the following form: then t Y can be expressed as follows: where 2 () ( | ) tt xVarYX x  X  == , and t  X  is a random variable that satisfies ( | ) 0 tt EX  X  = , ( | ) 1 tt Var X  X  = . 
Denote an arbitrary value of the regression function by 0 () mx . Local polynomial remote data point from 0 x provides very little information about 0 () mx . Hence, we can local model : parameters by minimizing parameter p is named fitting order . Formula (7) means the local parameters are estimated by fitting the local model (6) using the local data in the area 00 [, ] xhxh  X + . solution to the minimizing problem of (7). As mentioned before, both of the two score functions (1) and (2) need parametric outliers and changes. So in this section, we define two novel score functions based on the forward and backward prediction errors. These two scores are then used to alarm x is regarded as a regression function , it can be calculated by local polynomial by nonparametric techniques. 4.1 Forward and Backward Scores xx xx ++ + + X  " . Then two regression functions can be defined as the forward prediction of t x which means prediction of t x given by 1 t x  X  : and the backward prediction of t x which means prediction of t x given by 1 t x + : Similar local models can be defined as (6), and forward and backward local parameters can be defined as {,, } xx ++ " respectively, estimates for the forwar d and backward predictions can be obtained: and where and a change point. One is Forward Score : another one is Backward Score : stream with varying variance. 
Predictions based on local polynomial fitting do not need pre-selected parametric Furthermore, the window bandwidth h is always small enough to keep the mined performance in parametric methods. So we believe that our method is simpler and effective, and more convenient for implementation. 4.2 Fuzzy Partition and Decision always has both large forward and backward scores, while a change point usually has a large forward score and a small backward score. Here, these characters will be used basing on fuzzy partition and decision theory to distinguish between outliers and change points. 
We consider the data set { } t Xx as a domain, and define four fuzzy sets on it: where ( ) ( ( )) ft ft Sx SScorex , ( ) ( ( )) bt bt Sx SScorex , and value of the membership functions. 
Then, we define two fuzzy sets named as Outlier and Change respectively as Their membership functions are Finally, point t x with high value of Outlier  X  is highly probably an outlier, while point t x with high value of Change  X  is highly probably a change point. false alarm rate, he can add another four fuzzy sets: Then the data set Change can be revised to and its membership function is the membership functions. Analysts can set a threshold to alarm possible outliers and changes. Users can also make their ow n decisions according to the membership functions and the practical experience. So we believe that our method which synthesizes both statistical and fuzzy approaches will be more effective in interactive online mining of outliers and changes. 4.3 Parameter Selection In the proposed detection method, some parameters are essential to the detection performance, such as the bandwidth h of the weight function, and the fitting order p . Epanechnikov kernel which is 2 function is not critical. 
Selection of the bandwidth h is important for the detection performance. Too large bandwidth will result in large estimated bias, while too small bandwidth will results in large estimated variance. A basic idea for searching the optimal bandwidth is to minimize the estimated mean integrated square error (MISE) which is defined as employ a more convenient method to find a suboptimal bandwidth. First, we set an acceptable threshold of the MISE denoted by  X  and an initial value of h , which hX X L = X   X  for backward parameter estimation. searching algorithm can find a reasonable h quickly. better than that with even order. Increasing fitting order will increase computational complexity. So we set 1 p = for most cases and add it to 3 if necessary. We evaluate our methods by numerical simulations using different data sets. Case (1). The first data set is generated from an AR(2) model: 12 0.6, 0.5 aa is not very small. 
Fig.1 (b) shows false alarm rate versus effective alarm rate of the outlier detection methods are compared. They are the proposed method, the CF method proposed in [4], and the parametric method proposed in [5] which is denoted by CIS method. We that for the linear data stream with changing mean and constant variance, the proposed method performs comparably to the other two parametric methods. Case (2). In this case, we use the similar AR(2) model as data set 1. The only difference and outliers occur at the same time points as data set 1, but all with size 1. The second advantage of the proposed score functions. Because of dividing by the estimated why the proposed method outperforms the other two parametric methods in this case. Case (3). In this case, we change the AR(2) model to a nonlinear time series model, the ARCH(1) model: time 1000 501 ( 0,1, , 9) t  X  X  = X +  X = " with deviation size 7. Fig.3 (a) shows the third data set and the membership functions of Outlier and Change . Curves of false alarm shown in Fig.3 (b). Here, we test the outlier of size 7 at time t= 1501, and the change point of size 3 at time t= 7001. It is easy to see the proposed nonparametric detection parametric methods. from the dataset KDD Cup 1999 which is prepared for network intrusion detection. recover at t= 602. We present the real data set and the membership functions of Outlier and Change in Fig.4. It is shown that the proposed method is effective in the normal data is detect ed as change points. This paper presents a unifying method for outlier and change detection from data streams. Unlike conventional parametric methods, the proposed method is based on a nonparametric technique, the local polynomial fitting. Fuzzy partition and decision method are used to alarm possible outliers and changes. The proposed method is more appropriate to online and interactive data mining. Simulation results reveal its robustness and efficiency. Acknowledgement. This work is supported by the National Natural Science Foundation of China (No.10571127) and the Specialized Research Fund for the Doctoral Program of Higher Education (No.20040610004). 
