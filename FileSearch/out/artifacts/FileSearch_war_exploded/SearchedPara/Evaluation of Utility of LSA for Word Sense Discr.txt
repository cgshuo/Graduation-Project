 The critical step of the LSA algorithm is to com-pute the singular value decomposition (SVD) of the normalized co-occurrence matrix. If the matri-ces comprising the SVD are permuted such that the singular values are in decreasing order, they can be truncated to a much lower rank. According to Lan-dauer and Dumais (1997), it is this dimensionality reduction step, the combining of surface informa-tion into a deeper abstraction that captures the mu-tual implications of words and passages and uncovers important structural aspects of a problem while filtering out noise. The singular vectors re-flect principal components, or axes of greatest variance in the data, constituting the hidden ab-stract concepts of the semantic space, and each word and each document is represented as a linear combination of these concepts. Within the LSA framework discreet entities such as words and documents are mapped into the same continuous low-dimensional parameter space, re-vealing the underlying semantic structure of these entities and making it especially efficient for vari-ety of machine-learning algorithms. Following successful application of LSA to information re-trieval other areas of application of the same meth-odology have been explored, including language modeling, word and document clustering, call rout-ing and semantic inference for spoken interface control (Bellegarda, 2005). The ultimate goal of the project described here is to explore the use of LSA for unsupervised identi-fication of word senses and for estimating word sense frequencies from application relevant cor-pora following Sch X tze X  X  (1998) context-group discrimination paradigm. In this paper we describe a first set of experiments investigating the tight-ness, separation and purity properties of sense-based clusters. We used the line-hard-serve-interest cor-pus(Leacock et al, 1993), with 1151 instances for 3 noun senses of word  X  X ine X : cord -373, division -374, and text -404; 752 instances for 2 adjective senses of word  X  X ard X : difficult  X  376, not yield-ing to pressure or easily penetrated  X  376; 1292 instances for 2 verb senses of word  X  X erve X : serv-ing a purpose, role or function or acting as  X  853, and providing service 439; and 2113 instances for 3 noun senses of word  X  X nterest X : readiness to give attention -361, a share in a company or business  X  500, money paid for the use of money -1252. For all instances of an ambiguous word in the cor-pus we computed the corresponding LSA context vectors, and grouped them into clusters according to the sense label given in the corpus. To evaluate the inter-cluster tightness and intra-cluster separa-tion for variable-dimensionality LSA representa-tion we used the following measures: 1. Sense discrimination accuracy . To compute sense discrimination accuracy the centroid of each sense cluster was computed using 90% of the data. We evaluated the sense discrimination accuracy using the remaining 10% of the data reserved for testing by computing for each test context vector the closest cluster centroid and comparing their sense labels. To increas e the robustness of this evaluation we repeated this computation 10 times, each time using a different 10% chunk for test data, round-robin style. The sense discrimination accuracy estimated in this way constitutes an upper bound on the sense discrimination performance of unsupervised clustering such as K-means or EM: The sense-based centroids, by definition, are the points with minimal average distance to all the same-sense points in the training set, while the centroids found by unsupervised clustering are based on geometric properties of all context vec-tors, regardless of their sense label. 2. Average Silhouette Value . The silhouette value (Rousseeuw, 1987) for each point is a measure of how similar that point is to points in its own clus-ter vs. points in other clus ters. This measure ranges from +1, indicating points that are very distant from neighboring clusters, through 0, indicating points that are not distinctly in one cluster or another, to -1, indicating points that are probably assigned to the wrong cluster. To construct the sil-houette value for each vector i , S(i), the following formula is used: and cosine measures the cen troid is simply the av-erage of vectors in the clus ter, while for L1 it is the median, i.e., the value of i-th dimension of the cluster centroid vector is the median of values of the i-th dimension of all the vectors in the cluster. As can be seen from the sense discrimination re-sults in Fig. 1, cosine distance, the most frequently used distance measure in LSA applications, has the best performance in for 3 out of 4 words in the corpus. Only for  X  X ard X  does L1 outperforms co-sine for low values of LSA dimension. As to the influence of dimensionality reduction on sense dis-crimination accuracy, our results show that (at least for the cosine distance) the accuracy does not peak at any reduced dimension, rather it increases monotonically, first rapidly and then reaching satu-ration as the dimension is increased from its lowest value (50 in our experiments) to the full dimension that corresponds to the number of contexts in the corpus. These results suggest that the value of dimension-ality reduction is not in increasing the sense dis-crimination power of LSA representation, but in making the subsequent computations more effi-cient and perhaps enabling working with much larger corpora. For every number of dimensions examined, the average sense discrimination accu-racy is significantly better than the baseline that was computed as the relative percentage of the most frequent sense of each ambiguous word in the corpus. Figure 2 shows the average silhouette values for the sense-based clusters as a function of the dimen-sionality of the underlying LSA X  X ased vector rep-resentation for the 3 different distance metrics and for the 4 words in the corpus. The average silhou-ette value is close to zero, not varying significantly for the different number of dimensions and dis-tance measures. Although the measured silhouette values indicate that the sense-based clusters are not very tight, the sense-discrimination accuracy re-sults suggest that they are sufficiently far from each other to guarantee relatively high accuracy. In this paper we reported on the first in a series of experiments aimed at examining the sense dis-crimination utility of LSA-based vector representa-tion of ambiguous words X  contexts. Our evaluation of average silhouette values indicates that sense-ing is based on geometric properties of word vec-tors, we expect it to have a better tightness as measured by average silhouette value, but, at the same time, lower sense discrimination accuracy. The experiments reported here are based on LSA representation computed using the whole docu-ment as a context for the ambiguous word. In the future we plan to investigate the influence of the context size on sense discrimination performance. The project described above is supported by grant  X  X sing LSA to Compute Word Sense Frequencies X  from Air Force Research Lab. Its contents are solely the responsibility of the authors and do not necessarily represent the official views of the AFRL. J.R. Bellegarda. 2005. Latent Semantic Mapping , IEEE Signal Processing Magazine, 22(5):70-80. S.T. Dumais. 1994. Latent Semantic Indexing (LSI) and TREC-2 , in Proc Second Text Retrieval Conf. (TREC-2), pp 104-105. T.K. Landauer, S.T. Dumais. 1997. A solution to Plato's problem: The latent semantic analysis the-ory of acquisition, induction and representation of knowledge , Psychological Review, 104(2):211-240. T.K. Landauer, P. Foltz, and D. Laham. 1998. Introduction to Latent Semantic Analysis . Discourse Processes, 25, 259-284. C. Leacock, G. Towel, E. Voorhees. 1993. Corpus-Based Statistical Sense Resolution , Proceedings of the ARPA Workshop on Human Language Tech-nology. P.J. Rousseeuw. 1987. Silhouettes: a graphical aid to the interpretation and validation of cluster analysis . Journal of Computational and Applied Mathematics. 20. 53-65. H. Sch X tze. 1998. Automatic Word Sense Dis-crimination , Journal of Computational Linguistics, Volume 24, Number 2 
