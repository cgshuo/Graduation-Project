 A recommender system must be able to suggest items that are likely to be preferred by the user. In most systems, the degree of preference is represented by a rating score. Given a database of users X  past ratings on a set of items, traditiona l collaborative filtering algorithms are based on predicting the potential ratings that a user would assign to the unrated items so that they can be ranked by the predicted ratings to produce a list of recommended items. In this paper, we propose a collaborative filtering approach that addresses t he item ranking problem directly by modeling user preferences derived from the ratings. We measure the similarity be-tween users based on the correlation between their rankings of the items rather than the rating values and propose new collaborative filtering algorithms for ranking items based on the preferences of similar users. Experimental results on real world movie rating data sets show that the proposed approach outperforms traditional collaborative filtering al-gorithms significantly on the NDCG measure for evaluating ranked results.
 H.3.3 [ Information Systems ]: Information Search and Re-trieval X  Information Filtering Algorithms, Experimentation Ranking, Collaborative Filtering, Random Walk
With the information available to us growing far more rapidly than our ability to process it, technologies to help people sift through huge amount of information efficiently is becoming increasingly important in order to overcome the resulted information overload problem. Recommender sys-tem is one such promising technology that aims to generate item recommendations from a huge collection of items based on users X  preferences. Broadly speaking, existing technol o-gies used for recommender systems fall in either of the fol-lowing two categories: content-based filtering versus collab-orative filtering . Content-based filtering approach analyzes the content information associated with the items and users such as product descriptions, user profiles etc. in order to represent users and items using a set of features. To recom-mend new items to a user, content-based filters match their representations to those items known to be of interest to the user. In contrast, the collaborative filtering(CF) approac h does not require any content information about the items, it works by collecting ratings on the items by a large number of users and make recommendations to a user based on the preference patterns of other users. The CF approach is based on the assumption that a user would usually be interested in those items preferred by other users with similar interests . Besides avoiding the need for collecting extensive informa -tion about items or users, CF requires no domain knowledge and can be easily adopted in different recommender systems.
Collaborative filtering is usually adopted in two classes of application scenarios[2]. In the first class, a user is prese nted with one individual item at a time along with a predicted rating indicating the user X  X  potential interest in the item . An example of this category is GroupLens[17], a collabora-tive filtering system for Usenet news. The second class of applications produce an ordered list of Top-N recommended items where the highest ranked items are predicted to be most preferred by the user. The user is expected to ex-amine the items in the list starting from the top positions. Many existing E-Commerce Websites fall in this category. In this paper, we focus on improving collaborative filtering techniques for the second class of applications.

The computation of the Top-N item list for making recom-mendations is essentially a ranking problem. To produce a ranking of the items, most collaborative filtering algorith ms adopt a rating-oriented approach which first predicts the potential ratings a target user would assign to the items and then rank the items according to the predicted ratings. However, higher accuracy in rating prediction does not nec-essarily lead to better ranking effectiveness as illustrate d in the following simple example. Suppose we have two items i and j for which the true ratings are known to be 3 and 4 respectively and two different methods have predicted the ratings on i and j to be { 2, 5 } and { 4, 3 } respectively. In terms of rating prediction accuracy as measured by the ab-solute deviation from the true rating, there is no difference between the two sets of predictions. However, using the pre-dictions { 4, 3 } , item i and j will be incorrectly ordered while the predictions { 2, 5 } ensures the correct order. The prob-lem with rating-oriented CF approaches is that the focus has been placed on approximating the ratings rather than the rankings, which is a more important goal for recom-mender systems. Moreover, most existing methods predict the ratings for each individual items independently withou t considering the user X  X  preferences regarding pairs of item s.
In this paper, we propose a ranking-oriented approach to collaborative filtering that directly addresses the item -ranking problem without going through the inter-meditate step of rating prediction. The main contributions of this paper is first to describe a similarity measure for evaluat-ing the consistency between two user X  X  rankings of a set of items that can be used to determine a set of users that share similar preferences to the target users. We then present two methods for producing item rankings based on the prefer-ences of a set of similar users: one is a greedy algorithm that searches through the possible rankings for the optimal one and the other is a novel random walk model defined using a user X  X  preference information. Both methods aim to ef-fectively combine the partial and incomplete item rankings derived from the ratings of a set of similar users in order to rank the items in a way that is most consistent with all the known information about user preferences, which is why we name our approach  X  X igenRank X .

This paper is organized as follows: in section 2, we briefly review some related works. Section 3 describes in more de-tail several similarity measures and models in traditional rating oriented CF approach. We then present the similar-ity measures and models for the proposed ranking-oriented CF approach in section 4. The experimental results and analysis are shown in section 5. Finally, we conclude the paper in section 6.
There are two types of common approaches to collabora-tive filtering. One is the neighborhood-based approach and the other is the model-based approach.
The most common form of neighborhood-based approach is the user-based model, which estimate the unknown ratings of a target user based on the ratings by a set of neighbor-ing users that tend to rate similarly to the target user. A crucial component of the user-based model is the user-user similarity s u,v that is used to select the set of neighbors. Popular choices for s u,v include the Pearson Correlation Co-efficient(PCC)[22, 11]and the vector similarity(VS)[2].
One difficulty in measuring the user-user similarity is that the raw ratings may contain biases caused by the different rating behaviors of different users. For example, some users may tend to give high ratings. To correct such biases, differ-ent methods have been proposed to normalize or center the data prior to measuring user similarities. [22, 2] showed th at by correcting for user-specific means the prediction qualit y could be improved. Later, Jin et al. proposed a technique for normalizing the user ratings based on the halfway accu-mulative distribution[15].

Another difficulty in user-based models arises from the fact that the known user-item ratings data is typically high ly sparse, which makes it very hard to find highly similar neigh-bors for making accurate predictions. To alleviate such spa r-sity problem, different techniques have been proposed to fill in some of the unknown ratings in the matrix such as di-mensionality reduction[8] and data-smoothing methods[25 , 19].

An alternative form of the neighborhood-based approach is the item-based model[24, 18]. Here the item-item simi-larity is used to select a set of neighboring items that have been rated by the target user and the ratings on the unrated items are predicted based on his ratings on the neighboring items. Since the number of items is usually much less than the number of users in most applications, item-item similar i-ties are less sensitive to the data sparsity problem. Sarwar et al.[24] recommended using the adjusted cosine similarity t o compute the item-item similarity and found that the item-based model could obtain higher accuracy than the user-based model, while allowing more efficient computations.
In contrast to the neighborhood-based approach, the model-based approach to CF use the observed user-item ratings to train a compact model that explains the given data so that ratings could be predicted via the model instead of directly manipulating the original rating database as the neighborhood-based approach does. Algorithms in this cat-egory include clustering methods[25], aspect models[12] a nd Bayesian networks[21].
Learning to rank has been attracting broad attention in the machine learning community due to its importance in a wide variety of applications such as information retrieva l, collaborative filtering, etc. Most of the proposed methods are dedicated to ranking items represented in some feature space as is the setting for content-based filtering. Given a s et of ordered pairs of instances as training data, the different methods either try to learn an item scoring function[4, 16] or learn a classifier for classifying item pairs into two type s of relations(correctly ordered vs. incorrectly ordered)[ 5, 6]. Different machine learning models including SVM, Boost-ing and Neural Network have been used for learning such ranking functions, which led to methods such as Ranking SVM[16], RankNet[4] and RankBoost[6].
In this section, we first describe several rating-based simi -larity measures that have been commonly used in neighborhoo d-based CF approaches for finding similar users[22, 2] and sim-ilar items[24, 18]. We then discuss two models for rating prediction in neighborhood-based CF, namely user-based and item-based models. The notational framework is de-fined as follows. Suppose we are given a set of m users U = { u 1 , u 2 , ..., u m } and a set of n items I = { i The user X  X  ratings on the items can be represented by an m  X  n matrix R where each entry r u,i represents user u  X  X  rating on item i and r u,i = 0 if u has not rated i . The set of users who have rated item i is denoted by U i and the set of items that have been rated by user u is denoted by I u
The Pearson Correlation Coefficient(PCC) measures the similarity between two users based their normalized rating s on the set of items they rated in common:
Another way of measuring user-user similarity is to view each user as a vector in a high dimensional vector space based on his ratings so that the cosine of the angle between the two corresponding vectors can be used to measure their similarities:
For measuring item-item similarity in item-based models, the adjusted cosine similarity has been shown to be most effective [24]: where each user X  X  rating on an item is adjusted by his mean rating.
In user-based collaborative filtering, the unknown ratings b r u,i  X  X  are predicted by selecting a set of k most similar users N u based on the user-user similarities s u,v and compute the weighted average of the ratings on i assigned by users in N
Following the same idea, in the item-based model, b r u,i are predicted based on u  X  X  ratings on items in N i , the set of k items most similar to i determined using the item-item similarities s i,j :
Traditional rating-oriented collaborative filtering focu ses on predicting a user X  X  potential ratings on unrated items by utilizing the known ratings associated with similar users o r similar items. In this section, we present a ranking-orient ed collaborative filtering approach that aims at producing an item ranking for the target user. We first describe a user-user similarity measure that is based on two users X  prefer-ences over the items and then present two methods for rank-ing items based on the preferences of the set of neighbors of the target user.
Both PCC and VS described in Section 3 are rating-based similarity measures in the sense that they are calculated by comparing ratings values assigned to the items by differ-ent users. In the ranking-oriented approach, the similarit y between users is determined by their preferences over the items, which is reflected by their ranking of the items. Sup-pose we have a set of three items, to which two users have assigned ratings of { 2,3,4 } and { 3,4,5 } respectively. The rating values on the same items by the two users are clearly different, nevertheless their preferences are very close as the items are ordered in the way based the two user X  X  ratings. The Kendall rank correlation coefficient[20] is a similarity measure between two rankings of the same set of objects: where I  X  ( x ) is an indicator function defined as: The value of the coefficient is negatively correlated with the number of disconcordant pairs, where a pair of items i and j is disconcordant if i is ranked higher than j in one ranking but lower in the other.
Since our goal is to produce a ranking of the items for a user rather than predicting the rating values, we focus on modeling a user X  X  preference function of the form  X  : I  X  I  X  R , where  X ( i, j ) &gt; 0 means that item i is more preferable to j for user u and vice versa. The magnitude of this preference function |  X ( i, j ) | indicates the strength of preference and a value of zero means that there is no preference between the two items. Following [6], we assume that  X ( i, i ) = 0 for all i  X  I and that  X  is anti-symmetric, i.e.  X ( i, j ) =  X   X ( j, i ) for all i, j  X  I . Note that, however, we do not require  X  to be transitive, i.e.  X ( i, j ) &gt; 0  X   X ( j, k ) &gt; 0 does not imply  X ( i, k ) &gt; 0.

In content-based filtering, the preference function  X  is of-ten realized by a binary classifier that categorizes each pai r of items into two categories(correctly ranked and incorrec tly ranked) based on their content features. Various machine learning approaches including ensembles[5, 6], support ve c-tor machines[16] and neural networks[4] have been develope d for learning such a binary classifier to model the preference function. However, in the collaborative filtering setting, such approaches could not be applied due to the lack of features for describing the items.

Given a user X  X  ratings on a set of items, we can derive his preference over the items by comparing his ratings on pairs of rated items. Suppose user u  X  X  rating on item i and j are 5 and 3 respectively, this clearly indicates that he prefer i to j and should serve as evidence for  X ( i, j ) &gt; 0 and  X ( j, i ) &lt; 0. In ranking-oriented collaborative filtering, the key chall enge is to obtain preference information regarding pairs of item s that have not both been explicitly rated by the target user. Following the same idea of neighborhood-based collaborati ve filtering, we resort to a set of users with similar preference s to the target user, referred to as the neighborhood N u . The basic idea is that the more often the users in N u assign i a higher rating than j , the stronger the evidence for  X ( i, j ) &gt; 0 and  X ( j, i ) &lt; 0. This leads to the following formula for estimating the values of the preference function  X ( i, j ): where the summation is over N i,j u , the set of neighbors of u who have rated both item i and j .

Given a preference function  X , which assigns a score to every pair of items i, j  X  I , we want to choose a ranking of items in I that agrees with the pairwise preferences defined by  X  as much as possible. Let  X  be a ranking of item in I such that  X  ( i ) &gt;  X  ( j ) if and only if i is ranked higher than j . We can define a value function V  X  (  X  ) that measures how consistent is the ranking  X  with respect to the preference function  X  as follows: Therefore, our goal is to produce a ranking  X   X  that maxi-mizes the above value function.
One possible approach to solve the item ranking problem is to search through the possible rankings in an attempt to find the optimal ranking  X   X  that maximizes the value func-tion defined Equation 7 . However, Cohen et al.[5] showed that finding the optimal ranking  X   X  is a NP-Complete prob-lem based on reduction from the Cyclic-Ordering problem[7] and proposed an efficient greedy order algorithm for finding an approximately optimal ranking shown in Algorithm 1 be-low: Algorithm 1 Greedy Order INPUT : an item set I ; a preference function  X 
OUTPUT : a ranking  X   X  1: for each i  X  I do 2:  X  ( i ) = 3: end for 4: while I is not empty do 5: t = arg max i  X  I  X  ( i ) 6:  X   X  ( t ) = | I | 7: I = I  X  X  t } 8: for each i  X  I do 9:  X  ( i ) =  X  ( i ) +  X ( t, i )  X   X ( i, t ) 10: end for 11: end while
The algorithm maintains for each item i  X  I a potential value  X  ( i ), which is equal to the more items that are less preferred than i (i.e.  X ( i, j ) &gt; 0) the higher the potential of i . The greedy algorithm produces the ranking from the highest position to the lowest position by always picking the item t that currently has the maxi-mum potential and assign it a rank equal to the number of remaining items in I so that it will be ranked above all the other remaining items. It then deletes t from I and updates the potential values of the remaining items by removing the effects of t . The algorithm has a time complexity O ( n where n denotes the number of items and it was shown in [5] that the ranking  X   X  produced by the greedy order algo-rithm has a value V  X  (  X  ) that is within a factor of 2 of the optimal, i.e., V  X  ( X   X  )  X  1 2 V  X  (  X   X  ).
In this section, we describe a random walk model for rank-ing the set of items. Instead of directly searching for a rank -ing as the greedy order algorithm, we attempt to define a Markov chain model in which states correspond to the items and the transitional probabilities depend on a user X  X  prefe r-ence function  X . The stationary distribution of this Markov chain can then be used to produce a ranking.
The motivation for using the Markov chain model is that it is an effective model for aggregating partial and incom-plete preference information from many users. Suppose that among the set of users, some rated i higher than j and others rated j higher than k but very few have rated all three items i, j and k so the preferences regarding i and k is implicit and need to be inferred through transitivity. Such implicit rel a-tionships between pairs of items not both explicitly rated b y the user could be effectively inferred using multi-step ran-dom walks that can exploit the connectivity of the directed graph model underlying the Markov chain.

Our model is closely related to the  X  X ageRank X  scheme [3], which defines a random walk on the Web pages based on the Web X  X  hyperlink structure. In particular, the X  X ageR -ank X  model assumes that a random surfer always randomly pick a hyperlink on the current page to follow at each step. It interprets a direct link from page p to q as an endorsement of q by p so that the stationary probability of being at some page in the long run could reflect its authority. Similarly, our model could be viewed as deriving implicit links between items based on the observed preference information so that a less preferred item j would link to a more preferred item i and the transition probability p ( i | j ) would depend on the strength of the preference which can be told from the value  X ( i, j ).

Our goal is to obtain a probability distribution  X  ( i ) over items in I , which could be interpreted as the probability that a user would be interested in each item i . Imagine a user trying to find his favorite item and suppose that he has pref-erences over the items in his mind. So he would randomly select the items in the following manner. He first chooses an item j randomly. Then based on his preferences, he would switch to another item i based on the conditional probability p ( i | j ) which would be higher for those items that are more preferred than j and lower for the items that are less pre-ferred than j by the user. Such a process continues and in the long run, the user should select his favorite items most often, which explains intuitively how the stationary distr i-bution could be used to rank the items based on preferences. More precisely, the transition probability p ( i | j ) of switching to another item j given the current item i is defined as: where the transitional probability p ( j | i ) X  X  is proportional to e
The algorithm for computing the item rankings using the random walk model described in the last section can be de-scribed clearly using matrix notations. Let P be the tran-sition matrix for the random walk model where each en-try p i,j is equal to the transition probability p ( j | i ). Let  X  t = [ p t (1) , p t (2) , . . . , p t ( n )] T where p t of being at item i after walking t steps. Given an initial probability distribution over the items  X  0 ,  X  t  X  X  can be com-puted iteratively using the formula: which is the power or vector iteration methods for solving principal eigenvector problems[9]. The vector of stationa ry probabilities is defined to be  X   X  = lim t  X  X  X   X  t . In general, using the iterative power method,  X  t would converge to the dominant or principal eigenvector of the transition matrix P [3]. The existence and uniqueness of the stationary distri-bution  X   X  is guaranteed if and only if the matrix P is irre-ducible and different modifications to P have been proposed in order to improve numerical stability of the PageRank al-gorithm[3]. In our model, since the transition probabiliti es p ( j | i ) X  X  are calculated using Equation 8, the entries of P are all non-negative, which could guarantee the existence and uniqueness of the stationary distribution  X   X  [1].
To avoid the reducibility of the stochastic matrix, Brin and Page[3] proposed a trick which forms a revised transitio n matrix P by interpolating P with a perturbation matrix E = ev T /n where e is the vector with all components equal to 1 and v is a  X  X ersonalization X  vector: where is a scalar between 0 and 1. The reasoning is that a web surfer can sometimes X  X eleport X  X o other pages accordin g to the probability distribution defined by v independent of the current page and the parameter controls how often the surfer may teleport to another page rather than following th e hyperlinks. A few follow up works to PageRank proposed different methods to bias the personalization vector v to take into account different types of information besides the link structure such as contents[10, 23] and user preferences[14 ].
In our random walk model for item ranking, we follow the similar idea to define a personalization vector v u = [ p u (1) , . . . , p u ( n )] T for each target user u based on his known ratings on the items: So the user would teleport to those items with high ratings more often than to those items that have been rated low by him and all the unrated items have equal probabilities of be-ing visited via teleportation. The use of the personalizati on vector provides an effective way of incorporating the known preference information of the target user into the random walk model so that the user X  X  given preferences are not only used in selecting the neighbors but also in producing the item rankings.
We evaluated the proposed approach using two sets of real world movie ratings data and conducted different ex-periments to address the following issues: (1) Does the pro-posed ranking-oriented CF approach improve item ranking effectiveness compared with traditional rating-oriented a p-proaches such as user-based and item-based algorithms? (2) Which of the two ranking-oriented CF algorithms, namely greedy order and random walk model, is more effective? (3) Is the ranking-oriented similarity measure Kendall Ran k Correlation Coefficient more effective in finding users with similar preferences?
We evaluated the algorithm using two movie ratings data sets: EachMovie 1 and Netflix 2 . The EachMovie data set consists of about 2.8 million ratings made by more than 72 thousand users on 1628 movies. The Netflix data set contains over 100 million ratings from over 480 thousand users on around 18000 titles. The ratings for EachMovie are on a scale from 1 to 6 while the Netflix ratings are on a scale from 1 to 5. Due to the huge size of the Netflix data, we extract a subset comprised of the ratings on the 2000 movies with the most ratings. Then from both data sets, we randomly picked a set of 10600 users that have rated more than 40 different movies, where 10000 are used as the training data and the other 100 and 500 are used for parameter tuning and testing purposes respectively. The density of user-item rating matrix (i.e. proportion of non-zero entries) of the EachMovie and Netflix data sets are 6 . 1% and 6 . 6% respectively.
The major criterion for evaluating traditional rating-ori ented collaborative filtering algorithms is the rating predictio n ac-curacy. Commonly used measures for accuracy include the Mean Absolute Error (MAE) and the Root Mean Square Error (RMSE), both of which depend on difference between true rating and predicted rating. However, since the em-phasis of our work is on improving item rankings instead of rating prediction, we employ the Normalized Discounted Cu-mulative Gain(NDCG)[13] metric, which is an increasingly popular metric for evaluating ranked results in informatio n retrieval where the documents are assigned graded rather than binary relevance judgements. For collaborative filter -ing applications, the ratings on items assigned by the users can naturally serve as the graded relevance judgements.
The NDCG metric is evaluated over some number k of the top items on the ranked item list. Let Q be the set of users used for testing and R ( u, p ) be the rating assigned by u to the item at the p -th position on the ranked list produced for user u . The NDCG at the k -th position with respect to the http://nyc.lti.cs.cmu.edu/IRLab/11-743s03/lebanon/I R-lab.htm http://www.netflixprize.com set of users Q is: where Z u is a normalization factor calculated so that the NDCG of the optimal ranking has a value of 1. The value of NDCG ranges from 0 to 1 with a higher value indicates better ranking effectiveness. The NDCG is very sensitive to the ratings of the highest ranked items. This is modeled by the discounting factor log(1 + p ), which increases with the position in the ranking. This characteristic makes it highl y desirable for measuring ranking quality in recommender sys -tems as most users rarely look past the first few items on a recommendation list so the relevance of items at the top positions are far more important than those at low positions .
Note that the Kendall Rank Correlation Coefficient can also be used to evaluate the quality of a ranking by calcu-lating its correlation with the optimal ranking, however su ch an approach is not able to take into consideration the dif-ferent importance of high and low positions in a ranking as NDCG does. Therefore, we did not use it as the evaluation metric in our experiments.
For each user in the test set, we use 50% of his known ratings as input for model construction and use the remain-ing 50% as hold-out data for evaluation purposes. Different algorithms are evaluated based on the quality of the rank-ings they produced for the items in the hold-out data of each user, which can be measured using NDCG based on the true ratings on the items.
Similar to user-based and item-based collaborative filter-ing algorithms, the size of the neighborhood will affect the performance of our algorithms which need to estimate a user preference based a set of neighbors. For this set of experi-ments, we fix the number of training users at 5000 and use NDCG at the 1st position as the performance measure. We run both the greedy order algorithm and the random walk algorithm with varying neighborhood size. Figure 1 shows the change in performances when the size of the neighbor-hood increase from 20 to 200. We can see that the NDCG gradually increases as the neighborhood size increases fro m 20 to 100 since the preference  X ( i, j ) can be estimated more accurately given more neighbors. However, we also observe that the performance start to decrease as the neighborhood size exceeds 100, which is due to that many non-similar users began to enter the neighborhood and introduce incorrect preference information into  X ( i, j ) as the neighborhood size gets too large. The optimal value for the neighborhood size is around 100.
The parameter in Equation 10 controls how often the  X  X eleport X  X peration is performed in the random walk model. By setting to 0, the transition probabilities will be defined by Equation 8, which is only determined by the preference function  X ( i, j ). On the other hand, by setting to 1, the random walk model will perform the  X  X eleport X  operation Figure 1: NDCG vs. Neighborhood Size Results on EachMovie (Above) and Netflix (Below) all the time and the preference information  X ( i, j ) is totally ignored. In our experiments, we vary from 0 to 0.9 and measure the NDCG at the 1st, 3rd and 5th positions de-noted by NDCG1, NDCG3 and NDCG5 respectively. The results are shown in Figure 2. We can see that increasing the value from 0 can generally lead to improvements on all three NDCG measures and the improvements on NDCG1 are especially notable. We also note that as gets very large the performances would start to drop significantly. This is because with high value, the random walk model would perform the  X  X eleport X  operation most of the time and the stationary distribution would approach the personalizati on vector defined in Equation 11, which assigns equal proba-bilities to all the unrated items and makes it impossible to rank the unrated items effectively. The optimal value for is around 0.6.
We choose 4 rating-oriented collaborative filtering algo-rithms as the baselines including item based model using Pearson Correlation Coefficient(IPCC) and Vector Similar-ity(IVS), user based model using Pearson Correlation Co-efficient (UPCC) and Vector Similarity(UVS)and compared them with our algorithms: random walk model using Pear-son Correlation Coefficient (RWPCC), Vector Similarity (RW VS), and Kendall Rank Correlation Coefficient (RWKRCC), greedy order algorithm using Pearson Correlation Coeffi-cient(GOPCC), Vector Similarity (GOVS) and Kendall Rank Figure 2: NDCG vs. Epsilon Results on EachMovie (Above) and Netflix (Below) Correlation Coefficient (GOKRCC). For IPCC and IVS, we set the number of neighboring items to be 50 as suggested by [24]. For all the other algorithm, we set the size of the neighborhood N u to be 100. The parameter for the random walk based models are set to 0.6.

The evaluation results on both EachMovie and Netflix data sets are shown in Table 1(a) and 1(b) respectively. For both data sets, we vary the number of training users from 1,000 to 10,000. For each algorithm, we report the NDCG values at the 1st, 3rd and 5th positions, denoted by NDCG1, NDCG3 and NDCG5 respectively. For each column in Table 1(a) and 1(b), we have highlighted the top 3 performers and the values shown in the bottom row are the performance im-provements achieved by the best ranking-oriented methods over the best rating-oriented methods.

As can be seen from the results, in all the conducted ex-periments, the top 3 performers are consistently ranking-oriented methods. The improvements on NDCG1, NDCG3 and NDCG5 of the best ranking oriented methods over the best rating oriented methods are more than 8.8%, 4.7% and 3.4% on average. We can see that random walk model had consistently outperformed all the rating oriented methods and the greedy order algorithm in almost all the experi-ments.
 For the greedy order algorithm, we can see that using Kendall Rank Correlation Coefficient as the similarity mea-sure has led to higher performances than the Pearson Cor-relation Coefficient and the Vector Similarity on both data sets. For the random walk model, the performances of RW-PCC and RWKRCC are very close on the EachMovie data set while RWKRCC outperformed RWKRCC on the Net-flix data. So from the results we can see that the Kendall Rank Correlation Coefficient is a more effective similarity measure for finding users with similar preferences. It can also be noted that the performances of different algorithms would improve as the number of training users increases. This is because with a larger user database, it will be easier to find sufficient number of neighbors with high similarities to the target user so that his preferences can be estimated more accurately.
In this paper, we propose a ranking-oriented framework for collaborative filtering that addresses the item ranking problem directly without trying to predict a user X  X  ratings on the unrated items as an intermediate step. Our approach ex-tends the neighborhood-based collaborative filtering fram e-work by identifying and aggregating the preferences rather than ratings of similar users in order to produce a rank-ing of items. We described two methods for computing the item rankings based on preferences including a greedy order algorithm and a random walk model. Experimental results show that our approach outperforms existing CF algorithms in terms of ranking effectiveness.

For future work, we would like to investigate different techniques proposed for improving traditional rating ori-ented CF including data smoothing and utilizing content in-formation, and study their usefulness to our ranking-orien ted CF approach. The authors are supported by a grant from NEC Labs China and Hong Kong RGC project number 621307. [1] M. Bianchini, M. Gori, and F. Scarselli. Inside [2] J. S. Breese, D. Heckerman, and C. Kadie. Empirical [3] S. Brin and L. Page. Anatomy of a large-scale [4] C. Burges, T. Shaked, E. Renshaw, A. Lazier, [5] W. W. Cohen, R. E. Schapire, and Y. Singer.
 [6] Y. Freund, R. Iyer, R. E. Schapire, and Y. Singer. An [7] M. R. Gary and D. S. Johnson. Computers and [8] K. Y. Goldberg, T. Roeder, D. Gupta, and C. Perkins. [9] G. H. Golub and C. F. V. Loan. Matrix Computations . [10] T. H. Haveliwala. Topic-sensitive pagerank. In [11] J. Herlocker, J. A. Konstan, and J. Riedl. An [12] T. Hofmann. Latent semantic models for collaborative [13] K. J  X  arvelin and J. Kek  X  al  X  ainen. Cumulated gain-based [14] G. Jeh and J. Widom. Scaling personalized web [15] R. Jin, L. Si, C. Zhai, and J. Callan. Collaborative [16] T. Joachims. Optimizing search engines using [17] J. A. Konstan, B. N. Miller, D. Maltz, J. L. Herlocker, [18] G. Linden, B. Smith, and J. York. Amazon.com [19] H. Ma, I. King, and M. R. Lyu. Effective missing data [20] J. I. Marden. Analyzing and Modeling Rank Data . [21] D. M. Pennock, E. Horvitz, S. Lawrence, and C. L. [22] P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, and [23] M. Richardson and P. Domingos. The intelligent [24] B. M. Sarwar, G. Karypis, J. A. Konstan, and [25] G.-R. Xue, C. Lin, Q. Yang, W. Xi, H.-J. Zeng, Y. Yu,
