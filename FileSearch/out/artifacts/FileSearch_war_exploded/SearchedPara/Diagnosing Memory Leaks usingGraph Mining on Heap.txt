 Memory leaks are caused by software programs that prevent the reclamation of memory that is no longer in use. They can cause significant slowdowns, exhaustion of available storage space and, eventually, application crashes. Detecting mem-ory leaks is challenging because real-world applications are built on multiple layers of software frameworks, making it difficult for a developer to know whether observed references to objects are legitimate or the cause of a leak. We present a graph mining solution to this problem wherein we ana-lyze heap dumps to automatically identify subgraphs which could represent potential memory leak sources. Although heap dumps are commonly analyzed in existing heap pro-filing tools, our work is the first to apply a graph grammar mining solution to this problem. Unlike classical graph min-ing work, we show that it suffices to mine the dominator tree of the heap dump, which is significantly smaller than the underlying graph. Our approach identifies not just leak-ing candidates and their structure, but also provides aggre-gate information about the access path to the leaks. We demonstrate several synthetic as well as real-world exam-ples of heap dumps for which our approach provides more insight into the problem than state-of-the-art tools such as Eclipse X  X  MAT.
 Categories and Subject Descriptors: H.2.8 [Database Management]: Data mining; D.2.5 [Software Engineering]: Debugging aids; General Terms: Algorithms, Experimentation, Reliabil-ity.
 Keywords: Memory leaks, heap profiling, graph mining, graph grammars, dominator tree.
Memory leaks are a frequent source of bugs in applica-tions that use dynamic memory allocation. They occur if programmers X  mistakes prevent the deallocation of memory that is no longer used. Undetected memory leaks cause slow-downs and eventually the exhaustion of all available mem-ory, triggering out-of-memory conditions that usually lead to application crashes. These crashes significantly affect availability, particularly of long-running server applications, which is why memory leaks are one of most frequently re-ported types of bugs against server frameworks.

Memory leaks are challenging to identify and debug for several reasons. First, the observed failure may be far re-moved from the error that caused it, requiring the use of heap analysis tools that examine the state of the reachability graph when a failure occurred. Second, real-world applica-tions usually make heavy use of several layers of frameworks whose implementation details are unknown to the develop-ers debugging encountered memory leaks. Often, these de-velopers cannot distinguish whether an observed reference chain is legitimate (such as when objects are kept in a cache in anticipation of future uses), or represents a leak. Third, the sheer size of the heap  X  large-scale server applications can easily contain tens of millions of objects  X  makes man-ual inspection of even a small subset of objects difficult or impossible.

Existing diagnosis tools are either online or offline. On-line tools monitor either the state of the heap or accesses to objects in it, or both. They analyze changes in the heap over time to detect leak candidates, which are X  X tale X  X bjects that have not been accessed for some time. Online tools are not widely used in production environments, in part because their overhead can make them too expensive, but also be-cause the need to debug memory leaks often occurs unex-pectedly after an upgrade or change to a framework compo-nent, and often when developers believe their code has been sufficiently tested. Offline tools use heap snapshots, often obtained post-mortem when the system runs out of memory. These tools find leak candidates by analyzing the relation-ships, types, and sizes of objects and reference chains. Most existing heuristics, however, are based solely on the amount of memory an object retains and ignore structural informa-tion. Where structural information is taken into account, it often relies on priori knowledge of the application and its libraries.

This paper presents a graph mining approach to identify-ing leak candidate structures in heap dumps. Our approach is based on the observation that leaks often involve container data structures from which programmers fail to remove un-needed objects that were previously added. Consequently, the heap dump involves many subgraphs of similar struc-ture containing the leaked objects and their descendants. By mining the dump, we can identify those recurring subgraphs, present the developer with statistics about their frequency and location within the graph. Our key contributions can be summarized as follows: 1. Although analysis techniques are widely used in heap 2. Compared to other offline analysis techniques, our ap-3. Our approach can identify leaks even if the leaks X  lo-4. Graph grammar mining can find recursive structures, 5. Finally, the ability to combine subgraph frequency with
Although memory leaks can occur in all languages that use dynamically allocated memory, they are particularly preva-lent in type-safe languages such as Java, which rely on garbage collection to reclaim memory. In these languages, dynam-ically allocated objects are freed only if the garbage col-lector can prove that no accesses to them are possible on any future execution path, which is true if and only if there is no path from a set of known roots to the object in the reachability graph. The reachability graph consists of nodes that represent allocated objects and edges that correspond to inter-object references stored in instance variables (fields). Roots, also known as garbage collection (GC) roots, are nodes whose liveness does not depend on the liveness of other heap objects, but on the execution semantics of the program. For instance, in Java, local and global static variables repre-sent roots because the objects referred by them must remain reachable throughout the execution of a method or program, respectively. Hence, memory leaks form if objects remain reachable from a GC root even though the program will no longer access them. Such leaks also occur in programming languages with explicit memory management, such as C++, and our work applies to them. We do not consider leaks arising from memory management errors in those languages (e.g., failing to deallocate unreachable objects).
The Java program sketched in Figure 1 illustrates how leaks in a program manifest themselves in the reachability graph. In this example, a program maintains a number of objects of type Legitimate , which are stored in a hash map Figure 1: An example of a leak  X  X idden X  underneath legitimate objects. container. Each Legitimate instance, by itself, represents data the program needs to maintain and thus it needs to re-tain references to each instance. However, Legitimate also references a container leakyMap that accrues, over time, ob-jects of type Leak that should not be stored permanently. Figure 2 shows the resulting heap structure. The hash maps exploit an open hashing scheme, which uses an array of buck-ets. Each bucket maintains a separate chain of entries cor-responding to keys for which hash collisions occurred.
Over time, the space taken up by the leaked object will grow until all available heap space is exhausted. When this limit is reached, the Java virtual machine throws a runtime error ( OutOfMemoryError ). In many production environ-ments, the JVM is run with a flag that saves a snapshot of the heap at this point, which is then fed to a heap ana-lyzer tool.

Most existing tools compute and analyze the dominator tree, which represents a relationship between nodes in the heap that expresses which objects a given object keeps alive. Object  X  X  X  dominates  X  X  X  if all paths from a root to  X  X  X  go through  X  X  X . If the object graph is a tree, as in this example, then it is identical to its dominator tree. In the example, the static (global) variable legitimateMap is the dominator tree root that keeps alive all leaked objects.

However, inspection of the dominator tree for this exam-ple with existing tools does not readily point to the leak. For instance, when examining a heap dump with the Eclipse Memory Analyzer tool (available at http://eclipse.org/mat), the tool pointed at  X  X egitimateMap X  as a likely leak candi-date, because it keeps alive a large fraction of the heap. None of its children stands out as a big consumer with re-spect to retained heap size. The leak is  X  X idden X  under a blanket of legitimate objects. At this point, a developer would be required to  X  X ig down, X  and individually examine Figure 2: Heap graph after executing the program shown in Figure 1. paths through each Legitimate instance, which is cumber-some without global information about the structure of the subtrees emanating from these instances. Heap analyzers do support some global information, but is usually limited to histogram statistics that shows how often objects of a certain type occur. This approach often leads to limited insight be-cause String objects and char arrays are the classes whose objects usually consume most memory in Java programs.
Consequently, there is a need to mine the graph to iden-tify structures that are likely leak candidates, even if these structures are hidden beneath legitimate live objects. More-over, developers require aggregate information that describe where in the object graph these leak candidates are located.
As stated in the introduction, our approach is based on the observation that a leak would manifest as a heap dump containing many similar subgraphs. Rather than directly mine the heap dump, we compute the dominator tree of the heap dump and mine frequent graph grammars [15, 17] in the dominator tree. We describe the rationale behind this approach and algorithmic design decisions in this section.
The computation of dominators is a well studied topic and we adopt the Lengauer-Tarjan algorithm [19] from the Boost graph library implementation. This algorithm runs in of vertices and | E | is the number of edges.
 Formally, the dominator relationship is defined as follows. A node x dominates a node y in a directed graph iff all paths to node y must pass through node x . In Fig. 3 (left), all paths to node L must pass through node A, therefore A dominates L. A node x is said to be the unique immediate dominator of y iff x dominates y and there does not exist a node z such that x dominates z and z dominates y . Note that a node can have at most one immediate dominator, but may be the immediate dominator of any number of nodes. The dominator tree D = ( V D ,E D ) is a tree induced from the original directed graph G = ( V G ,E G ), where V D = V
G , but an edge ( u  X  v )  X  E D iff u is the immediate Figure 3: (i) An example graph and (ii) its domi-nator tree. In practice, the dominator will have a significantly reduced number of edges than the orig-inal graph. dominator of v in G . Figure 3 shows an example graph and its dominator tree. The computation of D requires the specification of an entry node into G . We therefore introduce a pseudo-root node  X  to G , and add edges (  X   X  GC i ) where GC i  X  GC , the set of Java garbage collection roots (see Section 2).

The dominator tree computation on the heap dump graph provides us with several benefits. First, it significantly re-duces the number of edges in the graph to be mined. Second, since the resulting graph is a tree, we can apply optimiza-tions in the mining algorithm specific to mining trees. Fi-nally, recall that our goal is not just to find the frequent subgraph representing the leak but also to characterize the source of the leak. Once the dominator tree has been com-puted, we can search the paths from the entry node of the leaking subgraph up to the root of the dominator tree. This path is generally sufficient to identify the source of the leak. Without the dominator tree computation, tracing all paths to garbage collection roots in the graph is much more ex-pensive and is full of noise.
In general, frequent subgraphs in the original heap dump need not necessarily be frequent in the dominator tree. To understand this, consider the cases in Fig. 4 which shows example graphs that are frequent in both the dump and the dominator, frequent in the dump but not the dominator, as well as the other two combinations. In particular, the (fre-quent in dump, infrequent in dominator) combination occurs due to the existence of different routes of entry into a fre-quent subgraph S in graph G . This situates S into different subgraphs in D that may not be frequent individually. The reverse combination, i.e., (infrequent in dump, frequent in dominator), also happens, because frequent subgraphs in D may contain edges that summarize dissimilar paths in G .
Nevertheless, practical heap dumps have specific degree distribution properties that we can exploit. As we show later, a large majority of nodes in heap dumps have an in-degree of either zero or one. This implies that cases as shown in Fig. 4 (top right) are much fewer in number than cases in Fig. 4 (top left). This is a key distinction because we can guarantee that if a frequent subgraph S in G contains only nodes having in-degree  X  1, all instances of S will be completely conserved after the computation of the domi-nator tree D and will retain their frequencies. Although it is unlikely that a frequent subgraph in the heap dump will comprise exclusively of nodes with in-degree  X  1, ex-perience shows that it will be composed predominately of such nodes. These observations justify our design decision to compute the dominator tree as a preprocessing step be-fore graph mining and to mine frequent structures in the dominator.
 Figure 4: Examples of subgraphs that may be fre-quent or not frequent in either or both the graph G and its dominator tree D . (i-iv) show all 4 classes of subgraphs defined by the different combinations. Dashed edges represent a  X  X ominates X  edge pro-duced only for D .
To mine patterns in the dominator tree, we explore the use of context-free graph grammars [10,28] instead of mere subgraphs. Graph grammars are necessary because leak-ing objects are often recursive in nature and we require the expressiveness of graph grammars. Furthermore, it is not necessarily the number of instances of a subgraph that is important in debugging the leak, but rather the percent-age of the heap dump that is composed of instances of the subgraph. An algorithm that finds subgraphs could be mis-leading because a simple count of the number of instances could over-calculate the composition of the subgraph.
The concept of a graph grammar is akin to a formal lan-guage grammar, except that the productions generate sub-graphs rather than substrings. We are specifically interested in node-label controlled grammars, as these contain a single non-terminal labeled node which can be replaced with any subgraph. These grammars take the form of S  X  P , where S is a single non-terminal node, P can be any subgraph, and the arrow implies a production/replacement rule.
As described in [9,15,17], we build graph grammars in a priori fashion where we find a production rule capturing a significant portion of the input graph, replacing instances of the production by its non-terminal symbol, and contin-uing. Candidate productions are evaluated for their ability to compress the graph. We use the alternative size heuristic from [17]: where size( G ) = | V | + | E | . Figure 5 shows two example input graphs G , a top-scoring graph grammar S for each, and the result of compressing G using S (denoted by G | S ). The first example shows how the graph grammar can de-scribe the same information as a frequent subgraph. The second example demonstrates additional features of graph grammars. The graph grammar mining algorithm works it-eratively, where in each iteration the top-ranked graph gram-mar is used to compress G . The next iteration repeats the process on the newly compressed version of G with non-terminal nodes. In practice, we run the algorithm for just a few iterations (  X  3) because we focus on the top-ranked grammars when trying to identify a memory leak. For scal-ability reasons, we use sampling at several key states in the mining process. 1. Candidate generation: When we expand an evalu-2. Scoring candidates: When a new candidate graph 3. Recursive Opportunities: Similar to the sampling Because the statistical significance of our sample would be largely dependent on the prevalence and recursive nature of a candidate graph grammar, we cannot generalize our method to all cases and we choose our sample sizes empiri-cally without claiming statistical significance. However, our small sample sizes worked well in all of our experiments. We also note that once the top scored graph grammar is re-turned by the algorithm with sampling, we ensure that the recursion detection and compression of the input graph by the grammar are done exactly.
Our evaluation contains three parts. First, we check whe-ther our algorithm finds seeded structures in a set of syn-thetically created dumps. Second, we examine its efficacy on heap dumps we obtained from Java developers. Third, we report its scalability and performance with respect to the sizes of the heap graphs considered. instruction.
We obtained heap dumps from Sun X  X  Java VM (version 1.6) using either the jmap tool or via the -XX:+HeapDump-OnOutOfMemoryError option, which triggers an automatic heap dump when the JVM runs out of memory. We use the com.sun.tools.hat.* API to process the dump and extract the reachability graph. Each node in the graph corresponds to a Java object, which is labeled with its class. Each edge in the graph corresponds to a reference, labeled with the name of the field containing the reference. We label edges from arrays with $array$ , ignoring the specific index in which a reference is stored. We remove all edges that correspond to weak and soft references, because weak and soft references to an object do not prevent that object from being reclaimed if the garbage collector runs low on memory. Figure 6: Most frequent grammar mined from Hid-denLeak example in Figure 2. The $ character de-notes nested classes. For example, the node Hidden-Leak$Legitimate$Leak corresponds to Java class Hid-denLeak.Legitimate.Leak in the source code.

We first present the results for the motivating example presented in Section 2. Figure 6 shows the most frequently occurring mined grammar, which represents a (key, value) pair anchored by an instance of type HashMap.Entry . This information directs an expert X  X  attention immediately to a HashMap mapping keys of type String to values of type Hid-denLeak.Legitimate.Leak . We found that 70% of the paths from the instances produced by this grammar to GC roots in the original graph exhibit the following structure, where java.lang.Class (top) is a root node of the dominator tree, java.util.HashMap$Entry (bottom) corresponds to the top node in the best grammar displayed in Figure 6, and edge labels (in parenthesis) stem from the explicit and implicit variable names used in the source code from Figure 1:
The remaining paths contain an additional edge Entry-.next , which represents the case in which a hash collision led to chaining. This information immediately describes the lo-cation of all instances of Leak objects in the graph, alerting the developer that a large number of these structures has accumulated underneath each Legitimate object. As dis-cussed in Section 2, a size-based analysis of the dominator tree as done in Eclipse X  X  Memory Analyzer would lead only to the bucket array of the HashMap object referred to by  X  X e-gitimateMap X  and require manual inspection of the subtree emanating from it.

Since programmers often choose container types depend-ing on specific space/time trade-offs related to an expected access pattern, we then investigated if the leaking struc-ture would be found if a different container type had been used. We replaced both uses of HashMap with class TreeMap , which uses a red-black tree implementation. Our algorithm correctly identified a grammar consisting of TreeMap.Entry objects that refer to a (key, value) pair, near-identical to the grammar shown in Figure 6. In addition, the aggre-gated path was expressed by the recursive grammar shown in Figure 7, which covers over 99% of observed paths from a root to the grammar X  X  instances.

This path grammar identifies the leak as hidden in a tree of trees and provides a global picture that would be nearly impossible to obtain by visual inspection. The use of recur-sive productions enabled the algorithm to identify a classic container data structure (a binary tree) without any a priori knowledge. The use of recursive grammars is also essential for other recursive data structures, such as linked lists. The following example demonstrates that our mining approach Figure 7: Resulting root path grammar if a TreeMap container is used for the example shown in Figure 2. easily captures such data structures, even when they occur embedded in application classes (rather than in dedicated collection classes). Class OOML in Figure 8 embeds a link el-ement next and an application-specific payload field. The main method contains an infinite loop which will add el-ements to a list held in a local variable  X  X oot X  until heap memory is exhausted. Figure 8: A singly linked list embedded in an appli-cation class.

Figure 9 shows the most frequent subgraph, which con-tains a recursive production OOML  X  next OOML , rep-resenting a single linked list. The root path aggregation showed the location of its instances in the graph:
We obtained a series of heap dumps that resulted from re-curring out-of-memory situations during the development of the LibX Edition Builder, a complex J2EE web application Figure 9: Most frequent grammar in synthetic linked list example. that makes heavy use of multiple frameworks [2] including the Apache Tomcat 5.5 servlet container. These heap dumps were generated over a period of several months. When the server ran out of memory during intense testing, develop-ers would simply save a heap dump and restart the server, without further immediate investigation of the cause.
We obtained a total of 20 heapdumps, varying in sizes from 33 to 47MB. In all of these dumps, the grammar shown in Figure 10 percolated to the top. This grammar represents instances of type BeanInfoManager that reference a HashMap through their mPropertyByName field. 80% of the root paths are expressed via the following grammar:
This grammar shows that the majority of these objects are kept alive via a field named mBeanInfoManagerByClass . Since the field is associated with a node of type Class , it represents a static field. Examination of an actual path in-stance reveals that this static field belongs to class org-.apache.commons.el.BeanInfoManager .

Similar to the HiddenLeak example, the Eclipse analyzer reported the (legitimate!) HashMap.Entry array stored in the mBeanInfoManagerByClass class as accumulation point, but could not provide insights into the structure of the ob-jects kept in this table without tedious manual inspection. We eventually found that this leak had already been re-ported by another developer against the Tomcat Apache server (Bug 38048: Classloader leak caused by EL evalu-ation). Interestingly, the original bug report had received little attention, likely because the bug reporter included only a single trace to a leaked object reachable from the Bean-InfoManager class. Figure 10: Most frequent grammar in Tomcat 5.5 heap dump.

This leak was subsequently fixed in a 6.x release of Tom-cat. After updating the server, we periodically took heap dumps via the jmat tool. We subjected these heap dumps, which contain no known leaks, to our analysis. Unsurpris-ingly, the subgraph anchored by HashMap.Entry rose to the top, reflecting the ubiquitous use of hash maps. However, path aggregation showed these hash maps were located in very different regions of the object graph, thus making it less likely for them to be leaks.
In a separate project, one of the authors developed a rule-based system for the application of software engineering pat-terns to enhance code [29]. During the development of this project, out of memory situations occurred when certain in-put was fed to the rule engine, which was written using the Drools rule engine framework. In this system, rules can contain expressions written in the MVEL scripting language (mvel.codehaus.org).
 Mining the resulting heap dump showed the grammar in Figure 11, which contains a recursive production RegExMatch  X  nextAST Node RegExMatch . This mined grammar mirrors the synthetic linked list discussed in Section 4.2. All RegEx-Match objects are contained in a single list held in a local variable:
This path indicates that the cause of the memory exhaus-tion was the unbounded growth of a singly-linked list of RegExMatch objects, likely due to a bug in the MVEL parser. Although this information does not directly lead to the un-derlying bug, it rules out a number of other scenarios, such as memory exhaustion due to a large object kept alive by a long list of RegExMatch objects. Figure 11: Most frequent grammar in MVEL heap dump.
In this section, we study some quantitative aspects of our graph mining approach to illustrate its effectiveness at min-ing heap dumps. First, we study the indegree distribution of nodes from 24 real (i.e., not synthetic) heap dumps. As-sessing the % of nodes that have indegree  X  1 across these dumps, we obtain statistics of a minimum of 84%, an av-erage of 89%, and a maximum of 99.8% (from the MVEL dumps). This suggests that assessing frequent subgraphs in the dominator tree should not cause significant loss of infor-mation as compared to the original heap dump. At the same time, Table 1 illustrates the reduction gained in the number of edges and the overall size of the graph by choosing to focus on the dominator tree.

Fig. 12 illustrates the time taken for diagnosing leaks as a function of the size of the dominator. This time does not in-clude loading and pre-processing (removal of weak and soft references) and computation of the dominator. It does in-clude the time to mine the top (best) graph grammar, for graph reduction, and for summarizing root paths. The lower cluster of points are drawn from the Tomcat/J2EE dumps. These are processed faster because they do not involve re-cursive constructs and there are fewer instances of the mined grammar in the dump. We see that these are processed in Runtime (seconds) 
Figure 12: Runtime statistics on real heap dumps. about 2 X 3 minutes. Conversely, the MVEL dumps involve significant recursion and several hundreds of thousands of instances. Furthermore, the path summarization for the MVEL constructs require greater work since we must tra-verse up the linked list to observe the root path for even a single instance.

Finally, we compared the runtime of our algorithm when used on the dominator tree versus the original heap dump graph. We chose one particular dump, tomcat.sep20 from Table 1, to make the comparison. We used this dump be-cause the Tomcat leak graph grammar does not display sig-nificant recursion and this dump is one of many good rep-resentatives of the leak class. In order to compare the run-times, we excluded the path summarization step that was included in the runtime plot in Fig. 12 because this step would not be comparable between graphs. We note that the preprocessing step of removing weak and soft references will differ between graphs as well (in fact it is less complex in the dominator tree), but the resulting graphs are comparable. Further, we found that the most frequent graph grammar in the dominator tree is a subgraph of the most frequent graph grammar in the full heap dump graph, thus requir-ing more iterations of candidate generation and therefore more runtime for discovery. To enable a fair runtime com-parison, we considered the time required to generate the most frequent single-edge graph grammar from the domi-nator tree versus from the full graph. We found that the dominator tree accomplished this task in 21 seconds versus 38 seconds in the full graph. We also compared the com-plete runtime for the graph grammar in the full heap dump graph for tomcat.sep20 versus the runtime on a dominator tree from a similar heap dump, tomcat.nov05, because the discovered graph grammar from the dominator tree in tom-cat.nov05 was closer in size to that found in the full heap dump graph for tomcat.sep20 and composed of the same leak  X  but was actually larger and more frequent. We found that in the dominator tree the runtime was 130 seconds ver-sus 426 seconds in the full heap dump graph. Our results show that we obtain  X  46% runtime reduction for identify-ing small graph grammars and  X  69% runtime reduction for large graph grammars when the percentage of size reduction is only 36%. This suggests that mining the dominator tree is not only quicker due to size reduction, but also because its tree structure contains less noise and redundancy, thereby simplifying the mining process.
Our research combines ideas from software engineering and graph mining. We discuss related work in each of these areas.
One of the first systems to debug leaks exploited visual-ization, allowing a user to interactively focus on suspected problem areas in the heap [26]. Most recent existing leak de-tection tools use temporal information, including object age and staleness, that is obtained by monitoring a program as it runs. For instance, IBM X  X  Leakbot [21 X 23] acquires snap-shots at multiple times during the execution of a program, applies heuristics to identify leak candidates, and monitors how they evolve over time.

Minimizing both the space and runtime overhead of dy-namic analyses have been the subject of intense study. Space overhead is incurred because object allocation sites and last access times must be recorded; runtime overhead because this information must be continuously updated. Bell and Sleigh [3] use a novel encoding to minimize space overhead for allocation sites. To minimize the runtime cost, statisti-cal profiling approaches have been developed [13]. Cork [16] combines low-overhead statistic profiling with type-slicing. Some profilers, notably the NetBeans profiler, use informa-tion already kept by generational collectors to determine ob-ject age. Lastly, hardware support for monitoring memory access events has been proposed in [30].

By contrast, our approach explores mining information from a single heap dump, which is often the only source of information available when out-of-memory errors occur un-expectedly, which is the common case in production environ-ments in which dynamic tools are rarely deployed. Our work is complementary to dynamic approaches. Mined structural information is likely to enhance information these tools can provide, especially in the common scenario in which software engineers diagnose suspected leaks in codes with which they are not familiar. Moreover, the ability to identify data struc-tures could be exploited to automatically infer which oper-ations are add/delete operations on containers, which could benefit approaches that rely on monitoring the membership of object containers to identify leaks [33].

In the context of languages with explicit memory man-agement, several static analyses have been developed that identify where a programmer failed to deallocate memory [8, 14,25,32]. Similarly, trace-based tools such as Purify [12] or Valgrind [24] can identify unreachable objects in such envi-ronments. By comparison, the garbage collected languages at which our analysis aims do not employ explicit dealloca-tion; we aim to identify reachable objects that are unlikely to be accessed in the future. Lastly, rather than eliminat-ing the source of leaks, some systems implement mitigation strategies such as swapping objects to disk [4].
Graph mining is a well studied field that expands far in both breadth and depth. Initial works such as [18, 35] fo-cused on the problem of discovering frequent subgraphs and these algorithms have been expanded in several directions over the past decade [6, 7, 34, 36, 37]. Building upon FP-tree data structures [11], fast data structures [1] have also been developed. Similar to our work, graph mining algo-rithms have been tailored toward specific application do-mains where the structure of the desired subgrahs can be exploited in the discovery process.

Cook and Holder X  X  work [9] takes a different approach to graph mining by finding a single,  X  X est X  subgraph as op-posed to all subgraphs frequent above some threshold. This approach uses a scoring function based on the minimum de-scription length (MDL) principle and is therefore computa-tionally more complex. This work has also been expanded upon for the use of finding highly descriptive graph gram-mars [15,17] which consider the recursive nature of the sub-graphs and allow for variability in the edge and node labels.
Graph grammars are synonymous with other formal lan-guage grammars, with the difference being that the  X  X en-tences X  being generated are connected graphs. Graph gram-mars have an array of applications, but have generally been researched from a theoretical perspective for graph genera-tion [10,28] as opposed to inference problems as studied here. The benefit of graph grammars is that they can capture richer information about the connectivity of subgraphs than traditional frequent subgraphs. Although these graph gram-mars are primarily context-free and therefore lossy, they pro-vide a more descriptive representation of a subgraph than just a frequency count. Our work follows the graph gram-mar philosophy but applies it toward the characterization of dominator trees, which has not been studied before.
Data from programming projects (code, bug reports, doc-umentation, runtime snapshots, heap dumps) is now so plen-tiful that data mining approaches have been investigated toward software engineering goals (see [31] for a survey). Graph data, in particular, resurfaces in many guises such as call graphs, dependencies across subprojects, and heap dumps. Graph mining techniques have been used mini-mally for program diagnosis. For instance, program behav-ior graphs have been mined for frequent closed subgraphs that become features in a classifier to predict the existence of X  X oncrashing X  X ugs [20]. Behavior graphs were also mined with the LEAP algorithm [34] in [5] to identify discrimina-tive subgraphs signifying bug signatures. However, to the best of our knowledge, nobody has investigated the role of mining heap dumps for detecting memory leaks or used a graph grammar mining tool.
We have presented a general and expressive framework for diagnosing memory leaks using frequent grammar min-ing. Our work extends the arsenal of memory leak diagnosis tools available to software developers. For the KDD commu-nity, we have introduced the notion of dominators and how they possess sufficient statistics for mining certain types of frequent subgraphs. The experimental results are promising in their potential to debug leaks when other state-of-the-art tools cannot. We expect our algorithm to be used in complement of tools like Eclipse MAT.

Our future work revolves around three themes. First, we seek to embed our algorithm in a runtime infrastructure so that it can track leaking subgraphs as they build up over time. Second, we seek to investigate the theoretical proper-ties of dominators and whether they can support a frequent pattern growth [11] style of subgraph mining. This approach will allow us to process larger heap dumps than our current approach. Third, we plan to perform a quantitative evalua-tion comparing the quality of our reports to existing tools. Such quantitative comparisons require the definition of a metric, which could be derived by approximating the num-ber of lines of code a user would have to investigate to verify the presence or absence of a bug, as proposed in [27]. This work is supported in part by US NSF grant CCF-0937133 and the Institute for Critical Technology and Ap-plied Science (ICTAS) at Virginia Tech. Also, we would like to thank Jongsoo Park, the developer of the dominator tree algorithm used in the Boost C++ libraries, for his ready responses to our questions and comments. [1] M. Akbar and R. Angryk. Frequent pattern-growth [2] A. Bailey and G. Back. LibX X  X  Firefox extension for [3] M. Bond and K. McKinley. Bell: bit-encoding online [4] M. Bond and K. McKinley. Tolerating memory leaks. [5] H. Cheng, D. Lo, Y. Zhou, X. Wang, and X. Yan. [6] H. Cheng, X. Yan, J. Han, and P. Yu. Direct [7] C. Chent, X. Yan, F. Zhu, and J. Han. gApprox: [8] S. Cherem, L. Princehouse, and R. Rugina. Practical [9] D. Cook and L. Holder. Substructure discovery using [10] J. Engelfriet and G. Rozenberg. Graph grammars [11] J. Han, J. Pei, and Y. Yin. Mining frequent patterns [12] R. Hastings and B. Joyce. Purify: A tool for detecting [13] M. Hauswirth and T. Chilimbi. Low-overhead memory [14] D. Heine and M. Lam. A practical flow-sensitive and [15] I. Jonyer, L. Holder, and D. Cook. MDL-based [16] M. Jump and K. McKinley. Cork: dynamic memory [17] J. Kukluk, L. Holder, and D. Cook. Inference of node [18] M. Kuramochi and G. Karypis. Frequent subgraph [19] T. Lengauer and R. Tarjan. A fast algorithm for [20] C. Liu, X. Yan, H. Yu, J. Han, and P. Yu. Mining [21] N. Mitchell. The runtime structure of object [22] N. Mitchell and G. Sevitsky. LeakBot: An automated [23] N. Mitchell and G. Sevitsky. The causes of bloat, the [24] N. Nethercote and J. Seward. Valgrind: a framework [25] M. Orlovich and R. Rugina. Memory leak analysis by [26] W. De Pauw and G. Sevitsky. Visualizing reference [27] M. Renieris and S.Reiss. Fault localization with [28] G. Rozenberg. Handbook of Graph Grammars and [29] E. Tilevich and G. Back. Program, enhance thyself! [30] G. Venkataramani, B. Roemer, Y. Solihin, and [31] T. Xie, S. Thummalapenta, D. Lo, and C. Liu. Data [32] Y. Xie and A. Aiken. Context-and path-sensitive [33] G. Xu and A. Rountev. Precise memory leak detection [34] X. Yan, H. Cheng, J. Han, and P. Yu. Mining [35] X. Yan and J. Han. gSpan: graph-based substructure [36] X. Yan and J. Han. CloseGraph: mining closed [37] Z. Zeng, J. Wang, L. Zhou, and G. Karypis.

