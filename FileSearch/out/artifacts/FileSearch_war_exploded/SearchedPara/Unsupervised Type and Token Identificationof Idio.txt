 University of Toronto University of Toronto University of Toronto
Idiomatic expressions are plentiful in everyday language, yet they remain mysterious, as it is not clear exactly how people learn and understand them. They are of special interest to linguists, psycholinguists, and lexicographers, mainly because of their syntactic and semantic idiosyncrasies as well as their unclear lexical status. Despite a great deal of research on the propertiesofidiomsinthelinguisticsliterature,thereisnotmuchagreementonwhichproperties are characteristicof these expressions.Because of theirpeculiarities,idiomatic expressions have mostly been overlooked by researchers in computational linguistics. In this article, we look recognition. Specifically, we develop statistical measures that each model a specific property of idiomatic expressions by looking at their actual usage patterns in text. We use these sta-tistical measures in a type-based classification task where we automatically separate idiomatic expressions (expressions with a possible idiomatic interpretation) from similar-on-the-surface literal phrases (for which no idiomatic interpretation is possible). In addition, we use some of the measures in a token identification task where we distinguish idiomatic and literal usages of potentiallyidiomaticexpressionsincontext. 1. Introduction
Idioms form a heterogeneous class, with prototypical examples such as byandlarge , kick thebucket ,and letthe catout of thebag . It is hard to find a single agreed-upon definition that covers all members of this class (Glucksberg 1993; Cacciari 1993; Nunberg, Sag, and Wasow 1994), but they are often defined as sequences of words involving some de-gree of semantic idiosyncrasy or non-compositionality. That is, an idiom has a different meaning from the simple composition of the meaning of its component words. Idioms are widely and creatively used by speakers of a language to express ideas cleverly, eco-nomically, or implicitly, and thus appear in all languages and in all text genres (Sag et al. 2002). Many expressions acquire an idiomatic meaning over time (Cacciari 1993); conse-quently, new idioms come into existence on a daily basis (Cowie, Mackin, and McCaig 1983; Seaton and Macaulay 2002). Automatic tools are therefore necessary for assisting lexicographers in keeping lexical resources up to date, as well as for creating and ex-tending computational lexicons for use in natural language processing (NLP) systems. words with spaces (Sag et al. 2002), most idioms are syntactically well-formed phrases that allow some variability in expression, such as shoot the breeze and hold fire (Gibbs and Nayak 1989; d X  X rcais 1993; Fellbaum 2007). Such idioms allow a varying degree of morphosyntactic flexibility X  X or example, held fire and hold one X  X  fire allow for an idiomatic reading, whereas typically only a literal interpretation is available for firewas held and held fires . Clearly, a words-with-spaces approach does not work for phrasal idioms. Hence, in addition to requiring NLP tools for recognizing idiomatic expressions (types) to include in a lexicon, methods for determining the allowable and preferred usages (a.k.a. canonical forms) of such expressions are also needed. Moreover, in many situations, an NLP system will need to distinguish a usage (token) of a potentially idiomatic expression as either idiomatic or literal in order to handle a given sequence of words appropriately. For example, a machine translation system must translate heldfire differently in Thearmyheldtheirfire and Theworshippersheldthefireuptotheidol . recognized the importance of drawing on their linguistic properties, such as their se-mantic idiosyncrasy or their restricted flexibility, pointed out earlier. Some researchers have relied on a manual encoding of idiom-specific knowledge in a lexicon (Copestake et al. 2002; Odijk 2004; Villavicencio et al. 2004), whereas others have presented ap-proaches for the automatic acquisition of more general (hence less distinctive) knowl-edge from corpora (Smadja 1993; McCarthy, Keller, and Carroll 2003). Recent work that looks into the acquisition of the distinctive properties of idioms has been limited, both in scope and in the evaluation of the methods proposed (Lin 1999; Evert, Heid, and Spranger 2004). Our goal is to develop unsupervised means for the automatic acquisition of lexical, syntactic, and semantic knowledge about a broadly documented class of idiomatic expressions.
 which are commonly and productively formed from the combination of a frequent verb and a noun in its direct object position (Cowie, Mackin, and McCaig 1983; Nunberg,
Sag, and Wasow 1994; Fellbaum 2002), for example, shoot the breeze , make a face ,and push one X  X  luck . We refer to these as verb+noun idiomatic combinations or VNICs.
We present a comprehensive analysis of the distinctive linguistic properties of phrasal idioms, including VNICs (Section 2), and propose statistical measures that capture each property (Section 3). We provide a multi-faceted evaluation of the measures (Section 4), showing their effectiveness in the recognition of idiomatic expressions (types) X  X hat is, separating them from similar-on-the-surface literal phrases X  X s well as their superiority to existing state-of-the-art techniques. Drawing on these statistical measures, we also propose an unsupervised method for the automatic acquisition of an idiom X  X  canonical 62 forms (e.g., shootthebreeze as opposed to shootabreeze ), and show that it can successfully accomplish the task (Section 5).
 meanings. For example, make a face is ambiguous between an idiom, as in The little girl made a funny face at her mother , and a literal combination, as in She made a face on the snowman using a carrot and two buttons . Despite the common perception that phrases that can be idioms are mainly used in their idiomatic sense, our analysis of 60 idioms has shown otherwise. We found that close to half of these also have a clear literal meaning; and of those with a literal meaning, on average around 40% of their usages are literal. Distinguishing token phrases as idiomatic or literal combinations of words is thus essential for NLP tasks, such as semantic parsing and machine translation, which require the identification of multiword semantic units.
 tokens either assume the existence of manually annotated data for a supervised clas-sification (Patrick and Fletcher 2005; Katz and Giesbrecht 2006), or rely on manually encoded linguistic knowledge about idioms (Uchiyama, Baldwin, and Ishizaki 2005;
Hashimoto, Sato, and Utsuro 2006), or even ignore the specific properties of non-literal language and rely mainly on general purpose methods for the task (Birke and
Sarkar 2006). We propose unsupervised methods that rely on automatically acquired knowledge about idiom types to identify their token occurrences as idiomatic or literal (Section 6). More specifically, we explore the hypothesis that the type-based knowledge we automatically acquire about an idiomatic expression can be used to determine whether an instance of the expression is used literally or idiomatically (token-based knowledge). Our experimental results show that the performance of the token-based idiom identification methods proposed here is comparable to that of existing supervised techniques (Section 7). 2. Idiomaticity, Semantic Analyzability, and Flexibility
Although syntactically well-formed, phrasal idioms (including VNICs) involve a certain degree of semantic idiosyncrasy. This means that phrasal idioms are to some extent nontransparent; that is, even knowing the meaning of the individual component words, the meaning of the idiom is hard to determine without special context or previous ex-posure. There is much evidence in the linguistics literature that idiomatic combinations also have idiosyncratic lexical and syntactic behavior. Here, we first define semantic analyzability and elaborate on its relation to semantic idiosyncrasy or idiomaticity. We then expound on the lexical and syntactic behavior of VNICs, pointing out a suggestive relation between the degree of idiomaticity of a VNIC and the degree of its lexicosyn-tactic flexibility. 2.1 Semantic Analyzability
Idioms have been traditionally believed to be completely non-compositional (Fraser 1970; Katz 1973). This means that unlike compositional combinations, the meaning of an idiom cannot be solely predicted from the meaning of its parts. Nonetheless, many linguists and psycholinguists argue against such a view, providing evidence from idioms that show some degree of semantic compositionality (Nunberg, Sag, and
Wasow 1994; Gibbs 1995). The alternative view suggests that many idioms in fact do have internal semantic structure, while recognizing that they are not compositional in a simplistic or traditional sense. To explain the semantic behavior of idioms, researchers who take this alternative view thus use new terms such as semantic decomposability and/or semantic analyzability in place of compositionality.
 constituents contribute some sort of independent meaning X  X ot necessarily their literal semantics X  X o the overall idiomatic interpretation. Generally, the more semantically analyzable an idiom is, the easier it is to map the idiom constituents onto their cor-responding idiomatic referents. In other words, the more semantically analyzable an idiom is, the easier it is to make predictions about the idiomatic meaning from the meaning of the idiom parts. Semantic analyzability is thus inversely related to semantic idiosyncrasy.
 neous class, not all of them being truly non-compositional or unanalyzable (Abeill  X  e 1995; Moon 1998; Grant 2005). Rather, semantic analyzability in idioms is a matter of degree. For example, the meaning of shootthebreeze ( X  X o chat idly X ), a highly idiomatic expression, has nothing to do with either shoot or breeze . A less idiomatic expression, such as spill the beans ( X  X o reveal a secret X ), may be analyzed as spill metaphorically corresponding to  X  X eveal X  and beans referring to  X  X ecret(s). X  An idiom such as pop the question is even less idiomatic because the relations between the idiom parts and their idiomatic referents are more directly established, namely, pop corresponds to  X  X uddenly ask X  and question refers to  X  X arriage proposal. X  As we will explain in the following section, there is evidence that the difference in the degree of semantic analyzability of idiomatic expressions is also reflected in their lexical and syntactic behavior. 2.2 Lexical and Syntactic Flexibility
Most idioms are known to be lexically fixed, meaning that the substitution of a near syn-onym (or a closely related word) for a constituent part does not preserve the idiomatic meaning of the expression. For example, neither shootthewind nor hitthebreeze are valid variations of the idiom shootthebreeze . Similarly, spillthebeans has an idiomatic meaning, while spillthepeas and spreadthebeans have only literal interpretations. There are, how-ever, idiomatic expressions that have one (or more) lexical variants. For example, blow one X  X owntrumpet and tootone X  X ownhorn have the same idiomatic interpretation (Cowie,
Mackin, and McCaig 1983); also keep one X  X  cool and lose one X  X  cool have closely related meanings (Nunberg, Sag, and Wasow 1994). Nonetheless, it is not the norm for idioms to have lexical variants; when they do, there are usually unpredictable restrictions on the substitutions they allow.
 nations. Many VNICs cannot undergo syntactic variations and at the same time retain their idiomatic interpretations. It is important, however, to note that VNICs differ with respect to the extent to which they can tolerate syntactic operations, that is, the degree of syntactic flexibility they exhibit. Some are syntactically inflexible for the most part, whereas others are more versatile, as illustrated in the sentences in Examples (1) and (2): 1. (a) Sam and Azin shot the breeze. 64 2. (a) Azin spilled the beans. combinations in terms of their semantic analyzability (Fellbaum 1993; Gibbs 1993;
Glucksberg 1993; Nunberg, Sag, and Wasow 1994; Schenk 1995). The common belief is that because the constituents of a semantically analyzable idiom can be mapped onto their corresponding referents in the idiomatic interpretation, analyzable (less idiomatic) expressions are often more open to lexical substitution and syntactic variation. Psy-cholinguistic studies also support this hypothesis: Gibbs and Nayak (1989) and Gibbs et al. (1989), through a series of psychological experiments, demonstrate that there is variation in the degree of lexicosyntactic flexibility of idiomatic combinations. (Both studies narrow their focus to verb phrase idiomatic combinations, mainly of the form verb+noun.) Moreover, their findings provide evidence that the lexical and syntactic flexibility of VNICs is not arbitrary, but rather correlates with the semantic analyzability of these idioms as perceived by the speakers participating in the experiments. (2005) conclude that idioms are not as fixed as most have assumed. These claims are often based on observing certain idiomatic combinations in a form other than their so-called canonical forms. For example, Moon mentions that she has observed both kick the pail and kick the can as variations of kick the bucket . Also, Grant finds evidence of variations such as eat one X  X  heart (out) and eat one X  X  hearts (out) in the BNC. Riehemann concludes that in contrast to non-idiomatic combinations of words,  X  X dioms have a strongly preferred canonical form, but at the same time the occurrence of lexical and syntactic variations of idioms is too common to be ignored X  (page 67). Our understand-ing of such findings is that idiomatic combinations are not inherently frozen and that it is possible for them to appear in forms other than their agreed-upon canonical forms.
However, it is important to note that most such observed variations are constrained, often with unpredictable restrictions.
 condition for an idiomatic combination to be lexically or syntactically flexible. Other factors, such as communicative intentions and pragmatic constraints, can motivate a speaker to use a variant in place of a canonical form (Glucksberg 1993). For exam-ple, journalism is well known for manipulating idiomatic expressions for humor or cleverness (Grant 2005). The age and the degree of familiarity of an idiom have also been shown to be important factors that affect its flexibility (Gibbs and Nayak 1989). Nonetheless, linguists often use observations about lexical and syntactic flexibility of VNICs in order to make judgments about their degree of idiomaticity (Kyt  X  o 1999;
Tanabe 1999). We thus conclude that lexicosyntactic behavior of a VNIC, although affected by historical and pragmatic factors, can be at least partially explained in terms of semantic analyzability or idiomaticity. 3. Automatic Acquisition of Type-Based Knowledge about VNICs
We use the observed connection between idiomaticity and (in)flexibility to devise sta-tistical measures for automatically distinguishing idiomatic verb+noun combinations (types) from literal phrases. More specifically, we aim to identify verb X  X oun pairs such as keep , word as having an associated idiomatic expression ( keep one X  X  word ), and also distinguish these from verb X  X oun pairs such as keep , fish which do not have an idiomatic interpretation. Although VNICs vary in their degree of flexibility (cf.
Examples (1) and (2)), on the whole they contrast with fully compositional phrases, which are more lexically productive and appear in a wider range of syntactic forms. We thus propose to use the degree of lexical and syntactic flexibility of a given verb+noun combination to determine the level of idiomaticity of the expression.
 we do not claim that it is inherently impossible for VNICs to undergo lexical sub-stitution or syntactic variation. In fact, for each given idiomatic combination, it may well be possible to find a specific situation in which a lexical or a syntactic variant of the canonical form is perfectly plausible. However, the main point of the assumption here is that VNICs are more likely to appear in fixed forms (known as their canonical forms), more so than non-idiomatic phrases. Therefore, the overall distribution of a
VNIC in different lexical and syntactic forms is expected to be notably different from the corresponding distribution of a typical verb+noun combination.
 ity, which quantify the degree of lexical, syntactic, and overall fixedness of a given verb+noun combination (represented as a verb X  X oun pair). 3.1 Measuring Lexical Fixedness
A VNIC is lexically fixed if the replacement of any of its constituents by a semantically (and syntactically) similar word does not generally result in another VNIC, but in an invalid or a literal expression. One way of measuring lexical fixedness of a given verb+noun combination is thus to examine the idiomaticity of its variants, that is, expressions generated by replacing one of the constituents by a similar word. This approach has two main challenges: (i) it requires prior knowledge about the idiomaticity of expressions (which is what we are developing our measure to determine); (ii) it can only measure the lexical fixedness of idiomatic combinations, and so could not apply to literal combinations. We thus interpret this property statistically in the following way:
We expect a lexically fixed verb+noun combination to appear much more frequently than its variants in general.
 noun constituent of a combination (the target expression or its lexical variants) as an indirect cue to its idiomaticity, an approach inspired by Lin (1999). We use the automatically built thesaurus of Lin (1998) to find words similar to each constituent, in order to automatically generate variants. 2 Variants are generated by replacing either 66 the noun or the verb constituent of a pair with a semantically (and syntactically) similar word. 3 bean , stream , bean , spill , corn ,and spill , rice .
 of the target pair v , n ,and S sim ( n ) = n j | 1  X  j  X  nouns to the noun n (according to Lin X  X  thesaurus). The set of variants for the target pair is thus:
We calculate the association strength for the target pair and for each of its variants using an information-theoretic measure called pointwise mutual information or PMI (Church et al. 1991): is the total frequency of the target (transitive) verb with any noun as its direct object; in the corpus.
 only if its PMI value is significantly different from that of all the variants. Instead, we propose a novel technique that brings together the association strengths (PMI values) of the target and the variant expressions into a single measure reflecting the degree of lexical fixedness for the target pair. We assume that the target pair is lexically fixed to the extent that its PMI deviates from the average PMI of its variants. By our measure, the target pair is considered lexically fixed (i.e., is given a high fixedness score) only if the difference between its PMI value and that of most of its variants X  X ot necessarily all, as in the method of Lin (1999) X  X s high. 4 Our measure calculates this deviation, normalized using the sample X  X  standard deviation: where PMI is the mean and s the standard deviation of the following sample:
PMI can be negative, zero, or positive; thus Fixedness lex positive values indicate higher degrees of lexical fixedness. 3.2 Measuring Syntactic Fixedness
Compared to literal (non-idiomatic) verb+noun combinations, VNICs are expected to appear in more restricted syntactic forms. To quantify the syntactic fixedness of a target verb X  X oun pair, we thus need to: (i) identify relevant syntactic patterns, namely, those that help distinguish VNICs from literal verb+noun combinations; and (ii) translate the frequency distribution of the target pair in the identified patterns into a measure of syntactic fixedness. 3.2.1IdentifyingRelevantPatterns. Determining a unique set of syntactic patterns appro-priate for the recognition of all idiomatic combinations is difficult indeed: Exactly which forms an idiomatic combination can occur in is not entirely predictable (Sag et al. 2002).
Nonetheless, there are hypotheses about the difference in behavior of VNICs and literal verb+noun combinations with respect to particular syntactic variations (Nunberg, Sag, and Wasow 1994). Linguists note that semantic analyzability of VNICs is related to the referential status of the noun constituent (i.e., the process of idiomatization of a verb+noun combination is believed to be accompanied by a change from concreteness to abstractness for the noun). The referential status of the noun is in turn assumed to be related to the participation of the combination in certain morpho-syntactic forms.
In what follows, we describe three types of syntactic variation that are assumed to be mostly tolerated by literal combinations, but less tolerated by many VNICs.
Passivization. There is much evidence in the linguistics literature that VNICs often do not undergo passivization. Linguists mainly attribute this to the fact that in most cases, only referential nouns appear as the surface subject of a passive construction (Gibbs and Nayak 1989). Due to the non-referential status of the noun constituent in most
VNICs, we expect that they do not undergo passivization as often as literal verb+noun combinations do. Another explanation for this assumption is that passives are mainly used to put focus on the object of a clause or sentence. For most VNICs, no such communicative purpose can be served by topicalizing the noun constituent through passivization (Jackendoff 1997). The passive construction is thus considered as one of the syntactic patterns relevant to measuring syntactic flexibility.
Determiner type. A strong correlation has been observed between the flexibility of the determiner preceding the noun in a verb+noun combination and the overall flexibility of the phrase (Fellbaum 1993; Kearns 2002; Desbiens and Simon 2003). It is however 68 important to note that the nature of the determiner is also affected by other factors, such as the semantic properties of the noun. For this reason, determiner flexibility is sometimes argued not to be a good predictor of the overall syntactic flexibility of an ex-pression. Nonetheless, many researchers consider it as an important part in the process of idiomatization of a verb+noun combination (Akimoto 1999; Kyt  X  o 1999; Tanabe 1999). We thus expect a VNIC to mainly appear with one type of determiner.

Pluralization. Although the verb constituent of a VNIC is morphologically flexible, the morphological flexibility of the noun relates to its referential status (Grant 2005). Again, one should note that the use of a singular or plural noun in a VNIC may also be affected by the semantic properties of the noun. Recall that during the idiomatization process, the noun constituent may become more abstract in meaning. In this process, the noun may lose some of its nominal features, including number (Akimoto 1999). The non-referential noun constituent of a VNIC is thus expected to mainly appear in just one of the singular or plural forms.
 tic patterns that are displayed in Table 1 along with examples for each pattern. When developing this set of patterns, we have taken into account the linguistic theories about the syntactic constraints on idiomatic expressions; for example, our choice of patterns is consistent with the idiom typology developed by Nicolas (1995). Note that we merge some of the individual patterns into one; for example, we include only one passive pattern independently of the choice of the determiner or the number of the noun. The motivation here is to merge low frequency patterns (i.e., those that are expected to be less common) in order to acquire more reliable evidence on the distribution of a particular verb X  X oun pair over the resulting pattern set. In principle, however, the set can be expanded to include more patterns; it can also be modified to contain different patterns for different classes of idiomatic combinations. 3.2.2 Devising a Statistical Measure. The second step is to devise a statistical measure that quantifies the degree of syntactic fixedness of a verb X  X oun pair, with respect to the selected set of patterns, P . We propose a measure that compares the syntactic behavior of the target pair with that of a  X  X ypical X  verb X  X oun pair. Syntactic behav-ior of a typical pair is defined as the prior probability distribution over the patterns in
P . The maximum likelihood estimate for the prior probability of an individual pattern pt  X  P is calculated as where V is the set of all instances of transitive verbs in the corpus, and instances of nouns appearing as the direct object of some verb.
 probability distribution over the patterns, given the particular pair. The maximum like-lihood estimate for the posterior probability of an individual pattern pt is calculated as the divergence of its syntactic behavior (the posterior distribution over the patterns) from the typical syntactic behavior (the prior distribution). The divergence of the two probability distributions is calculated using a standard information-theoretic measure, the Kullback Leibler (KL-) divergence (Cover and Thomas 1991): KL-divergence has proven useful in many NLP applications (Resnik 1999; Dagan,
Pereira, and Lee 1994). KL-divergence is always non-negative and is zero if and only if the two distributions are exactly the same. Thus, Fixedness large values indicate higher degrees of syntactic fixedness. 3.3 A Unified Measure of Fixedness
VNICs are hypothesized to be, in most cases, both lexically and syntactically more fixed than literal verb+noun combinations (see Section 2). We thus propose a new measure 70 of idiomaticity to be a measure of the overall fixedness of a given pair. We define
Fixedness overall ( v , n ) as a weighted combination of Fixedness where  X  weights the relative contribution of the measures in predicting idiomaticity. combine them in the overall fixedness measure, we rescale them, so that they fall in higher degree of overall fixedness. 4. VNIC Type Recognition: Evaluation
To evaluate our proposed fixedness measures, we analyze their appropriateness for determining the degree of idiomaticity of a set of experimental expressions (in the form of verb X  X oun pairs, extracted as described in Section 4.1). More specifically, we first use each measure to assign scores to the experimental pairs. We then use the scores assigned by each measure to perform two different tasks, and assess the overall goodness of the measure by looking at its performance in both.
 scores to separate idiomatic verb X  X oun pairs from literal ones in a mixed list. This is done by setting a threshold, here the median score, where all pairs with scores higher than the threshold are labeled as idiomatic and the rest as literal. report accuracy ( Acc ), as well as the relative error rate reduction ( ERR ) over a random (chance) baseline, referred to as Rand. Second, we examine the retrieval performance of our fixedness measures by using the scores to rank verb X  X oun pairs according to their degree of idiomaticity. For retrieval, we present the precision X  X ecall curves, as well as the interpolated three-point average precision or IAP  X  X hat is, the average of the interpolated precisions at the recall levels of 20%, 50%, and 80%. The interpolated average precision and precision X  X ecall curves are commonly used for the evaluation of information retrieval systems (Manning and Sch  X  utze 1999), and reflect the goodness of a measure in placing the relevant items (here, idioms) before the irrelevant ones (here, literals).
 the components of an idiom are expected to appear together more often than expected by chance. Hence, some NLP systems have used collocational measures to identify them (Smadja 1993; Evert and Krenn 2001). However, as discussed in Section 2, idioms have distinctive syntactic and semantic properties that separate them from simple colloca-tions. For example, although collocations involve some degree of semantic idiosyncrasy ( strongtea vs. ? powerfultea ), compared to idioms, they typically have a more transparent meaning, and their syntactic behavior is more similar to that of literal expressions. We thus expect our fixedness measures that draw on the distinctive linguistic properties of idioms to be more appropriate than measures of collocation for the identification of idioms. To verify this hypothesis, in both the classification and retrieval tasks, we com-pare the performance of the fixedness measures with that of two collocation extraction measures: an informed baseline, PMI, and a position-based fixedness measure proposed by Smadja (1993), which we refer to as Smadja. Next, we provide more details on PMI and Smadja.
 of words or collocations. It has also been used for the recognition of idioms (Evert and
Krenn 2001), warranting its use as an informed baseline here for comparison.
Equation (1), our calculation of PMI here restricts the counts of the verb X  X oun pair to the direct object relation. Smadja (1993) proposes a collocation extraction method which measures the fixedness of a word sequence (e.g., a verb X  X oun pair) by examining the relative position of the component words across their occurrences together. We replicate
Smadja X  X  method, where we measure fixedness of a target verb X  X oun pair as the spread (variance) of the co-occurrence frequency of the verb and the noun over 10 relative positions within a five-word window. 8 ment over the non-compositionality measure of Lin (1999). For the sake of completeness, we also compare the classification performance of our Fixedness (1999) measure, which we refer to as Lin. 9 and then present a discussion of the experimental results in Section 4.2. 4.1 Experimental Setup 4.1.1 Corpus and Data Extraction. We use the British National Corpus (BNC; Burnard 2000); to extract verb X  X oun pairs, along with information on the syntactic patterns they appear in. We automatically parse the BNC using the Collins parser (Collins 1999), and augment it with information about verb and noun lemmas, automatically generated using WordNet (Fellbaum 1998). We further process the corpus using TGrep2 (Rohde 2004) in order to extract syntactic dependencies. For each instance of a transitive verb, we use heuristics to extract the noun phrase (NP) in either the direct object position (if the sentence is active), or the subject position (if the sentence is passive). We then automatically find the head noun of the extracted NP, its number (singular or plural), and the determiner introducing it. 4.1.2 Experimental Expressions. We select our development and test expressions from verb X  X oun pairs that involve a member of a predefined list of transitive verbs, referred to as basic verbs . Basic verbs, in their literal use, refer to states or acts that are central to human experience. They are thus frequent, highly polysemous, and tend to combine with other words to form idiomatic combinations (Cacciari 1993; Claridge 2000; Gentner and France 2004). An initial list of such verbs was selected from several linguistic and psycholinguistic studies on basic vocabulary (Ogden 1968; Clark 1978; Nunberg, Sag, and Wasow 1994; Goldberg 1995; Pauwels 2000; Claridge 2000; Newman and Rice 2004).
We further augmented this initial list with verbs that are semantically related to another 72 verb already in the list; for example, lose is added in analogy with find . Here is the final list of the 28 verbs in alphabetical order: of these listed basic verbs, and that appear at least 10 times in the corpus in a direct object relation (irrespective of any intervening determiners or adjectives). From these, we select a subset that are idiomatic, and another subset that are literal, as follows: A verb X  X oun pair is considered idiomatic if it appears in an idiom listed in a credible dictionary such as the Oxford Dictionary of Current Idiomatic English (ODCIE; Cowie,
Mackin, and McCaig 1983), or the Collins COBUILD Idioms Dictionary (CCID; Seaton and Macaulay 2002). 10 To decide whether a verb X  X oun pair has appeared in an idiom, we look for all idioms containing the verb and the noun in a direct-object relation, irrespective of any intervening determiners or adjectives, and/or any other arguments.
The pair is considered literal if it involves a physical act or state (i.e., the basic semantics of the verb) and does not appear in any of the mentioned dictionaries as an idiom (or part of an idiom). From the set of idiomatic pairs, we then randomly pull out 80 de-velopment pairs and 100 test pairs, ensuring that we have items of both low and high frequency. We then double the size of each data set (development and test) by adding equal numbers of literal pairs, with similar frequency distributions. Some of the idioms corresponding to the experimental idiomatic pairs are: kickthehabit , movemountains , lose face ,and keep one X  X  word . Examples of literal pairs include: move carriage , lose ticket ,and keepfish .
 in determining the values of their parameters as explained in the next subsection. Test expressions are saved as unseen data for the final evaluation. 4.1.3 Parameter Settings. Our lexical fixedness measure in Equation (2) involves two parameters, K v and K n , which determine the number of lexical variants considered in measuring the lexical fixedness of a given verb X  X oun pair. We make the least-biased assumption on the proportion of variants generated by replacing the verb ( K those generated by replacing the noun ( K n ) X  X hat is, we assume K experiments on the development data, where we set the total number of variants (i.e.,
K v + K n ) from 10 to 100 by steps of 10. (For simplicity, we refer to the total number of variants as K ). Figure 1(a) shows the change in performance of Fixedness function of K . Recall that Acc is the classification accuracy, and IAP reflects the average precision of a measure in ranking idiomatic pairs before non-idiomatic ones. According to these results, there is not much variation in the performance of the measure for
K  X  20. We thus choose an intermediate value for K that yields the highest accuracy and a reasonably high precision; specifically, we set K to 50.
 which determines the relative weights given to the individual fixedness measures in the linear combination. We experiment on the development data with different values of  X  ranging from 0 to 1 by steps of . 02; results are shown in Figure 1(b). As can be seen in the figure, the accuracy of Fixedness overall is not affected much by the change in the value of  X  . The average precision ( IAP ), however, shows that the combined measure performs best when somewhat equal weights are given to the two individual measures, and performs worst when the lexical fixedness component is completely ignored (i.e.,  X  is close to 1). These results also reinforce that a complete evaluation of our fixedness measures should include both metrics, accuracy, and average precision, as they reveal different aspects of performance. Here, for example, Fixedness rable accuracy to Fixedness lex (  X  = 0), reflecting that the two measures generally give higher scores to idioms. However, the ranking precision of the latter is much higher than that of the former, showing that Fixedness lex ranks many of the idioms at the very top of the list. In all our experiments reported here, we set  X  to . 6, a value for which
Fixedness overall shows reasonably good performance according to both Acc and IAP . 4.2 Experimental Results and Analysis
In this section, we report the results of evaluating our measures on unseen test expres-sions, with parameters set to the values determined in Section 4.1.3. (Results on devel-opment data have similar trends to those on test data.) We analyze the classification performance of the individual lexical and syntactic fixedness measures in Section 4.2.1, and discuss their effectiveness for retrieval in Section 4.2.2. Section 4.2.3 then looks into the performance of the overall fixedness measure, and Section 4.2.4 presents a summary and discussion of the results. 4.2.1 Classification Performance. Here, we look into the performance of the individual fixedness measures, Fixedness lex and Fixedness syn , in classifying a mixed set of verb X  noun pairs into idiomatic and literal classes. We compare their performance against the 74 two baselines, Rand and PMI, as well as the two state-of-the-art methods, Smadja and and 50 literal pairs, each with total frequency (across all syntactic patterns under each with total frequency of 40 or greater. Classification performances of all measures except Lin are given in Table 2. Lin does not assign scores to the test verb X  X oun pairs, hence we cannot calculate its classification accuracy the same way we do for the other methods (i.e., using median as the threshold). A separate comparison between Lin and Fixedness lex is provided at the end of this section.
 shows that many VNICs have turned into institutionalized (i.e., statistically significant) co-occurrences. Hence, one can get relatively good performance by treating verb+noun idiomatic combinations as collocations. Fixedness lex performs considerably better than performance (shown in boldface), with 42% error reduction over the random baseline, and 21 . 6% error reduction over PMI. These results demonstrate that lexical and syntactic fixedness are good indicators of idiomaticity, better than a simple measure of colloca-tion such as PMI. On TEST all , Smadja performs only slightly better than the random baseline (8% error reduction), reflecting that a position-based fixedness measure is not sufficient for identifying idiomatic combinations. These results suggest that looking into deep linguistic properties of VNICs is necessary for the appropriate treatment of these expressions. 12 frequency on the measures, we analyze their performance on the two divisions of the given in the four rightmost columns of Table 2, with the best performance shown in boldface. As expected, the performance of PMI drops substantially for low frequency items. Interestingly, although it is a PMI-based measure, Fixedness performance on all data sets. The performance of Fixedness when it is applied to high frequency items, while maintaining similar performance on the low frequency items. These results show that the lexical and syntactic fixedness measures perform reasonably well on both low and high frequency items. can be used with a higher degree of confidence, especially when applied to data that is heterogeneous with regard to frequency. This is important because, while some VNICs are very common, others have very low frequency, as noted by Grant (2005). Smadja shows a notable improvement in performance when data is divided by frequency. This effect is likely due to the fact that fixedness is measured as the spread of the position-based (raw) co-occurrence frequencies. Nonetheless, on both data sets the performance of Smadja remains substantially worse than that of our two fixedness measures (the differences are statistically significant in three out of the four comparisons at p &lt; .05). are particularly suited for identifying idiomatic combinations, especially in comparison with more general collocation extraction techniques, such as PMI or the position-based fixedness measure of Smadja (1993). Especially, our measures tend to perform well on low frequency items, perhaps due to their reliance on distinctive linguistic properties of idioms.

Fixedness lex , Lin does not assign continuous scores to the verb X  X oun pairs, but rather classifies them as idiomatic or non-idiomatic. Thus, we cannot use the same threshold (e.g., median) for the two methods to calculate their classification accuracies in a com-parable way. Recall also from Section 3.1 that the performance of both these methods depends on the value of K (the number of variants). We thus measure the classification precision of the methods at equivalent levels of recall, using the same number of variants K at each recall level for the two measures. Varying K from 2 to 100 by steps of 4, Lin and Fixedness lex achieve an average classification precision of 81 . 5% and 85 . 8%, respectively. Performing a t-test on the precisions of the two methods confirms that the difference between the two is statistically significant at p &lt; .001. In addition, our method has the advantage of assigning a score to a target verb X  X oun reflecting its degree of lexical fixedness. Such information can help a lexicographer decide whether a given verb X  X oun should be placed in a lexicon. 4.2.2 Retrieval Performance. The classification results suggest that the individual fixed-ness measures are overall better than a simple measure of collocation at separating idiomatic pairs from literal ones. Here, we have a closer look at their performance by examining their goodness in ranking verb X  X oun pairs according to their degree of idiomaticity. Recall that the fixedness measures are devised to reflect the degree of fixedness and hence the degree of idiomaticity of a target verb X  X oun pair. Thus, the result of applying each measure to a list of mixed pairs is a list that is ranked in the order 76 of idiomaticity. For a measure to be considered good at retrieval, we expect idiomatic pairs to be very frequent near the top of the ranked list, and to become less frequent towards the bottom. Precision X  X ecall curves are very indicative of this trend: The ideal measure will have a precision of 100% for all values of recall, namely, the measure places all idiomatic pairs at the very top of the ranked list. In reality, although the precision drops as recall increases, we expect a good measure to keep high precision at most levels of recall.
 minimum interpolated precision is 50% due to the equal number of idiomatic and literal pairs in the test data. In this section, we discuss the retrieval performance of the two individual fixedness measures; the next section analyzes the performance of the overall fixedness measure.
 tently higher than Smadja), showing that the distribution of idiomatic pairs in the lists ranked by these two measures is only slightly better than random. A close look at the precision X  X ecall curve of Fixedness lex reveals that, up to the recall level of 50%, the precision of this measure is substantially higher than that of PMI. This means that, compared to PMI, Fixedness lex places more idiomatic pairs at the very top of the list. At higher recall levels (50% and higher), Fixedness lex still consistently outperforms PMI.
Nonetheless, at these recall values, the two measures have relatively low precision (com-pared to the other measures), suggesting that both measures also put many idiomatic pairs near the bottom of the list. In contrast, the precision X  X ecall curve of Fixedness shows that its performance is consistently much better than that of PMI: Even at the recall level of 90%, its precision is close to 70% (cf. 55% precision of PMI). sures reveals their complementary nature. Compared to Fixedness maintains higher precision at very high levels of recall, suggesting that the syntactic fixedness measure places fewer idiomatic pairs at the bottom of the ranked list. In con-trast, Fixedness lex has notably higher precision than Fixedness 40%, suggesting that the former puts more idiomatic pairs at the top of the ranked list.
Rank test (1945), we find that both Fixedness lex and Fixedness different rankings from PMI and Smadja (p .001). Also, the rankings of the items produced by the two individual fixedness measures are found to be significantly differ-ent at p &lt; .01. 4.2.3 Performance of the Overall Fixedness Measure. We now look at the classification and retrieval performance of the overall fixedness measure. Table 3 presents % Acc , % ERR ,and% IAP of Fixedness overall , repeating that of PMI, Smadja, Fixedness
Fixedness syn , for comparison. Here again the error reductions are relative to the random baseline of 50%. Looking at classification performance (expressed in terms of % Acc and % ERR ), we can see that Fixedness overall notably outperforms all other measures, including lexical and syntactic fixedness (18 . 8% error reduction relative to Fixedness and 10% error reduction relative to Fixedness syn ). According to the classification results, each of the lexical and syntactic fixedness measures are good at separating idiomatic from literal combinations, with syntactic fixedness performing better. Here we demonstrate that combining them into a single measure of fixedness, while giving more weight to the better measure, results in a more effective classifier. behavior of this measure as a function of  X  is displayed in Figure 3.
 75 . 3% and 75 . 9%, respectively. In comparison, Fixedness of 84 . 7%, reinforcing the claim that combining evidence from both lexical and syntac-tic fixedness is beneficial. Recall from Section 4.2.2 that the two individual fixedness measures exhibit complementary behavior, as observed in their precision X  X ecall curves shown in Figure 2. The precision X  X ecall curve of the overall fixedness measure shows that this measure in fact combines advantages of the two individual measures: At most recall levels, Fixedness overall has a higher precision than both individual measures. Sta-tistical significance tests that look at the actual scores assigned by the measures confirm that the observed differences in performance are significant. The Wilcoxon Signed Rank test shows that the Fixedness overall measure produces a ranking that is significantly different from those of the individual fixedness measures, the baseline PMI, and Smadja (at p .001). 4.2.4SummaryandDiscussion. Overall, the worst performance belongs to the two collo-cation extraction methods, PMI and Smadja, both in classifying test pairs as idiomatic or 78 literal, and in ranking the pairs according to their degree of idiomaticity. This suggests that although some VNICs are institutionalized, many do not appear with markedly high frequency, and hence only looking at their frequency is not sufficient for their recognition. Moreover, a position-based fixedness measure does not seem to sufficiently capture the syntactic fixedness of VNICs in contrast to the flexibility of literal phrases.
Fixedness overall is the best performer of all, supporting the hypothesis that many VNICs are both lexically and syntactically fixed, more so than literal verb+noun combinations.
In addition, these results demonstrate that incorporating such linguistic properties into statistical measures is beneficial for the recognition of VNICs.
 still shows great sensitivity to frequency differences, performing especially poorly on items with frequency between 10 and 40. In contrast, none of the fixedness measures are as sensitive to such frequency differences. Especially interesting is the consistent performance of Fixedness lex , which is a PMI-based measure, on low and high frequency items. These observations put further emphasis on the importance of devising new methods for extracting multiword expressions with particular syntactic and semantic properties, such as VNICs.
 and bottom 20 pairs (10%) in the lists ranked by each fixedness measure. Interestingly, the list ranked by Fixedness overall contains no false positives ( fp ) in the top 20 items, and no false negatives ( fn ) in the bottom 20 items, once again reinforcing the usefulness of combining evidence from the individual lexical and syntactic fixedness measures.
False positive and false negative errors found in the top and bottom 20 ranked pairs, respectively, for the syntactic and lexical fixedness measures are given in Table 4. (Note that fp errors are the non-idiomatic pairs ranked at the top, whereas fn errors are the idiomatic pairs ranked at the bottom.) an interesting one: even though the pair is not an idiomatic expression on its own, it is part of the larger idiomatic phrase throw one X  X  hat in the ring , and hence exhibits syntactic fixedness. This shows that our methods can be easily extended to identify other types of verb phrase idiomatic combinations which exhibit syntactic behavior similar to VNICs. Looking at the frequency distribution of the occurrence of the other two fp errors, touchfinger and losehome , in the 11 patterns from Table 1, we observe that both pairs tend to appear mainly in the patterns  X  v act det: POSS n lose one X  X  home )and/or X  v act det: POSS n pl  X ( touch one X  X  fingers ). These examples show that syntactic fixedness is not a sufficient condition for idiomaticity. In other words, it is possible for non-idiomatic expressions to be syntactically fixed for reasons other than semantic idiosyncrasy. In these examples, the nouns finger and home tend to be introduced by a possessive determiner, because they often belong to someone. It is also important to note that these two patterns have a low prior (i.e., verb X  X oun pairs do not typically appear in these patterns). Hence, an expression with a strong tendency to appear in such patterns will be given a high syntactic fixedness score.
 given low scores mainly because their distributions are similar to the prior. Even though make pile preferably appears in the two patterns  X  v act det: a/an n n , X  both patterns have reasonably high prior probabilities. Moreover, because of the low frequency of make pile ( &lt; 40), the evidence is not sufficient to distinguish it from a typical verb X  X oun pair. The pair keepsecret has a high frequency, but its occurrences are scattered across all 11 patterns, closely matching the prior distribution. The latter exam-ple shows that syntactic fixedness is not a necessary condition for idiomaticity either. affect scores given by this measure. Most important is the quality of the automatically generated variants. We find that in one case, push barrow , the first 25 distributionally similar nouns (taken from the automatically built thesaurus) are proper nouns, perhaps because Barrow is a common last name. In general, it seems that the similar verbs and nouns for a target verb X  X oun pair are not necessarily related to the same sense of the target word. Another possible source of error is that in this measure we use PMI as an indirect clue to idiomaticity. In the case of giveway and keephand , many of the variants are plausible combinations with very high frequency of occurrence, for example, give opportunity , give order , find way for the former, and hold hand , put hand , keep eye for the latter. Whereas some of these high-frequency variants are literal (e.g., hold hand )or idiomatic (e.g., keepeye ), many have metaphorical interpretations (e.g., giveopportunity , findway ). In our ongoing work, we use lexical and syntactic fixedness measures, in com-bination with other linguistically motivated features, to distinguish such metaphori-cal combinations from both literal and idiomatic expressions (Fazly and Stevenson, to appear).
 evidence from the lexical and syntactic fixedness of idioms. As can be seen in Table 4, the two fixedness measures make different errors, and combining them results in a measure 80 (the overall fixedness) that makes fewer errors. In the future, we intend to also look into other properties of idioms, such as their semantic non-compositionality, as extra sources of information. 5. Determining the Canonical Forms of VNICs
Our evaluation of the fixedness measures demonstrates their usefulness for the au-tomatic recognition of VNICs. Recall from Section 2 that idioms appear in restricted syntactic forms, often referred to as their canonical forms (Glucksberg 1993; Riehemann 2001; Grant 2005). For example, the idiom pullone X  X weight mainly appears in this form (when used idiomatically). The lexical representation of an idiomatic combination thus must contain information about its canonical forms. Such information is necessary both for automatically generating appropriate forms (e.g., in a natural language generation system or a machine translation system), and for inclusion in dictionaries for learners (e.g., in the context of computational lexicography).
 number of canonical forms. For example, shootthebreeze is listed in many idiom dictio-naries as the canonical form for shoot , breeze .Also, holdfire and holdone X  X fire are listed in CCID as canonical forms for hold , fire . We expect a VNIC to occur in its canonical form(s) with substantially higher frequency than in any other syntactic patterns. We thus devise an unsupervised method that discovers the canonical form(s) of a given idiomatic verb X  X oun pair by examining its frequency of occurrence in each syntactic pattern under consideration. Specifically, the set of the canonical form(s) of the target pair v , n is defined as
Here, P is the set of patterns (see Table 1), and the condition z ( v , n , pt whether the frequency of the target pair v , n in pt k is substantially higher than its frequency in other patterns; z ( v , n , pt k ) is calculated using the statistic z-score as in
Equation (8), and T z is a predefined threshold. where f isthesamplemeanand s the sample standard deviation.
 occurrence of the target pair v , n in a particular pattern pt mean, expressed in units of the sample standard deviation. To decide whether pt canonical pattern for the target pair, we check whether its z-score, z ( v , n , pt than a threshold T z . Here, we set T z to 1, based on the distribution of z and through examining the development data.
 its predicted forms against ODCIE and CCID. Specifically, for each of the 100 idiomatic pairs in TEST all , we calculate the precision and recall of its predicted canonical forms (those whose z-scores are above T z ), compared to the canonical forms listed in the two dictionaries. The average precision across the 100 test pairs is 81 . 2%, and the average recall is 88% (with 68 of the pairs having 100% precision and 100% recall). Moreover, we find that for the overwhelming majority of the pairs, 86%, the predicted canonical form with the highest z-score appears in the dictionary entry of the pair.

TEST all have one canonical form. Our canonical form extraction method on average finds 1 . 2 canonical forms for these 100 pairs (one canonical form for 79 of them, two for 18, and three for 3 of these). Generally, our method tends to extract more canonical forms than listed in the dictionaries. This is a desired property, because idiom dictionaries often do not exhaustively list all canonical forms, but the most dominant ones. Examples of such cases include: seethesights for which our method also finds seesights as a canon-ical form, and catch one X  X  attention for which our method also finds catch the attention .
There are also cases where our method finds canonical forms for a given expression due to noise resulting from the use of the expression in a non-idiomatic sense. For example, for holdone X  X horses , our method also finds holdthehorse and holdthehorses as canonical forms. Similarly, for getthebird , our method also finds getabird .
 in the dictionaries. These are catch the/one X  X  imagination , have a/one X  X  fling , make a/one X  X  mark ,and have a/the nerve . For the first two of these, the z-score of the missed pattern is only slightly lower than our predefined threshold. In other cases (8 out of 100), none of the canonical forms extracted by our method match those in a dictionary. Some of these expressions also have a non-idiomatic sense which might be more dominant than the idiomatic usage. For example, for give the push and give the flick , our method finds give a push and give a flick , respectively, perhaps due to the common use of the latter forms as light verb constructions. For makeone X  X peace , our method finds a different form, make peace , which seems a plausible canonical form; and moreover, the canonical form listed in the dictionaries ( make one X  X  peace ) has a z-score which is only slightly lower than our threshold. There is also one case where our method finds a canonical form that corresponds to a different idiom using the same verb+noun: we find lose touch as a canonical form, whereas the dictionaries list an idiom with a different canonical form ( loseone X  X touch ) as the idiom with lose and touch .
 may need to be further analyzed by a lexicographer to filter out incorrectly found patterns. Moreover, our method extracts new canonical forms for some expressions, which could be used to augment dictionaries. 6. Automatic Identification of VNIC Tokens
In previous sections, we have provided an analysis of the lexical and syntactic behavior of idiomatic expressions. We have shown that our proposed techniques that draw on such properties can successfully distinguish an idiomatic verb+noun combination (a
VNIC type) such as getthesack from a non-idiomatic (literal) one such as getthebag .Itis important, however, to note that a potentially idiomatic expression such as get the sack can also have a literal interpretation in a given context, as in Joegotthesackfromthetop shelf . This is true of many potential idioms, although the relative proportion of literal usages may differ from one expression to another. For example, an expression such as seestars is much more likely to have a literal interpretation than getthesack (according to our findings in the BNC). Identification of idiomatic tokens in context is thus necessary for a full understanding of text, and this will be the focus of Sections 6 and 7. perform the task as one of word sense disambiguation, and draw on the local context of 82 a token to disambiguate it. Such techniques either do not use any information regarding the linguistic properties of idioms (Birke and Sarkar 2006), or mainly focus on the property of non-compositionality (Katz and Giesbrecht 2006). Studies that do make use of deep linguistic information often handcode the knowledge into the systems (Uchiyama, Baldwin, and Ishizaki 2005; Hashimoto, Sato, and Utsuro 2006). Our goal is to develop techniques that draw on the specific linguistic properties of idioms for their identification, without the need for handcoded knowledge or manually labelled train-ing data. Such unsupervised techniques can also help provide automatically labelled (noisy) training data to bootstrap (semi-)supervised methods.
 is especially relevant to their type-based recognition. We expect such properties to also be relevant for their token identification. Moreover, we have shown that it is possible to learn about the fixedness of idioms in an unsupervised manner. Here, we propose unsu-pervised techniques that draw on the syntactic fixedness of idioms to classify individual tokens of a potentially idiomatic phrase as literal or idiomatic. We also put forward a classification technique that combines such information (in the form of noisy training data) with evidence from the local context of usages of an expression. In Section 6.1, we elaborate on the underlying assumptions of our token identification techniques.
Section 6.2 then describes our proposed methods that draw on these assumptions to perform the task. 6.1 Underlying Assumptions
Although there may be fine-grained differences in meaning across the idiomatic us-ages of an expression, as well as across its literal usages, we assume that the idiomatic and literal usages correspond to two coarse-grained senses of the expression. We will refer then to each of the literal and idiomatic designations as a (coarse-grained) mean-ing of the expression, while acknowledging that each may have multiple fine-grained senses.
 syntactic configurations in which they occur. For example, pull one X  X  weight tends to mainly appear in this form when used idiomatically. Other forms of the expression, such as pull the weights , typically are only used with a literal meaning. In other words, an idiom tends to have one (or a small number of) canonical form(s), which are its most preferred syntactic patterns. 16 Here we assume that, in most cases, idiomatic usages of an expression tend to occur in its canonical form(s). We also assume that, in contrast, the literal usages of an expression are less syntactically restricted, and are expressed in a greater variety of patterns. Because of their relative unrestrictedness, literal usages may occur in a canonical form for that expression, but usages in a canonical form are more likely to be idiomatic. Usages in alternative syntactic patterns for the expression, which we refer to as the non-canonical forms of the expression, are more likely to be literal.
 mine, for each verb+noun token in context, whether it has an idiomatic or a literal interpretation. Clearly, the success of our methods depends on the extent to which these assumptions hold (we will return to these assumptions in Section 7.2.3). 6.2 Proposed Methods
This section elaborates on our proposed methods for identifying the idiomatic and literal usages of a verb+noun combination: the CF ORM method that uses knowledge of canonical forms only, and the C ONTEXT method that also incorporates distributional evidence about the local context of a token. Both methods draw on our assumptions described herein, that usages in the canonical form(s) for a potential idiom are more likely to be idiomatic, and those in other forms are more likely to be literal. Because our methods need information about canonical forms of an expression, we use the unsupervised method described in Section 5 to find these automatically. In the following discussion, we describe each method in more detail.

CF ORM . This method classifies an instance (token) of an expression as idiomatic if it occurs in one of the automatically determined canonical form(s) for that expression underlying assumption of this method is that information about the canonical form(s) of an idiom type can provide a reasonably accurate classification of its individual instances as literal or idiomatic.

C ONTEXT . Recall our assumption that the idiomatic and literal usages of an idiom corre-spond to two coarse-grained meanings of the expression. It is natural to further assume that the literal and idiomatic usages have more in common semantically within each group than between the two groups. Adopting a distributional approach to meaning X  where the meaning of an expression is approximated by the words with which it co-occurs (Firth 1957) X  X e would expect the literal and idiomatic usages of an expression to typically occur with different sets of words.
 context of an idiom usage is useful in identifying its sense. Inspired by this work, we propose an unsupervised method that incorporates distributional information about the local context of the usages of an idiom, in addition to the (syntactic) knowledge about its canonical forms, in order to determine if its token usages are literal or idiomatic.
To achieve this, the method compares the context surrounding a test instance of an expression to  X  X old-standard X  contexts for the idiomatic and literal usages of the expres-sion, which are taken from noisy training data automatically labelled using canonical forms. 17 co-occurring words to two sets of gold-standard co-occurring words: one typical of idiomatic usages and one typical of literal usages of the expression (we will shortly explain precisely how we find these). If the test token is determined to be (on aver-age) more similar to the idiomatic usages, then it is labelled as idiomatic. Other-wise, it is labelled as literal. To measure similarity between two sets of words, we use 84 a standard distributional similarity measure, Jaccard, defined subsequently. following equation A and B represent the two sets of words to be compared:
Now we explain how the C ONTEXT method finds typically co-occurring words for each of the idiomatic and literal meanings of an expression. Note that unlike in a supervised setting, here we do not assume access to manually annotated training data. We thus use knowledge of automatically acquired canonical forms to find these.
 where each test token is labelled by using the other tokens as noisy training (gold-standard) data. Specifically, to provide gold-standard data for each instance of an expression, we first divide the other instances (of the same expression) into likely-idiomatic and likely-literal groups, where the former group contains usages in canonical form(s) and the latter contains usages in non-canonical form(s). We then pick represen-tative usages from each group by selecting the K instances that are most similar to the instance being labelled (the test token) according to the Jaccard similarity score. non-canonical form(s) are indicative of the literal usages of an expression. We thus expect the co-occurrence sets of the selected canonical and non-canonical instances to reflect the idiomatic and literal meanings of the expression, respectively. We take the average similarity of the test token to the K nearest canonical instances (likely idiomatic) and the K nearest non-canonical instances (likely literal), and label the test token accord-ingly. 19 In the event that there are less than K canonical or non-canonical form usages of an expression, we take the average similarity over however many instances there are of this form. If we have no instances of one of these forms, we classify each token as idiomatic, the label we expect to be more frequent. 7. VNIC Token Identification: Evaluation
To evaluate the performance of our proposed token identification methods, we use each in a classification task, in which the method indicates for each instance of a given expression whether it has an idiomatic or a literal interpretation. Section 7.1 explains the details of our experimental setup. Section 7.2 then presents the experimental results as well as some discussion and analysis. 7.1 Experimental Setup 7.1.1 Experimental Expressions and Annotation. In our token classification experiments, we use a subset of the 180 idiomatic expressions in the development and test data sets used in the type-based experiments of Section 4. From the original 180 expressions, we discard those whose frequency in the BNC is lower than 20, to increase the likelihood that there are both literal and idiomatic usages of each expression. We also discard any expression that is not from the two dictionaries ODCIE and CCID (see Section 4.1.2 for more details on the original data sets). This process results in the selection of 60 candidate verb X  X oun pairs.
 tracted from the automatically parsed BNC, using the method described in Section 4.1.1. For a pair which occurs less than 100 times in the BNC, all of its usages were extracted.
Two judges were asked to independently label each use of each candidate expression as literal, idiomatic, or unknown. When annotating a token, the judges had access to only the sentence in which it occurred, and not the surrounding sentences. If this context was insufficient to determine the class of the expression, the judge assigned the unknown label. In an effort to assure high agreement between the judges X  annotations, the judges were also provided with the dictionary definitions of the idiomatic meanings of the expressions.
 from completely semantically transparent, or literal, to entirely opaque, or idiomatic.
The human annotators were required to pick the label, literal or idiomatic, that best fit the usage in their judgment; they were not to use the unknown label for intermediate cases. Figurative extensions of literal meanings were classified as literal if their overall meaning was judged to be fairly transparent, as in You turn right when we hittheroad attheendofthistrack (taken from the BNC). Sometimes an idiomatic usage, such as have word in At the moment they only had the word of Nicola X  X  husband for what had happened (also taken from the BNC), is somewhat directly related to its literal meaning, which is not the case for more semantically opaque idioms such as hit the roof . This sentence was classified as idiomatic because the idiomatic meaning is much more salient than the literal meaning.
 annotated each use of each candidate expression. Based on this judge X  X  annotations, we removed the 25 expressions with fewer than 5 instances of either of their literal or idi-omatic meanings, leaving 28 expressions. 20 (We will revisit the 25 removed expressions in Section 7.2.4.) The remaining expressions were then split into development ( DEV )and would be approximately equal with respect to the frequency of their expressions, as well as their proportion of idiomatic-to-literal usages (according to the primary judge X  X  annotations). At this stage, DEV and TEST contained a total of 813 and 743 tokens, respectively.
 tated DEV and TEST sentences. The observed agreement and unweighted kappa score (Cohen 1960) on TEST were 76% and 0 . 62, respectively. The judges discussed tokens on which they disagreed to achieve a consensus annotation. Final annotations were gener-ated by removing tokens that received the unknown label as the consensus annotation, leaving DEV and TEST with a total of 573 and 607 tokens, and an average of 41 and 43 to-kens per expression, respectively. Table 5 shows the DEV and the TEST verb X  X oun pairs used in our experiments. The table also contains information on the number of tokens considered for each pair, as well as the percentage of its usages which are idiomatic. 86 7.1.2 Baselines, Parameters, and Performance Measures. We compare the performance of our proposed methods, CF ORM and C ONTEXT , with the baseline of always predicting an idiomatic interpretation, the most frequent meaning in our development data. We also compare the unsupervised methods against a supervised method, S UP , which is similar to C ONTEXT , except that it forms the idiomatic and literal co-occurrence sets from manually annotated data (instead of automatically labelled data using canonical forms). Like C ONTEXT ,S UP also classifies tokens in a leave-one-out methodology using the K idiomatic and literal instances which are most similar to a test token. For both
C ONTEXT and S UP , we set the value of K (the number of similar instances used as gold-standard) to 5, since experiments on DEV indicated that performance did not vary substantially using a range of values of K .
 perform t-tests for verifying whether different methods have significantly different performance. To further analyze the performance of the methods, we also report their recall and precision on identifying usages from each of the idiomatic and literal classes. 7.2 Experimental Results and Analysis We first discuss the overall performance of our proposed unsupervised methods in
Section 7.2.1. Results reported in Section 7.2.1 are on TEST (results on DEV have similar trends, unless noted otherwise). Next, we look into the performance of our methods on expressions with different proportions of idiomatic-to-literal usages in Section 7.2.2, which presents results on TEST and DEV combined, as explained subsequently. Sec-tion 7.2.3 provides an analysis of the errors made because of using canonical forms, and identifies some possible directions for future work. In Section 7.2.4, we present results on a new data set containing expressions with highly skewed proportion of idiomatic-to-literal usages. 7.2.1 Overall Performance. Table 6 shows the macro-averaged accuracy on two unsupervised methods, as well as that of the baseline and the supervised method for comparison. The best unsupervised performance is indicated in boldface. method outperform the baseline, confirming that the canonical forms of an expression, and local context, are both informative in distinguishing literal and idiomatic instances of the expression. 21 Moreover, CF ORM outperforms C ONTEXT (difference is marginally significant at p &lt; .06), which is somewhat unexpected, as C ONTEXT was proposed as an improvement over CF ORM in that it combines contextual information along with the syntactic information provided by CF ORM . We return to these results later (Section 7.2.3) to offer some reasons as to why this might be the case. However, the results using CF ORM confirm our hypothesis that canonical forms X  X hich reflect the overall behavior of a verb+noun type X  X re strongly informative about the class of a token. Importantly, this is the case even though the canonical forms that we use are imperfect knowledge obtained automatically through an unsupervised method.
 outperforms the former, the difference is not statistically significant (p &gt; .1). A close look at the performance of these methods on the individual expressions reveals that neither consistently outperforms the other on all (or even most) expressions. Moreover, as we will see in Section 7.2.2, S UP seems to gain most of its advantage over CF ORM on expressions with a low proportion of idiomatic usages, for which canonical forms tend to have less predictive value (see Section 7.2.3 for details).
 to those of its K nearest  X  X diomatic X  and its K nearest  X  X iteral X  usages. The difference is that C ONTEXT uses noisy (automatically) labelled data to identify these nearest usages for each token, whereas S UP uses manually labelled data. One possible direction for fu-ture work is thus to investigate whether providing substantially larger amounts of data alleviates the effect of noise, as is often found to be the case by researchers in the field. 7.2.2 Performance Based on Class Distribution. Recall from Section 6 that both of our un-supervised techniques for token identification depend on how accurately the canonical forms of an expression can be acquired. The canonical form acquisition technique which we use here works well if the idiomatic meaning of an expression is sufficiently frequent compared to its literal usage. In this section, we thus examine the performance of the 88 token identification methods for expressions with different proportions of idiomatic-to-literal usages.
 sulting set of 28 expressions according to their proportion of idiomatic-to-literal usages (as determined by the human annotations) as follows. 22 Looking at the proportion of idiomatic usages of our expressions in Table 5, we can see that there are gaps between 55% and 65% in DEV , and between 58% and 82% in TEST , in terms of proportion of idiomatic usages. The value of 65% thus serves as a natural lower bound for dominant idiomatic usage, and the value of 58% as a natural upper bound for non-dominant 65 X 90% of their usages being idiomatic (i.e., their idiomatic usage is dominant), whereas
DT I low contains 11 expressions with 8 X 58% of their occurrences being idiomatic (i.e., their idiomatic usage is not dominant).
 expressions, with the best performance on each group shown in boldface. We first look both the baseline (difference is not statistically significant) and C ONTEXT (difference is statistically significant at p &lt;. 05). CF ORM also has a comparable performance to the su-pervised method, reinforcing that for these expressions accurate canonical forms can be acquired and that such knowledge can be used with high confidence for distinguishing idiomatic and literal usages in context.
 and C ONTEXT outperform the baseline, showing that even for expressions whose idi-omatic meaning is not dominant, automatically acquired canonical forms can help with their token classification. Nonetheless, both these methods perform substantially worse than the supervised method, reinforcing that the automatically acquired canonical pared to the supervised performance) is likely to be mostly due to the less predictive canonical forms extracted for these expressions. In general, we can conclude that when method is comparable to that of a supervised method. One possible way of improving the performance of unsupervised methods is thus to develop more accurate techniques for the automatic acquisition of canonical forms. classifier, especially when the number of items in the two classes (here, idiomatic and literal) differ. Instead, one can have a closer look at the performance of a classifier by examining its confusion matrix, which compares the labels predicted by the classifier method for the expression blowtrumpet is given in Table 8.
 class) is arbitrary; however, because our ultimate goal is to identify idiomatic usages, there is a natural reason for this choice. To summarize a confusion matrix, four standard measures are often used, which are calculated from the cells in the matrix. The measures are sensitivity (Sens), positive predictive value (PPV), specificity (Spec), and negative predictive value (NPV), and are calculated as in Table 9. As stated in the table, Sens and PPV are equivalents of recall and precision for the positive (idiomatic) class, also referred to as R idm and P idm later in the article. Similarly, Spec and NPV are equivalents of recall and precision for the negative (literal) class, also referred to as R supervised method. 24 (The performance measures on individual expressions are given in Tables 12, 13, and 14 in the Appendix.) Table 10 shows that, as expected, the baseline has very high Sens (100% recall on identifying idiomatic usages), but very low Spec (0% 90 recall on identifying literal usages). We thus expect a well-performing method to have lower Sens than the baseline, but higher Spec and also higher PPV and NPV (i.e., higher precision on both idiomatic and literal usages).
 high Sens and PPV, revealing that the methods are good at labeling idiomatic usages.
Performance on literal usages, however, differs across the three methods. C ONTEXT has very low Spec and NPV, showing that it tends to label most tokens X  X ncluding the literal ones X  X s idiomatic. A close look at the performance of this method on the individual expressions also confirms this tendency: on many expressions (10 out of 17) the Spec and NPV of C ONTEXT are both zero (see Table 13 in the Appendix). As we will see in
Section 7.2.3, this tendency is partly due to the distribution of the idiomatic and literal usages in canonical and non-canonical forms; because literal usages can also appear in a canonical form, for many expressions there are often not many non-canonical form instances. (Recall that, for training, C ONTEXT uses instances in canonical form as being idiomatic and those in non-canonical form as being literal.) Thus, in many cases, it is a priori more likely that a token is more similar to the K most similar canonical form instances. Interestingly, CF ORM is the method with the highest Spec and NPV, even higher than those of the supervised method. Nonetheless, even CF ORM is overall much better at identifying idiomatic tokens than literal ones (see Section 7.2.3 for more discussion on this).
 indicating that most idiomatic usages are identified correctly, but many literal usages are also misclassified as idiomatic (hence a low Spec). C ONTEXT shows the same trend as CF ORM , though overall it has poorer performance. Performance of S UP varies across the expressions in this group: S UP is very good at identifying literal usages of these expressions (high Spec and NPV for all expressions). Nonetheless, S UP has a low recall in identifying idiomatic usages (low Sens) for many of these expressions. 7.2.3DiscussionandErrorAnalysis. In this section, we examine two main issues. First, we look into the plausibility of our original assumptions regarding the predictive value of canonical forms (and non-canonical forms). Second, we investigate the appropriateness of our automatically extracted canonical forms. formance of CF ORM on the 28 expressions under study. More specifically, we look at the values of Sens, PPV, Spec, and NPV on these expressions, as shown in Table 12
The formulas in Table 9 indicate that if both Sens and PPV are high, then tp fn and tp fp . Thus, most idiomatic usages of expressions in DT I and most usages in a canonical form are idiomatic. The values of Spec and NPV on the same expressions are in general lower (compared to Sens and PPV), showing that tn is not much higher than fp or fn .

This indicates that for these expressions, most idiomatic usages appear in a canonical has generally high NPV, but mostly low Spec. These indicate that tn fn , that is, most usages in a non-canonical form are literal, and that tn is often lower than fp , that is, many literal usages also appear in a canonical form. For example, almost all usages of hitwall in a non-canonical form are literal, but most of its literal usages appear in a canonical form.
 of the syntactic form they appear in; they can appear in both canonical form(s) and in non-canonical form(s). For an expression with a low proportion of literal usages, we can thus acquire canonical forms that are both accurate and have high predictive value for identifying idiomatic usages in context. On the contrary, for expressions with a relatively high proportion of literal usages, automatically acquired canonical forms are less accurate and also have low predictive value (i.e., they are not specific to idiomatic usages). We expected that using contextual information would help in such cases. However, our C ONTEXT method relies on noisy training data automatically labelled using information about canonical forms. Given these findings, it is not sur-prising that this method performs substantially worse than a corresponding supervised method that uses similar contextual information, but manually labelled training data. It remains to be tested in the future whether providing more noisy data will help. Another possible future direction is to develop context methods that can better exploit noisy labelled data.
 not sufficiently accurate. For a verb+noun such as make pile (i.e., make a pile of money ), we correctly identify only some of the canonical forms. The automatically determined canonical forms for make pile are make a pile and make piles . However, we find that idi-omatic usages of this expression are sometimes of the form makeone X  X pile . Furthermore, we find that the frequency of this form is much higher than that of the non-canonical forms, and not substantially lower than the frequency cut-off for selection as a canonical form. This indicates that our heuristic for selecting patterns as canonical forms could be fine-tuned to yield an improvement in performance.
 mixture of literal and idiomatic usages in this form. However, many of the literal usages are verb-particle constructions using out ( pulltheplugout ), while many of the idiomatic usages occur with a prepositional phrase headed by on ( pull the plug on ). This indi-cates that incorporating information about particles and prepositions could improve the quality of the canonical forms. Other syntactic categories, such as adjectives, may also be informative in determining canonical forms for expressions which are typically used idiomatically with words of a particular syntactic category, as in blow one X  X  own trumpet . 92 7.2.4 Performance on Expressions with Skewed Distribution. Recall from Section 7.1.1 that, from the original set of 60 candidate expressions, we excluded those that had fewer than 5 instances of either of their literal or idiomatic meanings. It is nonetheless important to see how well our methods perform on such expressions. In this section, we thus report the performance of our measures on the set of 23 expressions with mostly idiomatic usages, referred to as SKEWED -IDM . Table 11 presents the macro-averaged accuracy of our methods on these expressions. This table also shows the accuracy on all unseen test expressions, that is, the combination of SKEWED -IDM and TEST , referred to as ALL ,for comparison. 25 both unsupervised methods perform worse. 26 Note that for 19 out of the 23 expressions in SKEWED -IDM , all instances are idiomatic, and the baseline accuracy is thus 100%. On these, S UP also has 100% accuracy because no literal instances are available, and thus
S UP labels every token as idiomatic (same as the baseline). As for the unsupervised (the difference is statistically significant at p &lt; .001). We saw previously that C ONTEXT tends to label usages as idiomatic. This bias might be partially responsible for the better performance of C ONTEXT on this data set. Moreover, we find that many of these expressions tend to appear in a highly frequent canonical form, but also in less frequent syntactic forms which we (perhaps incorrectly) consider as non-canonical forms. When considering the performance on all unseen test expressions ( ALL ), neither unsupervised method performs as well as the baseline, but the supervised method offers a substantial improvement over the baseline. 27 either a literal interpretation was almost impossible (as for catch one X  X  imagination ), or extremely implausible (as for kick the habit ). Hence, the annotators could predict beforehand that the expression would be mainly used with an idiomatic meaning. A semi-supervised approach that combines expert human knowledge with automatically extracted corpus-drawn information can thus be beneficial for the task of identifying idiomatic expressions in context. A human expert (e.g., a lexicographer) could first filter out expressions for which a literal interpretation is highly unlikely. For the rest of the expressions, a simple unsupervised method such as CF ORM  X  X hat relies only on automatically extracted information X  X an be used with reasonable accuracy. 8. Related Work 8.1 Type-Based Recognition of Idioms and Other Multiword Expressions
Our work relates to previous studies on determining the compositionality (the inverse of idiomaticity) of idioms and other multiword expressions (MWEs). Most previous work on the compositionality of MWEs either treats them as collocations (Smadja 1993), or examines the distributional similarity between the expression and its constituents (Baldwin et al. 2003; Bannard, Baldwin, and Lascarides 2003; McCarthy, Keller, and
Carroll 2003). Others have identified MWEs by looking into specific linguistic cues, such as the lexical fixedness of non-compositional MWEs (Lin 1999; Wermter and Hahn 2005), or the lexical flexibility of productive noun compounds (Lapata and Lascarides 2003). Venkatapathy and Joshi (2005) combine aspects of this work, by incorporating lexical fixedness, distributional similarity, and collocation-based measures into a set of features which are used to rank verb+noun combinations according to their compositionality. Our work differs from such studies in that it considers various kinds of fixedness as surface behaviors that are tightly related to the underlying semantic idiosyncrasy (idiomaticity) of expressions. Accordingly, we propose novel methods for measuring the degree of lexical, syntactic, and overall fixedness of verb+noun combinations, and use these as indirect ways of measuring degree of idiomaticity. tence of human annotations, especially for detecting which syntactic variations (e.g., passivization) an idiom can undergo (Odijk 2004; Villavicencio et al. 2004). Evert, Heid, and Spranger (2004) and Ritz and Heid (2006) propose methods for automatically determining morphosyntactic preferences of idiomatic expressions. However, they treat individual morphosyntactic markers (e.g., the number of the noun in a verb+noun combination) as independent features, and rely mainly on the relative frequency of each possible value for a feature (e.g., plural for number) as an indicator of a preference for that value. If the relative frequency of a particular value of a feature for a given combination (or the lower bound of the confidence interval, in the case of Evert, Heid, and Spranger X  X  approach) is higher than a certain threshold, then the expression is said to have a preference for that value. These studies recognize that morphosyntactic preferences can be employed as clues to the identification of idiomatic combinations; however, none proposes a systematic approach for such a task. Moreover, only subjec-tive evaluations of the proposed methods are presented.
 of idioms and other MWEs. Widdows and Dorow (2005), for example, look into the fixedness of a highly constrained type of idiom, namely, those of the form  X  X  conj X X  where X is a noun or an adjective, and conj is a conjunction such as and , or , but .Smadja (1993) also notes the importance of syntactic fixedness in identifying strongly associated multiword sequences, including collocations and idioms. Nonetheless, in both these studies, the notion of syntactic fixedness is limited to the relative position of words within the sequence. Such a general notion of fixedness does not take into account some of the important syntactic properties of idioms (e.g., the choice of the determiner), and hence cannot distinguish among different subtypes of MWEs which may differ on such 94 grounds. Our syntactic fixedness measure looks into a set of linguistically informed patterns associated with a coherent, though large, class of idiomatic expressions. Results presented in this article show that the fixedness measures can successfully separate idioms from literal phrases. Corpus analysis of the measures proves that they can also be used to distinguish idioms from other MWEs, such as light verb constructions and collocations (Fazly and Stevenson 2007; Fazly and Stevenson, to appear). Bannard (2007) proposes an extension of our syntactic fixedness measure X  X hich first appeared in
Fazly and Stevenson (2006) X  X here he uses different prior distributions for different syntactic variations.
 language. For example, Melamed (1997a) assumes that non-compositional compounds (NCCs) are usually not translated word-for-word to another language. He thus pro-poses to discover NCCs by maximizing the information-theoretic predictive value of a translation model between two languages. The sample extracted NCCs reveal an important drawback of the proposed method: It relies on a translation model only, without taking into account any prior linguistic knowledge about possible NCCs within a language. Nonetheless, such a technique is capable of identifying many NCCs that are relevant for a translation task. Villada Moir  X  on and Tiedemann (2006) propose measures for distinguishing idiomatic expressions from literal ones (in Dutch), by examining their automatically generated translations into a second language, such as English or
Spanish. Their approach is based on the assumptions that idiomatic expressions tend to have fewer predictable translations and fewer compositional meanings, compared to the literal ones. The first property is measured as the diversity in the translations for the expression, estimated using an entropy-based measure proposed by Melamed (1997b). The non-compositionality of an expression is measured as the overlap between the meaning of an expression (i.e., its translations) and those of its component words. more easily extended to different domains and languages. Our measures incorporate language-specific information about idiomatic expressions, thus extra work may be required to extend and apply them to other languages and other expressions. (Though see Van de Cruys and Villada Moir  X  on [2007] for an extension of our measures to Dutch idioms of the form verb plus prepositional phrase.) Nonetheless, because our measures capture deep linguistic information, they are also expected to acquire more detailed knowledge X  X or example, they can be used for identifying other classes of MWEs (Fazly and Stevenson 2007). 8.2 Token-Based Identification of Idioms and Other Multiword Expressions
A handful of studies have focused on identifying idiomatic and non-idiomatic usages (tokens) of words or MWEs. Birke and Sarkar (2006) propose a minimally supervised algorithm for distinguishing between literal and non-literal usages of verbs in context.
Their algorithm uses seed sets of literal and non-literal usages that are automatically extracted from online resources such as WordNet. The similarity between the context of a target token and that of each seed set determines the class of the token. The approach is general in that it uses a slightly modified version of an existing word sense disambigua-tion algorithm. This is both an advantage and a drawback: The algorithm can be easily extended to other parts of speech and other languages; however, such a general method ignores the specific properties of non-literal (metaphorical and/or idiomatic) language.
Similarly, the supervised token classification method of Katz and Giesbrecht (2006) relies primarily on the local context of a token, and fails to exploit specific linguistic properties of non-literal language. Our results suggest that such properties are often more informative than the local context, in determining the class of an MWE token. positional and non-compositional usages of English verb-particle constructions. Their classifier incorporates linguistically motivated features, such as the degree of separation between the verb and particle. Here, we focus on a different class of English MWEs, namely, the class of idiomatic verb+noun combinations. Moreover, by making a more direct use of their syntactic behavior, we develop unsupervised token classification methods that perform well. The unsupervised token classifier of Hashimoto, Sato, and
Utsuro (2006) uses manually encoded information about allowable and non-allowable syntactic transformations of Japanese idioms, which are roughly equivalent to our notions of canonical and non-canonical forms. The rule-based classifier of Uchiyama,
Baldwin, and Ishizaki (2005) incorporates syntactic information about Japanese com-pound verbs (JCVs), a type of MWE composed of two verbs. In both cases, although the classifiers incorporate syntactic information about MWEs, their manual development limits the scalability of the approaches.
 tion method for JCVs. This method is similar to ours, in that it also uses type-based knowledge to determine the class of each token in context. However, their method is supervised, whereas our methods are unsupervised. Moreover, Uchiyama, Baldwin, and Ishizaki only evaluate their methods on a set of JCVs that are mostly monosemous.
Our main focus here is on MWEs that are harder to disambiguate, that is, those that have two clear idiomatic and literal meanings, and that are frequently used with either meaning. 9. Conclusions
The significance of the role idioms play in language has long been recognized; however, due to their peculiar behavior, they have been mostly overlooked by researchers in computational linguistics. In this work, we focus on a broadly documented and cross-linguistically frequent class of idiomatic MWEs: those that involve the combination of a verb and a noun in its direct object position, which we refer to as verb+noun idiomatic combinations or VNICs. Although a great deal of research has focused on non-compositionality of MWEs, less attention has been paid to other properties relevant to their semantic idiosyncrasy, such as lexical and syntactic fixedness. Drawing on such properties, we have developed techniques for the automatic recognition of VNIC types, as well as methods for their token identification in context.
 about the lexicosyntactic behavior of idiomatic combinations. More specifically, we propose novel statistical measures that quantify the degree of lexical, syntactic, and overall fixedness of a verb+noun combination. We demonstrate that these measures can be successfully applied to the task of automatically distinguishing idiomatic ex-pressions (types) from non-idiomatic ones. Our results show that the syntactic and overall fixedness measures substantially outperform existing measures of collocation extraction, even when they incorporate some syntactic information. We put forward an unsupervised means for automatically discovering the set of syntactic variations that are preferred by a VNIC type (its canonical forms) and that should be included in its lexical representation. In addition, we show that the canonical form extraction method can effectively be used in identifying idiomatic and literal usages (tokens) of an expression in context. 96 they are a literal or idiomatic usage. We found that for 28 expressions (1, 180 tokens), approximately 40% of the usages were literal. For the remaining 23 expressions (1, 285 tokens), almost all usages were idiomatic. These figures indicate that automatically determining whether a particular instance of an expression is used idiomatically or lit-erally is of great importance for NLP applications. We have proposed two unsupervised methods that perform such a task.
 overall syntactic behavior of a VNIC type, in order to do token classification. More specifically, our methods draw on the syntactic fixedness of VNICs X  X  property which has been largely ignored in previous studies of MWE tokens. Our results confirm the usefulness of this property as incorporated into our methods. On the 23 expressions whose usages are predominantly idiomatic, because the baseline is very high none of the methods outperform it. Nonetheless, as pointed out by our human annotators, for many of these expressions it can be predicted beforehand that they are mainly idiomatic and that a literal interpretation is impossible or highly implausible. On the 28 expressions with frequent literal usages, all our methods outperform the baseline of always predicting the most dominant class (idiomatic). Moreover, on these, the accuracy of our best unsupervised method is not substantially lower than the accuracy of a standard supervised approach.
 Appendix: Performance on the Individual Expressions
This Appendi xcontains the values of the four performance measures, Sens, PPV, Spec, and NPV, for our two unsupervised methods (i.e., CF ORM and C ONTEXT ) as well as for (verb X  X oun pairs) in each data set are ordered alphabetically.
 98 Acknowledgments References 100 102
