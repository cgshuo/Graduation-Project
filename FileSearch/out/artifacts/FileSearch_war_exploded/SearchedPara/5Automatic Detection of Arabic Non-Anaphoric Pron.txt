 MUHAMMAD ABDUL-MAGEED , Indiana University The term anaphora describes backward reference to items previously occurring in a text (see e.g., Mitkov [2002]). The pointing back item is called an anaphor and the item to which it refers is called its antecedent . The identification of an anaphor X  X  an-tecedent is termed anaphora resolution and is considered one of the most difficult tasks in natural language processing (NLP) since it relies on both linguistic and word knowl-edge. Resolving an anaphor to its antecedent is crucial in many NLP applications such as text summarization, machine translation, information extraction and ques-tion answering systems. I employ the term non-referential pronouns to refer to cases of pronouns that do not introduce a new referent in discourse. In the literature, the terms pleonastic , non-anaphoric ,and expletive have been used to label these types of pronouns.

The ability to identify non-referential pronouns before attempting an anaphora res-olution task is significant since the system would not have to attempt resolving such pronouns and hence would end up with fewer errors. Given the difficulty of the task of anaphora resolution, identification of non-referential pronouns becomes even more valuable. In addition, as Boyd et al. [2005] maintain in their study of non-referential  X  X t X  in English, this task of detecting non-referential pronouns could be incorporated into a part-of-speech tagger or parser, or treated as an initial step in semantic inter-pretation. The number of non-referential pronouns is sometimes non-trivial and hence it is significant to devote enough attention to its identification. For instance, Boyd et al. find 28% of  X  X t X  in their data to be non-referential. In addition, Lappin and Leass [1994] found that 8% of all the pronouns in their corpus were non-referential and Evans [2001] reports about one third of pleonastic  X  X t X  in his corpus. In my own data, 13.86% of the pronouns considered were found to be non-referential, which shows how important these pronouns are.

In this article, I present a machine learning method for identifying non-referential pronouns in Arabic. I follow, for example, Evans [2001] in defining the task as a clas-sification problem in which a learner has to decide whether a given pronoun is refer-ential or not. I also investigate which context (i.e., left, right, or combined left and right) is more useful for the task. Another overarching goal of the article is to inves-tigate how the specific machine learning method employed here (i.e., memory-based learning) compares to previous approaches on the task of identifying non-referential pronouns. Arab grammarians use a number of terms to refer to a non-referential pronoun. These include pronoun of importance ( Dmyr Al$  X  On) (since what follows the pro-noun is supposed to be an important topic), pronoun of likeness or manner ( Dmyr AlHAl) (since a description of the manner or likeness of an object or a certain entity follows), pronoun of issue ( ( writer/speaker wants to attract attention to). The term pronoun of the unknown ( fact that this type of pronoun does not have referents in the discourse. Non-referential pronouns in Arabic occur exclusively in the singular masculine or feminine form, al-though they occur much more frequently in the masculine form. Furthermore, based on whether they practically appear in a sentence or not, there are two types of non-referential pronouns in Arabic: lexical ( (which is also sometimes called understood or hidden). Consider the following exam-ples (taken from Hasan [1995]) that illustrate non-lexical non-referential pronouns in Arabic: (1) Buckwalter: lys xalaq Almr X  nfsh English gloss: not+ create+ past+ man+ himself English: Man has not created himself (2) Buckwalter: kAna Ont xyr mn zyd English gloss: were+ you+ better+ than+ Zayd English: You were better than Zayd
In Example 1, as Hasan [1995] maintains, there is a non-referential pronoun hidden in can hardly occur following one another without this hidden pronoun in Example 2, Hasan maintains that there is an understood/hidden pronoun in Occurrences of hidden non-referential pronouns in Arabic, though, are infrequent. Lexical non-referential pronouns in Arabic, in turn, are of two categories: bound ( mutaSil) and unbound ( bic are  X -hi X , and are given in Table I in Buckwalter [Buckwalter 2002] form, along with their English translation.

It should be also noticed that whereas the form for the third person singular fem-inine  X -ha X  is the same in both the accusative and the genitive case, the form for the third person singular masculine becomes  X -hu X  in the accusative and  X -hi X  in the genitive.

Fehri [1993] indicates that unbound expletives appear as subjects of  X  X dentifica-tional X  sentences. Example 3 below illustrates unbound expletives occuring in identi-ficational sentences: (3) Buckwalter: hiYa Al$jaAEapu English gloss: it+ the+ courageousness English: Courageousness is important
Unbound expletives functioning as subjects of  X  X dentificational X  sentences also occur in the Holy Qur X  X n, as illustrated by Example 4 below: (4) Buckwalter: qul huwa { lla  X  hu OHad English gloss: say+ he+ Allah+ one English: Say: He is Allah, the One! 3 and 4, respectively. In Example 3, the English translation does not have any pro-noun since the intended meaning is to emphasize the importance of the concept (i.e., courageousness), rather than refer to it. Example 4 is verse 1 from chapter 112 (i.e., Al-Ikhlas) of the Holy Qur X  X n. Standard translations of the meanings of the Holy Qur X  X n for this verse usually include the pronoun  X  X e X , which might confuse an English-language reader who might think  X  X e X  in this case refers to  X  X llah X  and hence does not use of non-referential restricted to very high-standard varieties of Arabic (as Hasan [1995] also maintains). The use of  X  X e X  in the English translation of the verse in Example 4 above is thus unnecessary and the meaning can be communicated with a translation along the lines of  X  X ay: Verily, Allah is One! X , where the word  X  X erily X  achieves, I would claim to a considerable extent, the intended significance behind the use of the expletive pronoun in the Arabic sentence.

As for bound non-referential pronouns, these usually occur in a position preced-ing the predicate, with an encliticized nominal sentence modifier [Fehri 1993; Hasan 1995]. In Example 5 below, the pronoun  X  X n  X   X . In this specific example, (5) Buckwalter: mina Almu&amp;sifu On  X  ahu yaf$al English gloss: it is+ the+ regrettable+ that+ he+ 3person+ fail English: It is regrettable that he fails
Non-referential pronouns in Arabic also occur in riddles, proverbs, and sayings. For instance, Hechiri [1998] gives the following example of a proverb that describes a per-son who seems stupid but is in fact intelligent: (6) Buckwalter: tHsbhA HmqA X  why bAxs English gloss: 2person masc-sing+ think+ her+ stupid+ and+ it + intelligent English: You take her for a stupid, but she is intelligent
Example 6 contains the bound pronoun  X  ! hA X  and the unbound pronoun  X   X  both of which have no reference in the sentence and would have no reference in a wider context.

Similarly, these non-referential pronouns can occur in dialectal Arabic (e.g., in proverbs). The following is an example from Egyptian Arabic that describes an in-telligent person, with  X  ! hA X  and  X   X  (7) Buckwalter: yfhmhA why A TAyrh English gloss: 3person masc-sing+ understand+ her/it fem-sing+ and+ her/it fem-sing+ flying English: He is very intelligent
It is worth mentioning that among the potentially pleonastic pronouns in Arabic  X -hu X  is the most frequent. In fact, Hammami et al. [2010] report that they found no other pronouns than  X -hu X  to occur as pleonastic. This is also the case in the dataset I use here. It is thus plausible to claim that other potentially pleonastic pronouns in Arabic occur almost only in specific domains (e.g., literary or religious) in texts written by highly skilled writers. This specific claim has been also made by Hasan [1995], although he provided no empirical evidence. Most of the research on non-referential pronouns focused on English and can be classi-fied into two main categories: rule-based and machine learning-based. As for the rule-based systems, Lappin and Leass [1994] provide a number of rules (e.g., It is Modaladj that S, It is Modaladj (for NP) to VP , etc.) and two word lists, one including modal ommend, think, believe , etc.) for use with the identification of pleonastic it. However, Lappin and Leass do not report results for these heuristics. Denber [1998] offers a modification of Lappin and Leass X  X  system, including integrating temporal construc-It is cloudy ). However, Denber does not report results for these rules of identifying non-referential  X  X t X .

Paice and Husk [1987] also employ a rule-based system for detecting non-referential  X  X t X  in the technical section of the Lancaster-Oslo/Bergen (LOB) Corpus. They indi-cate that they wrote rules to match extrapositional and cleft it . Unlike Lappin and Leass [1994] and Denber [1998], they apply some constraints on the pattern matching process. For instance, for the pattern it ...that no more than 25 words and certain punctuation symbols (i.e., either zero or two or more commas or dashes) were allowed to lie between these two items. They also use certain word lists to match in between it and the right bracket. Paice and Husk report quite high results: they have an accuracy of 92%, a precision of 93%, and a recall of 97%.

In their study about Arabic anaphora resolution, Elghamry et al. [2007] introduce some rules to filter non-referential anaphors. Examples of these rules are (with PN standing for a pleonastic pronoun) tm/sytm/ytm + Verb + PN, Tm/sytm/ytm + Nega-tion + Verb + PN, tm/sytm/ytm + Verb + Preposition + PN . Observably, these rules are far from exhaustive and the authors do not report results for these heuristics. In addition, it is not clear to what extent these rules helped in the overall performance of the system.

A number of machine learning-based studies were also conducted. Evans [2001] reports a memory-based learning system that classifies it into seven types based on the type of referent, using 35 different features including, for example, positional information as to the position of the sentence in terms of word position in a sentence and sentence position in a paragraph, features describing the number of elements suggestive of the pronoun X  X  class in the surrounding text, lemmas of preceding content such as verbs and following content such as verbs or adjectives in the same sentence as the instance, the POS of a window size of eight POS (four before and four after) the instance. Evans reports 73.38% precision and 69.25% recall for binary classification of pleonastic  X  X t X , and an overall binary classification accuracy of 71.48%.
Boyd et al. [2005] use two machine-learning algorithms (i.e., a memory-based learner [MBL] and a decision tree [DT]) with 25 different features (e.g., lengths of certain syntactic structure, POS, lemmas of verbs , etc.) to identify pleonastic  X  X t X . Boyd et al. report an overall precision of 82%, a recall of 71%, and an accuracy of 88% us-ing MBL and a precision of 82%, a recall of 42%, and an accuracy of 81% using DT. Clemente et al. [2004] use support vector machines (SVM) with a feature set similar to that of Evans [2001] on biological and medical texts. More specifically, Clemente et al. use 21 of the features proposed by Evans and report an overall accuracy of 92.7%.

Weissenbacher and Nazarenko [2007] use a Bayesian classifier with linguistic knowledge similar to that proposed by Lappin and Leass [1994] and Paice and Husk [1987] to identify pleonastic  X  X t X . Weissenbacher and Nazarenko report an accuracy of 95.91%. Hammami et al. [2010] also employ a Bayesian classifier to identify the non-referential unbound pronoun  X -hu X  mains. The Bayesian network implemented by Hammami et al. include attributes that are used to compute the probability of each class. These attributes, for example, include the POS of the word immediately following the pronoun; Boolean variables that check whether certain nouns and verbs follow the pronouns; Boolean variables that check the person, number, and gender of the verb occurring with the pronoun. Hammami et al. report a precision of 93.63%, a recall of 84.87%, and an F -measure of 89.03%. I used a subsegment of Part 1 v3.0 of the Penn Arabic Treebank (PATB) [Maamouri et al. 2004] as my training and testing data. This section of the treebank is encoded in Buckwalter transliteration [Buckwalter 2002] and is an improved version that uses a level of annotation that is more accurately described as morphological analysis than as POS tagging. Two trained native speakers of Arabic independently annotated more than one half of the documents (i.e, 410 out of 734 documents) of Part 1 v 3.0 for potentially non-referential pronouns. Differences between the annotators were dis-cussed until total agreement was reached. The data includes 721 pronouns of which 100 pronouns were judged as non-referential. Thus, as mentioned earlier, the percent of non-referential pronouns in the annotated part of the PATB is 13.86. It should be noted that the annotators found all non-referential pronouns to be occurrences of  X -hu X   X  , and so in the current paper I focus on identification of non-referential occurrences of the pronoun  X -hu X  occurrences of non-referential pronouns other than  X -hu X  For classification I use a memory-based learner, the Tilburg University X  X  Memory Based Learner (TiMBL) [Daelemans et al. 2010]. Memory-based learning (MBL) is a lazy learning method that does not abstract rules from the data, but rather keeps all training data for processing. The learner uses a training set in which each instance is represented by a feature vector with its correct class label to classify new instances. Given a new instance, the classifier finds the k nearest neighbors in the training set and chooses their most frequent class for the new instance. Due to the many conflicting regularities, sub-regularities, irregularities, and exceptions that NLP exhibits, NLP tasks are difficult and abstracting rules from data to solve such tasks is not a guarantee of success. Since MBL does not abstract away from the data, that is, it always has access to the original instances, new instances that are close enough to any of the irregular, sub-regular, etc., original instances, can still be correctly classified. For this reason, MBL has been proven to have a suitable bias to NLP tasks [Daelemans et al. 1999]. In addition, MBL can successfully handle symbolic features with a high number of feature values, which allows me to incorporate lexical context into the features used. I use the IB1 algorithm as implemented in TiMBL since it has been described to usually lead to more accuracy on natural language problems [Daelemans et al. 2010]. With IB1, I use the weighted overlap metric with gain ratio as the relevance feature weighting method. In this way, each feature is assigned a weight that determines its relevance in solving the task.
 I define the identification of pleonastic pronouns as a binary classification problem. For each potentially pleonastic pronoun (henceforth the focus pronoun [ F ]), the learner needs to decide whether the pronoun is pleonastic or not. The features used are of two main types: (1) lexical positional features whose values are certain tokens if such to-kens exist in certain positions in instances, and (2) syntactic positional features whose values are certain POS if these POS exist in certain positions in instances. A third type of features that was used is (3) Boolean features. This specific type of features was employed in conjunction with the syntactic and lexical features. More specifically, with most of the lexical and syntactic features, I use a Boolean variable to check for the existence or lack thereof of the related token/POS in certain position(s) in each instance. Every time a Boolean variable is used to perform such a check, the returned value of the Boolean (i.e.,  X  X up X  if the token or POS exists and  X  X ope X  otherwise) is itself used as a feature value for a Boolean feature that is associated with the lexical or syntactic feature in question. In this way, each of the syntactic and lexical features has an associated Boolean feature. Three sets of experiments were run with: (1) left For each focus pronoun, lexical and syntactic features related to the focus pronoun it-token is used here to refer to any of the different parts a word is divided into in the PATB, part1 v3, as well as punctuation. In this specific version of the PATB, a word is tokenized into a stem, suffixes, proclitics (attaching to the beginning of a stem), and enclitics (attaching to the end of a stem). For example, the word ( alwilayat tokenized into three parts in the PATB: 1) the proclitic al and 3) the inflectional suffix At @ . Below is a summarization of the features used for each of these L, R, and W contexts. (1) Left context. I use 27 linguistically-motivated features for L. These include lexical (2) Right context. I make use of 26 features for R. The pleonastic pronoun -hu (3) Whole context. I use a concatenation of L and R as my features for W. The two Table II below shows results with 10-fold cross-validation for whole (W), left (L), and right (R) contexts. My baseline is the majority class, which is 86.13%. As the table shows, I acquire 97.22% accuracy using W. The second best accuracy is 95.98% and is achieved using L. With R only, I reach an accuracy of 95.83%. Although there is one work on the same task in Arabic (i.e., Hammami et al. 2010), it is difficult to compare the results of the current study with those acquired by Hammami et al. [2010], since the two studies are performed on two different datasets. To situate the current study within the state-of-the-art, however, I provide the results reported by Hammami et al. in Table II below. As can be seen in the table, the results I achieve considerably outper-with W). Hammami et al. did not report results for accuracy.

A consideration of the performance of the classifier with each of the three contexts shows that the pleonastic pronoun -hu features of the immediately surrounding context are very useful for detecting it. Even though I use a small window size of -5/+5 tokens, the classifier was able to detect the pleonastic pronoun with very high accuracy. The classifier performs slightly better on L than it does on R, which is an artifact of the fact that the pleonastic pronoun -hu tends to have a more limited immediate L context (i.e., m  X  1 ). The weights that TiMBL assigned to the features of L reflect this observation in that the features related to the nominal sentence modifier (i.e., Onna and Iinna very useful for the classification. The best performance is acquired by W since its features is a concatenation of L and R. Given that the classifier weights each feature X  X  contribution to knowledge of the class label, it is logical that the classifier performs best using W. The weights assigned by TiMBL to the features vary according to the context used, as follows: (1) Left context most important features. The Boolean feature checking the presence of (2) Right context most important features. The Boolean feature checking the existence (3) Whole context most important features. The features that proved most useful for
The weights assigned by TiMBL to the features of R show that it is useful to use certain trigger POS or lexical information when attempting to detect pleonastic pro-nouns in Arabic. More specifically, information about the immediately following POS and following verbs can be useful.

Again, in order to situate the current results into the wider state-of-the-art, I com-pare my results to those reported in previous research in other languages (i.e., Eng-lish). Importantly, it is to be kept in mind that comparison with research in a different language/different languages is never a straightforward one and should be done with caution. All of the studies that achieved high accuracies employed machine learning algorithms, except Paice and Husk [1987] who used a rule based (RB) approach. As the table III shows, the results I report here outperform the state-of-the art on the same task on English. As can be observed, even though Evans [2001] and Boyd et al. [2005] use the same machine-learning method I employ here, their results are out-performed by mine. Boyd et al. acquire better accuracy than Evans by adding more relevant generalized grammatical patterns. As one of the goals of the current article is to investigate how MBL would perform on the task of identifying pleonastic pronouns, I will specifically compare my approach to that of Evans since he was the first to use the same approach. Also Boyd et al. [2005] use features that are in general similar to those of Evans.

Like Evans, I use both lexical and syntactic features. But there is a number of dif-ferences between the specific decisions each of us make. First, unlike Evans, I make use of certain trigger POS and tokens. Although he decides to include lemmas of pre-ceding material (e.g., verbs) and following material in the same sentence (e.g., verbs and nouns), this is not still giving enough weight to the trigger words (e.g., weather lish as the values of the feature(s) related to this semi-closed set/these semi-closed sets are unnecessarily increased. After all, there is no reason not to include a feature for words that belong to a semi-closed set. Second, whereas I use a value of k = 1, Evans uses a value of k = 15 and does not justify this specific choice. The default k value in TiMBL is 1, and usually this value works well if the weighted overlap metric is used for assigning weight to features [Daelemans et al. 2010]. Given that Evans does not indeed specify which metric he used for his implementation, it is likely that he has used the default metric (i.e., weighted overlap). Using weighted overlap with k =15 might have hurt the performance of the classifier. In fact, Boyd et al. [2005] achieve better accuracy using a value of k = 2. Third, Evans does not explore features belong-ing to different window sizes, nor does he investigate which context (i.e., R, L, or W) is most relevant to his task. Thus, unlike Evans, I consider three different feature settings and prove that they render different results. My approach also differs from Evans X  in that even though I utilize positional features as described earlier, I do not include features related to the position of a pronoun in a sentence nor its position in a paragraph.

While the differences between my and Evans results can partly be an artifact of the behavior of non-referential pronouns in the two different languages, some of the decisions Evans have made, as explained above, may have hurt the performance of his classifier. Feature engineering and informed use of a classifier remain two very important aspects of machine-learning research. In this article, I reported experiments for identifying non-referential pronouns in an annotated sub-segment of part 1 v3 of the PATB with three different feature settings. An accuracy of 97.22% was acquired using a W context of 52 features. I also sum-marized which features were most significant for each of the three feature settings investigated. As explained, I found that W is the most useful context when modeling the behavior of these pronouns in Arabic using a memory-based classifier. It was also shown that the classifier performs slightly better on L than R with the feature set em-ployed here. Although the relatively small data set used in the current study is one of its limitations, it is believed that the research reported here is important in various ways. First, I have provided a description of the linguistic behavior of non-referential pronouns in Arabic, a topic that has remained to a considerable extent under-described research in Arabic natural language processing. Second, I have provided a description of how the behavior of the pleonastic -hu classifier. I have also showed potential reasons for the lower accuracy that was ac-quired using the same machine-learning approach on English by comparing my study to that of Evans [2001]. Third, I have showed which contexts are most useful for de-tecting pleonastic pronouns in Arabic, a finding that can be used for future research on the same topic and also inspire future research on other languages that are similar in certain aspects to Arabic (e.g., Hebrew). Fourth, the high accuracy I acquire is very promising and an MBL classifier for non-referential pronouns in Arabic can be thus integrated into a POS tagger or a parser, and also be used for filtering these pronouns in an anaphora resolution system.

Many future directions seem possible. For example, I plan to annotate more data and experiment with the same classifier to test whether the same feature sets em-ployed here will scale up or not. Another future direction would also be to test the same approach on real-world data using a tokenizer and a POS tagger. A third possi-bility is to investigate how different classifiers would perform on the same task using the same feature settings and sets I describe here.

