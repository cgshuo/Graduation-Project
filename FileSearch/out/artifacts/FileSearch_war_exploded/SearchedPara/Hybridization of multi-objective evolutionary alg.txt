 1. Introduction 1.1. Motivation
Today, electrical drives account for about 70% of the total electrical energy consumption in industry and for about 40% of used global electricity ( EMSA ). In De Keulenaer et al. (2004) it is stated that, each year, in the European Union, the amount of wasted energy that could be saved by increasing the ef fi electrical drives is around 200 TWh and for this reason, in 2009, a
European regulation was concluded forcing a gradual increase of the energy ef fi ciency of electrical drives ( European Union, 2009 ).
However, manufacturers of electrical machines need to take more than just the ef fi ciency into account to hold their own value in the global market. To be able to successfully compete, the electrical drives should be fault-tolerant and should offer easy to control operational characteristics and compact dimensions. Apart from these, the most important quality factor is the price. During the development of an electrical machine, a multi-objective optimiza-tion approach ( Chiong, 2012 ; Chiong et al., 2012 ) is required in order to address all of the above aspects and to fi nd an appropriate tradeoff between the fi nal ef fi ciency and the cost of the drive. 1.2. State-of-the-art in electrical drive design parameter sweep and calculating a maximum of several hundred designs ( Johansson et al., 1994 ). Calculating a design actually means predicting the operational behavior of the electrical drive for a concrete set of parameter settings. Because of the nonlinear behavior of the materials involved, such a prediction needs to be based on time intensive fi nite element simulations. This, combined with the need to have an acceptable duration of the overall analysis, imposed a severe limitation in the number of designs to be calculated. As such, only major design parameters could be taken into consideration and only a rather coarse parameter step size could be applied.

During the last decade, the use of response surface methodo-logy ( Hwang et al., 207 ), genetic algorithms ( Bianchi and
Bolognani, 1998 ; Jannot et al., 2011 ), particle swarm optimization ( del Valle et al., 2008 ) and other techniques ( Russenschuck, 1990 ) for the design of electrical machines and the associated electronics has become state-of-the-art. For a detailed comparisons of these modern approaches and additional reviews of the state-of-the-art in electrical drive design, the reader is kindly directed to consult ( Duan et al., 2009 ; Duan and Ionel, 2011 ; Skaar and Nilssen, 2003 ).
Although the above mentioned search methods have proved to be far more suitable for the task of multi-objective optimization than basic parameter sweeps, they are still plagued by the huge execution times incurred by the need to rely on FE simulations throughout the optimization procedure. The usage of computer clusters where multiple FE simulations can be performed in parallel can partially address this problem, but the following drawbacks still remain severe:
The FE evaluation of one particular design still takes a long time and conventional methods need to evaluate each individual design.

There are high costs associated with the usage of computer clustering architectures and various software licenses. 1.3. Our approach
In our attempt to create an ef fi cient optimization framework for electrical drive design, we are exploiting well known and widely applied genetic algorithms used for multi-objective opti-mization. These specialized algorithms are generally able to ef fi ciently handle several optimization objectives. For us, these objectives are electrical drive target parameters like ef cogging torque, total iron losses, etc. In our implementation, the goal is to minimize all the objectives. If a target needs to be maximized in the design (e.g. ef fi ciency), during the optimization, its negative value is taken to be minimized. The FE simulations required by each fi tness function evaluation are distributed over a high throughput computer cluster system. Although it is able to evolve electrical drive designs of remarkable high quality, the major drawback of this initial, and somewhat conventional, optimization approach ( ConvOpt ) is that it is quite slow as it exhibits overall optimization run-times that vary from  X  44 to  X  70 h. As a particular multi-objective genetic algorithm, we employ the well-known and widely used NSGA-II ( Deb et al., 2002 ).

One main method aimed at improving the computational time of a multi-objective evolutionary algorithm that has a very time-intensive fi tness function is to approximate the actual function through means of metamodels / surrogate models ( Santana-Quintero et al., 2010 ). These surrogate models can provide a very accurate estimation of the original fi tness function at a fraction of the computational effort required by the latter. Three very well documented overviews on surrogate based analysis and optimiza-tion can be found in Queipo et al. (2005) , Forrester et al. (2008) and Tenne and Goh (2010) .

In our case, the idea is to substitute the time-intensive functions based on FE simulations with very-fast-to-evaluate surrogates based on highly accurate regression models. The surrogate models act as direct mappings between the design parameters (inputs) and the electric drive target values which should be estimated (outputs). For us, in order to be effective in their role to reduce overall optimization run-time, the surrogate models need to be constructed on-the-fl y, automatically, during the run of the evolutionary algorithm . This is because they are quite speci fi c for each optimization scenario and each target value (i.e., optimization goal or optimization constraint) that we consider.
In other words, we would like that only individuals (i.e., electrical drive designs) from the fi rst N generations will be evaluated with the time-intensive FE-based fi tness function. These initial, FE evaluated, electrical drive designs will form a training set for constructing the surrogate models. For the remaining genera-tions, the surrogate models will substitute the FE simulations as the basis of the fi tness function. As our tests show, this yields a signi fi cant reduction in computation time.

The novelty of our research lies in the analysis of how to ef fi ciently integrate automatically created on-the-fl y-surrogate-models in order to reduce the overall optimization run-time without impacting the high quality of the electrical drive designs produced by ConvOpt.

Arti fi cial Neural Networks (ANNs) ( Haykin, 1999 ) are among the popular methods used for constructing surrogate models because they possess the universal approximation capability ( Hornik et al., 1989 ) and they offer parameterization options that allow for an adequate degree of control over the complexity of the resulting model. Another advantage of ANNs is the fact that they are known to perform well on non-linear and noisy data ( Paliwal and Kumar, 2009 ) and that they have already been successfully applied in evolutionary computation for designing surrogate models on several instances ( Jin et al., 2004 ; Hong et al., 2003 ). For the purpose of this research, the particular type of ANN we have chosen to use is the multilayered perceptron (MLP). MLP is a popular and widely used neural network paradigm that has been successfully employed to create robust and compact prediction models in many practical applications ( Gupta et al., 2007 ; Wefky et al., 2011 ). However, our choice for the MLP is fi rst and foremost motivated by the fact that, for our speci fi c modeling requirements, MLP-bases surrogate models have proved to be both relatively fast and easy to create as well as extremely accurate.

There is a wide choice of methods available for constructing surrogate models. In this paper, we describe in details how we created surrogates based on MLPs, but our hybridization schema itself is general and suitable for a multitude of modeling methods. In Section 5.1 we present results obtained with other non-linear modeling methods that can be used as alternatives for construct-ing the surrogate models. These modeling methods are, support vector regression (SVR) ( Collobert and Bengio, 2001 ), RBF net-works ( Buhmann, 2003 ) and a regression orientated adaptation of the instance based learning algorithm IBk ( Aha et al., 1991 ). In the aforementioned section, we also further motivate our current preference for MLP surrogate models.

Regardless of the modeling method used, the automatic surro-gate model construction phase involves testing different para-meter settings (e.g. different number of neurons and learning rates in the case of MLPs, different values of C and  X  in the case of SVR), yielding many models with different complexities and prediction behaviors. Given a certain target parameter we propose a new, automated model selection criterion, aimed at selecting the best surrogate to be integrated in the optimization process. The selected surrogate model should deliver the best tradeoff between smoothness, accuracy and sensitivity, i.e., the lowest possible complexity with an above-average predictive quality.

The rest of this paper is organized in the following way: Section 2 presents an overview of multi-objective optimization problems (MOOPs) in general with a special focus on the particular complex-ities associated with MOOPs encountered in the design and proto-typing of electrical drives. Section 3 contains a description of our hybrid optimization procedure ( HybridOpt )focusingonthecreation and integration of the MLP surrogate models. Section 4 provides the description of the experimental setup. Section 5 contains an evaluation of the performance of the hybrid optimization process with regards to the overall run-time of the simulations and the quality of the obtained solutions. Section 6 concludes the paper with a summary of achieved and open issues. 2. Problem statement
The design of an electrical machine usually comprises at least the optimization of geometric dimensions for a pre-selected topology. Fig. 1 gives the cross-section of an electrical drive featuring a slotted stator with concentrated coils and an interior rotor with buried permanent magnets. The geometric parameters of this assembly are depicted in the fi gure ( d si ; b st
Depending on the actual problem setting, usually, most of these parameters need to be varied in order to achieve a cheap motor with good operational behavior. Furthermore, due to the fast moving global raw material market, companies tend to investigate the quality of target parameters with regard to different materials.
Sometimes, the study of different topologies is also required during the design stage. All these lead to a relatively high number of input parameters for the optimization procedure.

Furthermore, because the behavior of the materials used to construct the electrical drive cannot be modeled linearly, the evaluation of a given design has to be done by using computa-tionally expensive FE simulations. These are solving non-linear differential equations in order to obtain the values of the target parameters associated with the actual design parameter vector.
Speci fi cally, we use the software package FEMAG TM for the calculation of 2D problems on electro-magnetics.

As our main goal is the simultaneous minimization of all the objectives (target values) involved, we are faced with a multi-objective optimization problem which can be formally de fi min  X  o 1  X  X  X  ; o 2  X  X  X  ; ... ; o k  X  X  X  X  ;  X  1
 X  where o  X  X  X  ; o 2  X  X  X  ; ... ; o k  X  X  X  X  2
 X  are the objectives (i.e., target parameters) that we consider and X T  X  X  x 1 x 2 ... x n  X  3
 X  is the design parameter vector (e.g. motor typology identi geometric dimensions, material properties, etc.).

Additionally, hard constraints like (4) can be speci fi ed in order to make sure that the drive exhibits a valid operational behavior (e.g. the torque ripple is upper bound). Such constraints are also used for invalidating designs with a very high price, c  X  x  X   X  0  X  R m  X  4  X  fi rst explain the notion of Pareto dominance ( Deb, 2001 ): dominate another solution B if A is not inferior to B with regards to any objectives and there is at least one objective for which A is better than B .
 set of Pareto-optimal solutions named the Pareto front ( Deb, 2001 ) (a set where no solution is Pareto dominated by any other solution in the set). The ideal result of the multi-objective optimization is a
Pareto front which is evenly spread and situated as close as possible to the true Pareto front of the problem (i.e., the set of all non-dominated solutions in the search space). 3. Optimization procedure 3.1. Conventional optimization using multi-objective evolutionary algorithms for improving sets (populations) of solutions, various extensions aimed at making EA populations store and ef fi ciently explore
Pareto fronts have enabled these types of algorithms to ef fi nd multiple Pareto-optimal solutions for MOOPs in one single run. Such algorithms are referred to as multi-objective evolution-ary algorithms or MOEAs in short.
 represented as a fi xed length real parameter vector that is actually an instance of the design parameter vector described in (3) .
Computing the fi tness of every such individual means computing the objective functions from (2) and, at fi rst, this can only be achieved by running FE simulations.
 ( Deb et al., 2002 ) proposed by Deb in 2002 is, alongside with the Strength Pareto Evolutionary Algorithm 2 (SPEA2) ( Zitzler et al., 2002 ), one of the most successful and widely applied MOEA algorithms in literature. A brief description of NSGA-II is presented in Appendix A . On a close review, it is easy to observe that both mentioned MOEAs are based on the same two major design principles: (1) an elitist approach to evolution implemented using a second-ary (archiving) population; (2) a two-tier selection for survival function that uses a primary
Pareto non-dominance metric and a secondary density esti-mation metric;
In light of the above, it is not surprising that the respective performance of these two algorithms is also quite similar ( Zitzler et al., 2002 ; Khare et al., 2003 ) with minor advantages towards either of the two methods depending on the particularities of the concrete MOOP problem to be solved ( Raisanen and Whitaker, 2005 ; Anauth and Ah King, 2010 ). Taking into account the similarity of the two MOEAs and the very long execution time required by a single optimization run, we mention that all the tests reported on over the course of this research have been carried out using NSGA-II. Our choice for this method is also motivated by a few initial comparative runs in which the inherent ability of NSGA-
II to amplify the search around the extreme Pareto front points enabled it to fi nd a higher number of very interesting solutions than SPEA2 for two of our optimization scenarios. 3.2. Hybrid optimization using a fi tness function based on surrogate models 3.2.1. Basic idea
Our main approach to further improve the run time of the our optimization process is centered on substituting the original FE-based fi tness function of the MOEAs with a fi tness function based on surrogate models. The main challenge lies in the fact that these surrogate models, which must be highly accurate, are scenario dependent and as such, for any previously unknown optimization scenario, they need to be constructed on-the-fl y (i.e., during the run of the MOEA). A sketch of the surrogate-based enhanced optimization process (HybridOpt) outlining the several new stages it contains in order to incorporate surrogate-based fi tness evalua-tion is presented in Fig. 2 .

In the FE-based MOEA execution stage the fi rst N generations of each MOEA run are computed using FE simulations and all the individuals evaluated at this stage will form the training set used to construct the surrogate models. Each sample in this training set contains the initial electrical motor design parameter values (3) and the corresponding objective function values (2) computed using FEMAG TM . Please refer to Section 5.2 for a description of the methodology we used in order to determine a good value of N .
In the surrogate model construction stage , we use systematic parameter variation and a selection process that takes into con-sideration both accuracy and architectural simplicity to fi train the most robust surrogate design for each of the considered target variables.

The next step is to switch the MOEA to a surrogate-based fi function for the remaining generations that we wish to compute ( surrogate-based MOEA execution stage ). The surrogate-based function is extremely fast when compared to its FE-based counter-part, and it enables the prediction of target values based on input variables within milliseconds. Apart from improving the total run time of the MOEA simulation, we can also take advantage of this massive improvement in speed in two other ways: (1) by increasing the total number of generations the MOEA will (2) by increasing the sizes of the populations with which the Both options are extremely important as they generally enable MOEAs to evolve Pareto fronts that are larger in size and exhibit a better spread.

In the surrogate-based Pareto front computation stage apre-liminary surrogate-based Pareto front is extracted only from the combined set of individuals evaluated using the surrogate models. This secondary Pareto front is constructed independently, i.e., without taking into consideration the quality of the FE-evaluated approach makes the surrogate-based front less prone to instabilities induced by inherent prediction errors and by the relative differences between the qualities of the surrogate models.

We mention that, in the current stage of development, at the end of the MOEA run (the FE-based reevaluation stage ), it is desired that all the Pareto-optimal solutions found using the surrogate models are re-evaluated using FE calculations. There are two main reasons for which we do this. The fi rst one is a consequence of the fact that in our optimization framework, the check for geometry errors is tightly coupled with the FE evaluation stage and as such some of the Pareto optimal solutions found using the surrogate models might actually be geometrically invalid. The second reason for the re-evaluation is to assure that all the simulation solutions presented as Pareto optimal have the same approximation error (i.e., the internal estimation error of the FEMAG TM software).
In the fi nal Pareto front computation stage , the fi nal Pareto front of the simulation is extracted from the combined set of all the individuals evaluated using FE simulations, i.e., individuals from the initial N generations and FE-reevaluated surrogate-based individuals.

It is important to note that our enhanced optimization process basically rede fi nes the role of the FE simulations. These very accurate but extremely time intensive operations are now used at the beginning of the MOEA driven optimization process, when, generally, the quality-improvement over computation time ratio is the highest. FE simulations are also used in the fi nal stage of the optimization process for analyzing only the most promising individuals found using the surrogate models. In the middle and in the last part of the optimization run, when quality improve-ments would come at a much higher computational cost, a surrogate-based fi tness function is used to steer the evolutionary algorithm.

In the results section, we will show that, using the surrogate enhancement, Pareto fronts with similar quality to the ones produced by ConvOpt can be obtained while signi fi cantly reducing the overall simulation time. 3.2.2. The structure and training of ANN surrogate models
Generally, the MLP architecture ( Fig. 3 ) consists of one layer of input units (nodes), one layer of output units and one or more intermediate (hidden) layers. MLPs implement the feed-forward information fl ow which directs data from the units in the input layer through the units in the hidden layer to the unit(s) in the output layer. Any connection between two units u i and u j associated weight w ij that represents the strength of that respec-tive connection. A concrete MLP prediction model is de fi speci fi c architecture and by the values of the weights between its units.
 connect to node u i , i.e., all the units u j for which w
Similarly, the set Succ ( u i ) contains all the units u k u i connects to, i.e., for which w ik exists.
 based on a given set of inputs. Depending on how this output is computed, one may distinguish between two types of units in a
MLP: (1) Input units  X  all the units in the input layer. The role of these (2) Sigmoid units  X  all the units in the hidden and output layers. i.e., for every sigmoid unit u i , Pred u i exclusively contains all the units in the previous layer of the network. In the input layer, we use as many units as design variables in the data sample. Also, as we construct a different surrogate model for each target variable in the data sample, the output layer contains just one unit and, at the end of the feed-forward propagation, the output of this unit is the predicted regression value of the elicited target (e.g. P ( o the MLP presented in Fig. 3 ).
 values and then are subsequently adjusted during a training process. In this training process we use a training set T and every instance (data sample) s design parameters (i.e., X T ) as well as the FE-computed value of the elicited target variable (e.g. s y FE is the FE estimated value of o from (2) when o 2 ( X ) is the target for which we wish to construct a
MLP surrogate model): !  X  X  evaluated by passing every instance from the training set through the network and then computing a cumulative error metric (i.e., the batch learning approach). When considering the MLP archi-tecture presented in Fig. 3 and the squared-error loss function, the cumulative error metric over training set T is
E  X  w to minimize this error metric. The standard approach in the of ANNs for solving this task is the backpropagation algorithm ( Werbos, 1974 ) which is in essence a gradient-based iterative method that shows how to gradually adjust the weights in order to reduce the training error of the MLP.
 using (8) . Afterwards, each weight w ij t in the MLP will be updated according to the following formulas:
 X  w t ij  X   X  X   X  u j  X  P  X  u i  X  where  X   X   X  0 ; 1 is a constant called the learning rate .By mark the control parameter of the empirical enhancement known as momentum , which can help the gradient method to converge faster and to avoid some local minima. The function  X   X  u the cumulated impact that the weighted inputs coming into node u have on E t  X  w  X   X  u
 X  X  P  X  u j  X  X  1  X  P  X  u j  X  X  X  y  X  P  X  u j  X  X  X  10  X  if u is the output unit and as  X   X  u
 X  X  P  X  u j  X  X  1  X  P  X  u j  X  X   X  if u is a hidden unit. The standard backpropagation method proposes several stopping criteria: the number of iterations exceeds a certain limit, E t  X  w  X  , the overall computation time exceeds a certain pre-de fi threshold. We have chosen to adopt an early stopping mechanism that terminates the execution whenever the prediction error computed over a validation subset V does not improve over 200 consecutive iterations. This validation subset is constructed at the beginning of the training process by randomly sampling 20% of the instances from the training set T . This stopping criterion may have a bene fi t in helping to prevent the over fi tting of MLP surrogate models. 3.2.3. The evaluation and automatic model selection of ann surrogate models
Usually, in MLP-based data modeling tasks the most important design decision concerns the network architecture: how many hidden layers to use and how many units to place in each hidden layer. In order to construct a highly accurate model, based on the previous architecture choice, one should also experiment with several values for the learning rate and momentum constants. In practice, this problem is most often solved by experimentation usually combined with some sort of expert knowledge.

It has been shown that MLPs with two hidden layers can approximate any arbitrary function with arbitrary accuracy ( Churchland and Sejnowski, 1992 ) and that any bounded contin-uous function can be approximated by a MLP with a single hidden layer and a fi nite number of hidden sigmoid units ( Cybenko, 1989 ).
The optimization scenarios used in this research (see Section 4.1 ) do not require the use of two hidden layers. Like with many other interpolation methods, the quality of the MLP approximation is dependent on the number of training samples that are available and on how well they cover the input space. In our application, we have the fl exibility to select the number of samples used for training the surrogate model according to the complexity of the learning problem (i.e., number of design parameters and their associated range values) and this aspect is detailed in Section 5.2 .
In order to automatically determine the number of hidden units, the learning rate  X   X   X  and the momentum  X   X   X  needed to construct the most robust MLP surrogate model, we conduct a best parameter grid search, iterating over different parameter value combinations (see Section 4.2 for exact settings).

Our model selection strategy is aimed at fi nding the most accurate and robust surrogate model where, by robust, we under-stand a model that displays a rather low complexity and a stable predictive behavior . Our tests have shown that these two qualities are very important when striving to construct surrogate models that enable the MOEAs to successfully explore the entire search space .

The surrogate model selection process ( Fig. 4 ) is divided in two stages. In the fi rst stage, all the surrogates are ranked according to a metric that takes into account the accuracy of their predictions.
Next, an accuracy threshold is computed as the mean of the accuracies of the best performing 2% of all surrogate models. The choice of the fi nal surrogate model is made using a complexity metric that favors the least complex model that has a prediction accuracy higher than the accuracy threshold. The general idea is similar to that of a model selection strategy used for regression trees ( Breiman et al., 1993 ) with the noticeable difference that we compute the accuracy threshold using a broader model basis in order to increase stability (i.e., avoid the cases where the accuracy threshold is solely set according to a highly complex, and possibly over fi t, model that is only marginally more accurate than several much simpler ones).

The metric used to evaluate the prediction accuracy of a surrogate model q m , is based on the coef fi cient of determination ( R ). In order to evaluate the accuracy of a MLP surrogate model we use a 10-fold cross-validation data partitioning strategy ( Hastie et al., 2009 ) and we compute the value of R 2 over each of the ten folds. The fi nal accuracy assigned to the surrogate model is the mean value of R 2 minus the standard deviation of R 2 over the folds: q  X   X   X  R 2  X   X  s  X  R 2  X  X  12  X  Using the standard deviation of R 2 over the cross-validation folds as a penalty in (12) has the role of favoring models that exhibit a more stable predictive behavior. The reason for this is that a signi fi cant value of s  X  R 2  X  indicates that the surrogate model is biased toward speci fi c regions of the search space. The existence of locally biased surrogate models is quite probable because our training data is rather unbalanced as it is the byproduct of a highly elitist evolutionary process that disregards un fi t individuals.
The second metric used in the surrogate model selection process favors choosing less complex models. One MLP surrogate model is considered to be more complex than another if the former has more units in the hidden layer (ties are broken in favor of the model that required more computation time to train).
It is worth mentioning that this automatic surrogate model selection strategy can easily be adapted when opting for another surrogate modeling method. In this case, one only needs to choose a different indicator (or set of indicators) for measuring complex-ity (e.g. the C parameter and/or the number of required support vectors in the case of a SVR).
 Algorithm 1. Description of the hybrid optimization process. 1: procedure HybridOpt ( Scenario , PopSize ini , PopSize 3: E  X  FE-E VALUATOR ( Scenario ) 4:  X  P ; Valid FE  X   X  NSGA  X  II  X  Search  X  N ; PopSize ini 6: for all target  X  Scenario do 7: Map  X   X  8: for all c  X  Configurations do 10: end for 11: BestSurrogateModels  X  target  X   X  S ELECT B EST S URROGATE 12: end for 13: E  X  S URROGATE E VALUATOR  X  Scenario ; BestSurrogateModels 14:  X  P ; Valid MLP  X   X  NSGA-II-Search  X  M  X  N ; PopSize ext 16: E  X  FE-E VALUATOR ( Scenario ) 18: return E XTRACT P ARETO F RONT  X  Valid FE  X  OptimalSet 19: end procedure 20: function NSGA-II-Search 21: t  X  1 22: ValidIndividuals  X   X  23: P  X  t  X   X  InitialPopulation 24: P  X  t  X   X  E VALUATE F ITNESS  X  P  X  t  X  ; FitnessEvaluator 25: While t  X  NrGen do 26: O  X  t  X   X  C REATE O FFSPRING  X  P  X  t  X  ; PopSize  X  27: O  X  t  X   X  E VALUATE F ITNESS  X  O  X  t  X  ; FitnessEvaluator 28: ValidIndividuals  X  ValidIndividuals  X  O  X  t  X  30: t  X  t  X  1 31: end while 32: return  X  P  X  t  X  ; ValidIndividuals  X  33: end function 3.2.4. Algorithmic description of HybridOpt Our hybrid optimization procedure is presented in Algorithm 1 .
Apart from method calls and the normal assignment operator , we also use the operator  X  in order to mark the dynamic binding of a given object to a speci fi c method with the implied meaning that all future references to the object are redirected to the correspond-ing targeted method.
 The main procedure, named H YBRID O PT ,has fi ve input parameters:
Scenario  X  the description of the scenario to be optimized with information regarding design parameters and targets.

PopSize ini  X  the size of the NSGA-II population for the FE-based part of the run.

PopSize ext  X  the size of the NSGA-II population for the surrogate-based part of the run.

N  X  the number of generations to be computed in the FE-based part of the run.

M  X  the total number of generations to be computed during the optimization (i.e., M  X  N generations will be computed in the surrogate-based part).

The NSGA-II implementation contained in the NSGA-II-S EARCH function differs from standard implementations as it returns two results, the Pareto optimal set obtained after constructing the last generation and a set containing all the valid individuals generated during the search. This function has four input parameters: NrGen  X  the number of generations to be computed.
 PopSize  X  the size of the population.

InitialPopulation  X  a set containing the starting population of the evolutionary search.

It receives as input a set of unevaluated individuals and an object that is bound to a speci fi c fi tness evaluation function. E NESS returns a fi ltered set containing only the valid individuals.
Each individual in the returned set also stores information regarding its fi tness over the multiple objectives  X  note that the fi tness is directly associated with the values of the target para-meters, which are either predicted by the surrogate model or calculated using differential equations in the FE simulation. If the concrete fi tness function used is FE-E VALUATOR , individuals are checked for validity with regards to both geometrical (meshing) errors and constraint satisfaction (4) . Geometrical errors may arise because of speci fi c combinations of design parameter values.
When using the S URROGATE E VALUATOR , only constraint satisfaction validity checks can be performed.

C OMPUTE N EXT P OPULATION are responsible for implementing the evolu-tionary mechanism described in Appendix A . 4. Experimental setup 4.1. The optimization scenarios ing from the fi eld of designing and prototyping electrical drives: the rotor and stator topologies are shown in Fig. 1 . The design parameter vector has a size of six and is given by where all parameters are illustrated in Fig. 1 except for denotes the ratio between the actual magnet size and the max-imum possible magnet size as a result of all other geometric parameters of the rotor. The targets for the MLP surrogate model construction stage are the four, unconstrained, Pareto objectives: in order to minimize vibrations and noise due to torque fl uctuations.

T 3  X  TotalCosts  X  the material costs associated with a particular motor. Obviously, minimizing this objective is a very important task in most optimization scenarios.

T 4  X  T rippPP  X  the equivalent of T cog ; PP at load operation. The values of this objective should also be as small as possible.
The second problem (Scenario OptS2 ) is on an electrical machine featuring an exterior rotor. The design parameter vector contains seven geometric dimensions. The aim of this optimization problem was to minimize the total losses of the system at load operation and to minimize the total mass of the assembly while simultaneously maintaining other desired operational character-scenario, the fi rst target ( T 1) is a hard-constrained Pareto optimi-zation goal, the second ( T 2) is an unconstrained Pareto optimiza-tion goal, whilst the third ( T 3) is a secondary hard constraint imposed on the evolved motor designs.

The third problem (Scenario OptS3 ) also concerns a motor with an exterior rotor. The design parameter vector has a size of ten .
This scenario proposes four, hard-constrained, Pareto optimization goals. All of them are considered targets in the surrogate model construction phase: T 1  X  l s  X  the total axial length of the assembly.
 T 2  X  TotalMass  X  the total mass of the assembly.
 T 3  X  P Cu  X  the ohmic losses in the stator coils.

T 4  X  P fe  X  the total losses due to material hysteresis and eddy currents in the ferromagnetic parts of the motor. 4.2. The testing framework
In order to compare the performance of the two optimization processes we are using optimization runs that compute 100 generations with a population size of 50. This rather small choice of the population size is motivated by restrictions regarding time and the available cluster computation power for running the required simulations.

In order to illustrate some immediate bene fi ts of using the enhanced approach (see Section 3.2.1 ), we also performed tests where, during the run of the MOEA, after the construction of the mappings, we doubled the population size and the number of generations to be evolved.

Our optimization framework uses the NSGA-II implementation provided by the jMetal package ( Durillo and Nebro, 2011 ). For all tests reported in Section 5 , we used NSGA-II with a crossover probability of 0.9, a crossover distribution index of 20, a mutation probability of 1 = j X T j and a mutation distribution index of 20. The high values of the distribution indexes for the crossover and mutation operators (that are recommended by literature ( Deb et al., 2002 ) and set as default in jMetal) force NSGA-II to generate near parent values for almost all spawned offspring. While this parameter choice seems to determine an overall search strategy that favors exploitation over exploration, the highly elitist nature of NSGA-II coupled with the high mutation probability, help to balance the exploitation versus exploration ratio over the entire run. Using ConvOpt, we have performed a tuning phase to check whether smaller values (i.e., 15, 10, 5 and 2) for the crossover and mutation distribution indexes would yield better results when using a population size of 50 and a limited number of evolved generations. The results showed that using these smaller index values does not produce any improvement.

In the case of HybridOpt, we perform the mapping training stage after N  X  25 generations (see Section 5.2 for a detailed explanation of this parameter choice). As we use a population size of 50, the maximum possible size of the training sets is 1250 samples. The size of the actual training sets we obtained was smaller because some of the evolved design con fi gurations were geometrically unfeasible or invalid with regards to given optimi-zation constraints. When considering all the performed tests, the average sizes and standard deviations of the obtained training sets is presented in Table 1 .

The MLP implementation we used for our tests is largely based on the one provided by the WEKA open source machine learning platform ( Hall et al., 2009 ). In the case of the best parameter grid searches that we performed in order to create the MLP surrogate models: the number of hidden units was varied between 2 and double the number of design variables.  X  was varied between 0.05 and 0.40 with a step of 0.05.  X  was varied between 0.0 and 0.7 with a step of 0.1.

The search is quite fi ne grained as it involves building between 704 (scenario OptS1 ) and 1216 (scenario OptS3 ) MLP surrogate models for each elicited target. This approach is possible because we make use of the early stopping mechanism in the MLP training process (see Section 3.2.2 ) which in turn ensures an average surrogate model training time of 356.70 s. We achieve a consider-able speedup in the surrogate model creation stage by distributing all the MLP training tasks over the same high throughput cluster computing environment that is used to run in parallel the FE simulations. As a result, the surrogate model creation stage took, on average, 146.33 min, over all performed tests. 4.3. Considered performance metrics
In order to compare the performance and behavior of the conventional and hybrid optimization processes we use four performance metrics: (1) the hypervolume metric H ( Zitzler, 1999 ) measures the overall (2) the generalized spread metric S ( Zhou et al., 2006 ) measures (3) the FE utility metric U offers some insight on the ef (4) the run-time metric T records the total runtime in minutes
The hypervolume and generalized spread metrics are com-monly used in MOEA literature when comparing between differ-ent non-dominated solution sets. The H metric has the added advantage that it is the only MOEA metric for which we have theoretical proof ( Fleischer, 2003 ) of a monotonic behavior. This means that the maximization of the hypervolume constitutes the necessary and suf fi cient condition for the set of solutions to be  X  maximally diverse Pareto optimal solutions of a discrete, multi-objective, optimization problem  X  . By design, the upper bound of 1.00. For any optimization problem, the true Pareto front yields the highest H value. As we are not dealing with arti fi cial problems, for our considered scenarios, the best possible value of H for each problem is unknown.

In the case of the S metric, a value closer to 0.0 indicates that the solutions are evenly distributed in the search space. Although this metric is not monotonic in showing true Pareto front con-vergence, in our case, it is extremely useful as it is a good indicator of the diversity of Pareto-optimal electrical drive designs that our optimization runs are able to fi nd.

The FE utility metric is constructed for the purpose of illustrat-ing how ef fi ciently the optimization process is using the very time intensive FE simulations over an entire run. The U metric is computed as the ratio between the total number of non-dominated solutions found during the optimization (i.e. the size of the fi nal Pareto front) and the total number of performed FE simulations. 5. Results 5.1. Overview of surrogate model performance
In order to offer a quick insight into the characteristics of the elicited target variables, Table 2 contains the comparative results of trying to model the targets using linear regression, MLPs and three other non-linear modeling methods. We considered sets containing all the samples obtained using FE simulations over 100
NSGA-II generations with a population size of 50 and split them into training and test data sets. The training data sets contain the individuals from the fi rst 33 generations while the test data sets are made up from the individuals from the last 67 generations (i.e., a  X  1/3  X  training, 2/3  X  test  X  data set partitioning scheme).
After removing the geometrically unfeasible and invalid designs, we ended up with training sets of size 1595 ( OptS1 ), 1197 ( OptS2 ), and 1103 ( OptS3 ).
 achieved by the best surrogate model which was selected based on 10-fold cross-validation performance after doing a best parameter grid search on the training data. In the case of the MLP, the grid search was set up as described in Section 4.2 . In the case of SVR, we trained 675 surrogate models for each target as we varied: the general complexity parameter C between  X  2  X  4 ; 2  X  3 ; ... ; kernel parameter  X  between  X  2  X  5 ; 2  X  4 ; ... ; 2 3 and the the  X  intensive loss function between  X  0 : 001 ; 0 : 005 ; 0 : 025 ; 0 : 05 . For RBF networks, we trained 918 surrogate models for each target by varying the number of clusters between  X  2 ; 3 ; 4 ; 5 ; 10 ; 20 ; ... ; 500 and the allowed minimum standard deviation for the clusters between  X  0 : 25 ; 0 : 5 ; 1 :
When using IBk modeling, we created 900 surrogate models for each target as we varied the number of nearest neighbors from 1 to 300 and we used three different distance weighting options: no weighting, weight by 1/distance and weight by 1-distance.
Firstly, one can observe that while most targets display a strong linear dependency towards their respective design variables, the surrogate models obtained using linear regression for some targets (e.g. OptS1-T1 , OptS1-T2 , OptS1-T4 , OptS3-T4 ) are by no means accurate. For the purpose of this research, we decided on a linear regression R 2 threshold value of 0.9 in order to classify a target as linear or non-linear.
 When considering only the six non-linear targets, MLPs and SVR are the best performers (MLP slightly better than SVR) while RBF networks produce results that are signi fi cantly worse.
We conducted all the best parameter grid searches by distributing the surrogate model training tasks over the computer cluster.
We measured the time required by the grid searches conducted for non-linear targets and, for each modeling method, averaged it over the total number of surrogate models to be trained. We present these results in Table 3 and, together with some model complexity information, they indicate that, when comparing with the MLP:
RBF networks and SVR require  X  15 % and  X  55 % more (wall) time in order to fi nish the grid search.

When taking into account the sizes of the training sets, RBF networks and SVR seem to produce surrogate models that are quite complex (i.e., number of clusters required by the RBF network and number of support vectors used by SVR).

The difference in required training time, the low structural complexity, and the higher accuracy motivate our choice of using MLP surrogate models. 5.2. The accuracy and stability of surrogate model predictions
In the current version of HybridOpt, it is very important to choose a good value for the parameter N that indicates for how many generations we wish to run the initial FE-based execution stage. A value of the parameter that is too low will result in creating inconclusive training sets which in turn will lead to surrogate models that are not globally accurate or stable. By choosing a value for N that is a lot higher than the optimal one, we are more or less  X  wasting  X  FE simulations by creating oversized training sets. In order to choose a good value of N we take into account the in fl uence that this parameter has on the accuracy and stability of the resulting MLP surrogate models.
In order to estimate the in fl uence that N has on the accuracy of the surrogate models, for each optimization scenario we consider fully FE-based runs of 100 generations and the combined pools of samples that each such simulation produces. We construct 50 different test cases and, for each target of each scenario, we divide the available samples into a training and a test set. For test number i , the training set contains the individuals from the fi tions and the validation set contains the individuals from the last 100  X  i generations. For each test, we use the best parameter grid search and the automated model selection strategy in order to obtain the best MLP surrogate model on the training data. Next, we evaluate the quality of this surrogate model by computing the coef fi cient of determination over the corresponding test set. The resulting values are plotted in Fig. 5 . It can be easily observed that all targets display a stable logarithmic saturation behavior that suggests that a choice of N in the 20  X  30 generations range should be able to produce highly accurate surrogate models for all considered targets.

The concrete decision for the value of N is based on the stability over time of the obtained surrogate models. We estimate the stability over time by computing the individual R 2 of every generation in the test data sets. For example, Fig. 6 contains the plots of the generational coef fi cients of determination for the most dif fi cult to model targets of scenarios OptS1 and OptS3 (i.e., OptS1-
T2 and OptS3-T4 ). We are only interested in the best surrogate models constructed using the samples from the fi rst 20  X  generations.

Finally, we have chosen N  X  25 as this is the smallest value of N for which the trained surrogate models exhibit both a high prediction accuracy as well as a high prediction stability . Over all three data sets and the 6 non-linear targets, the generational coef fi determination (for generations 31  X  100) obtained by the surrogate models constructed using samples from the fi rst 25 generations: are higher than 0.9 in 94.52% of the cases; are higher than those obtained by the surrogate models constructed using 20  X  24 generations in 57.52% of the cases and by those obtained by the surrogate models constructed using 26  X  30 generations in 42.52% of the cases.

All HybridOpt tests reported in the next section have been performed with the parameter setting of N  X  25. 5.3. The comparative performance of HybridOpt
In Table 4 we present the comparative performance of ConvOpt and HybridOpt after runs of 100 generations each. The results for each scenario are averaged over fi ve independent runs. For these tests, the size of the population in HybridOpt was fi xed, through-out the simulation, to 50 individuals. The performance of our method is very good for scenarios OptS1 and OptS2 as the resul-ting fi nal Pareto fronts have comparable hypervolumes, better spreads and were computed  X  63 % and  X  72 % faster than their counterparts.

On the highly constrained scenario OptS3 , the enhanced opti-mization process is a little bit worse. The main reason for this is that the hard constraints determine a high ratio of geometrically invalid individuals to be generated during the surrogate-based evaluation stage. However, the computation time could still be reduced by  X  46 % . Even though for this scenario, ConvOpt pro-duces pareto fronts with a better H , HybridOpt is still able to evolve well balanced individual solutions in key sections of the
Pareto front  X  see Fig. 7 for two such examples: the black dots denote solutions obtained from HybridOpt and some of them are very well placed with regards to the origin of the projected Pareto space.
 generations to be computed (in the surrogate-based MOEA execu-tion stage of HybridOpt), the results of the enhanced optimization process are much improved (see Table 5 for details). In this case, for scenarios OptS1 and OptS2 , HybridOpt surpasses ConvOpt with regards to all the considered performance metrics.
 surrogate-creation population and of the number of generations to be evaluated enable HybridOpt to surpass ConvOpt with regards to the spread of the generated Pareto fronts. The hyper-volume values, although much better, are still 4  X  8% worse than those of ConvOpt.
 is directly translated into a higher number of individuals that need to be re-evaluated using FE-simulations, the improvement in computation time is reduced to values ranging from  X  14 %  X  69 % . The reduction is particularly visible in the case of the hard-constrained scenario OptS3 , where the amount of geometrically invalid individuals generated in the surrogate-based execution stage also grows substantially. 6. Conclusion
In this paper, we investigated multi-objective optimization algorithms based on evolutionary strategies, exploiting concepts from the famous and widely used NSGA-II algorithm, for the purpose of optimizing the design of electrical drives in terms of ef fi ciency, costs, motor torque behavior, total mass of the assem-bly, ohmic losses in the stator coils and others. Despite the parallelization of the whole optimization process over a computer cluster, as both the design and the target parameter space can be quite large, very long optimization runs are required in order to solve the complex scenarios that we deal with. This is because the fi tness function used by NSGA-II search requires very time-intensive FE simulations in order to estimate the quality of a given motor design.

In order to alleviate the problem, we experimented with a system that automatically creates, on-the-fl y, non-linear surrogate models that act as direct mappings between the design and the target parameters of the electrical drive. These surrogate models form the basis of a very fast to surrogate fi tness function that replaces the original FE-based fi tness for the latter part of the optimization process. Empirical observations over averaged results indicate that this leads to a reduction of the total run-time of the optimization process by 46  X  72%. For setting up the non-linear surrogate models, we applied multi-layer perceptron (MLP) neural networks, as they turned out to be more ef fi cient in terms of accuracy versus training and evaluation time than other soft computing techniques.
 The tests that we have performed show that, on average, the
Pareto fronts obtained using the hybrid, surrogate-enhanced approach, are similar (or even slightly better) than those obtained by using the conventional NSGA-II optimization process, which uses only the FE-based fi tness evaluation function. This may come as a surprise because when we shift the optimization process to the surrogate-based fi tness function, the optimization algorithm will in fact try to converge to a new, surrogate-induced, arti optimum. The high quality of the MLP surrogate models we obtain directly translates into the fact that the arti fi cial optimum lies in the vicinity of the true (FE-induced) optimum. The close proximity of the two optima is the likely reason for which the surrogate models are able to ef fi ciently steer the optimization process towards exploring high-quality Pareto fronts (as the results in Section 5.3 indicate).

Future work will basically focus on two issues: (1) Reducing the importance and the sensitivity of the N para-meter in HybridOpt by shifting our optimization algorithm towards an active learning approach. The idea is that initial (2) Implementing a similarity analysis mechanism that will help Acknowledgments
This work was conducted in the frame of the research program at the Austrian Center of Competence in Mechatronics (ACCM), a part of the COMET K2 program of the Austrian government. The work-related projects are kindly supported by the Austrian government, the Upper Austrian government and the Johannes Kepler University Linz. The authors thank all involved partners for their support. This publication re fl ects only the authors Appendix A. An overview of the NSGA-II algorithm
NSGA-II stores at each generation t two distinct populations of the same size n , a parent population P ( t ) and an offspring population O ( t ). Population P  X  t  X  1  X  is obtained by selecting the best n individuals from the combined populations of the previous generation, i.e., from C  X  t  X  X  P  X  t  X   X  O  X  t  X  . The fi assessed by using two metrics. The fi rst metric is a classi the individuals in the population into non-dominated fronts. The fi rst front F 1  X  t  X  is the highest level Pareto front and contains the Pareto optimal set from C ( t ). The subsequent lower-level fronts F  X  t  X  , j 4 1 are obtained by removing higher level Pareto fronts from the population and extracting the Pareto optimal set from the ranked as having a higher fi tness than individuals in a lower-level in order to rank the quality of individuals from the same front. The crowding distance ( Deb et al., 2002 ) associated to a certain individual is an indicator of how dense the non-dominated front is around that respective individual.

Population P  X  t  X  1  X  is constructed by adding individuals from the higher non-dominated fronts, starting with F 1  X  t  X  . If a front is too large to be added completely, ties are broken in favor of the individuals that have the higher crowding distance, i.e., that are located in a less crowded region of the front. The full mechanism through which population P  X  t  X  1  X  is obtained from population P population P  X  t  X  1  X  by using binary tournament selection, simu-lated binary crossover ( Deb and Agrawal, 1995 ) and polynomial mutation ( Deb and Goyal, 1996 ).
 References
