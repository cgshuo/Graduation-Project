 Context-aware recommendation (CAR) can lead to signif-icant improvements in the relevance of the recommended items by modeling the nuanced ways in which context influ-ences preferences. The dominant approach in context-aware recommendation has been the multidimensional latent fac-tors approach in which users, items, and context variables are represented as latent features in a low-dimensional spa ce. An interaction between a user, item, and a context variable is typically modeled as some linear combination of their la-tent features. However, given the many possible types of interactions between user, items and contextual variables , it may seem unrealistic to restrict the interactions among them to linearity.

To address this limitation, we develop a novel and power-ful non-linear probabilistic algorithm for context-aware rec-ommendation using Gaussian processes. The method which we call Gaussian Process Factorization Machines (GPFM) is applicable to both the explicit feedback setting (e.g. nu-merical ratings as in the Netflix dataset) and the implicit feedback setting (i.e. purchases, clicks). We derive stoch as-tic gradient descent optimization to allow scalability of t he model. We test GPFM on five di ff erent benchmark con-textual datasets. Experimental results demonstrate that GPFM outperforms state-of-the-art context-aware recom-mendation methods.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Information Filtering Collaborative Filtering, Context-Aware Recommendation, Gaussian Processes, Implicit Feedback, Nonlinear, Proba-bilistic Modeling  X 
Part of this work was conducted when the first author was an intern at Telefonica Research, Barcelona.

Collaborative Filtering (CF) methods capable of modeling vast amounts of user data now make it possible for on-line stores and content providers to recommend items tailored to a specific user X  X  interests. Companies are finding that getting those personalized recommendations right -or even close -can mean significantly higher user engagement and sales. This is the driving force behind research on methods that retrieve relevant items to be recommended to on-line users. Recommendation is an Information Retrieval problem whereby the task is to retrieve for a specific user a relativel y small number (5-100) of  X  X elevant X  items out of an inventory of potentially tens of thousands of items.

CF methods predict the preferences of users based on their collective past consumption behavior, which can be e ff ectively inferred from the data traces stored in web-logs . These traces come either in the form of implicit feedback, that is we know which items a user interacted with, e.g., purchased, used, or clicked, etc., or in the form of explicit ratings e.g. in a 1 to 5 stars Likert scale. The learning of preference functions in the context of collaborative filter ing using implicit or explicit feedback data can be cast as eithe r aregressionproblemwhereapotentialratingistobepre-dicted, [8, 29], or a ranking problem where an optimal list of items is to be computed [20, 26, 30].

Context. In the quest for the perfectly relevant recom-mendations it is essential to use all the information that is available and can influence the relevance of an item. This ad-ditional information that defines the environment in which arecommendationisprovidedisoftenreferredtoas con-text [1]. Context could be for example the location where the user is listening to a song on his/her mobile phone or the time and weekday of the user-item interaction. Context-aware recommendations (CARs) can significantly improve the recommendation relevance and quality, compared to con-ventional recommendations that are solely based on user-item interactions [1, 4, 10, 21, 26, 25]. The most successful approaches in context-aware collaborative filtering are ba sed on contextual modeling whereby the user-item-context in-teractions are modeled jointly in some types of factor mod-els. Two particularly popular classes of factor models for context-aware recommendation are the Tensor Factoriza-tion [10, 25] models and the Factorization Machines [21, 19] . Both classes represent the user-item-context interaction as a linear combination of the latent factors to be inferred from the data. Building models without this limitation of linear -ity to better capture the complex interplay between users X  preferences and their contexts is the main goal of our work in this paper.

Gaussian processes. Gaussian processes (GP) is one of the most widely used family of stochastic processes for modeling dependent data. GP-based models can use flex-ible covariance functions, which are the same as the class of positive definite kernels used in Support Vector Machines (SVM), they can thus model very complex functions with-out restricting them to manually chosen parametric (e.g. linear, polynomial) forms. GP have become an important tool for modeling non-linear complex patterns in real-worl d settings for which human preferences is a prime example. While Gaussian processes have been used in conventional collaborative filtering [5, 7, 15], GPFM is the first GP-based attempt for context-aware recommendations.

The vast majority of CF methods developed as of today using latent factors approaches are based on linear models. In this work we present a powerful non-linear context-aware collaborative filtering method that is based on Gaussian Pro -cesses and builds upon past non-linear matrix factorizatio n methods [16] called Gaussian Processes Factorization Ma-chines (GPFM) :
Factor models in Collaborative Filtering been shown to perform well in terms of predictive accuracy and scalabil-ity [2, 13, 23, 8, 30]. Restricted Boltzmann Machines (RBM X  X  ) [24] have been successfully used in the Netflix prize and coul d be seen as some form of nonlinear model since the activa-tion functions of the units typically are of nonlinear form (sigmoid, tanh etc.). RBM X  X  models for CF are currently restricted to the user-item problem and have not been ex-tended to context.

Context-aware recommendation (CAR). Early work in CAR utilized contextual information for pre-processing , where the context drives data selection, or post-processin g, where the context is used to filter recommendations [1, 4]. More recent work has focused on building models that in-tegrate contextual information with the user-item relatio ns and model the user, item and context interactions directly. Two state-of-the-art approaches have been proposed as of today, one based on Tensor Factorization (Multivers Rec-ommendations) [10, 31] and the other on Factorization Ma-chines (FM) [21]. However, both approaches have been de-signed exclusively for the rating prediction problem, i.e. for explicit feedback. TFMAP a ranking based Tensor Factor-ization methods has been proposed by [25] for implicit feed-back data.

Note that recommendation approaches have been proposed to take into account additional information (also referred as metadata, side information, or attributes) about users or items, e.g. ,collectivematrixfactorization[27],localizedfac-tor models [3] and graph-based approaches [11]. However, this type of information would go beyond our definition of  X  X ontext X , since we refer to context as information that is as-sociated with both the user and the item at the same time. Finally, note that a recommended item set from a recom-mender is regarded as the  X  X ontext X  of user choice in the work of [34]. However, this type of context is still extracte d from the user-item relations, thus, not in the scope of the context studied in this paper.

Gaussian processes. Gaussian processes have been used to model relational data e.g. in [6] data that contains re-lational information in the form of an undirected graph is modeled using GP. The model is then applied to classify web-pages, documents and handwritten digits. A GP model for modeling multi-relational data that can include undi-rected graph or bi-partite graph relationships is built in [32] and tested on Country interactions data and the Movie-Lens data. Link Analysis models using GP X  X  have been also used on collaborative filtering e.g. [35]. Note that none of the above models is fit for context modeling since they ei-ther deal with undirected or bi-partite graph type relation -ships, while also having scalability constrains. A non-lin ear method for Matrix Factorization [15] based on GP X  X  was shown to outperform standard Matrix Factorization on the MovieLens data. This method while scalable does not deal with context, and does only deal with explicit feedback data. ABayesianapproachtoTensordecomposition(Tuckerde-composition) is introduced in [33]. The method is used in chemometrics and link prediction in social networks.
In this section we shortly introduce the context-aware rec-ommendations problem and explain how to represent user-item-context interactions in the latent feature space. Nex t we describe the GPFMs and relate it to other models. Fi-nally we derive an extension of GPFMs through modifying the kernel to obtain GPPW, a pairwise preference model, for learning with the implicit feedback.
For ease of exposition, we describe the context-aware rec-ommendations problem with a running example in mobile applications (app) recommendation. Let U = { Alice, Bob, Charlie,... } be the set of users and V = { AB, CCS, D 4 ,... } be the set of items. An event is observed when a user runs an app in the user X  X  current context (location, time etc.). For example, we observe that Bob used app AB in the morning at work 4 times in total and Charlie used app D4 in the evening at home 11 times in total. Here there are two contextual factors: time of the day, i.e. C = { morning, afternoon, evening } and location, i.e. C 2 = { home, work, public } .Sincecontextismulti-dimensional, we call these dimensions the contextual factors to avoid con-fusion. A specific context is a unique combination of di ff er-ent contextual factors: e.g. two context values in the exam-ple are ( morning, work )and( evening, home ). Let P = | U | , N = | V | ,and L m = | C m | ,where m =1 ,...,M and M is the number of contextual factors (i.e. the dimension of con-text). We reserve the subscripts i, j, c 1 ,...,c M for indexing the users, items, and contextual factors, respectively.
We represent each observation as a tuple of (user, item, context, utility). For instance, the two events in the above example correspond to the tuples ( Bob,AB, ( morning, work ) , 4) and ( Charline, D 4 , ( evening, home ) , 11). Note that the data in this example is typically considered as implicit feedback. Our problem description, however, applies to bot h the implicit and explicit feedback settings so we use the ter m utility to enclose both scenarios. Given all observed inter-actions, the goal of context-aware recommendations is to predict the utility of items in di ff erent contexts, which can be used for e.g. to construct an ordered list of items to recommend to the users.
Since our framework is based on the latent factors ap-proach, in this section we define how to transform an ob-servation into its latent representation. Let the user i ,item j ,andcontextualfactor c m be represented by hidden d -dimensional real-valued feature vectors u i , v j ,and v c spectively. Note that we abuse the notation to avoid using di ff erent symbols for the item and contextual factors and instead identifying the two based on their subscripts ( j for item, c m for contextual factor). Conceptually the roles of item and contexts are equivalent so this should not be a problem.

We define a transformation of a pair of (item, context) as: where D =( M +1) d is the dimension of the latent represen-tation, ( d is the dimension for each individual item, context factor vectors) i.e., the latent representation is a stacke d column vector of the feature vectors of the item and con-textual factors. The mapping between an observation and its transformed representation is one-to-one so we will use them interchangeably henceforth.

Our user-centric approach assumes that, for any given user i ,theutilityofapairofitemandcontext( j, c ), is a function of the corresponding latent representation, f i ( t ( j, c )). The form of the utility function can be freely chosen, and dif-ferent forms lead to di ff erent models as discussed in Section 3.4.3 where we connect di ff erent latent factors methods. In this paper we model the utility function using the powerful Gaussian Process (GP) framework which is reviewed in the next section.
We briefly review GP, more details can be found in e.g. [18]. A GP is specified by a mean function m ( x )anda covariance function k ( x , x  X  ;  X  )parametrizedby  X  ,where x and x  X   X  R D .AGaussianprocesspriordefinesadistri-bution over a real-valued function f ( x )if,foranycollection X = { x n } N n =1 ,thesetoffunctionvalues f = { f ( x n ) } has the multivariate Gaussian distribution, where m = { m ( x n ) } N n =1 and the covariance matrix K is the values of the covariance function evaluated between all pai rs f ( x )  X  GP ( m ( x ) ,k ( x , x  X  ;  X  )).

An example of a mean function is m ( x )=0,whichisa typical assumption in GP models. An example of a covari-ance function is the popular RBF kernel, where  X  = { s, l } is called the covariance hyperparameters , s is known as the signal variance and l the length-scale .Us-ing GP as a prior means that, apriori ,weexpectthatthe function values are correlated .Thecorrelationdependson the similarity among the inputs. This makes GP an attrac-tive choice to model the utility function in recommendation s since similarity-based models, such as the neighborhood ap -proach, have been shown to be e ff ective for collaborative filtering [12]. Having introduced GPs, we now describe the Gaussian Process Factorization Machines (GPFMs) for context-aware recommendations. Let X i be the matrix of all latent repre-sentations of the observations of user i and y i be the corre-sponding observed utilities. Let X = { X i } P i =1 .Weusebold capital letters to denote matrices, bold letters for vector s, and regular letters for scalars.

The utility of each user is a function over the latent rep-resentations, therefore we will be operating exclusively on the space R D of X .WeplaceindependentGPpriorsforthe where x and x  X   X  R D and  X  i are the covariance hyperpa-rameters unique to user i .Since X i is a collection of inputs in X ,bythedefinitionofGPswehave: where f i = { f i ( x z ) } N i z =1 is the range of f i over x N i = | X i | ; K i is the N i  X  N i covariance matrix (of user i ) with elements K i z,z  X  = k ( x z , x z  X  ;  X  i )for z, z  X  =1 ...N complete prior is thus given by: where  X  = {  X  i } P i =1 .

For any observation ( i, j, c ,y ), it is unlikely that the utility value f i ( x = t ( j, c )) is exactly the same as the actual utility y .Toaccountforthispresenceofnoiseweusethestandard iid Gaussian likelihood for an observation: where  X  i is the noise hyperparameter unique to user i and y iz is the z -th element of the vector y i .

The complete likelihood of all the observations is: p ( y 1 ,..., y P | f 1 ,..., f P , X ,  X  )= where I is the identity matrix and  X  = {  X  i } P i =1 .
The GPFM model is specified by the prior in Equation 4andthe likelihood in Equation 6, and is thus a Bayesian model. Next we discuss some of the covariance functions that can be used with the GP priors.
The first covariance function we consider is the RBF func-tion defined in Equation 2. Recall that the transformation x = t ( j, c )isaconcatenationoftheindividuallatentvec-tors v j and v c m ,m =1 ...M ,hencewecanrewritetheRBF function (say, for the user i )as: where k ( v c m , v c and  X  i = { s i ,l i } .Noticethatthekernels k ( v j , v j k ( v c m , v c has a special form: it is the product of the RBF covariances of the item and contextual factors.

Another popular kernel is the linear covariance defined as, hence the linear kernel in GPFM has the special form of the sum of the linear kernels of the item and contextual factors.
Bias is a well-known phenomenon in recommendations, e.g. some users always give high ratings or some items al-ways receive high scores. To account for this, we allow each user, item, and contextual factor to have a latent bias b b ,and b c m ,m =1 ...M ,respectively. 1 For each user i ,we define a bias function that absorbs its bias in addition to the bias of an observation ( j, c ): Replacing the standard zero-mean GP prior over the utility functions (Equation 4) with m i (  X  )wegetthenewGPFM prior that accounts for bias: sponding to the observations of user i (similar to X i )and m i is the values of m i (  X  )evaluatedat X bias i .
The most closely related model to GPFM is the proba-bilistic matrix factorization (NPMF) [15], which is a non-linear generalization of matrix factorization [28] based o n GPs. Indeed, GPFM subsumes NPMF as a special case when there is no context, no bias and only explicit feedback data. Another class of popular factorization models is the 1 Again we abuse the notations to avoid using di ff erent sym-bols.
 Factorization Machines [19]. Using the same notations as in our problem setting, FM defines the utility function of user i given item-context ( j, c )as, where v i  X  R d is the latent vector of user i .Theterm involving the latent biases is called the unary interaction in FM. This unary interaction is exactly the mean function m ( j, c )oftheGPpriorofuser i .Theremainingpairwise linear combinations of the user, item, and context latent features are known as the 2-way interactions in FM. GPFM replaces this linear interaction with a non-linear functio nby using a GP prior with covariance function over the latent feature space. Hence GPFM can be seen as the non-linear generalization of FM models of order 2.

Notice that the utility functions in FM are parametric where the latent features v i can be seen as the weights in alinearregressionmodel. Incontrast,theutilityfunctio ns in GPFM are non-parametric (i.e. having no parametric formula).
We now present a variant of GPFM for personalized rank-ing with implicit feedback. The utility here is not explicitly expressed by users but is in the form of implicit behaviour (e.g. user opening a website or purchasing an item). A typical approach to implicit feedback has been to cast the observed interactions as having positive utility, say 1, an d all non-observed interactions as having negative utility, say -1. However, as pointed out in [20], this causes an underes-timation problem e.g. for ranking, due to the much larger number of irrelevant (negative) items used for training. In [20], Rendle et al. addressed this problem by optimizing apairwisecomparison(context-agnostic)model.Wetakea similar approach to build a GPFM-based pairwise preference model which we call GPPW.
We start by formulating a latent representation of a paired comparison similar to section 3.2. A paired comparison for the user has higher utility for item j 1incontext c1 than item j 2incontext c2 2 .Thiscomparisonisexpressedinthe latent space via the transformation, where jc is the short notation for ( j, c ), e.g jc 1 =( j 1 , c 1).
Following the work in [7, 20] which define the paired com-parison as the di ff erence in utility, we define the pairwise preference function of user i , g i : R 2 D  X  R as, i for j 1over j 2 given asamecontext,butitislessgeneral. where x 1 = t ( jc 1 ), x 2 = t ( jc 2 ), and ( x 1 , x 2 From the above and f i  X  GP (0 ,k (  X  ,  X  )) we can show that g is also a GP with covariance function: k This preference kernel has desirable properties for prefer -ence learning, including anti-symmetry and transitivity [ 7]. Specifically, this means that the functions generated from the kernel satisfy: g i ( x 1 , x 2 )=  X  g i ( x 2 , x 1 )and g 0if g i ( x 1 , x 2 ) &gt; 0and g i ( x 2 , x 3 ) &gt; 0.
Having derived the preference function and its kernel based on the utility function over items, we now describe the pair-wise preference model. Since the user utility functions f are independent GPs a priori, the pairwise preference func-tions are also independent GPs. The prior of the pairwise preference model is thus representations of the paired comparisons of user i ; g i g ( X pair i )isvalueof g i evaluated at all points in X pair is the covariance matrix of the preference kernel k pref (  X  ,  X  ) evaluated at X pair i .NotethattheGPPWpreferencekernel is induced from the GPFM utility kernel and thus they share the same set of hyperparameters.

For the likelihood ,weusestandardiidGaussiannoise model leading to p ( y pair 1 ,..., y pair P | g 1 ,..., g P , X ,  X   X  )= where y pair i is the set of observed paired comparisons cor-responding to X pair i .Notethatthenoisehyperparameter  X   X  = {  X  i } is unrelated to that of the utility model.
The analogy between the GPFM and the GPPW can be seen by inspecting their prior and likelihood definitions in the equations 4, 6, 13, and 14. Although sharing the same set of underlying latent utility functions, GPFM models item-based observations whereas GPPW models pair-based observations. E ff ectively, in terms of learning, GPFM fits a model which aims to score individual items right. GPPW on the other hand fits a model which seeks to order items correctly. As will be seen in the experiments, these di ff eren t learning goals can lead to substantial di ff erence in perfor-mance, for example in learning to rank.

While common in many ranking models our application of the pairwise preference model in this paper is novel with respect to previous applications in the GP literature. In par-ticular, we use GPPW to learn the utility functions whose values can be used to produce an ordered list e ffi ciently. In contrast, traditional paired comparison GP models (e.g. [5, 7]) are used to predict or classify, given two items, whic h one is preferred by a user. Such comparisons cannot be used to trivially create a ranked list of items for recommenda-tions. Furthermore, these conventional approaches requir e observed item features and thus do not belong to the class of latent factors model like GPPW.
To apply GPPW to the implicit feedback setting, we need to convert the implicit feedback by each user to his/her set o f pairwise comparisons. This can be done simply by sampling the negative/irrelevant feedback and creating a pair jc 1 jc 2 for every jc 1 in the positive / relevant feedback and every jc 2 from the rest (i.e. the negative/irrelevant feedback). Although this may lead to quadratic number of pairs (per user), our experiments in Section 5.3 suggest that GPPW can be e ff ective using only the same number of observations as GPFM.
In this section we derive inference for GPFM, which in-cludes learning of the hyperparameters and latent features and making predictions for unseen items. Inference for GPPW can be done similarly thanks to the analogy of the two mod-els. Although a Bayesian model, fully Bayesian inference of GPFM is not feasible for large-scale data. The standard approach in GP is to use the empirical Bayes (also known as type-II maximum likelihood) approach. This means opti-mizing the marginal likelihood of the model with respect to the latent features and covariance hyperparameters.
The marginal likelihood is obtained by integrating out (hence the term marginal )theutilityfunctionvalues f i , which is given by: where f = { f i } P i =1 and y = { y i } P i =1 .Substitutingthe prior p ( f | X , X bias ,  X  )(equation10)andthelikelihood p ( y | f ) (equation 6) into the above we get, p ( y | X , X bias ,  X  ,  X  )= %
This gives the negative log marginal (with the conditioned variables omitted for brevity): which is the sum of the (negative log) marginals of all users. Each user marginal likelihood is given by: where K i y =  X  2 i I + K i and N i is the cardinality of y
With the (negative) log marginal given in equation 15, learning becomes an optimization problem with the opti-mization variables being the set { X , X bias ,  X  ,  X  } .Sincethe objective  X  log p ( y )decomposesintothesumoftheneg-ative log marginals, we can use stochastic gradient descent with respect to users for training with GPFM. In recommen-dations, the number of observations for a user is relatively small. Thus, this decomposition across users makes GPFM feasible for large-scale datasets as we will see in Section 4 .1.3.
We iterate over each user and update its parameters { X i X i ,  X  i ,  X  i } according to the following update rule:  X  is the learning rate and h is the momentum term which allows a large range of  X  to be used with SGD.
In this section we find the derivatives of the individual marginal of each user with respect to its parameters. As can be seen from Equation 15, the marginal depends on the form of the covariance function. Here we derive for the RBF covariance function as it generates non-linear functions. To avoid notational clutter, we drop the dependent on subscrip t i ,butthederivationappliestoallusers.

First, the derivatives of the RBF covariance with respect to the latent features x are given by: Derivatives of k ( x , x  X  ;  X  )withrespecttothe  X  can be simi-larly computed. Note that both of the latent features x and the covariance hyperparameters  X  are parameters of the ker-nel. This is contrary to standard GP where the inputs are observed and thus are constant in the kernel function.
The gradient of the marginal with respect to any u  X  { x ,  X  } is composed of two parts (see Equation 16):  X  ( y  X  m ) T K  X  1 y ( y  X  m ) where it should be emphasized again that y , m , K y are that of user i with the subscript dropped.

The gradient with respect to any of the latent bias u is given by:
To simplify the analysis, we make the crude assumption that each user has the same number of observations i.e. N B/P = a ,where B is the total number of observations. The main cost in computing the marginal and its derivatives (for each user) is the cost of matrix inversion which require s O ( a 3 ). Once the inverse is calculated, the cost of taking derivatives of all parameters of i is O ( a 2  X  a ( Md + d +2), where the a 2 factor is due to the matrix multiplication and a ( Md + d +2)istheupperboundonthetotalparameters of the user. The total cost is thus O ( Pa 3 + Pa 3 Md )= O ( Ba 2 Md ). In real world recommendations, the data is very sparse while P is very large, hence a is typically small. The number of contextual factors M is usually less than 20. The latent dimension d can be much smaller than that used in linear latent factors methods (e.g. d=3) since the GP model allows a higher modeling capacity. Hence the computational complexity of GPFM is linear in the number of total observations B ,aswelaterdemonstrateempirically in Section 5.4. The complexity of GPPW is also linear in the number of paired comparisons as the computation is the same as GPFM, except that the GPPW kernel requires 4 evaluations of the GPFM kernel.
Once the latent features X and covariance hyperparame-ters  X  are learned, they can be used to make prediction for unseen pairs of (item, context). Since GPFM and GPPW use the same underlying set of utility functions, the predic -tive distribution is the same with respect to the goal of pre-dicting utility for items. Given a test observation ( j  X  we first use the transformation to convert it to its latent representation x  X  = t ( j  X  , c  X  ). Prediction of the utility for ( j , c  X  )foruser i then follows standard GP regression [18] which is, where s  X  = k ( x  X  , x  X  ;  X  i )  X  k ( x  X  , X ;  X  i )( K i y )  X 
Notice that the prediction mean  X   X  has the intuitive in-terpretation of being a weighted linear combination of all seen utilities of user i .Thepredictionvariance s  X  expresses the confidence of the model about the (item, context) being predicted. This is an additional advantage of GPFM and GPPW over the non-Bayesian counterpart as, for example, one can use the variance to decide whether or not to recom-mend an item to the user.
We evaluate the performance of GPFM against two state-of-the-art methods in context-aware recommendations. Fir st we describe the datasets in details. We then evaluate GPFM for explicit feedback and GPFM pairwise for implicit feed-back separately. We conclude the section with additional ex -periments demonstrating the linear scalability of our SGD-based learning algorithm. Our implementation is available at http://trungngv.github.io/gpfm .
We use 5 contextual datasets, two of which are in the food domain, two in the movie domain, and one in the mobile applications domain. The statistics of all datasets are giv en in Table 1 where the first 4 datasets are explicit and the Table 1: Dataset statistics (#obs is the number of observations and scale is the range of ratings in the datasets). name #users #items #contexts #obs scale adom 84 192 5 1464 1 -13 comoda 121 1232 12 2296 1 -5 food 212 20 2 5554 1 -5 sushi 5000 100 7 50000 0 -4 frappe 953 4073 4 61465 1 last dataset frappe is implicit. For frappe ,thenumberof observations is the number of user-item-context interactions.
The first explicit dataset is adom [1] which contains 1464 ratings by 84 college students for 192 movies. The students were asked to rate the movies on a scale from 1 (hate) to 13 (absolutely love) and they also filled out information about the context of the watching experience. Following the work in [10, 21] we use 5 contextual factors: companion, day of the week, if it was on the opening week-end, season, and year seen.

The second dataset is comoda [14] which contains 2296 ratings of 1232 movies by 121 users. It is interesting to note that data acquisition occurred immediately after a user fin-ished watching a movie. As a result, the ratings may be more reliably captured in this dataset compared to oth-ers. The user submitted a rating for the movie and also provided the context of the experience: time of the day, day type (working day, weekend, holiday), season, location , weather, social (companion watchers), ending and dominant emotions, mood, physical condition, discovery (self-sele cted or suggested by others), and interaction (first, n-th).
The third dataset is food [17] which contains 5554 rat-ings by 212 users on 20 food menus. The users were asked to rate the menus while being in three di ff erent levels of hunger. They did so while being either in a real or supposed situation (i.e. the subjects imagined that they were in a specific state of hunger, which may di ff er from the actual state). We found that the original dataset is contaminated with conflicted ratings where a tuple of (user, item, con-text)) corresponds to two outputs (ratings) that di ff er by at least 2. There are 804 such inputs in total and for each of them we replace the conflicted ratings with their average. This results in a clean dataset of 5554 observations from the original 6360 observations.

The fourth dataset is sushi [9] which contains 50,000 rat-ings of 100 di ff erent types of sushi by 5000 Japanese users. Each user was asked to score a di ff erent set of 10 sushi on a scale from 0 to 4. We use the following contextual factors: style, major group (seafood or otherwise), minor group (12 in total), heaviness/oiliness in state, popularity (how fr e-quently people eat the sushi), price, and availability in sh ops. Despite the contextual information coincides with the item attributes, we use this dataset to verify the scalability of our model due to the lack of large-scale explicit contextual datasets.
The first implicit feedback dataset we use is from the mo-bile app recomender frappe which contains 61,465 implicit feedback of 4073 Android applications by 953 users. The recommender logs the app usage counts by a user in di ff er-ent contexts. The observations with count of at least one is regarded as positive / relevant feedback. The following 4contextualfactorsareused: timeoftheday,dayofthe week, location (unknown, home, workplace), and weather.
In addition to frappe ,wecreatedtwomoredatasetsby converting food and comoda into implicit feedback. This is done by treating all observations with a rating higher than 3 (for food )and4(for comoda )asthepositivefeedback,i.e. users like the food or movie. This results in 2,882 implicit observations for food and 1526 observations for comoda . To avoid over-sparsity in the case of comoda (due to the large number of contextual factors), we use only two,  X  X he ending X ,  X  X ominant emotions X  and  X  X ood factors X  in the ex-periments.
In this section we describe our experimental protocols to evaluate GPFM for explicit feedback and discuss the results .
We use the 4 explicit feedback datasets detailed in the pre-vious section. We compare GPFM ( gpfm )withtwostate-of-the-art methods in context-aware recommendations namely factorization machines ( fm 3 )[21]andtensordecomposition ( multiverse )[10]. Similarto[21],wealsocomparewithstan-dard matrix factorization ( mf )whichdoesnotuseanycon-textual information. Finally, we use a naive predictor ( con-stant )whichpredictsforeveryuserthemeanofhisratings.
We split each dataset into 5 folds and repeat the exper-iments 5 times using one fold as the test set and the re-maining 4 folds as the training set. For all methods (except constant )weempiricallytunetheparametersusingoneof the 5 folds as the validation set. We then fix the tuned pa-rameters when running experiments with the other 4 folds.
For gpfm with SGD training, we find that a momentum of 0.9 and a fixed learning rate of 0 . 5  X  10  X  4 seems to work ically converges after 10 epochs (an epoch is a single pass through the dataset). The latent features are initialized b y random sampling from the normal distribution N (0 , 10  X  4 ), the covariance hyperparameters from the standard normal distribution, and the noise hyperparameter initialized to 1. We find that the RBF kernel always outperform the linear kernel so we use RBF in all of the experiments.

The task we are evaluating is prediction of utilities (rat-ings) of unseen items and contexts for users. We use four evaluation metrics: mean absolute error (MAE), root-mean-square error (RMSE), Normalized Discounted Cumulative Gain of top 10 items (NDCG@10), and Expected Recipro-cal Rank also of top 10 items (ERR@10). Note that while MAE and RMSE measure the overall prediction quality of a model, ERR and NDCG are better suited for ranking as they place higher reward for the top items in a recommended list (typically consists of 5-10 items only). For all datasets, t he Note that it only implements a regression model. iteration but this seems to have marginal e ff ects. Table 3: Performance comparison on the 4 explicit datasets in terms of ERR@10, higher is better Figure 1: Performance comparison on the 4 explicit datasets in terms of NDCG@10, higher is better. performance is averaged over the 5 di ff erent folds. The re-sults are statistically significant and the variances are sm all so not reported.
The performance comparison of all methods are shown in Table 2 for MAE and RMSE, Table 3 for ERR@10, and Figure 1 for NDCG@10.

First we compare the context-aware and context-agnostic methods. It is clear that both gpfm and fm significantly outperform mf on all datasets and on metrics (with the ex-ception of mf slightly outperforms fm on the sushi dataset. This confirms the benefits of using contextual information in recommendations, as was previously demonstrated in CAR [10, 21]. Multiverse outperforms mf on the adom and food but has poor performance on comoda and sushi where it su ff ers because of the high dimensionality of context in thos e two datasets. Meanwhile, mf does only slightly better than the naive constant predictor. This can be explained by the fact that users may have di ff erent utility for the same item under two di ff erent contexts. Failing to account for this use r-item-context interaction leads to the low predictive quali ty of standard matrix factorization.

Next we compare the two best context-aware methods: gpfm and fm .Theoverallperformancemeasureinterms of MAE and RMSE (Table 2) shows that gpfm does signif-icantly better than fm on all of the datasets except adom For example, on comoda ,theMAEandRMSEby gpfm are smaller (better) than that of fm by 11% and 13%, respec-tively. Similarly, the MAE and RMSE di ff erences are 6% and 2% for food and 1% and 3% for sushi respectively. The superiority of gpfm over fm is further reflected in terms of ERR in Table 3 and NDCG in Figure 1. This also demon-strates that GPFM gives much better predictions for the items near the top of a ranked recommendation list com-pared to the state-of-the-art methods. Thus, the experimen t results confirm that modeling user-item-context interacti on nonlinearly with GPFM leads to substantial performance in context-aware recommendations.
In context-aware recommendations, di ff erent contextual factors are likely to influence the user-item-context inter ac-tions at varying degrees. Can we identify which context is most important or relevant to the users? To answer this question, we perform a qualitative analysis with the co-moda dataset. We chose comoda for two reasons: it has the highest context dimension and also has the most natu-ral, non-intrusive data acquisition process. We run exper-iments on this dataset using the same experimental setup aforementioned, except that only one of the contexts is used at a time. The results show that the two most influential contextual factors are ending and dominant emotions  X  gpfm using those two factors alone gives an MAE of 0.7119 and aRMSEof0.8953.Thisturnsouttobenottoosurprising: the ratings of user for movies are typically conditioned on their emotions triggered from watching the movies. Perhaps one implication is that movie recommendation can be im-proved by taking into account the mood/emotional state of a user, which was the focus of a recent challenge in CAR [22]. While it may not be practical to obtain the users X  emotions in the same way as in [14], social medias such as Twitter, Facebook, or online movie review websites may be used to collect similar information.
In this section we describe our experimental protocols for evaluation of GPPW for the implicit feedback datasets and discuss the results.
We use the 3 implicit feedback datasets described in Sec-tion 5.1.2. Since we are comparing a pairwise preference model (GPPW) with item-based models (GPFM and FM), we must make sure that the comparison is fair.

We use 70% of the relevant feedback in each dataset for training. Let say there are N positive instances, we ran-domly sample N negative instances, one for each positive item of a user under a given context. The relevant obser-vations are given a rating of 1 and the sampled irrelevant observations are given a rating of -1. These 2 N observa-tions are then used for training with GPFM and FM, just like in the explicit setting.

The 2 N observations are also used to create the paired comparisons for GPPW training. Specifically, consider user i in context c ,let j + be one of the relevant items and j  X  its sampled irrelevant counterpart. The items j + and j  X  are used to create two pairs, ( j + , c ) &gt; i ( j  X  , c )andsymmetri-of 2 N for GPPW. Note that if the number of relevant items is n for ( i, c ), the actual number of comparisons is 2 n 2 :ev-ery j + induces 2 n pairs since j + is preferred over all of the n sampled irrelevant items. This can be a potential problem for training GPPW. However, our experiments suggest that the training size needs only be the same as GPFM and FM for it to be e ff ective.

We carry out the same sampling procedure to create val-idation sets (10%) and test sets (20%), except that the ra-tios of irrelevant to relevant are 5, 10, and 20 for food comoda ,and frappe ,respectively. Thesamplingisdone such that the items in training, validation, and test sets ar e non-overlapped. We use the validation sets to empirically tune the parameters of all methods, afterward the experi-ments are run 5 times using the tuned parameters.
The task we are evaluating here is prediction of utilities (ratings) for items given a context for the users .Weuse two ranking evaluation metrics: ERR@10 and Mean Aver-age Precision (MAP@10). For all methods, the predicted utility values are used to create ranked lists which are then scored by the metrics. Note that the ERR and MAP are averaged over user given context, as this was how the data is generated.
The performance of all methods on the 3 implicit feedback datasets is shown in Table 4. It can be seen than GPPW significantly outperforms both GPFM and FM on the food and comoda dataset while having comparable ERR@10 and MAP@10 on the frappe dataset. Recall that GPPW uses the same set of latent utility functions as GPFM, only op-timizing a di ff erent likelihood model. The results therefor e suggest that learning with paired comparisons can lead to substantial improvement for ranking compared to optimiz-ing item-based scores. Furthermore, as stated in the pre-vious section, GPPW achieves this performance using the same training size as GPFM. This suggests that GPPW can be more e ff ective than GPFM in the implicit feedback set-ting with little overhead in computation.
Finally we verify the linear computational complexity of the stochastic gradient descent learning for GPFM. To this end, we measure the running time against the amount of data used for training and the dimensionality of the la-tent features. We normalize the measured time by the time needed to train with 100% of the data and with the latent dimension d =8.Thenormalizedtrainingtimeperepochis shown in Figure 2, where the linear correlation between the training size and time can be readily observed. Since the number of optimization variables increases linearly with d , the training time also scales with d ,buttheoverallcomputa-tional complexity is still linear with respect to the total n um-ber of observations. Note that one iteration on the frappe dataset on a MATLAB implementation took approximately one minute. Figure 2: GPFM training time per iteration for the frappe dataset as a function of training size and di-mensionality of latent features.
We presented the Gaussian Process Factorization Machines, anovellatentfactorsbasedapproachforcontext-awarerec -ommendations. The utility of an item under a context is modeled as functions in the latent feature space of the item and context. By introducing Gaussian processes as pri-ors for these utility functions, GPFM allows complex, non-linear user-item-context interactions to be captured lead -ing to powerful and flexible modeling capacity. Learning in GPFM is carried out with stochastic gradient descent that scales linearly with the total number of observations and thus making GPFM scalable to large datasets. We also de-rive a pairwise preference variant of GPFM by changing its covariance function, which can be used seamlessly to deal with implicit feedback.
The work leading to these results has received partial funding from the European Union X  X  Seventh Framework Pro-gramme (FP7/2007-2013) under grant agreement n o 610594 (CrowdRec). We would like to thank Edwin V. Bonilla for helpful discussions and the anonymous reviewers for their constructive feedback.
