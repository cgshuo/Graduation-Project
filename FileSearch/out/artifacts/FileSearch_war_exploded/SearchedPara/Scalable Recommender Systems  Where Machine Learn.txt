
This tutorial provides an overview o f how search engines and machine learning techniques can be tightly coupled to address the need for building scalable recommender or other prediction -based systems. In particular, we will review ML -Scoring, an open source framework , created by the authors that tightly integrate s machine -learning models into Elasticsearch, a popular search engine that is distributed, scalable, highly available with real -time search and analytic functionalities . 
The fundamentals and basic methods in information retrieval and machine learning will be explained . Accompanying the theory, practical examples will illustrate their application s with a series of hands -on exercises . The se will demonstrate how to load a dataset into Elasticsearch [5], how to train a model in an externa l software framework such as Spark [13 ], Weka [6], or R [7], and finally how to load the trained model s as a ML -Scoring plugin s created for Elasticsearch. D.2.11 [ Software ]: Software Architecture  X  data abstraction , dom ain-specific architectures; H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval  X  information filtering, query formulation, relevance feedback, retrieval process, search process, selection process ; I2.6 [ Artificial Intelligence ]: Le arning  X  parameter learning . Search engines; l arge-scale recommender systems . 
The r ecomm ender systems and search engine problems are similar. B oth can be formulated as prediction based system s wi th roots in data mining that comprises the following stages in: 3. Post -processing (i.e. filtering, visualization, and 
In the early days of their development, the ir communities diverged. One focused on the problem of information retrieval (IR) and another one on information filtering (IF) . Consequently, different avenues of research were followed that produced different technologies and areas of expertise . 
Modern search engines use distributed computing for both indexing and serving of results to provide scalable and speedy data retrieval . This can be of great value in applications such as e-commerce, online advertising and recommender systems [10, 12] . I n these applications , the search space may be large and results need to be determined with in just a small fraction of a second. To achi eve speed and scalability , the IR community has developed techniques to represent items, such as products, movies or advertisements, as semi -structured documents that are indexed . In most cases, these systems require the results to be scored and ranked in order to determine the top set of items . These will match a particular serving opportunity while satisfying the constraints that are expressed as a query (e.g. keyword, user and context as input). 
Relevance ranking of results by search engines is modeled a fter the early days of IR , primarily dealing with keywords and text. These are represented as queries in the term document vector space. Overtime as search engines became widely adopted, more complex ranking and scoring functionalities were implemented, such as multi -field document structures , and ways to  X  X weak X  the basic TF -IDF weights used in the (Q  X   X  D  X  ) dot product to compute the similarity score between a query expression and a document [1, 3, 9 ]. 
On the other hand, the recommender systems community has concentrated on solving the information filtering aspect with successes on methods developed in collaborative filtering to predict ratings [8]. Over time as the number of users and the size of items X  catalog have multiplied , the need to build scalabl e recommender system is becoming a fast growing priority . Typically, such scalable systems architect retrieval and prediction in two phases. In Phase I, a search engine returns the top -k results based on constraints expressed as a query. In Phase II, the top -k results are re -ranked in another system according to an optimization function that uses a supervised trained model. However this approach presents several issues, such as the possibility of returning sub -optimal results due to the top -k limits during qu ery, as well as the presence of some inefficiencies in the system due to the decoupling of retrieval and ranking [2, 4, 11 ]. 
To address this issue the authors created ML -Scoring, an open source framework that tightly integrates machine -learn ing models into Elasticsearch . ML -Scoring replaces the default information retrieval ranking function with a custom supervised model that is trained through Spark, Weka, or R and loads the model as a plugin into Elasticsearch. Once a learning -to-rank model has been created , the customized Elasticsearch plugin can be use d to write function_score queries to perform both constraint -based retrieval of candidate items and relevance ranking of those items according to the learnt model . As a result, the scoring of the model hap pens during query time as a single step process in a single system within the search engine . Models can also be updated and loaded periodically to reflect the change s in the data as parameters are updated with new observations . This tutorial is broken down into three sections 
This tutorial is intended for researchers and software practitioners that wish to build scalable recommender systems using searc h engines. No prior experience is required in any system listed (Elasticsearch, Spark, Weka, R), though some information retrieval, machine learning background and programming experience is recommended. [1] Baeza -Yates, R., &amp; Ribeiro -Neto, B. 2011 . Modern information retrieval . New York: ACM press. [2] Chirita, P. A., Firan, C. S., &amp; Nejdl, W. 2007. Personalized query expansion for the web. In Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information re trieval (pp. 7 -14). ACM. [3] Croft, W. B., Metzler, D., &amp; Strohman, T. 2010. Search engines: Information retrieval in practice . Reading: Addison -Wesley. [4] Dunning, T. 1993 . Accurate methods for the statistics of surprise and coincidence. Computational linguistic s , 19 (1), 61-74. [5] Elastic, Elasticsearch: RESTful, Distributed Search &amp; Analytics . 2015. https://www.elastic.co/products/elasticsearch. [6] Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reute mann, P., &amp; Witten, I. H. 2009 . The WEKA data mining software: an update. ACM SIGKDD explorations newsletter , 11 (1), 10 -18. [7] Ihaka, R., &amp; Gentleman, R. 1996 . R: a language for data analysis and graphics. Journal of computational and graphical statistics , 5 (3), 299 -314. [8] Kantor, P. B., Rokach, L., Ricci, F., &amp; Shapira, B. 2011. Recommender systems handbook . Springer. [9] Manning, C. D., Ra ghavan, P., &amp; Sch X tze, H. 2008. Introduction to information retrieval . Cambridge: Cambridge university press. [10] Qiu, F., &amp; Cho, J. 2006 . Automatic identification of user interest for personalized search. In Proceedings of the 15th international conference on World Wide Web (pp. 727 -736). ACM. [11] Sun, J. T., Zeng, H. J ., Liu, H., Lu, Y., &amp; Chen, Z. 2005 . Cubesvd: a novel approach to personalized web search. In Proceedings of the 14th international con ference on World Wide Web (pp. 382 -390). ACM. [12] Xi ng, B., &amp; Lin, Z. 2006 . The impact of search engine optimization on online advertising market. In Proceedings of the 8th international conference on Electronic commerce: The new e -commerce: innovations for co nquering current barriers, obstacles and limitations to conducting successful business on the internet (pp. 519 -529). ACM . [13] Zaharia, M., Chowdhury, M., Franklin, M. J., Shenke r, S., &amp; Stoica, I. 2010 . Spark: cluster computing with working sets. In Proceedings of the 2nd USENIX conference on Hot topics in cloud computing (Vol. 10, p. 10).
