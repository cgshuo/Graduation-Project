 Relevance is a central notion in Information Retrieval, but it is considered to be a difficult concept to define. We analyse brain signals for the first 800 milliseconds (ms) of a relevance assessment process to answer the question  X  X hen relevance is happening in the brain? X  with the belief that it will lead to better operational definitions of relevance. For this purpose, we devised a user study in which we captured the brain re-sponse of 20 participants. Using a 64-channel EEG device, we measured the electrophysiological activity of the brain while the subjects were in the phase of giving an explicit judgement about the relevance of presented images accord-ing to a given topic. Analyses were then performed over different time windows of the recorded EEG signals using re-peated measures ANOVA. Data reveal significant variation between relevance and non-relevance within the EEG signals from the presentation of the image to 800 milliseconds af-terwards. At an early stage these differences were located at frontal and posterior electrode sites. However, at later stages these differences were located in central, centro-parietal and centro-frontal areas. Our findings are an important step to-wards (i) a better understanding of the concept of relevance and (ii) a more effective implicit feedback systems. Categories and Subject Descriptors: H.3.3 Information Storage and Retrieval -Information Search and Retrieval -Search Process General Terms: Performance, Experimentation Keywords: Relevance, EEG c  X 
In this paper we focus on the process of relevance assess-ment performed by humans in an image retrieval task. The main aim of this study is to identify the time frame in which the brain has the highest activities with regard to the pro-cess of relevance assessment from the moment of observing a stimulus. Identification of the period of time in which there is a clear association of the activation of brain regions with the task of relevance assessment can be the basis to detect implicit signals of the relevance of images. This may lead to robust definitions and implementation of the concept of relevance.

Relevance is a core notion in Information Retrieval. It has been advocated that the relevance of an information ob-ject to the information need of a specific user is a subjective and multidimensional concept, which encompasses various properties and characteristics of the sought information ob-jects [3]. In Information Retrieval systems searchers express their information needs via a set of query words, a process considered to be uncertain and noisy [13]. A progressive dis-ambiguation of the user information need can be achieved through an interactive and iterative process known as the relevance feedback cycle. This process may rely either on ex-plicit or implicit user X  X  indications of relevant objects that the system processes to construct a better representation of the user X  X  needs. To account for the highly interactive nature of the IR task, a number of relevance feedback tech-niques have been introduced in the literature, which vary from explicit to implicit.

Techniques that rely on explicit feedback are cognitively difficult to use, and hence implicit feedback based systems have been proposed, which, though noisy, allow us to col-lect several distinct signals of the user X  X  interests through the analysis of both the user X  X  actions and user generated contents [14]. Over the last few years affective and phys-iological features have been considered as valid ground to define implicit feedback techniques [1, 10, 8]. For example, Arapakis et al., studied the role of emotions in information retrieval, and introduced a number of models [1, 2]. In their subsequent work, they showed that emotional features can be effectively included in building implicit feedback systems [2], and they can also be used to personalise searching [1]. Another example is the work by Moshfeghi et al. in which they demonstrated that, in addition to emotional features, physiological features can also be used to model relevance [8], and they can also be used to predict task types [9].
More recently, a new wave of research was initiated to bet-ter understand relevance by analysing brain activity. Mosh-feghi et al. [10] show that it is possible to identify brain regions activated during the process of relevance judgement. Another example is the study conducted by Eugster et al. [4] using EEG to show that the frequency content of the EEG signal over extended time windows, along with Event Related Potentials (ERPs) can be used as an effective fea-ture set for decoding relevance of text. Likewise, Kauppi et al. [6] using magnetoencephalography (MEG) show that the frequency content of the MEG signal along with eye move-ment data can be used for decoding relevance of images. Finally, Zhang et al, [15] show that brain signals monitored via EEG may be used to predict term relevance. Despite the great progress made over this period in terms of better un-derstanding relevance and how to use it more unobtrusively, these studies fail to answer an important and complementary question which is when the relevance assessment is happen-ing in the brain. In this paper we aim towards answering this research question.

We conjecture that EEG signals can be exploited to de-tect significant brain activities in the process of assessing relevance of images. In particular, we aim to identify the time frame in which that significative activity appears in a user X  X  brain while they are assessing pictures. In this spirit, this paper reports the results of an EEG-based user study on image search. We therefore devised an experiment consist-ing of collecting data via a 64-node EEG in a lab-based user study, and analyzed the collected data off-line. In contrast to the approaches [4, 6], we examined the time variation of the amplitude of the EEG response to relevant and non-relevant items so as to better understand how the difference in relevance evolves over time. In fact, our hypothesis is that there is a time frame in which the EEG signals would be different for relevant documents from non-relevant doc-uments. The rest of the paper is organised as follows: the experiment methodology is described in Section 2, results and discussion are presented in Section 3, and finally the paper is concluded in Section 4.
In this section, we report detailed settings of our experi-mental methodology.

Experiment Design: This study used a within-subject design. The independent variable was the relevance (with two levels: relevant, and non-relevant), The dependent vari-ables were the EEG signal of the brain.

Tasks: During the experiment, subjects were asked to judge the relevance of images according to a topic. The im-ages used were selected from the ImageCLEF 2009 -Photo Retrieval Task 1 . To this end, 100 images (stimuli), 50 rel-evant and 50 non-relevant, were shown to each subject. In order not to tire them, stimuli were presented in two sep-arate tasks of 50 images each. For both tasks users could choose between two different topics from a total of four top-ics, one for each ImageCLEF used in the experiment (11, 49, 02 and 46).

Apparatus: The experiment was run in a purpose-designed room, with a soft light in order to avoid distrac-tions. Stimuli were presented with E-Prime 2.0 2 installed on a PC with a video resolution of 1024 x 768 pixels. Subjects were able to interact with the computer via a keyboard. EEG signals were recorded with a 64 Ag/AgCl electrodes BrainProducts cap (BrainCapMR) 3 . Eye movements and the electrical activity of the heart were monitored by 2 elec-trodes (EOG, which was the combination of VEOG and HEOG, and ECG), while the other 62 channels were placed on the scalp at the locations based on the International 10-20 system[5]. All the 64 channels were referred to the reference electrode placed in the middle of the scalp. Data was digi-tally sampled for analysis at 1024 Hz sampling rate with a 0.016 to 250 Hz analogue bandpass filter and a resolution of 0.5  X  V per bit.

Participants: Data were collected from 20 participants (11 females and 9 males) with European origins (10 from UK and 10 from other EU countries). They were recruited from the University of Glasgow population (12 BSc, 5 MSc and 3 PhD) and the average age was 22.35 (  X  1.66) years (from 20 to 25). All of them had a normal or corrected-to-normal vision, no history of neurological or psychiatric disorders and declared not to be on any drug or medication which could affect their EEG.

Procedure: The user study was carried out in the fol-lowing manner. The formal meeting with the participants took place in the laboratory setting. At the beginning of the session the participants were given an information sheet which explained the conditions of the experiment. They were then asked to sign a Consent Form and were notified about their right to withdraw at any point during the study, without affecting their legal rights or benefits. Then, they were given an Entry Questionnaire to fill in. The session proceeded with a brief tutorial on the use of the interface with a short training task.

Figure 1 shows how a stimulus was presented to partici-pants. At the beginning, a fixation cross was shown for 1000 ms and it was used to capture the attention of the partic-ipant in the middle of the screen. Then, an image, which was randomly chosen among the 50, was presented for 1000 ms. During this period of time, from the appearance of the fixation cross on the screen to the disappearance of the im-age, the participant was asked to stay as relaxed as possible, and to try not to blink or move 4 . After the presentation of the stimulus, participants were asked to provide a feedback about relevance by pressing a key of the numeric keypad on the right-hand side of the keyboard. The subjects were in-structed to press key 1 with the first finger of their right hand for positive feedback (which means the image was relevant), or press key 2 with the second finger for negative feedback. In order not to put any pressure on the participants, and reduce the probability of errors in pressing buttons, there were no time limits to answer the question. In the end, a blank screen was shown for 1500 ms to let them rest before the next picture.
Finally, an Exit Questionnaire was administered at the end of the session. Participants were then asked to sign a payment form, prior to receiving the payment. Each study took approximately 100 minutes to complete. Users could only participate once. Prior to running the actual user study, a pilot study was performed using 5 participants to confirm that the process worked correctly and smoothly. A number of changes were made to the system based on feedback from the pilot study.

Preprocessing Steps: The acquired EEG signals were pre-processed using the tools provided by EEGLAB 5 . The pre-processing steps started by referencing the data to the common average (CAR). Then, a band-pass filter, from 0.3 to 40 Hz, was applied to remove power line noise. Epochs were then extracted from 500 ms before stimulus presen-tation to 1000 ms afterwards. Bad epochs containing only noise were manually removed. Finally, a spatial filter was run using Independent Component Analysis (ICA) in order to remove interference caused by eye blinking and other ar-tifacts (e.g., muscle movement).

Time Frame Based Analysis: We decided to examine the behavior of the EEG signals across all the first 800 ms from the time when the stimuli was presented to the partic-ipants. In order do so, we defined four consecutive windows of time as follows: from 0 to 180 ms, from 180 to 300 ms, from 300 to 500 ms, and from 500 to 800 ms. A similar analysis strategy was adopted by Koelstra et al. [7] and in-cluded a time window of 300-500 ms. A decision for the other values used in these time boundaries was based on prelimi-nary examination of the data, consideration of the task and consideration of the literature on the timing of EEG events in relation to perceptual and cognitive processing. For ex-ample, since approximately 150 milliseconds is the shortest duration of Event Related Potential (ERP) related to vi-sual object categorization [12] we chose 0-180ms as our first epoch to include any such ultra-rapid potentials. Following Koelstra et al. we also chose 300-500 ms, a range that would include activity such as the P300, which has been related to attentional and memory processing [11].

Statistical Analysis of Button Responses: The col-lected responses were compared to the relevance assessment set (Qrel) provided with the ImageCLEF 2009 tasks. In gen-eral, the overall accuracy was 0.89 (  X  0.10). In particular, the accuracy over relevant stimuli was 0.90 (  X  0.12), while over non-relevant stimuli it was 0.87 (  X  0.14). Regarding the response time, the overall mean response time was 676 (  X  506) ms, where an average of 669 (  X  480) ms was taken by subjects to judge relevant images, while 683 (  X  530) ms was taken to judge non-relevant ones.
This section presents the analysis of our EEG results. We firstly calculated the mean value for each channel obtained by averaging over the 20 participants X  recorded signals and over the target window of time for two conditions: relevance and non-relevance. The Mean Significant Difference (MSD) was then calculated between the two conditions in each time range. This was calculated by subtracting the mean signal for the non-relevant condition from the mean signal for the relevant one. We finally obtained an F -value for each of the 62 electrodes by performing an ANOVA test.

Figure 2 shows topographical plots of the significance in difference ( F -value) between the two conditions in the differ-ent time ranges. In these plots, the blue color indicates that there is no difference between relevance and non-relevance. Conversely, colors from yellow to red indicate a significant difference between two conditions, and the more the color is red the higher the difference. Moreover, the electrodes that carry significant differences ( p  X  0 . 001) are highlighted with a white dot. 0 -180 ms This is the first window of time which goes from the initial presentation of the image to 180 ms after-wards. Looking at the first topographical plots on the left in Figure 2, it is clear that there are no apparent differences between the two conditions. This was also confirmed by an ANOVA test that did not reveal any significant effects. One possible reason for this lack of a difference between condi-tions is that this early time window is dominated by encod-ing of the stimulus features. Since both the relevant and non-relevant images are rich in detail it is possible that the coding of these stimulus features might mask any potential differences in processing relevance. 180 -300 ms The window of time 180 -300 ms shows an early process of implicit judgements of relevance. This process takes place in different areas of the scalp, as shown in the second topographical plot in Figure 2. The most relevant ones are located in the frontal area and in partic-ular in F1 ( F (1 , 19) = 22 . 063, MSD = 1 . 123  X V ) and AF4 ( F (1 , 19) =, MSD = 1 . 126  X V ) locations. Since in both electrodes the MSD value is positive, the potential associ-ated with relevance is greater than non-relevance. 300 -500 ms This time-window shows (third topo-graphical plot in Figure 2) that the positive value of MSD has moved to central areas. In particular, the most signifi-cant difference between the two conditions can be found in the electrodes located at C2 ( F (1 , 19) = 29 . 031, MSD = 1 . 074  X V ) and CP2 ( F (1 , 19) = 27 . 655, MSD = 1 . 273  X V ) positions on the scalp.

This window of time is also the same analysed by Koelstra et al. in their study. Looking at both our and their results, it is possible to state that they tally. In fact, the electrodes which carry the most significant differences between the two studies are very similar. In both experiments the area sur-rounding electrode CP2 is the one which carries the greatest difference between the two conditions 6 . 500 -800 ms The last window of time taken into ac-count is the one which shows the most significant difference between relevance and non-relevance condition. As shown in the topographical plots in Figure 2, in the fourth plot the difference between the two conditions is more accen-tuated than in the third one. Nonetheless, it is possible to notice that the region of interest is still located in the centre of the scalp. In this last time range, the electrodes which carry the greatest difference between the two con-ditions are C2 ( F (1 , 19) = 53 . 369, MSD = 1 . 781  X V ), Cz ( F (1 , 19) = 48 . 154, MSD = 1 . 800  X V ) and C1 ( F (1 , 19) = 43 . 257, MSD = 1 . 848  X V ).

Discussion Timing and topography of our results suggest a timecourse of processing relevance that involves an early stage in the time window of 180 -300 ms and a later stage that begins around 300 ms and builds through 800 ms. This first stage was evident in the larger potentials for relevant images found at frontal and posterior electrode sites. The timing of this difference suggests a role for late perceptual encoding of relevance and might explain the fMRI activity reported by Moshfeghi et al [10] in the inferior temporal cortex. Moreover, this early difference in amplitude might be related to establishing differences in the EEG frequency content used as features in recent research [6, 4]. From 300 to 800 ms after the stimulus was presented, the mean difference between EEG signals elicited by relevant and non-relevant images became greater in the electrodes centered around Cz at the central area of the scalp. Similar results have been obtained by Eugster et al. [4]. They found a peak difference at 757 ms between relevant and non-relevant stimuli at the CZ and C4 electrode sites, arguing that this potential was due to processing of memory. Despite the different nature of the two studies (Eugster et al. focused on textual terms, while we focused on images), it is possible to assert that this later stage might be common across the visual modalities of text and image, and related to cognitive encoding of visual information. Hence, regardless of context, our brain needs around 800 ms to judge the relevance of a visually presented stimulus.
In this paper we aimed to answer a fundamental question which is when the relevance assessment is happening in the brain. Focusing on the process of assessing relevance of im-ages, we tried to identify the time frame in which users X  brain EEG signals are the strongest and most distinguishable from the time that the images are shown to them. Our hypothesis was that there is a time frame in which the difference be-tween EEG signals elicited by relevant and non-relevant im-ages would be significant. To investigate that, we analysed how relevance assessment evolves over different windows of time within the first 800 millisecond of relevance judgment. Our findings revealed time frames as well as regions which carry the most significant difference between relevance and non-relevance conditions within this period of time. Despite the fact that the process of relevance assessment is very com-plex, this novel study provides an important step towards unravelling the nature of relevance and operationalising it for IR processes.
