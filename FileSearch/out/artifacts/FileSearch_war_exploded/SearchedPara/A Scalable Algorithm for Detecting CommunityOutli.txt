 Outlier detection is a task that seeks t o determine and report such data ob-jects which are grossly different from o r inconsistent with other members of the sample [1,2]. The technique has the ability to potentially shed light on the unexpected knowledge with underlying va lue. Therefore, outlier detection has attracted much attention within diverse areas, ranging from fraudulent trans-actions to intrusion detect ion [3,4]. Recently, the advent of social networks ex-emplified by websites such as Facebook and MySpace has brought the following unprecedented challenges to outlier detection.  X  Content &amp; Structure: A social network is defined as a graph where the  X  Tremendous Amounts of Information: Compared with average data  X  Context of Community: Communities, in the social network sense, are In this paper, community outliers are defined as those objects have a higher density of external links, compared with its internal links. As mentioned above, the community here is a group of entities that presumably share some common properties [6].

The example in figure 1 is adopted to illustrate directly the feature of com-munity outlier. According to income, individuals in figure 1 are partitioned into three communities, namely low-incom e, middle-income an d high-income com-munity. The links between nodes disclose the friend relationship. In most cases, as a well-known proverb says,  X  X  man is known by the company he keeps X , one is supposed to make friends with those who have the same income level. Most of nodes in figure 1 correspond to prediction. However, node v 13 is devi-ating widely from others. It is located in low-income group with 1 low-income friends, while its high-income friends and middle-income friends are 2 and 2, respectively. Community outlier node v 13 is usually regard as a rising star in the social networks, for instance, a young and promising entrepreneur [9,10]. Obvi-ously, different from global and local outliers, node v 13 can hardly be detected by algorithms based on either content information or structure information.
The contribution of our work can be summarized as follows:  X  Besides descriptive concept, we put forward a novel measurable definition of  X  We propose a scalable community outliers detection algorithm (SCODA),  X  Our algorithm takes effective measures to minimize input parameters. Only  X  The extensive experiment s demonstrate that the time complexity of SCODA The rest part of this work is organized as follows: Section 2 discusses the recent related work; Section 3 gives the prelim inaries about Squeezer algorithm; Section 4 proposes our scalable community outliers detection algorithm,SCODA; Section 5 gives experiments for our approach on both real and synthetic data sets, and shows the achieved results. Section 6 makes a conclusion about the whole work. To focus on the theme, the majority algorithms that aim at detecting global or local outliers by using either content or structure information will no more be introduced in this paper. We are eager to discuss some state-of-art algorithms that encompass both individual object and network information.

Some literatures[15,16] cluster data points according to the combination of data and link information. However, instead of outlier detection, they are pro-posed for community discovery, assuming that there are no outliers in social networks.

A contextual outlier detection method i n [9] couples content and relation-ship information by modeling networked data as a mixture model composed of multiple normal communities and a set of randomly generated outliers. The probabilistic model characterizes both data and links simultaneously by defining their joint distribution based on hidden Markov random fields (HMRF). Maxi-mizing the data likelihood and the posterior of the model gives the solution to the outlier inference problem. Unfortunately, the algorithm could not overcome the weakness of statistical outlier det ection techniques which are limited in the sense that the data distribution and underlying parametric formulation are diffi-cult to directly obtain in advance [11]. Moreover, most of the distribution models are not suitable for multi-dimensional space. Another limitation with these ap-proaches is that they typically do not scale well to large or even moderately large datasets [14].

Some methods [17-19] solve the problem by first conducting graph partition using link information, and then adopting distance-based approaches or density-based approaches within each community. However, they suffer expensive com-putational cost as they require the calculation of the distances [5] or the analysis of the neighborhood density [12,13].

In summary, limitations of aforementioned approaches prompted us to look for a scalable community outlier detection algorithm that considers both content and structural information with low time cost and minimum input parameters. 3.1 The usmSqueezer Algorithm Dataset D is featured by m attributes and A i is the i -th attribute. There is an as-sumption that the first p continuous attributes before the rest (m-p) categorical attributes. The domain of the i -th categorical attribute A i denotes as Dom ( A i ), which has r i different values. The usmSqueezer algorithm [20] reads each tuple t in sequence, either assigning t to an existing cluster, or creating t as a new cluster, which is determined by the usmSimilarity between t and clusters. usm-Similarity (C,t) is the sum of similarity measure between categorical attributes and similarity measure between numerical attributes . More details can be found in reference [20].

Summary = { c i | 1  X  i  X  p } { ( A ij ,sup ( A ij )) | p +1  X  i  X  m, 1  X  j  X  r } where sup() is a function to measure the frequency of categorical attribute a i , and c i represents the mean of firs t p numeric attributes.

Intuitively, the cluster stores its own summary information. The information contained in Summary is sufficient enough to compute the similarity between a tuple and Cluster. Our SCODA algorithm involves two major phases. In the first phase, the modi-fied usmSqueezer algorithm (MSqueezer for s hort) efficiently groups data objects into communities by their content information. The second phase is community outlier detection. SCODA identifies community outliers within communities gen-erated in the first phase according to Community Outlying Degree Factor ,which is a novel measurable standard considering the structure information of social networks. 4.1 Phase I: Content-Based Clustering The first phase aims to efficiently obtain the partitions based on objects X  infor-mation. The success of the usmSqueezer al gorithm in rapidly producing high-quality clustering results in high-dimensional datasets mixed type of attributes motivates us to take advantage of it in our first phase. However, the number and the size of clusters obtained from the usmSqueezer algorithm are suffering the influence of the similarity threshold value, which is a static parameter prede-fined by users. Since the partitions generated in the first phase are principal to community outlier detection in the second phase, we design a similarity thresh-old dynamic update mechanism with no personal interventions for usmSqueezer algorithm. The modified usmSqueezer al gorithm is named MSqueezer for short.
The definitions of usmSimilarity and Summary are still maintained just as in section 3.
 Definition 1 ( SS and SS 2 ). Given a Cluster C with | C | tuples, the Sum of usmSimilarities ( SS ) and the Sum of squared usmSimilarities ( SS 2 )forCare respectively defined as
SS =
SS 2 = Definition 2 (Mortified Cluster Structure: MCS ). Given a Cluster C with |
C | tuples, the Mortified Cluster Structure(MCS) for C is defined as MCS = { Cluster, Summary, | C | ,SS,SS 2 } The MCS is the main data structure stored by MSqueezer algorithm, which could be used to compute usmSimilarity and Dynamic Similarity Threshold . Definition 3 (Dynamic Similarity Threshold:  X  ). According to Chebyshevs inequality:
Pr ( |  X .lower  X   X  | X  k X  )  X  Here the real number k is set to Alternatively, the  X  .upper for C is set to be  X  .

Where  X  isthesampleexpectedvalueand  X  is sample standard deviation, which can be easily determined from SS and SS 2 .

The multi-granularity threshold is a dopted to determine whether to receive tuple t as a new member or not, because 1) our purpose is to produce commu-nities of proper size without p ersonal interventions; 2)  X .lower is able to avoid the phenomenon that clusters ten d to decrease in size, if increasing  X .upper is used as the only threshold; 3) This can partly reduce the sensitivity towards data input order.

Our MSqueezer algorithm partitions n tuples into communities according to objects X  information. Initially, the first tuple is read in and a MCS is constructed. Then, the rest tuples are read iteratively.

For each tuple, MSqueezer computes its usm Similarity with all existing clus-ters. We examine the usmSimilarities in descending order, if the i -th largest usmSimilarity ( C k ,t ) is larger than the  X  .upper of cluster k , the tuple t will be put into cluster k .Ifall  X  .upper s are unsatisfied, tuple t will be put into the cluster whose  X  .lower is the first to be satisfied. The corresponding MCS is also updated with the new tuple. If the above condition does not hold, a new cluster must be created with this tuple. The algorithm continues until all the tuples have been traversed.
 Algorithm: MSqueezer Algorithm (High level definition) Input: Dataset D; Output: A group of communities Step 1: Read in a tuple t in sequential order; Step 2: If t is the first tuple, add t to new MCS , else goto step3; Step 3: For each existing cluster C , compute usmSimilarity(C, t) and then sort usmSimilarities in descending order; Step 4: For each usmSimilarity, get the corresponding threshold  X .upper .If usmSimilarity  X   X .upper , add tuple t into cluster C ,updatethe MSC ,  X .upper and  X .lower of C and then goto step7, else goto step5; Step 5: For each usmSimilarity, get the corresponding threshold  X .lower .If usmSimilarity  X   X .lower , add tuple t into cluster C ,updatethe MSC ,  X .upper and  X .lower of C and then goto step7, else goto step6; Step 6: add t to new MCS ; Step 7: Goto step1 until ther e is no unread tuple.
 Time Complexity Analysis: The computational complexity of the MSqueezer algorithm has two parts: 1) the complexity for executing original Squeezer al-gorithm on the dataset; 2) the complexity for sorting and updating dynamic similarity thresholds; . The time comp lexity of the original Squeezer algorithm is O ( k  X  m  X  n ), where n, m, k are the number of nodes, attributes and clusters, respectively. As for part 2), sorting and updating dynamic similarity thresh-olds are O ( k log k )( k ! n )and O( n ), respectively. Therefore, the overall time complexity for the MSqueezer algorithm is O ( k  X  m  X  n ). 4.2 Phase II: Structure-Based Community Outlier Detecting In this section, we develop a formal measurement of community outliers by taking full account of the link information between communities, which are produced in phase I. We will first establish some notations and definitions. The network G = &lt;V,E&gt; consists of a set of nodes V and a set of links E. The weights attached to links are stored in an adjacency matrix. For  X  v ij  X  V , we define its intra-community neighbor and inter-community neighbor as follows. Definition 4 (Intra-Community Neighbor).  X  node v ij  X  community C i ,if node v ij can communicate with node v ip ( v ip  X  community C i ,and p = j ), node v ip is called a intra-community neighbor of node v ij , all the intra-community neighbors of node v ij constitute its intra-community neighbor set Intra-NS( v ij ), including v ip .
 Definition 5 (Inter-Community Neighbor).  X  v ij  X  V ,ifnode v ij can com-municate with node v qp ( v qp  X  community C q ,and q = i ), node v qp is called a inter-community neighbor of node v ij ,all v ij  X  X  inter-community neighbors in community C q constitute its inter-community neighbor set with respect to com-munity C q , which is denoted as Inter-NS C q ( v ij ).
 Example 1: In figure 1, v 16 is a intra-community neighbor of v 13 , while v 21 and v 24 constitute v 16  X  X  inter-community neighbor sets with respect to community C v Definition 6 (Link Density: LD ). Let k be the number of communities in the network.  X  v ij  X  V , the Link Density of ( v ij ) to community C q (1  X  q  X  k ) is defined as where W C q v ij denotes the sum of edges X  weights. These edges are between v ij and its neighbors in community C q . | C q | is the number of nodes in community C q .
Intuitively, an object is supposed to mainly communicate (make friends) with the intra-community nodes that presumably share some common properties. In contrast, a community outlier owns a high external link density, whereas links within the community to which it belongs have a comparatively lower density. In other words, the object X  X  community outlying degree is directly proportional to its inter-link density with respect to Inter-NS, and inversely proportional to intra-link density.
 Definition 7 (Community Outlying Factor: COF ). Let k be the number of communities in the network. The community outlying factor of v ij ( v ij  X  C i ) is defined as Note that the link density can be  X  if v ij has no intra-community neighbor. For simplicity, we handle this case by adding the same infinitesimal positive number  X  (e.g. 10  X  6 )to both numerator and denominator.
 Example 2: Continuing with Example 1 , the community outlying factor of v 13 can be computed using Definition 7 as: COF ( v 13 )= Algorithm: SCODA Algorithm (High level definition) Input: Dataset D , the number of community outliers n ; Output: n community outliers Step 1: Get a set of communities part itioned by MSqueezer (Phase I) Step 2: Compute community outlying factor for each object; Step 3: Select and output the objects with the first n -largest COF; Obviously, the overall time complexity for the SCODA algorithm mainly depends on that of MSqueezer algorit hm, which is O(k*m*n) as we discussed in Phase I. The above analysis demonstrates that the time complexity of SCODA algorithm is approximately linearly dependent on the number of nodes, which makes this algorithm more scalable. In this section, we illustrate the general behavior of the proposed SCODA algo-rithm. We compare the accuracy performance of SCODA with several baseline methods on synthetic datasets, and we examine the scalability of SCODA on real datasets. 5.1 Data Description and Evaluation Measure Real Data Sets: We perform scalability experiments on 3 real data sets. These networks come from the same data set (DBLP, dblp.uni-trier.de/), but they vary in the number of nodes and edges (up to more than 400K nodes). DBLP bibli-ography is one of the best formatted and organized compute science community datasets. In our representation, we consider a undirected co-authorship network. The weighted graph W is constructed by extracting author-paper information: each author is denoted as a node in W; journal and conference papers are repre-sented as links that connect the authors t ogether; the edge weight is the number of joint publications by these two authors. Synthetic Data Sets: Since  X  X ommunity outlier X  is a new concept, the proper benchmark datasets are rare. Therefore, we attempt to convert a few classifi-cation datasets where each object consists of attribute values and a class label into datasets for community outlier detection. We generate synthetic data sets through two steps. First, we select tw o real UCI machine learning data sets, Adult and Yeast. The Adult dataset, which is based on census data, contains 45222 instances corresponding to 2 classes. The Yeast dataset is composed of 1484 instances with 8 attributes. Then we apply link generation procedure on these two data sets. The distribution of links follows Zipf X  X  law, i.e. roughly 80% of the links come from 20% of the nodes. The self-links and the nodes without any links are removed from data sets. We denote the synthetic data sets based on Yeast and Adult as SYN1 and SYN2, respectively.
 More detail information about real and synthetic datasets is shown in Table 1. We measured the performance of different algorithms using well-known metric F1 measure, which is defined as follows.
 where recall is ratio of the number of re levant records retrieved to the total number of relevant records in the data set; precision is ratio of the number of relevant records retrieved to the total nu mber of irrelevant and relevant records retrieved. 5.2 The Accuracy of SCODA Algorithm To evaluate the clustering performance, we compared SCODA algorithm against three other algorithms. The first approach is a well-known single content-based outlier detection method, which identifies global outlier by its k-nearest neigh-bors X  distance. Therefore we denote i t as the Content Approach (CA). The sec-ond one (CODA) takes advantage of the probabilistic model, which characterizes both data and links simultaneously by defining their joint distribution based on hidden Markov random fields (HMRF). In fairness to all algorithms, we set the same number of outliers (from 5 to 20) for each method. We compared the F1 of the three algorithms on two simulated data sets. Table 2 illustrates the comparison results.

Table 2 obviously indicates that CA algorithm which completely ignores the inherent structure information of datasets is far inferior to other algorithms. The experiments once again prove that solely using one type of information cannot accomplish accurate community outlier detect ion. The performance of CODA and SCODA are satisfactory in the situations because of considering both object and link information. The effectiveness of our proposed algorithm SCODA surpasses the state-of-the-art CODA approach. 5.3 The Scalability of SCODA Algorithm To evaluate the scalability of SCODA, the next series of tests report the com-putation time as we vary the number of nodes. Figure 2 indicates the scalability of SCODA Algorithm with increasing number of nodes.

Figure 2 demonstrates that our method returns results that agree with our intuition, and there is a linear dependency of SCODAs processing time on the number of nodes in networks. Moreover, we can see that for the largest network, the computation time is less than one hundred seconds. This property means that the algorithm can easily deal with large data sets. In this paper, we have investigated a nov el outlier detectio n problem, namely community outlier detection, which springs from the advent of social network. Besides descriptive concept, we put fo rward a straightforward measurement named Community Outlying Factor, which quantifies how outlying a commu-nity member is. We propose a scalable community outliers detection algorithm (SCODA), which fully considers both content and structure information of social networks. Furthermore, we take effectiv e measures to eliminate personal inter-vention by requiring a single input parameter. The experimental results on both real datasets and synthetic datasets clearly ascertain that SCODA algorithm is capable of detecting community outlier a ccurately and effectively. The scalabil-ity tests demonstrate SCODA algorithm is a scalable method that can efficiently work for large datasets.
 Acknowledgment. This work was supported by the National High Technol-ogy Research and Development Program of China (Grant No. 2012AA011002), National Science and Technology Major Program (Grant No. 2010ZX01042-002-002-02, 2010ZX01042-001-003-05), National Science &amp; Technology Pillar Program (Grant No. 2009BA H44B03), Natural Science Foundation of China 61073018, the Cultivation Fund of the Key Scientific and Technical Innovation Project, Ministry of Education of China (Grant No. 708001) and the Shenzhen-Hong Kong Innovation Cooperation Project (No. JSE201007160004A). We would like to thank anonymous reviewers for their helpful comments.

