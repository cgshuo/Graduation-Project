
Department of Computer Science, The University of Auckland, Auckland, New Zealand School of Computer and Mathematical Science, Auckland University of Technology, Auckland, New Zealand 1. Introduction
Association rule analysis is the task of discovering association rules that occur frequently in given transaction data set [1,2]. Initially this particular technique was proposed for market basket analysis. Given a set of transactions D , association rule mining finds the complete set of association rules whose support is greater than a user-defined minimum support threshold ( minsup )and confidence greater than a user-defined minimum confidence threshold ( minconf ). This is known as the  X  X upport-confidence X  framework.

The dominant theme in traditional association mining is the discovery of positive association rules in frequently occurring itemsets such as [3 X 7]. However in this paper we consider the complementary problem called negative association rule mining. A negative association rule describes a relationship whereby the occurrence of some itemset implies the absence of some other itemset, i.e., what items that are not purchased together in a market basket scenario. An example of such a rule is 80% of customers who buy  X  X utter X  do not buy  X  X argarine X . Thus, the supermarket can launch simultaneous promotions on both butter and margarine, confident in the fact that increased sales on either product will not adversely affect the sales of the other. Another example of such a rule would be 99% of customers who buy  X  X laystations console X  do not buy the  X  X ii console X . Negative association rule mining can be applied in a wide variety of fields such as medicine, telecommunications, and education. Pears et al. [8] working in the mobile telecommunications area found two high confidence assocation rules linking the call signal strength, measured in terms of the signal to noise ratio (SNR) with the call duration. The first rule was:  X  (SNR = high)  X  call length = low with a confidence of 99%, meaning that 99% of the cases where high quality signals were absent resulted in low duration calls. The second rule expressed the inverse relationship as:  X  (call length = low)  X  SNR = high with confidence of 95%. Taken together these two rules indicate that improvements in network infrastructure could promote longer duration calls.
Negative association rule mining is a computationally hard problem. In a transaction database there may be tens of thousands of items. It is possible that many of these combinations may not appear in any of the transactions. For example, if there are 10000 it ems the possible number of combinations of items is 2 10000 , many of which will probably not appear in the entire database. Finding all combinations that lead to rules will be prohibitively expensive. Furthermore, taking into consideration absence of items will result in a very large number of rules, many of which will prove to be trivial, as our experimentation in section 5 shows.

In Section 2 we give a precise definition of the association rule mining problem and then discuss background in Section 3. In Section 4 we present our approach to negative association rule mining. Experimental results are described in Section 5. We summarize our research and discuss some directions for future work in Section 6. 2. Background
The following is a formal statement of association rule mining for transaction databases. Let I = { i 1 ,i 2 ,...,i m } be the universe of items. A set X  X  I of items is called an itemset. A transaction t =( tid ,X ) is a tuple where tid is a unique transaction ID and X is an itemset. A transaction database D is a set of transactions. The count of an itemset X in D , denoted by count ( X ) , is the number of transactions in D containing X .The support of an itemset X in D , denoted by supp ( X ) , is the proportion of transactions in D that contain X .Therule X  X  Y holds in the transaction set D with confidence c where c = conf ( X  X  Y ) and conf ( X  X  Y )= supp ( XY ) / supp ( X ) .
 A negative association rule is an implication of the form X  X  X  Y ,  X  X  X  Y ,or  X  X  X  X  Y ,where X  X  I and Y  X  I .  X  X and  X  Y are negations, and denote the absence of itemsets. A strong negative association between itemsets whose distribution fulfills the minimum confidence requirements implies a negative association rule between the two itemsets. 3. Related work
Negative association was first noted by Brin et al. [9]. Since then there have been several attempts to solve the problem of negative association rule mining. In this section we discuss some of the related work carried out.

Savasere et al. [10] proposed a method to mine strong negative association rules. They discovered positive association rules and combined them with domain knowledge to constrain the search space to mine interesting negative association rules. The main drawback of this approach is that it requires a predefined taxonomy, which may not be readily available in the application domain that is targeted. Consequently, their approach may not be applicable across all domains.
 Yuan et al. [11] proposed a method of mining negative association rules based on locality of similarity. Items that belong to the same locality of similarity tend to participate in similar association rules. Mem-bers of the same group tend to have a similar pattern. The use of localities of similarity provides clues to potentially useful negative rules. Suppose that items i h ,i k  X  I are members of LOS. If rule r : X  X  Y is true and i h  X  X , then based on the similarity assumption, by substituting i k for i h in the antecedent of rule r , a sibling positive rule r : X  X  Y is generated. However, if such association is not supported, meaning the occurrence of Y is not related to X , then the corresponding negative association may exist. A salience measure is defined as a distance between confidence levels:
Here conf ( r ) is the actual confidence of rule r . E ( conf ( r )) is the estimated confidence of rule r , which is defined to be equal to the confidence of rule r based on the similarity assumption. A large value for SM is evidence for accepting the hypothesis that X  X  Y is false. That is, X  X  X  Y may be true. However this approach has the same drawback to the approach proposed by Savasere et al. [10], in that it requires a predefined taxonomy.
 Wu et al. [12] proposed a new method of mining for both positive and negative association rules. They defined an interestingness function, interest(XY) = | supp(XY)  X  supp(X)supp(Y) | .Theinterest function is a heuristic, and itemsets with an interestingness value greater than or equal to a user defined threshold are considered potentially interesting. All such items give rise to negative association rules of the form X  X  X  Y where X and Y are disjoint subsets of the universe of items I , while the confidence and interest levels of the rule both exceed their preset threshold levels. Their scheme adds interest to the standard support and confidence framework for evaluating rule quality. While this method yields certain types of negative association rules, the main drawback is that it is incapable of finding rules that are interesting but do not meet the support threshold. For example, suppose that supp(AB) = 0.5, supp(C) = 0.8, supp(ABC) = 0.1 and suppose that the minimum support threshold is set at 0.2. Now interest (ABC) = | 0 . 1  X  0 . 4 | =0 . 3 . If the interest threshold is set at 0.25, then the rule AB  X  X  C is interesting. However the rule support at 0.1 is less than the minimum support threshold of 0.2, thus preventing the rule from being generated. This example illustrates that the use of a minimum support threshold may not be desirable if the objective is to detect negative associations. The key issue is that a strong and reliable indicator of negative association is needed, while guaranteeing that such associations do not occur purely by chance. As we illustrate in the next section the use of Fisher X  X  exact test provides a rigorous method of ensuring such an objective.

Antonie and Za X ane [13] introduced an automatic progressive threshold process. They used the Pear-son X  X   X  correlation coefficient to measure the strength of an association. They adopt this measure from Cohen [14]; they consider a correlation of 0.5 as large, 0.3 as moderate, and 0.1 as small. They start off by setting a correlation threshold to 0.5. If there are n o strongly correlated rul es found, the threshold is lowered progressively until some rules are found with moderate correlation. However this method still requires the user to define a minimum support threshold, through a trial and error process.
Koh and Pears [15] propose a method of mining a method of mining negative association rule using the Fisher exact test as a basis for eliminating items that occur by chance. Pairs of items that occurred together with a frequency greater than a chance threshold were flagged as candidate items for rule gener-ation; all other pair of items were excluded from participating in the rule generation process. They com-pared their method with rule generation using Pearson correlation as a basis and noted that certain types of rules involving items that had asymmetry in support between the antecedent and consequent terms were not generated with the use of Pearson but were extracted with their method. The work reported in this paper extends this work in a number of different ways. Firstly, we prove that items participating in certain types of negative rules excludes them in participating in others. Secondly, we generate data synthetically and track the Precision and Recall of rules extracted. The use of synthetic data enabled us to deliberately inject relationships into the data, thus enabling us to study Precision and Recall. Thirdly, we analyse the scalability of rule generation time with parameters such as dataset size. 4. Mining interesting negative rules (MINR)
The basic philosophy behind the proposed method is the use of Fisher X  X  exact test in identifying itemsets that occur together with a statistically significant probability. Any itemset which has a support greater than the generated positive chance threshold is considered to be a candidate for positive rule generation, whereas any itemset which has a support less than the generated negative chance threshold is considered to be a candidate for negative rule generation. These itemsets are considered to be potentially interesting. The calculations of these thresholds were adapted from the minabssup method introduced by Koh et al. [16]. 4.1. Effect of noise on rule generation
Noise is a major factor in generating negative rules as a given item may occur in the absence of another item purely by chance and if this combination were to happen with sufficient frequency then it would trigger an explosion in the number of rules generated, most of which would be trivial at best or unreliable at worst. In standard rule generation the use of the support measure helps to reduce the possibility of spurious rules being generated but in the case of negative association rule the support measure would not be effective as an item such X that occurs rarely will have high support in its complement  X  ( X ) . Furthermore,  X  ( X ) may occur frequently with another item Y, thus indicating a rule of the form  X  ( X )  X  Y , when in fact the joint occurrence of (  X  ( X ) ,Y ) is a chance one that is triggered by the presence of noise.

In order to eliminate such cases a rigorous method of assessing whether a given association occurs by chance or whether it indicates the existence of a strong and genuine relationship between the items involved. The exact Fisher test assesses the probability of chance collision between any given pair of items. Together with the use of a chance threshold, the Fisher test provides a rigorous and reliable method of noise removal.

In the case of missing data in attribute values a symbol can be used to flag that the value is unknown to distinguish from the case where the attribute value (item) simply does not occur in a given data instance. Such items will not be subjected to the Fisher exact test and hence will not be considered for rule generation. Values from the same attribute that are not missing will be subjected to the Fisher test as described earlier. 4.2. Chance threshold
We examine the probability of seeing two itemsets occurring together. For N transactions in which the antecedent A occurs in a transactions and consequent B occurs in b transactions, we can calculate the probability that A and B will occur together exactly c times by chance. This is known as the  X  X robability of chance collision. X  The probability is calculated as Pcc in Eq. (1) which is derived from Fisher X  X  exact test [14]. The probability that A and B will occur together exactly c times is: The chance threshold is calculated independently for each pair of candidate itemsets. Given Pcc in Eq. (1), we want the least number of collisions above which Pcc is larger than (1  X  p ) for a positive association, where p is a small value (usually 0 . 0001 ). That is:
Given Pcc in Eq. (3), we want the least number of collisions below which Pcc is larger than some small p-value (usually 0.0001) for a negative association. That is:
This amounts to inverting the usual sense of Fisher X  X  exact test. Usually a 2  X  2 contingency table is provided and a p-value calculated, however here we have in effect, three of the four values from the contingency table and a p-value, and are calculating the minimum value to complete the table. We use a chance threshold s , that allows us to identify itemsets that do not appear together by chance. For instance, Pcc ( c = 100 N = 10000 , | A | = 1000 , | B | = 1000) = 0.044. If the probability Pcc(count( AB )= s N, | A | , | B | ) 0.0001 and i = s unlikely that the candidate itemsets occur together by chance. Hence, the chance threshold is set to s .In this particular example, s is 135. In frequent itemset generation, by calculating the chance threshold for each pair of itemsets we are able to prune out itemsets that occur together due to coincidence. Candidate itemsets that appear together with a frequency greater than the chance threshold are considered to be candidates in a positive association.

Alternatively if the probability Pcc(count( AB )= s N, | A | , | B | ) 0.0001 and i = s i =0 Pcc ( s N, | A | , | B | ) 0.0001, and if count( AB ) s then AB is appearing less than chance would allow. Hence, the chance threshold is set to s . In this particular example, s is 68. Itemsets that appear together with a frequency lower than the chance threshold are considered to be candidates for generating negative association rules. 4.3. The MINR algorithm
In this section we investigate how the chance threshold is exploited in the MINR algorithm. Figure 1 illustrates how the candidate negative itemsets are identified with the help of these thresholds. On the first pass through the database, an inverted index is built using the unique items as keys and the transaction IDs as data. The inverted index is used to speed up the calculation of itemset support in the second and subsequent passes. Initially, the set of frequent itemsets is empty. After generating all frequent 1-itemsets, we iterate to find all k -itemsets, with k&gt; 1.
The ( k -1)-itemsets are extended in precisely the same manner as Apriori to generate candidate k -4} and {1, 3, 6} can be extended to form the 4-itemset {1, 3, 4, 6}, but {1, 3, 4} and {1, 2, 5} will not produce a 4-itemset due to their prefixes failing to match at the second item. Figures 2 and 3 contain the pseudo code for the calculation and satisfaction checks that are necessary for these thresholds.
Only pairs of candidate itemsets that are above the positive chance threshold for that itemset will be extended. Similarly, only candidate pairs that are below the negative chance threshold are considered during negative rule generation.

The use of the chance threshold allows us to construct itemsets through an objective measure of support whose value is tailored to each pair of itemsets. This allows us to dispense with a single user-defined support threshold which if set inappropriately may exclude rules of interest.

The chance threshold performs better compared to  X  correlation as a pruning method. Fisher X  X  exact test is known to perform better when datasets are unbalanced and when the itemsets have low frequency when compared to  X  correlation.

The rule generation process mirrors that of traditional association rule generation except that rules are divide into three categories. The three categories cover the various types of negative association rules that are possible. Table 1 illustrates these categories.
 All negative rules need to meet the confidence and lift thresholds. The latter threshold is set to 1. Before we discuss the overall rule generation process we need to establish some facts that constrain the way in which rules are generated.
 Theorem: if (X,Y) is involved in a Type 1 rule, whereby X  X  X  Y with Lift(X  X  X  Y ) &gt; 1 then  X  X  X  X  Y with Lift(  X  X  X  X  Y) &gt; 1 is not possible. In effect, the participation of X and Y in a Type 1 rule with Lift greater than 1 prevents the ( X,Y ) from participating in a Type 3 rule with Lift factor greater than 1.
 Proof: We use the Lift metric to establish this result.
 Proof: Since ( X,Y ) defines a Type 1 rule it follows from the Lift threshold satisfaction that Now suppose that ( X,Y ) is also involved in a Type 3 rule. Applying the Lift constraint once again we have: Combining Eqs (4) and (5) gives: .

Since supp ( X,  X  Y )+ supp (  X  X,  X  Y )= supp (  X  Y ) , we have: supp (  X  Y ) &gt; supp (  X  Y )( supp ( X )+ supp (  X  X )) Now supp ( X )+ supp (  X  X )=1 , thus giving supp (  X  Y ) &gt; supp (  X  Y ) which is impossible. Thus our original assumption of simultaneous membership for Type 1 and Type 3 must be in error and this proves the result.

A similar proof holds on Type 2 and Type 3 membership. For a Type 2 rule we have: supp (  X  X,Y ) &gt; We can thus conclude that membership of Type 1 or Type 2 is mutually exclusive to Type 3 rules. We now summarise the rule generation procedure in Fig. 4.
 5. Results and discussion
In this section, we discuss the results from the experiments carried out to evaluate the performance of our algorithm. We tested our algorithm using both real and synthetic datasets. 5.1. Experiments using real datasets
In this section, we compare the performances of the MINR algorithm based on pruning with the chance threshold with a rule generator based on Pearson X  X   X  correlation [14]. Eight different datasets from the UCI Machine Learning Repository [17] where chosen as shown in Table 2. We chose these datasets because they contain categorical attributes, thus eliminating any contaminating effect from pre-processing.
Table 3 displays the results of running MINR using minimum confidence of 0.95. We only report on the negative association rules generated by both methods. Each row of the table represents an attempt to find rules from the database named in the left-most column. Passes represents the number of extensions to the candidate itemset ( e.g. , passes is 2 when the candidate 2-itemsets are generated). Average negative itemsets is the average number of negative itemsets appearing in a rule. In the experiments, minconf is set to 0.95. We tracked the time needed to generate all the itemsets and rules. Note that the rules are divided into three different types. Type 1 represents rules which are of the form of X  X  X  Y ,whereas Type 2 rules are of the form  X  X  X  Y . Type 3 represents rules which are of the form  X  X  X  X  Y .
In terms of generating positive rules we used Cohen X  X  guideline [14] to decide whether a pair of item-sets (X,Y), is strongly or moderately correlated with each other. With respect to negative association rules we used the inverse ranges, i.e. a correlation value less than  X  0.5 signalling a strong negative cor-relation, whereas a value greater than  X  0.5 but less than  X  0.3 denoting a moderate negative correlation.
Table 3 displays the results generated based on Pearson X  X   X  correlation using minimum confidence 0.95. We generated two sets of results using the threshold value  X  0.3,  X  0.5, and  X  0.70. From the results in Table 3, it is evident that pruning with chance threshold results in less rules on the average than with Pearson X  X  correlation at the 0.3 threshold. When we increased the Pearson correlation threshold to 0.5 there were fewer Type 1 and Type 2 rules found by Pearson X  X  than with the MINR algorithm. We then increased the Pearson correlation threshold to 0.7. We noticed that three of the eight datasets were not able to produce any Type 1 or 2 rules. Overall we notice that the MINR algorithm generated less Type 3 rules than Pearson X  X  correlation. This is due to MINR setting a stricter threshold than Pearson on rule generation. To make sense of the rules produced by the chance and Pearson thresholds, we chose to analyse three datasets in depth: Zoo, Hepatitis, and Soybean-Large in greater depth. Due to the numerous rules generated, we chose to only analyse the top ten rules ranked by additional measures, Cosine and Jaccard.

From our implementation based on the Zoo dataset using chance threshold we were able to find the 142 rules. Table 4 shows the top ten rules found. Each rule in the table has a Support, Confidence, Lift, Cosine, and Jaccard value, and the rule type. From Table 4 we notice that these ten rules cover only the Type 1 and 2 categories. In general, MINR produces lesser Type 3 rules than Pearson at the  X  0.3 and  X  0.5 thresholds across all dataset that we experimented with.

Using the Pearson threshold at  X  0.3 level resulted in 477 rules. Table 5 shows the top ten rules pro-duced from the Zoo dataset. Note that the first eight rules found using Pearson was also detected by MINR. The last two rules which were Type 3 rules were not found by MINR. These two rules are indeed not interesting. Both items {name = scorpion} and {name = octopus} occurred once in the dataset. The item {leg = 8} occurred twice within the dataset. While an asociation rule does not imply causality between antecedent and consequent items, weak rules involving items such as {leg = 8} rule out the possibility of causality and involving Type 3 rules from such items does not bring any additional value to the set of rules. Despite this, all four interest measures in the table indicates that it is an interesting rule. Table 5 also exposes the limitations of using correlation to identify negative associations. The cor-relation between fins = 0 and type = 4 was not sufficiently negative in strength to trigger the generation of Type 1 and Type 2 rules. On the other hand MINR identifies that the low number of occurrences of the pair is sufficient to exclude the possibility of chance occurrence and generates the appropriate Type 1 and Type 2 rules.

In the second experiment we chose to test both the chance and Pearson threshold in a larger dataset, namely Hepatitis. From the Hepatitis dataset MINR was able to generate 27 rules. Table 6 shows the top ten rules produced.

When comparing these rules with the top ten rules produced by the Pearson threshold at the  X  0.3 level in Table 7, we notice that the values produced by the support, confidence, Cosine, and Jaccard measures on average are higher with Pearson. However when analysed closely we note that all of the rules produced by Pearson are of Type 3. Furthermore, the rules themselves cannot be considered strong as the consequent itemset occurs just once (in its positive form) in a dataset containing 155 transactions. These rules thus cannot be used to establish causality and therefore do not provide any value. The Pearson rule generator produced 1349 rules, out of which a very large majority (97.6 %) are of Type 3. On the other hand the Fisher test ensures that such trivial Type 3 rules are not generated with MINR. However MINR avoids these spurious Type 3 rules. In section 4.2 we provide further empirical evidence of the vulnerability of Pearson towards spurious Type 3 rules.

We also note that the Top 10 rules generated had only a few instances of multiple terms for Pearson and no cases involving multiple terms for MINR. It should be noted that both methods do have the capability of generating rules with multiple terms and there were many instances of such rules in their respective rule bases. In general, such rules tend to have relatively low support and hence do not appear in MinR X  X  top 10 list which was ranked in descending order of support.

When we tested the algorithms on the Soybean-Large dataset we noticed that we were able to generate 633 rules with MINR and 2158 rules with Pearson at the  X  0.3 threshold level. Once again, the large majority of rules (1899 out of 2158) generated by Pearson were of Type 3. Tables 8 and 9 shows the top ten rules produced by chance and Pearson respectively. Notice that all the top ten rules generated by Pearson are once again of Type 3. These rules all have the same properties of the trivial rules found in the previous two datasets. However, the problem is of a much higher scale for this dataset in comparison to the others tested earlier.
 From these expeeriments we observe that Pearson produces a much higher number of Type 3 rules. However many of these rules turn out to be trivial. This problem becomes extreme when such rules are highly ranked according to the commonly used metrics such as Confidence, Lift, etc. In a real-world scenario where decision makers tend to focus on the TopN rules as a pragmatic method of overcoming an overwhelming number of rules, the appearance of a relatively large number of these spurious rules is bound to be adversely affect the decision making process. In this respect, MINR performs much better as it filters such rules through the use of the Fisher test.

One problem that Pearson X  X   X  correlation faces is that the greater the difference between the support of the two itemsets analysed, the smaller the possible maximum correlation value becomes [18]. We note that the significance of  X  correlation is the same as chi-square.  X  correlation tends to understate asymmetric relationships and is very sensitive to shifts in marginal distributions.

In the next section we test both MINR and Pearson  X  correlation on a family of synthetic datasets. We analyse the rules produced by comparing them to the set of rules deliberately injected into the dataset. 5.2. Synthetic dataset generator
To assess the performance of our algorithm in discovering negative rules, we used a modified version of the data generator proposed by Agrawal and Srikant [2]. Our use of synthetic data was motivated by two factors: Firstly, the ability t o track preci sion and recall by del iberately i njecting a rule base. Secondly, the level of noise could be controlled and kept to a minimum.
 We generated Type 1 rules, such as A  X  X  B , by including a constraint which generates rare itemsets. In this particular constraint two different itemsets are mapped to each other. If an itemset appears within a transaction, the mapped itemset would not be allowed into the transaction. However to ensure that it would be effective with noise, we included a corruption level. The corruption level is set to value close to 1.0. We generate a random sampling index which is between 0 and 1.0. If the random sampling index is below a corruption level we include both itemsets in the transaction. Type 2 rules, such as  X  A  X  B , were generated by changing the weighting assigned to negative itemsets. The weighting of one of the two itemsets used in generating Type 1 rules was doubled. This is to ensure that the particular itemset would at least appear half as much as the other. In these experiments we have refrained from injecting any Type 3 rules in order to test the false positive rate of detection of Type 3 rules. Despite this, it is clear from the results that we present that Pearson mistakenly identifies Type 3 rules.

Table 10 summarises the characteristics of several of the datasets generated during our tests. To create a dataset D , our synthetic data generation program takes the following parameters: number of transactions number of negative itemsets | N | .

We first determine the size of the next transaction, which is generated using a Poisson distribution whose mean is the average size of the transaction. We then fill the transactions with items. Each transac-tion is assigned a series of potential frequent itemsets and/or a negative itemset. Each itemset in T has a weight associated with it, which corresponds to the probability that this itemset will be picked. Random items are also injected into the transactions. These items are treated as noise and should be pruned out by the association rule mining algorithm.

We attempt to quantify the accuracy of mined association r ules based on t he ability of our algorithm to derive a known set of association rules. To measure the performance of our algorithm, we use two stan-dard Information Retrieval measures, precision and recall . Precision and Recall are the basic measures used in evaluating search strategies [19].
 Precision refers to the ratio of the number of relevant rules found to the total number of rules found. Recall is the ratio of the number of relevant rules found to the total number of relevant rules in the database. Here relevant refers to rules where itemsets are strongly associated, whereas irrelevant refers to rules with itemsets which are not strongly associated. The relevant rules found are considered true-positive cases, the irrelevant rules found are considered false-positive cases, and the relevant rules that were not found are considered false-negative cases. Both of these measures are defined as a proportion in the range [0,1]. In order to compute these evaluation metrics, we must have prior knowledge of rules that are correct, rules that are incorrect, and the total number of rules that exist within the dataset.
It makes sense to use Precision and Recall because we are able to deliberately inject rules and all other rules thus detected by the algorithms are quite literally random. Hence, we would be able to evaluate the results produced by using Apriori with pruning. If we were to run standard Apriori on the dataset, with support set to 1 N , where N is the number of transactions we would definitely be able to detect all the rules that were injected and the Recall would be 1. However, the execution time would be prohibitive in view of the extremely low support threshold. Furthermore, rule Precision value would be very low in view of the large number of irrelevant rules found. To test the accuracy of chance threshold we generated synthetic data in which we injected a known number of itemsets into the dataset. We checked the rules generated from the datasets against the list of injected rules. If a rule exists within the list of known rules, it is considered to be a relevant rule, whereas if the rule is not contained within the set of predetermined rules, it is considered an irrelevant. Our experimentation on synthetic data revolved around two parameters of importance which we controlled. The first factor was the influence of the number of negative itemsets on the Precision and Recall measures. In practice, real world datasets differ in the number of negative itemsets that they contain. Ideally an association miner should perform equally well no matter how many negative itemsets are present in the dataset. Secondly, we wanted to test the ability of each of the two algorithms to deal with long itemsets (i.e. composite itemsets containing many items). This is important as some rules are inherently complex, consisting of a large number of negative items either in their antecedent or consequent. 5.3. Effect of the number of itemsets on performance
This experiment was designed to determine sensitivity of MINR and Pearson  X  correlation on the number of itemsets in a dataset. For each value of the number of itemsets parameter we generated ten different versions of datasets with different seed values for random generation. The average of the results from the 10 different runs are presented below. Figure 5(a) shows the Precision and Fig. 5(b)shows the Recall from the experiments with different number of negative itemsets.

In the first experiment we vary the number of negative itemsets. In this particular family of datasets, we varied the number of negative itemsets injected into the data from 2 to 20 with an interval size of 2 for the T30.L50.D10K datasets. Figure 5(a) clearly shows that the Precision for Pearson is consistently lower than that of MINR. A close examination of the detailed results revealed that the underlying cause for the low Precision was Pearson X  X  tendency to include spurious Type 3 rules. Figure 5(b) shows that in terms of the Recall metric, Pearson fares better, its Recall values are on par with MINR.
 Given that the two approaches perform similarly on Recall, we need to examine the significance of Pearson X  X  relatively poor performance on Precision. In a real-world context Precision assumes more im-portance than Recall. For decision makers to place faith in the rules generated, accuracy is of prime im-portance. Since Precision reflects accuracy it follows that a rule generator should exhibit a very high level of Precision no matter how many negative itemsets are present in the transaction database. Therefore, these experiments clearly show that MINR outperforms Pearson as a negative itemset rule generator. 5.4. Effect of itemset length on performance
In the next set of experiments we varied the size (or length) of the negative itemsets. The size of the negative itemsets injected into the data was varied from 1 to 5 with an interval of 1 for the T30.L50.N10.D10K family of datasets. Figure 6(a) shows that the Precision and Recall for MINR is very high and stable throughout the size range that we tested. As the number of items comprising an itemset increases, there is a natural tendency for the support of the composite itemset to decrease. In the case of MINR the Fisher test is sensitive enough to distinguish between coincidental co-occurrences and those that occur due to a genuine associative relationship.

Figure 6(b) shows that both Precision and Recall peak at a size of 2 for Pearson and thereafter fall sharply as the size increases to 3 while dropping to zero at a size of 4. Note that when the average size increases to 3, the overall support of each of the itemsets reduces as the size of a transaction is fixed. This is due to the nature of the datasets produced when the average itemset size is increased. When the average itemset size is 3 and the support of the items involved in an itemset falls below 0.30, any composite itemsets comprising of 3 or more items will have very low support. In such cases the  X  correlation value never goes below  X  0.3, and thus Pearson does not generate any rules at all, resulting in both zero Precision and zero Recall.

We next reduced the number of large itemsets to 30 and the number of negative itemsets to 5. We then varied the size of the negative itemsets from 1 to 5 with an interval of 1 for the T30.L30.N5.D10K datasets. Figure reffig:avgsize1 shows similar trends to the previous experiment. The Precision value for MINR is insensitive to itemset size. With respect to Recall, MINR starts off at a relatively low value of around 0.55 for a size of 1 but then quickly rises to a high value of around 0.9 at size 2 and stabilises thereafter. With respect to Pearson, both pr ecision and recal l fall sharply at size 5. Basically, the underlying cause is the same as in the previous experiment, except that the sharp drop takes place at a slightly higher value of size as the pool of negative itemsets is smaller (5, rather than 10) causing the support of each of the items forming the composite itemset to be relatively higher than with a larger pool. However, at size 5 we note that the support for the individual negative items had fallen below 0.41, thus reducing relatively large composite itemsets to have too low a support value to trigger the Pearson rule generator. These experiments have demonstrated that Pearson correlation cannot handle cases when itemsets are particularly rare.

The use of Pearson X  X   X  correlation involves the setting of an arbitrary threshold. Setting this particular threshold is problematic, if the threshold is set too low, it no longer filters uninteresting rules but if set too high then we may end up pruning some useful rules. The dilemma faced by the user is to avoid over pruning while ensuring that useful rules are generated. Resolving this dilemma requires the user to experiment with different values of the Pearson X  X   X  coefficient and to perform a comparative analysis of the results to identify an optimum value for the correlation threshold. The latter value is also likely to be domain dependent, thus further compounding the difficulty of mining.
 5.5. Scalability study
This experiment was designed to evaluate the runtime of MINR and Pearson  X  correlationwhenthe size of the transaction varied. We varied the size of the transaction and recorded the runtime for each of the datasets.
 Figure 8 shows that MINR scales much better than Pearson with dataset size. Although the curve for Pearson starts at a slightly lower level than MINR, the run time for Pearson grows at a much higher rate than MINR. MINR scales better because of the stricter control on the growth of candidate itemsets through the use of the Fisher test. Pearson, on the other hand generates a much higher number of candi-dates as it does not eliminate items that occur together purely by chance and this explains its higher run time overhead.

The use of Pearson X  X   X  correlation involves the setting of an arbitrary threshold. Setting this particular threshold is problematic, if the threshold is set too low, it no longer filters uninteresting rules but if set too high then we may end up pruning some useful rules. The dilemma faced by the user is to avoid over pruning while ensuring that useful rules are generated. Resolving this dilemma requires the user to experiment with different values of the Pearson X  X   X  coefficient and to perform a comparative analysis of the results to identify an optimum value for the correlation threshold. The latter value is also likely to be domain dependent, thus further compounding the difficulty of mining. 6. Conclusion
Negative association rules are harder to generate as extra measures are required to ensure that only meaningful rules are generated. Most of the research carried out in this area requires some form of arbitrary threshold to be fixed on the dataset. In this paper, we introduce the MINR algorithm that generates negative association rules without the need to set a user defined threshold. We compared the results produced by our implementation against Pearson X  X   X  correlation. On average MINR produces a more concise set of rules than Pearson X  X   X  correlation. We also note that  X  correlation has problems dealing with datasets where there is a wide variation in support amongst the itemsets, while the MINR algorithm does not suffer from this problem.

The MINR algorithm turns out to have some very desirable properties. It shows excellent performance with respect to important information retrieval metrics such as Precision and Recall. Furthermore its performance is insensitive to both the number of negative itemsets and the size of itemsets involved in rules. The latter property means that it is able to generate rules with a large number of terms thus making it applicable to scenarios where complex rules exist.
 References
