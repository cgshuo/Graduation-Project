 This paper describes a prototype that predicts the shopping lists for customers in a retail store. The shopping list predic-tion is one aspect of a larger system we have developed for retailers to provide individual and personalized interactions with customers as they navigate through the retail store. In-stead of using traditional personalization approaches, such as clustering or segmentation, we learn separate classi ers for each customer from historical transactional data. This allows us to make very ne-grained and accurate predictions about what items a particular individual customer will buy on a given shopping trip.

We formally frame the shopping list prediction as a classi-cation problem, describe the algorithms and methodology behind our system, its impact on the business case in which we frame it, and explore some of the properties of the data source that make it an interesting testbed for KDD algo-rithms. Our results show that we can predict a shopper's shopping list with high levels of accuracy, precision, and re-call. We believe that this work impacts both the data mining and the retail business community. The formulation of shop-ping list prediction as a machine learning problem results in algorithms that should be useful beyond retail shopping list prediction. For retailers, the result is not only a practical system that increases revenues by up to 11%, but also en-hances customer experience and loyalty by giving them the tools to individually interact with customers and anticipate their needs.
 H.2.8 [ Database Management ]: Database Applications| Data Mining Design, Experimentation Applications, Machine learning, Classi cation, POS Data
Retailers have been collecting large quantities of point-of-sale data in many di erent industries. One area that has been particularly active in terms of collecting this type of data is grocery retailing. Loyalty card programs at many grocery chains have resulted in the capture of millions of transactions and purchases directly associated with the cus-tomers making them.

Despite this wealth of data, the perception in the grocery industry is that this data has been of little use. The data collection systems have been place for several years but sys-tems to make sense of this data and create actionable results have not been very successful. This is not to say that there has been no work attempted on retail transaction data. Re-search in mining association rules [3] has led to methods to optimize product assortments within a store by mining fre-quent itemsets from basket data [6]. Customer segmentation has been used with basket analysis in the direct marketing industry for many years to determine which customers to send mailers to. Additionally, a line of research based on marketing techniques developed by Ehrenberg [9] seeks to use a purchase incidence model with anonymous data in a collaborative ltering setting [10].

Traditionally, most of the data mining work using retail transaction data has focused on approaches that use cluster-ing or segmentation strategies. Each customer is \pro led" based on other \similar" customers and placed in one (or more ) clusters. This is usually done to overcome the data sparseness problem and results in systems that are able to overcome the variance in the shopping behaviors of individ-ual customers, while losing precision on any one customer. We believe that given the massive amounts of data being captured, and the relative high shopping frequency of a gro-cery store customer, we can develop individual consumer models that are based on only a single customer's historical data. Our hypothesis is that by utilizing the detailed trans-action records to build separate classi ers for every unique customer, we can improve on the performance of clustering and segmentation approaches.

A major reason that individually targeted applications have not been more prominent in retail data mining research is that in the past there has been no individual channel to the customer for brick &amp; mortar retailers. Direct mail is coarse-grained and not very e ective as it requires the at-tention of customers at times when they are not shopping and may not be actively thinking about what they need. Coupon based initiatives given at checkout-time are seen as irrelevant as they can only be delivered after the point of sale. However with the advent of PDA's and shopping cart mounted displays such as the model Symbol Technologies is piloting with a New England grocer [1], retailers are in a position now to deliver personalized information to each customer at several points in the store.
 In fact, a few systems of this sort have been developed. For example the IBM Easi-Order system [4] and a system developed at Georgia Tech [13] use PDA's to display per-sonalized grocery information to each shopper before, and during their shopping trips. In the rst system, a list is rst developed on the PDA, then sent to the store to be compiled and picked up. In the second, the PDA was used as an aide during the shopping trip to show locations and information on items in a list. In each, the shopping list was emphasized as the essential artifact of a grocery trip, enabling all other interactions. Both also stated as a de-sign goal that it should be possible to compile or augment a shopping list per customer based on previous purchase his-tory. The 1:1Pro system described in [2] was designed to produce individual pro les of customer behavior in the form of sets of association rules for each customer which could then be restricted by a human expert. Theoretically these pro les could then be used to develop personalized promo-tions and predict certain purchases. However, nowhere has there been a thorough experimental attempt to predict and evaluate customer grocery shopping lists from transactional data with a large set of customers.

We present our shopping list predictor as an integral part of a larger system targeted at presenting personalized in-formation to a customer in a retail setting. Our Shopping Assistant system uses the list as a starting point for inter-acting with the customer. Instead of promoting random products, we uses the items on the predicted list to deliver personalized promotions.

The work presented in this paper uses machine learning techniques to predict and populate a shopping list for each customer, on the day they visit the store. We use two years of customer purchase data from a major grocery chain and train classi ers for each customer in our data set. When a particular customer enters the store, they identify them-selves (through a loyalty card, for example) to a shopping cart-mounted display device (see Fig. 1). The predicted shopping list is then presented to the customer on the dis-play as the \suggested" list. Since the number of items an average person buys in a grocery trip can be large, we only show the entire list at the beginning of the trip. From that point on, the device can detect which aisle the customer is in and only show them items that are in their list in that particular aisle. While the main rationale behind this task remains to provide the convenience and personalized service that a customer should expect in return for their personal information, we view it in the wider context of di erentiat-ing and improving business for the retailer. By suggesting a realistic shopping list for a customer, we remind them of purchases that might otherwise be forgotten. These sug-gestions translate into recovered revenues for the store that might otherwise be transferred to a competitor, or foregone as the customer goes without the item until the next trip. Figure 1: Cart-mounted display device used in our prototype.

The remainder of the paper is organized as follows: Sec. 2 describes the way in which we frame shopping list predic-tion as a classi cation problem, along with the criteria for success and organization of the datasource. Sec. 3 describes the results of the classi cation experiments using the loyalty card data from a grocery store chain. Sec. 4 discusses the implications the experimental results in the context of our larger system and possible directions for future research on this topic. In Sec. 5 we conclude.
This section explains the methodology behind our shop-ping list predictor, as well as the evaluation criteria we use to judge its success. In order to de ne the problem of grocery shopping list prediction in a rigorous way, we rst introduce some terms and explain their meanings.

We de ne a set C of customers, a set T of transactions made by those customers, and a xed set P of product cat-egories bought by these customers equivalent to those nor-mally used on shopping lists. Within T and P we de ne for each c 2 C sets T c T and P c P , consisting of the trans-actions of each customer c and the product categories bought by customer c respectively. For each transaction t 2 T c our task then becomes to output a vector y 2f 0 ; 1 g j P c j y = 1 if for a given order of all categories in P c , customer c bought p i 2 P c in transaction t , and where y i = 0 if customer c did not buy p i . We can then formulate the overall problem as j P c j binary classi cation problems for each customer and derive a separate classi er for each. We experimented with many di erent types of methods.
We present some baseline methods to predict customer shopping lists that we can hopefully improve on using data mining techniques.
The most basic baseline we use is random guessing. In this scheme for each transaction of a given customer, we output a prediction vector y 0 where each y 0 i is equal to 0 or 1 with an equal probability. This results in a method where every category that the customer has purchased before has 50% chance of being included in the shopping list.
The next baseline method just produces a shopping list that consists of products bought in their previous shopping trip. To de ne it more formally, let us impose an ordering on the set T c for each customer c corresponding to the temporal sequence of each transaction. Then for each transaction t we output a prediction vector y 0 equal to the purchase vector seen for transaction t k 1 . Let this method be called the same as last trip predictor.
Finally we describe an approach we call the top n method, where we aggregate all the transactions of the given cus-tomer, and select the top n products from their history as their current shopping list, ranked by the quantity/frequency of purchase. We de ne a new ordering on the set P c for each customer, corresponding to the frequency with which each category is purchased within T c . Speci cally for each p 2 P c let f req ( p i ) = P each transaction t , outputs a vector y 0 for which the values corresponding to the top n categories in P c as ordered by f req are valued 1, with all else valued 0. A variation on this method would be to only use the past m transactions to create the Top N list which might account for some of the temporal changes a customer might exhibit.
The second group of approaches we experiment with are all machine learning classi cation methods. As mentioned before, the problem of predicting the overall assortment of categories purchased y can be broken down into j P c j individ-ual binary classi cations. Each class can be thought of as a customer and product category pair. If our data set consists of j C j customers and an average of q categories bought by each customer, we construct j C j q classes (and as many binary classi ers). For each of these classes y i , a classi er is trained in the supervised learning paradigm to predict whether that category will be bought by that customer in that particular transaction. Here we present a series of ex-amples of the form ( x; y i ), where x is a vector in &lt; n , encoding features of a transaction t , with y i 2f 0 ; 1 g representing the label for each example ( i.e. whether the category corresponding to y i was bought or not).
We experimented with two kinds of machine learning meth-ods to perform this task. First we trained decision trees (speci cally using C4.5 [14]) to predict each class label. Next we tried several linear methods (Perceptron[15], Winnow[11], and Naive Bayes) to learn each class . These linear meth-ods o er several advantages in a real-world setting, most notably the quick evaluation of generated hypotheses and their ability to be trained in an on-line fashion.
In each case, a feature extraction step preceded the learn-ing phase. Information about each transaction t is encoded as a vector in &lt; n . For each transaction, we include proper-ties of the current visit to the store, as well as information about the local history before that date in terms of data about the previous 4 transactions. The assumption here is that examples and their labels are not independent, and that we can model this dependence implicitly by including information about the previous visits. This tactic is simi-lar to methods in Natural Language Processing (NLP) for tasks such as part-of-speech tagging, where tags of preceding words are used as features to predict the current tag [16].
The features we include in example ( x j ; y j i ) about trans-action t j are: 1. Number of days at t j since product category was p i 2. Frequency of interval at t j . For each category p 3. The interval range that the current purchase falls into. 4. Day of the week of the current trip. 5. Time of the day for the current trip broken down into 6. Month of the year for the current trip. 7. Quarter of the year for the current trip.

We also include all of the above attributes for the pre-vious 4 transactions, t j 1 ; t j 2 ; t j 3 ; t j 4 in ( x tionally we include four additional features with respect to each transaction in the local history. These are: 1. Whether category p i was bought in this transaction. 2. The total amount spent in this transaction. 3. The total number of items bought in this transaction. 4. The total discount received in this transaction.
Note that the previous 4 features are only used for the local history of the current transaction and not for the cur-rent transaction itself. Since we are predicting the products bought for the current transaction when the customer enters the store, we obviously do not have access to these features.
In the case of the decision tree learners, the above is the entire set of features used. For the set of linear classi -cation methods we utilized, it is often dicult to learn a linear separator function using a relatively low-dimensional feature space such as we have constructed. By combining basic features, e ectively increasing the dimensionality of each example vector x , we increase the chance of learning a linear function that separates all the positive and nega-tive examples presented. Once again this tactic is similar to those used to learn classi ers in NLP contexts where com-binations of words such as bi-grams and tri-grams are used as features in addition to the basic words.

Therefore for the linear methods, several combinations of the basic features listed above were added to each example to improve learnability. For each numbered feature type above, we combine it with those of the same type in the customer's previous four transactions (local history). For example, fea-ture 4 ( day of the week for the current transaction) is com-bined with feature 4 of the previous transaction to produce a new feature. For the set-valued feature types above such as 4, boolean features are instantiated for each value ( eg one feature per day). The combinations of these features used are simple boolean conjunctions. For the feature types corresponding to continuous valued attributes such as 2, we create a single real valued feature. To create combinations of these features we use a non-linear transformation.
The nal set of methods explored in our experiments took the form of several hybrid methods. As we mention below, due to the large number of output classes we are trying to predict over all customers, we would like to evaluate the performance of our prediction strategies in aggregate with a single measure. However, as we treat each class as inde-pendent of each other for a given transaction (a simplifying albeit untrue assumption), di erent classi cation methods can be used for di erent classes. This is our hybrid ap-proach. In the experiments, we combined the top n baseline classi er with the various learned classi ers in the following fashion. If the top n predictor (for given n ) is positive for a given class, then we predict positive, otherwise we predict according to the output of a given learned predictor.
The problem of predicting grocery shopping lists is an in-teresting learning problem because of the sheer number of classes that must be predicted. Abstracting from the prod-uct level (around 60,000 products) to the level of relatively speci c categories useful for grocery lists reduces this num-ber to some degree. However for real world datasets such as the one we explore in Sec. 3, this number could be from fty to a hundred classes per customer, with tens of thou-sands of regular customers per store, resulting in millions of classi cation categories and classi ers.

In general the metrics we use to judge the performance of our list predictors per class are the standard recall , precision , accuracy and f-measure quantities. For a set of test exam-ples, recall is de ned as the number of true positive predic-tions over the number of positive examples; precision is the number of true positive predictions over the total number of positive predictions; accuracy is the number of correct pre-dictions over the total number of examples; and f-measure is the harmonic mean of recall and precision : 2 recall precision
In obtaining an overall measure of performance by which we measure our success in predicting shopping lists for large groups of customers, there are many considerations to take into account. Typically in a learning scenario with a large number of output classes, the above quantities can be aggre-gated in several ways. Microaveraged results are obtained by aggregating the test examples from all classes together and evaluating each metric over the entire set. The alternative is to macroaverage the results, in which case we evaluate each metric over each class separately, and then average the results over all classes. The rst strategy tends to produce higher results than the second. When the number of classes is large and very unbalanced, the microaveraged results are implicitly dominated by the classes with a large number of examples, while the macroaveraged results are dominated by the smaller classes. Macroaveraging is intuitively more attractive for our purposes as it gives us an idea of how we are performing for the majority of customers rather than just those with a large number of transactions.

However, the transactional nature of the purchase data-source gives us additional methods to aggregate our results. One option is to aggregate all examples associated with a single customer, obtain results for the above metrics for each set, and average them. This approach lets us know how we are performing for the average customer . Although these aggregate sets are still unbalanced, given some customers shop more than others, the average results for this approach are generally between micro and macro-averaging. We call this customer averaging . The last type of aggregating we can do is on the transaction level. Here we aggregate all the examples from each transaction, calculate each metric, and average the results over all transactions. We call this method transaction averaging . This averaging technique is perhaps most attractive of all in light of its ability to gauge how many categories per trip predicted are bought, and how many bought per trip are predicted. However since it breaks up example sets within classes, it is dicult to compare this approach with the other aggregation techniques.
In this section we describe the results of our initial experi-ments predicting customer grocery shopping lists, using data for several thousand customers. The dataset used contains transaction based purchase data for over 150,000 customers from a grocery store collected over two years. From this overall set, 22,000 customers shopped between 20 and 300 times, which was judged to be the legitimate population for whom to predict lists. This population was sampled to pro-duce a dataset of 2200 customers with 146,000 associated transactions. Since the number of transactions for each cus-tomer follow a power law, uniform random sampling to select 10% of the customers would result in a sample skewed to-wards customers with a small number of transactions. In or-der to get a representative sample, we rst split the popula-tion into deciles along three attributes: total amount spent, set of deciles, 10% of the data was selected with uniform probability from each decile. The 10% samples obtained for each attribute were found to be statistically similar to the other two (details omitted), and the nal sample used was taken from total amount spent. The motivation be-hind working with a somewhat smaller working sampled set in our case is purely computational. As we are building classi ers for each &lt; customer, category &gt; individually, the running time to train and evaluate predictors scales linearly with the number of customers. By performing the type of strati ed sampling mentioned above, we preserve the wide variation in the quality of training data available to each in-dividual predictor, i.e. the number of examples and di erent purchasing behavior.

The transactional information present in the data includes the attributes described in the previous section and lists of products purchased in each transaction. Products are ar-ranged in a hierarchy of categories. At a fairly speci c level of this hierarchy, categories resemble grocery shopping list level items. Examples of these categories include: ched-dar cheese, dog food, sugar, laundry detergents, red wine, heavy cream, fat-free milk, tomatoes, etc . 551 categories are represented in the dataset forming the set P as de ned in Sec. 2. Customers within our sample bought 156 distinct categories on average (w/ standard deviation of 59). Of these categories, we restrict the set P c for each customer to include only the categories bought on greater or equal to 10% of their trips. This brings the average size of P c for a given c to 48 with standard deviation of 27.59.
For each transaction for the customers in the sample, ex-amples are constructed as detailed in Sec. 2. The datasets for each class 1 ranged from 4 to 240 examples. For each class in the resulting dataset, the example sets are split into a training set composed of the rst 80% of examples in tem-poral order, and a test set composed of the last 20%. We run the baseline methods only on the test sets for consistency in evaluation. For the top-n methods we chose a cuto of 10 categories. For the decision tree classi er, C4.5 was used with 25% pruning and default parameterization. For the lin-ear classi cation methods, the SNoW learning system was used [7]. SNoW is a general classi cation system incorpo-rating several linear classi ers in a uni ed framework. In the experiments shown, classi ers were trained with 2 runs over each training set.

Results are shown in Table 1 for each approach, broken down by the transaction and customer averaging methods mentioned in the previous section. Fig.2 (top) shows two graphs with the performance of the top-n method for dif-ferent values of n . For the linear classi cation methods, the activation values output by the classi er can be normalized to produce a con dence score for each class. We can then choose a di erent threshold than the one used in training to test the classi er's performance. In Fig.2 (bottom), we show the performance of the Winnow and Perceptron classi ers at di erent con dence thresholds. Activations are normalized to con dence values between -1 and +1, with the original training threshold mapped to 0.
As mentioned in Sec. 1, a major motivation for predicting shopping lists stems from the goal of reclaiming forgotten purchases. Of course the data collected does not include information on the instances in which categories are forgot-ten. A priori we would not like to make any assumptions about the instances in which forgetting has occurred. This artifact produces a data set that has noisy labels: examples where a customer \should" have bought a particular prod-uct, but forgot to do so, shows up as a negative example in our data. This not only creates noise in the training set (which can be overcome to some extent by robust learning algorithms), but also reduces the reported accuracy of our results. Examples where our system predicts an item is on the list are judged to be incorrect if the customer didn't buy that item (even if they forgot it). However, we would hope that the algorithms we examine should be somewhat robust to label noise as long as they are not over tting the data. In order to estimate this robustness and determine the value of our suggestions via reclaiming forgotten purchases, we make some assumptions about the distribution of these instances and correct noisy label values in the test data. By training on the noisy data and then evaluating on the corrected test data, we hope to see the number of true positive predictions go up without a serious increase in false negatives. &lt; customer, product category &gt; pair random .20 .23 .20 .63 sameas .22 .29 .25 .66 top-10 .37 .36 .37 .65 Perceptron .42 .31 .36 .61 Winnow .16 .40 .23 .75 C4.5 .24 .42 .32 .73 Hybrid-Per .60 .32 .42 .54 Hybrid-Win .43 .41 .42 .65 Hybrid-C4.5 .46 .38 .42 .62 Table 2: Transaction averaged results from cor-rected label data.

The manner in which we estimate noisy labels in the test data to correct is described as follows. First, for each class p 2 P c for a given customer, we nd the mean and stan-dard deviation of the replenishment interval i . 2 Next, we identify examples for which i + c for di erent constants c . For each of these examples that have negative labels, we determine whether any example within a window of k following transactions is positive. We estimate each of these examples to be an instance of forgetting, with noisy negative labels.

To evaluate the robustness of our predictors to this noise, we ip each noisy (forgotten purchase) negative label to be positive, and re-evaluate each classi cation method on the modi ed test data. We show the results of this evaluation below in Table 2 for c = 1. 3 Here we show only the trans-action averaged results.
In this section we discuss the results of the experimen-tal evaluation and their implications for larger issues within machine learning and knowledge discovery.

Many of the results seen in Sec. 3 are promising in the con-text of predicting shopping lists for a large number of gro-cery customers. In terms of providing useful suggestions, we would like to obtain results that cover most of the items in a customer's potential shopping list (high recall) while not overloading the customer with a long list of non-relevant items (precision). As we see in the previous section, it is dicult to accurately predict over 50% of the bought cate-gories with a reasonable level of precision. Only the hybrid method combining the top 10 classi er with the Perceptron based classi er achieves this high level of recall.
In general each hybrid method performs much better than all the other methods. Each obtains a signi cantly higher level of recall than its individual component classi ers, with comparable levels of precision. We hypothesize the following scenario to explain this phenomenon.

Due to the wildly imbalanced training set sizes across classes both within and without customer groupings, many classes may contain very few positive examples. The base-line top-10 classi er gives us a basic level of recall across all classes regardless of the training set size, while the learned classi ers would very rarely produce true positives for these
Note that these moments exist without specifying a distri-bution over the replenishment interval.
This choice of cuto equates to a customer forgetting 11% of the product categories that they would otherwise buy on an average trip. random .19 .20 .19 .65 sameas .26 .26 .26 .70 top-10 .37 .35 .36 .59 Perceptron .38 .26 .31 .65 Winnow .17 .36 .23 .79 C4.5 .22 .34 .24 .77 Hybrid-Per .59 .28 .38 .53 Hybrid-Win .43 .36 .39 .65 Hybrid-C4.5 .46 .35 .40 .62 random .20 .19 .20 .65 sameas .25 .29 .27 .70 top-10 .41 .33 .37 .65 Perceptron .40 .27 .32 .66 Winnow .17 .38 .24 .79 C4.5 .25 .28 .26 .70 Hybrid-Per .60 .27 .37 .55 Hybrid-Win .44 .32 .37 .64 Hybrid-C4.5 .48 .34 .40 .62 classes. For classes with large training set sizes, using the learned classi ers gives us an advantage in terms of precision and accuracy. We can see this advantage by comparing the performance of the hybrid classi ers to the performance of the top-n classi er for higher values of n as seen in Fig. 3. This precision gain is important to only show the most rel-evant suggestions to the customer as they enter the store, as we have limited screen space and want to utilize it intel-ligently.

Given such an extremely large and imbalanced datasource, metaclassi cation approaches such as the simple hybrid tech-nique described, along with other metalearning methods current in KDD and machine learning, seem to be par-ticularly suited to prediction tasks involving transactional market basket data. One technique we intend to experi-ment with in future work to overcome the problem of data sparsity is the shrinkage approach detailed in [12]. In this line of work, a hierarchy is imposed over large numbers of classes, and statistics about groups of classes are used to smooth conditional probability estimations for classes with small numbers of datapoints. These smoothed condition-als can be used in likelihood maximization techniques such as Naive Bayes to improve the accuracy in predicting the subclasses.

The other major distinctive feature of the data source we use is its high degree of systematic (non-random) noise due to customers forgetting to buy items they intended to buy. Although in this work we do not attempt to modify the classi cation algorithms used to correct for this noise, it has been shown that linear classi ers such as Perceptron (with some modi cations) can learn from examples with la-bel noise [8, 5]. In practice linear classi ers are often able to learn well in the presence of classi cation noise. Based on the assumptions made about the distribution of forgot-ten purchases in the dataset, we can estimate the degree to which classi ers used in our experiments are robust to the label noise. For example, several of the algorithms exhibit enhanced precision when labels for instances of forgetting are manually ipped to become positive, while the random baseline technique performs the same. While the number of true positives do increase, not all the added positive ex-amples are classi ed correctly, so in some cases the overall recall decreases or remains constant. But in Table 3 we show the number of added positive examples \recaptured" by the di erent classi cation algorithms, suggesting a measure of their relative robustness. Here as in the earlier results, we estimate the forgetting using a constant c = 1 (as explained in Sec. 3), which results in 11% of each customer's pur-chases per transaction being forgotten. The total number of examples for which we ip labels from negative to positive throughout all test sets in this case is 47916. This number represents a relative upper bound for the amount of pur-chases we can recapture given our assumptions.

When the system we present in this paper is implemented in a retail store setting, we expect the noise in the new data collected to decrease. As the shopping list predictor is used regularly, the forgetting behavior of customers should take place less often as now they are reminded of purchases that would otherwise be forgotten. An interesting aspect to study in the future would be the e ects of such an implementation and how the reduction in noise a ects each classi er. In general, we believe that deploying data mining systems may result in changes to the data that is being collected to train Table 3: Number of forgotten purchases recaptured. those systems and that this change can provide new chal-lenges and open problems for the data mining community
In this work we consider the dicult and useful problem of predicting customer purchase decisions from transaction based individual purchase history. This problem is interest-ing from the perspective of the KDD and machine learning community as a large-scale experimental application of well-known classi cation techniques, in a time-sequence domain with a high degree of systematic noise. From a business perspective the advent of technologies such as shopping cart mounted displays o ers us a unique opportunity to apply personalization techniques to present individually tailored information to customers as they shop. Using individual gro-cery purchase history, we predict shopping lists for a large set of customers of a major grocery chain. These lists are useful as a tool to build customer satisfaction, as well as a means of reclaiming otherwise forgotten purchases. Our calculations show that our shopping list prediction system can result in an increase of revenues for the store by up to 11%.

Additionally the shopping lists we provide become the ba-sis for a larger system for the delivery of individually relevant promotional strategies. We show that we can predict pur-chase categories with a high degree of recall per transaction and reasonable precision, and that given certain assump-tions about the distribution of forgotten purchases, we can reclaim many of these purchases. [1] Symbol Technologies Inc. http://www.symbol.com. [2] G. Adomavicius and A. Tuzhilin. Using data mining [3] R. Agrawal and R. Srikant. Fast algorithms for mining [4] R. Bellamy, J. Brezin, W. Kellogg, and J. Richards. [5] A. Blum, A. M. Frieze, R. Kannan, and S. Vempala. A [6] T. Brijs, G. Swinnen, K. Vanhoof, and G. Wets. Using [7] A. Carlson, C. Cumby, J. Rosen, and D. Roth. The [8] E. Cohen. Learning noisy perceptrons by a perceptron [9] A. Ehrenberg. Repeat-Buying: Facts, Theory, and [10] A. Geyer-Schulz, M. Hahsler, and M. Jahn. A [11] N. Littlestone. Learning quickly when irrelevant [12] A. K. McCallum, R. Rosenfeld, T. M. Mitchell, and [13] E. Newcomb, T. Pashley, and J. Stasko. Mobile [14] J. R. Quinlan. C4.5: Programs for Machine Learning . [15] F. Rosenblatt. The perceptron: A probabilistic model [16] D. Roth. Learning in natural language. In Proc. of the
