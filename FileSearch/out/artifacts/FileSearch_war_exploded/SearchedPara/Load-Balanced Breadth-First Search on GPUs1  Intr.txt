 Graph algorithms are becoming increasingly important, with applications rang-ing from web link analysis to computer-aided design to machine learning. Breadth-first search (BFS) is an important low-level operation that serves as a fundamental building block for more complicated graph algorithms. Thus efficient paralleliza-tion of BFS has gained much attention.

Unfortunately, exploiting the nested parallelism in BFS is challenging. As-signing the workloads to each thread evenly is non-trivial because the work distribution patterns are determined by the structure of the input graph.
Modern GPUs have become popular general computing devices due to their high memory and computational throughput, low costs and power efficiency. However, accelerating BFS on GPUs requ ires much more attention. The wide SIMD architecture of GPUs is particularly sensitive to load imbalance [3]. Inad-equate handling of this issue can lead to a significant performance hit.
Prior work has proposed several parallelization approaches [7,8,10,11]. They mainly rely on overlapped execution of massive amount of threads, local reorga-nization of workloads and work stealing to limit load imbalance to some extent. However, none of them eliminates this issue in general.

In this paper, we present a load-balanced GPU BFS algorithm, which decou-ples each BFS iteration into two phases: work redistribution and neighbor gath-ering. Work redistribution phase serves as a preprocessing operation, employing a parallel expansion to reorganize the nested and irregular workloads of a BFS iteration. Neighbor gathering phase then subsequently assigns the workloads to threads uniformly and visits each neighbor in a load-balanced way.
Specifically, we make the following contributions:  X  We propose a load-balanced GPU BFS algorithm. To the best of our knowl- X  We analyze the coupling possibilities between different phases of the algo- X  Our approach delivers great performance on a wide diversity of real-world In this section, we first introduce some unique properties of GPU architecture. Then we review existing BFS algorithms on GPUs and motivate our approach. 2.1 Modern GPU Architecture In order to deliver high computational throughput, modern GPUs adopt a wide SIMD architecture[3], meaning threads within a warp execute the same instruc-tions synchronously. Control flow divergence among these threads will result in serialization of different execution paths. Warps are grouped into cooperative thread arrays (or CTAs). Threads within a CTA can communicate through a lo-cal shared memory , and GPU hardware treats the CTA as the unit of scheduling. A program running on the GPU is called a kernel .
 This hierarchical model introduces seve ral types of workload imbalance. The SIMD execution within a warp will cause thread load imbalance and under-utilization if control flow diverges. Within a CTA, the warp with the highest workload will cause other completed warps to sit idle and prevent the comple-tion of the CTA, which in turn will prevent other CTAs in the wait queue from being scheduled. Likewise, few CTAs taking too much time to complete can ex-tend the completion time of the kernel. Figure 1 illustrates these three types of workload imbalance.
 Algorithm 1. Linear-work parallel BFS 2.2 Existing BFS Algorithms on GPUs Given a source vertex v 0 , the BFS process traverses the vertices in breath-first order and label each vertex with its distance from v 0 . Other variants of BFS may record other attributes such as the parent of each vertex.

Earlier GPU BFS research mainly focuses on work-inefficient parallelization [7,8] which has quadratic work complexity ( O ( n 2 + m )or O ( mn ), n and m represent the vertex and edge numbers, res pectively). Luo et al. [10] present the first linear work BFS ( O ( m + n )) and achieve much better performance. In this paper, we will focus on wor k-efficient algorithms.

The skeleton of the linear-work BFS algorithm on the GPU is similar to the standard serial BFS on the CPU [9], which is listed as Algorithm 1. On each iteration, vertices are taken out of the input queue, and their neighbors are visited and inserted into the output queue for next iteration. However, there are two main differences between CPU and GPU BFS algorithms, which are also the main challenges of GPU BFS:
Parallel neighbor gathering . The neighbor gathering process read in all the neighbors of the input vertices. Both the vertices in the input queue and all the neighbors of a vertex are independent of each other so there is sufficient parallelism to exploit. However this nested and irregular loop structure makes the parallelization difficult. A poor mapping strategy between threads and vertices will suffer from severe workload imbalance.

Status lookup . When inspecting the neighbors, they need to be checked to see if they have already been visited. This often results in many costly random accesses to the dist array. An effective optimization is to add a status lookup process and use a bitmap array to check the status, leading to reduced global memory overhead and improved cache hit rate.

We will focus on the neighbor gathering process, as it is where load imbalance happens and can easily become the bo ttleneck of the whole BFS algorithm.
The simplest strategy is to map each thread to a vertex in the input queue, having each thread inspect the neighbors of the assigned vertex serially. Harish et al. [7] and Luo et al. [10] use this strategy. It only exploits the parallelism of the outer loop, and can lead to sever e thread imbalance within a warp for graphs having non-uniform degree distributions. Moreover, the arbitrary memory accesses from each thread result in terrible coalescing too.

AbetterstrategyistomapawholewarporCTAtoavertexinthein-put queue, which is adopted by Hong et al. [8] and Merrill et al. [11]. In this way, the whole warp or CTA gather the adjacency list of the vertex in parallel. This approach provides good thread balance for vertices having large numbers of neighbors. However for vertices with the adjacency list sizes smaller than the warp/CTA width, some threads in the warp/CTA will go unused, imposing un-derutilization of the warp/CTA. Furthermore, there may exist warp imbalance or CTA imbalance if the adjacency list sizes vary significantly.

Another scan-based strategy introduced by Merrill et al. [11] maps a CTA to a certain number of vertices in the input queue. The CTA first constructs a shared array of neighbor locations corresponding to the concatenation of the assigned adjacency lists. Then the CTA reads in the locations from the shared array and gather the neighbors iteratively. Compared to the CTA mapping approach, this strategy solves the CTA underutilization problem at the cost of additional concatenating operations, which is effic ient for vertices having small sizes of adjacency lists. Since each thread constr ucts its part of the shared array serially and its workload is proportional to the size of the assigned adjacency list, large adjacency lists can impose thread imbalance and inefficiency.
 Each of the above mapping strategies is suitable for certain types of graphs. Merrill et al. [11] therefore adopt a hybrid approach. For vertices having more neighbors than the CTA width, CTA mapping is applied. For vertices having the number of neighbors smaller than the CTA width but larger than the warp width, warp mapping is applied. Finally, scan-based mapping is performed on the remaining vertices. This hybrid approach limits thread imbalance and warp imbalance, which is the current state of the art on GPU BFS.

Other works explore general graph algorithms on GPUs [12,16]. They focuses on flexibility and clarity but lacks specific optimization. Their BFS implemen-tations are inefficient.
 2.3 Motivation of This Work All the existing parallelization strategies suffer from load imbalance issues. They cannot achieve consistent performance over various graphs. The hybrid CTA+ warp+scan approach has been shown to per form efficiently. However, this solu-tion is not good enough for the following reasons: (1) It does not solve the load imbalance problem in general, but only limits (2) The neighbor gathering and status lookup process must be put in separate (3) It is complicated and unintuitive. Work partitioning and neighbor gathering
To address these problems, we present a load-balanced BFS algorithm. It is decoupled into two phases: work redistribution and neighbor gathering. More-over, in the absence of CTA imbalance we get to fuse neighbor gathering and status lookup into one kernel and further improve performance. The nested and highly irregular parallelism shown in BFS, together with the static thread creation mechanism of GPUs, make a balanced work partitioning very difficult. The latest NVIDIA GPU architecture GK110 supports dynamic parallelism [3] in order to ease this problem, which enables the GPU kernel to launch other kernels itself. However, this does not solve this issue in general because the number of newly allocated threads does not match the problem size very well. Vertices with few neighbo rs would be provisioned entire CTAs, leading to underutilization. To address this problem, we preprocess the input to reorganize the workloads, eliminating the nested parallelism. In this section, we introduce the expand operation which is the basis of the workload reorganization, and the parallelization of expand . 3.1 The expand Operation To get rid of the nested workload structure, we pack the neighbor gathering work produced by each input vertex together into a single sequence, with each element of the sequence representing the gathering address. In this way, threads can be uniformly mapped to this sequence and do the neighbor gathering in a load-balanced fashion.

In order to generate this sequence, we first define a basic operation. As il-lustrated in Fig. 2, taking the degree of each vertex in the queue as input, this operation outputs an array whose length is equal to the total number of neigh-bors to be produced. Each element in the array represents the index of the vertex in the queue that will produce it so in the subsequent gathering phase we can find that vertex and its neighbors.

We will call this operation expand , which is a useful pattern in data-parallel algorithms. Using expand , the nested loop structure is reorganized and flattened, which is the key to achieving load balance. Obviously, serial implementation of expand has O ( m ) time complexity, thus efficient parallelization of the expand operation is the basis of high performance of the whole BFS algorithm. 3.2 Parallelization of expand The expand operation can actually be converted to a merging of two sorted arrays. As demonstrated in Fig. 3, we first run an exclusive scan [13] on the inputs, obtaining the result array s and the sum total . We then construct an array t of length total filled with [0 ...total  X  1] and merge s and t . The difference compared to a normal merge is that we only output total elements, and the value of each output element equal s to the current index of array s . In practice, the array t is not necessary because the indices and values are the same. Algorithm 2 shows the sequential implementation of the expand operation.
 The parallelization of the merge operation has been studied for decades [15,6]. Basically, the input sequences are partitioned into non-overlapping segments, and the independent pairs of segments are merged in parallel. Odeh et al. [14] present a merge path algorithm that achieves a perfectly load-balanced partitioning. As depicted in Fig. 4, the two input sequences are listed perpendicularly. The merge process can be seen as the traversal of a path from the upper left corner to the bottom right corner, and ea ch step represents a comparison operation. This path is partitioned by equispaced cross diagonals, and the intersection points are computed using binary searches (search along the diagonal for the dividing point between s&gt;t and s  X  t ). In this way, each segment of the path contains exactly the same number of merge steps (except the last segment, which we can handle through padding), resulting in a load-balanced partitioning.
This partitioning scheme can be easily applied to GPUs. We first employ a coarse-grained CTA-wide partitioning, assigning each CTA with the same num-Algorithm 2. Sequential expand ber TILE SIZE of elements to process, which is a tunable constant. This is done by placing each cross diagonal at a distance of TILE SIZE steps. After that, each CTA runs a similar fine-grained local partitioning to further assign TILE SIZE/CTA SIZE input elements to each thread. When threads have obtained their independent segments of the input elements, they can run the sequential expand in parallel, leading to a high-performance parallel expansion. Having explained the parallel expansion in detail, we now use it as a work redis-tribution scheme to construct the full algorithms for a BFS iteration. We also explore the coupling possibilities of work redistribution and neighbor gathering.
To efficiently utilize the GPU memory model, we use the well-known com-pressed sparse row (CSR) format to store the graph in GPU main memory, which contains two arrays, namely column-indices C and row-offsets R . 4.1 Perfect Balance + Global Data Movement The most straightforward approach is to separate the work redistribution phase and neighbor gathering phase into different kernels. In work reditribution phase, we read in the vertices in the input queue and construct the array offsets holding the starting index of each vertexs adjacency list. Then we compute the adjacency list size neighbor num of each vertex, and run the parallel expansion using neighbor num as input. With the expansion output vertex index we can further compute the location of each neighbor to be gathered as: These locations are then written to the output queue.

In neighbor gathering phase, the locations of all the neighbors are read back in. We then gather the neighbors at these locations and perform status lookup. Finally the valid vertices are output for distance update. As mentioned in Sect. 2.3, since the neighbor gathering is now fully load-balanced, the subsequent status lookup no longer needs to be put in a separate kernel.

This process is listed as algorithm 3, which requires at least five kernel launches (each code fragment marked by in parallel indicates a separate kernel). The work redistribution and neighbor gathering are both load-balanced: each CTA always processes TILE SIZE elements, making the algorithm insensitive to the differ-ence in graph structure. But the net sl owdown caused by writing and reading the work redistribution results will limit the obtained overall performance. 4.2 Imbalanced Redistribution + Balanced Gathering A natural optimization is to fuse work redistribution and neighbor gathering. Unfortunately this will compromise the load balance property. Assume that the input queue has input total vertices and they generate output total neighbors. The redistribution phase will take input total + output total elements as input but only output output total elements for the next phase, which makes the thread mapping policy inconsistent across the two phases if we fuse them together. In normal cases however, the performance gain through reduced I/O overhead can often make up for the impact of the load imbalance.

When coupling the redistribution and gathering, we may choose the thread map-ping policy so that it benefits either pr ocess. We first focus on balanced gather-ing because it is the more time-consuming phase. Assuming each CTA processes TILE SIZE elements, the algorithm will assign output total/T ILE SIZE CTAs to perform the gathering. To achieve the coupling, the same number of CTAs should be assigned to the redistribution, and each CTA should output TILE SIZE ele-ments at the end of the redistribution process which are then fed into the gathering process on the fly.

We use a different redistribution approach to fulfill these requirements. In the coarse-grained partitioning step, we partition the merge path vertically rather Algorithm 3. Perfectly load-balanced BFS iteration than diagonally and at a distance of TILE SIZE as illustrated in Fig. 5. In this way, it is guaranteed that each CTA produces TILE SIZE outputs. We then do a fine-grained partitioning and expansion within each CTA.

This work redistribution process is rel atively inefficient and imbalanced, be-cause a CTA does not know the number of inputs it will process a priori. For-tunately, since the gathering process is the more time-consuming phase and is perfectly load-balanced, this approach can achieve better overall performance from the reduced I/O overhead. 4.3 Balanced Redistribution + Imbalanced Gathering Another coupling strategy is to focus on balanced work redistribution. In this way, ( input total + output total ) /TILE SIZE CTAs are assigned to run the redistribution process as in the first approach, the outputs are then fed into the gathering process immediately. Since each CTA will take TILE SIZE elements as input but produce less than TILE SIZE outputs, subsequent gathering can suffer from CTA imbalance: each CTA will gather 0 to TILE SIZE neighbors.
When output total is much larger than input total , the gathering load imbal-ance is negligible, and this approach can be more efficient than previous strategy because of the balanced redistribution process. However, if they are close, the imbalance problem can make the parallelism drop down by half, compromising the overall performance significantly. 4.4 Hybrid The hybrid strategy combines the advantages of the imbalanced redistribution + balanced gathering and balanced redistribution + imbalanced gathering ap-proaches. We define expand factor as the ratio of output total versus input total . If expand factor is larger than a threshold f 0 for a given BFS iteration, we in-voke the balanced redistribution + imbalanced gathering approach because the gathering imbalance will be small enough to be safely ignored, achieving the best performance. Otherwise we invoke the imbalanced redistribution + balanced gathering approach to guarantee the efficiency of the gathering process, which dominates the overall performance.

By selecting an appropriate f 0 , this strategy can ensure that the neighbor gathering phase is always load-balanced while the efficiency of the work redis-tribution phase is maximized. In this section, we evaluate the performance of the proposed BFS algorithms. Our algorithms are implemented using CUDA 5.5 [3], and all experiments are run on a host machine with 4GB memory, an Intel 3.4 GHz Core i7 2600k CPU and an NVIDIA Geforce GTX 580 GPU. For each graph, the BFS performance is measured by the average traversal throughput (edges per second) across 100 randomly-sourced traversals. 5.1 Strategy Evaluation We first compare different coupling strategies of work redistribution and neighbor gathering. We use Random and R-MAT graphs generated with GTgraph [5], and adjust the average degree d to see its impact on each strategy. Fig. 6 and Fig. 7 plot the traversal throughput for each graph and strategy. All the graphs have 2 million vertices while d ranges from 2 to 64, and we choose the threshold f 0 to be 10 for the hybrid strategy. As anticipated, the balanced redistribution + imbalanced gathering strategy excels at traversing graphs with large d because the expand factor tends to be large for the BFS iterations. On the contrary, the imbalanced redistribution + balanced gathering strategy performs better on graphs with small d .The hybrid approach outperforms or is as good as the others in all the tests.
 5.2 Comparison with Other Algorithms To compare with the CPU implementation, we implement our own efficient se-quential BFS according to the standard algorithm in [9], which has optimal single-threaded performance. For the GPU implementation, we compare our ap-proach to that from Merrill et al. [11] which is the current state of the art and achieves the highest published performance for GPU BFS. Note that we compile and run Merrills source code on the same platform under the same configuration so the results are comparable.

Our benchmark suite incorporates twelve graphs listed in Table 1. In addition to random and rmat , the rest are from the Graph500 Competition [2], the 10th DIMACS Implementation Challenge [1] and the University of Florida Sparse Matrix Collection [4].

The results are presented in Table 1. As we can see, our hybrid approach performs very well compared to the CPU sequential BFS. For the majority of the graphs, our approach provides traversal speedups of an order of magnitude, and at the extreme, we achieve a 39x speedup for the random graph. We do not have an available parallel CPU BFS implementation, but we can simply assume a perfect 8x speedup for our 4-core/8-thread CPU, and our GPU approach still outperforms this theoretical performance upper bound for almost all the tests.
The state-of-the-art GPU implementation [11] employs a hybrid CTA+warp+ scan strategy to do neighbor gathering. Through full load balance, our approach outperforms theirs for most of the tests, and we obtain up to 1.42x speedup. The last few tests also reveal the limitation of our approach. The advantage of load balance comes at the price of additional preprocessing of the input vertices. When the search depth is small, the numbe r of vertices examined each iteration is large enough to fully utilize the high throughput of GPU hardware, making the preprocessing overhead negligible. However, when the search depth gets high, the overhead of the work redistribution process and additional kernel launches starts to become significant. As a result, the performance gain through load-balanced gathering is outweighed by the preprocessing penalty and we observe aslowdownfor germany.osm and hugebubbles-00020 datasets. In practice, we can choose to apply direct gathering for graphs with large diameters. Load balance is a key factor in designing efficient algorithms for GPUs. We have demonstrated a GPU BFS algorithm that leverages the unique wide SIMD GPU architecture and achieves fully load-balanced neighbor gathering. We have showed that our approach achieves very high performance on a broad range of graphs, and outperforms current state-of-the-art implementation.

In order to exploit the nested and irregular parallelism on a BFS iteration, we have introduced a work redistribution process to flatten the nested workloads. It utilizes a parallel expansion to compute the gathering location of each neighbor so the neighbor gathering process can visit the neighbors in a load-balanced way. We have also explored the coupling possibilities of different phases, and proposed a hybrid approach that yields the best overall performance.
 Acknowledgements. We thank all the anonymous reviewers for their valuable comments. This work is substantially supported by National Natural Science Foundation of China under G rants No.61300045, and China Po stdoctoral Science Foundation under Grant No.2013M531696.

