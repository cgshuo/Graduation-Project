 As the World Wide Web rapidly grows, a huge number of online documents are easily accessible on the web. Finding information relevant to user needs has become increasingly important. Ther e are many images on the web. Web image retrieval systems are one of the most significant tasks in web applications. Most of existing web image retrieval systems, such as Google image search 1 , utilize keywords extracted from text areas surrounding images. The method is effective for concrete queries.

In this paper, we focus on abstract queries. For example, a user inputs  X  X um-mer X  as a query to a search engine. The query  X  summer X , however, is ambiguous because it is an abstract query. The target images that related to the abstract query  X  X ummer X  depend on the user. Moreover, the concrete words related to the abstract query do not always exist in text areas surrounding the images. For example, assume that a user wants images about  X  X  white sand beach with the sea X  and uses  X  X ummer X  as a query. Exi sting systems can not often retrieve images that the user wants. If a web image retrieval system can connect the word  X  X ummer X  with concrete words related to it, it is useful. Kato et al. [1] have proposed a web image search method for an abstract query. They used social tagging information in Flickr 2 for the image search method. Freng and Lapata [2] have reported a automatic tagging system for images in BBC news. The system tagged appropriate keywords extracted from the caption of an image, the headline of the news and so on. These methods were useful. However, they did not treate any information in images such as color. Many researchers have proposed content-based image retrieval techniques[3,4]. Sezaki and Kise [5] have proposed a recommending system about a tagging process for images. They used the co-occurrence of tags and a similarity between images. However, the method needed social tag information of images. Barthel et al. [6] have reported an image search system on the web. First, the method retrieved images from the web on the basis of a keyword-based search process. Next, it sorted the images according to their visu al similarity. However, they did not argue abstract queries.
 In this paper, we propose a web image retrieval system for abstract queries. We focus on both of text and image informat ion. First, we detect concrete words associated with an abstract query by usi ng results from a text-based web search engine. Next, we search and sort the im ages extracted by the text-based web search engine by using a similarity between images and user X  X  feedback. We use the Earth Mover X  X  Distance as the similarity. In this section, we discuss search results concerning concrete queries and abstract queries on an existing system. We comp ared 6 concrete que ries and 6 abstract queries in terms of precision rates in the top 20 and top 50 search results. Table 1 and Table 2 show the precision rates 3 . We evaluated the correctness of the extracted images from the existing system subjectively. The precision rates con-cerning concrete queries such as  X  X ose X  and  X  X now X  were high. However, the precision rates concerning abstract queries such as  X  X ummer X  were generally low as compared with concrete queries. The r easons of the low precision rates are as follows: 1. a concrete query does not always appear in the text surrounding a target 2. a concrete query frequently appear in the text surrounding non-target images. An example of the 1st reason is a target image about  X  X  white sand beach with the sea X  with an abstract query  X  X ummer X . The same tendency is shown in other abstract queries such as  X  X pring X  and  X  X utumn X . Moreover, the precision rate of a concrete query occasionally becomes low. See the case of  X  X oon X  in Table 1. The word  X  X oon X  is expressed  X  X suki X  in Japanese. The word  X  X suki X  contains two meanings;  X  X suki as moon X  and  X  X suki as month X . The ambiguity is the 2nd reason of the low precision rate.
To solve the 1st problem, we extract wo rds related to an ab stract query from the web. For example, we detect concre te words, such as  X  X ea X ,  X  X each X  and  X  X ireworks X , concerning  X  X ummer X . For the 2nd problem, we apply a feedback process from a user into our retrieval method. In this section, we explain our proposed method using text and image informa-tion. Also we apply user X  X  feedback to the method. Figure 1 shows the outline of the proposed method.

Our method consists of three processes; (1) text processing, (2) feedback pro-cessing and (3) image processing. If a user inputs an abstract query, the system extracts concrete words associated with t he query. Then, it searches images with the extracted words and displays the images as initial outputs. Next, the user selects images that he/she wants, namel y relevant or positive examples. On the basis of the selected images, our syste m computes a similarity between images and sorts the images by using the similari ty. The user iterates these processes until the system outputs images that he/she wants. The following subsections describe each process in our method. 3.1 Text Processing In the text processing, our method detect s related words concerning a query and searches images on the basis of the words. For the related word extraction, we use snippets in search results. A snippet is a summary that is displayed in search results from a search engine. Figure 2 shows an example. We use Yahoo! Web search API 4 as the search engine in this process
For the related word extraction, it is not suitable to extract related words by using the original query that a user inputs. In the situation, the search engine usually outputs pages that contain the origin or the explanation of the query word. For example, one snippet of the word  X  X pring X  is  X  X ne of the four temperate seasons. Spring marks the transition from winter into summer. X  This snippet does not contain effective information for our system because we need concrete words to associate  X  X pring X  such as  X  X herry Blossom X .

To solve this problem, we add the phrase  X  X o ieba X  to the initial query. In other words, we use the phrase  X  X Query] to ieba ([Query] is associated with) X  as the new query. Using this phrase leads to reduction of the number of pages that we do not need in this process. First, we divide sentences in snippets of top 30 pages into words by using the Japanese morphological analyzer ChaSen 5 . Next, we compute frequency of each noun in the results. Finally, we employ high frequency words (top 15 words) as related words of the query.
 Our method retrieves images by the init ial query and the extracted words. Then, it displays top 10 images extracted by each query-set (the initial query and an extracted word) for the feedback process mentioned below. We also use Yahoo! Image search API for retrieving images in this process. 3.2 Feedback Feedback methods are effective for the image retrieval systems [6,7]. We also apply user X  X  feedback to our system to retrieve images that users want. Figure 3 shows the interface of our system.
As the 1st step, our system displays the i mages retrieved by each query-set in the previous subsection. In Figure 3, the initial query is  X  X pring X . In this case we obtained 15 related words (including the initial query itself) such as  X  X herry X  and  X  X lower X . Each line with a related word in the figure denotes a kind of cluster of images that are retrieved with the related word. In our system, a user can select the related words and the im ages with a check box in the list. On the basis of the selected elements, our system retrieve images again from the web. If images are selected by a user, it com putes a similarity between the selected images and other images retrieved and sorts the images by using the similarity. The similarity calculation is described in the next subsection. 3.3 Image Processing Image retrieval systems based on keywords only do not always refine the search results. For example they can not distinguish between a image of a mouse as animals and a image of a mouse as devices. One solution to the problem is to apply a visual similarity measure 6 . In our system, we use a visual similarity measure. The inputs of this image processing are the images that a user selects in the feedback process des cribed in the previous subsection. If a user select images in the list on our system, it computes a similarity. The features for the similarity calculation are a color signature which is a pair consisting of a color p i and the ratio r i of the color in all pixels. To co mpute a distance between color signatures, we use the Earth Mover X  X  Distance (EMD), which has been used by Rubner et al for a metric for image retrieval [8]. In our method, we use the L  X  a  X  b  X  color space and the Euclidean distance for the EMD calculation. Here In this situation, the EMD is computed by the following equation.
 where f ij is the optimal solution of Eq. (1) under the following conditions. In our system, we compute the EMD bet ween a selected image and top 50 images from Yahoo Image search API. Our system displays top 20 images in ascending order of the EMD value. We compared an existing web image se arch system with our method. We used the Yahoo! image search API as the existing system. The criteria of evaluation in this experiment were (1) the precision rates of top 50 images 7 from each method and (2) appropriateness of relat ed words extracted by our method.

For the 1st criterion (the precision rate), we prepared 10 abstract queries. We subjectively defined the target images, na mely the correct images for the queries. If we can imagine a query from an im age, we accept the image as the correct image for the query. For example, the correct images for  X  X ummer X  were images about  X  X ea X ,  X  X atermelon X  and  X  X ireworks X . Table 3 shows the experimental result. In the table,  X  X ue X  and  X  X xt word X  denote an initial abstract query and one example of extract ed words from our method, respectively.  X  X ue only X  denotes a naive method with the initial query only, namely the existing web image search system with an abstract query.  X  X xt only X  denotes a method with the extracted word. As compared with  X  X ue only X , the  X  X xt only X  yielded high precision rate (0.28 vs. 0.54). This result shows that the words extracted by our method were suitable for image retrieval with abstract queries.  X  X ue+Ext X  in the table denotes a system that used the initial query and the extracted word. The combination of two words, namely the initial query and the extracted word, produced the best performance.

The sorting process based on interaction including the EMD was not applied to three methods, namely  X  X ue X ,  X  X xt w ord X  and  X  X ue+Ext X , in Table 3. Next we evaluated a method with the EMD. Table 4 shows the experimental result of the effectiveness of the EMD. n denotes the number of images extracted. In other words, the precision rate on n = 1 denotes the correctness of the 1st out-put.  X  X ue+Ext+EMD X  denotes a method with the EMD. By sorting the images with interaction including the EMD, the change of the precision rates was small even if the n became large, as comp ared with two method without the EMD. Our system boosted correct images in lower ranks by using image information, i.e., the EMD between images. However, the results about the query  X  X eautiful X  did not improve by using the EMD. The query  X  X eautiful X  is too abstract word for our system because it is an adjective. Adject ives such as  X  X eautiful X  are associated with many words. To solve this problem, we need to apply other features or a framework of KANSEI image retrieval to our method.
 In general, synonyms are effective in information retrieval as query expansion. We also evaluated a system based on synon yms extracted from some dictionaries such as Nihongo-Goi-Taikei [9]. However, using synonyms from the dictionar-ies was not effective. The reason was th at the synonyms from the dictionaries were not always concrete words. For example, the synonyms of  X  X ummer X  are  X  X pring X ,  X  X inter X  and so on. These words are not suitable to retrieve images about  X  X ummer X . This result shows the effectiveness of our method based on related words extracted from the web.

In this experiment, we evaluated our system with abstract queries only. One future work is to evaluate our system with both of concrete and abstract queries.
The 2nd criterion was appr opriateness of related words extracted by our method. In other words, we evaluated our method as a tagging system for im-ages on the web. We regarded related words extracted by our method as tags of images. The number of test subjects was 4. In this experiment, we defined target images of each query first. For instance,  X  X chiro who is a baseball player standing in a batter X  X  box X  as a concrete image for  X  X chiro X  as an abstract query. Next we iterated the retrieval proces s until the system output images that we wants. The test subjects evaluated the i mage and extracted word pairs that the system output. The scores for the evaluation were as follows: 1: reject, 2: weak reject, 3: f air, 4: weak accept, 5: accept.
Table 5 shows the experimental result.  X  X  X  to  X  X  X  in the table are each test subject. The score on average was 3.2. The result was fair but not enough for a tagging system of images. We need to improve the related word extraction process for the tagging system of images. In this paper, we proposed a web image retrieval system for abstract queries. Our method could retrieve images of  X  X ireworks X  and  X  X  white sand beach with the sea X  from the query  X  X ummer X . We used both of text and image information for the system. First, Our method extrac ted concrete words associated with an abstract query by using results from a te xt-based web search engine. Next, It searched and sorted the images by using a similarity between images and user X  X  feedback. We used the Earth Mover X  X  Distance as the similarity.

In the experiment, we compared our m ethod with a naive method based on an existing web search engine. As a resul t, our method was effective as compared with the naive method. We also evaluated our method as a tagging system for images. The evaluation score was 3.2 (fair) on average. Future work includes (1) evaluation of other abstract queries and a large-scale experiment and (2) im-provement of the related word extraction process, especially as a tagging system of images.

