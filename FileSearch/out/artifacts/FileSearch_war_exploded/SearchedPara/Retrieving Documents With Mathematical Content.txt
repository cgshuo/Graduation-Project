 Many documents with mathematical content are published on the Web, but conventional search engines that rely on keyword search only cannot fully exploit their mathemati-cal information. In particular, keyword search is insufficient when expressions in a document are not annotated with nat-ural keywords or the user cannot describe her query with keywords. Retrieving documents by querying their mathe-matical content directly is very appealing in various domains such as education, digital libraries, engineering, patent doc-uments, medical sciences, etc. Capturing the relevance of mathematical expressions also greatly enhances document classification in such domains.

Unlike text retrieval, where keywords carry enough se-mantics to distinguish text documents and rank them, math symbols do not contain much semantic information on their own. In fact, mathematical expressions typically consist of few alphabetical symbols organized in rather complex struc-tures. Hence, the structure of an expression, which describes the way such symbols are combined, should also be consid-ered. Unfortunately, there is no standard testbed with which to evaluate the effectiveness of a mathematics retrieval al-gorithm.

In this paper we study the fundamental and challenging problems in mathematics retrieval, that is how to capture the relevance of mathematical expressions, how to query them, and how to evaluate the results. We describe various search paradigms and propose retrieval systems accordingly. We discuss the benefits and drawbacks of each approach, and further compare them through an extensive empirical study. H.3.3 [ Information Storage And Retrieval ]: Informa-tion Search and Retrieval  X  Retrieval models Mathematics retrieval, Search, Math queries, Documents with math content.

Many collections of documents contain mathematical ex-pressions. Examples include technical and educational web sites, digital libraries, and other document repositories such as patent collections. Currently, due to the lack of an ef-fective mathematics retrieval system, such rich mathemati-cal knowledge is not fully exploited when searching for such documents. Querying with mathematical expressions, and consequently retrieving relevant documents based on their mathematical content, is not straightforward:
As is true for other retrieval systems, a mathematics search engine should be evaluated based on its usefulness, that is, how well it can satisfy users X  needs. What makes math-ematics retrieval distinct is the difficulty of judging which mathematical expressions are relevant and which are not. For example, a user who is interested in sin 2 ( x ) might also no consensus for similarity of mathematical expressions in general. On the other hand, if we were to limit the search to exact matches only, many relevant expressions will be missed, and the user might need to issue too many queries to find a useful answer. For example if the user is looking for and
Mathematics retrieval is still at an early stage. Unfortu-nately, content-based mathematics retrieval systems [7, 15] are limited to resources that encode the semantics of mathe-matical expressions, and they do not perform well with pre-sentation markup. The lack of content information within web pages forces a retrieval system to rely mostly on the presentation of expressions, and it is often hard to judge whether a similar-looking expression is relevant to a query.
Some systems rely on the presentation of mathematical expressions [3, 9, 20, 26, 27, 28], but they either find exact matches only or they use models that ignore the whole or parts of the structure and usually return many irrelevant results. They do not define how to measure the relevance of matched mathematical expressions, and there has not been much effort to evaluate such systems in terms of the useful-ness of search results.

In this paper we focus on the problem of matching mathe-matical expressions, and hence we assume that a query con-sists of a single expression. Systematically addressing this problem is a prerequisite for developing systems that handle more complex queries, such as ones that consist of multiple expressions or a combination of expressions and keywords.
Because mathematical expressions are often distinguished by their structure rather than relying merely on the sym-bols they include, we describe two search paradigms that incorporate structure: 1. Structural similarity: The similarity of two expressions 2. Pattern match: As an alternative approach, a query
If the two mentioned approaches perform equally well, the simpler query language is probably preferred; the ex-tra cost of forming a query with the expressive query lan-guage is justified only when this expressive power results in higher-quality answers. We discuss the advantages and dis-advantages of each approach, and we report on an extensive empirical study to evaluate them in terms of their ability to predict the relevance of pages containing mathematical expressions. We also describe other alternative algorithms (e.g. keyword search only, etc.) and compare them against the proposed algorithms.

The contributions of this paper are as follows: Figure 1: Content MathML (left) vs. Presentation MathML (right) for 2( x + 3 y )
This is the first attempt to describe and evaluate possible solutions in a principled way. Understanding the effective-ness of approaches to matching mathematical expressions is necessary for evaluating the further development of any mathematics retrieval algorithm. Hence, we believe the re-sult of this study is an important step towards building a useful mathematics retrieval system.

In this paper we focus on the quality of results when matching mathematical expressions. Indexing and other op-timization techniques to reduce query processing time or in-dex size is out of the scope of this paper (Elsewhere, we extensively discuss such optimization techniques [14].). In this paper, we also do not address the problem of evaluating mathematical expressions, which is the goal of systems such as Wolfram Alpha [1], or Bing Math [11].

The rest of this paper is organized as follows. After for-mulating the mathematics retrieval problem more precisely in the next section, we describe related work in more detail in Section 3. In Section 4 we describe an approach based on matching structurally similar expressions, and in Section 5 we describe an approach based on matching expressions to templates. We present the results of our experiments and the comparison of alternative search approaches in Section 6. We finally conclude the paper with an indication of future work.
In this section we present definitions for some general con-cepts. We also describe the search problem and any assump-tions we make about the query and the results.
Math Expression: A mathematical expression is a fi-nite combination of symbols that is formed according to some context-dependent rules. Symbols can designate num-bers (constants), variables, operations, functions, and other mathematical entities.

There are various ways to encode and represent a math-ematical expression. Such approaches can be divided into two main groups: 1. Content-based: Semantics of symbols and their inter-Figure 2: Two trees representing sin ( i ) (left) and sin j (right) in Presentation MathML.
 2. Presentation-based: Expressions are encoded with re-Example 1. Consider 2( x + 3 y ) as a simple expression. The Content MathML encoding for this expression is shown in Figure 1 (left), and the Presentation MathML is shown in Figure 1 (right). Presentation MathML contains some sur-face semantic information. For example, &lt; mn &gt; and &lt; mi &gt; indicate that 2 and 3 are numbers and x and y are variables, respectively. However, the multiplication operator is repre-visible and hence not shown in presentation markup. On the other hand, parentheses are not encoded in content markup because they do not carry semantic information. The plus operator is represented by the &lt; plus &gt; tag in content markup, and its operands ( x and 3 y ) are also clearly specified. Using presentation markup, the  X + X  symbol is shown where it ap-pears in the expression, and even though it is marked as an an operator, its operands are not explicitly indicated.
Presentation MathML is part of the W3C recommenda-tion that is increasingly used to publish mathematics infor-mation on the web, and many web browsers support it [18]. There are various tools to translate mathematical expres-sions from other languages, including L A T E X, into Presenta-tion MathML. Moreover, Presentation MathML expressions can be processed by parsers and other applications for XML documents. Hence, in this paper we assume mathematical expressions are encoded with Presentation MathML unless otherwise is specified.

DOM Tree: Documents with XML markup can be nat-urally expressed as ordered labelled trees, also called Docu-ment Object Model (DOM) trees. A DOM tree T is repre-sented by T = ( V,E ), where V represents the set of vertices and E represents the set of edges of T . A label  X  ( n ) is as-signed to each node n , and  X  is the set of all possible labels. Two examples are shown in Figure 2.

A text document, such as a web page, that contains a mathematical expression is a document with mathematical content . The search goal is to retrieve such documents by querying their mathematical content.
Here we present a general definition for the search problem and the query language. Details of the query language and the way a match is defined are specific to a mathematics retrieval system. We describe several possible approaches in the following sections.
 Query: The aim of a query is to describe a mathematical Search problem: Given a query, the search problem is to
The query and all mathematical expressions are encoded with Presentation MathML. Because forming queries directly with Presentation MathML is difficult, input devices such as pen-based interfaces and tablets [17, 25] or more widely-known languages such as L A T E X could be used instead to enter a query. Automatic tools can then be applied to trans-late queries to Presentation MathML. Hence, regardless of the user interface, we assume the query is eventually rep-resented in the form of Presentation MathML. Thus, this approach is appropriate for the majority of the available mathematics information on the web.
In the case of text retrieval, syntactic variants of query terms can be matched through stemmers and semantic vari-ants can be matched through ontologies. These and similar tools can improve the results of search systems. Similarly, for mathematics retrieval using mathematical equivalence rules and transforming expressions to canonical forms ac-cordingly (e.g.  X  ab + ac  X  and  X  a ( b + c ) X ) can improve search results. Nevertheless, such approaches are orthogonal to our algorithms and out of the scope of this paper.

Extending the query language to cover more complex cases can increase the usefulness of a search system. For exam-ple, allowing a query to consist of multiple mathematical expressions or a combination of mathematical expressions and text keywords can increase its expressive power. In-cluding a (symbolic) mathematics engine to calculate the answer to a mathematical query can also be used to address some users X  needs. However, in this paper our primary goal is to study the usefulness of the basic search paradigms and to compare them. While such extensions are potentially use-ful, the effectiveness of the basic search primitives should be proved first. Hence, in this paper we only focus on the basic search paradigms. An extended query language can then be studied by leveraging our findings.
In this section, we describe existing algorithms for mathe-matics retrieval systems in a framework that classifies them based on how they attempt to match expressions.
Some algorithms assume expressions are available only in images, and they try to match a given query by calculat-ing the similarity of images [30, 31]. In the best case, the performance of such algorithms is similar to ExactMatch al-gorithms, which allow for very limited variation among the expressions returned. We describe and evaluate ExactMatch algorithms further in Section 6.

TexSN [27] is a textual language that can be used to nor-malize mathematical expressions into canonical forms. Af-ter that a search is performed to find mathematical expres-sions that exactly match a (normalized) query. MathQL [9] and MML Query [3] propose very detailed and formal query languages through which mathematical expressions are pre-sented as sets of symbols. To perform a search, sets of ex-pressions containing specific symbols are selected and then intersected using relational database operations. Einwohner and Fateman [7] propose a data structure and an algorithm for searching integral tables. In this approach, pre-calculated integrals are stored in a table. A requested integral matches an entry in the table if its integrand agrees with that of the table entry up to a choice of parameters, e.g. 1 x 2 +1 matches x 2 + a . We characterize all of these approaches as Normal-izedExactMatch algorithms, which we describe and evaluate further in Section 6.

As shown in Section 6, ExactMatch and NormalizedEx-actMatch perform poorly in retrieving web pages with math-ematical content.
Sojka and Liska [26] propose another algorithm that first tokenizes expressions, where a token is a subtree of the ex-pression. Each token is next normalized with respect to var-ious rules (e.g. variables names are removed, number values are removed, or both), and multiple normalized copies are preserved. The resulting collection of tokens is then indexed with a text search engine. A query is similarly normalized (but not tokenized) and then matched against the index. Similarly, Egomath [19] tranforms math expressions into to-kens (that represent subexpressions), and uses a text search system to index and query them. Regardless of the tok-enization details, some structure information is missed by transforming an expression into bags of tokens, which af-fects the accuracy of results as shown later in this paper. MathWebSearch [15] is a semantic-based search engine for mathematical expressions. The query language is an exten-sion to OpenMath, with some added tags and attributes, e.g. mq:not, mq:and, mq:or . Mathematical expressions are inter-preted as prefix terms and are stored in a tree data struc-ture called a substitution tree, where common prefixes are shared. A search is performed by traversing the tree. Math-WebSearch can only process and index expressions encoded with Content MathML and OpenMath; presentation-based encoding is not well suited for use by this system. Schel-lenberg et al. [24] propose extending substitution trees to expressions with L A T E X encoding. Such approaches support exact matching of expressions well, but they support partial matching only when expressions share a common part at the top of the tree. Kamali and Tompa [12] propose to allow the common parts of two expressions to appear anywhere in the trees. We characterize such algorithms as SubexprEx-actMatch algorithms, and we show in Section 6 that their performance remains relatively poor.
Pillay and Zanibbi [23] propose an algorithm based on tree edit distance for combining the results of different math recognition algorithms. The goal of this approach is to enhance such algorithms to recognize hand-written expres-sions. Algorithms for retrieving general XML documents based on tree-edit distance have been proposed [16], and these could be adapted to match XML-encoded mathemat-ical expressions. However, these approaches have not been thoroughly investigated for retrieving mathematical expres-sions. We propose an algorithm in this SimSearch class in Section 4 and show in Section 6 that it has a much better performance than other approaches such as exact match.
An alternative for matching based on structural similarity is to express a query in the form of a template, much as QBE does for querying relational data [33]. We describe how templates may be used to specify precisely where variability is permitted. We review our previous work on PatternMatch algorithm [13] in more detail in Section 5 and evaluate its performance in Section 6.
The maturity of keyword search algorithms has motivated some researchers to use them for mathematics retrieval [28, 31]. Such approaches typically represent a mathematics ex-pression as a bag of words, where each word represents a mathematics symbol or function. Youssef [28] proposes an algorithm based on the vector space model to rank mathe-matical expressions in response to a given query. To try to accommodate the specific nature of mathematics, alterna-tive weighting schemes are considered instead of term fre-quency and inverse document frequency. Nguyen et al. [21] propose another algorithm that considers a semantic encod-ing (Content MathML) of expressions. Each expression is represented by several textual tags, after which standard keyword search algorithms are used to search mathemati-cal expressions. This allows supporting queries that contain both keywords and mathematical expressions and using ex-isting IR optimizations. As shown in Section 6, ignoring the structure significantly affects the performance.
Very few studies consider the problem of evaluating math retrieval systems in terms of satisfying user needs. This is partly due to the lack of a consensus on the definition of the relevance of math expressions, and partly due to the lack of a clear understanding of users X  needs. Zhao et al. [32] report on the interviews of a small group of potential users to ascertain their needs. They conclude that users prefer to use keywords that describe an expression to search for it rather than specifying the expression (e.g.  X  X inomial coef-ficient X  instead of n k ). As we mentioned earlier, in many cases an expression is not described with keywords or the user is not aware of such keywords. Moreover, with math expressions more details can be specified (e.g. n 2 n ). Finally, user-friendly interfaces for entering math expressions, such as pen-based devices, were not widely available at the time of the interview. Some search algorithms that compare im-ages of expressions evaluate their systems in terms of success rate [31, 29]. In such cases, the success rate mostly captures the correctness of recognizing math expressions rather than their relevance. In other words, if an expression or subex-pression is returned as the search result, and they exactly match, it is counted as a successful search.

To date, mathematics retrieval systems that perform ap-proximate matching and then rank expressions based on their similarity to a query have not been analyzed in terms of their effectiveness: there are no experimental results com-paring their ability to find relevant matches. However, the lack of their popularity may be a sign that in many situa-tions they do not perform well. Figure 3: The flow of data in a mathematics retrieval system based on similarity ranking.
The similarity function for mathematics considers only the mathematical content of a document, where each potentially relevant document contains at least one mathematics expres-sion that matches the query. After the user inputs a query through a user interface, it is translated into Presentation MathML to be processed by the ranking algorithm. The result consists of a list of ranked documents sorted with re-spect to the similarity of their mathematical content to the query. Figure 3 shows the flow of data in this approach.
A general sketch for similarity search is presented in Algo-rithm 1. The definition of similarity between two mathemat-ical expressions (Line 6) is a key concept that significantly affects such systems.

Just like other information retrieval systems, semantic similarity ranking is generally very useful, as it can better capture the intention of a user. Thus, the limited seman-tic information that is available (i.e., whether a symbol is a number, a variable, or an operator) should also be con-sidered to calculate similarity in order to broaden the set of potentially matching expressions.

Unfortunately, a ranking function based on more expres-sive semantic similarity requires that the query and the ex-pressions be semantically encoded using a markup language such as OpenMath or Content MathML. Hence, it requires more effort from the user to form a query semantically and also requires that content markup be used to publish math-ematical expressions. As stated earlier, this is generally un-available for retrieval from the web.
 Algorithm 1 Similarity Search 1: Input: Query q and collection D of documents. 2: Output: A list of documents ranked with respect to 3: Define list L that is initially empty 4: for each document d  X  D do 5: for each math expression E in d do 6: Calculate the similarity of E and q and store the 7: end for 8: Calculate the similarity of d and q and store the result 9: end for 10: Sort documents in L with respect to the calculated sim-11: return L
We now propose a similarity function that is based on tree edit distance [4], and define the similarity of a document to a math query accordingly. More specifically, we propose appropriate similarity functions to be used in Lines 6 and 8 of Algorithm 1.

Consider two ordered labelled trees T 1 = ( V 1 ,E 1 T 2 = ( V 2 ,E 2 ) and two nodes N 1  X  V 1  X  P  X  and N 2 V 2  X  P  X  where P  X  is a special node with label . An edit operation is a function represented by ( N 1  X  N 2 ) where (  X  ( N 1 ) , X  ( N 2 ))  X  ( X   X  )  X  ( X   X  )  X  X  ( , ) } . The operation is a relabelling if  X  ( N 1 ) ,  X  ( N 2 ) 6 = . It is a deletion if N not the root of T 1 and  X  ( N 2 ) = , where deleting N 1 makes the children of N 1 become the children of the parent of N in place of node N 1 . Finally, the operation is an insertion if  X  ( N 1 ) = , where insertion is the mirror image of deletion. A transformation  X  from T 1 to T 2 is a sequence of edit op-erations that transforms T 1 to T 2 . To each edit operation N 1  X  N 2 we assign a cost  X  ( N 1  X  N 2 ). The cost of a transformation is the sum of the costs of its edit operations. The edit distance of T 1 and T 2 is defined as follows:
We customize the cost of an edit operation N 1  X  N 2 for mathematical expressions as follows: 1. If  X  ( N 1 ) =  X  ( N 2 ) then  X  ( N 1  X  N 2 ) = 0. 2. If N 1 , N 2 are leaf nodes and  X  ( N 1 ) 6 =  X  ( N 3. If N 1 , N 2 are leaf nodes and  X  ( N 1 ) 6 =  X  ( N 4. If N 1 , N 2 are not both leaf nodes and  X  ( N 1 ) 6 =  X  ( N
In the above definition, C I and C L , and C PL are static functions that assign values to an edit operation. Their val-ues for various inputs are shown in Table 1. In this table, bers, and operators respectively;  X  ,  X  , and  X  are constants whose values are set based on the following observations about math expressions (Some math retrieval systems nor-malize math expressions based on similar observations [19].). Typically, renaming variables affects the semantics less than changing math operators. Similarly, renaming a variable should be less costly than changing a variable to a number, and renaming non-leaf nodes should be more costly that re-naming leaf nodes. Therefore, we set  X   X   X   X   X  .
 Example 2. Consider nodes X and Y in Figure 2. X  X  that they are variables. According to Table 1, C PL ( X  &lt; mi &gt;  X  ,  X  i  X  ,  X  j  X ) =  X  . Hence,  X  ( X  X  Y ) =  X  . Also, Z  X  P deletion and  X  ( Z  X  P  X  ) =  X  . The edit distance between the two trees is equal to  X  +  X  .

Consider two mathematical expressions E 1 and E 2 repre-sented by trees T 1 and T 2 . The similarity of the two expres-sions is calculated as follows: where | T | is the number of nodes in tree T .

There are many algorithms for calculating the edit dis-tance between two trees. We use RTED [22] to calculate the tree edit distance. Table 1: Examples of various cost values assigned to edit operations Assume document d contains mathematical expressions E 1 ...E n . The rank of d for a query Q is calculated with the following formula: that is, a document X  X  score is equal to the similarity of the most similar expression in that document.
An alternative to similarity ranking is to specify a tem-plate as the query and return expressions that match it as the search result [13]. This allows flexible matching of ex-pressions but in a controlled way (as distinct from the simi-larity ranking where the user has less control on approximate matching of expressions). For example, the user can specify that she is looking for [ E ] n where n is a number and [ E ] is an expression that contains sin( x ). This capability is not supported by any exact matching algorithm, and the simi-larity search may not rank relevant expressions high enough. The approach is analogous to querying a collection of strings by specifying a partial context-free grammar, and returning strings that can be parsed by the grammar. Similarly, a template can be defined using wildcards as non-terminals, and regular expressions to describe their relationships. For example, p [ V ], where [ V ] is a wildcard that matches any variable, can be used to search for expressions that consist of the square root of a variable.

According to this paradigm, the user has more power to direct the search; hence the results are expected to be more relevant. However, the variety of wildcards and operations that are available to specify a template may result in a com-plex query language, which requires more effort from the user.

To find a relevant document, the user starts with a pattern to be searched. It may be necessary to tune the query, as the initial pattern may not correctly model the expression the user is looking for or it may be too general or too specific. After the results are shown, she tunes the pattern until she finds a relevant answer. A diagram of the data flow for this search paradigm is shown in Figure 4. Algorithm 2 presents a general sketch for this search paradigm.

In some cases, combining similarity ranking and struc-tured search is useful. For example, assume a user is looking for expressions that contain the square root of an expression E such that E is similar to sin ( x ). In this case, p sin ( x ) is a better match than p sin ( x 2 + 1), and while the latter still complies with the pattern, p sin ( x ) + 1 is not match. This search paradigm has been adopted in other contexts. Exam-ples include XQuery with full-text capability [2] and other Figure 4: The flow of data in a mathematics retrieval system based on pattern matching. keyword search features on structured data [10]. Adding this capability to a search system can increase its flexibility to capture relevant results.

In conclusion, this search paradigm is suitable for spe-cialized search where the user can be expected to put more effort to form a query and get better results in return. Algorithm 2 Structured Search 1: Input: Query q and collection D of documents. 2: Output: A ranked list of documents that match the 3: Define list L that is initially empty 4: for each document d  X  D do 5: for each math expression E in d do 6: if E matches q then 7: put d in L 8: end if 9: end for 10: end for 11: Sort documents in L with respect to ranking criteria 12: return L
A query is expressed as a pattern consisting of a mathe-matical expression augmented with wild cards , optional parts, and constraints in the form of where clauses . A query matches an expression (Algorithm 2-Line 6) as follows. A wild card represents a slot that will match any subtree of the appro-priate type, where [ V i ] matches any variable, [ N i ] matches any number, [ O i ] matches any operator, and [ E i ] matches any expression. A wild card X  X  index i is an optional natural number such that if two or more wild cards share the same type and index, they must match identical subtrees. Wild cards with no index are unconstrained.

Example 3. The query x [ N 1 ]  X  y [ N 1 ] matches x 2  X  y x  X  y 5 but not x 2  X  y 3 , whereas either of the queries x y
Optional parts are enclosed by braces and they may ap-pear in some matching expressions.

Example 4. x 2 { +[ N ] } matches x 2 and x 2 + 1 but not x + y or x 2  X  1 .
 Constraints can be specified for wild cards in a query using a  X  X here X  clause, as follows:
Example 5.
In our experiments we assume a pattern does not contain a similarity constraint. Otherwise, pattern search would be a generalized form of the similarity search approach, which makes it hard to compare them. Moreover, ranking docu-ments with respect to a pattern query that contains multiple similarity constraints is a complex problem that should be addressed after the more basic problem of capturing the sim-ilarity of two math expressions (discussed in this paper) is addressed. This problem is a direction of our future work.
A query is processed by trying to match it against the stored expressions by parsing them with respect to the query. Each document that contains a match is included in the search result.

While similarity ranking is in fact an information retrieval approach to the problem, pattern search resembles a database look-up. Therefore, the result of this search paradigm is a list of documents with expressions that match the query. To rank documents in the list (Algorithm 2-Line 11), a ranking criterion should be considered. In our implementation we sort results with respect to the sizes of the matched expres-sions in increasing order.
In this section we present the results of our empirical eval-uation of the described approaches.
In our experiments we consider the following specific al-gorithms:
We used Apache Lucene in our implementation.
Note that among the above algorithms, the results of Ex-actMatch are subsets of the results of TextSearch, Normal-izedExactMatch, and SubexprExactMatch.
For our experiments we use a collection of web pages with mathematical content. We collected pages from the Wikipedia and DLMF (Digital Library of Mathematics Func-tions) websites. Wikipedia pages contain images of expres-sions annotated with equivalent L A T E X encodings of the ex-pressions. We extracted such annotations and translated them into Presentation MatchML using Tralics [8]. DLMF pages use Presentation MathML to represent mathematical expressions. Statistics summarizing this dataset are pre-sented in Table 2.
To evaluate the described algorithms we prepared two sets of queries as follows.
The precise query formulations for PatternSearch were created by one of the authors. Thus the experimental re-sults reflect search environments in which queries are formed reasonably well by an experienced user.

Table 3 summarizes statistics about the queries, where the number of nodes in the query tree is used to represent query size. For the sake of reproducibility and as a basis for further evaluation of various search paradigms, both the dataset and the complete set of queries can be obtained from the authors upon request 2 .
For each query we use each algorithm to search the dataset, and only consider the top 10 results.

The way we collected queries ensures that a user X  X  infor-mation needs are clear, which allows us to judge if a match is actually relevant or not. Searches for which we do not have a user X  X  relevance feedback (i.e., Forum queries) re-quire that we manually judge results. Hence, for Forum queries we consider discussion threads that clearly describe an information need with no ambiguity. For example a dis-cussion thread might start with this question:  X  X rove that F number X . A search result page is considered relevant if it sat-isfies the information need that is inferred from the thread. If a page contains data that can be clearly used to answer the query, we judge it as relevant. Note that a page may contain an exact match to a query, but it still does not an-swer the information need, hence we assume it is irrelevant (e.g. if a page contains the same expression as in the previ-ous example, but F n is not a Fibonacci number, or it does not contain any information that helps to prove it.).
As mentioned earlier, for PatternSearch the query may be refined repeatedly unless appropriate results are returned or the query is refined a certain number of times and the user gives up (Figures 4). Hence, unless otherwise specified, the results for PatternSearch are presented with respect to the final refined query. For other algorithms however, refining a query is often not necessary or effective, and the results are shown for the original query.
NFR: A search fails if fewer than 10 results are returned (including nothing returned), and none of them is relevant.
The query collections with examples of matching documents are publicly available at http://db.uwaterloo.ca/mathretrieval/queries.xhtml. Non-Failure-Rate (NFR) is the number of searches that do not fail divided by the total number of searches:
MRR: The rank of the first correct answer is a representa-tive metric for the success of a mathematics search. Hence, for each search we consider the Reciprocal Rank (RR), that is, the inverse of the rank of the first relevant answer. For example if the first correct answer is ranked second, the re-ciprocal rank of the search is 1 2 . The Mean Reciprocal Rank (MRR) is the average reciprocal rank for all queries: where Q is the collection of queries, and C ( q ) is the rank of the first relevant answer for query q .

If no relevant document is among the top 10 results, we optimistically assume the search did not fail, and the rank of the first relevant document is 11. If a search fails, we do not include it for calculating MRR.

Rewrite-Rate: It often happens that a search is not suc-cessful, and a user must rewrite the query to find a relevant result. For each search algorithm, starting from an initial query, we logged how many times a query was rewritten to obtain a relevant answer among the top 10 results. We as-sume that the user gives up after five tries, and the search fails or no relevant result is found. The average number of rewrites for all queries is the rewrite rate of an algorithm.
Other measures such as Mean Average Precision (MAP) could alternatively be considered. However, for our data and query collections, MRR seems to be a better choice. In most cases, there are a few (often one) relevant documents for the query. Hence, MRR can better reflect the accuracy of algorithms. Recall that some of the baselines (e.g. pattern search and substructure search) deploy database operators to perform a search, while some other ones (e.g. structural similarity and keyword search) use IR techniques. Hence, because such approaches are inherently different, it is impor-tant to consider measures that fairly compare them. MRR and NFR together provide an indicative measure of the ac-curacy of such algorithms. The NFR and MRR for each algorithm are presented in Tables 4 and 5 for the Forum and Interview queries, respec-tively. As the results suggest, PatternSearch and SimSearch have high NFR and also high MRRs. PatternSearch has a higher MRR because irrelevant expressions are less likely to match a carefully formed pattern. On the other hand, Sim-Search has a slightly higher NFR because in some cases even an experienced user may not be able to guess the pattern that will yield a correct answer. Furthermore, the next sec-tion shows that a template pattern may need to be modified several times to capture a relevant result. Table 4: Algorithms X  performance for Forum Queries.
Because MRR is only calculated when the search does not fail, ExactMatch has a high (in fact, perfect) MRR. However, in most cases, there is no expression that exactly matches the query, and hence no result is produced and this algorithm fails. SubexprExactMatch has a slightly better NFR, but it is still too low to satisfy many users X  needs. This implies that often there are no relevant expressions or subexpressions that exactly match the query. However, in instances where a matching expression or subexpression ex-ists, it is ranked highly by ExactMatch and SubexprExact-Match. Normalizing expressions, as done in NormalizedEx-actMatch and NormalizedSubExactMatch, further increases the NFR, but it also increases the chances that irrelevant expressions are matched. Because such algorithms do not offer an effective ranking algorithm, in many cases the most relevant results are not among the top 10 results.
 Note that although the MRR of SimSearch is lower than ExactMatch and SubexprExactMatch, it has a much higher NFR as it produces some results for all queries. If we only consider queries for which there is an exact match (so Ex-actMatch produces at least one answer), SimSearch has an MRR that is not significantly different from that of Exact-Match. The reason is that in such cases, the structural sim-ilarity for documents that contain exact matches is 1, and such documents are ranked at the top of the results.
TextSearch has a very low MRR. Because this algorithm ignores the structure, it often does not rank a correct answer highly enough against many irrelevant expressions with sim-ilar MathML tags and symbols but different structures.
Note that, although we reformulate queries only for pat-tern search, the structural similarity search produces results that are comparable with the results of well-formulated pat-tern queries. ExactMatch or NormalizedExactMatch are essentially pattern search with poorly formed queries. As shown, such algorithms produce poor results.

To show the statistical significance of the results, we use a Student X  X  t-test on the reciprocal ranks of the queries. For each algorithm, we test whether there is a statistical dif-ference between the reciprocal ranks of its produced results and that of SimSearch. We consider a one-tailed t-test for paired samples (i.e. only non-failed searches are considered). As the data in Tables 4 and 5 suggest, there are significant differences (at the 0.05 significance level) between the re-sults of SimSearch and all algorithms except PatternSearch, ExactMatch, and SubexprExactMatch (for Forum queries). The reason is that in cases that such algorithms do not fail, SimSearch ranks relevant results equally well.
To compare how much effort is required from the user to perform a search, we look at PatternSearch in terms of its rewrite rates. Assume a user is looking for Table 5: Algorithms X  performance for Interview pose the only relevant match to this query is distance between the corresponding DOM trees is relatively low, and thus this answer is ranked highly by the SimSearch algorithm. For PatternSearch, however, if the user forms a query with no wild cards, it performs similarly to Exact-Match, and the correct answer is not found. The following is a plausible sequence of query refinements before an answer is found:
While the rewrite rate of SimSearch is always 1 (as no query rewriting is required), PatternSearch has an average rewrite rate of 2.2 and 1.45 for the Forum and Interview queries respectively. As the results suggest, when using Pat-ternSearch, each query may well be refined to obtain relevant results, and hence the user must invest more effort to find relevant documents.
In summary, simply viewing mathematics expressions as if they were conventional document fragments, as represented by TextSearch, or not allowing variations in matched ex-pressions or subexpressions, as represented by ExactMatch and SubexprExactMatch, leads to extremely poor search re-sults. On the other hand, SimSearch and PatternSearch per-form very well: much better than the other algorithms that ignore the structure or perform exact matching only. Pat-ternSearch may perform slightly better than SimSearch, but the user will likely need to spend more time to tune a query pattern when using this algorithm. Reassuringly, these re-sults are consistent across the two sources of queries.
Given a mathematics expression, finding pages with rele-vant mathematical content is an important problem that is the basis of many mathematics retrieval systems. Correctly predicting the relevance of mathematical expressions is a core problem that should be addressed in order to develop useful retrieval systems.

We characterized several possible approaches to this prob-lem, and we elaborated two working systems that exploit the structure of mathematical expressions for approximate match: structural similarity search and pattern matching. We empirically showed that these two search paradigms out-perform other search techniques, including the ones that per-form exact matching of (normalized) expressions or subex-pressions and the one that performs keyword search. We also showed that it takes more effort from the user to form queries when doing pattern search as compared to similar-ity search, but when relevant matches are found they are ranked somewhat higher. So in conclusion, structural sim-ilarity search seems to be the best way for general users to search for mathematical expressions, but we hypothesize that pattern search may be the preferred approach for ex-perienced users in specific domains.

In this paper we focussed on the usability of answers and how well a search system can find relevant documents for a given query. Others may wish to re-evaluate these results using more controlled methods for assessing relevance. The study should next be extended in an ongoing effort to in-clude new approaches as they are developed. Optimizing the proposed search techniques in terms of query process-ing time and index size is a separate direction [14]. Based on the results of this paper, more complex query languages can also be developed to accommodate queries that con-sist of multiple mathematical expressions supplemented by textual keywords that might match other parts of relevant documents, or pattern queries with one or more similarity constraints.

NTCIR is an international initiative to create a public and shared infrastructure to facilitate research in Math IR. It aims to provide a test collection and a set of math tasks. As a part of our future research, we plan to use this data (which is not yet available) to further evaluate the discussed algorithms.
We acknowledge financial support from NSERC, Mprime, and the University of Waterloo, and we thank the referees for their suggestions. [1] www.wolframalpha.com. [2] S. Amer-Yahia, C. Botev, and J. Shanmugasundaram. [3] G. Bancerek. Information retrieval and rendering with [4] P. Bille. A survey on tree edit distance and related [5] S. Buswell, O. Caprotti, D. P. Carlisle, M. C. Dewar, [6] D. Carlisle, P. Ion, and R. Miner. Mathematical [7] T. H. Einwohner and R. J. Fateman. Searching [8] J. Grimm. Tralics, A L A T E X to XML Translator . [9] F. Guidi and I. Schena. A query language for a [10] V. Hristidis, L. Gravano, and Y. Papakonstantinou. [11] S. Kamali, J. Apacible, and Y. Hosseinkashi.
 [12] S. Kamali and F. W. Tompa. Improving mathematics [13] S. Kamali and F. W. Tompa. A new mathematics [14] S. Kamali and F. W. Tompa. Structural similarity [15] M. Kohlhase and I. A. Sucan. A search engine for [16] C. Laitang, M. Boughanem, and K. Pinel-Sauvagnat. [17] S. Maclean and G. Labahn. A new approach for [18] B. Miller. 3 years of DLMF: Web, math &amp; search. In [19] J. Misutka and L. Galambos. System description: [20] R. Munavalli and R. Miner. Mathfind: a math-aware [21] T. T. Nguyen, K. Chang, and S. C. Hui. A [22] M. Pawlik and N. Augsten. RTED: A robust algorithm [23] A. Pillay and R. Zanibbi. Intelligent combination of [24] T. Schellenberg, B. Yuan, and R. Zanibbi.
 [25] E. S. Smirnova and S. M. Watt. Communicating [26] P. Sojka and M. L  X  X ska. The art of mathematics [27] A. Youssef. Search of mathematical contents: Issues [28] A. Youssef. Methods of relevance ranking and [29] R. Zanibbi and D. Blostein. Recognition and retrieval [30] R. Zanibbi and L. Yu. Math spotting: Retrieving [31] R. Zanibbi and B. Yuan. Keyword and image-based [32] J. Zhao, M.-Y. Kan, and Y. L. Theng. Math [33] M. M. Zloof. Query-by-Example: the invocation and
