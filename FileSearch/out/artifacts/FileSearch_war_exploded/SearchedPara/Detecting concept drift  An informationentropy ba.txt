 Department of Computer Science and Technology, Xi X  X n Jiaotong University, Shaanxi, China 1. Introduction
In recent years, data-intensive applications have become pervasive owing to the rapid development of hardware and storage technology. These types of applications, in which examples (instances, points, many examples of such applications, including backbone network monitoring, industrial processes, fi-
Different from traditional stationary database, a data stream poses distinct challenges due to its dy-namic nature, one-pass scan requirement and rigorous memory limitation [3,5]. An emerging and attrac-up-to-date examples. It is highly provable that examples of data stream are generated from a sequence data stream concept drift are essential and meaningful.
To date, a plethora of literatures have been touc hed upon the task of learning from data stream con-our understanding of it, is nontrivial and has not been well addressed. One of the first works which explicitly mentions concept dri ft is the STAGGER system proposed by Schlimmer and Granger [45]. Widmer and Kubat [54] proposed the FLORA system using a window to learning from concept drift-ing data stream. Ganti et al. [19] introduced a framework to effectively learn from time-changing data stream. They assumed the data examples arrive in block. Another distinct method CVFDT, proposed by Hulten el al. [23], assumed examples arrived continuously and used an adaptive decision tree to mine this evolving data stream. However, all these methods put emphasis on the learning accuracy other than the detecting of concept drift.

When leaning from streaming data, sliding window is a widely used technique. A sliding window Unfortunately, the decay factor is not easy to choose since the rate of concept drift is unknown.
Both the above strategies fix the window size, which is not suitable for streaming environment. On a method (ADWIN) used a variable sized window to learn from data stream. The method compares the difference between two sub-windows with the Hoeffding bound [14,23,27] to determine if the target con-cept is drifted. Whenever a concept drift is found, ADWIN shrinks the window. Otherwise, the window keeps increasing, which will cause excessive time consumption.
 Motivated by above discussions, we propose a novel Adaptive sliding window based Drift Detection Method (ADDM) to detect concept drift quickly. We employ the Hoeffding bound to determine the sliding window size adaptively according to each separate concept. Different from ADWIN, the concept drift detector of our method is the entropy dynamically obtained from sliding window. Furthermore, we introduce the MB-GT algorithm [38] to find the exact timestamp for retraining the classifier whenever a concept drift is detected. We conduct this work with the main contributions being summarized as follows:  X  A novel sliding window determination algorithm which dynamically calculates the sliding window  X  A new entropy based concept drift detection algorithm is proposed for efficiently detecting concept  X  It integrates the MB-GT algorithm to find the exact timestamp for retraining, which can make the
In the experimental study, we use seven publicly available data sets containing various of concept drifts to explore the advantage of our ADDM. The experimental results show that the proposed method outperforms four benchmark methods, i.e. DDM [18], EDDM [6], ADWIN [8] and STEPD [39], not only be a considerable solution of concept drift detection.
 drift detection. In Section 3, we systemically motivate and describe our framework for concept drift it with four benchmarks. In Section 5, a concluding discussion is contained.
 2. Related work
As a sketchy taxonomy, two types of methodologies about learning from concept drifting data stream are generally proposed: 1. Incremental updating. This me thodology [11,14, 20,23,49] does not detect concept drift explicitly,
There are several methods refer to the first type, and they focus on the improvement of classification accuracy. For examples, the STAGGER system [45], the FLORA system [54] and the CVFDT algo-rithm [23]. In this paper, ADDM is one of the second t ype which intends to expl icitly detect concept drift. Thus we highlight the related works being relative to this type.

Gama et al. [18] presented the work to detect concept drift using the classification error rate .The method (DDM) was packaged with a classifier and kept monitoring the prequential error rate. If the error rate was beyond of the threshold, DDM reported a concept drift. It performed well for abrupt concept drift and obtained more accurate results than that directly learning from the stream. However, DDM was not good at detecting gradual concept drift. Baena-Garc X a et al. [6] proposed an early drift detection method (EDDM) to address this problem. They found that EDDM outperformed DDM on gradual concept drifting data stream. Nishida and Yamauchi [39] explored the STEPD method which used the same learning framework as DDM and EDDM, but it applied statistical test to detect concept one. The shortcoming is that STEPD requires a pre-given sliding window size. As long as the size is information of examples which defers their reaction to concept drift. For example, DDM and EDDM only use the information provided by incorrect classifications, and STEPD only uses the information of correct classifications.

Bifet and Gavald X  [8] presented the work using a variable sliding window to mine time-changing increasing. Whenever a new example is in, ADWIN splits the window into two sub ones, and compares |  X  1  X   X  2 | (  X  1 and  X  2 are the mean of two sub-windows) with the Hoeffding bound. So, the change was found. The drawback is that it takes too much time as the window grows. Although the authors have improved version can degrade the accuracy though the authors state that the degradation is negligible.
The method in [28] handled concept drift by support vector machines (SVM). This was a theoretically proposed to deal with concept drifting data stream [9,25,36,37,49]. Different from the works in this paper, their primary goals are to improve the learning accuracy.
 Though the method can deal with both continuous and disceret data, it cannot address nominal data. So, label. Takeuchi and Yamanishi [50] used the AR model to find change point and outlier in time series. to classification data stream.

The proposed method uses the information entropy of a sliding window to address concept drift detec-determined from Hoeffding bound. The entropy makes full use of the information provided by both cor-rect and incorrect classificat ions. So, ADDM is different from DDM, EDDM and STEPD. Likewise, it is also quite distinct from ADWIN whose change indicator is the difference between two sub-windows. 3. Adaptive sliding window based concept drift detection method 3.1. Overview
The proposed concept drift detection method ADDM is based on the information entropy of an adap-tive sliding window. Firstly, ADDM incrementally builds a classifie r of the original data stream, and of the following four components, viz: 2. Adaptive sliding window det ermination. ADDM works on the time series to determine an appro-3. Entropy based concept drift detection. Once the sliding window is determined, ADDM dynamically 4. Seeking retraining timestamp. Whenever a concept drift is found, ADDM first discards the current 3.2. Online learning
In this work, we denote a data stream example as a pair ( stream: (1) the prequential mode or interleaved test-then-train mode [10]. In this mode, every example is processed successively and separately; (2) the batch/block mode or holdout mode [28], which means the data stream is split into many successive blocks, and each block is treated integrally.
The prequential mode does not need extra storage to store examples, and it makes sufficient use of the already available examples [10,40]; while the batch mode cannot. The prequential mode can be viewed as an incremental single training and output strategy which can be easily extended to batch mode [18, 28,40,47,52].

On this account, ADDM adopts the prequential mode, that is, the learner handles each example once at a time [16,42]. The online learning procedure can be modeled as follows: the future of data stream, Then the label of the example is available for being incorporated to update the learner [18,29 X 31,53].
From the above process, a sequence regarding correct or incorrect classification is formed. The se-quence can be viewed as a time series being made up of 1 and 0. This is true as long as we consider a correct prediction to be 1; while an incorrect one to be 0. 2 3.3. Adaptive sliding window determination
ADDM detects concept drift depending on the entropy of a sliding windo w. Since the entropy is related to the window size, the first important task is to determine the window size. 3.3.1. Basis In this subsection, we introduce the basic theorem in sliding window determination.

The Hoeffding bound [14,23,27], or known as additive Chernoff bound , is stated as follows: with probability 1  X   X  (  X  is the confidence level), the estimated mean after n independent examples of a random variable of range R will not differ from the true mean by more than  X  ,where
The Hoeffding bound gets smaller as the increase of n , which means that if n is large enough,  X  can be small enough. In other words, the estimated mean will fully approximate to the true mean. According to the definitio n of Hoeffding bound, we have the following lemma, Lemma 1. Given two independent samples having n examples from a same random variable, then with probability 1  X   X  ,wehave where is the Hoeffding bound,  X  1 and  X  2 are the mean of two samples, separately.
 Proof. Assume the true mean of the random variable is  X  0 . Applying the Hoeffding bound, we then obtain |  X  1  X   X  0 |  X  and |  X  2  X   X  0 |  X  separately. Now, they can be transformed to  X   X  1  X   X  0  X  and  X   X  0  X   X  2  X  . By summing these two inequalities, we have precisely  X  2  X   X   X  1  X   X  2 2  X   X  , i.e. |  X  1  X   X  2 | 2  X   X  .
 Then, by replacing the  X  of Eq. (1), we have the following results.
 their means will be no larger than two times Hoeffding bound, i.e.
This lemma shows that if Eq. (3) is satisfied, we can use  X  1 or  X  2 to approximate the actual mean of size is large e nough, this le mma will be satisfied (with probability 1  X   X  ).
 we set the minimum sample size to 30, which is a conventional use.
 Then, we have the following results.
 Theorem 1. Assume S 1 and S 2 are two samples both consisting of n ( n 30) examples from a same random variable, the difference between their means will be no larger than 2 ,where  X  is the Hoeffding bound.
 According to the above discussions, we can obtain the following lemma, Lemma 3. If we intend to use  X  1 or  X  2 to approximate  X  0 (is unknown), the following two conditions must be satisfied: (1) sample size n 30 ;
Having this lemma, even though we know nothing about a variable, it can theoretically estimate the variable X  X  mean ,aswellasthevariantof mean , e.g. information entropy. This is valid since the entropy can be viewed as an average value. 3.3.2. Sliding window size determination to approximate. Here the sample is viewed as a sliding window.
 of a data stream both having equal amount of examples, and they both slide along the time series ob-We present the algorithmic description of sliding window determination method as follows. are added into the classification time series and the procedure is repeated (lines 8  X  13 ).
As stated in Lemma 3, we set the initial window size to 30 examples according to the conventional concept X  X  nature. 3.4. Entropy based concept drift detection
ADDM uses the determined sliding window upon the classification time series, and dynamically mon-itors the entropy of the window to detect concept drift.
 Procedure 1 Determine sliding window size Require: Ensure: 1: initialize S as the first 2 N 0 examples of TS; 2: for i =2 N 0 to the end of TS do 3: S 1  X  first half part of S; 4: S 2  X  second half part of S; 5: N  X  number of examples in S 1 (or S 2 ); 6:  X  1  X  mean ( S 1 ) ,  X  2  X  mean ( S 2 ) ; 8: if |  X  1  X   X  2 | then 9: sw  X  N ; 10: return sw ; 11: else 12: i  X  i +2 ; 13: end if 14: end for 3.4.1. Basis In information theory, entropy is used to measure the uncertainty associated with a random variable. For a database only containing two elements, suppose 0 and 1, the entropy can specifically be defined as, the logarithm to 2.

Assume a sample from a database only contains 1 and 0, where 0 and 1 are fifty-fifty. That is, both p of extreme impurity has the maximum entropy 1. On the other hand, for a sample only contains 1 or 0, which means the sample is pure ( p 0 =1  X  p 1 =0 or p 0 =0  X  p 1 =1 ). Then the value of the entropy p 0 &lt; 1 / 2  X  p 1 &gt; 1 / 2 , the entropy will be smaller than 1 but larger than 0 ( H  X  (0 , 1) ). Then, we have the following lemma.
 Lemma 4. Given a binary sample where 0 and 1 are skew distributed, its entropy will be smaller than 1. the entropy equals 1.

In the next subsection, we will detail how to use this lemma to quickly find concept drift. 3.4.2. Concept drift detection method
Here we consider the following hypothesis: for a stable data stream where no concept drift occurs, can be viewed as containing only one concept, and more examples provide more information which can make the classifier more sophisticated. Then, according to the prequential learning mode (please see fluctuate faintly) from beginning to end.
 in this window. Thus, if no concept drift occurs in data stream, the entropy in the sliding window of classification time series is smaller than 1 and remains stationary.

Unfortunately, a concept drifting data stream will violate the above hypothesis. During the transfor-window will first rise and then down. Within this period, the entropy reaches its maximum value when the sliding window is totally impure. This can be a signal of concept drift and we use it as a change indicator in our method.
 To summarize, we have the following theorem.
 Theorem 2. That the entropy over the sliding window equaling to 1 suggests a concept drift; Otherwise, no concept drift occurs. The sliding window size is determined from Lemma 3.

Then, according to Theorem 2, the specific procedure of the concept drift detection method is as entropy of it and compare its value to 1; Whenever this instruction is satisfied, our method reports a concept drift.

The algorithmic pseudo code of the method is presented above: (1) the sliding window SW is firstly initialized as the first sw points of classification time series TS (line 1); (2) the entropy of SW is the entropy equals to 1, ADDM reports a concept dri ft, and calls MB-GT algorithm to find the optimal retraining timestamp (lines 5  X  8); (4) while no concept drift is found, ADDM goes to the next points. This procedure is iterated till the end of data stream. 3.5. Seeking retraining timestamp
Whenever a concept drift is detected, the classifier needs to be rebuilt. But, the declared time com-make use of the available examples between the true concept drift and the detected one. This probably degrades the classifier X  X  performance on new concept.

DDM, EDDM and STEPD set a warning threshold in their separate works [6,18,39]. When monitor-ing the change indicator, if the value exceeds the warning, these method begins storing examples for Procedure 2 Detect concept drift Require: Ensure: 1: initialize SW as the first sw points of TS ; 2: while not at end of stream do 3: t 0  X  the current timestamp; 4: calculate H ; 5: if H == 1 then 6: report concept drift at t 0 ; 7: t r  X  MB-GT(SW);{ t r is the retraining timestamp obtained by MB-GT algorithm} 8: retrain classifier from t r ; 9: end if 10: slide SW by1example; 11: end while declared drift time always contains delay. Thus the warning moment cannot be exact, too. To over this shortcoming, we integrate MB-GT algorithm in ADDM to find the retrai ning timestamp. This algorithm finds the retraining timestamp as exact as it can to rebuilt the classifier.

MB-GT, acronym for Memory Based Graph Theoretic, is proposed to identify change point from a graph-theoretic perspective [38]. It works on the assumption that only one change occurs in a time one concept drift occurs within the sliding window. In the method, MB-GT divides a sliding window suppose consumption (please refer to [38] for details).

In our method, MB-GT works as follows: (1) when a concept drift is detected, it divides the current window has been divided for sw  X  1 times, MB-GT outputs the time step having the maximum C i,j . Finally, the time step is assigned the timestamp for retraining.
 by MB-GT will not be expensive. Note that when retraining the classifier, the sliding window is also recalculated from the algorithm in Section 3.3.2. 4. Experiment and results 4.1. Data source drift. Therefore, only using real world data sets could not exhaustively access the performance of a diverse concept drifts for evaluation. To thoroughly evaluate ADDM, we use seven data sets in the publicly available, thus the experimental results are reproducible. 4.1.1. Artificial data sets Thus they are fully diverse. 1. Gauss . This data set contains abrupt concept drift and noise. It has two relevant attributes. The 5. Sine1g . This data set contains very slow gradual concept drift, and does not contain noise. It is 4.1.2. Real world data sets
Apart from the artificial data sets shown above, we also use two real world data sets. There are two been used by more than one researchers [6,8,18] which demonstrates their effectiveness. 2. Elec2 (Electricity market data) . Elec2 is collected from Australian New South Wales Electricity 4.2. Experimental method 4.2.1. Validation method
In order to evaluate the proposed method, we compared it with four drift detection methods, i.e. drift detection method (DDM) [18], early drift detection method (EDDM) [6], adaptive sliding window algorithm (ADWIN) [8] and statistical test based detection method (STEPD) [39]. All methods run upon generalize examples. They are nearest-neighborhood classifier (IB1) [4], tree-based classifier (J48 or SVM [24]. All classifiers in the experiments are implemented in WEKA, a well known machine learning workbench. 5 and all parameters of four classifiers are set to default as they are in WEKA. 4.2.2. Evaluation criteria
For an abrupt concept drift, its occurring time can be easily known. This is because that abrupt drift presents dramatically change and we can clearly define it. However, in a gradually changing environ-criteria for different types of concept drift.
 criteria here. Firstly, we entail the following definitions:  X  False positive (FP). It is the timestamp when the method declares a concept drift, while no concept  X  False negative (FN). It is the timestamp when a concept drift indeed occurs, while the method
Then, the corresponding quality metrics, such as precision and recall , can be defined, viz: For both precision and recall , a higher value suggests a better performance.
 We also utilize the criteria of false positive rate (FPR) and the false negative rate (FNR), where FPR also means the false alarm rate FNR also means the miss detection rate . For both of them, a higher value suggests a worse performance.

Another evaluation criterion is the mean delay which denotes the averaged delay of each TP. The mean delay is defined as, For mean delay, a higher score means worse results, suggesting a worse real-time performance. learning algorithm X  X  performance. It is defined as the average accuracy obtained from each example to be learned. The prequential accuracy at timestamp t can be obtained from Eq. (8) [6,37]. the prequential accuracy is the higher the better, suggesting a better performance.
 The last evaluation criterion is runtime . Obviously, the value is the smaller the better.
Evaluation criteria upon gradual concept drift data sets . Since it is impossible to exactly define a abrupt concept drift.

On this account, in order to evaluate our methods as well as other benchmarks, we use the prequential accuracy as a criterion. Its value can obtained from Eq. (8). Here a higher prequential accuracy also suggests a better performance.

The other evaluation criterion is the runtime , whose score is the smaller the better. 4.3. Results and analysis 4.3.1. Experiments on artificial data: Abrupt concept drift
The empirical results show that all methods cannot declare a concept drift exactly when one in fact occurs, which means every method has detection delay. Once the threshold of delay is determined, the this account, we portray the precision-delay, recall-delay, FPR-delay and FNR-delay curves for each axis shows the delay value. When drawing these curves, we change the value of acceptable delay to tune the corresponding rate. To make reasonable, we consider the maximum delay is 100, indicating that a declared drift arises within after 100 examples from the true concept drift can be acceptable. When increasing the delay, the TP number can be increased while the FP and FN number are decreased. Hence left to right in figures.

Figures 1, 2, 3 and 4 show the curves in terms of precision-delay, recall-delay, FPR-delay and FNR-rest methods with all four used classifiers. Though DDM can obtain the same value to ADDM with J48, it has more delay; (2) for the recall, ADDM achieves t he maximum value with th e least delay, which means it again outperforms those benchmarks regardless of the wrapped classifier; (3) From Eqs (6) and (7), its clearly that precision + FPR =1 , recall + FNR =1 . Thus the FPR-delay curve and FNR-delay curve are the mirror figures of the precision-delay curve and recall-delay curve separately across the vertical direction. Due to ADDM X  X  better performance on precision and recall, we observe that it also outperforms four benchmarks in terms of FPR and FNR. For example, ADDM X  FPR gets 0 within about 15 examples delay when using IB1, J48 and NNge. While none of those other methods can do this, which means they all have higher FPR than ADDM. For the FNR, though most methods can get value of 0, ADDM has the least delay, which suggests that ADDM has the least miss detection. All these results indicate that the proposed method ADDM wins out in this round.
 when using classifier IB1 and J48, ADDM and EDDM can obt ain the best precision. i.e. 1, while those others cannot. Besides, when NNge and SVM are wrapped, ADDM and DDM can reach the highest precision, outperforming the rest three methods. This means ADDM performs consistently and obtains higher precision than those benchmarks; (2) For the recall, there are four methods, i.e. DDM, EDDM, ADWIN and ADDM, can get the best value of 1. But, A DWIN needs too many delay to achieve. This indicates that ADDM , DDM and EDDM perform similarly no mat ter which classifie r is used, and are better than ADWIN and STEPD; (3) For the evaluation criteria FPR, ADDM reaches the value of 0 regardless of used classifiers, and those rest methods cannot do this consistently; (4) From the FNR-delay curve, DDM, EDDM and ADDM are outperformers, and their delay are all less than about 15 examples. The results o n this data set revel that ADDM perform s consistently and s tably no matter which classifier is used, and thus it is better than four benchmarks.
 The four rates curves upon Sine1 is contained in Fig. 3. We can observe that: (1) for the precision, ADDM obtains the highest value, i. e. 1, with all four used classifiers, while DDM and EDDM can only those methods; (2) for the recall, ADDM, DDM and ADDM has similar curves which means they all can find all the concept drift. Though ADWIN and STEPD can do the same, they both require more delay; (3) from the FPR-delay and FNR-delay curves , ADDM, DDM and EDDM are better than ADWIN and to DDM and EDDM, and they all are better than ADWIN and STEPD.

Figure 4 contains the four curves upon Stagger. From it, we can find that: (1) DDM is the best per-former on precision, since it not only achieve the highest precision, but also successfully detect all concept drifts when using NNge. For the rest four methods, they all fail to detect when wrapped with NNge; (2) Except for DDM, ADDM performs better than those rest detection methods. This is also the situation for the criteria recall, FPR and FNR.

We also present the mean detection delay of each method in Table 2. When calculating their scores, we assume all the declared concept drifts are acceptable and average them. Thus a method detects more in boldface. From the table, we can observe that: (1) ADDM has the least mean delay on Gauss and Sine1 (only inferior to DDM and EDDM on Sine1 with IB1 wrapped); (2) though ADDM are not the For this reason, by averaging these delay, we obser ve that ADDM holds the smallest value of 20.1 (row AvgDelay), which is smaller than that of DDM (26.6), and is quite better than that of EDDM (134.2), ADWIN (359.8) and STEPD (401.7). This means that EDDM X  X  delay is about 6 times that of ADDM, ADWIN X  X  is about 18 times and that of STEPD is about 20 times. In order to make clearly, we rank all and thus demonstrates its better performance than those benchmarks.
 Since the prequential accuracy is a measure used to show the performance along with time, here we that: (1) ADDM wins out on Gauss w hichever classifier is used; (2) it inferiors to DDM and EDDM on Mixed, Sine1 as well as Stagger. This seems t hat our method ADDM performs badly at first glance, but, it is not the truth. We can observe that ADDM X  X  accuracy is only slightly lower than that of the outperformer X  X . For example, on Mixed when SVM is used, ADDM X  X  accuracy is 0.9387, which is only 0.0004 smaller than that of EDDM (0.9391). This is quite an insignificant gap. Therefore, when ADDM ranks the first, which means it has consistently more accurate results than those other methods.
Table 4 contains the comparison results in terms of runtime. From it we find that our method wins out for 5 out of 16. Though this is not a high proportion, ADDM X  X  averaged time consumption (82) is smaller than that of DDM (87), EDDM (85) and ADWIN (84), suggesting that it only takes more time than STEPD (row TimeRank). This reveals that ADDM outperforms three methods. Similarly, the rank is presented in the last row of the table.
 the rank score, i.e. the sum of DelayRank, PreAccRank and TimeRank, in Table 5, where a smaller value stands for a better general performance. We obser ve that ADDM scores 4, which is much smaller than those four benchmarks. For ex ample, the value of DDM is 2.25 times that of ADDM, EDDM  X  X  and STEPD X  X  are 2.5 times, and that of ADWIN is 3 times. We again rank all five methods according to their respective RankScore, which shows that ADDM ra nks first. This revels t hat ADDM outperforms four data stream. 4.3.2. Experiments on artificial data: Gradual concept drift Gradual or slow concept drift is more complicated, however which occurs commonly in real world. In this experiment we employ Sine1g as a simulation. As stated earlier, we cannot calculate precision, recall etc. as on abrupt concept drift data sets, thus prequential accuracy and runtime are used here.
Table 6 shows the final prequential accuracy obtained by four classifiers equipped with distinct de-tection methods, where the highest value is presented in boldface. It is obviously that ADDM holds averaged prequential accuracy is also better than that of all benchmarks. In the ranking row, ADDM correspondingly ranks first (row PreAccRank).

Figure 5 contains the detailed prequential accuracy which is obtained successively from every exam-ple. These figures shows a streaming method X  X  performance during the prequential process. We observe that all ADDM X  X  curves are above that of those ben chmarks, especially wh en using classifier NNge. This means no matter which classifier is used, the prequential accuracy of ADDM is higher than those methods X , i.e. DDM, EDDM, ADWIN and STEPD. Thus the results of these figures demonstrate the results obtained from Table 6 that ADDM obtains better accuracy than all benchmarks.
Table 7 contains the runtime of each concept drift detection method. From the table we find that ADDM takes less time than DDM and EDDM, but c onsumes more time than ADWIN and STEPD. When ranking all five methods, ADDM ranks third, i.e. the middle of five methods (the last row).
Table 8 contains the rank score of all five methods, which is the sum of prequential accuracy rank and time rank. Here a small score means a better re sult. From this table, ADDM scores 4, which is the concept drift. 4.3.3. Experiments on real data: Abrupt concept drift
In this subsection, we experimentally evaluate the proposed drift detection method X  X  performing on real abrupt concept drifting stream, i.e. Elist.
 methods. From them we observe that: (1) for the precision, ADDM are better than EDDM, ADWIN and STEPD, and only inferior to DDM with IB1 used. This means ADDM successfully finds all the four concept drifts occurs every 300 examples excep t for using classifier IB1; (2) for the recall, ADDM than DDM when using IB1; (4) for the FNR, ADDM gets the lowest score, i.e. zero, suggesting it is the best method in false negative reporting.

We present the summarized results of five respective methods with four classifier in terms of mean delay in Table 9, where the minimum is reported in boldface. The delay of ADDM are small and it wins out for two times. Though ADDM loses to DDM with NNge and SVM, thereinto its delay are slightly larger than that of DDM. For instance, DDM X  X  de lay is 16 with SVM and that of ADDM is 16.25, which is a tiny difference. For this reason, ADDM obtains the smallest mean delay among all five methods. Most importantly, its value are far less than that of EDDM, ADWIN and STEPD, i.e. the mean delay of EDDM is 3.1 times to DDM, and that ADWIN X  X  is 4.3 times and STEPD X  X  is 6.3 times. To summarize, we rank them according to their separate mean delay, and show them in the last row of the table. Again we find that ADDM ranks first, which means it out performs DDM, EDDM, ADWIN and STEPD on this criteria.
 racy, where the highest one is reported in boldface. Unfortunately, we observe that ADDM wins out only once (0.8047 obtained with J48) and inferiors to DDM for three times, however its averaged accuracy (0.7922) is the highest (row AvgPreAcc), indicating that ADDM performs consistently regardless of the again ADDM stands in the first place.

For the runtime, all methods X  separate results are presented in Table 11. We find that ADDM only takes less time than ADWIN, and it takes more time than DDM, EDDM, and STEPD, which means it is not a good method in time consumption. By averaging the results over all four classifiers, ADDM obtains 338, still a h igher value than that of DDM (297), E DDM (262) and STEPD (104). As a result, ADDM ranks the forth among all five methods (the last row).

To summarized, Table 15 shows the rank score obtained from all evaluation criteria. In this table, a small value indicates a better performance. We observe that ADDM obtains score of 6, which is the on real abrupt concept drift data set Elist. 4.3.4. Results on real data: gradual concept drift is also unknown. Therefore, we use the prequential accuracy and the runtime for evaluation. ing algorithms, and Fig. 7 presents the trace of separate prequential accuracy of all methods.
From the table we observe that ADDM only perform s better than ADWIN, and is inferiors to EDDM and STEPD. By averaging their respective accuracies and ranking them, we find that ADDM ranks of accuracy, which is consistent with the results in Table 13.

Table 14 contains the time consumption when all five methods running with different classifiers. From are time-saving. While when J48 and SVM is used, the time consumption is significantly large. In this round, ADDM obtains the ranks score of 4, which means it is inferior to three methods, i.e. STEPD, DDM and EDDM, and only performs better than ADWIN.
Table 15 contains the rank score of all five methods on this real data. Here a higher score means a worse performance. From this table we find that ADDM unfortunately obtains 8, a quite high score. At the ranking row, ADDM ranks fourth among these methods (the last row). 4.3.5. Discussion
The experimental results show that our proposed method ADDM obtains more better results, such as methods for most cases at least for these experimental data sets.

For the artificial abrupt concept drift data sets, ADDM outperforms those benchmarks in terms of data set, ADDM is also the best performer in terms of prequential accuracy among all five methods, regardless of wrapped classifiers.
 For the real abrupt concept drift data set Elist, ADDM wins out not only on precision, recall, FPR and FNR, but also has the least mean delay and more accurate prequential accuracy than those benchmarks. While for the real data set Elec2, ADDM is only be tter than ADWIN, and performs similarly to DDM, and is inferior to the rest competing methods EDDM and STEPD.

Overall, to show the general performance of the proposed method upon all types of concept drift data separately.

From the table we clearly observe that ADDM ranks the first among all five methods on artificial data set, which means ADDM are the best method at least for these used data sets. Though ADDM is data stream concept drift detection. 5. Conclusion
In this paper, we have proposed a novel approach based on the information entropy over an adap-tive sliding window to address concept drift detection in data stream. The use of the entropy makes the method response quickly. Most importantly, the sliding window size is dynamically determined according to each concept X  X  separate character, which is more suitable to an evolving data stream.
In order to evaluate the performance of the proposed method, we have used seven publicly available (DDM) [18], early drift detection method (EDDM) [6], adaptive sliding window algorithm (ADWIN) [8] show that the proposed method outperforms those four methods in terms of precision, recall, mean proposed method only loses upon Elec2, one out of seven data sets, which is quite a low proportion. The results reveal the encouraging performance of the proposed method and indicate its considerable potential.
 Acknowledgements
The authors would like to thank all the editors and reviewers for their insightful comments and sug-gestions. This work is supported by the National Natural Science Foundation of China under grant NO. 61070006, and the Ph.D. Programs Foundation of Ministry of Education of China under grant NO. 20110201110007.
 References
