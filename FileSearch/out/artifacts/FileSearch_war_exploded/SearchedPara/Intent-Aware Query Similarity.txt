 Query similarity calculation is an important problem and has a wide range of applications in IR, including query rec-ommendation, query expansion, and even advertisement mat-ching. Existing work on query similarity aims to provide a single similarity measure without considering the fact that queries are ambiguous and usually have multiple search in-tents. In this paper, we argue that query similarity should be defined upon search intents, so-called intent-aware query similarity . By introducing search intents into the calculation of query similarity, we can obtain more accurate and also informative similarity measures on queries and thus help a variety of applications, especially those related to diversi-fication. Specifically, we first identify the potential search intents of queries, and then measure query similarity under different intents using intent-aware representations. A reg-ularized topic model is employed to automatically learn the potential intents of queries by using both the words from search result snippets and the regularization from query co-clicks. Experimental results confirm the effectiveness of intent-aware query similarity on ambiguous queries which can provide significantly better similarity scores over the traditional approaches. We also experimentally verified the utility of intent-aware similarity in the application of query recommendation, which can suggest diverse queries in a struc-tured way to search users.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Query formulation Algorithms, Experimentation, Performance, Theory Query Similarity, Search Intent, Regularized Topic Model, Pair-wise Measure, Graph-based Measure
Calculating similarities between queries is a key element of various IR applications. For example, query recommenda-tion [2, 34] manages to provide similar queries to users and help them to reformulate their queries regarding their in-formation needs. In query expansion [14, 17], similar terms (words) are added to improve the recall of search, and the expanded query can also be considered as a similar query to the original query. Besides , query similarity can also be helpful to advertisement matching [29]. However, due to the high ambiguity of queries, how to properly define the similarity between queries is not a trivial problem. For ex-ample, given query  X  X pple X , it is similar to  X  X pple tree X  if the searcher is looking for apple fruits, while it is also similar to  X  X pple store X  if the search intent is to find products of the apple company. The similarity is actually not compa-rable across different search intents, which means that we cannot say  X  X pple tree X  is more similar to  X  X pple X  than  X  X p-ple store X  and vice versa. In this paper, we argue that the similarity between queries should be defined upon search intents, so-called intent-aware query similarity .Notethat search intent here refers to the goal or need of a user during a search. In this manner, we can provide more precise and also informative similarity information without being biased by popular intents or wrongly making queries from different intents similar. Evidently intent-aware query similarity will be especially helpful for various diversity problems.
To the best of our knowledge, none of existing work for-mally addressed the problem of similarity calculation with the awareness of search intents and thus it is the unique po-sition of this paper. Also it is important to notice that tra-ditional similarity measures may encounter some problems when dealing with ambiguous queries, namely the queries with multiple search intents. Various data sources, including search results [30], user clicks [2, 26, 13] and search sessions [34, 9], have been employed to enrich the representation of search queries. While similarity measures defined on these representations can be divided into two major categories:
Pair-wise Measures . The similarity is independently mea-sured on each query pair, using similarity functions like co-sine similarity [2, 33], Jaccard coefficient [3], kernel functions [30], etc. For ambiguous queries, the information from mul-tiple search intents are actually mixed together and thus pair-wise measures without the awareness of search intents will be easily biased by dominant search intents and ignore unpopular ones, for example query  X  X pple X  is only similar to  X  X pple store X  but not related to  X  X pple tree X .

Graph-based Measures . The similarity between queries is defined on a query graph, or query relation graph [13, 9]. It means that the similarity is not pair-wise independent and the similarity of adjacent queries is considered. In some sense, graph-based measures can be considered as propa-gating the similarity on top of the query graph. However, if the queries are ambiguous, the propagation should not cross the boundary of different search intents. Without the awareness of search intents, the queries with different search intents will be wrongly connected, for example  X  X pple store X  becomes similar to  X  X pple tree X .

In this paper, as the first attempt, we cast some light on the problem of  X  X ntent-aware query similarity X . Specifically, we propose first identifying the potential search intents of queries, and then measuring query similarity under differ-ent search intents using intent-aware representations. Note that the identification of potential search intents of queries are largely different from classifying the queries into a set of predefined categories [23, 12], since the search intents of queries are usually fine-grained and substantial. In our work, a regularized topic model is employed to automatically learn the potential intents of queries by using both the words from search result snippets and the regularization from query co-clicks. Based on the learned intents of queries, we then ex-tract the query representation under each intent, and thus different measures can be applied to measure query similar-ity with respect to different search intents. Both pair-wise measures (e.g., cosine similarity measure) and graph-based measures (e.g., spectral embedding [4]) can be easily applied.
While there are many applications requiring a similarity measure between queries, one direct application in the con-text of search is query recommendation. In this paper, we adopt query recommendation as an example to demonstrate the usefulness of introducing search intent into the calcula-tion of query similarity. With our approach, we can identify similar queries to the user X  X  initial query with respect to different search intents, and then a structured query rec-ommendation [19] can be easily built by grouping diverse recommendations based on the search intents.

We conducted experiments based on a large collection of query logs and search results from a commercial search en-gine, and demonstrated the effectiveness of our intent-aware query similarity by comparing with other baseline methods. Experimental results show that by identifying search intents of queries, we can measure query similarity significantly bet-ter than traditional approaches. We also demonstrate that by grouping query recommendations based on search intents and presenting them in structured way, we can largely en-hance users X  click behaviors on recommendations.

The rest of the paper is organized as follows. Section 2 introduces related work. Section 3 describes our solution to intent-aware query similarity. Section 4 discusses applying our application to query recommendations. Experimental results are presented in Section 4. Conclusions are made in the last section.
Measuring similarity between queries is an interesting and difficult problem. A reliable query similarity measure can be very useful for a variety of applications such as query rec-ommendation [2, 34, 26], query reformulation [32, 1, 22], query expansion [14, 17], and advertising [29]. However, since queries are usually very short and ambiguous, it is difficult to calculate their similarity only based on query terms. Many existing approaches resolve the information inadequate problem in query by leveraging auxiliary infor-mation, including search results [30], clickthrough [2, 26, 13] or search sessions [34, 9], to enrich query representation for better similarity measurement.

Based on the augmented representation of queries, two major approaches are then applied to measure similarity be-tween queries:
Pair-wise Measures . The similarity is independently measured on each query pair using pair-wise metrics. For example, Beeferman et al. [3] leveraged Jaccard similarity coefficient over the clickthrough vector of queries as the similarity measure. Baeza-Yates et al. [2] calculated query similarity using cosine similarity based on the aggregation of the term-weight vectors of the URLs clicked after the query. Wen et al. [33] applied various similarity metrics over both query term vectors and clickthrough vectors to measure query similarity, including term overlap, cosine similarity, edit distance, and Jaccard coefficient. Typical approaches using the hybrid similarity measurements over queries can also be found in [34, 22]. In [16], Deng et al. introduced two new schemes for representing queries based on clickthrough and applied both cosine similarity and Jaccard coefficient for measuring query similarity. In [30], Sahami et al. pro-posed a Kernel Function for mea suring the query similarity based on the Tf-Idf weighted vectors of search result snip-pets. However, for ambiguous queries, the information from multiple search intents are actually mixed together and thus pair-wise measures without the awareness of search intents will be easily biased by dominant search intents and ignore unpopular ones.

Graph-based Measures . The similarity between queries is defined on a query graph, or query relation graph [13, 9]. Therefore, the similarity is not pair-wise independent and the similarity of adjacent queries is considered. In some sense, graph-based measures can be considered as propagat-ing the similarity on top of the query graph. For example, Craswell et al. [13] applied two types of random walk pro-cess to propagate the query similarity along the query-URL bipartite graph and obtain better similarity scores between queries. Mei et al. [26] described a random walk on the one-mode query graph and employed the hitting time as the similarity measure. In [1], Antonellis et al. used the bipar-tite SimRank on the query-URL graph to measure query similarity. In [24], matrix factorization was employed to calculate query similarity based on the user-query-URL tri-partite graph. Recently, Bordino et al. [9] introduced the query-flow graph based on the session data and employed graph projection to measure query similarity. Work on such a graph to compute query similarity can also be found in [7, 8]. However, if the queries are ambiguous, the graph-based measures without the awareness of search intents will wrongly connect the queries with different search intents.
Related work also includes topic modeling. Topic mod-eling has been popularly used for data analysis in various domains including topic discovery, document classification, citation analysis, and social network analysis. Topic mod-els, such as Probabilistic Latent Semantic Indexing (PLSI) [21] and Latent Dirichlet Allocation (LDA) [6] have shown impressive empirical success in revealing the hidden struc-tures of documents and in related applications like document classification and collaborative filtering. Based on the above models, a set of variants and extensions [18, 5, 31] have been further proposed to address document modeling problems in different scenarios. Our work exploits topic modeling in a new application (i.e., query similarity measure), and we employed a regularized topic model to fully leverage both search result snippets and co-clicks to help learn the search intents of queries. There have been several regularized topic models proposed to incorporate auxiliary knowledge as a constraint into topic model learning process and show the resulting benefits. For example, Cai et al. proposed two topic models, Laplacian pLSI (LapPLSI) [10] and Locally-consistent Topic Modeling (LTM) [11], which incorporate manifold structure information as a constraint into the PLSI model to smooth the probability density functions. Simi-larly, Mei et al. [25] regularized the statistical topic model PLSI with a harmonic regularizer based on a graph structure in the data. In [20], Guo et al. introduced a weakly super-vised topic model, i.e. WS-LDA, by incorporating human labels as a soft constraints into the LDA model to supervise the topic alignment.
In our work, we propose to measure query similarity with the awareness of search intents. The key idea is that we first identify the potential search intents of queries, and then measure the query similarity under different search intents using their intent-aware representations. As afore-mentioned, there are a large amount fined-grained poten-tial search intents behind different queries (e.g. the fruit or product intent for query  X  X pple X ), and it is usually difficult to define an appropriate prior taxonomy for search intents. Therefore, we propose to leverage the large amount of hid-den topics in topic model to help capture the potential search intents of queries.

Specifically, a regularized topic model is employed to au-tomatically learn the potential intents of queries by using both the words from search result snippets and the regular-ization from query co-clicks. Based on the learned intents of queries, we then extract the query representation under each intent, and thus different measures can be applied to measure query similarity with respect to different search in-tents. Both pair-wise measures (e.g., cosine similarity mea-sure) and graph-based measures (e.g., spectral embedding) can be easily applied.

In this section, we will first introduce the auxiliary data we leveraged for identifying the search intents of queries. We then describe the regularized topic model for the key learn-ing problem. Finally, we show how to extract the query representation under each intent, and apply different sim-ilarity metrics to measure query similarity with respect to search intent.
In order to identify the potential search intents of queries, we need to leverage some auxiliary data to provide a rich representation for short queries. Different types of auxiliary data, including search results [30], clickthrough [2, 26, 13] or search sessions [34, 9], have been leveraged to enrich query representation for similarity measurement in many existing approaches. For ambiguous queries, such auxiliary data is a mixture of information from multiple search intents. How-ever, traditional approaches usually directly leverage such kind of mixed-intent representations of queries for similarity measure. In our work, we leverage both search result snip-pets and clickthrough of queries to help learn the potential search intents of queries. This is largely different from the traditional work.

Although both the two types of data can provide rich in-formation for identifying potential search intents of queries, they have some natural different characteristics. The search result snippets provide a great context for the query. We can thus construct a virtual document by the words from the snippets of the top search results to well  X  X escribe X  the given query. Thanks to the advance of modern search en-gines, such a description often show a high recall of potential search intents of the given query. Take the query  X  X ffice X  for example, a typical search results from the commercial search engines (e.g. Google, Bing or Yahoo!) may contain the con-tent about the microsoft office software, the office tv series, and even some office furniture or supplies. However, search results may also have some irrelevant, spam or advertise-ment information, and words itself may have ambiguity. All these factors may hurt the quality or precision of the search result snippets on resolving search intents of queries.
Meanwhile, the large amount of clickthough data from search logs also provide us useful information for identifying search intents of queries. Unlike the search result snippets, clickthrough information is a resource with higher precision but lower recall. As we can see, although one query may convey multiple search intents, it is often determined when a specific URL is clicked. Therefore, if two queries share a set of same clicked URLs, they will convey similar search in-tent [2, 3]. The  X  X isdom of the crowds X  property thus makes clickthrough, especially the query co-clicks, a more precise resource for identifying similar search intent of queries. How-ever, query co-click information is relative sparse (i.e. lower recall) in describing search intents compared with the search result snippets, since usually there are limited clicks for each query.

Based on the above analysis of the different characteristics in search result snippets and clickthrough, we propose to simultaneously leverage the two types of auxiliary data in our work so that they can supplement each other in resolving search intents of queries.
From previous section we can see, the search result snip-pets provide rich context information for a given query. We can thus construct a virtual document by the words from the search result snippets to describe the given query and capture its major search intents. Since queries may con-vey multiple search intents, it is natural to apply a mixture model (e.g. topic model) over the virtual document of the query to help learn the potential search intents. Meanwhile, the clickthrough information, especially the query co-clicks, provides us clear evidence about which queries convey the similar search intent. Such evidence can be used as a pow-erful constraint over the intent distribution of queries to help us reveal the search intents of queries more accurately. Therefore, we propose to employ a regularized topic model to fully leverage the two types of auxiliary data to help learn the potential search intents of queries. Suppose there is a collection of N queries Q = { q 1 ,...,q sharing the same set of K potential search intents S { s 1 ,...,s K } , and each query is represented by a set of words w  X  X  = { w 1 ,...,w M } , which are collected from its top search result snippets. By viewing queries as virtual  X  X oc-uments X , words from top search result snippets as  X  X ords X , and potential search intents as  X  X opics X , we can apply the Probabilistic Latent Semantic Indexing (PLSI) [21] to model the generation of each query and its words from top search result snippets by the following scheme: 1. select a query q i with probability P ( q i ), 2. pick a potential search intent s k with probability P ( 3. generate a word w j with probability P ( w j | s k ).
By summing out the latent variable s , the joint probability of an observed pair ( q i ,w j ) can be computed as Based on this joint probability, we can calculate the log-likelihood as  X  L = where n ( q i ,w j ) denotes the number of times word w j curred in the top search result snippets of query q i . Follow-ing the maximum likelihood principle, one can determine the model parameters { P ( w j | s k ) ,P ( s k | q i ) } the relevant part of Equation (2).

Recall that the query co-clicks provide us clear evidence about similar search intent between queries. That is, if two queries share many same clicked URLs, they convey similar search intent. Therefore, we can use the co-click information as a constraint over the search intents of queries to help us reveal the intents more accurately. More formally, we need to minimize the proximity of the probability distribution P ( s | q ) of co-clicked query pairs, expressed by where matrix C contains the co-click relationship between queries with C ij set as unique co-clicked URL number of the query pair ( q i ,q j ). Note that other definitions for the co-click matrix C and proximity measure can also be used.
Now we give out the regularized topic model for identi-fying potential search intents of queries. The model adopts the generative scheme of PLSI. It aims to maximize the reg-ularized log-likelihood as follows:
L = L X   X  R where  X  is the regularization parameter. Note that the reg-ularized topic model essentially have the same form of the LapPLSI model proposed by Cai et al. [10]. However, in their case, they adopted the manifold structure information from document dataset to help modeling latent topics in the same document collections. While in our problem, we adopt the regularized topic model to effectively combine the two different types of data (i.e. search result snippets and query co-clicks) in the learning task for identifying the potential search intents of queries.
The standard procedure for maximum likelihood estima-tion in latent variable model is the Expectation Maximiza-tion (EM) algorithm [15]. Here we use the Generalized EM algorithm [27] for parameter estimation in our regularized topic model as [10]. The major difference between Gener-alized EM and traditional EM is that in the M-step, Gen-eralized EM only finds parameters that  X  X mprove X  the ex-pected value of the complete data log-likelihood function rather than  X  X aximizing X  it.
 In our model, we have NK + MK parameters { P ( w j | s k ), P ( s k | q i ) } to be estimated, which is the same as PLSA. For simplicity, we define  X  = { P ( w j | s k ) } and  X  = { P
E-step: The E-step of the regularized topic model is ex-actly the same as that of PLSI. By applying Bayes X  formula, we compute posterior probabilities.

M-step: In M-step, we maximize the expected complete data log-likelihood which is Q ( X  ,  X ) = Q 1 ( X  ,  X )  X   X Q 2 ( X )
The M-step re-estimation equation for  X  is exactly the same as PLSI since the regularization term does not include P ( w j | z k ).

However, we do not have a closed form re-estimation equa-tion for  X . Based on the concepts of Generalized EM, we re-estimate  X  by increasing Q ( X ) rather than maximizing it. Specifically, let {  X  n ,  X  n } denote the parameter values of the previous iteration and {  X  n +1 ,  X  n +1 } denote the parameter values of the current iteration. We first find {  X  n +1 , which maximizes Q 1 ( X  ,  X ) instead of the whole Q ( X  ,  X ) us-ing the re-estimation Eqn. (7) and (8) for  X  and  X  respec-tively.
 We then try to start from  X  (1) n +1 and decrease Q 2 ( X ), by using the Newton-Raphson method [28]. Therefore, we can obtain the closed form solution for updating  X  n +1
P Algorithm 1 Generalized EM for Regularized Topic Model where 0  X   X   X  1 is the step parameter. It can be easily hold in Eqn. (9) as long as K k =1 P ( s k | q i ) ( t ) P ( s k | q i ) ( t ) n +1  X  0. Note here  X  n +1 will be fixed since does not include  X .

The iteration of Eqn. (9) is repeated until Q ( X  n +1 ,  X  Q Q ( X  n ,  X  n ). If it is not true, we reject the proposal of  X  n +1 } and return {  X  n ,  X  n } as the result of the M-step, and continue with the next E-step. The specific model fitting al-gorithm for the regularized topic model is summarized in Algorithm 1.

Finally, we obtain the probability P ( s k | q i ) for each query q , which denotes the distribution of potential search intents of the query, and the probability P ( w j | s k )foreachintent which denotes the distribution of words under each search intent. Here we further cut off the search intent with the proportion under a pre-defined threshold (e.g. 0.1 in our case) for each query to only preserve its major intents and avoid potential noises.
Based on the learned intents of queries, here we show how to extract the query representation under each intent, and apply different metrics to meas ure query similarity with re-spect to different search intents. Both pair-wise measures (e.g. cosine similarity) and graph-based measures (e.g. spec-tral embedding) are adopted in our work as examples.
Pair-wise Measures: For pair-wise measures, the sim-ilarity of each query pair is independently measured by pair-wise metrics over the corresponding representations of queries. A typical representation for query q i is the word vector from its search result snippets, where the l -th element of query q  X  X  vector is denoted as
Such a word vector is a mixed-intent representation since words describing different intents of the query are merged together. In order to apply pair-wised measures to estimate query similarity with respect to search intents, we need to extract the word vector representation of the query under different search intents. This can be easily obtained with the topic model learned above.

As we can see, with our learned model, we can infer the probability P ( s k | q i ,w l ) using the Eqn. (5), which denotes the expected search intent distribution for each word occur-rence w l given query q i . In other words, we have the specific topic assignment for each word w l from the top search result snippets of query q i . Therefore, it is straightforward to rep-resent query q i under the k -th search intent using the word vector with the l -th element defined as
With the query representation under different search in-tents in hand, we can directly apply pair-wise measures to calculate the similarity between queries with respect to search intents. Here we take the traditional cosine simi-larity for example. Given query q i and q j , the similarity between the two queries under the k -th search intent can be calculated as follows
Graph-based Measures: For Graph-based measures, the similarity between queries is defined on a query graph, or a query relation graph [13, 9]. A typical query graph is the query similarity graph, which is an undirected graph G =( V, E,A ), where V is the set of unique queries Q = { q 1 ,...,q N } , E  X  V  X  V is the set of edges, and A = [
W the similarity between the i -th and j -th queries. Here we simply define W ij as the Jaccard coefficient on clicked URLs between the i -th and j -th queries for demonstration. Obvi-ously, such a query graph is a mixed-intent representation of queries, since queries from different search intents are con-nected together. To leverage graph-based measures to esti-mate query similarity with respect to search intent, the key problem is to extract the query graph representation under different search intents.

In our topic model, we obtain the probability P ( s k | q each query q i , which denotes the probability that query conveys the search intent s k . Here, we define the probability that an edge will generated between query q i with search in-tent s k and query q j with search intent s k is P ( s k | q This probability obviously satisfies the normalization condi-tion k,k P ( s k | q i ) P ( s k | q j ) = 1. In this way, we can obtain the query graph representation under the k -th search intent by re-define the edge weight between query q i and q j as
With the query similarity graph representation under dif-ferent search intents in hand, we can then apply graph-based measures to calculate the similarity between queries with re-spect to search intents. Here we take the graph projection method, referred as spectral embedding [4], as an example. The basic idea of spectral embedding is to project the orig-inal graph into a low-dimensional Euclidean space and then measure distances between graph nodes by considering the distances of the corresponding projected points. The spec-tral embedding has the property of preserving the distances in the projected space. The process of applying spectral em-bedding on the query graph representation under k -th search intent is described briefly below: 2. Let y 0 ,..., y l  X  1 be the solution of Eqn. (11), ordered
On the projected space under each search intent, we can take cosine similarity as the metric to measure the similarity between queries. The similarity between query q i and q j under the k -th search intent is obtained by Note here we follow the way in [9] to rescale the cosine to ensure a measure in [0 , 1].
After describing our approach for measuring query simi-larity with respect to search intents, we turn our attention to the task of developing a simple application based on our approach. While there are many applications requiring a similarity measure between queries, one particularly useful application in the context of search is query recommenda-tion. Query recommendation is to suggest a set of poten-tially related queries to search users to help them refine their original query. Here we use query recommendation as one example to show the potential utility of our approach and also demonstrate its effectiveness.

Traditionally, query recommendation provide search users a list of related queries. Since queries are often ambiguous in search intent, the recommendation list is thus a mixture of related queries from different search intents, or even worse, dominated by related queries from one popular search in-tent. As proposed in [19], a structured approach is effec-tive in providing users with diverse query recommendations and thus enhance users X  click behavior on recommendations. With our approach to intent-aware similarity, we can iden-tify similar queries to the user X  X  initial query with respect to different search intents, and thus a structured query rec-ommendation can be easily built by grouping diverse recom-mendations based on the search intents.

More specifically, the structured query recommendation based on our approach can be divided into two stages, i.e. the offline learning stage and the online testing stage. In the offline learning stage, we applied the regularized topic model described in previous section to learn the potential search in-tents of queries and extract the query representations under each search intent. We can then index all the result repre-sentations for fast retrieval later. In the online testing stage, for a given user query q  X  , we find its major search intents and corresponding representations under those intents. For each of its major search intent, we retrieve all the exist-ing queries in the repository that potentially match q  X  (i.e., aquery q  X  X  vector representation matches q  X   X  X  in at least one dimension), calculate the similarity between them us-ing certain metrics, and sort the queries under that search intent. Finally, we provide users the structured recommen-dation results, where similar queries under the same search intent are grouped together and the groups are further or-dered according to the proportion of the search intents of the initial query.
We have conducted experiments to verify the effectiveness our similarity measure approach. In this section, we first compare the performance of query similarity calculation of our approach with two baseline methods. We then compare the performance on identifying search intents of queries be-tween our approach and traditional PLSI model. Finally, we apply our approach to query recommendation and evaluate its effectiveness by users X  click behavior.
In our experiments, we obtained a query clickthrough data set by randomly sampling from a commercial search engine X  X  search logs during a time period of one month. This sampled clickthrough data set contains about 15 million records. The queries were processed via the following normalization steps (i) trimming of each query, (ii) converting letters into lower case, and (iii) space sequence reduction to one space charac-ter. Queries and corresponding clickthrough data containing adult content were filtered out. For each query, we then col-lected its top N (i.e. N = 10 in our case) search results from the same search engine. A virtual document was con-structed for each query by aggregating all the words from its top search result snippets with the stop words removed. Finally, we obtained 11 , 524 unique queries, 87 , 415 unique URLs, and 45 , 882 unique words.

Two types of similarity measures (i.e., pair-wise measures and graph-based measures) were adopted as baselines in our evaluation. For pair-wise measures, we used cosine similarity based on Tf-Idf weighted word vector from top search results as a baseline measure, referred as Cos-Word . For graph-based measures, we used the spectral embedding over the query similarity graph based on clickthrough (described in section 3.3) as another baseline measure, referred as Embed-Click . Note that a similar approach has been used in [9] for measuring query similarity. In our experiments, we empiri-cally set the embedding dimension to 10 since we found that increasing the number of dimensions does not determine a considerable gain in terms of quality.

For our approach, we identified potential search intents of queries with our regularized topic model, and adopted pair-wise measure (i.e. cosine similarity) and graph-based measure (i.e. spectral embedding) based on the intent-aware representations of queries for similarity measure. We denote our two approaches as Cos-Intent and Embed-Intent ,re-spectively. In our experiments, we empirically set the value of Newton step parameter  X  to 0 . 1, the value of the regu-larization parameter  X  to 10, and the number of potential search intent to 500. We found that when the number of potential search intents is reasonable large (i.e.  X  500), the performance would be relatively stable.
To get a cursory evaluation for how well our approach performs, we show some example query pairs with the sim-ilarity scores calculated by different methods in Table 1. In this table, we take the two multi-intent queries  X  X pple X  and  X  X aylor X  as the central queries and show the similarity scores between the central query and their similar queries from dif-ferent search intents.
 From Table 1 we can see, both the Cos-Word and Embed-Click measures, which do not take search intent into account, assign a single similarity score for each pair of queries. Take the Cos-Word measure for example, the similarity score be-tween  X  X aylor X  and  X  X aylor swift X  is 0.55, while the similar-ity score between  X  X aylor X  and  X  X aylor soft serve machine X  is 0.58. Since they are calculated under the same measure, it seems that we can derive a strange conclusion that  X  X aylor soft serve machine X  is more similar to  X  X aylor X  than  X  X aylor swift X . In fact,  X  X aylor soft serve machine X  and  X  X aylor swift X  are from different search intents of the query  X  X aylor X , one about a company and the other about a famous singer. The similarity is actually not comparable across different search intents in such case. The similar problem can also be found in the query  X  X pple X  which is also shown in Table 1 and many other multi-intent queries.

On the other hand, by identifying potential search intents of queries, both the Cos-Intent and Embed-Intent measures show a more proper similarity measure for the same set of queries. For example, we can see that queries like  X  X aylor swift X  and  X  X aylor swift new songs X  both obtain high simi-larity scores under the search intent about the singer, while low similarity scores (i.e. zero) under other search intents. Note here the names of the search intents are manually la-beled for illustration. Clearly , under the search intent about the singer,  X  X aylor swift X  is much more similar to  X  X aylor X  than  X  X aylor soft serve machine X , while under the search in-tent about the company, it is the opposite. Similar results can also be found for the query  X  X pple X .

To have a deeper understanding of the problems in similar-ity measures without the awareness of search intents, we fur-ther extract some pairs of similar and dissimilar queries for comparison as shown in Table 2. From the results we can see, the pair-wise measure Cos-Word gives the query pair ( X  X p-ple X ,  X  X pple store X ) a much higher similarity score (i.e. 0 than the query pair ( X  X pple X ,  X  X pple tree X ). The major rea-son is that, for the ambiguous query  X  X pple X , the represen-tation (i.e. words from top search result snippets) used by Cos-Word for similarity measure is actually a mixture of its multiple search intents but dominated by the intent about the apple company. Therefore, without the awareness of search intents, the similarity measure Cos-Word is easily bi-ased by dominant search intents and ignore unpopular ones. On the contrary, the intent-aware pair-wise measure Cos-Intent calculates the similarity for each pair under differ-ent search intents using intent-aware representations. Such intent-aware representations convey precise information of each query under each intent. Therefore, our approach can produce more reasonable similarity scores without the bias on only popular intents. For example,  X  X pple tree X  receives a much higher similarity score (i.e. 0 . 44) to  X  X pple X  than  X  X pple store X  (i.e. 0) under the fruit intent.

Moreover, we observe that the dissimilar query pairs also obtain reasonably large similarity scores under the tradi-tional graph-based measure Embed-Click. For example, the query pair ( X  X pple store X ,  X  X pple fruit X ) receives a similar-ity score of 0 . 37 and the query pair ( X  X aylor swift X ,  X  X aylor soft serve machine X ) receives a similarity score of 0 . 36 un-der the Embed-Click measure. As we know, the Embed-Click measure leverages the spectral embedding technique, which in some sense propagates the similarity on top of the query graph during embedding. Therefore, since query  X  X p-ple store X  and  X  X pple fruit X  are both close to  X  X pple X  in the original graph, without the awareness of search intents, the similarity will be propagated cross the boundary of differ-ent search intents and thus query  X  X pple store X  and  X  X pple fruit X  will become similar after embedding. On the con-trary, the intent-aware graph-based measure Embed-Intent extracts the intent-aware graph representation under each search intent, where queries not conveying that intent will not be connected (or connected with a very large distance). In this way, we can see that the similarity is properly propa-gated among queries, and dissimilar queries like  X  X pple store X  and  X  X pple fruit X  will not be wrongly connected any more.
We further conducted quantitative comparison between our approaches and baseline approaches. For evaluation, we first constructed a test set based on our query logs. We collected a set of single-term queries that are likely to have more than one search intent. From these candidate queries, we asked three human judges to figure out the queries which have multiple search intents. Specifically, for each candidate query, queries that share co-clicks with it were collected as its potential similar queries. The human judges then exam each candidate query whether there are at least two distinct clusters in its potential similar queries. Finally, we collected 200 seed queries that have multiple search intents which are agreed by at least two human judges. For each seed query, we then created a test set of similar queries by extracting 3 representative similar queries under each major intent. In this way, we obtained a test set with total 1 , 581 queries labeled. Such a test set represents the ground truth for our evaluation. Table 3 show examples of the test set. We then apply different similarity measures over the queries Table 4: H  X  S ( Sim ) for Different Similarity Measures the significant levels are denoted as 0 . 1* 0 . 05 ** 0 . in the test set, and evaluate their agreement with human la-beled search intents. Specifically, given a seed query, let Q be the set of its similar queries which can be categorized into K search intents S = { S 1 ,...,S K } . Obviously, we have Q =  X  i S i . For a similarity measure Sim ( q, q ), we introduce two scores similarly as [9]: Expected Intra-intent Similarity : Expected Inter-intent Similarity : InterSim ( S )= 1
The intuition is that a similarity measure agrees with hu-man labeled search intent if the expected inter-intent simi-larity score is small compared to the expected intra-intent similarity score. Therefore, we calculate the following ex-pected ratio to evaluate the quality of a similarity measure Given two different similarity measures, the best one is the one that minimize the measure H  X  S ( Sim ).

The results are reported in Table 4. From the results we can see, for the traditional measures which do not take search intent into account, the pair-wise measure Cos-Word performs better than the graph-based measure Embed-Click. The major reason is that the Embed-Click measure would generate a higher inter-intent similarity, since the similarity propagation often wrongly connects the dissimilar queries and assign them a large similarity score. By considering search intent of queries, both Cos-Intent and Embed-Intent can significantly outperform the baseline measures (p-value 0 . 01). With some further analysis, we find that our approach generates a much smaller inter-intent similarity as well as a larger intra-intent similarity as compared with the tradi-tional measures. It shows that, by measuring query similar-ity with respect to search intent, we can generate more pre-cise similarity scores for both similar and dissimilar queries.
In our approach, we employ the regularized topic model to learn the potential search intents of queries by using both words from search results and r egularization from query co-clicks. A natural question is how about learning the search intents only based on words from search results, e.g., to just apply the traditional PLSI model over the virtual document of queries. In other words, does the regularization from query co-clicks really helps for the learning problem?
To answer this question, we compared our regularized topic model with traditional PLSI model on the performance of identifying potential search intents. We applied PLSI over Figure 1: Comparison between PLSI and Regular-ized Topic Model on Average Purity Score the search result snippets of queries to learn the search in-tents. To make the comparison fair, we use the same intent number for PLSI and our regularized topic model. For eval-uation, we use the same test set described above. With the topic model learned in hand, we assign each query in the testsettoanintentgroupaccordingtoitslargestintent. The intuition is that the topic model learns better if the pre-dicted intent groups are more like the human labeled results. For each seed query, let S = { s 1 ,...,s J } denote the intent groups predicted by the topic model, and  X  S = {  X  s 1 ,..., denote its manually labeled intent groups. We then borrow the purity metric [35] from traditional clustering problem to evaluate the quality of predicted intent groups, which is defined as where N is the total number of similar queries in the test set for a seed query. A higher purity score means a better prediction on intent groups.

The average purity scores for both PLSI and our regular-ized topic model over different runs are depicted in Fig. 1. The results show that our regularized topic model can con-sistently outperform PLSI. The average purity score ob-tained by our regularized topic model is about 0 . 94, while the average purity score obtained by PLSI is about 0 . 73. The results indicate that the query co-clicks can largely help resolve the ambiguity in search intents of queries. By lever-aging the regularization from query co-clicks, we can learn the potential search intents of queries significantly better than using the search results alone. Moreover, we can also observe that the performance of our regularized topic model is more stable than PLSI. It shows that the regularization from query co-clicks can help our model produce high accu-racy in prediction constantly.
In this section, we applied our approach to query recom-mendation. As described in Section 4, we can easily gen-erate a structured query recommendation for a given query to suggesting diverse related queries from different search intents. We also implemented a traditional list-based rec-ommendation system for comparison, where similar queries are ranked according to their similarity scores under a tra-ditional measure and the top ones are returned in a list. For demonstration, here we employ the Cos-Word and Cos-Table 5: Comparisons between List Approach and Our Approach on Click Performance Intent measures for the list approach and structured ap-proach, respectively. We used the previous selected 200 multi-intent queries plus 200 randomly sampled queries for evaluation. For each query, top 10 recommendations are used for performance comparison.

We follow the way proposed in [19] to compare the perfor-mances of different recommendation methods by users X  click behavior. The manual labeling process is almost the same, where human judges are required to label for each recom-mendation how likely he would like to click it with a 6-point scale (0, 0 . 2, 0 . 4, 0 . 6, 0 . 8, and 1) as the willingness mea-sure. We asked 5 judges with or without computer science background to label the recommendations.

We also adopted the Clicked Recommendation Number (CRN) , Clicked Recommendation Score (CRS) ,and Total Recommendation Score (TRS) as evaluation measures [19]. Given a query q ,let R = { r 1 ,...,r k } denote the k rec-ommendations generated by a certain approach, and L = { l ,...,l k } denote the corresponding label scores on these recommendations. The three measures for a query q are then defined as follows where | X  X  denotes the size of a set.
 Table 5 shows the evaluation results of the two approaches. The numbers in the parentheses are the relative improve-ments of our approach compared with list approach. The results show that by recommending structured queries based on our intent-aware approach, we can largely improve both the click number and click willingness on recommendations. When compared with list approach, the relative improve-ments obtained by our approach are about 12 . 9%, 9 . 3% and 13 . 3% in terms of average CRN, average CRS and average TRS, respectively. This simple experiment demonstrates the utility and effectiveness of our intent-aware approach in real applications.
In this paper, we propose to measure query similarity with the awareness of potential search intents. A regularized topic model is employed to effectively identify search intents of queries using words from search result snippets and regu-larization from query co-clicks. We then extract the query representation under different intents, and apply two types of similarity measures to estimate query similarity with re-spect to search intent. Experimental results verify the ef-fectiveness of our approach to intent-aware query similarity. We also demonstrate the utility of intent-aware similarity in the application of query recommendation, which can suggest diverse queries in a structured way to search users.
For the future work, we will consider using more context information of queries, e.g. search sessions, for identifying search intents better. It is also interesting to apply our intent-aware query similarity in other real applications in the search context. This research work was funded by the National High-tech R&amp;D Program of Chin a under gra nt No. 2010 AA 012500, and the National Natural Science Foundation of China under Grant No. 61003166 and Grant No. 60933005.
