
Although most time-series data mining rese arch has conc en-trate d on providing solutions for a single distanc e function, in this work we motivate the need for a single index structur e that can supp ort multiple distanc e me asur es. Our speci c area of inter est is the ecient retrieval and analysis of tra-jectory similarities. Traje ctory datasets are very common in envir onmental applic ations, mobility exp eriments, vide o surveil lanc e and are esp ecial ly imp ortant for the disc overy of certain biolo gic al patterns. Our primary similarity me a-sur e is base d on the Longest Common Subse quenc e (LCSS) mo del, that o ers enhanc ed robustness, particularly for noisy data, which are enc ounter ed very often in real world applic a-tions. However, our index is able to accommo date other dis-tanc e me asur es as wel l, including the ubiquitous Euclide an distanc e, and the incr easingly popular Dynamic Time Warp-ing (DTW). While other rese archers have advo cate d one or other of these similarity me asur es, a major contribution of our work is the ability to supp ort all these me asur es without the need to restructur e the index. Our framework guar an-tees no false dismissals and can also be tailor ed to provide much faster resp onse time at the exp ense of slightly reduc ed precision/r ecall. The exp erimental results demonstr ate that our index can help speed-up the computation of exp ensive similarity me asur es such as the LCSS and the DTW.
In this work we presen t an ecien t and compact, external memory index for fast detection of similar tra jectories. Tra-jectory data are prev alen t in div erse elds of interest suc h as meteorology , GPS trac king, wireless applications, video trac king [5] and motion capture [18]. Recen t adv ances in mobile computing, sensor and GPS tec hnology have made it possible to collect large amoun ts of spatiotemp oral data and Cop yright 2003 ACM 1 X 58113 X 737 X 0/03/0008... $ 5.00. there is increasing interest in performing data analysis tasks over suc h data [17]. In mobile computing, users equipp ed with mobile devices mo ve in space and register their loca-tion at di eren t time instances to spatiotemp oral databases via wireless links. In environmen tal information systems, trac king animals and weather conditions is very common and large datasets can be created by storing locations of ob-serv ed ob jects over time. Human motion data generated by trac king sim ultaneously various body join ts are also multi-dimensional tra jectories. In this eld of computer graph-ics fundamen tal operations include the clustering of similar mo vemen ts, leading to a multitude of applications suc h as in-teractiv e generation of motions [2]. Spatiotemp oral data are also pro duced by migrating particles in biological sciences, where the focus can be on the disco very of subtle patterns during cellular mitoses [19]. In general, any dataset that involv es storage of multiple streams (attributes) of data can be considered and treated as a multidimensional tra jectory .
One very common task for suc h data is the disco very of ob jects that follo w a certain motion pattern, for purp oses of clustering or classi cation. The ob jectiv e here is to e-cien tly organize tra jectories on disk, so that we can quic kly answ er k-Nearest-Neigh bors (kNN) queries. A frequen t ob-stacle in the analysis of spatiotemp oral data, is the presence of noise, whic h can be intro duced due to electromagnetic anomalies, transceiv er problems etc. Another imp edimen t is that ob jects ma y mo ve in a similar way, but at di eren t speeds. So, we would like our similarit y mo del to be robust to noise, supp ort elastic and imprecise matc hes.
Cho osing the Euclidean distance as the similarit y mo del is unrealistic, since its performance degrades rapidly in the presence of noise and this measure is also sensitiv e to small variations in the time axis. We concen trate on two simi-larit y mo dels: the rst is an extension of Dynamic Time Warping for higher dimensions. We note that DTW has been used so far for one-dimensional time series. Here we presen t a form ulation for sequences of arbitrary dimensions. The second distance measure is a mo di cation of the Longest Common Subsequence (LCSS), specially adapted for con tin-uous values. Both measures represen t a signi can t impro ve-men t compared to the Euclidean distance. Ho wever, LCSS is more robust than DTW under noisy conditions [20] as g-ure 1 sho ws. Euclidean matc hing completely disregards the variations in the time axis, while DTW performs excessiv e matc hings, therefore distorting the true distance between se-quences. The LCSS pro duces the most robust and intuitiv e corresp ondence between poin ts.

By incorp orating warping in time as a requiremen t to matc hings, in the presence of noise. our mo del, our algorithms are automatically challenged with quadratic execution time. Moreo ver, these exible functions are typically non-metric, whic h mak es dicult the design of indexing structures. To speed up the execution of a similar-ity function, one can devise a low cost, upp er bounding func-tion (since the LCSS mo del captures the similarit y, whic h is inversely analogous to the distance). We utilize a fast pre ltering scheme that will return upp er bound estimates for the LCSS similarit y between the query and the indexed tra jectories. In addition to pro viding similarit y measures that guaran tee no false dismissals , we also prop ose appr oxi-mate similarit y estimates that signi can tly reduce the index resp onse time. Finally , we sho w that the same index can supp ort other distance measures as well.

Our tec hnique works by splitting the tra jectories in multi-dimensional MBRs and storing them in an R-tree. For a giv en query , we construct a Minimum Bounding Envelop e (MBE) that covers all the possible matc hing areas of the query under warping conditions. This MBE is decomp osed into MBRs and then prob ed in the R-tree index. Using the index we can disco ver whic h tra jectories could poten tially be similar to the query . The index size is compact and its construction time scales well with the tra jectory length and the database size, therefore our metho d can be utilized for massiv e datamining tasks.
 The main con tributions of the pap er are: tidimensional tra jectories, that supp orts multiple distance functions (suc h as LCSS, DTW and Euclidean), without the need to rebuild the index.
 and for appro ximating the LCSS(DTW) for a set of tra jec-tories. We incorp orate these tec hniques in the design of an ecien t indexing structure for the LCSS and the DTW. specify queries of variable warping length, and the tec hnique can be tuned to optimize the retriev al time or the accuracy of the solution.
There has been a wealth of pap ers that use an L p dis-tance family function to perform similarit y matc hing for 1D time-series. Work on multidimensional sequences can be found in [14, 9]. Ho wever, they supp ort only Euclidean distance, whic h, as men tioned in the intro duction, cannot capture exible similarities.

Although the vast ma jorit y of database/data mining re-searc h on time series data mining has focused on Euclidean distance, virtually all real world systems that use time series matc hing as a subroutine, use a similarit y measure whic h al-lows warping. In retrosp ect, this is not very surprising, since most real world pro cesses, particularly biological pro cesses, can evolv e at varying rates. For example, in bioinformat-ics, it is well understo od that functionally related genes will express themselv es in similar ways, but possibly at di eren t rates. Because of this, DTW is used for gene expression data mining [1, 3]. Dynamic Time Warping is a ubiquitous tool in the biometric/surv eillance comm unit y. It has been used for trac king time series extracted from video [7], classifying handwritten text [16] and even ngerprin t indexing [13].
While the above examples testify to the utilit y of a time warp ed distance measure, they all echo the same complain t; DTW has serious scalabilit y issues. Work that attempted to mitigate the large computational cost has app eared in [12] and [21], where the authors use lower bounding measures to speed up the execution of DTW. Ho wever, the lower bounds can be loose appro ximations of the original distance, when the data are normalized. In [15] a di eren t approac h is used for indexing Time Warping, by using sux trees. Nonethe-less, the index requires excessiv e disk space (ab out 10 times the size of the original data).

The exibilit y pro vided by DTW is very imp ortan t, how-ever its eciency deteriorates for noisy data, since by matc h-ing all the poin ts, it also matc hes the outliers distorting the true distance between the sequences. An alternativ e ap-proac h is the use of Longest Common Subse quenc e ( LCSS ), whic h is a variation of the edit distance. The basic idea is to matc h two sequences by allo wing them to stretc h, with-out rearranging the order of the elemen ts but allo wing some elemen ts to be unmatche d . Using the LCSS of two se-quences, one can de ne the distance using the length of this subsequence [6]. In [20] an internal memory index for the LCSS has been prop osed. It also demonstrated that while the LCSS presen ts similar adv antages to DTW, it does not share its volatile performance in the presence of outliers.
Closest in spirit to our approac h, is the work of [10] whic h, however, only addresses 1D time-series. The author uses constrained DTW as the distance function, and surrounds the possible matc hing regions by a mo di ed version of a Piecewise Appro ximation, whic h is later stored as equi-length MBRs in an R-tree. Ho wever, by using DTW, suc h an approac h is susceptible to high bias of outliers. Also, the xed MBR size (although simpli es the index operations) can lead to degenerate appro ximations of the original se-quence. Moreo ver, the em bedding of the envelop e in the indexed sequences can slo w the index construction time and limit the user's query capabilities to a prede ned warping length. The use of LCSS as our primary similarit y measure, lends itself to a more natural use of the R-tree, where the similarit y estimates are simply computed by calculating the MBR intersection areas. Since the index is not constructed for a speci c warping windo w, the user can pose queries with variable warping length.

The purp ose of this pap er is to reconcile the best of both worlds. We pro vide a framew ork that can supp ort in the same index, the LCSS, DTW and Euclidean distance func-tions. The only asp ect that changes, is the di eren t repre-sen tation of the query for eac h distance measure. In this section we presen t details of how the Dynamic Time Warping and the LCSS mo del can be extended to de-scrib e the similarit y between tra jectories.
We describ e an extension in 2D of the original DTW func-tion as describ ed by Berndt and Cli ord [4]. Let A and B be two tra jectories of mo ving ob jects with size n and m resp ectiv ely , where A = (( a x; 1 ;a y; 1 ) ;:::; ( a
Definition 1. The Time Warping betwe en 2-dimensional sequenc es A and B is: where L p is any p-Norm. Using dynamic programming and constraining the matc hing region within , the time required to compute DTW is O ( ( n + m )). In order to represen t an accurate relationship of distances between sequences with di eren t lengths, the quan tity in equation 1 is normalized by the length of the warping path. The extension to n di-mensions is similar. In gure 2 we sho w an example of time warping for two tra jectories.
The original LCSS mo del refers to 1D sequences, we must therefore extend it to the 2D case. In addition, the LCSS paradigm matc hes discrete values, however in our mo del we want to allo w a matc hing, when the values are within a certain range in space and time (note that like this, we also avoid distan t and degenerate matc hings).

Definition 2. Given an inte ger and a real numb er 0 &lt; &lt; 1 , we de ne the LCSS ; ( A;B ) as fol lows: Figure 2: The supp ort of exible matc hing in spa-tiotemp oral queries is very imp ortan t. Ho wever, we can observ e that Dynamic Time Warping matc hes all poin ts (so the outliers as well), therefore distort-ing the true distance. In con trast, the LCSS mo del can ecien tly ignore the noisy parts. where sequences A and Head ( A ) are de ned similarly as before. The constan t con trols the exibilit y of matc hing in time and constan t is the matc hing threshold is space. The aforemen tioned LCSS mo del has the same O ( ( n + m )) computational complexit y as the DTW, when we only allo w a matc hing windo w in time [6].

The value of LCSS is unbounded and dep ends on the length of the compared sequences. We need to normalize it, in order to supp ort sequences of variable length. The distance deriv ed from the LCSS similarit y can be de ned as follo ws:
Definition 3. The distanc e D ; expr esse d in terms of the LCSS similarity betwe en two traje ctories A and B is given by:
Ev en though imp osing a matc hing windo w can help speed up the execution, the computation can still be quadratic when is a signi can t portion of the sequence's length. Therefore, comparing a query to all the tra jectories becomes intractable for large databases. We are seeking ways to avoid examining the tra jectories that are very distan t to our query . This can be accomplished by disco vering a close matc h to our query , as early as possible. A fast pre-ltering step is emplo yed that eliminates the ma jorit y of distan t matc hes. Only for some quali ed sequences will we execute the costly (but accurate) quadratic time algorithm. This philosoph y has also been successfully used in [21, 10]. There are certain prepro cessing steps that we follo w: 1. The tra jectories are segmen ted into MBRs, whic h are stored in an Rtree T . 2. Giv en a query Q , we disco ver the areas of possible matc hing by constructing its Minimum Bounding Envelop e ( MBE Q ). 3. MBE Q is decomp osed into MBRs that are prob ed in the index T . 4. Based on the MBR intersections, similarit y estimates are computed and the exact LCSS (or DTW) is performed only on the quali ed tra jectories.
 The above notions are illustrated in gure 3 and we explain in detail how they can be applied for the LCSS case in the sections that follo w.
 Figure 3: An example of our approac h (in 1D for clarit y); A query is extended into a bounding en-velop e, whic h in turn is also split into the resulting MBRs. Ov erlap between the query and the index MBRs suggest areas of possible matc hing. Let us rst consider a 1D time-series and let a sequence A be ( a x; 1 ;:::;a x;n ). Ignoring for now the parameter , we would like to perform a very fast LCSS matc h between sequence A and some query Q . Supp ore that we replicate eac h poin t Q i for time instances before and after time i . The envelop e that includes all these poin ts de nes the areas of possible matc hing. Ev erything outside this envelop e can nev er be matc hed. Figure 4: The Minimum Bounding Envelop e (MBE) within in time and in space of a sequence. Ev-erything that lies outside this envelop e can nev er be matc hed.

We call this envelop e, the Minimum Bounding Envelop e (MBE) of a sequence. Also, once we incorp orate the matc h-ing within in space, this envelop e should exten t above and belo w the original envelop e ( gure 4). The notion of the bounding envelop e can be trivially extended in more dimen-sions, where MBE ( ; ) for a 2D tra jectory Q = (( q x; 1 :::; ( q x;n ;q y;n ) covers the area between the follo wing time-series: The LCSS similarit y between the envelop e of Q and a se-quence A is de ned as: For example, in gure 4 the LCSS similarit y between MBE Q and sequence A is 46, as indicated in the gure. This value represen ts an upp er bound for the similarity of Q and A . We can use the MBE Q to compute a lower bound on the distanc e between tra jectories:
Lemma 1. For any two traje ctories Q and A the fol lowing holds: D ; ( MBE Q ;A ) D ; ( Q;A ) , therefore it is sucien t to sho w that: LCSS ; ( MBE Q ;A ) LCSS ; ( Q;A ). This is true since MBE Q by construction con tains all possible areas within and of the query Q . Therefore, no possible matc hing poin ts will be missed. 2
The previous lemma pro vides us with the power to create an index that guaran tees no false dismissals. Ho wever, this lower bound refers to the raw data. In the sections that fol-low, we will 'split' the MBE of a tra jectory , into a num ber of Minimum Bounding Rectangles (MBRs), to accommo-date their storage into a multidimensional R-tree. We will sho w that the above inequalit y still holds between tra jectory MBRs.

The MBR generation pro cedure is orthogonal to our ap-proac h, since any segmen tation metho dology can be applied to our framew ork. Therefore, the description of the poten-tial MBR generation metho ds (and of our implemen tation choice) will be dela yed until later.
Supp ose that we have an index with the segmen ted tra-jectories and the user pro vides a query Q . Our goal is the disco very of the k closest tra jectories to the giv en query , ac-cording to the LCSS similarit y. A pre ltering step will aid the quic k disco very of a close matc h to the query , helping us discard the distan t tra jectories without using the costly quadratic algorithm. Therefore, in this phase, we compute upp er bound estimates of the similarit y between the query and the indexed sequences using their MBRs.

Belo w we describ e the algorithm to nd the closest tra-jectory to a giv en query: The above algorithm can be adjusted to return the k-NN sequences, simply by comparing with the k th bestSoFar matc h. Next, we examine the possible similarit y estimates. Some of them guaran tee that will nd the best matc h (they lower bound the original distance or upp er bound the origi-nal similarit y), while other estimates pro vide faster but ap-pro ximate results.
Here we will sho w how to compute estimates of the LCSS similarit y, based on the geometric prop erties of the tra jec-tory MBRs and their intersection. An upp er bound estimate is pro vided by the length of the MBR intersection and an appro ximate estimate is giv en as a parameter of the inter-secting volume. To formalize these notions, rst we presen t sev eral operators. Then we will use these operators to deriv e the estimates. Eac h tra jectory T can be decomp osed into a num ber of MBRs. The i th 3D MBR of T consists of six num bers: M
T;i = f t l ;t h ;x l ;x h ;y l ;y h g . No w, let us de ne the oper-ators M
R;j , belonging to ob jects P and R , resp ectiv ely: 1.
 2.
 3.
 We can use upp er bound or appro ximate estimates for the similarit y: Figure 5: Top left : Intersection recorded in list L t;partial . Top right : Intersection recorded in list L t;complete . Bottom left : Percen tage of Volume In-tersection kept in L V . 1. Upp er bound estimates (L-similarit y estimate) . Suc h estimates are computed using the follo wing data-structures:
The list L t;complete , an elemen t L ( P ) of whic h is de ned as: where Q is a query and P is a tra jectory in the index. So the list stores for each tra jectory the total time that its MBRs intersected with the query's MBRs. We record into this list only the intersections, where a query MBR is fully con tained in all spatial dimensions by a tra jectory MBR (or vice versa -it is equiv alen t. See gure 5, top righ t).
 The list L t;partial , an elemen t L ( P ) of whic h is de ned as:
This list records for eac h sequence the total intersection in time for those query MBRs that are not fully con tained within the x,y dimensions by the tra jectory MBRs (or vice versa. Figure 5, top left).
 Regarding a query Q , for any tra jectory P the sum of L on the similarit y of P and Q .

The reason for the distinction of the L-similarity estimate in two separate lists deriv es from the fact that the esti-mates stored in list L t;partial can signi can tly overestimate the LCSS similarit y. If one wishes to relax the accuracy , in favor of enhanced performance, it is instructiv e to giv e a weigh t 0 &lt; w p &lt; 1 to all estimates in list L t;partial though now we may miss the best matc h to our query , we are going to nd a close matc h in less time. This weigh ted approac h is used when we are seeking for appro ximate, but very good qualit y answ ers, however it will not be explained further due to space limitations. 2. Appro ximate estimates (V-similarit y estimate) . This second estimate is based on the intersecting volume of the MBRs. This typ e of estimates are stored in list L V :
An y elemen t L V ( P ) of list L V records similarit y estimates between tra jectory P and query Q , based on the total vol-ume intersection between the MBRs of P and Q .
 where jj M jj V denotes the volume of MBR M and jj M jj t length on the time axis.

The L-similarity overestimates the LCSS ; between two sequences A and B and so it can be deplo yed for the design of an index structure.

Lemma 2. The use of the L-similarity estimate upp er bounds the LCSS ; similarity betwe en two sequenc es A and B and ther efor e does not intr oduc e any false dismissals.
The V-similarity estimate can be used for appro ximate query answ ering. Ev en though it does not guaran tee the absence of false dismissals, the results will be close to the optimal ones with high probabilit y. Also, because this es-timate pro vides a tigh ter appro ximation to the original dis-tance, we exp ect faster resp onse time. Indeed, as we sho w in the exp erimen tal section, the index performance is boosted, while the error in similarit y is frequen tly less then 5%.
When the distance function used is the Time Warping, using the index we obtain a lower bound of the actual dis-tance. In this case we have the inverse situation from the LCSS; instead of calculating the degree of overlap between the MBRs of the indexed tra jectories and the query , we eval-uate the distanc e between the MBRs. The overall distance between the MBRs underestimates the true distance of the tra jectories, and no false dismissals are intro duced. Using the MBRs we can also calculate upp er bound estimates on the distance, whic h hadn't been exploited in previous work [10, 22]. Sequences with lower bound larger than the small-est upp er bound can be pruned. With this additional pre-ltering step we can gain on average an additional 10-15% speedup in the total execution time.

Due to space limitations only a visual represen tation of this approac h is pro vided in gure 6.
Giv en a multidimensional time-series (or an MBE) our ob jectiv e is to minimize the volume of the sequence using k MBRs. Clearly , the best appro ximation of a tra jectory (or an MBE) using a xed num ber of MBRs is the set of MBRs that completely con tain the sequence and minimize the volume consumption. We can sho w the follo wing lemma:
Lemma 3. Minimizing the volume of the Minimum Bound-ing Envelop e, minimizes the exp ecte d similarity appr oxima-tion err or.

Three di eren t approac hes are considered: 1. k-Optimal . We can disco ver the k MBRs of a sequence that tak e up the least volume, using a dynamic programming algorithm that requires O ( n 2 k ) time ([8]), where n is the length of the giv en sequence. Since this approac h is not reasonable for large databases, we are motiv ated to consider appro ximate and faster solutions. 2. Equi-Split . This tec hnique pro duces MBRs of xed length l . It is a simple approac h with cost linear in the length of a sequence. Ho wever, in pathological cases in-creasing the num ber of splits can result to larger space uti-lization,therefore the choice of the MBR length becomes a critical parameter (see gure 7 for an example).
 Figure 6: A visual intuition of the DTW indexing tec hnique (the one-dimensional case is sho wn for clarit y). The original query (A) is enclosed in a minim um-b ounding envelop e (B) like the LCSS ap-proac h. The MBE is split into its MBRs using equi or greedy split ( g. (C)). The candidate sequences in the database have their MBRs stored in the in-dex (D). Bet ween the query and any sequence in the index, the minim um and maxim um distance can be quic kly determined by examining the distance between the MBRs and the query's bounding enve-lop e, as represen ted by the arro ws in (E) and (F). 3. Greedy-Split . The Greedy approac h is our implemen-tation choice in this pap er. Initially we assign an MBR to eac h of the n sequence poin ts and at eac h subsequen t step we merge the consecutiv e MBRs that will intro duce the least volume consumption. The algorithm has a running time of O ( nlogn ). We can see a sketc h of the metho d in g. 8. Al-ternativ ely , instead of assigning the same num ber of splits to all ob jects, according to our space requiremen ts we can assign a total of K splits to be distributed among all ob jects. This metho d can pro vide better results, since we can assign more splits for the ob jects that will yield more space gain. Also, this approac h is more appropriate when one is dealing with sequences of di eren t lengths. The complexit y of this approac h is O ( K + NlogN ), for a total of N ob jects ([8]). Figure 8: The greedy algorithm for pro ducing k MBRs that cover the tra jectory T .

After a tra jectory is segmen ted the MBRs can be stored in a 3D-R tree. Using the greedy split eac h additional split will alw ays lead to smaller (or equal) volume ( gure 7). A similar greedy split algorithm is also used for splitting the MBE of the query tra jectory Q . increases volume gain to 10.595.
The application of the Minimum Bounding Envelop e only on the query suggests that user queries are not con ned to a prede ned and rigid matc hing windo w . The user can pose queries of variable warping in time. In some datasets, there is no need to perform warping, since the Euclidean distance performs acceptably [11]. In other datasets, by using the Euclidean distance we can nd quic kly some very close matc hes, while using warping we can distinguish more exible similarities. So, we can start by using a query with = 0 (no bounding envelop e), and increase it progressiv ely in order to nd more exible matc hes ( gure 9).

Therefore, our framew ork o ers the unique adv antage that multiple distance functions can be supp orted in a single in-dex. The index sequences have been segmen ted without any envelop e applied on them and nev er have to be adjusted again. For di eren t measures, the asp ects that change are, the creation of the query envelop e and the typ e of operation between MBRs. In order to pose queries based on Euclidean distance we follo w the steps: distance are deriv ed by calculating the distance between the query and index MBRs, just like in the DTW case. Figure 9: By incorp orating the bounding envelop e on the query , our approac h can supp ort Euclidean distance, constrained or full warping. This is accom-plished by progressiv ely expanding the MBE.
In this section we compare the e ectiv eness of various splitting metho ds and we demonstrate the sup eriorit y of our lower bounding tec hnique (for the DTW) compared to other prop osed lower bounds. We describ e the datasets we used and presen t comprehensiv e exp erimen ts regarding the index performance for the two similarit y estimates. In addition, we evaluate the accuracy of the appro ximate estimates. All exp erimen ts conducted were run on an AMD Athlon 1.4 Ghz with 1GB RAM and 60GB of hard driv e. Figure 10: Datasets used for testing the eciency of various MBR generation metho ds.
The purp ose of our rst exp erimen t is to test the space consumption of the presen ted MBR generation metho ds. We have used eigh t datasets with div erse characteristics, in or-der to pro vide ob jectiv e results.

We evaluate the space consumption, by calculating the \Av erage Volume Gain" ( AvgV olGain ), whic h is de ned as the percen tage of volume when using i MBRs, over the volume when using only 1 MBR, normalized by the maxi-mum gain pro vided over all metho ds (for various num ber of splits).
 Figure 11: The greedy-split MBR generation algo-rithm presen ts the highest volume gain, by pro duc-ing MBRs that consume consisten tly less space, over a num ber of datasets and for div erse num ber of gen-erated MBRs actual similarit y.

AvgV olGain is a num ber between 0 and 1, where higher num bers indicate increased volume gain (or less space con-sumption) against the comp etitiv e metho ds. In gure 11 we observ e the average volume gain for the eigh t datasets. The greedy-split algorithm pro duced MBRs that took at least half the space, compared to equi-split. The equi-split o ers sligh tly better results, than pro ducing MBRs at ran-dom positions. The volume gain of greedy-split was less, only for the buoy sensor , whic h is a very busy and unstruc-tured signal. This exp erimen t validates that our choice to use the greedy-split metho d was correct. Since, the indexed MBR tra jectories will tak e less space, we also exp ect tigh ter similarit y estimates, therefore few er false positiv es.
In table 1 we sho w how close our similarit y estimates are (for LCSS and DTW) to the actual similarit y between se-quences. Num bers closer to 1, indicate higher similarit y to the value returned by the exact algorithm. To our best kno wledge, this pap er intro duces the rst upp er bounding tec hnique for the LCSS . For DTW there have been a few approac hes to pro vide a lower bound of the distance; we re-fer to them as LB-Kim [12] and LB-Yi [21]. These lower bounds originally referred to 1D time-series; here we extend them in more dimensions, in order to pro vide unam biguous results about the tigh tness of our estimates. Note that the previously prop osed metho ds operate on the raw data. Our approac h can still pro vide tigh ter estimates, while operat-ing only on the tra jectory MBRs. Using the raw data our exp erimen ts indicate that we are consisten tly 2-3 times bet-ter than the best alternativ e approac h. Ho wever, since our index operates on the segmen ted time-series we only rep ort the results on the MBRs.

The greedy-split metho d appro ximates the similarit y con-sisten tly tigh ter than the equi-split. In table 1 only the results for = 5% of the query's length are rep orted, but similar results are observ ed for increasing values of . It is eviden t from the table that using our metho d we can pro vide very tigh t lower bounds of the actual distance.
We demonstrate the usefulness of our similarit y measures in a real world dataset. The Library of Congress main tains thousands of handwritten man uscripts, and there is an in-creasing interest to perform automatic transcribing of these documen ts. Giv en the multiple variations of eac h word and due to the man uscript degradations, this is a particularly challenging task and the need for a exible and robust dis-tance function is essen tial.
 We have applied the LCSS and DTW measures on word Figure 12: Results for a real world application. 3NN rep orted for eac h query , using Dynamic Time Warping to matc h features extracted from scanned man uscript words. images extracted from a 10 page scanned man uscript. 4-dimensional time-series features have originally been extracted for eac h word. Here we main tain the 2 least correlated time-series features and treat eac h word as a tra jectory . In gure 12 we observ e the 3-KNN results using DTW for various word queries. The results are very good, sho wing high ac-curacy even for similarly looking words. Analogous results have been obtained using the LCSS .
We tested the performance of our index using the upp er bound and the appro ximate similarit y estimates, and com-pared it to the sequen tial scan. Because of limited space, the ma jorit y of the gures record the index performance us-ing the LCSS as a similarit y measure. The performance measure used is the total computation time required for the index and the sequen tial scan to return the nearest neigh-bor for the same one hundred queries. For the linear scan, one can also perform early termination of the LCSS (or the DTW) computation. Therefore, the LCSS execution can be stopp ed at the poin t where one is sure that the curren t sequence will not be more similar to the query than the bestSoF ar . We call this optimistic linear scan. Pessimistic linear scan, is the one than does not reuse the previously computed similarit y values and can be an accurate time estimate, when the query matc h resides at the end of the dataset. We demonstrate the index performance relativ e to both typ es of linear scan, because this pro vides a realistic upp er or lower bound on the index speedup.

The dataset we used con tained 2 10 ::: 2 16 tra jectories. Tak-ing under consideration that the average tra jectory size is around 500 poin ts, this resulted to a database with more than 16 million 2D poin ts. The tra jectories have been nor-malize d by subtracting the average value in eac h direction of mo vemen t. All data and queries can be obtained by emailing the rst author.
 Mixed two-dimensional Time-series (2D-Mixed) . This second dataset consists of time-series of variable length, rang-ing from less than 100 poin ts to over 1000 poin ts. The dataset is comprised by the aggregation of the eigh t datasets we used for comparing the MBR generation metho ds. Since the total num ber of these tra jectories is less than 200, we have used them as seeds to generate increasingly larger datasets. We create multiple copies of the original tra jectories by in-corp orating the follo wing features: pattern time
The small variations in the pattern were added by interp o-lating peaks of Gaussian noise using splines. In this manner we are able to create the smo oth variations that existed in the original datasets.
The index performance is in uenced be three parameters: the size of the dataset, the warping length (as a percen tage of the query's length) and the num ber of splits. For all exp erimen ts the parameter (matc hing in space) was set to std= 2 of the query , whic h pro vided good and intuitiv e results.
 performance of the index scales with the database size (for various lengths of matc hing windo w). We record the index resp onse time relativ e to both optimistic and pessimistic lin-ear scan. Therefore, the gra y region in the gures indicates the range of possible speedup. It is eviden t that the early termination feature of the sequen tial scan can signi can tly assist its performance. The usefulness of an index becomes obvious for large dataset sizes, where the quadratic compu-tational cost dominates the I/O cost of the index. For these cases our approac h can be up to 5 times faster than linear scan. In gure 15 we also demonstrate the pruning power of the index, as a true indicator (not biased by any implemen-tation details) about the ecacy of our index. Using the index we perform 2-5 times few er LCSS computations than the linear scan. We observ e similar speedup when using the DTW as the distance function in gure 17.
 smaller warping lengths (parameter ). The exp erimen ts record the performance for warping from 5% to 20% of the query's length. Increasing values signify larger bounding envelop es around the query , therefore larger space of searc h and less accurate similarit y estimates. The graphs suggest that an index cannot not be useful under full warping (when the data are normalized).
 for eac h tra jectory implies better volume utilization, nonethe-less more MBRs also lead to increased I/O cost. When we are referring to x% splits, it means that we have assigned a total of 100 =x ( our gures we pro vide the 5% splits scenario for the MBRs, whic h o ers better performance than 10% and 20% splits, since for the last two cases the I/O cost negates the e ect of the better query appro ximation. The index space require-men ts for 5% splits is less than a quarter of the dataset size.
Here we presen t the index performance when the volume intersections of the MBRs are used as estimates of the sim-
Figure 15: Eac h gra y band indi-cates (for a certain warping win-dow ) the percen tage of LCSS computations conducted by the in-dex compared to linear scan. ilarit y and the results are sho wn in gure 14. We observ e that using this appro ximate similarit y estimate, our index performance is boosted up. The use of the V-similarity es-timate leads to more tigh t appro ximations of the original similarit y compared to the L-similarit y estimate, however now we ma y miss nding the best matc h.

Naturally , comes the question of the qualit y of the re-sults. We capture this by calculating the absolute di erence between the similarit y of the best matc h returned by the index, and the best matc h found by the sequen tial scan for eac h query . Then we average the results over a num ber of queries j q j . Therefore, the Aver age Similarity Err or (ASE) is:
The results are sho wn in gure 16. We can see that the similarit y returned by the V-similarit y estimate is appro xi-mately within 5% of the actual similarit y (5% splits used). Therefore, by pro viding two similarit y estimates the user can decide for the trade-o between the exp edited execution time and the qualit y of results. Since by using the latter es-timator we can signi can tly increase the performance of the index, this is the approac h we recommend for mining large datasets.
In this pap er we have presen ted an external memory in-dexing metho d for disco vering similar multidimensional time-series. The unique adv antage of our approac h is that it can accommo date multiple distance measures. The metho d guaran tees no false dismissals and depicts a signi can t ex-ecution speed up for the LCSS and DTW compared to se-quen tial scan. We have sho wn the tigh tness of our similarit y estimates and demonstrated the usefulness of our measures for challenging real world applications. We hop e that our e ort can act as a bridge between metric and non-metric functions, as well as a tool for understanding better their strengths and weaknesses. In the future we plan to investi-gate the com bination of sev eral heuristics, in order to pro-vide even tigh ter estimates.
 Ac kno wledgemen ts: We would like to thank Margrit Betk e for pro viding us the Vide o Track I and II datasets. We also feel obliged to T. Rath and R. Manmatha for kindly pro vid-ing the man uscript words dataset.
