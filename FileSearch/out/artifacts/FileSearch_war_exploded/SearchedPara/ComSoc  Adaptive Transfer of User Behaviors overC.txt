 Accurate prediction of user behaviors is important for many social media applications, including social marketing, per-sonalization and recommendation, etc. A major challenge lies in that, the available behavior data or interactions be-tween users and items in a given social network are usually very limited and sparse (e.g.,  X  99 . 9% empty). Many pre-vious works model user behavior from only historical user logs. We observe that many people are members of several social networks in the same time, such as Facebook, Twit-ter and Tencent X  X  QQ 1 . Importantly, their behaviors and interests in different networks influence one another. This gives us an opportunity to leverage the knowledge of user behaviors in different networks, in order to alleviate the data sparsity problem, and enhance the predictive perfor-mance of user modeling. Combining different networks X  X im-ply and naively X  does not work well. Instead, we formulate the problem to model multiple networks as  X  X omposite net-work knowledge transfer X . We first select the most suitable networks inside a composite social network via a hierarchi-cal Bayesian model, parameterized for individual users, and then build topic models for user behavior prediction using both the relationships in the selected networks and related behavior data. To handle big data, we have implemented the algorithm using Map/Reduce. We demonstrate that the proposed composite network-based user behavior model sig-nificantly improve the predictive accuracy over a number of existing approaches on several real world applications, such as a very large social-networking dataset from Tencent Inc. H.2.8 [ Database Management ]: Database Applications  X  Data Mining  X  http://www.tencent.com/en-us/ps/imservice.shtml Social Network Analysis, Transfer Learning
An important challenge for user behavior modeling in so-cial media is how to push the right information to the right users at the right time. Accurate user-behavior models en-able us to predict users X  actions and intents based on data collected from online product purchasing, webpage brows-ing and ads clicking history, etc. Different approaches of user-behavior modeling, such as collaborative filtering, have been proposed [19]. A major challenge to use these meth-ods lies in the  X  X parse X  nature of historical data, whereby users have interactions with only few other users and items; users may click on only one or two advertisements and lis-ten to a few songs during a time period. For example, the dataset from Tencent has more than 99 . 9% empty entries in the user-item interaction matrix. The problem with sparse data makes existing methods overfit, and thus fails to model users X  behaviors accurately.

With the development of Web 2.0, billions of users are now engaged in multiple online social networks, such as Facebook, Twitter, Tencent X  X  QQ, etc. In many cases, a given user is simultaneously a member of several different networks. These networks form a composite social net-work, where users have various relationships, and can both exhibit different behaviors in each individual network or subnetwork, and share some common latent interests across networks in the same time. Many people use Facebook to communicate with their friends, but post their real-time in-formation on Twitter and browse video uploaded by others on Youtube. Inside a composite social network, links in different sub-networks reflect users X  behaviors and relation-ships from different aspects. For example, friendship rela-tionships on Facebook reflect users X  acquaintances in daily life, but contacts on Youtube capture users X  common prefer-ences on videos instead. Users tend to build social relations based on interests, and their behaviors are closely related to interests. Thus, one X  X  behaviors can be inferred from that of his/her neighbors. For example, one may want to watch a movie as he/she finds that most friends have watched al-ready. Hence, the knowledge in users X  social relationships shed light on solving the sparsity problem.

While interactions in a single social network can be sparse, there is an opportunity to exploit data in multiple networks by considering overlapping users as bridges. Several previ-ous research works have considered combining multiple net-works to form a larger network, in which a holistic user model could ideally be built. For example, Pan et al. [16] has proposed to combine multiple user relationships to rec-ommend Apps to users, where the subnetworks are treated uniformly, such that each user-user relationship holds the same importance. However, we observe that in a compos-ite network, the solution by treating each relationship uni-formly may likely result in poor prediction performance, due to the following two reasons. First, different networks have their own properties, such as density, degree distributions, clustering coefficient or diameters. If we combine dense and sparse networks together, the information in the sparse net-work will be overwhelmed inside the dense one. Second, users play different roles and get different levels of influence from their neighbors in individual networks. Some users may prefer Facebook over Twitter for one application, while others may use Twitter more frequently instead. Hence, neighbors in different networks may have different impacts on a given user. To illustrate the idea, a synthetic example is drawn in Figure 1, where there are four users (John, Sara, Bob, Alice) and their preferences on four hobbies: watching movie, listening to music, reading book and playing games. In this figure,  X 1 X  represents  X  X ike X  and  X   X  1 X  denotes  X  X is-like X . Based on the interaction matrix in Figure 1(a), we compute the users X  similarities with cosine distance [19], as shown in Figure 1(b). Clearly, John is similar to Bob, Bob is similar to John and Sara, and Sara is similar to both Bob and Alice. Figure 1(c) summarizes their relations under a given relationship, such as the friendship on Facebook while Figure 1(d) shows another one, such as the following rela-tionship on Twitter. Clearly, both of the friendship and fol-lowing relationships can only partially reflect the similarities in interests. If we simply merge them together, as shown in Figure 1(e), the naively combined network does not reflect the correct similarity among them. For example, John and Alice are dissimilar, but there is still a link between them.
In this paper, we present a hierarchical Bayesian model to cope with the above challenges. It transfers knowledge of behavior models across subnetworks in a composite net-work, specifically adapted and parameterized for different users. The common users across subnetworks form bridges to enable the transfer. To uncover the common knowl-edge across different subnetworks, we apply transfer learning techniques [15] to exploit both the topological and topical knowledge in social networks. The basic idea is to inte-grate relationships adaptively, where different users will be influenced by their neighbors in each subnetwork with per-sonalized weights.

We explain the approach briefly as follows. The model is based on latent Dirichlet allocation (LDA) [1]. Essentially, we model users X  interests as latent topics. We maintain two distributions, i.e., users X  distributions over topics and t opics X  distributions over items. These distributions are denoted as Pr( t | u ) and Pr( v | t ), where t , v and u denote topic, item and user respectively. To exploit the relational knowledge among users, we add a constraint on Pr( t | u ) to enforce that one user X  X  distribution over topics should be similar to his/her neighbors X . In addition, we introduce one more measure Pr( G s | u ) to indicate the importance of a chosen social net-work G s for a given user u . This probability is important, since each user is influenced by his/her neighbors in different social networks with different levels of importance. We re-visit the synthetic example in Figure 1 to illustrate the idea. By introducing Pr( G s | u ), each user can adopt relationship from different subnetworks individually according to their similarities to others. For example, Bob adopts the Face-book relationship in Figure 1(c) while Alice adopts the  X  X ol-lowing X  relationship in Figure 1(d). Hence the adaptively combined network can reflect users X  interests correctly, as shown in Figure 1(f). We derive an efficient Gibbs sampling method with a Map/Reduce implementation to compute pa-rameters in the proposed model, and infer the user-topic dis-tribution Pr( t | u ), the item-topic distribution Pr( v | t ) and the user-network distribution Pr( G s | u ). Extensive experiments were performed to verify the effectiveness and the efficiency of the proposed model, by comparing with state-of-the-art approaches on several large social-networking datasets -such as the actual datasets from Tencent Inc.
First, we formally define the concept of composite social network. The notations are summarized in Table 1. Let G = { G i = ( U i ,E i ) }  X  i =1 denote a composite social network, where G i is the i -th subnetwork, U i is the user set of G E i is the user relationship of U i and  X  is the number of subnetworks. In addition, we define a complete user set as U and a complete link set as E , where U =  X  X  U i }  X  i =1 { u network, users and links in different subnetworks overlap: These properties are easy to satisfy in practice. For exam-ple, users of Facebook and Twitter often overlap, although are not identical. Two users may be friends on Facebook, but may or may not always be followers on Twitter. We notice that in different social networks, a user can have a different set of neighbors, and also have different levels of influence on their neighbors. This depends on how often they interact and the closeness of their relationships. It is a key property to exploit for knowledge transfer in a com-posite social network, as different subnetworks may capture partial aspects of a given user X  X  behaviors. Consequently, we define the task of user behavior prediction as follows. Let V = { v j } T j =1 be an item set, where v j is the j -th item, which can be a movie, music, news, advertisement, webpage, etc. Let the matrix A = { a i = ( u j ,v k ) } Q i =1 denote the historical user behavior data, where each user-item pair ( u j ,v k ) rep-resents the interaction between u j and v k , such as clicking, rating, etc., and most the entries in this matrix are empty. Formally, the task of user behavior prediction is to predict the non-existing elements in A with the help of G .
We propose a composite social topic model (ComSoc) for selecting subnetworks in a composite social network, in or-der to adaptively transfer the relationship knowledge. A key point is that, the regularization from different networks is adjusted adaptively depending on the user. This is consis-tent with the observation that, someone may use Facebook more often than Twitter and hence the neighbors on the Facebook shall have higher level of influence for the given user, while others may be influenced more by their followers on Twitter, as they prefer Twitter over Facebook. The complete generating process of ComSoc is as follows. Firstly, ComSoc models users X  interests as topics and then each user is represented as a distribution over topics, Pr( t | u ). In addition, ComSoc adds one constraint on Pr( t | u ) by en-forcing that users X  distributions over topics can be used to generate links between users. Intuitively, common interests tend to create relationships among people. For each user in each subnetwork G d , ComSoc assumes Pr( t | u ), a Multi-nomial distribution, is generated by a Dirichlet distribution with a prior  X  d . Subsequently, a topic indicator is drawn from this distribution for each user. Then every link in each network is generated by a Bernoulli distribution, of which the prior is determined by the topic indicators of the users and a topic compatibility matrix B d related to G d , where B d represents the topic connections. After generating the user-topic distribution Pr( t | u ) for each user in every social networks, to transfer knowledge from social relationships adaptively, we introduce a term of users X  distribution over networks, Pr( G d | u ), in order to represent the probability of how much a user is influenced by a given network. Com-Soc models this user-network distribution in a hierarchical manner. At first, for each user u i , a network proportion  X  drawn from a Dirichlet distribution with a prior  X  . Then, for every interaction of a given user, a social network is drawn from a Multinomial distribution according to the network proportion. The user-topic distribution of the selected net-work, Pr( t | u ), is picked to generate a topic assignment. Fi-nally, ComSoc generates each interaction according to the item-topic distribution, Pr( v | t ), over the chosen topic. We formulate this process as follows. We observe that, each user u i has her/his own network pro-portion  X  i . This means that we choose different subnetworks to transfer knowledge adaptively for each user.

We draw the graphical model of ComSoc, as well as the basic LDA, LinkLDA [7] and RTM [3] in Figure 2. To make the figures clearer, for ComSoc, we draw only two social networks. In contrast to both LinkLDA and RTM, ComSoc follows a novel heuristic to exploit the knowledge in social networks in two levels or hierarchies: (1) it first introduces a network indicator to judge which network is appropriate to transfer behavior data and help the recommendation for each user adaptively -the portion surrounded by the red box in Figure 2(a); (2) for each user, it generates topics from shared user-topic distribution, in order to produce user-item interactions and user-user relations in each subnetwork at the same time -the portions highlighted by the green box. We notice that, this adaptation is not employed in the global merging approach proposed in [16]. To learn the model, we propose an efficient inference algorithm based on Gibbs sampling. In addition, to cope with the massive data issue, we also propose a large-scale implementation based on Map/Reduce [5].
T he basic idea is to update topic assignments from the posterior distribution. To guarantee sampling efficiency, the posterior distribution is represented in collapsed format [18]. We first define a number of statistics. Let n t,v denote the number of the topic t related to an item, and n s u,t denote the number of the topic t assigned to a user in the s -th network. Formally, for each topic assignment z i,k , In addition, we denote n t = P v n t,v , where n t stores the number of times that items are assigned to the topic t , and n , which maintains the number of items interacted with the user u . Lastly, we define another statistic n u,d , which is the number of times that a user u utilizes subnetwork G d order to regularize her/his distribution over topics.
We express the full joint probability of the interaction data in A with network indicators as: Pr A ,z,s |  X , X , X  = h  X  N i =1 i We notice that, different from the inference in LDA [18], the above equation has one additional term to model, which network to be selected, in order to regularize users X  distribu-tions over topics. Following the inference in [18], let z denote the topic assignments without the current topic on a i,k , and then we rewrite the above equation to obtain the following un-normalized probability, in order to resample the topic z i,k for a i,k between user u i and item v k : The resulting equation is used to update the topic assign-ments for user-item interactions. In addition, we need to sample users X  pairwise topic assignments for user-user re-lationships in each subnetwork G s , which regularizes the user-topic distributions for user-item interactions. In each network, we first define the full joint probability as: Pr  X  z,E s | B s , X  s = h  X  N i =1 Following the same inference process, the un-normalized prob-ability for resampling the pairwise topic for user relationship between u i and u j is This equation is used to update the pairwise topic assign-ments for user-user relations. In summary, in each itera-tion of Gibbs sampling, we update the topic assignments for Algorithm 1 I nference of ComSoc 1: I nput : Composite network: G , Interactions: A , # of itera-2: Output : User-topic distribution  X  s for each subnetwork G 3: Assign topics for user-item pairs randomly 4: Assign topics for user-user pairs in each subnetwork 5: Initialize the user-network assignments randomly 6: Initialize the  X  d ,  X  and  X  with zeros 7: for i = 1 to I do 8: Update user-item topic assignments using Eq.(3) 9: Update user-user topic assignments using Eq.(4) 1 4: end for Figure 3: L arge Scale Implementation on Map/Reduce user-item interactions and user-user relations in each sub-network alternatively using Eq.(3) and Eq.(4) respectively until convergence. We revisit the synthetic example in Fig-ure 1. After learning the model, to predict the preference of each user, it first selects an appropriate social relationship. For example, Bob adopts the Facebook relationship in Fig-ure 1(c) while Alice adopts the  X  X ollowing X  relationship in Figure 1(d). Then, an adaptively combined network is con-structed, as shown in Figure 1(f). The neighbors X  knowledge in this network is exploited to help pick a topic. Finally an item is selected to recommend to the given user according to the item proportion of this topic.
 Inference Framework The inference framework of Com-Soc can be found in Algorithm 1. At the beginning, it randomly picks topics for user-item interactions and user-user relationships. Afterwards, in each iteration, Eq.(3) and Eq.(4) are utilized to update the topic assignments from user-item interactions and user-user relations in each social network. The iteration is repeated until convergence. In addition, a burn-in process is introduced in the first sev-eral iterations to remove unreliable sampling results. The parameters  X  s ,  X  and  X  are used to predict user behaviors.
Time Complexity We analyze the time complexity as follows. Suppose the process needs I iterations to reach convergence. In each iteration, it requires to go through all user-item pairs ( Q ) in the interaction network and user-user pairs ( M i ) in each sub social network. In addition, for each pair, it requires O ( K ) operations to compute the posterior distribution and sample topics, and constant cost to update the statistics. At last, it needs O ( N + T ) operations to generate topic proportions. Thus, the whole time complexity is O ( I ( Q + P  X  i =1 M i ) K + N + T ) = O ( I ( Q + P
In many real world applications, the number of users ( N ) can be in the order of several billions, the number of items ( T ) can be up to millions and the number of user-item inter-actions ( Q ) and user-user relations ( M i ) can be tens of bil-lions. In a way, these are very big datasets. Thus, the ability to scale up the proposed algorithm is crucial for real-world practice. We implement the inference algorithms of ComSoc based on Map/Reduce [5]. The main idea is to compute the posterior distribution and resample the topic assignments on partial data in each single machine and then aggregate pieces of results. Recall that in Eq.(3) and Eq.(4), several statistics will be updated in the sampling process, including the user-topic count n s u,  X  of each user in the s -th network, the user-network count n u,  X  , the topic count n t , the item-topic count n  X  ,v of each item and the topic assignment z i,k for u and v k . We partition the data by users. For example, if there are D machines, then the whole dataset will be divided into D groups and each group will contain parts of users as well as their relationship and interaction data. As stated in [20], n s u,  X  , n u,  X  and z i,k are entirely local to each user and thus do not need to be shared. They can be written to the disk after resampling. In addition, n t and n  X  ,v change slowly, and hence, a delay in obtaining their up-to-date representa-tions will not affect the sampler significantly. Furthermore, the number of topic statistics, { n t } K t =1 , is small, where K is the number of topics. Thus we can keep them in the mem-ory permanently. These observations accomplish the local sampling without losing too much precision. In summary, the distributed implementation of Algorithm 1 is also an it-erative approach, but in each iteration, it resamples topic assignments in a distributed manner. Let M/R denote a pair of Map/Reduce operations for simplicity.

Before the start of iterations, the inference algorithm per-forms distributed initialization. Due to limited space, we omit the details here. The sampling process in each iteration needs four M/R. The main flow can be found in Figure 3. The first M/R is used to duplicate the statistics n  X  ,v of every item for each related user. Similarly, the third M/R is used to duplicate the statistics n s u,  X  , since each user is linked to multiple users in the s -th social network. For each user u the related statistics n s u = i,  X  will be copied | N s ( u where | N s ( u i ) | is the number of its neighbors in the s -th network, and each duplicated statistics is used for the sam-pling of each neighbor u j  X  N s ( u i ). The second M/R is used to resample the topic assignments for user-item interactions and the last one resamples the topic assignments for user-user relations in each subnetwork. All information related to users and items are represented as h key,value i pairs, where key can be either user or item identities and value can be statistics, topic assignments z i,  X  , item interactions a user relations information N s ( u i ). Let  X  denote the type of value and c indicate whether the value is for a given user or her/his neighbors. Formally, the process is as follows:
Subsequently, the increments for the counts on topics and item-topic pairs will be used to update n  X  ,v = k . Finally, n in each single machine and the updated statistics will be shuffled to each single machine for the next iteration.
We evaluate the proposed methods on two data collec-tions, one is from Douban 2 , and the other is from Tencent; both contain composite social networks and rich user be-havior information. We compare the proposed approach with three state-of-the-art methods: latent Dirichlet allo-cation (LDA) [1], LinkLDA [7] and relational topic models (RTM) [3]. For LinkLDA and RTM, we implement two vari-ations: one is to build models with only one single social network, and the other is to build models with a naive com-bined social network, of which the edge set is the union of all edges in subnetworks. For the model parameters, we set the priors for topic models as  X  = 0 . 5,  X  = 50 /K and  X  = 0 . 5. In addition, we set the number of topics as K = 50. We will study the effectiveness of this parameter later. The results are evaluated based on two criteria: perplexity (perp) and mean average precision (MAP) on the hold-out set T . where pre r represents the precision on top-r predictions. Be-havior records in T are represented as a list of user-item pairs. For example, for the music listening prediction, one user-item pair represents one user will listen to the given music. Then the task is to predict if such behaviors happen or not, in other words, if the corresponding user-item pairs exist in T or not. Generally, perplexity measures how pre-cisely the algorithm generates the behaviors in the hold-out set, and MAP measures how well the algorithms rank the behaviors in the hold-out set above non-existing behaviors. In addition, to evaluate the significance in improvement of the proposed model, we randomly split the hold-out set into 10 subsets and then calculate the error bar. We notice that, the observed behaviors are implicit, where we only know which items are interacted by a given user. http://www.douban.com
The Douban collection contains two subnetworks. One is the online contact network, representing who pay attention to whom, and the other is the offline physical network, indi-cating who are familiar with whom in the real world. Since the website does not provide APIs to collect the data of of-fline relations, we construct the offline network using users X  co-occurrence in social gatherings, where people physically meet. If two users take part in the same gatherings more than 20 times, we consider that they know each other. Fi-nally, the task is to predict users X  behaviors on movie, music and book domains using their historical behavior logs, as well as the information in the online and offline networks. This dataset can be downloaded 3 .
 The Tencent collection contains two subnetworks. One is QQ 4 , which contains about 1 billion users and 80 billions links, making it the biggest instant messaging network in the world, and the other is Tencent X  X  Microblog network 5 which contains more than 200 millions users, making it one of the biggest Microblog networks in China. We introduce two subtasks: the first one is to predict which songs users will collect in the future, which can be applied to radio ap-plications 6 , and the second one is to predict users X  profiles, which is crucial to display online advertisements. To gener-ate users X  profiles, we recorded the words from three big Web sites: QQ.com, one of the biggest portals in China, qzone the biggest social blogging service in China and wenwen 8 one of the biggest QA systems in China. Subsequently, for a given user, 5 , 000 words with commercial values, such as in-surance, loans, etc., were extracted from webpages that the user has browsed. These words are used to describe users and then each user is represented with a ? / 1 vector, where 1 represents a particular user browsing the corresponding word, and the question mark (?) represents unknown. As http://www.cse.ust.hk/TL/data set/Douban-50000.zip http://www.tencent.com/en-us/ps/imservice.shtml http://t.qq.com/?lang=en_US http://fm.qq.com/ http://qzone.qq.com http://wenwen.soso.com/ Figure 5: M AP with Error Bars of Tencent Collection users X  browsing contents can change over time, the task here is to predict which words the user will browse in the future.
Table 2 presents the statistics of the datasets. In sum-mary, the Douban collection contains three types of user behavior: movie watching, music listening, and book read-ing, while the Tencent collection contains two other types: music collection and user profile modeling. We observe that the user-item interactions and user-user relations in each sin-gle network are very sparse. The degree distributions of the social networks in both Douban and Tencent datasets are plotted in Figure 4. We observe that degree distribution of each network follows the power-log distribution, that means each subnetwork is still sparse and most users have limited interactions. Hence we should utilize the knowledge from multiple networks together.

Data Sampling Process For the Douban dataset, we crawled the data through the APIs provided by the website. We randomly retrieved 30 senior users, who registered more than 4 years ago and are still active. Then we performed breadth-first-search based on their online contacts to collect more users iteratively, until the number of users reached a threshold (50,000 in this paper). Subsequently, the con-tact relations and the social gathering co-occurrence among these users, and their behaviors on music, book and movie domains were recorded. For the Tencent dataset, we firstly picked a user whose number of neighbors is around 100 ran-domly. Then, this user as well as his/her neighbors on QQ and Microblog networks are retrieved as a seed set. Similar to the Douban data, we performed breadth-first-search on these two networks to extend the user set until the number of users exceeded a threshold. Finally, corresponding social networks of these users, their music collection records and webpages browsing logs within two months were extracted as the experimental data. Behavior data in the final week are hold out as the test set.
Table 3 and Figure 6 summarize the perplexity and MAP of LDA, LinkLDA, RTM and the proposed ComSoc on the (f) E fficiency-links three datasets of the Douban collection. For the Movie dataset, as highlighted in bold, ComSoc consistently out-performs LDA, LinkLDA and RTM on MAP and perplex-ity. The MAP of ComSoc is at least 0.017 larger than LDA. If we overlook the model differences, compared to its com-peting methods, ComSoc on average achieves 0.017, 0.016 and 0.007 higher MAP as compared to LDA, LinkLDA and RTM respectively. The better performance of ComSoc over RTM and LinkLDA with one subnetwork, e.g, RTM-Online, etc., can be ascribed to the fact that, ComSoc considers more knowledge from auxiliary networks, and hence, cap-tures more aspects of users X  interests. For example, users can share their interests through different subnetworks so some regularization knowledge will be missed if only one network is considered. On the other hand, although RTM-C and LinkLDA-C explore knowledge from multiple networks to improve their accuracies, they assign uniform regulariza-tion on users without considering the network differences to each user, i.e., different users actually receive different levels of influence from their neighbors in different social networks. In this sense, RTM-C and LinkLDA-C may intro-duce unnecessary regularization from unrelated networks. For example, the offline network is less useful to infer users X  interests. As shown in Table 3, LinkLDA-Off and RTM-Off do not improve the performance of LDA. However, ComSoc adaptively selects network and hence solve the above prob-lems. Moreover, in all cases, ComSoc outperforms LDA on all three datasets, implying that when the historical inter-action knowledge is sparse, social network information can actually improve the prediction performance.

Table 4 and Figure 5 summarize the results on the two datasets from Tencent. Similar to the performance in the Douban collection, ComSoc consistently outperforms RTM, LinkLDA and LDA on both perplexity and MAP for both datasets. For example, on the Profile dataset, ComSoc gets MAP higher than 0.605 while other baselines do not exceed 0.587. In addition, on the Music dataset, the improvement of ComSoc is as high as 0.03 on MAP comparing to LDA. Importantly, the improvement of ComSoc on Tencent col-lections is more significant. One reason is that, users share more contents through both QQ and Microblog networks, and hence the links in these two networks can reflect more users X  interests. These justify the effectiveness of the pro-posed methods empirically.
We conduct five extensive experiments on the Douban col-lection to answer the following questions: (1). Does ComSoc transfer knowledge from composite social networks to differ-ent users adaptively? (2). Does ComSoc enrich the knowl-edge in the user-item interaction network and therefore re-duce the X  X parsity X ? (3). How does the correspondence ratio between composite social network and user-item interaction network affect ComSoc X  X  performance? (4) What is the ef-fectiveness of the model parameters?
We answer the first question by examining the network proportions of different users in the Movie dataset captured by ComSoc. We pick 100 users who have the most behavior data, as these users have the highest confidence to derive the weights of different networks. The results are presented in Figure 7(a), where the y-axis represents the proportion dif-ference between online and offline networks of a given user u : Pr(network=online | u )  X  Pr(network=offline | u ). The differ-ences of most users are not equal to zero, meaning different networks have different impacts to different users and Com-Soc utilizes the knowledge in each network adaptively.
We evaluate the results on long-tail users, whose number of behaviors are smaller than 10. These users suffer from the harm of  X  X parsity X  the most, since each of them inter-acts with only  X  0 . 01% items. The results are presented in Figure 7(b). We observe that, the improvement of ComSoc on long-tail users is at least twice more than the average level. For example, on the Book dataset, the improvement o f ComSoc is smaller than 0.01 on MAP on the average level, while larger than 0.03 on long-tail users. One reason is that, for those users who have a large number of inter-actions, LDA has gained enough knowledge to infer their distributions over topics; but for the long-tail users, Com-Soc can significantly exploit knowledge from the composite social network to help enhance the prediction. This pro-vides justification to the argument that ComSoc can enrich the knowledge in the user-item interaction network.
In real world, many people may only use parts of on-line services, i.e., they may exist in one subnetwork but not in all networks. We test the effect of the correspondence ratio be-tween the composite social network and the user-item inter-action network, e.g., the number of users who exist in both social and interaction networks. Figure 7(c) presents the results with different ratios between the offline/online net-works and the Movie interaction network. ComSoc X  X  perfor-mance becomes worse if fewer correspondences are provided across networks. An important observation is that it out-performs LinkLDA consistently if there are corresponding users among networks, implying that ComSoc successfully use the overlapping users as bridges to transfer knowledge.
We analyze the effect to change the number of topics K on the Douban collection. We change K from 5 to 100. The results are illustrated in Figure 7(d). We observe that the performance of ComSoc improves with the increase of K but the increment becomes smaller. The reason is that K represents the model complexity. Thus, when K is too small, the model has limited ability to describe the data. On the other hand, when K exceeds a threshold (e.g, 50, the default value in the experiment), the model is complex enough to handle the data. At this point, it is less helpful to improve the model performance by increasing K . In practice, K can be tuned through cross-validation techniques [25].
As analyzed in the end of Section 3.2, the computational time of ComSoc increases linearly with the number interac-tions between users and items, the number of links in the composite networks, and the number of topics K . We evalu-ate this empirically as shown in Figure 7(e)  X  (g). Three sub-figures from left to right illustrate the computational time of LinkLDA-C, RTM-C and ComSoc on the Movie dataset, with different ratio of interactions and links, and different number of topics respectively. We observe that the com-putational time linearly increases with larger data size and number of topics. For our experiment setting, each iteration takes about 80 seconds in our computer, of which memory is 4G and CPU is 2.0Gz. Although ComSoc has better pre-diction performance as show in Table 3 and Table 4, it is faster than RTM and has similar time cost with LinkLDA.
The proposed methods can be considered as transfer col-laborative filtering algorithms based on topic models. We summarize the novelty of the proposed approaches in Ta-ble 5. Most previous works either focus on one social net-work or treat users uniformly, where different users receive the same influence from different social networks, but the proposed model exploits knowledge adaptively in a compos-ite social network, which contains several subnetworks. Al-though the problem studied in this paper is how to solve the  X  X parsity X  problem, sparse learning [21] is in fact a different formulation that does not solve this problem; it builds mod-els with very few non-zero coefficients to reduce the compu-tation cost, but does not resolve the data sparsity.
Social Networks Analysis [6] has drawn much research interest, ranging from link prediction [12], predicting how likely an unobserved edge exists between an arbitrary pair of nodes; community detection [11, 10], identifying communi-ties of interest and studying their behaviors over time in so-cial networks; to social influence [23], studying how the per-ceived relationships with other users influence the behavior of a given user. Most previous works of social influence focus on how to measure the social influence [2] or maximize the user influence [4, 8]. However, the proposed methods in this paper instead exploit social influence to help predict users X  behaviors. Collaborative Filtering (CF) is the process to filter information or patterns using techniques involving col-laboration among multiple agents, viewpoints, data sources, etc. The proposed methods in this paper belong to the cat-egory of model-based CF which uses the observed user-item interactions to train a compact model that explains the given data. Models in this category include matrix factorization[9] and topic models [22]. Among them, topic models provide an interpretable low-dimensional representation for the interac-tions between users and items. The simplest topic model is latent Dirichlet allocation (LDA) [1], where a topic is a dis-tribution over items and a user is a distribution over topics. Multiple variants have been proposed to incorporate the re-lational knowledge [3, 14, 7]. However, these previous works utilize only one single network. Transfer Learning solves the lack of class label problem in the target application by  X  X orrowing X  X nowledge from related domains [15, 24]. It was on collaborative filtering recently. According to the different kinds of auxiliary data, transfer CF can be categorized into three classes. The first one is to exploit the meta data or user/item content [22]. For example, the algorithm in [22] utilizes both articles X  content and users X  interactions on ar-ticles together to perform recommendation. The second one is to borrow knowledge from other CF domains, such as transferring knowledge from a movie to a book domain [17]. The third kind is to exploit users X  or items X  relationship, such as a single trust network [13]. More recently, the work in [16] utilizes multiple social networks to recommend Apps to users using a nearest neighbor model. However, it needs to enumerate all user-item pairs and hence cannot scale up to handle large datasets. In addition, these previous works either consider one auxiliary source or regularize users mod-eling uniformly, which ignore the fact that different networks have different influences to different users.
In this paper, we studied a new problem on how to trans-fer knowledge from composite social network for user be-havior prediction, where the behavior data (or user-item matrix) of the target application can be more than 99 . 9% empty. We defined a composite social network as a set of nested single networks, where users and links in different subnetworks overlap. Each network reflects partial aspects of users X  interests and has different properties. For different users, individual networks have a diverse range of influences. T hus, we proposed a hierarchical Bayesian model to trans-fer knowledge for different users adaptively. The knowledge from the composite social network is utilized to regularize users X  distributions over topics. Unlike prior works, the pro-posed model considers knowledge transfer adaptively. This is formulated into a parametric model that controls the prob-ability of how one user is influenced by a given network. In addition, different from the previous relational topic models, ComSoc exploits user-topic distributions to generate users X  social relations. The proposed model is flexible in that, it can be extended to any number of networks. We proposed a large-scale implementation based on Map/Reduce to cope with massive amount of data. We conducted empirical stud-ies on two data collections from Tencent Inc. and Douban, where ComSoc outperforms several state-of-the-art baselines by as high as 0 . 03 on MAP.

Future Works In this paper, we only build models to predict whether a user will interact with a given item or not. In future work, we plan to extend the proposed model to handle different kinds of behavior, such as rating, multi-class prediction, etc. We will extend the experiments over multiple social networks, such as Facebook + Twitter + MSN. We will consider incorporating heterogeneous auxil-iary knowledge together, such as item profiles, user behav-iors in auxiliary domains, etc.
 We thank the support of Hong Kong RGC GRF Projects 621010 and 621211.
