 There exists considerable literature on estimating the car-dinality of set intersection result. In this paper, we con-sider a generalized problem for integer sets where, given a gap parameter  X  , two elements are deemed as matches if their numeric difference equals  X  or is within  X  . We call this problem the gapped set intersection size estimation ( GSISE ), and it can be used to model applications in database sys-tems, data mining, and information retrieval. We first dis-tinguish two subtypes of the estimation problem: the point gap estimation and range gap estimation. We propose op-timized sketches to tackle the two problems efficiently and effectively with theoretical guarantees. We demonstrate the usage of our proposed techniques in mining top-K related keywords efficiently, by integrating with an inverted index. Finally, substantial experiments based on a large subset of the ClueWed09 dataset demonstrate the efficiency and ef-fectiveness of the proposed methods.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Indexing; Set Intersection Size Estimation; Top-k
Set intersection is a fundamental operation in many fields in computer science. Given two sets S A and S B , set intersection S A  X  S B is to find all the common elements from two sets. A common case is that all elements in the set are integers (e.g., document IDs or positions in an inverted index). Hence, the common element pair ( a, b ) satisfies b  X  a =  X  , where a  X  S A , b  X  S B and  X  = 0.

In this paper, we generalize the set intersection on integer sets to allow for  X  X aps X  (i.e.,  X  &gt; 0). We define two primi-tives: the point gap constraint corresponds to a fixed gap of  X  , and the range gap constraint corresponds to a gap of size no larger than  X  . We are interested in methods to estimate these gapped set intersection size efficiently and accurately. This problem has many applications. For example,  X  Information Retrieval : In information retrieval, the search engine needs to intersect the positional inverted lists of query keywords to answer a multiple keyword phrase query. A state-of-the-art query processing method, svs , performs binary intersection using a heuristic order that is purely based on the length of the inverted lists [11]. This heuristic is not effective when search keywords are not very selective (e.g.,  X  to be or not to be  X ). It is possible that a pair of query keywords with the positional constraint imposed by the phrase query will result in very small intermediate result size (e.g.,  X  be  X  followed immediately by  X  or  X ). Hence, if we can estimate its cardinality accurately and efficiently, we may find a better inverted list intersection order to process such queries. We can model this as a gapped set intersection size estimation problem with a point gap constraint of 1.  X  Sentiment or Event Analyses : In sentiment analysis, we extract different types of events, including a mention of a product, and an occurrence of sentiment (e.g., the word  X  fantastic  X ). We are usually interested in events that occur in a close vicinity. For instance, the positions of their occurrences in a document are within  X  [17] or the timestamps of their occurrences in tweets are within  X  [25]. We can model this as a gapped set intersection size estimation problem with a range gap constraint of  X  .
Motivated by the examples, we define and study the problem of gapped set intersection size estimation (abbre-viated as GSISE ). For the estimation problem with point gap constraints, we propose a basic method that reduces the problem to the standard set intersection size estimation problem, which can be solved using the state-of-the-art sketch method. However, the index space is linear to the maximum query gap allowed. We improve it by judiciously selecting a subset of sketches to construct, and this reduces our sketch size from O ( N ) to O ( approach is proved to be asymptotically optimal, while the time complexity remains the same. For the estimation prob-lem with the range gap constraint, a baseline method is to reduce the problem into multiple estimation problems with different point gap constraints, and this requires estimation time linear in the gap size. We propose an extension of the bottom-k sketch to multiset and an unbiased estimator for inner product, we achieve an accurate and fast estimation method that is independent of the gap size. To demonstrate the use of our estimation methods, we consider the problem of finding highly correlated keywords from a large document collection. We design a new query processing method based on indexing the hash values in our sketches. Finally, we per-f orm large-scale experimental evaluation using 500 million documents from the ClueWeb09 data collection and demon-strate the accuracy and efficiency of our proposed methods. Contributions. The contributions of this paper are summarized as follows.  X  To the best of our knowledge, this is the first work to for-mally define the point and range gapped set intersection size estimation problems, which can be used as primitive operations in a wide spectrum of applications.  X  We design space and time efficient sketch and estima-tion methods for both types of estimation tasks. Our estimates are unbiased and have theoretical guarantees.  X  We demonstrate the application of our technique for approximately mining top-K related keywords from large document collections. Our technique is especially useful in this application scenario where an exact solution requires orders of magnitudes larger space and time.  X  Comprehensive experiments on the ClueWed09 dataset demonstrate the efficiency and accuracy of the proposed methods.
 Organization of the paper. The rest of the paper is organized as follows. Section 2 briefly surveys the related works. Section 3 defines the problem formally and intro-duces several useful techniques. Section 4 elaborates the estimation framework for point query and range query, to-gether with their theoretical properties. Section 5 presents algorithm to top-K related keywords mining application. The experimental results are reported and analyzed in Section 6. We conclude the paper in Section 7. Exact set intersection. Set intersection has long been a fundamental problem. There are plenty of literature focus-ing on set intersection problem [12, 13]. The algorithms working on sorted set are mostly used [24]. By applying lin-ear merge of two sorted set S A and S B , the set intersection can be finished in O ( | S A | + | S B | ) time. However, when the set sizes are unbalanced, the method is inefficient. In [18], authors propose a set intersection approach requiring O ( | S B | + log | S A | + | S B | | S also works further improving the performance by utilizing hashing, and adaptive methods [3, 2]. Unlike the above literature, we want to estimate the gapped set intersection size rather than calculating the exact result.
 Set intersection size estimation. The problem of set intersection size estimation is to estimate the cardinality of intersection with a sketch method, which has been exten-sively studied in [6, 4, 7]. Nevertheless, all existing methods are designed for non-gapped set intersection size estimation. A na  X   X ve way to extend existing methods to support the GSISE problem is to build sketch for each possible query gap. However, it will result in the index space linear to the maximum gap. Furthermore, the computational complexity for range query will be linear to the query gap. In this paper, we try to reduce both space and computational complexity in processing GSISE . In addition, there are several works [26, 21] that calculate an upper bound of set intersection size, which is orthogonal to our problem. Top-K query. One of the most important applications of GSISE is top-K related keyword mining. The problem is well studied in [16, 15]. Afterwards, there are varieties of follow-up works dealing with top-K ranking for different applications, e.g., keyword queries [20], top-K preference ranking queries [23] and semi-structure queries [27].
Most of the works, such as [28], are based on the strategy that gradually scans the inverted index and updates the upper and lower bounds of the ranking terms, in order to achieve early stopping. However, the above strategy is not well suited in our sketch based estimation framework. Since it is non-trivial to obtain a tight bound for the estimation. Instead, a hash table based method is proposed in Section 5 to accelerate the top-K query processing.
In this section, we define two estimation problems, intro-duce existing work on estimating the size of set intersection using sketch, and finally list important notations used in the paper.
Given two sets S A and S B , their intersection is defined eq ( a, b ) checks if a equals b . We can generalize the set intersection by considering other meaningful predicates. Specifically, with a gap parameter  X   X  0, we consider the following two predicates:  X  PointGap  X  ( a, b ), which returns true if and only if b  X  a =  X  .  X  RangeGap  X  ( a, b ), which returns true if and only if 0  X  b  X  a  X   X  .
 We call set intersection with these two new predicates collectively gapped set intersection . They are denoted as S A  X  =  X  S B (named point gapped set intersection ) and S
A  X   X   X  S B (named range gapped set intersection ), respec-tively. Obviously, the standard set intersection is a special case of both types of gapped set intersection where  X  = 0.
In this paper, we study space and time-efficient methods to estimate the results size of these two types of gapped set intersection. Motivated by the applications we aim at, we consider sets whose elements are integers.

Definition 1 ( GSISE ). Given two sets S A and S B , and a gap parameter  X   X  [0 , N ] where N is a predefined maximum gap value. The Point and Range Gapped Set Intersection Size Estimation Problem is to estimate | S A  X  =  X  S B | and | S
A  X   X   X  S B | , respectively. They are abbreviated as point estimation and range estimation hereafter.

Example 1. Let S A = { 1 , 3 , 4 , 7 } and S B = { 2 , 5 , 6 , 8 } , and  X  = 2 . Under the point gap constraint, S A  X  =2 S B = { (3 , 5) , (4 , 6) } . Hence its size is 2 . Under the range gap Hence its size is 5 .
 Discussions. In the above definitions, we only need to consider  X   X  0. This is because S A  X  =  X  S B = S B  X  =  X   X  (this also holds for range gapped set intersection too).
Many other types of interesting gapped set intersections can be defined using our point and range gapped set intersection as primitives. For example, consider the predicate RangeWithin  X  1 , X  2 ( a , b ) with two range parameters that its query result is exactly the difference of two range gapped set intersection, i.e., ( S A  X   X   X  2 S B ) \ ( S A
In a similar fashion, we can derive point gapped set intersection based on range gapped set intersection, and vice versa. Nevertheless, we still consider them as two s eparate primitives, as each of them can model different applications respectively, and we will propose related but different estimation methods and optimizations for them.
The state-of-the-art method to estimate the size of set intersections is the bottom-k sketch [7, 8, 9]. It is a lightweight sketch that supports efficient update. We use sk ( S A ) to denote the bottom-k sketch for a set S , which is a set of k hash values. To construct the sketch, we apply a random hash function h to every element a  X  S A , and keep the k minimum hash values. We also assume the codomain of h is sufficiently large such that we can safely assume that there is no collision.

An important property of the bottom-k sketch is that it is closed under set union operation. Specifically, we can directly compute the bottom-k sketch of the union of two sets from their respective bottom-k sketches. The resulting sketch is called short combination sketch [9]: scs ( sk ( S A ) , sk ( S B )) = { v | v  X  sk ( S A )  X  sk ( S min( sk ( S A ) ( k ) , sk ( S B ) ( k ) ) } , where the notation S denotes the k -th smallest value in the set S .

To estimate the intersection size of two sets S A and S B from their respective sketches, we compute [9] proved that t is an unbiased estimator of | S A  X  S B can be computed efficiently. Besides, it is shown to have smaller variance compared with the Minhash [5] method. Table 1 lists notations frequently used in the paper.
In this section, we introduce solutions to point and range estimation problems. The na  X   X ve index structure and our intuition are explained in Section 4.1, followed by technique details of GSISE methods in Section 4.2 and 4.3.
Point estimation is a challenging problem due to the following reasons:  X  Almost all the set intersection size estimation methods are based on random hash functions. Therefore, given a gap value  X  , and two different hash values h ( x +  X  ) and h ( y ), it is almost impossible to infer if x +  X  is equal to y .  X  While locality sensitive hash functions [19] do preserve locality probabilistically, the intersection size is highly sensitive to the point gap threshold. It is often the case that | S A  X  =  X  S B | and | S A  X  =  X  +1 S B | differ substantially.
For instance, in Example 1, | S A  X  =0 S B | is 0 while | S A  X  =1 S B | is 3. Therefore, even a small approximation in the gap may result in a large estimation error.
Therefore, we first propose a baseline method, which reduces the point estimation problem to a standard set intersection size estimation problem, which in turn can be solved using the state-of-the-art method, such as the method based on bottom-k sketches.
 Our reduction is based on the notion of shifted sets . Given a set S A = { a 1 , a 2 , . . . , a n } and integer param-eter d , we define the shifted set with shift d as follows: S A : = { a i + d | a i  X  S A } .

Given the maximum gap size N , we compute N + 1 bottom-k sketches by shifting S A : the i -th bottom-k sketch is built for the shifted set S + i A (0  X  i  X  N ). To perform the estimation for S A  X  =  X  S B , we retrieve the sketches of S and S +0 B , and perform the estimation using the bottom-k estimation procedure (i.e., Eq. (1)).

Example 2 . Table 3 shows the sketches built by the baseline method for two sets S A and S B , where the bottom-k sketch size is 3 and maximum gap N is 9 .

To perform the point estimate for  X  = 5 , we load sk ( S +5 A ) and sk ( S +0 B ) , the estimate according to Eq. (1) is min(0 . 48 , 0 . 79) = 2 . 08 . The actual point gapped intersection size is 2.
 Table 3: N + 1 bottom-k Sketches Built for S A = { 1 , 3 , 4 , 7 } and S B = { 2 , 5 , 6 , 8 } using the Hash Function in Table 2. N = 9 .
Obviously, this baseline method achieves the same a ccuracy guarantee as the standard bottom-k sketch [4, 7, 22], and the estimation time is O ( k ). The main problem is its space complexity of O ( N  X  k ) for each set, which is not optimal.
In this subsection, we seek to improve the space complex-ity per set from N  X  k to same O ( k ) estimation time. We also show that this space complexity is asymptotically optimal with an approximation r atio of
W e observe that we can generate sketches for a judiciously chosen subset of all possible shifted sets, to ensure that can still find two appropriate sketches for two sets to perform the point estimation for any  X   X  [0 , N ].

Let  X  : =  X  for S A shifted by i  X  I , where
Algorithm 1 describes the estimation procedure. Lines 2 X  5 compute the correct offsets (also called indices) of the sketches of S A and S B . Then Line 6 performs the estimation with the corresponding bottom-k sketches.
 Algorithm 1 : P ointQueryOnlineEstimation ( S A , S B ,  X  ) Input :  X  : query gap. N : maximum gap.

Output : An estimate of | S A  X  =  X  S B |  X   X  X  X  i f  X  (mod  X  ) = 0 and  X  6 = N then e lse return B ottom-k -Estimate ( sk ( S + i A A ), sk ( S + i
Example 3 . Continue the previous example.  X  =  X  = 3 . In our improved method, the following sketches are generated for every set S sk ( S +0 i ) , sk ( S +1 i ) , sk ( S +2 i ) , sk ( S +3 For point estimation with  X  = 5 , we compute i A = 6 and i
B = 1 according to Algorithm 1. Then we load sk ( S +6 A ) and sk ( S +1 B ) and perform the estimation.

The correctness of Algorithm 1 depends on two facts:  X  Gapped set intersection size is shift-invariant as shown in
Lemma 1, and  X   X   X   X  [0 , N ], we can always locate the i A and i B from the index set (Equation (2)) such that i A  X  i B =  X  .
The improved method has a O ( per set, O ( k ) estimation time, and the same estimation quality guarantees as the bottom-k sketch.
We show that our improved method is asymptotically space optimal in this reduction framework. To facilitate the analysis, a computational model is formalized below in Definition 2.

Definition 2. Given set G = { 0 , 1 , 2 ,  X  X  X  , N } , where N is the maximum gap predefined. We want to find an integer set P with minimum cardinality, such that  X  g  X  G , there exist i, j  X  P satisfying i  X  j = g .

Property 1. The lower bound of | P | is  X (
P roof. First there are no duplicate elements in P , otherwise | P | cannot reach the minimum since it is allowed to choose two identical elements from P to get 0  X  G . Now that all elements in P are different, we can construct a mapping f from i  X  j to G \ { 0 } . It is easy to see the lower bound will be achieved when the mapping is bijective. Hence, the number of all possible choices of i  X  j is | P | Since | P | 2  X  N , we have | P | =  X (
Corollary 1 . The number of sketches constructed in our improved method is within a factor of solution.
Our basic method for range estimation is to reduce a range estimation to multiple point estimations, due to the following equivalence.
 addition,  X  i 6 = j, ( { S A  X  = i S B } )  X  ( { S A  X  = j
Theorem 1 reveals that the range gapped set intersection results can be partitioned into disjoint subsets, each is the result of a point gapped set intersection. Taking the cardinality on both sides of the equation and we have the following Corollary.

Corollary 2 enables us to sum up  X  + 1 point estimation results to answer a range estimation. While this does not increase the space complexity, the estimation time is linear in the range  X  . When  X  is large, the estimation time grows quickly, which is not desirable.
We introduce several essential concepts, which enable us to present an observation using an example. This relates the range estimation to the problem of estimating the inner product of multisets, each obtained by merging shifted sets in a particular pattern.

We define a multiset M as a set of elements, each associated with its multiplicity, i.e., M = { a 1 : m 1 , a 2 : m 2 , . . . , a n : m n } . elems ( M ) returns all the elements in the multiset M , i.e., { a 1 , a 2 , . . . , a multiplicity of an element e in M is denoted as cnt M ( e ). Note that a set is just a special case of a multiset where all the multiplicities equal 1.

Let U be the universe of all elements. Each multiset can be implicitly cast into a | U | -dimensional vector where the dimension values are the multiplicities of the corresponding elements (default to 0). Hence, we can define the inner product of two multisets as h M A , M B i = X
Now, we can illustrate an important observation that leads to our improved range estimation in Example 4.
Example 4. Consider the same instance in Example 3 and we want to estimate S A  X   X   X  S B . Table 4(a) enumerates for all possible  X   X  [0 , 8] the shifted S A and S B that will be used for set intersection with point gap  X  . For example, the cell with green background is for  X  = 5 ; it is associated with S
A and S Now consider the range gapped set intersection with  X  = 5 . Corollary 2 shows that the result size | S A  X   X  5 S B | equals the sum of the size of 6 point gapped set intersections, with the gap constraint between 0 and 5. By looking at Table 4(a), we can see the latter is equivalent to h M A , M B i , where Note that we need to use multiset union (also called merge in this paper, denoted as  X  ) and the inner product, as there may be potential duplicate elements. Obviously, if we can estimate the inner product of multisets, then we can perform one estimation rather than six point estimations.
By considering all possible  X  values in Example 4, we can observe the pattern where multiple shifted sets are merged. To simplify the notation, we use the set of shift values as an identifier (or index) for the merged multiset, is { i 1 , i 2 , . . . , i j } and it uniquely identifies M .
Let  X  =  X   X  For shift values within [1 ,  X  ], we need to merge its suffixes, i.e., generating indices { i, i + 1 , . . . ,  X  } , for 1  X  i &lt;  X  .  X  For shift values within [  X ,  X  2 ], we need to merge its prefixes, i.e., generating indices {  X , 2  X , . . . , i  X   X  } , for 1 &lt; i  X   X  .
As motivated in Example 4, we need to estimate the inner product of two multisets. While there are many alternative methods (such as Tug-of-War [1] and Count-Min [10] sketches), we observe that the input multisets are always those shifted sets generated for the point estimation task, which means each of them has already its bottom-k sketch built or maintained. Therefore, we develop an estimator by extending the bottom-k sketch as follows.

Firstly, we define our multiset bottom-k sketch for a multiset obtained by merging multiple shifted sets, each with its own bottom-k sketch. Let S = { S 1 , S 2 , . . . , S denote a set of shifted sets, each with its bottom-k sketch sk ( S i ). Let M =  X  n i =1 S i . M  X  X  multiset bottom-k sketch, denoted by msk ( M ), is obtained by a truncated merge of the sketches, i.e., 1. first merging sk ( S i ) into a multiset M  X  , and 2. then keeping only the k smallest elements and their multiplicities in M  X  .
 Figure 1 illustrates the relationship between a multiset bottom-k sketch and its constituent bottom-k sketches.
Given two multiset bottom-k sketches msk ( M A ) and msk ( M B ), their range union sketch , denoted by rus ( msk ( M A ) , msk ( M B )), is a multiset that contains all the hash values in elems ( msk ( M A ))  X  elems ( msk ( M B )) that are sum of their multiplicities in msk ( M A ) and msk ( M B ). Given Figure 1: From bottom-k S ketches to a Multiset bottom-k Sketch msk ( M A ) and msk ( M B ), we propose an unbiased estimator of h M A , M B i , as shown in Theorem 2. Furthermore, it can be shown that, by using the range union sketch, our method takes advantage of all the information available in msk ( M and msk ( M B ) to arrive at the best possible estimation.
Theorem 2. Given two multiset bottom-k sketches msk ( M A ) and msk ( M B ) , let rus  X  = elems ( msk ( M elems ( msk ( M B ))  X  elems ( rus ( msk ( M A ) , msk ( M is an unbiased estimator of h M A , M B i .

Proof. Define adjusted multiplicity for each e  X  elems ( M A )  X  elems ( M B ) to be: a = the l -th smallest hash values in rus . Then we can write E  X  t r = E The last step is because rus keeps complete multiplicity information for each underlying set element included in rus . Complete means if element e is sampled in rus  X  , it holds that cnt msk ( M ) ( e ) = cnt M ( e ). Since we are doing consistent uniform sampling in elems ( M A )  X  elems ( M B ). Therefore, E  X  t r = h M A , M B i .
Furthermore, by setting k t o an appropriate value, we can achieve a probabilistic guarantee for  X  t r , as shown in Theorem 3.

Theorem 3. Let  X  = h M A , M B i . For any given  X  and  X  , by setting k = min { max { k 1 , k 2 } , max {| elems ( M | elems ( M B ) |}} , where k 1 satisfies Eq. (5) and k Pr |  X  t r  X   X  | X   X  X   X  1  X   X  .
 Proof. We first define two propositions (a) and (b). element, a i as defined in Eq. (4), and k 1 and k 2 as defined in the Theorem.  X  Proposition (a): When k  X  k 1 , Pr [ X i &gt; 1]  X   X  2 .  X  P roposition (b): When k  X  k 2 , Pr |  X  t r  X   X  | X   X  X   X  I f both of them are proved, then when k  X  max { k 1 , k 2 we know that Pr |  X  t r  X   X  | X   X  X   X   X  based on the Union Bound.
 Proof of Proposition (a). Without loss of generality, we assume | elems ( M A ) | &gt; | elems ( M B ) | . Given  X  , let k solution to Eq. (5): where B ( k, | elems ( M A )  X  elems ( M B ) | X  k + 1) is the Beta function. It also holds: Besides, when k &gt; k 1 , Eq. (5) is equivalent to: Since we are doing uniform random sample in the space of elems ( M A )  X  elems ( M B ), where msk ( M A ) ( k ) order statistics therein.
 Thus from Eq. (6) and (7), we know when k &gt; k 1 , Pr [ X i &gt; 1]  X   X  2 .
 P roof of Proposition (b). Now that we can guarantee X i  X  [0 , 1] almost surely by proving Proposition (a), we can define X = P X i and apply the Chernoff bound to X . 1 A ccording to the Chernoff bound, we have
T hen from Union Bound, it guarantees that when k  X  max( k 1 , k 2 ), Pr |  X  t r  X   X  | X   X  X   X   X  .
In our improved methods, given a maximum gap N , let  X  =  X   X  Category I:  X  + 1 bottom-k sketches for shifts i  X  X  j X  | 0  X  j  X   X  }  X  Category II:  X   X  1 multiset bottom-k sketches with indices {  X , 2  X  } , {  X , 2  X , 3  X  } ,  X  X  X  , {  X , 2  X , . . . ,  X  2  X  Category III:  X   X  1 multiset bottom-k sketches with indices {  X ,  X   X  1 } , {  X ,  X   X  1 ,  X   X  2 } ,  X  X  X  , {  X ,  X   X  1 , . . . , 1 } .
Table 4(b) illustrates Category I sketches on the right-hand side, Category II sketches on the left-hand side, and Category III sketches on the bottom side, for the running example.

For any range [0 ,  X  ], it can always be decomposed to at most two sub-ranges. For example, Table 4(b) illustrates that [0 , 7] is decomposed into  X  [0 , 5]. This corresponds to S A  X   X  5 S B , and can be answered  X  [6 , 7]. This corresponds to S A  X  [6 , 7] S B , and can be answered by estimating the size of h S +9 A , U i  X  X  2 , 3 } Algorithm 2 : D ecomposeRange ( S A , S B ,  X  ) Input :  X  : query gap. N : maximum gap.

Output : An array of indices pairs.  X   X  X  X  i f  X  &lt;  X  or (  X  + 1) mod x = 0 then else Algorithm 3 : R angeQueryOnlineEstimation ( S A , S B ,  X  ) Input :  X  : query gap. N : maximum gap.

Output :  X  t r : an estimate for S A  X   X   X  S B . arr  X  DecomposeRange (  X  ) ;  X  t r  X  0; for each ( i A , i B )  X  arr do return  X  t r ;
We use Algorithm 3 to perform a range estimation with t he gap constraint  X  . In Line 1, it calls the DecomposeRange (  X  ) to decompose the range [0 ,  X  ] into one or two parts, utilizing the multiset bottom-k sketches. The returned results are one or two pairs of indices to these sketches. Lines 3 X 5 retrieve the corresponding sketches and perform the estimation based on Eq. (3) in Theorem 2.

The space complexity of the sketch for the range estima-tion is O ( is O ( k ). Thanks to Theorem 3, by setting the proper k , our estimation has at most  X  relative error with probability at least 1  X   X  .

Example 5 . We run Algorithm 3 for the same running example given before. Given  X  = 7 , we want to estimate | S
A  X   X  7 S B | . Line 1 decomposes [0 , 7] into two parts of For ( { 3 , 6 } , { 1 , 2 , 3 } ) , Line 4 retrieves msk ( S 2 , 0 . 48 : 2 } from Table 5. Then Line 5 calculates  X  t while there is no matching for this part. Finally, the algorithm returns  X  t r to be 10 . 42 . The actual | S A  X   X  7 S B | is 11 .
The proposed methods have many important applications, e.g. top-K related keywords mining, query optimization for search engine, and system troubleshooting in log analysis. In this section, we present the details of efficient mining top-K related keywords from a document collection. Let V be the vocabulary of the document collection. For ease of illustration, we concatenate all documents into one single document D with suitable padding of out-of-vocabulary keywords. For each keyword v  X  V , we create a set S v , which consists of all the positions in D where it occurs. Let query S Q be a set of positions. For any given keyword v , we can measure its correlation with the query by counting the number of occurrences of v in a  X  -vicinity of any position in S Q . The top-K related keywords problem is to find the K keywords in V that has the highest correlation.
Solving the problem exactly requires either intersecting all keywords in V or retrieving the  X  -vicinity centered at positions in S Q . Neither method scales well with large document collections.

To solve the problem approximately, we can apply range estimation to estimate the correlation, then return the K keywords with largest estimated size. Nevertheless, this method is still time consuming, as it is linear to vocabulary size |V| .

We observe that most of the keywords set do not have a significant gapped intersection size with the query, hence it is highly likely that their sketches share no common hash value with the sketch of the query. It is thus desirable to consider only those keywords that share at least one hash value in their appropriate multiset bottom-k sketches with the bottom-k sketch of the query.

Therefore, we propose to build an inverted index, which maps ( hashValue , index ) to a keyword v . Intuitively, by probing the inverted index with every hash value in S Q  X  X  sketch, we can obtain a list of candidate keywords. Due to the range decomposition, we also have the additional constraint that the indices of these shared hash values must agree with those calculated for the current  X  (i.e., returned by DecomposeRange ).
 Algorithm 4 : T op K RangeEstimation ( S Q ,  X  , K , I )
Input : S Q : sets of query positions;  X  : query gap; K :
Output : Top-K keywords based on their estimated
R  X  X  X  ; Cand  X  X  X  ; arr  X  DecomposeRange (  X  ) ; for each ( i A , i B )  X  arr do for each k eyword v  X  Cand do return t he K largest entries in R in terms of the estimated intersection size;
Algorithm 4 gives the pseudocode for the algorithm. Ini-t ially the candidate set Cand is empty (Line 1). In Line 2, we obtain one or two pairs of indices, indexing into S Q  X  X  and a potential candidate set X  X  multiset bottom-k sketches. We it-erate over all the pairs. For each pair of indices, we use i retrieve the sketch of S Q , and use Line 5 X 6 to retrieve all key-words such that their sketches with index value i B share the same hash value (i.e., e in the code). This step is aided by the precomputed inverted index as a simple index lookup. Fi-nally, we perform range estimate between S Q and the set of each candidate keywords and return the largest K keywords.
The algorithm issues at most 2 k  X  2 index lookups, and performs | Cand | number of range estimations, where | Cand | is the size of the candidate set. Finding the top-K entries from R and sorting them take O ( K log K ) time. Therefore, the total estimation time is O ( | Cand | X  k + K log K ).
In our implementation, we also perform the following optimizations. For every keyword returned from the index lookup (Line 6), we can accumulate its partial inner product with the query X  X  sketch (i.e., the numerator of Eq. (3)). It can be shown that the numerator X  X  value will be correctly calculated after the loop of Lines 3 X 6 ends. Therefore, the RangeQueryOnlineEstimation function only needs to do O (1) computation to get the range estimation for each candidate.
Example 6. Using the same example, we can build the inverted index as shown in Table 6.

Consider the top-1 related keyword query for A with  X  = 5 . DecomposeRange gives us one pair of indices ( { 3 , 6 } , { 1 , 2 , 3 } ) . This means we are concerned with the query X  X  sketch indexed by { 3 , 6 } and the candidate X  X  sketch indexed by { 1 , 2 , 3 } . We load the query sketch msk ( S Table 6: Inverted Index for top-K R elated Keyword Mining These lookups find matches S B , which is added to the candidate set. Finally we perform range estimation between the query and the candidates then return the top-1 keyword.
In this section, we present the results of a comprehensive performance study to evaluate the efficiency and effective-ness of the proposed techniques.
We use the following algorithms for point and range estimation.  X  GSISE-k is our proposed point (range) estimation method and k determines the size of a single bottom-k sketch.  X  PointSum-k is our basic range estimation methods by summing up multiple point estimation results.  X  Exact calculates the exact answer for point and range estimation, respectively.

We use the following algorithms for the top-K related keyword query.  X  TopK is the hash table based top-K range estimation method proposed in Section 5.  X  Exact topk is the exact algorithm for top-K range estima-tion. The algorithm is conducted by scanning the whole dataset, finding each occurrence of the query keyword, and bookkeeping the count of every other keyword that occurs within the  X  neighborhood. Finally, it returns the K keywords with highest number of occurrences.

The dataset we use is a subset of the ClueWeb con-taining 500 million English web pages from the ClueWeb09 collection. 3 We remove infrequent keywords and keep the 100k most frequent keywords. We build the positional inverted index for these keywords, and treat each inverted list as a set. We then build three sets of sketches on these sets, i.e., point sketch, range sketch, and top-K sketch for the respective estimation problems.

The complete original positional index requires more than 2 days to construct using Hadoop on a cluster of 20 PCs, and the final index is stored on the HDFS of the Hadoop cluster. Without compression, the overall index consumes around 1TB space, which is impossible to load into a single commodity PC X  X  memory. The overall size of the sketch is small enough to fit into our testing environment with 96GB RAM. Therefore, the experiments conducted on the sketches are memory-based, while exact algorithms that processes inverted lists or scanning documents have to use disk I/Os. Estimation Workload . We randomly select 100 pairs of keywords to perform point and range estimation with differ-ent parameter settings on their corresponding sets. We set maximum gap N = 100. k varies between 1,000 to 100,000 (default). The query gap  X  varies between 20 and 100.
We measure the running time and relative error for point and range estimation methods. We measure recall and extended recall for TopK methods. Recall is defined as A K / K , where A K is the number of exact top-K results returned by an algorithm that outputs K results. The number of exact top-K results returned by an algorithm that outputs L  X  K results, L is the extension rate. All measurements shown are averaged over 100 queries.
The experiment parameter settings of the evaluated algo-rithms are listed in Table 7, where the default parameters are highlighted in bold.

I n Figure 2(a), we show the point estimation time by varying query gaps. Compared with the exact algorithm, the sketch based method is more than 2 order of magnitudes faster. Query gaps do not affect the estimation time and exact time. As both exact and estimation methods rely on intersection algorithm of complexity O ( k ) to find common elements. GSISE-1k, GSISE-5k, GSISE-10k, GSISE-15k, and to perform one estimation. The trend is linear. Average length of inverted list size is around 2 . 5 million, which is 125 times of GSISE-20k X  X  sketch size. Meanwhile, Exact algorithm uses 892 ms to calculate exact answer, which is 892 / 6 . 92 = 128 times of GSISE-20k X  X  estimation time. When dataset size increases, exact results will need longer time, while the sketch estimation time is immune to the increasing dataset size.

In Figure 2(b) and figure 2(c), we show how the relative error decreases while the bottom-k sketch size is increasing. When gap is 80, the relative error drops from 1 to 0 . 4 with k changing from 1000 to 20 , 000. By further increasing k up to 100 , 000, the relative error reduces to less than 0 . 19. Based on the analysis in section 3.2, the relative error is inverse proportional to the square root of bottom-k size. Despite the fluctuation, relative error is not affected by the different query gaps, the fluctuation is caused by different intersec-tion sizes at different gaps. In our experiments, gap 40 has slightly more intersections than gap 100, which reflects that gap 40 has slightly less relative error than gap 100.
From Figure 2(d) to 2(f), we present range query estimation results.  X  Time. Figure 2(d) shows that our GSISE range estima-tion method has the best performance compared to other methods. For example, GSISE-20k is 128 times faster than
Exact and 108 times faster than PointSum-20k when gap is 100. Similar to point estimation, GSISE is stable with different gaps. According to Algorithm 2, any range query can be decomposed into at most two estimation queries, a nd the efficiency of estimation only relies on k . PointSum performs individual point estimations for each gap and uses the summation as the estimation result. Thus the processing time of PointSum is linear to the query gap. When gap is 20, 40, 60, 80 and 100, the processing time of
PointSum-20k is 109 . 0, 213 . 1, 302 . 7, 410 . 6, and 508 . 0 mil-liseconds, which is linearly increasing with respect to gap.  X  Relative Error. As shown in Figure 2(e), when query gap increases, the relative errors of all methods decrease.
This is because larger range gap tends to result in larger intersection size. According to Theorem 3, it is equivalent to using a larger k .
 error than range estimation given the same k setting. The reason is that PointSum utilizes all values in the point shifted sketch for estimating, which is equivalent to merg-ing without truncating at k -th hash value. As opposed to the truncated merge operation applied to GSISE r index,
PointSum will consume up to more than  X  times space.To be more specific, in Figure 2(e), when query gap is 100, the range sketch required for GSISE-20k is 2  X  20 k , while for PointSum , the cost is 20  X  20 k . However, the PointSum-20k only decrease the error by less than 0 . 05. Considering the tremendous performance gain in efficiency and storage, the tiny sacrifice in relative error can be ignored. k will lead to smaller relative error. The relative error decreases rapidly at the initial increasing of k , then flattens after k &gt; 10 , 000. PointSum has smaller relative error than GSISE methods, however, the relative errors are almost the same when k is large. Interestingly, the storage cost of PointSum-1k of gap 100(20  X  1 k = 20 k ) and of GSISE-10k of gap 100(2  X  10 k = 20 k ) are the same, so are the relative error of PointSum-1k of gap 100 and GSISE-10k, which are 0 . 267 and 0 . 266, respectively.
The experiment results of top-K problem are presented in Figures 2(g) to 2(o).  X  Time . In Figures 2(g), 2(j) and 2(m), we investigate the response time by varying K of top-K from 1 to 100. In general, we can see that the average query processing time is under 25 milliseconds, which is quite small compared to Exact topk . In fact, as we use large web page corpus, the Exact topk algorithm must run on the cluster in a batch mode for the given queries, which takes 6 hours to scan through the original documents in order to output top-K results. In each figure, by increasing the query gaps from 20 to 100, we observe that the query processing time increases slightly. This is due to the processing of top-K range estimation needs to count the number of common sketch values in the hash table.
Larger query gap will result in larger intersection size, which means more common sketch values when looking up the hash table. Same reason goes for the increasing query processing time when k increases.  X  Recall . We show the recall of our algorithms in different top-K settings in Figures 2(h), 2(k) and 2(n). We can ob-serve that the recall grows with the increase of k . Larger k incurs smaller relative error, consequently improves the recall of the top-K algorithms. Furthermore, it is observed that query gap has no influence on the recall, which shows great stability over different query gap settings.  X  Extended Recall . As shown in Figure 2(g) and Fig-ure 2(m), the processing time of returning top 1 result and top 100 results are similar. This gives us the motivation of measuring extended recall. Figures 2(i), 2(l) and 2(o), present the extended recall. The extension rate is up to 4.
In Figure 2(i), when extension rate is larger than 3, the recall of GSISE-15k and GSISE-20k both reach 90%. In other figures, all GSISE-20k experiments can reach more than 80% of recall when extension rate is 4. GSISE-1k performs inadequate even when extension rate reaches 4. substantial performance advantage over exact methods in efficiency. Meanwhile, the recall of our algorithms can reach around 90% with slight extension of returned top-K results.
In this paper, we formally define the GSISE problem, for both point and range gap constraints. We propose space and time efficient estimation methods, based on bottom-k sketches and its extension to multisets. In addition, our estimation methods provide the probabilistic quality guarantees. We also apply our technique to the problem of finding top-K related keyword, by combining our estimation technique with the use of an inverted index. Our experi-ments using half a billion documents empirically verify the effectiveness and efficiency of the proposed methods. Acknowledgements. We would like to thank Stefan B  X  ottcher
