 Department of Computer Science and Technology, Xi X  X n Jiaotong University, Xi X  X n, Shaanxi, China 1. Introduction k -nearest neighbor ( k -NN) is an instance-based classification algorithm that has shown to be very effective for a variety of problem domains such as text classification [1 X 3], marketing [4,5], biology [6] and pattern recognition [7,8] with higher performance.

However, the performance of the k -NN classification algorithm greatly depends on the value of k .Ifit is too small, the k -NN classifier may be susceptible to overfitting because of noise in the training data; may include data points located far away from its neighborhood [9]. Therefore, the determination of k is an important issue. Unfortunately, there have been few works that try to optimize the value of k .
The existing methods can be divided into the four different types. In the most straightforward method, the closest existing instance is used to assign the class for the new sample [10] (e.g., WEKA X  X  default set-ting is k = 1). This method suffers from noise, and cannot reflect the diversity of different data sets. The most widely used method is cross-validation that sets k to be a fixed value [6,11 X 16], which can obtain different k values for different data sets but consumes much time. The different k values can be ob-tained according to the number of instances in training set [17] or the distribution of class [1]. Although Okamoto and Satoh [17] observed that the optimum k value increases gradually as the number of train-ing instances increases, they did not provide a uniform relationship model. However, Wettschereck [11] via evolutionary algorithms and especially genetic algorithm [18 X 20], which is much time consuming as well. The aforementioned methods have not taken the effect of the data set characteristics on the value of k into consideration.

On the other hand, Quinlan [21] pointed out  X  X here are certain classification tasks that lend them-selves to methods of one or the other type X . This reveals that there is an intrinsic relationship between data set characteristics and the classification algorithm, and choosing a proper classification algorithm based on data characteristics may help a lot in practice. Therefore, many research works have been done, including [11,22 X 27]. These works firstly use some statistical and information theoretical mea-sures to characterize data sets, and then try to capture the relationships between the measured data set characteristics and the classification algorithm performance by decision tree, instance based rule induc-tion methods or regression models. Finally, these relationships are used to make recommendations as to which classification algorithm could be used for a given data set.

Inspired by the above mentioned studies on classification algorithm recommendation, we believe that there is some relationship between data set characteristics and the optimal k value of the k -NN classifier, and this relationship can be used to estimate the value of k for a new data set. Based on this assumption, in this article, we intend to explore how to construct this relationship and further how to use the built relationship to predict an optimal or near-optimal k value for a given new data set. This idea takes account of data set characteristics, and it is expected to give the most reliable estimate with the smallest computational effort. Thus, it is quite different from the traditional methods.

The rest of this article is organized as follows. Section 2 briefly reviews the related work. Section 3 presents our proposed k value prediction method. Section 4 describes experimental procedure and ana-lyzes the experimental results. Section 5 concludes our work. 2. Related work
Existing related methods for determining the value of k in the available literatures can be classified into four categories: the constant value method, the cross-validation method, the heuristic method, and the evolutionary parameter optimization algorithm.

The constant value method sets k to be some constant value in advance, and one choice of k in the literatures is k = 1 [10,11]. In this case, the classification performance is prone to be effected by noise. Wettschereck [11] suggested that k should be set to 1 in the following cases: (i) For very small training sets (e.g., &lt; 200 examples), (ii) If the task is known to be noise free and decision boundaries do not overlap, and (iii) Data that are distributed in a highly non-Gaussian manner. However, no single value of k can give the best performance in all possible tasks, setting k to some fixed value without cross-validation would lead to good results only if some prior knowledge as to what the value of k should be is known [11].

The cross-validation method assigns k a fixed value via cross-validation over all possible values of k [6,11 X 16]. Leave-one-out cross-validation on all possible values of k generally leads to the best per-formance across all domains that are not entirely noise-free. The n -fold cross-validation method firstly presets a upper bound ub of k , and then for each k  X  [1 ,ub ] , the cross-validation strategy is used to select the optimal k in terms of classification accuracy. These methods suffer from how to define the set of potential candidates for k , inefficiency and sometimes impractical since it consumes much time and needs huge computation.

The heuristic method determines different values of k for a new data set according to the number of instances in training set, class distribution or similarity measure [1,28,29]. Okamoto and Yugami [28] presented that optimal k increases gradually as the number of training instances increases. Li et al. [1] proposed to determine different numbers of nearest neighbors for different classes rather than a fixed number across all class. However, there are two restrictions: (i) it is only promising when the parameter k each class s till need to be determined thr ough trial and error. Lee and Pa rk [29] proposed a mathematical programming (MP) model based on similarity distribution. The MP model is worthwhile for enhancing the model X  X  classification performance because it can generate a potentially different optimal set of k neighbors every time a new case is input. However, it wastes too much computation time and no mechanism to identify an appropriate value of parameter p occurring in the model.

The evolutionary parameter optimization algorithm and especially the genetic algorithm, which is a search heuristic that mimics the process of natural evolution and is widely employed for parameter selection, was used as a tool to optimize the number of neighbors in k -NN by Jarmulak et al. [18], Ahn et al. [19], and Ahn and Kim [20]. This evolutionary process has been implemented in the toolbox RapidMiner used for a parameter optimization. Although its prediction accuracy is desired, this method is quite inefficient as it searches randomly and is easy to trap in local optimum.

Although the methods mentioned above can be employed to determine an optimal or near-optimal k , they lack either availability or generality so that cannot be widely used in practice. The constant value method attempts to use one single value of k for tackling all tasks, ignoring the diversity of different training data sets. The cross-validation method resorts to trial and error to select an optimal or near-optimal value of k , occupying huge memory, consuming much time and disregarding the nature of data set itself as well. The evolutionary parameter optimization algorithm won X  X  stop executing the fitness time-consuming and the result is random. The above three methods have one problem in common, that is none of them take into account the effect of data set characteristics on the value of k comprehensively. Even though the heuristic method analyzed the relation between some feature of the data set and the value of k , it is not comprehensive enough. 3. The number of nearest neighbors prediction method 3.1. Framework of the prediction method
We believe that there exists some intrinsic relationship between data set characteristics and the suitable number of nearest neighbors. Therefore, the k value prediction method is straightforward: after building the relationship model between the characteristics of historical data sets and the corresponding most suitable k values, the model is used to predict the k value for a new data set. That is, the method consists of the two components: the model construction and the k value prediction , Fig. 1 shows the details. 1. Model construction 2. k value prediction 3.2. Data set characteristics
In machine learning, one of the most challenging problems is to characterize a data set uniquely that makes one learning algorithm more appropriate than another.

In order to address this problem, many measures of data set characteristics have been proposed by researchers. These measures can divided into four categories, they are simple measures [22,23,26,27], statistical measures [22,23,26,27], geometrical measures [24,26,30] and information theoretical mea-sures [22,23,27].

The simple, statistical and information theoretical measures are most commonly used for determining the competence of classifiers, while the geometrical measures are typically used to characterize the complexity of one data set.

Although so many data set measures are proposed and some of them have been analyzed to be helpful for determining the k value in previous researches, such as the number of training instances [28], class distribution [1], we do not know which ones on earth are really related to the determination of the k value in k -NN. Therefore, various measures are collected and feature selection should be employed on them in order to choose the most useful ones for modeling k value prediction model. 3.2.1. Simple measures
The simple measures describe the summarized properties of a data set. Table 1 shows the most com-monly used simple measures, Brazdil et al. [22,23] and Ali and Smith [27] provided the detailed defini-tions and corresponding formulas. 3.2.2. Statistical measures
The descriptive statistic is used to describe the distribution of data, digital features and correlation between random variables.

The descriptive statistic can be divided into three parts, central tendency analysis, dispersion analysis and correlation analysis. The mostly used statistical measures defined in [22,23,26,27] are presented in Table 2. 3.2.3. Geometrical measures
The geometrical measures are typically used to characterize the complexity of a data set, focusing on the geometrical complexity of the class boundary and topological constraints.

Ho and Basu [24] pointed that geometrical measures count most in classification compared with other three kinds of measures. Mansilla and Ho [30] studied the domain of dominant competence of six pop-ular classifiers in a space of data complexity measurements.

Table 3 lists the mostly used geometrical measures. Detailed descriptions and formulas can be found in [24]. 3.2.4. Information theoretical measures
The information theoretical measures are used to describe the quality of the relationships in the data set. In information theory, entropy is a key measure used for quantifying the uncertainty of a random variable.

The mostly used information theoretical measures are shown in Table 4, please refer to [27] for the corresponding explanations. 3.3. Identification of the optimal k value
When determining the optimal k value for k -NN, Wettschereck [11], G X ra et al. [13] and Manocha et al. [31] firstly predefined an interval that ranges from 1 to the number of training instances ( numTrain ), andthena Leave -One -Out cross-validation strategy was employed to choose the one with the highest classification accuracy as the desired k .The Leave -One -Out cross-validation has been proved to be almost unbiased, but it is too time consuming to be used in practice especially for large data sets.
In this article, we restrict the searching for the optimal k value to the interval of [1 , numTrain ] ,and the m  X  n cross-validation strategy instead of the Leave -One -Out cross-validation is used to identify the optimal k value. This is intended to reduce the computation time and make sure the classification as accurate as possible.

For a given data set, it is very likely that the highest accuracy can be obtained by classification with several different k values. However, only one value can be used for modeling the relationship between it and the data set characteristics. In this case, the smallest one is selected as the optimal k value, and the remainders are viewed as the applicable ones that are one part of the applicable k value set. Another part consists of those k values whose corresponding classification accuracies have no significant differences with the highest accuracy.

Brazdil et al. [22] and Gama and Brazdil [23] presented an applicable classification algorithm selection method. In their method, all algorithms whose error rates fall within a given margin are considered applicable, while the others are labeled as inapplicable.

We borrow this idea to determine the applicable k value set for the k -NN classification algorithm. All k values whose classification accuracies fall in the interval [ Acc  X  w  X  AM, Acc ] are considered to be no significant difference with the best accuracy and can be applied to a given data set. Where AM denotes the accuracy margin and can be obtained via AM = Acc  X  (1  X  Acc ) /N T , Acc represents the highest classification accuracy, and NT represents the size of the data set. The value of w determines the size of the interval. Clearly, the larger the value of w is, the higher the confidence that the best algorithm will have in the interval [22]. Moreover, what we most concern is to exclude those accuracies with significant difference from the confidence interval as many as possible, so the parameter w should be set as small as possible under the condition of losing less confidence.

The detail process for determining all applicable k values is shown in Algorithm 1. Suppose k max is the the number of instances in training set, to determine the optimal k for each preprocessed data set, DATA is split into FOLDS bins, one for testing and the rest for training. Repeat this process for TIMES . Algorithm 1 ApplicablekDetermination
The optimal and minimal k can be picked out from appkSet as the target concept for modeling, others will be stored for estimating the k value predicted by our prediction method. If the predicted k equals to anyone member of appkSet , it will be viewed as a correct prediction. 3.4. Construction of the optimal k value  X  data set characteristics relationship
Neural networks, with their remarkable ability to derive meaning from complicated or imprecise data, can be used to extract patterns and detect trends that are too complex to be identified by either humans or other computational techniques. Smith et al. [32] has used neural networks to construct the relationship between problem characteristics and data mining algorithm performance.

The attraction of neural networks is that they are best suited to the situations where the input and output data are available, but we are not sure how to relate the input to the output. A trained neural network can be thought of as an expert in the category of information, it has been given to analyze. This expert can then be used to provide projections given new situations of interest and answer  X  X hat if X  questions. On the other hand, although we believe that there is some relationship between data set characteristics and the optimal k values, we do not know what the relationship is and how to represent it. Thus, we use back-propagation neural networks (BP) to model this relationship, which has been implemented in WEKA named as MultilayerPerceptron (MLP).

BP is a feed-forward artificial neural network model which learns the complex relationships between inputs and outputs via adjusting connection weights after each piece of data is processed, based on amount of error in the output compared to the expected result. After that, the weight of each input unit will be listed when the squared error reaches the lowest. Although it is time consuming, its following advantages convince us to choose it instead of other prediction methods for constructing the prediction model :
Although neural networks have the ability of identifying useful features and have been used to choose feature subset for other learning algorithms [33], many researchers found that feature selection algo-rithms can improve the performance of neural networks [34 X 37]. On the other hand, as many as 39 features (see Section 3.2) are identified to describe a data set, but we still do not know which features are salient. Therefore, when building relationship model with the BP neural networks, wrapper fea-ture selection method is employed in advance. Figure 2 shows the details of this approach, where the BP algorithm is used for evaluating the subset, the best accuracy is the stopping criterion. The loop  X  X earching-evaluating X  won X  X  stop until the subset with the best accuracy is obtained.

With the features selected as the inputs and the optimal k value as the output, the k value prediction method is constructed with BP algorithm. To increase the generalization of the model, the Delete-One observation jackknife [38], which is a technique for reducing the bias of a serial correlation estimator based on splitting the sample into two half-samples, is employed to evaluate the performance of our proposed prediction method. That is, the modeling process is repeated as many times as the number of instances in a data set. For each time, instances are split into two parts, one part contains only one instance for testing, while others are used for constructing regression model. The parameter k for the test data will be predicted with the BP regression model built on the training set. 4. Experimental results and analysis 4.1. Experiment setup
Benchmark data sets . For the purpose of comparing our proposed method (PKM) with other existing ones in a fair way and allowing other researchers can repeat our experiment, the 49 benchmark data sets, which are available from UC Irvine Machine Learning Repository [39], were employed.

The statistical information of these 49 data sets is summarized in Table 5. From Table 5, we observe that these data sets come from many different fields, and their sizes vary from 15 to 1,728.
For those data sets containing continuous numeric features, as some data set measures are calculated on the basis of probability, the MDL discretization method [40] was applied in advance.

Benchmark methods . Four existing representative methods of determining the k value for the k -NN algorithm were employed as the benchmark methods used to compare with our proposed PKM method. They are the cross-validation method (CV) [6,11 X 16], the improved k -NN method (IMP k NN) [1], the genetic algorithm (GA) method [18 X 20] and the most commonly used constant value method with k = 1 (1NN) [10,11].

Feature selection and modeling method . Wrapper is used to select the feature subset with the Best first as the search strategy and the MLP as the evaluation method. With the default parameter setting, MLP regression method in function part of WEKA was used for constructing the k value prediction model.
Evaluation methods . When identifying the optimal k , 5  X  10 cross-validation was used to estimate the performance of the k -NN classification algorithm with the incremental k value from 1 to the number of training instances. While evaluating the performance of the prediction model constructed with MLP regression method, the Delete-One observation jackknife was employed.

Parameter setting . The setting of significant level  X  plays an important role for determining the set the possibility containing the values which are significantly different from the optimal will increase. Ensuring less loss of confidence, we set  X  = 0.1 corresponding to the confidence bound w = 1.2816. Procedure Model Construction&amp;Evaluation&amp;Prediction 4.2. Experimental process
The whole experimental process consists of two parts: (i) feature selection, and (ii) model construction with MLP regression method, evaluation and prediction.

When choosing those relative measures used to characterize data sets, two steps were followed: (i) extracting all measures summarized in Section 3.2, and determining the optimal k value and the appli-cable k value set of for each data set via Algorithm 1; (ii) selecting features from the extracted data set characteristics using wrappers with the BP networks as evaluation method and the Sequential Backward selection (SBS) as the search strategy, which starts with the full set of attributes and searches backward sequentially.
 Based on the selected features and the optimal k value, the prediction model was constructed with MLP regression method. Procedure Model Construction&amp;Evaluation&amp;Prediction provides the details. 4.3. Results and analysis
In this subsection, we first present the selected data set characteristics that used to construct the pre-diction model. Then we provide the comparison results of our proposed k value prediction method with other existing methods in terms of (i) the predicted k value, (ii) the classification accuracy of the k -NN with the k value determined by each method, and (iii) the runtime for determining the k value, respec-tively.

The selected data set characteristics . Through wrapper feature selection carried on the whole set of data set characteristics, four measures for characterizing the data set in Table 6 are considered as the factors which effect the determination for the value of k , in which number of features F is one simple measure, noise-signal ratio NSR, entropy of classes H(C) and mean entropy of variables to information theoretical measures. F denotes the dimensionality of the data set. A large NSR implies that much irrelevant information (noise) is contained in a data set. H(C) measures the randomness in the class assignment. entropy H(C) or variables, respectively.

Computing the entropy of classes, variables or the mutual entropy of both, we can efficiently obtain the data characteristics H(C) , is m , the number of classes is c and the average number of the values in all variables is q , according to the computation formula of entropy, we have to get statistical probabilities of classes and all variables of classes H(C) , the mean entropy of m variables variables Since NSR is calculated based on the we conclude that the total of time complexity for computing the selected data characteristics is T = O ( n )+ O ( m  X  q  X  c ) , which is acceptable in practice.

The proposed k value prediction model . Based on the new data set consisted of the selected feature subset and optimal k value of each data set listed in Table 5, the k value prediction model (PKM) was constructed and illustrated in Fig. 3, employing the MLP regression method with the default parameter setting.

From the Fig. 3, we can observe that the proposed PKM is constructed by three parts. The left is the input layer consisted of F , H(X) , H(C) and NSR . The middle contains two hidden layers Unit 1 and Unit 2 . used in the hidden layers and the linear function is used in the output layer. Finally, the weight of each two nodes is identified and labeled on the link between them, taking the weight between the input F and The predicted k values . Table 7 presents the applicable k values and the predicted k values of the four methods. From it we observe that the number of hits 1 is 40, 49, 28 and 35 for the methods PKM, CV, IMP k NN, and GA, respectively. Our proposed PKM method ranks 2 while CV obtains the first position. The reason why PKM is defeated by CV is that the applicable k value set is determined by the CV method itself, so it should perform best. Moreover, the hit rate of PKM outperforms IMP k NN and GA by 42.86% and 14.29%, respectively.

Classification accuracy comparison . For each of the 49 data sets, we obtained the classification accu-racy of k -NN with the k value determined by each of the four methods. The results are shown in Table 8. From it we observe that the classification accuracy of k -NN with our predicted k value has a decrease of 1.61% on average compared with the CV method. On the other hand, our proposed PKM method out-performs the other three methods IMPkNN, GA and 1NN, the classification accuracy has been improved by 3.11%, 0.57% and 0.89% on average, respectively.

We also employed Wilcoxon signed-rank test to further test whether the classification accuracy dif-ferences between PKM and the other methods except CV are significant. The alternative hypotheses are that the classification accuracy of PKM is significantly higher than those of the other three methods at the significance level  X  =0 . 05 .The p values are 0.005, 0.048 and 0, respectively. Obviously, they are all less than 0.05. This means the null hypotheses are rejected and the alternative hypotheses are accepted. This further reveals that PKM is significantly better than the other three methods in terms of classification accuracy.

Runtime comparison . Table 9 records the runtime of each method used for determining k value. From the average runtime we observe that our proposed PKM method ranks 1, its runtime is only 0.003% of CV, 12.70% of IMP k NN, and 0.04% of GA, respectively. This means our proposed PKM method is much better than others in terms of runtime.

Similarly, we also conducted a Wilcoxon signed-rank test to further explore whether there exists sig-nificant differences between the runtime of PKM and those of the other methods. The alternative hy-potheses are that the runtime of PKM is significantly less than those of others except 1NN at significance level  X  = 0.05. The p values are all 0, which is less than 0.05. This means all the null hypotheses are strongly rejected and the alternative hypotheses are accepted. This confirms the conclusion: our proposed PKM method is much better than others in terms of runtime.

Although our proposed PKM loses to CV method in terms of classification accuracy, it wins CV by a large margin in runtime. To summarize, our proposed PKM method is better than other methods and can be used to predict the number of nearest neighbors for k -NN for a given data set, considering the trade off between the classification accuracy and the runtime. 5. Conclusions
In this article, we have proposed a novel method to predict the number of nearest neighbors for the k -NN classification algorithm in the perspective of analyzing the relationship between the data set char-acteristics and the optimal k value. We have also extensively tested our proposed k value prediction method PKM on the 49 UCI benchmark data sets. The results show that our PKM method is able to greatly save computation time, and further can be used to predict the number of nearest neighbors for the k -NN classification algorithm for a given new data set.

We have also compared our method with four existing methods: cross-validation used for selecting the optimal k value, an improved k -NN algorithm with determining the top n neighbors for each category, the genetic algorithm which searching the locally optimal value of k with some randomness, and the most commonly used 1NN. The experimental results show that our proposed prediction method outperforms other methods on the 49 data sets in terms of hit rate and classification accuracy except for CV. Even though CV can obtain the highest classification accuracy, it costs too much time to be widely used in practice, especially for large data sets. Therefore, our proposed k value prediction method is a better choice for identifying k value for the k -NN classification algorithm.
 Acknowledgements
The authors would like to thank the editor and the referees for their helpful comments. This work is supported by the National Natural Science Foundation of China under grant 61070006.
 References
