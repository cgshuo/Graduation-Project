 Location-based services have beco me more and more prevalent and have attracted significant attentions from both industry and academic community. Apple has an application to locate frequently used software; Yelp finds nearby restaurants of interest; and Faceboo k and FourSquare offers its members the capability to find his or her nearby (local) friends or points of interest.
One obvious way [1] to combine spatial distance and textual similarity is to use a spatial index to a spatial partition of the large dataset, which is most relevant to the spatial location of the query issuer, and for the given partition a string index is used to filter out those irrelevant objects by keywords matching and then rank the results using a hybrid ranking function that can combine spatial distance and textual similarity [2 X 4]. Spatio-textual data ordinarily are high-dimensional. For example, a typical microblog with location has 2 coordinates and some keywords, say 100, then the whole microblog, simultaneously considering location and text, contains 2  X  100=200 features(dimensions). Due to the curse of dimensionality, many traditional methods are not efficient. It X  X  known that locality sensitive hashing(LSH) is a good method for similarity queries on high-dimensional data. However, none of previous work, to the best of our knowledge, has explored the feasibility of utilizing LSH for processing spatio-textual similarity queries. We argue that LSH is an attractive alternative method for processing spatio-textual similarity queries: First, LSH-based methods have no hierarchical structure, thus are easy to be maintained and scaled. Second, LSH can be directly used to hash spatially and textually similar objects to the same buckets, which can be obtained with less I/O cost.

In this paper, we design hybrid-LSH to process spatio-textual similarity queries, and the method treats spatial information and textual content of an object as a whole, rather than builds indices separately and combines two sets of query results when there is a query. The first challenge is how to design the hybrid-LSH such that hash buckets are conducted by considering spatial and textual similarity simultaneously. For each object, one hash value that reflects both spatial information and textual content considered as a whole, should be generated. The second challenge is how to make the hybrid LSH adaptive to spatio-textual similarity queries wit h different similarity ranges efficiently, because for LSH based methods their sensitive radii are fixed and it X  X  difficult to answer queries with varying ranges.

To address these challenges, we propose a hybrid-LSH structure which considers both spatial and textual similarity, so that it is with high probability that spatially and textually similar objects are stored in the same bucket and can be found with one disk I/O. Then we present adaptive algorithms for queries with varying ranges. In addition, the hybrid-LSH X  X  effectiveness and algorithms X  accuracy are guaranteed by theoretica l analysis. To summarize, we make the following contributions.  X  By simultaneously considering spatial and textual similarity, we propose a  X  To process query with varying ranges on the hybrid-LSH, we provide  X  We conduct extensive experiments on real and synthetic datasets in a Reference Model. Both the object model and the query model are defined with spatial location information and textual content consisting of keyword tokens. We assume that the spatial information and the textual content of objects are independent.

Formally, let P denote the universe of discourse, namely the set of spatial objects. Each object p  X  P is defined as a two-element tuple ( loc,tok ), where p.loc is the spatial location information of object p and p.tok is a set of tokens which represent the textual description of p . In order to compute spatio-textual similarity between two objects, say p 1 and p 2 , we define a spatio-textual distance metric that combines spatial and textual similary through a weight parameter  X  , as shown in Eqn. 1.
 We use the normalized Euc lidean distance of objects p 1 ,p 2  X  P , denoted as dist( p 1 .loc, p 2 .loc ), to compute the spatial distance DistS, as shown in Eqn.2. dmax and dmin in Eqn.2 denote the maximum and minimum distance for pairs of objects in P . We use Jaccard distance [5] to measure the distance of textual similarity as shown in Eqn.3. Note that our hybrid LSH method is generic and independent of the specific distance functions used and thus can incorporate other spatial distance function and textual similarity distance function. For simplicity, B( q,D ) denotes object set { o  X  P | DistS ( o.loc,q.loc )  X  D } , similarly, B( q,R )= { o  X  P | DistT ( o.tok, q.tok )  X  R } ,andB( q,D,R )= { o  X  P | DistS( o, q )  X  D and DistT ( o, q )  X  R } .

Given that spatial location based similarity is defined based on Euclidean distance and textual similarity is defined based on Jaccard distance, [6] and [7] describe the construction of an LSH family for Euclidean distance and the construction of an LSH family for J accard distance respectively.

Because the traditional ( R, c )-NN problem [6, 8] just adapts to objects with single data type. we extend the ( R, c )-NN problem to ( D,R,c )-NN for spatio-textual objects, which return an object o  X  B( q,cD,cR ) if there exists an object o  X   X  B( q,D,R ).
 Related Work. There are many studies on spatia l textual similarity query processing [2,3,9]. A good survey of tec hniques can be found in [10]. Generally they can be classified into two categories: tree-like style and grid style. Specifically for tree-like style, [2] proposes a new hybrid index structure Inverted File Quad-tree (IQ-tree) to manage a stream of Boolean range continuous(BRC) queries on a stream of incoming. [11] proposes a new indexing framework for processing the location-aware text retrieval query. [3] proposes a hybrid indexing structures called Intersect ion-Union-R tree (IUR-tree) and an efficient approach that take into account the fusion of location proximity and document similarity. For grid style, this category of indices combines a grid index with a text index (e.g., the inverted file). For example, [4] proposes a spatio-textual similarity search method (SEAL), which is a filter-and-verification framework.
 In this section, we introduce the construction of hybrid-LSH. Concretely, each object o  X  P consists of spatial information s and textual content t . Assume that the following three parameters are provided: the spatial range d ,the textual similarity range r , and the approximation factor c&gt; 1. The hybrid LSH construction algorithm works as follows: For s we can find ( d, cd, sp 1 ,sp 2 )-sensitive LSH family, denoted by sH, for Euclidean distance (recall Section 2), while for t we can obtain ( r, cr, tp 1 ,tp 2 )-sensitive LSH family, denoted by tH, for Jaccard distance (recall Section 2). We combine the two hash families. In particular, let k 1 and k 2 denote the number of hash functions generated in sH and tH respectively. We define an LSH function family G= g: S  X  U ( k 1 + k 2 ) with k where th i  X  tH and sh i  X  sH. Let L be an integer, we choose L functions g 1 ,  X  X  X  ,g L from G independently and uniformly at random. During preprocessing, we store an indicator of object o in the bucket g i ( o )for i =1,  X  X  X  ,L . We define the spatial
Intuitively, hybrid-LSH is composed by k 1 hash values from ( d, cd, sp 1 ,sp 2 )-sensitive LSH and k 2 hash values from ( r, cr, tp 1 ,tp 2 )-sensitive LSH. Thus, { sp 2 ,tp 2 } )-sensitive is simplified as ( d, r, c )-sensitive hybrid-LSH when no con-fusion occurs.

Base on hybrid-LSH, in order to process a ( D,R,c )-NN query with query g ( q ), then search corresponding buckets of the hash values and randomly check C  X  L objects in the buckets where C is a constant number. Let o we return YES and o i , otherwise we return NO. Because there are probably lots of objects in all the buckets, it saves lots of computation to only check constant number of objects.

To ensure the correctness of the algorithm, the parameters k 1 ,k 2 and L are chosen so as to ensure the following properties hold with constant probability: P 1 If there exists object o such that DistS( o, q ) &lt;D and DistT ( o, q ) &lt;R , P 2 The total number of collisions of q with the number of objects, which do not
P 1 ensures objects who satisfy the query at least collide once for the L hash values. P 2 ensures if there is object who satisfies the query algorithm can find the object after checking 3 L objects.
 Theorem 1. setting k 1 =log sp 2 (1  X  1  X  1 n ) , k 2 =log tp 2 (1  X  1  X  1 n ) and hold with constant probability.
 Proof. Let P 1 hold with probability p 1 and P 2 hold with p 2 . Without loss of 1  X  1 n ). Use P(A) to denote the probability of event A. P(g( o )=g( q )&amp; o  X  ( P  X  B( q,cD )  X  B( q,cR )) (denoted as Pa ) is not larger than P (g objects allocated for g i which don X  X  satisfy the query condition is less than 1.5. The expected number of the objects for all g i doesn X  X  exceed 1.5 L , According to the Markov inequality, the probability that this number exceed 3 L is less than 1 2 .soP 2 follows. The probability of g( o  X  )=g(q) is sp 1 k 1  X  tp 1 k 2 =(1  X  the probability that all g i ( o  X  ) =g i ( q )islessthan 1 e .sotheP 1 holds with the probability 1-1 e &gt; 1 2 . This section focuses on describing how to split a ( D,R,c )-NN query into multiple subqueries with smaller query ranges su ch that each subquery can be processed directly using our hybrid LSH index. Recall Section 3, we show the structure of ( d, r, c )-sensitive hybrid-LSH. For ( D,R,c )-NN queries where D  X  d and R  X  r , we need to decompose each ( D,R,c )-NN query into multiple subqueries with spatial range d and textual range r . 4.1 Adaptive ( D,R,c )-NN Query Processing Let d&lt;D and r&lt;R , and we build a hybrid-LSH with sufficiently small d and r so that ranges from query are bigger than them. The intent of the adaptive ( D,R,c )-NN query method is to transform an or iginal query into several queries with small query range which can be processed by the constructed hybrid-LSH. Then we give a formal definition of the transform as follows.
 Definition 1. ( LSH query transform ) LSH query transform is based on a single query set S which contains several queries based on ( r 1 ,r 2 ,p 1 ,p 2 ) -sensitive LSH, where r 1 &lt;R , r 2 &lt;cR ,and S satisfies the following two properties, then S is a ( r 1 ,r 2 ,p 1 ,p 2 ) -sensitive LSH query transform of q .
 P 1 the area or content which is covered by R in q is contained by the area or P 2 the area or content which is covered by r 2 in S is contained by the area or Then we show the effect of LSH query transform in Lemma 1, compared with the original query.
 Lemma 1. If there is an answer for a ( R, c ) -NN query, then a ( r 1 ,r 2 ,p 1 ,p 2 ) -sensitive LSH query transform of the ( R, c ) -NN query can return a c -approximate answer with constant probability.
 Proof. Set QT be a LSH query transformation of a ( R, c )-NN query q ,where QT = { qt i | 0 &lt;i&lt; | QT |} . If there is an object o  X   X  B( q,R ), according to P1 in definition 1, then o  X  locate in the query range of at least one query in QT , say qt i . In addition, the objects which are outside of B( q,cR ), denoted as O ,are outside of B( qt i ,r ). According to property 2 of LSH ( R, c )-NN query in the [8], the number of collisions of st i and O is less than C  X  L , So after checking C  X  L objects st i can return a c -approximate answer with constant probability. Then Lemma 1 follows.

According to Theorem 1 we can use a LSH query transform to processing queries with varying ranges. However it is nontrivial to construct LSH query transform for spatial information or textual content. Now we present the LSH query transform methods for spatial information and textual content respectively.

For spatial information, it is similar with a disk covering problem to find a LSH query transform. To the best of our knowledge, optimal solutions of disk covering problems are only available for limited situations. We try to give a general algorithm and show it is a 3-approximate optimal method. Given a ( d, cd, p 1 ,p 2 )-sensitive LSH and a ( D,c )-NN query with centre coordinate p = ( p x ,p y ), where d&lt;D , we use several squares with sides B( p, D ), as shown in figure 2. The number of squares is 2 D 2 d 2 . Then the ( D,c )-NN queries from central points of the s quares is a LSH query transformation, denoted as ST = { st i } . Note that because d&lt;D , ST is easy to satisfy the condition that the coverage of all queries in ST with radii cd is contained by the circle with radius cD of query q . According to the area formula, the low bound of optimal method is D 2 d 2 . So it is easy to get an corollary in the following. Corollary 1. There is a constant c which makes ST a LSH query transforma-tion of query q , and the LSH query transformation is a 3-approximate optimal method.

For textual content, given a ( r, cr, p 1 ,p 2 )-sensitive min-hash and a textual ( R, c )-NN query q ,where R&gt;r and there are TL tokens in q , in order to find similar token sets by ( r, cr, p 1 ,p 2 )-sensitive LSH, we should consider two kinds of objects: objects in which the number of tokens are smaller than q and objects in which the number of tokens are bigger than q . For smaller objects, we should get rid of some tokens in q to match them. For an integer m specified later, we generate a query set which consists of all possible combinations of ( TL  X  m ) tokens from tokens of q , which is denoted as DS . And for bigger objects, we should add some wildcard tokens in q to mach them. For an integer w specified later, we add w wildcard tokens to q .When q is hashed to a hash value, a wildcard token is hashed to all possible hash values. In this way we get another query set AS . Then by combining DS and AS we get a query set TT .

Let IN and UN be the size of intersection and union of two token sets, respectively. When parameters m and w satisfy the formulae 4, 5 and 6, it ensures that all similar objects of q are covered by the similar objects of query set TT , corresponding to P1 in definition 1. And when parameters m and w satisfy the formula 7, 8 and 9, it ensures that all c approximate similar objects of query set TT are covered by c approximate similar objects of q , corresponding to P2 in definition 1. By selecting the smallest m and w which satisfy the formula, corollary 2 follows.
 number of tokens in the query q ,queryset TT is a LSH query transformation of query q .
 Proof. Due to the limited space, the proof is omitted.

Based on LSH query transform, the adaptive ( D,R,c )-NN query algorithm is straightforward. The idea of the algorithm is to decompose a query for hybrid type data to queries for single type data, then generate LSH query transforms of the queries, join the LSH query transforms of two types, and lastly process the joined queries on hybrid-LSH. Specifically, for a ( D,R,c )-NN query, it can be seen as a join of two single type queries ( D,c )-NN and ( R, c )-NN. First We find a ( d, cd, sp 1 ,sp 2 )-sensitive LSH query transform DT of ( D,c )-NN and a( r, cr, tp 1 ,tp 2 )-sensitive LSH query transform RT of ( R, c )-NN query. By combining the set DT and RT in Cartesian product way, we generate a ( d, r, c )-sensitive hybrid-LSH query transform, denoted as DRT .Atlastweprocessthe DRT in the hybrid-LSH and return the query result.
 Theorem 2. If there is an answer for a ( D,R,c ) -NN query, the adaptive ( D,R,c ) -NN query algorithm can return a c -approximate answer with constant probability.
 Proof. The proof is straightfoward. 4.2 Multiple Adaptive Hybrid-LSHs Shown in Theorem 1, each query in LSH query transformation at most checks 3 L objects, so the number of buckets accessed by each query is directly proportional to the number of queries. Hence, the number of queries in hybrid-LSH query transformation is a direct indicator o f query cost. The number of queries in hybrid-LSH query transformation is: According to Formula 10, when the query range is big, the query cost is very high, so we propose the multiple adaptive hybrid-LSHs.

The intent of the multiple adaptive hybrid-LSHs is to build many adaptive hybrid-LSHs to make the distance between queries and the closet adaptive hybrid-LSH small, which can significantly reduce the cost of query.

Shown in Formula 10, QN is in direct proportion to D d (spatially) and ( R  X  r ) (textually). For ( D,R,c )-NN queries where MinD  X  D  X  MaxD and MinR  X  R  X  MaxR , we build { d MinR , r i +1  X  r i = t ,and b , t are the common ratio and difference respectively. Corollary 3. Multiple adaptive hybrid-LSHs uses log b ( MaxD MinD )  X  MaxR  X  MinR t adaptive hybrid LSHs to process any ( D,R,c ) -NN query, where MinD &lt; D &lt; MaxD and MinR &lt; R &lt; = MaxR , by hybrid-LSH query transformation with at Proof. Set multiple adaptive hybrid-LSH MAH = { mah ij | mah ij is ( d i ,r j ,c )-sensitive adaptive hybrid-LSH, 0 &lt;i&lt; log b MaxR MinR ,0 &lt;j&lt; For the spatial part, qd d monotonically increasing function for qr ,and qr  X  r s (1  X  qr ) r which is monotonically decreasing function for qr .So QN  X  (2 b 2 +1)  X  ( C m TL + H w ) Setup. In order to show scalability and maintainability, we built the adaptive hybrid-LSH (HLSH), multiple adaptive hybrid-LSH(MHLSH), and implemented the proposed ( D,R,c )-NN in a distributed setting. For comparison, we also implemented state-of-the-art method SEAL [4] and LSHDSS [12]. SEAL uses hash based hybrid signature to process query, belongs to filter-and-verification framework and is an exact method, so for ( D,R,c )-NN queries we stop the algorithm when one object which satisfies query condition is obtained. LSHDSS is a LSH based distributed similarity search algorithm, however it is designed for single data type, so we extended it to support Spatial-textual similarity query by executing separately and combining intermediate result. In this paper we mainly focus on high-dimensional spatio-textual data, so we compared with methods with little global information which can be easy maintained in a distributed setting when there are lots of updates, an d due to expensive maintenance cost, methods with tree structures or hierarchical structures were not considered in our experiments.

Two datasets are used, The first one is a real dataset, which contains 0.5 million micro-blogs with location information collected from Sina microblog website, denoted as MicroBlog. According to the rule of microblog, each message must contain less than 140 characters and for MicroBlog, the longest meaningful spatial distance is 30km. After deleting the stop words, the average number of words of a message is 24, and in our experiments each word is taken as a token. The other dataset is a synthetic dataset, denoted as SynSet. SynSet has 1 million objects and objects X  tokens are chosen from a word set, and each object X  X  location is generated from a square area of which the side length is 100km.

All experiments are implemented in Cassandra v1.2.6. The Cassandra cluster consists of 10 machines with the same configuration: Intel(R) Core(TM) i7 Quad 870 @2.93GHz CPU and 8 GB RAM, and the same operating system: Ubuntu 10.04. To evaluate the performance of algorithms, we vary one parameter while keeping the others fixed at their default values. We run 20 times for each test, the average result of the query set is reported in the experiments.

Two performance measures are used: number of messages and accuracy. We count the number of messages from sending one query to obtaining result. The number of messages is an important indication of algorithm efficiency. Query accuracy [6] is used to measure the quality of the results. Specifically, o  X  is the actual result and o are the returned resu lts, query accuracy is DistST ( q,o ) DistST Effect of c . We first investigate the effect of the approximate ratio c on space consumption and query accu racy. Table 1 shows the performance of adaptive hybrid-LSH when c =2or c = 3. Because L is in direct proportion to dataset size, and index size is in direct proportion to L , the index size of MicroBlog is smaller than SynSet. As shown in table 1, the query accuracy of case c = 3 is a bit bigger than the case that of case c = 2, but it is still good, while the number of messages of case c = 3 is about 1 3 of that of case c = 2 . So it is worth trading a little accuracy for much higher query efficiency.
 Performance of ( D,R,c )-NN Query. We now show the results obtained from the ( D,R,c )-NN query, Figures 3 show the number of messages and accuracy for on MicroBlog and SynSet. Due to the limited space, in figures (1 , 0 . 02)-NN, NN2, NN3, NN4 and NN5 respectively. As the distance and range increase, the number of messages cost of HLSH and SEAL increase notably at first and then decrease. When the distance an d range increase for HLSH, some ( D,R,c )-NN queries LSH-transforms are generated, which result in the increasing of the number of messages, and for SEAL, the efficiency of filtering of the algorithm degrade and it needs check more inverted lists and candidates. However, from (2 . 5 , 0 . 08) the objects which satisfy the queries increase, in turn the algorithms can terminate ear lier and the number of disk accesses decreases. In contrast, the number of messages of MHLSH is stable. The number of messages cost of MHLSH is lower than that of SEAL, which is further lower than LSHDSS. From Figures 3(b) and 3(d), the average accu racy of HLSH is best, and the accuracy of MHLSH is better than that of SEAL.

Figures 4(a) and 4(b) illustrate the trends of number of messages and accuracy of the methods in terms of data size on S ynSet. As the dataset size increases, the number of messages of SEAL increases fast, as well as that of LSHDSS. The reason is that, the number of objects encountered in an inverted list for SEAL is linearly proportional to the dataset size. As a result of two phases of similarity query for LSHDSS, the algorithm is sensitive to the data size. Due to the P 2 of Theorem 1, HLSH and MHLSH are relatively stable with the data size varying. The number of messages cost of MHLSH is still the lowest. Figure 4(b) shows that the accuracies of HLSH and MHLSH are better than those of SEAL and LSHDSS, and HLSH is slightly better than MHLSH at the cost of much more messages.

Figures 4(c) and 4(d) show the performance of ( D,R,c )-NN query with dif-ferent average number of tokens on SynSet. Obviously the number of tokens is similar to the dimensionality in traditional databases. Generally LSH methods are not sensitive to dimensionality, so it X  X  easy to explain that MHLSH and LSHDSS are relatively not affected by the number of tokens. For HLSH, the number of LSH transform queries increases when the number of tokens increases, in result the number of messages of HLSH increases fast. For a fixed query distance and query range, SEAL is in direct proportion to the number of tokens. That X  X  why the number of messages for SEAL increases as the number of tokens increases. Shown in Figure 4(d), the a ccuracy of HLSH is still the best and the accuracy of MHLSH is better than that of SEAL and that of LSHDSS. In this paper, we propose a hybrid-LSH scheme for the spatio-textual similarity query. We devise efficient adaptive ( D,R,c )-NN algorithm and approximate k -NN method based on the hybrid-LSH scheme. Our theoretical studies show that the algorithms can have a guarantee on query quality. Results of empirical studies demonstrate that the paper X  X  proposal offers scalability and efficiency. Acknowledgments. This work is supported by the National Basic Research 973 Program of China unde r Grant (2012CB316201) and the National Natural Science Foundation of China under Gra nt (61472070). The first author is funded by China Scholarship Council. The third author is partially supported by the grants from NSF NetSE, SaTC, I/UCRC and Intel ICST on Cloud Computing.
