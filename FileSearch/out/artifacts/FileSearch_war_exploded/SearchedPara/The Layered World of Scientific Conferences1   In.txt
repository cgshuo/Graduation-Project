 Imagine your research has drifted into a field unfamiliar to you, and you do not know where to publish. In such situations it is helpful to have a better understanding of the world of computer science conferences. Throughout this paper we will explore this world and present an application that bases on this exploration and seeks to assist people that are in situations as described before.
The starting point of our research are recent findings in the context of social networks. These findings emphasize the fact that nodes in natural graphs are interconnected for differen t reasons, such as common interests, close geographic distances, or family relations in case of friendship networks. Based on the re-searchers X  social network we will intro duce a similarity measure for conferences and setup a conference graph. Similar as in friendship networks or the world-wide-web, edges in this graph are caused by different reasons X  X e will refer to them as the layers of our graph. Such reasons surely are area of research, but maybe also the quality, geographic location, or the community behind the con-ference. Throughout this paper, we demonstrate that and how it is possible to isolate some of these layers in the case of the conference graph. In particular, we will show that:  X  The social network behind conferen ces provides a good measure to relate  X  This measure consists of a thematic as well as a quality component X  X he  X  The thematic layer can be identified by a mere analysis of publication titles.  X  The quality layer can be partly isolate d by subtracting the thematic compo-
As a result of the layer separation, it becomes possible to explore the confer-ence graph under different points of view. We introduce a novel idea for con-ference rating based on the quality layer of the graph. Afterwards, we present a collaborative conf erence search website that demonstrates the advantages of having independent notions of the thematic scope and the quality of a confer-ence. It offers different ways to search for conferences and can be fine-tuned to match the quality and deadline restrictions of an author and thus greatly assists researchers finding themselves in situations as described in the very beginning of this paper. This section briefly reviews relevant liter ature in the context of our work, namely the mining of bibliometric data and social networks.

The analysis of publication records has been an active field of research for a long time. Clearly, one of the most a ttractive goals for publication database mining is automated conference and journal rating. Garfield X  X  pioneering work in 1972 [1], which describes the use of citation analysis for this purpose, initiated a long X  X nd still ongoing X  X ontroversy. On one hand, many authors point out the wide variety of problems of the citation indexing approach [2,3,4]. On the other hand, citation analysis is presumably still the best method to automatically rate scientific conferences and journals. Other measures that are used to indicate a venue X  X  relevance are the acceptance rat e as well as time delays, such as turn-around time, end-to-end time, or reference age [5]. It seems that the community behind a conference has so far not been taken into account for automated rating. We believe that this criterion should not be neglected and provide an idea to fill this gap.

The rating of venues is not the only motivation for research on bibliometric data. Other insights have been gained from publication databases. One closely related aspect is the characterization of authors (rather than venues). Various measures, such as closeness [6,7,8,9,10], betweenness [6,8,9], or AuthorRank [9] have been evaluated in this context. Also, many studies analyze the evolution of different properties [6,7,10,11,12]. For us, the publications of Lee et al. [12] and Smeaton et al. [10] are of particular interest, as they study the topical changes within a single conference over the years. Thereby they show that the analysis of publication titles, keywords, and abstracts is sufficient to extract the thematic scope of a venue X  X  fact that we will take advantage of.

Another perspective to looking at the t hematic scope of venues is presented in [6]. By considering a common author o f two venues an indicator for thematic similarity, a weighted graph is constructed that interrelates the most important conferences in the field of database resea rch. We improve on this measure by in-corporating some means of normalization and show that the thematic proximity is only one aspect contained in this weight.

Newer studies on social networks em phasize that many of these graphs ex-hibit some sort of social dimensions [13,14,15,16]. They state that there exist different catalysts for friendships, such a s geography, family ties, or occupation. An observation that Killworth and Ber nard [17] already made in 1978, when examining the different reasons by which a starter in a Milgram-like experiment would choose the next hop. Their findings show that most decisions are based on the geographic location and the occupation of the target. This result agrees with the findings of Dodds et al. [13] in a recent Internet-based small-world experi-ment. Based on this evidence, Watts et al. [16] developed a graph model based on different social dimensions. We will show that similar dimensions can also be found in our conference graph and refer to them as layers. This section describes how t he publication records of DBLP 1 canbeusedto generate a graph that interconnects sci entific conferences. The graph construc-tion bases on the social network behind t hese conferences. We b asically assume, that the more common authors two conferences have, the more related they are. To avoid overestimating the similarity of massive events X  X hey naturally have a large number of common authors X  X e improve on this idea by incorporating a normalization method: Consider two conferences, C 1 and C 2 ,thatcontaina total of s 1 and s 2 publications, respectively. Fu rther, assume that there are k authors A i ( i =1 , ..., k ) that have published in both places and that author A i has p i, 1 publications in conference C 1 and p i, 2 publications in conference C 2 .We can now define the similarity S ( C 1 ,C 2 ) between C 1 and C 2 as follows:
Applying this similarity measure to all pairs of conferences results in the desired graph. The required information for this graph was extracted from the DBLP bibliographic repository. Any publications that appeared in a scientific conference between 1996 and 2006 have been taken into account. To reduce the amount of data, edges of extremely low weight that do not significantly contribute to the connectivity have been removed. To give a more concrete idea of the structure of this graph, Table 1 lists the 10 top edges for some sample conferences. This section introduces the idea of layers as the building blocks of our graph. These layers reflect, as we will see, different catalysts for edges. We will have a closer look at two of these layers, namely the thematic and the quality layer, throughout this section.
Proximity in the conference graph is n ot purely defined by the thematic sim-ilarity of venues as a careful look at Table 1 reveals. ECAI is, for example, typ-ically said to be thematically closer to AAAI than ATAL , ICML ,or AGENTS , which appear earlier in the AAAI top-10 list. We conclude that authors choose conferences not only becaus e of the topic it covers. Other properties, such as quality, geographic location, or the community behind a venue also influence the author X  X  decision. In fact, we believe that it is a weighted combination of all these factors that leads to a submission at a certain place. Exactly this combination is reflected by the conference graph presented in the previous section. The graph consists of different layers , where each layer represents one of these factors. This idea is illustrated in Figure 1.
 4.1 The Thematic Layer Clearly, the thematic scope of a venue has a significant impact on its relationship to other venues. In the following, we present a technique that bases on publication title analysis and measures the themati c similarity of conferences. It thus allows to define the thematic layer , which is surely an ingredient of the social similarity measure, as a majority of authors mostly work in only one area and therefore submit papers to thematically similar venues.

For each conference, we have extracted all the titles from DBLP and applied the well-known term frequency -inverse document frequency (TF-IDF) method (see [18] for some theoretic background) to identify the most relevant keywords. The TF-IDF score for a document increa ses proportionally to the number of occurrences of the keyword in the document (TF). However, words that have a high overall frequency are penalized (I DF). In our context, a document corre-sponds to a venue and the words stem from publication titles. Consequently, a document consists of all titles in a venue and the complete corpus consists of all venues in DBLP.

Once a score has been applied to all the k eywords that appear in the confer-ence X  X  collection of titles, the scope of th e conference can easily be estimated by looking at the most relevant terms. Table 2 shows some examples.

Using the keyword-lists seen before, we have implemented a simple algorithm that estimates the thematic relationship between two venues. It takes the top-50 keywords of each conference, and counts the number of keywords appearing in both lists, resulting in a score from 0 to 50 for each pair of conferences. 2
Applying the thematic similarity function to each pair of venues results in a weighted undirected graph X  X he thematic layer of our graph. The corresponding neighborhood lists for our sample conferences are shown in Table 3. 4.2 The Quality Layer: Filtering by Subtraction Section 2 briefly discussed the problem of conference rating and its difficul-ties. For computer sciences, the Cites eer Impact List tries to estimate the im-pact of venues based on citation analysis. Further, many researchers maintain hand-made lists that distinguish between tier-1, tier-2, and tier-3 conferences. Even though hand-made lists suffer from a subjective bias and citation analysis from other weaknesses (recall Section 2), tier-1 conferences ty pically have a high impact and, contrariwise, tier-3 confe rences get low scores in the Citeseer list. We will refer to similarly classified conferences as conferences of similar quality.
Comparing the neighborhood tables for the total graph (Table 1) and the the-matic layer (Table 3) shows, that the total graph is not purely defined by the the-matic correlation of conferences. Looking at the total graph, an interesting obser-vation is that conferences often considered to be of high quality (such as KDD and AAAI ) tend to have other high quality confere nces in their proximity. In contrast, the number of lower-tier conferences in the proximity of ECAI , which is mostly clas-sified as tier-2, is significantly higher. This observation is illustrated in Table 4 that uses the impact value of the Citeseer Impact List 3 to classify the conferences.
We conclude that a single author tends to publish not only in venues of similar topic, but also in venues of similar quality, meaning that our graph contains a second major layer X  X he quality layer .

The observation that thematically weaker related nodes in a conference X  X  prox-imity tend to be closer in quality suggests that the quality layer can be extracted using the information about the total graph and the thematic layer. In the follow-ing we will introduce a layer subtraction approach to demonstrate that such a layer separation can indeed be achieved. The approach bases on the assumption that the total graph is a linear combination of the single layers. As a result of the obser-vations in the previous section we assume that the major layers of the conference graph are the thematic layer t and the quality layer q . This also matches our ex-perience when selecting a conference: We make sure the publication matches the call for papers and we try to submit at a conference of reasonable quality. Other factors, such as geographic location, play a minor role in the decision. These fac-tors (including noise) are thus subsumed into a remainder layer r .Consequently the total edge weight S becomes to S =  X  1  X  t +  X  2  X  q +  X  3  X  r ,forsomeweights  X  i , with  X  1 , X  2  X  3 . Neglecting  X  3 and setting  X  2 =1(  X  2 can be chosen arbitrarily as it only results in a scaling of q ) allows to extract the quality layer q as
Note that the validity of the linear combination assumption greatly depends on the characteristics of the weight functions in the different layers. In [19] Fernandez et al. presented the idea of score distribution normalization for ag-gregation purposes. They suggest to shape the histograms of the independent score functions to match the  X  X deal X  distribution prior to merging them by linear combination. For simplicity we assume a uniform weight distribution for both, the total as well as the thematic scores.

Observe that the subtraction approach generally allows to extract one out of L layers of a graph, if the remaining L  X  1 layers are known. It seems that such a layered structure can often be obs erved X  X ecall Sect ion 2 and also think of recommendation systems that often build on similar co-occurrence structures as our graph. We thus believe that the layer-subtraction approach might be a valuable preprocessing step in various data-mining settings.

The next sections discuss how the quality of the filtering can be estimated by producing a conference rating and there by show some evidence of the correctness of the proposed subtraction approach. 4.3 Interpolation Based Conference Rating The proximity of a conference in the quality layer is supposed to contain mostly conferences of similar quality. This obse rvation immediately leads to the idea of conference rating by interpolation: Provided some initial ratings are known, the tier of a conference can be estimat ed by looking at its proximity in the quality layer. Initial ratings can be retrieved from manually created lists (we use the one found at www.ntu.edu.sg/home/assourav/crank.htm and refer to it as CS Rating List ) as well as from Citeseer X  X  impa ct list. We have further intro-duced the Citeseer Tier List , which assigns a tier (1, 2, or 3) to each conference in the Citeseer Impact List. The borders b etween tiers have been chosen such that the number of incorrectly rated conferences with respect to the CS Rating List becomes minimal. The best that can be achieved is an error rate of 38 . 8%, which indicates how difficult the task of conference rating is.

We have then defined a heuristic to rate a conference C 0 as follows: 1. For all conferences in the CS Rating List or the Citeseer Tier List, set the 2. Overwrite the initial rating of C 0 with unrated . This step avoids that the 3. Take the 30 shortest edges e i adjacent to C 0 in the total graph, together 4. For the first 5 entries C j ( j =1 .. 5) in N f ( C 0 ), calculate N f ( C j ). 5. Return the median of all the rated conf erences found within the first 5 entries
Note that this conference rating method is in some sense natural. Many people would judge a venue based on people participating in it (or leading it). This information is implicitly contained in the total graph which forms the basis of the rating heuristic.

The quality of the heuristic can be estimated by comparing the calculated ratings to those found in the CS Rating List (which is presumably the most accurate list we dispose of). The optimal value of  X  1 was scanned for by exhaus-tive search over some reasonable interval. 4 This is illustrated in Figure 2 which plots the error rate of the rating function with respect to the CS Rating List for different values of  X  1 . The figure clearly shows that the subtraction approach reduces the number of incorrect ratings and suggests that the optimal value of  X  1 is somewhere between 0 . 5and1.
 Arguing with error rates beyond 40% might at the first glance seem suspicious. However, the fact that approximately 75% of the input values (namely those that originate from the Citeseer Tier List) exhibit an error rate of approximately 40% themselves relativizes the high erro r rate produced by our algorithm. Ignoring all the conferences rated as tier-2 either by the algorithm or the CS Rating List shows that the errors are not random. Dividing the number of conferences rated as tier-1 instead of tier-3 (and vice versa) by the number of conferences the algorithm rates as tie r-1 or tier-3 results in an error rate of around 6 . 4% without thematic filtering and of 2 . 6% for the optimal value of  X  1 . (Note that dividing by the number of tier-1 and tier-3 conferences in the list would overestimate an algorithm that tends to rate confer ences as tier-2.)
These low values show three things: 1. The total edge weight is clearly influenced by the quality of conferences. This 2. The success of extracting the qualit y layer by subtraction of the thematic 3. Most of the around 43% of errors are minor errors. That is, they are wrong Remark: The rating heuristic was develop ed for two reasons: To provide a complete rating list for the conference search application presented next, and to demonstrate the effect of subtraction filtering. It is thought as a proof-of-concept algorithm that neither has a strong mathematical foundation nor provides any guarantees on the results. In this section we will show that the previously discussed conference graph and its separation into different layers can directly be applied for confer-ence search. For this purpose we have developed a website that is able to suggest conferences together with thei r most important attributes (try it at http://www.confsearch.org ). The application offers four different search types:  X  Keyword Search : Search by keywords provided.  X  Related Conference Search : Explore the proximity of a given conference in  X  Author Search : Search for the places a given author publishes most often.  X  General Search : A weighted combination of the above search methods.
For all search types the application allows to sort the results by deadline, a criteria that has a considerable impact when deciding for one or the other venue. Motivated by the success of Wikipedia-like services, we fo llow a collaborative approach to gather conference deadlines as well as locations and website URLs. Our application can be seen as an improv ement on the many lis ts with conference deadlines found in the Internet today: We basically cover the whole area of computer science and augment the typically static lists with sophisticated search options.

The keyword search bases on a score s ij for each keyword-conference pair (where only keywords appearing in the query are considered), which is a slightly modified variant of the TF-IDF value pres ented in Section 4.1. Next, the scores s ij of the conference-keyword pairs are combined to a single value S ference C i using the p-norm method introduced by Salton et al. [20]. The final score S i results from the quality adjustment of S  X  i controlled by a user-settable to smoothly adapt to the different score distributions for different queries. The quality part Q is estimated using the heuristic presented in Section 4.3. Table 5 presents a keyword search example a nd the effect of quality filtering.
The related conference search operates directly on the conference graph. We simply return the closest nodes around a conference in terms of path-length. Again, a user settable parameter allows to control whether the thematic or the quality aspect should be emphasized. A visualization of the AAAI neighborhood in the thematic and the quality layer can be found in Figure 3. The increased amount of high quality nodes (dark) in the AAAI  X  X   X  X ualitative proximity X  indicates that AAAI itself is also likely to be of high quality. The search option on one hand allows to browse the conference graph and on the other hand might prove extremely helpful if you look for alt ernative places to submit, after a reject, for example, or because a deadline does not fit.
 Throughout this paper we have provided e vidence for recent small-world models using the real-world data of a scientific conference graph. We have shown that this graph indeed consists of layers and demonstrated that these layers can be effectively combined. The combination assumption has led to the subtraction approach for layer segregation which provides an attractive preprocessing step when mining graphs. In our setting it was used to accentuate the different aspects of conference relations.

We have seen that the conference graph consists of two major layers X  X he thematic layer and the quality layer. We have then presented a novel rating method for scientific conferences that op erates on the quality layer of the graph.
The separation of the two layers further builds the basis of the conference search application presented in the last section. Exploring the thematic layer allows to retrieve venues matching a user query. The sorting of the retrieved venues can then be adjusted using the information gained from the quality layer and thereby effectively fitted to the user X  X  needs.

