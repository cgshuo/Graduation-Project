 } In this paper we propose a non-greedy active learning method for text categorization using least-squares support vector machines (LSSVM). Our work is based on transductive ex-perimental design (TED), an active learning formulation that effectively explores the information of unlabeled data. Despite its appealing properties, the optimization problem is however NP-hard and thus X  X ike most of other active learn-ing methods X  X  greedy sequential strategy to select one data example after another was suggested to find a suboptimum. In this paper we formulate the problem into a continuous optimization problem and prove its convexity, meaning that a set of data examples can be selected with a guarantee of global optimum. We also develop an iterative algorithm to efficiently solve the optimization problem, which turns out to be very easy-to-implement. Our text categorization experiments on two text corpora empirically demonstrated that the new active learning algorithm outperforms the se-quential greedy algorithm, and is promising for active text categorization applications.
 H.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Algorithms, Theory, Performance Active Learning, Convex Optimization, Text Categoriza-tion, Transductive Experimental Design
There has been a long tradition of research on active learn-ing for text classification. In order to train a classification model that can automatically assign semantic tags on docu-ments, usually human experts need to provide a large set of labeled examples. Active learning reduces the labeling costs by identifying and presenting the most informative examples for experts to label.

Despite of a large body of work done by researchers, most of active learning algorithms are still far from being satis-factory and have apparent shortcomings. Many methods do not explore the information about the distribution of unla-beled data. As another drawback, nearly all the algorithms take greedy strategies to iteratively select one examples af-ter another, which is however suboptimal compared with optimizing a set of selections at a time.

In this paper we propose a non-greedy active learning method for text categorization using least-squares support vector machines (LSSVM). Our work is based on trans-ductive experimental design (TED) [17], an active learn-ing formulation that effectively explores the information of unlabeled data. Despite its appealing properties, the opti-mization problem is however NP-hard and thus X  X ike most of other active learning methods X  X  greedy strategy to se-lect one data example after another was suggested to find a suboptimum. In this paper we transform TED problem into an equivalent form and further replace the cardinality constraint by a novel sparsity regularization. The original discrete problem then becomes a continuous optimization problem. A bit surprisingly, the new formulation is convex , meaning that a globally optimal set of data examples can be selected. To the best of our knowledge, few attentions have been put to active learning algorithm that can select multi-ple data examples simultaneously with a global optimality. We describe an efficient learning algorithm that is very easy to implement. Our text categorization experiments on two text corpora empirically demonstrated that the new active learning algorithm is superior in comparisons with compet-itive methods.

The paper is organized as follows. In Section 2 we briefly review the related work in active learning. In Section 3 we begin by introducing the transductive experimental design and then propose the idea of convex transductive experi-mental design, where we prove the convexity and describe the algorithm. We also discuss how to control the sparsity of the result. Finally we empirically evaluate the suggested method in Section 4 and conclude this work in Section 5.
There has been extensive research on the subject of active learning. Existing approaches either select the most uncer-tain data given previously trained models [5], or choose the most informative data that optimize some expected gain [3, 10, 2]. The latter typically requires expensive retrain-ing of models when evaluating each candidate. Some other approaches assume generative models and explore the de-pendency between inputs and outputs [11]. Active learning methods for Gaussian processes [6] has also been suggested. [16] proposed active learning methods for support vector machines. The method queries points to reduce the size of the version space as much as possible. As the difficulty in measure the version space, they provided three ways of ap-proximating the procedure, Simple Margin, MaxMin Margin and Ratio Margin. The simple margin method, which selects the example closest to the current decision boundary, was also proposed by [13] and has been very popular. However, the method tends to select untypical data points, which may lead to a poor performance.

Active learning is also referred to as experimental design in statistics [1]. In order to learn a predictive function from experiment-measurements pairs, experimental design selects the most informative experiments to measure, given that conducting an experiment is expensive. [12] proposes an ex-perimental design method based on logistic regression mod-els. The goal is to minimize the variance. As the variance estimation depends on the label value of data point to be labeled, a factitious label has to be added into the training data before evaluating the variance reduction for each candi-date data point. This procedure takes a lot of computation power when the size of the candidate set is large. [8] also investigated the active learning problem for logistic regres-sion models. Their method requires non-trivial optimization techniques to solving submodule problems.

Usual experimental design methods aim to reduce the un-certainty of models (or model parameters), transductive ex-perimental design (TED) was proposed in [17] to directly reduce the assessed uncertainty of predictions on given un-labeled data, and thus effectively explore the information of unlabeled data in active learning. The method was applied to active learning for sponsored search [20]. A related ap-proach was applied in image retrieval [7]. However, despite its appealing performance, the problem is essentially NP-hard, and was thus solved by a greedy sequential algorithm that each time selects only one data example.
Suppose that we have a binary classification problem. A classifier is expected to predict the relationship from the feature vector x of a document to its labels y  X  X  X  1 , 1 } via where the function is assumed to be f ( x ) = w &gt; x in this pa-per. We note that a bias term can be incorporated into the form by expanding the weights and input feature vector as x  X  [ x, 1] and w  X  [ w , b ] . Based on a set of training exam-machine [14] (LSSVM) is equivalent to least-square ridge re-gression, which, in linear case, learns f ( x ) by estimating w via w  X  = min where  X  &gt; 0 , k X k is the vector 2-norm, X A = { x i } i  X  X  set of |A| = K training examples. The method has shown state-of-art text categorization performance [19, 18].
A generic active learning problem aims to choose an opti-mal training set X A , what we call active set in this paper, from a set of candidates X C , |C| = N , such that some quality measurement of w  X  is maximized.

Throughout this paper, we will somewhat abuse the nota-tion, for example, X A and X C represent sets, but may also be used to denote the matrices ( x i ) i  X  X  and ( x j ) j  X  X  tively. Their meanings should be clear given their contexts. If the feature vector x be D -dimensional, then X A  X  R K  X  D |A| denotes the size of set A , and | a | denotes the absolute value of a if a is a scalar. Moreover, we use k  X  k 0 , k  X  k and k  X  k to represent the ` 0 -norm, ` 1 -norm and ` 2 -norm of vector  X  , respectively. We note that k  X  k 0 is the number of nonzero elements in  X  .
Based on the learning method (2), the key idea of TED [17] is to minimize the average predictive variance of the learned function f ( x ) on pre-given data X P , |P| = M , which are to be predicted. It is formulated as an optimization problem where H is the Hessian matrix In many applications, like text categorization, it is reason-able to assume a large availability of unlabeled data X P whose distribution should be taken into account to effec-tively impact the choice of the active set A . Generally the candidates X C can be a subset of X P , or a completely dif-ferent set, or simply X C = X P .

Somewhat surprisingly, the predictive variance of f ( x ) =  X  w  X  , x  X  depends only on the input features of training ex-amples, due to the fact that, in J ( w ; X A ) labels y i linearly couple with w and hence a second order derivative with respect to w has all the y i terms canceled out. This in-dependence of y i removes the complication of the unknown factor of human labeling in active learning process. After some mathematical derivation, the minimization of predic-tive variance can be formulated as an equivalent optimiza-tion problem with a cardinality constraint which reveals that TED aims to find the optimal common set of K active examples X A to approximate every test data x  X  X P by  X  x i = X &gt; A  X  i , i  X  P . The approximation can be seen as the (regularized) projection of x i onto the linear subspace spanned by X A . Therefore, TED has a geometric interpretation that it tends to find representative data X spanning a linear subspace to retain most of the information of the whole set of test data X P . Therefore, given a suffi-ciently large set X P , TED actually explores the information about the distribution of unlabeled data.
 Despite of the appealing interpretation, (5) is however an NP-hard problem. Two suboptimal solutions have been sug-gested so far. The first is a sequential algorithm that solves a problem (5) of size K = 1 at each step, to approximate the residuals of the previous step. The algorithm is described as Algorithm 1.
 Algorithm 1 Sequential TED Require: candidates X C , unlabeled data X P ,  X  &gt; 0 , K ; 1: initialize  X  i,j  X  X  x i , x j  X  , for i  X  X  , j  X  X  ; 2: repeat 3: j  X  arg max j  X  X  4: A X  X  X  j ; 6: until |A| = K ; 7: return X A ;
The second approach aims to optimize the set X A simul-taneously, which replaces the cardinality constraint |A| = K by an ` 1 -norm regularization subject to x i  X  X P , B = diag (  X  ) , B  X  0 . (6) The above formulation introduces a set of variables  X  j to control the overall  X  X n X  and  X  X ff X  of each candidate x j in terms of being selected or not. The ` 1 -norm k  X  k 1 enforces some elements of  X  to be zero. The optimization is done by alternatively optimizing  X  j or  X  j while fixing the other. This problem is however non-convex, which means that the results are highly sensitive to the initialization of the algo-rithm, and can be easily trapped into a poor local minimum.
In this section we introduce a new formulation of TED, which is convex and hence avoids the risk of being trapped into any local optimum. Unlike most of the other active learning algorithms, the new method aims to select multiple examples at a time with a guarantee of global optimum. We will also show that the optimization procedure is actually easy to implement.
 Again, we introduce auxiliary variables  X  = [  X  1 , . . . ,  X  to control the inclusion of examples into the training set. The optimization problem is subject to x i  X  X P ,  X  j  X  0 , j = 1 ,  X  X  X  , N, known LASSO method [15], the ` 1 -norm k  X  k 1 will enforce some elements of  X  to be zero. It is not difficult to see, if  X  j = 0 , then all  X  1 ,j , . . . ,  X  M,j must be 0, otherwise the objective function goes to infinity, which means the j -th can-didate is not selected. The new formulation appears to be similar to (6), but we can prove that it is a convex problem and thus guarantees a global optimal solution.
 Theorem 1. The problem (7) is convex w.r.t.  X  , {  X  i } .
Proof. In the objective function, the first term is a square loss and the third term is an ` 1 -norm, both are known to be convex. Since a summation of convex functions is also convex, in the following we only need to prove that S j = P tion of S j being convex is that its Hessian  X  S j is positive semidefinite, therefore we compute the second-order deriva-tive terms M , whose i -th element is  X   X  j and the rest are zeros. There-fore we have  X  j  X  0 and thus  X  3 j  X  0 , therefore  X  S j  X  0 . The proof is completed.
 By noticing the inequality whose equality holds only if  X  2 j = 1  X  a necessary condition for the optimal solution of (7). We plug this condition into (7) and find that the problem (7) is equivalent to Though (7) and (10) are equivalent, we find it convenient to implement an iterative algorithm to find the local optimum of (7), which is also the global optimum, without accessing any optimization package. The algorithm is based on the observation that the update of  X  or  X  i while fixing the other has an analytical solution. The iterations proceed as described in Algorithm 2. Simi-lar to Algorithm 1, the method is extremely easy to imple-ment, without requiring any optimization package. The ma-jor computational cost comes from the update of  X  i , which can be greatly simplified by applying the Woodbury identity if the dimensionality of data is smaller than the size of can-didates, which is the case in our experiments since we often reduce the dimensionality of data before the data selection. The computational cost can be further reduced by consid-ering smaller sizes of X C and X P that are random subsets from all available unlabeled data.
Compared with the greedy procedure described in Algo-rithm 1, we lose the direct control on the budget | X A | = K . A detailed relationship between  X  and the resultant K needs to be investigated, e.g., computing the whole solution path, Algorithm 2 Convex TED Require: candidates X C , unlabeled data X P ,  X  &gt; 0 ; 1: initialize (  X  i,j ) ; 2: repeat 3:  X  j  X  5: until converge; 6: X A  X  X  x j | x j  X  X C ,  X  j 6 = 0 } ; 7: return X A which is however not the scope of the current paper. We con-jecture that the sparsity is almost monotonic with respect to the regularization weight  X  , so we can do line search to find an appropriate  X  that selects roughly K examples. We provide Theorem 2 to show that the range of  X  is upper bounded by a value  X  max , by checking the condition of pro-ducing at least one non-zero element in  X  . This result can be used to narrow down the range of our line search.
Theorem 2. A necessary condition for the cardinality con-straint |  X  | 0  X  1 is
Proof. Suppose that  X  is sufficiently large so that  X  j = 0 and thus  X  i,j = 0 for all i and j . We compute the partial derivatives of the two costs in (10) d d equals to a constant = 4  X  . The first derivative tends to pull  X   X  ,j away from the origin while the second tends to push  X   X  ,j toward the origin. Thus in order to pull out nonzero elements of  X  i,j or  X  , there should be k d 2 k  X  k d 1 k , which completes the proof.

However the line search is still too costly, because it has to solve an optimization problem (7) at each step of changing  X  . In this paper we develop a practical heuristic to obtain result subject to the budget constraint |  X  | 0 = K . The ba-sic idea is that, instead of changing  X  to enforce the desired sparsity of the result, we can change the problem to make it indeed sparse, and ensure that a result with the desired spar-sity can be produced with a high probability under a fixed roughly chosen  X  . If the intrinsic dimensionality of data in X
P is K 0 , we know that it requires at least K 0 linearly in-dependent factors whose linear combination can sufficiently approximate every data example in X P . Therefore K 0 offers a lower-bound for the sparsity |  X  | 0 = K of the result. If we increase the lower bound K 0 , the obtained K is likely to be increased. This explains why empirically we found it very effective to control the sparsity K of result by changing the intrinsic dimensionality K 0 of data using principal compo-nent analysis (PCA). The detailed steps are the following 1. Perform singular value decomposition (SVD) on the 2. Project data into the K 0 principal space 3. Replace X P and X C with  X  X P and  X  X C in problem (7), 4. Retrieve the data examples from X C , whose corre-Note that we use the low-dimension data for data selection only, while use the original full-dimension data for training the classifier. In our experiments we found it effective to use a simple linear relationship to control the sparsity, where  X  can be empirically estimated from data (e.g., see Section 4). We simply choose the regu-larization parameter  X  among { 0 . 001 , 0 . 01 , 0 . 1 } X   X  approach is computationally much cheaper than line search, and is also cheaper than solving the original (7) due to the reduced dimensionality of data. We note that a theoretical linear relationship between the resultant sparsity K and the data dimensionality K 0 has been suggested by Donoho [4] as a condition of equivalence between ` 0 -norm and ` 1 -norm minimization. A detailed connection to this theoretical work is not the purpose of the present paper, we will instead pro-vide some empirical justification in our experiments.
In this section we evaluate the proposed convex TED algo-rithm for text categorization. Our empirical study was con-ducted based on two real-world text corpora. Our first data set is a subset of Newsgroup corpus, which contains 3970 documents with 8014 dimensional TFIDF features. This data set covers four categories:  X  X utos X ,  X  X otorcycles X ,  X  X ase-ball X ,  X  X ockey X , each with 988, 993, 992 and 997 documents respectively. The other data set is a subset of the RCV1-v2 text data set, provided by Reuters and corrected by Lewis et al. [9]. The data set contains the information of topics, regions and industries for each document and a hierarchi-cal structure for topics and industries. A set of 10000 doc-uments is chosen for our experiments, including categories  X  X 15 X ,  X  X CAT X ,  X  X CAT X , and  X  X CAT X , each with 1826, 2477, 2999, and 4671 documents respectively. In this data set we use 9705 dimensional TFIDF features.

We conduct one-against-all classification for each cate-gory and thus treat the problem as binary classification, i.e., y = { X  1 , 1 } , where documents from the target category are labeled as positive one, while those not belonging to this category are labeled as negative one. In the one-against-all setting, each binary classification task has unbalanced data, i.e., 18%  X  25% examples are positive and the rest negative. Because each classification task is unbalanced, classification accuracy rate may not be suitable to measure the perfor-mance. In the experiments we use the AUC score, i.e., area under the Receiver Operating Characteristic (ROC) curve , to measure the overall classification performance. Another reason is that ROC curves use true positive rates and false positive rates, which is closely related to precision and recall commonly used in IR tasks.

In each run of our experiments, an active learning method is applied to select a given number K of training examples, trained on these examples with their labels. The trained classifier is then used to predict the class labels of the re-maining examples, and an AUC score is computed based on the results. In order to randomize the experiments, in each run of experiments we restrict the training examples to be selected from a random candidate set of 50% of the total data. Therefore for each combination of active learn-ing method and a number K , we compute the mean and standard error based on 10 randomized experiments. In this paper, we evaluate and compare five active learning meth-ods, We note that all the methods use least-squares SVM (LSSVM) as the base classification method, except the Simple Margin method that uses hinge-loss SVM. In all the experiments we fix the parameters as  X  = 0 . 01 and  X  = 0 . 1  X  max .
We first empirically illustrate some properties of our al-gorithm in the aspect of achieving sparse results. Due to the space limitation, all the results shown here are based on the Newsgroup data. However similar phenomena can be observed on the other data set as well. Figure 1 shows that the achieved sparsity K can be controlled by either changing the regularization parameter  X  , or changing the dimension-ality K 0 of data as suggested in Section 3.4. However, as suggested in Figure 1-(a), the resultant sparsity K has a monotonic but nonlinear dependence on the parameter  X  , which makes the line search difficult to ensure the sparsity budget. In contrast, as suggested by Figure 1-(b), we empir-ically found the simple linear connection between K and the data dimensionality K 0 (in this case  X  = 1 . 61 ). This pro-vides a hint for us to efficiently achieve the desired sparsity. Figure 1: Control the sparsity of optimization re-sults: (a) complex non-linear dependence on  X  vs. (b) simple linear relationship with the data dimen-sionality K 0 .
 Figure 2: Updates of  X  (30 dimensions in this case) over iterations (a) K 0 = 5 (b) K 0 = 10 .
 In fact, since the examples are selected based on the ranking of elements in  X   X  , we only require the achieved sparsity to be approximately close to K . Therefore  X  does not have to be very accurate. In our experiments we simply fix  X  = 1 .
In the next, we use an example to show that our formu-lation can indeed achieve sparse results across iterations of Algorithm 2. For illustration purpose, we restrict the candi-date set X C to be 30 random examples from the 3970 docu-ments, therefore  X  is a 30-dimension vector of non-negative numbers, which are initialized to be  X  j = 5 , j = 1 , . . . , 30 . As shown in Figure 2, in both cases of K 0 = 5 and K 0 = 10 , most of the elements in  X  vanish to zero quickly over it-erations. Eventually only 2 and 5 elements survive to be nonzero at the 30-th iteration. In general, we found the al-gorithm locate the active set within hundreds of iterations given many thousands of candidates.
Newsgroup : We compute the AUC scores for each ex-periments of a given method and a given K , and average them over all the categories and random trials to obtain the overall performance of each pair of method and K . The re-sults are shown in Table 1 with a figure on the left and a table showing the numbers on the right. A little bit sur-prisingly, the K-Means approach only performs slightly bet-ter than the Random Sampling approach. Sequential TED exhibits performances better than K-Means and Random Sampling, but worse than the Convex TED method. The new algorithm produces very impressive results in this case: classifiers trained on only 5 training examples give the AUC score 90% in average, while Random Sampling needs almost 10 times of that training size to reach the same level of ac-curacy. standard error of AUC score over 10 random trials.
Note that here we compare only the methods whose data selection is label-independent . The Simple Margin method selects the next data based on the current classifier, which is trained on the previously seen labels of examples. There-fore, for each category the method selects a different set of training data that are largely non-overlapped, while those data-independent methods select a common set of data for training classifiers of all the categories. In order to put the performance of each binary classifier in a comparable ground, each learner is supposed to pick up the same num-ber K of examples, which however makes the comparison a bit unfair for the multi-category case, because then Sim-ple Margin actually employs 4 K (if no overlap) examples in total while other methods use only K examples.

Nevertheless we can still make a comparison in the binary classification case for each individual category, whose results are plotted in Figure 3. For the 3 categories  X  X utos X ,  X  X o-torcycles X  and  X  X aseball X , Convex TED method outperforms the second best  X  Sequential TEC  X  by a large margin, and performs similarly on the category  X  X ockey X . The Sim-ple Margin method works surprisingly bad in this data set. We conjecture that the method is trapped to find outlier or untypical examples that are likely to stay close to the boundary of classifiers. In contrast, the TED methods set the optimization goal as finding data to well preserve the rest of other data, and are thus unlikely to find those outliers.
RCV : The overall performances of different methods ex-cept Simple Margin on the RCV data are presented in Ta-ble 2. In this case the K-Means method performs very close to the Sequential TED method, except for the case of K = 5 where the AUC of Sequential TED is 75 . 3% while that of K-Means is 65 . 9% . The Convex TED method demonstrates the best performance in all the cases when less than 40 ex-amples are selected. Especially the advantage is notable when K = 5 , 10 , 15 and 20 . Furthermore, as shown in Fig-ure 4 all the methods including Simple Margin are compared on the bases of individual categories. We find that Simple Margin performs quite good on the categories of  X  X 15 X  and  X  X CAT X , while very poor on the category  X  X CAT X . Sequential TED and K-Means behave very closely. Random Sampling shows fair performance except on  X  X 15 X . Convex TED out-performs Sequential TED and exhibits good results in all the cases, especially on the category  X  X CAT X  where Simple Margin clearly fails.

Label-independent vs. Label-dependent : The ex-periment results, especially regarding those of Convex TED and Simple Margin methods, raise an interesting question: what are the pros and cons of label-dependent/independent active learning algorithms? We feel that label-independent active learning, e.g., TED, tends to be somewhat more gen-erative than discriminative, because it explores the distri-bution of unlabeled data and is less prone to untypical pat-terns or outliers. Moreover, as we discussed already, label-independent approaches seem to be cheaper for active learn-ing with multiple categories , a topic rarely touched by the previous research. In practice, label-independent active learn-ing should be useful in the early stage when very little labels are known. Our experiments showed that the advantage of Convex TED is particularly prominent when the training size is very small, the task involves multiple classes, or out-liers are present. On the other hand, label-dependent active learning is naturally compelling, because it uses the infor-mation of labels. For example, the Simple Margin method performed very well for the category  X  X 15 X , which turns out to be the smallest category among the four. It could be un-derstood that a label-dependent approach is good at finding small categories, as the information of known labels helps to push the classification boundary to shrink and be more fo-cusing. However, these methods are usually too greedy, and sometimes prone to untypical data, as what we observed on the Newsgroup data. This analysis suggests a future direc-tion of combining two kinds of approaches to make active learning less greedy and meanwhile discriminative.
In this paper we developed a non-greedy active learning al-gorithm by extending the framework of transductive experi-mental design (TED). Unlike the previous sequential greedy algorithm, the new formulation can simultaneously select multiple data examples at a time with a global optimum. We proposed an iterative algorithm that does not require to apply any non-trivial optimization technique. Our ini-tial experiments demonstrated that the non-greedy solution outperforms the greedy approach, and produced good per-formances for active text categorization, especially at the initial phase. In the future, it is interesting to combine the strengths of convex TED and label-dependent methods to develop active learning approaches that are label-dependent and also less greedy. [1] A. C. Atkinson and A. N. Donev. Optimum [2] O. Chapelle. Active learning for Parzen window [3] D. Cohn and Z. Ghahramani. Active learning with [4] D. Donoho. For most large underdetermined systems [5] Y. Freund, H. S. Seung, E. Shamir, and N. Tishby. [6] C. Guestrin, A. Krause, and A. Singh. Near-optimal [7] X. He, W. Min, D. Cai, and K. Zhou. Laplacian [8] S. C. H. Hoi, R. Jin, J. Zhu, and M. R. Lyu. Batch [9] D. D. Lewis, Y. Yang, T. Rose, and F. Li. RCV1: A [10] D. MacKay. Information-based objective functions for [11] K. Nigam, A. K. McCallum, S. Thrun, and T. M. [12] A. Schein and L. Ungar. Optimality for active learning [13] G. Schohn and D. Cohn. Less is more: Active learning [14] J. Suykens and J. Vandewalle. Least squares support error of AUC score over 10 random trials. [15] R. Tibshirani. Regression shrinkage and selection via [16] S. Tong and D. Koller. Support vector machine active [17] K. Yu, J. Bi, and V. Tresp. Active learning via [18] J. Zhang and Y. Yang. Robustness of regularized [19] T. Zhang and F. J. Oles. Text categorization based on [20] W. V. Zhang, X. He, B. Rey, and R. Jones. Query
