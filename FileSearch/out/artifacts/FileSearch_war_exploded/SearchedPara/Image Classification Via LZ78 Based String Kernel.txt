 Defining a similarity measur e between two objects, without explicitly modelling of their task-specific statistical behaviour, is a fundamental problem with many important appli-cations in areas like information retrieval an d classification. A broad spectrum approach to this problem is to use the compression-based techniques as a tool for measuring the information redundancy among the objects. Informally, the more information shared between two objects, the more likely they are similar. Based on the concept of (condi-tional) Kolmogorov complexity [4], authors in [1] formalized such an idea into a sim-ilarity metric called Normalized Information Distance (NID). It is illustrated in Fig. 1. Although the Kolmogorov complexity KC (  X  ) is not computable, any compression al-gorithm gives an upper bound and this can be taken as an estimate of KC (  X  ) .Some earlier studies on this approach can be found in [5, 6, 1], which were mainly focused on 1D sequences.

Recently, researchers start exploring the applicability of this compression-based technique (i.e. NID) in the field of two-dimensional images. The key to its feasibil-ity lies in the fact that the raster-scanned version of the raw image preserves enough regularity in both dimensions for the compression algorithm to discover. The authors in [7] tested the technique on the task of handwritten digit recognition and reported an accuracy around 87% which is close to state-of-the-art performance (90% accuracy). However, this image collection is relatively simple due to the binary image representa-tion (i.e.  X # X  for a black pixel and  X   X   X  for a white pixel) and consistent object scale. In [8], the authors tackled a more challenging task i.e. object identification from real-life pho-tographs where images are of unknown and v arying scale of scene. The best accuracy over the raw images is around 84% and it is reported to be better than conventional intensity-histogram based techniques. Technically, in both studies, the kernel of Sup-port Vector Machine (SVM) was simply repl aced with the similarity (i.e. NID) approx-imated by compressed length. The potential risk is that, compression-based similarity may result in a non positive-semi-definite (PSD) kernel matrix and thus the optimiza-tion problem is no longer convex; SVM learning with SMO-type implementation [9] could converge but the global optimality might not be guaranteed.

To avoid the above problem, we developed the notion of NID into a valid kernel dis-tance, called LZ78-based string kernel, which is suitable for use with SVM classifier [2]. Essentially, it is based on the mapping of example input to a high-dimensional feature space that is indexed by all the phrases identified by a LZ78 parse of the input exam-ples. Further comparisons with other state-of-the-art algorithms yield improved results for a variety of distinct tasks e.g. the classi fication of music genre, spoken words, and text documents [3].

In this paper, we investigate the applicability of the LZ78-based kernel on 2D image data and empirically demonstrated its advantage over pure compression-based tech-niques and conventional classification algorithms. The outline of the paper is as fol-lows. In Section 2, we recall the fundamental tools used in this work: the concept of normalized information distance and Lempel-Ziv type compression algorithm. In Sec-tion 3, we describe our LZ78-based scheme for image classification. Section 4 presents the application of the proposed method to two practical image classification tasks and experimental results are presented and compared. Finally, conclusions are given in Section 5. 2.1 Approximation of Normalized Information Distance The Normalized Information Distance (NID) as proposed in [1] is a similarity met-ric based on the concept of Kolmogorov Complexity. Informally, it is the ratio of the information shared by the two objects to the total information content of the pair of objects. This is illustrated in Fig. 1. Two identical objects will have NID=0, whilst two objects with no common information content will have NID=1. Given an object en-coded as a binary string x , its Kolmogorov complexity KC ( x ) is the minimum number of bits into which the string can be compressed without losing information [4]. Intu-itively, Kolmogorov complexity indicates the descriptive complexity contained in an object. A random string has relatively high complexity since no structural pattern can be recognized to help reduce the size of program. Strings like structured texts and musi-cal melodies should have lower complexity due to repeated terms and musical structure. Kolmogorov complexity is only an idealized notion be-cause it is not computable. How-ever, any compression algorithm (e.g. LZ78 [10] and PPMZ [11]) gives an upper bound and this can be taken as an estimate of the Kolmogorov complexity. As a result, the theoretical elegant NID amounts to a normalized compression distance [7] in practice. 2.2 Lempel-Zip (LZ) Type Coding As mentioned before, NID can be approximated by many compression algorithms. In this work, we select a compressor from LZ family [10] i.e. LZ78, which is simple and extremely fast. Moreover, LZ78 is driven b y a dictionary-based coding scheme, which can be easily developed into a valid string kernel.
The figure above captures the essence of LZ78, which works by identifying patterns, called phrases, of the data and stores them in a dictionary (i.e. encoding table) that defines shorter  X  X ntries X  that can be used in their stead. In other words, it segments a sequence into several distinct phrases such that each phrase is the shortest subsequence that is not a previously parsed phrase. For example, given a sequence x =  X  X bcabcabc X , LZ78 parsing yields (a, b, c, ab, ca, bc), namely, KC ( x )=6 . In this work, image classification implies to be able to measure the similarity between the strings obtained by scanning the images in raster row-major order. As mentioned previously, such a raster-scanned version of the image retains enough regularity in both dimensions.

Based on the coding scheme mentioned in Section 2.2, two alternatives for the cal-culation of the similarity are: using compressed length (i.e. dictionary size) or using compressed patterns (i.e. entries within the dictionary). 3.1 Using Compressed Length In this way, compressed length is used to approximate the normalized information dis-tance between two images. Following the works in [7] and [8], we choice a variant of NID to calculate the pairwise similarity (see Equation 1). Furthermore, to avoid the risk of finding local optimality because of the non-PSD problem, we convert the image into a vector form where the i th element corresponds to the NID score between current image and the i th image in the data, so that the standard kernel function (e.g. RBF ker-nel) can be applied. Note that with this technique the dimension of feature space is set by the number of examples.
 3.2 Using Compressed Patterns The second way to calculate the similarity is based on the patterns (i.e. phrases) iden-tified during compression. In our case, the image (i.e. raster-scanned version) is repre-sented by the set of all the features (i.e.  X  lz 78 ) identified by our modified LZ78 parsing and the pairwise similarity is then defined as the inner product of the weighted 2 feature vectors:
As illustrated in Fig. 1, it is natural to normalize the similarity score in order to take account of object size. In the kernel method, this effect can be achieved by normalizing the feature vectors in the feature space: In this study, we take an empirical approach to evaluate the performance of our pro-posed scheme for image classification. More specifically, we are concerned about two issues: (i) how does our LZ78 kernel compare with other similarities approximated by compressed length? (ii) is our approach competitive with conventional classification algorithms applied in medical image classification? To conduct the evaluation, the pro-posed approach is applied to two distinct applications. The first is the classification of the photograph dataset used in [8] that contains two classes, each of which consists of 761 grayscale images with 247  X  165 pixel resolution 3 . The second is the detection of extracapsular extension (ECE) [12] of prost ate cancer using a collection of 18 prostate MR images taken from 10 prostate cancer patients, among whom 6 have histological confirmed ECE and the others are proven to have organ confined tumors. All experi-ments are carried out using the libsvm 4 package, which guarantees the convergence to stationary points for non-PSD kernels. 4.1 Experiment on Photograph Collection Some images about this collection are shown in Fig. 2. Based on a simple subset of the whole collection, the authors in [8] pointed out that the two classes of this dataset are separable on mean intensity alone. They therefore built a benchmark classifier based on comparing intensity histograms. The res ults showed that compression-based classi-fier outperforms the intensity-based classi fier by 25% in accuracy, which demonstrates a desirable characteristic of the compression-based techniques-they can automatically identify discriminative regularities (i.e. patterns) from the training dataset. Further, a more complicated image dataset, containing all 1492 images, was used in [8] to test their technique.

For comparison, we evaluate our method on the same image dataset and re-implement the alternative technique mentioned in [8] which uses partial matching compression technique (PPM) [11] to approximate the NID between two images. The performance is evaluated by a standard ten-fold stratified cross validation (CV). No sieve transformation [13] or ground truth data 5 are used in this experiment since we are interested in comparing the performance made by the compression kernels rather than the improvement made by other techniques (e.g. feature transformation and image segmentation). Note that, when no ground tr uth data are utilized, the best performance in Lan X  X  work (84%) is achieved by using sieve transformation. As shown later, our approach could achieve even better performance with raw images only.

Table 1 displays the accuracy of SVM classi fiers with various strategies for kernel matrix construction. Lan X  X  experiments in [8] are repeated and the performance of their SVM-based method on raw images (74% accu racy) is confirmed in our experiment: note that it occurred only when RBF kernel is applied (i.e. using RBF function to re-calculate the distance between two vectors representing the corresponding im-ages). The bottom row of Table 1 shows that, based on smoothed greyscale images, our LZ78 kernel could achieve better performance but without such extra computational overhead.
It is interesting to note that PPM genera lly performs better than LZ-type coding in terms of the compress ratio. However, comparing the results shown in the first and second rows, LZ78-based approach performs better in terms of classification accu-racy. Two points should be noted. Firstly, in our implementation, PPM acts on binary-encodings of the image string while LZ-based algorithm directly acts on descriptive symbol sequences (i.e. greyscale values); the results may imply the fact that, the format-similarity 7 [14] introduced by the low-level (e.g . binary) encodings may deteriorate the complexity approximation, especially wh en the sequences are relatively short. Sec-ondly, as mentioned before, compression-based similarity may result in a non-PSD ker-nel matrix; although a SMO-type implementation could converge but no global opti-mality is guaranteed, which is empirically confirmed in our experiments. Computer-aided diagnosis of diseases using medical images is an active research do-main. We have previously described the use of a few classification algorithms to detect the extra-capsular extension (ECE) of prostate cancer using Magnetic Resonance (MR) images [12]. Basically, each pixel along th e prostate boundary is represented by a grey-level intensity profile extracted orthogonal to the prostate boundary and centered on the pixel. A classification model is trained to predict the ECE probability of the pixels (i.e. intensity profiles) along the prostate boundary . Then, a probability filtering process is applied to calculate the overall ECE probability of the image. The classifiers used in this study are k Nearest Neighbor ( k NN) and Parzen classifier (PZC).
 In this study, we present the application of our LZ78-based SVM to ECE detection. It begins with a sequence of intensity profiles representing a particular MR image, and then applies the following steps: (i) a string example is constructed by concatenating all the intensify profiles of the image in row-major order; (ii) the distances from the ex-ample to the decision boundary of positive class c 1 and negative class c 2 are calculated according to Equation 4; (iii) the final ECE probability of the image, P ( x ) ,isgivenby Equation 5. bination coefficient and K lz 78 (  X  ) is the kernel function (see Equation 2) to perform the similarity calculation.

The MR image data set used in this study consists of 18 MR images from 10 patients, among which seven patients have histologically confirmed ECE, and the other three are proven to have organ confined (non-ECE) prostate cancer. Two mid-gland MRI slices are used for each of the non-ECE patients and five of the seven ECE patients, and one from each of the other two ECE patients. Each slice from the ECE patients includes at least one ECE region.

Since the main aim of this experiment is to evaluate the ability of a trained model to predict the ECE risk of unseen MR images, to avoid the effects of possible variations in automatic boundary localization and to provide an objective evaluation of the classifi-cation models, manual annotations of the prostate and the ECE regions are used as the ground truth. The annotations are provided b y an expert radiologist, and subsequently verified by a second expert to avoid inter-observer variation and ensure the accuracy and consistency. A typical example slice, with a region of ECE annotated can be found in Fig. 3 (a). Fig. 3 (b) shows the profile extraction positions on the example slice, as well as the determination of profile lab els according to the manual annotation.
To conduct a statistical evaluation of the me thods, the area under the receiver opera-tor characteristic curve (AUROC) of the classification results is computed and com-pared. The results are obtained by using leave-one-image-out testing. As shown in Table 2, the LZ78-SVM classifier correctly classified 16 of all 18 images, with only 2 images from a non-ECE patient detected as false positive, and hence correctly iden-tified the ECE status of 9 of 10 patients. Overall, based on the intensity profile fea-tures, LZ78-SVM offers the best detection res ults when compared to other classification methods. This paper has described the applicatio n of the LZ78-based kernel technique to the classification of 2D images. Instead of following the commonly adopted strategy which approximates the NID by the compressed length of the input data, the technique uses a modified LZ78 compression algorithm as the heuristic for feature extraction and then builds a valid string kernel for SVM. Experiments based on two image collections show that, this method yields better performance when compared with previously proposed approaches. This implies a promising efficiency and wide applicability of the presented method.

Several issues would be considered for future work. Firstly, so far, we merely con-sider the raw image information (i.e., intensity values or intensity profiles). The perfor-mance of the proposed method can be further enhanced by incorporating more sophisti-cated image representation techniques, e.g., morphological operators and content-based descriptors. This should provide more compact and descriptive representation of the images, and hence better classification outcome. Second, the experiment on MR image data for prostate cancer diagnosis is based on a relatively small date set. Experiments on larger data sets are expected to conduct a more comprehensive evaluation, and will be performed in due time when such data are available. Furthermore, the use of other compression algorithms as the feature extrac tion techniques, such as the block-sorting algorithm [15] and the PPM family [11], will be investigated. We wish to thank anonymous reviewers for their helpful comments and Yuxuan Lan for providing us the photograph image dataset. We also thank Prof. Ronan Sleep and Dr. Richard Harvey for interesting and useful discussion.

