 The concept of paraphrasing is generally defined on the basis of the principle of semantic equivalence: A paraphrase is an alternative surface form in the same language expressing the same semantic content as the original form. Paraphrase recognition is aimed to classify the object sentence pair positive paraphrase or not.Paraphrases recognition has attracted global intellectuals devoting their ef-forts because of its wide range of applications in Query Expansion, Information Extraction, Machine Translation and so forth [1].Consider the following exam-ples, paraphrased from MRSPC sources: S1: Special, sensitive light sensors pick up the telltale glow, he said. S2: A sensitive light detector then looks for the telltale blue glow. Forward methods like surface string similarity and vector model method will fail in recognize this positive paraphrase as they ignored the synonyms of words as well as the structure which represent the meaning of sentence. This paper concentrates on introducing a novel data-driving method to recognize sentence level paraphrase. Sentence X  X  part-of-speech labels as well its parsing tree are be-ing employed to discovery deep semantic relations of sentence pair. Our work is divided into two phases. Firstly, POS-tagging and syntactic analysis are done on the sentence pair to obtain kernel information of the semantic role and parsing tree structure. Secondly , adopt train data to construct a two hierarchical Model based on kernel information of semantic role and parsing tree structure extracted from the first phase. Then test data is employed to recognize paraphrase rela-tionship of the sentence pair. We do deep semantic mining and construct the hierarchical model to do the sentence level paraphrase recognition which does not employed by previous methods .we take the distinguish into consideration and they indeed achieve encourage result. The rest of the paper is organized as follows. A survey of related works is conducted in Section 2, then the definition of semantic level difference method and its algorithm are proposed in Section 3. Section 4 introduces the experiment details and the progress of the method,with detailed analysis of the result. Finally we conclude the paper in Section 5 with a guideline of the future work. Sentence level paraphrase recognition is aimed to judge whether two sentences express the same meaning or not. Previous methods can be classified into fol-lowed categories due to their different viewpoints. These are the method based on surface string similarity, operated on syntactic or semantic, Machine Learning Method, method employs co-reference or text entailment,and method combine information from different levels.
 of common words,and combination of several string similarity measures to rec-ognize paraphrase[2].This method just considered the surface feature without semantic information of string so that it can not deal with the synonym in sen-tences. Vector Space Model for semantics is another popular method combine the vector of single word and its cosine similarity to recognize paraphrase[4,5].Vector Space Model employed bag-of-words model but ignored the syntactic relations to calculate the similarity of the two original sentences.
 pute the similarity of the dependency trees to detection paraphrase,this method neglected basic lexical similarity X  X  contribution to the task[6,7,8,9]. job.They trained a classifier using training data to classify unseen pairs para-phrase or not by examining their inherited features[10,11,12,18]. The point is to select proper restraint of the object sentences. Other researchers had put forward the opinion that co-reference resolution could be employed to solve paraphrase recognition to some extend. more practical work is needed to examine the theo-ry X  X  efficiency [3,13].
 onym detection for sentence pair. So the principal work is to seek appropriate characteristics and set fit constraints[19] on those characteristics to measure two sentences indicating the approximately same meaning or not. Generally compo-nents of sentence are from lexical and syntactic aspects,different lexical parts or syntactic parts do distinguishing contribution on the semantic point.Take this into account,we combine the POS part with syntactic relationships to meet the approval of the paraphrase standard.
 learning process to treat the lexical and syntactic features of the sentence to do paraphrase recognition and get our improvement. The learning process provide us the chance to know the internal rules of the paraphrase and the proper envi-ronment to adjust our method. Our method employ the advantages of machine learning and avoid the unilateral feature of surface string similarity and vector space model approaches. 3.1 Approach Overview As introduced forward,we use machine learning which employ the two different levels of a sentence, one is the lexical level ,the other the syntactic level, which correspond to the POS-phase and Syntactic-phase respectively, to do sentence level paraphrase recognition. Figure 1 describes the whole process of our ap-proach. The POS-phase: Do sentence POS-tag job to obtain the sentence lexical analysis ,then to calculate the object sentence pair X  X  similarity on lexical level .The main idea is based on the premise that paraphrase sentences consists of the same or similarity concepts, so the Noun part ,the Verb part and the Adjective part of sentence should reach a certain level of similarity.
 object sentence pair X  X  similarity on syntactic level .The core part of sentence is consisted of the subject ,object and the predict connects the above two.Similarity of this phase is to extract the subject ,object and the predict part of the object sentence pair and setting proper constraints on them to identify paraphrase. phase and the Syntactic-phase to recognize paraphrase.The model can give a similarity score of the sentence pair to compared with the threshold,which is obtained from the training data.Sentence pair will be identified as positive para-phrase if the final result over the threshold,otherwise the negative. 3.2 Calculating Lexical and Syntactic Similarity As described forward, the lexical level contribution on paraphrase recognition is based on POS-tagging result. The nouns shoulder the responsibility to express the static part of the sentence, the verbs part represent the action, while the adjective part describes how the verbs affects the nouns or the degree of the change. Those three parts take the dominate state to determine the similarity of the sentence pair.Furthermore, those three parts also have different degrees of effect on determine the paraphrase positive or not. So we first employ POS-tagging tools to obtain the part of speech result .Here, We take a sentence pair for example.
 Sentence pair(Sentence 1 , Sentence 2) Sentence 1 :The settling companies would also assign their possible claims against the underwriters to the investor plaintiffs, he added.
 Sentence 2 :Under the agreement, the settling companies will also assign their potential claims against the underwriters to the investors, he added. According to the POS-tagging analysis, we take Noun parts( X  X N X , X  X NP X , X  X NS X , X  X NPS X ), Verb parts( X  X B X , X  X BD X , X  X BG X , X  X BN X , X  X BP X , X  X BZ X ), and Adjective parts( X  X J X ) of the sentence pair and obtain the following Table 1. respectively with Formula (1),(2),(3),then adopt the Noun,Verb,Adjective parts of the sentence pair to calculate the POS similarity.
 1, N oun s 2 of sentence2. We employ WordNet[20] to search the similar word of the nouns to help calculate the common part N oun s 1 \ N oun s 2 ,then the N oun s 1 , N oun s 2 union to get the N oun s 1 [ N oun s 2 part.
  X  X BN X , X  X BP X , X  X BZ X .
 parts.
 la(4), , , are the coefficients of each part, here To normalization, the result value between 0 and 1 , + + = 1 .The number of each coefficient will represent the distinguishing power of itself to POS similarity. The value of these parameters will be detailed in the experiments part.
 cial fact about dependency grammars is that the subject and object part play the vital role relative to other parts in determining the meaning of the sentence. The subject part holds the responsibility to illustrate the kernel concept of the sentence, while the object part indicates the variation of the kernel concept. Those two parts consist the backbone of one sentence. Here ,we make use of the dependency relationship to weigh the similarity degree of a sentence pair. we first employ dependency parser to get the dependency relationships.Still take the forward sentence pair(Sentence 1 , Sentence 2) for example. The pair X  X  depen-dency relationships are shown in Table 2. From the dependency parser result ,we obtain the subject parts(nsubj, nsubjpass, xsubj) and object parts( dobj, iobj) as the kernel part of the sentence which expresses the semantic of the sentence. Consider the two parts X  role , we endow them the same proportion in compu-tation dependency similarity. The dependency similarity process is described as follows.Formula(5),(6),(7) give the detail calculation.
 contribution of the subject parts, and the Obj sim delegates the object parts. We employ the Resnik method[14] to measure the Obj sim and the Obj sim shown as follows.  X  on the notion of information content,it gives the similarity score of two con-cept C 1 ; C 2 , S ( C 1 , C 2 ) is the common ancestor nodes. words ( c ) represents the number of words in c branch, N is number of words of whole tree which the the c in. Here we use the upper formula to compute Subj sim and Obj sim . As referred forward, subject parts include nsubj, nsubjpass, xsubj part, and the information content of subj s 1 , subj s 2 is computed from the words they contain, subj s 1 is the subject parts of sentence s1, subj s 2 is that of s2. For example, nsubj(assign-6,companies-3), nsubj(added-19,he-18) composes the subj s 1 of s1 , nsubj(assign-10 , companies-7), nsubj(added-22,he-21 ) creates the subj s 2 . We get the average IC ( assign; assign ) ; IC ( companies; companies ) to express IC ( subj s 1 ; subj s 2 ). Similarly, the Obj sim is achieved by the same compute pro-cess with Subj sim . Object parts include iobj, dobj part.
 ity and the dependency similarity, which described by POS similarity and DEP similarity. So we get the combination of the two aspects to weigh a sentence pair X  X  similarity. The followed Formula(9) illustrates our combination. the parameter, we can get the best P R sim by adjust with train data. From the details of the method described forward ,we give the algorithm in Figure 2. In the experiment we employ Microsoft Research Paraphrase Recognition Cor-pus[15] to test our method. The MRPRC is made up with 5801 pair sentences which is divided into train data(4077 pair sentences) and test data(1726 pair sentences). The data is unbalanced in that 67words in POS-similarity part and DEP-similarity part both have been expanded with WordNet. The value of the , , is from 0 to 1 ,and is bigger than and . We use the train data to adjust the three parameters to achieve the state of art result. Figure 3 describes the variation of the P OS sim under different parameters combination, and we get the combination that = 0 : 45 , = 0 : 35, = 0 : 2 to achieve the best result of P OS sim . With the result of the P OS sim and Dep sim of the training data, we go on training the in P R sim to get the proper threshold to maximize the precision ,and set the = 0 : 40. Figure 4 shows  X  X  effect on precision. for the similarity score which maximized accuracy. Strict definition of paraphrase requires the object sentence pair have identical meanings,but the creator of the corpus[11] found that this standard will limit the paraphrase to identical string copies of the each other,so they relaxed the paraphrase from X  X ull bidirectional entailment X  to  X  X ostly bidirectional entailments X . The key message of the guide-lines for the annotators of the corpus stated that a paraphrase sentence pairs should describe the same event and contain the same important information .We finally adopted the training data with our method to get the appropriate threshold 0.30.The sentence pair would be recognized as true when the PR sim-ilarity of the test data over the threshold,otherwise the false . By setting the parameters,we adopt test data to get the experiment result. Here we use the general evaluation measure: accuracy, precision, recall, and F measure. Those are defined as follows.  X  and F P are false positives.
 shown in Table 3.Our method(POS+DEP) result lays on top line, and previous approach results are down the Table 3. The distinguish level similarity approach outperforms both baselines for all three of the similarity measures used in these experiments. It can also be seen that, our result outperforms the previously reported methods in terms of precision and the accuracy is on the average level. From the Table 3,we find that the accuracy part is lower than the recent previous method ,we suppose the followed factors may have negative effects on it.As we adopted Stanford POS Tagger to do part of speech work, and Stanford Parser to obtain the dependency relationships. The best resulting accuracy for the tagger is 96.86% overall, and 86.91% on previously unseen words [16],meanwhile the Parser owns the precision 86.32%[17].Because our work based on POS-tagging and Dependency parsing, those two procedures X  precision can definitely have effect on the performance of paraphrase recognition, in the future ,we will take those factors into account to improve our current method. This paper proposed a novel hierarchical model based on lexical and syntactic level to do paraphrase recognition. We used two aspects, the POS-tagging and syntactical structure to construct the model and obtain the effective results. The POS-tagging gives the lexical level semantic similarity and syntactical structure shows the work of dependency similarity on paraphrase recognition, each aspect use WordNet to do semantic expansion in finding similarity. The outcome of evaluation experiments shows that this method outperforms the previous simi-lar approaches. Our semantic level difference method in paraphrase recognition indicates the following viewpoints: (1)The Nouns ,Verbs and adjectives shoulder the primary responsibility in lexical level semantic level paraphrase recognition. Nouns describes the entities and verbs illustrate the variation of the entities, adjectives describe the degree of the variation.(2) The subject parts and the object parts in dependency structure of a sentence pair , play vital role in sen-tence pair paraphrase recognition.(3) Both lexical level semantic and syntactic structure have respective effect on the paraphrase recognition, we adopt linear combination of the two to do paraphrase recognition is valid.The two-hierarchical model method can be apply to the task such as sentence translation, query ex-pansion, question answering etc. Future work will be focus on deep mining of paraphrase constrains besides those put forward in this paper, and solutions will be researched to avoid the problem described in the experiment analysis part. This work was supported by the National Natural Science Foundation of China (No. 61003192), the Major Research Plan of National Natural Science Founda-tion of China (No. 90920005).

