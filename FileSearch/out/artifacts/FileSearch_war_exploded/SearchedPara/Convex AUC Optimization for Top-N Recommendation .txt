 In this paper, an effective collaborative filtering algorithm for top-N item recommendation with implicit feedback is proposed. The task of top-N item recommendation is to predict a ranking of items (movies, books, songs, or products in general) that can be of inter-est for a user based on earlier preferences of the user. We focus on implicit feedback where preferences are given in the form of bi-nary events/ratings. Differently from state-of-the-art methods, the method proposed is designed to optimize the AUC directly within a margin maximization paradigm. Specifically, this turns out in a simple constrained quadratic optimization problem, one for each user. Experiments performed on several benchmarks show that our method significantly outperforms state-of-the-art matrix factoriza-tion methods in terms of AUC of the obtained predictions. H.4 [ Information Systems Applications ]: Miscellaneous; H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Collaborative Filtering; Top-N Recommendation; Implicit Feed-back; AUC optimization
Collaborative filtering aims at improving customer experience in e-commerce applications. These techniques exploit the history of user interactions to improve future recommendations to users. Dif-ferent types of interactions can be stored and used. For example, a user can be asked a vote, a rate, or a degree of satisfaction for some of the items available. The system can also keep the history of user purchases autonomously, browsing activity of the users, etc. The former case is commonly called explicit feedback while the latter is usually referred to as implicit feedback .

In a collaborative recommender system we have a set U of n users, a set I of m items, and a user-item rating matrix R = { r ui }  X  R n  X  m representing, for any user and item, how much user u likes item i . In this paper, we assume implicit feedback and user u rated the item i , while a value r ui = 0 means not availability of information about whether user u likes item i .

There are two principal recognized approaches to collaborative filtering [1]. On one hand, model-based collaborative filtering, a.k.a. matrix factorization (MF) aims at constructing a model of the matrix R . There are several proposed methods of this type, in-cluding Bayesian models, clustering models, classification, and re-gression models. On the other side, there are memory-based (MB) collaborative filtering methods where similarities among users (or items) are computed on the basis of the training ratings and the pre-diction is made on the basis of these similarities.

As shown in this paper, the two approaches above can be seen in the same optimization framework where a matrix factorization has to be found. Specifically, in the memory based approaches, like user-based and item-based nearest neighbors, particular factor-izations are fixed a-priori and no actual train needs to be performed.
Despite MF is recognized to be the state-of-the-art technique in collaborative filtering, typically much better than MB techniques, MF has some drawbacks that made it impractical and unsuccessful sometimes. First of all, training the corresponding model is compu-tationally onerous and this fact is crucial when the size of the matrix R is very large. Second, since MF is typically modelled as a regres-sion problem, then it seems unsuitable for implicit feedback tasks and some modifications to the original technique are needed [4]. Third, MF techniques typically solve the associated non convex minimization problem by using gradient descent algorithms which do not guarantee the convergence to a global minimum and, it is well known, the rate of convergence is quite low when near to local minima. Finally, the high number of parameters to optimize, the sparsity of the rating matrix, and no apriori knowledge available can possibly lead to overfitting and strong validation and/or early-stopping of the stochastic gradient descent is often necessary.
In this paper we propose a solution lying midway between the two extreme approaches of MB and MF. In particular, we cast the problem into a instance ranking one and we propose a convex quadratic optimization framework for the optimization of AUC.
In the top-N recommendation setting, for each user u , there are available a subset I ( u )  X  I of items that have been rated by the user and the task is to predict a ranking of the items not yet rated such positions of the ranking. In this paper, we indicate as U ( i ) = { u  X  U | i  X  I ( u ) }  X  U the subset of users that have rated the item i in of users that have rated the item i in the test set. By construction, the sets are chosen such that I ( u )  X   X  I ( u ) =  X  . We also define m u = | I ( u ) | and m  X  u = m  X  m + u .

In the following we indicate by R = { r ui }  X  R n  X  m the initial rating matrix such that r ui = 1 whenever i  X  I ( u ) and r that  X  r ui = 1 whenever i  X   X  I ( u ) and  X  r ui = 0 otherwise.
In this section, we consider a general framework where many different approaches can be cast. Let the matrix W  X  R n  X  k be the embedding of users in a factor space of dimension k with users representations w u  X  R k as rows. Similarly, let the matrix X  X  R k  X  m be the embedding of items in the same factor space with items representations x i as columns. A recommendation is performed on the basis of the ranking induced by the following factorization: The factorization parameters are typically computed minimizing a functional where L ( R , WX ) is the training loss, that is a measure of the dis-crepancy between the initial rating matrix and the obtained approx-imated matrix, and R ( W , X ) is a regularization term.
Now, we review well known state-of-the-art methods in the frame-work above. We start with user-based NN and item-based NN pre-diction although in these cases there is a fixed embedding and no real training has to be performed.

In the user-based NN case the embedding is performed in R the space of users, according to: w
In this case, the embedding is performed in R m , the space of items, according to: x
In WR-MF, both the user embedding and the item embedding have to be trained. These embeddings are performed in a common space of dimension k , which is an external parameter, and the opti-mization problem consists of a regularized weighted squared loss
P ( R , W , X ) = X where c ui are apriori given weights for each (rated and unrated) item. The coefficients of positive feedback typically gets a greater value (see [6, 4]).

The method in [5] can be cast in our framework as well. In this case, the embedding is performed in item space ( k = m ). SLIM learns a sparse matrix X  X  R m  X  m by minimizing a least square loss LS ( R , XW ) such that x ij  X  0 , x ii = 0 . Specifically, the regularization term is R ( W , X ) =  X  2 | | X || 2 F +  X  || X || are two external parameters. The matrix W is fixed ( W = R ).
The method in [7] learns the two embeddings in a factor space of dimension k (external parameter). The optimization problem is obtained by a Bayesian interpretation of AUC maximization and it is defined by: P ( R , W , X ) = X where  X  ( ) is the sigmoid function and  X  w ,  X  x are external param-eters. The problem is clearly not convex and the training is per-formed by stochastic gradient descent.
As seen in the previous sections, typical approaches to collabo-rative filtering cast the problem of item recommendation as a reg-ularized regression problem [4, 6, 5]. This means that they try to fit the matrix R with a regularized function that should predict val-ues close to 1 for rated items and values close to 0 for unrated items. For the regression case, a natural choice of a loss to opti-mize is the least square loss. Even if this choice has been shown to be very good for explicit feedback, where the evaluation is usually performed with RMSE, this seems less suited to the implicit feed-back setting where different ranking-based evaluation measure, like AUC, mean average precision, etc., are preferred.

In this paper, we propose a different paradigm inspired to prefer-ence learning and instance ranking [3] by considering preferences on pairs of items of a user. In particular, we consider a user pre-ferring an item i over an item j ( i  X  u j ) whenever the user u has rated item i but we have not information about the user preference on item j . Moreover, we assume that users act independently, that is, the fact that a user has ranked or not an item gives no additional information about what other users do. With this hypothesis any user can be modeled independently.

In our model a user ranks items based on the usual scoring func-w u and x i are enforced to be unitary norm vectors. Note that, given this assumption, we have |  X  r ui | X  1 since |  X  r ui | X || w always holds.

In the following, we focus on a fixed item representation, namely the same used by user-based NN method, i.e. x i = r i / || r
Given a user, we define the margin for a item pair ( i, j ) such that i  X  u j , and we denote it by  X  ( i  X  u j ) , as in the following: N ote that  X  1  X   X  ( i  X  u j )  X  +1 holds for any pair of items. The function  X  ( i  X  u j ) well approximates the indicator function J  X  r ui &gt;  X  r uj K having value 1 when a pair is correctly ranked or 0 otherwise. In particular, we have that the margin is a non trivial lower bound of the indicator function: Following the same line as in [2] we consider for each user u the following game. Let P min (the nature), and P max (the player). On each round of the game, P max picks an hypothesis w u such that || w u || = 1 , and simultaneously P min picks a preference i  X  P max wants to maximize its pay-off defined as the achieved margin on the pair of items which, in our setting, is defined by  X  ( i  X 
Let now be given a mixed strategy for the P min player defined by two probability distributions:  X  + u , the probability of each posi-tive item to be selected, and  X   X  u the corresponding probabilities for negative items. We can assume these probabilities can be marginal-ized as the associated events are independent. In other words, the probability to pick the pair ( i  X  u j ) is simply given by  X  Hence, the value of the game, i.e. the expected margin obtained in a game, will be: When the player P min is free to choose any possible strategy, the following problem is obtained that determines the equilibrium of the game, that is where C ( u ) = {  X  |  X  i  X  0 , P i  X  I ( u )  X  i = 1 , P The expected margin can now be reformulated as follows: E where we set
Setting v u = XY u  X  u , then the w u maximizing the expected margin is simply defined by w  X  u = c v u , where c = || v that, since c depends on the user only, then the ranking of items induced by w  X  u is the same as the one induced by v u . Substituting back the obtained solution for w u , we obtain: Every element of the set C ( u ) represents two points, one in the con-vex hull of positive items, that is x + = P i  X  I ( u )  X  in the convex hull of negative items, that is x  X  = P j /  X  I ( u ) for any given user. It is possible to show that v u corresponds to the vector starting from x  X  and ending in x + , that is v u = x As shown above, the expected margin is proportional to the length of this vector.

Given the game defined above, we see now that the expectation of the margin is also a lower bound of the expected AUC obtained in the game for that user. In fact, given the probability distributions  X   X  C ( u ) we get:
As discussed in [2] for the classification case, the pure maxi-mization of the minimum margin is not necessarily the best choice. Especially in our case, noise is always present in the negative set of items. For this, we consider two quadratic regularization terms that give a bias towards uniform solutions for  X  , namely  X  ui experiments we will see that an imbalanced setting of these regu-larization parameters is crucial for the effectiveness of our method.
For each user, we define the following optimization problem with the aim to maximize the expected margin and the AUC lower bound: where Rearranging the terms in matrix form we obtain: where the diagonal matrix  X  is defined as follows: This problem is convex quadratic and can be optimized with any tool for convex optimization. For our experiments, we used Python and the CVXOPT package 1 .

Note that, when  X  p ,  X  n = +  X  , it is possible to show that the optimization problem has a closed form solution, that is The datasets used for the evaluation have been extracted from MovieLens1M (ML1M), NetFlixSmall (NFS), BookCrossing (BX). All these datasets correspond to multi-value ratings that we con-verted into binary ratings (rated/non-rated). In particular we used the following three datasets 2 : M . S. Andersen, J. Dahl, and L. Vandenberghe. CVXOPT: A Python package for convex optimization, version 1.1.6. Available at cvxopt.org, 2013. http://www.math.unipd.it/~aiolli/DATA/RECSYS14/ Table 1: AUC comparisons. Our method vs. WRMF (in parenthe-s is the number of users and items of the subset).  X  p \  X  n 1 10 100 1000 10000 1 000 0.87903 0.89685 0.89151 0.88777 0.88727
T able 2: ML1M AUC results varying the external parameters 1. ML1M . The ML1M 3 dataset is a subset of the MovieLens1M 2. NFS . The NFS dataset 4 is a subset of the NetFlixSmall movie-3. BX . The BX 5 dataset is a subset of the BookCrossing book-
To evaluate the performance of the proposed method, and com-pare it with other methods, 5-fold cross-validation has been em-ployed. We first compared all the state-of-the-art methods described in this paper (UserBased and ItemBased NN, WRMF, SLIM, and BPR). MyMediaLite 6 implementations of these methods has been used. WRMF performed similar to BPR and better than SLIM and it has been selected for direct comparison with our method (see Table 1). Note that this partially contradicts results presented in the original paper [5] where they were presented in terms of HR (leave-one-out). Worse performance of SLIM can be due to the fact that it is based on least-square/regression and does not weights dif-ferently positive (unambiguous) and negative (ambiguous) implicit h ttp://grouplens.org/datasets/movielens/ http://www.netflixprize.com/ http://www.informatik.uni-freiburg.de/~cziegler/BX/ http://mymedialite.net/  X  p \  X  n 1 10 100 1000 10000 1 000 0.85290 0.88358 0.89309 0.89327 0.89326  X  p \  X  n 1 10 100 1000 10000 1 000 0.69184 0.71897 0.73676 0.73931 0.73957 feedback. From the table we can note that our method outperforms the state-of-the-art method in terms of AUC. We observed the same trend when using other top-N measures (e.g. map@10).

Further analysis has been done to demonstrate the robustness of the proposed method with respect to the setting of external param-eters. In Tables 2,3,4, the results obtained with different settings show that  X  p  X  1 ,  X  n  X  1000 always give good results and this is a great advantage of our method with respect to other state-of-the-art methods that typically are more sensitive to the external parameter setting and often require heavy parameter tuning to work well.
Finally, we can note that the results of our method tend to get worse for big  X  p values or small  X  n values. In the case of  X  (unambiguous information parameter), smaller values allows the model to (safely) optimize the minimum margin in the training set. In the case of  X  n , small values tend to make the ambiguous infor-mation to be too relevant in the construction of the model and this introduces erroneous information in the final model estimate. On the other side, larger  X  n values tend to mitigate the negative ef-fect of ambiguous information on the constructed model and this explains why so high values of  X  n are preferable in our context. We presented an effective method for AUC optimization of top-N recommendation with implicit feedback. Future work will ex-tend the method to learn in a principled way the user and item em-beddings simultaneously. [1] F. Aiolli. Efficient top-n recommendation for very large scale [2] F. Aiolli, G. D. S. Martino, and A. Sperduti. A kernel method [3] F. Aiolli and A. Sperduti. A preference optimization based [4] Y. Hu, Y. Koren, and C. Volinsky. Collaborative filtering for [5] X. Ning and G. Karypis. Slim: Sparse linear methods for [6] R. Pan, Y. Zhou, B. Cao, N. N. Liu, R. Lukose, M. Scholz, and [7] S. Rendle, C. Freudenthaler, Z. Gantner, and
