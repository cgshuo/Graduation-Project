 Software is a ubiquitous component of our daily life. We of-ten depend on the correct working of software systems. Due to the difficulty and complexity of software systems, bugs and anomalies are prevalent. Bugs have caused billions of dollars loss, in addition to privacy and security threats. I n this work, we address software reliability issues by propos ing a novel method to classify software behaviors based on past history or runs. With the technique, it is possible to gener-alize past known errors and mistakes to capture failures and anomalies. Our technique first mines a set of discriminative features capturing repetitive series of events from progra m execution traces. It then performs feature selection to sel ect the best features for classification. These features are the n used to train a classifier to detect failures. Experiments an d case studies on traces of several benchmark software system s and a real-life concurrency bug from MySQL server show the utility of the technique in capturing failures and anomalie s. On average, our pattern-based classification technique out -performs the baseline approach by 24.68% in accuracy 1 . Categories and Subject Descriptors: H.2.8 [Database Management]: Database Applications  X  Data Mining General Terms: Algorithms, Experimentation  X  Copyright 2009 ACM 978-1-60558-495-9/09/06 ... $ 5.00.
In the information age, software is omnipresent. Many of our activities are dependent on the correct working of soft-ware systems. Ensuring the reliability of systems througho ut their lifetime is certainly a worthwhile goal.

If analyzed, software produces a massive amount of data corresponding to its various behaviors. Software behavior is the way a program executes. It corresponds to a path a program takes when executing from the start of the program till the end when it terminates. Some behaviors are desirabl e while a minority of others are not. Undesirable behaviors can correspond to bugs, malwares, intrusions, etc .. These undesirable behaviors are often referred to as failures.
Note that failures are often not easily identifiable. Some failures cause crashes ( e.g. , blue screen in windows, unhan-dled exception thrown, etc .) which are noticeable. How-ever, many others do not cause any  X  X isible X  effect. The software still runs to completion, while the computation re -sult is wrong, data stored in the database is erroneous, or some system security constraints are violated. These  X  X on-crashing X  failures are often hard to identify and one might only have a few known samples of these. These failures are worthy of special concerns since they are not easily identifi -able and might potentially pose serious security risks. US National Institute of Standards and Technology (NIST) re-ported that software bugs cost US economy 59.5 billions annually [25].

Can data mining help? In this paper, as a new step to ad-dress the reliability of software systems, we present a nove l classification approach to predict software behaviors. Bas ed on historical data of software and known failures, we con-struct a classifier to generalize the failures and to further detect other unknown failures. Generalizing past failures are useful in many situations as: programmers might miss other related failures in the program, programmers could make similar mistakes as those made before, many programmers could commit the same errors in using common or standard libraries, programs could be re-infected by the same mal-ware, etc .. This step of failure detection is the first step of the software quality assurance process. After a failure is detected, fault localization approaches, e.g. , [18], which assume that a set of relevant failures are known, can then be employed to localize the bug in the code. Failure detec-tion techniques can be applied periodically in the lifecycl e of a software system to improve the reliability of the sys-tem. Furthermore, the classifier can aid other software en-gineering tasks, for example, by serving as a test oracle for test-suite augmentation ( i.e. , adding new test cases to a test suite) [7].

A software behavior can be viewed as a series of events, where an event can correspond to the invocation of a method, the execution of a program statement, etc .. When recorded, this path or behavior is referred to as an execution trace. A set of these execution traces can be represented as a se-quence database which is the basis of our analysis.
Recently there are active interests in developing discrimi -native pattern-based classifiers [10, 9, 29], especially fo r un-structured or semi-structured data including itemsets and graphs. A set of patterns are mined and used to represent multi-dimensional discriminative features from a set of da ta. These features are then further selected and used to build ef -fective classifiers. On a related front, iterative pattern m in-ing, based on the semantics of several software modeling languages, has been proposed to extract frequent repetitiv e series of events from program execution traces as candidate software specifications [21]. Iterative pattern mining con -siders ordering among events in the traces. It further takes into account repeated occurrences of patterns both within a sequence and across multiple sequences to address loops and repetitions in an execution trace.

Our proposed classification framework works in a three-step process. As the first step, we propose a new scalable algorithm to mine closed unique iterative patterns from pro-gram traces of known normal and failing executions ( i.e. , failures). By capturing both the important temporal order and repetitions in a trace, iterative patterns are good fea-tures to characterize software behaviors and distinguish f ail-ing software traces from normal ones. Mining closed unique iterative patterns is much more scalable than mining the set of closed patterns. Feature selection is then applied to select highly discriminative patterns as classification fea-tures, which reveal important temporal information in soft -ware traces. A classifier is constructed based on the trainin g traces with such pattern-based feature representation. Th e classifier can be used to classify unknown program behaviors corresponding to the current or a future version of a soft-ware system as similar errors might potentially be made. The trained classifier can be updated several times during the life cycle of a software system with new known good and bad behaviors. It can be treated as a black box to predict and give warning signals in case the program is behaving in an undesirable way.

Our approach is not dependent on the availability of source code and precise documented specification. It follows a re-cent trend of dynamic analysis and specification mining [5, 21]. Dynamic analysis approaches analyze software execu-tion traces which can be collected by various instrumenta-tion methods, c.f. , [5, 20]. It is complementary to static analysis, i.e. , analysis of program code, and has the bene-fit of avoiding some problems faced by static analysis, e.g. , pointer aliasing and infeasible paths. Furthermore, dynam ic analysis is crucial since (1) many Commercials-Off-The-She lf (COTS) components and legacy systems come without any source code; and (2) many software systems are developed with poorly documented specifications [5].

To validate the utility of our proposed classifier, we per-formed controlled experiments and case studies on syntheti c and real datasets. For comparison, we implemented a base-line classification model based on single events as features . A simulator proposed in [19] is used to generate synthetic traces following some real-world models. Real traces are al so generated from programs belonging to the Siemens bench-mark [15]. Furthermore, we experimented with a real-life data race concurrency bug from MySQL server [1].

Experiments demonstrate the effectiveness of our proposed discriminative iterative pattern-based classification fo r soft-ware failure detection. Over all tested datasets, our itera tive pattern-based method is 24.68% more accurate on average than the baseline method. In the MySQL data race bug, a series of program statements are executed in a wrong or-der due to bad interleavings of threads. Iterative pattern-based features are able to characterize the MySQL data race, order-related bug with 100% classification accuracy and AUC = 1.0 while simple event-based features fail to classify this bug accurately (accuracy = 50%, AUC = 0.5).
Our proposed discriminative iterative pattern-based clas -sification is not only confined to the classification of soft-ware behaviors, it is also potentially applicable to a range of other problems including user profile and behavior predic-tion based on web log analysis, and protein sequence classi-fication based on motifs (patterns). In summary, our main contributions include the following:
The structure of this paper is as follows. In Section 2 we introduce preliminary concepts. Section 3 describes our pr o-posed closed unique iterative pattern mining algorithm. In Section 4, we describe the iterative pattern-based classifi ca-tion framework. Experimental evaluation and case studies are presented in Section 5. Section 6 discusses related work , followed by conclusions and future work in Section 7.
In this section, we describe preliminary details on softwar e execution traces and iterative patterns. We also present some notations and definitions. A software behavior can be viewed as a series of events. An event in turn corresponds to a unit behavior of inter-est. This can correspond to the execution of a statement, a method call or a basic block in a Control Flow Graph (CFG). When logged, a series of events corresponding to a software behavior forms an execution trace .

We denote a trace or sequence S as h e 1 , e 2 , . . . , e each e i is an event from an event set I . The set of input traces or sequence database under consideration is denoted by T DB .
 1  X  i 1 &lt; . . . &lt; i n  X  m where e 1 = f i 1 , , e relation is denoted as P 1  X  P 2 . P 2 is a super-sequence of P . We denote the concatenation of two patterns with the ++ operator.
Patterns which are found in software usually correspond to programming rules or usage patterns. Some software pat-terns are well documented: a well-known example is the set of commonly used software design patterns. The following are some examples of patterns in software documentations: 1. Resource Locking Protocol : h lock, unlock i 2. Java Transaction Architecture Protocol ( c.f. , [24]):
To mine frequent patterns in software traces, one needs to consider repetitions both within a sequence and across multiple sequences . Based on the above motivation of pat-terns in software, Lo et al. defined iterative patterns [21] by counting the frequency of a pattern within a sequence and across multiple sequences. Iterative pattern is defined based on the semantics of commonly used software modeling languages: Message Sequence Chart (MSC) (a standard of International Telecommunication Union (ITU)) [16] and its extension, Live Sequence Chart (LSC) [14].

Different from frequent itemset [3], iterative pattern take s into consideration temporal orders in a trace. The behavior  X  allocate followed by consume , followed by release  X  has a very different meaning from  X  release followed by consume , followed by allocate  X . In the latter, a resource is consumed before it is allocated. Different from traditional sequen-tial pattern mining [4], iterative pattern takes into accou nt repetitive behaviors within a trace. This is important due t o loops and repetitive behaviors observed by a program. Also different from episode mining [23], iterative pattern minin g considers a database of sequences rather than a single se-quence and removes the restriction that related events must occur close together in an episode. Important patterns like h lock, unlock i can have their events separated by an arbi-trary number of other events in the traces. This permits the pattern to be robust enough to characterize error cases that appear in different variants due to occurrences of many unrelated events.

The pattern instance definitioncould be expressed unam-biguously in Quantified Regular Expression (QRE). Quan-tified regular expression is very similar to standard regula r expression with  X ; X  as the concatenation operator,  X  X -] X  as the exclusion operator ( e.g. , [-P,S] means any event except P and S), and  X * X  as the standard Kleene star.
 Definition 2.1 ( Pattern Instance ). Given a pattern P h e 1 , e 2 , . . . , e n i , a consecutive series of events SB ( sb . . . , sb m ) in a sequence S in T DB is an instance of P iff it is of the following QRE expression
An instance is denoted compactly by a triple ( s idx , i start i end ) where s idx refers to the ID of a sequence S in the database while i start and i end refer to the starting point and ending point of a substring in S . By default, all indices start from 1.

As an example, consider a pattern P ( h A, B i ) and a data-base consisting of two sequences:
The set of instances of P denoted as Inst ( P ) is the set of triples { (1, 3, 5), (1, 6, 8), (2, 3, 5), (2, 8, 9) } . Note that multiple occurrences of an iterative pattern in the same se-quence are taken into account to reflect loops and repetition s in an execution trace. We treat the frequency of pattern in-stances within a sequence and that across multiple sequence s with an equal weight.

Definition 2.2 ( Frequent Iterative Pattern) . For a trace (sequence) dataset T DB , an iterative pattern P is frequent if its instances occur above a certain threshold of min sup in T DB , i.e., | Inst ( P, T DB ) |  X  min sup . The size of Inst ( P, T DB ) is referred to as the support of the pattern and is denoted as sup ( P ) .

Furthermore, an iterative pattern is closed if the followin g requirements stated in Definition 2.3 are satisfied.
Definition 2.3 ( Closed Iterative Pattern) . A fre-quent iterative pattern P is closed if there exists no super-sequence Q s.t.: 1. P and Q have the same support; 2. Every instance of P corresponds to a unique ins-
An instance of P ( seq P , start P , end P ) corresponds to an instance of Q ( seq Q , start Q , end Q ) iff seq P = seq start P  X  start Q and end P  X  end Q .
Iterative patterns capture higher-order features from ex-ecution traces. Traces correspond to the various program behaviors a software system exhibits. An event in a trace, corresponding to an execution of a method, a statement, or a building block, can be treated as a feature of the behav-iors. These features are not occurring in isolation. Rather , related features happening before or after a particular fea -ture dictate whether the feature corresponds to a correct or failing behavior. Difficult-to-find bugs are often caused by interactions between multiple features. Single events occ ur-ring separately might be permissible, however, when they occur together in a particular order or context, they might cause a problem to the system.

Iterative pattern mining not only captures higher-order features but also their frequencies. To distinguish softwa re behaviors, the frequency of an iterative pattern within a si n-gle trace is important. A program may work well for most cases, but fails on boundary cases. Errors might not oc-cur when a program behavior repeats one or two times, but might crop out when a program behavior is repeated many times. An example is recursion, where after a certain num-ber of recursions, system stack space might be exhausted. At times, a state-based system might run well when a behav-ior occurs once but becomes erroneous on a future repetition due to a wrong assignment made to the program state.
To reduce the number of iterative patterns, we tried to mine closed iterative patterns introduced in Definition 2.3 since they capture the frequency of all frequent iterative p at-terns without any loss of information. However, even with a closed definition, we may still generate a large number of iterative patterns, due to the combination between sin-gle events, especially if  X  X oise X  or unrelated events appea r often in the trace. The  X  X oise X  can correspond to utility related events, for example, appendToXML() , hashCode() , toString() method calls, etc. that appear very frequently but carry little meaning. Consider for example the follow-ing database:
Given min sup = 2, patterns h A, C i , h A, A, C i , h A, A, A, C i and h A, A, A, A, C i will be reported. These four patterns have different support values and hence each one is not sub-sumed by the other. If we mine closed patterns, all four patterns will be reported. If the traces are reasonably long and the  X  X oise X  event A appears very often, the pattern set is likely to explode due to random pairings with the  X  X oise X . To avoid this problem and further reduce the number of pat-terns, we propose to mine a compact set of closed patterns that are composed of unique events. We define closed unique patterns as follows.

Definition 3.1 ( Closed Unique Pattern) . A frequ-ent pattern P is a closed unique pattern if P contains no re-peated constituent events, and there exists no super-seque nce Q s.t.: 1. P and Q have the same support; 2. Every instance of P corresponds to a unique 3. Q contains no constituent events that repeat.
 As an example, consider a database with two sequences:
Assume min sup = 2. The pattern h A, B i is a closed unique pattern. It contains unique elements A and B , and there is no longer unique patterns having the same support as h A, B i . Consider another pattern h C, D i which is unique. This pattern is not closed, as there exists a longer pattern h C, E, D i which is also unique and the two patterns have corresponding instances.

Although we do not prove it formally, instances of closed unique patterns are guaranteed to be non-overlapping. In our experiments, the set of closed unique patterns is much less than the set of closed patterns, and it is much more efficient and scalable to mine closed unique patterns.
Algorithm 1 presents the pseudocode for mining closed unique patterns. The algorithm performs a depth-first trave r-sal of the search space to grow iterative patterns. It first computes frequent single events (Line 1). The frequent events are then grown in a depth-first fashion by performing recursive calls to the procedure GrowRec . At each recursive step, a check is performed to test whether the current pat-tern to-be-grown is closed and unique. If this is the case, we will output the current pattern (Line 6). If a pattern is not unique, all its extensions will not be unique either. Hence, we only grow the current pattern if it is composed of unique events (Line 7). NP t is a new pattern grown from P at concatenated with a unique event f (Line 9). We use the InfixScan pruning property in [21] to cut the search space of Algorithm 1 Mining Closed Unique Iterative Patterns Procedure: Mine Closed Unique Patterns Inputs: T DB : Trace database 1: Let FqEv = { p | ( | p | = 1)  X  ( sup ( p )  X  min sup ) } 2: for every e in FqEv 3: Call GrowRec ( e , T DB, min sup , F qEv ) Procedure GrowRec Inputs: P at : Pattern so far 4: Let FqLoc = { e  X  F qEv | sup ( P at ++ e )  X  min sup ) } 5: if ( P at is closed unique) 6: Output P at 7: if ( P at is unique) 8: for every f 6 X  P at in FqLoc 9: Let NPt = P at ++ f 10: if NPt doesn X  X  satisfy the InfixScan pruning 11: Call GrowRec( NP t , T DB , min sup , F qEv ) non-closed patterns. We only grow the pattern NPt if it does not satisfy the pruning condition (Lines 10-11). We abstrac t the support computation process from the algorithm; to ef-ficiently calculate support, we use the projected database operations defined in [21].

In Section 5, we show through experiments and case stud-ies that closed unique patterns are powerful enough to be utilized as discriminative features and achieve satisfact ory classification accuracy. We also show that Algorithm 1 is scalable and efficient even with low min sup thresholds on datasets, while closed iterative pattern mining is unable t o finish even at a high min sup due to an explosion in the number of patterns. To abbreviate, after this point, unless otherwise stated, closed patterns refer to closed unique it er-ative patterns.
Different from relational data, a program trace, which is composed of a sequence of single events, has no predefined feature vector. One could potentially use the set of events a s a feature vector, however the single events by themselves ar e not discriminative to capture the temporal order in a trace. To solve this problem, we generate the set of closed pat-terns by Algorithm 1 from a set of program execution traces containing failing and normal traces, and use them as classi -fication features. This is the core idea of our proposed itera -tive pattern-based classification approach. Existing stud ies which used frequent itemsets [9] and frequent subgraphs [10 , 29] for classifying transaction data and graphs have demon-strated the effectiveness of the frequent pattern-based cla s-sification approach. Furthermore, Cheng et al. [9] derived a frequency upper bound of discriminative measures such as information gain and Fisher score, showing a close re-lationship between frequency and discriminative measures . The theoretical results demonstrate that most discrimina-Algorithm 2 Feature Selection on Iterative Patterns Procedure: Feature selection Inputs: F : A set of frequent iterative patterns Output: F s : A selected set of iterative patterns 1: Sort iterative patterns in F in decreasing order of
Fisher score; 2: Start with the first pattern f 0 in F ; 3: while ( true ) 4: Find the next pattern f ; 5: if f covers at least one sequence in T DB 6: F s = F s  X  { f } ; 7: F = F  X  { f } ; 8: if a sequence S in T DB is covered  X  times 9: T DB = T DB  X  { S } ; 10: if all sequences are covered  X  times or F =  X  11: break; 12: return F s tive patterns likely fall into the high-quantile of frequen cy, i.e. , if we rank all iterative patterns according to their fre-quency, those discriminative patterns usually have a high rank. We name this phenomenon frequency association . Our proposed frequent iterative patterns will serve as discrim i-native features for distinguishing software behaviors.
The pattern-based classification method includes three major steps: iterative pattern mining which has been dis-cussed in Section 3, feature selection and model learning. In the following, we will examine the feature selection and model learning issues.
The set of closed iterative patterns mined from the set of failing and normal traces are considered as the initial set of features. Usually a large number of patterns will be generated from the mining step. Assume the initial feature set is F = { f 1 , f 2 , ..., f m } where each iterative pattern f represents a feature. Given a software trace S and a feature set F , x is the feature vector representation of S . Then, where sup ( f i , S ) is the support of f i in the trace S . In other words, we treat an iterative pattern f i as a feature and its occurrence frequency sup ( f i , S ) in a sequence S as the corresponding feature value.

To evaluate the discriminative power of a feature, the popularly used statistical measure of Fisher score [13] is adopted. This score is defined as: where n i is the number of data samples in class i ,  X  i is the average feature value in class i ,  X  i is the standard deviation of the feature values in class i , and  X  is the average feature value in the whole dataset. Assume x ij is the attribute value for the j th instance in class i , then  X  ,  X  i and  X  i are defined tively. When  X  is quite different from each  X  i , or when each  X  is very small, Fisher score becomes large. A feature will have a very large Fisher score if it has very similar values within the same class and very different values across differ-ent classes. In this case, this feature is very discriminati ve to differentiate instances from different classes. Therefor e, if the occurrence frequency of an iterative pattern in the fail ing traces is different from that in the normal traces, the pat-tern is discriminative with a large Fisher score. On the othe r hand, an iterative pattern with similar occurrence frequen cy in both failing and normal executions is not discriminative .
We then rank the set of iterative patterns in the descend-ing order of Fisher score. A feature selection algorithm is proposed in Algorithm 2 to filter indiscriminative patterns . The algorithm performs a sequential scan of the ranked iter-ative patterns. If a pattern covers some training instances , it will be selected. Any data instances covered by at least  X  features will be removed from further consideration. The algorithm terminates if either all instances are covered by the selected features or the feature set becomes empty.
Our proposed iterative pattern-based classification frame -work can be divided into three stages: 1. Mine closed unique iterative patterns from a software 2. Select discriminative iterative patterns from the pat-3. Train a classifier from the trace database T DB . In
The iterative pattern-based classification framework is de -scribed in Algorithm 3.
 Algorithm 3 Iterative Pattern-based Classification Procedure: Model construction Inputs: T DB : Trace database Output: Classifier : Software behavioral classifier 1: Let F = Mine Closed Unique Pat( T DB, min sup ); 2: Let F s = Feature Selection( F , T DB ,  X  ); 3: Transform T DB into the feature space of F s ; 4: Classifier = Train a classifier on T DB ; 5: return Classifier ;
Collected failing traces are usually much fewer than nor-mal traces. For example, from the print tokens system de-scribed in Section 5, the portion of traces with anomalies is less than 10%. The skewed class distribution causes two problems in the iterative pattern-based classification pro -cess. First, when directly mining from the skewed dataset with both failing and normal traces, iterative patterns pre va-lent in the normal execution traces will dominate the result set while iterative patterns unique in the failing traces ar e overwhelmed. As a consequence, the failing traces will be insufficiently represented by iterative pattern features. S ec-ond, skewed class distribution also poses great challenges in the model learning phase. Traditional inductive learn-ing methods would perform rather poorly on such software traces with skewed distribution, since the goal of those met h-ods is to minimize classification error rate. As a result, the failing traces tend to be ignored and every instance is pre-dicted as normal. In such cases, we could build a model with very high accuracy, but of very little use in practice.
To address the above two challenges caused by skewed class distribution, the failing traces in the training set a re duplicated multiple times until the class distribution be-comes balanced. Iterative pattern mining on the balanced training set will discover discriminative patterns from bo th classes. In addition, a classification model from the balanc ed training set avoids bias towards the majority class as well as improves recall on the minority class. Other techniques to handle the class imbalance issue are also applicable, in-cluding sampling [6] and ensemble [12]. But it is beyond the scope of this paper.
To validate the utility of our proposed classifier, we per-formed a set of controlled experiments on simulated trace data and case studies on real trace data. The experiments and case studies are designed to test whether the iterative pattern-based features are useful in detecting software fa il-ures. A characterization of failures based on how successfu l the pattern-based features are in training good classifiers is also discussed.
We test the performance of our proposed iterative pattern-based classification approach on nine datasets. For compar-ison, we design a baseline method, which uses individual events in a software trace as features. According to this definition, a sequence is represented based on a feature vec-tor of unique single events. The corresponding feature valu e is the number of times a particular event occurs in that se-quence. The baseline method simply measures the frequency distribution of single events in a sequence, but ignores the temporal order between them. For fair comparison, we ap-ply the same feature selection procedure based on Fisher score to the baseline method as well. We denote the base-line method as Evt and our iterative pattern-based method as Pat in the following tables. Minimum support in iter-ative pattern mining is set to 0 . 25 unless stated otherwise. Parameter  X  in Algorithm 2 is set to 5.

We use LIBSVM [8] with probability estimates as the classification model. Classification accuracy, defined as th e percentage of test cases correctly classified, is used as one measure. Due to the skewed class distribution, the measure AUC which is the area under a ROC curve is also used. ROC curve shows the trade-off between true positive rate and false positive rate. The best possible classifier would generate an optimal AUC value of 1 . 0.

For each dataset, we perform 5-fold cross validation. In each fold, the training set is first rebalanced by duplicat-ing the rare class if the class distribution is skewed. It is then used for iterative pattern mining, feature selection a nd model learning, while the test set with the original class distribution, is only used for prediction given a construct ed classifier. Average performance over 5-fold cross validati on is reported. Since both iterative pattern mining and fea-ture selection are performed for each fold separately (on th e training set in each fold), our evaluation guarantees that there is no information leak in classification.
For the controlled experiments, we generated simulated data, i.e. , synthetic program traces, using the simulator QUARK proposed in [19]. QUARK provides a controlled environment for experiments. Given an input software com-ponent model in the form of a probabilistic finite state au-tomaton, QUARK can generate traces that represent the model well following some coverage criteria. QUARK is also able to inject errors to the synthetic traces.

In this sub-section, we describe the models used to gener-ate traces using our software behavior simulator. We then describe the generated synthetic datasets and the experi-mental results. Due to the space limitation, we move the graphical representation of the software models to a techni -cal report [2].
 CVS Application. The first program we analyze is a Concurrent Versions System (CVS) application built on top of FTP library of Jakarta Commons Net [26]. This CVS functionality can be considered as a client of Jakarta Com-mons Net with a certain protocol pattern. The application is originally described in [19, 20].

There are six FTP interaction scenarios in our CVS im-plementation: initialization, multiple-file upload, down load, and deletion, multiple-directory creation and deletion. A ll scenarios begin by connecting and logging in to the FTP server. They end by logging off and disconnecting from the FTP server. Each invocation of a method of FTPClient may generate exceptions, especially FTPConnectionClosedException and IOException . Hence the code accessing the FTPClient methods needs to be enclosed in a try...catch...finally block. Every time such an exception happens, the pro-gram simply logs out and disconnects from the FTP server. This is a bug as the corresponding CVS scenarios ( e.g. , file upload, deletion, etc .) are not performed atomically and some method calls are omitted. It has been studied in [28] that programmers often make mistakes on the exceptional control flow path, i.e. , those involving error handler like
X11 Windowing Protocol. Next, we experimented with a model describing an XLib and XToolkit intrinsic li-brary usage protocol for X11 windowing system previously studied in [5, 20].

A common security concern is intrusion where valuable system resources are utilized by unauthorized system or party. An example of valuable system resources is privi-leged system call [27]. A system call can be  X  X angerous X  when used inappropriately. We model a potential intrusion by adding an extra transition corresponding to a misuse of a privileged system call to the X11 Windowing Protocol model. The models of X11 windowing protocol with and without errors are available in the technical report [2].
Three Types of Injected Bugs. In the first program, we injected omission bugs. Some method calls do not get called when they should have been, which is a common type of bug. For the second program, we injected additional events resulting in failures. This is also a fairly common ty pe of bug and could correspond to security concerns. The third type of bug is referred to as ordering bug where the order of events occurring is wrong. This bug occurs, for example, in the wrong usage of an Application Programming Inter-face (API). Furthermore, ordering bug has recently been reported as one common family of concurrency bug which is not addressed by existing bug detection algorithms [22]. To simulate this ordering bug on API, we simply reorder the traces from our model of CVS application.

Experiment Details and Results. We generated three sets of traces from the X11 and CVS models and attached labels to them. We compared our iterative pattern-based method with the single event-based method. The sizes of the datasets in terms of the number of traces are described in Table 1. Datasets  X  X 11 X  and  X  X VS Omission X  contain only addition and omission bugs respectively;  X  X VS Ordering X  contains ordering bugs by permuting events in the traces of a CVS model; and  X  X VS Mix X  contains a mixture of all three types of bugs. It is obvious that addition/omission bugs change the frequency distribution of single events in software traces while ordering bugs do not affect the fre-quency distribution but only change the order.

Table 1 also shows the classification accuracy, AUC and standard deviation on synthetic software traces using 5-fold cross validation. For these four datasets, our iterati ve pattern-based method selects 7, 16, 5 and 26 features, re-spectively. We observe that, by capturing the frequency distribution of single events, the single event-based meth od can effectively detect addition/omission bugs. Therefore, it achieves very high accuracy on the first two datasets. How-ever, in the latter two datasets, ordering bugs are injected by permutation of single events without affecting the fre-quency distribution, thus the single event-based method fa ils in identifying the ordering bugs. As a result, in  X  X VS Or-dering X , all test traces are predicted as normal traces with an accuracy of 50% and AUC of 0 . 50. On the other hand, the iterative pattern-based method works well on all three types of addition, omission and ordering bugs.
To further evaluate our classification framework for soft-ware failure detection, we analyze different programs from Siemens Test Suite [15]. The test suite was originally used for research in test coverage adequacy and was developed by Siemens Corporation Research. We use the variant pro-vided at www.cc.gatech.edu/aristotle/Tools/subjects/. The test suite contains several programs. Each program con-tains many different versions where each version has one bug. These bugs comprise a wide array of realistic bugs.
We take four largest programs in the test suite. They are referred to as: replace , schedule , print tokens and tot info . There are two variants of schedule and print tokens pro-grams. For this case study, we choose the first variant of each program. More information of the test suite is avail-able in [15, 18].

To simulate real life situation where there are many bugs occurring together, we inject 3 bugs to each program and add 3 additional simulated ordering bugs to the execution traces. Running the instrumented program with an input produces a trace. We collect a set of traces by running a set of test cases provided by Siemens Test Suite. The test suite also allows us to compute the actual correct output. By comparing the output of the program with the correct actual output we can see if the program runs correctly or not. We label a trace as 0 if it corresponds to a correct execution or 1 if it corresponds to a failing execution. We run the test cases on each of the buggy programs, collect traces, and label them accordingly.

For replace , schedule , print tokens and tot info programs we run 5548, 2637, 4092 and 1067 test cases respectively. Some test cases cause the program to crash, and others pro-duce the same trace as another test case. We remove the test cases that cause the program to crash and remove dupli-cate traces. There is no need to build a classifier for crashes as the crash itself is a sure evidence of a trace being faulty. Non-crashing failures are hard to identify and are the focus of our study. We also add some extra traces containing sim-ulated ordering errors. The description of the datasets aft er the above processing is shown in Table 2.

From the four programs, we find that bug happens in only a minority of traces. In the first two datasets ( tot info and schedule ), we introduce more simulated ordering errors to get balanced trace datasets. In the last two datasets ( print tokens and replace ), we collect unbalanced datasets. We handle the skewedness issue by duplicating the failing traces multiple times to get a balanced training set in each fold, as described in Section 4.3. The numbers in Table 2 correspond to the number of traces before the duplication is performed.

We also analyze a data race concurrency bug from MySQL server [1]. A data race bug causes wrong ordering of state-ment executions. The bug causes a corrupted mysqlbinlog . Since the log is used to restore databases, inconsistency ca n result from the bug. This bug is rated as serious in MySQL bug database. We collected 102 traces, where 51 correspond to the case when the bug is manifested ( i.e. , corrupted binlog and another 51 correspond to the case when the bug is not manifested ( i.e. , binlog is not corrupted).

Table 2 shows the classification accuracy, AUC and stan-dard deviation on the real software traces. For these five datasets, our iterative pattern-based method selects 65, 3 8, 49, 27 and 11 features, respectively. It is very clear that, according to both accuracy and AUC, the iterative pattern-based method outperforms the single event-based method significantly by preserving the important temporal informa -tion in the software traces. We find that our method works well on both balanced and unbalanced datasets (by applying the rebalance technique). For the Siemens dataset, we find that the lengths of patterns range between 1 and 10 with an average of 4 . 29. For the MySQL dataset, the lengths of pat-terns vary between 4 and 15 with an average of 9.63. The pattern set provides a rich combination of single features which contributes to the classification accuracy in classif y-ing correct and failing traces. The results show that our method outperforms by up to 50% accuracy on the real-life MySQL bug that involves only wrong ordering of statement executions.
In this sub-section, we describe an extended set of ex-periments to see the effect of varying minimum support on classification accuracy. We also investigate the scalabili ty of our iterative pattern mining algorithm (which takes up the bulk of the time required for classification) on a range of support values and sizes of the trace databases.
Table 3 shows the classification performance with stan-dard deviation when min sup is varied in the range of [0 . 05 , 0 . 50] to mine the iterative patterns on traces of the replace program. As we increase min sup , we get fewer number of iterative patterns and may miss some highly discriminative ones. As a result, the classification performance slightly d e-grades, but still maintains a good performance in general.
Figure 1 (a) shows the iterative pattern mining time on
Table 3: Classification Performance vs. min sup (a) Mining Time vs. min sup traces of the replace program as we vary min sup 2 . We can observe from the figure that the run time of iterative pat-tern mining does not increase significantly as we lower down min sup . One important factor that helps in ensuring scala-bility of our mining technique is our new definition of closed unique patterns. With the new definition, the number of mined patterns is less and the occurrences of  X  X oise X  events in the data do not cause the number of patterns to explode. Still with this reduced pattern set, the patterns are pow-erful enough to serve as classification features resulting i n good classification accuracy. For comparison, we also tried mining closed iterative patterns which are allowed to have non-unique constituent events. Unfortunately, closed pat -tern mining throws an out-of-memory exception after run-ning for more than 4 hours and consumes more than 1.7GB of memory even on a support level of 100% 2 , 3 . This shows the need for and scalability of mining closed unique pattern s.
Figure 1 (b) shows the scalability test on iterative pattern mining when we increase the size of input trace database T DB 2 . We increase the number of traces of the replace program and run the mining algorithm. As shown in the figure, the mining algorithm scales linearly with the size of the sequence database.
Dickinson et al. detected program failures by performing hierarchical clustering on program traces [11]. They first obtain a set of profiles of interesting events ( e.g. , branch decision, method calls) in program traces. The traces are then grouped into a pre-defined set of clusters in a hier-archical agglomerative fashion. The process stops when a desired number of clusters are found. Several distance met-rics are used to measure similarity between two program traces. They found that small clusters are candidates of failures. Their approach considers only frequency of singl e events but not the ordering information of event executions . It also remains a question whether the generated clusters can cleanly separate correct behaviors from incorrect ones .
Bowring et al. proposed an active learning approach to build a classifier of program behaviors [7]. The input to their approach is a frequency profile of single events in the trace. They learn two sets of first-order Markov models, where each set characterizes correct and incorrect behavio rs separately. A first-order Markov model ( c.f. , [17]) is a state-based transition system, where the probability of the next state at time t +1 is determined by the current state at time t . Different from this work, our iterative patterns capture more than  X  X irst order X  relationship, i.e. , it can relate that a state frequently leads to another state which is k distance away, where k can be arbitrarily large.

Studies on fault localization ( e.g. , [18]) are also related to fault detection in programs. They usually work in two phases. In the first phase, a set of labeled traces needs to be provided. Each input trace is labeled to indicate whether it is correct or erroneous. In the second phase, possible error locations are computed. Since it is expensive to assig n labels to execution traces manually [11], our classificatio n approach can complement studies in fault localization  X  a classifier constructed from a small set of labeled traces can be used to label a much larger set of unlabeled traces which, after being labeled, are then used for fault localization.
There are several recent studies on frequent pattern-based classification which use frequent itemsets [9] and frequent connected subgraphs [10, 29] for classifying transaction a nd graph data. In this work, we enrich the past studies by proposing a pattern-based classification utilizing iterat ive patterns. A program trace can alternatively be  X  X oiled X  to form a behavior graph [18]. In this work, we prefer to use iterative patterns as features as they capture repetitions of patterns within a trace . This information is lost when a trace is  X  X oiled X  to form a behavior graph. Also, different from nodes in a connected subgraph, adjacent events in an itera-tive pattern not necessarily occur directly after another i n a sequence since gaps are allowed in mining iterative patterns. This permits a degree of flexibility in capturing discrimina -tive patterns that appear in several variants with unrelate d events appearing in between.

As to iterative pattern mining, there are many related work including sequential pattern mining [4] and episode mining [23]. Different from those studies, iterative pat-terns are patterns that repeat a substantial number of times both within a sequence and across multiple sequences . Con-stituent events of an iterative pattern can be separated by an arbitrary number of unrelated events in its instances in the execution traces  X  a pattern is not necessarily an episod e occurring close together. A detailed discussion is availab le in [21]. There are other studies mining repetitive series of events, however since they are not used for pattern based classification, we omit references to them.
In this paper, we proposed a novel approach to mine closed unique iterative patterns for classifying sequenti al data, through an example of software trace analysis for fail -ure detection. We address the issue of automating testing process by training a classifier based on discriminative ite ra-tive patterns and using it to find failures in program traces. A three-step framework is employed including feature gener -ation using closed unique iterative pattern mining, featur e selection based on Fisher score, and pattern-based model learning.

Experimental study has been performed on synthetic and real datasets. For the synthetic datasets, we generate trac es from various models of existing systems and inject various types of errors: addition, omission and ordering. We also in -vestigate standard programs from the Siemens benchmark and a real-life data race concurrency bug from MySQL. The iterative pattern-based classifier outperforms the sin gle event-based method on all the datasets. On average, classi-fication accuracy is improved by 24 . 68%. Furthermore, we are able to classify the real-life data race failures accura tely while the baseline approach is not.

As a future work, we are looking into the possibility of direct mining of discriminative iterative patterns, appli ca-tions of the classifier to other domains, and pipelining the proposed approach to existing fault localization techniqu es to enable both failure detection and fault localization.
