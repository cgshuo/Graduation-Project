 Social networks have become a major focus of research in recent years, initially directed towards static networks but increasingly, towards dynamic ones. In this paper, we in-vestigate how different pre-processing decisions and differ-ent network forces such as selection and influence affect the modeling of dynamic networks. We also present empirical justification for some of the modeling assumptions made in dynamic network analysis (e.g., first-order Markovian as-sumption) and develop metrics to measure the alignment between links and attributes under different strategies of using the historical network data. We also demonstrate the effect of attribute drift, that is, the importance of individual attributes in forming links change over time.
 H.2.8 [ Information Systems ]: Database ManagementAp-plications Data Mining Algorithms,Measurement networks, data mining, dynamic networks
Social networking is becoming an increasingly active re-search topic due to its broad appeal to a wide range of disci-plines, including physics, social sciences, statistics, and com-puter science. Much of the early work has focused only on static networks whereas real social networks are often dy-namic, with nodes changing their attributes and links while reacting to the changes in other nodes. For example, in an on-line social network such as FaceBook, the nodes (mem-bers) change their attributes (e.g. favorite movies), make new links (friends), and join new groups. Dynamic net-works pose a significant challenge for network analysts not only because of the modeling complexity, but also the sensi-tivity of the modeling results on the preprocessing decisions made during the construction of the network.

Our objective in this paper is to study the nature of dy-namic networks to better understand the consequences that arise from pre-processing decisions and from other network forces. Specifically, we studied:
As part of the study we also present several metrics to measure the forces of selection and influence from dynamic network data. Although these processes have been exten-sively studied in the past [2, 5, 19], our metrics are unique in that they allow us to measure the selection and influence based on changes in the adjacency and data matrices of the dynamic network data.

To measure the relationship between the links and at-tributes in a dynamic network, we apply a metric called the alignment distance, which was previously developed in our work [22] for link prediction in static networks. In that work, we presented a framework that establishes the align-ment between links and attributes using a weighted simi-larity between the node pairs. In a network with perfect alignment, nodes that are linked to one another will have maximum attribute similarity and those that are not linked will be minimally similar. In this work, we extended the metric to allow for measurements of temporal data.
To study the above issues we ran experiments on four dy-namic network data sets. Our results provide insights into the nature of dynamic networks as well as the effects that pre-processing decisions have on the relationship between attributes and links. We also demonstrate the effect of at-tribute drift, that is, the importance of individual attributes in forming links change over time. In the next section we provide some background on the recent work in dynamic and static networks. Section 4 presents the methods used in our study. The data sets are described in Section 5 and the re-sults of the experiments are explained in Section 6. Finally, we present concluding remarks in Section 7.
A number of models have been proposed to explain the structure and growth of networks. This resulted in a num-ber of network characterizations such as regular, random [6], small world [29], scale-free [3], cellular [1, 7], core-periphery[1, 4] and forest fire [14]. All of these models treat link forma-tion as a function of the link structure of the graph and ignore the effects of attributes.

Several generative models have been proposed for net-works that do incorporate both the link structure and the attributes. Taskar et al., developed a relational Markov net-work approach to infer missing node class [25] or links [26]. Neville and Jensen X  X  [17] latent group model similarly learns conditional probabilities for attributes, links and groups. These models are designed specifically for static networks. The exponential random graph model is another well-known network modeling approach [28, 24]. These models are de-fined using network statistics such as transitivity and reci-procity. None of these studies consider the effect of prepro-cessing decisions during network construction.

Link prediction in a network is another active area of study. Liben-Nowell and Kleinberg [15] presented a model using only features derived from link topology. Al Hasan, et al. [10], O X  X adadhain, et al. [18], and Popescul, et al. [20] proposed applying classification methods for link prediction using attributes and link-based features. Lahiri and Berger-Wolf [13] use frequent subgraphs to predict when a particular event (or link) will take place. Finally, Rattigan and Jensen [21] described the class skew problem with link prediction and suggested an anomaly detection-type approach to pre-dicting interesting links. All of the attribute-based models described above are designed only for static networks.
Finally, there has been recent studies specifically targeting temporal network data. Hanneke and Xing [9] proposed an exponential random graph model that uses network statis-tics over multiple time periods. Kempe et al. [12] consider networks with explicit time-ordering of their edges. The paper by Guestrin et al. [8] uses a first-order Markov as-sumption to model a dynamic network. Sharan and Neville [23] uses kernels to summarize dynamic networks and then applies a relational classifier on the summarized graph.
We consider a dynamic network to be a series of periodic snapshots of the network. Each snapshot is a static network of nodes and links, where the nodes have associated descrip-tive attributes. We begin by defining our notation, first for static networks and then for dynamic ones.

Consider a physical or social network represented as a graph G = ( V, E ), where V = { 1 , 2 , ..., | V |} is the set of nodes and E  X  V  X  V is the set of links. Let A = [ a ij ] note an adjacency matrix representation of the graph, where n = | V | , a ij = 1 if there is a link between nodes i and j and zero otherwise. In this study, we assume the network contains undirected links, which means A is a symmetric non-negative matrix. Also let X = [ x ik ] n  X  d denote its cor-responding data matrix, where d is the number of attributes and x ik is the k th attribute value for node i . Assume that the row vectors in X have been properly normalized (to unit length) or standardized (to have zero mean and vari-ance equals to one) so that the matrix product XX T (where X
T is the transpose of X ) is equivalent to either the cosine similarity or correlation between every pair of nodes.
To represent dynamic networks, we consider  X  snapshots of the network at discrete time steps. The network at time t , would be represented by the adjacency matrix A ( t ) and the data matrix X ( t ) . We let x ( t ) ik be k th attribute for node i at time t and x ( t ) i be the row vector of attribute values for the attribute vectors of nodes i and j at time t .
Selection (also called homophily) and influence (also called assimilation) are concepts from the area of social network analysis that represent forces within a social network [5]. Selection is the process where people choose friends with whom they have a lot in common, while influence is the process where people change their attributes to match those of their friends.

Most literature defined these concepts with respect to a specific node (or actor)-pair and a specific attribute [16, 19]. For example, it can be said that Eric exhibited selection because he befriended Jill who enjoys the same sports ac-tivities as Eric. In contrast, Crandall, et al. [5] defined these concepts in terms of the overall (cosine) similarity for all at-tributes. They also studied the network evolution in terms of its recorded activities instead of the discrete snapshots of its adjacency and data matrices. They examined the feedback effect between social selection and influence, in which social interactions are initially formed between similar nodes, but the interaction would further increase its similarity.
For many network data sets, it is not possible to follow the progression of changes in attribute values since the network data is gathered only at periodic intervals. As in [5] we measure similarity using the cosine metric, but we evaluate the effect of selection and influence based on changes in the adjacency and data matrices.
 Definition 1. The selection process in a dynamic network where the denominator is the conditional probability an un-linked pair will become linked and the numerator is the same probability for unlinked pairs whose similarity exceeds the threshold  X  . Values greater than one indicate the presence of selection. Definition 2. The influence process in a dynamic network influence = where the numerator is the conditional probability that sim-ilarity increases from time t  X  1 to t between two nodes that became linked at time t and the denominator is the prob-ability that the similarity increases from time t  X  1 to t between two nodes that were not linked at time t  X  1. As with selection, values greater than one indicate the presence of influence.
A static network can be easily formed by accumulating the links and attribute information for all the nodes since the start of the data collection period. Building a dynamic network is more challenging because an analyst must make many preprocessing decisions. To our knowledge, the ef-fects of these decisions has not yet been extensively studied. In this paper, we examine the impact of such decisions on subsequent network analysis
First, the effect of accumulating the link or attribute data over time is examined. Accumulating link data means any links established in an earlier snapshot will remain in the future snapshots of the network even though the node pairs may not interact with each other. The same applies to ac-cumulating attribute data. There may be times when the analyst can choose whether or not to accumulate, but at other times, the data may be accumulated by default. For example, consider an online social network where members are initially asked to enter information such as musical pref-erences during registration time but often do not bother to change them. In this scenario, the attributes can be thought of as accumulated by default.

Second, in the adaptive modeling of dynamic networks, a predictive model has to consider the number of previous snapshots to use for making its future prediction. Should the model utilize only the recent data or should it incor-porate older history? For efficiency reasons, some models would limit the number of previous snapshots to consider. We show in our results that employing a first-order Markov assumption is often sufficient for many of our data sets.
In addition to studying these decisions, we also examine the effect of selection and influence in network data using the measures defined in the previous section. Although these processes have been studied previously, our measures are unique in that they allow us to measure the selection and influence in snapshot data using a single metric rather than producing a separate value for each attribute. This is useful for networks with thousands of attributes.

We also measure the amount of attribute drift in the dy-namic networks. When predicting the formation of links us-ing the attributes, some attributes will be more predictive. As the network changes over time, the predictive power of attributes also changes, which we refer to as attribute drift. The presence of attribute drift along with evidence of the validity of the Markov assumptions leads to the conclusion that attribute drift is at least partly responsible to the di-minished value of historical data.
In our earlier work [22], we presented a matrix alignment framework that uses a set of weights to determine the im-portant attributes for establishing links between nodes. Es-sentially, the goal is to learn a set of weights ~w = { w that minimizes the objective function where the diagonal elements of W correspond to ~w and k X k denote the Frobenius norm. We consider the expression k A  X  XWX T k 2 F as a distance measure between the links and the attribute similarity between node pairs. Smaller values of this alignment distance imply a higher degree of align-ment between the attributes and links. Our research has shown that, in general, smaller alignment distances imply more accurate link prediction (given that the link predic-tion technique uses attributes). Next we modify the align-ment distance to allow for measurements of temporal data by substituting adjacency and data matrices from different time periods.
To test the value of using the historical data we need to modify the objective function above to incorporate more than a single snapshot. Specifically, we chose to use mul-tiple time periods to learn a single set of weights as follows: where  X  is the number of network snapshots available. To avoid overfitting, a regularization technique is employed by adding a penalty term  X  k W  X  I k 2 F to the objective function:
L = This will coerce the weight vector ~w to ones for high values of  X  , which is equivalent to assigning equal importance to all the attributes. To solve for the weights the first step is to take the partial derivatives with respect to W :  X  X   X  X  Setting the derivative to zero and rearrange the terms, we obtain a system of linear equations, Z ~w = b , by letting b Z Z
The weight vector ~w can be computed using Gaussian elimination or the conjugate gradient method.
In the experiments section, a number of different distance metrics and weights are used. To make those discussions clearer we give a few definitions here. The general align-ment distance is the same as the objective function given in Equation (2). To compute the distance using matrices from different timestamps we define the following alignment functions: dist 0 ( t ) measures the alignment distance between the links and attribute similarity for a snapshot t . Since dist +1 lates the alignment distance between the links at time t + 1 and the attributes at time t , it provides a measure of the future linking behavior of nodes. In contrast, dist  X  1 is re-flective of changes to future attribute values.

We also adopt the following notation to indicate the dif-ferent ways in which the weights are calculated:
Once the vector ~w has been learned, the expression x relative measure of the likelihood of nodes i and j forming a link in time step t + 1 . As in our previous work [22], pre-dictions are made using a pair of quadratic discriminators, g and g 1 . g 0 is trained on the weighted similarity scores for each pair of nodes in the training set that are not linked, and g 1 is trained on the weighted scores for linked training set pairs. Each pair in the test set is predicted to be a link/non-link depending on which discriminator g 1 / g 0 is higher using the score calculated for the pair.
The data sets used in this paper are described below. In each case the raw data was processed to create binary at-tributes and in some cases to limit the number of nodes to the most active ones.

The teen data set was built from the teenage friends and lifestyle study taken from the Siena [27] website. The study followed changes in the friendship relations of students in the West of Scotland starting in 1995, recording information about their drug, smoking, and drinking habits, their sport participation and changes in their families.

The wiki data is created from articles contributed by vol-unteered editors on the Wikipedia website. Editors also maintain their own pages where they can leave messages for other editors to discuss differences of opinions and other subjects. We downloaded the English version and processed the data to build a network using editors as nodes and pages that they edited as attributes. Links were established based on editors leaving messages on other X  X  pages. Of the hun-dreds of thousands of editors and millions of web pages, we extracted the 3900 most active editors (those who edited more than 24 pages) and the 5,027 most edited pages (those with over 90 edits).
  X  3 8 8 8 8 25 d 5 5027 613 613 613 18 n (1) 50 445 473 336 57 130 | E (1) | 158 864 1309 996 137 308 dist 0 /n (1) 3.13 1.08 0.83 1.00 0.23 2.10 n (  X  ) 50 2344 1483 1410 878 129 | E (  X  ) | 167 7684 5403 5974 3074 397 dist 0 /n (  X  ) 3.31 2.60 1.87 1.99 1.48 2.05 | XX T  X  A | 2 F 0.7 0.06 0.84 0.88 0.87 0.5 | XX T  X  A c | 2 F 0.56 0.01 0.03 0.04 0.04 0.29
The DBLP bibliography website catalogs the publishing activity of computer science researchers. From the data, a network can be built using the authors as nodes and their coauthor relationships as links. We created three separate networks using conferences associated with database (dblp1), artificial intelligence (dblp2) and computer networks (dblp3). For attributes, we used selected keywords from the paper ti-tles. The eight time periods were based on yearly scans from 1997 to 2004.

The levant data set was constructed from data down-loaded from the KEDS website [11]. It contains informa-tion gathered from twenty five years of Reuters news stories relating to countries located in the Levant (eastern Mediter-ranean area). The actors in the Levant set represent coun-tries, individuals and organizations related by one of many different relationship types. The relationships are broadly grouped into twenty different types, such as provide aid , en-gage in material cooperation and threaten . We constructed an adversarial network by using two types of relationships  X  fight and attack with WMD  X  to form the links. Linked nodes are those who are in some way enemies of each other. The other 18 relationship types are used as node attributes based on participation. For example, a node that cooper-ates materially with at least one other node is assigned the attribute  X  X ooperates materially X . In this adversarial net-work, link prediction is the task of inferring which nodes will attack each other given their other activities.
The diversity of the dynamic networks can be seen from the statistics listed in Table 1. In terms of their sizes teen and levant have fewer numbers of both nodes and attributes. Besides being larger sets, wiki and dblp also have more at-tributes than nodes. Next we examine the stability by mea-suring the changes in the network. The teen set starts and ends with the same number of nodes with a slight increase in the number of links. The levant set gains and loses nodes with fairly active changes in the links. The dblp sets have steady growth in the number of nodes and links while the wiki set experiences dramatic growth.

Another way to compare the sets is by alignment. Notice the average alignment ( dist 0 /n ) for both the first and last snapshot. The teen set is has the highest alignment distance while dblp has the lowest. Also, the alignment changes little for teen and levant but more so for dblp and wiki. The poor alignment for teen can be explained by the fact that there are too few attributes to explain the friendship behavior. For dblp, because the attributes are created from words in paper titles and the links are built from the co-authorship relations of the same papers , it is not surprising that the alignment would be good. However, the alignment gets worse over time for dblp and wiki due to the added complexity of the network as more nodes and links are introduced.

Another characteristic to consider is the differences in the similarity between linked and unlinked nodes. This can be done using the squared norm of Hadamard product of the similarity and the adjacency matrix | XX T  X  A | 2 F and the complement of the adjacency matrix | XX T  X  A c | . In a net-work where the attributes are very predictive of the links we would expect to see a large difference in these two statistics. Looking at the last two rows of the table, it can be seen that the similarities for teen and dblp are high for linked nodes while levant is slightly lower and wiki is quite low. The difference between the linked and unlinked is quite low for teen and levant, medium for wiki and dramatically high for dblp. Again for dblp, the difference is explained by the way the network is built. In the wiki set, the large number of attributes results in an overall low similarity even between linked nodes.
In this section we present experiments that explore the effects of pre-processing decisions and network forces such as selection and influence on network analysis. Each data set is composed of several snapshots of static network states that include an adjacency and a data matrix. For the teen and levant sets, the data was already processed into yearly chunks. Each paper in the dblp data set is labeled with the year of publication, so it was natural to break them into yearly snapshots. The wikipedia data has date stamps asso-ciated with each action so any size interval could be chosen for the snapshots. For Sections 6.1 through 6.5, we used a window size of six months. In Section 6.6, the experiments are repeated using a one month window size.
Recall that selection is the process of forming links be-tween pairs of nodes with common attributes and that in-fluence is the process of changing one X  X  attributes to be more like one X  X  linked nodes. The purpose of this experiment is to find out the extent of selection and influence in the data sets and how these forces compare to the measurements of dist +1 and dist  X  1 . Using the formulas given in Section 4, we calculated these metrics for all the data sets. For selection we used  X  = 0 . 9.

The results in Figure 1 show bars for the measurements of selection and influence and lines for the values of dist +1 dist  X  1 . The bars are scaled to the left axis and the lines are scaled to the right axis. The charts show the values calculated between two snapshots so the bars labeled 2 are for the period between snapshots 1 and 2.

For our measures of selection and influence, values above 1 are evidence that these forces are present. In the wiki set, the presence of both selection and influence are very strong at first, taper off dramatically in the middle periods but then rebound slightly towards the end. To see why the statistics dropped so dramatically, recall from Table 1 that there was a very large growth in the number of nodes. Our conjecture is that in the early years of Wikipedia there were fewer editors and more core pages. As the site matured, larger numbers of editors worked on more specialized pages. So it became less likely that two editors that became linked had many common attributes and that two linked editors would continue to work on similar pages.

In dblp, there is strong evidence for influence but much weaker evidence for selection. To explain this, recall that the links are formed by co-authorship and the title key-words provide the attributes. In many cases, two authors with similar keywords still have a low probability of collabo-rating which explains the low selection. On the other hand, linked authors often continue to collaborate increasing their similarity leading to a high influence score.

In levant, there is strong evidence for selection but weaker evidence for influence. There is some intuition for this as countries, or organizations may select each other to fight based on similar threatening and aggressive expressions. And while fighting parties might accelerate their expressions of aggressiveness it is likely that by the time they actually are fighting that the similarity of their expressions is already quite high and so less likely to increase.

Reviewing the formulas in Section 4.2 we would expect there to be an inverse relationship between selection and dist +1 and between influence and dist  X  1 . This is borne out in the charts where there is often an increase (decrease) in influence for every decrease (increase) in dist  X  1 .
In general, all sets display at least some evidence of se-lection and/or influence. The values fluctuate over time which suggests a changing linking strategy. We explore these changes in the section below on attribute weight drift.
This experiment is designed to learn how the alignment is affected when different accumulating strategies are used. To accumulate links means that a link established on one timestamp persists. Considering bibliographic sets, an ar-gument can be made that just because two authors did not collaborate in time t +1 but did in t does not mean that they are no longer considered collaborators. Attributes can also be accumulated and a similar argument can be used with bibliographic sets.

For each of the data sets we ran four tests, one with no accumulation, one where only the links are accumulated, another for which only the attributes are accumulated and a last that accumulates both links and attributes. For each of the sets we calculated the distance dist 0 for each snapshot.
Figure 2 shows the results. The four strategies above are grouped together by snapshot with the bars represent-ing the alignment distance dist 0 . The larger the value, the greater the distance between the alignment of the links and attributes. With all six data sets, the alignment distance grows larger with time because generally, more nodes are added to the networks over time. With other factors remain-ing stable and additional nodes, the alignment can only get larger.

With all data sets the lowest distance results from accu-mulating neither the links or attributes. In most instances, accumulating both links and attributes results in the high-est distance. In teen, wiki and levant, accumulating just the links results in a higher distance than accumulating just the attributes; with dblp the situation is reversed. The im-portant message in this experiment is that the accumulated networks have a higher distance than non-accumulated.
By accumulating the links, the network becomes less aligned. This suggests that as nodes change their attributes and links, they do so purposefully. Links are dropped for a reason that is related to the changes in attributes the node has made. The implications are important for preprocess-ing data. In some social networks they can be implicitly accumulated, like when users do not often change certain interests (like movie preferences). The network can possi-bly be better aligned if the analyst tries to remove old data values.
This experiment attempts to discover the value of using historical data in a dynamic network. The general idea is to learn different sets of weights for increasing window sizes of historical data and use those weights to find the alignment distance for a future time period. While we could have used any of the alignment measures, we chose dist +1 since one of our primary interests is in the area of link prediction.
For the experiment we learned the weights ~w +1 , ~w +2 , ~w and ~w  X  to calculate dist +1 for the time periods from t to t +1 . The results can be seen in Figure 3. The bars represent the alignment distance values for different weights for the time periods predicted.

In all of the data sets, alignment distance generally be-comes lower (better) or stays the same with the addition of older data. With both wiki and levant there was no or very little improvement. For these sets, the Markov assumption of using only the most recent data appears to be appropriate. In the dblp sets, the alignment improves only marginally in most time periods except year 8 of dblp1 and years 6 and 8 of dblp3.

Many link prediction models assume that only the most recent snapshot of the network is adequate for predicting the state of the next snapshot. Our results support this assumption for some networks. In networks where past data is helpful, it could be due to the drift in attribute weights. Examples are provided in the next section to support this suggestion.
A possible explanation for the diminished value of his-torical data is the possibility that over time, the attributes that are important to linking will change. We tested this by learning the weights for each attribute and then calcu-lating the correlation coefficient between them for each time (a) neither attributes nor links are accumulated (b) links are accumulated but attributes are not (c) attributes are accumulated but links are not (d) both the links and the attributes are accumulated Figure 4: Correlation between attribute weights. Yearly refers to the average of the correlations be-tween adjacent years and first to last is the correla-tion between the weights for the first and last peri-ods. period. The correlation was calculated for all adjacent time periods and also between the first and last time period. The results in Figure 4 compare the average of the period-to-period correlations with the correlation between the first and last period.

Not surprisingly, the correlation over an extended period of time is very low but is better for the average period-to-period correlation. This shows that within a network the weights of the attributes drift over time but the drift is some-what gradual. In Figure 4(a), the correlation for all three dblp sets is low even for the period-to-period averages. In a network, like dblp, where the importance of attributes for linking changes more often, one would expect that just using one prior period would not be sufficient for predictive tasks. In these networks the Markov assumption may not be as appropriate as those where the drift is less significant. This is supported by the results in the previous section where alignment improves using past data for dblp1 and dblp3.
Examining the drift with respect to accumulating links and attributes, it can be seen in Figures 4(a) X (d) that all of the sets have higher yearly correlation when the links are accumulated. Comparing charts (a) to (b) and (c) to (d) it appears that (with the exception of levant) accumulating attributes does not change the yearly correlation very much.
Clearly, there is a tendency for attributes to change their importance for linking. For social networks, this implies that while selection and influence take place, the attributes that encourage selection or those that are changed through influence, tend to be different over time. In other words, qualities that someone looks for in a friend today might be different than the ones they look for next year.

The set with the most consistently high first-to-last cor-relation was levant data which has only 18 attributes. This is reasonable since the attributes in this set are positive or negative actions that the actors can take, such as offer as-sistance or threaten . As the links are determined by actors who fight , it is unlikely that the attribute weights would drift much over time.
In addition to investigating the impact of using historical data on the theoretical measure of alignment we also con-sider the practical issue of link prediction. Here we want to know the result of changing window size of historical data when predicting new links. Accordingly, we applied different weights, learned with differing amounts of historical data, to the link prediction method described in Section 4.
Results for link prediction can be found in Figure 5. The bars in the plots show the precision for the different weights used, for each time period. We chose to report the precision because the class skew (many more non-links than links) makes the accuracy misleadingly high. Link prediction is notoriously difficult so the precision is quite low [21]. The important information in the plots though is the relative dif-ference between the weights. With the exception of levant, using only the most recent data ( ~w +1 ) results in better link prediction (except one timestamp in dblp3). Even in the levant set, for many of the timestamps, ~w +1 is either the best or very close to the best. These results support our previous findings that increasing the window size provides minimal benefit. In fact, the prediction results indicate that the first-order Markov assumption provides the best results for the majority of the sets.
As discussed earlier, one of the decisions when creating the network matrices that might impact the analysis is the interval size or the amount of time between snapshots. To study this further, we created an additional eight snapshots from the wikipedia data  X  monthly snapshots from January to August of 2006. The experiments were repeated on this new data set and the results are presented in Figure 6. In chart (a), selection and influence again appear to be present in the data. Like in the six month snapshots, selection ap-pears to play a larger role than influence.

In chart (b), once again, the alignment distance is not only very close but actually decreases with the amount of historical data used to learn the weights. Finally, in chart (c), with one exception, the prediction precision is slightly lower when using weights that were learned using more than one period of data.
Social network analysts have proposed the complementary processes of selection and influence as major forces at work in social networks. We were able to verify that these forces are at work in a variety of data sets. Our experiments also demonstrated that a larger window size of historical data is either not very helpful or even harmful. When network data is accumulated (using past link and attribute data), we show that the alignment distance between links and attributes widens. This suggests that not only should accumulation be avoided but if old data values can be removed from network snapshots, it could improve the prediction precision.
Using the Markov assumption to limit the amount of his-torical data used in learning is a convenient simplifying as-sumption. We have shown that with a variety of data sets it is also the best choice for optimal performance. To confirm these results we calculated the precision of predicting links
Figure 6: Experiments on wiki monthly data set using different levels of history. In nearly all cases, using historical data actually reduced the precision. In the cases of networks where the past historical data was helpful for prediction it is suggested that significant attribute drift is at least partly responsible.
