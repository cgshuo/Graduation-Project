 Lexical paraphrasing aims to acquire paraphrases of words, which is elementary but very important in many NLP applications. For instance, in Question Answering (QA), paraphrases should be detected in question and answer sentences so that the exact answers can be pinpointed. In automatic evaluation of Machine Translation (MT), lexical paraphrases need to be recognized in order to evaluate the systems X  translation IE patterns should be identified so as to extract the required information from texts. 
Two broad approaches to lexical paraphrasing have dominated the literature. One approach acquires paraphrases from dictionaries, such as WordNet in English [2], [6] and Tongyici Cilin in Chinese [7]. The other approach collects lexical paraphrases from monolingual or bilingual corpora. Lin identified words with similar meaning by measuring the similarity of the contextual words [8]. Barzilay and McKeown extracted paraphrases from a corpus of multiple English translations of the same source text [3]. Bannard and Callison-Burch derived paraphrases using bilingual parallel corpora [1]. Wu and Zhou extracted lexical paraphrases with multiple resources, including a monolingual dictionary, a bilingual corpus, and a large monolingual corpus [9]. 
These methods facilitate the acquisition of paraphrases. However, none of them specify the contexts in which the derived paraphrases can be adapted. Recently, topic adaptation for paraphrasing has been researched. For example, Kaji and Kurohashi selected lexical paraphrases according to different topics [5]. However, the topics are limited and predefined rather than any given context. 
This paper addresses the problem of context-specific paraphrasing. Here, a specific context means a sentence in which a word occurs. A new web mining method is each sentence. 2.1 Candidate Paraphrase Extraction Two stages are included: candidate paraphrase extraction and paraphrase validation. The method for candidate paraphrase extraction is based on two principles. The first is authors on the web create information independently, thus their "vocabularies" vary greatly [4]. In other words, if a concept is widely discussed on the web, then various paraphrases play similar syntactic roles in sentences, which indicates that paraphrases of a given word w in sentence S can be derived by extracting words whose syntactic roles are similar with w . Three main steps are included in candidate paraphrase extraction: Step1: Query S on the web and retrieve similar sentences. In this step, the sentence S is searched on the web using Baidu. From the retrieved snippets, sentences whose sentences. Word overlapping rate (WOR) is used here for computing the similarity between S and any candidate sentence S' : where " WS(.) " denotes the set of words in a sentence. "|.|" denotes the cardinality of a set. 
Step2: Extract candidates according to syntactic similarity. In this step, sentence S and all the candidate sentences are first parsed by a Chinese dependency parser. In a dependency result, two words and their dependency relation are represented as a used for extracting candidate paraphrases. 
Step3: Filter candidates using ECilin. HIT IR-Lab Tongyici Cilin (Extended) Chinese synonym dictionary. In ECilin, each word has a sense code and all sense codes classified into 12 classes, while at the fifth level thousands of classes are formed with Given: Criterion: 2.2 Paraphrase Validation candidates. Therefore, a method for validating candidate paraphrases is necessary. Let w Accordingly, word w and w i are similar in this specific context. 2.2.1 Assumption for Paraphrase Validation ( PD Si ( w i )) is constructed using these extracted sentences. In this work, paraphrases are validated based on the following assumption: between their pseudo documents PD S ( w ) and PD Si ( w i ) exceeds a predefined threshold T , then w i is validated as w 's paraphrase within the specific sentence S . 2.2.2 Similarity Measurements for Pseudo Documents According to the as sumption, a similarity measurement is needed for computing similarities between pseudo documents. Here, two different similarity measurements are investigated: VSM-based similarity and syntactic similarity. VSM-based similarity (VSMSim): Given two pseudo documents PD S1 ( w 1 ) and PD S2 ( w 2 ). In VSM, they are represented as vectors V 1 and V 2 , in which the weight of each word is calculated using a tf X itf heuristic: where tf(w, PD) denotes the term frequency of word w in pseudo document PD . tf ( w, C
CD ) is w 's term frequency counted on a China Daily Corpus ( C CD ). max ( tf ( w X , C CD )) is the largest term frequency obtained on the corpus. The VSM-based similarity is calculated as the cosine similarity between V 1 and V 2 : where "  X  " denotes inner product. " . " denotes the length of a vector. syntactic similarity of pseudo documents is calculated with the same method as the surrounding contextual words which have dependency relations with the investigated words according to the parsing results. where T ( w i ) denotes the set of words that have the dependency relation rel with w i . 3.1 Data and Metrics because in many applications, such as QA, IE, and multi-document summarization, the words and sentences to be paraphrased are usually from news articles. The news titles are collected from "sina news (http://news.sina.com.cn/)". All titles in the "important news" section from March 15, 2006 to April 5, 2006 are downloaded. 257 titles are left after removing duplications. 
The metrics are precision, recall, and f-measure. Let M 1 , ..., M T be T paraphrasing methods to be compared. N is the number of sentences in test data. n i is the number of in the nt ij paraphrases. Precision of method M t is defined as: that a word has within a context. Therefore, an approximate approach is used to calculate recall of each method. Specifically, for the j-th paraphrased word in the i-th sentence, all its correct paraphrases acquired by the T methods are put together (with Recall of method M t is defined as: 
The f-measure of method M t is defined as: 3.2 Experimental Results In the experiments, four methods are completed and compared, including: (1) M ECilin : M
CSP-Candi : the context-specific paraphrasing (CSP) method that extracts candidate CSP method using VSMSim in paraphrase validation. (4) M CSP-SYN : CSP method using SYNSim in paraphrase validation. 
Three thresholds are used in the methods: (1) T CE : threshold for candidate 0.60, and 0.08 respectively. The comparing results are shown in Table 1: 3.3 Analysis 3.3.1 Comparison with Method Using ECilin As can be seen from Table 1, all the three CSP methods, i.e. M CSP-Candi , M CSP-VSM , and M Specifically, precision of M ECilin is quite low, which shows that most synonyms words " (die)" and " (die)" are synonyms. However, they can never be used in the same context, as the former expresses the death of a personage while the latter is usually used to express the death of an evil person. In contrast, in the CSP methods, these kinds of synonyms cannot be extracted as paraphrases, which makes precision CSP methods, which demonstrates that paraphrases in specific contexts are not necessarily synonyms. 3.3.2 Evaluation of Paraphrase Validation In this section, the effectiveness of paraphrase validation stage is analyzed. It can be measurements are both effective in filtering incorrect candidates. At the same time, it the increases in f-measure demonstrate the effectiveness of paraphrase validation. 3.3.3 Comparison of Similarity Measurements measurements. It can be seen from Table 1 that M CSP-VSM and M CSP-SYN produce similar helpful in filtering incorrect candidates. For example, the sentence " 48 (Tourist boat sinks off Bahrain, at least 48 died)" is from our test data. For the word " (tourist boat)", " (coast)" is extracted as a candidate paraphrase mistakenly. In M CSP-VSM , this incorrect candidate cannot be filtered in validation, since their PDs share a lot of identical words, which makes them quite similar when represented as vectors in VSM. Nevertheless, these two words play different syntactic functions in sentences and have dependency relations with quite different words in filtered. This paper proposes a web mining method to automatically acquire context-specific paraphrases. There are three main contributions. First, this work focuses on the problem of context-specific paraphrasing, which has seldom been addressed before. measurements are investigated. 
For the presented CSP methods, M CSP-VSP and M CSP-SYN , precisions are 63.34% and 66.10%, and recalls are 56.06% and 55.28% respectively. The results significantly outperform the method using ECilin. 
In the future work, paraphrase validation will be improved. Especially, different similarity measurements will be combined so as to get an optimal compromise of precision and recall. Acknowledgments. This research was supported by National Natural Science Foundation of China (60435020, 60575042, 60503072). We thank Wanxiang Che and Weigang Li for useful discussions and their valuable comments on this paper.

