 Customer preferences for products are drifting over time. Product perception and popularity are constantly changing as new selec-tion emerges. Similarly, customer inclinations are evolving, lead-ing them to ever redefine their taste. Thus, modeling temporal dy-namics should be a key when designing recommender systems or general customer preference models. However, this raises unique challenges. Within th e eco-system inters ecting multiple products and customers, many different characteristics are shifting simulta-neously, while many of them influence each other and often those shifts are delicate and associated with a few data instances. This distinguishes the problem from concept drift explorations, where mostly a single concept is tracked. Classical time-window or instance-decay approaches cannot work, as they lose too much signal when discarding data instances. A more sensitive approach is required, which can make better distinctions between transient effects and long term patterns. The paradigm we offer is creating a model tracking the time changing behavior throughout the life span of the data. This allows us to exploit the relevant components of all data instances, while discarding only what is modeled as being irrele-vant. Accordingly, we revamp two leading collaborative filtering recommendation approaches. Evaluation is made on a large movie rating dataset by Netflix. Results are encouraging and better than those previously reported on this dataset.
 H.2.8 [ Database Management ]: Database Applications X  Data Min-ing Algorithms collaborative filtering, recommender systems, concept drift Modeling time drifting data is a central problem in data mining. Often, data is changing over time, and up to date modeling should be continuously updated to reflect its present nature. The analysis of such data needs to find the right balance between discounting Copyright 2009 ACM 978-1-60558-495-9/09/06 ... $ 5.00. temporary effects that have very low impact on future behavior, while capturing longer-term trends that reflect the inherent nature of the data. This led to many works on the problem, which is also widely known as concept drift ; see e.g. [15, 25].

Modeling temporal changes in customer preferences brings unique challenges. One kind of concept drift in this setup is the emergence of new products or services that change the focus of customers. Re-lated to this are seasonal changes, or specific holidays, which lead to characteristic shopping patterns. All those changes influence the whole population, and are within th e realm of traditional studies on concept drift. However, many of the changes in user behavior are driven by localized factors. For example, a change in the family structure can drastically change shopping patterns. Likewise, indi-viduals gradually change their taste in movies and music. All those changes cannot be captured by methods that seek a global concept drift. Instead, for each customer we are looking at different types of concept drifts, each occurs at a distinct time frame and is driven towards a different direction.

The need to model time changes at the level of each individ-ual significantly reduces the amount of available data for detecting such changes. Thus we should resort to more accurate techniques than those that suffice for modeling global changes. For example, it would no longer be adequate to abandon or simply underweight far in time user transactions. The signal that can be extracted from those past actions might be invaluable for understanding the cus-tomer herself or be indirectly useful to modeling other customers. Yet, we need to distill long term patterns while discounting tran-sient noise. This requires a more sensitive methodology for ad-dressing drifting customer preferences. It would not be adequate to concentrate on identifying and modeling just what is relevant to the present or the near future. Instead, we require an accurate modeling of each point in the past, which will allow us to distinguish between persistent signal that should be captured and noise that should be isolated from the longer term parts of the model.

Modeling user preferences is relevant to multiple applications ranging from spam filtering to market-basket analysis. Our main focus in the paper is on modeling user preferences for building a recommender system, but we believe that general lessons that we learn would apply to other applications as well. Automated rec-ommendations is a very active research field [12]. Such systems analyze patterns of user interest in items or products to provide per-sonalized recommendations of items that will suit a user X  X  taste. We expect user preferences to change over time. This may stem from multiple factors, some are fundame ntal while others are more cir-cumstantial. For example, in a movie recommender system, users may change their preferred genre or adopt a new viewpoint on an actor or director. In addition, they may alter the appearance of their feedback. E.g., in a system where users provide star ratings to products, a user that used to indicate a neutral preference by a  X 3 stars X  input, may now indicate dissatisfaction by the same  X 3 stars X  feedback. Similarly, it is known that user feedback is in-fluenced by anchoring, where current ratings should be taken as relative to other ratings given at the same short period. Finally, in many instances systems cannot separate different household mem-bers accessing the same account, even though each member has a different taste and deserves a separate model. This creates a de facto multifaceted meta-user asso ciated with the account. A way to get some distinction between different persons is by assuming that time-adjacent accesses are being done by the same member (some-times on behalf of other members), which can be naturally captured by a temporal model that assumes a drifting nature of a customer.
All these patterns and the likes should have made temporal mod-eling a predominant factor in building recommender systems. Non-etheless, with very few exceptions (to be mentioned in Sec. 7), the recommenders literature does not address temporal changes in user behavior. Perhaps, because user behavior is composed of many different concept drifts, all acting in a different timeframe and dif-ferent directions, thus making common methodologies for dealing with concept drift and temporal data less successful at this setup. We are showing that capturing time drifting patterns in user behav-ior is essential to improving accuracy of recommenders. This also gives us hope that the insights from successful time modeling for recommenders will be useful in other data mining applications.
Our test bed is a large movie rating dataset released by Netflix as the basis of a well publicized competition [4]. This dataset com-bines several merits for the task at hand. First, it is not a syn-thetic dataset, but contains user-movie ratings by real paying Net-flix subscribers. In addition, its relatively large size  X  above 100 million date-stamped ratings  X  makes it a better proxy for real life large scale datasets, while putting a premium on computational ef-ficiency. Finally, unlike some other dominant datasets, time effects are natural and are not introduced artificially. Two interesting (if not surprising) temporal effects that emerge within this dataset are shown in Fig. 1. One effect is an abrupt shift of rating scale that happened in early 2004. At that time, the mean rating value jumped from around 3.4 stars to above 3.6 stars. Another significant effect is that ratings given to movies tend to increase with the movie age. That is, older movies receive higher ratings than newer ones. In Sec. 6 we will return to these phenomena and use our temporal modeling to shed some light on their origins.

The major contribution of this work is presenting a methodology and specific techniques for modeling time drifting user preferences in the context of recommender systems. The proposed approaches are applied on the aforementioned extensively analyzed movie rat-ings dataset, enabling us to firmly compare our methods with those reported recently. We show that by incorporating temporal infor-mation we achieve best results reported so far, indicating the sig-nificance of uncovering temporal effects.

The rest of the paper is organized as follows. In the next section we describe basic notions and notation. Then, in Sec. 3 our prin-ciples for addressing time changing user preferences are evolved. Those principles are then materialized, in quite different ways, within two leading recommender techniques: factor modeling (Sec. 4) and item-item neighborhhod modeling (Sec. 5). In Sec. 6 we describe an exploratory study, followed by surveying related work in Sec. 7.
We are given ratings about m users (henceforth, interchangeable with  X  X ustomers X ) and n items (henceforth, interchangeable with  X  X roducts X ). We reserve special indexing letters for distinguishing users from items: for users u, v , and for items i, j .Weuse time (or, date). A rating r ui ( t ) indicates the preference by user of item i at day t , where high values mean stronger preferences. Figure 1: Two temporal effects emerging within the Netflix movie rating dataset. Top: the average movie rating made a sudden jump in early 2004 (1500 days since the first rating in the dataset). Bottom: ratings tend to increase with the movie age at the time of the rating. Here, movie age is measured by the time span since its first rating event within the dataset. In both charts each point averages 100,000 rating instances. For example, values can be integers ranging from 1 (star) indicat-ing no interest to 5 (stars) indicating a strong interest. User item i at most once, otherwise we take only the freshest rating, so given u and i , the day of rating is unique. Sometimes, when the day of rating is not relevant, we will use the short notation tinguish predicted ratings from known ones, by using the notation  X  r ( t ) for the predicted value of r ui ( t ) . Usually the vast major-ity of ratings are unknown. The ( u, i, t ) triples for which known are stored in the set K = { ( u, i, t ) | r ui ( t ) is known
We evaluated our algorithms on a movie rating dataset of more than 100 million date-st amped ratings performed by about half mil-lion anonymous Netflix customers on 17,770 movies between Dec 31, 1999 and Dec 31, 2005 [4]. We are not aware of any publicly available comparable dataset that is close to the scope and qual-ity of this one. To maintain com patibility with re sults published by others, we adopted some common standards. We evaluated our methods on two comparable sets designed by Netflix: a hold-out set ( X  X robe set X ) and a test set ( X  X uiz set X ), each of which contains over 1.4 million ratings. Reported results are on the test set, while experiments on the hold-out set show the same findings. In our time-modeling context, it is important to note that the test instances of each user come later in time than his/her training instances. The quality of the results is measured by their root mean squared sure that puts more emphasis on large errors compared with the al-ternative of mean absolute error. Achievable RMSE values on the test set lie in a quite compressed range, as reported by many partici-pants in the related competition. Nonetheless, there is evidence that small improvements in RMSE terms can have a significant impact on the quality of the top few presented recommendations [8].
Recommender systems are often based on Collaborative Filter-ing (CF), which relies only on past user behavior X  X .g., their previ-ous transactions or product ratings X  X nd does not require the cre-ation of explicit profiles. When enough ratings were gathered per item, as in the Netflix movie rating dataset, CF becomes the pre-ferred and more accurate technique. Notably, CF techniques re-quire no domain knowledge and avoid the need for extensive data collection. In addition, relying directly on user behavior allows un-covering complex and unexpected patterns that would be difficult or impossible to profile using known data attributes. As a conse-quence, CF attracted much of attention in the past decade, resulting in significant progress and being adopted by some successful com-mercial systems, including Amazon [9], TiVo and Netflix.
In order to establish recommendations, CF systems need to com-pare fundamentally different objects: items against users. There are two primary approaches to facilitate such a comparison, which con-stitute the two main disciplines of CF: the neighborhood approach and latent factor models . Neighborhood methods are centered on computing the relationships between items or, alternatively, be-tween users. An item-item approach [9, 14] evaluates the prefer-ence of a user to an item based on ratings of similar items by the same user. In a sense, these methods transform users to the item space by viewing them as baskets of rated items.

Latent factor models, such as matrix factorization, comprise an alternative approach by transforming both items and users to the same latent factor space, thus making them directly comparable. The latent space tries to explain ratings by characterizing both prod-ucts and users on factors automatically inferred from user feed-back. For example, when the products are movies, factors might measure obvious dimensions such as comedy vs. drama, amount of action, or orientation to children; less well defined dimensions such as depth of character development or  X  X uirkiness X ; or completely uninterpretable dimensions.
One of the frequently mentioned examples of concept drift is changing customer preferences ove r time, e.g.:  X  X ustomer prefer-ences change as new products and services become available X  [7]. This aspect of drifting customer preferences highlights a common paradigm in the literature of having global drifting concepts influ-encing the data as a whole. However, in many applications, includ-ing our focus application of recommender systems, we also face a more complicated form of concept d rift where interconnected pref-erences of many users are drifting in different ways at different time points. This requires the learning algorithm to keep track of multi-ple changing concepts. In additio n the typically low amount of data instances associated with individual customers calls for more con-cise and efficient lear ning methods, which ma ximize the utilization of signal in the data.

In a survey on the problem of concept drift, Tsymbal [22] ar-gues that three approaches can be di stinguished in th e literature. The instance selection approach discards instances that are less rel-evant to the current state of the system. A common variant is time window approaches were only recent instances are considered. A possible disadvantage of this simple model is that it is giving the same significance to all instances within the considered time win-dow, while completely discarding all other instances. This might be reasonable when the time shift is abrupt, but less so when time shift is gradual. Thus, a refinement is instance weighting were instances are weighted based on their estimated relevance. Fre-quently, a time decay function is used, under-weighting instances as they occur deeper into the past. The third approach is based on ensemble learning , which maintains a family of predictors that to-gether produce the final outcome. Those predictors are weighted by their perceived relevance to the present time point, e.g., predictors that were more successful on recent instances get higher weights.
We performed extensive experiments with instance weighting schemes, trying different exponential time decay rates on both neigh-borhood and factor models. The consistent finding was that predic-tion quality improves as we moderate that time decay, reaching best quality when there is no decay at all. This is despite the fact that users do change their taste and rating scale over the years, as we show later. However, much of the old preferences still persist or, more importantly, help in establishing useful cross-user or cross-product patterns in the data. Thus, just underweighting past actions loses too much signal along with the lost noise, which is detrimen-tal given the scarcity of data per user.

As for ensemble learning, having multiple models, each of which considers only a fraction of the total behavior may miss those global patterns that can be identified only when considering the full scope of user behavior. What makes them even less appealing in our case is the need to keep track of the independent drifting behaviors of many customers. This, in turn, would require building a separate ensemble for each user. Such a separation will significantly com-plicate our ability to integrate information across users along multi-ple time points, which is the cornerstone of collaborative filtering . For example, an interesting relation between products can be es-tablished by related actions of many users, each of them at a totally different point of time. Capturing such a collective signal requires building a single model encompassing all users and items together.
All those considerations led us to the following guidelines we adopt for modeling drifting user preferences.
Now we turn to how these desirable principles materialize into concrete methods when dealing with two leading approaches to col-laborative filtering -matrix factorization and neighborhood models.
One of the more successful approaches to CF is based on a ma-trix factorization model [2, 5, 10, 13, 18]. This approach lends itself well to an adequate modeling of temporal effects. Before we deal with those temporal effects, we would like to establish the foundations of a static factor model.

Matrix factorization models map both users and items to a joint latent factor space of dimensionality f , such that ratings are mod-eled as inner products in that space. Accordingly, each user associated with a vector p u  X  R f and each item i is associated with a vector q i  X  R f . A rating is predicted by the rule: In order to learn the vectors p u and q i we minimize the regularized squared error: The constant  X  controls the extent of regularization, as usually de-termined by cross validation. Minimization is typically performed by either stochastic gradient descent or alternating least squares.
Such a pure factor model serves well in capturing the interaction between users and items. However, much of the observed rating values are due to effects associated with either users or items, in-dependently of their interaction. A prime example is that typical CF data exhibit large user and item biases  X  i.e., systematic tenden-cies for some users to give higher ratings than others, and for some items to receive higher ratings than others.

We will encapsulate those effects, which do not involve user-item interaction, within the baseline predictors . These baseline predic-tors tend to capture much of the observed signal, in particular much of the temporal dynamics within the data. Hence, it is vital to model them accurately, which enables better identification of the part of the signal that truly represents user-item interaction and should be subject to factorization.

A suitable way to construct a static baseline predictor is as fol-lows. Denote by  X  the overall average rating. A baseline predictor for an unknown rating r ui is denoted by b ui and accounts for the user and item main effects: The parameters b u and b i indicate the observed deviations of user u and item i , respectively, from the average. For example, suppose that we want a baseline estimate for the rating of the movie Titanic by user Joe. Now, say that the average rating over all movies, is 3.7 stars. Furthermore, Titanic is better than an average movie, so it tends to be rated 0.5 stars above the average. On the other hand, Joe is a critical user, who tends to rate 0.3 stars lower than the average. Thus, the baseline estimate for Titanic X  X  rating by Joe would be 3.9 stars by calculating 3 . 7  X  0 . 3+0 . 5 .
The baseline predictor should be integrated back into the factor model. To achieve this we extend rule (1) to be: Here main effects are explicitly isolated, thus letting the torization deal effectively with the relevant portions of the signal; see also [8, 10].

The factor model we are using in this work is SVD++ [8], which slightly differs from (3). This model was shown to offer a supe-rior accuracy by also accounting for the more implicit informa-tion recorded by which items were rated (regardless of their rating value). To this end a second set of item factors is added, relating item i to a factor vector y i  X  R f . Those new item factors are used to characterize users based on the set of items that they rated. The exact model is as follows (see [8] for further explanations): The set R( u ) contains the items rated by user u .

The decomposition of a rating into distinct portions is convenient here, as it allows us to treat different temporal aspects in separation. More specifically, we identify the following effects: (1) user biases ( b ) change over time; (2) Item biases ( b i ) change over time; (3) User preferences ( p u ) change over time. On the other hand, we would not expect a significant temporal variation of item character-istics ( q i ), as items, unlike humans, are static in their nature. We start with a detailed discussion of the temporal effects that are con-tained within the baseline predictors.
Much of the temporal variability is included within the baseline predictors, through two major temporal effects. First is addressing the fact that an item X  X  popularity is changing over time. For exam-ple, movies can go in and out of popularity as triggered by external events such as the appearance of an actor in a new movie. This is manifested in our models by the fact that item bias b i will not be a constant but a function that changes over time. The second major temporal effect is related to user biases -users change their base-line ratings over time. For example, a user who tended to rate an average movie  X 4 stars X , may now rate such a movie  X 3 stars X , for various reasons explained earlier. Hence, in our models we would like to take the parameter b u as a function of time. This induces the following template for a time sensitive baseline predictor: The function b ui ( t ) represents the baseline estimate for of i at day t . Here, b u ( t ) and b i ( t ) are real valued functions that change over time. The exact way to build these functions should reflect a reasonable way to parameterize the involving temporal changes. We will detail our choice in the context of the movie rating dataset, which demonstrates some typical considerations. A major distinction is between temporal effects that span extended pe-riods of time and more transient effects. In the movie rating case, we do not expect movie likeability to fluctuate on a daily basis, but rather to change over more extended periods. On the other hand, we observe that user effects can change on a daily basis, reflecting inconsistencies natural to customer behavior. This requires finer time resolution when modeling user-biases compared to a lower resolution that suffices for capturing item-related time effects.
Let us start with our choice of time-changing item biases -which are easier to capture since we do not need finest resolution there. Thus, an adequate decision would be to split the item biases into time-based bins. During each time period corresponding to a single bin we use a distinct item bias. The decision of how to split the timeline into bins should balance the desire to achieve finer res-olution (hence, smaller bins) with the need to have enough ratings per bin (hence, larger bins). For the movie rating data, there is a wide variety of bin sizes that yield about the same accuracy. In our implementation each bin corresponds to roughly ten consecutive weeks of data, leading to an overall number of 30 bins spanning all days in the dataset. A day t is associated with an integer Bin( number between 1 and 30 in our data), such that the movie bias is split into a stationary part and a time changing part:
While binning the parameters works well on the items, it is more of a challenge on the users side. On the one hand, we would like a finer resolution for users to detect very short lived temporal effects. On the other hand, we do not expect having enough ratings per user to produce reliable estimates for isolated bins. Different function forms can be considered for paramet erizing temporal user behavior, with varying complexity and accuracy.

The first modeling choice is very concise, and uses a linear func-tion to capture a possible gradual drift of user bias. Let us first introduce some new notation. For each user u , we denote the mean date of rating by t u .Now,if u ratedamovieonday t , then the associated time deviation of this rating is defined as: Here | t  X  t u | measures the time distance (e.g., number of days) between dates t and t u . We set the value of  X  by cross validation; in our implementation  X  =0 . 4 . We introduce a single new parameter for each user called  X  u so that we get our first definition of a time-dependent user-bias: This offers a simple linear model for approximating a drifting be-havior, which requires learning two parameters per user: b  X  . A more flexible parameterization is offered by splines. Let be a user associated with n u ratings. We designate k u time points  X  as kernels that control the following function: The parameters b u t l are associated with the control points (or, ker-nels), and are automatically learnt from the data. This way the user bias is formed as a time-weighted combination of those parameters. The number of control points, k u , balances flexibility and computa-tional efficiency. In our application we set k u = n 0 . 25 with the number of available ratings. The constant  X  determines the smoothness of the spline; we set  X  = 0 . 3 by cross validation.
So far we have discussed smooth functions for modeling the user bias, which mesh well with gradual concept drift .However,in many applications there are sudden drifts emerging as  X  X pikes X  as-sociated with a single day or session. For example, in the movie rating dataset we have found that multiple ratings a user gives in a single day, tend to concentrate around a single value. Such an effect does not span more than a single day. This may reflect the mood of the user that day, the impact of ratings given in a single day on each other, or changes in the actual rater in multi-person accounts. To address such short lived effects, we assign a single parameter per user and day, absorbing the day-specific variability. This parameter is denoted by b u,t . Notice that in some applications the basic primitive time unit to work with can be shorter or longer than a day. E.g., our notion of day can be exchanged with a notion of a user session.

In the Netflix movie rating data, a user rates on 40 different days on average. Thus, working with b u,t requires, on average, 40 pa-rameters to describe each user bias. It is expected that b equate as a standalone for capturing the user bias, since it misses all sorts of signals that span more than a single day. Thus, it serves as an additive component within the previously described schemes. The time-linear model (7) becomes: Similarly, the spline-based model becomes: model static mov linear spline linear+ spline+ RMSE .9799 .9771 .9731 .9714 .9605 .9603 Table 1: Comparing baseline predictors capturing main movie and user effects. As temporal modeling becomes more accu-rate, prediction accuracy improves (lowering RMSE).

A baseline predictor on its own cannot yield personalized recom-mendations, as it misses all interactions between users and items. In a sense, it is capturing the portion of the data that is less relevant for establishing recommendations and in doing so enables deriving accurate recommendations. Nonetheless, to better assess the rela-tive merits of the various choices of time-dependent user-bias, we will compare their accuracy as standalone predictors. In order to learn the involved parameters we minimize the associated regular-ized squared error by using stochastic gradient descent. For exam-ple, in our actual implementation we adopt rule (9) for modeling the drifting user bias, thus arriving at the baseline predictor:
To learn the involved parameters, b u , X  u ,b u,t ,b i and one should solve: min Here, the first term strives to construct parameters that fit the given ratings. The regularization term,  X  ( b 2 u + ... ) , avoids overfitting by penalizing the magnitudes of the parameters, assuming a neutral 0 prior. Learning is done by a stochastic gradient descent algorithm running 20 X 30 iterations, with  X  =0 . 01 .

Table 1 compares the a bility of various suggested baseline pre-dictors to explain signal in the data. As usual, the amount of cap-tured signal is measured by the root mean squared error on the test set. As a reminder, test cases come later in time than the training cases for the same user. We code the predictors as follows: The table shows that while temporal movie effects reside in the data (lowering RMSE from 0.9799 to 0.9771), the drift in user bi-ases is much more influential. The additional flexibility of splines at modeling user effects leads to better accuracy compared to a lin-ear model. However, sudden changes in user biases, which are cap-tured by the per-day parameters, are most significant. Indeed, when including those changes, the difference between linear modeling ( X  X inear+ X ) and spline modeling ( X  X pline+ X ) virtually vanishes.
Beyond the temporal effects described so far, one can use the same methodology to capture more effects. A prime example is capturing periodic effects. For example, some products can be more popular in specific seasons or near certain holidays. Similarly, different types of television or radio shows are popular throughout different segments of the day (known as  X  X ayparting X ). Periodic effects can be found also on the user side. As an example, a user may have different attitudes or buying patterns during the weekend compared to the working week. A way to model such periodic ef-fects is to dedicate a parameter for the combinations of time periods with items or users. This way, the item bias of (6), becomes: E.g., if we try to capture the change of item bias with the season of the year, then period( t )  X  X  fall , winter , spring , summer larly, recurring user effects are modeled by modifying (9) to be: E.g., if we try to model a day-of-week user effect, then period( {
Sun , Mon , Tue , Wed , Thu , Fri , Sat } . We could not find peri-odic effects with a significant predictive power within the movie-rating dataset, thus our reported results do not include those.
Another temporal effect within the scope of basic predictors is related to the changing scale of user ratings. While b i ( independent measure for the merit of item i at time t ,userstend to respond to such a measure differently. For example, different users employ different rating scales, and a single user can change his rating scale over time. Accordingly, the raw value of the movie bias is not completely user-independent. To address this, we add a time-dependent scaling feature to the baseline predictors, denoted by c u ( t ) . Thus, the baseline predictor (11) becomes: b All discussed ways to implement b u ( t ) would be valid for imple-menting c u ( t ) as well. We chose to dedicate a separate parame-ter per day, resulting in: c u ( t )= c u + c u,t . As usual, stable part of c u ( t ) , whereas c u,t represents day-specific variabil-ity. Adding the multiplicative factor c u ( t ) to the baseline predictor lowers RMSE to 0.9555. Interestingly, this basic model, which captures just main effects disregarding user-item interactions, can explain almost as much of the data variability as the commercial Netflix Cinematch recommender system, whose published RMSE on the same test set is 0.9514 [4].
In the previous subsection we discussed the way time affects baseline predictors. However, as hinted earlier, temporal dynamics go beyond this, they also affect user preferences and thereby the in-teraction between users and items. Users change their preferences over time. For example, a fan of the  X  X sychological thrillers X  genre may become a fan of  X  X rime dramas X  a year later. Similarly, hu-mans change their perception on cer tain actors and directors. This effect is modeled by taking the user factors (the vector p function of time. Once again, we need to model those changes at the very fine level of a daily basis, while facing the built-in scarcity of user ratings. In fact, these temporal effects are the hardest to capture, because preferences are not as pronounced as main effects (user-biases), but are split over many factors.

The same way we treat user biases we also treat each component of the user preferences p u ( t ) T =( p u 1 ( t ) ,...,p application, we have found modeling after (9) effective leading to: Here p uk captures the stationary portion of the factor,  X  approximates a possible portion that changes linearly over time, and p uk,t absorbs the very local, day-specific variability. Table 2: Comparison of three factor models: prediction ac-curacy is measured by RMSE (lower is better) for varying factor dimensionality ( f ). For all models accuracy improves with growing number of dimensions. Most significant accuracy gains are achieved by addressing the temporal dynamics in the data through the timeSVD++ model.

At this point, we can tie all pieces together and extend the SVD++ factor model by incorporating the time changing parameters. This leads to a model, which will be denoted as timeSVD++ ,wherethe prediction rule is as follows:  X  r ( t )=  X  + b i ( t )+ b u ( t )+ q T i The exact definitions of the time drifting parameters b i and p u ( t ) were given in (6),(9) and (13). Learning is performed by minimizing the associated squared error function on the training set using a regularized stochastic gradient descent algorithm. The procedure is analogous to the one involving the original SVD++ al-gorithm [8]; details are omitted here for brevity. Time complexity per iteration is still lin ear with the input size, while wall clock run-ning time is approximately doubled compared to SVD++, due to the extra overhead required for updating the temporal parameters. Importantly, convergence rate was not affected by the temporal pa-rameterization, and the process converges in around 30 iterations.
Addressing temporal dynamics leads to significant accuracy gains within the movie rating dataset, when considering past RMSE im-provements on the dataset. In Table 2 we compare results of three algorithms. First is the plain matrix factorization algorithm as per (3), denoted by SVD. Second, is the SVD++ method (4), which was considered as a significant improvement over SVD by incor-porating also a kind of implicit feedback [8]. Finally is the newly proposed timeSVD++, which accounts for temporal effects as in (14). The three methods are compared over a range of factoriza-tion dimensions ( f ). All methods benefit from a growing number of factor dimensions, what enables them to better express complex movie-user interactions. Notice that the improvement delivered by timeSVD++ over SVD++ is consistently more significant than the improvement SVD++ achieves over SVD. In fact, we are not aware of any single algorithm in the literature that could deliver such ac-curacy. We attribute this to the importance of properly addressing temporal effects. What further demonstrates the importance of cap-turing temporal dynamics is the fact that a timeSVD++ model of dimension 10 is already more accurate than an SVD model of di-mension 200. Similarly, a timeSVD++ model of dimension 20 is enough to outperform an SVD++ model of dimension 200.
The most common approach to CF is based on neighborhood models. While typically less accurate than their factorization coun-terparts, neighborhood methods enjoy popularity thanks to some of their merits, such as explaining the reasoning behind computed rec-ommendations, and seamlessly accounting for new entered ratings.
Recently, we suggested an item-item model based on global opti-mization [8], which will enable us here to capture time dynamics in a principled manner. The static model, without temporal dynamics, is centered on the following prediction rule:  X  r Here, the item-item weights w ij and c ij represent the adjustments we need to make to the predicted rating of item i , given a known rating of item j . It was proven greatly beneficial to use two sets of item-item weights: one (the w ij s) is related to the values of the ratings, and the other disregards the rating value, considering only which items were rated (the c ij s). These weights are automatically learnt from the data together with the biases b i and b u stants b uj are precomputed according to (2). Recall that R( the set of items rated by user u .

When adapting rule (15) to address temporal dynamics, two com-ponents should be considered separately. First, is the baseline pre-dictor portion,  X  + b i + b u , which explains most of the observed signal. Second, is the part that captures the more informative sig-nal, dealing with user-item interaction | R( u ) |  X  1 2 j  X  b uj ) w ij + c ij . As for the baseline part, nothing changes from the factor model, and we replace it with  X  + b i ( t )+ b u ( to (6) and (9). However, capturing temporal dynamics within the interaction part requires a different strategy.

Item-item weights ( w ij and c ij ) reflect inherent item characteris-tics and are not expected to drift over time. Learning process should make sure that they capture unbiased long term values, without be-ing too affected from drifting aspects. Indeed, the time changing nature of the data can mask much of the longer term item-item re-lationships if not treated adequately. For instance, a user rating both items i and j high in a short time period, is a good indicator for relating them, thereby pushing higher the value of w ij other hand, if those two ratings are given five years apart, while the user X  X  taste (if not her identity) could considerably change, this is less of an evidence of any relation between the items. On top of this, we would argue that those considerations are pretty much user-dependent  X  some users are more consistent than others and allow relating their longer term actions.

Our goal here is to distill accurate values for the item-item weights, despite the interfering temporal effects. First we need to parameter-ize the decaying relations between two items rated by user adopt exponential decay formed by the function e  X   X  u  X   X   X  u &gt; 0 controls the user specific decay rate and should be be learnt from the data. We also experimented with other decay forms, such results. This leads to the prediction rule:  X  r ui ( t )=  X  + b i ( t )+ b u ( t )+ (16) Here, in a slight abuse of notation, we assume that the set R( contains not only the items rated by u , but also the time of those ratings. The involved parameters, b i ( t )= b i + b i, Bin( b +  X  u  X  dev u ( t )+ b u,t , X  u ,w ij and c ij , are learnt by minimizing the associated regularized squared error: Minimization is performed by stochastic gradient descent. We run the process for 25 iterations, with  X  =0 . 002 , and step size (learn-ing rate) of 0.005. An exception is the update of the exponent where we are using a much smaller step size of 10  X  7 . Training time complexity is the same as the original algorithm, which is: O ( u | R( u ) | 2 ) . One can tradeoff complexity with accuracy by sparsifying the set of item-item relations as explained in [8].
Like in the factor case, properly considering temporal dynamics improves the accuracy of the neighborhood model within the movie ratings dataset. The RMSE decreases from 0.9002 [8] to 0.8885. To our best knowledge, this is significantly better than previously known results by neighborhood methods. To put this in some per-spective, this result is even better than those reported [1, 10, 21] by using hybrid approaches such as applying a neighborhood ap-proach on residuals of other algorithms. A lesson is that addressing temporal dynamics in the data can have a more significant impact on accuracy than designing more complex learning algorithms.
We would like to highlight an interesting point related to the ba-sic methodology described in Sec. 3. Let u beauserwhosepref-erences are quickly drifting (  X  u is large). Hence, old ratings by u should not be very influential on his status at the current time -t . One could be tempted to decay the weight of u  X  X  older ratings, leading to  X  X nstance weighting X  through a cost function like: b Such a function is focused at the current state of the user (at time t ), while de-emphasizing past actions. We would argue against this choice, and opt for equally weighting the prediction error at all past ratings as in (17), thereby modeling all past user behavior. This allows us to exploit the signal at each of the past ratings, a sig-nal that is extracted as item-item weights. Learning those weights would equally benefit from all ratings by a user. In other words, we can deduce that two items are related if users rated them similarly within a short timeframe, even if this happened long ago.
In Fig. 1 we showed two strong temporal effects within the Net-flix movie-rating data. First effect exhibits a sudden rise in the average movie rating beginning around 1500 days into the dataset, corresponding to early 2004. The second effect shows that people tend to give higher ratings as movies become older (movie age is measured by number of days since its first rating in the dataset). The patterns that our temporal models capture may help in explain-ing what created those two global temporal effects.

Let us start with the first effect. We can come up with several hypotheses on what caused the sudden increase of rating scores. 1. Since 2004 people are matched with movies better suited for 2. Since 2004 people are biased to give higher ratings in gen-3. The vast majority of the users in the Netflix dataset gave their
A straightforward analysis rejects the third hypothesis  X  even when concentrating on earlier customers, e.g., those who have rated earlier than 2003, we can find a strong shift in rating scale since early 2004. As for the two other hypotheses, we use our models for examining them. The first hypothesis corresponds to the interaction part of the models (e.g., q T i p u ( t )+ | R( u ) |  X  1 the timeSVD++ model), which measures how well user and movie characteristics match together. On the other hand, the second hy-pothesis, deals with general biases that have nothing to do with the matching of users to movies. Thus, it corresponds to the baseline predictor portion of them model (  X  + b i ( t )+ b u ( t ) ). In order to analyze this, we modeled the data using the timeSVD++ model (of dimensionality f =50 ). While the full model could accurately regenerate the shifts in rating values over time, more interesting to us is to separate the model predictions into baseline and interaction components, and examine how each of them evolve over time. Re-sults are shown in Fig. 2. We observe that since early 2004 (1500 days into the data), the score due to interaction between users and movies steadily rises, indicating that users are increasingly rating movies that are more suitable for their own taste. This supports the first hypothesis of an ongoing improvement in the way Netflix matches users to movies beginning at early 2004 and continuing since then. Apparently, this could be expected knowing the large effort that company invests in improving their recommender system [4]. At the same time, the various biases, captured by the baseline predictors, exhibit a onetime pha se transition ar ound the 1500 days time point. While shallower than the change in the interaction part, the jump is clear and supports the more surprising second hypoth-esis. This hints that beyond a constant improvement in matching people to movies they like, something else happened in early 2004 causing an overall shift in rating scale. Uncovering this may require extra information on the related circumstances. Figure 2: Tracking the change of the two components of mod-eled movie-ratings over time. First component ( X  X aseline X ) represents rating behavior influenced by exterior considera-tions, while the other component ( X  X nteraction X ) captures the rating behavior that is explained by the match between users and movies.

Now we move to the second temporal effect. We would like to suggest two hypotheses to why ratings rise as movies become older. 1. Older movies are getting rated by users better matching them. 2. Older movies are just inherently better than newer ones. This Once again we split the modeled behavior into two parts  X  the inter-action part measuring the match between users and movies and the baseline part capturing other effects. In Fig. 3 we track how those two components change over time. Much like the original raw data (in Fig. 1), the interaction part shows a steady increase virtually throughout the whole movie age range at a close to linear pace. On the other hand, the baseline portion is increasing only between days 1000 and 1500, while being captured within a narrow range else-where. Since we measure movie age by number of days since first rating, as movies become older they are more exposed to the afore-mentioned early 2004 rating jump effect. In particular, all movies older than 1500 days must be fully susceptible to this effect. Thus, it is possible that the increase in baseline values between days 1000 and 1500 reflects such a side effect. To wipe out this interfering ef-fect we concentrate only on ratings to movies aged 1500 days or older. This leaves us with a bout 44% of the poi nts (  X 44 million rating instances) and makes the picture much clearer. While the raw ratings as well the interaction part continue to steadily increase beyond day 1500, the baseline portion does not increase after that day. We view this as an indication that the first hypothesis is closer to the truth than the second one. Figure 3: Tracking the change of the two components of mod-eled ratings against age of rated movie. We observe a consistent improvement in the match between users and movies as movie age rises (captured by the  X  X nteraction X  component).
In the past few years, much research was devoted to the Netflix dataset. Many works were published in the two KDD workshops dedicated to that dataset [3, 23]. Other notable works include [8, 13, 19]. Best reported results were obtained by integrating the fac-torization and neighborhood models. Results reported in this paper by pure factorization are more accurate, in a sense showing that ad-dressing temporal dynamics is not less important than algorithmic sophistication created by integration of two different models.
Despite the high impact of temporal effects on user preferences, the subject attracted a quite negligible attention in the recommender literature. Notable discussions of temporal effects include Ding and Li [6], who suggested a time weighting scheme for a similarity-based collaborative filtering approach. At the prediction stage, sim-ilarities to previously rated items are decayed as time difference in-creases. The decay rate is both user-dependent and item-dependent. Sugiyama et al. [17] proposed a personalized web search engine, where they let the user profile evolve over time. There, they distin-guish between aspects of user behavior computed over a fixed time decay window, and ephemeral aspects captured within the current day. In a prior work, we suggested an incremental modeling of global effects [1], which include some baseline time effects. This scheme was later enhanced [11, 21].

Our work is within the topic of tracking and modeling concept drift, which has gathered much interest in the data mining commu-nity. Early works in the field (e.g. [15, 25]) used techniques like adjusted and decayed weights of past instances or using a sliding time window. Another approach popular in newer publications (e.g. [7, 16, 24]) is based on maintaining an ensemble of models capable of capturing various states of the data. As explained in Sec. 3, the problem of tracking user preferences, especially in a collaborative filtering scenario, requires different approaches.
Tracking the temporal dynamics of customer preferences to prod-ucts raises unique challenges. Each user and product potentially goes through a distinct series of changes in their characteristics. Moreover, we often need to model all those changes within a sin-gle model thereby interconnecting users (or, products) to each other to identify communal patterns of behavior. A mere decay of older instances or usage of multiple separate models lose too much sig-nal, thus degrading prediction accuracy. The solution we adopted is to model the temporal dynamics along the whole time period, allowing us to intelligently separate transient factors from lasting ones. We applied this methodology with two leading recommender techniques. In a factorization model, we modeled the way user and product characteristics change over time, in order to distill longer term trends from noisy patterns. In an item-item neigh-borhood model, we showed how the more fundamental relations among items can be revealed by learning how influence between two items rated by a user decays over time. In both factoriza-tion and neighborhood models, the inclusion of temporal dynam-ics proved very useful in improving quality of predictions, more than various algorithmic enhancements. This led to the best results published so far on a widely analyzed movie rating dataset. [1] R. Bell and Y. Koren. Scalable collaborative filtering with [2] R. M. Bell, Y. Koren and C. Volinsky. Modeling [3] J. Bennett, C. Elkan, B. Liu, P. Smyth and D. Tikk (eds.). [4] J. Bennet and S. Lanning. The Netflix Prize. KDD Cup and [5] J. Canny. Collaborative filtering with privacy via factor [6] Y. Ding and X. Li. Time weight collaborative filtering. Proc. [7] J. Z. Kolter and M. A. Maloof. Dynamic weighted majority: [8] Y. Koren. Factorization meets the neighborhood: a [9] G. Linden, B. Smith and J. York. Amazon.com [10] A. Paterek. Improving regularized singular value [11] G. Potter. Putting the collaborator back into collaborative [12] P. Pu, D. G. Bridge, B. Mobasher and F. Ricci (eds.). Proc. [13] R. Salakhutdinov, A. Mnih and G. Hinton. Restricted [14] B. Sarwar, G. Karypis, J. Konstan and J. Riedl. Item-based [15] J. Schlimmer and R. Granger. Beyond incremental [16] W. N. Street and Y. Kim. A streaming ensemble algorithm [17] K. Sugiyama, K. Hatano and M. Yoshikawa. Adaptive web [18] G. Takacs, I. Pilaszy, B. Nemeth and D. Tikk. Major [19] G. Takacs, I. Pilaszy, B. Nemeth and D. Tikk. Matrix [20] C. Thompson. If you liked this, you X  X e sure to love that. The [21] A. Toscher, M. Jahrer and R. Legenstein. Improved [22] A. Tsymbal. The problem of concept drift: Definitions and [23] A. Tuzhilin, Y. Koren, J. Bennett, C. Elkan and D. Lemire [24] H. Wang, W. Fan, P. S. Yu, and J. Han. Mining concept [25] G. Widmer and M. Kubat. Learning in the presence of
