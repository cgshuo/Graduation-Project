 A large number of recommender systems have been developed to serve users with interesting news, ads, products or other contents. One main limitation with the existing work is that they do not take into account the inventory size of of items to be recommended. As a result, popular items are likely to be out of stock soon as they have been recommended and sold to many users, significantly affecting the impact of recommendation and user experience.

This observation motivates us to develop a novel aware recom-mender system. It jointly optimizes the recommended items for all users based on both user preference and inventory sizes of different items. It requires solving a non-smooth optimization involved esti-mating a matrix of n  X  n , where n is the number of items. With the proliferation of items, this approach can quickly become computa-tionally infeasible. We address this challenge by developing a dual method that reduces the number of variables from n 2 to n , signifi-cantly improving the computational efficiency. We also extend this approach to the online setting, which is particularly important for big promotion events. Our empirical studies based on a real bench-mark data with 100 millions of user visits from Tmall verify the effectiveness of the proposed approach.
 H.1.0 [ Information Systems Applications ]: Models and Princi-ples General; I.2.6 [ Artificial Intelligence ]: Learning Model,Optimization Recommendation; Tmall; Online Learning
Tmall ( www.tmall.com ), a business unit of Alibaba group, is the largest third-party platform for brands and retailers in China. Since 2008, it has served more than 100 millions of costumers and 100 thousands of merchants, including a large number of Chinese and international famous brands. According to the public report the Gross Merchandise Volume (GMV) of Tmall exceeds 45 billion dollars in the last quarter of 2014, and 9 billion dollars for the 11/11 day of 2014.

In order to help customers find products of interests and im-prove the chance of making online purchase, online recommenda-tion techniques have been studied and deployed extensively on the Tmall platform, resulting in significant increase in revenue. In this paper, we are focused on the recommendation function on detailed pages, named  X  X lso view X : before a consumer decides to purchase an item (i.e. a product) from Tmall, he/she will first visit the  X  X etail page X  of the item that contains information such as title, descrip-tion and reviews of items. To effectively utilize the traffic to detail pages,  X  X lso view X  recommends to consumers a subset of items that are closely related to the displayed item on the detailed page. Fig. 1 shows the detail page of a silk blouse as an example, together with recommended items highlighted by a circle. Many computational approached have been developed to support the recommendation function in literature. For example, click-through rate (CTR) mod-els have been developed [9, 30, 15] that aim to recommend items with the largest CTRs. Multiple similarity functions have been ex-plored [10, 27, 28] recommend items with the largest similarities to the displayed one. Markov chain or matrix factorization meth-ods [22, 31, 20] have been developed to recommend items with the highest potential for next-to-buy.

One main limitation of the existing works in e-commerce is that they did not take into account the inventory size of items to be rec-ommended. Given the limited number of items stocked by mer-chants, a naive recommender system could encounter the situation where all/most the recommended items for certain user visits are out of stock, significantly reducing the impact of recommendation. We found that this issue is particularly severe when coming to the big promotion day, in which popular items are often sold out in the first a few hours and as a result, our recommendation system was unable to make appropriate recommendation for many user visits. This observation motivates to develop a stock aware recommender system that select recommended items based on both the user pref-http://www.alibabagroup.com/en/global/home Figure 1: An example of detail page and recommendations by  X  X lso view X . erence and the inventory size of items. The key contributions of this work are:
The rest of this paper is organized as follows. Section 2 gives re-views on recommendation systems and budget constrained adver-tising methods. Section 3 then describes the proposed model, fol-lowed by its online extension. Experimental results are presented in Section 5, and the last section gives some concluding remarks.
Notations: In the sequel, we denote by  X  &gt;  X  the transpose of vec-tor/matrix, by  X   X   X  the elementwise matrix (vector) multiplication and by  X   X  the projection onto convex set  X  .
In the past decade, recommender system has been examined ex-tensively in literature [3, 23]. Most recommender systems can be classified into four categories, including demographic filtering [12], collaborative filtering [6, 24], content-based filtering [13, 25] and hybrid filtering [21]. None of these methods take into account the stock condition either on training or recommending stage.
Our work is also closely related to online advertising systems [1, 11, 16]. Given a query, the search engine will display proper ads to users based on their relevance scores and the auction result, and get constraints are taken into consideration, the problem becomes similar to ours. Without assuming the distribution of queries, bud-get restricted advertising can be approximately casted into an on-line learning problem, and multiple error bounds have been es-tablished [5, 16]. Multiple settings of budget restricted advertis-ing, e.g.  X  X nreliable estimation X  and  X  X andom permutation X , have been proposed and studied in [14, 7]. Besides revenue, Karande et al. [11] develop a system and algorithms for various objectives, such clicks and ad quality. Recently, Agarwal et al. [1] propose a budget pacing algorithm such that the advertisers may stay on the platform longer before using up their budgets.

Although budget restricted online advertising share similarity with stock aware recommend, the specific approaches developed for online advertising are unsuitable for our problem due to the fol-lowing reasons
Let n be the number of items to be purchased online, and each item i  X  { 1 , 2 ,...,n } is associated with an unique detail page. For each item i , we introduce a tuple { p i ,s i ,f i ,r price, its inventory size, its expected traffic flow, and its estimated conversion rate, respectively. In particular, We note that both f i and r i are estimated from the historical data. C i,j denotes the probability of clicking the ad for item j from the detail page of item i , and can be estimated from the log data. Note that C is usually extremely sparse. Throughout this work, we as-sume that CTR matrix C is pre-computed.
 The objective of stock aware recommendation is to revise the CTR matrix C by explicitly taking into the stock information in s as well as other information of items (i.e. the price p i the recommendation matrix A = ( a 1 , a 2 ,..., a n ) &gt; where A i,j represents the chance of recommending item j when someone is visiting the detailed page of item i . Our goal is to opti-mize A , based on C and the stock information of items.
Using the introduced notations, the expected sales for item i can be computed as follows: where C  X  A is the element wise product between two matrices, and ( C  X  A ) &gt; f i measures the additional number of visits to the detail page of item i via our recommender system. Since f ( C  X  A ) &gt; f i computes the expected traffic, including both the di-rect visits and the traffics through recommendation, calculates the average number of sales for item i . By taking the minimum value between s i and r i f i + ( C  X  A ) &gt; f i pression in (1) yields the sales for item i that takes into account the stock size. By adding up the expected sales from all items, the total sales is computed as
Directly optimizing R ( A ) may not be desirable because CTR matrix C , traffic flow f i , and conversation rate r from historical data and are therefore noisy when computing A . To alleviate the impact of estimated noise in C , f i and r i larize the solution for A by introducing the entropy function as a regularizer, which is defined for probability vector a as Combining the objective R ( A ) and the regularizer H ( a ) , we have the following optimization for stock aware recommendation where parameter  X  balanced the tradeoff between the objective and the regularizer, and domain  X  is defined as The first set of constraints A i,j  X  0 ensures that all elements in A are non-negative. The second set of constraints enforces each column vector to be a probability distribution. This follows the fact that the recommendation in one detail page is modeled as a unit resource to be allocated to all other items. The last set of constraints ensures that both A and C share the same sparse pattern, which is very important for reducing computational cost given hundreds of millions of items to be handled in our case.
There are two challenges in solving the optimization problem in (2). First, the number of variables to be optimized in (2) is O ( n making it computationally challenging. Second, the objective func-tion R ( A ) is piece wise linear and therefore non-smooth in terms of variable A , leading to relatively slow convergence rate. We ad-dress the computational challenges by developing a dual formation for (2) in which the objective function is smooth and the number of variables to be optimized is linear in n .

To develop our dual formation for (2), we need the following proposition to deal with min(  X  ,  X  ) .

P ROPOSITION 1. Given any scalar { a,b } , following equality holds: Using the above proposition, we introduce dual variables  X  = {  X  1 , X  2 ,..., X  n } to [min(  X  )] s X  in (2) and rewrite the optimization problem in (2) as an optimization problem in terms of dual vari-ables  X  , as revealed by the following theorem.

T HEOREM 1. The dual problem of (2) is given by min and the solution to A is given by where where I ( z ) is an indicator faction that outputs 1 if z is true and zero otherwise, and
P ROOF . Using the dual variable  X  , we rewrite (2) into convex-concave optimization problem  X  max  X  min where g = s  X  ( r  X  f ) and the last step follows the Von-Newman lemma. To compute the optimization over A , we use the following lemma.

L EMMA 1. The optimization problem admits a unique optimal solution The above lemma can be found in the standard literature for convex optimization, e.g. [18, 29]. Using Lemma 1, it is straightforward to obtain the expression for A in (4). Z i is the normalization factor that ensure the sum of each row of A is 1 and is given by Since A i,j can be expressed in terms of dual variables  X  , for each row i we obtain Plug above equation into (5), we can find the optimal  X  by solving the following the optimization problem min
One nice feature of the dual formulation in (6) is that its objective property is revealed by the following theorem.

T HEOREM 2. The optimization problem (6) is convex and smooth w.r.t.  X  . Moreover, the Hessian matrix H (  X  ) of the objective func-tion is upper bounded by where diag ( v ) denotes a diagonal matrix V with V i,i = v v . 2 = ( v 2 1 ,v 2 2 ,...,v 2 n ) is elementwise square for a vector v .
P ROOF . To prove the theorem, we need to introduce two useful lemmas.

L EMMA 2. [17] The duality of a  X  -strongly convex function is convex and 1  X  smooth.

L EMMA 3. [4] The maximum over a set of linear function is convex, i.e. F ( a )  X  max i F i ( a ) is w.r.t. a when F functions.

It is well known that  X  X  ( a ) is a 1-strongly convex w.r.t. norm k  X  k 1 over the simplex [18, 29], then  X  P n i =1 f strongly convex as f i  X  0 ,  X  i . Moreover,using Lemma 3 we have the function max  X  s i ,  X  r i f i + ( C  X  A ) &gt; f i convex. As a dual(i.e. (6)) is convex and ( 1  X  min
Now we consider the second part. Noting that the Hessian of is H i with summation over i = 1 , 2 ,...,n , the conclusion follows.
Finally, since our approach is a first order method In addition, we need to calculate the gradient of G (  X  ) , which is given as
A function F ( a ) is  X  -strongly convex w.r.t. some norm kk over a compact set S if the following inequality holds for any a ,  X  a  X  X  Algorithm 1 Accelerated Gradient Descent 1: Initialization: p = q = 1 ,  X  0 =  X  1 = p 2 , X  max = 10000 2: Compute the diagonal Hessian 3: for t = 1 ,...,T do 4: Compute auxiliary solution  X   X  as 5: Set p = q 6: Compute matrix A (  X   X  t ) as (4) 7: Compute the gradient as 8: Set  X  =  X  max 9: Update the solution of  X  by 10: if the inequality (8) fails to hold then 11: Set  X  =  X / 10 and goto 9 12: end if 13: Compute 14: end for Return solution A (  X  T )
Together with the upper bound of Hessian matrix, we have the solution updated from  X  t to  X  t +1 by where This update scheme admits a special case of adaptive gradient de-scent methods [8] and has a strong convergence guarantee.
We can further improve the convergence of the above algorithm by exploring the accelerated gradient methods [2, 19]. In particu-lar, we introduce a parameter  X  and auxiliary solution  X   X  into the algorithm, such that  X   X  is a combination of  X  t and  X  t +1 . It is introduced to take ad-vantage of the smoothness of the objective function to speed up the convergence. One of the key component of the accelerated gradi-ent descent method is to determine the step size. We follow the Nesterov X  X  approach. It starts with a large step size  X  and gradually reduces it until the following inequality holds More details are given in Algorithm 1. Note that since diag ( w ) is the upper bound of Hessian, L in Algorithm 1 is lower bounded by 1. The convergence rate of accelerated gradient descent method is O (1 /T 2 ) [17, 19, 2]. It is also known that the Nesterov X  X  method achieves the optimal convergence rate for optimizing smooth ob-jective function.
One problem with the offline optimization method presented in and r . It is known that these quantities, despite the best efforts, can not be estimated accurately and reliably. Below, we list two examples that illustrate these quantities can be seriously affected by unpredictable things: The above observations motivate us to develop an online learning framework for stock aware recommendation that can utilize online information to make better estimation for quantities f and r . But, on the other hand, due to the limited computational resources that are available for online updating, we need to develop efficient up-dating algorithms that allow us to effectively update the dual vari-ables without having to accurately solve the optimization problem in (6).

Let t = 1 ,...,T be T different time points, and let s t , r C t be the stock, conversation rate, traffic data, and CTR that are online computed based on the real-time user feedbacks. Using the can be written as It is easy to verify that the objective is indeed the same to (2) in the view of optimization.

Now, instead of using the same solution A over all time points, therefore the objective function becomes Similar to that in Section 3.2, we rewrite the objective as where As a result, we will online update the dual variables, instead of the dual variables, because the number of dual variables is significantly smaller than the number of primal variables.
 Our online updating approach is based on the fact that function G (  X  t ) is smooth. In particular, its Hessian H t is upper bound in a similar way: where L = max matrix.

At the beginning of the t  X  th time slot, we do not know the true mation. One possible estimation will be  X  Since s , the total inventory stock, is known before hand, we can compute s t based on the difference between the consumption and s t  X  1 . Thus, we will assume s 1 ,..., s T are known to the online updating process.

Our algorithm is based on the extra gradient algorithm that was originally developed for smooth objective function. Different from most optimization algorithm, it maintains two sets of solutions, i.e. real solutions  X  1 ,  X  2 ,..., X  T and auxiliary solution  X   X  We start with some initial solution  X  1 =  X   X  1 . At each time point t , we employ {  X  r t ,  X  f t ,  X  C t } to construct a function approximate the function G t (  X  ) . Formally, we define  X   X 
G t (  X   X  t ) =  X  [  X   X  t ] &gt;  X  g t
Using  X  G t (  X  ) , we update the solution  X  t by where  X  &gt; 0 is the step size and is often set as 1 / This computed  X  t will then be used to compute A t (  X  t ) for recom-mendation. After time point t , we observe the true quantities r C , and update the auxiliary solution  X   X  t by The auxiliary step can be regarded as a calibration  X  G t
R EMARK 1. As there may be not enough traffic flow at time t  X  1 to estimate an accurate { r t , f t ,C t } , one may use a decay update as where  X  r t the true conversion rate at time t . Moreover, we set  X  r r
We deployed the Algorithm 1 on www.Tmall.com , and per-form experiments on a large volume of real traffic. Our first base-line is the CTR-first recommender system that always recommends items with highest C i,j s.
We first report the result for all item as a whole and then zoom in on four representative categories to see more details. Table 1: Performance w.r.t.  X  X caled #clicks X  and  X  X caled sales revenue X  at the end of each day.
 Wednesday 1 0.908609 1 1.164695
Improvement -14.33% 15.76%
Since considering the conversion rate (CVR) may help the im-provement of sale revenue, our second baseline is the CTR*CVR tion 5.1. Due to the space limitation, we only report results of four days. As can be seen in Figure 5, the proposed stock aware recom-mendation system outperforms the CTR*CVR method in terms of both the number of clicks and the sales revenue in all cases, where the overall improvements for clicks and revenue are 11 . 31% and 12 . 48% , respectively. This result indicates that the proposed ap-proach is more effective than a simple CTR*CVR based method in making the tradeoff between CTR and revenue.
Due to engineering issues, we don X  X  have the evaluation result for the proposed online algorithm with live traffic. Instead, we demon-strate the effectiveness of online stock aware recommendation us-ing synthetic data sets with 100 items that are generated as follows: price p , the inventory size s and conversion rates r are generated by sampling numbers from a uniform distribution while traffic flows f and CTR matrix C are created by sampling numbers from Gaussian distributions. The parameter  X  is manually chosen to maximize the performance.

At the prediction stage, a stream of customers (as the traffic flow f but in random order) arrives and takes actions following param-eters { p , s , r ,C } . The sales revenue is then recorded as perfor-mance measure. Since the main motivation of online algorithm is to catch the changes in traffic flow and conversion rate 3 f and r before testing as following.
The online algorithm uses its batch counterpart as an initial so-lution, and updates the dual solutions based on the procedure de-scribed in Section 4. To reduce the impact of variance, all the ex-periments are repeated for 10 times. Average results are shown in Figure 6. We observe the results that are consistent with the ones reported in the previous subsections: the CTR*CVR method per-forms slightly better than the CTR-first method in terms of sales revenue, while the proposed batch learning algorithm outperforms both methods, particularly when the number of impression is suffi-ciently large. It is not surprising to observe that the proposed online learning method yields the best performance since it can catch the change in information and therefore is most sensitive to the case of out of stock. The advantage of the proposed online learning algo-rithm is further illustrated in Figure 7 where we show the number of out of stock views. We clearly observe that the online learning algorithm yields the smallest number of out of stock views. It is slightly to our surprise that the CTR*CVR performs even worse than CTR-first in terms of out of stock views.
In this paper, we propose a stock aware recommender system in e-commerce and extend it to online setting. The key idea is to optimize the recommendation selection for individual users based on both user preference and the limit of stock supply. We deploy
The CTR of  X  X lick ads of item j in the detail page of item i  X  is relative stable, so we keep it as constant here. this system to Tmall.com, the Chinese largest B2C platform, and verify the effectiveness of our approach using the live traffic from Tmall. Experiments with more than 100 million use visits shows that the proposed method can significantly improve the sales rev-enue of item-to-item recommendation. In the future, we will con-tinue working on the online setting for stock aware recommenda-tion and verify its effectiveness using the real traffic from Tmall.
Our research was partially supported by Tianchi Research plat-form "http://tianchi.aliyun.com/". We thank the reviewers for very detailed and valuable comments.
 [1] D. Agarwal, S. Ghosh, K. Wei, and S. You. Budget pacing for [2] A. Beck and M. Teboulle. A fast iterative shrinkage-[3] J. Bobadilla, F. Ortega, A. Hernando, and A. Guti X rrez. [4] S. Boyd and L. Vandenberghe. Convex optimization . Cam-[5] N. Buchbinder, K. Jain, and J. S. Naor. Online primal-dual al-[6] L. Candillier, F. Meyer, and M. Boull X . Comparing state-[7] N. R. Devanur and T. P. Hayes. The adwords problem: on-[8] J. Duchi, E. Hazan, and Y. Singer. Adaptive subgradi-[9] T. Graepel, J. Q. Candela, T. Borchert, and R. Herbrich. [10] T. Hofmann. Learning the similarity of documents: An [11] C. Karande, A. Mehta, and R. Srikant. Optimizing budget [12] B. Krulwich. Lifestyle finder: Intelligent user profiling using [13] N. Landia and S. Anand. Personalised tag recommendation. [14] M. Mahdian, H. Nazerzadeh, and A. Saberi. Allocating on-[15] H. B. McMahan, G. Holt, D. Sculley, M. Young, D. Ebner, [16] A. Mehta, A. Saberi, U. Vazirani, and V. Vazirani. Ad-[17] Y. Nesterov. Introductory lectures on convex optimization: A [18] Y. Nesterov. Smooth minimization of non-smooth functions. [19] Y. Nesterov. Gradient methods for minimizing composite ob-[20] M. Nickel, V. Tresp, and H.-P. Kriegel. Factorizing yago: [21] C. Porcel, A. Tejeda-Lorente, M. Mart X nez, and E. Herrera-[22] S. Rendle, C. Freudenthaler, and L. Schmidt-Thieme. Factor-[23] A. Said and A. Bellog X n. Comparative recommender system [24] X. Su and T. M. Khoshgoftaar. A survey of collaborative fil-[25] R. Van Meteren and M. Van Someren. Using content-based [26] H. R. Varian. Position auctions. international Journal of in-[27] W. Wu, H. Li, and J. Xu. Learning query and document [28] W. Wu, Z. Lu, and H. Li. Learning bilinear model for match-[29] L. Xiao. Dual averaging methods for regularized stochastic [30] C. Xiong, T. Wang, W. Ding, Y. Shen, and T.-Y. Liu. Rela-[31] G.-E. Yap, X.-L. Li, and S. Y. Philip. Effective next-items
