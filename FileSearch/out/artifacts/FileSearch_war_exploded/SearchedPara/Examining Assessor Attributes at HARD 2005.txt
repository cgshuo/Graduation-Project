 Categories and Subject Descriptors: H.3.3 [Informa-tion Storage and Retrieval]: Information Search and Re-trieval -Relevance feedback.
 General Terms: Performance, Experimentation Keywords: Query expansion, clarification forms
The TREC HARD (High accuracy Retrieval from Doc-uments) track was motivated to investigate techniques for personalised retrieval of documents. Through the use of a limited dialogue with the TREC assessors, the track facil-itated the gathering and exploitation of information about the assessors X  personal search context (e.g. knowledge of search topic) which could be used to improve document re-trieval. In this paper we describe experiments, run within the context of the 2005 HARD track, which indicate that as-sessor attributes such as familiarity, interest and confidence when searching a topic can help determine when the utili-sation of automatic query expansion improves retrieval over the original document ranking.
The HARD track protocol is as follows. First a set of 50 topics were distributed to the participating groups who each perform a baseline retrieval run on the AQUAINT doc-ument corpus. Each group is then allowed to ask the topic assessor to complete a clarification form for each topic they will assess. Each form was designed to gather personal, con-textual information about the assessor X  X  relationshi pto the topic which can be used for personalising the search. Con-textual knowledge could consist of information on the asses-sor X  X  knowledge of the topic or their confidence in judging retrieved documents. Once this data had been gathered it was used to re-rank the baseline run, typically by performing some form of query modification. The new retrieval runs are returned to TREC, with the results from by both the base-line and modified retrievals evaluated by the assessor who completed the clarification form.

Our interest was to compare techniques that might per-form well under different searcher contexts. Specifically we looked at assessor knowledge of the search topic, asses-sor interest in the topic and assessor confidence in judging docume ntsabou tthetopic .Weas kedtheassesso rabout these aspects in the clarification form using a 3-point scale (high/average/low for each attribute) [1, 2]. Our aim was to analyse the relative effectiveness of retrieval strategies across these attributes, with assessors separated by their responses, against a baseline run; Okapi BM25 using the short title of each TREC topic. The strategies we investigated were:
Query expansion using representative terms: Terms from the top N ranked documents (topic language model) were scored by how representative they were to a topic using the Kullback-Leibler distance between the topic and collec-tion language model [3]. Representative terms are those that are very general or common to a topic. We then se-lected the top Q representative terms to expand the original query, performing a new retrieval. We hypothesised that assessors with low topical knowledge, for example, would benefit from this technique as it would lead to the retrieval of more general, introductory documents about a topic.
Query expansion using discriminatory terms: Dis-criminatory terms are those that are specialised or infre-quent with respect to a topic. We selected the top Q dis-criminative terms for a topic and added these to the query to perform a new retrieval. We hypothesised that assessors with high knowledge of a topic would benefit from this tech-nique as it would lead to the retrieval of less general but more detailed documents on a topic.

Query expansion using emotive terms: Documents that are more interesting to read may be ones that could lead the assessor to read in more detail (and hence find rel-evant information) or are more suitable for assessors who are less interested in the topic being search. To test this as-sumption, we carried out a query expansion using emotive terms. Emotive terms are those that carry an emotional im-pact, e.g. dramatic, significant, amazing. We extracted 280 of these from a thesaurus and, for each topic, selected those terms that contributed most to the topic language model, expanding the original query to provide a new retrieval [1]. The new retrieval prioritises those documents that contain emotive text.

Retrieval by readability: Assessors with low interest, knowledge, or confidence in assessment may find it easier to assess documents that are easier to read. To investigate this we used a combined readability score measure which com-bines the document Retrieval Status Value with the Flesch readability score, which assigns high values to documents that are more readable [4].

Pseudo-relevance feedback: Our final retrieval strat-egy was a query modification strategy based on Pseudo-relevance feedback. The original query was then expanded by the top Q terms that contribute most to the top N doc-uments. This was a benchmark strategy to compare against our novel approaches.

Our hypotheses -compressed into a general hypotheses here for space reasons -was that individual techniques would work better for different assessor attributes (knowledge, in-terest, confidence). We also investigate the relative effect of assessor attribute and topic to retrieval success. Our inves-tigation examines which strategies performed best for each assessor grou pe.g. assessors with low to pical knowledge.
We examined various combinations of N and Q ranging from N =1 ,..., 25 and Q =1 ,..., 40.Wepresenttheper-centage improvement (or deterioration) in R-precision over the OKAPI BM25 baseline for the optimal parameter setting only for each technique (Table 1). We also present the num-ber of topics where there was an improvement over the base-line across the various aspects of assessor attributes. Over-all, expanding the query with discriminative terms ( Disc. ) and also Pseudo-relevance feedback ( Pseudo. ) performed best for all 50 topics, while utilising document readability and query expansion using emotive terms were worst.
When examining the performance of each technique across the different levels of assessor familiarity ( Famil. ) we found that expanding the query using Disc. improved over the baseline by 10% for assessors with high topic familiarity. This was in agreement with our original assumption. Using pseudo-relevance feedback did provide better improvement, 12.6%, although for one topic there was no gain at all. How-ever, expanding the query with representative terms ( Rep. ), did not benefit those assessors with low topic familiarity. Examining the performance of each technique across the different levels of assessor interest in a topic we found that using Disc. improved document ranking for those assessors with average to low topic interest. Also, when examining the performance of each technique across the different levels of assessor confidence in assessing a topic we again discov-ered that Disc. improved document ranking for those as-sessors with low confidence. Finally, when examining the performance of each technique across the various assessors separately, it was highlighted that assessors  X  X  X  and  X  X  X  were more receptive to Disc. than others such as  X  X  X  and  X  X  X .
There was evidence to suggest that assessor attributes such as familiarity, interest and confidence could be utilised as part of a decision mechanism to determine when per-forming automatic query expansion for improving document ranking. Although sample sizes are relatively small, the results indicate that particular assessor attributes may be more conducive to successful query expansion, especially when using discriminative terms. Further investigation is re-quired to confirm these assumptions. Of particular interest is to determine whether expanding the query with discrim-inative terms does indeed retrieve more suitable documents or if the improvement in retrieval is a consequence of the ac-tual document assessment process. For example, assessors  X  X  X  and  X  X  X  assessed more documents relevant, on average, than the remaining assessors, which may be a contributing factor to the improved performance [2]. Future work will investigate these issues in greater detail. [1] M. Baillie, D. Elsweiler, E. Nicol, I. Ruthven, S. [2] I. Ruthven, M. Baillie and D. Elsweiler. The relative [3]D.J.Harper,G.Muresan,B.Liu,I.Koychev,D.
 [4] N.J. Belkin, I. Chaleva, M. Cole, Y.-L. Li, L. Liu, Y.-H.
