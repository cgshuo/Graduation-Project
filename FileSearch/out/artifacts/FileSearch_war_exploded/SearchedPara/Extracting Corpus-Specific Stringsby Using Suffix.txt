 In this paper, we propose a new algorithm for term extraction which considers all the substrings as term candidates. Term extraction is a task aimed at the ex-traction of phrases characterizing a given corpus. In our problem setting, we also use a reference corpus that is used to characterize the target corpus. Applications of such all-substring term extraction algorithms include finding the phrases that characterize some specific regions (such as the Western area in Japan compared to the Eastern area), some specific authors (such as young people), some specific topics (such as computer science), som e time spans (such as in recent one year), etc. Typical term extract ion algorithms use TF-IDF scores to rank phrases. In-stead, we use a Bayesian probabilistic model for the scoring function because it is suitable in our situation where the task does not demand the extraction of document-specific phrases, but the extraction of corpus-specific phrases, which makes it difficult to use document frequency scores effectively.

Previous term extraction systems for Asian languages make a set of can-didate phrases by performing morphological analysis on the corpus, obtaining the term candidates by concatenating successive nouns, and ranking the ex-tracted candidates. However, extracting candidates before considering the merit of each chunk as a corpus-specific phrase can miss numerous substrings that are document-specific phrases but cannot be ext racted easily using heuristic candi-date extraction rules.

In this paper, we propose an algorithm to use all the substrings of the given corpus as term candidates. Our algorithm extracts term candidates in a reason-able time by using suffix arrays and a scoring function that indicates the merits of substrings as linguistic chunks and can be calculated in a bottom-up manner. Several algorithms for term extraction have been proposed in literatures [1], [2], [5], [11]. Term extraction is typically performed by extracting a list of term candidates and then ranking them by a scoring function that represents the  X  X er-mhood, X  which indicates how good each candidate term is as a term. The recent growth of electronic texts available on t he Internet has resulted in many scoring functions using corpus statistics proposed in the past decade. They typically compare the frequency of the term in the corpus with the frequency outside (i.e., its frequency in the document other than the target corpus). TF-IDF is a well-known example of this approach. They usually extract term candidates by performing morphological analysis on the text and extracting the sequence of words with specific POS sequences. For languages with no word boundaries, e.g., Japanese, word segmentation is also performed in morphological analysis. To the best of our knowledge, no previous work has considered all substrings as term candidates.

Few researchers propose considering all the substrings as feature candidates for machine learning [4], [10]. The algorithm by Okanohara et al. [10] uses suffix arrays for data structure to enum erate all substrings efficiently. We assume that the input to our system is a pair of corpora &lt;C,C &gt; . C is a target corpus from which we want to extract term-specific phrases. C is a reference corpus , which is used to characterize the target corpus. Corpus C is assumed to be a string. For a set of documents, C is a result of concatenating those documents into one string. The output of the system is a list of substrings that are characteristic to corpus C compared with the r eference corpus C .Thus, C should be relatively a set of unbiased texts compared to C . 1
We denote the concatenation operation by a period. (e.g., x.y means the substring by concatenating x and y ). 3.1 Suffix Arrays and LCP A suffix tree [13] is a tree structure that is a modified trie for all suffixes of the given string (i.e., the corpus for our problem setting). The difference between a suffix tree and a trie is that all the nodes with only one branch are removed where the edge labels are concatenated. Becaus e suffix trees are ver y space-consuming, we instead use the suffix arrays explained below for our implementation, which can emulate the search on suffix trees.

A suffix array [6] is a data structure that represents all the suffixes of a given string and is a sorted array of all suffixes of the string. Given the corpus C and C , after concatenating them into one corpus C ,weconstructthesuffix all suffixes of C are sorted in alphabetic order. Moreover, we assume that we have the label array L = &lt;l 1 ,l 2 ,  X  X  X  l n &gt; ,where l k = 1, 0 if the index i k is in the target corpus and the reference corpus, respectively. By using the suffix array constructed on the corpus S , all the positions of s in S can be obtained quickly (in P ( logN ) time, where N is the length of S ) for any s . They require 4 N bytes 2 of additional space in order to store indexes and even more space for construction. Here, we assume that both the corpus and the suffix array are in memory.

The longest common prefix (LCP) array is defined as the array that records the length of the longest string that i s common in two consecutive suffixes in the suffix array, i.e., LCP [ i ] is defined as the length of longest common prefix between SA [ i  X  1] and SA [ i ].

We denote the frequency of s appearing in corpus C by freq ( s, C ). We also define freq ( s )= freq ( s, C )+ freq ( s, C ), i.e., the number of appearance of string s in both C and C . We use a phrase score SS ( s )forstring s defined as: This score can be seen as the Bayesian a posterior probability of s being in corpus C after observing freq ( s, C )and freq ( s, C ).  X  1 and  X  2 are parameters that indicates  X  X he confidence of the prior knowledge about the score. X  It can be regarded as assuming that we observed  X  2 samples before observing actual samples. Currently, we set the number of these  X  X irtual X  samples as 10 and the prior ratio of observing s in C to C is proportional to the ratio of the size of C to the size of C . Therefore,  X  2 issetto10and  X  1 is set to 10  X  | C | | C | + | C | where |
C | is the length of the corpus C .

One of the main problems faced when performing the extraction of  X  X ny-length X  strings is that there are many similar candidates with the same (or very near) SS ( s ) value, and the string with  X  X est boundaries X  should be selected from them. To achieve this goal, we define the following edge scores reflecting the merits of the string as linguistic chunks or the merits of the left and right boundary of string s , i.e. , string s starts and ends at the semantic boundary between words, phrases, sentences, etc.
 The edge score of string s is defined as follows.
 where DL ( s ), the description length of string s , is defined as the number of bits required to select the node in the suffix tree that has an edge label s . We define the description length of string s as the number of bits needed to select it in the suffix tree of corpus C . Note that the description length is calculated as  X  log p , where p is the probability of s and defined as p = freq ( s ) | C | + | C | .
Intuitively, the ES ( s ) score models the merits of the strings as linguistic chunks as the number of areas in the corpus divided by the description length for the string. This score is defined based on the assumption that  X  X  string is likely to be a representative expression if it can cover the corpus with a short description length. X  The term  X  1 is added to freq ( s ) to exclude one-frequency substrings because all of the one-frequency terms c an be extended without increasing the value of DL ( s ), which makes the corpus the best candidate among all one-frequency substrings.
 As will be mentioned in section 5.2, if x is the substring of x and ES ( x ) &lt; ES ( x ), x is removed from chunk candidates. Consider the selection of the right boundary of string s . 3 Note that if only one character c can appear on the right and DL ( s )= DL ( s.c ). Thus, all the substrings corresponding to internal nodes with no branches in the suffix tree can be extended without reducing the ES ( s ) value. Therefore, we only have to consider all the internal nodes in the suffix tree as candidate substrings. Similarly, edge selection with a small number of branches tends to proceed with an increase of ES ( s ) scores, resulting in the preference for longer strings until we face a sudden increase in branch numbers. 4.1 Similarity to other Algorithms Tanaka et al. [12] proposed Kiwi, an algorithm to find appropriate boundaries to extract common expressions starting with the given query string. The idea of Kiwi is to detect a sudden increase in the number of branches in tries, which tends to indicate semantic boundaries (i.e., to be a boundary of linguistic chunks). Our ES ( s ) scoring function also tends to detect such sudden increases of branches as boundaries as mentioned above.

The Kiwi algorithm is designed in order to detect appropriate cutting points when some queries are provided and that the Kiwi score is for one-direction string searches where the query is given. This means that the Kiwi algorithm can find the right boundary of the phrase when the left boundary (i.e., starting point of the phrase) is given, or can find the left boundary when the right boundary is given, but it cannot find the left and right boundary simultaneously when no boundary information is provided first. (For example, it can find the phrase  X  X atural Language Processing X  when the string  X  X at X  is given as a query, or when the string  X  X sing X  is given as a query (for left direction search), but cannot find the phrase if such prefixes or suffixes are not given as queries.) This is because finding  X  X ncrease of the number of branches X  in the Kiwi algorithm needs the  X  X revious number of branches X  and the previous number of branches depend on the search direction and what queries are used first. In other words, boundary detection of the Kiwi algorithm require not only the statistics of the current string, but also the statistics of the previous string, and the previous string is changed according to the search direction and the query string. Thus, the Kiwi algorithm is not suitable for our purpose, i.e., finding the good chunk candidates from the corpus when no previous information about the boundaries is given.

However, our proposed score is able to extract all good chunks from the corpus when no queries are provided because the ES ( s ) score is defined using only high for chunks with the large number of branches as discussed in the previous section, and does not require the statistics of previous strings like the Kiwi algorithm. Therefore, our proposed score can be seen as the generalization of the Kiwi algorithm that provide a way to apply the idea of  X  X etecting increase of the number of branches X  to term extraction in a unified manner. As mentioned above, we only take the strings followed by two or more different characters and can ignore others including substrings with a frequency of 1. This means that we have only to calculate the score of phrases at all the branching nodes in the suffix tree; this calculation is emulated by the suffix array by using the LCP array as complementary information. The following section explains how to calculate scores for all internal nodes in the suffix tree. Scores for each node in the suffix tree are written in the position (in the suffix array) of the first (top) string that starts with the edge label of the node. Note that multiple nodes can thus be associated with the same entry. In such a case, the algorithm overwrites the scores. Thus, the value we find at each entry is the result for the node whose depth is the smallest among those processed so far. 5.1 Bottom-Up Calculation of Scores We define the summation array S to record statistics of subregions. We also define the end position array E and backlink array B . S is used in STEP-2.
Figs. 2 (for STEP-1) and 3 (for STEP-2) show the algorithm, and Fig. 1 shows the example suffix array for explanation. S 0 [ i ]and S 1 [ i ] record the values for the region starting at the position i processed most recently. Note that we reuse these values for processing larger regions. For example, we can use the value S [4] and S 1 [4] in the calculation of the values S 0 [0] and S 1 [0] because the value for the region starting at 4 and ending at 8 is already calculated and recorded at S 0 [4] and S 1 [4].
 At each step, the algorit hm calculates scores ( ES ( s ) in STEP-1 and SS ( s )in STEP-2) of the string and records them to the hash table. Note that the SS ( s ) score in STEP-2 can be calculated in the following way: 5.2 Two-Stage Filtering Algorithm We use a two-stage re-ranking approach for candidate extraction.

After STEP-1, the algorithm makes a list of candidate strings ranked in de-scending order of the ES score. Then, we keep the top N elements in the resulting list 4 .

The extracted lists often contain redundant elements because they contain strings of any length. For example,  X  X ave to do X  and  X  X ave to do it X  can be in the same list. To remove such redundancy, we perform list cleaning on the resulting list. If the n -th element is a substring of the m -th element for n&lt;m , the n -th element is removed from the list: List Clearning If rank ( x ) &gt;rank ( y )and x is contained by y ,then x is re-We make a set K of elements remaining after the list cleaning.

In a similar way, after STEP-2, candidate strings are ranked in the descending order of the SS score. Note that we only consider the bottom-up score calcula-tion, and only the substrings in the set K are included in the candidate list. We also perform list cleaning on the resulting list in order to obtain final results. We used the corpus called  X  X akamono Kotoba Corpus X  X 7], which consists of  X  X asual X  sentences found on the Web. The sentences are provided with  X  X asual words X  tags, where  X  X asual words X  means new words, especially those used by young people.

Note that the corpus is constructed by collecting sentences by querying the words in  X  X akamono Kotoba Dictionary X  to the  X  X ahoo! blog search X  system, thus each sentence in the corpus must include one or more  X  X akamono Kotoba X  terms. Thus, the experimental setting is somewhat  X  X rtificial X  in the sense that the corpus is biased to contain more answer strings (i.e., strings to be extracted) than the corpus constructed not by such keyword search algorithms (e.g., the corpus constructed by collecting all ar ticles including specific tags in the meta-data.)
As a reference corpus C , we collected texts from Twitter by the random sampling function provided by TwitterAPI because Twitter texts are also casual texts written by relatively young people.

Existing term extraction algorithms for Asian languages, e.g., Japanese, typ-ically make a set of candidate terms by performing morphological analysis on the corpus and then extracting nouns or two or more consecutive nouns, as can-didates [9]. Moreover, typical unknown-word extraction systems extract  X  X nde-fined X  tag sequences as candidates of unknown words [8]. Thus, as a baseline, we used Gomoku 5 , a Japanese morphological analyzer implemented as Java classes 6 . Candidate strings are extracted as one or more consecutive nouns 7 ,whichare then ranked in order of SS ( s ) that is the score used in our proposed algorithm. By comparing our algorithm and the baseline, we can investigate the effect of using all substrings as term candidates. 6.1 Evaluation Metrics We used average precision [3] for our performance evaluation. This is the value defined in the ranked list of some elements where the list includes some correct elements that are the elements included in some set of answers . Given a list of extracted terms c 1 ,c 2 ,  X  X  X  c n ranked by the score, and a set of answers (i.e., the set of  X  X akamono Kotoba X ) S = { s 1 ,s 2 ,  X  X  X } , the average precision of the result list is calculated as where precision ( k ) is the accuracy (i.e., the rat io of correct answers to all an-swers) of the top k candidates, and r k represents whether the k -th document is relevant (1) or not (0) (in other words, r k =1if c k  X  S ,and r k = 0 otherwise). We calculated the average precision in several settings by changing the threshold value for the set of answers. When using the threshold  X  , only the answers a whose frequency f ( a )  X   X  are considered.
 Table 1 shows the results. We observed that the proposed algorithm outper-formed the baseline algorithm for highly-frequent terms, such as the average precision for the terms with frequency values equal or more than 100 and 50. Examples of the terms that were extracted by our algorithm but not by the base-line algorithm include phrases that contain two kinds of parts of speech (like a sequence of an adjective and a noun, or a sequence of a noun, preposition, and noun, etc.), and terms that contain no Kanji (Chinese characters). These terms are difficult to extract as candidates by using ordinary morphological analyzers, whereas our algorithm can e xtract them due to the cha racter-based candidate enumeration approach.

However, for the average precision for all the terms, including those whose frequency is 1, neither of the two algorithms showed a good performance. Thus, we need some method to combine these two algorithms by, for example, merging the results by looking at the frequency of each extracted term. This paper proposed a new term extraction algorithm that considers all of the substrings as term candidates. We proposed a suffix-array based algorithm for the efficient calculation of scores, and a two-stage re-ranking approach to combine two scoring functions. Experimental results showed that our algorithm works well, especially for high-frequency ter ms. However, because the proposed algo-rithm does not work well for low-frequency terms, we need to improve our algo-rithm by, for example, merging the results from our algorithm and other algo-rithms looking at the frequency of the extracted terms. Comparing our algorithm with algorithms using unknown word extraction algorithms as preprocessing is also interesting future work.
 Acknowledgement. This work was supported by JSPS KAKENHI Grant Number 24500162.

