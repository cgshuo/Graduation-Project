 We propose a novel approach to context-aware music rec-ommendation  X  recommending music suited for places of interest (POIs). The suggested hybrid approach combines two techniques  X  one based on representing both POIs and music with tags, and the other based on the knowledge of the semantic relations between the two types of items.
We show that our approach can be scaled up using a novel music auto-tagging technique and we compare it in a live user study to: two non-hybrid solutions, either based on tags or on semantic relations; and to a context-free but personal-ized recommendation approach. In the considered scenario, i.e., a situation defined by a context (the POI), we show that personalization (via music preference) is not sufficient and it is important to implement effective adaptation techniques to the user X  X  context. In fact, we show that the users are more satisfied with the recommendations generated by combining the tag-based and knowledge-based context adaptation tech-niques, which exploit orthogonal types of relations between places and music tracks.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Information Filtering Algorithms, Design, Experimentation, Human Factors Music recommendation; context-aware recommendation; hy-brid recommendation; auto-tagging; tag prediction
Music recommender systems are decision support tools that reduce information overload by retrieving relevant mu-sic items based on a user X  X  profile [8]. However, most of the available music recommenders suggest music without tak-ing into consideration the user X  X  context, e.g., her mood, current location, activity, or any other contextual condition that might influence the user X  X  perception or evaluation of music [1]. In response to these observations, in recent years a new research topic of contextual music retrieval and rec-ommendation has emerged [12]. In this work we address a particular type of context-aware music recommendation  X  recommending music suited for places of interest (POIs). Finding music items that suit POIs can be exploited in a number of engaging information services. In particular, we have considered a scenario in which a mobile city guide pro-vides an enhanced presentation of a place for a tourist by playing music that is related to the place, i.e., music that is culturally or emotionally associated with the place (e.g., a Mozart sonata in Salzburg or a Bach fugue in a Gothic Cathedral) [6].

The main challenge to face when addressing the above mentioned goal is related to the fact that POIs and music are two rather different domains, and there is no obvious way to match such heterogeneous items. In previous works [6, 11], we have developed two alternative techniques to solve the problem of matching music and POIs  X  one based on a common representation of both types of items, and the other exploiting semantic relations between the items.
The first technique represents items in the two domains with a common set of features  X  user-assigned tags describ-ing the emotional properties of music and POIs [6]. We de-cided to use tags that describe emotional properties of the items, since music and places can both raise emotions, and the commonality of these emotions could provide the base for establishing a degree of match between a place and a music track. The tag-based representation allows matching music tracks and POIs by comparing the tag profiles of the items.

The second technique is based on extracting explicit knowl-edge about items in the two domains [11]. Obtaining such knowledge automatically has become possible with the ad-vent of the Semantic Web and specifically with its reference implementation in the Linked Data initiative [5]. We have exploited the DBpedia Linked Data repository to build a framework in which semantic networks linking items from music and POI domains are automatically created. These networks are represented as graphs, on which a graph-based algorithm is run to rank the items in the music domain with respect to their relatedness to an item in the POI domain.
These two techniques  X  tag-based and knowledge-based  X  represent two complementary ways of establishing a match between a place and a music track: a track may  X  X eel right X  for a POI or it can be linked to a POI by factual rela-tions (e.g., belonging to the same cultural era or composed by someone whose life is related to the POI). In previous works, we have evaluated the two techniques independently on different datasets and against a simple baseline (random recommendations). In this paper, we take some next steps toward location-aware music recommendation by (i) propos-ing a hybrid recommendation approach which combines the tag-based and knowledge-based techniques using rank aggre-gation, (ii) proposing an extension to the tag-based tech-nique to scale up the tagging process for the music tracks employing a state-of-the-art auto-tagger , and (iii) evaluat-ing the performance of these techniques on a dataset of POIs and music tracks against personalized recommenda-tions. We have validated the research hypothesis that the combination of knowledge-based and tag-based techniques is preferred by the users over the recommendations produced by each technique separately and over the classical person-alization approach.
 The remainder of the paper is structured as follows. In Section 2 we overview works related to location-aware mu-sic recommendation and music auto-tagging. Section 3 de-scribes the used dataset of music tracks and POIs. In Section 4 we describe the automatic tag prediction technique that we have used for tagging music tracks. Section 5 describes the user study to evaluate the proposed recommendation ap-proach. Finally, we summarize the findings of the evaluation and define future work directions in Section 6.
Finding music that suits a POI can be viewed as a context-aware recommendation problem [1], the place being the con-text for consuming the recommendations (music). There are several works on context-aware music recommendation that exploit location-related context information. Reddy and Mascia [18] present a mobile music recommender sys-tem Lifetrak that generates a playlist using the user X  X  music library based on the current context of the user (location, time, weather, and activity information). Similarly to our tag-based approach [6], Lifetrak requires the user to label songs with tags from a controlled vocabulary. However, in contrast to our approach, the tags in the vocabulary directly represent the values of the previously mentioned context pa-rameters. So for instance, songs have to be labeled with a ZIP code of a certain area to be recommended for that lo-cation.

More recently, Ankolekar and Sandholm [2] presented a mobile audio application that plays audio content associ-ated with a particular location with the goal of enhancing the sense of being in a place by creating its emotional at-mosphere. Instead of establishing relations between music and location automatically, the presented approach relies on crowd-sourcing  X  users are allowed to assign audio pieces (either a music track or a sound clip) to a specific location (represented by the geographic coordinates).

Our research is also related to music auto-tagging , the pro-cess of automatically assigning labels to music pieces. This task is typically performed employing a supervised learning approach; based on a training set of music content features and semantic labels, a classifier is trained and subsequently used to predict tags for unseen pieces. Rhythm or timbre descriptors are frequently used as content features [16] and sometimes high-level features are included [23].
 Recent work in music auto-tagging includes [23], where Sordo proposed a simple though efficient algorithm based on a weighted vote k -Nearest Neighbour (kNN) classifier to propagate tags from training data to unseen music items. Moreover, in order to increase the computational efficiency, he used feature selection and dimensionality reduction of the input feature vectors before training the classifier. A similar approach is suggested in [13] for auto-tagging artists. Kim et al. analyzed artist similarity functions based on differ-ent data sources: artist co-occurrences in Last.fm playlists, Last.fm tags, web pages about the artists, and music content features. It is found that the similarity measure based on Last.fm co-occurrences performs best in terms of precision and recall. Mandel et al. [16] used conditional Restricted Boltzmann Machines [22] to learn tag language models over three sets of vocabularies: annotations by users of Amazon X  X  Mechanical Turk, of the tagging game MajorMiner [15], and of Last.fm. Theses models are learned on the level of song segments. Optionally, track level and user level annotations are considered.

A recent trend in music auto-tagging is adopting two-stage algorithms. In the first stage, such algorithms infer higher-level information from content features, such as term weight vector representations. These representations are then fed into a machine learning algorithm to learn semantic labels [9, 17]. For instance, Miotto et al. [17] first model seman-tic multinomials over tags based on music content features. To account for co-occurrence relations between tags, they subsequently learn a Dirichlet mixture model of the seman-tic space, which eventually yields a contextual multinomial used for tag prediction.

In this work, we employ a variant of the auto-tagger pre-sented in [19], where Seyerlehner et al. proposed a com-bination of different audio features described within their block-level framework [21]. This tagger showed superior per-formance in the  X  X udio Tag Classification X  and the  X  X udio Tag Affinity Estimation X  tasks, run at the 2012 Music Infor-mation Retrieval Evaluation eXchange (MIREX) 1 .Weex-tended the set proposed in [21] with two additional audio features.
In order to evaluate the proposed hybrid recommendation approach, we required a dataset of POIs and music tracks on which both tag-based and knowledge-based techniques could be applied. Since the ground truth relatedness of music and POIs can only be assessed by subjective users X  evalua-tions, and the users cannot perform a large number of judg-ments during an evaluation session, we have limited the size of the dataset to 25 well-known POIs from 17 major city tourism destinations in Europe (Madrid, Berlin, Florence, Paris, etc.).

Acquiring music tracks related to the selected POIs was performed by retrieving the top-5 musicians for each POI using the knowledge-based technique [11], and aggregating them into a single set. This resulted in a collection of 123 musicians (there were two repetitions in the initial list of 125 musicians). Subsequently, we retrieved 3 music tracks http://www.music-ir.org/mirex Table 1: The controlled vocabulary used for tag-based matching of music and POIs Tags Type Affectionate, Agitated, Animated, Bouncy, tal, Serene, Spiritual, Strong, Tender, Thrilling Ancient, Modern, Bright, Dark, Colorful, Physical
Heavy, Lightweight, Open, Cold, Warm for each musician by taking the top-ranked results returned by the YouTube search interface. Doing so ensured the col-lected tracks to be representative of the musicians in our dataset. Eventually, a set of 369 music tracks belonging to 9 music genres was obtained: Classical, Medieval, Opera, Folk, Electronic, Hip Hop, Jazz, Pop, and Rock.

We note that using the knowledge-based technique, which retrieves musicians from the DBpedia knowledge base [11], allowed us to avoid the popularity bias , i.e. selecting only well-known musicians. In fact, the collected dataset covers a wide variety of less-known musicians from the so-called  X  X ong tail X  of music content [7].

In order to evaluate the tag-based approach on this dataset, the POIs and music tracks had to be tagged using the con-trolled tag vocabulary as described in [6]. While tagging the 25 POIs was easily performed through a tagging survey, tagging 369 music tracks required substantial user effort and was not practical. Therefore, to address this issue we have selected a third of the music tracks (123 tracks  X  one ran-dom track per musician) to be tagged through a survey. The collected annotations were used as training data for au-tomatically tagging the remaining tracks in the dataset (see next section).

The tagging survey was performed through a web inter-face where the users were asked to annotate POIs and music tracks using a controlled vocabulary consisting of adjectives from the GEMS emotion model [26] and adjectives describ-ing physical characteristics of items (Table 1). In [6] we have shown that this tag vocabulary is suitable for annotat-ing both music and POIs and performs well for establishing relations between the two types of items. Compared to our previous research, in this work we have used a revised version of the vocabulary. In fact, by analyzing the data collected during the previous tagging surveys [6], we observed that certain tags were rarely used and therefore were marginally providing useful information when recommending music for POIs. We therefore discarded the tags that in the previous surveys were applied to less than 1% of the items. The revi-sion allowed us to reduce the size of the vocabulary from 46 to 24 tags, which was beneficial for the music auto-tagging procedure, in which a separate classifier is trained for each tag (see next section).

The tagging procedure was performed by 10 volunteers recruited via email  X  students and researchers from the Free University of Bolzano and other European universities. We note that the tagging of music and POIs is a subjective task and users may disagree whether certain tags apply to an item [24]. Consequently, aggregating tags provided by dif-ferent users into items X  tag profiles may result in contradict-ing tags. Therefore, to ensure the quality of the acquired tags, we considered the agreement between users, which is a standard measure of quality for user-generated tags [14]. We cleaned the data by keeping for each item only the tags on which at least 2 taggers agreed. As a result, we obtained an average of 5 . 1 distinct tags for the POIs and 2 . 5forthemu-sic tracks. The lower number of tags for music tracks can be explained by the large number of items and the small number of taggers  X  on average a music track was tagged by 2 users. However, the quality of the acquired data was more important than the quantity, since it was crucial to train the music auto-tagger on reliable data. In the next section we will show how the evaluation of the auto-tagging algorithm allowed us to collect more tagging data for the music tracks.
We used a variant of the high-performance, state-of-the-art auto-tagger proposed in [19]. It was applied in the data acquisition phase, to reduce the human effort required in the annotation process, and to scale up tagging. We hence used the tags manually obtained for a third of the music dataset to train the auto-tagger, and automatically label the remaining 246 music tracks.

Our auto-tagger is based on a set of audio features defined within the block-level framework (BLF)[21]. Thisframe-work describes a music piece by first modeling it as over-lapping blocks of the Cent spectrum representation of the audio signal. More precisely, a window size of 2048 sam-ples and a hop size of 512 samples are used. The Short Time Fourier Transform (STFT) is then computed on the Hanning-windowed samples of the audio signal. To account for the musical nature of the audio under consideration, the resulting magnitude spectrum with linear frequency resolu-tion is mapped onto the logarithmic Cent scale.
 Figure 1: Overview of the block-level framework.

Based on these Cent spectrum representations, we defined several features that are computed on blocks of frames (Fig-ure 1). The features which describe a single block were even-tually aggregated over all blocks of the piece under consid-eration, using a summarization function. This yielded the following music descriptors used in the auto-tagger: Spec-tral Pattern (SP) characterizes the frequency content, Delta Spectral Pattern (DSP) emphasizes note onsets, Variance Delta Spectral Pattern (VDSP) aims at capturing variations of onsets over time, Logarithmic Fluctuation Pattern (LFP) describes the periodicity of beats, Correlation Pattern (CP) models the correlation between different frequency bands, and Spectral Contrast Pattern (SCP) uses the difference be-tween spectral peaks and valleys to identify tonal and per-cussive components. Figure 2 illustrates the different feature values for a Jazz piece. The y-axis represents the frequency bands and the x-axis the sorted temporal components of the blocks. In addition to these block-level descriptors, we fur-ther included two variants of Mel Frequency Cepstral Coeffi-cient (MFCC) features, which are commonly used to capture music timbre [25, 3], although they originate from speech processing. Finally, the song level feature vectors resulting from these individual music descriptors were concatenated and associations between songs and tags learned using a Random Forest classifier. We used a RF classifier because in previous experiments its performance was among the best and comparable to that of a Support Vector Machine classi-fier using Principal Component Analysis. Moreover, RF has a much better computational performance [20].

As described in Section 3, the set of 123 music tracks was initially tagged by a small number of human taggers to ac-quire data for training the music auto-tagger. Following this initial data acquisition survey, which resulted in 2 . 5 tags per track on average, we evaluated the auto-tagger on the 123 tracks using leave-one-out train/test data split and cross-validation. The results showed that the auto-tagger can ac-curately predict the small number of tags for the tracks. However, more rich tagging data had to be obtained before the auto-tagger could be trained and applied to the untagged portion of the dataset.

Therefore, we conducted a second tagging survey on the same set of 123 music tracks, aimed to measure how much the users agree with predictions generated by the auto-tagger and to acquire more tagging data. Figure 3 shows the in-terface of the web application used in this user study. The participants of the study were asked to tag the music tracks using the controlled tag vocabulary, with 6 of the usable tags pre-selected by the system: 3 tags predicted for the music track by the auto-tagger and 3 tags randomly selected from the remaining 21 tags in the vocabulary. 31 users participated in the study. There was no overlap with the users involved in the initial tagging of the tracks. On average, each music track was tagged by 2 . 6 users. The participants of the study were informed about the nature of pre-selected tags:  X  Note that some tags are pre-selected by a recommender system and some at random. If you disagree with any of the suggestions, please de-select them  X . This Figure 3: Interface of the experiment on automatic tag prediction. information was provided to encourage the users X  critical thinking when assessing the pre-selected tags.

In total the users performed 318 evaluation sessions (i.e., tagged a music track) assigning on average 5 . 29 tags to a track per session. Out of 1683 acquired music annotations, 652 were those predicted by the auto-tagger, 377 randomly pre-selected, and 654 newly assigned by the users. This shows that the users were active in assigning new tags, in-stead of merely revising the pre-selected tags.

We have calculated the probability for a predicted/random tag to be accepted by a user as the ratio of the number of times such tags were selected by users over the total number of times they were displayed by the system. The results (Ta-ble 2) show a higher selection probability for the predicted tags compared to random tags to be accepted. Note that the probability for a random tag to be selected by a user is still relatively large, which can be explained by two facts. Firstly, due to the large number of tags assigned to a music track per session, the baseline probability for any tag in the vocabulary to be selected by a user is large: 5 . 29 / 24 = 0 . 22. Secondly, by suggesting certain tags we created a presen-tation bias  X  the users were paying more attention to the pre-selected tags, even those at random. Nevertheless, the difference between the two obtained probabilities is statisti-cally significant with p&lt; 0 . 001 in a two-proportion z-test. Therefore, this result confirms that the users agree with the tag predictions produced by the auto-tagger.
 Table 2: Selection probabilities of predicted and ran-domly pre-selected tags.

In addition to validating the effectiveness of the auto-tagger, the described experiment also allowed us to collect more tagging data for music tracks, since the study partici-pants not only reviewed the predicted tags, but also added new ones. Upon the completion of the user study we had the 123 tracks tagged with 5 . 8 distinct tags on average.
Finally, having acquired sufficient tagging data for the 123 tracks and validated the effectiveness of the auto-tagging al-gorithm, we ran the auto-tagger on the full set of 369 tracks, training it on the 123 tagged tracks considered so far.
The auto-tagger outputs a probability for each tag in the vocabulary to be relevant for a track. However, the Jac-card similarity metric between sets of tags, which we use for the tag-based music-to-POI similarity computation, requires to compute the intersection and union of the items X  tag pro-files [6]. Therefore, we decided to generate binary tag assign-ments based on the probabilistic output of the auto-tagger by applying a threshold to the tag prediction probabilities. The standard value for the binarization threshold is 0 . 5, al-though it can be set higher or lower to trade precision with recall [20]. Typically, an optimal threshold value is deter-mined using cross-validation (e.g., in [20] the authors report an optimal value of 0 . 25). However, in our research, the performance of the auto-tagger is defined by the quality of music-to-POI recommendations which have to be assessed by users. As it was not feasible to conduct multiple user studies with different binarization threshold values, we de-termined the threshold value based on the average size of items X  tag profiles it produced. Empirical analysis showed that a threshold of 0 . 4 produced an average tag profile of 5 . 2 tags which is in accordance with the average profile size of manually tagged items (5 . 1 tags for POIs and 5 . 8formusic tracks).
As described in the previous sections, we have collected a dataset of 25 POIs and 369 music tracks from 9 music genres. Both tag-based and knowledge-based techniques can be applied to this dataset, since the music tracks and POIs were tagged using the controlled tag vocabulary, and the tracks belong to musicians semantically related to the POIs.
We designed an evaluation study to compare the perfor-mance of the two techniques and evaluate their combina-tion. Additionally, we wanted to compare the performance of tag-based music recommendations obtained with manu-ally vs. automatically tagged music tracks. Therefore, we considered two variants of the tag-based technique: one us-ing only the manually annotated 123 tracks, and the other using the full set of 369 auto-tagged tracks. Moreover, we implemented a baseline approach which exploits only the users X  music genre preferences. Hence, in total we consid-ered five approaches to recommend music for POIs, which we describe in the next section.
The genre-based music recommendation approach imple-ments a basic personalization technique: the music tracks are recommended based on the users X  genre preferences. We aimed to compare a personalized music recommendation ap-proach with the knowledge-based and tag-based approaches, which are not personalized, but rather directly match music with the users X  context (i.e., POIs). We did not implement a more sophisticated personalization approach since the users were requested to evaluate if the proposed music tracks suit the presented POI and therefore it was not necessary and even deleterious to totally match the detailed user X  X  music preferences in this particular contextual situation.
In order to obtain the users X  preferences, we asked the study participants to select their preferred music genres prior to performing the evaluation. The genre taxonomy was based on the music tracks in our dataset, and included: Clas-sical, Medieval, Opera, Folk, Electronic, Hip Hop, Jazz, Pop, and Rock. For each displayed POI, the genre-based track is randomly selected from the whole set of music tracks be-longing to the user X  X  preferred genres.
The knowledge-based music recommendation approach em-ploys the technique presented in [11]. Given a POI, this approach ranks musicians by their relatedness to the POI. The relatedness is computed from the semantic relations be-tween the POI and musicians extracted from the DBpedia knowledge base 2 .

To extract relations between POIs and musicians, we con-sidered only a subspace of DBpedia by identifying classes and relations belonging to the two domains of interest  X  places and music. We identified three types of relations that are useful for matching POIs with musicians: location rela-tions (e.g., POI located in City, City birthplace of Musician), time relations (e.g., POI construction Date, Musician active Date), and relations through historical/cultural eras (e.g., POI has category Architecture Style, Musician has category Music Genre). Subsequently, for each POI, we built a net-work consisting of a directed acyclic graph whose nodes rep-resent the identified classes, and edges represent the selected relations. We assigned relevance weights to nodes and edges of the graph, and performed a weight spreading algorithm over the graph to compute relatedness scores for musician nodes in the graph.

As explained in Section 3, we have downloaded three rep-resentative music tracks for each musician in the dataset. Using this approach, we implicitly assume that there are no major differences between these tracks of the same musi-cian. Therefore, for each POI, the knowledge-based track is randomly selected from the three music tracks by the top-ranked musician.
The tag-based music recommendation approach uses the technique presented in [6] and is applied to the previously described set of 123 manually tagged tracks. This approach computes the weighted Jaccard similarity between a POI u and a music track v as: where X u and X v are the items X  tag profiles and f ( t )is the fraction of items in our dataset (both POIs and music tracks) annotated with the tag t .ForeachPOI,the tag-based approach recommends the top-ranked music track.
The auto-tag-based approach is applied to the full dataset of 369 music tracks which are auto-tagged using the subset of 123 manually tagged tracks for training (see Section 4).
Given the tag vocabulary of size K (in our case K = 24), for each music track v the auto-tagger produces a tag affinity vector: http://dbpedia.org/ where p ( t i ) denotes the probability for a tag t i to be relevant for the track. Then, the track X  X  tag profile X v is defined as:
The similarity between a POI u and a music track v is computed using Equation 1. For each POI, the auto-tag-based approach recommends the top-ranked music track.
This music recommendation approach is a hybrid com-bination of the knowledge-based and auto-tag-based tech-niques, employing a rank aggregation technique [10]. Since the music-to-POI similarities produced by the two techniques have different value ranges, we used the normalized Borda count rank aggregation method to give equal importance to the two. This method is also applied in other recom-mender systems [4] and works as follows: Given a POI u , the knowledge-based and auto-tag-based approaches produce the rankings of music tracks  X  kb u and  X  tb u .Wedenotethe position of a track v in these rankings as  X  kb u ( v )and  X  respectively. Then we compute the combined score of the track v for the POI u as: CombinedScore( u, v )= where N kb and N tb are the total number of tracks in the corresponding rankings. Finally, for each POI the combined approach recommends the top-scored music track.
To determine which approach produces better music rec-ommendations we designed a web-based interface (Figure 4) for collecting the users X  subjective assessments of whether a music track suits a POI. The participants of the exper-iment were repeatedly asked to consider a POI, and while looking at its images and description, to listen to the rec-ommended music tracks. They were asked to check all the tracks that in their opinion suit that POI. During each eval-uation step, the music recommendations for a POI were se-lected using the proposed five approaches described above  X  the personalized baseline approach and the four context-aware approaches. The order of the recommendations was randomized, and the user was not aware of the algorithms that were used to generate the recommendations. In total, a maximum of five tracks corresponding to the top-ranked tracks given by each approach were suggested for each POI, but sometimes less tracks were shown as the tracks selected by the different approaches may overlap.
A total of 58 users participated in the evaluation study, performing 564 evaluation sessions: viewing a POI, listen-ing to the suggested music tracks, and providing feedback. 764 music tracks were selected by the users as well-suited for POIs. Figure 5 shows the performance of the recommen-dation approaches, computed as the ratio of the number of times a track produced by each approach was considered as well-suited over the total number of evaluation sessions. All context-aware approaches perform significantly better than the personalized genre-based track selection ( p&lt; 0 . 001 in a two-proportion z-test). This result shows that in a situation defined by a context (i.e., a POI), it is not sufficient to rec-ommend a music track liked by the user, but it is important to adapt music recommendations to the user X  X  context.
Among the four context-aware approaches, the combined approach produced the best results, outperforming the oth-ers with statistical significance at p&lt; 0 . 01. These results confirm our hypothesis that the users are more satisfied with the recommendations when combining the tag-based and knowledge-based techniques, which represent orthogo-nal types of relations between a place and a music track. Figure 5: Selection probabilities of the different mu-sic recommendation approaches.

While our research hypothesis is supported by the users X  feedback averaged across the full set of POIs, it is also in-teresting to look at the users X  judgments of music appropri-ateness for the individual POIs. Figure 6 shows two inter-esting cases. For the POI Casa Batll  X  o, the knowledge-based approach outperforms both tag-based approaches, while for the Royal Palace of Brussels, the tag-based approaches per-form better. These results can be explained by analyzing the tag profiles of the items. We observe the differences of tag distributions in the profiles of the two POIs. Casa Batll  X  o is tagged as [ Modern, Spiritual, Energetic, Warm, Col-orful, Animated, Lightweight ], with over half of the tags in the profile being very frequent in our dataset (among both music tracks and POIs). Instead, the Royal Palace is tagged as [ Calm, Heavy, Strong, Ancient, Open ], with most of the tags being quite rare in the dataset. Note that the Jaccard similarity metric, used in the tag-based ap-proach, weights the tags with respect to their frequency in the dataset (by assigning more weight to rare tags, see Equa-tion 1). Therefore, the approach is better at identifying a good match for a POI tagged with a smaller set of tags unique in the set of music tracks compared to a POI tagged with a large number of common tags.

Furthermore, the different performance of the knowledge-based approach for the two POIs suggests that for certain POIs the technique fails to provide a relevant recommen-dation. In fact, we observe that for the Royal Palace of Brussels, the approach recommends a modern music piece by a Brussels-born composer, however, not fitting the nature of this particular POI. Notwithstanding the shortcomings of each individual technique discussed above, the obtained re-sults suggest that the proposed hybrid combined approach can effectively balance the effects of the two alternative tech-niques and therefore produce better recommendations. Figure 6: Selection probabilities of the different mu-sic recommendation approaches for two individual POIs.

Finally, the evaluation results suggest that the tag-based music recommendation approach can be successfully scaled up using automatic tag prediction techniques. The auto-tag-based approach even outperformed the tag-based approach with marginal significance ( p =0 . 078). This can be ex-plained by the larger variety of music in the auto-tagged music dataset  X  using the auto-tag-based approach the rec-ommendations were selected from the full set of 369 music tracks, while the tag-based approach used only the subset of 123 manually annotated tracks. Scaling up the process of tag generation without harming performance is hence the vital advantage of using the auto-tagger.
In this paper, we have presented a novel hybrid approach to recommend music related to POIs. This approach is based on combining two music recommendation techniques: a tag-based one and a knowledge-based one [6, 11].
Since the tag-based technique was previously assessed on a manually tagged dataset of limited size [6], in this work we have shown that it can scale up employing a music auto-tagging technique. In fact, in a user study we have demon-strated that music auto-tagging can be successfully applied in tag-based music recommendation for POIs. Subsequently, we have presented a user study where the proposed ap-proach was evaluated on a dataset of POIs and music tracks and was compared with a personalized recommendation ap-proach that considers users X  music genre preferences and does not adapt music to the POIs. The different recommen-dation techniques were evaluated in a web-based user study where the users were required to evaluate the appropriate-ness of the music selected by the system for a set of 25 POIs. The results of the evaluation study confirm our hypothesis that the combination of the tag-based and knowledge-based techniques produces better recommendations. We believe that these findings provide a solid base for the implementa-tion of real-life location-aware music recommenders.
We stress that the ultimate goal of this research is a location-aware music delivery service that combines the tag-based and the knowledge-based music recommendation tech-niques. While in this work we demonstrate the effective-ness of such combination through a web-based evaluation, it is important to evaluate the approach in real-life settings and with a larger music/POI dataset to confirm our find-ings. Moreover, additional evaluation would help us under-stand which type of associations between music and POIs  X  emotion-based or knowledge-based  X  the users prefer in dif-ferent recommendation scenarios (e.g., sightseeing, choosing a holiday destination, or acquiring knowledge about a des-tination).

Other important future work directions include automati-cally acquiring tags describing POIs (using web mining tech-niques and folksonomy datasets like Flickr as sources of tag-ging information); analyzing the importance of individual audio features when automatically tagging music tracks; us-ing more complex hybrid recommendation strategies to com-bine our music recommendations with, e.g., those produced by Last.fm. Finally, we believe that the designed context-aware recommendation solutions may be adapted to other types of content, for instance, recommending music content that fits movies, books, or paintings.
This research is supported by the Austrian Science Fund (FWF): P22856 and P25655; and by the EU FP7/2007-2013 through the PHENICX project under grant agreement no. 601166. The authors would further like to thank Klaus Sey-erlehner for providing source code and expertise on music auto-tagging. [1] G. Adomavicius, B. Mobasher, F. Ricci, and [2] A. Ankolekar and T. Sandholm. Foxtrot: a soundtrack [3] J.-J. Aucouturier and F. Pachet. Improving Timbre [4] L. Baltrunas, T. Makcinskas, and F. Ricci. Group [5] C. Bizer, T. Heath, and T. Berners-Lee. Linked data -[6] M. Braunhofer, M. Kaminskas, and F. Ricci.
 [7] ` O. Celma. Music Recommendation and Discovery in [8] ` O. Celma and P. Lamere. If you like radiohead, you [9] E. Coviello, A. B. Chan, and G. Lanckriet. Time [10] C. Dwork, R. Kumar, M. Naor, and D. Sivakumar. [11] I. Fern  X  andez-Tob  X   X as, I. Cantador, M. Kaminskas, and [12] M. Kaminskas and F. Ricci. Contextual Music [13] J. H. Kim, B. Tomasik, and D. Turnbull. Using Artist [14] E. Law, L. Von Ahn, R. Dannenberg, and [15] M. I. Mandel and D. P. W. Ellis. A Web-Based Game [16] M. I. Mandel, R. Pascanu, D. Eck, Y. Bengio, L. M. [17] R. Miotto, L. Barrington, and G. Lanckriet.
 [18] S. Reddy and J. Mascia. Lifetrak: music in tune with [19] K. Seyerlehner, M. Schedl, P. Knees, and [20] K. Seyerlehner, M. Schedl, T. Pohle, and P. Knees. [21] K. Seyerlehner, G. Widmer, M. Schedl, and P. Knees. [22] P. Smolensky. Information Processing in Dynamical [23] M. Sordo. Semantic Annotation of Music Collections: [24] D. Turnbull, L. Barrington, and G. Lanckriet. Five [25] G. Tzanetakis and P. Cook. Musical Genre [26] M. Zentner, D. Grandjean, and K. R. Scherer.
