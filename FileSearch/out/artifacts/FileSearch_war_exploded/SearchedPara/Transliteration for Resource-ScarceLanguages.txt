 MANOJ K. CHINNAKOTLA, OM P. DAMANI, and AVIJIT SATOSKAR Indian Institute of Technology Bombay 1. INTRODUCTION Transliteration is the process of mapping a written word from a language-script pair to another language-script pair. For example, Hindi words and correspond to English words param and share , respectively. Transliterating a word from the language of its origin to a foreign language is called Forward Transliteration , while transliterating a loan-word written in a foreign language back to the language of its origin is called Backward Transliteration .Inthis article, we focus on general purpose tra nsliteration involving resource-scarce languages for which very large parallel corpora of transliteration pairs do not exist. By general purpose, we mean that the system should do both forward and backward transliteration.
 pings, or character sequence mapping rules, between the languages involved. However, transliteration is one of th ose problems where the accuracy of an answer is not defined solely by algorithmic rules but also by human conven-tion, which can be inconsistent and somewhat ad hoc at times. Therefore, it is only natural that parallel corpus based systems dominate the translit-eration research landscape [AbdulJaleel and Larkey 2003; Ekbal et al. 2006; Ganesh et al. 2008; Haizhou et al. 2004; Kumaran and Kellner 2007; Sherif and Kondrak 2007]. Statistical techniques based on large parallel translitera-tion corpus work well for the resource rich languages but the resource scarce languages do not have the luxury of such resources. For such languages, rule-based transliteration is the only viable option.
 junction with manually created rule base, one can achieve reasonable translit-eration performance when compared to that of baseline statistical systems trained using parallel corpora. We achie ve this performance by properly har-nessing the power of Character Sequence Modeling (CSM) , typically called the Language Model. Our system uses CSM on the source side for word origin iden-tification, a manually generated non-probabilistic character mapping rule base for generating transliteration candidates, and then again uses the CSM on the target side for ranking the generated candidates. We perform a step-by-step fine-tuning of various CSM parameters.
 Hindi transliteration systems. We also perform extrinsic evaluation of translit-eration systems in the context of Cross Lingual Information Retrieval. Another important contribution of our work is to explain the widely varying accuracy numbers reported in transliteration literature, in terms of the entropy of the language pairs and the datasets involved.
 mented with a non-Indian language. Our only criterion for selecting the lan-guage was that there should be a publicly available character mapping, and a parallel transliteration corpus for evaluation. We found that such resources are available for Persian to English transliteration in Karimi [2008]. Hence, we de-cided to work with Persian, despite the fact that none of the authors have any knowledge of Persian whatsoever (we cannot even read the Persian script). We also discovered that short vowels are typically absent from the written Persian words [Karimi 2008], thus making the problem even more challenging.  X  X e show how to build a reasonable transliteration system for resource scarce languages that lack large parallel corpora required to train statistical systems. Our system employs only monolingual resources and simple non-probabilistic character mapping.  X  X esides intrinsic evaluation, we also perform extrinsic evaluation of translit-eration systems in the context of Cross Lingual Information Retrieval (CLIR). To our knowledge such a wide-ranging evaluation on multiple lan-guage pairs and data-sets has not been performed earlier for transliteration.  X  X e provide an entropy based explanation for widely varying transliteration accuracy numbers reported in the literature. 2. RELATED WORK Existing transliteration generation approaches can be classified along two di-mensions: the level at which the bilingual mapping process is modeled and the approach taken to learn the mapping rules. Table I shows this classification. of mapping a grapheme/character sequence from a source language to a target language ignoring the phoneme-level processes involved. In contrast, in phoneme-based approaches, the whole process of mapping from source lan-guage graphemes to source language phonemes to target language phonemes to target language graphemes, is modeled. In hybrid approaches, the models learnt using the above two approaches are combined by either interpolating them or by conditioning the grapheme models on corresponding phonemes [Oh et al. 2006].
 between corresponding entities. These rules can either be manually created or can be learned by employing statistical techniques. When these rules are created manually, we call them rule-based approaches. As discussed before and shown in Table I, most of the existing systems learn these rules by em-ploying machine-learning techniques. In general these rules are learned from parallel transliteration corpora. In con trast, given our focus on resource-scarce languages, we use manually created bilingual mapping rules and rely on sta-tistical knowledge that can be gleaned from monolingual corpora only. The work described in Ekbal et al. [2006] also combines rule-based and statistical techniques by learning character mappings from parallel corpora and falling back to manually created rule bases to resolve ambiguity. In contrast, we do not use parallel corpora at all and use statistical techniques only for learning monolingual language models.
 ing systems that try to obtain parallel transliteration pairs from comparable corpora [Collier et al. 1997; Klementiev and Roth 2006; Pas  X ca 2007; Sproat et al. 2006; Udupa et al. 2009]. In Klementiev and Roth [2006], transliteration pairs are obtained by doing frequency analysis of words in a weakly temporally aligned comparable corpora. It is assumed that the aligned named entities will have comparable frequency vs. time signatures. In Collier et al. [1997] and Udupa et al. [2009], documents from comparable corpora are first aligned with each other and then named-entity pairs are mined from each pair of document by using a cross language transliteration similarity model. In Sproat et al. [2006], both frequency and similarity models are combined. The transliter-ation mining approach is supplementary to the transliteration generation ap-proach in that one may always need to transliterate words which have not been mined. Also, while document similarity based methods are shown to perform much better than the frequency based methods [Udupa et al. 2009], unlike the frequency based methods, document similarity based mining method do need to employ some kind of transliteration similarity/generation model to identify potential pairs.
 used for measuring system performance. 3. EVALUATION METRICS AND BASELINE APPROACHES Given a source language word, a translit eration system produces a ranked list of possible candidate answers. Given a set of correct transliterations for that word, we define the answer generated by the transliteration system to be cor-rect at rank k , if one of the top k candidates generated by the system belongs to the set of correct transliterations for that word. The accuracy at rank k is defined as the fraction of the test words for which the system generates the correct answer at rank k .Given N input words to be transliterated and list of top k candidates generated for each input word, we use another metric called the Mean Reciprocal Rank (MRR) at rank k defined as follows: Rank ( n ) is the rank of the first correct answer for the n th input word in the corresponding list of k candidates. In case, no correct answer is found for a word in the list, its rank is taken to be infinite. We report the Accuracy and MRR figures at Rank 5 throughout the article, unless otherwise stated. 3.1 Evaluation Data We randomly partition a parallel cor pus of 30,000 word pairs (referred to as 30K Dataset ) into training, development, and the test set, the details of which are given in the Table II. To make sure that our partitioning is not bi-ased, we perform a five-fold cross validation on this dataset and all numbers reported on this dataset are the average values obtained from five different partitions. In addition to this, we also use the standard NEWS 2009 Translit-eration Shared Task dataset [Li et al. 2009]. The NEWS 2009 dataset con-tains many multi-word named-entities which were converted into single word source-target transliteration pairs. Note that the word origin information is not used and discussed until Section 6, but we include it in Table II for presenting all related information in a single place. 3.2 Baseline Approaches for Comparison The following language independent statistical approaches have recently been shown to perform quite well for the transliteration task. We chose them as baseline since they can be implemented easily using off-the-shelf components like CRF++ [Kudo 2003], GIZA++ [Och and Ney 2003], and Moses [Hoang et al. 2007]. Both of the following systems are trained using the training set men-tioned in Table II. tion problem is posed as a sequence learning problem and a Conditional Ran-dom Field (CRF) based approach is used. They report better accuracies than the HMM based approach [AbdulJaleel and Larkey 2003]. We implemented a modified version of their approach using CRF++. We use two way alignment in GIZA++ for learning the character mappings whereas the original approach uses only one way alignment. Huang [2005] the transliteration problem is posed as a Phrase-Based Machine Translation problem where the words are replaced by the characters. We im-plemented the above approach using GIZA++ aligner, the Moses decoder, and the SRILM toolkit. We use N = 5 for language modeling in SRILM. SRILM and Moses were used with the default options, except that the distinct option was also given to Moses to avoid any duplicates in the output list.
 proved by tuning the various model parameters. In case of CRF, we varied the C parameter which controls the trade-o ff between train and test error, and in case of SMT based transliteration, we tune the weights assigned to various models like language model and translation model. We disabled the distortion model by assigning it zero weightage. Note that, as discussed in Section 5.1, we use same enlarged alphabet for our system as well as for the baseline systems. step by step development of our system architecture. 4. TRANSLITERATION SYSTEM ARCHITECTURE The main modules in our system are shown in Figure 1. To help motivate various design choices made by us, we present a detailed development his-tory of our system. We start by presenting a very basic rule based system in Section 4.1. This system relies on manually created character mappings for generating transliteration candidates and uses a language model called Char-acter Sequence Model (CSM) to rank the generated candidates. This rudimen-tary system is enhanced in Section 5 by fine-tuning various CSM parameters such as the character set being used, the order of the language model, the weight being assigned to each word, and the smoothing techniques being used. The system is further developed by identifying the word-origin and employing the origin dependent rule bases and language models in Section 6. This final system is evaluated for Hindi-English and English-Hindi transliteration tasks on various datasets and the results are presented in Sections 7 and 8. 4.1 Basic Rule-Based System Our basic rule-based transliteration system works by employing a set of charac-ter mapping or character sequence mapping rules between languages involved. We have used this system for Hindi to English, English to Hindi, and Persian to English transliteration tasks. We illustrate the system architecture in detail using Hindi to English transliteration as an example.
 written in Roman script. When there is no confusion, we use the terms De-vanagari word and Hindi word interchangeably. Each Devanagari consonant symbol that is not followed by a vowel represents that consonant plus an inherent schwa vowel sound [Shukla 2000]. For example, is repre-sented as + + + + + . Note that the schwa vowel is not pronounced in certain contexts.
 character is mapped to one or more English character sequences kh, ck, k . Some rules are of the form (  X  x ) where a Hindi character sequence is mapped to a single English character x . The rules sometimes also include constraints which specify the context in which they are applicable like Start of a Word (S), Ending of a Word (E), After Vowel (AV), After Consonant (AC), etc. Negation of these constraints is also allowed by prefixing the constraint with !. A snippet of the constrained rule base is shown in Table III. Since the schwa vowel sound gets dropped in some contexts, we also add a (NULL) character mapping (i.e., no character appended during candidate generation) corresponding to schwa .
 Hindi word results in different transliteration candidates. For example con-sider the Hindi word ( deepak ). As discussed before, is processed as + + + + + . As shown in Table III, , , , ,and have 2, 10, 1, 5, and 6 possible mappings, respectively. Hence a total of 2*10*1*5*6*5=3000 transliteration candidates should be considered (Examples: d+ee+p+a+k+ , d+i+p+ +k+a , d+ee+p+u+k+ ,etc.).
 (1) A procedure is needed to rank the generated candidates. (2) A search strategy is needed to avoid exploring the exponential number of on Character Sequence Model (CSM) discussed next. To avoid processing ex-ponential number of candidates, we process the input characters one at a time, and greedily prune the list of partially generated candidates by keeping only top k ranked candidates. 4.2 Character Sequence Modeling (CSM) A language generally allows only certain spelling patterns in its word forma-tions. For example, sound formations such as hlad and mgla are not natural in English. The aim of Character Sequence Modeling is to learn the permissible patterns.

A Character Sequence Model for a language is a probability distribution over sequence of characters within a word. Let W = &lt; c 1 , c 2 ,..., c m &gt; be a word where c i is the i th character in the word. The probability of observing the word W in the corpus is defined as: The very first step in any language modeling work is the decision of what to model, that is, which corpus to model. Most researchers used the unique word list from the training data or some named entity list from the Web as the corpus being modeled. We use English Wikipedia as our target corpus. The Wikipedia includes words and named entities from all parts of the world (5.6 million word forms in 2007, of which 1.8 million word forms had frequency greater than 2) and continues to grow exponentially. Therefore, it serves as a good general purpose corpus for transliterating into English. We train a trigram CSM on the unique words of Wikipedia using the SRILM toolkit [Stolcke 2002] with the default options.
 strained rule base to generate all possible candidates. At each step, the candi-dates are ranked based on the word generation probability given by the CSM. To avoid processing exponential number of candidates, only the top k candi-dates are retained at each step and the rest are discarded. 5. IMPROVING THE BASIC RULE-BASED SYSTEM Table IV shows the performance of our basic system and that of the baseline systems. Both the baseline systems employing parallel corpus outperform our basic system with a huge margin. 5.1 Enlarging the Alphabet on Target Side In our system, the candidates generated are of varying length since one Hindi character can map to multiple English characters, and the CSM assigns lower probability to the longer candidates than to the shorter ones. For example, for word ( phatak ), candidate fatak is assigned higher probability compared to phatak because letter p and h are treated as two different graphemes, even though both f and ph correspond to the same Hindi letter .Wesolvethis problem by changing the alphabet (basic unit) in our N -Gram model. We treat several multi-character sequences as a single character. In Ekbal et al. [2006], the basic alphabet is extended by extracting multi-character sequences derived from an alignment of parallel corpus. Since we are not using parallel corpora, we add multi-characters gram based on the following.  X  X ommon Digraphs. As in Teahan [1997], we treat frequently occurring di-graphs such as sh , ck , etc., as a single character.
  X  X ouble letters. Typically, a pair of identical letters is pronounced as a single phoneme in English, and hence we add them to our alphabet. For example, ll and ss in mill and miss .  X  X chwa handling. In Section 4.1, we discussed that in written words, each
Devanagari consonant that is not followed by a vowel contains an inherent schwa vowel which may or may not be pronounced. For a simple rule-base system, it is hard to decide when a schwa will be pronounced and when will it be deleted. Hence we treat basic consonants followed by schwa to be a single letter for example, ka,kha,ga ,etc.
 As shown in Table IV, this enlarging of alphabet improves the performance of system from 31.3% to 36.4%. As an example, candidates for word ( im-press ) changes from { impres , empres , empras , imprec } in the basic system to { impres , empres , impress , empress , impras } . 5.2 Varying N of N -Gram So far we have been using the trigram model because that is the default in the SRILM toolkit, and it is the model used by many other transliteration re-searchers. We next vary the value of N as shown in Figure 2 and find that N =5 gives the best results and this increases the accuracy from 36.4% to 53.1%. For example, candidates for word ( dissolve ) changes from { dicallo , dicalo , decolo , disolo , dicalva } to { dissolo , dissolve , decolo , disallo , desalu } taking benefit of dissol as a 5-gram unit in the training corpus. 5.3 Weighing Each Word Until now, we have been using the list of unique words from the Wikipedia for learning the Character Sequence Model on the target side. A list of unique words gives equal importance to all the words in the corpus, whether it be a correct spelling, or a misspelling, or a rare spelling variation. To give more im-portance to the frequent spellings, we could use word frequency as the weight of a word when modeling the CSM. Given that many words occur with very high frequency, such a model will unduly favor the common words. To strike a balance, we use the following weighting function for a word w when learning the CSM model: Here, f ( w ) is the frequency of word w in the corpus. As a desirable side effect, words occurring only once or twice are not used at all and the number of unique word forms in the corpus reduces from 5.6 million to 1.8 million. This weighing increases the system accuracy from 53.1% to 61.4%. For example, candidates for !" ( danish ) changes from { dennis , danes , denis , denes , danese } to { denis , danish , danes , dennis , danese } .
 5.4 Smoothing and Discounting Techniques The experiments so far have used the default SRILM smoothing, which is the Katz Backoff with Good-Turing Discounting. While this is known to work well for word sequence modeling tasks, Character Sequence Modeling may require a different smoothing method. The number of characters in a given alphabet is orders of magnitude smaller than the number of words in a language. Hence the number of N -Grams to be considered in a transliteration application is far less than that in a word modeling task. Also, the number of distinct sentences a system may have to process is infinite, while the number of possible words is arguably finite. Therefore, the smoothing technique for the CSM should give less weightage to the unseen N -Grams than what is typically done in the word modeling tasks.
 ing with two other methods: Chen-Goodman Backoff with Kneser-Ney Dis-counting (implemented in the SRILM toolkit), and PPM-D smoothing (not implemented in SRILM) [Teahan 1997]. Since methods implemented in SRILM toolkit are widely known in NLP community, we do not describe them here. We only explain the PPM-D smoothing which is relatively unknown in the NLP community.
 model well-known in the text compression community [Cleary et al. 1984]. Let a be the context observed so far and z be the next symbol in sequence. Let c ( z ) be the number of times the context a was followed by the symbol z and n ( k c ( k )) be the total number of symbols that have followed a ;Let t be the number of distinct symbols that have followed context a so far and M be the total number of distinct symbols seen in the training data. We use the PPM-D smoothing method [Teahan 1997] which is given by: Sincewewanttogivemuchlessweighttotheunseen N -Grams, a natural baseline method is to use Maximum Likelihood Estimate (MLE), and employ no smoothing. We also present the comparison results for this option. To put the results in perspective, we categorized them by whether the correct English transliteration is present in the corpus being modeled or not. The Kneser-Ney technique gives the best result for the out-of-vocabulary (words which are not in Wikipedia) target words while the PPM-D smoothing gives the best result for the in-vocabulary words. The performance of the PPM-D is not unexpected since it concentrates the probability mass heavily on the seen events. The choice of the smoothing technique depends on whether we expect to see lot of out-of-vocabulary words in our application or not. Hence for a general-purpose system with Wikipedia as the target corpus, we expect to run into the in-vocabulary words much more often than the out-of-vocabulary words. Therefore, we chose PPM-D smoothing. With this choice, a seen word like # "$ (kushinagar) breaks into the top 5 with the candidate set changing from { choosinger , cusinger , cussinger , cousinger , kusinger } to { kushinagar , kusinagara , cousinger , kuchinger , cusinger } due to the less weightage given to unseen sequences like choosinger , cusinger etc. 6. WORD ORIGIN IDENTIFICATION It is observed in Huang [2005] and Surana and Singh [2008] that identifying the word origin is critical to the transliteration success. In Huang [2005], a statistical clustering technique is employed on a parallel transliteration corpus, and 50 different classes of English words are created. Since our work focuses on the use of monolingual resources, ideally we should classify words based on the phonological typology. In the absence of resources to do such a classification, we simply classify words by whether they are of Indian origin or not. In Shukla [2000] the origin of Hindi words is traced to four sources: a) Native words (Sanskrit words and their derivatives), b) Persian, Arabic, and Turkish words, c) English words, and d) Portuguese words. Since not only the words of other Indian languages, but even the words of Persian (e.g., % " zameen ), Arabic (e.g., &amp;' aurat ), and Turkish (e.g., $ daroga ) sound like Hindi words to native speakers, we finally classified words by whether they are of Indo-Arabic origin or not. Note that in the context of resource scarce languages, effort required to manually annotate the origin of a given word is much less than that of producing the correct transliteration.
 tion in Llitjos and Black [2001] and Surana and Singh [2008]. We use a similar model where we learn two different CSM classes corresponding to each origin and assign a word to the class which gives it higher probability. The 30,000 and NEWS 2009 datasets were manually annotated with word origin informa-tion. The word origin data of training set was used for training the word origin identification module. The development set was used to determine the ideal N -Gram size. The N -Gram size 3 gives the best accuracy of 87% for the word origin identification task. In Surana and Singh [2008], 5-grams are found to be most effective for identifying the origin of words written in the Roman script. In contrast, we find that 3-grams are best suited for the origin identification of written Hindi words. This is because many consonants in written Devanagari words include an inherent schwa vowel, as discussed in Section 4.1. 6.1 Origin-Dependent CSM The purpose of word origin identification is to use a different origin-dependent CSM on the target side. For training the English CSM for the words of Indo-Arabic origin, a collection of 167,814 Indo-Arabic names written in the Roman script were used. For non-Indo-Arabic origin words, the English Wikipedia corpus was used. While Wikipedia also contains many words of Indo-Arabic origin, words of Non-Indo-Arabic origin are orders of magnitude more frequent. ranking the candidates is now based on the origin assigned by the classifier as depicted in Figure 1. As shown in Table IV, the accuracy of the system now jumps from 62.7% to 71.7%, exceeding that of the CRF. Note the particular in-crease in the accuracy of Indo-Arabic ori gin words, since the language model for them gets quite altered. As an example, ()$ ( bodhgaya ) benefits from the changed CSM where the prefix bodh gets preference over the prefix bod and the candidates change from { bodgaya , bodgia , bodegua , bodeguo , bodegea } to { bodhagaya , bodhagya , bodhgya , bodhgaya , bodhegya } . For non-Indo-Arabic origin words the CSM has not really changed much. Compared to results shown in Table IV, the slight reduction in the a ccuracy of foreign origin words is due to misclassification errors; it is fatal for a non Indo-Arabic word to be classified as that of Indo-Arabic origin. For example, when * ( sunnyvale )getsmis-classified as Indo-Arabic origin, its candidates change from { sunnyvale , snivel , snivell , snivelle , conewall } to { sanewal , shanewal , sanewala , shanewala , sha-neevala } . 6.2 Origin-Dependent Rule Base The error analysis at this stage still sh ows scope for improvement. Regard-less of the word origin, same set of candidates are currently being generated. Hence we decided to use different character mapping depending on the word origin. This step is arguably tricky. We cannot characterize our system as a simple one anymore. In fact, the mapping rules were improved using trial-and-error. Despite having these misgivings, we think that such a step still helps us show the power of CSM. The system guesses the origin of the input Hindi word, generates candidates from the appropriate mapping table based on the word origin, and ranks the generated English candidates using the appropriate CSM. The final system architecture is shown in Figure 1. The performance of this system is shown in Table IV. From 71.7%, the system accuracy increases to 75.1% compared to 71.9% accuracy of the SMT based system. Its perfor-mance is comparable to that of the SMT-based system. The major beneficiaries of Origin Dependent Rule Base are words of Indo-Arabic origin. For example, maps to only k and not to ch in the Indo-Arabic origin rule base and hence the candidates for ( kamrao ) changes from { chamaroo , kamaroo , kamarava , chamarava , komrao } to { kamarava , kamrao , kamarav , kaamrao , kamerava } . 7. EXPERIMENTAL RESULTS AND ERROR ANALYSIS Until now we have been optimized our system based on its performance on the development data. We next experiment with the test set of 30,000 dataset mentioned in Table II. As mentioned before, a five-fold cross validation was performed on this dataset and all reported numbers are the average figures for five runs. We repeated the same sequence of steps on the NEWS 2009 dataset. From these results, we can conclude that our system competes fairly well with statistical systems for Hindi-English transliteration task. Our chosen base-lines do not take advantage of the word origin identification. To remedy this, we also implemented an improved version of the baseline systems where the training data was separated by word origins. The results of that experiment on NEWS 2009 dataset is shown in Table VII. Surprisingly, the overall result for statistical systems does not benefit from the word origin identification. Our preliminary investigations indicate that the effect of origin misclassification is much more detrimental for statistical systems than the rule-based systems but we need to further investigate the root causes for this. 7.1 Error Analysis There are several sources of error in our system.  X  Multiple Transliterations. For many words of non-Indian origin, multiple
English words correspond to a given Hindi word and our system fails to guess the one in the Gold Standard. For example, for $ ( gets, gates ), top five results from our system are: { gets , ghats , getz , geths , geats } ,whereasthe gold standard only contains gates .  X  Origin Misclassification. As discussed in Section 6.1, origin misclassification is one of the important sources of error.  X  Lack of Context Sensitive Mapping Rules. While the previous two causes of errors are system errors, this one is a model error. Only context we use is whether a character is at the beginning of a word or at the end of a word, and whether or not it follows a vowel. As a result our top five candidates for ( share )are chair , cheer , seer , sheer ,and sauer ,whereasasystems with rules like followed by a gets transliterated as sh only might give the correct answer.
  X  CSM Related. In a system based on language modeling on target side, more prevalent spelling patterns in the target language are ranked higher than less prevalent spelling patterns.  X  Schwa Related Errors. Our system cannot distinguish between different role played by letter in two very closely related words like ) " ( dhadkan )and ) ( dhadak ) due to schwa deletion phenomena discussed earlier. Although the context of letter ( da ) is same in both cases, the schwa is dropped in one case and not in another.
 Figure 4. For comparison sake, this figure includes the error distribution for English-Hindi transliteration task described next. 8. ENGLISH TO HINDI TRANSLITERATION In the previous sections, we described our approach for transliterating from a phonetic script (Devanagari) to a non-phonetic script (Roman). In this section, we show that our approach works in the reverse direction as well, that is, it works for transliterating from a non-phonetic script (Roman) to a phonetic script (Devanagari). 8.1 English-to-Hindi Rule Base As done earlier, we build a constrained rule-base for mapping English charac-ter sequences to Hindi character sequences. Similar to Hindi to English, the constrained rule-base contains both simple and compound rules where a rule is defined as simple or compound depending on whether the source of a rule is a single English letter ( k  X  ) or an English letter sequence ( ck  X  ). In English, vowel sequences (Example: oe,eo,ie,ee,ai ) and silent letters (e.g., lm (holmes), ps (pseudo)) are handled through compound rules.
 discussed in Section 5.1, English vowels may not be mapped to any character on the Hindi side. For example, in ganesh  X  $+ , but  X  ( , ton  X  " ,the letters a, u, o do not map to any Hindi character. To handle this, we include NULL mapping on the target side for each English vowel. For example, both ( # (contains three characters) and ( (contains two characters) are generated as transliteration candidates for but . Since the shorter candidates are likely to have higher probability in CSM, the NULL mapping may end up getting preference over other mappings. As discussed in Section 5.1, we take care of this by enlarging the target side alphabet. We fuse the Hindi vowels with their previous consonants and add them to the alphabet. As a result, the NULL and non-NULL mappings for English vowels contribute the same number of char-acter units towards the generated transliteration candidates thereby solving the length bias problem. For example, as ( # is added to the alphabet, both ( # and ( contain two character units only. 8.2 Experiments and Results For evaluation of English-to-Hindi transliteration, we use the standard NEWS 2009 shared task dataset, the details of which are already given in Table II. We use the training set to train the CRF and SMT transliteration systems used for the baseline comparisons. The development set was used to tune the various CSM parameters in our rule-based system and other parameters in the baseline statistical systems.
 documents obtained from Guruji , 1 an Indian Search Engine company. We ex-tract the list of unique Hindi words from the above corpus and train a basic tri-gram CSM using SRILM toolkit. Later, we progressively improve the CSM accuracy by following the sequence of techniques mentioned previously like enlarging alphabet, varying CSM order, varying smoothing technique, using origin-wise rule base and CSM. The results on the development set is shown in Table VIII. The origin classification mod ule was trained on English side using the same training data as mentioned in Table II.
 Hindi to English transliteration results shown in Table V, the accuracy of the rule-based system is lower than both CRF and SMT approaches. However, its performance for the words of Indo-Arabic origin still remains respectable. Since written English is non-phonetic, pronunciation of a letter depends lot more on the context, and hence a rule based system that does not pay much attention to context fares poorly. A detailed comparison of the relative complexities involved in Hindi to English and English to Hindi transliteration tasks will be presented in Section 9. 9. ANALYSIS OF TRANSLITERATION COMPLEXITY In this section, we analyze the results of the rule-based system using an entropy-based measure which allows the comparison of transliteration com-plexity across various datasets. For the rule-based system, we  X  X ompare the relative complexity of Hindi-English and English-Hindi translit-eration tasks; and  X  X nalyze the effect of dataset choice o n transliteration accuracy for Hindi-
English transliteration. 9.1 Average Entropy of a Dataset Let L 1 and L 2 be two languages with alphabets A 1 = { x 1 , x 2 ,..., x m } and A D with parallel list of transliterations, we measure the uncertainty involved in mapping characters of L 1 to characters of L 2 using Average Entropy [Jurafsky and Martin 2008] defined as follows: character y j corresponding to the source character sequence x i in the given dataset D .
 (e.g.,  X  kh) have zero entropy and do not contribute to the overall en-tropy whereas characters whose mappings are highly ambiguous and context-dependent (e.g.,  X  k,c,q,ck | !S,ch) have high entropy and contribute more. Hence, A v gEntropy ( L 1 , L 2 , D ) serves as an indicator for the relative hardness of the transliteration task for the language pair L 1  X  L 2 on a given dataset D . tain the character-level alignments and compute A v gEntropy ( L 1 , L 2 , D )using Equation 1. 9.2 Hindi-to-English vs. English-to-Hindi Transliteration Intuitively, we expect the transliteration from a non-phonetic language to a phonetic language to be harder than the reverse task. We use the A v gEntropy measure defined above to formalise the above intuition. While calculating A v gEntropy , we use the same NEWS 2009 dataset for both directions. The result is shown in Figure 6 which corre lates the accuracy of the rule-based system with the average entropy.
 English to Hindi and hence the task of Hindi-to-English transliteration is ex-pected to be easier when compared to English-to-Hindi transliteration. Also, we find that the uncertainty involved in character mapping is most significant in case of English vowels. This is not surprising since there are many more vowel sounds in English compared to only the six vowels in the roman alpha-bet especially if dipthongs are treated as a single unit [Rollings 2004]. 9.3 Effect of Dataset Choice on Transliteration Accuracy The results reported on the test set in Table V do not outperform the best ac-curacy numbers reported in transliterat ion literature. Currently researchers report widely varying accuracy numbers: from 32%-88% [Karimi et al. 2007] at Rank 1. For Hindi-to-English transliteration, Ganesh et al. [2008] report 72.1% accuracy at rank 5 for a CRF based system, while Kumaran and Kellner [2007] reported 31.1% accuracy at Rank 10. An important factor affecting any transliteration system performance is the quality of the test set, as discussed in Karimi et al. [2007]. On a different parallel name list of 5,000 Indian names (will be referred to as Indian Names Test (5,000)), our system gives accuracy of 87.4% at Rank 5. But this list seems to have been generated using a simple mapping table and is not representative of the real-life spelling variations and idiosyncrasies, and does not have enough instances of the schwa deletion phe-nomenon. Hence, it is highly imperative that results reported on non-open or non-standard datasets 2 should also report measures similar to average entropy to quantify the inherent hardness of transliteration.
 test set increases. In Figure 7, the average entropy and the Hindi-to-English transliteration accuracy is shown for the different dataset 30,000, NEWS 2009 and Indian Names Test (5,000). As discussed earlier, Indian Names Test (5,000) is the simplest of all three and hence has the least average entropy. The 30,000 dataset is the hardest, followed by NEWS 2009. However, the results reported in Tables V and VI are not in sync with the above observation. Indian Names Test (5,000) has the highest accuracy. But NEWS 2009 has lower accuracy than 30,000 which has higher entropy. This shows that Average Entropy alone cannot fully explain the performanc e of a system. We next provide a cross entropy based explanation for the above trend. probabilistic rule based system has rules of the form x  X  X  y 1 , y 2 ,..., y k } listing all possible target language character mappings corresponding to a letter x in source language. During candidate generation, all the target language charac-ter mappings { y 1 , y 2 ,..., y k } are treated as being equally probable and hence the conditional probability distribution Pr RB ( y | x ) used by the rule base could be stated as: Average Cross Entropy [Jurafsky and Martin 2008] of Pr D with respect to Pr RB given by:
A v gCrossEntropy ( L 1 , L 2 , D , RB )= x i  X  A 1 CrossEntropy ( x i transliteration task on the dataset D when the rule-based system Pr RB ( y | x ) is used to approximate the actual distribution Pr D ( y | x ).
 corresponding transliteration accura cies are shown in Figure 8. We observe that average cross entropy adequately explains the observed performance. uniform, unlike the CRF and SMT based systems where these probabilities are learnt from a training set. The performance of these statistical systems will depend on the extent of similarity between their training and testing data. A cross-entropy measure can be similarly computed for each of these systems. ing data involved before comparing results obtained using different datasets. 10. END-END CLIR EVALUATION USING FIRE 2008 DATASET In the previous sections, transliteration approaches were evaluated intrinsi-cally , as a independent standalone module. In this section, we evaluate the Hindi-to-English and English-to-Hindi transliteration approaches in the con-text of Cross Lingual Information Retrieval using the FIRE 2008 3 dataset. The details of the FIRE 2008 Hindi and English datasets are given in Table X. For CLIR, we use a query translation based CLIR approach using bilingual dic-tionaries [Padariya et al. 2008]. For the query words which are not found in the bilingual dictionary, their top five transliteration candidates are fed to the query translation engine. End-to-end cross lingual information retrieval was performed using each of the three transliteration approach (CRF, SMT, and Rule-Based). The standard method for CLIR evaluation is to compare the MAP (Mean Average Precision) score for cross-lingual evaluation with a monolin-gual baseline as % monolingual MAP. The results of our evaluation are shown in Figures 9 and 10. As expected, the effectiveness of the retrieval is directly proportional to the transliteration accuracy. 11. APPLICABILITY TO OTHER LANGUAGE PAIRS Having described our system for Hindi-English and English-Hindi transliter-ation tasks, we now wish to explore the generalizability of our ideas. As per Frawley [1992] and Crystal [1992], a majority of the existing writing systems are phonological and have a clear relationship between sounds and symbols. The major exceptions are the lopographic/morphographic Chinese script and the Japanese Kanji script. Our approach to rule-based transliteration is ap-plicable only to languages with phonological writing systems. Phonological systems are further divided into four categories: syllabic (e.g., Japanese Kana), only consonant letters (e.g., Arabic), independent consonant and vowel letters (e.g., Roman), independent vowel and inte grated consonant-vowel letters (e.g., Indian Devanagari). Cutting across these categories, some writing systems are over-determined X  X hey use multiple letters for one sound, while others are un-der determined X  X hey use one letter for multiple sounds.
 termined writing systems, or to transliterate from under determined writing systems. In these scenarios, contextual information will be vital for disam-biguation. Such information can be obtained either by a detailed understand-ing of the phonology of the language or by exploring a large parallel corpora. For all other settings, a rule-based approach may be applicable.
 guage. Our only criterion for selecting the language was that there should be two publicly available resources; a character mapping into English, and a par-allel transliteration corpus for evaluation. We next describe our experiments with Persian to English transliteration task. We had to spend only two days to get the basic experiments done, thus showing the adaptability of our approach. 11.1 Persian-to-English Transliteration Character mappings and parallel transliteration corpus are publicly available for Persian to English transliteration in Karimi [2008]. Hence, we decided to work on it, despite the fact that none of the authors have any knowledge of the Persian whatsoever (we cannot even rea d the Persian script). Persian being a consonantal language, short vowels are typically absent from the written Persian words [Karimi 2008], making the problem even more challenging. The Persian-English parallel corpus of 19940 word pairs used in Karimi [2008] was randomly partitioned by us into training, development, and test set, details of which are given in Table XI. Due to the lack of data, we could not perform the extrinsic evaluation of Persian-to-English transliteration in the context of CLIR. 11.2 Persian-to-English Rule Base We augmented the rule base obtained from Karimi [2008] slightly with the help of English to IPA (International Phonetic Alphabet) and Persian to IPA map-pings. If an English character sequence and a Persian character sequence map to same IPA symbol, we mapped these sequences to each-other, for example, and ei, ay, ai, ee . A segment of the mapping rules is shown in the Table XII. Also, since short vowels are dropped from written Persian words, if a Persian consonant is not followed by a vowel, then we insert a short vowel after the con-sonant. For example, consider the word (note that Persian is read from right to left) is followed by another consonant ( r ). Since gets mapped to f , ph , we also generate fa, fe, fi, fo, fu, pha, phe, phi, phu, pho as candidates for .
 11.3 Experiments and Results We repeated the step-by-step procedu re given in Table IV. We first experi-mented with the basic system, then enlarged the alphabet on the English side, and then weighed each English word as per its logarithmic-frequency in the Wikipedia corpus. Since the Persian-to-English character mapping table is not separated by word origin, we could not do the word origin-based steps. We also experimented with various smoothing techniques and found that PPM-D performed the best. The results of our experiments are shown in Tables XIII and XIV. The results follow the trend for Hindi to English transliteration as discussed in Section 5. The performance of our system is comparable to the CRF system while the SMT system does much better. Being a consonantal lan-guage, Persian is heavily under determined, and therefore transliterating from it using rule bases alone is harder. 12. CONCLUSIONS In conclusion, we have shown that for resource-scarce languages, a reason-able transliteration system can be built by judiciously applying statistical techniques to monolingual resources in conjunction with manually created bilingual rule bases. The statistical technique that we focus on is the Char-acter Sequence Modeling (CSM), typically called Language Modeling. It was not properly exploited by the existing systems and rich dividends are obtained by paying proper attention to it. We have also presented an entropy-based ex-planation for widely varying transliter ation accuracy numbers reported in the literature. This analysis explains in general why some transliteration tasks are harder than others.
 We thank Dr. Sarvnaz Karimi for providing us the Persian-English dataset and the rule bases. We also thank Dr. Maryam Shojaei Baghini for helping us in understanding issues related to the Persian script. The Indian search-engine company Guruji Inc. provided us with the Hindi Web content, and we are thankful to them. Finally, we would like to thank the anonymous reviewers who helped us improve not just the presentation but also the content of this work.

