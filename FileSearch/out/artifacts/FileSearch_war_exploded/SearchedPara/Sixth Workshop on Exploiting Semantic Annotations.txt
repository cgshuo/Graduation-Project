 There is an increasing amount of structure on the web as a result of modern web languages, user tagging and annotation, emerging ro-bust NLP tools, and an ever growing volume of linked data. These meaningful, semantic, annotations hold the promise to significantly enhance information access, by enhancing the depth of analysis of today X  X  systems. Currently, we have only started exploring the pos-sibilities and only begin to understand how these valuable semantic cues can be put to fruitful use. ESAIR X 13 focuses on two of the most challenging aspects to address in the coming years. First, there is a need to include the currently emerging knowledge re-sources (such as DBpedia, Freebase) as underlying semantic model giving access to an unprecedented scope and detail of factual infor-mation. Second, there is a need to include annotations beyond the topical dimension (think of sentiment, reading level, prerequisite level, etc) that contain vital cues for matching the specific needs and profile of the searcher at hand.

The goal of the sixth ESAIR workshop is to create a forum for researchers interested in the use of application of semantic anno-tations for information access tasks. There are many forms of an-notations and a growing array of techniques that identify or ex-tract information automatically from texts: geo-positional mark-ers; named entities; temporal information; semantic roles; opinion, sentiment, and attitude; certainty and hedging to name a few di-rections of more abstract information found in text. Furthermore, the number of collections which explicitly identify entities is grow-ing fast with Web 2.0 and Semantic Web initiatives. Yet there is no common direction to research initiatives nor in general tech-nologies for exploitation of non-immediate textual information, in spite of a clear family resemblance both with respect to theoretical starting points and methodology. Previous ESAIRs made concrete progress in clarifying the exact role of semantic annotations in sup-is used to include conceptually related articles that do not match the initial query. The experiments use CLEF/CHIC X  X  Europeana data.
Alonso et al. [2] propose to annotate entities in tweets and ex-ploit these annotations for improving the web search experience. The paper uses clickstream analysis to identify entities, exploiting queries and clicks on canonical pages.

Buscaldi and Zargayouna [4] present an extension of Lucene pro-viding concept-based information retrieval, by using SKOS/OWL terminologies, by annotating documents and queries, and by com-bining textual and conceptual matching scores in the ranking.
Ceccarelli et al. [5] propose a general framework for entity link-ing systems, allowing researchers to compare entity linking meth-ods under the exact same conditions. Three state-of-the-art entity linking algorithms are available within the framework.

De Ribaupierre and Falquet [6] propose a user-centric annotation model based on discourse elements (defined as an OWL ontology) and annotate a corpus of scientific articles in gender studies. The paper shows how complex queries, proposed by scientists, can be expressed in this model and solved by a description logic reasoner.
Friberg Heppin [7] investigates  X  X emantic frames X , essentially templates based on the lexical units in FrameNet, as a way to im-prove search results. Experiments on a Swedish corpus shows that the majority of matches conforms to the FrameNet meaning of the pattern, suggesting their potential for conceptual search.
Garkavijs [8] discusses exploratory image search by building a textual representation of a search trail based on viewed images. The paper proposes a simple algorithm for system training, that uses dwell-time data as input parameters for relevance recalcula-tion, which is implemented a the prototype image search system.
Guha [9] investigates the problem of customizing web search results to suit a particular context derived from a user profile or use case, focusing on the context of a  X  X igh school US history course X . The approach compares web content to Wikipedia pages of relevant entities (anchored by comparing the websites to a textbook).
Habib and Keulen [10] argue that named entity disambiguation and extraction are intimately linked and as such should be imple-mented together. One approach is to use the extraction confidence to maximize recall, and use this extra information to filter down to the best extracted entities and to disambiguate results.
Janowicz and Hitzler [11] is a position paper on how linked data and semantic annotation changes the interaction from the user X  X  point of view, and tries to disentangle some of the complexities focusing on geo-search. There is a persuasive argument for the im-plications for building systems consistent with these views.
Kaptein et al. [12] discusse a a number of possible approaches for reusing multiple existing web search engines to create a recall-oriented search engine. Specifically, three abstract techniques to re-order the retrieved results are discussed: clustering, reranking, or aggregation ( X  X nalysis X ).

Kim et al. [13] propose a method that mines subtopics based on the clusters of relevant documents. The approach uses simple patterns to mine candidate subtopics that partly match the original topic, and use an hierarchical sub topic ranker.

Leber et al. [14] investigate annotating legal documents with se-mantic elements extracted from the text by off-the-shelf NLP tech-niques. The approach deals with partly changed or updated docu-ments, in particular by parsing contract amendments to understand how the original contract is altered.

Yan [15] studies the use of Systemic Functional Analysis (a branch of linguistics) to capture the communicative context. A small cor-pus is manually annotated, and an initial classifier performs rea-sonably, opening up the possibility to deploy SFA in information access-related tasks.
