 Mahmood Bijankhan  X  Javad Sheykhzadegan  X  Mohammad Bahrani  X  Masood Ghayoomi Abstract This paper addresses some of the issues learned during the course of building a written language resource, called  X  X eykare X , for the contemporary Per-sian. After defining five linguistic varieties and 24 different registers based on these linguistic varieties, we collected texts for Peykare to do a linguistic analysis, including cross-register differences. For tokenization of Persian, we propose a descriptive generalization to normalize orthographic variations existing in texts. To annotate Peykare, we use EAGLES guidelines which result to have a hierarchy in the part-of-speech tags. To this aim, we apply a semi-automatic approach for the annotation methodology. In the paper, we also give a special attention to the Ezafe construction and homographs which are important in Persian text analyses. Keywords Contemporary Persian  X  Corpus  X  EAGLES-based tagset  X  Ezafe construction  X  Homographs 1 Introduction Persian belongs to the Indo-European (IE) language family and to the Arabic script-based languages in terms of orthography and text processing. As a subclass of the western Iranian Languages, Persian is currently spoken in Iran, Afghanistan, and Tajikistan where it is called  X  X ersian/Farsi X ,  X  X ari X , and  X  X ajik X  respectively. Persian has been in interaction with other non-Iranian languages such as Arabic, Turkish, Hindi, Mongolian, Latin, Greek, Russian, English, and French. Hussain and Gul ( 2005 ) compared status of standardization and development of basic localization applications among 14 Asian languages, and they found Persian to be in a satisfactory status.

To study linguistic phenomena in Persian, we collected various texts in the electronic format and built a corpus as a language resource. The end goal of this article is addressing the lessons learned from building this corpus. As an introduction to the discussion, it is useful to mention some of the available general corpora for Persian. The FARsi Spoken language DATabase (FARSDAT) is one of the sources offered by the European Language Resources Association (ELRA). This corpus consists of the speech of 300 native speakers of Persian chosen from ten different dialectal areas in Iran which is produced by the Research Center for Intelligent Signal Processing (RCISP; http://www.rcisp.com ; Bijankhan et al. 1994 ). The Linguistic Data Consortium (LDC) has designed and collected another linguistic resource for Persian in the OGI Multilingual Corpus which has covered the data of 100 Persian speakers (Muthusamy et al. 1992 ). This consortium has also produced another telephone database called CALLFRIEND Farsi with the code LDC96S50 in which the telephone conversations of more than 100 Persian speakers are recorded and verified.

The Institute for Humanities and Cultural Studies (IHCS) has produced an online database called the Persian Linguistic DataBase (PLDB; http//www.pldb.ihcs.ac.ir ), in which millions of words from the contemporary modern Persian with different genres have been collected such that the syntactic categories of a small amount of data is labeled by means of a set of 44 tags (Assi and Abdolhosseini 2000 ) and it is manually lemmatized. Moreover, the phonetic tags of the sample texts are assigned semi-automatically. The database includes texts of both formal and informal styles. The Hamshahri Corpus ( http://www.ece.ut.ac.ir/dbrg/Hamshahri/ ) consists of 345 MBs of news texts from the Hamshahri newspaper during the years 1996 X 2002 developed by the DataBase Research Group (DBRG) of the Faculty of Engineering at the University of Tehran. This corpus is prepared for different information retrieval research areas such that 65 queries and their relevance judgments for the top 100 retrieved documents according to TREC standard were created.

RCISP, in addition to FARSDAT, has produced three spoken corpora and a written corpus. The Telephone FARsi Spoken language DATabase (TFARSDAT) consists of 7 h of read and spontaneous speech produced as monologue by 60 native speakers of Persian from ten different dialectal areas of Iran, segmented and labeled into phonemic, phonetic, and word levels (Bijankhan et al. 2003 ). The Large FARSDAT is a Persian speech corpus which consists of read aloud speech from the newspaper texts in which 100 Persian speakers have produced, in average, 25 pages each, and whose speech was recorded by three kinds of microphones. This corpus consists of 45 h of microphone speech (Bijankhan et al. 2004 ). The Persian Telephone Conversation Corpus includes 100 long-distance calls from ten different dialectal areas of Iran in which each call is about 20 min long and each word is manually labeled phonemically, phonetically and orthographically. In all of these calls, the variety of the subject matter of the conversation is considered and the number of male speakers is twice as many as the female speakers (Sheykhzadegan and Bijankhan 2006 ). Peykare is a written corpus which contains approximately 110 million words of both written and spoken texts of the Contemporary Persian (CP). This corpus is categorized according to the criteria such as factuality, format, style, and linguistic material. About ten million word tokens of this corpus were selected randomly and labeled according to the EAGLES guidelines. Table 1 illustrates a summary of the available general corpora for Persian along with their function.

This paper is organized in eight sections. After this brief introduction of Persian and the available general corpora, we will talk about the non-/linguistic parameters taken into consideration for sampling frame in Sect. 2 . Then in Sect. 3 , we will describe how the texts are collected to construct Peykare. In Sect. 4 , the tokenization process will be elaborated by defining two linguistic units: multi-unit tokens and multi-token units. In Sect. 5 , we will mainly discuss the annotation of Peykare with the help of EAGLES guidelines. In Sects. 6 and 7 , two important issues of Persian that should be considered in corpus development are taken into consideration; namely the Ezafe construction and homographs. The paper ends with a summary in Sect. 8 . 2 Linguistic preliminaries In this article CP is in focus. CP is the last era of the modern Persian which has been the formal language of Iran for the last 162 years. To clarify the time intervals in which CP texts have been published, we have considered the political milestones as a distinctive border. This is because of the strong effects of the political events in each period (as listed below) on the lexical items of both written and spoken Persian, used by the media and the speakers of this language:  X  1847 X 1906: AD before the period of  X  X ashroutiyat X  (Constitutionality);  X  1906 X 1925: from Constitutionality until the first king of the Pahlavi dynasty;  X  1925 X 1941: from the first king of the Pahlavi dynasty to the second king;  X  1941 X 1978: from the second king of the Pahlavi dynasty to the Islamic  X  1978 X 1988: from the Islamic revolution to the end of the war with Iraq;  X  1988 X 2006: from the end of the war until 2006 when designing Peykare ended;  X  2006 X  X resent: from 2006 until now when text collecting for Peykare resumed.
In addition to the above metalinguistic parameters, linguistic varieties are also considered as a socio-linguistic parameter. Since  X  X tandardness X  (Douglas 2003 ) and  X  X ormalness X  (Hodge 1957 ) are two complex and fuzzy parameters, we believe that three linguistic varieties can be identified for Persian during the last century: Standard (S), Super-Standard (SupS), and Sub-Standard (SubS) in which for each of them, potentially, there exist Formal (F) and InFormal (InF) styles; thus, twelve varieties of CP can be taken into account. Douglas ( 2003 ) has explained the complexities of how to define language varieties based on these parameters in gathering the Scottish corpus. Almost the same situation holds for CP, too. Since the written mode has only been considered in Peykare, and there is no formal style for the sub-standard variety, it can be expected that the texts can be collected for five varieties of CP; namely standard-formal, standard-informal, super-standard-formal, super-standard-informal, and sub-standard-informal. 3 Composition of Peykare Peykare is a core synchronic general corpus which includes texts of the five above-mentioned linguistic varieties. To have the qualification of being the representative of the language, the corpus is designed in such a way to be comprehensive enough and include different registers so that the  X  X andom error X  and the  X  X ias error X  decrease to the minimal level (Leech 2002 ; Biber 1992 , 1993 ). When the number and the length of the text samples are not enough to estimate the linguistic parameters, random error increases; and when the text samples do not cover a wide domain of registers, the bias error increases. The first requirement, nowadays, is easy to achieve because of the vast amount of sample texts freely available on the Internet; but satisfaction of the second requirement is not easy for CP. However, the real challenge is how well a corpus represents the register diversity given that there are marked linguistic differences across registers (Biber 1993 ).

Peykare consists of 35,058 text files, each of which includes either a full text or a random sample of a full text. The size of each text is a chain of at least one thousand words; while the size of some newspaper texts which include short news or commercials is less. Two kinds of criteria have played the main function in the process of choosing data for Peykare: a linguistic criterion to distinguish the five linguistic varieties of CP; and the non-linguistic criteria which include the variables depicting the communicative function of the texts among the language users such as time, mode, factuality, and the medium (Al-Sulaiti and Atwell 2006 ; Kuc  X  era 2002 ; http://www.corpora.fi.muni.cz/ske/doc/urg.html ). Peykare, for the time being, includes the texts produced during the years 1978 X 2003. Of course, the works of some famous writers that are out of this time span, such as Heda  X yat, are included as well.

Mode shows the way the linguistic data is conveyed. Peykare merely includes the written texts. Spoken corpora have been planned and produced in projects such as FARSDAT, TFARSDAT, and the Large FARSDAT. Generally, written texts can be classified into two groups (Atkins et al. 1992 ): written to be read (WR), and written to be spoken (WS). The Statistical Center of Iran ( http://www.sci.org.ir/ ) has reported that the literacy rate of 15 X 24 year old people has increased from 84.6% in 1990 to 95.4% in 1998. Furthermore, because of the significant increase of educational facilities, technical and occupational services, the number of readers of books, magazines, and newspapers has increased as well. As a result, the size of WR texts in Peykare is greater: 87% of WR versus 13% of WS on the whole.

Factuality is a variable with the values of fiction and non-fiction (Kralik and S  X  ulc 2005 ). Since Persian literature is replete with fiction texts in prose and poem, and they have a tremendous effect on the written and spoken Persian, it covers a significant proportion of Peykare. This is against Sinclair X  X  ( 1987 ; 1 X 8) opinion since he believes that the proportion of literary works should be low in a general corpus; but it is a fact that Persian as a communicative language and the language of 40.20% non-fiction, and about 36.8% a combination of both fiction and non-fiction. A considerable amount of fiction and non-fiction texts which are read by many readers are translated from foreign languages, mostly from English and Arabic. The vocabulary and the syntactic structures of translated texts are completely marked.
Medium is a variable which shows in what format the contents of the texts are published. The medium in Peykare are: books, magazines, periodicals, newspapers, web pages, compact disks, unpublished texts, and manuscripts.

The content of Peykare is categorized under 24 different registers as represented in Table 2 along with the linguistic criteria used for text collection. We have classified these 24 registers under the five linguistic varieties and evaluated the cross-register differences for the five levels. To test the extent of cross-register differences for language variety, twelve linguistic parameters were chosen namely: first and third personal pronouns; the most frequent nouns, preterite verbs, and indicative present verbs; prepositions; verb-locative construction; question words; relative, complement, and conditional subordinate clauses; passive construction I and II. Each parameter consists of a finite set of words obtained by searching through the tagged Training Corpus (TC) using the Searchdata tool which looks for morphological and syntactic structures via regular expressions. The most frequent words were obtained by sorting words with their tags in descending order. Relative and complement clauses were obtained simply by the following orthographic regular expression (X is a string of allographs):
Passive construction I comprises a past participle followed by the inflected forms of the passive auxiliary-verb  X   X /s  X  odan/  X  X o become X . Passive construction II comprises any other words followed by the passive auxiliary verbs.

To examine cross-register differences in the distribution of the twelve parameters, the text files of each register in Peykare were divided into subtexts with 4,000 words length. 100 subtexts were chosen randomly for 15 registers whose total size is larger than 400,000 words. The number of subtexts for registers of governmental projects, correspondences, minutes, personal letters, and prepared lectures were 83, 21, 5, 15 and 44, respectively. Frequency of the words pertaining to each linguistic parameter was counted for all subtexts; and then the ANOVA test was used to differentiate the levels of varieties with mean, standard deviation, and F -value. The conclusion, as follows, suggests that there exist significant differences among the levels of varieties:  X  Conditional subordinators, first person pronouns, prepositions, present indicative  X  Irrespective of standardness, first and third person pronouns, preterite verb, verb- X  Nouns and passive construction I are the only linguistic parameters discrimi- X  Irrespective of formality, prepositions, indicative present verbs and passive 4 Tokenization Ghayoomi and Momtazi ( 2009 ) and Ghayoomi et al. ( 2010 ) have described the problems to deal with in developing a corpus for Persian including the tokenization problem. Word boundary is the most challenging issue for tokenization. In Persian texts, a word can be considered as a chain of letters which makes up at least one free morpheme. Typists intuitively recognize words according to this definition, like other literates; while typing texts, however, they do not separate words which results in orthographic variations (Buckwalter 2005 ).
 At least two reasons can be considered for the orthographic variations of words in Persian electronic texts: 1. In typing Persian texts, typists do not reach a unified way of writing, even by following the grammar of Persian orthography published by the Persian Academy of Language and Literature (PALL). 2. According to the cursive nature of Arabic scripts, two potential forms of writing can be envisaged for a word consisted of at least two morphemes:  X  X oncatenative X  where the final letter of a token attaches to the next coming token; and  X  X on-concatenative X  where a blank or Zero-Width-Non-Joiner (ZWNJ) inserts between the tokens. Bear in mind that there exist some letters in Persian which do /v/. If the first token ends with any of these letters, then there will be at most two non-concatenative forms. Generally speaking, if a word has n tokens, then the possible number of written forms of that word will be 3 n  X  1 . For example, considering the word  X   X  /mi + foruxte +  X  am/  X  X  have been selling X  in which n = 3, there will be nine possible forms:  X   X ,  X   X ,  X   X *,  X   X ,  X   X ,  X   X *,  X   X ,  X   X , and  X   X * (the symbol ^ stands for ZWNJ). The forms with asterisks are basically ill-formed because the final letter of the token  X   X  /foruxte/  X  X old X  which is Silent Heh  X   X  should not attach to the following token. With this method, the problem of determining the boundaries between Persian words will be reduced to the level of determining the orthographic variations of the morphemes which make up the word. Following Cloeren ( 1999 ) if each written token consists of more than one morpheme, then we will have a multi-unit token (MUT) such as  X   X /buse +  X  i/  X  X  kiss X , and  X   X /raft + o +  X  a  X mad/  X  X raffic X ; and if some tokens, in whole, make up a linguistic unit, we will have a multi-token unit (MTU) such as  X   X /busha  X ye/  X  X isses of X , and  X   X /rafto  X  a  X mad/  X  X raffic X . As a result, a word in the Persian text can be considered as a MUT or MTU. MTUs are mostly normalized according to the orthographic variations.

Morphophonemic processes in the word formation are usually reflected in orthographic representation, as some MTUs show. For example, the allograph of Heh  X   X  /h/inserts between the two vowels/e/in the word  X   X /behem/ X  X o each other X , and Alef  X   X  inserts between the vowel graphemes Silent Heh  X   X  and Yeh  X   X  in the word  X   X .

It is worth mentioning that token concatenation will result in an ill-formed MTU form, if the last allograph of the token to which the next token concatenates happens to be Silent Heh  X   X /h/; or if one of the concatenated tokens happens to be the conjunctor  X   X  /va/  X  X nd X  in structural template of the form.  X  X  X X  (X denotes a morpheme or allomorph). Therefore, we need a standard to normalize MTU forms.
In recent years, a strategy was prescribed by the PALL for the grammar of the CP orthography which concentrates upon independence of tokens from each other within the MTUs by using ZWNJ between tokens, while the whole MTU is surrounded by a blank to keep its unity in the running text. To generalize MTU evaluation, the MTUs of different types which are inflectional, derivational, and specific compound were obtained from Peykare by using an automatic substring search in input texts. Results showed that contrary to the uniform treatment of the PALL strategy for different types of MTUs, when prefixal and compounding tokens tend to be transparent and separate from the neighboring tokens except for derivational  X   X  /be/ (adverbial  X -ly X ), suffixal and enclitic tokens are prone to concatenate to the neighboring tokens which result in the opacity of the morpheme boundary.

The systematic statistical tendency observed in the MTU forms of Peykare can be explained by the following descriptive generalization to evaluate and normalize MTUs X  orthographic variation based on PALL:  X  X rthographic words cannot include a blank as a word boundary, and this requirement is enforced by (a) or (b), except when the result is inconsistent with (c), (d), (e) or (f) X : (a) ZWNJ inserts between a prefixal or a compounding token and a following one. (b) Suffixal or enclitic tokens should concatenate to the neighboring tokens. (c) No token ending with Silent Heh  X   X  should concatenate to the following one. (d) The conjunctor  X   X  /va/  X  X nd X  should not concatenate to its preceding token ending with a joining letter. (e) Token concatenation is prohibited when suffix, enclitic, or compounding token begins with Alef  X   X  or Alef with Mad above  X   X . (f) Some exceptional derivations and compounds do not obey (a) or (b) for orthographic, aesthetic or any other reason. X  One issue close to tokenization in CP text processing is lemmatization. Lemmatizing MUT inflected words to find lexemes or stems of the word formation is useful in many respects such as morphological analysis, word stemming, and NLP applications like information retrieval. Although a large number of words may occur with a very small frequency as a result of Zipf X  X  law (Manning and Schu  X  tze 1999 ), coverage of a wide domain of registers in a language resource results in the richness of lexicon, thus it causes the reduction of the bias error to some extent. To gain a practical knowledge to deal with the problem of automatic lemmatization of Peykare texts (Mosavi-Miangah 2006 ), we firstly decided to lemmatize the TC texts in which each word is provided by an EAGLES-based hierarchical tag, as will be described in the next section. To this end, an automatic process of stripping off clitics and affixes from the inflectional MUT words for 2,990 original non-lemmatized text files of the TC resulted in the same number of lemmatized text files. In the second step the TC lexicon was captured by lexical ordering of all lemmatized TC texts. 5 Linguistic annotations To annotate Peykare with POS tags, we collected a small corpus as a training data set of the TC for automatic POS tagging. This sub-corpus consists of Ettela X  X t and Hamshahri newspapers from the years 1999 X 2000, dissertations, books, magazines, blogs, written and spoken texts were collected randomly from 68 different subjects pertaining to different registers to cover varieties of lexical and grammatical structures. The size of the TC has reached 10,612,187 tokens, in which it decreased to 9,781,809 words after tagging some MTUs by means of one specific tag and considering each MTU as a word. This represents an 8% reduction in the corpus size. This reduction means any Persian tokenizer should find a satisfactory algorithm to deal with about 8% of the size of a given text for MTU resolution. This size is computed without taking into account complex predicates such as complex infinitives and verbs. The TC consists of 2,990 text files, each with at least one subject. DBRG at the University of Tehran has provided 2.6 million words of the first version of the TC called the  X  X amshahri Corpus X .

In sum, the TC contains 8,856 subtexts mostly about politics. The chosen subjects are based on the classification made by media. The TC dictionary contains 146,665 non-lemmatized entries in which 27,317 entries are non-linguistic symbols, Arabic and English strings of letters. 5.1 EAGLES-based tagset The EAGLES guidelines (Leech and Wilson 1999 ) have been used to mark-up grammar of the texts for the European languages; however, they are also used for tagging the texts of non-European languages as well such as Japanese (Kawata 2001 ) and Arabic (Khoja et. al. 2001 ). We have also benefited from these guidelines for Persian because besides being a member of the IE family, its inflectional morphology is rich enough for nouns and verbs at least in comparison with English. As a sample, in Table 3 we have shown three categories of Persian based on the EAGLES guidelines. Tags are defined on the basis of the major categories (POS) and attributes. It should be added that in our task, contrary to EAGLES which only has 13 major categories including adposition, we have defined two separate categories for preposition and post-position instead of adposition so the major categories added up to 14. The reason for dividing adpositions into the two categories is that the only postposition of CP is  X   X  /ra  X / (which functions as a definite marker) and it is more active than prepositions in fusing with other major categories. Ultimately, we have 14 tags for the major categories, 52 tags for the recommended attributes, 25 tags for the generic attributes, and 18 tags for the language-specific attributes which add up to 109 tags.

The tags have been given names on a mnemonic framework so that the value of the categories can be easily defined. The structure of the whole given name of a tag is hierarchical, i.e. the major category, the recommended attributes, the generic attributes, and the language specific attributes are represented respectively and they have been separated by commas. The predictable values of some attributes have not been specified. The semantic features, such as the generic attributes of nouns, have been used for distinguishing homophones. For example  X   X  /dos  X  anbe/ could be  X  X onday X  with the tag name N,PR,SING,DAY (which stands for Noun, PRoper, SINGular, and DAY); or could be  X  X ushanbe X  with the tag name N,PR,SING,LOC (which stands for Noun, PRoper, SINGular, and LOCation).

The total number of hierarchical tag names of the TC has reached 606 tags. For the main verbs of Persian, a dichotomy of copulative and non-copulative was defined. Mood has been specified merely for the non-copulative verbs; while the copulative verbs are, by default, indicative mood and present tense. Person and number of the subjects of verbs are specified by the numbers 1 X 6 in which the numbers 1 X 3 show the first, second, and third person singular, and the numbers 4 X 6 show the first, second, and third person plural.

The copulative verbs are always accompanied with the indicative mood of the verb /budan/ which is added as an enclitic to a non-verbal element, usually a noun, an adjective, an adverb, a pronoun, or a prepositional phrase. The non-verbal elements of the copulative verbs are tagged with NC,AJC,ADVC,PROC and PC, respectively. The tag SIM has been uniquely used for the copulative simple verb /  X  ast/. For example  X   X  /xub + am/  X  X  am good X  is a bi-unit token of which the major category is a verb and its tag will be: V,COP,PRES,AJC,1.

Because of language-specific attributes for Persian, two kinds of morphemes are added to the tagset to distinguish non-lexical homographs from each other and to prepare the necessary information for the process of lemmatization and semi-automatic construction of the treebank. One class of morphemes consists of attaching functional categories such as enclitics to the end of words; and the other one is morphemes or words fusing with the host words and forming a compound tag with at least two tags of the major categories. The most important characteristic of the fused words is that at the morpheme boundary morphophonemic processes are usually involved. For example,  X   X  /ku/  X  X hat (s)he X  appears in literary texts and it is a word which is made from fusing the conjunctor  X   X  /ke/  X  X hat X  and the third person singular pronoun  X   X  /u/  X (s)he X ; so its tag would be: CONJ,PRO,PERS,SING,3.
The enclitics consist of pronominal enclitics, YEH, and Ezafe morphemes. The pronominal enclitics have different syntactic functions, such as subjective, objective, possessive, impersonal, and partative. Each of these enclitics attaches to certain major categories (Megerdoomian 2000 ). These pronouns are inflected according to person and number. The syntactic functions of such enclitics have not been specified in the full name of a tag. For example,  X   X  /xord + am + as  X  /  X  X  ate it X  has been specified by the tag V,PA,SIM,1,3 such that the number  X 1 X  is the personal pronoun with subjective function belonging to the recommended attributes, and the number  X 3 X  shows the third person singular with objective function belonging to the language-specific attribute.

The morpheme  X   X   X   X  /i/ with the tag YEH represents either inde fi niteness or relativization of a noun phrase. In either case, it attaches to a noun or the farthest modi fi er of a noun on which the relativizer conjunctor/ke/will appear. It should be added that the similarity between the pronominal enclitics and the enclitic YEH is that their presence means the end of a syntactic phrase is reached; but, they are in complementary distribution.

Ezafe as another enclitic will be described in Sect. 6. Its difference with the two previous enclitics is that the presence of Ezafe does not determine the end of the syntactic phrase is reached.

The advantage of the EAGLES guidelines in tagging a subcorpus of Peykare can be judged on the basis of the tagset size. The tagset size of a language resource largely depends on the goal of the tagset designer to provide a distinction for all classes of words having a distinct grammatical behavior (Marcus et al. 1993 ), the inflectionality of the language, and the orthographic representation of words. The POS tagsets developed for English corpora have different sizes according to the different strategies adopted for POS tagging: the Brown corpus with 87 simple tags; the LOB with 135 tags; the UCREL with 165 tags; the LLC with 197 tags; the Penn Treebank with 48 tags; and BNC with 138 tags. Hajic  X  ( 2000 ) has shown that the tagset size for highly inflective and agglutinative languages can reach 3,000 X 5,000 tags; as a result, increasing the degree of inflectionality of a language makes the tagset size bigger. Since the morphology in Persian is agglutinative and somewhere between highly inflective languages like Arabic and Czech, and less inflective like English, for each tag in the TC there exist information about POS classes and details about inflections, Ezafe, and semantic features to have a feature structure centralized to the POS class. Representing the language inflectionality in orthographic words, in English the possessive construction is represented by a minimal NP consisting of two separate simple orthographic words: such as  X  X our book X ; while in Persian it can be represented by a minimal NP equal to one MUT word like  X   X  /keta  X b + at / [noun +possessive enclitic]  X  X our book X . This example shows that the number of hierarchical tags in Persian starting with noun as a POS class must be larger compared to English. Therefore, more and more noun-initial tag names will be added to the Persian tagset if other nominal features like number, indefinite marker, and Ezafe are added to the list of Persian nominal enclitics or suffixes.

Before focusing on the process of tagging in Peykare, it is interesting to determine the advantages of tagging in Peykare compared to PLDB. In Peykare we have used the EAGLES guidelines to standardize tags while tagging in PLDB (Assi and Abdolhosseini 2000 ) does not follow any special standards. The most distinctive feature in Peykare is that it has used 14 main categories based on EAGLES in which they are enriched linguistically by adding more information to them and there are hierarchical relationships between the tags; while in PLDB only 44 simple tags were used which cannot represent the complexities of Persian. 5.2 Semi-automatic POS tagging The Editor tool developed for the TC performs two simultaneous operations: segmenting the input raw text into MUTs and MTUs by using a database for free and bound morphemes; and POS tagging semi-automatically. The semi-automatic POS tagging process is as follows:  X  Four linguistic graduate students, as annotators, trained to tag words of the very  X  Editor tool was programmed to compute the frequency distribution of different  X  Annotators corrected wrong tags on the Editor tool and proofread the tagged  X  UEPRJ software developed for final correction of the tagged text due largely to
UEPRJ is a powerful tool for data search and correction which provides simultaneous access to frequency vocabulary, word tags, and tagged text files via the TC depending on the linguistic context it appears in. UEPRJ can be used to list each tag accompanying the absolute frequency of the word which has occurred. If correction is needed, the annotator can select the target word with one of its tags and review it in the speci fi c sentences of the source tagged texts it occurred in. In the corresponding absolute frequencies, and sample sentences have come: Singular demonstrative pronoun (41,265):  X   X /a  X n ra  X  xordam/  X  X  ate it X 
Demonstrative determiner (15,345):  X   X /a  X n keta  X b ra  X xa  X ndam/  X  X  read that book X  Noun, singular common Ezafe (272):  X   X  /az a  X n e s  X  oma  X st/  X  X t is yours X 
Noun, singular common (25):  X   X  /har a  X n momkene/  X  X t is possible at any moment X  Noun, singular Proper (10):  X   X /a  X n a  X bra  X mson/  X  X nn Abaramson X 
The Editor allocates the tag of singular demonstrative pronoun to the word /a  X n/ automatically, as long as it is the most frequent tag among the five tags. The annotator can change the automatically allocated tag manually only when the mistake is found after proofreading the tagged text. It is important to mention that most of the wrong tags we found in the two last stages are homographs, homophones, proper nouns and Ezafe markers.

After lemmatization of Peykare the number of hierarchical tags sank to 131 tags from 606 tags which is about a 78% reduction as represented in Table 4 . In addition, 39% of the word tokens are nouns, which is 2% more than the finding of Hudson ( 1994 ) for English corpora as he claimed the generalization that about 37% of word tokens are nouns for any reasonably large body of written English such as LOB and Brown. We believe that the 2% difference for the Persian corpus is due largely to two reasons: highly frequent usage of the Latinized equivalents of English transliterated into Persian as loanwords in scientific texts; and considering complex verbs made of a non-verbal word (mostly nominal) or phrases and light verbs as separate words and not MTU. 6 Ezafe construction Ezafe is an enclitic pronounced /e/ to disambiguate the boundary of a syntactic phrase and a linking element to join the head of a phrase to its modifiers, found in the IE languages like Persian and Pashto (Samvelian 2007 ). This construction has been studied mostly in the framework of Chomsky X  X  GB theory (Ghomeshi 1996 ); but the scope of Ezafe defined in this paper is equal to or less than the scope defined in theoretical linguistics. For example, the whole phrase of Ezafe construction for  X  X he book of the clever student X  is considered the same for both theoretical and text processing viewpoints. But, the phrase  X   X  student X  has two Ezafe constructions in text processing namely [N EZ] and [DET N EZ AJ]; while one Ezafe construction is theoretically embedded within another [N EZ [DET N EZ AJ]].

The Ezafe construction can be demarcated by function words like conjunctors, determiners, postposition  X   X   X   X  /ra  X /, some prepositions, verbs and non-verbal elements of a complex verb. A frequency counting of POS categories accepting Ezafe shows a descending order as follows: noun (82%), adjective (10%), preposition (5%), determiner (1%), number (1%), adverb (0.7%), conjunctor (0.03%), pronoun (0.2%), and residual (0.02%). Statistics showed that, regardless of CP varieties, 23% of words have accepted Ezafe in TC. Moreover, 87% of these words with frequency of at least 1,000 items had no overt orthographic symbol for Ezafe which means on average about 20% of words in CP text can include words with Ezafe while no orthographic symbol is used to refer to it. As a result, Ezafe recognition of the words with no overt orthographic symbol is a challenging issue for language engineers working on Persian. Having a moderate error rate of recognizing Ezafe will result in a rather poor intelligibility of Persian speech synthesizers and also a poor performance of syntactic parsing in Persian machine translation which result in increasing the error rate of phrase boundary detection.

To investigate the structure of the Ezafe construction, the following regular expression is applied to TC: This regular expression is defined to match any POS tag sequence consisting of a tag with Ezafe, followed by any number of tags with Ezafe, ending in a tag without Ezafe. A tag sequence found in this way provides useful information about the length of the Ezafe construction and perhaps semantic constraints among tags within the construction. Table 5 shows the result of pattern matching for the most frequent POS tag sequences of the Ezafe construction. The weighted average of length for such POS tag sequences equated to 2.53 tags. As the length of the Ezafe construction increases, the frequency decreases. Note that almost 44% of the Ezafe constructions are  X  X apax legomena X  i.e. they occurred once; and 78% of them occurred ten times or less which are largely made up of combinations of a noun with other nouns found in registers like scientific articles, official news, and governmental protocols/documents.
 Automatic demarcation of the Ezafe construction is a controversial issue in Persian text processing. As the length of a word sequence increases, recognizing the Ezafe construction correctly will be harder in the absence of any orthographic Ezafe enclitic. We hypothesize that semantic features of the words within a word sequence defined by the EAGLES-based tagset could resolve such a problem, before a syntactic X  X emantic or discourse methodology is tried.

To judge this proposal, two other regular expressions were defined to search for instantiations of the most frequent Ezafe construction pattern i.e.  X  X oun-Ezafe Noun X , with this regular expression: and its counterpart without Ezafe, i.e.  X  X oun Noun X , with this regular expression: In Tables 6 and 7 the five most frequent sequences obtained by applying the two regular expressions on the TC are represented. It is found that the semantic features of 93% are two-tag sequences for both kinds. The semantic features LOC (LOCal), TIME, DAY, DIR (DIRection), SURN (SURName), ACR (ACRonym), MON (MONth) and YEH provide appropriate cues to detect the Ezafe construction; as a result, the Ezafe construction detection can be improved at least by using semantic features of the words inserted in the lexicon.
 7 Homograph Homography, in our terminology, refers to one of two or more words that have the same spelling but differ in meaning and pronunciation, and not necessarily belonging to the same family of languages. The differences in pronunciation can make differences in short vowel and/or stress structure of homographs. Here we are more concerned with the Persian homographs made up from adhesion of suffixes and also enclitics to the stem of at least one homographic word which is one of the most critical issues of the Persian POS tagging. We call such homographs  X  X on-lexical homographs X . In contrast,  X  X exical homographs X  are found directly in the lexicon like  X  X ow X  in English with two different meanings and pronunciations of / so  X  / and /sa  X  /. Non-lexical homographs can be classified into different classes in terms of the major morpho-syntatic category each homograph belongs to, such that the members of each class obey an exact orthographic and phonological pattern. In this paper, the sporadic homographs having barren patterns and lexical homographs are excluded from our study.
 Because of the productive structure of non-lexical homographs, their analysis in Persian texts is a crucial task while building a Persian resource. Based on the experiment on Peykare, Persian non-lexical homographs can be classified into 13 patterns presented in Table 8 with pattern names, examples, POS patterns, and their frequency distribution both in the TC and Peykare. Pattern names are selected according to the enclitics or suffixes added to one of the homographs.
The homograph richness of Peykare was judged in a process of three steps: firstly, the sets of word tokens with more than one major category, representing 13 types of homographs, were identified by searching the TC. Secondly, the identified words of each type were classified into two or three POS patterns, in which a star is used to show a range of values of attributes defined for major categories (see Table 3 ). For example, the POS pattern N, *, YEH covers the hierarchical tag names such as N,COM,SING,YEH; N,COM,PL,YEH; or N,PR,PL,YEH among others.
 Lastly, relative frequency of homographs was computed for each type in Peykare.
The analysis of the results shows that the pronominal clitics and YEH are among the main sources of non-lexical homographs in CP. The six most frequent types of homographs involve the contrast between nouns, verbs, and adjectives. Syntactic and lexical semantic features can be used to resolve noun homographs. Hearst ( 1991 ) has checked the contextual surrounding of the target noun to disambiguate English noun homographs using large text corpora. Assuming that a homographic word is ambiguous between a nominal (noun or adjective) and verbal category, a null hypothesis might be that if syntactic context convinces us that the word has to accept Ezafe, then verbal homograph will be rejected since verbs do not accept Ezafe. However, if syntactic context does not provide evidence of Ezafe for the homographic word, then ambiguity will remain unsolved.

Another big challenge that the Persian NLP community should deal with is recognizing noun versus adjective. This is very important for applications like machine translation and TTS. From the Persian TTS point of view, this challenge may be more crucial because poor recognition of the first type of homographs will result in wrong pitch accent patterns of sentences. 8 Summary and future work In this paper, we explained the major issues in building and evaluating written corpora in contemporary Persian on the basis of findings from two resources: a register-diversified corpus called  X  X eykare X  and a training corpus annotated by the EAGLES-based POS tagset. After defining five linguistic varieties and 24 different registers based on these linguistic varieties, we collected the texts for Peykare to do linguistic analysis including cross-register differences. In tokenization process of Persian which is challenging for corpus designers, we should deal with multi-token units and multi-unit tokens. To this end, we proposed a descriptive generalization to normalize orthographic variations existing in texts. To annotate Peykare, we benefited from the EAGLES guidelines to have tag hierarchies as a result. For the methodology used in the annotation of Peykare, we have used a semi-automatic approach. The Ezafe construction and homographs, which are problem makers in text processing, were discussed.

As for the future work, we will use the tags for automatic treebanking of the TC as the training data for treebanking of Peykare.
 References
