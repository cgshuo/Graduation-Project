 Improvements in communication technology facilitate decision-making within groups of agents that are distributed geographically or in time. Examples include electronic commerce, first-response systems, and online gaming. A common characteristic of many of these domains is that relevant information is distributed among different sources, and the extent to which agents can make good decisions depends on their ability to collect salient, reliable information about how their decisions affect their utilities.
The focus of this article is on the circumstances in which agents X  success depends on the unknown capability of potential partners, and information about the competency of partners is distributed among potential information providers. Agents can query these agents X  X t a cost X  X o obtain information about the capabilities of potential partners, in addition to using their own experience from prior interactions. To succeed, agents must weigh the trade-offs between purchasing external information and using their own experience to make decisions. As an example, consider an executive that is choos-ing among one of several possible airline club memberships. This decision involves a commitment to fly with the chosen airline for the next year. The competency of an airline is measured as the percentage of punctual arrivals over a given time frame. When making a decision about which airline to choose, the executive can rely on her own experience from flying different airlines in the past, or she can ask colleagues or query online reviews to get additional opinions.

In the setting we consider in this article, a principal agent needs to choose a partner to engage in a long-term series of interactions. The success of each interaction stochas-tically depends on the unknown competency of the partner agent. The principal agent can query different information providers about their experience from interacting with the candidates. We formalize the task of information gathering in this setting as an op-timization problem in which the principal agent chooses to query different information providers about each candidate in a way that maximizes its expected future reward, given that queries are associated with a cost.

Following the airline example, the principal agent may choose to obtain information about candidate partners from several possible sources: (1) personal interaction , refer-executive herself. (2) Gossip information , referring to the views and opinions of other agents about their interactions with candidates, that is, the reports of other executives from their own interactions with various airlines. (3) Reputation information , referring to a repository summarizing the interactions of several interactions with candidates, that is, repositories of reports (such as online review sites) about the experience of other travelers when using the candidate airlines.

These different sources of information may differ in the quality, cost, and amount of information they provide about past interactions with the various candidate. In our example, asking colleagues about their airline experiences would allow the executive to make a more informed decision as compared to the case in which the executive relies solely on personal experiences. However, these actions may take time and effort.
The article establishes the task of obtaining the optimal allocation of information requests in the setting as an NP-hard problem. It provides a statistical model called Information-Acquisition Source Utility (IASU) for approximating the expected reward to the principal agent for a given set of information requests about each candidate from the different information providers. The model heuristically computes the likelihood that the principal agent changes its choice of candidate partner based on the acquired information.

We evaluate this paradigm empirically using two domains: one is a simulation do-main base on the Surrogate Venture game introduced by Hendrix and Grosz [2007b], and the other is a real-world domain in which an employer seeks a restaurant as a subcontractor from which she can purchase a quantity of meals for her employees. In these domains, the principal agent has a sequence of prior interactions with each potential candidate, and additional information about each candidate may be obtained by purchasing it from external sources, or by interacting directly with the candidate. In both domains, our approach was able to outperform alternative approaches from the literature for choosing to allocate information-gathering actions from different sources.
The article makes the following contributions. First, it establishes the task of opti-mal allocation of information gathering actions from different sources as an NP-hard problem. Second, it defines a formal model, IASU, for optimizing the allocation of information-gathering actions for information providers. Third, it provides a novel ap-proximation for computing the expected gain to the agent. Lastly, it demonstrates the efficacy of this model empirically for a variety of domains that include ecologically realistic data.

The article is structured as follows. In the following section, we formalize our research problem and several key concepts in our environment. Then, in Section 3, we present the IASU model. In Section 4, we provide the experimental settings, and in Section 5 we present an empirical evaluation of the IASU model. In Section 6, we discuss related work, and Section 7 concludes. We consider a chooser interested in choosing a partner c i from a set of k independent 1 with a candidate and obtains no reward for a failed interaction. 2 In many real-world domains, the evaluation of success is based on binary interaction. For example, when evaluating a delivery company, a result of a parcel delivery to a certain destination can be positive if the parcel had reached its destination, and negative otherwise. The success rate of websites in social networks is also based on a binary feedback from the members (for instance, like in Facebook).
 function of the reward the chooser receives for n  X  N successful interactions with a candidate. 3
Each candidate c i is assigned a competence value. This value is the probability of candidate c i having a successful interaction with any agent a .
 denoted p i , is the probability of a successful interaction between any agent and the candidate c i .

In reality, there are cases in which the competence of c i is dependent on the agent it interacts with. However, in this article, we focus on domains, where this statement is not necessarily needed, such as the competency of an airline which is measured as the percentage of punctual arrivals over a given time frame.

The competence values of the candidates are unknown to the chooser and may be taken from any kind of distribution. Here it is assumed that the competence values of all candidates are sampled from the same beta random distribution [Abramowitz and each candidate c i . However, our model is not restricted by this assumption and can be easily revised to any other distribution. Nevertheless, we assume a beta distribution, the real-world experiments of restaurants, we show that the competence of restaurants is actually beta distributed.
 A unit of information will be the result of the manager X  X  request from the messenger candidate to deliver a package within a specified time. If the messenger succeeds in delivering the package within the required time, then the interaction is considered a Candidate c 2 has the highest probability for a successful interaction with the manager. However, the manager does not know the competence values of each candidate, only that they where sampled from a beta random distribution Beta (  X ,  X  ) for specific values of  X  and  X  .

The chooser might have a small amount of baseline information units about each candidate. A unit of information about a candidate is the result of an interaction with that candidate. We represent each unit of information as a Bernoulli random variable, which obtains 1 if the result of the interaction is a success and 0 otherwise. For simplicity, we assume that the units of information are independent.

Definition 3( Baseline Information ). The variable T B , c baseline information units the chooser has about candidate c i ; S B , c of successful interactions with candidate c i among the T B , c tions.
 the chooser. The set S B ={ S B , c among the baseline information associated with each candidate.

Example 2.2 . In the previous example, baseline information units about the candi-date messenger was the result of a few missions. If, for instance, T B , c a messenger candidate, c 1 , has four mission requests and succeeded in delivering the message within the specified time in three of the four missions.

The chooser aims to select a partner with the highest competence value; however, the baseline information may be too small to decide on the best candidate. The more the same prior information, there is not enough information to prefer one candidate over the others. Even in the case that the prior information shows better success for one candidate, additional information may change this bias by presenting more successful interactions with another candidate. Therefore, the chooser may be inter-ested in obtaining additional information using different information sources, such as new interactions with possible candidates or interactions of other agents with possi-ble candidates. The sources of information are grouped according to their type. The set I ={ I 1 ,..., I m } represents a set of m types of information sources from which the chooser can obtain information. Note that each information type includes a set of information sources. The type defines (1) the average number of information units the source can send and (2) their cost. (1) All information sources of the same type have the same expected number of information units. We use I j to denote this number. (2) The cost function Cost : I  X  R specifies the cost of each information source in type I j . Nevertheless, we assume that the number of information units available about a candidate from information sources of the same type is distributed uniformly and that their expected values are equivalent.

The chooser may ask for additional information about a candidate using several information sources of one or more types.

Definition 4( Requests for Additional Information ). r I chooser X  X  requests for additional information about candidate c i from information sources that are in I j  X  I . Thus, r I
The expected number of information units that the chooser will receive for a request from I j about c i is r I requests for additional information units is limited. Thus, there is an integer M such that
For every I j ,1  X  j  X  m , the vector R i = ( r I of the Chooser X  X  requests for additional information units about candidate c i , from different types of information sources.
 interactions, (2) from reputation systems, (3) from other business manager (gossip agents). In particular, a business manager reports the results of all her interactions with the candidate. The number of information units of each business manager about a specific candidate may be different, since the number of interactions of each manager with a candidate may be different. In our example, consider a large company. The manager may interact many times with a messenger, while in a small company, they may interact only a few times. Continuing with Example 2.1, the chooser received the service of each of the messengers five times, that is, he has five units of baseline information about each candidate c 1 , c 2 , c 3 (i.e., T B , c to this baseline information, the number of successful interactions among T B , c additional information, the chooser will choose candidate c 3 . However, to improve its decision, the chooser may decide to request additional information units. Assume two where the number of reputation systems in I 1 is 3 and the number of gossip agents in I 2 is 7. Suppose further that the expected number of information units they can that the average number of information units obtained by reputation systems is much higher than by personal interaction. Suppose the chooser decides to approach three of the business managers asking about c 1 ,thatis, r I two of the reputation systems, that is, r I reputation systems and four of the business managers, that is, r I Then the expected number of additional information units the chooser will have is 3  X  4 = 12 about c and R 3 = (1 , 4) about c 3 .

The function E gain is used to denote the expected gain from the allocation ( R ward from making the decision using the additional information and the expected reward from making the decision using baseline information only.
 M , Re w ard , R  X ,  X  such that p of requests for additional information units M , a Reward function, and an allocation R ,..., R C . The function E gain calculates the chooser X  X  expected gain from this allocation ( R
We use the notation E gain ( R 1 ,..., R k ) as an abbreviation with reduced parameters when these parameters are clear from the context.
 The calculation of function E gain will be specified in Section 3.

Obtaining information is costly due to either the time used for searching the infor-mation or the payment of the information source for the knowledge. The total cost depends on the type of information source and the number of information requests. is COSTS ( I , R 1 ,..., R k ) = k i = 1 I
Example 2.4 . In Example 2.3, assume that the cost of one request for an additional unit of information from the information source in I 1 is Cost ( I 1 ) = 5 and from the additional information is COSTS ( I , R 1 , R 2 ) = 3 i = 1 2 j = 1 Cost ( I j )  X  r I 5  X  2 + 4  X  0 + 5  X  1 + 4  X  4 = 43.

The chooser X  X  goal is to determine the amount of information to request from each type of information source about each candidate that will maximize its overall expected utility. The expected utility takes into consideration the gain and the associated costs of obtaining the additional information.
 Definition 7( Expected Utility ). The utility E utility function obtains the following: upper bound M ,the Reward function, an allocation R 1 ,..., R k , and a cost function Cost . The E utility function calculates the total expected utility of the Chooser from this allocation of information, while taking the costs into consideration. when they are clear from the context.
 Based on these definitions, we can now formally define the allocation problem (AP) .
Definition 8( Allocation Problem ). Given a set of candidates C , a set of information sources I , the expected number of information units that can be obtained from each the baseline information B and S B , a positive integer upper bound to the number of requests for additional information M ,the Re w ard , E gain ,and Cost functions, the allocation problem (AP) aims to find the vectors ( R 1 ,..., R k ) that maximizes the E utility function.
 We can also present this problem as a decision problem as follows.
 Given the parameters specified in Definition 8 and a nonnegative integer T .
Answer  X  X es X  if there exist vectors ( R 1 ,..., R k ) R i = ( r I M such that E utility ( R 1 ,..., R k )  X  T .
 T HEOREM 2.5. The allocation problem is NP-hard.

P ROOF . We will present a reduction from the Knapsack problem [Garey and Johnson ( u C .

Create an instance of our allocation problem (AP) as follows.  X  X or each item i , create a candidate c i .  X  X or each variable u i , create a variable r I  X  X et M = C .  X  X e set T = V .  X  X he function Cost is defined as follows: The overall cost from the requests for additional information in this case is Thus, Suppose the chooser knows its expected gain from r I mation about c i from the set I j of information sources which is r I E gain ( R 1 ,..., R n ) = n i = 1 r I knapsack problem. ( r E utility ( R 1 ,..., R n ) = 0, thus n i = 1 r I v . As a result, since V = T , n i = 1 r I ( R (  X  ) Suppose there is a solution to the KNAPSACK instance, that is, a vector ( u
As a result we find that the allocation problem is NP-hard. 4 We present the information-acquisition source utility (IASU) model which provides a heuristic solution to the AP problem. The model is a statistical method that repre-sents the trade-off between exploration and exploitation when choosing a candidate for long-term collaboration. It specifies the allocation of the information among various information sources and the different candidates. Table I summarizes the notation we use in describing the model.

We consider environments in which the chooser has three possible sources of infor-mation I ={ P , G , S } . (1) Personal interactions. Interactions between the chooser and a candidate, that is, (2) Gossip agents. Agents that provide information about a candidate solely based on (3) Reputation system. A centralized repository of information about the personal inter-
The chooser X  X  goal is to solve the problem of finding the allocation R i = ( r
We will describe the model and construct the utility function in two stages. First, we present the simple case of only two candidates. Then we expand it to the general case of an arbitrary number of candidates. Suppose the chooser needs to select one of two candidates, c 1 and c 2 . To determine the optimal allocation of the request for information R i = ( r P , c chooser needs to estimate the value of E gain ( R 1 , R 2 ).

Without loss of generality, we assume that the chooser believes that c 1 is the best choice given the baseline information ( T B , c formation is worthwhile only if the chooser consequently changes its decision from the chooser must calculate the probability that this information will lead it to change change its decision: mation units T  X , c A detailed description of the function P change will be presented in the Section 3.3.1.
In the next proposition, we present the function E gain ( R 1 , R 2 ) considering all the possible values of p 1 and p 2 .
 formation units ( R 1 , R 2 ) about candidates c 1 and c 2 : where N is the number of interactions the Chooser intends to perform with the chosen candidate.
 does not obtain any additional information, it will choose c 1 . The expected reward is The chooser will change its decision from c 1 to c 2 with a probability of P change ( R 1 , R 2 ). In this case, the expected reward of choosing c 2 is The chooser will continue with c 1 with a probability of 1  X  P change ( R 1 , R 2 ). So, the expected reward of continuing with c 1 is
The expected gain from requesting additional units of information is the difference between the reward obtained with the additional information and the reward obtained without the additional information, which is
To calculate the expected gain, we integrate over all possible values of parameters p 1 and p 2 and multiply the equation by their posterior functions [Lee 2004], denoted
To calculate the posterior functions denoted Pr ( p i = x i ), we use the assumption that p i is a beta random variable such that p i that the posterior function for p i is parameters a , b .  X  and  X  may be calculated using the mean  X  and the variance  X  i of where the gamma function ( z ) =  X  0 e  X  t t z  X  1 dt .

Finally, using Definition 7, to calculate E utility we subtract Cost from E gain . The expected utility from the allocation R 1 , R 2 is where COSTS ( I , R 1 , R 2 ) = z  X  X  P , G , S } Cost ( z )  X  ( r z , c
The function E utility ( R 1 , R 2 ) estimates the expected utility of the agent from the chooser X  X  expected utility, E utility ( R 1 , R 2 ), and solves the allocation problem. denote the probability that after requesting R i additional units of information about each candidate c i , candidate c b will be superior to all other candidates and therefore will be chosen by the chooser.
 section.

Without loss of generality, assume candidate c 1 is currently the best candidate among these k candidates. The chooser X  X  gain after obtaining additional units of information consists of the following elements.  X  X andidate c 1 is currently the baseline-best candidate. If the chooser does not obtain any additional information, it will choose c 1 . The expected reward will be  X  X he chooser will change its decision from candidate c 1 to candidate c i with a proba-bility of best i . In this case, the expected reward is  X  X he Chooser will continue with candidate c 1 with a probability of best 1 = 1  X 
The expected gain from obtaining additional units of information is the difference between the reward of the process after obtaining the additional information, and the reward without obtaining the additional information, which is
To calculate the expected gain, we integrate over all possible values of the parameters p ,1  X  i  X  k multiplied by their posterior functions. Considering all possible values of p i , the following proposition is attained. The proof is immediate from the preceding explanation.
 tion about each candidate c i is
E gain ( R 1 ,..., R k )
The various costs involved in requesting additional units of information is considered in order to present the agent X  X  expected utility. Based on Definition 7, the expected utility of the chooser after collecting T  X , c given the direct costs Cost ( P ), Cost ( G ), and Cost ( S )is
As stated in the two-candidate case, since E utility ( R 1 ,..., R k ) estimates the ex-function can be found using the Nelder-Mead (Simplex) method [Nelder and Mead 1964]. This maxima estimates the expected optimal allocation of the request for infor-mation units that maximizes the chooser X  X  expected utility.
 how the chooser decides on the best candidate, given the information about the different candidates. Let T I the chooser obtains about candidate c i through information source I j  X  I ,and S I denotes the expected number of successes among the T I the total sum of the expected additional information units about candidate c i ,that candidate c i among T  X , c
Since each information unit is a Bernoulli random variable, the number of successful information units from each knowledge source (personal interaction S P , c and reputation system S R , c success, ( S P , c total number of successful information units, S  X , c S
After obtaining the additional information, the chooser should combine the baseline information and the additional information about the candidates and decide on the best candidate by comparing the success of the different candidates. The amount of infor-mation collected for each candidate may not be identical, and thus a naive comparison may be biased. In this article, we implement a heuristic to normalize the information. We calculate the expected number of successful interactions among t interactions for each candidate based on the known information and then choose the candidate with the highest value. Let t be the maximum number of information units obtained on any candidate and  X  the mean of the candidates competence values. 7 If the chooser has n &lt; t units of information for a specific candidate, it will compute the success rate of the missing t  X  n units of information based on the average success rate of  X  . There-fore, the normalized average of the successful units of information values for c i after obtaining T  X , c demonstrate later that the specific value of t does not influence the expected utility of the chooser.

Example 3.3 . Suppose the following are the information units and the success interactions: T B , c maximum information units is about c 2 and thus t = 6. Assume the beta distribution parameters are  X  = 2,  X  = 2, thus  X  = 0 . 5. To equalize the number of information units on both candidates, the chooser adds five units of information to T B , c the competence of candidate c 1 and 5 6 for candidate c 2 . Thus the chooser would prefer candidate c 2 over c 1 .
 The chooser will change its choice from candidate c 1 to candidate c 2 , after obtaining T This inequality is equivalent to
We use c
Intuitively, c we obtain that P change ( R 1 , R 2 ) = Pr ( S  X , c where 8 c S We then obtain In the Appendix, we provide a detailed example for the two-candidate case. questing R i additional units of information about each candidate, candidate c b will be superior to all other candidates and therefore will be chosen by the chooser. where c candidate c j to candidate c i , as a result of obtaining T  X , c units of information, given the value S  X , c holds when S  X , c
Thus, Pr ( c j &gt; c i | S  X , c
The candidates are independent, and as a result, the probability that given the value S  X , c
Thus, best b ( R 1 ,..., R k ) is the sum of the probabilities of S  X , c Pr ( c b &gt; c i | S  X , c According to Equation (5), In this section, we apply the IASU model to evaluate its effectiveness in choosing a long-term partner. We present applications for some environments, using both simu-lated and real-world domains. We specify the utility function for each domain and run experiments to check the utility obtained using our model. We describe two domains in which obtaining information is necessary, the Surrogate Venture Game (a simulated domain), and a real-world domain of restaurants. In both domains, the chooser must select a candidate for long-term commitment. The Venture Game domain is a simulation domain similar to the Surrogate Venture game introduced by Hendrix and Grosz [2007a]. In this game, an agent has the ability to enter business ventures with other agents by investing its resources in a venture. There are two types of agents: investment agents and candidates. The investment agent plays many games of Surrogate Venture. In each game, the investment agent chooses a candidate with whom to make an investment. A venture can end in either a success or a failure. The candidates working with the invested resources will successfully complete the venture and return a fixed reward, or fail and produce no reward. 4.1.1. Scoring. Each candidate is assigned a competence value at the beginning of the game. The success or failure of a venture depends on the competence of the candidate. The probability of a success of the venture is the same as the candidate X  X  competence . venture is a Boolean value determined by where x is sampled from a uniformly distributed random value in the range of [0 , 1). The scoring function can be compared to an employer utilizing the work of an employee. When the employer assigns an employee to a task, the employer must pay the employee (the investment), and the employee may or may not succeed at its assigned task. The employer receives a reward for an employee completing the task. If the employee fails, the payment is lost, and there is no reward. 4.1.2. The Utility Function. In this domain, the goal of the chooser (as an investment agent) is to choose the best partner for playing the Surrogate Venture game for N ventures. The chooser looks for the candidate that will maximize its overall reward in the game. To make the best decision it may have information about the candidates from personal interactions, gossip agents that have played with the candidates or a reputation system containing games results of the candidates. We hypothesized that the IASU model would increase the reward of the chooser, due to its ability to acquire precise amounts of additional information. In this game, any interaction with a can-didate c i produces a successful venture with a probability of p i .Let r be the reward successful interactions. An investment of the chooser in a single venture entails a cost which is Cost ( P ).

The general utility function was described in Section 3. Here we describe the specific attributes of this domain which affect the E utility function. (1) In the Surrogate Venture domain, the request for additional personal interactions (2) A reward is also obtained from the k i = 1 T P , c (3) Although in Definition 6 we defined the cost for each source of information, in As a result, the utility function is E utility ( R 1 ,..., R k ) = In this domain, an employer seeks for a restaurant as a subcontractor from which it can purchase a quantity of meals for its employees at a reduced cost. The employer is committed to selecting a high-quality restaurant to avoid having to pay for additional meals if employees choose to select a different restaurant. The employer may have information about the different candidate restaurants by eating at the restaurants (personal interaction). She can also obtain information about the restaurants by ask-ing customers of those candidate restaurants about their satisfaction (gossip agents). Finally, she can obtain information from online restaurant reviews (a reputation system).

Real-world data about restaurants was collected using customer surveys and online restaurant reviews. In our case, r R , c about candidate c i can be only 0 or 1, since there is only one reputation system in our environment. candidates restaurants: c 1 ... c k . Each restaurant c i has an unknown parameter p i , which is the restaurant X  X  satisfaction rate. The employer has to pay the chosen restau-rant, for N meals in advance. If the employees are not satisfied with the chosen restau-rant, they can eat at another restaurant at the expense of the employer. As a result, it duced cost of each meal from the subcontractor X  X  restaurant and exp to denote the cost of each meal for the unsatisfied employees. Since in this domain the employer should choose the best restaurant at a minimal cost, we detail the utility function which was described in general in Section 3 for this domain.

We assume that c 1 is the best choice according to the agent X  X  baseline knowledge.  X  X ince c 1 is currently the best candidate, if the agent does not obtain additional knowledge, c 1 will be chosen. In this case, the expected cost will be 1  X  p 1 is the unsatisfactory rate which estimates the percentage of employees that will choose another restaurant.  X  X he employer will change its arbitrary choice of restaurant c 1 to restaurant c i with will be  X  X he overall costs from obtaining additional units of information is the difference between the total costs received by using additional units of information (presented in Formula (8)), and choosing the candidate when using only the baseline information (presented in Formula (7)), that is, and for I j = P , G , R , the utility function is defined as The IASU model was empirically evaluated in the venture game domain and in the restaurants domain. The evaluation process consisted of two stages:
In the first stage, we used the IASU model to estimate the optimal expected alloca-tion of the information about the different candidates from the different information sources. In the second stage, we used the additional information and the baseline information to identify the best candidate among the possible candidates. Then we cal-culated the gain obtained from that decision while subtracting the costs of obtaining the information. For the simulated domain (the venture game domain) we used a sta-tistical formula to calculate the expected gain of the chooser from the allocation. The statistical formula is given in detail in Appendix A. For computing the expected gain in the restaurant domain, we ran simulations using the data obtained from the survey. sample means of different candidates are independent. We compare the results of IASU with two models. (1) A baseline strategy that takes the best prior candidate without using additional (2) The Fixed Number of Experiments model (FNE) [Talman et al. 2005] which decides In the venture game domain, we present four sets of experiments. (1) In the first experiment, we investigate the effect of T B , c (2) The second experiment set examines the influence of Cost ( G ), the direct cost of (3) In the third experiment, we examine the effect of r , that is, the reward obtained (4) The forth experiment investigates the influence of N , the number of total interac-
In each experiment, only one parameter was varied where the others were set to a fixed value as follows: Cost ( G ) = 0 . 5 , T B , c were set throughout all of the experiments: the cost of a personal interaction was set distribution were set to  X  = 0 . 5,  X  =  X  = 2.

In the preceding experiments, we consider two candidates which involve only per-sonal interactions and gossip agents. For simplification, we assume that each gossip agent has only one interaction with each candidate, that is, G = 1 (and thus T G , c number of information units from a gossip agent about c i is equal to r G , c of gossip requests about c i ).

The results for all four sets of experiments show the advantage of the IASU model over FNE and baseline models. Since the expected gain is calculated analytically for there is no need for a significance test.

Figures 1 and 2 present the results for the first experimental setting. The x-axis represents the number of baseline information units and the y-axis the expected gain. As the number of baseline information units ( T B , c ing the best candidate grows, and therefore the expected gain increases. In Figure 2, we evaluate the effect of the number of baseline information units (x-axis) on the number of requests from gossip agents (y-axis). As the amount of baseline information increases, the IASU model requests less resources for additional units of information from gossip agents, since statistically, the baseline units contain enough information to make a decision without using additional information. This also explains the decrease in the gap between the models as the amount of baseline information increases (see Figure 1).
The results for the second experiment are presented in Figure 5. The figures illustrate the effect of the cost of gossip (x-axis) on the expected gain of IASU, FNE, and the baseline model (y-axis). Aside from the baseline model which is not affected by the cost of the gossip request (since it does not use additional information), the reward increases as the cost of the gossip requested decreases. Note that the cost decreases more moderately for IASU than for FNE. This can be explained by the fact that in the FNE model, the number of additional information units is constant, whereas the IASU model is affected by the cost. Thus, the IASU model considers the weight of the cost in order to determine the most beneficial number of additional information units from gossip agents and personal interactions.

In addition, as can be seen in Figure 6, when using the IASU model, as the cost of requested gossip agents decreases, the amount of additional information from gossip increases.

Figures 7 and 8 present the results for the third experiment, which examines the effect of the reward value r (x-axis) on the expected gain of the chooser (y-axis). There is a direct relation between the two, as r increases, the overall gain also increases. In addition, as can be seen in Figure 8, as r increases, more resources are requested for information. The reason is that as r increases, the investment in additional information is more worthwhile, since the cost of obtaining the additional information remains constant.

A similar relation was found in the results of the fourth experiment. According to the results depicted in Figures 3 and 4, as the total number of total interactions (x-axis) increases, the expected gain (y-axis) increases linearly (Figure 3) as well as the number investment in additional information is worthwhile long term. 5.1.1. Evaluation of the Restaurants Domain. We evaluate the IASU model with a real-world restaurant domain in which an employer searches for a restaurant to acquire a quantity of meals for her employees among several candidate restaurants. We used a database derived from a survey conducted on employees at several high-tech companies from two different areas and online information related to those restaurants. The database includes 19 different restaurants and between 10 to 100 opinions of gossip agents about each of them. It is not possible to determine the distribution from 19 instances, and thus we assumed symmetric  X  -distribution, which is the most similar to normal distribution, which reflects the distribution of many real-world domains.
The subjects were asked to judge restaurants they had visited recently and to rate a specific restaurant contributed a single unit of information about that restaurant. In this domain, we refer to three information sources: personal interaction, gossip agents, and a reputation system. The knowledge obtain from each information source was produced as follows. (1) The information obtained from one of the subjects was used as personal experience (2) Any person who visited a specific restaurant was considered a reputable source of (3) The reputation system for the restaurants was taken from online websites from gossip, cost ( G ), at $2, and the cost of obtaining information from the reputation mean of symmetric  X  -distribution); sub , the cost of a meal according to the agreement with the subcontractor at $6; and exp , the cost of a meal in another restaurant at $10.
We investigated five pairs of restaurants and ran experiments for each pair, varying the value of N , (i.e., the number of meals the agent commits to pay for in advance), between 200, 500, and 1,000. In addition, we investigated three groups, each contain-ing three different restaurants. For the three-candidate case, we set N to 200. We experimented with 37 different choosers, while their baseline information was taken from their first personal interactions with the candidate restaurants. The additional information was taken randomly 30 times.

The experiments were conducted as follows. For each pair c 1 , c 2 in the two-candidate case, the IASU model calculated a 6-tuple ( r P , c case, the IASU output a 9-tuple ( r P , c this recommended allocation and the baseline information, we chose the candidate. Then, we calculated the gain obtained from our decision while subtracting the cost of the information acquired. Since we are dealing with a real-world domain, the calcu-lation of the gain was not done by an analytical formula but by estimating the value of p i , the competence of the chosen candidate, using all the information we had about the candidate. Then we calculated the expected cost by multiplying p i with Reward(N) and adding the direct costs of obtaining the information. We compared the results that were obtained with the results of the baseline model and the FNE model.

The IASU succeeded in reducing the agent X  X  expenses. The agent X  X  costs in the two candidate case are statistically significantly lower when using the IASU in contrast to the baseline model (t-test, PV &lt; 0.005 for all the values of N) and to the FNE model (t-test, PV = 0.01 for N = 200, PV = 0.05 for N = 500 and PV = 0.06 for N = 1000). Table II summarizes the average costs of the agent according to IASU, the baseline model, and the FNE model for the different values of N in the two-candidate case. In the three-candidate case, the IASU improves the costs incurred by the agent in all three experiments. Table III provides the costs incurred by the agent according to the baseline, the FNE, and the IASU models. The results are statistically significant in comparison to the two other models (t-test, PV = 0.004 compared to the baseline model, PV = 0.02 compared to the FNE model).

In conclusion, the results of the experiments in both domains show the advantage of the IASU model in maximizing the chooser X  X  utility. Our model takes into consideration the cost of obtaining information together with the risks of making decisions without enough information. As the cost of gossip increases, the number of gossip requests decreases, and the information obtained from other information sources. In addition, we see that as the reward obtained from a successful interaction with a candidate or the total number of personal interactions to which the chooser has committed with its chosen partner increases, the gain obtained from using the IASU model increases as well as the average number of gossip requests suggested by the IASU model. The basic idea of the IASU model was presented by Reches et al. [2008]. This article extends the former by formalizing mathematically the IASU model and proving its hardness as well as other theoretical parts of the model. In addition, it presents comprehensive experiments which prove the benefits of the model. The IASU model, presented in this article, differs from other previous work mainly by combining three considerations when making non-myopic allocation decision: (1) which candidate to col-lect information about, (2) which information source to request from, and (3) how much information to request about each of the alternatives from the different information sources.

We present several related works which focus on the challenge of determining the amount of information to obtain about the alternatives that maximizes the expected utility. Our work is distinguished from these works, since it considers a general prob-lem. We do not only allocate the amount of information units to acquire about each alternative, but we also decide which information sources to use and the necessary amount of the information units to obtain through each of the information source.
In the Max K-Armed Bandit problem, an agent allocates trials to slot machines, each yielding a payoff from a fixed (but unknown) distribution [Cicirello and Smith 2005; Streeter and Smith 2006]. The objective is to allocate trials among the k-arms to maximize the expected best single sample reward. In Cicirello and Smith [2005], the agent runs trials repeatedly, where in each trial, it tries to improve the reward it has achieved thus far. Selman et al. [1993] conduct a large number of experiments in order to identify the best heuristic. Contizer and Sandholm [1998] formalized several meta-reasoning problems in which agents collect information prior to making decisions. One of these problems involves an agent that optimizes which set of anytime algorithms to use for different problem instances.

Azoulay-Schwartz and Kraus [2002] construct a formal statistical model to find the optimal additional units of information to reveal the best alternative. Talman et al. [2005] generalize this model to suit domains that involve choosing between heuristics number of experiments model (FNE), which decides in advance on a fixed amount of additional units of information the agent should obtain and divides it between the candidates in proportion to their quality according to the agent X  X  baseline knowledge (initial units of information). In contrast to the FNE model, the EURIKA model [Reches et al. 2007] presents a statistical model for finding the best heuristic among several alternatives using information from personal interactions.

Rehak et al. [2009] present a mechanism designed for the selection of the optimal information provider in a multi-agent, heterogeneous, and unsupervised monitoring system. The mechanism is designed for intrusion/fraud detection systems, which are frequently deployed as part of online transaction processing. Their goal is to select the best classification provider from the set of classifier agents in an unsupervised, open, and dynamic system. The mechanism is able to determine the optimal num-ber of challenges that needs to be inserted into the system to determine the best agent.

Our model, on the other hand, decides not only on the amount of information units to obtain about each candidate, but also which source type to use in order to obtain this information. None of the other studies consider the use of several types of information sources, like a reputation system or gossip agents, as in our approach.

Dearden et al. [1998] determine the value of information when choosing actions (physical actions in the environment) based on the need to explore vs. exploit. They implement a learned-based approach by learning the optimal policy through many iterations. Our model, on the other hand, focuses on a single iteration decision-making, where the agent should decide on the information request in advance. In addition, in our model, there are different types of information sources, like the reputation and gossip agents. These differences in objectives lead to significant differences in the models and formalization.

In the work presented in Grass and Zilberstein [2000], we present a decision-theoretic approach that uses an explicit representation of the user X  X  decision model in order to plan and execute information-gathering actions. However, their problem is different than ours. Their system searches (under time and resources restrictions) for a subset of available information sources to obtain information from. Nevertheless, their agent has a large amount of knowledge in advance about those sources, which is expressed via probability functions that describe the quality of each alternative. Thus, their model does not have to obtain additional information about the alternatives in order to make the choice. This work is orthogonal to IASU model, since IASU deals with uncertain situations and as a result searches for the allocation of the information units about the alternatives in order to decide which maximizes the overall utility of the choosing agent.

There are several works [Huynh et al. 2004; Zacharia and Maes 2000; Pujol et al. 2002; Teacy et al. 2005] which use agents that collect reputation information from many individual agents, rather than a central reputation authority. These papers do not address the cost of continuously asking many agents for reputation information about multiple agents. The current research extends Hendrix and Grosz [2007b] by considering the cost and tackles this problem by charging a defined cost for reputation information.

A variety of ways of combining personal information and reputation information have been introduced. In Ramchurn et al. [2003], for example, a trust model based on confi-dence and reputation is presented. This model proposes to guide agents in evaluating past interactions and in establishing new contracts with one another. The model helps agents in determining who to interact with and how interactions unfold. Fullam and Barber [2007] learn how to appropriately mix previously acquired information from personal interaction and gossip sources. Their research examines how the accuracy of experience-and reputation-based trust models is influenced by parameters such as frequency of transactions with the trustee, trustworthiness of the trustee, and accuracy of provided reputations. They present a technique for dynamically learning the best source of trust information. Our research determines the appropriate amounts of such information, not how to combine them.

In the machine learning literature, there are works that address the challenge of cost-sensitive features selection, and in the sense that it considers the cost of the features by determining which features are the most important to request for the learning, this research problem is related to ours [Yang et al. 2006]. Also in this article, we consider the cost of the information units by trying to minimize the number of information units required for the decision. However, we consider an allocation problem where we should decide on the resources of the information as well as the amount.

Another class of problems related to ours is decision-making in regard to multi-ple observations that are informative but expensive. The challenge is to decide which variables to observe in order to maximize the expected utility. Krause and Guestrin study this problem in the domain of sensor placement. They consider a sensor net-work, where the utility of a sensor is determined by the certainty about the measured quantity. The task is to efficiently select the most informative subsets of observations. Specifically, they propose non-myopic optimal and approximation algorithms [Krause and Guestrin 2005a, 2005b; Krause et al. 2008]. Bilgic and Getoor [2007] address a similar problem for efficiently acquiring classification features in domains in which costs are associated with the acquisition. The objective is to minimize the sum of the information acquisition cost. They propose a data structure known as the  X  X alue of information lattice X  (VOILA). VOILA exploits dependencies between missing features, making it possible to share information value computations between different feature subsets.
 Similarly, another work [Tolpin and Shimoni 2010; Radovilsky and Shimoni 2010; Radovilsky and Shimony 2008] deals with selection under uncertainty and develops algorithms based on value of information (VOI) with a semi-myopic approximation scheme for problems with real-valued utilities. In particular, Tolpin and Shimoni [2010] interpret VOI as the expected difference between the expected utility of a meta-level action and the expected utility of the current base-level action. Radovilsky and Shimoni [2010, 2008] deal with optimizing the selection of a set of observations. Their aim is to bring to optimum an objective function, taking into consideration the cost of observation and the remaining uncertainty after executing the observation. Our work also tries to acquire information in order to increase a utility function while considering the cost of the information. However, our work differs from these in two aspects: (1) we consider different types of resources of information and thus our model decides both on the type as well as the amount of information, and (2) we consider multiple candidates and thus our model should decide for which of the candidates information should be acquired. This article presents the Information-Acquisition Source Utility model (IASU), which is a statistical model that aims to improve the decision-making of choosing the best candidate for a partner by incorporating external sources of information. The IASU model computes (1) the amount of additional information the chooser should obtain about each candidate and (2) the sources to request for the information. Our model takes into consideration the trade-off between the cost of obtaining information and the benefit of this information in improving the decision.

We evaluated IASU with a simulated data from the venture game domain and with the real-world restaurants domain. We compared IASU to another model that obtain fixed amount of information (FNE) and to a baseline strategy that takes the best prior candidate without using additional information. We examined the influence of different paraments of the IASU model and found that the IASU model is effective in maximizing the chooser X  X  utility.

In the future, we plan to generalize our model to deal with situations in which the obtained information is biased. Meaning, the competence of a candidate with respect to the chooser could be different than the competence with respect to other agents. Bias is important in domains where the success rate of an interaction is personal dependent. In such cases, we should take the bias when choosing an appropriate source of information. As we mentioned at the beginning of Section 5, the IASU model determines the nec-essary amount of additional information from each resource. The chooser uses this allocation to make the decision about the appropriate candidate. To evaluate the ex-pected gain from the experiments we run, we constructed a statistical formula which obtains an allocation from the IASU model and estimates the expected utility of the chooser from using that allocation. We will describe the formula for calculating the expected utility for the two candidates case.

Let binom ( S , T , p ) denotes the binomial distribution function of obtaining S suc-cesses of T experiments when the probability of success is p . Then, the probability of obtaining S B , c probability p i is
Let prior = ( T B , c dates c 1 , c 2 , respectively, and let PRIOR ( T B , c information among T B , c
We use PrPrior ( prior , p 1 , p 2 ) to denote the probability of receiving S B , c successes among the T B , c 1 , 2. Since the candidates are independents,
For every prior and for each candidate c i , the IASU model estimates the expected number of additional information units T P , c gain, while T  X , c to collect, and S  X , c additional information units.

Let add = ( T  X , c of all possible add for T I
Let pr Add ( add , p 1 , p 2 ) denote the probability of receiving S  X , c among the T  X , c model. Thus,
In the IASU model (as described in Formula (4) in Section 3.1), the chooser will change
We use choose ( prior , T  X , c chosen candidate. Thus, choose ( prior , T  X , c
Given r , the reward obtained from a successful performance, N , the total amount of personal interactions, and the costs of the information obtaining COSTS = Cost ( P )  X  N + Cost ( G )  X  ( r information S B , c
This formula contains three parts, the first part choose ( prior , T  X , c r  X  ( N  X  T  X , c interactions with the chosen candidate. The second part r  X  ( S P , c obtained from the success additional personal interactions, and the third part is the reduction of the costs.

To calculate the expected utility from the recommended allocation, we go over all the combinations of prior successes S B , c combination, we go over the possible combinations of S  X , c units of information that was recommended by IASU, and multiply their probability and the gain obtained by using them:
The expression expGain is expressed in terms of p 1 and p 2 . As a result, the equations for calculating the reward integrate over all possible values of p 1 and p 2 , and so the expected gain is computed based on the following formula: where betaPdf ( p i , X , X  ) is the beta probability density function.
 Assume two candidates c 1 and c 2 and two sources of information: a set of gossip agents gossip agent has only one previous interaction with each candidate, and as a result, r is equal to T G , c c through gossip agents). Giving the following data,  X  X he number of baseline information units are T B , c  X  X he number of successful interactions among the baseline information units are  X  X he costs of requesting additional information are Cost ( P ) = 1 , Cost ( G ) = 0 . 5.  X  X he parameters of the competence distribution functions are  X  = 2 , X  = 2.  X  X he size of G is | G |= 12, and as a result, r G , c  X  X or the upper bound of the number of personal interactions, we used the constraints  X  X he total number of interactions of the chooser with the chosen partner is N = 200. For these values, and
IASU then computes the allocation ( R 1 , R 2 ): r P , c That means that IASU recommends the chooser to interact with candidate c 1 17 times and to request information from 12 gossip agents about c 2 . Table IV de-scribes the expected utility E utility (( r P , c allocations:( R 1 , R 2 ), where R 1 = ( r P , c
