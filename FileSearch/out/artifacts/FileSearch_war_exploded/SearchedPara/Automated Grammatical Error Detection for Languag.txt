
Claudia Leacock 1 , Martin Chodorow 2 , Michael Gamon 3 , and Joel Tetreault ( CTB McGraw-Hill; 2 Hunter College and the Graduate Center, City University of New York; 3 Microsoft Research; 4 Yahoo! Labs) Morgan &amp; Claypool (Synthesis Lectures on Human Language Technologies, edited by Graeme Hirst, volume 25), 2014, xv+154pp; paperbound, ISBN 978-1-62705-013-5 Reviewed by Xiaofei Lu Pennsylvania State University
Research in automated grammatical error de tection and correction has gained consid-erable momentum in the past few years. Although much progress has been made in this area, numerous challenges and opportun ities exist for further research. For NLP researchers and students who are consider ing following or pursuing work in this area and for English language teaching practitio ners and researchers who are interested in utilizing systems resulting from research in this area, this book by Leacock, Chodorow,
Gamon, and Tetreault provides a timely, updated review of the state of the art in automatic learner error detection and correction. grammatical error detection and correction since the publication of the first edition of the volume. It then orients the reader to the book by detailing the changes from the first edition, providing a working definition of grammatical error, justifying the book X  X  focus on English language learners, clarifying the use of the term  X  X nglish language learner  X  to refer to learners of English as either a second or foreign language, putting forth a few claims about the relationship between NLP and Computer-Assisted Language Learning (CALL), specifying the intended audience of the book, and outlining the structure of the book.
 and correction. The chapter first discusses how varying degrees of tolerance of gram-matical errors are achieved in computational grammars used in grammar-checking and proofreading tools. It then offers a quick overview of data-driven and hybrid approaches to error detection.
 reported in previous empirical and corpus-based learner error studies, touches upon the influence of L1 on learner English, and then delves into a detailed discussion of three specific problem areas for English language learners: prepositions, articles, and collocations.
 introduces traditional evaluation measures (e.g., precision, recall, F-score, accuracy, and kappa) and the evaluation measures adopted in recent shared tasks on grammatical er-ror correction. It then discusses evaluation using a corpus of correct usage, questioning the value of this approach for indicating how well the system may perform on actual learner data. The advantages and challenges of evaluating system performance on learner writing are then examined. The authors advocate the use of multiple annotators and crowdsourcing as a means to improve the reliability of manual evaluation. The chapter concludes with a discussion of how stati stical significance testing of differences in system performance may be performed and provides a checklist for consistent re-porting of system results.
 and preposition errors. The chapter first looks at four types of information used by different systems, including lexical, syntac tic, semantic, and source information. It then describes three prevailing types of data used to train statistical models of grammatical error correction, namely, well-formed text, artificial errors, and error-annotated learner corpora. Next, it discusses classification methods and n -gram statistics-related methods for error detection and correction. Finally, t he chapter presents two end-to-end systems, Criterion and MSR ESL Assistant.
 erties of collocations, the chapter introd uces a range of metrics commonly used to measure the association strength between pairs of words and reviews a number of recent collocation error detection and correction systems.
 rule-based and statistical methods for dete cting and correcting verb-form, spelling, and punctuation errors and for identifying ungrammatical sentences. A small number of error detection systems for learners of lang uages other than English are also discussed. prehensive and targeted annotation schemes, and proposes three methods for im-proving the efficiency of large-scale annota tion: sampling, crowdsourcing, and mining online revision logs.
 grammatical error correction. These includ e three recent shared tasks on grammatical error correction, the use of machine translati on techniques for grammatical error correc-tion, real-time crowdsourcing of grammatical e rror correction, and longitudinal studies on the efficacy of automated error correction systems for improving the writing of users of such systems.
 the field, including annotation for evaluation, error detection for underrepresented languages, research on understudied error types, L1-specific error detection modules, collaboration with second language learning and education groups, and applications of grammatical error correction. The book also includes an Appendix that contains a list of textual learner corpora with at least some publicly accessible URLs or references. interested in learning about, following, or pursuing research in automated grammatical error detection and correction. Not only does it offer a comprehensive systematic review of research in this field, but it also highlights real challenges and opportunities for fruitful future research. Practitioners an d researchers in the language teaching and
CALL community can also use this book to obtain a realistic understanding of the state of the art of the field. They will also most certainly welcome the volume X  X  repeated emphasis on the importance for the NLP community to join efforts with the language teaching and CALL community to assess the eff ect of automated grammatical correction systems on improving the quality of language learners X  writing.
 better reflect the content of the book and the goals of the research field in question with the words  X  X nd correction X  added after  X  X etection. X  Second, in both Chapter 3 150 and Chapter 6, native speakers X  preference of powerful computer over strong computer is cited as an example of the arbitrariness of collocations. I do not intend to delve into the debate over whether collocations a re arbitrary or linguistically motivated, but I note that the preference in this particular case is not arbitrary but semantically motivated (consider the semantic difference between powerful man and strong man ). In fact, this preference merely reflects the fact that we are generally more concerned about the functional power of computers than their physical build, and it would be a false positive if a system marks strong computer as an error in a sentence that talks about a computer that is well-built and not easily breakable.

