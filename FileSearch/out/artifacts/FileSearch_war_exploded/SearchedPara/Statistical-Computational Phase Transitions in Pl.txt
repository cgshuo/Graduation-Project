 The planted models are standard models for generating a random graph from the underlying clustering structure. We consider a general setup called the planted clustering model. The model assumes that rK out of a total n nodes are grouped into r clusters of equal size K , while the other n  X  rK nodes (called isolated nodes ) are not in any clusters; each pair of nodes are connected by an edge independently with probability p if they are in the same cluster, and with probability q otherwise. The goal is to recover the underly-ing unknown clusters given the graph.
 We are particularly interested in the so-called high-dimenional setting (Rohe et al., 2011) where the number r of clusters may grow unbounded with the problem di-mensions n . This setting is important in many empirical networks (Leskovec et al., 2008), and more challenging to analyze than the r =  X (1) setting. The parameters p,q and K can scale with n as well.
 The formulation above covers many classical planted prob-lems including planted clique/r-clique (Alon et al., 1998; McSherry, 2001), planted coloring (Alon &amp; Kahale, 1997), planted densest subgraph (Arias-Castro &amp; Verzelen, 2013), planted partition and the stochastic blockmodel (Holland et al., 1983; Condon &amp; Karp, 2001). These models have a broad range of applications: They are used as generative models for approximating real world networks with natural cluster/community structures (Fortunato, 2010), and serve as benchmarks in the evaluation of clustering and commu-nity detection algorithms (Newman &amp; Girvan, 2004); they also provide a standard venue for studying the average-case behaviors of NP-hard graph theoretic problems including max-clique, max-cut, graph partitioning and coloring (Bol-lob  X  as &amp; Scott, 2004).
 The planted clustering problems pose themselves as both statistical and computational problems. Statistically, the parameters n,r,K,p,q govern the  X  X oisiness X  of the prob-lems: The problems become statistically harder with smaller values of p  X  q , K and larger r , as the observations are noisier and the cluster structures are more complicated and weakly expressed in the data. A statistically powerful algorithm is one that can recover the clusters for a large range of model parameters.
 Computationally, we are concerned with the running-time of different algorithms. An exhaustive search over all pos-sible clusterings might make for a statistically powerful al-gorithm but has high time-complexity. A simpler algorithm with polynomial or even linear running time is computa-tionally more desirable, but might succeed for a smaller region of the parameter space and thus have less statistical power.
 Here we take a joint statistical-computational view to planted clustering, and try to understand the tradeoffs be-tween these two aspects: How do algorithms with differ-ent computational time achieve different statistical perfor-mance? For what regions of the parameter space is recov-ery infeasible, either for any algorithm, or for an algorithm with specific computational time? Our results highlight the following: The parameter space can be partitioned into four regions, where each region cor-responds to successively easier instances of the problem than the previous region statistically, and recovery can be achieved by simpler algorithms with lower time complexi-ties. Significantly, there are large gaps between the statis-tical performance of computationally expensive algorithms and computationally efficient algorithms. We elaborate be-low. 1.1. The Four Regimes for Planted Clustering For concreteness, we first consider the setting with r  X  2 , p &gt; q and p/q =  X (1) . This covers the standard planted partition and planted r -clique models. The statistical hard-ness of the cluster recovery problem can be summarized to-Noise Ratio. Our main theorems identify the following four regimes of the problem defined by the values of this quantity.  X  The Impossible Regime: ( p  X  q ) 2  X  The Hard Regime: 1  X  The Easy Regime: n We illustrate these four regimes in Figure 1 assuming p = 2 q =  X ( n  X   X  ) and K =  X ( n  X  ) . Here cluster recovery is harder with larger  X  and smaller  X  . In this setting, the four regimes correspond to four disjoint and non-empty re-gions of the parameter space. Therefore, a computationally more complicated algorithm leads to a significant (order-wise) enhancement in statistical power. For example, when p = 2 q = n  X  1 / 4 , the cluster sizes K that can be handled by the simple, polynomial-time and computationally ex-pensive algorithms are  X ( n 0 . 75 ) ,  X ( n 0 . 625 ) and  X ( n respectively. The results in the impossible and hard regimes together es-tablish the minimax recovery boundary of the planted clus-tering problem, and show that MLE is statistically optimal. These two regimes are separated by an  X  X nformation bar-rier X : In the impossible regime the graph does not carry enough information about the clusters, so recovery is sta-tistically impossible.
 We conjecture that no polynomial-time algorithm succeeds in the hard regime. This will mean the convex relaxation of MLE achieves the computational limit . While rigor-ously proving the conjecture is difficult, there are many evidences supporting it. The hard regime contains the stan-dard Planted Clique problem with clique size K = o ( which has no polynomial-time algorithms so far despite decades of effort and is widely believed to be computation-ally intractable (Juels &amp; Peinado, 2000). Moreover, there is a  X  X pectral barrier X , determined by the spectral norm of an appropriately defined noise matrix, that prevents the con-vexified MLE and spectral algorithms, and possibly many other polynomial-time algorithms as well, from succeeding in the hard regime.
 The simple counting algorithm fails outside the simple regime due to a variance barrier associated with the node degrees and the numbers of common neighbors. Therefore, the simple algorithm is order-wise weaker statistically than the convexified MLE.
 General results: Our main theorems apply to general val-ues of p , q , K and r . The four regimes and the statistical-computational tradeoffs can be observed for a broad spec-trum of planted models. We discuss them in the main result section. 1.2. Extensions to Submatrix Localization Similar results hold for the related submatrix localization problem, a.k.a. bi-clustering (Kolar et al., 2011). Here Gaussian entries with unit variance, where there are r sub-matrices of size K L  X  K R with disjoint row and column supports, such that the entries inside the submatrices have mean  X  &gt; 0 , and the entries outside have mean zero. The goal is to locate these submatrices given A . We allow r to grow unbounded. This generalizes the single-submatrix model previously studied (Balakrishnan et al.; Arias-Castro et al., 2011).
 The quantity  X  2 measures the Signal-to-Noise Ratio (SNR). Most interesting is the low SNR setting with  X  2 = O (log n ) . Suppose n L = n R = n and K L = K R = K ; the problem has the following four regimes, with the same meaning as before:  X  The Impossible Regime:  X  2  X  The Hard Regime: 1  X  The Easy Regime: n  X  The Simple Regime: We illustrate these regimes in Figure 1 assuming  X   X ( n  X   X  ) and K =  X ( n  X  ) . Complete results will be pro-vided in a forthcoming full paper. 1.3. Discussions The results above highlight the interaction between the sta-tistical and computational considerations in planted cluster-ing and submatrix localization. Our study parallels a recent line of work that takes a joint statistical and computational view on learning problems (e.g., Berthet &amp; Rigollet (2013); Chandrasekaran &amp; Jordan (2013)). While we investigate two specific problems, we expect that the phenomena and principles in this paper are relevant more generally. Below we provide additional discussions on our innovation com-pared to previous work.
 The high dimensional setting: Several recent works in-vestigate the statistical-computational tradeoffs in subma-trix detection/localization (Kolar et al., 2011; Ma &amp; Wu, 2013), planted densest subgraph detection (Arias-Castro &amp; Verzelen, 2013) and sparse PCA (Berthet &amp; Rigollet, 2013; Krauthgamer et al., 2013). Even earlier is the extensive study of the Planted Clique problem. The majority of these previous works focus on the setting with a single clique, cluster, submatrix or principal component (i.e., r = 1 ). In this paper, we study the more general high-dimensional setting with a growing of clusters/submatrices, which is more difficult and poses significant challenge to the anal-ysis. Moeover, there are qualitative differences between these two settings, where are discussed in the next para-graph.
 The power of convex relaxations: In previous work on the r = 1 setting of submatrix localization (Kolar et al., 2011) and sparse PCA (Krauthgamer et al., 2013), it is shown that very simple algorithms based on thresholding/averaging have the order-wise similar statistical performance as more sophisticated convex optimization approaches. In contrast, for planted clustering and submatrix localization with mul-tiple clusters/submatrices, we show that convex relaxation approaches are order-wise statistically more powerful than simple counting/thresholding. Our analysis reveals that the power of convex relaxations lies in separating differ-ent clusters/submatrices , but not in identifying a single cluster/submatrix. This demonstrates a finer spectrum of computational-statistical tradeoffs.
 Detection vs. estimation: Several recent works on planted densest subgraph (Arias-Castro &amp; Verzelen, 2013), subma-trix detection (Ma &amp; Wu, 2013) and sparse PCA (Berthet &amp; Rigollet, 2013) have focused on the detection or hypoth-esis testing version of the problems, i.e., deciding whether or not there is a structured cluster/submatrix/principal com-ponent. In this paper, we study the estimation problem, i.e., to estimate the locations of the clusters/submatrices. If we compare Figure 1 in this paper with Figure 1 in (Ma &amp; Wu, 2013), we see that submatrix localization is strictly harder than its detection counterpart. We have a simi-lar observation for planted densest subgraph by comparing with (Arias-Castro &amp; Verzelen, 2013). Conditional compu-tational hardness results have been obtained for the detec-tion of submatrix and sparse principal component (Ma &amp; Wu, 2013; Berthet &amp; Rigollet, 2013), and it is interesting to see if similar results can be obtained for the estimation problems here. 1.4. Main Technical Contributions We consider the general planted clustering model, which allows for a growing number of clusters and covers many existing models including planted clique, planted partition and planted coloring.  X  We obtain minimax lower bounds for planted clus- X  We consider a polynomial-time algorithm based on  X  We analyze a simple algorithm based on counting There is a vast literature on graph clustering and their ex-tensions. Here we focus on planted clustering and its spe-cial cases, and primarily on theoretical work that studies exact cluster recovery. Detailed comparisons are provided after each of our main theorems.
 Planted Clique/Densest Subgraph: Planted Clique is the most widely studied planted model. It is known that a clique with size K =  X ( by counting degrees (Ku  X  cera, 1995); if K =  X ( ous polynomial-time algorithms work (Dekel et al., 2010); if K =  X (log n ) , an exhaustive search in super-polynomial time succeeds (Alon et al., 1998); if K = o (log n ) , re-covery is statistically impossible. It is an open problem to find polynomial-time algorithms for the K = o ( regime, which is widely believed to be intractable (Juels &amp; Peinado, 2000). The four regimes here can be considered the r = 1 special case of our results for general planted clustering. Extension to general values of p and q , namely planted densest subgraph, has also been considered (Arias-Castro &amp; Verzelen, 2013).
 Planted r -Cliques, Partition and Coloring: Subsequent works consider r  X  1 planted cliques, and the planted par-tition setting (Condon &amp; Karp, 2001) with general values of r , p and q . Existing work focus on the statistical perfor-mance of polynomial-time algorithms. The state-of-art re-sults are given in (McSherry, 2001; Ames &amp; Vavasis, 2014; Chen et al., 2012) for planted r -clique and in (Chen et al., 2012; Anandkumar et al., 2013) for planted partition. The p &lt; q setting is called the heterophily case, with planted coloring ( p = 0 ) as an important special case (Alon &amp; Ka-hale, 1997).
 Converse Results for Planted Problems: Complementary to the achievability results above, another line of work stud-ies converse results, i.e., when recovery is impossible, ei-ther by any algorithm, or by any algorithm in a specific class. The K =  X ( n ) case is considered by Chaudhuri et al. (2012) and Chen et al. (2012), who establish that p  X  q &amp; p p/n is necessary for any algorithm. For spectral clustering algorithms and convex optimization approaches, more stringent conditions are needed (Nadakuditi &amp; New-man, 2012; Vinayak et al., 2014). We generalize and im-prove upon these existing converse results.
 Sparse PCA: A similar gap between the statistical power of computationally expensive algorithms and known polynomial-time algorithms is observed for the sparse PCA problem. The computational hardness for detecting a sin-gle sparse principal component is proved in the seminal work (Berthet &amp; Rigollet, 2013) conditioned on the hard-ness of planted clique detection. We now define the planted clustering problem, which has five parameters n,r,K,p and q .
 Definition 1 (Planted Clustering) . Suppose n nodes are di-vided into two subsets V 1 and V 2 with | V 1 | = rK and | V 2 | = n  X  rK . The nodes in V 1 are partitioned into r clusters C  X  1 ,...,C  X  r (called true clusters), where | C K,  X  m . The nodes in V 2 do not belong to any clusters and are called isolated nodes. A random graph is generated as follows: for each pair of nodes and independently of all others, we connect them by an edge with probability p if they are in the same cluster, and with probability q other-wise.
 The goal is to exactly recover the true clusters { C  X  m } given the graph. We emphasize that K,r,p and q are allowed to scale with n . We assume the values of ( p,q,r,K ) are known to the algorithms.
 To facilitate subsequent discussion, we introduce a matrix representation of the problem. We represent the true clus-ters { C  X  m } r m =1 by a cluster matrix Y  X   X  X  0 , 1 } n Y ii = 1 if and only if i  X  V 1 , and Y nodes i and j are in the same cluster. Note that the rank of Y  X  equals r . The adjacency matrix of the graph is denoted as A , with the convention that A ii = 0 for all i . Under the planted clustering model, we have P ( A ij = 1) = p if Y ij = 1 and P ( A ij = 1) = q if Y problem reduces to recovering Y  X  given A .
 The above formulation covers many classical models.  X  Planted r -Disjoint-Clique : Here p = 1 and 0 &lt; q &lt;  X  Planted Densest Subgraph : Here 0 &lt; q &lt; p &lt; 1  X  Planted Partition/stochastic blockmodel : Here n =  X  Planted r -Coloring : Here n = rK and 0 = p &lt; q &lt; In the next four subsections, we present our main theorems for the four regimes of the planted clustering problem. For clarity of the presentation, we shall focus on the p &gt; q setting in the sequel, as the theorems and proofs for the p &lt; q setting are very much similar. We use c 1 to denote universal constants independent of ( n,r,K,p,q ) . With high probability (w.h.p.) means with probability at 3.1. Impossible Regime: Minimax Lower Bounds We first characterize the statistical limit of any algorithm regardless of its computational complexity. Let Y be the set of admissible cluster matrices, given by
Y = { Y | there exist clusters { C m } r m =1 with | C m | = K , We use  X  Y  X   X  Y ( A ) to denote an estimator which outputs an element of Y as an estimate of the true Y  X  . We have the following lower bound on the minimax error probability of recovering Y  X  .
 Theorem 1. Suppose that 8  X  K  X  n/ 2 , n  X  128 and p &gt; q . If any one of the following conditions holds: 12 K ( p  X  q ) 2  X  min { p (1  X  p ) ,q (1  X  q ) } log( n  X  K ) , (2) The theorem shows that it is fundamentally impossible to recover the clusters with reasonable probability in the regime where (1), (2) or (3) holds, which is thus called the impossible regime . If p/q =  X (1) , then the condition (2) is the least restrictive when p is bounded away from 1 and the condition (1) is the least restrictive otherwise. They im-ply the following impossible regimes for various standard models:  X  Planted r -clique: K (1  X  q ) . log( n/K ) .  X  Planted r -coloring: Kq . log r .  X  Planted partition/densest subgraph with p bounded If q = o ( p ) , then Condition (3) is the least restrictive. Theorem 1 is proved using an information-theoretic argu-ment. The ratio of the RHS and LHS of (1) corresponds to the ratio of the entropy of Y  X  randomly chosen from Y and the mutual information between A and Y  X  . Therefore, the impossible regime is due to an information/statistical bar-rier : the graph A does not carry enough information about the clusters Y  X  .
 Comparison to previous work: For r = 1 and q is bounded away from 1 , our results recover the well-known K =  X (log n ) threshold for planted clique; we show that the same is true for r  X   X  . For planted partition with p &gt; q and p/q =  X (1) , previous work (Chaudhuri et al., 2012; Chen et al., 2012) considers the r = O (1) and K =  X ( n ) case; our results are tighter and apply to the general setting. 3.2. Hard Regime: Optimal Algorithms We show that the statistical limit in Theorem 1 is achieved by the Maximum Likelihood Estimator given in Algo-rithm 1.
 Algorithm 1 Maximum Likelihood Estimator ( p &gt; q ) Enumerating over the set Y is computationally expensive in general since |Y| =  X ( e rK ) . The following theorem provides success condition for the MLE.
 Theorem 2. Suppose K  X  8 and p &gt; q . With high proba-bility, the optimal solution  X  Y to (4) is unique and equals to Y  X  provided that for some constant c 1 &gt; 0 We refer to the regime for which the condition (5) holds but (9) fails as the hard regime . When p/q =  X (1) , Con-lowing success conditions for the MLE:  X  Planted r -clique: K (1  X  q ) &amp; log n .  X  Planted r -coloring: Kq &amp; log n .  X  Planted partition/densest subgraph: K ( p  X  q ) 2 &amp; If q = o ( p ) , Condition (5) reduces to Kp &amp; log n . By comparing with Theorem 1, we see that the MLE achieves the statistical limit up to at most a log factor and is thus statistically optimal. In particular, if p/q =  X (1) and p,q are bounded away from 1 , the conditions (2) and (5) match each other up to a constant, thus establishing the minimax Comparison to previous work: Theorem 2 provides the first achievability result that is information-theoretic opti-mal when the number of clusters grows. It shows that for a fixed cluster size K , even if r grows, possibly at a nearly linear rate r = O ( n/ log n ) , MLE still succeeds under the same condition (5). When r = p = 1 , q = 1 / 2 , our result recovers the K log n boundary for planted clique (Alon et al., 1998). 3.3. Easy Regime: Polynomial-Time Methods We present a polynomial-time algorithm that succeeds in the easy regime described in the introduction. Our algo-rithm is based on taking the convex relaxation of the MLE in Algorithm 1. Note that the objective function in the MLE (4) is linear, so complications come from the non-convex combinatorial constraint Y  X  Y . To obtain a com-putationally tractable algorithm, we replace this constraint with a convex trace norm constraint and a set of linear con-straints. The resulting convexified MLE is given in Algo-rithm 2. Here the trace norm k Y k  X  (also known as the nu-clear norm) is the sum of the singular values of Y . Note that the true Y  X  is a feasible solution as k Y  X  k  X  = trace ( Y rK.
 Algorithm 2 Convexified Max Likelihood Estimator  X  Y = arg max The optimization problem in Algorithm 2 can be cast as a semidefinite program (SDP) and solved in polynomial time. Fast specialized algorithms have also been devel-oped (Jalali &amp; Srebro, 2012; Chen et al., 2012). The following theorem provides a sufficient condition for the success of the convexified MLE.
 Theorem 3 (Easy) . Suppose p &gt; q . With high probability, the optimal solution to the problem (6)  X  (8) is unique and equals to Y  X  provided ( p  X  q ) 2 K 2  X  c 3 ( p (1  X  q ) K log n + q (1  X  q ) n ) . (9) Remark 1. Theorem 3 immediately implies guarantees for other tighter convex relaxations. Define the sets B := { Y | Eq. (8) holds } and S 1 := { Y |k Y k  X   X  n 1 } , S 2 := S 1  X  X  Y |k Y k max  X  1 } , S 3 := { Y | Y 0; Trace ( Y ) = n 1 } , norm of Y and k X k  X  , 2 is the maximum of the ` 2 norms of the rows. The constraint (7) is equivalent to Y  X  S 1  X  X  . Observe that (Jalali &amp; Srebro, 2012) Therefore, if we replace the constraint (7) with Y  X  S 2 or Y  X  S 3 , we obtain tighter convex relaxations of the MLE. Theorem 3 immediately implies that these relaxations also recover Y  X  w.h.p. under (9) .
 When r = 1 , the easy regime is where the condition (9) holds and (12) fails. When r &gt; 1 , the easy regime is where (9) holds and (13) fails. When p/q =  X (1) , the condi-following success conditions for the convexified MLE un-der standard models:  X  Planted r -clique: K (1  X  q ) &amp; log n + n  X  Planted r -coloring: Kq &amp; log n + n  X  Planted partition and densest subgraph with p In all these cases, the smallest possible cluster size is K =  X ( is r =  X ( This generalizes the tractability threshold K =  X ( of Planted Clique to the growing r setting. In the high SNR case with q = o ( p ) , the condition (9) reduces to Kp &amp; max { log n, go beyond the K =  X ( cluster size is K =  X (max { log n, p =  X (1) .
 Converse for trace norm relaxation We have a converse to the achievability results in Theorem 3. The following theorem characterizes when the trace norm relaxation (6) X  (8) fails.
 Theorem 4 (Easy, Converse) . Suppose p &gt; q . For any constant 1 &gt; 0 &gt; 0 , there exist positive constants c for which the following holds. Suppose c 1 log n  X  K  X  n/ 2 , q  X  c 1 log( n ) /n and p  X  1  X  0 . If then w.h.p. Y  X  is not optimal to the program (6)  X  (8) . Theorems 3 and 4 together establish that under the assump-tions of both theorems and ignoring logarithmic factors, the sufficient and necessary condition for the success of the convexified MLE is Comparing this with the condition (5) for the MLE, we see that the convexified MLE is statistically sub-optimal due to the extra second term in (10). This term thus represents the statistical price of computational tractability. It has an in-teresting interpretation. Let e A := A  X  q 11 &gt; + qI be the centered adjacency matrix. The matrix E := ( Y  X  11 &gt; )  X  ( e
A  X  E e A ) , i.e., the deviation e A  X  E e A projected onto the cross-cluster node pairs, can be viewed as the  X  X ross-cluster noise matrix X  2 . Note that the squared largest singular val-ues of the matrix E e A = ( p  X  q ) Y  X  is K 2 ( p  X  q ) the squared largest singular value of E is  X ( qn ) w.h.p. by standard results. Therefore, the extra second term in (10) is the  X  X pectral Noise-to-Signal Ratio X . In fact, our proofs for Theorems 3 and 4 build on this intuition.
 We note that when K =  X ( n ) , the conditions (5) and (9) coincide up to constant factors, and the performance of MLE and its relaxation matches. In this case the hard regime disappears.
 Comparison to previous work: We refer to (Chen et al., 2012) for a survey of the statistical performance of the state-of-art polynomial-time algorithms for various planted models. Theorem 3 order-wise matches and in many cases improves upon these existing results. For planted partition, the previous best result is ( p  X  q ) 2 &amp; p ( K log 4 in (Chen et al., 2012). Our results remove a log 3 n factor, and is also sharper for small q . For planted r -clique, exist-ing results require 1  X  q to be  X (( rn + rK log n ) /K 2 ) (Mc-Sherry, 2001),  X (  X (( n + K log 4 ) /K 2 ) (Chen et al., 2012). We improve them to  X (( n + K log n ) /K 2 ) . Our converse result in Theorem 4 improves on the recent work by Vinayak et al. (2014). There they focus on the special case p &gt; 1 / 2 &gt; q , and show that a convex relaxation that is equivalent to our formulation (6) X (8) without the equality constraint in (8) fails when K 2 ( p  X  1 / 2) 2 . qn . Our result is stronger, as it applies to a tighter convex relaxation and a larger region of the parameter space.
 L We conjecture that no polynomial-time algorithm has order-wised better statistical performance than the convex-ified MLE and succeeds beyond Condition (9).
 Conjecture 1. For any constant &gt; 0 , there is no algo-rithm with running time polynomial in n that, for all n and with probability at least 1 / 2 , outputs the true Y planted clustering problem with If the conjecture is true, then the boundary of the easy regime will characterize the computational limit of planted clustering. This will mean there exists a significant gap between the statistical performance of intractable and polynomial-time algorithms.
 A rigorous proof of Conjecture 1 seems difficult with current techniques. There are however several evidences which support the conjecture:  X  The special case with p = 1 and q = 1  X  As mentioned earlier, if (11) holds, then the spectrum  X  In the sparse graph case with p,q = O (1 /n ) , Decelle 3.4. Simple Regime: A Counting Algorithm We consider a simple procedure in Algorithm 3 based on counting node degrees and common neighbors.
 Algorithm 3 A Simple Counting Algorithm 1. (Identify isolated nodes) For each node i , declare it as 2. (Identify clusters when r &gt; 1 ) Assign each pair of The two steps in Algorithm 3 are considered in (Ku  X  cera, 1995; Dyer &amp; Frieze, 1989) for the special cases of finding a single planted clique or planted bisection. Let E be the set of edges. The first step runs in time O ( | E | ) , and the second step runs in O ( n | E | ) since each node only needs to look up its local neighborhood up to distance two to compute S ij The following theorem provides sufficient conditions for the simple counting algorithm to succeed.
 Theorem 5 (Simple) . Suppose p &gt; q . W.h.p. Algorithm 3 correctly identifies the isolated nodes if
K 2 ( p  X  q ) 2  X  c 3 [ Kp (1  X  q ) + nq (1  X  q )] log n, (12) and finds the clusters if further K 2 ( p  X  q ) 4  X  c 4 [ Kp 2 (1  X  q 2 ) + nq 2 (1  X  q 2 )] log n. (13) When there is a single clusters r = 1 , the simple regime is where the condition (12) holds; if r &gt; 1 , the simple regime is where both conditions (12) and (13) holds. When p/q =  X (1) , these conditions simplify to r = 1 : This implies the following success conditions for the count-ing algorithm under various standard models:  X  Planted clique and densest subgraph: K 2 ( p  X  q ) 2 &amp;  X  Planted r -clique ( r &gt; 1 ): K (1  X  q ) &amp;  X  Planted r -coloring ( r &gt; 1 ): Kq &amp;  X  Planted partition with p bounded away from 1 : K ( p  X  Comparing these conditions with (9) for the convexified MLE, we see that the counting algorithm requires an ad-ditional log n factor on the R.H.S when r = 1 , and an ad-ditional K log n/ The last discussion shows that in the r = 1 case where the task is to separate isolated and non-isolated nodes, the counting algorithm has similar (up to a log factor) statistical performance as the more sophisticated convexified MLE, which is the best known polynomial-time algorithm. How-ever, when r &gt; 1 , the convexified MLE is much more pow-erful. In particular, its power lies in separating different clusters, as can be seen by comparing the conditions (9) and (13).
 Converse for the counting algorithm We have a partial converse to Theorem 5. The following theorem shows that the conditions (12) and (13) are also nearly necessary for the counting algorithm to succeed.
 Theorem 6 (Simple, Converse) . Suppose p &gt; q . For any constant c 0 &lt; 1 , there exist constants c 1 , c 2 for which the following holds. Suppose K  X  n/ 2 , p  X  1  X  c 0 and Kp 2 + nq 2  X  c 1 log n . Algorithm 3 fails to identify all the isolated nodes with probability at least 1 / 4 if
K 2 ( p  X  q ) 2 &lt; c 2 [( Kp + nq ) log( rK ) + nq log( n  X  rK )] , and fails to correctly recover all the clusters with probabil-ity at least 1 / 4 if Remark 2. Theorem 6 requires a technical condition Kp 2 + nq 2  X  c 1 log n , which is not too restrictive. If Kp 2 + nq 2 = o (log n ) , then two nodes from the same cluster will have no common neighbor with probability (1  X  p 2 ) K (1  X  q 2 ) n  X  K  X  exp[  X  c ( p 2 K + q 2 ( n  X  K ))] = exp[  X  o (log n )] , so Algorithm 3 cannot succeed w.h.p. Apart from the technical condition discussed above and the assumption p &lt; 1  X  c 0 , Theorems 5 and 6 show that the conditions (12) and (13) are sufficient and necessary for the counting algorithm. In particular, the counting algorithm is indeed strictly weaker in separating different clusters as compared to the convexified MLE. Our proof reveals that the R.H.S. of (12) and (13) are associated with the vari-ance of the node degrees and common neighbors, respec-tively. If (12) does not hold, the difference between the ex-pected degrees of isolated and non-isolated nodes will be outweighed by their deviations; a similar argument holds for the number of common neighbors. Therefore, there is an variance barrier that prevents the counting algorithm from succeeding outside the simple regime.
 Acknowledgements: Research supported in part by NSF ECCS 10-28464.
 Alon, N. and Kahale, N. A spectral technique for coloring random 3-colorable graphs. SIAM Journal on Comput-ing , 26(6):1733 X 1748, 1997.
 Alon, N., Krivelevich, M., and Sudakov, B. Finding a large hidden clique in a random graph. Random Structures and Algorithms , 13(3-4):457 X 466, 1998.
 Ames, B. P.W. and Vavasis, S. A. Convex optimization for the planted k-disjoint-clique problem. Mathematical Programming , 143(1-2), 2014.
 Anandkumar, A., Ge, R., Hsu, D., and Kakade, S. A tensor spectral approach to learning mixed membership com-munity models. arXiv:1302.2684 , 2013.
 Arias-Castro, E. and Verzelen, N. Community detection in random networks. arXiv:1302.7099 , 2013.
 Arias-Castro, E., Cand ` es, E. J, and Durand, A. Detection of an anomalous cluster in a network. The Annals of Statistics , 39(1):278 X 304, 2011.
 Balakrishnan, S., Kolar, M., Rinaldo, A., Singh, A., and
Wasserman, L. Statistical and computational tradeoffs in biclustering. In NIPS 2011 Workshop on Computational Trade-offs in Statistical Learning .
 Berthet, Q. and Rigollet, P. Complexity theoretic lower bounds for sparse principal component detection. Jour-nal of Machine Learning Research: Workshop and Con-ference Proceedings , 30:1 X 21, 2013.
 Bollob  X  as, B. and Scott, AD. Max cut for random graphs with a planted partition. Combinatorics, Probability and Computing , 13(4-5):451 X 474, 2004.
 Chandrasekaran, V. and Jordan, M. I. Computational and statistical tradeoffs via convex relaxation. PNAS , 110 (13):E1181 X  X 1190, 2013.
 Chaudhuri, K., Graham, F. C., and Tsiatas, A. Spectral clustering of graphs with general degrees in the extended planted partition model. JMLR , 23, 2012.
 Chen, Y., Sanghavi, S., and Xu, H. Clustering sparse graphs. arXiv:1210.3335 , 2012.
 Condon, A. and Karp, R. M. Algorithms for graph parti-tioning on the planted partition model. Random Struct. Algorithms , 18(2), 2001.
 Decelle, A., Krzakala, F., Moore, C., and Zdeborova,
L. Asymptotic analysis of the stochastic block model for modular networks and its algorithmic applications. Physics Review E , 84:066106, 2011.
 Dekel, Y., Gurel-Gurevich, O., and Peres, Y. Find-ing hidden cliques in linear time with high probability. arxiv:1010.2997 , 2010.
 Dyer, M.E and Frieze, A.M. The solution of some random
NP-hard problems in polynomial expected time. Journal of Algorithms , 10(4):451  X  489, 1989.
 Fortunato, S. Community detection in graphs. arXiv:0906.0612 , 2010.
 Holland, P. W., Laskey, K. B., and Leinhardt, S. Stochastic blockmodels: First steps. Social Networks , 5(2):109 X  137, 1983.
 Jalali, A. and Srebro, N. Clustering using max-norm con-strained optimization. ICML , 2012.
 Juels, A. and Peinado, M. Hiding cliques for cryptographic security. Designs, Codes &amp; Crypto. , 2000.
 Kolar, M., Balakrishnan, S., Rinaldo, A., and Singh, A.
Minimax localization of structural information in large noisy matrices. In NIPS , 2011.
 Krauthgamer, R., Nadler, B., and Vilenchik, D. Do semidefinite relaxations really solve sparse PCA? arXiv:1306.3690 , 2013.
 Ku  X  cera, L. Expected complexity of graph partitioning problems. Discrete Appl. Math. , 57(2-3), 1995.
 Leskovec, J., Lang, K., Dasgupta, A., and Mahoney, M.
Statistical properties of community structure in large so-cial and information networks. In WWW , 2008.
 Ma, Z. and Wu, Y. Computational barriers in minimax sub-matrix detection. arXiv:1309.5914 , 2013.
 McSherry, F. Spectral partitioning of random graphs. In FOCS , pp. 529  X  537, 2001.
 Nadakuditi, R. R. and Newman, M.E.J. Graph spectra and the detectability of community structure in networks. Physical Review Letters , 108(18), 2012.
 Newman, M. E. J. and Girvan, M. Finding and evaluat-ing community structure in networks. Phys. Rev. E , 69: 026113, Feb 2004.
 Rohe, K., Chatterjee, S., and Yu, B. Spectral clustering and the high-dimensional stochastic blockmodel. The Annals of Statistics , 39(4), 2011.
 Vinayak, R. K., Oymak, S., and Hassibi, B. Sharp perfor-mance bounds for graph clustering via convex optimiza-
