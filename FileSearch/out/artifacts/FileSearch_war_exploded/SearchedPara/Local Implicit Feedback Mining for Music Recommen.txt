 Digital music has experienced a quite fascinating transfor-mation during the past decades. Thousands of people share or distribute their music collections on the Internet, result-ing in an explosive increase of information and more user dependence on automatic recommender systems. Though there are many techniques such as collaborative filtering, most approaches focus mainly on users X  global behaviors, neglecting local actions and the specific properties of mu-sic. In this paper, we propose a simple and effective local implicit feedback model mining users X  local preferences to get better recommendation performance in both rating and ranking prediction. Moreover, we design an efficient train-ing algorithm to speed up the updating procedure, and give a method to find the most appropriate time granularity to assist the performance. We conduct various experiments to evaluate the performance of this model, which show that it outperforms baseline model significantly. Integration with existing temporal models achieves a great improvement com-pared to the reported best single model for Yahoo! Music. H.3.3 [ Information Systems ]: Information Search and Re-trieval X  Information Filtering Collaborative Filtering, Recommender System, Local Im-plicit Feedback, Efficient Training
During the past decades, music has experienced a quite fascinating transformation since expensive records and CDs are replaced by enjoying a lot of music free online. People could ask music store staff or just select from existing records to get what they wanted in the past, while nowadays they can surf on the Internet for music service, and turn to an automatic recommender system for a recommendation as the amount of music available expands explosively.
There are many approaches to music recommendation, such as Collaborative Filtering (CF)[12], which has been widely used and proved to be quite effective in handling users X  preferences. Latent factor models, like matrix factor-ization (MF), and neighborhood models are two canonical approaches in CF to capture users X  interests. MF, or sin-gular value decomposition, maps users and items into the same low-dimension space, maintaining vectors of items and users. MF predicts a user X  X  rating on an item through the inner product of two vectors. On the other hand, neigh-borhood models, put more emphasis on detecting the sim-ilarities and correlations between users or items, and make prediction based on observed information. Besides, there are other techniques for recommendation, such as graph-based models [26], and content-based approaches[8].

Though effective in maintaining users X  overall preferences, many CF methods concentrate more on users X  global inter-ests. Such information might be enough to capture users X  preferences in some cases, such as recommending academic papers or movies. However, music recommendation differs from those in several ways 1 . Firstly, music has a large item space and a low consumption time, where each song receives attention for a relatively short time. Secondly, a person can listen to songs in many situations, such as working, jog-ging or resting. However, he or she cannot read papers or watch movies all the time. Finally, people often consume music continually. That is, a user X  X  behaviors in the next time interval are likely to be consistent with his/her recent behaviors.

Many traditional CF approaches focus on users X  global in-terests that stay stable for a long time. They do not take the local consistent behaviors into full consideration[18]. That is, things which have happened just now or very recently are likely to influence users X  decisions in the near future. We call these local preferences . For example, John might suddenly change his favorite Jazz to light music just because he was going to sleep. Or, a person might be blue and turn to some brooding tracks due to a week of rainy days. Such local information is often neglected and not captured. However, better performance may be achieved if local behaviors are considered. In this paper, we propose a simple and effective local implicit feedback model. We also design an efficien-t training algorithm to speed up the training. Our main contributions are as follows: http://recsys.acm.org/2011/tutorials.shtml, by Oscar Cel-ma and Paul Lamere
Experiments conducted on three different datasets using two evaluation metrics show that our local model outper-forms baselines in capturing users X  local preferences in both rating and ranking prediction. We also show that our local model is to some extent complementary to other time-aware models. We combine our model with the best single model reported on Yahoo! Music, which achieves an RMSE de-crease from 22 . 346 to 21 . 879.
 The remainder of this paper is organized as follows. In Section 2, we present our local implicit feedback model. Our efficient training algorithm is described in Section 3, and experiments are discussed in Section 4. Related work is in Section 5. We conclude our work and point out some future directions in Section 6.
In this section, we present our local implicit feedback mod-el that extracts users X  local preferences, and also present the ranking approach we used. To demonstrate that this model is complementary to time-aware models, we integrate our model with some temporal approaches.
Local user preferences, as stated above, are mainly used to capture user X  X  varying behaviors in a very local time pe-riod. That is, his/her actions during current time interval might have effects on his/her decisions in the next few min-utes. His/her actions in the next time period tend to be consistent with his/her recent behaviors, but might be dif-ferent from his/her global behaviors. For example, if Alice is a music lover keen on Hip Hop and Rock, but something unfortunate has happened so she is depressed at present, then it is likely for her to turn to some sad songs. It is possible that people might change their accustomed habits temporarily and return to them after a short time. Habits can also change quite gradually, and those changes might persist for a long time. Transient events affect users X  pref-erences during a short time period, like a week, a day, an hour or even a minute. On one hand, a user X  X  interests might be affected by his/her established preferences; on the other hand, they could be also influenced by a very local event, like a new record release or a song that rises to fame overnight. Moreover, such very local and transient incidents, tend to be more determined by the characteristic of music that people X  X  consumption is always continuous. However, such contextual information might be unavailable to recom-Representations Descriptions mender systems. To solve this problem, we propose to use users X  local behaviors to model their local preferences.
User local preferences are characterized by using users X  implicit feedback in a short time period. The implicit feed-back is represented by users X  behaviors in history, i.e items he/she rated. Through rated/unrated binary information, the implicit feedback model is provided with a non-explicit ability to capture users X  potential and global interests. This model was originally proposed by Koren[12], whose formu-lation was: r Table 1 gives some commonly used notation for our work. Here, given two items i and j ,  X  j is an indication of user u  X  X  preference, and will be high if j is predictive on item Based on MF and implicit feedback, this model focuses more on users X  global behaviors. Since implicit feedback works well in characterizing users X  global and potential interests, we implement our local preferences idea based on it. Our local implicit feedback model is formulated as this: r Here, user X  local preferences are characterized by using their very localized rating history represented by N ( u, t ), which we call Local Implicit Feedback . By using users X  implicit information during a localized time interval, we assume that user behaviors during that period correlate to their current decisions. The Time Granularity is defined as the length of the local time interval, which can be a minute, an hour, a day and even a week. A period larger than a week is beyond what we define as a local time period. For example, if we set the time granularity as day, it means a user X  X  ratings during the current day will be picked as his/her local implicit feed-back. The most appropriate time granularity that directly and accurately reflects users X  local interests, can be discov-ered by testing different granularity settings. However, it could be observed that due to differences in various music datasets, the optimal time granularity might be in different datasets. If there are few items rated during a time peri-od, then that granularity might have little ability to capture users X  local behaviors. Having implemented our local mod-el with classical SVD++[12] , we could characterize users X  global interests with the global implicit feedback, and local preferences by using the local implicit feedback model. We present detailed statistics in the experimental part.
To investigate whether our implicit feedback model can further improve the performance of the existing temporal models, we integrate our model with those existing approach-es. Some classical temporal models have already been pro-posed, such as [13, 5]. Incorporating those time-aware mod-els with our local implicit feedback into an integrated model, we get the following formulation. p ( t ) ,q i ( t ) are used to denote the corresponding p u that change over time. This integration model is used to test that our implicit feedback model has an unique ability to discover some unheeded information.
There are two kinds of prediction tasks, rate prediction and top K ranking recommendation. Rate prediction is a general recommendation orientation [13], and ranking based approaches [17] are popularly used on datasets like Pandora and Last.fm. Both rate prediction and ranking task will be studied in our paper.

To recommend the top K items, we have to rank items over the r ui that directly reflects users X  interests. Optimization of ranking order is needed to get the updated parameters. Most traditional ranking approaches maximize the area under the ROC curve as follows: AUC ( u ):= 1 where N ( u ) + is the set of users X  liked items in N ( u means user u prefers items in N ( u ) + over I \ N ( u ) + optimize the rank order, we first define a hard 0-1 function as this:  X  ( x ) is non-differentiable, thus we can replace it with surro-gate functions  X  l ( x ). One widely-used surrogate function is logistic loss, which is adopted later in our ranking approach-es.
In this section, we present our efficient training algorithm that is used to speed up training in our experiments, after which we provide a complexity analysis. We can characterize implicit feedback models described in Equation 1 and 2 with the following general implicit feed-http://www.pandora.com back model: Here,  X ( u ) stands for implicit feedback information that could include global implicit feedback described in Equa-tion 1 as well as local feedback in Equation 2.  X  j is the implicit feedback term, and could be  X  j in global implicit feedback or  X  j in local model. Meanwhile,  X  j could be giv-en the value  X  j = 1  X  | and  X  j = 1  X  |
The traditional stochastic gradient descent algorithm [14] updates the above model as follows: We focus on p u , q i and  X  j ; the rules for updating bias omitted. The  X  s are regularization parameters.  X  is the learning rate, and  X  e is the difference between actual and predicted ratings. Obviously, the cost of updating  X  j is linearly related to the number of non-zero entries in  X ( u proportional to the number of items the users have rated.
The traditional updating procedure becomes expensive when the average number of items rated by users is large. For example, last.fm customers have listened to 3996 songs on average, so their updates would be at a great cost. When we add more implicit feedback information, that problem be-comes more prominent. Thus, some optimization methods are needed.

Before turning to our efficient algorithm, let us do some observations on the general model first. Define a derived user implicit feedback factor p im as follows: Theupdatingruleof  X  j after one step is like this (omitting regularization terms): Difference in p im before and after updating is as follows: With more care, we find that there exists a relation between  X  p im and  X   X  j , which is formulated as follows: Therefore, to get new  X  p im , we do not need to update each  X  . For logistic loss or square loss, those update rules and relations also remain valid. However, if the L 2 regularization term is added, update rules changes to this: Corresponding differences in p im change similarly. Those changes do not affect the use of this relation, since the reg-ularization term is usually small.
This general relation is used to speed up the stochastic gradient descent training, and can also handle all variants of implicit feedback models, such as SVD++ in Equation 1 and local implicit feedback in Equation 2. We develop an efficient algorithm for our local implicit feedback model described in Equation 2 by using the general relation in Equation 13. The detailed algorithm is presented as Algorithm 1. The general idea is that we do not need to update each  X  j or  X  j . Instead, we directly update p im and p im,t , and return changes to and  X  j using the relation in Equation 13. Figure 1 presents an intuitive comparison of local and global implicit feedback models using the efficient training algorithm. It is obvious that efficient training of SVD++ is just a special case of Algorithm 1.
 Algorithm 1 Efficient Training Algorithm for Training with Local Implicit Feedback for all user u do end for
Compared with classical stochastic gradient descent algo-rithm, our efficient training algorithm achieves a significant-ly reduction in time complexity. Algorithm 1 has a time complexity of O ( N e K + U R ) for general implicit feedback form, i.e. O ( N e K ), usually K&gt; 1. N e stands for all non-zero entries, and K refers to the latent dimension. U is the number of users, while R represents the average number of items rated by a user. The cost of updating p im for all users amounts to the product of dimension and all non-zero en-tries of user-item rating samples. While the complexity of updating all  X  j for all users is approximately the number of non-zero entries for all users. Thus, the overall complexity is the product of all non-zero entries and dimension. Com-pared to the cost of updating p im , this can be neglected. However, since original stochastic gradient descent needs to update  X  j whenever you get a updated p im ,itscomplexity is O ( N e K R ). Obviously,  X  = O ( N e K R ) our training algorithm performs R times faster than original one, where R is larger than 100 in general.
In this section, we present our experimental results to e-valuate the proposed local implicit feedback models. There are several questions we want to answer.
Our experiments are conducted on three datasets, Ya-hoo! Music 3 , Last.fm 4 , and Douban Music 5 .Yahoo!Mu-sic dataset is used by 2011 KDD Cup Workshop track 1. Last.fm is a famous personalized music website. We use the dataset provided by Celma et al.[4]. Douban Music is the largest Chinese music recommendation website. We crawl the dataset from users X  recent listening history along with time stamps. Table 2 is a statistical comparison for each dataset. Here, STG stands for the Smallest Time Granu-larity provided by the datasets or available, and AIR is the Average Items Rated per user. Traditional rating predic-tion is performed on Yahoo! Music, and is evaluated with RMSE(root mean square error). We train local models on the provided training set and test them on the validation set. Personalized ranking is implemented on the remaining Last.fm and Douban Music datasets. We follow the top-N recommendation evaluation metric proposed by Cremonsei http://kddcup.yahoo.com http://last.fm http://music.douban.com Yahoo! Music 1000990 624961 253M Min 252 Douban Music 22454 497744 2.94M Day 88 et al.[6]. First, we randomly 4 : 1 split the original training sets into training and validation sets. Then we get our final testing sets by sampling 1000 not rated items for each high rating example in the validation sets. Recall@K is used as evaluation metric like this: For each positive example with 1000 negative samples, it is called a hit if the positive example is ranked in the top K among the 1001 items. H is the overall hit number. T is the total number of items that users like in the test set.
We conduct several kinds of experiments on different data-sets to evaluate the performances of purely global implicit feedback model and our local implicit feedback models.
To fully illustrate the local models later, detailed descrip-tions of relevant models referred to Equation 2 are given as follows: The MLIF, HLIF, DLIF and WLIF models are all imple-mented with IMFB, a combination of global and local im-plicit feedback information. IMFB is regarded as a baseline. The five models are all trained with our efficient training algorithm, and are built based on the time granularity avail-able in the corresponding dataset. Through comparisons we set the latent factor as 100 in our experiments.
Since Yahoo! Music is a rate prediction task, RMSE is adopted as our evaluation metric. It is appropriate to this specific dataset. The detailed RMSE results of the five mod-els are in Figure 2. From the RMSE results of each of the models with different time granularity, we can get some basic observations. Firstly, we find that our proposed approach-es do give significant improvements in this rate prediction task. MLIF, which achieves the best performance in terms of accuracy, attains an RMSE of 22 . 673. While our baseline model IMFB gives 23 . 233. It can be also observed that the performances of the day and week models are similar, with RMSE of 22 . 922 and 22 . 972 respectively. No matter what RMSE Figure 2: RMSE of Local Models on Yahoo! Music
Table 3: Recall of Localized Models on Last.fm time interval is used, a local model al ways outperforms the baseline, though degrees of improvement are different. Thus, we can conclude that a local implicit feedback model works better than a purely global model. Secondly, it seems possible that a smaller time granularity gives better perfor-mance. That is, MLIF works better than DLIF, while DLIF is superior to others except the minute model. However, it might not be true on all datasets. The different performance among various time granularity reflect different descriptions of users X  local behaviors and we will discuss this in detail in Section 4.3. We do not present the basic MF method here, since it is generally inferior to SVD++[12].
In this section, we report the performance of our local im-plicit feedback models. From Table 2, the STG of Last.fm is minute. Based on time granularity available, minute, hour, day and week local implicit feedback models are constructed. We give the comparison of the best local implicit feedback against the global one in Figure 3. The detailed recall re-sults of all models are shown in Table 3. It is evident that our implicit feedback model achieves a significant improve-ment over the baseline. Our localized model DLIF achieves arecallof0 . 383 when K = 20, which means an item that a user likes has a probability of 38 . 3% to be ranked in the top 20 in DLIF during a large sample collection (1001 item-s). While the baseline gives a Recall@20 of 0 . 335. That is, day local implicit feedback has a 14% improvement over the baseline. Such big progress indicates that our model does outperform a purely global model significantly. Table 3 shows detailed recall results for the local implicit feed-back model. From Table 3, we know that compared to the Recall@K Figure 3: Recall@K of Localized and Baseline Mod-els on Last.fm
Table 4: Recall of Localized Models on Douban baseline, local implicit feedback models give improvemen-t to different extents. Obviously, DLIF, HLIF and WLIF give similar performance. HLIF and WLIF give Recall@20 of 0 . 373 and 0 . 380 respectively, and DLIF is a little higher than either of them. Moreover, MLIF gives approximately the performance of IMFB. With a recall@20 of 0 . 339, it is a bit better than IMFB. The experiments show that our local implicit feedback model can achieve significant improvement over baseline on ranking task.
This dataset is handled similarly to Last.fm, and shares the same evaluation methodology with it. Experiments are conducted on three models, IMFB, DLIF and WLIF. We present our results on Douban Music as Table 4, and com-parison curves as Figure 4. Figure 4 gives us an abstract impression that a local implicit feedback model outperforms IMFB. As anticipated, a local implicit feedback model gives a consistent improvement in terms of top K precision from Table 4. With a Recall@20 of 0 . 746 for IMFB, DLIF and WLIF outperform it with 0 . 783 and 0 . 780 respectively. Such improvement also can be observed from Recall@5, Recall@10 and Recall@15 in Table 4. Therefore, overall performances show again that local implicit feedback models do work in capturing users X  preferences that are neglected by a global model.
In this part, we evaluate the performance of our local im-plicit feedback models under different time granularity, and propose an empirical standard to find the most appropriate time granularity for each dataset. For convenience, define Recall@K Figure 4: Recall@K of Localized and Baseline Mod-els on Douban ARP(u) as the set of time-adjacent rating pairs of user u and ARP as the union of all users X  ARP(u). Statistics are done on the percentage of all ARP pairs which are catego-rized into five groups by their time differences. Time gap groups include: 0(No time difference 6 ), [1 M, 1 H ), [1 [1
D, 1 W ) and larger than 1 week. M, H, D, W refer to minute, hour, day and week respectively. The results are presented in Figure 5. The statistics is a direct reflection of users X  behavior frequency distributions.

From statistics of Yahoo! Music in Figure 5(a), we find that nearly 60% ARP pairs have no timestamp difference. Recalling the results in Figure 2, we find the minute model gives the best performance among all time granularity. This can be explained by our statistics since minute is the small-est granularity that contains sufficient information : 60% of ARP pairs have no time difference, indicating that sufficient feedback information can be obtained within a minute. Un-der the condition of sufficient information, a smaller granu-larity can lead to a better modeling of users X  behaviors.
In Last.fm, it appears that most ARP pairs lie in group [1
M, 1 H ). Using the day as time granularity allows us to cover sufficient information. The results in Table 3 suggest that day is the most proper time granularity, which achieves the best Recall@20 of 0 . 383. This is consistent with our pre-vious observation. In Douban, we can see that almost 75% of ARP pairs have no difference with each other. The re-sults in Table 4 show that day is the most appropriate. This is also consistent with our previous observation since day is the smallest time granularity with sufficient information.
Through comparison, we discover that the appropriate time granularity depends more on the property of specific dataset, and generally varies in different datasets. From the experiment results, we observe that the most proper time granularity is given by the smallest granularity that contains sufficient information. The most appropriate time granular-ity are minute, day and day on Yahoo! Music, Last.fm and Douban respectively. Moreover, by analyzing statistics on
This means there is no difference in timestamp, due to the limitation of minimal timestamp available on dataset
Table 5: RMSE Performance on Yahoo! Music each dataset, we can choose the appropriate time granularity using the empirical standard.
The experimental results presented in Section 4.2 show that local implicit feedback performs well on music dataset-s. Using a combination of global and local implicit feedback information, our local implicit feedback models capture not only their global interests, but also users X  local behaviors that could be indicated through the local rating entries. However, it can be argued that, even if our models cap-tures users X  changing interests, it might be largely due to some general influences of changes that existing time-aware models could handle. To answer this question, we conduct a comparison experiment to show that local model captures an unique property of music that differs from properties mined by existing time-aware models on the Yahoo! Music dataset. Here, Integrated.MF stands for the model adopted in [5], the reported best single model on Yahoo! Music, which contain-s state-of-the-art temporal dynamics modeling approaches. Integrated.Minute.LIF, represents the combination of a lo-cal model and Integrated.MF referred to Equation 3. We take the best local implicit feedback model on Yahoo! Mu-sic here to integrate with Integrated.MF. That is, Integrat-ed.Minute.LIF is a combination of local implicit feedback (MLIF) and a state-of-the-art temporal approach. Results are shown in Table 5. The combination gives a significan-t improvement from 22 . 346 to 21 . 879, better than all local models on Yahoo! Music dataset. Therefore, it can be con-cluded that a local implicit feedback model is complemen-tary to time-aware models, and combining it with the best single model reported can provide better performance. In conclusion, our proposed local model does have an unique capability to discover users X  potential preferences from a d-ifferent perspective.
Collaborative filtering has been an effective technique for recommender systems during the past years. Compared with content-based models [25], CF approaches do not nec-essarily need any attributes of users/items. In general, CF models are often adaptive and flexible since they learn from the dynamically changing user feedback [16]. Neighborhood based models [23, 21] and latent factor models [14] are two canonical approaches to CF. Recently, context-aware mod-els [1] are proposed to capture users X  behaviors on specific context. Context-aware models always leverage users X  con-text information such as mood [24], location [19], social re-lationship [3] etc.. However, these contextual information are often unavailable.

User implicit feedback plays an important role in informa-tion retrieval and data mining applications[2, 11]. Due to the limitations on obtaining explicit feedback (e.g. detailed ratings), implicit feedback, has been paid much attention [22] due to availablility. For some recommender system ap-plications, users do not always return their explicit feedback due to application limitations. Thus, implicit feedback can be leveraged to improve the recommendation performance. Hu et al. [10] studied CF implicit feedback datasets and proposed to transform users X  implicit feedback into training data in a preference-conference format. Koren [12] discov-ered that incorporating implicit feedback into a neighbor-hood integrated latent factor model (SVD++) could give significant improvement. However, training with implicit feedback becomes quite expensive in general recommender systems, and is not well studied. G. Takacs proposed a spe-cific unified approach of factor and neighbor based models for large recommender systems[9], differing from our general efficient training one.

Since users X  preferences generally change over time, rec-ommender systems should capture both global and local changing interests in order to provide more accurate rec-ommendations. Temporal dynamic models distinguish user-s/items from different time slots so as to maintain users X  changing preferences. Koren [13] proposed a time day bin approach in capturing users X  fixed preferences during a time period. Xiang et al.[26] designed a session-based temporal graph and applied a personalized random walk on it. The graph has three types of nodes for users, items, and user ses-sions, and is used to capture users X  long term and short term interests. Chen et al. [5] proposed a multi-resolution tem-poral CF model that consists of time-dependent user/item bias, latent factors, time-dependent neighborhood, and rat-ing session to cope with Yahoo! Music recommendation. Rendle et al. [20] proposed personalized Markov chains to-gether with MF in capturing both sequential effects and long term user-state, which focuses on influences of sequential ac-tions on the next action. There are also other recommenda-tion approaches involving temporal information in various ways, such as decreasing weights for old data [7], and time-dependent iterative prediction in a growing dataset[15].
In this paper, we propose a simple and effective local im-plicit feedback model to mine users X  local interests. We also design an efficient training algorithm to speed up the train-ing procedure. Experiments conducted on three datasets show that our local implicit feedback models significantly outperform the global implicit feedback model, and have a capability different from existing time-aware models in cap-turing users X  changing preferences. Meanwhile, we observe that the appropriate resolution changes on different dataset-s, and also give an empirical standard to determine the most appropriate time granularity. In the future, we plan to take this further to extract personalized local implicit feedback information and other localized properties.
Yong Yu is supported by grants from NSFC-RGC joint research project 60931160445.
