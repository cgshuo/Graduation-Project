 Social tagging is becoming increasingly popular in many Web 2.0 applications where users can annotate resources (e.g. Web p ages) with arbitrary keywords (i.e. tags). A tag recommendation m odule can assist users in tagging process by suggesting relevant t ags to them. It can also be directly used to expand the set of tags ann otat-ing a resource. The benefits are twofold: improving user expe rience and enriching the index of resources. However, the former on e is not emphasized in previous studies, though a lot of work has r e-ported that different users may describe the same concept in differ-ent ways. We address the problem of personalized tag recomme n-dation for text documents. In particular, we model personal ized tag recommendation as a  X  X uery and ranking X  problem and propose a novel graph-based ranking algorithm for interrelated mul ti-type objects. When a user issues a tagging request, both the docum ent and the user are treated as a part of the query. Tags are then ra nked by our graph-based ranking algorithm which takes into consi der-ation both relevance to the document and preference of the us er. Finally, the top ranked tags are presented to the user as sugg es-tions. Experiments on a large-scale tagging data set collec ted from Del.icio.us have demonstrated that our proposed algorithm signif-icantly outperforms algorithms which fail to consider the d iversity of different users X  interests.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Algorithms, experimentation.
 Social tagging, recommender systems, personalization, ra nking.  X  Corresponding author
Tagging refers to the behavior of bookmarking resources wit h keywords (tags). In recent years, social tagging is becomin g more and more popular in many Web 2.0 applications where users can freely annotate various resources, such as Web pages [7], ac ademic publications [6], and multimedia objects [8]. Tag recommen dation, an actively pursued research topic in tagging [22, 18, 19], i s con-cerned with suggesting relevant tags to the users, which the y could potentially use to bookmark the Web resources they visited. The motivation of tag recommendation is twofold. From the syste m X  X  perspective, it aims at expanding the set of tags annotating a re-source [18], thus enriches the index of resources. From the u ser X  X  perspective, like all other recommendation systems, the ta rget is to improve the experience of the user in her tagging process. In exist-ing work, however, the latter perspective is not emphasized . Fig-ure 1 shows the recommendation system provided by Del.icio. us [7]. When a user issues a URL, the system shows both popular and recommended tags for the URL.

Using a simple strategy, the popular tags are those frequent ly used by other users to annotate this URL, while the recommend ed tags are the intersection of this user X  X  tag vocabulary and a ll the tags annotated to this URL. Such a strategy resembles collaborat ive fil-tering [1] in that it exploits collaborative knowledge and d oes not require the content of documents. However, the tag recommen da-tion problem in reality is far more challenging. On one hand, since the popularity distribution of URLs in a social tagging syst em like Del.icio.us follows the power law [15], which indicates tha t most URLs are only bookmarked once or twice, it is very likely that a user issues a URL that few users, or even no user has ever book-marked. In that case, the aforementioned strategy can hardl y work. There is a need to further explore the interrelation of the We b doc-uments (e.g., URLs) as well as the tags used to bookmark them.
On the other hand, different users may have very different pr ef-erences on the tags they would select to bookmark a document. Previous work shows that people trying to convey the same ide a often disagree on how to describe it [17], due to different pe rsonal habits and different levels of expertise in related domains (the no-tion of basic levels [10]). For example, a mobile phone also can be called cell phone , cellular phone or cellular telephone . The ESP Game [21] demonstrates how difficult it is for two people to ag ree on even simple descriptive words for a picture. Therefore, i t is de-sirable to develop personalized recommendation systems fo r social tagging, which could improve user experience and encourage users to annotate more resources.
Neither of the two challenges is well addressed in literatur e. This paper addresses the problem of personalized tag recommenda tion for text documents. We model personalized tag recommendati on as a  X  X uery and ranking X  problem and propose a novel algorithm f or Graph-based Ranking of Multi-type interrelated Objects (GRoMO) for this purpose. Specifically, we construct an affinity grap h on the documents and a bipartite graph between documents and tags b y using the annotation relationships. When a user issues a tag ging request, both the document and the user are treated as query i nputs. The tags are then ranked by the proposed graph-based ranking al-gorithm which considers both relevance to the document and p ref-erence of the user. Finally, the top ranked tags are presente d to the user for selection.
As one may see, the problem here bears some similarities with other paradigms of personalization, such as personalized s earch [20, 16]. Indeed, the goal here is to recommend a personalize d list of tags given a user and a document, and personalized search c an be viewed as recommending a personalized list of documents g iven a user and a query. However, there are fundamental differenc es between these two problems, which makes existing technique s of personalized search incapable to be applied to personalize d tag-ging: 1) the  X  X ueries X  (i.e., documents to be bookmarked) in tag-ging are much more informative than the queries in search, wh ich makes it easy to compute the interrelation (e.g., similarit y) between  X  X ueries. X  This brings in a new opportunity to explore the un derly-ing structure of the  X  X ueries X  in tagging, which is hard to ac hieve in search. Meanwhile, the  X  X ocuments X  (i.e., candidate tag s) in tagging are far less informative than documents in search. T his prevents us from exploring the well studied content-based m ethods in personalized search, such as feedback. 2) Techniques of p erson-alized search usually rely on the initial set of relevant doc uments returned by the search engine. Indeed, most personalized se arch systems are developed by reranking the top documents in the l ist. In the tagging context, however, the  X  X ocuments X  (tags) are an open set. There is no  X  X earch engine X  to obtain an initial list of r elevant documents (tags) for a query (document), especially for a pr evi-ously unseen query (document). The relevance of a tag can be o nly judged by the particular user, who could well tag a document w ith an acronym only used by herself.

All these typical characteristics of tagging have brought i n new challenges as well as opportunities to its personalization problem. Our algorithm can naturally address these problems by lever ag-ing the underlying structure of documents and the annotatio n rela-tionships between documents and tags collectively contrib uted by users.

The rest of the paper is organized as follows: the next sectio n outlines related work. Formal definition of the problem and o ur novel graph-based ranking algorithm GRoMO are presented in sec-tion 3. In section 4 we show how to use this algorithm to achiev e personalized tag recommendation. Experiments are describ ed in section 5, and finally, Section 6 concludes our work.
In this section we briefly review previous work related to our s: automatic tag recommendation and graph-based ranking algo rithms.
Xu et al. exploit collaborative tagging information to recom-mend tags [22]. Their recommendation algorithm favors tags used by a large number of people on the target document (high autho r-ity) and attempts to minimize the overlap of concepts among t he recommended tags to allow for high coverage of multiple face ts. This algorithm is similar to the recommendation strategy em ployed by Del.icio.us, which cannot handle new documents. The P-TA G algorithm [5] automatically generates personalized tags f or Web pages. The generated tags are relevant to the textual conten t of target Web page as well as the documents residing on the surfe r X  X  Desktop. However, the problem is different from ours in that they focus on extracting personalized keywords as tags from Web p ages to automate the tagging process while we concern the problem of personalized tag recommendation using collaborative tagg ing data. Sigurbj X rnsson and Van Zwol study tag recommendation in Fli ckr [18]. When a user submits a photo and enters some tags, an orde red list of candidate tags is derived for each of those entered ta gs, based on tag co-occurrence. These lists of candidate tags are then prop-erly merged to form the final recommendation list. Their appr oach depends on user entered tags and cannot be directly applied t o re-sources. Furthermore, since they only exploit co-occurren ce data, there may exist the problem of topic drift . A personalized, interac-tive tag recommendation algorithm is introduced in [9], whi ch pro-vides a special treatment for personal tagging data. It also depends on tag co-occurrence based on user entered tags. Thus, the af ore-mentioned disadvantages also apply in such an algorithm. So ng et al. developed a clustering-then-classifying framework for ta g recommendation [19]. They explore spectral clustering on b ipar-tite graph to simultaneously group tags, documents and word s into clusters. Then a two-way poisson mixture model is trained on the obtained clusters. Given a query document, the algorithm co mputes its posterior probabilities over those clusters, and then t he tags are ranked by considering both a static score and the correspond ing posterior probability. Their approach could not generate p ersonal-ized suggestions, and only the top-ranked tags in each clust er could ever be recommended.
Our work is also related to graph based ranking. There have been several developments in theory and algorithms for lear ning on graph data [2, 3, 4, 12, 13, 23]. They are all developed with in the Laplacian-based regularization framework.

Zhou et al. propose a manifold ranking algorithm which ranks data objects with respect to the intrinsic manifold structu re among the data objects [23]. The ranking function is obtained by pr eserv-ing the local structure. In other words, two similar objects should have similar ranks. A regularization framework is thus esta blished for this purpose. Agarwal [2] models preference training da ta as a (directed) weighted graph and then minimizes the empirical rank-Figure 2: An illustration of the ranking problem that we con-sider. The solid lines represent the affinity relationships be-tween objects in D . The dotted lines denote the relationships between objects from D and those from T . ing error regularized by the Laplacian smoothness constrai nt which ensures that the ranking scores are similar for closely-con nected objects. For tag recommendation, we need to deal with multi-type interrelated data objects. Therefore, the existing rankin g algorithms can not be directly applied. We have two types of objects, documents and tags, denoted by D and T , respectively, an affinity graph G D for D and a bipar-tite graph H D , T describing annotation relationships between D and T . Figure 2 illustrates the situation described above. The le ft dotted ellipse represents D and the right one represents T . The solid lines represent the affinity relationships among docu ments (e.g. we can use cosine similarity or Gaussian similarity as edge weights.), and the dotted lines denote the annotation relat ionships between documents and tags (e.g. in Fig. 2, if tag t 2 is totally used 3 times to annotate d 6 , then we can simply set the correspond-ing edge weight to 3.). The problem is, given query documents from D and/or query tags from T , to rank documents and tags, respectively, according to their relevance to the queries. Let W be a | D |  X  | D | affinity matrix corresponding to G D and R be a | D |  X  | T | affinity matrix corresponding to H D , T f = [ f 1 , . . . , f |O| ] T and g = [ g 1 , . . . , g |T| vectors for documents and tags, respectively. We define a que ry vector y d = [ y d 1 , . . . , y d |D| ] T in which y di = 1 if d query. y t is defined similarly for T . Then the goal is to infer f and g from W , R , y d and y t . This definition is quite general, where given a query of y d and/or y t , we can rank documents and tags according to f and g , respectively. We define three diagonal matrices D , D d and D t . The size of D and D d is | D |  X  | D | . D t has size | T |  X  | T | . The ( i, i ) -elements of D , D d and D t equal to the sum of the i -th row of W , the sum of the i -th row of R and the sum of the i -th column of R , respectively. f and g should be as consistent as possible with the given infor-mation, that is, W , R , y d and y t . This leads to the following cost function associated with f and g : where D ii , D d ii and D t ii are the ( i, i ) -elements of D , D respectively. The first and second terms of the right-hand si de in the cost function are the smoothness constraints. The first term means that a good ranking of documents should assign similar ranki ng scores to similar documents. The second term means if a tag is strongly associated with a document (e.g. a tag is applied to a doc-ument many times), then they should have similar ranking sco res. Please note that in the second term the ranking scores of docu ments and tags are normalized by p D d ii and q D t jj , respectively. In other words, the scores are normalized by the popularity of corres pond-ing nodes. The explanation is as follows: the documents anno tated by a generally popular tag such as  X  X esign X  or  X 2008 X  may not share a common topic; the large set of tags annotating a popul ar document is likely to contain irrelevant tags or even spam. B y nor-malization, we can to some extent suppress popular document s and tags from dominating result rankings. The normalization in the first term is necessary for the optimization problem to be solvabl e. The third and fourth terms measure the difference between the ob tained ranking scores and the pre-given labels which needs to be min i-mized. The trade-off among these terms is controlled by the r egu-larization parameters  X  ,  X  and  X  and  X  , where 0 &lt;  X ,  X ,  X ,  X  &lt; 1 and  X  +  X  +  X  +  X  = 1 .
 We define matrices With simple algebraic formulations, the first term can be rew ritten as follows: Similarly, the second term can be computed as follows: Then we can rewrite Equation (1) in the corresponding matrix -vector form: Q ( f , g ) =  X  f T ( I  X  S W ) f +  X  ( f T f + g T g  X  2 f Then the optimal rankings are achieved when Q ( f , g ) is minimized: Differentiating Q ( f , g ) with respect to f , we have Differentiating Q ( f , g ) with respect to g : Substituting equation (9) into equation (8), we obtain the c losed form solution for f  X  : f = (1  X   X  ) I  X   X  S W  X   X  . It can be proved that the matrix h (1  X   X  ) I  X   X  S W  X   X  is invertible. We omit the proof due to space limitation. Onc e f obtained, g  X  can then be computed as Although the closed form is achieved, in some practical case s, the iterative form might be preferable. We can devise an iterati ve algo-rithm like HITS algorithm [14] from Equation (8) and (9). Wit hout loss of generality, suppose f (0) = y d and g (0) = y t . In the t -th iteration, we first use f ( t ) and g ( t ) computed in the last iteration to compute g ( t + 1) : and then f ( t + 1) is computed from f ( t ) and g ( t + 1) : f ( t +1) = We can see that f ( t ) and g ( t ) reinforce each other in each iteration. Substituting equation (12) into equation (13), we have Figure 3: An illustration of the problem of personalized tag recommendation. Figure 4: Frequency of tag usage as a function of the relative position (descending order by frequency) for five users. This form of iteration involves f only and is more efficient for com-putation. By a similar analysis as in [23], it can be shown tha t f ( t ) converges to f  X  : Once f  X  is obtained, we can then compute g  X  using equation (11).
We can intuitively interpret the GRoMO algorithm as heat dif fu-sion among vertices of the graphs through edges until a stati onary state is established. The stronger the edge is (i.e. W ij the more heat is transferred between the vertices connected by the edge. There are two types of diffusion: 1) diffusion among ob jects in D (first term of the right-hand side of Equation (1)); 2) diffus ion between D and T (second term); The third and fourth terms assure that there are heat sources (i.e. queries) on graphs. Parame ters  X  ,  X  ,  X  and  X  control the relative importance of two types of diffusion and two types of sources. Hence, objects with many strong pat hs (paths that have many strong edges, re-weighed by the  X  or  X  ) from important query objects will have high ranking scores.
In this section, we propose to solve the problem of personal-ized tag recommendation using the GRoMO algorithm introduc ed. Figure 3 shows a sketch of the problem. We continue to use D and T to represent the sets of documents and tags, respectively. We are given n users U = { u 1 , . . . , u n } and their tagging history B = { ( u i , d j , t k ) } where ( u i , d j , t k ) means user u t to annotate document d j . The task is, given a user-document pair ( u, d ) , to rank tags considering both relevance to d and tag preference of u . There are mainly two issues we need to address: the construction scheme of the affinity graphs and personali zation of the recommended tags. We also summarize the whole algorit hm at the end of this section.
We need to construct matrices W and R . R is constructed as follows: obtain the users X  tagging history B and set R ij u k  X  U and ( u k , d i , t j )  X  B} | . W is constructed using similarity measures between documents. Cosine similarity is used: where x i is the feature vector representation of d i . W is formed by setting W ij = sim( d i , d j ) if i is among the k most similar documents of j or j is among the k most similar documents of i . All the other elements of W are set to zero.
The recommended tags should be biased to the user X  X  tag vocab -ulary. For example, in Figure 3, both t 1 and t 2 are used to annotate d . Suppose they have similar meaning. We should recommend t for u 1 and t 2 for u 3 when d 6 is involved. For u 2 , both t should be recommended since u 2 may use synonyms when anno-tating documents.

To retrieve relevant tags, the query vector y d is set so that only the entry corresponding to the query document d is 1: As a document becomes popular (i.e. annotated many times by users), the distribution of frequencies of tags annotating it gradually forms power law [11]. If we use document d alone as a query, the most frequently used tags may become dominant, which may not conform to the user X  X  preference. We propose to utilize the q uery vector y t to achieve personalization. By setting tags used by the user as queries we can promote tags that are not only relevant to the query document but also preferred by the user. The remain ing question is then how to distribute query weights to each tag u sed by the user. We investigate tag usage patterns of users in Del.i cio.us (the dataset is described in section 5), and selectively sho w the tag usage patterns of five users in Figure 4 (in log-log scale). Th e x-axis represents relative positions, from the most frequent tag to the least frequent tag, and the y-axis is the corresponding freq uency of the tag. All users are represented by the IDs in our database.  X  u tv = j , all = l  X  means user with ID i has a tag vocabulary of size j and has used them l times in total. We can see that the larger the all/tv ratio, the better the points fit a power law. This means there are a small number of tags used frequently by a user, while a la rge number of tags are only used once or twice. Therefore, if a use r decides to use previously used tags to annotate a new documen t, the frequently used tags should be used rather than those in t he long tail. However, assigning weights to each tag proportio nal to Algorithm 1 : Personalized Tag Recommendation the frequency by which it was used by the user tends to bias to t he most frequently used tags. We use log frequencies: where y ti denotes the i -th entry of y t corresponding to t frequency u,t i is the number of times user u has used tag t is the tag vocabulary of user u . We add 1 to the log frequency to avoid zero weights.

The personalized tag recommendation algorithm is summariz ed in Algorithm 1. We employ the closed form of GRoMO in our ex-periments. In the online recommendation phase, we first use E qua-tion (10) to compute the ranking vector f  X  of documents. Then the ranking vector g  X  of tags is computed using Equation (11). Finally, the top ranked tags are presented to the user.
The dataset used in this paper is crawled from Del.icio.us. W e use a user-centric strategy to collect data. In particular, we sub-scribed to 20 popular tags and harvested 47,355 distinct use rs ex-tracted from the user field of each fetched bookmark, from Nov . 27th, 2008 to Dec. 2nd, 2008. We discarded users whose book-marks were fewer than 30 or whose average number of tags per bookmark is less than 3. For the remaining 15,732 users, we cr awled all their bookmarks from Del.icio.us (i.e. snapshots of the users X  tagging data by the time the bookmark pages were crawled). Ab out 8.9 million bookmarks and 4.4 million URLs were obtained. We then constructed a unweighted bipartite graph in which vert ices were users and URLs and applied HITS algorithm [14] to find au-thoritative users. We selected 300 the most authoritative u sers and 12,677 URLs that were saved more than 6 times 1 by these users. The page content of these URLs were crawled. Among the suc-cessfully downloaded pages, we discarded non-HTML pages an d non-English pages. Texts are extracted from the remaining W eb pages and URLs are represented using normalized word freque ncy vectors. Finally, we ended up with a dataset containing 300 u sers, 11,795 URLs, 17,777 tags and 167,885 bookmarks, averaging 6 .11 tags per bookmark.
For comparison, two variations of the Vector Similarity (VS ) ap-proach are employed: Personalized Vector Similarity (PVS) and Global Vector Similarity (GVS). PVS works as follows: for a query ( u, d ) , calculate the similarity between d and each training docu-ment annotated by u using Equation (16), and then the similarity scores of s most similar documents are accumulated to the corre-sponding tags used by u to annotate them. The top ranked tags are recommended to u . GVS works similarly. In GVS, all training documents, tags and bookmarks are exploited, and when calcu lat-ing the ranking score of tag t , the similarity of a related top-s doc-ument is weighted by the number of times tag t is applied to the document normalized by the total number of times of all tags a p-plied to the document. Note that PVS uses completely the pers onal data of a query user and concerns only personalization, whil e GVS considers the tagging data of all users and returns the same r ecom-mendation for a document regardless of the query user. The pa ram-eter s is set empirically. When constructing W , we empirically set k = 50 . In experiments, we set the number of recommended tags to 10.

For evaluation, we sort each user X  X  bookmarks by time and use the first x % (we test different values of x , from 50 to 90) from each user to form the training set. The last 10% bookmarks are trea ted as test data as well as the ground truth. Since we concern pers on-alization, it is reasonable to use the users X  bookmarks as gr ound truth. Note that we can still recommend tags to documents onl y appearing in the test set since we can recommend tags associa ted with similar documents. We use Normalized Discount Cumulat ive Gain (NDCG), precision and recall to evaluate recommendati on al-gorithms. Consider a test instance ( u, d ) . NDCG at position n is defined as where r i is the rating of tag at rank i . In our case, r used this tag to annotate d and 0 otherwise. Z n is chosen so that the perfect ranking has a NDCG value of 1. Precision is defined as t he number of correctly recommended tags divided by the number o f all recommended tags. Recall is defined as the number of corre ctly recommended tags divided by the number of all tags u actually used for d .
GRoMO has four parameters (three free parameters) which con -trol the relative importance of different types of score dif fusion. To explore the influence of different parameter settings on t he per-formance of GRoMO, we use the first 90% of each user X  X  book-
Bookmarks with zero tags are discarded because they are of no use to both training and testing. marks for training and the rest for testing. Due to space limi tation, we show only the results that reveal characteristics of para meters. From preliminary experiments, we found user used tags can ea sily reinforce one another through co-occurrence relationship s bridged by documents. Although the total query weight assigned to us er tags is equal to that of query document, the influence of the re -inforcement phenomenon can easily dominate the score diffu sion process and consequently user frequently used tags are rank ed high regardless of the query document (i.e. overly biased to the u ser X  X  preference). Therefore, we should keep  X  small. In particular, we fix two of {  X ,  X ,  X  } at 0.3 and vary  X  against the other one. Fig-ure 5 shows the results. As we expect, when  X  varies against  X  or  X  , the performance first increases then decreases. Since  X  and  X  represent the influence from documents, Figure 5 illustrate s that we indeed can achieve better performance by trading off betw een relevance and personalization.  X  controls the importance of score diffusion between documents and tags. Increasing  X  , however, can not only increase the score flowing from documents to tags, bu t also amplify the reinforcement phenomenon mentioned above. Nev er-theless, varying  X  against  X  exhibits similar performance curve as varying  X  against  X  or  X  . It seems  X  is more crucial. We select the best parameter setting for the remaining experiments:  X  = 0 . 3 ,  X  = 0 . 17 ,  X  = 0 . 5 and  X  = 0 . 03 .
We compare GRoMO with the other two algorithms with respect to different amounts of training data. Specifically, we use t he first 50%, 60%, 70%, 80% and 90% of each user X  X  bookmarks as train-ing data, respectively. At each run, the last 10% of each user  X  X  bookmarks are used for testing. The results are presented in Fig-ure 6. GRoMO is clearly the winner. Our algorithm significant ly outperforms both PVS and GVS (by t-test,  X  = 0 . 05 ). GVS per-forms better than PVS. This can be explained by: 1) users do ha ve some degree of consensus on which tags to apply (i.e. the powe r law distribution of tags annotating a document [11]); 2) con sider-ing the diverse interests of users, it may be difficult to find d ocu-ments directly related to the current document from the user  X  X  per-sonal tagging history. However, by combining both collabor ative and personal data, we can achieve better performance on all e valu-ation metrics, as shown by the curves of GRoMO. There is a drop of performance for GRoMO on NDCG@10 when the training data changes from 80% to 90%, which is unexpected. Though precisi on and recall increase (Figure 6(b) and 6(c)), it seems the rele vant tags tends to reside at lower positions within the top 10 tags comp ared to the case of 80% training data. We tune the parameters of GRoMO using 90% data as training data, but it performs even better o n NDCG with less training data. We also report the performance of the three recommendation algorithms on NDCG@1, NDCG@3 and NDCG@5, as shown in Table 1. By Wilconxon test, in most cases our proposed algorithm significantly outperforms the other methods at significance level  X  = 0 . 01 . The 90% case is again due to the performance drop of GRoMO on NDCG. In general, we find that GVS can achieve competitive performance when training data is abundant. However, such a condition is rarely satisfied in real world.

Table 2 shows an example demonstrating that our algorithm ca n correctly adapt to the users X  personal habits of tag usage. T he page  X  X ttp://www.brand-name-coupons.com/how-to-search-am azon-for-deals/ X  tells people how to find discounted deals in Amazon show three users X  annotations (the ground truth) in the last 10% testing data and the corresponding tag lists suggested by GR oMO http://www.amazon.com/ (b) Precision and (c) Recall. test instances. (trained on 90% data). In our dataset, we find that the majorit y of users annotating this URL use bargains , discount and coupons . Only a few users use cheap to express the same meaning. From Table 2 we can see that our algorithm correctly adapts to u preference. We also find that in our dataset u 37982 had already used cheap several times before he/she annotated this URL. The same analysis can be derived for u 5472 with respect to tips . Note that in the recommended list for u 5472 there are some irrelevant tags. They are mainly the user X  X  most frequently used tags.
We address the problem of personalized tag recommendation i n social tagging systems. We model it as a  X  X uery and ranking X  p rob-lem and propose a novel graph-based ranking algorithm of Mul ti-type interrelated objects (GRoMO). When a user issues a tagg ing request, both the document and the user are treated as querie s, ac-counting for relevance and personalization, respectively . After ap-plying GRoMO, the top ranked tags are presented to the user. A l-though we consider text data in this paper, our algorithm is g en-eral and can be applied to any social tagging systems as long a s a notion of similarity between resources is defined. We compa re GRoMO with Personalized Vector Similarity and Global Vecto r Similarity on a dataset crawled from Del.icio.us. The resul ts show that GRoMO is effective and outperforms the other algorithm s. For future work, we would like to examine the efficiency issue of o ur algorithm. It would be also interesting to apply GRoMO to oth er types of tagging systems and other recommendation problems . This work was supported by National Key Technology R&amp;D Program (2008BAH26B02 &amp; 2007BAH11B06) and the Key S&amp;T Projects of Zhejiang Province (2007C13019). We would like t o thank Zhengguang Chen, Tianyu Li and Zhaohong Chen for algo-rithm implementation and detailed discussion. [1] G. Adomavicius and A. Tuzhilin. Toward the next generati on [2] S. Agarwal. Ranking on graph data. In Proceedings of the [3] D. Cai, X. He, and J. Han. Spectral regression for efficien t [4] D. Cai, X. He, and J. Han. SRDA: An efficient algorithm for [5] P. A. Chirita, S. Costache, W. Nejdl, and S. Handschuh.  X  = 0 . 05 and  X  = 0 . 01 , respectively.
 Tags with bold font indicate matches with the ground truth. URL: http://www.brand-name-coupons.com/how-to-search -amazon-for-deals/
UserID Ground Truth GRoMO Recommended 8414 amazon, bargains, Coupons, deals, discount, howto, [6] CiteULike. http://www.citeulike.org. [7] Del.icio.us. http://delicious.com. [8] Flickr. http://www.flickr.com. [9] N. Garg and I. Weber. Personalized, interactive tag [10] S. A. Golder and B. A. Huberman. Usage patterns of [11] H. Halpin, V. Robu, and H. Shepherd. The complex [12] X. He and P. Niyogi. Locality preserving projections. I n [13] X. He, S. Yan, Y. Hu, P. Niyogi, and H.-J. Zhang. Face [14] J. Kleinberg. Authoritative sources in a hyperlinked [15] X. Li, L. Guo, and Y. E. Zhao. Tag-based social interest [16] Q. Mei, D. Zhou, and K. Church. Query suggestion using [17] S. Sen, S. K. Lam, D. Cosley, D. Frankowski, J. Osterhous e, [18] B. Sigurbj X rnsson and R. van Zwol. Flickr tag [19] Y. Song, Z. Zhuang, H. Li, Q. Zhao, J. Li, W. C. Lee, and [20] J. T. Sun, H. J. Zeng, H. Liu, Y. Lu, and Z. Chen. Cubesvd: a [21] L. von Ahn and L. Dabbish. Labeling images with a [22] Z. Xu, Y. Fu, J. Mao, and D. Su. Towards the semantic web: [23] D. Zhou, J. Weston, A. Gretton, O. Bousquet, and
