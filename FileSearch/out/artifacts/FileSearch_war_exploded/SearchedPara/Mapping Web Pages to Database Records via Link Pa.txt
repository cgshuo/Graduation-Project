 In this paper we propose a new knowledge management task which aims to map Web pages to their corresponding records in a struc-tured database. For example, the DBLP database contains records for many computer scientists, and most of these persons have pub-lic Web pages; if we can map the database record with the appro-priate Web page then the new information could be used to further describe the person X  X  database record. To accomplish this goal we employ link paths which contain anchor texts from multiple paths through the Web ending at the Web page in question. We hypothe-size that the information from these link paths can be used to gen-erate an accurate Web page to database record mapping. Experi-ments on two large, real world data sets, DBLP and IMDB for the structured data and computer science faculty members X  Web pages and official movie homepages for the Web page data, show that our method does provide an accurate mapping. Finally, we conclude by issuing a call for further research on this promising new task. H.2.8 [ Database Management ]: Database applications X  data min-ing ; H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Algorithms, Experimentation mapping, Web, link paths, semi-structured data
The World Wide Web contains a wealth of information, and it is rapidly expanding in size and scope. Despite the vast complexities of the Web X  X  landscape, billions of people, even young children, are able to navigate the Web with relative ease. This is partly due to the usefulness of modern Web browsers, search engines and Web design techniques, and partly due to the link-based construction of the Web itself. Arguably, the aspect most fundamental and essential to the ongoing operation of the Web is the existence of hyperlinks. These page-to-page links have shown their ability to tame the Web over and over again, and has transformed an otherwise unwieldy mass of documents into information accessible to the World. Structured databases of all types have grown alongside the World Wide Web. Recently, efforts have been made to bridge the gap be-tween this structured data and the unstructured data from the Web, but most of these efforts have been one-way. That is, most cur-rent work focuses on extracting structured information from one or more Web pages. While this is an important task, if technol-ogy could be provided to map specific Web pages to records in a database then the structured and unstructured data could be used to mutually enhance each other in order to address many difficult problems. Therefore, mapping structured database records to Web pages is a specific challenge to the database and information re-trieval community.

On the World Wide Web, to supplement the numerical PageRank-type probabilities, edges can be assigned labels according to their associated anchor text. For example, the HTML hyperlink &lt;a href ="www.yorku.ca/cikm10/"&gt;CIKM Conference&lt;/a&gt; can be an-notated by the anchor text,  X  X IKM Conference X . It is a widely ac-cepted practice for search engines to index an inbound link X  X  anchor text because  X  X nchors often provide more accurate descriptions of Web pages than the pages themselves X  [1]. This observation did not start with Google, in fact, the idea of indexing incoming an-chor text with the page it refers to was implemented in the World Wide Web Worm in 1994 [4], and since then dozens of studies have looked at various ways to leverage anchor text information.
The main contributions of this paper are as follows: (1) We for-mulate a new knowledge management task which aims to map Web pages to their corresponding structured database record; (2) We de-fine link paths and show that they are able to represent the ref-erenced Web page more effectively than existing methods; (3) We use link paths to generate mappings from Web pages to their appro-priate records in a structured database; and (4) We perform a case study to judge the effectiveness of our approach and demonstrate the implications of this new task.
Let G = ( V, E ) denote a given graph, where V = { v 1 , . . . , v is the set of vertices and E = { e 1 , . . . , e m }  X  V  X  V is the set of directed edges, where each edge e k can be represented by  X  v , v j  X  . A path p  X  G is a sequence of directed edges p =  X  X  v 1 , v 2  X  , . . . ,  X  v l  X  1 , v l  X  X  . In this paper we denote u = v v = v l as the source and destination vertices of path p respectively. Each edge is associated with a value called the edge cost denoted Figure 1: Cropped Web graph from the Computer Science De-partment at the University of Illinois at Urbana-Champaign by c e . For our purposes all edge costs are uniform; so for any path p in G , c ( p ) = l .

On the Web, each Web page represents a vertex and each hy-perlink represents a directed edge. A link path , therefore, is a path through the Web-graph from one Web page to another. Specifically, if a path between page u and page v contains pages x , and y then a link path from u to v is u  X  x  X  y  X  v .

Anchor tags along the link path are extremely important. To capture this information we label each edge in the link path with the corresponding anchor text. If the link between pages u and x has the anchor text a then the link is labeled u a  X  X  X  x . Because there are an infinite number of possible paths on the World Wide Web, the first step is to identify the source page u and destination pages v  X  V 0 where V 0  X  V . The source page u , known as the reference page , provides context to the mapping task and is therefore task dependant. For instance, if the task is to map personal Web pages at the University of Illinois to the structured university phone book then an appropriate reference page would be www.illinois.edu ; if the task is to map official movie Web pages to structured IMDB data then an appropriate reference page may be http://trailers.apple.com . In any case, the refer-ence pages should be identified either manually or by some heuris-tic.

Identifying the set of destination pages V 0 is similar to the home-page identification task from the 2002 TREC Conference [2] and similar to other work on homepage finding [3, 5]. Otherwise, sim-ple heuristics can be of limited use to extract the destination pages.
Now that the source u and destination V 0 pages have been iden-tified, we turn our attention to the various link paths between u and each destination page v  X  V 0 .
A simple way to find the link path between u and v is to per-form a shortest path search on the graph. Unfortunately, a single link path may not contain all the information needed to provide an accurate mapping. We propose two solutions to this problem: (1) find the K -shortest link paths, and (2) find the K -shortest loop-less [6] link paths. Our intuition is that loopless paths will result in a greater variety of anchor texts than the K -shortest path method because the loopless paths are not susceptible to the cycles within Web site menus. In both the K -shortest and K -shortest loopless path finding methods we would expect to collect a set of anchor texts along various paths between the reference page u and the des-tination page v .
The path p from u to v will have edges { e 1 , . . . , e l  X  1 tated by the anchor text of each edge a e . The set of anchor texts { a e 1 , . . . , a e l  X  1 } for the path p , denoted A p , typically contains a descriptive text relative to the reference page u of the destination page v .
 Example. The anchor texts retrieved from two paths two Dan Roth X  X  homepage in Figure 1 are: A p 1 ={ People , Faculty , Dan Roth , Personal Site } and A p 2 ={ Research , Data Mining , Dan Roth , Personal Site }.
From this real world example, we see the utility of anchor texts from link paths because Dan Roth is a person and a faculty member who does research in data mining .

Next the K link paths { p 1 . . . p K } are combined into a bag-of-words representation { A p 1 , . . . A p K }  X  A u,v for each of the K link paths between u and v . We refer to A u,v as a bag-of-anchors. Example. The bag-of-anchors from the running example is { Re-As discussed earlier, there will be many destination pages in each Web site. Therefore, each destination page v  X  V 0 will have its own set of K link paths and its own bag of anchors A u,v resulting in | V 0 | bags {A u,v 1 , . . . , A u,v Example. In the example from Figure 1 there exist three destina-tion pages, and therefore three bags: A u,v 1 ={ Research:1 , People:1 , Faculty:1 , Data Mining:1 , Dan Roth:2 , Personal Site:2 } A u,v 2 ={ Research:1 , People:1 , Faculty:1 , Data Mining:1 , Jiawei Han:2 , Personal Site:2 } A u,v 3 ={ People:1 , Faculty:1 , Vikram Adve:1 , Personal Site:1 }
The next step is to rank the texts within each bag of anchors so that more descriptive anchor texts are given a higher ranking. To do this, we normalize the score of each word a of the i th where f ( a  X  X  ) is the frequency of anchor a in the bag of anchors A . Put more simply, we normalize each word by the frequency each word occurs in an bag of anchors (term frequency) over the frequency of each term in all bags (global term frequency). Finally, we sort the bag of anchors in descending order.
 Example. Continuing the example above, the ranked bags of an-chors are:
A u,v 1 ={ Dan Roth :2/2=1 , Research :1/2=0.5 , Data Mining :1/2 =0.5 , Per-sonal Site :2/5=0.4 , People :1/3=0.33 , Faculty :1/3=0.33 } A u,v 2 ={ Jiawei Han :2/2=1 , Research :1/2=0.5 , Data Mining : 1/2=0.5 , Personal Site :2/5=0.4 , People :1/3=0.33 , Faculty :1/3= 0.33 }
A u,v 2 ={ Vikram Adve :1/1=1 , People :1/3=0.33 , Faculty :1/3= 0.33 , Per-sonal Site :1/5=0.2 }
Thus, we find that the most descriptive terms for each destination page are ranked highest in each list. We especially notice that the anchor text nearest the destination page is not necessarily the most descriptive.
The ranked link path information described in the previous sec-tion can be used for many purposes including Web search and in-formation retrieval, and while the IR task may be beneficial it is not the goal of this work. Instead, our particular goal is to use the texts encoded in the link path to map the destination Web page ( v  X  V to its corresponding record in a structured database r  X  R .
To rephrase, given a set of structured database records, we wish to add a new column to the schema labeled URL and populate the new cells of the record with URLs of the corresponding Web pages.
Very frequently the text on a link path is not exactly the same as corresponding text in the database. Names, especially, can be represented in several different ways. For example, a persons name can be represented with or without the middle name, with the mid-dle name abbreviated, last name first, and so on. Therefore, an exact byte-by-byte query would rarely return any results. To miti-gate this problem, before a query is actually performed, the anchor text is sanitized, that is, all punctuation an extra spaces are removed and all letters are lowercased.

The actual retrieval function should collect records which match terms from the query string, otherwise the ordering of terms would matter ( e.g. ,  X  X an Roth X  would not match  X  X oth, Dan X ). Most database systems have an indexing or search function to handle these types of queries; we use MySQL and its match against function to retrieve records. Frequently the search function will return several candidate matches. To select the optimal match from these results we adapt a word dis-tance heuristic with a threshold. This threshold  X  ( 0  X   X   X  1 ) does not allow a mapping to occur when the word distance is above the threshold. For our purposes, we examine the two possible extremes of  X  : strict matching (  X  = 0 ), and approximate matching (  X  = 1 ).
In strict matching we map a Web page to a database record if and only if an exact match is found, that is, when the word distance is 0. In approximate matching we map a Web page to the database record with the closest word distance.
The overall algorithm, shown in Algorithm 1, should serve as a general framework for the the mapping task.

As input to the framework, we require a set of records ( i.e. , a structured database), a column from that database to match against, a Web page from which link paths originate called a reference page , and a set of Web pages to be mapped to records in the database called destination pages . These destination pages most commonly refer to a single entity or item that is dually described in the records of the database. Finding these end pages is the topic of previous and ongoing research known as the homepage finding task.

The output of the framework is a one to one mapping of a record to an destination page. In some problem settings a many to one, one to many or many to many mapping may be preferred, but in this initial work we only consider singular mappings. These map-pings can be used for any number of tasks; we describe some of the potential outcomes resulting from accurate record to Web page mappings in Section 6.
We evaluated the effectiveness of our algorithm using two data sets, and we compare the performance of our methods against two worthy baseline systems. Despite the large number of studies re-lated to this work, to the best of our knowledge there do not exist other methods for mapping Web pages to structured records. There-fore, we cannot directly compare our algorithm to other published methods.

Algorithm 1 : Mapping Framework input : Set of records r  X  R , Selected column c  X  DB , output : One to one mapping M foreach v  X  V 0 do return M ;
Our first data set is a crawl of the departmental Web sites of the top 25 American computer science graduate schools 1 ond data set is a crawl of movie Web pages starting from http:// trailers.apple.com and http://www.allmovie.com . Given these data sets the task is to map faculty members X  homepages to their records in DBLP and movie Web pages to their record in IMDB.
One of the goals of this section is to compare the expressive power of link paths to the current method which uses only adja-cent links. Therefore, for the first baseline we query Yahoo X  X  Site Explorer Service  X  which returns inbound links to the query page  X  with each destination Web page v  X  V 0 , and we retrieve the first 10 results and extract the corresponding anchor text from the ref-erencing Web page. The resulting 10 anchor texts are ordered by their frequency and mapped to the structured database. The results of this baseline will allow for a comparison between adjacent links and link paths.

The second baseline maps the result of a Google query to the corresponding record in the database.
For all experiments we set K = 10 . The link paths were found between the departments X  homepage and each faculty members X  personal Web page using the K -shortest path and K -shortest loop-less path methods. Likewise, the link paths were found between http://trailers.apple.com and http://www.allmovie.com and each of the movie Web pages also using the K -shortest path and K -shortest loopless path methods. These paths were combined and ranked as described in Section 2 and mapped to appropriate column using the strict and approximate matching methods from Section 3.
Table 1 shows the results of the baseline algorithms. As we alluded to earlier, we find that the MRR results from the Google baseline are comparable to (and in some instances better than) the results from the TREC results (now shown). Based on this obser-vation we believe that the precision at 1 is a good baseline for the mapping task.
 Table 2 shows the results for the variations of our algorithm. The first four columns show the the results for the strict matching
Rankings from US News 2010 method on both the K -shortest path and K -shortest loopless path algorithms. These results show that, even under the strict match-ing conditions, the mappings are very precise but have low recall. Moreover, the overall accuracy under strict conditions confirms our assertion that anchor texts often represent succinct, canonical rep-resentations of the referenced Web page.

In terms of recall, our algorithm will always return a result when there is no threshold to limit the string distance so recall statistics are not necessary. For tasks which require a higher level of preci-sion a lower threshold (  X  ) may be appropriate. Figure 2 shows how the precision and recall of the DBLP data set fluctuate as  X  varies between 0 and 1.

The graph in Figure 2 confirms our assertion that lower thresh-olds will result in high precision and lower recall. We also see that at its worst the recall is relatively low, but the lowest precision score is not too low. For our purposes we prefer  X  = 1 because the small drop in precision is worth the large gain in recall.
In conclusion, this paper proposes a new information manage-ment task: the automatic mapping of Web pages to their corre-sponding records in a structured database. We show that sorted link paths can be used to achieve this mapping, and we perform experi-ments on two large real-world data sets that show the effectiveness of our algorithm. Finally, we demonstrate that our approach is able to generate an accurate mapping across two large and varied data sets. Furthermore, we believe that our method does generalize to other data sets, and we encourage the community to explore this approach on more data sets.

Linking unstructured data with the records in structured database has become a popular task because researchers have recognized that there is a greater use for information when it is available in a struc-tured or otherwise organized form. Yet most of the current work has revolved around extracting records from a Web page or ranking documents for retrieval. While these are important tasks, we argue that there is a greater need for a framework which employs struc-tured data to enhance unstructured data, and conversely, employs unstructured data to improve the expressiveness of structured data. We believe that the mapping algorithm proposed in this paper is a promising step towards the development such a framework.
The task of mapping Web pages to database records is not an end in itself, but rather an intermediary step to a number of other tasks. For instance, unstructured data (from a Web page) can be used to aid in the retrieval of semantically related database records, or to extend the database schema, etc. Alternatively, structured data can Figure 2: Precision and Recall tradeoff for DBLP data with K -shortest loopless paths as  X  varies from 0 to 1. be used in unstructured tasks in order to categorize search results or improve ranking algorithms, etc.

In terms of the specific link path method, we do not argue that our approach is optimal. There may indeed exist extensions to our method that improve the mapping performance. For example, by modifying the link path weighting algorithm to apply a higher weight to anchor texts closer to the destination page may be more effective than our ranking approach.

Otherwise, the use of title text, URL text, and page content infor-mation may be used to improve the overall accuracy of the mapping algorithm. We intend to continue this line of research, and expect to develop a mutually enhancing Web-database system based on this framework in the near future.
We would like to thank Jordan Weninger for her help retrieving and labeling data. This work is funded by an NDSEG Fellowship to the first author. The second and fourth authors are supported by both the project  X  X nowledge Discovery in Relation Domains X  funded by the University of Bari  X  X ldo Moro X  and the Strategic Project DIPIS (Distributed Production as Innovative Systems) funded by Apulian Region. [1] S. Brin and L. Page. The anatomy of a large-scale [2] N. Craswell and D. Hawking. Overview of the trec-2002 web [3] N. Craswell, D. Hawking, and S. Robertson. Effective site [4] O. A. McBryan. Genvl and wwww: tools for taming the web. [5] W. Xi, E. A. Fox, R. P. Tan, and J. Shu. Machine learning [6] Y. Yen. Finding the k shortest loopless paths in a network.
