 1. Introduction
The vast amount of information currently available has fuelled research into systems and tools capable of managing such extraction [8] , text classification [38] , or automatic rating prediction [36] .
 systems for indexing, searching and retrieving information without having to process the whole document. Moreover, another drugs, novel treatments, etc.

However, the process of TS, and in particular, the automatic generation of abstracts, is still very challenging. The relevant and the wrong link between sentences.
 research paper abstracts in the biomedical domain. In particular, we develop a TS system: ( that were developed for addressing specific applications. In Section 3 , our proposed TS system, human abstracts of the research papers on the one hand, and we outline the experiments performed, on the other hand. Then, the the conclusions of the paper together with the future work are outlined in Section 6 . 2. Related work
In this section, we explain existing TS systems that produce summaries automatically, as well as previous work on different etc.).

Regarding the TS systems, we can find a wide range of them for generating different types of summaries. One of the most cited records [28] .
 summaries, or MUSE  X  MUltilingual Sentence Extractor [21] , that employs language-independent techniques for generating summaries in English and Hebrew.
 use opinion mining techniques for extracting opinion features from customer reviews and then summarizing them. Sauper and abstracts are used, on the one hand, to determine the information to include in a summary, and on the other hand, to generate  X  date/place of birth) from others that do not.
 Natural Language Generation (NLG) has been also applied for adding new vocabulary and language structures in summaries. NLG, in order to generate weather forecast reports automatically.
 summaries from this input information, in Qazvinian and Radev [30] citations are analyzed to produce a single-document summary from scientific articles. The final objective is to generate summaries about a specific topic.
The generation of technical surveys has also been addressed in the recent years. In Mohammad et al. [24] citations are used to and analyzed different already existing summarization systems to create such surveys, such as LexRank [11], Trimmer [44],or
C-RR and C-LexRank [30]. Among the conclusions drawn from the experiments, it was shown that multi-document technical survey creation benefits considerably from citation texts.
 it contains that could introduce relevant information, such as the document.
 Our contribution with respect to state-of-the-art systems is that the biomedical domain, we do not rely on specific patterns, nor we learn the structure or the content of the document for generating summaries. Moreover, we carry out an analysis with the purpose of determining which approach performs better, not only according to the information contained in summaries, but also, to user's assessment. 3. Text summarization approach: COMPENDIUM In this Section, the two suggested approaches that COMPENDIUM attempt to improve the final summaries by integrating abstractive techniques, leading to 3.1. COMPENDIUM E : extractive summarization
For generating extractive summaries, COMPENDIUM relies on four main stages, as it can be seen in Fig. 2 :  X 
Such analysis comprises tokenization, sentence segmentation, part-of-speech tagging, and stop word identification, since stop words will not be taken into consideration for the remaining stages.  X 
Redundancy detection : a Textual Entailment (TE) tool [12] is used to detect and remove repeated information. The main idea different manner, TE has been successfully applied to summarization in previous research [41] .  X  the next stage of the TS process for determining the overall relevance of a sentence.  X  stage previously explained and a cognitive-based feature: the Code Quantity Principle (CQP) [15]. The CQP states that the most on the information detail one wants to provide. Therefore, in order to generate the summary, sentences containing longer noun chances to appear in the final summary.  X 
Summary generation : finally, having computed the score for each sentence, in this last stage of the TS process sentences are ranked according to their relevance and the highest ones are selected and extracted in the same order as they appear in the original document, thus generating an extractive summary, and leading to 3.2.
 COMPENDIUM E  X  A : abstractive-oriented summarization The second type of summaries COMPENDIUM is able to generate is abstractive-oriented summaries, by means of approach, extractive and abstractive techniques are combined in the following manner: we take as a basis the containing information from two individual ones. The main steps involved in this stage are ( Fig. 3 ):  X 
Word graph generation : for generating new sentences, we rely on word graphs adopting a similar approach to the one described where the words represent the nodes of the graph, and the edges are adjacency relationships between two words. The weight of each edge is calculated based on the inverse frequency of co-occurrence of two words and taking also into account the importance of the nodes they link, through the PageRank algorithm [5]. Once the extract is represented as a word graph, a pool first word of each sentence in the extract, in order to cover its whole content. The reason why we used the shortest path is twofold. On the one hand, it allows sentences to be compressed, and on the other hand, we can include more content in the summary, in the case several sentences are fused.  X  some of them may suffer from incompleteness (  X  Therefore the immune system. (e.g. a, the), a preposition (e.g. of), an interrogative word (e.g. who), nor a conjunction (e.g. and).  X 
Given and new information combination : the objective of the last step is to decide which of the new sentences are more the new sentences and the ones that are already in the extract, given that the similarity between them is above a predefined threshold. For this, we use the cosine measure to compute the similarity between two sentences, and a threshold has been the former will be substituted for the latter; otherwise, we take the sentence in the extract. 4. Experimental framework
In this section, we provide a description of the corpus employed ( Subsection 4.1 ), we analyze the abstracts included in the research papers ( Subsection 4.2) and we finally explain the experiments performed ( Subsection 4.3). 4.1. Description of the data set: research articles For our experiments, a set of 50 research articles from a specialized journal of medicine was collected directly from the Web.
Specifically, these articles belonged to the Autoimmunity Reviews journal. of each one, there are also two special sections: one is the into consideration for generating the summaries.

A fragment of an article together with its complete abstract is shown in Tables 1 and 2 , respectively. For clarity reasons we articles were generated by the authors, and therefore, we use them as gold-standard for comparing them with respect to the results obtained by our TS system COMPENDIUM .
 words (minimum = 949, maximum = 4464) and 83 sentences (minim um = 44, maximum = 151), whereas the abstracts only 162 words (minimum = 64, maximum = 341) and 6 sentences (minimum = 2, maximum = 15). This means that the compression ratio articles are very long compared to the length of the abstracts. 4.2. Analysis of the model summaries to quantify and understand their nature with respect to the types of summaries
From this analysis, we found out that 82% of the abstracts had an abstractive nature, and they were created by identifying of the content of the abstract was extracted directly from the text of the article.
 to sentences 1 and 78 in the article) and the remaining sentences (sentences 3 and 4 ) were generated from relevant pieces of other hand, sentence 4 has been created by the author and consequently, it does not have a direct correspondence to any other
Therefore, as a result of this analysis, one may think that a TS approach that combines extractive with abstractive techniques together can be more appropriate to tackle this task. In this article, we analyze two types of summaries generated by extractive ( COMPENDIUM E ) and abstractive-oriented ( COMPENDIUM extractive and abstractive information. 4.3. Experiments
COMPENDIUM is employed for producing generic summaries of the data set previously explained. In particular, we generate two kinds of summaries: i) extractive summaries with COMPENDIUM we can analyze on the one hand if COMPENDIUM is capable of determining the most relevant information, and on the other hand, biomedical domain, articles usually contain an abstract no longer than 250 words. Since it was previously analyzed that the COMPENDIUM , since it is even shorter than the standard length for abstracts (i.e., 250 words).
It is worth mentioning that for generating the summaries neither the keywords of the original article nor the information in the titles or in the abstract have been taken into consideration. Moreover, before passing the articles through entries, keywords, figures and tables are removed.
 Table 4 shows two examples of the types of summaries generated with for these summaries is the article showed in Tables 1 and 3 .

As it can be seen, the resulting summary for COMPENDIUM E  X  A and 8 ), whereas others have been compressed or merged (e.g., 1 , 3 , 4 and 5 ). 5. Evaluation and discussion
The aim of this section is to explain the evaluation performed and show the results obtained together with a discussion. For evaluating the summaries generated by COMPENDIUM , two types of evaluation were conducted: quantitative ( Subsection 5.1) and qualitative ( Subsection 5.2).

The goal of the quantitative evaluation is to assess whether the automatic summaries contain the main information from the articles and we compare them with the ones generated by COMPENDIUM evaluating the information contained in the summaries, we also want to measure the user satisfaction towards the automatic summaries, thus carrying out a qualitative evaluation. Next, each of these evaluations is explained. 5.1. Quantitative evaluation the articles are representative of the main contents of the whole document; and ii) they have been manually generated, and evaluation of summaries. The most common ROUGE metrics are : ROUGE-1 and ROUGE-2, which compute the number of overlapping unigrams and bigrams, respectively; ROUGE-L, which calculates the longest common subsequence between two summaries; and summarizer would perform, we also use MS-Word Summarizer 2007 statistical significances according to a t -test performed (p As it can be seen, our both TS approaches (extractive and abstractive, with comparable with respect to the state-of-the-art TS tool (i.e., MS-Word 2007 Summarizer). Regarding summaries, we rely on the sentences detected as important in the relevance detection stage, and we compress or merge some recall value will never be higher than it is for COMPENDIUM included in the extract, because of summary length restrictions. Regarding for most of the metrics, except for ROUGE-L; however, there are no statistical differences between them, except for ROUGE-1.
Although from the results obtained we show that COMPENDIUM from documents, we need to evaluate the generated summaries with respect to other criteria, in order to confirm whether these summaries are good.

As a consequence, for evaluating also the information contained in the summaries, we relied on the keywords provided with keywords represent essential concepts of the document, if summaries included them, this would mean that they would capture the important information. Therefore, for this experiment, we took into account the keywords of each article and we analyzed whether they appeared or not in the summaries (the original abstract, and the summaries generated by
COMPENDIUM E  X  A ). For each article, the author assigned 4 keywords on average (minimum = 2, maximum = 9). The preliminary include any keyword at all.

In light of these results, we decided to expand the keywords with equivalent concepts, by using the MeSH thesaurus, analyze to what extent the summaries contained also synonyms of the keywords or equivalent terms. Again, we first analyzed the original abstracts, and we found out that, as in the previous analysis, most of the expanded keywords were not present in the original abstracts, nor in the summaries generated by COMPENDIUM globally describe the content of the article, and they have to be selected from a normalized set of keywords (i.e., MeSH). It of using synonyms of the terms, authors tend to use their own abbreviations, which do not appear in the aforementioned not appear in MeSH). This strategy helps them to ensure that the abstract and the text do not surpass the maximum number of words allowed with respect to the journal requirements.
 we measure the user satisfaction of the generated summaries with respect to different aspects, including issues regarding the most important topics stated in the summaries, so that we can confirm the appropriateness of the summaries produced using COMPENDIUM in its extractive and abstractive variants ( COMPENDIUM detail the qualitative evaluation performed. 5.2. Qualitative evaluation In this evaluation, we aim at assessing the user satisfaction with respect to the generated summaries with independently the content of the extractive and abstractive-oriented summaries ( with respect to the human abstracts and the text of the articles.

The evaluation focused on three questions (Q1: The summary reflects the most important issues of the document ; Q2: The and 5 = strongly agree).

The first question (Q1) evaluates how informative a summary is, i.e., whether the summary contains relevant information or and check if it appears in the summary. The second question (Q2) allows us to determine to what extent the automatic summaries automatic summaries are good enough to substitute the original abstracts. Moreover, by rating the summaries, we can also analyze if the users prefer extractive or abstractive summaries, thus determining which approach would be more appropriate.
In Table 6 , the statistics of the results for each question and each TS approach are shown. The best assessment is obtained when using abstractive-oriented summaries generated by compendium
It is also worth noting the values for the mode in both TS approaches. This value shows which value of the scale appears more frequently. Concerning this, we can observe that for all the questions the most frequent value for
COMPENDIUM E is 2 for Q1, and 1 for Q2 and Q3. This means that most of the users classified the abstractive-oriented summaries (
In this sense, in Table 7 we can observe that the percentage of summaries evaluated as 36% and 28%, for questions Q1, Q2 and Q3, respectively) increases compared to the accumulated percentage obtained with
COMPENDIUM E for the criteria  X  Agree  X  and  X  Strongly Agree higher satisfaction towards the summaries generated with COMPENDIUM respect to the ones obtained with COMPENDIUM E according to a Chi-square test ( = 35.390, p = .004 for each of the questions, respectively). This means that according to the results obtained when assessing the user satisfaction, summaries generated with COMPENDIUM and they provided an overview of the article. In addition, these summaries were good enough for serving as a surrogate of the abstract written by the authors. 6. Conclusion and future work
In this paper we presented COMPENDIUM , a text summarization system applied to the generation of abstracts of research papers for the biomedical domain. In particular, two types of generic summaries were produced: extractive and abstractive-oriented, with the corresponding variants of COMPENDIUM : COMPENDIUM and extracted the most relevant sentences, whilst for the abstractive-oriented one, we proposed a novel approach, which combined extractive and abstractive techniques, by incorporating an information compression and fusion stage once the most important content was identified.

With the aim of determining if COMPENDIUM was able to generate good summaries, as well as studying which approach should identify the relevant information. On the other hand, the qualitative evaluation was conducted by means of a user satisfaction study where real users rated the generated summaries according to three criteria: their topics, content, and suitability for substituting the original abstracts in the research articles.

Although the results concerning the quantitative evaluation benefited the extractive summaries, showing that the summaries summaries produced with the extractive approach ( COMPENDIUM towards both kind of summaries, the abstractive-oriented summaries we can draw two main conclusions: i) COMPENDIUM is useful for producing automatic summaries of biomedical research papers, since both TS approaches are able to keep the most important information; ii) abstractive-oriented summaries generated with COMPENDIUM E  X  A are better from a human perspective. Therefore, we showed the appropriateness of well as our proposed strategy for facing abstractive summarization.

In the future, we plan to analyze other variants of the proposed approach for building abstracts, such as taking the source document as a starting point instead of the extractive summary. Moreover, focusing also in the biomedical domain, we want to periodically a brief summary of recent biomedical articles, new treatments, drugs, etc.
 Acknowledgment
This research was partially supported by the FPI grant (BES-2007-16268) and the project grants TEXT-MESS (TIN2006-15265-C06-01), TEXT-MESS 2.0 (TIN2009-13391-C04) and LEGOLANG (TIN2012-31224) from the Spanish Government.
It has been also funded by the Valencian Government (grant no. PROMETEO/2009/119 and ACOMP/2011/001). The authors would like to thank Ester Boldrini, Paloma Moreda, Isabel Moreno, Helena Burruezo, Jes X s Hermida, Jorge Crua X es, Fernando Peregrino, H X ctor Llorens, Felipe Sell X s, and Rub X n Izquierdo for their help in the manual evaluation of the summaries.
References
