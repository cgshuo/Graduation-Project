 The rapid progress of information and communication technologies not only modernizes people X  X  lives, but also create s great opportunities and challenges for urban policy and management. An important part of urban management is mon-itoring and solving millions of urban events everyday, e.g. traffic accident, noise nuisance, etc. This problem is increasingly concerned by city administrators, es-pecially major cities. They are calling for technologies that can automatically detect and monitor the citywide events and the distribution of events in different places.

While monitoring urban events is very difficult, some ubiquitous data sources indicating urban events are already available. For example, many cities have operated a hotline platform that allows people to make a phone call to tell about what they feel annoyed by. The phone reco rds are actually a result of  X  X uman as a sensor X  and  X  X rowd sensing X , containing rich human intelligence that can help detect urban events [1,2], especially em ergency events [3,4]. A hotline receives a lot of phone calls everyday and many cit izens tell about the same event. It is heavy work to manually find out how many events and what events these records describe. From the perspective o f urban management, urban alerts must be detected early, preferably before th ey explode, and therefore the number of records involved may be small at the time of detection. That makes the task harder than standard topic detection, mainly due to sparsity issues. In this study, we present the event detection approach of our system, Urban-EMS ( Urban Events Monitoring System ). Generally, given a set of records, we need to identify their events and for each record, further decide which event it describes. The process of the approach is summarized in Fig. 1. We have modeled the problem as a combination of two tasks: 1. The first is learning phone record similarity: we use all types of features to learn a supervised classifier that takes two records as input and decides if the records describe the same event. 2. The second is applying an improved version of Affinity Propagation cluster-ing algorithm that uses the positive confidence probability of the classifier above as a similarity measure between records a nd generates clusters as urban events.
Finally, the events are dispatched to diff erent departments and their feedbacks are used to re-train the classifiers.

We detail our approach in Section 2, describe and discuss the result of our experimentation in Section 3, review r elated work in Section 4, and summarize our study and discuss future work in Section 5. 2.1 Modeling Similarity as a Classification Task For our problem, many events only consist of a small number of phone records. Pure unsupervised approaches often mis-detect them. So following the method-ology proposed in [5,6] for a different clustering problem, we first model our problem as a binary classification task: given a pair of records r 1 and r 2 ,the system must decide whether they belong to the same event (true) or not (false). Each pair of records is represented as a set of features F ( r i ,r j ), which is used to feed a classification model CM ( r i ,r j ).
 CM ( r i ,r j )is SVM with confidence probability estimation and default parameter settings in this paper. Once we have learn ed to classify records pairs, we take the positive classification confidence probability as a similarity measure. later. All similarities S i,j between each pair of records f orm the similarity matrix S , which is then used by our proposed Improved Affinity Propagation ( IAP ) clustering algorithm to identify urban events.

Each raw phone record r is a four-tuple ( content,time,phone,category ), where content is the content of the phone call recorded by telephonists, time is the time when the phone call is received, phone is the phone number, category is the category selected by telepho nists. Note that the categories are predefined, e.g. traffic, pollution, etc. An instance is shown as follows:
In our study we consider a total of 13 features that capture many characteris-tics of phone records. Features can be divided in five families: Property Features ( F PF ( r i ,r j )), Term Position-based Features ( F TPF ( r i ,r j )), Bag-of-Word-based Features ( F BWF ( r i ,r j )), Knowledge-based Similarity Features ( F KSF ( r i ,r j )) and Neighbor-based Similarity Features ( F NSF ( r i ,r j )).
 Property Features ( F PF ( r i ,r j )). The property features describe the prop-erty similarity of two records, e. g. category, address, time, etc.

Given a record, we first extract its a ddress descriptions if exists. Then we submit extracted addres s descriptions to an online coordinate converter 1 to get their GPSs. Finally, the centroid of these GPSs is considered as the GPS of the record. Specifically, we adopt three approaches for address extraction, namely Dictionary-based Extraction , Regex-based Extraction ,and Named Entity Recognizer-based Extraction .For Dictionary-based Extraction ,we compare each segmented phase with Chinese dictionaries 2 for place names. For Regex-based Extraction , we define several Regex (Regular Expression) patterns to extract address d escriptions, e.g.  X  X 0-9 \ u4E00-\ u9FA5]*?(square | viaduct | rode | street | alley) X . For Named Entity Recognizer-based Extraction ,we use the Chinese NER 3 tool provided by Stanford NLP.

Geographical Distance Feature ( f GDF ) measures the geographical distance of two records based on the obtained GPSs 4 . lon ( r ) is the longitude of r ; 6378 . 137 is the radius of the earth in kilometers. Note that f GDF is set an extreme value when GPS is not available for some records.

The other three property features are: Time Gap Feature ( f TGF )measures the time distance of two record s in seconds. Category Feature ( f CF )measures the category consistency of two records. The existing category system of Urban-EMS is a tree structure. So f CF is defined as the maximum category level that both records belong to. Person Feature ( f PF ) indicates whether the records are from the same person. PF = 1 if they are, 0 if unknown, or  X  1otherwise. Term Position-based Features ( F TPF ( r i ,r j )). The first Term Position-Based Feature is called Term Match Feature ( f TMF ). where r p i represents the term at the p -th position of record r i , Pos ( r j ,r p i )is the set of all positions of record r j where the term is r p i . The more words two records share, the higher f TMF is. The more similar word order also indicates higher f TMF .

The other three Term Position-based Features are: Longest Common Subse-quence Feature ( f LCSeqF ) measures the similarity of two records by finding the longest common subsequence. Longest Common Substring Feature ( f LCStrF ) measures the similarity of two records by finding the longest common substring. Levenshtein Distance Feature ( f LDF ) measures the edit distance between two sequences. Informally, the Levenshtein d istance between two records is the min-imum number of single-term edits (i.e. insertions, deletions or substitutions) required to change one record into the other.
 Bag-of-Word-Based Features ( F BWF ( r i ,r j )). The first Bag-of-Word-based Feature, Jaccard Similarity Feature ( f JSF ), measures the similarity of two records by Jaccard metric. where T ( r )isthetermsetofrecord r .

Another Bag-of-Word-based Feature, Cosine Similarity Feature ( f CSF ), mea-sures the similarity of two records by Cosine metric. where V ( r ) is the term vector of record r .
 Knowledge-Based Similarity Feature ( F KSF ( r i ,r j )). HowNet-based Sim-ilarity Feature ( f HSF ) measures the semantic similarity of two records based on an extra Chinese knowledge base HowNet 5 . For two records r i and r j , suppose that | r i | X | r j | ,wehave wordSim is the semantic similarity of two words computed based on HowNet [7]. Records similar to each other generally tend to have same special words, or extensively high words semantic similarity. To calculate the f HSF similarity between r i and r j ,wefirstcalculate wordSim on each pair of words. Then we greedily select | r i | pairs of words without repetition, which maximize the sum of their words X  similarity across these two record strings. Note that p  X  q is a one-to-one mapping, i.e. a q -th word of r j can only be mapped to one p -th word of r i . Finally, to normalize this feature, we divide it by | r i | . Neighbor-Based Similarity Feature ( F NSF ( r i ,r j )). Neighbor-based Co-sine Similarity Feature ( f NCSF ) measures the semantic similarity by computing Cosine of the expanded term vectors. where V n ( r ) is the expanded term vector of record r by adding its n neighbors. In this paper, the neighbors are top n = 5 search results w ith Lucene Vector Space Model.
Symmetric KL-divergence Feature ( f SKLF ) measures the semantic similarity by computing symmetric KL-divergence between language models of the ex-panded records. where r n is the expanded record of r by adding its n neighbors. 2.2 Improved Affinity Propagation ( IAP ) Next, we detail our improved version of a famous clustering approach, Affinity Propagation ( AP ) [8]. Specifically, let PR = { r 1 ,r 2 , ..., r N } be a set of phone records. Let  X  ( i ) associate to each r i the index of its nearest exemplar (Each ex-emplar corresponds to a cluster). Then the goal of Improved Affinity Propagation ( IAP ) is to find the mapping  X  = {  X  ( i ) | r i  X  X R} maximizing the expectation:
E (  X  ) PR} is the cluster whose exemplar is  X  ( i ). PR k ( C 10 indicates how well r  X  ( i ) is suited to be the exemplar for r i . The second part in Formula 10 expresses that if r i is selected as an exemplar by some records, it otherwise.

In order to detail the idea of IAP , we explain IAP with an election voting process. Specifically, when choosing an exemplar (corresponding to a cluster) for record r i , we consider two aspects of v otes balanced by a parameter  X  . The first aspect is S i, X  ( i ) , which is from the current exemplar  X  ( i ). The second aspect current cluster C  X  ( i ) . In this paper, the k representatives are k records with increase the robustness so as to alleviate the situation where S i, X  ( i ) is incorrect or inaccurate. Also note that Formula 10 does not directly specify the number of exemplars (corresponding to the number of clusters) to be found. Similar to raw AP , it takes as input a real number S i,i for each record r i so that records with larger values are more likely to be chosen as exemplars of their clusters. Usually, S i,i is set to the median value of S .

The resolution of the optimization problem defined by Formula 10 can be achieved by a Message Passing Algorithm [8], considering two types of mes-sages: The  X  X esponsibility similarity X   X  i,j , sent from record r i to candidate ex-emplar r j , reflects the accumulated similarity for how well-suited r j is to serve as the exemplar for r i , taking into account other potential exemplars for r i .The  X  X vailability similarity X   X  i,j , sent from candidate exemplar record r j to record r , reflects the accumulated similarity for how appropriate it would be for r i to choose r j as its exemplar, taking into account the support from other records that r j should be an exemplar.
 Algorithm 1. Message Passing Algorithm For IAP .

All availability and responsibility similarity messages  X  i,j and  X  i,j are set to 0 initially. Their values are iteratively updated according to:
The index of exemplar  X  ( i ) associated to r i is defined as:
The pseudo code is shown in Algorithm 1. The algorithm stops after a maximal number of iterations or when the exemplars do not change for a given number of iterations. 3.1 Evaluation of Event Detection Approach Experimental Setup. We evaluate our event detection approach with one month public phone records from a mayor hotline 6 . We adopt two best ap-proaches from [14] as baselines, which use Affinity Propagation clustering with Cosine similarity and Jaccard similarity respectively. Five groups of measures are used which are summarized in Table 1. For all measures, larger values mean better results.
 Model Performance Comparison. The comparison of our event detection approach with baselines on real public phone records dataset is summarized in Table 2. Generally, our approaches especially IAP CLS achieve great improve-ment. As we can see, the improvement comes from two aspects. First, the pro-posed IAP greatly improves the clustering pr ocess, which reflects in comparison of IAP Cos with AP Cos , IAP Jac with AP Jac and IAP CLS with AP CLS . Second, the proposed features and supervised learning approach can approximate the real similarity between two records more accura tely, which reflects in comparison of IAP Linear with IAP CLS . This indicates that previous annotations can be used to learn better similarity functions compared with heuristical or unsupervised approaches. We also analyze the phenomenon of the reduced measures, i.e. P-P, B-R and S-IP. The reason is that baselines tend to split large clusters into many small clusters, which results in abnorm al improvement of the three measures. For example, AP Cos achieves the best in terms of Precision (P-P). However, it X  X  Recall (P-R) is very low, which leads to a 31.7% decrease in terms of F1-measure compared with our model IAP CLS .
 Feature Effectiveness. Table 3 gives the performance of different feature com-binations. Unsurprisingly, combining all features gives the best choice with an accuracy of 84.35%. The accuracy is not very high which indicates that the prob-lem is challenging. In terms of single feature, F PF is the most effective. F PF are some unique features for our data compared with many other short text datasets. Besides, though effectiveness of different features is varied, however drop of any feature causes an accuracy decline, which is significant according to paired t-test ( p-value &lt; 0.05). This means all our proposed features are useful. 3.2 Evaluation of IAP : Improved Affinity Propagation Experimental Setup. The improvement of IAP on our dataset is significant. We wonder whether IAP is still effective on standard clustering datasets. So we further evaluate the performance of IAP algorithm with three standard datasets for clustering test, Iris 7 , Wine 8 and Zoo 9 .Theraw AP is adopted as the baseline. The same measures summarized in Table 1 are adopted.
 Model Performance Comparison. The comparison of raw AP and IAP is summarized in Table 4. We report experiments with Cosine similarity only, other metrics have similar results e.g. Euclidean distance, etc. We can see that great improvement is achieved by IAP in terms of almost all measures, especially on Iris dataset. The most possible reason is, the additional consideration of representatives (corresponding to the second part of Formula 10) in the current cluster make IAP more robust. In another word, when deciding the exemplar is alleviated by consideration of additional representatives during the clustering to split large clusters. This can be confirmed by visual comparison of AP and IAP clustering results (especially the circled ones) shown in Fig. 2. We further analyze the reduced measures in Table 4. Take P-P and P-R on Iris dataset for example, the slight reduction of P-P (precision) results in great improvement of P-R (recall). The same applies to the other three pairs.

We also analyze the parameter sensitiveness of IAP . The results are shown in Fig. 3. On all three standard datasets,  X  is not sensitive for all tried values basically and k is also not sensitive for a wide range of values. Note that some measures decrease for the la st two points because we tried k =25and k = 30. The results mean that when applying IAP we do not need to worry about spend much time on tuning the parameters. Though not sensitive, the choice of parameter values indeed has a little influence on clustering results. Generally,  X   X  (0 . 2 , 0 . 5) and k  X  (5 , 20) are better choices. Recent event detection techniques include wave analysis [15], topic model [16], hierarchical dirichlet process (HDP) [17], text clustering [18] and so on [19].
AlSumait et al. [20] presented online topic model (OLDA), a topic model that automatically captures the thematic patterns and identifies emerging top-ics of text streams and their changes over time. Wang et al. [21] proposed a mixture Gaussian model for bursty word extraction in Twitter and then em-ployed a novel time-dependent HDP model for new topic detection. Sakaki et al. [22] first devised a classifier of tw eets based on features such as the key-words in a tweet, the number of words, and their context. Then, they produced a probabilistic spatiotemporal model for the target event that can find the cen-ter and the trajectory of the event location. Becker et al. [23] focused on online identification of real-world event and its associated Twitter messages using an online clustering technique, which continuously clusters similar tweets and then classifies the clusters content into real-world events or nonevents. Chen et al. [24] presented Non-Parametric Heterogeneous Graph Scan (NPHGS), a new ap-proach that considers the entire heterogeneous network for event detection: they first modeled the network as a sensor network. Then, they efficiently maximized a nonparametric scan statistic over connected subgraphs to identify the most anomalous network clusters. Rozenshtein et al. [25] formalized the problem of event detection using two graph-theoreti c formulations. The first one captures the compactness of an event using the sum of distances among all pairs of the event nodes. The second formulation captures compactness using a minimum-distance tree.

Although there are many researches investigating event detection, however most of them are bursty based event detect ion, i.e. they only focus on identifying events major from data. In addition, some are not suitable for the short text characteristics of our problem (A record is usually no more than three sentences). Besides, some important application dependent features are not considered by existing approaches, e.g. geographical features, time features, etc. In this paper, we introduce the event detection algorithm in our Urban-EMS system and demonstrate its e ffectiveness through extensive experiments. Great improvement is achieved compared with baseline approaches. In future work, we plan to further improve it by defining more features, e.g. language model features, syntax features, etc. Beside s, further work is necessary on issues like streaming clustering, automatic events description, etc.

