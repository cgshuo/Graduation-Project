 Trust plays important roles in diverse decentralized envi-ronments, including our society at large. Computational trust models help to, for instance, guide users X  judgements in online auction sites about other users; or determine qual-ity of contributions in web 2.0 sites. Most of the existing trust models, however, require historical information about past behavior of a specific agent being evaluated  X  informa-tion that is not always available. In contrast, in real life interactions among users, i n order to make the first guess about the trustworthiness of a stranger, we commonly use our  X  X nstinct X   X  essentially st ereotypes developed from our past interactions with  X  X imilar X  people.

We propose StereoTrust , a computational trust model in-spired by real life stereotypes. A user forms stereotypes using her previous transactions with other agents. A stereo-type contains certain features of agents and an expected out-come of the transaction. These features can be taken from agents X  profile information, or agents X  observed behavior in the system. When facing a stranger, the stereotypes match-ing stranger X  X  profile are aggregated to derive his expected trust. Additionally, when some information about stranger X  X  previous transactions is available, StereoTrust uses it to re-fine the stereotype matching.

According to our experiments, StereoTrust compares fa-vorably with existing trust models that use different kind of information and more complete historical information. Moreover, because evaluation is done according to user X  X  personal stereotypes, the system is completely distributed and the result obtained is personalized.

StereoTrust can be used as a complimentary mechanism to provide the initial trust value for a stranger, especially when there is no trusted, common third parties.
 H.3.3 [ Information Systems ]: Information Search and Retr-ieval  X  Clustering; H.2.0 [ Information Systems ]: General  X  Security, integrity, and protection Algorithms, Performance, Theory stereotypes, trust model, group, reputation
Trust is an important abstraction used in diverse scenar-ios including e-commence, distributed and peer-to-peer sys-tems, grid systems and dynamic collaborative systems. By the very nature of the large scale and openness of these sys-tems, one is often required to interact with other agents with whom there are few or no shared past interactions. To as-sess the risk of such interactions and to determine whether an unknown agent is worthy of engagement, these systems usually offer some trust-management mechanisms.

If a user has sufficient direct experience with an agent, the agent X  X  future performance can be reliably predicted [1]. However, in large-scale environments, direct experience is often not sufficient or even non-existent. In this case, pre-diction is based on user X  X   X  X ndirect experience X   X  opinions obtained from other agents [11, 16, 2] (also known as tar-get agent X  X  reputation ). Simple aggregations (like a seller X  X  ranking on eBay) rely on access to global information like the history of the agent X  X  behavior. Alternatively, transitive trust models [2, 9] (or web of trust models) build chains of trust relationships between the user and the target agent. The basic idea is that if A trusts B and B trusts C ,then A can derive C  X  X  trust using B  X  X  referral on C and A  X  X  trust in B . In a distributed system, such chains are not trivial to discover. Moreover, they suffer inaccurate reports and  X  X eakest link X  [6].

All the mentioned approaches aggregate the same kind of information  X  agents X  impressions about the transactions. At the same time, most of the systems provide a vast con-text for each transaction, including transaction X  X  type, cat-egory, or participant X  X  profile. We were curious to see how accurately we could predict trust using only (or  X  also) the context. Thus, we did not want to propose a better mecha-nism using the same information, but rather a complement-ing alternative when information used by existing models is unavailable.

The result of our work is StereoTrust, a trust model that estimates a target agent X  X  trus t using stereotypes learned from interactions with other agents. Our work is inspired by [14, 15], which studies the relation between the reputation of a company and its employees: The company X  X  reputation can be modeled as an aggregate of employees X  reputations and it can suggest a prior estimate for employee X  X  reputa-tion. In StereoTrust, users form stereotypes by aggregating information from their interaction partners X  profile pages, or the context of the transaction. Example stereotypes are  X  X gents selling mobile phones are less honest than others X  or  X  X gents living in small towns are more honest X . To build stereotypes, a user has to group other agents ( X  X gents sell-ing mobile phones X  or  X  X gents living in small towns X ). These groups do not have to be mutually exclusive. Then, when facing a new agent, the user estimates the agent X  X  trust using stereotypes on groups to which the new agent belongs ( X  X oes she sell mobile phones? X ,  X  X oes she live in a small town? X ).
StereoTrust has its own weaknesses and limitations. For instance, not in all circumstances a user can determine the profile of an agent. Similarly, a new user cannot form a decent local stereotype, as she does not have enough prior interactions.

However, we think that Stere oTrust is interesting both academically and in practice. Academically, as it emulates a real world human behavior by using stereotypes for a first guess about a stranger. In practice, as, firstly, Ste-reoTrust X  X  predictions are personalized; and, secondly, Ste-reoTrust works when global information (required by other models) is not available, inaccurate, or tampered. But when global information is available, StereoTrust can still be used as a mechanism to enhance the prediction (thus a dual con-text of the word  X  X tereo X ). Our experiments show that such an augmentation, called d-StereoTrust, significantly improves the accuracy.

Notice that StereoTrust is generic, and its use of abstract group definitions allow it to be used in very different kinds of applications. Also, the notion of trust itself can be easily adapted to different contexts. In this paper, we adopt the definition from [7]:  X  Trust (or, symmetrically, distrust) is a particular level of the subjective probability with which an agent assesses that another agent or group of agents will perform a particular action, both before he can monitor such action (or independently of his capacity ever to be able to monitor or enforce it) and in a context in which it affects his own action  X .

For an example application, consider judging quality of product reviews from a web site (such as Epinions.com). In such community, users write reviews for products, struc-tured into different categories (e.g., books, cars, music). These reviews are later ranked by other users. Normally, each reviewer has some categories in which she is an  X  X xpert X  (like jazz albums for a jazz fan). The reviewer is more likely to provide high quality reviews for products in these famil-iar categories. Of course, users may also write reviews for products from other categories, but their quality might be not so high, because of, e.g., insufficient background knowl-edge.  X  X astery X  can be correlated between categories. For instance, audiophiles (people who use top-end music equip-ment) usually know how to appreciate music, and thus, if they review a jazz album, the review is more likely to be in-depth. The correlation might be also negative, as we do not expect an insightful review of a jazz album from, e.g., a game boy reviewer. When facing an unrated review of a jazz al-bum by an unknown contributor, we can use the information on contributor X  X  past categories (game-boy fan or an audio-phile?) and our stereotypes ( X  X oisy X  gamers vs. insightful audiophiles) to estimate the quality of the review. In fact, evaluation of our method on Epinions.com dataset (Section 3) indicates that considering reviewer X  X  interests provides a good estimation of the quality of the review.

Consider a very different kind of application, for example, that of a peer-to-peer storage system. If a peer wants to store a new block of data at some peers, it would need to choose a suitable peer to do so. The suitability of a peer may depend on the likelihood that the peer will be available when the data needs to be retrieved (which may depend on its geographic location/time-zone difference), the response time to access the data (which may depend on agreements and infrastructure between ISPs, but the user would need to perceive it by measurements), and so on. Conventional systems design approach models such a scenario as a multi-criterion optimization problem. Such an approach would typically need knowledge about the specific peer in ques-tion -for instance, what time does this peer come online and go offline, what is the end to end latency and available bandwidth (which in practice varies over time, and is hard to measure and anticipate), etc. Applying StereoTrust can provide an alternative systems design 1 , where a peer in, say Tokyo, can think -my past experiences tell me that peers in Beijing and Hong Kong have more common online time with me compared with peers in London and New York. Likewise, peers in New York and Hong Kong with specific IP prefix provide reliable and fast connections, while the others don X  X . Based on such information, the peer would be able to make a first guess that a peer in Hong Kong is likely to be its best bet, if it has to choose between a peer in Hong Kong and London, without needing to know the history of the specific peer in question. Of-course, a second-order op-timization in due course by studying the history of specific peers will be necessary to optimize such a system (as well as refine StereoTrust X  X  accuracy).
We refer to a participant in the system as an agent. We denote by A the set of all agents in the system; and by A the set of agents known to agent a x . An agent can pro-vide services for other agents. A transaction in the system happens when an agent accepts another agent X  X  service. To indicate the quality of a service, an agent can rank the trans-action.  X  a x ,a y denotes the set of transactions between ser-vice provision agent a y and service consumption agent a x  X 
In StereoTrust, a group is a community of agents who show some common properties or behave similarly in cer-tain aspects. Because of the common properties shared by all the members of this group, we believe that the group can act as a collective entity to represent its member agents (to a certain extent). For instance, people may consider a programmer working in a well-known software company as skilled, even if they do not personally know the person. People trust the company based on the quality of produced software, thus they also trust the programmers who create the software. On the other hand, a company employing
We are not claiming that it will provide the best possible system design, but merely that it opens the opportunity for alternative designs. skilled (i.e., trusted) programmers can release high-quality products, and thus gain high reputation. Such interplay be-tween the group X  X  and its members X  reputation is the basis of our work. We derive the trust of an agent according to the trusts of its corresponding groups.
 Groups are defined subjectively by the agent a x that uses StereoTrust to derive trust to other agents. A group G i x set of agents. We denote by G x = { G 1 x ,G 2 x ,...,G n of all groups defined by a x . Based on a x  X  X  previous experi-ence, stereotypes, and any other information, a x formulates grouping functions M x ( G i x ,a ):[ G x , A x ]  X  [0 , 1], that, for each group G i x , map agent a to the probability that a is the member of this group. Thus, in the most general model, a group is a fuzzy set of agents. If M x ( G i x ,a ) = 1, it is certain that a is member of G i x ( a  X  G i x ); if M x ( G i x ,a ) = 0, it is certain that a does not belong to G i x ( a/  X  G i x ).
Note that in this paper we do not discuss how to derive the grouping functions M x ( G i x ,a ). However, during our ex-periments, we propose how to formulate such functions for Epinions.com dataset. For instance, a group can gather all agents responsible for the same type of task; or all agents interested in a certain topic; or all agents living in the same location. Depending on the type of criteria used, groups may overlap (an agent belongs to multiple groups simulta-neously) or be disjoined (each agent belongs only to one group).
A computational trust model models the complex notion of trust by a variable (binary, discrete, continuous, etc.). We assume (after [7]) that trust indicates the probability that an agent will perform a particular, expected action during a transaction. Thus, agent X  X  trust rating is a real number from range [0 , 1], where 0 indicates that the agent is absolutely untrustworthy and 1 indicates that the agent is absolutely trustworthy.

The Beta distribution is commonly used to model un-certainty about probability p of a random event (including agent X  X  reputation [10, 5]). We model a series of transac-tions between a pair of agents as observations of indepen-dent Bernoulli trials. In each trial, the success probability p is modeled by Beta distribution with parameters  X  and  X  (we start with  X  =  X  = 1, that translate into complete un-certainty about the distribution of the parameter, modeled by the uniform distribution: Beta (1 , 1) = U (0 , 1)). After observing s successes in n trials, the posterior density of p is Beta (  X  + s,  X  + n  X  s )[4].

The following definition defines trust function between en-tities (an individual agent or a group) based on a beta func-tion. By E t , we denote the entity participating in the trust calculation.

Definition 1 (Trust Function). Entity E 1 evaluates entity E 2 . From the viewpoint of E 1 , S E 1 ,E 2 and U represent, respectively, the number of successful transactions and unsuccessful transactions between E 1 and E 2 ( S E 1 ,E 2 mapping trust rating p ( 0  X  p  X  1 ) to its probability is de-fined by: T The expected value of the trust function is equal to: E
StereoTrust model uses only agent X  X  local information to derive another agent X  X  trust.

Consider a scenario where an agent a x , a service requestor encounters a potential service provider a y with whom a x no prior experience. We assume that a x can obtain some meta-information about a y ,suchas a y  X  X  interests, location, age etc. Such information as well as other information like a  X  X  previous experience is used by a x to form groups that help derive a y  X  X  trust.

In the basic model, StereoTrust considers only groups for which the membership is certain. We denote these groups the sake of simplifying the notation, we will use G i in place of G i x,y when the context is clear). The trust between a each of these groups G i is derived based on past interactions with agents that belong to G i with certainty. Thus, from the set of all agents a x has previously interacted with ( A x { a 1 ,a 2 ,... } ), a x extracts those that belong to G i (i.e., G { a : M x ( G i ,a )=1 } ). Then, a x counts the total number of successful S a x ,G i transactions with G i by summing up the successful transactions with G i  X  X  members: S a x ,G i a  X  G i S a x ,a . The total number of unsuccessful transactions U x ,G i is computed similarly. Finally, a x uses Eq. (1) to derive G i trust function.

To derive agent X  X  a y trust value, a x combines her trust towards all the groups G x in which a y is a member. The trust is computed as a weighted sum of groups X  trust with weights proportional the fraction of transactions with that group. For group G i , weight factor W i x,y is calculated as a number  X  x,y of a x  X  X  transactions with G i x,y members (  X  i x,y such that a  X  G i x,y ); divided by the total number of a transactions with members of any G x,y group. Obviously, the higher the number of transactions regarding one group, the more likely is a x to interact with agents of this group, so this group contributes more to represent a y  X  X  trust from viewpoint of a x . We define weight factor W i x,y for G i
Using the estimated weights, we combine all group trusts to derive a y  X  X  trust. The process of trust calculation is illus-trated in Figure 1.

We propose two approaches to calculate and combine group trusts.
 In this approach, we first calculate probability density of trust rating for each group using trust function (Eq. (1)) and then combine them to produce a y  X  X  probability density Figure 1: Process of trust calculation. Weighted sum of each group G i  X  X  trust by assigning corre-sponding weight factor W i x,y
Figure 2: Structure of group G i in d-StereoTrust of trust rating TD a x ,a y ( p )usingEq. (3): where S a x ,G i and U a x ,G i are aggregated numbers of success-ful and unsuccessful transactions between a x and members of group G i .
 In this approach, we use only one trust function by setting the parameters, i.e. numbers of corresponding successful and unsuccessful transactions.
 where S a x ,G i and U a x ,G i are defined as in SOF approach.
StereoTrust model simply groups agents based on agents X  profiles. This makes StereoTrust model difficult to accu-rately predict the performance of an agent who behaves quite differently from the other agents of the same groups. For in-stance, consider a case when most of the agents that a x has interacted are honest, while the target agent is malicious. StereoTrust will derive high trust for the malicious target agent.

To improve prediction accuracy, we propose dichotomy-based enhancement of StereoTru st (called d-StereoTrust). The main idea is to construct sub groups that divide agents on a finer level than groups based on agents X  profiles. Ad-ditional information (third party information) is needed in this case. Figure 2 illustrates this kind of grouping.
In d-StereoTrust, each top-level group G i is further di-vided into two sub groups, an honest G i,h and a dishon-est G i,d sub group (hence dichotomy-based). a x assigns an agent a  X  G i to either sub group by analyzing history of her transactions with a . The basic criterion we use is that if a Figure 3: Process of trust calculation. Trusts of honest sub group G i,h and dishonest sub group G i,d of each group G i are firstly combined using closeness and then trusts of all groups G i are combined using weight factor W i x,y to derive target agent X  X  trust. has more successful than unsuccessful transactions with a , a is added to the honest sub group G i,h (and, consequently, in the alternative case a is added to G i,d ). Several alterna-tive criteria are possible, for instance, the average rating of transactions with a .

After dividing a group G i into sub groups ( G i,h , G i,d determining a x  X  X  trust towards the sub groups (computed as in the previous section), d-StereoTrust computes how simi-lar is the target agent a y to the honest and the dishonest sub group. If a y  X  X eems X  more honest, a x  X  X  trust towards aggre-gated G i should reflect more a x  X  X  trust towards the honest sub group G i,h ; similarly, if a y  X  X eems X  more dishonest, the dishonest sub group G i,d should have more impact on a x  X  X  aggregated trust towards G i . This process is illustrated on Figure 3.
 The closeness, which can be measured by membership M  X  represents d or h ) is based on other agents X  opinions about a . Note that we cannot group a y as any other agent a  X  X  x because the grouping described above is based on a x history with a , and, obviously, there are no previous transactions be-tween a x and a y .Thus,both M x ( G i,h ,a y )and M ( G i,d are fuzzy (in [0 , 1]).

Agent a x obtains opinions about a y by requesting a cer-tain metric from other agents. For instance, a x can ask other agent a k about the percentage (denoted by m k,y ) of success-ful transactions she had with a y . a x will seek opinions from honest agents from the group G i,h ; and also from agents in-terested in G i , but with no transactions with a x (based on their profile information, these agents could be classified as members of G i , but they had no transactions with a x ). Ob-viously, the agents who have no transactions with a x may be dishonest thus may provide false reports.

Note that the amount of historic information needed from other agents in d-StereoTrust is a small subset of infor-mation required in models based on feedbacks or transi-tive/Eigentrust. To collect feedbacks or form transitive trust paths, Eigentrust-like algorithms must explore the whole network (take into account all the available historic transac-tions). In contrast, in d-StereoTrust, a x only asks the agents who are interested in the corresponding groups.

Based on all opinions m k,y received, a x computes an ag-gregated opinion m y , which is used to measure the closeness of a y to sub groups as a simple average of m k,y .
To characterize sub groups in a similar way, a x computes similar aggregation of her opinions towards sub groups G i,h and G i,d . Aggregated opinion m h about sub group G i,h equal to the simple average of m x,j (percentage of successful transactions a x had with a j ), where j is the index of agent a  X  G i,h . The aggregated opinion m d about sub group G i,d is derived in the same way.

Finally, the closeness between a y and each of the sub groups is computed as the fraction of the distance between m y from one side and m h and m d from the other:
This procedure has a straightforward interpretation. If other agents have similar opinions about target agent a y a x has about the dishonest sub group, then the target agent is most likely dishonest, so the dishonest sub group trust should more influence a y  X  X  trust in the context of group G Similarly, if other agents have experienced similar perfor-mance with a y as a x with the honest group, then a y is most likely honest.

Note that we do not use the opinions provided by other en-tities to directly calculate a y  X  X  trust. Instead, we use them as metrics to measure closeness between a y and the sub groups. In other words, we do not ask other agents  X  X s a y honest? X , but rather we ask about quantified experience they had with a . This allows us, firstly, to be more objective; and, sec-ondly, to easily extend d-StereoTrust to use multiple metrics (and to combine them with, e.g., Euclidean distance). Simu-lation results show that d-Ste reoTrust derived trust is more accurate than that is derived directly using others X  opinions.
Also note that when other agents X  opinions are not avail-able, d-StereoTrust model degrades to StereoTrust model.
After calculating closeness, we combine groups X  trusts to derive a y  X  X  trust. Similarly to the original StereoTrust, there are two approaches to combine various trust sources. Using Eq. (1)(3)(6) and (7) we have probability density of target agent ( a y ) X  X  trust rating TD a x ,a y ( x ): gated numbers of successful and unsuccessful transactions of each member of G i  X  X  sub group G i,h / G i,d from viewpoint of agent a x .
 Using Eq. (1)(3)(6) and (7) we have probability density of agent a y  X  X  trust rating TD a x ,a y ( x ): M meanings with that in SOF approach.
In this section, we conduct experiments to evaluate the performance of (d-)StereoTru st. We first discuss methodol-ogy in 3.1. In 3.2 and 3.3, we present our results that use Epinions dataset and synthetic dataset respectively.
To evaluate performance of proposed models, we compare our models with some other algorithms. We consider two factors: the accuracy of prediction that compares the result of the algorithm with some ground truth; and the coverage  X  fraction of the population that can be evaluated by the trustor, given trustor X  X  limited knowledge.
 We compare StereoTrust with the following algorithms. Feedback Aggregation In this model, If trustor does not EigenTrust EigenTrust [11] uses transitivity of trust and Transitive Trust (Web of Trust) This model is based on Group Feedback Aggregation d-StereoTrust uses opin-Dichotomy-only d-Stereotrust divides each group into an
Please note that we only compare StereoTrust model with the existing models using synthetic dataset because we lack the information of how users in Epinions dataset carry out these existing models.

To estimate the accuracy of each algorithm, we compare the value of trust computed by the algorithm for a pair of agents with the ground truth. Then, we aggregate these differences over different pairs using Mean Absolute Error (MAE).

We present the results in two formats. Firstly, to measure overall performance of an algorithm, we show MAE aggre-gated over the whole population of agents (e.g., Table 1). Secondly, to see how the algorithm performs in function of agent X  X  ground truth, we construct figures presenting the de-rived trust for a subset of agents (e.g., Figure 4). To avoid cluttering, we randomly choose 50 target agents. Y-axis rep-resents the trust rating of the agents. X-axis represents the index of the evaluated agent. For clarity, agents are ordered by decreasing ground truth.

Ideally, the ground truth of an agent represents agent X  X  ob-jective trustworthiness. However, as we are not able to mea-sureit,wehavetoestimateitusingtheavailabledata. We will discuss how to derive the ground truth when mapping each dataset. Besides prediction accuracy, we also measure the performance of algorithms using coverage  X  percentage of agents in the system that can be evaluated by trustor.
The complete Epinions dataset we crawled contains 5,215 users, 224,500 reviews and 5,049,988 ratings of these reviews. For our experiments, we selected 20 trustors and 150 target agents randomly (we repeated the experiments with different agents and got the similar results). On the result plots (e.g., Figure 4), error bars are added to show the deviation of predictions by each trustor for the same target agent.
In the experiments using synthetic dataset, we choose one honest agent randomly as trustor to predict behavior of other agents in the system (there are totally 200 agents in the system). Each experiment is repeated 10 times (each running uses different synthetic dataset) and error bars are added to indicate the deviation of each running (e.g., Fig-ure 8).
Epinions.com is a web site where users can write reviews about the products and services, such as books, cars, music, etc (later on we use the generic term  X  X roduct X ). A review should give the reader detailed information about a specific product. Other users can rate the the quality of the review by specifying whether it was Off Topic , Not Helpful , Some-what Helpful , Helpful , Very Helpful or Most Helpful .For each review, Epinions.com shows an average score assigned by users.
 Epinions.com structures products in tree-like categories. Each category (e.g., books) can include more specific cat-egories (e.g., adventure, non-fiction, etc.). The deeper the level, the more specific category the product belongs to.
Epinions community provides a good scenario to test our proposed model, where users write reviews or rate reviews of products they are interested. This gives the intuitive group-ing criteria, that is, users are g rouped if they are interested in the same product/category. We use Epinions dataset to test the performance of StereoTrust and see whether the enhanced model d-StereoTrust performs better.
To map Epinions.com to StereoTrust model, we treat each user as an agent. Epinions.com categories provide a natu-ral representation of interested in relation. A user is in-terested in a (sub)category if she wrote or rated at least one review of a product under this category. Groups are formed according to agents X  in terested in relations. Conse-quently, each Epinions.com category corresponds to a group of agents, each of whom is interested in (wrote or rated a review for) this category. A transaction between agents a and a y occurs when a x rates a review written by a y .Tomap Epinions.com ratings to StereoTrust binary outcome, we as-sume that the transaction is successful only if the assigned rate is Very Helpful or Most Helpful . We set the threshold so high to avoid extreme sparsity of unsuccessful transactions (over 91% review ratings are Very Helpful or Most Helpful ).
We compute the ground truth of an agent as the average rating of the reviews written by this agent. For instance, if an agent wrote 3 reviews, the first review was ranked by two users as 0.75 and 1.0 respectively, while the second and the third received one ranking each (0.75 and 0.5), the ground truth for that user is equal to (0 . 75+1 . 0+0 . 75+0 . 5) / 4. Note that the  X  X round truth X  computed with this simple method only approximates the real trustworthiness of an agent, as we do not adjust the scores to counteract, e.g., positive or negative biases of the scoring agents. Figure 4 shows the performance of StereoTrust model. SOF/SOP on the legend indicates that the trust rating is calculated using SOF/SOP approach respectively. From the figure we can see that both SOF and SOP approaches fail to provide a good fit to the ground truth. This is because in Epinions dataset, most ratings given by the agents are positive ( Very Helpful or Most Helpful ). So trustors are in a very friendly environment, which makes them difficult to identify the agents who write somewhat low quality reviews simply using local information. Figure 4: Comparison of StereoTrust model and ground truth using Epinions.com dataset.
 Figure 5 show the performance of d-StereoTrust model. We can see both SOF and SOP derived trust ratings are more accurate than feedbacks derived trust rating (group feedback aggregation), which supports that our model out-performs that simply aggregates other agents X  feedbacks. SOF approach gives a better fit to the ground truth than SOP approach. Comparing Figure 4 and 5, We observe that d-StereoTrust is obviously better than StereoTrust (d-StereoTrust provide better fit to ground truth), so d-StereoTrust improve the accuracy of prediction of target agent X  X  perfor-manceasweexpected. Figure 5: Comparison of d-StereoTrust and ground truth using Epinions.com dataset.

Figure 6 compares d-StereoTrust model with dichotomy-only (StereoTrust is omitted as it is worse than d-StereoTrust in terms of prediction accuracy). Error bars are removed for clarity and only SOF approach, which outperforms SOP ap-proach is showed for each model. From the figure we see that d-StereoTrust model provides more accurate prediction than dichotomy-only does. This proves that considering both in-terests based group and some global information can predict target agent X  X  behavior more accurately. Figure 6: Comparison of d-StereoTrust model and dichotomy-only using Epinions.com dataset.

Table 1 lists the calculated MAE along with 95% confi-dence interval. Although plots only show 50 target agents, MAE/95% C.I. is computed using all 20  X  150 (trustor, tar-get agent) pairs. Confidence interval is computed using the expression  X  x  X  S E  X  1 . 96, where  X  x isthesamplemean, S is the standard error for the sample mean, and 1.96 is the 0.975 quantile of the normal distribution.
 Table 1: Mean Absolute Error (with 95% Confi-dence Interval) StereoTrust (SOF) 0.1114 (0.1067,0.1161)
StereoTrust (SOP) 0.1177 (0.1136,0.1218) d-StereoTrust (SOF) 0.0632 (0.0586,0.0678) d-StereoTrust (SOP) 0.1299 (0.1245,0.1353) dichotomy-only (SOF) 0.1365 (0.1307,0.1423) dichotomy-only (SOP) 0.1750 (0.1690,0.1810) group feedback aggregation 0.1452 (0.1386,0.1518)
From the results we can see that simply using only  X  X tereo-type X  (category information) to form group (StereoTrust model) does not predict target agent X  X  performance accu-rately because Epinions is a friendly community. Users are likely to give high ratings to reviews written by others, which makes successful transactions dominate the groups. In such environment, StereoTrust model more probably derives a high rating for the target agent. Due to the same reason, dichotomy-only does not work well either. On the contrary, d-StereoTrust improves the prediction accuracy. This proves that using groups and small amount of trust information from other agents helps provide more accurate prediction of target agent X  X  performance.
Epinions.com has a friendly community with few dishon-est agents. To test StereoTrust in a more hostile environ-ment, we generated a synthetic dataset simulating a hostile version of Epinions.com-like community.
In the synthetic dataset, 40% of the population of 200 agents are dishonest. A honest agent provides a high quality review (with real rating = 0.6 or 0.8 or 1.0) or a true feedback with a probability 0.9. A dishonest agent provides a low quality review (real rating = 0.0, 0.2, 0.4) or a false feedback with a probability 0.9. Note that if a true feedback is a value of  X  , the corresponding false feedback is a value of 1  X  Both number of reviews written by an agent and number of ratings of a review are generated by a Normal distribution (  X  = 10,  X  = 4). Note that the agents who assign ratings to a review are selected randomly from a set of agents who are also interested in the category that this review is about.
We simulate an environment with 12 categories (indexed 1 , 2 , ..., 12) and 20 products in each category. Honest and dishonest agents are biased towards different categories. A honest agent with probability 0 . 7 writes a review for a prod-uct from categories 1 , 2 , 3 , 4; with probability 0 . 21 for prod-ucts from categories 9 , 10 , 11 , 12; and with probability 0 . 03 for products from categories 5 , 6 , 7 , 8. A dishonest agent with probability 0 . 7 writes a review for products from cate-gories 5 , 6 , 7 , 8; with probability 0 . 21 for products from cat-egories 9 , 10 , 11 , 12; and with probability 0 . 03 for products from categories 1 , 2 , 3 , 4.

We compute the ground truth of an agent as the average rating of the reviews written by this agent. Different from ground truth in Epinions dataset, in synthetic dataset, rat-ing of one review is determined by the design of dataset, so this rating represents the real quality of the review, thus the calculated ground truth more approximates the objective trustworthiness of one agent.
Figure 7 shows the performance of StereoTrust model. We can see that the model derived trust rating fits the ground truth in general but not very closely. However, the trend looks better than that in real Epinions dataset. Figure 7: Comparison of StereoTrust model and ground truth using synthetic dataset.

Figure 8 shows the performance of d-StereoTrust. Obvi-ously, d-StereoTrust provides more accurate prediction than StereoTrust model (more fits to ground truth). This is be-cause, d-StereoTrust forms groups in a finer granularity thus local trust information and third party information are prop-erly used to represent target agent X  X  trust. Similar to Epin-ions dataset, feedback derived trust (group feedback aggre-gation) is less accurate than that derived by SOF/SOP. Figure 8: Comparison of d-StereoTrust and ground truth using synthetic dataset.

Figure 9 compares d-StereoTrust model (using SOF) with dichotomy-only (using SOF) and various existing algorithms (described in section 3.1). Error bars are removed for clarity. From the figure we observe that the existing algorithms pre-dict target agent X  X  trust less accurately than d-StereoTrust does. These existing algorithms show obvious gaps between ground truth and derived rating for honest target agents part (like EigenTrust and most reliable path transitive trust) or dishonest target agents part (like shortest path transitive trust) or all the target agents (like feedback aggregation). Figure 9: Comparison of all the algorithms using synthetic dataset.

Table 2 summaries MAE (with 95% confidence interval for all the agents) and coverage of each model involved in comparison. For each model, we show MAE for evaluating honest target agents part, dishonest target agents part and all target agents respectively. Note that for StereoTrust, d-StereoTrust and dichotomy-only, we only show the results using SOF approach, which outperforms SOP approach.
Feedback aggregation and both variations of transitive trust models are significantly worse than d-StereoTrust in d-StereoTrust (SOF) 0.1154 0.1099 0.1126 (0.1036,0.1216) 95.5% EigenTrust 0.1487 0.1002 0.1263 (0.0966,0.1510) 96.4% Dichotomy-only (SOF) 0.1326 0.1215 0.1288 (0.1202,0.1374) 96.3% StereoTrust (SOF) 0.1377 0.2641 0.1884 (0.1300,0.2753) 96.9% Feedback aggregation 0.1450 0.1642 0.1535 (0.1432,0.1678) 99.9% terms of prediction accuracy even if feedback aggregation and transitive trust (shortest path) have the best cover-age. Transitive trust model (most reliable path) has the worst coverage. EigenTrust performs almost as good as d-StereoTrust but requires more third party information thus incurring higher communication overhead. Additionally, the assumption of pre-trusted agents is not realistic, which is es-sential to this model. Dichotomy-only, as a baseline, proves that considering  X  X tereotypes X  improves the accuracy pre-diction of target agent X  X  behavior definitely. So to sum up, d-StereoTrust, which has the highest prediction accu-racy (MAE is the smallest) at the cost of losing a bit cov-erage (95.5%) and incurring medium communication over-head (trustor only asks agents that are also interested in corresponding categories) outperforms among all the mod-els. This also proves that d-StereoTrust is more robust to large portion of malicious agents (up to 40% in the ex-periments) than other algorithms. Both real and synthetic dataset proves that StereoTrust model does not work well as d-StereoTrust model. However, StereoTrust has its own ad-vantage in term of communication overhead because it only uses local information to derive trust of target agent. This is very promising in some scenarios where by carefully form-ing groups, honest and dishonest agents are put into groups which seldom overlap, thus group trust can represent indi-vidual trust accurately.
Past mutual interactions information can be used to pre-dict an agent X  X  future behavior (e.g., [1]), but such an ap-proach is unsuitable in distributed systems where one may need to assess trustworthiness of an agent with whom there have been no past personal interactions.

Instead of using only local experience, many works derive the trust of interaction partners based on reputation  X  in-formation gathered from third parties. Abdul-Rahman et al [2] and J X song et al [9] used transitive trust path to derive participant X  X  trust. However, transitive trust is not always true in real world (some conditions must be fulfilled) and it has several drawbacks: (i) This method does not handle wrong recommendations properly, which affect the accuracy of derived trust seriously. (ii) This method does not provide a mechanism for updating trust efficiently in a dynamic sys-tem. (iii) Establishing a trust path, even if such a path exists, is nontrivial.

EigenTrust [11] is a reputation system developed for P2P networks. It tries to fulfill the goals of self-policing, anonym-ity, no profit for newcomers, minimal overhead and robust to malicious collectives of peers. EigenTrust uses transitiv-ity of trust and aggregates trust from peers by having them perform a distributed calculation to determine the eigenvec-tor of the trust matrix over peers. The main drawback of EigenTrust is that it relies on some pre-trusted peers, which are supposed to be trusted by all peers. This assumption is not always true in real world. First, these pre-trusted peers become points of vulnerability for attacks. Second, even if these pre-trusted peers can defend attacks, there are no mechanisms to guarantee that they are reliable/trustworthy permanently. Additionally, EigenTrust (and some other rep-utation systems like [16]) is designed based on Distributed Hash Tables and thus imposes system design complexity and deployment overheads. Our proposed model does not need an overlay for trust management.

REGRET [13] combines direct experience with social di-mension of agents, that also includes so-called system rep-utation. System reputation is based on previous experience with other agents from the same institution . Unlike Stereo-Trust X  X  groups, REGRET X  X  institutions exists outside the system and there is objective function to assign agents to institutions. REGRET also assumes that an agent belongs only to one institution.

Ravichandran et al [12] proposed a trust system built on top of a peer group infrastructure. The group in this paper is formed based on a particular interest criterion and mem-bers must follow a set of rules of its group. The authors assumed that a group leader creates the group and controls the membership. To calculate trust, the authors introduced Eigen Group Trust, which is an aggregative version of Eigen-Trust [11]. In Eigen Group trust, all the transactions rely on the group leaders, who are assumed to be trusted and re-sourceful. Their notion of groups is thus very different from ours.

Different from existing works, we define groups using agent X  X  local information according to certain group criteria (not merely interests ). These locally defined groups may overlap or be disjoined depending on the criteria used. Moreover, different agents may have entirely different criteria.
While our technique is novel in the context of evaluat-ing trust  X  and provides a new paradigm of using stereo-types for trust calculation instead of using feedbacks or web of trust  X  it bears resemblance with collaborative filtering techniques. The primary difference is that StereoTrust uses only local information in a decentralized system. However, the similarities also mean that while our work proposes a new paradigm to determine trust, the methodology we use is not out of the blue. Also, we anticipate that sophisticated collaborative filtering techniques can be adopted to further improve StereoTrust X  X  performance.

StereoTrust also has parallels to web search engines X  rank-ing mechanisms. Using the group information is analogous to using the content of the web pages to rank them. Transi-tive trust models resemble  X  X ure X  PageRank, that uses only links between pages. Similarly to web search, where using both content and links together gives better results, we de-rive an enhanced method (d-StereoTrust), that uses both groups and (limited) trust transitivity.
We consider the problem of predicting the trust between a trustor and an unknown agent in a large-scale distributed setting. Traditional approaches to this problem derive un-known agent X  X  trust essentially by combining trust of third parties to the agent with the trustor X  X  trust of these third parties; or simply by aggregating third parties X  feedbacks about the unknown agent. In contrast, StereoTrust uses dif-ferent kind of information: that of semantic similarity of the unknown agent to other agents that the trustor person-ally knows. In StereoTrust, a trustor builds stereotypes that aggregate and summarize the experience she had with differ-ent kinds of agents. The basis of the grouping to construct stereotypes is very flexible. For instance, stereotypes can be based on information from agents X  personal profiles, or the class of transactions they make. Facing a possible transac-tion with an unknown agent, the trustor builds its trust by cumulating the experience from the stereotypes to which the unknown agent conforms.

The stereotypes are based entirely on the local perspective and local information of the trustor, and, therefore, are nat-urally suited for large-scale systems; personalized for each trustor; and less susceptible to false or unsuitable informa-tion from third parties. The rationale for the StereoTrust approach is to determine an alternative and complementary mechanism (than existing techniques) to compute trust even in absence of (global) information that is likely to be un-available under some circumstances, and instead using some other class of information (stereotypes) which can be estab-lished by local interactions.

When some of third parties X  opinions about an agent are available, we propose an enhancement (d-StereoTrust), which creates a  X  X ood X  and a  X  X ad X  subgroup inside each stereo-type. The trustor assigns each one of her previous transac-tion partners to one of these groups based on the her per-sonal experience with the partner (e.g., the ratio of failed transactions). Then, the trustor uses the aggregated third parties X  opinions about the unknown agent to determine how similar is the agent to the  X  X ood X  and  X  X ad X  subgroup. Third parties X  opinions are a small subset of information used by traditional mechanisms (such as feedback aggrega-tion or Eigentrust-type algorithms). However, according to our experiments, by combining stereotypes with these par-tial historic information, d-StereoTrust predicts the agent X  X  behavior more accurately than Eigentrust and feedback ag-gregation.

StereoTrust can not only be personalized for the trustor, but also, it can be used to determine an agent X  X  trustworthi-ness for specific type of interactions (classified by groups). We are currently working on suc h extensions of StereoTrust, as well as exploring possible concrete applications to employ it on, including in designing a p2p storage system like we ex-plained in the motivation.
 This work has been partly supported by the HP Labs Inno-vation Research Program research grant. [1] L. Mui and M. Mohtashemi. A computational model [2] A. Abdul-Rahman and S. Hailes. A distributed trust [3] K. Aberer and Z. Despotovic. Managing trust in a [4] R. Bartoszynski and M. Niewiadomska-Bugaj.
 [5] S. Buchegger and J.-Y. L. Boudec. A robust [6] A.Datta,M.Hauswirth,andK.Aberer.Beyond X  X eb [7] D. Gambetta. Can we trust trust? In D. Gambetta, [8] M. Gupta, P. Judge, and M. Ammar. A reputation [9] A. J X sang, E. Gray, and M. Kinateder. Analysing [10] A. J X sang and R. Ismail. The beta reputation system. [11] S. D. Kamvar, M. T. Schlosser, and H. Garcia-Molina. [12] A. Ravichandran and J. Yoon. Trust management [13] J. Sabater and C. Sierra. Regret: reputation in [14] S. Tadelis. Firm reputation with hidden information. [15] J. Tirole. A theory of collective reputations (with [16] L. Xiong, L. Liu, and I. C. Society. Peertrust: [17] Powertrust: A robust and scalable reputation system
