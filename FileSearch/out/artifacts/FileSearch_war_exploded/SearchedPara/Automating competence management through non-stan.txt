 1. Introduction
It is well known that knowledge intensive companies have their most promising source of competitive advantage in human resources. Such an assumption is at the basis of the widely investigated research area well known in the literature by the name knowledge management (KM).

A variety of methodologies have been proposed for an efficient use of the so-called intellectual capital, whose impact on return on investments is nowadays considered as valuable as the one deriving from any other material asset.

Emphasis has been given, in particular, to the identification of capabilities leading companies to business success: several approaches to strategic management have been proposed and classified according to the perspective they take on the problem ( Hafeez et al., 2002 ).

In particular, many research contributions sustain the resource-based theory of the firm ( Wernerfelt, 1995 , 1984 ) suggesting to search for competitive advantage in unique company capabilities ( Halawi and McCarthy, 2005 ; Meso and Smith, 2000 ; Barney, 1986 , 1991 ).

Other proposals focus on the achievement of competitive advantage trough the deployment and exploitation of capabilities embedded in business processes: such a dynamic capabilities approach asks for continuous reshaping of firms assets ( Teece et al., 1997 ).

Alternative approaches ( Tampoe, 1994 ; Sanchez and Heene, 1997 ; Bogner and Thomas, 1994 ) take the so-called competence-based perspective , which identifies in the core competence of the firm as a whole a source of competitive advantage more crucial than the discrete assets of the firm itself. In Hamel and Prahalad (1990) the notion of core competence was firstly defined as a sort of capability providing customer benefits, hard to be imitated from competitors and possessing leverage potential. Further definitions of core competence have been proposed in the literature in the attempt of finding methods for detecting such a collective knowledge ( Markides and Williamson, 1994 ; Nelson, 1991 ).

Our proposal takes the competence-based perspective and in particular shares with it the interpretation of company strategic competence as a collective asset, resulting from the synergy of human resources. In particular, we adopt a recently proposed semantic-based approach ( Colucci et al., 2008a ) supporting long term organizational strategy in the identification of such knowl-edge, mentioned above as core competence.

The main focus of the paper is to present and evaluate the implementation of such an approach in a knowledge management system (KMS) ( Colucci et al., 2007a ) exposing also services for human resources assignment and training programs composition.
The system treats company personnel as a  X  X  X ompetence ware-house X  X  available for the production of goods and services to be placed on the market. As with any other asset, knowledge needs to be scheduled with respect to production plans, and acquired from external sources when the figurative warehouse runs out of stock.

When dealing with automatic management of knowledge  X  rather than material assets  X  the peculiarities of the involved resource may cause several difficulties. The most significant drawback is due to the subjectivity and intangibility typical of knowledge: the description of personnel competence needs to take implicit and negative information into account and to unambiguously interpret the domain vocabulary.

Using ontologies and formal languages endowed with seman-tics allows automatic systems to overcome limits peculiar to less expressive sorts of knowledge representation. Moreover, the choice of suitable formal languages allows to define and adopt reasoning services exploiting explicit information description to infer new knowledge. Though standard deductive services over logic-based descriptions, such as subsumption and satisfiability, can already infer informative content crucial for solutions to human resources management, specific non-standard inferences can be devised that are characterized by a higher potential impact, as we show in this paper.

Among available languages for knowledge representation, we adopt description logics (DLs) ( Baader et al., 2002 ), which offer a formalism to create representations whose expressiveness grows with the cardinality of adopted formalisms set. A trade-off is of course required between expressiveness of descriptions and computational complexity of provided reasoning services. Thus, we give up to the use of formal languages providing full expres-siveness of descriptions, because the proposed KMS implements specifically developed non-standard inferences in DLs to provide sophisticated knowledge management services.

The remaining of this article is organized as follows: the logical architecture of the integrated KMS is introduced in Section 2.
Then the logical framework supporting core competence identi-fication is presented. KMS usage is then shown with reference to all possible use cases in Section 4. A performance evaluation focused on core competence computations is reported in Section 5. Related work and conclusions close the paper. The interested reader can find in Appendix A an overview of basic formalism and reasoning services we exploit here. 2. An integrated knowledge management system
The integrated KMS we designed and implemented basically aims at helping management in identifying strategies for an efficient human resources allocation and management.

Fig. 1 depicts the system logical architecture, made up by three categories of decision support services, which are detailed in the following sections. 2.1. Strategical choices
Imagine a company in which personnel profiles have been stored as formal descriptions in an ontology: management has the whole  X  X  X nowledge inventory X  X  at hand for possible strategical choices. In particular, the knowledge representation effort may be exploited for the identification of the collective competence characterizing a company, the fields of excellence to invest on in long term strategy: core competence. The KMS allows for automatically extracting possible sources of collective knowledge from personnel profile descriptions or, given some target core competence, for evaluating whether the company possesses it ( core competence identification ). The resulting fields of excellence may be exploited to characterize companies in term of skill excellence cluster, so that a core competence-based classification process for companies may be performed ( cluster identification ) ( Colucci et al., 2007b ). Different clusters include companies sharing formalized classes of knowledge. Through the proposed process a company may discover its profile in terms of core competence and check whether it can join a given knowledge class or, in case it cannot, the reasons why it happens. In both cases, investigations aimed at strategical choices may lead to the determination of a knowledge gap, which may be source of suggestions for possible training programs. 2.2. HR allocation choices
Organizational life is characterized by several tasks and activities to be performed by employees enabled with the needed competence. The assignment of the right individual to the right job is crucial for business success, even though very hard to achieve in an efficient fashion. An automated support to such a critical activity may help management in overcoming the danger of wrong assignments due to incomplete information or subjec-tive choice criteria. If personnel profiles are stored as formal descriptions in an ontological repository, it is possible to provide automatic allocation proposals based on the semantic similarity between the profile and the needed task, which requires to be represented as a formal description according to the same ontology. Of course a perfect match between individual and task description, although wished, is quite rare to happen: also personnel lacking of some competence to completely fulfill the task may represent good assignment candidates if an explanation about missing skills is provided and is judged acceptable. In some cases, instead, the request is such that no profile can potentially match it: only personnel with features conflicting with the required ones are available. Such an unlucky situation may be supported by suggesting conflicting characteristics to be retracted in the request, in a possible negotiation process. An extended matchmaking process allows for evaluating also missing and conflicting information in profile descriptions to determine the similarity degree of task and profile description. The approach exploits concept abduction and concept contraction reasoning services ( Colucci et al., 2007a ). In particular, missing information may be interpreted as possible suggestions for training programs, enabling the selected individual with the missing knowledge. Furthermore, not all tasks are solvable by only one individual and sometimes allocations affect each other: if more than one task at a time needs to be assigned, criteria for overall optimization need to be adopted. Three different allocation services, implementing the approach originally proposed in Colucci et al. (2007a) , are, therefore, provided: the assignment of one individual to one task ( single task assignment ), the contemporary choice of more than one single assignments ( multiple task single assignment ), the creation of an ad-hoc team ( team creation ). Most of HR allocation services have been implemented in the framework of I.M.P.A.K.T., a novel and optimized commercial system for competences and skills management ( Tinelli et al., 2009 ). 2.3. Training programs
The shared repository for knowledge resources may be enriched with learning resources descriptions referred to the same ontology as profile descriptions: the provided vocabulary details in fact competence domain and gives terms useful for describing both knowledge to acquire (by learning resources) and possessed skills (in personnel profiles). The inventory of learning resources descriptions may be then addressed each time manage-ment needs to plan training programs involving personnel selected for acquiring new competence. As hinted before, the decision to plan training programs derives in most cases from the identification of a knowledge gap, either in the profile of one or more selected employees (after HR allocation choices) or in the whole company excellence profile (after strategical choices).
Regardless of the reasons for a learning need, if required, support is provided in composing available learning resources to create personalized training paths. The composition process exploits non-standard reasoning services, namely concept covering and concept abduction ( Colucci et al., 2007a ). 3. Core competence identification
The process of identifying core competence is usually char-acterized by high complexity and low objectivity because of the intangibility of knowledge itself and difficulties inherent in formalizing them. We, therefore, propose an automated logic-based solution performing non-standard inferences over concept descriptions representing personnel profiles formalized in ALN .
We observe that, despite the collective nature of company core competence, it has not necessarily to be shared by the whole personnel: a significant portion of it could be enough. In order to understand the rationale of this observation, consider the follow-ing simple example. In a small consulting company only three people are employed: Alex , an engineer with knowledge about C  X  X  ; Frank , a TCP/IP expert, skilled in Java; Mike , a C programmer.
The implication relationships between concepts involved in these individual profile descriptions, quite intuitive, may be found in the ontology in Fig. 3 for the reader interested in their logical formalization.

If we give only to competence held by all of the employees the name core competence, we may simply assert that the company in our tiny example has programming knowledge in its core competence. If we instead give up to such a full skill coverage and assume that core competence is held by the majority of employ-ees, we may assert that object oriented programming is a core competence for the company, which is a more specific and then a much more significant result than the previous one.

We assume hereafter for the sake of simplicity that the only source of knowledge lies in company personnel and we, therefore, focus on employees profile descriptions, although it is obvious that real-world applications may have to exploit all available information.

We implement two alternative processes originally proposed in Colucci et al. (2008b) for core competence identification: the first one, core competence extraction, exploits non-standard inference services to discover unknown fields of excellence of the company; the second one, target core competence reaching evaluation, checks for the possession of a list of known target competencies by a significant portion of company personnel and explains how to reach the target in case the check fails.
Core competence extraction. The objective of the implementa-tion of services for automatic core competence extraction is identifying a common know-how in a significant portion of company personnel, with a degree of coverage to be set by the management.

Least common subsumers (LCS) have been originally proposed by Cohen et al. (1993) as novel reasoning service for finding commonalities in a collection of concepts. By definition, for a collection of concept descriptions, their LCS represents the most specific concept description subsuming all of the elements of the collection:
Definition 1 ( LCS, Cohen et al., 1993 ). Let C 1 , ... , C in a DL L . An LCS of C 1 , ... , C n , denoted by LCS  X  C concept E in L such that the following conditions hold: (i) C i L E for i  X  1, y , n satisfying C i L E 0 for all i  X  1, y , n , then E L E 0 .
Intuitively, the LCS represents properties shared by all the elements of a given collection. In some other applications, like core competence evaluation, such a sharing is not required to be full: in other words we are interested in finding a concept description subsuming a portion of the elements in a collection, rather than the collection as a whole. We name such concept description k-common subsumer ( k -CS):
Definition 2 ( k-CS, Colucci et al., 2008b ). Let C 1 , ... , C concepts in a DL L , and let be k o n . Ak -common subsumer among C 1 , ... , C n .

In particular we are interested in finding k -common subsumers adding informative content to the LCS, defined in the following as Informative k -common subsumers:
Definition 3 ( IkCS, Colucci et al., 2008b ). Let C 1 , ... , C concepts in a DL L , and let k o n . An informative k -common subsumer (IkCS) of C 1 , ... , C n is a k -CS E such that LCS  X  C strictly subsumes E .

Among possible IkCSs , some are characterized by maximum cardinality of the set of subsumed concepts: we define in the following such concepts as best informative common subsumers.
Definition 4 ( BICS, Colucci et al., 2008b ). Let C 1 , ... , C concepts in a DL L . A best informative common subsumer (BICS) of C , ... , C n is a concept B such that B is an Informative k -CS for
C , ... , C n , and for every k o j r n every j -CS is not informative.
If a collection admits an LCS not equivalent to the universal concept, such LCS is the best common subsumer the collection may have. Alternatively, only for collections whose LCS is equiva-lent to the universal concept the following definition makes also sense:
Definition 5 ( BCS, Colucci et al., 2008b ). Let C 1 , ... , C cepts in a DL L . A best common subsumer (BCS) of C 1 , ... , C every j -CS &gt; .

Even though the services defined above may appear similar at first sight, it has to be underlined that they deal with different issues: k -CS: can be computed for every collection of elements and finds least common subsumers of k elements among the n belonging to the collection;
IkCS: describes those k -CSs adding an informative content to the one provided by LCS, i.e., more specific than LCS. Observe that IkCS does not exist when every subset of k concepts has the same LCS as the one of all C 1 , ... , C n ;
BICS: describes IkCSs subsuming h concepts, such that h is the maximum cardinality of subsets of the collection for which an
IkCS exists. A BICS does not exist if and only if C i C j i , j  X  1 , ... , n ;
BCS: may be computed only for collections admitting only LCS equivalent to the universal concept; it finds k -CSs such that k is the maximum cardinality of subsets of the collection for which an LCS not equivalent to &gt; exists.

In the following we define, with respect to a collection of concept descriptions, BCS the set of BCSs, BICS the set of BICSs,
ICS k the set of IkCSs, given k o n and CS k the set of k-CSs, given k o n .

In Colucci et al. (2008a) we proposed the algorithm common subsumer enumeration determining the sets BICS , CS k , ICS input the collection in the form of a collection subsumers matrix , introduced in the following (see Definition 8), after two preli-minary definitions, 6 and 7.

Definition 6 ( Concept components ). Let C be a concept descrip-tion in ALN , with C written in a conjunction C 1 uu C m .
The concept components of C are defined as follows: 1. if C j , with j  X  1 ... , m is a concept name, a negated concept concept descriptions C i in a description logics L and let
D j A f D 1 , ... , D m g be the concept components deriving from a set of concepts. We define the subsumers matrix S  X  X  s ij  X  , with i  X  1 ... n and j  X  1 ... m , such that : s ij  X  1 if the component D j subsumes C i s ij  X  0 if the component D j does not subsume C i .

Definition 8 ( Collection subsumers matrix ). Let C 1 , ... , C collection of concept descriptions C i in a description logic L .
We define the collection subsumers matrix as a subsumers matrix in which D j A f D 1 , ... , D m g are the concept components deriving from all concepts in the collection.

With reference to complexity issues for the computation of solution sets, the following Theorem provides some useful bounds ( Colucci et al., 2008b ). 1 Theorem 1. Let C 1 , ... , C n , T be n concepts and a simple Tbox in monotone function bounding the cost of deciding C L T Din ALN , whose argument s is j C j X j D j X j T j . The computation of the solution ALN is then a problem in O  X  m 2  X  X  S  X  m  X  X  2  X  .

Target core competence reaching evaluation . An approach was proposed in Colucci et al. (2007b) to evaluate whether a company possesses a given core competence, taken as target. The approach implemented an algorithm performing a subsumption check for each profile description in the repository, in order to determine the number of employees holding the target knowledge. We added to this approach an explanation feature, hypothesizing, in case the target is not reached, the reasons why this happens: in Colucci et al. (2008a) we provided an algorithm for evaluation of target core competence reaching, with explanation features. The algorithm takes as input the concept subsumers matrix (see Definition 9) deriving from a collection of employees knowledge profiles C 1 , ... , C n and a target core competence description R , both in ALN .
 Definition 9 ( Concept subsumers matrix ). Let C 1 , ... , C lection of concept descriptions C i and R a concept description, both in a description logic L .

We define the concept subsumers matrix as a subsumers matrix in which D j A f D 1 , ... , D m g are the concept components of R , denoted by R j .

The complexity results for the computation of an explanation set through the above mentioned algorithm are given in Theorem 2 (we omit the proof because it is similar to the one for Theorem 1 and needs some definitions omitted in the paper for the sake of brevity).
 Theorem 2. Let C 1 , ... , C n , T be n concepts and a simple Tbox in monotone function bounding the cost of deciding C L T Din ALN , whose argument s is j C j X j D j X j T j . The computation of the explana-tion set E for a collection of concept descriptions and a concept in ALN is then a problem in O  X  m 2  X  X  S  X  m  X  X  2  X  . 4. The KMS in use
We here introduce the architecture of the proposed KMS with respect to the use cases outlined in Section 2. A sketch of the functional architecture is represented in Fig. 2 .

It is noteworthy that the proposed KMS relies on a repository of descriptions related to different sources of knowledge. All such descriptions need to adopt the same vocabulary for knowledge representation.

In Fig. 3 we provide the ALN TBox corresponding to an excerpt of such a vocabulary in order to make the example terminology available to the reader.

The repository exploited by the KMS contains the knowledge sources descriptions making up the ABox of the employed DL System. The available individuals describe two different kinds of knowledge sources:
Personnel profiles : descriptions according to the TBox vocabu-lary of the persons available for the solution of different tasks;
Learning objects : descriptions according to the TBox vocabulary of the learning resources to be composed for the creation of personalized training programs.

Considering personnel profile descriptions it is noteworthy that, coherently with the aim of providing knowledge manage-ment support services, only personnel competence is conveyed in them: features different from skills are not taken into account in the semantic base processes and then there is no need to model them as DL descriptions.

Learning object descriptions are modeled in the ontology as concept descriptions made up by a background knowledge and a description component, coherently with the LOM standard ( IEEE, 2002 ) for learning content modeling. The KMS operations can be triggered by any of the use cases in
Fig. 2 , in accordance with the contextual need of the manage-ment. The system obviously allows to permanently store knowl-edge profiles in the repository for reuse. In order to perform each of the available services, the KMS asks the reasoner for the solution of the inference problems at the basis of the implemen-ted algorithms.

In particular, the solution of concept abduction and concept contraction problems require using MaMaS-tng , 2 that implements solutions to those inference services. MaMAS-tng extends DIG standard ( Bechhofer et al., 2003 ) for communication with DL reasoners, in order to implement also the needed non-standard reasoning services.
 The execution flow of each of the three main use cases in
Section 2 (Strategical choices, Human resources allocation choices, Training programs) is indicated by the numbers on the arrows in Fig. 2 : the ask phase (1) initiates the use case indicated in the subscript (e.g., 1 1 is the ask phase related to use case 1) and is followed by the select (2) and the return phase (3). We notice that Fig. 2 explains the execution flow of use cases 1 and 2 without delving into details about their sub-cases, i.e., by generalizing them according to a uniform view.

The system provides a GUI based on AJAX technology ( O X  X eilly, 2005 ) and exploiting Google Web toolkit libraries. 3 The GUI is consistent with the standard for personnel profile descriptions for recruitment process proposed by HR-XML consortium 4 :thestaffing exchange protocol (SEP). All of the features identified by SEP are embedded in our system. In order to pr ovide the semantic description panel available for ontology navigation aimed at profile composition.
According to the approach outlined in Section 2, the KMS exploits MaMaS-tng services to select in the repository the resources providing answers to the contextual need. In particular the HR allocation use case, regardless of the chosen multiplicity, returns an allocation proposal and the explanation about missing skills in the selected individuals. Such unavailable knowledge can be used as learning request in a training program definition process.
The first use case may then call the services provided by the third one, which exploits the reasoner services to compose learning objects in the repository, according to the implemented courseware composition algorithm. The remaining missing knowledge after the possible courseware fruition is also returned to the system user.
The second use case asks the reasoner for the inferences needed in the strategical support services detailed in Section 2.1. By investigating on the individual profiles stored in the repository, the KMS returns the possible core competence of the company or the knowledge clusters the company belongs to, together with the explanation about competence missing to fit the cluster. Such missing skills may motivate the need for training programs, as hinted in Section 2.1, to perform through the third use case.

The operating mode of our system is hereafter detailed with the help of an extended example, covering all possible use cases of the KMS.

Let us suppose the system profiles repository is made up by the four individual descriptions in Table 1 , for the sake of simplicity. 4.1. Use case 1: HR allocation choices We assume the management of the company, the individuals in Table 1 are employed in, has an assignment need. According to the multiplicity of the specific assignment problem, the management can choose among one of the three use cases detailed hereafter. 4.1.1. Use case 1.1: single task assignment
Suppose in our example company there is a job vacancy asking for a computer science degree, an advanced knowledge about Active X, Flash, Markup Languages and at least five years of working experience . The task is formalized in the following w.r.t. the ontology in Fig. 3 : T 1  X  ( hasMasterDegree u8 hasMasterDegree :
ComputerScience u8 advKnowledge :  X  ActiveX u Flash4 u MarkUpLanguages  X u  X  Z 5 hasExperience  X  .
 Fig. 4 shows the panel of the GUI supporting ontology navigation for the composition of the query. Profiles are ranked according to a function ( Colucci et al., 2007a ) which measures the utility of assigning a task T i to an assignee A j by taking into account both missing and conflicting features. The higher utility values are, the less the related assignment is preferred.

As a consequence, the employee Ra ffaella Guerrini is selected: her profile almost perfectly matches the required task, except for the experience requirement, which is in conflict and then returned in a specific panel for features to be possibly given up in the request. 4.1.2. Use case 1.2: multiple task single assignment
Let T be the set of knowledge requests composed by the tasks given in the following together with their ALN descriptions:
Computer Scientist speaking English and endowed with advanced knowledge of C  X  X  , DBMS and Markup Languages :
T  X  ( hasMasterDegree : u8 hasMasterDegree :
ComputerScience u 8 advKnowledge :  X  C  X  X u DBMS u MarkUpLanguages  X u 8 hasLanguageKnowledge : English ;
Engineer with advanced knowledge of client server protocol, asset allocation and quality assurance techniques :
T  X  ( hasMasterDegree : u 8 hasMasterDegree : Engineering u8 advKnowledge :  X  ClientServer u AssetAllocation u QualityTechniques  X  ;
Computer Science Engineer with advanced knowledge of client server protocol, object oriented programming and ability in meet-ing and team coordination :
T  X  ( hasMasterDegree : u8 hasMasterDegree : ComputerScienceEngineering u8 advKnowledge :  X  ClientServer u OOP u MeetingsCoordination u TeamCoordination  X  .

The matching process detailed in Colucci et al. (2007a) is performed and an assignment problem ( Kuhn, 1955 ) is solved according to the values, provided by the same utility function in use case 1.1, shown in the following table: Raffaella Guerrini 0.64 0.71 0.83 Allison Hence 0.55 0.57 0.75 Tom Barclay 0.82 0.14 0.67 Miriam Lebez 0.64 0.43 0.42
The assignment solutions consist in a set of 4-tuples contain-ing a task, an assignee, the knowledge lacking in the assignee profile, the requirements to be possibly given up in the task description.

In our case example the following 4-tuples are, therefore, returned: 1. x  X  T 2 , Allison Hence ,
H 21  X 8 hasMasterDegree : ComputerScience u 8 advKnowledge :  X  C  X  X  u DBMS  X  ,
G 21  X &gt; ); 2. x  X  T 3 , Tom Barclay ,
H 32  X 8 advKnowledge : QualityTechniques ,
G 32  X &gt; X  ; 3. x  X  T 4 , Miriam Lebez ,
H 43  X 8 advKnowledge :  X  MeetingsCoordination u TeamCoordination  X  X  ,
G 43  X &gt; X  . 4.1.3. Use case 1.3: team composition
If the management of our company is searching for a team endowed with advanced knowledge about Active X, HTML, software engineering and client server protocol and with at least one member with a computer science degree , the required task is formalized as:
T  X  ( hasMasterDegree : u8 hasMasterDegree :
ComputerScience u 8 advKnowledge :  X  ActiveX u HTML u SoftwareEngineering u ClientServer  X  .

The system solves a concept covering problem by implement-ing a greedy approach ( Colucci et al., 2005 ; Haddad et al., 2005 ) adding profiles maximizing the utility function recalled in use case 1.1 to the selected set, trying to cover the whole task. The solution algorithm returns the assignment set, together with missing and conflicting information. The team composed of Raffaella Guerrini , Allison Hence and Tom Barclay is selected, as shown in Fig. 5 .
Unfortunately, no one in the company has knowledge about software engineering, which remains uncovered after the team composition. 4.2. Use case 2: strategical choices
The management of the small company employing the person-nel described in Table 1 is involved in the decisional problem of identifying collective core competence in the company. According to the approach detailed in Section 3, the degree of competence sharing needs to be set: imagine the required coverage is half of the employees ( k  X  2).

The system makes available a GUI for choosing between the two evaluation processes introduced in Section 2.1.

Profiles in Table 1 constitute the input collection. 4.2.1. Use case 2.1: core competence extraction
If the user asks for automated core competence extraction, the system computes the set of partial common subsumers as recalled in Section 3.

The concept components deriving from the input collection are listed hereafter:
D 1  X  ( hasMasterDegree
D 2  X 8 hasMasterDegree : ComputerScience
D 3  X  ( advKnowledge
D 4  X 8 advKnowledge : ActiveX
D 5  X 8 advKnowledge : Flash4
D 6  X 8 advKnowledge : MarkUpLanguages
D 7  X 8 advKnowledge : AssetAllocation
D 8  X  ( basKnowledge
D 9  X 8 basKnowledge : Psychology
D 10  X  X  r 4 hasExperience  X 
D 11  X 8 hasMasterDegree : MechanicalEngineering
D 12  X 8 advKnowledge : HTML
D 13  X 8 advKnowledge : ITConsulting
D 14  X  ( hasLanguageKnowledge
D 15  X 8 hasLanguageKnowledge : English
D 16  X 8 hasLanguageKnowledge : German
D 17  X 8 hasMasterDegree : ElectronicsEngineering
D 18  X 8 advKnowledge : TCP = IP
D 19  X 8 advKnowledge : ClientServer
D 20  X 8 advKnowledge : InternetTechnology
D 21  X 8 advKnowledge : InternetUse
D 22  X 8 advKnowledge : Javascript
D 23  X  ( toolsKnowledge
D 24  X 8 toolsKnowledge : InternetDevelopment
D 25  X  X  Z 5 hasExperience  X 
D 26  X 8 hasMasterDegree : ComputerScienceEngineering
D 27  X 8 advKnowledge : VBscript
D 28  X 8 advKnowledge : OOP The LCS of the whole collection is
LCS  X  ( hasMasterDegree u ( advKnowledge u ( basKnowledge which is in fact quite a useless information for strategical choices.
By analyzing the subsumers matrix of the collection, we obtain that both Tom Barclay and Miriam Lebez know about
CC 1  X  ( advKnowledge u8 advKnowledge :  X  TCP = IP u ClientServer u InternetTechnology u ScriptLanguages  X u ( toolsKnowledge u8 toolsKnowledge : InternetDevelopment u ( hasMasterDegree u8 hasMasterDegree : Engineering .
 Analogously, the concept
CC 2  X  ( advKnowledge u8 advKnowledge :  X  AssetAllocation  X u ( basKnowledge u8 basKnowledge :  X  Psychology  X  subsumes both Raffaella Guerrini and Tom Barclay .

Moreover, both Raffaella Guerrini and Allison Hence share knowledge CC 3  X  ( advKnowledge u8 advKnowledge :  X  ActiveX u MarkUpLanguages  X  The concept CC 4  X  ( hasMasterDegree u8 hasMasterDegree : Engineering subsumes instead Allison Hence , Tom Barclay and Miriam Lebez .

Given the input threshold k  X  2, we can assert that CC 1 , CC CC 3 and CC 4 are k -CSs of the collection; in particular they are IkCSs, because they add informative content to the LCS.
CC 4 subsumes the largest number of individual profiles less than n (  X  4): hence it is also a BICS.
 As a result, the company knowledge profile is defined as: C  X  CC 1 u CC 2 u CC 3 u CC 4 .

Now, imagine the knowledge classes in which the network of companies may be classified are the ones formally defined in Table 2 .

The system solves a concept abduction problem (CAP) to find skills required in the knowledge classes, but unavailable in the company knowledge profile ( Colucci et al., 2007b ). Therefore, we get to the following results, which show the competence missing in our example company to fit each of the clusters presented in Table 2 .
 Knowledge class : ICT Solutions For Human Resources Management Explanation results : H 1  X 8 basKnowledge : WorkflowManagement ; Knowledge class : Industrial Software Production For Operations Management Explanation results :
H 2  X  ( advKnowledge u8 advKnowledge :  X  ComputerGraphics u OOP u StrucProgramming u SoftwareEngineering u
OperationsOptimization u DistributionManagement u ProductionManagement  X  u ( basKnowledge u 8 basKnowledge :  X  Design u InformationSystems u
SupplyChain u ProcPerformMonitoring  X  For Operations Management ; Knowledge class : Total Quality Management Solutions Explanation results :
H  X  ( advKnowledge u8 advKnowledge :  X  QualityTechniques u StatisticalMethods  X u ( basKnowledge u8 basKnowledge : ProcPerformMonitoring .

The company does not belong to any knowledge cluster, but the first result suggests that only a basic knowledge about workflow management is needed to fit ICT Solutions
For Human Resources Management cluster. Such a result may be interpreted as a learning need to be possibly covered with a learning path ad-hoc composed by the system (use case 3).

The second result shows instead that the company has nothing in common with the Industrial Software Production For
Operations Management cluster, given that it lacks of the whole knowledge required to fit it. Finally, the company lacks almost all knowledge required to fit Total Quality Management Solu-tions cluster, except basic knowledge of InformationSystems deriving form CC 1 core competence. 4.2.2. Use case 2.2: target core competence reaching evaluation
The user chooses to investigate on possible fields of excellence by evaluating whether a given core competence, taken as target, is hold by an established number of employees. Again such a threshold value is set to fifty percent of company personnel (two in our example). Our example target core competence is human resource management described as:
Human Resources Management  X  ( advKnowledge u8 advKnowledge :  X  AssetAllocation u
Management  X u ( basKnowledge u8 basKnowledge :  X  Psychology  X  .
 The concept components deriving from Human Resources Management are listed below:
R  X  ( advKnowledge
R  X 8 advKnowledge : AssetAllocation
R  X 8 advKnowledge : Management
R  X  ( basKnowledge
R  X 8 basKnowledge :  X  Psychology  X 
By performing the process recalled in Section 3, the systems returns the following explanation set: either Raffaella Guerrini or Tom Barclay need to learn about management in order for the company to hold human resources management core competence. 4.3. Use case 3: training programs
The example provided for use case 1.3 is solved by the composition of a team, composed of Raffaella Guerrini , Allison
Hence and Tom Barclay . The three employees cover almost the whole task request, except for software engineering competence, which is not available in the company.

Such an explanation about unavailable knowledge can be filled by automatically composed personalized coursewares ( Colucci et al., 2007a ). The approach solves a concept covering problem analogous to the one recalled in use case 1.3. Imagine for example that the learning objects in Table 3 are available for fruition.
Observe that learning objects (LOs) are defined as composed in a description, i.e., the knowledge taught by the LO, and a background knowledge, i.e., the competence profile needed to be able to take the course.

The learning need description originating the courseware composition process is formalized as follows:
T  X  r D  X 8 advKnowledge : SoftwareEngineering
Given that the three individuals selected for the team do not share the background knowledge (i.e., the knowledge profile), three different personalized coursewares are provided: 1. Raffaella Guerrini 2. Allison Hence 3. Tom Barclay
All of the three proposed coursewares completely fulfill the learning need (the unavailable knowledge is equivalent to the universal concept). The courseware most immediate to learn is the one proposed to Tom Barclay, which nevertheless does not provide any additional knowledge. On the contrary, the course-wares proposed to Raffaella Guerrini and Allison Hence give UML knowledge as bonus, even though their fruition is less immediate.
Moreover the second solution should be preferred to the first one because of the courseware length. Still the choice of the course-ware to start is up to the management, which could decide between the second and the third solution on the basis of a trade-off between gained additional knowledge and fruition simplicity. 5. System evaluation
In the following we present system evaluation from a two fold perspective: first we present results in terms of accuracy in retrieving best fulfilling profiles, then we report on computational performances of the core competence identification component. 5.1. Human resource allocation In order to show the significance of results provided by the
KMS in business scenarios, we report here on one to one skill matching as test functionality, given the high number of available alternative approaches and systems performing the above men-tioned process. In particular, our experiments aimed at evaluating our KMS solutions both vs. the ones provided by an alternative system and vs. human users judgment. In order to compare our
KMS to an alternative automated system, we involved a recruit-ment agency, that currently uses a custom RDBMS-based system to automatically perform human resources assignment.
The agency stores several hundred CVs, manually translated into a structured template, as database records. Such structured infor-mation constitute an important asset of the agency. For the ICT domain, their CV template is composed of four sections: Educa-both candidate abilities and competences with the respective expertise level) and Projects (it represents both candidate working experience and held job titles). The candidates database can be queried through a GUI allowing for the insertion/selection of different sets of keywords, where each set is related to a CV template section mapped to the database. The search process relies on a string matching over database fields and on OR operator employment(requirements expressed by keywords are considered not strict). In accordance to such a GUI, we proposed the task T 1 in Use Case 1.1. From the most recently inserted CVs, the agency extracted 96 ICT professionals individuals, where only 55 out of 96 had at least one feature shared with requirements of our task. From the 96 profiles, we selected 16 ones (13 belonging to the set of 55 selected outcome and three profiles not so) to model in accordance with our skills ontology, sketched in Fig. 3 . The four individuals in Table 1 , chosen as knowledge source for modeling the use cases described in Section 4, were extracted from such a set. We then asked the company to search in its current system for CVs solving our task, i.e., Professionals endowed with a computer science degree , an advanced knowledge about Active X , Flash , Markup Languages and at least five years of working experience . Their system returned an unordered list of 82 CVs: 40 of the 55 ICT professional profiles and 42 more CVs, belonging to people with a degree in Computer Science, but not working as ICT professionals. Only 11 profiles among the 16 modeled in our system were returned. The system returned such candidates because they matched some of the keywords included in the query. We noted that the employment agency personnel manu-ally extracted 55 ICT professional profiles by considering them as possible matches for the task T 1 in Use Case 1.1, but the RDBMS-based system detected only 40 matches. Our semantic-based KMS, ranking candidates according to the process outlined in Use Case 1.1 description, allowed for significant automation features: the KMS returns the highest ranked candidate: Raffaella Guerrini , together with explanation features crucial for the recruiter to understand the proposed assignment; the KMS candidates set includes 13 of the 16 ICT Professionals modeled according to the ontology: two profiles not returned by database search potentially match the task request if implicit information is taken into account; in particular, the fifth candidate ranked by the KMS is an ICT professional excluded by the company recruiting system, 7. Michele Natali , a Computer Science Engineer, with an advanced knowledge of
XML, German Language, TCP/IP and three years of working experience.
 Performance of the proposed KMS vs. the judgment of human experts is hereafter presented in terms of R norm ( Bollmann et al., 1985 ) as quality measure for the retrieval effectiveness. R values range between 0 and 1, where a value of 1 corresponds to full agreement between system ranking and human ranking, and values less than 1 measure different levels of disagreement. To evaluate human judgment for the similarity of different pairs Task-Profile, we asked three recruiters in the agency to indepen-dently rank in decreasing order the 13 profiles returned as candidates set by the system with respect to the queries T for features corresponding to multiple CV sections (and they then allow for evaluating recruiters priorities for different features), while the sixth one asks for a single feature. As an example, consider the classification related to the query T 1 in Table 4 . Given that the three recruiters provided not univocal classifications, the final ranking of each profile was determined as the minimum one among the three available. Table 5 shows R norm values for each of the six performed queries.

The evaluation shows that our KMS is at least as effective in performing human resources allocation as a traditional DBMS-based system and as a human recruiter: the KMS is able to rank all promising candidates  X  even when the traditional DBMS-based systems fail; it excludes all those not relevant with respect to the required task  X  as opposite to the unordered lists of results returned by traditional DBMS-based systems; it behaves almost exactly like a recruiter. We notice that KMS disagreement with human judgment, revealed by R norm values less than 1, may depend on ontology modeling issues: the representation of some concepts in the ontology does not correspond to the way human beings conceive them; R norm can thus be also a significant measure to support ontology engineering and maintenance efforts. 5.2. Core competence identification
For the evaluation, 20 CVs focused on the ICT knowledge domain have been randomly selected. Such competence profiles have been modeled according to the ontology used in our KMS.
The test procedure has been designed to randomly extract a number of profiles among the twenty and perform Common subsumer enumeration and target core competence reaching evaluation algorithms detailed above.

The performed tests can be classified in two main categories: variable number of profiles and concept components (200 tests); constant number of profiles and variable number of concept components (50 tests).

In the common subsumer enumeration process the number of profiles is randomly selected, while the number of concept components depends on the composition of the selected profiles.
Instead, in the target core competence reaching evaluation process, the number of profiles is randomly selected, while the number of concept components depends on the description of the input core competence, which has been automatically generated by conjoining concept components in the ontology. Moreover, in each test the threshold values k have been set to a number ranging from 1 (included) to the number of profiles (excluded).
To numerically evaluate performances, the following para-meters have been taken into account: n  X  number of profiles; n  X  number of concept components deriving from the n p profiles; k  X  threshold; t sscse  X  collection subsumers matrix computation time; t cse  X  common subsumer enumeration algorithm execution time; n tcc  X  number of concept components deriving from the input core competence of target core competence evaluation algorithm; t sstccre  X  concept subsumers matrix computation time; t tccre  X  target core competence evaluation algorithm execution time.

The collected data show that time for performing core compe-tence extraction and target core competence evaluation algo-rithms are negligible w.r.t. subsumers matrix computation times: in the following we therefore represent the time complexity results of the presented approach in terms of subsumers matrix computation time.

Figs. 6 and 7 show, respectively, the time for collection and concept subsumers matrix computation (in seconds) vs. the number of profiles ( n p ).

The functions are polynomial (second order) w.r.t. the number of profiles. The offsets from the function are due to the different number of concepts components generated by the profiles test. Figs. 8 and 9 show, respectively, the time for computing collection and concept subsumers matrix in function of the number of concept components (constant number of profiles).
In this second test category the resulting functions are almost linear. The offset from average times for tests with the same number of profiles and concept components is due to connection delays in the reasoner querying process. 6. Related work
Recent research in human resources management is populated by several attempts to overcome limits of classical keyword-based retrieval by enriching resource descriptions through a semantic annotation. Non-logic approaches to retrieval show their limits in efficiently managing the informative content of knowledge resources. As an example, database querying or search based on similarity between weighted vectors of stemmed terms  X  a typical approach of text-based Information Retrieval  X  have been used to evaluate possible matches between job offers and candidates ( Veit et al., 2001 ). Even if recent systems for ranking candidate answers w.r.t. a job offer have been proposed ( Kessler et al., 2008 ), forcing profiles in being expressed by data structures or terms vectors does not allow to deal with incomplete informa-tion, always present in matchmaking contexts as either unavail-able or irrelevant data.

Skill matching has been also modeled as a graph containing two sets of nodes. The first one includes employees and the second one tasks to be performed ( Saip and Lucchesi, 1993 ).
Edges link people to tasks. A cost function associates each edge with a real value, hence a weighted graph ensues, where the association task-people results in a well-known problem in Operational Research area: the  X  X  X ssignment X  X  one ( Galil, 1986 ; Hillier and Lieberman, 1995 ; Kennington and Wang, 1991 ).
The assignment is only based on the evaluation of matching cost, which neither takes into account semantics nor is automatically computed. As a consequence such approaches show their limits both in effectiveness and in expressiveness.
 In Sure et al. (2000) , two skill matching systems  X  ProPer and
OntoProper  X  were presented, both storing in a database skill profiles represented as vectors. Approaches derived from decision theory are exploited to allow approximate matches, not allowed by plain database queries. OntoProper also embeds an ontology so reducing the effort for database maintenance. In fact, database information is updated/enriched with facts derived from second-ary information sources, such as project documents. Unfortu-nately, both systems lack of an ontology modeling skills and a KB storing job positions, hence inferences on introduced profiles are made impractical.

In Becerra-Fernandez (2000) two people finder knowledge management systems are proposed: the searchable answer generat-ing environment ( SAGE ) and the expert seeker . Both use databases as skill repositories and a query engine for retrieving expertise (keyword-based as well as other search options are allowed).
There is no possibility of both eliciting knowledge from skill matching operations and to keep automatically up to date profiles.

Also agent-technologies have been employed to support the search of the right expert: in Garro and Palopoli (2003) it has been proposed an XML multi-agent system providing, among many other facilities, support in searching the most suitable employee for a specific job. Although agent-technologies allow for a high degree of automation in skill search, the proposed framework needs a significant formalization effort to achieve the expressive-ness required for the knowledge representation problem.
The issue of performing the right modeling of competences to facilitate the further matching phases has been addressed by Keenan (2004) , where a web-based system for validating relation-ships among skills modeled in a graph structure is set. The proposed modeling does not handle semantics, causing the matching process not to be semantic-based.

In spite of the variety of non logic approaches proposed so far, the use of ontologies as knowledge repositories has been largely recognized as useful to provide a common vocabulary, to use inference services ( O X  X eary, 1998a , b ) and to model general knowl-edge management procedures ( Holsapple and Joshi, 2004 ). Competence definition initiatives like IEEE Reusable Competency Definition (IEEE RCD) 5 and HR-XML measurable competencies evidence the need for interoperable and machine-understandable data structures for managing knowledge description.

In Lau and Sure (2004) an ontology-based skill management system is proposed, allowing employees to elicit their skills and contributing to an advanced expert search through the intranet. Such an approach only handles explicit information in the matching process and is mainly focused on competence gap analysis.

In Liu and Dew (2004) a system integrating the accuracy of a semantic-based search with the flexibility of a keyword-based search is proposed to find expertise within academia. The system is based on the use of semantic Web technologies  X  particularly RDF and XML  X  in order to extract expertise profiles from heterogeneous information sources. On the one hand, a problem as complex as expert search would need a higher expressiveness for representation; on the other hand, the keyword-based search process apparently does not takes semantics into account.
In Coi et al. (2007) a novel, machine-understandable definition of competences is proposed able to take into account both proficiency and context awareness in definition of job profiles. Although the paper does not propose a modern, semantic-based, retrieval infrastructure, it provides a useful distinction of compe-tences in required and acquired ones. Particularly, recruiter X  X  need are modeled as  X  X  X trict X  X  or  X  X  X ptional X  X  in required competences and  X  X  X uantitative X  X  information helpful in ranking results (accomplish-ments, dates, marks, experiences), are added in acquired ones. An OWL-DL competence modeling has been also proposed in Schmidt and Kunzmann (2006) to support and integrate most of the aspects of knowledge management, from business process management to competence enhancement, through learning. The effort spent in ontology modeling is valuable, but the paper does not present services exploiting the proposed ontology. In Mochol et al. (2007a) a query reformulation approach through rule rewriting is proposed with the aim of relaxing job requests, typically over-constrained and therefore leading to an unaccep-tably low number of retrieved candidates. The proposed process makes more flexible query formulation, but forces constraint relaxing of the whole query. No logic-based explanations are provided in case of approximate matches. The approach is implemented in a semantic-enabled job portal ( Mochol et al., 2007b ) based on a skill ontology which is part of the HR ontology developed for the knowledge nets project, 7 according to the guidelines proposed in Mochol et al. (2006) . The semantic job portal embeds a match engine relying on the framework proposed in Oldakowski and Bizer (2005) , based on conceptual graphs matching ( Zhong et al., 2002 ). The retrieval process ranks selected candidates by computing the similarity of thematic clusters identified in both job postings and workers profiles. The matching process is, therefore, less accurate than ones based on single features comparison.

A relevant issue arises in using ontologies once they have been built, i.e., reasoners and reasoning services must be designed and implemented to take full advantage from the effort placed in structuring an ontology. Although several semantic facilitators have been proposed in literature for several scenarios ( Staab et al., 2001 ; Sure et al., 2000 ; Trastour et al., 2002 ) often they do not fully leverage the ontological structure limiting their inferences to simple subsumption matching. The work in Colucci et al. (2007a) gathers several semantic-based approaches to retrieval, based on specifically devised non-standard services in description logics.
Thanks to them, the matchmaking process may be extended w.r.t. exact match. Also in Biesalski and Abecker (2006) an approach seemingly similar in overcoming exact matches is proposed. It extends the one for measuring similarities in ontol-ogies by Ehrig et al. (2005) for combining the advantages of similarity-based search with those of ontology-based systems.
Nevertheless, such an approach does not allow to provide expla-nation of results in case of non-exact matches.

In Hefke and Stojanovic (2004) an approach to skill matching, which may appear close to the one proposed in Colucci et al. (2007a) , is presented. It is based on the technique presented in Stojanovic and Stojanovic (2003) for ranking query results.
The relevance of query outcomes is computed taking into account the structure of the underlying domain (using the knowledge base content) and the inference process characteristics. The ranking, though providing a useful support to the choice between the returned profiles, only classifies answers w.r.t. queries formalized with a well-defined structure. Such an approach lacks then of expressiveness in the querying process. Moreover, the open world assumption is not made, because only answers explicitly provid-ing characteristics required by the query are considered. Finally, no explanations are provided about the rationale in case of absence of match.

Nowadays, most of commonly employed recruitment systems are online job search sites that, therefore, need to handle a large amount of unstructured information describing job offers and profiles. In Kessler et al. (2009) a system supporting analysis and categorization of job offers and candidates responses is proposed.
The system aims at automating the recruitment process by implementing strategies based on vectorial and probabilistic models to solve the problem of profiling applications according to a specific job offer. A noteworthy effort is placed in the information extraction, but the paper lacks of a semantic-based matching mechanism.

All the systems and approaches so far outlined deal with the search for skills among the available assignees. Creating new competencies when the available ones are not enough to perform all the needed tasks may represent a competitive advantage opportunity. In order to achieve such knowledge creation, KMSs may integrate components supporting the training process of employees, exploiting e-learning technologies. The term e-learning has become common, describing several concepts, from complete web-based courses to distance learning and tutoring. Recently, also thanks to various standardization efforts ( IEEE, 2003 ), emphasis has been placed on the concept of learning object i.e., small and easily reusable educational resources to be composed to allow persona-lized instruction and courseware creation ( Vossen and Jaeschke, 2003 ; Ajami, 2004 ; Cabezuelo and Beardo, 2004 ; Ip et al., 2002 ).
Obviously, discovery and composition of such learning objects in an automated way requires the association of unambiguous and semantically rich metadata, defined in accordance with shared ontologies ( Sanchez and Sicilia, 2004 ; Sicilia and Lytras, 2005 ).
The LOM  X  learning object metadata ( IEEE, 2002 )  X  standard, though limited in the basic annotation items, allows to freely define annotated metadata describing a learning resource.
The semantic-based annotation of educational resources is hence fully in the stream of the semantic Web initiative ( Berners-Lee et al., 2001 ), and it can share with it both techniques and approaches ( Bennacer et al., 2004 ; Gasevic et al., 2004 ; Sanchez and Sicilia, 2004 ).

In particular, as more and more learning objects become avail-able on the Web as services with well-defined machine interpre-table interfaces as described e.g., in OWL-S ( OWL-S, 2004 ; Sycara et al., 2003 ), personalized learning units can be built by scratch, by retrieving learning resources. Automated composition of learning resources, exposed as Web services for example, can then match a personalized learning need.

Recent studies ( Draganidis and Mentzas, 2006 ) underline the rarity of approaches integrating knowledge and learning manage-ment: in this paper an approach of such kind has been proposed.
The semantic-based integration of competences with learning needs is also tackled e.g., in Draganidis et al. (2006) . Nevertheless, relying on standard services and on RDQL, such systems cannot deal with approximation nor provide explanation services.
An alternative proposal of integration may be found in Karam et al. (2007) , in which the composition of learning objects is based on the solution of a concept covering problem defined in terms of
LCS computation. Such an approach, although dealing with approximation, does not provide explanation facilities.
One attempt to integration mostly focused on knowledge modeling is proposed in Sicilia et al. (2006) , which present a case study for modeling e-learning procedures in the general purpose ontology for knowledge management proposed in Holsapple and
Joshi (2004) . The paper nevertheless does not cope with auto-mated search of knowledge resources. 6.1. Commercial tools
Currently, several commercial tools for talent management and e-recruitment are available. Most of them are enterprise suites supporting human resource management, including solu-tions that, even though improving the recruitment process by means of innovative media and tools, do not introduce a significant novelty charge. Available solutions in fact exploit databases to store candidate personal and employment informa-tion, and do not ground on a logic-based structure.

To the best of our knowledge, one of the first logic-based solutions for recruitment and referral process is STAIRS, in use at US Navy Department allowing to retrieve referral lists of best qualified candidates w.r.t. a specific mansion, according to the number of required skills they match. The commercial software supporting STAIRS is RESUMIX 10 an automated staffing tool making use of artificial intelligence techniques and adopted only as an internal tool. The system allows also to distinguish skills in required and desired ones in the query formulation: all required skills must be matched by the retrieved candidate, differently from desired ones. No explanation is returned for the proposed solutions.

Among semantic-based tools for recruitment, noteworthy are products offered by Sovren, 11 which provide solutions for both CV and job requests parsing starting from several text formats to
HR-XML schema. A semantic-based matchmaking engine automati-cally returns a ranked list of best candidates given a job vacation, posted in any textual format. The matching process is by the way completely hidden to the recruiter, which does not receive any explanation about retrieved results. Sovren tools also manage the distinction between required and preferred skills in job offers posting.

Last year Monster : com  X  R  X  , the leading Web job matching engine, introduced MonsterPowerResumeSearch TM 12 to improve the rele-vance of candidates recruitment. The product relies on the semantic 6 Sense  X  TM  X  search technology, patented by Monster
Worldwide, Inc. itself. Thanks to such a semantic search technol-ogy, the novel engine retrieves candidates according to most of their qualifications including how closely they match job require-ments, the recency of their experience, how they compare to similar candidates. The query interface allows for distinguishing between essential and nice-to-have skills and allows the user to describe her request in natural language keywords. The search process exploits the semantics of queries and available candidate profiles to rate them w.r.t. to the entered search criteria and rank them according to the comparison between each other.

Summarizing, the proposed KMS presents several distinguish-ing features w.r.t. approaches existing both in literature and in commerce, above reported. It is a semantic-based system, which incorporates in a unique modeling framework knowledge management solutions related to different organizational needs, rarely  X  if ever  X  faced from an integrated perspective. To the best of our knowledge, it is among the few systems fully exploiting the knowledge representation effort spent in modeling informative resources. The KMS proposes, in fact, significant explained solu-tions double-tied with description logics inferences. Moreover, such inferences have been specifically developed for explanation purpose, causing functionalities provided by the system to be original. 7. Final remarks
A growing interest in solutions extracting more informative and meaningful results from knowledge resources is witnessed both in literature and in actual commercial systems. Fully in this trend, we propose the integration in a single knowledge manage-ment system of a variety of advanced semantic-based services supporting competence management. The KMS treats compe-tence as any other material asset, and exploits the knowledge sources descriptions stored in a shared repository, working as a competence warehouse. The employed formalism for knowledge representation, description logics, on the one hand ensures inter-operability of our services with the languages developed for the semantic Web initiative ad on the other hand allows all imple-mented solutions to exploit non-standard DL inferences devised to overcome some limits of available standard ones. The imple-mentation of such non-standard inferences ensures the novelty of our system by distinguishing it from any other available solution.

The main contribution of the paper is the seamless integration of recently proposed services supporting long term strategical choices in a KMS devoted to human resources allocation and training programs planning. Our KMS allows in fact for searching in the warehouse for the knowledge resources needed to solve a task in three different multiplicity cases. Furthermore, our system supports the identification of flexible learning resources present in the repository to plan training programs aimed at covering skills missing in the figurative warehouse. The introduced services supporting long term strategical choices add a third class of functionalities for the evaluation of company core competence and the determination of knowledge clusters the company possibly belongs to. In particular, new non-standard inferences have been defined for the identification of company core compe-tence from the knowledge warehouse and related computation algorithm have been implemented and evaluated.

Computation algorithms for such inferences in DLs more expressive than ALN have been object of our investigation ( Colucci et al., 2008b ) and led to the introduction of a tableau-based framework for least common subsumer computation ( Donini et al., 2009 ), recently generalized for the solution of several non-standard inferences ( Colucci et al., 2010 ). The imple-mentation of such a framework is object of our current research work, aimed at the release of a novel KMS version able to handle more expressive descriptions in the knowledge warehouse while still solving introduced non-standard inferences crucial for com-petence management.
 Acknowledgments The authors acknowledge partial support of Apulia Region Strategic Project L X  X RMA  X  Processes and technologies supporting quasi-markets in logistics (PS 025).
 Appendix A. Basic description logics
DLs are a family of formalisms and reasoning services widely employed for knowledge representation in a decidable fragment of first order logic.

The alphabet of each DL is, therefore, made up by unary and binary predicates, denoted as concepts names and role names , respectively. The domain of interest is represented through more expressive and complex concept descriptions , involving construc-tors over concept and role names. The set of constructors allowed by a DL characterizes it in terms of expressiveness and reasoning complexity: of course the more a DL is expressive, the harder is inferring new knowledge on its descriptions.

Concept definitions allow to assign an unique concept name to complex concept descriptions: the so-called unique name assump-tion (UNA) holds in every DL. Names associated to concept descriptions constitute the set of defined concepts , distinguished by primitive concepts not appearing on the left hand side of any concept definition and corresponding to the concept names. Defined and primitive concepts constitute the set of concept names, which will be referred to by the letter A in the following; C and D will denote instead arbitrary concept descriptions.
Concept inclusions detail instead specificity hierarchies among concepts, either defined or primitives.

The set of concepts inclusions and definitions represents the formal representation of the domain of interest, the intensional knowledge which takes the name TBox in DL systems and Ontology in the generic knowledge representation framework.
TBoxes containing recursive concept definitions are called cyclic ( acyclic otherwise).

The semantic of concept descriptions is conveyed through an interpretation I  X  X  D I , I  X  , where D I is a non empty set denoting the domain of I and I is an interpretation function such that: I maps each concept name A in a set A I D D I I maps each role name R in a binary relation r I D D I D I Possible DL constructors and the related semantics are shown in Table A1 . 13
The behavior of the interpretation function in presence of concept definitions and inclusions is detailed in Table A2 and can be inductively explained by taking the semantics of allowed constructors into account.

An interpretation I is a model for a TBox T if it satisfies the whole set of assertions in T .

A DL system embeds also an assertional component, which takes the name ABox and includes the following two possible elements:
Concept assertions : C ( a ) states that individual a belongs to the concept description C
Role assertions : R  X  a , b  X  states that individual a participates to role R with individual b
An interpretation I assigns an element a I of the domain D to each individual a and is a model for a ABox A if it satisfies  X  a I , b I  X  A R I for all role assertions R  X  a , b  X  A A and a I concept assertions C  X  a  X  A A .

The proposed KMS adopts ALN sublanguage of DLs for knowl-edge representation. The full expressiveness of ALN is explained, with the aid of constructors usage examples, in Table A3 .
Ontologies using DL can be easily modeled using languages for the semantic Web ( DAML  X  OIL, 2001 ; McGuinness et al., 2002 ;
OWL, 2004 ; OWL 2 Web Ontology Language Structural Specification and Functional-Style Syntax, 2009 ). These languages have been conceived to allow for representation of machine understandable, unambiguous, description of web content through the creation of domain ontologies, and aim at increasing openness and inter-operability in the web environment. The strong relations between
DLs and the above introduced languages for the semantic Web languages (OWL-Lite, OWL-DL, OWL-Full), which reach the same expressiveness as SHOIN ( Horrocks et al., 1999 ). One more evidence may be found in the introduction of OWL2, which extends the semantics of the description logic SROIQ ( Horrocks et al., 2006 ).

Thechoiceof ALN may appear limiting in terms of expressive-ness, but such a languages allows for keeping bounded the com-plexity of reasoning. In particular standard inferences may be computed in polynomial time in ALN ( Borgida and Patel-
Schneider, 1994 ) and non-standard reasoning may be exploited to provide crucial advanced services, also solvable in polynomial time.
The most important service characterizing reasoning in DL checks for specificity hierarchies, by determining whether a concept description is more specific than another one or, formally, if there is a subsumption relation between them.

Definition 10 ( Subsumption ). Given two concept descriptions C and D and a TBox T in a DL L , we say that D subsumes C w.r.t. T if for every model of T , C I D I . We write C L T D , or simply C we assume an empty TBox.

For example, consider the following concept descriptions, referred to a required task and a personnel profile, respectively: T  X 8 basKnowledge : programming P  X 8 basKnowledge : Java u 8 hasMasterDegree : ComputerScience u Consultant Considering a TBox with the two following concept inclusions Java
L OOP and OOP L Programming , knowledge expressed by P 1 is more specific than the one required by T 1 : according to the previous definition T 1 subsumes P 1 .

Several widely used services may be reduced to subsumption, as shown in the following definitions.

Definition 11 ( Concept equivalence ). Given two concept descrip-tions C and D and a TBox T in a DL L , we say that D is equivalent to C  X  C T D  X  iff C L T D and D L T C .

Intuitively, two concept descriptions are said equivalent if they, regardless of syntactic differences, subsume each other. For example, the descriptions P 1 and T 1 introduced before are not equivalent, because P 1 does not subsume T 1 .

Definition 12 ( Concept satisfiability ). Given a concept descrip-tions C and a TBox T in a DL L , we say that C is satisfiable
Intuitively, a concept description is satisfiable w.r.t. T if there exists any model in T assigning a non empty subset of the domain to it, if it can be somehow interpreted in the knowledge domain.
For example, consider the following profile, adding new features to P 1 : P  X 8 basKnowledge : Java u8 hasMasterDegree : ComputerScience u Consultant u Employee
If T contains the concept inclusion in Table A3 , P 2 is unsatisfiable w.r.t. T , because no interpretation can be given in T to a concept describing an element working both as a consultant and as an employee.
 References
