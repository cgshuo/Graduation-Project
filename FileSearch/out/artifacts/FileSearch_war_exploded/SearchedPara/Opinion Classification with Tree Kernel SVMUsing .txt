 We propose a method for classifying opinions which cap-tures the role of linguistic modalities in the sentence. We use richer features than simple bag-of-words or opinion-holding predicates. The method is based on a machine learning technique, and utilizes opinion-holding predicates and lin-guistic modalities as features. Two different detectors help to classify the opinions: the opinion-holding predicate de-tector and the modality detector. An opinion in the target is first parsed into a dependency structure, and then the opinion-holding predicates and modalities stick onto the leaf nodes of the dependency tree. The whole tree is regarded as input features of the opinion, and it becomes the input of tree kernel support vector machines. We have applied our method to opinions in Japanese about television pro-grams, and have confirmed the effectiveness of the method against conventional bag-of-words features, or against sim-ple opinion-holding predicates features.
 Categories and Subject Descriptors: H.4.m [Informa-tion Systems Applications]:Miscellaneous General Terms: Algorithms, Experimentation, Languages, Theory Keywords: Knowledge Management, Large-scale statisti-cal techniques, Sentiment Analysis, Text Mining  X 
The author is also affiliated with Graduate School of Infor-mation Science and Technology, The University of Tokyo, JAPAN  X  The author is also affiliated with the Text Mining School of Computer Science, University of Manchester, UK and Na-tional Center for Text Mining (NacTeM), Manchester, UK
The task in this paper is to classify opinions into a set of given, currently 8, categories. These categories, shown in Table 1, are being used across different types of TV pro-grams. We have a collection of opinions for 8 TV programs, which 987 viewers submitted. The submitted opinions, 6,989 in total, were classified manually by analysts. Although the viewers were hired by the project, no specific guidelines were given, and thus the corpus reflects the actual comments where the final product of the project will have to deal with.
The 8 categories include categories which are not common in ordinary settings of opinion mining. For example, the cat-egory, Requests to the program , should contain suggestions or requests which viewers think contribute to the improve-ment of the program. A conventional keyword search system may find it difficult, if not impossible, to retrieve all of the viewers X  comments which contain such requests.

The final system will receive an opinion, and will classifie it into one of these 8 categories. Currently, similar tasks are being performed by human analysts, the results of which are actually used by producers/directors of TV programs. These real comments are not available for research, due to legal issues. The details of the opinion corpora on TV programs can be found in [5].
While modality has been variously defined in linguistics, philosophy, etc., there is a broad understanding that infor-mation conveyed by utterances is divided into two types. One type is objective, or consists of propositional content, while the other is subjective, or consists of propositional attitude. Broadly defined, the latter includes not only ordi-nary modals in logic such as Necesiity, Possibility, etc. but also a variety of things such as the speakers X  belief, desire, understanding, guess, etc. The modality in this broad sense has a strong bearing with opinion-holding expressions.
In Japanese, modalities in the sense of propositional at-titudes are often expressed by a sequence of auxiliary verbs which follow the main verb in a sentence. In some cases, a sequence which contains even nouns or verbs is also used as a canned expressions of modality which follows the main verb. As Table 2 shows 1 , rich information, including as-pects, tenses, voices, etc. as well as modalities are expressed in such sequences following the main verb. Modality analy-The meaning categories are an excerpt from the Japanese Functional Expressions Dictionary[7, 8], translated and clas-sified by us. The original dictionary contains 341 functional expressions with their 16,801 inflectional forms, and they are classified into 89 meaning categories.
 edge. The list of words together with the spanned edges are regarded as a graph. The words are disambiguated by determining the best candidate path calculated with a prob-abilistic model, for which we chose a Markov model. The accuracy of detecting functional expressions is about 98(%).
A novel part of this study is that the system tries to cap-ture the sentence structure, and tries to estimate the role of the opinion-holding expressions in the sentence.

For dealing with both the opinion-holding predicates and modalities, we have laid out the two detectors side by side, because they are independent of each other and can be exe-cuted in parallel. The system architecture is shown in Fig-ure 1. The input sentence is first morphologically analyzed and is divided into the sequence of words. Then, the depen-dency parser chunks the words and conducts a dependency analysis. The sequence of words forms a parsed tree, and goes into two parallel parts: the predicate detector, and the modality detector. Each detector reports the candidates of opinion-holding expressions for the succeeding component, the integrated judgement component. The integrated judge-ment considers all of these candidates, and decides the final output category by using a machine learning system.
The opinion-holding predicates in the input sentence are detected by the predicate detector. The predicate analysis nominates the opinion-holding verbal and adjective words or clauses which are stored in the pre-defined dictionary, each entry of which is connected to a candidate of the output category. We manually prepared a small dictionary made up of 472 vocabulary terms.
Modality detector uses a functional expression detector which is described in detail in Section 3. Since the functional expression detector does not require dependency informa-tion, the output of the dependency analysis is not used; the sequence of words are used instead in the system architec-ture, and after the modalities are detected, each modality sticks into the dependency tree.

The modality detector post-processes the output of the functional expression detector, so that the relevant 20 of the 89 meaning categories from the functional expression detector output is filtered by a rule. gory number, as in Table 1, and the  X  X odality-type X  is the modality category.

The  X  X utput accuracy X  column displays the accuracy of an opinion classification task. The classification categories are described in the upper 5 rows in Table 1.

We conducted two kinds of experiments. The  X  X losed X  la-bel indicates the opinions that are used for both training and testing. Since the system knows the answers in the training data, this experiment is a bit erratic. However, we can ob-serve the richness of the input features, because the figures of the closed experiments is thought to show the upper-limit of the system. The  X  X eave-one-out X  label indicates an instance where one opinion is left out from the training and is used to test itself; all of the opinions are chosen as such for cyclical testing. This test is an open experiment that indicates a realistic performance. The top four accuracies are shown in bold face, and are above 77(%).

Our method can be seen as a natural extension of con-ventional methods. In a conventional method, there are two kinds of baseline systems, which are dependent on the avail-able NLP resources. One baseline is the bag-of-words fea-tures, and the other baseline is the bag-of-words features with the opinion-holding predicate.

The first baseline, classification with bag-of-words fea-tures, is shown in the  X  X ag X  of  X  X ord-surface X . As shown, fea-tures of  X  X ep-tree X  with  X  X red-surface X ,  X  X red-category X , and  X  X odality-type X  show a significantly better accuracy than did the baseline.

The second baseline, classification with the combination of bag-of-words and opinion-holding predicates features, is shown in the  X  X ag X  of  X  X ord-surface X ,  X  X red-surface X , and  X  X red-category X . The accuracy is relatively high (76.86%); however, the best performance was achieved by the X  X ag+dep-tree X  of the same features. The accuracy is 1.23 point higher, and the error reduction rate is 5.32(%).

We then compared our system to other systems that deal with similar tasks. One of the tasks in [10] contains reviews on movies, which are also considered to be media contents, as is the case for TV programs. In [10], binary classifications are made  X  positive and negative opinions, with semantic orientation of the adjective or adverb dictionary words. The accuracy remains relatively low, at around 65 to 67(%) for this domain, while the accuracy for product reviews scored higher than 80(%). Although the task is not exactly the same as in ours, our system seems to perform quite compet-itively.
We have proposed a method for mining opinions with lin-guistic modalities. The method uses modality analysis as well to detect the subjective part of an opinion, and uses the tree kernel SVM to capture the role of the subjective part in the sentence. The experiments show the effective-ness of the method.
 The authors would like to thank Prof. Takehito Utsuro, Prof. Satoshi Sato and Dr. Suguru Matsuyoshi, Dr. Simon Clippingdale, Dr. Yusuke Miyao, Dr. Takuya Matsuzaki and Dr. Makoto Miwa for useful discussions, as well as to Mr. Jiro Sekiba, Mz. Chieri Matsuda and Mz. Rumi Mu-rakami for the research supports.
