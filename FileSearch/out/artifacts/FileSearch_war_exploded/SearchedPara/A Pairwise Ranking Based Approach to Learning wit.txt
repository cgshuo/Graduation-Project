 A large fraction of binary classication problems arising in web applications are of the type where the positive class is well dened and compact while the negative class comprises everything else in the distribution for which the classier is developed; it is hard to represent and sample from such a broad negative class. Classiers based only on positive and unlabeled examples reduce human an-notation effort signicantly by removing the burden of choosing a representative set of negative examples. Various methods have been proposed in the literature for building such classiers. Of these, the state of the art methods are Biased SVM and Elkan &amp; Noto's methods. While these methods often work well in practice, they are computationally expensive since hyperparameter tuning is very important, particularly when the size of labeled positive examples set is small and class imbalance is high. In this paper we propose a pairwise ranking based approach to learn from positive and unla-beled examples (LPU) and we give a theoretical justication for it. We present a pairwise RankSVM (RSVM) based method for our approach. The method is simple, efcient, and its hyperparame-ters are easy to tune. A detailed experimental study using several benchmark datasets shows that the proposed method gives compet-itive classication performance compared to the mentioned state of the art methods, while training 3-10 times faster. We also propose an efcient AUC based feature selection technique in the LPU set-ting and demonstrate its usefulness on the datasets. To get an idea of the goodness of the LPU methods we compare them against su-pervised learning (SL) methods that also make use of negative ex-amples in training. SL methods give a slightly better performance than LPU methods when there is a rich set of negative examples; however, they are inferior when the number of negative training examples is not large enough.
 Categories and Subject Descriptors: I.5.2 [Pattern Recognition] Design Methodology-Classier design and evaluation General Terms: Algorithms, Performance, Experimentation Keywords: Learning with Positive and Unlabeled Examples, Pair-wise Ranking, Classication, Support Vector Machines
Binary classication problems arise frequently in web applica-tions. Traditionally binary classiers are built via supervised learn-ing (SL) using a training set that consists of manually collected positive and negative examples. Consider, as an example, the prob-lem of forming a classier that determines if a page contains re-views of restaurants or not. While it is easy to sample from the positive class, i.e., collect a representative set of pages having re-views of restaurants, it is not that easy to form a representative set of negative examples. What is usually done in practice is to analyze the domain and choose `boundary' negative examples that are truly negative but which potentially look like positive examples. For in-stance, in the case of the restaurant reviews example one can choose the following as (boundary) negative examples: pages that describe restaurants but do not contain reviews; and pages that only contain reviews of businesses other than restaurants. There are two prob-lems with this approach. (1) The relative proportion of positive and negative examples in the training set may not be indicative of the corresponding proportion in the space of pages where the classi-er will be deployed. (2) It is possible that other types of negative examples that are similar to positive examples are missed during the analysis. Several other interesting web applications of a similar kind can be found in [16][23].

While it is hard to choose representative negative examples, it is usually easy to form a large collection of unlabeled examples from the space of interest. Therefore it is useful to look for methods that learn from positive and unlabeled examples (LPU). The presence of positive examples in the unlabeled set and high class imbalance (ratio of positive to negative examples is small) bring in challenges in building classiers in the LPU setting. Various approaches have been suggested in the literature [2],[8],[9],[16],[18],[19],[20],[21], [23],[24] for solving this problem. These approaches differ in the way the examples are used, the type of classiers employed, etc. The main aim of this paper is to propose a new approach for LPU. This approach is related to two good LPU methods, namely, Biased SVM [18] and a method recently proposed by Elkan and Noto [9]. We will refer to these methods as BSVM and EN re-spectively. These methods are based on building a binary classi-er that separates positive examples from unlabeled examples; the above mentioned papers also provide good theoretical justications for the proposed idea. The BSVM method has been demonstrated to work well in practice; however, 2-dimensional hyperparameter tuning using cross-validation makes it computationally expensive. In [9] the EN method was demonstrated to work well using a de-fault hyperparameter setting on a dataset that is not imbalanced. In general, for imbalanced datasets EN also requires expensive 2-dimensional hyperparameter tuning to achieve good classier per-formance. In addition, EN requires the estimation of some proba-bilistic quantities, which is of concern in imbalanced situations.
Our approach for LPU is based on ranking and we give a theoret-ical justication for this. We use the pairwise ranking method [7], [13]. The basic idea is to rst build a ranking model that encourages the score of each positive example to be higher than that of each un-labeled example and then estimate a threshold parameter to form the nal classier. The approach is general in the sense that any pairwise ranking method can be used. In this paper we use a sup-port vector machine (SVM) based ranking method (RSVM) pro-posed in [7],[12],[13] for learning, and employ the efcient RSVM solver in [7] for fast solution. The main advantage of the proposed method over BSVM and EN is that it has only one hyperparameter (
C ); an additional threshold parameter ( ) can also be estimated efciently. Further, it is easy to implement using publicly available RSVM codes [5],[14]. Experimental results show that our method gives a performance that is competitive with BSVM and EN, while being 3-10 times faster than them.

A second contribution of this paper is the proposal of a new technique for doing feature selection in the LPU setting. Feature selection is useful in web classication since it helps to remove useless/redundant features and thus reduce classier complexity. Except the recent work of Calvo et al [3], there is no other tech-nique for feature selection in LPU that we are aware of; Calvo et al's technique is limited to discrete variables and also requires addi-tional knowledge on the fraction of positive examples. Our feature selection method is free of such limitations, is based on comput-ing the best AUC value possible with each feature used alone, and works effectively; for instance, an order of magnitude reduction in the number of features can be achieved using it with a loss in F Measure performance of only 2-3%.

A third useful contribution of the paper is a detailed set of exper-iments that shed insight on various methods in the SL and LPU set-tings. The paper is organized as follows. Related work is presented in adequate detail in Section 2. Section 3 describes our method in detail followed by a presentation of our AUC based feature selec-tion technique in Section 4. The discussion of the various methods in Section 5 forms a prelude to the detailed empirical evaluation and comparison of methods given in Section 6. We conclude the paper in Section 7.
Various approaches have been suggested in the literature to solve the problem of positive example based learning [2],[8],[9],[16], [18],[19],[20],[24]. These approaches differ in the way the dataset is constructed and used by the methods, and by the choice of clas-siers employed. In the rst approach, the dataset consists of only labeled positive examples. One-class SVM [20] is one such ap-proach and it does not use any unlabeled examples U . The classier is built using only P . In One-class SVM, the origin is considered to be the only member of the negative class. A previous study in [17] shows that the performance of one class SVM is poor. Wu et al [22] studied one-class SVMs in detail and showed that the poor performance can partly be attributed to document representation. They empirically showed that a modied document representation helps in improving classication accuracy.

In the second approach, unlabeled examples ( U ) are also used along with the labeled positive examples ( P ). The methods that use this approach differ in the way they use the unlabeled examples. In one such class of methods, the classier is built iteratively. For ex-ample, suppose a set of reliable negative examples R ( i ) from the unlabeled set U , say, in i -th iteration and a classier is built using P and R ( i ) predictions of C i on U R ( i ) terion is met. These techniques are referred to as 2 step techniques in [9],[18], where identifying R N is the rst step and the second step is building the standard classier using them. Roc-SVM[17], S-EM[19], PEBL[23] and Support Vector Mapping Convergence (SVMC) [24] are some of the well known 2-step techniques with some variations.
 In another class of methods, Denis et al [8] showed how the Naive Bayes algorithm can be adapted (called positive Naive Bayes (PNB)) for learning from positive and unlabeled examples. Subse-quently, Calvo et al [2] enhanced the PNB algorithm and also pro-posed a Bayesian approach to deal with the prior probability of the positive class.

Semi-supervised learning methods can be used to solve LPU; see [21]. But these methods require a knowledge of the fraction of positive examples in the distribution.

Biased SVM (BSVM) [18] falls under another class of positive example based learners. It treats all the unlabeled examples negative examples; that is, f y i = 1 : i 2 P g and f y i U g . The SVM classier is built by giving appropriate weights to the positive examples P and unlabeled examples U . It solves the following optimization problem: Here C P and C U are the weights given to the classication error on P and U respectively; w and denote the weight vector and threshold parameter of the SVM classier; x i and i denote the input feature vector and slack variable respectively. Intuitively, is expected to be given a higher value than C U . This is because is noise-free and U contains noise as it contains positive examples as well. Liu et al [18] showed that the BSVM method outperforms the 2-step techniques.

Elkan &amp; Noto [9] also considered the problem of learning from positive and unlabeled examples. Let us represent each training example by ( x ; y; s ) where y 2f 1 ; 1 g is the class label of the example and let s be a binary variable that denotes if the example is labeled ( s = 1 ) or unlabeled ( s = 0 ). By making the (reason-able) assumptions that (i) P is chosen by labeling randomly chosen positive examples and (ii) p ( s = 1 j y = 1) = 0 (that is, nega-tive examples are never labeled), they derived the following useful result: p ( s = 1 j x ) = Kp ( y = 1 j x ) where K = p ( s = 1 j y = 1) Note that K is independent of x and so p ( s = 1 j x ) and are proportional to each other.

Using the above result Elkan &amp; Noto [9] suggested two meth-ods. In their rst method (EN1), a rst stage classier that predicts probability of an example as labeled p ( s = 1 j x ) is learnt by treat-ing each positive example as belonging to labeled class and each unlabeled example as belonging to unlabeled class. Now given a test example x , p ( s = 1 j x ) is estimated using this classier; then p ( y = 1 j x ) is estimated as: p ( y = 1 j x ) = p ( s = 1 j x ) =K constant K = p ( s = 1 j y = 1) is estimated using a validation set. In the second method (EN2), another classier (second stage) is learnt by giving each training example a different weight using the estimated probability from the rst stage classier. EN2 is much more complex than EN1 because it involves two stages of classi-cation. In the rest of the paper we will use EN1 to represent Elkan and Noto's method, and simply refer to it as EN.

Since the new approach that we propose for LPU in section 3 is based on ranking, it is useful to review some related work on rank-ing methods. Learning to rank is an important problem [1],[7],[11], [12],[13] in various applications like web search ranking, informa-tion retrieval etc. For example, in web search ranking the training data consists of a number of queries and for each query there is an associated set of returned documents. For each (query, document) pair there is a feature vector x i , i = 1 ; : : : ; n and a relevancy judg-ment of how suitable the document is to the query. The aim is to build a ranking model that ranks a set of documents based on rel-evance scores for a given query. There are several methods known as pointwise methods, pairwise methods, etc., to address this prob-lem. See [7] and references given there. Here we consider only the pairwise ranking method. In this method rst a set of preference pairs Q is constructed by comparing the relevance of the documents associated with a given query. If ( i; j ) 2 Q then document ferred over document j . A specic example is the ranking model based on SVM (RSVM) that is built by minimizing the following objective function [7]: where g ( ) is a suitable loss function. Typical loss functions are L 1 and L 2 loss functions dened as: g ( t ) = max (0 ; 1 t ) g ( t ) = max (0 ; 1 t ) 2 . The use of the L 1 loss leads to the method in [13]. In the next section we show how this formulation can be used to learn from the labeled positive and unlabeled examples. Other pairwise rank modeling methods like RankNet [1] and Rank-Boost [11] can also be used.
Our aim is to nd a classier function f ( x ) = w T x + such that f ( x ) = 0 represents the boundary between the positive and nega-tive classes; we want to do this using only positive and unlabeled examples. The essence of our approach consists of two steps. First we nd w such that, along the w T x score axis positive examples are placed higher than negative examples. Given the lack of neg-ative examples, we instead work on placing the positive examples higher than the unlabeled examples and this can be achieved using a ranking method. In subsection 3.1 we borrow ideas from Elkan and Noto [9] to give a theoretical justication for this. A ranking method such as RSVM is used to form w . In the second step we choose the threshold by maximizing a proxy F Measure. We give all the details associated with these steps as well as the complete design in the rest of the section.
Let us begin by recalling (2). If we take two examples x x , (2) implies In fact Elkan &amp; Noto [9] make the observation that if the classier is only used to rank examples x according to the chance that they belong to class y = 1 , then the classier p ( s = 1 j x ) directly instead of p ( y = 1 j x ) .

In linear classiers such as logistic regression (where the proba-bility function is in-built) and large margin methods such as SVM (where the probability function is formed after the classier is de-signed), the probability of belonging to the positive class at a given x has a monotonic relationship with the scoring function ~ f ( x ) = w For us the take away from the above two results is the following. Let P , N and U denote positive, negative and unlabeled exam-ple index sets. We are interested in building a classier that ranks positive examples higher than negative examples, i.e., ~ ~ f ( x j ) for all ( i; j ) 2 P N . By the monotonic relation between ~ for all ( i; j ) 2 P N . By (4), this is equivalent to asking for ( i; j ) 2 P U to achieve this. By invoking the monotonic relation between ~ f ( x ) and p ( s = 1 j x ) we can see that building such a clas-sier is same as building a classier that satises ~ f ( x i for all ( i; j ) 2 P U .

While the above results and arguments suggest how to build a ranking model ( ~ f ) in the LPU setting, we need a classier model ( f ) for which we need to set a value for the threshold parameter . We determine this parameter using an idea given by Liu et al [19]; we will give the details in subsection 3.3.
A ranking model based on SVM (RSVM) [7],[12],[13] is con-structed by minimizing a regularized margin based pairwise loss as given in (3). Our binary classication context correspond to a simpler case of the more general ranking model given in [7] with a single query and two relevance values; the given can be partitioned into two sets that dene a binary classication problem: A = f i : x i is in the higher relevance class g B = f i : x i is in the lower relevance class g . In our context, we set A = P and B = U ; that is, the labeled positive examples belong to the higher relevance class and the unlabeled examples belong to the lower relevance class. Then from (3) we have the following objective function: where g ( ) is a suitable loss function and we choose g ( ) L2-loss function. One can also use L1-loss function; often there is very little difference in their performances. This objective function penalizes any violation of ~ f ( x i ) &gt; ~ f ( x j ) ; i 2 P; j 2 U margin where ~ f ( x ) = w T x ; it can be minimized using the Trun-cated Newton method efciently [7]. A key aspect of this objective function is that the summation is over all pairs of examples in the sets P and U ; therefore, the computational cost can be prohibitively high if done crudely. In [7] a very efcient solution to this problem is obtained with computational complexity O ( n log n + n n and n nz denote the number of training examples and number of non-zero elements in the ( j P j + j U j ) d data matrix respectively. (Here d is the number of features, i.e., the dimension of
The choice of the hyperparameter C in (5) and the threshold pa-rameter play important roles in the classication performance. They can be selected using standard 5-fold cross-validation (CV) technique by computing a suitable measure. In this technique we partition the sets P and U separately into 5-folds. We build ve models where each model is built using one combination of 4-folds of data and then evaluated on the corresponding left-out 5th fold of data.
In traditional binary classication problems, measures like val-idation set accuracy and F Measure are typically used. While the accuracy is dened as the percentage of examples correctly clas-sied, F Measure is dened as F = 2 pr precision and recall (with respect to the positive class) respectively. Precision p is dened as: p = T P r = T P j P j where T P and F P denote the number of true positive and false positive examples respectively. ^
F Optimization Unlike standard binary classication problems, we do not have all the examples labeled; also, we have only posi-tive examples. Therefore, it is not possible to nd FP and hence we cannot directly use the F Measure. Simply using the accuracy mea-sure based on the labeled positive examples is not good enough. This is because we also would like to to minimize the number of unlabeled examples getting classied as positive. This requirement is motivated by the key observation made by Liu et al [18],[19]:  X  If the sample size is large enough, minimizing the number of un-labeled examples classied as positive while constraining the pos-itive examples to be correctly classied will give a good classier." While using this principle as a guideline it is also necessary to be in tune with F Measure (giving appropriate importance to the positive class). The following F Measure like quantity (we call it as proxy F Measure ) due to Lee and Liu [16] 1 satises these requirements: where ^ P ( f ( x ) 0 ) = TP + UP beled as positive; UP (Unlabeled Positive) denote the number of unlabeled examples classied positive and r = T P Therefore, we can rewrite ^ F as: ^ F = T P 2 j P j are xed, it is seen that the numerator maximizes the number of labeled positive examples to be correctly classied as positive and the denominator minimizes the number of unlabeled examples classied as positive . This measure when used to optimize both C and in the LPU setting gives a good classier. For a given value we nd the optimal value for the threshold parameter using 5-fold CV technique. The threshold value that gives the maximum average ^ F over the 5-folds is chosen as the optimal threshold value ( C ) . The optimal C value is chosen similarly as the one that gives the best ^ F value. In all our experiments we used this ap-proach to choose the hyperparameter. Finally we note that it is also possible to use other measure like AUC (Area under the ROC) [13] (to choose C ) given below: AU C = j ( i; j ) such that i 2 P; j 2 U; w We can estimate C by maximizing a 5-fold CV estimate of AU C however, given that AU C is unaffected by , estimation of has to be done using an alternate measure such as ^ F .
The algorithmic implementation of the proposed method for learn-ing with positive and unlabeled examples (LPU) is given in algo-rithm 3.1. This algorithm is quite easy to implement with a wrapper module (to perform optimization of C and ) and having the pub-licly available RSVM codes [5] and [14] to solve (5) as the core module. As mentioned earlier, an efcient solution to solve (5) is very useful to reduce the computational complexity. Some varia-eters; they did not use it for tuning .
 Algorithm 3.1 Pairwise RSVM based LPU Algorithm tions of algorithm 3.1 include using the AUC-score (7) to nd the optimal C value, choice of N f , choice of C values in C , etc.
Feature selection is useful in web classication since it helps to remove useless/redundant features and thus reduce classier com-plexity. While there have been several techniques proposed in the literature to address the problem of feature selection in the super-vised learning (SL) setting, class imbalanced condition, etc (see eg., [10], [25]), little has been done in the LPU setting. We are not aware any work other than that of Calvo et al [3], who proposed a correlation based lter selection (CFS) technique which forwardly selects the features by maximizing a merit function; this function is based on the correlation between each feature and the class and on the correlation among the features. The technique has two lim-itations: (i) it works only on discrete data; and (ii) it requires ad-ditional information in the form of either the overall probability of positive examples or some (parameterized) beta distribution that models this probability.

Here we propose an AUC based feature selection (AUCFS) tech-nique. It is generic in the sense that it can also be used in the super-vised learning setting. It is free of the type of limitations mentioned for Calvo et al's method [3].

The AUCFS technique is a lter technique where we take each feature one by one and compute achievable AUC score using only that feature on the training set. This is done as follows. In the sin-gle feature scenario the scoring function is given by ~ f ( x ) = w x where w and x are scalar quantities. Then the AUC score is com-puted using (7). Further with w a scalar and x i;k and x j;k k -th feature value of i -th and j -th examples, w:x i;k &lt; w:x ply either x i;k &lt; x j;k or x i;k &gt; x j;k depending on the sign of Therefore only the sign of w matters and not the magnitude of Thus we do not have to nd w for any individual feature. Now to take care of the sign part, we can compute two AUC scores one each by considering the actual feature value and its negated value sepa-rately. This is necessary because the values for some feature could be higher for positive class examples and lower for negative class examples, and vice-versa. Let us denote AU C ( k ) the AUC scores corresponding to using the k -th feature value and its negated value. Then we compute the AUC score for the feature as: AU C ( k ) = max( AU C ( k ) because with appropriate sign for the weight, the maximum value can be achieved. These quantities can be computed efciently by sorting the feature values. After doing this computation for all fea-tures, the features are ranked by sorting AU C ( k ) ; 8 k order and the required number of features are selected from the top of the list. We do not claim any optimal properties for this se-lection; nevertheless, we found this approach to work well in our experiments.

We note that the AUCFS technique can be applied in the SL set-ting also. While the procedure to compute the scores remains the same, we have j 2 N (negative examples) instead of j 2 U . We feel that, compared to other feature selection metrics AUCFS has the innate ability to be less affected by differences in the distribu-tion of positive and negative examples in the training and test sets. This needs to be tested. For the LPU setting, although it is possible to consider other measures like proxy F Measure, here we restrict our attention to AUCFS technique only. In subsection 6.5 we do experiments to demonstrate the usefulness of AUCFS.
A highlight of this paper is a set of experiments that shed in-sight into various methods in the SL and LPU settings. These ex-periments and the conclusions derived from them are described in section 6. In this section we discuss various practical aspects of the methods and raise questions that form a prelude to the experiments.
SL with SVM and RSVM Since SVM and RSVM (as applied to binary classication in the SL setting) form the basis for LPU methods, it is useful to understand them comparatively. Although these methods are well known we are unaware of any results that compare binary classiers built using them under varying train/test distributions. Note that in the SL setting we have both positive and negative examples for training. Suppose our aim is to maximize F Measure. Since the loss functions associated with SVM or RSVM are not truly designed to optimize F Measure, it is useful to ad-just the classier threshold after the models are trained. We can use 5-fold CV based F Measure to estimate ; the same measure can also be used to optimize the hyperparameters. Hyperparam-eter optimization is easier with RSVM since it involves only one hyperparameter; SVM requires two hyperparameters to effectively handle imbalance data. Experimental results comparing SVM and RSVM in the SL setting are given in subsection 6.2.

SL versus LPU Given that SL also has knowledge of negative examples, one expects that SL will perform better than LPU. Is this true? If so how much is the difference? Also, if the distribution of positive and negative examples in the test set differs from that in the SL train set, does SL suffer, say to the point of being even worse than LPU? One of the weaknesses of LPU is that, given the lack of negative examples, it doesn't have clear cues to set the clas-sier threshold . The proxy F Measure in (6) is what RSVM-LPU (RSVM in the LPU setting) use, but how good is it for choosing ? These are questions worth answering, and are taken up in subsec-tions 6.3 and 6.6.

Hyperparameter Optimization Note that there are three terms in (1); therefore, two hyperparameters will be needed under any reparametrization, unless one hyperparameter is set as xed con-stant times the other hyperparameter. For example, we can also ~ C
P =1 and equal importance is given to both positive and negative examples. However, it is important to have two hyperparameters when the class imbalance is high, which is the case in our setting with large number of unlabeled examples. Furthermore, there is some amount of noise present in the unlabeled examples (when treated as negative examples) since they can contain positive ex-amples. Therefore, for achieving good performance, it is necessary to have two hyperparameters C P and C U in (1). In BSVM the unlabeled examples are treated as negative examples, and the so-lution is obtained by using any SVM solver as the core module and optimizing the hyperparameters C P and C U using the proxy F Measure(6) [18]. Two dimensional grid search to optimize the hyperparameters C P and C U makes BSVM computationally ex-pensive.

In [9] where EN is proposed, there is no discussion of how the hyperparameters must be chosen; in the datasets used there, there is no class imbalance and j P j is not small, and so default hyperpa-rameters give good performance. In our experiments with EN we observed that when the percentage of positive labeled examples is small compared to the unlabeled set size, the performance loss due to the use of default hyperparameters as compared to with hyper-parameter optimization can be quite high. Thus, like BSVM, op-timizing the two hyperparameters C P and C U is necessary for EN too. In fact, the situation is worse with EN since it requires more parameters to be estimated. The additional parameters are: the parameters in the probability model that converts the decision function score to the probability score ( p ( s = 1 j x ) eters are again estimated using cross-validation. Any estimation error in these parameters compounds the performance loss. In our implementation of EN we used the proxy F Measure for selecting the hyperparameters. Since EN is a probabilistic method, proba-bilistic measures (e.g., likelihood) may be worth exploring.
For RSVM we have only one hyperparameter C to be optimized and this reduces the computational complexity signicantly. The following two observations are also relevant here. (i) The com-putational complexity of solving (5) may seem higher compared to solving a standard SVM problem due to pairwise comparison in the data tting term. However, as pointed out at the end of subsection 3.2, (5) can actually be solved efciently. (ii) Even though RSVM needs to optimize the threshold parameter separately, this step is not expensive because the CV data used for C tuning is also used for tuning (see steps 2 and 3 of Algorithm 3.1).

The experiments of subsection 6.4 give more insight on the LPU methods.
We conducted experiments on six benchmark datasets (details are given in Table 1) to answer the following ve questions: (1) In a supervised learning (SL) setting how good is RSVM when com-pared to SVM? (2) How does LPU compare with SL, given the ex-pectation that SL will do much better because it has a knowledge of negative training examples? (3) In the LPU setting how do BSVM, EN and RSVM compare and, how important is hyperparameter op-timization? (4) How effective is the AUC based LPU feature se-lection method? and (5) How good is the proxy F Measure when it comes to setting the classier threshold correctly? In these ex-periments RSVM is used both in SL and LPU settings; so, to avoid confusion we will refer to RSVM in the LPU setting as RSVM-LPU and RSVM in the SL setting simply as RSVM. Throughout, classier performance is measured in terms of F Measure. When the underlying problem is a multi-class problem (News20 and We-bKB) the Macro F Measure (average of the F Measures of all One-vs-All binary classication problems) is used; for computational effort we report the average time over all these problems. While re-porting training time, the time taken by the RSVM based method is considered as the reference and is taken as one unit; then the times taken by the other methods are given relative to this unit. The time is computed as the total training time taken by any given method is as in (8). as it searches over its grid of hyperparameter values. For each hy-perparameter setting, 5-fold CV estimate of F Measure (for the SL setting) or proxy F Measure (for the LPU setting) is used. The search is done in two stages. In the rst stage a coarse grid is used to narrow down the region around the optimal value. Then a ner grid search is carried out in the second stage. For BSVM and EN, and J = f 1 ; 3 ; 9 ; 27 ; 81 ; 243 g ; note that C P = J C SL setting we have C N in place of C U . In the case of RSVM it is set to C = f 10 7 ; 10 6 ; : : : ; 10 2 g . The ner grid contained 6 values around the optimal value chosen from the coarser grid. For BSVM and EN we used Liblinear ( http://www.csie. ntu.edu.tw/~cjlin/liblinear ) since it uses state-of-the-art SVM solvers and is suited for text classication. We integrated the probability estimation module from libsvm [4] ( http://www. csie.ntu.edu.tw/~cjlin/libsvm ) with Liblinear to get the probability estimates for EN. For RSVM, we used the C im-plementation of [5] in our experiments. In the case of BSVM we used 5-fold CV based proxy F Measure estimate to choose the hy-perparameters. In the case of EN method we used 5-fold CV based F Measure estimate since the classication problem is labeled ver-sus unlabeled in the rst stage (that is, estimating p ( s = 1 j x ) In all the experiments with random partitions average performance over 10 partitions is reported. Finally, due to space limitation we present plots only for some datasets and report observations on other datasets when some behavioral variations were observed.
The News20 [15] dataset contains text documents from 20 dif-ferent newsgroups. We combined the preprocessed train and test sets obtained from [4] to form the whole dataset. Each newsgroup is used as the positive class and the rest as the negative class. This results in 20 One-vs-All binary classication problems. The We-bKB [6] dataset is a web page classication problem where the web pages are collected from university websites and these web pages belong to one of 7 classes. For our experiments we consid-ered only the classes 1, 3, 4 and 7. This is because the number of positive examples was very small (for example, to do meaningful cross-validation) for other classes. We considered 4 One-vs-All bi-nary classication problems treating examples belonging to each of the 4 classes (1, 3, 4 and 7) as the positive class and the rest of the examples as negative class. The adult dataset is a binary classica-tion problem. We combined the train and test splits of a 5 a from [4] to form the whole dataset. The ccat and gcat datasets are binary classication problems that classify articles into corporate versus non-corporate and government versus non-government arti-cles respectively. The classes corporate and government are top-level categories in the RCV1 training dataset. The realsim dataset is also a binary classication problem and is obtained from a col-lection of UseNet articles from four discussion groups, for sim-ulated auto racing, simulated aviation, real autos, and real avi-ation [21]. The ccat , gcat and realsim datasets are available at http://people.cs.uchicago.edu/~vikass/svmlin. html ; see original source details there-in. These datasets cover a wide range of problems, class imbalance and n . The construction of train/test sets are explained for each experiment below in detail.
In this experiment we compare RSVM and SVM in the SL set-ting. Apart from a basic comparison, the intention is to study how well these methods perform under different train and test distribu-tion conditions; this is important for web classication because, many a times there is lack of clarity in the space of negative exam-ples and so it is often the case that the negative examples chosen for training do not represent that space well.

Experimental Setup We evaluate the performances under dif-ferent scenarios of train and test distributions. We x the test dis-tribution and vary the train distribution. The train and test sets are constructed as follows. First we randomly split the dataset into two sets in a 80:20 proportion, while maintaining the same class imbal-correspond to the cases, X =20 and 40 respectively. ance ratio between the positive and negative examples in the two sets. Let us denote these sets as S and T . Now keeping test set, the train set is constructed from S as follows. We randomly select X % of positive examples from S . Let us denote this set as P . Now keeping P xed, we randomly select the negative example set N ; to vary the train distribution we vary the size of as j N j ). We conduct this experiment on 10 random partitions of negative examples for each size and repeat this experiment for 3 different sizes of P (denoted as j P j ). Since we did not nd any no-ticeable behavioral changes for different j P j we report results only for one j P j value (corresponding to X =30). The results are given in gure 1. In the gure where r ( A ) is the class ratio in A, i.e., the ratio of the number of positive examples and the number of negative examples in set Thus when the class ratios in the train and test distributions are the same we have = 1 .

Observations The F Measures of RSVM and SVM are very close. One key observation is that the performances of both the methods drop rapidly as falls below 1; note that this corresponds to the situation where there are relatively lesser negative examples in the train distribution as compared to the test distribution. For very small values of , we also observed that the performance of RSVM was better, particularly on the News20 and WebKB datasets as
X decreased. The performances of both the methods improve for ing examples) and their performances are very close. The results suggest that an insufcient number of negative training examples ( &lt; 1 ) (with respect to the test set distribution) has signicant impact on performance. RSVM is signicantly faster ( &gt; In fact, on the adult dataset the speed-up was around 10 times; on this dataset the SVM classier chooses a high value of C P for some of the folds, resulting in larger training times. Note that RSVM is faster only when two hyperparameters are needed in the standard SVM (i.e., when the class imbalance is high).
To represent SL we choose SVM since it is more well known standard; also, in section 6.2 we saw that its performance is close to that of RSVM. For LPU we choose RSVM-LPU to represent it. Our intention is to see how well RSVM-LPU performs in compari-son to SVM and see if there are any specic conditions under which it even performs better.

Experimental Setup We construct the train and test sets as fol-lows. For the LPU setting, we rst randomly pick X % of positive examples from the overall dataset. Let us denote this dataset as Then we split the remaining examples in 80:20 unlabeled-test set proportion. Let us denote this split as U and T . The main moti-vation behind this construction is that the unlabeled set is collected in such a way as to represent the test set in practice. Therefore the same class ratio is maintained in the unlabeled and test sets . Thus ( P ; U ) form the training set and T forms the test set. In the SL setting, we randomly sample negative examples N sl from the neg-ative example set N u in U . Thus, ( P ; N sl ) form the training set and T again forms the test set. We conduct this experiment on 10 random partitions for different sizes of N sl and repeat this experi-ment on three different sizes of P (corresponding to X =20,30 and 40). The F Measure values corresponding to the cases X =20 and 40 are given in gure 2. The performance results corresponding to X =30 turned out to be closer to the case of X =40. Note that the performance in the LPU setting does not change as the -axis re-ects only the change in the number of negative training examples.
Observations Though unimportant for comparing RSVM-LPU and SVM, it is worth noting that different values of X correspond to test sets with different class ratios. Low values of correspond to lesser number of negative examples. Interestingly, on all the datasets, RSVM-LPU performs signicantly better when is small. SVM improves as more negative examples are added and the per-formance almost stabilizes after some point when X =40. When the number of positive examples is less ( X =20), there is some drop in the performance seen when large number of negative examples is added; of course the drop is not as high as the one observed when is small. In general, the peak performance of SVM was observed approximately around =1, which is expected since the distribu-tion used for parameter tuning in training matches the distribution evaluated in testing. Overall, around = 1 SVM does better than RSVM-LPU. While this improvement is signicant on News20 and WebKB datasets it is not that signicant ( &lt; 3%) on other datasets like gcat, ccat and realsim.
In this section we present two sets of experiments. In the rst ex-periment we demonstrate the need for hyperparameter optimization in LPU methods. In the second experiment we compare the perfor-mances of the proposed RSVM-LPU method with the BSVM and EN methods.
 Experimental Setup The construction of the sets P , U and remains the same as in subsection 6.3. In this experiment we also study the performances of the LPU methods as the number of pos-itive examples is increased. We construct the positive labeled set ~ P by randomly sampling percentage of samples from P . Thus ( ~
P ; U ) forms the training set and T forms the test set. Note that j ~
P j = 100 j P j and = 100 corresponds to the case in subsection 6.3 (that is, P = ~ P ). We conducted this experiment on 10 ran-dom partitions of ~ P and repeated this experiment for each size of ~ P . The results given in the gure are average F Measure values ob-tained from these partitions. We also varied j P j by varying responding to X =20,30 and 40) and since there were no changes in the behavioral patterns of methods (relative to one another) we only present the results corresponding to X =30.

Observations on Hyperparameter Optimization Hyperparam-eter tuning turns out to be important for all three LPU methods, viz. BSVM, EN and RSVM-LPU. We take EN to illustrate this. We conducted an experiment to study the effect of hyperparame-ter optimization as is varied. Default hyperparameter values for EN are: C P = 1 and C U = 1 . We observed signicant perfor-mance improvements (more than 10% F Measure value in several cases) with hyperparameter optimization for EN. The performance difference with and without hyperparameter optimization was more at lower values of (that is, when the number of labeled positive examples is low).

Observations on RSVM-LPU, BSVM and EN Methods In this experiment we performed hyperparameter optimization for all the methods. Since no specic behavioral differences were seen for different X values, we give results only for X =30; see gure 3. All the methods improve their F Measure as increases. At lower values, the F Measure values of all the methods fall relatively sharply. This is both due to the paucity in (positive) labeled exam-ples as well as the fact that this paucity causes CV based hyperpa-rameter tuning to become inferior.

Overall RSVM-LPU and BSVM are quite close in classier per-formance. There are exceptions too: on News20 RSVM-LPU is signicantly better and, on WebKB BSVM is signicantly better. EN is generally inferior, sometimes quite badly (see, for example, the results in gure 3 for News20 and gcat). We believe that the inferior performance of EN is due to inaccurate estimates of both K and p ( s = 1 j x ) , and this affects the nal probability score: p ( y = 1 j x ) = p ( s = 1 j x ) =K ; refer to sections 2 and 5 for de-tails. In general, we observed that the performance comes closer to other methods as increases and this happens due to improved parameter estimates.

The training times for BSVM and EN are close; RSVM-LPU is signicantly faster than them. As can be seen from gure 3, the speed-up is more than 3 times; on the adult dataset it was about 10 times. On the adult dataset, the BSVM and EN methods picked large C U as the optimal value on some of the folds, resulting in longer training time; on the other hand the RSVM-LPU method picked the hyperparameter value more consistently.
We did the feature selection experiment on WebKB and News20 in both LPU and SL settings with RSVM. We note that the feature selection technique proposed by Calvo et al [3] cannot be directly compared with our method for the reasons explained earlier (see section 5). For reference we present results from SL setting using the proposed AUC based feature selection technique. Note that our intention here is not to compare AUC based feature selection method with other feature selection methods in supervised setting, a study that can be taken up separately.

Experimental Setup The experimental setup is essentially same as the one described in section 6.4. We set aside 20% of positive examples ( X =20) and set = 100 . In the SL setting we have both positive and negative labeled examples, and we set = 1 . We xed C individual feature observed in the training set as discussed in Sec-tion 4. We evaluated the Macro F Measure on the test set as a func-tion of number of selected features. To assess the quality of features selected in the LPU setting, we can also evaluate the performance of SL classier built with features selected in the LPU setting and compare it with the performance obtained using features selected in the SL setting. We considered the following variations of LPU-LPU, LPU-SL and SL-SL. The prexes LPU and SL correspond to the cases where the features are selected from positive/unlabeled and positive/negative examples respectively. The sufxes LPU and respectively. and WebKB; denition of is as in the caption of Figure 3. SL correspond to the cases where the classier is built in the LPU and SL setting respectively.

Observations The results corresponding to these variations are shown in gure 4. On News20, the performances of all variations are very close. On WebKB, it is observed that the LPU classier performance is slightly better than the SL classier when the num-ber of features is small. The SL classier starts performing better after a sufcient number of features have been added. On both the datasets, the usefulness of the proposed technique is clearly seen: even with an order of magnitude reduction in the number of fea-tures the loss in performance is within 2-3%. Also, the SL classi-er performance with LPU selected features is almost same as the performance achieved with SL selected features.
In this experiment we compare the performances of RSVM clas-sier in the LPU setting with estimated and best thresholds. The experimental setup for the LPU setting remains the same as in sub-section 6.4. Recall that in the LPU setting we estimate the thresh-old using 5-fold CV proxy F Measure. To assess the quality of the threshold estimate we compared the F Measure performances (as a function of ) achievable by the estimated threshold and the best threshold on the test set. The results are given in gure 5. Note that the proxy F Measure estimate and hence the threshold estimate are expected to be poor at lower values of . This is because the number of examples available to perform 5-fold CV is very small and the proxy F Measure cannot be reliably estimated. This effect is more clearly seen in the News20 dataset as compared to the We-bKB dataset. We believe this is due to the reason that the class ratio is lower in the News20 dataset as compared to the WebKB dataset. The results demonstrate that when is reasonably high, the perfor-mance difference is almost same and is within approximately 2-3%. Overall, the results in this subsection seem to indicate that further research to come up with a measure better than proxy F Measure for tuning threshold is worthwhile. Suppose one has a knowledge of the fraction of positive examples in the train/test distributions. How this can be effectively used to choose the threshold is worth investigating.
In this subsection we summarize the key observations from all the experiments discussed in the previous subsections.

In this paper we proposed a pairwise ranking based SVM (RSVM) method to build classier models from positive and unlabeled ex-amples. We build a ranking model by encouraging the positive ex-amples to score higher than the unlabeled examples. Then the nal classier is built by estimating a threshold parameter. The pro-posed method is fast and also easy to implement via publicly avail-able RSVM codes. We also proposed an AUC based feature selec-tion technique for the LPU setting and demonstrated its usefulness. We conducted comprehensive experiments with various methods in both SL and LPU settings on several benchmark datasets and made several important observations. These experiments show that RSVM-LPU is worthy of inclusion in the repertoire of good meth-ods for solving binary classication problems in web applications. Acknowledgments: The authors are thankful to the anonymous reviewers for their helpful comments. [1] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, [2] B. Calvo, P. Larranaga, and J. A. Lozano. Learning Bayesian [3] B. Calvo, P. Larranaga, and J. A. Lozano. Feature subset [4] C.-C. Chang and C.-J. Lin. LIBSVM: a library for support [5] O. Chapelle. Software for Rank SVM . {http: [6] O. Chapelle and S. S. Keerthi. Multi-class feature selection [7] O. Chapelle and S. S. Keerthi. Efcient algorithms for [8] F. Denis, R. Gilleron, and M. Tommasi. Text classication [9] C. Elkan and K. Noto. Learning classiers from only positive [10] G. Forman. An extensive empirical study of feature selection [11] Y. Freund, R. Iyer, R. Schapire, and Y. Singer. An efcient [12] R. Herbrich, T. Graepel, and K. Obermayer. Large margin [13] T. Joachims. A support vector method for multivariate [14] T. Joachims. Training linear SVMs in linear time. In KDD [15] K. Lang. Newsweeder: Learning to lter netnews. In ML [16] W. S. Lee and B. Liu. Learning with positive and unlabeled [17] X. Li and B. Liu. Learning to classify texts using positive [18] B. Liu, Y. Dai, X. Li, W. S. Lee, and P. S. Yu. Building text [19] B. Liu, W. S. Lee, P. S. Yu, and X. Li. Partially supervised [20] L. M. Manevitz, M. Yousef, N. Cristianini, J. Shawe-taylor, [21] V. Sindhwani and S. S. Keerthi. Large scale semi-supervised [22] X. Wu, R. K. Srihari, and Z. Zheng. Document representation [23] H. Yu, J. Han, and K. C.-C. Chang. PEBL: Web page [24] H. Yu, C. Zhai, and J. Han. Text classication classiers [25] Z. Zheng, X. Wu, and R. Srihari. Feature selection for text
