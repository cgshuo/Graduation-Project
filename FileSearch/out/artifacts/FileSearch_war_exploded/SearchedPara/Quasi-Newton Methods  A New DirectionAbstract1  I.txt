 Philipp Hennig philipp.hennig@tuebingen.mpg.de Martin Kiefel martin.kiefel@tuebingen.mpg.de Quasi-Newton algorithms are arguably the most pop-ular class of nonlinear numerical optimization meth-ods, used widely in numerical applications not just in machine learning. Their defining property is that they iteratively build estimators B i for the Hessian B ( observations of f  X  X  gradient searching for a local minimum along a line search di-rection Newton-Raphson search direction. Some of the most widely known members of this family include Broy-den X  X  (1965) method, the SR1 formula (Davidon, 1959; Broyden, 1967), the DFP method (Davidon, 1959; Fletcher &amp; Powell, 1963) and the BFGS method (Broy-den, 1969; Fletcher, 1970; Goldfarb, 1970; Shanno, 1970). Decades of continued research effort in this area make it impossible to give even a superficial overview over the available literature. The textbooks by No-cedal &amp; Wright (1999) and Boyd &amp; Vandenberghe (2004) are good modern starting points for readers interested in background. An insightful and exten-sive contemporary review was compiled by Dennis &amp; Mor  X ee (1977). The ubiquity of optimization problems in machine learning has made these algorithms tools of the trade. But, perhaps because they predate machine learning itself, they have rarely been studied as learn-ing algorithms in their own right. This paper offers a probabilistic analysis.
 Throughout, let f not necessarily convex, function; gradient; B iterative algorithms moving from location x `  X  1 to location x ` . The algorithm performs consecutive line searches along one-dimensional subspaces x i  X  e spanning the line search space starting at x 0 i . Evalu-ations at x i evince the gradient also f The goal is to find a candidate x a root The derivations of classical quasi-Newton algorithms proceed along the following line of argument: We require an update rule incorporating an observation  X  f mate  X  B i + 1 , subject to the following desiderata: Low Rank/Cost Updates Optimization problems Consistency with Quadratic Model If f is lo-Symmetry The Hessian of twice differentiable func-Positive Definiteness Convex functions have pos-This paper X  X  contributions are twofold: Section 2 offers a probabilistic viewpoint on classical quasi-Newton methods, in the process showing that symmetry is only achieved in a partial, definiteness in only a weak way by the classical algorithms. In Section 3 we use these insights to construct a novel nonparametric Bayesian quasi-Newton algorithm; this addresses several short-comings of classic algorithms, and increases perfor-mance at only mildly higher cost.
 We will write row-wise into a vector of length nm . Its elements can be enumerated by an index set The symbol b ) vectorised matrices: have size I size IK finite Y and Z . From a probabilistic perspective, Equation (1) is a like-lihood for B . Using s i Dirac X  X  distribution p ( with any arbitrary N the linear operator real numbers in y i are not sufficient to identify the N 2 numbers in B . Classical derivations (Dennis &amp; Mor  X ee, 1977; Nocedal &amp; Wright, 1999) thus introduce a regularizer based on the weighted Frobenius norm around the current best estimate B i  X  1 from previous iterations. The weight in the Frobenius norm is en-coded using a positive definite matrix, which we will suggestively call V identify with the V i  X  1 of Eq. (2) Y The new estimate is the unique matrix B i minimizing the regularizer subject to Eq. (2). Inspecting Eq. (3) we see that, up to isomorphisms, the Frobenius reg-ularizer is the negative logarithm of a Gaussian prior Gaussian likelihoods are conjugate to Gaussian priors. case of a Dirac likelihood. A few lines of algebra show that the posterior has mean and covariance respectively. The new mean is a rank-1 update of the old mean, and the rank of the new covariance  X  i is one less than that of  X  i  X  1 . The posterior mean has maxi-mum posterior probability (minimal regularized loss), and is thus our new point estimate. Choosing a unit variance prior  X  i  X  1 quasi-Newton algorithms: Broyden X  X  method (1965): Broyden X  X  method does not satisfy the third require-ment of Section 1: the updated estimate is, in general, not a symmetric matrix. A supposed remedy for this problem, and in fact the only rank-1 update rule that obeys Eq. (2) (Dennis &amp; Mor  X ee, 1977) is the symmetric rank 1 (SR1) method (Davidon, 1959; Broyden, 1967): The SR1 update rule has acquired a controversial rep-some authors report good successes with this method, others note that it is unstable and overly limited. Our Bayesian interpretation adds to the doubts about the SR1 formula, since it identifies it as Gaussian regres-sion with a prior variance involving V i  X  1 with a data-dependent prior covariance. Given the prior (4), there is no rank 1 update rule that gives a sym-metric posterior. This blemish of rank-1 updates is also reflected in Eq. (6): Uncertainty drops only in the  X  X ow X , or  X  X rimal X  subspace of the belief (the right hand side of the Kronecker product in the covariance). While this still means uncertainty goes toward 0 over time, it does so in an asymmetric way. 2.1. Symmetric Estimates, The proper probabilistic way to encode Hessians X  sym-metry is to include an additional likelihood term using  X , the antisymmetry operator  X  the linear map defined through Since this is a linear map, the resulting posterior is analytic, and Gaussian. But the rank of  X  is 1 ~ 2 &amp; 20), so the corresponding update rule does not obey the first requirement of Section 1. However, the structure of Eq. (6) hints at another idea, which in fact turns out to give rise to the most popular quasi-Newton methods. We introduce a second, dual ob- X  X rimal-dual optimization X ). The posterior after both primal and dual observation is a Gaussian with mean and covariance B  X  The posterior mean is clearly symmetric if B i  X  1 is sym-metric (as V i  X  1 is symmetric by definition). Choosing the unit prior  X  i  X  1 what is known as Powell X  X  (1970) symmetric Broyden (PSB) update. Eq. (13) has previously been known to be the most general form of a symmetric rank 2 up-date obeying the quasi-Newton equation and minimiz-This old result is a corollary of our derivations. But note that symmetry only extends to the mean, not ated by Eq. (10), samples from this posterior are, with probability 1, not symmetric. Of course, they can be projected into the space of symmetric matrices by ap-plying the symmetrization operator  X  defined by  X   X  X 
X Since  X  is a symmetric linear operator, the projec-tion of any Gaussian belief N ( obey the quasi-Newton Equation (2). While Eq. (12) does convey useful information, it is not equivalent to encoding symmetry. It is cheaper, but also weaker, than using the correct likelihood (10). 2.2. Positive Definiteness: Consider choosing V i  X  1 p  X  exp This is an intriguing prior. Although there is some semblance to the Wishart distribution, the second term in the exponential means this prior is broader than the Wishart. It is not well-defined for degenerate matrices, and it is not clear whether it is proper. It is thus surprising to discover that it engenders the two most popular quasi-Newton methods: If we use the quasi-Newton equation (2) a second time to replace V 1959; Fletcher &amp; Powell, 1963) And, if we exchange in the entire preceding deriva-tion s at the BFGS method (Broyden, 1969; Fletcher, 1970; Goldfarb, 1970; Shanno, 1970), which ranks among the most widely used algorithms in machine learning over-all. DFP and BFGS owe much of their popularity to the fact that the updated B i, DFP and B guaranteed to be positive definite whenever B i  X  1 , DFP and B additionally y It is relatively straightforward to extend a theorem by Dennis &amp; Mor  X ee (1977) to find that, assuming B is positive definite, the posterior mean of Eq. (13) is positive definite if, and only if, 0 If the prior covariance is not to depend on the data, it is thus impossible to guarantee positive definiteness in this framework  X  BFGS and DFP circumvent this conceptual issue by choosing V i  X  1 ing Eq. (2) a second time. But, even casting aside such philosophical reservations, our analysis also casts doubt upon the efficacy of the way in which DFP and BFGS achieve positive definiteness: Eq. (16) does not exclude indefinite matrices; in fact it assigns pos-itive measure to every invertible matrix. For exam-ple, under a mean B i  X  1 B and BFGS achieve positive definiteness, not by includ-ing additional information, but by manipulating the prior such that, as if by accident, the MAP estimator (not the belief) happens to be positive definite. These observations do not rule out any utility of guarantee-ing positive definiteness in this way. But there is less value in the positive definiteness guarantee of DFP and BFGS than previously thought. The algorithm should aim to find the  X  X est X  positive definite explanation for the data, not  X  X ny X  such explanation. 2.3. Rank M Updates The classical quasi-Newton algorithms update the mean of the belief at every step in a rank 2 operation, then, implicitly, reset their uncertainty in the next step, thereby discarding information acquired earlier. Albeit inelegant from a Bayesian point of view, this scheme is still a good idea given other aspects of the framework: Since the quasi-Newton likelihood models the objective function as a quadratic, model mismatch would lead to strong overfitting under exact Bayesian inference. But it is instructive to consider the effect of encoding more than just the most recent observation. It is straightforward to extend Eq. (2) to observations (
Y,S Given a prior p terior then has mean and covariance Here, the absence of information about the symmetry of the Hessian becomes even more obvious: No matter the prior covariance V 0 , because of the term S the third line of Eq. (20), the posterior mean is not in general symmetric, unless Y tive function is in fact a quadratic). 2.4. Summary The preceding section showed that quasi-Newton al-gorithms, including the state-of-the-art BFGS and DFP algorithms, can be interpreted as approximate Bayesian regression from the primal and dual likeli-hood of Eqs. (2) and (12) under varying priors, in the following sense: At each quasi-Newton step, fix a Gaussian prior ad hoc, update the mean, then  X  X orget X  the covariance update. Two particularly interesting observations concern the way in which the desiderata of symmetry and positive definiteness of the MAP es-timator are achieved in these algorithms. Symmetry is encoded via dual observations, which is a useful but imperfect shortcut. Positive definiteness is achieved not by encoding relevant information, but by shifting the prior post hoc. It is thus doubtable whether the proven good performance of BFGS and DFP is actu-ally down to positive definiteness, instead of a simpler effect of moving from the clearly pathological formu-lation of Broyden X  X  method to dual observations and a less restrictive (though nontrivial) prior. Section 2 used the probabilistic perspective to gain novel insight into classical methods. In this second part of the paper we depart from the traditional frame-work to construct a nonparametric, Bayesian quasi-Newton method, de novo. To motivate this effort, no-tice some further deficiencies of DFP/BFGS regarding use of available information: Eq. (2) assumes that the function is (locally) a quadratic. Old observations col-lected  X  X ar X  from the current location (in the sense that a second order expansion is a poor approxima-tion) may thus be useless or even harmful. The fact that the function is not quadratic should be part of the model. On an only slightly related point, indi-vidual line searches typically involve several evalua-tions of the objective function f and its gradient; but the algorithms only make use of one of those (the act Bayesian parametric algorithm of Section 2.3 has this problem: Because a matrix S of several observa-tions along one line search has rank 1, the inverse of S
V 0 S is not defined. The following section will ad-dress all these issues. Several aspects of the resulting algorithm are involved. Derivations can be found in the journal version. A matlab implementation can be found at www.probabilistic-optimization.org . 3.1. A Nonparametric Prior Defining a prior for the function B we choose a set of N 2 correlated Gaussian processes. The mean function is assumed to be an arbitrary inte-grable function B 0 a constant function, but the analytic derivations do not need to be so restrictive). The core idea is to as-sume that the covariance between the element B ij at location x  X  and the entry B k` at location x  X  is cov with an N concrete intuition: In our implementation we use one joint squared exponential kernel for all elements. I.e. with a positive definite matrix V and length scales  X . Other kernels can of course be chosen; but it will be-come clear that an important practical requirement is the ability to efficiently integrate the kernel. This is feasible, though nontrivial, with the squared exponen-tial kernel. Another option, not yet explored by us, may be offered by spline kernels (Minka, 2000). 3.2. Line Integral Observations For the Hessian B quasi-Newton equation (2) is only a zeroth order ap-proximation (a second-order approximation to f it-self), assuming a constant Hessian everywhere. In our treatment, we will replace it with the exact statement: We observe the value of the line integral along the path r  X  [ Y This uses the classic result that line integrals over scalar fields, such as B path X  X  start and end point, irrespective of the path itself. Hence, the nonparametric version of the quasi-Newton equation is the likelihood with a linear operator ( element-wise product  X   X  3.3. Gaussian Process Inference from Integral Because the Gaussian exponential family is closed un-der linear transformations, Gaussian process inference is analytic under any linear operator. Since integra-tion is a linear operation, Gaussian process inference is possible, in closed form, from integral observations. Nevertheless, this idea has only rarely been used in the literature (e.g. by Minka, 2000). Figure 1 gives a 1D toy example for intuition.
 The posterior distribution under our nonparametric prior, the likelihood of Eq. (25) and its dual equiva-lent is a Gaussian process with mean and covariance functions This uses B 0 the Gram matrix K k These objects are homologous to concepts in canonical Gaussian process inference: B 0 ,nm is the n -th mean prediction along the m -th line integral observation. k the Hessian at location x  X  and the m -th line-integral observation. K pq is the covariance between the p -th and q -th line integral observations. An important as-pect is that, because k is a positive definite kernel, un-less two observations are exactly identical, K has full rank M (the number of function evaluations), even if several observations take place within one shared 1-dimensional subspace. So it is possible to make full use of all function evaluations made during line searches, not just the first and last one, as in the classical set-ting. A downside is that evaluating the mean function involves finding the inverse of K , at cost aspects of numerical optimization make this issue less problematic than one might think. First, solving an optimization problem takes finite time, often just a few hundred evaluations; so the cubic cost in M is of-ten manageable. Where it is not, note that, because optimization proceeds along a trajectory through the parameter space, old observations tend to have low co-variance with the Hessian at the current location, and thus a small effect on the local mean estimate (the ef-fect of this influence is measured by kK can often simply be ignored. 3.4. Numerical Implementation As mentioned above, for a concrete implementation, we chose to use the squared exponential kernel (23), and a constant mean function assigning B 0 everywhere. It is another advantage of the Bayesian formulation that prior assumptions are easy to ana-lyze and understand: The squared exponential prior amounts to the assumption that the elements of the Hessian vary independently over the parameter space, on one unique set of length-scales  X . Multiple length scales could be modeled using sums of kernels, but our implementation does not currently offer this option. Changing the length scales  X  amounts to automatic pre-conditioning , another benefit of a Bayesian for-mulation that we cannot dwell on for space reasons. Hyperparameters could be fitted by type-II maximum likelihood, as in canonical Gaussian process regression. Unfortunately, this is an optimization problem itself. Another option is to instead fix the hyperparameters ad hoc by tracking the signal variance to fix V in Eq. (23) and the relative change along line searches to fix  X .
 Implementing the integrals of Eq. (29) for the squared-exponential kernel, particularly those in K , is nontriv-ial, because definite integrals over Gaussians are not analytic. k involves the error function, for which good double-precision approximations are widely available. The integrals in K are of two distinct types: The co-variance between observations made as part of the same line search involve 1D integrals of the error func-tion, which can be analytically reduced to the error and exponential functions 2 . The covariance between observations made during different line searches are bivariate Gaussian integrals. Fortunately, good, light-weight numerical approximations are available for this problem (Genz, 2004).
 From Sec. 1, recall that updating the search direc-tion requires the inverse of B . Explicit inversion costs O ( cally, from the matrix inversion lemma, in NM an argument largely analogous to the derivation of the L-BFGS algorithm (Nocedal, 1980) lowers cost to method is thus applicable to problems of even very high dimensionality. 10 10 f ( x x Figure 2 shows averages of experiments on a 200-dimensional domain. The objective functions were the logarithms of products of Gamma distributions with different parameters for each dimension (a simplified version of hyperparameter learning for Gaussian pro-cess regression). In this experiment, the nonparamet-ric algorithm outperforms its predecessors strongly. The performance advantage is not always so drastic (the journal version contains additional empirical re-sults, including less pronounced cases). Despite the relatively precise numerical treatment of the integrals involved, the nonparametric Bayesian quasi-Newton algorithm poses more numerical challenges than its predecessors. This issue becomes clear when mini-mizing quadratic functions, whose constant Hessian voids the modelling advantage of the nonparametric method: The Bayesian algorithm behaves more regu-larly initially, but towards the end of the optimization process the numerical conditioning of the Bayesian al-gorithms begins to play a role, offering an advantage to the better conditioned older methods. At this small scale, however, the Hessian is essentially constant, and the function is well described by a local model. In our practical implementation, we check for convergence, then pass the learned inverse Hessian to the better conditioned BFGS for the final few steps.
 An additional benefit of the nonparametric formula-tion is the availability of a global estimate of the Hes-sian function. Figure 3 illustrates this point with re-sults from a popular two-dimensional test problem  X  Rosenbrock X  X  polynomial (details in caption). This figure is mostly for intuition: Rosenbrock X  X  valley is challenging even for the exact Newton method since it breaks the line search paradigm, so the similarity be-tween the methods on this problem is not particularly indicative of general performance.
 Cost As pointed out above, the computational com-plexity of this algorithm, given a diagonal prior mean, is O ( where M is the number of function evaluations used to build the model (which can be controlled ad hoc within the algorithm by excluding redundant or irrel-evant evaluations). This compares to corresponding cases of DFP and BFGS. Although the overhead created by the squared-exponential integrals is nontrivial, we found the computational demands of our implementation manageable: In our experiments, the cost of constructing and inverting the matrix K was negligible, and could, in very time-sensitive settings, be further reduced by a more efficient implementation. Owing to the limitations of a conference publication, we have only outlined many of our core results. To give an intuition for the potential of probabilistic formula-tions of numerical optimization, consider some of the most immediate future work: Perhaps the most obvi-ous insight is that Gaussian process integration is triv-ial to extend to noisy evaluations. In combination with a robust replacement for the traditional line searches, our work may thus lead to robust numerical optimiz-ers. Repeated integration, and non-Gaussian likeli-hoods in combination with approximate inference, may allow optimization without gradients, and from only gradient sign observations, respectively. Structured new avenues for optimization of very high-dimensional functions. We have shown that the most popular quasi-Newton algorithms can be interpreted as approximations to Bayesian regression under Gaussian and other priors. This deepens our understanding of these algorithms. In particular, it emerged that symmetry in the esti-mators of SR1, PSB, DFP and BFGS, and positive definiteness in those of DFP and BFGS, are encoded in only approximate, incomplete ways.
 new class of Bayesian nonparametric quasi-Newton al-gorithms. These use a kernel model to utilize all ob-servations in each line-search, explicitly track uncer-tainty, and thus achieve faster convergence towards the true Hessian. While the new methods are not triv-ial to understand and implement, their computational sors. A demonstrative implementation can be found at www.probabilistic-optimization.org .
 The authors thank Christian Schuler, Tom Minka and Carl Rasmussen for helpful discussions, as well as Carl Rasmussen for his release of minimize.m , which sim-plified development. MK is supported by a grant from Microsoft Research Ltd.
 Boyd, S.P. and Vandenberghe, L. Convex Optimiza-tion . Cambridge Univ Press, 2004.
 Broyden, C.G. A class of methods for solving nonlinear simultaneous equations. Math. Comp. , 19(92):577 X  593, 1965.
 Broyden, C.G. Quasi-Newton methods and their ap-plication to function minimization. Math. Comp. , 21(368):45, 1967.
 Broyden, C.G. A new double-rank minimization algo-rithm. Notices American Math. Soc , 16:670, 1969. Davidon, W.C. Variable metric method for minimiza-tion. Technical report, Argonne National Laborato-ries, Ill., 1959.
 Dennis, J.E. Jr and Mor  X ee, J.J. Quasi-Newton meth-ods, motivation and theory. SIAM Review , pp. 46 X  89, 1977.
 Fletcher, R. A new approach to variable metric algo-rithms. The Computer Journal , 13(3):317, 1970. Fletcher, R. and Powell, M.J.D. A rapidly convergent descent method for minimization. The Computer Journal , 6(2):163 X 168, 1963.
 Genz, A. Numerical computation of rectangular bivari-ate and trivariate normal and t probabilities. Statis-tics and Computing , 14(3):251 X 260, 2004.
 Goldfarb, D. A family of variable metric updates de-rived by variational means. Math. Comp. , 24(109): 23 X 26, 1970.
 L  X utkepohl, H. Handbook of Matrices . Wiley, 1996. Minka, T.P. Deriving quadrature rules from Gaussian processes. Technical report, Statistics Department, Carnegie Mellon University, 2000.
 Nocedal, J. Updating quasi-Newton matrices with lim-ited storage. Math. Comp. , 35(151):773 X 782, 1980. Nocedal, J. and Wright, S.J. Numerical optimization . Springer Verlag, 1999.
 Powell, M.J.D. A new algorithm for unconstrained optimization. In Mangasarian, O. L. and Ritter, K. (eds.), Nonlinear Programming . AP, 1970.
 Shanno, D.F. Conditioning of quasi-Newton methods for function minimization. Math. Comp. , 24(111):
