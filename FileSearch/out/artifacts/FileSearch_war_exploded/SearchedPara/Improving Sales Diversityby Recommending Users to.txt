 Sales diversity is considered a key feature of Recommender Systems from a business perspective. Sales diversity is also linked with the long-tail novelty of recommendations, a qual-ity dimension from the user perspective. We explore the inversion of the recommendation task as a means to en-hance sales diversity  X  and indirectly novelty  X  by selecting which users an item should be recommended to instead of the other way around. We address the inverted task by two approaches: a) inverting the rating matrix, and b) defining a probabilistic reformulation which isolates the popularity component of arbitrary recommendation algorithms. We find that the first approach gives rise to interesting refor-mulations of nearest-neighbor algorithms, which essentially introduce a new neighbor selection policy. The second ap-proach, as well as the first, ultimately result in substantial sales diversity enhancements, and improved trade-offs with recommendation precision and novelty. Two experiments on movie and music recommendation datasets show the ef-fectiveness of the resulting approach, even when compared to direct optimization approaches of the target metrics pro-posed in prior work.

Sales diversity has been pointed out as a relevant quality of recommendation from the business point of view [7]. Sales diversity means that all or most products in the business catalog get purchased to some extent, rather than having sales concentrating around a few items. Sales diversity gets meaning in the context of recommendation in the sense that recommending a product exposes it to being sold. By link-ing recommendation to purchase in the analysis of diversity,  X  X ales diversity X  becomes a shorthand for  X  X romoting sales diversity X .

Sales diversity can be measured, for instance, by the total number or the ratio of items that are recommended in the top-N to at least one user [1]. Better yet, we can use the Gini coefficient as a finer measure of the concentration of top N recommendations around a few items [7]. Prior research has found there is an indirect connection between sales diversity and selling (recommending) in the long tail [1]: promoting long-tail (novel) items has a positive effect on sales diversity, even though sales diversity and long-tail novelty are not in themselves the same thing. Several approaches have been proposed in the literature to enhance recommendations over such metrics, most of which consist of re-sorting the top-K items ( K &gt; N ) of an initial ranking produced by a base-line recommendation algorithm [1, 17]. Other authors have also researched the effect of different basic recommendation methods on sales concentration [7].

In the research presented here, we consider a different out-look on the problem of sales diversity. If we aim to pro-cure a fair opportunity for most items to be recommended, one may consider selecting which users each item should be recommended to, instead of the other way around. This view entails a symmetric swap of the recommendation task, whereby users are recommended to items rather than the opposite. From this perspective, we address three main re-search questions: a) How can we define suitable and effec-tive algorithms that recommend users to items? b) Does the inverted formulation actually enable any improvements in sales diversity? c) If so, what trade-offs if any are in-volved with respect to other qualities such as precision or recommendation novelty from the user point of view?
To address these questions we propose, firstly, to explore the application of state of the art collaborative filtering algo-rithms to the inverted recommendation task, that is, simply swapping the role of items and users in the algorithms. We find interesting derivations, equivalences, and new insights on the behavior of neighborhood-based algorithms in partic-ular, where the inversion results in the emergence of new neighbor selection policies, with an impact on the poten-tial connections to item popularity. We furthermore find that the inversion approach results in a significant increase of sales diversity while retaining a good trade-off on top-N item recommendation precision. In addition to this, we develop a probabilistic scheme which formulates user recom-mendation to items as a Bayesian layer which can be applied on top of any recommendation algorithm. The probabilistic scheme provides a principled means to isolate the item pop-ularity component of the baseline algorithm; by means of simple smoothing techniques, the presence of this popular-ity component can be calibrated (i.e. kept unchanged or neutralized) to any desired degree. This parametrization is shown to enable an enhanced precision-diversity trade-off, even above, somewhat surprisingly, direct optimization ap-p roaches targeting the precision vs. long-tail novelty trade-off. Furthermore, the resulting algorithmic scheme is com-petitive with respect to direct optimization even in terms of long-tail novelty.

The rest of the paper is structured as follows. In Section 2 we review the related work on assessment and enhancement of sales diversity and novelty. Section 3 discusses the pop-ularity bias in collaborative filtering algorithms detected by several authors, and how this bias also influences the evalu-ation of Recommender Systems in ranking tasks. Section 4 introduces the inverted recommendation task of recommend-ing users to items. Then, Section 5 describes our first pro-posal of using inverted neighborhoods to improve sales diver-sity. An analysis of the properties of standard and inverted neighborhoods and their differences is shown in Section 6. Section 7 presents our second proposal, a probabilistic re-formulation layer that allows the calibration of the popular-ity bias in state-of-the-art collaborative filtering algorithms. Experiments with two different recommendation scenarios  X  movies and music  X  are described in Section 8. Finally, Section 9 offers the conclusions and future work.
As Anderson [4] stated, some businesses or economic mod-els present a Long tail effect, in which a few of the most pop-ular items are extremely popular, while the rest  X  the long tail  X  is much less known. Promoting the recommendation of items in this long tail may offer benefits for both users and the business behind the recommender system. From the user side, offering not so popular items may help receive less ob-vious, unexpected recommendations, which correspond with the natural notion of a recommender system as a tool to help users discover new content. From the system side, avoiding the recommendation of short-head items may also contribute to make the most of the catalog.

Adomavicius et al. [1] proposed to measure sales diversity in terms of the aggregate diversity, i.e., how many different items of the catalog were recommended to the users. Given a recommender system S , they proposed a metric, denoted here as aggr-div, which return the total number of different items that have been recommended to at least one user: where L S u is the recommendation list generated by the sys-tem S for the user u . This metric, while being simple and intuitive, may not be very robust, since the contribution to the metric of an item that has been recommended just once is equal to that of other item recommended a thousand times. Therefore, we think that using a metric to measure the imbalance in the number of times each item is recom-mended would be more adequate. Fleder and Hosanagar [7] proposed a better alternative by using the Gini coefficient to measure sales concentration: where p ( i k | S ) is the probability of the k -th least recom-mended item being drawn from the recommendation lists generated by a system S : Note that in our definition we use the complement of the standard definition for the Gini coefficient so that higher values of our metric correspond to more balanced recom-mendations.

In previous work [17], we proposed the expected popular-ity complement metric to measure the long-tail novelty of the items in a recommendation list, which is defined as the average novelty of the recommended items: where nov ( i ) measures the novelty of an item as the proba-bility of not to being known by a user:
Several proposals to promote sales diversity and novelty in recommender systems have been proposed [1, 11, 15, 17]. A simple approach, which we compare against our proposals, consist in a re-scoring of a previously generated recommen-dation baseline by using a normalized linear combination between the scores provided by the baseline and the novelty component described in 5: s
NR ( u, i ) = (1  X   X  ) norm s s ( u, i ) +  X  norm nov nov ( i ) (6) where norm s and norm nov are normalizing functions that help making a balanced combination of both relevance and novelty components, such as the standard score norm X ( x ) =
In a ranking prediction task, the popularity-based recom-mendation is the obvious baseline to beat [3]. In terms of sales diversity and recommendation novelty, personalized al-gorithms easily improve over the popularity-based recom-mendation which, by definition, has the lowest scores in terms of the metrics described in the previous section. Im-proving the precision of popularity recommendation is less obvious than one might think but is also a feasible goal [6]. While it is clear that collaborative filtering algorithms out-perform popularity-based recommendations in terms of ac-curacy and sales diversity, some authors have pointed out that they still suffer from a bias [18].

Collaborative filtering algorithms, in particular, are known to generally have a bias towards recommending popular items, commonly known as the  X  X arry Potter Effect X  1 . There is a natural reason for this trend to begin with: collaborative filtering thrives on the populated regions of the user-item in-teraction history matrix (rating matrix for short), and falls short in the sparser regions. Popular items live by defini-tion in the more populated areas, since they carry more rating data that populates matrix cells, and collaborative algorithms are therefore more prone to end up recommend-ing these items. The popularity bias of collaborative filtering algorithms has been pointed out by several authors and stud-ied by some. For instance, Zhao et al. [18] show empirical evidence that popular items tend to be more recommended than not so popular ones, and proposes methods to alleviate his effect. Steck [15] examined this issue in further depth and justified this popularity bias by the selection bias towards popular items in the available data. h ttp://recsyswiki.com/wiki/Harry_Potter_effect
Furthermore, common precision-based evaluation method-o logies reward this behavior, since popular items have more test ratings and are more likely to be counted as hits for more users. This has motivated several evaluation protocols [5, 6, 15] that try to enable a less biased assessment of the person-alized relevance of the recommendations, by removing the tip of the bias in the test data.

The popularity bias has a negative effect on the discovery-related added value and practical usefulness of collaborative filtering recommendations, as well as their effect on sales concentration [7]. The research and findings we report here provide means to better cope, directly and indirectly, with this bias, as we discuss in the next sections.
The recommendation task can be formulated as defining a scoring function s : U  X  I  X  R for pairs of users u  X  U and items i  X  I so that, for each user, a ranked list of items L I  X  I  X  . . . is defined by sorting items by decreasing score order. The scoring function of a recommender algorithm is based on previous interactions between users and items recorded in a matrix R = ( r u,i ) u,i  X  R |U| , |I| and, possibly, additional sources, as in the case of content or social-based recommenders. We shall focus here on collaborative filtering approaches, which use only the interaction matrix R .
Analogously to the original task of recommending items to users, the task of recommending users to items can be formulated as defining a scoring function which induces a ranking of users by their decreasing pre-dicted relevance to item i . In a pure collaborative filtering setting, the input data for this task consists of the trans-posed rating matrix  X  R = R t  X  R |I| , |U| .

Since collaborative filtering algorithms do not depend on the content or internal characteristics of both users and items, they can be adapted for this task without any mod-ification apart from the change of roles between users and items. An initial observation is that, for many popular, state-of-the-art collaborative filtering algorithms, the scoring func-tion  X  s is actually identical to that of the original problem s . That is the case, for instance, of many matrix factorization approaches, such as the implicit matrix factorization of Hu et al. [9]: There are other collaborative filtering approaches that break this symmetry. That is the case of other matrix factorization approaches [13, 14, 16] which, even having the same scoring function as in Equation 8, have non-interchangeable roles for users and items in their model training, and thus pro-vide new scoring functions between users and items. How-ever, we focus on the case of nearest neighbors approaches, whose asymmetry offers an interesting, new alternative for generating diverse recommendations.
A first application of the inverted recommendation task lies in the asymmetry of the nearest neighbor approaches when applied to the inverted recommendation task. Through-out this section we will focus on the user-based k -nearest neighbors (kNN) approach, since most of the observations, unless explicitly discussed, are straightforwardly translat-able to the item-based alternative. Table 1: Example of user neighborhoods of size 2.
T he scoring functions of the user-based and item-based kNN recommenders[2, 6] can be formulated as follows : where sim ( u, v ) is a similarity function between two users and N ( u ) is the neighborhood of user u , containing the top-most similar users to item u .

Reformulating these algorithms in the inverted recommen-dation task, the scoring functions become: As previously commented, the symmetry of the nearest neigh-bors scoring functions with respect to the original problem is broken. In particular, the user-based approach s UB in Equa-tion 9 is notably different from the scoring function  X  s Equation 11. Interestingly, it is almost equivalent to the item-based approach  X  s IB for the inverted recommendation in Equation 12, the difference lying on the neighborhood se-can re-formulate the scoring function  X  s IB as a variant of the standard user-based approach s UB in which the policy for neighbor selection is inverted, that is, by considering user inverted neighborhoods N  X  1 ( u ) defined as where N ( v ) is the original neighborhood for a user v , so borhoods originally appeared in [12], where it was proposed as an ad-hoc method to efficiently predict ratings for item-based approaches, without any relationship with the inverted recommendation tasks or the improvement of sales diversity.
Note what the resulting inverted neighborhood formation policy means: instead of selecting N ( u ) as the top-K most similar users to the target user u , all the users v for which the target user is among the K most similar to v are se-lected as the neighbors N  X  1 ( u ) of u . Table 1 shows an example of a community of users and their corresponding standard and inverted neighborhoods for K = 2. This has several consequences. In the first place, the resulting, in-verted neighborhoods no longer have all the same size. The size of the inverted neighborhood of a user u is the number of users to whose neighborhood u belongs  X  in particular this means that some users might have an empty neighbor-hood at the cost of user coverage of the recommendation, but we have observed in our experiments that this situation does not happen in practice if the original neighborhoods are large enough. Having different neighborhood sizes is not necessarily a drawback, on the contrary, it may be favorable that users have as large a neighborhood as the reliability of the available data for each user enables. Table 3: Definition of the neighborhood properties. N d enotes in this case a generic user or item neigh-borhood, either standard or inverted.

The inverted neighborhoods approach implies, on the other hand, that all users will appear in exactly the same number | N ( u ) | of inverted neighborhoods (except perhaps a few low activity users for which it was not possible to form a direct neighborhood of size K in the first place). This flattens the influence power of all users, so that all users X  opinions X  X ount X  to the same extent overall in the produced recommendations. This may be expected to avoid a concentration of recommen-dations over the tastes of a reduced set of users, thereby in-directly enhancing a more even distribution of items across recommendations to the user population.

In the case of the item-based variant this effect is even more direct: if all items appear in the inverted neighbor-hood of the same number of items (neighbor items being the candidates for recommendation in the item-based kNN method), they will have more even chances of making it to the top-N of recommendations, whereby one may expect better distributed recommendations over the set of items (i.e. more diverse  X  X ales X ). Moreover, long-tail items, by getting a more equal opportunity to be recommended with respect to popular items, might make for a long-tail novelty enhancement of recommendations.

In order to have a preliminary understanding of these potential effects, we will analyze more closely in the next section the relation between user and item characteristics, namely profile size, and their distribution across neighbor-hoods for the direct and inverted selection policies. Our discussion of the potential effects on final recommendation diversity is so far speculative and needs to be tested empiri-cally, as we report in Section 8.2.
We test and illustrate the biases suggested in the previous section by taking some measurements on data from the Net-flix Prize and the Million Song Dataset, for which we study the characteristics of user and item neighborhoods with dif-ferent neighborhood sizes K .

We show in Table 4 the following measurements: Table 4: Properties of user neighborhoods with c osine similarity for the Netflix and Million Song datasets. Dashes mark undefined correlations since | N  X  1 ( u ) | was constant for all the users. See Table 3 for the meaning of S , G and C .
 Table 5: Properties of item neighborhoods for the N etflix and Million Song datasets. Dashes mark un-defined correlations since | N  X  1 ( i ) | was constant for all the items. See Table 3 for the meaning of S , G and C . A more formal definition of the above measurements is given in Table 3, where we denote by N K ( u ) the direct neighbor-hood formed by the K most similar users to a user u , and by N  X  1 K ( u ) the inverted neighborhood for u .
The results in Table 4 reveal, as hypothesized, biases and concentrations in the selection of user for standard neighbor-hoods. In the case of Netflix data, the standard neighbor-hood method is slightly biased towards selecting users with big profiles and shows a clear concentration on a small sub-set of users. In the case of the Million Song Dataset, there is an opposite bias towards small profiles, which also causes a concentration of neighbors. A possible explanation of why these methods differ in the direction of the bias may lie in the incomparable number of items between them and the different levels of sparsity in each dataset. In any case, the inverted selections strategy corrects this biases, that is, elim-inates the correlation between profile size and the number o f neighborhoods a user belongs to and, at the same time, creates a perfectly balanced distribution of this number.
Table 5 shows the equivalent measurements for item neigh-borhoods. Again, we can observe biases and concentration in the direct selection method that are partly solved by the inverted neighborhoods. The Netflix data shows a bias to-wards popular items that, ultimately, compose the majority of the neighborhoods. These issues are solved by the in-verted item neighborhoods, which achieve a perfectly equi-tative distribution of the items in the neighborhoods, doing away with the bias towards popular items. In the Million Song dataset, a bias towards popular items is also observed for large neighborhood sizes, and an uneven distribution of the items in the distribution is observed for all neighborhood sizes. Again, inverted neighborhoods help solving these ef-fects by significantly reducing the bias towards popular items and achieving more uniform distributions in the number of neighborhoods each item belongs to.
The inverted recommendation task can also be addressed in probabilistic terms. Probabilistic formulations have been used extensively in the conventional item recommendation task as a means to develop collaborative filtering methods. For instance, Hofmann [8] proposed ranking items by the decreasing probability p ( i | u ) that the target user would pre-fer each item over the others. This principle is developed by means of an adaptation of the probabilistic Latent se-mantic Indexing (pLSA) framework into an effective scoring procedure for producing ranked recommendations.

Turning the task around, recommending users for items would consist of estimating p ( u | i ) for each user u given an item i . A straightforward way of linking any recommenda-tion algorithm to a probabilistic formulation can be estab-lished by assuming that the recommender scoring function s ( u, i ) is roughly proportional to p ( u, i ). This assumption, coarse as it may be, provides a very direct means to bring the recommendation algorithm to a probabilistic interpretation as per:
We can therefore use this approach to obtain an inverted recommendation method out of any direct item recommen-dation algorithm. Note that the resulting formulation pro-duces a totally equivalent output as its scoring function pre-mulation is however useful as it enables a probability-based manipulation of the popularity bias in recommendation al-gorithms, as we see next.

First, the resulting output of the inverted recommenda-tion should be reverted to a list of ranked items to be deliv-ered to each user. A principled way to do this is by applying Bayesian inversion on p ( u | i ), thereby obtaining an estimate for p ( i | u ) as a suitable scoring function for ranking items for each user: where the prior p ( i ; s ) represents how likely the item is to be the favorite of a random user.
 Table 6: Pearson correlation between prior p ( i ; s , 0) and item popularity.

Note that we could instead have derived an estimate of p ( i | u ; s ) by an equivalent symmetric version of equation 14. However, the advantage of equation 15 is that it explicitly reflects the popularity component carried by the item prior p ( i ; s ). Using the same assumption as before between the scoring function and probabilities, we have:
Now that the popularity component is isolated, we pro-pose to smooth the prior estimate in a way that has it range from the literal estimate based on the recommender X  X  scores, to a flat uniform background prior where all items are con-sidered equally popular. We do so by an entropic regulariza-tion of the estimate  X  similar to the tempered expectation maximization algorithm in [8], which simply introduces an exponent in the expression: In the above expression, the  X   X  [0 , 1] smoothing parameter allows controlling how much of the algorithm popularity bias we wish to leave as is or remove.

Interestingly, by combining equations 15 and 17, the re-sulting probabilistic interpretation p ( i | u ; s ) can be simpli-fied to a re-scoring procedure for a standard scoring function s as follows: This last reformulation allows to see more clearly the role of the parameter  X  . On one hand, when  X  = 0 we obtain the original recommendation list created with the scoring func-tion. On the other hand, when  X  = 1 the prior is uniform and thus the recommendations to users will be completely based on p ( u | i ;  X  s ), eliminating any possible popularity bias in the items. The use of intermediate values of  X  is a means to provide more varied recommendation lists while retaining an appropriate level of relevance, that is  X  is a parameter that controls the relevance/novelty trade-off, only that nov-elty is not applied as the opposite to popularity (as is the case in most novelty enhancement approaches [1, 17]), but rather as neutrality with respect to popularity.

To illustrate how we can control the popularity bias by the proposed approach, we show in Table 6 the Pearson corre-lation values between the priors p ( i ; s, 0) and the popularity of the items (understood as the number of users who know  X  i.e. have rated  X  the item) for some recommendations base-lines  X  further detailed in Section 8.1  X  for the Netflix and Million Song datasets. The values reveal a strong correlation between our score-based estimate of the item priors and the actual popularity of the items. This, on the other hand, em-pirically illustrates the popularity bias of these state of the art algorithms as discussed in Section 3, and shows how the prior component captures it, enabling its gradual adjustment by the  X  parameter. Table 7: User coverage as the fraction of users in t he test split which receive a recommendation in the Netflix and MSD data.
In order to test the effectiveness and analyze the prop-erties of the proposed inverted nearest neighbor methods and the probabilistic popularity adjustment, we carry out two experiments on the Netflix Prize 2 and Million Song Dataset Challenge [10] datasets. The Netflix data contain 100M ratings (from one to five stars) by 480,000 users to 18,000 movies. And we used the Taste Profile Subset of the Million Song Dataset, containing 48M play count triplets by 1,100,000 users for 380,000 songs. As in the work of Aiolli [2], we take binarized play counts since, as warned by the challenge organizers, play counts are unreliable and not necessarily correlate with likings.
Each dataset is split for evaluation into training and test subsets. For Netflix, we do a 80-20% random split of the h ttp://www.netflixprize.com/ Table 8: Comparison of inverted neighborhood m ethods to other recommendation algorithms. data, while in the Million Song dataset we take the parti-tion provided with the data release. For every user with test data, we generate recommendation lists by ranking all the items with training data. We then measure rank-based precision, novelty and sales diversity for the top-10 items in the recommendation for each user. Precision is measured as the proportion of relevant test items of the user included in the recommendation he is delivered. Novelty is measured by EPC [17] and sales diversity by the Gini coefficient. For illustrative purposes, we also report results for aggregate di-versity [1] normalized by the number of items.

For the inverted neighborhood approach, we compare the inverted kNN approaches described (Equations 11 and 12) to the corresponding standard user-based and item-based formulations (Equations 9 and 10). We used cosine as the similarity function between users and items, and explored a range of neighborhood sizes for both datasets.
For the probabilistic reformulation, a comparison between our approach and the novelty-oriented re-scoring approach defined by Equation 6 in three different recommendation baselines, namely the standard user and item-based kNN recommenders ( N 100 and N 10 respectively) and, for the case of the Netflix dataset, the implicit matrix factorization pro-posed by Hu et al. [9], by considering positive ratings as im-plicit data. As stated in [2], matrix factorization approaches are not effective in the Million Song dataset, as our attempts at it confirmed, whereby we omit results with this baseline in this dataset. The two compared approaches have a param-eter that controls the trade-off between the original scoring function (  X  = 0 . 0 and  X  = 0 . 0) and a pure novelty compo-nent (  X  = 1 . 0 and  X  = 1 . 0). We explore these trade-offs by a grid search on the full interval by steps of 0.1.
Figure 1 shows the comparison of the direct (i.e. standard) and inverted nearest-neighbor approaches in terms of the metrics of interest for different neighborhood sizes.
The results confirm a systematic increase in sales diver-sity (measured by the Gini coefficient), as hypothesized in Section 5. The improvement is consistent in the user-based and item-based versions for all neighborhood sizes on both datasets. Notably moreover, for the item-based approach, the inverted method offers better accuracy and novelty for every value of K . For inverted user-based kNN, accuracy and novelty are better than in direct kNN only for large enough neighborhoods ( K  X  100). This is caused by user coverage degradation that occurs with smaller K , that is, many users do not receive recommendations since their in-verted neighborhoods are empty, resulting in a penalization in metrics such as precision and EPC (we sum zero precision and EPC when a user cannot be delivered a recommenda-tion). The details about the user coverage degradation are shown in Table 7. In a real recommender system this would not be acceptable, and a fallback solution, such as using the standard neighborhood, should be resorted to in those cases. However, in this analysis we are interested in the properties of the pure algorithm, and we therefore report the results for a plain version of the approach.

In order to provide a wider perspective in the context of alternative recommendation algorithms, Table 8 shows the comparison of inverted kNN for K = 100 in user-based kNN and K = 10 in item-based kNN with random, popularity-based and matrix factorization recommendations. It can be seen that the inverted kNN approaches obtain the best re-sults  X  after random recommendation of course  X  in sales di-versity and novelty. Random recommendation, as expected, produces inaccurate but highly novel and diverse results in both datasets. Popularity-based recommendation also yields predictable outcomes, producing moderately accurate results  X  depending on the sparsity of each dataset  X  and the lowest possible novelty and sales diversity  X  which should be so by definition. Matrix factorization (only tested on Netflix for the aforementioned reasons) has good novelty and sales diversity, outperforming the standard nearest neighborhoods methods, but not the inverted variant.
The results of our experiments with the Probabilistic Layer approach are shown in Figure 2. For each dataset-baseline pair we display two scatter plots showing the trade-offs be-tween precision vs. novelty and sales diversity for the novelty-oriented re-scoring technique (NR) and our probabilistic ap-proach (BR). Curves for each approach start from  X  =  X  = 0 . 0 as the points with the lowest novelty and diversity and, as  X  and  X  tend to 1.0, improve in terms of EPC and Gini while  X  generally  X  having lower precision values. Assum-ing that the interpolated lines are a good approximation to the continuous range of the trade-off parameters, we deter-mine that a method is better that the other if its curve is generally above the other in each plot. Under this criterion, the results in Figure 2 show the validity of our probabilistic approach.

In the Netflix data, we can see how the compared ap-proaches show practically identical trade-offs in terms on EPC and, in terms of Gini, our probabilistic method clearly outperforms the novelty-oriented re-ranking. Surprisingly, the probabilistic approach outperforms the original scoring function even in terms of precision and, among baselines, it is the one that achieves the highest sales diversity scores. On the other side, the improvements on the matrix factorization approach, although being perceptible, are more limited that those in the nearest neighbors recommenders.
In the Million Song dataset the results are analogous. Both r e-ranking approaches present similar outcomes in terms of EPC, while the probabilistic approach clearly outperforms the novelty-oriented re-ranking. Again, item-based kNN is the baseline that enables a higher improvement in terms of sales diversity.

In conclusion, the proposed probabilistic approach pro-vides a new method for improving trade-offs between accu-racy, novelty and sales diversity. Compared to a simpler approach that optimizes directly the long-tail novelty of rec-ommendations, our proposal obtains comparable results in terms of the novelty of recommendations, while it shows clearly better results in terms of sales diversity.
Starting from the aim of improving sales diversity by rec-ommendation, we explore in this paper where the inversion of the recommendation task leads to. By ranking users for items, the recommendation approach focuses on the rele-vance of user-item pairs in a different way, and item pop-ularity gets left aside as a result. Starting from this task inversion, we derive two approaches to improve the sales di-versity of the original item recommendation task. The first one, inverted neighborhoods, results in a novel way of  X  X e-mocratizing X  the weight of user opinions (in the user-based approach) and item opportunity (in the item-based variant), leading to substantial improvements in terms of sales diver-sity, competitive results in recommendation novelty and a good precision trade-off. The second approach, a probabilis-tic reformulation of the recommendation problem, allows isolating the popularity component of any recommendation baseline and calibrate it in order to increase the chances of less popular items to appear in recommendations lists. Experiments on two different datasets, namely Netflix for movie recommendation and the Million Song Dataset for music recommendation, confirm and illustrate the effective-ness of our proposals.

The symmetric inversion of the recommendation task en-tails more than a simple transposition of the rating matrix. It brings up a new view on the task where the system seeks the most appropriate users to whom an item can be recom-mended, even though the final action is still the delivery of a ranked list of items to each user. This problem statement can reflect real-world situations where a business is selecting targets for advertising a particular product.

As future work, we envisage deeper studies on the prop-erties of neighborhoods we examined in Section 6 with ad-ditional metrics in order to uncover further potential biases in user and item neighborhoods. We also envision further improvements of the Bayesian reformulation. In particular, we intend to explore increasing the exclusivity of items, that is, recommending each item to only a limited selection of users. In our probabilistic scheme, this exclusivity could be carried out by re-defining the likelihood component p ( u | i ; s ) in Equation 14, for instance by creating a cut-off of the users with highest scores for item i or by means of parametrization similar to the one of the prior in Equation 17. This work was supported by the national Spanish project TIN2013-47090-C3-2.
