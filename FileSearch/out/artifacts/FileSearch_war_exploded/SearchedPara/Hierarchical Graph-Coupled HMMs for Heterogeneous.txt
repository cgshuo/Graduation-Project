 The purpose of this study is to leverage modern technology (mobile or web apps) to enrich epidemiology data and infer the transmis-sion of disease. We develop hierarchical Graph-Coupled Hidden Markov Models (hGCHMMs) to simultaneously track the spread of infection in a small cell phone community and capture person-specific infection parameters by leveraging a link prior that incor-porates additional covariates. In this paper we investigate two link functions, the beta-exponential link and sigmoid link, both of which allow the development of a principled Bayesian hierarchical frame-work for disease transmission. The results of our model allow us to predict the probability of infection for each persons on each day, and also to infer personal physical vulnerability and the relevant association with covariates. We demonstrate our approach theoret-ically and experimentally on both simulation data and real epidemi-ological records.
 J.3 [ Computer Applications ]: LIFE AND MEDICAL SCIENCES X  Health ; I.2.1 [ Computing Methodologies ]: ARTIFICIAL INTEL-LIGENCE X  Applications and Expert Systems: Medicine and sci-ence Dynamic Bayesian Modeling; Social Networks; Heterogenous In-fection; burn-in Gibbs EM
Recently, much emphasis has been placed on personalized med-ical treatment and advice, encouraging prediction of disease on an c  X  individual level. However, the majority of research on detecting patterns in and discovering the risks of infectious disease has been at the population level. The purpose of this paper is to use popu-lation data from social networks to develop individualized predic-tions for infectious disease risk and transmission.

Social network data at the population levels provides a frame-work for identifying interactions and transmission and has been used to populate complex systematic models and individual level risk models. [6] utilized fixed social network analysis on susceptible-infectious-recovered (SIR) models to identify high-risk individuals. [20] X  X  work on close proximity interactions (CPIs) of dynamic so-cial networks at a high school indicated immunization strategies is more credible if extra contact network data were provided.
However, the preponderance of available social network data re-lies primarily on reported network connections, resulting in a miss-ing data problem and reducing the robustness of inferences that can be made with this data. In this study, we sought to overcome these problems by utilizing a novel cell phone bluetooth network contact app to infer dynamic social network interaction, infection proba-bility and transmission. Location and time based information from this app allow us to track personal daily contacts between partici-pants. Proximity can be measured by the contact duration within a certain range. Similar social experiments have been conducted and mentioned in [1, 9, 8], but these prior models assumed homoge-neous individuals or global parameter sharing within the networks, and did not include data on potential modifying factors, such as personal health habits and demographic features of individuals in the network.

The intuition of hierarchies to improve model flexibility is exten-sively studied in topic modeling, in models such as latent Dirich-let allocation (LDA) [5, 2, 17]. [5] used a sigmoid link function, introduced in Relational Topic Model to learn fixed networks of documents. These, and further works have exemplified a trend in data-driven machine learning applications  X  hierarchical modeling applied in order to infer complex data structure. Our work can be considered as a hierarchical extension of either GCHMMs [9] or topic HMMs [11] with a nested transition function.

The main contribution of this paper is to characterize person-specific infection parameters under a covariate dependent hierar-chical structure on GCHMMs. Our link function is associated with covariates referring to personal features, such as gender, weight, Figure 1: Illustration of GCHMMs including 3 people. 1 and 3 have social contact between t  X  1 and t . The infection states of 1 and 3 at t are then both influenced by each others X  infection states at time t  X  1 . hygiene habits, and diet habits, with the hypothesis that better per-sonal hygiene, diet, and lower weight, should be result in lower susceptibility to influenza. However, it is difficult to choose an ap-propriate link function or distribution to obtain a conjugate prior for inference. Our proposed link function can be easily generalized to Dirichlet-exponential or softmax link. Inspired by [7], a burn-in Gibbs sampling Expectation Maximization (bGEM) algorithm is developed for parameter estimation in hGCHMMs, and addi-tional infection network inference simultaneously. Specifically, a faster version of our EM algorithm when binary latent variables are appropriate is primarily used for our experimental tests, which significantly accelerates the computational speed without a signif-icant impact on accuracy. In the case of unavailable covariates, our model is easily reduced to a no-link version by simply infer-ring each infection parameter from a common prior, the same as in standard GCHMMs.

The rest of the paper is organized as follows. In Sec. 2, we de-scribe the basic idea of GCHMMs and our proposed hGCHMMs, explicitly discussing the two different link schemes. In Sec. 3, we show how to modify the EM algorithm for a burn-in Gibbs sam-pling version. In Sec. 4, we report empirical results by imple-menting our algorithm and applying it to synthetic and real-world datasets. Conclusions and future research directions are discussed in Sec. 5.
We first briefly introduce the standard graph-coupled hidden Markov model (GCHMM) (evolving from coupled hidden Markov model [3]), a dynamic model for analyzing the discrete-time series data by leveraging the interactions of a non-fixed social network (see Figure 1 for an example, where filled in nodes are observed).
Let G t = ( N,E t ) be a network structure at time t , where each agent or participant is represented by a node n  X  N in graph G n covariates indicating personal features ) recovery probability if infectious at pervious timestamp ) probability being infected from some one outside networks ) probability being infected from some one inside networks ,s emission probability of symptom s onset given x n,t and E t is a set of undirected edges in G t , where ( n i two participants n i and n j have a valid contact between time t and t + 1 . The generative model of GCHMMs is then defined in a fully bayesian way (Notations in above Table). where the transition probability  X  n,x tion of the infection parameters and the dynamic graph structure. Figure 1 also indicates that the transition of the hidden state is not only dependent on the previous state of its own HMM but also influ-enced by states from other HMMs that have edges connected to it. One undirected edge in G t indicates a valid contact in time interval [ t,t + 1] , thus leading to a directed edge in GCHMMs. Recalling the definition in terms of  X , X , X  , we have the transition probability as follows: fectious sources for node n in G t , and I {} is the indicator function. This Bayesian formulation of the GCHMMs can be applied to fit homogenous susceptible-infectious-susceptible (SIS) epidemic dy-namics. Next we will generalize this basic model for other related purposes by leveraging hierarchical structure and the relevant co-variates.
It is assumed that personal health features (covariates) are present, as well as the observed symptoms, denoted as z n  X  R K , where K is the dimension of the covariate feature space. Without loss of generalization, the feature space includes a default feature being constant at 1. An appropriate mapping f : R K  X  [0 , 1] or transfor-mation from the feature space to infection parameters is necessar-ily introduced to construct a correlation between personal condition and vulnerability, (see Figure 2, notice that node G t is shared by rectangle template of each person, thus being represented by par-tially intersection). In this section, we propose two link function Figure 2: Template Representation of hGCHMM: The graphi-cal model renders a clear structure visualization on the depen-dence between all variables and parameters. constructions. A natural way to go is to extend the beta prior of the standard GCHMM to a beta-exponential link.

Beta-exponential link where  X   X  ,  X  is distributed as multivariate Gaussian playing the role of the regression coefficients, since the expectation 1 can be considered as an approximation for logistic regression with term exp( z &gt; n  X   X  ,  X  ) to take the place of the hyper-parameter of beta prior. The usual count update to the hyper-parameter will implicitly update  X  via our EM algorithm.
 Once  X , X , X  are allowed to be indexed by n , the arguments in Equation (2) need index modification, but the other terms remain the same. We put an individual level distribution on transition but not on emission because it makes more sense that everyone has the same probability of physical behavior given an infection state. Patients should have corresponding symptoms, such as cough or throat pain, or the flu cannot be discovered or diagnosed. The ad-vantage of this setting is that it allows for the Gibbs sampling of infection parameters in a way that still holds from previous models, except for  X  , so that the original Gibbs sampling scheme to update the beta distribution by event counts is the same in the later E-step. Another advantage is, when X is generalized to categorical vari-ables, a similar construction also works. Furthermore, rather than do approximate logistic regression, we next propose a real logistic regression link.

Sigmoid link where  X  ( x ) = 1 1+ e  X  x is the sigmoid function.

In the generative process of infection parameters, less  X  s are present, thus leading to a simpler model. Instead of sampling, the equations for  X , X , X  will actually make these parameters vanish in the model. In other words,  X  n,x placed by  X  n,x perspective, the EM derivation will be easier, and the experimental results imply its outperformance of competing methods. Addition-ally, this link function inspires another two-step model: first, the infection parameters in Equation (1) are enforced to be individually indexed by n , and the inference process is run in a similar Gibbs sampling scheme [9]; second, a standard logistic regression is fit between the learned individual parameters and covariates Z .
Remark (1) The beta-exponential generative model is not well defined for one time step data simulation, because we need a unique sample from this generative model, which actually uses a set of fixed parameters (  X  f n , X  f n , X  f n ) N n =1 to sample X and Y . Take  X  for example, E (  X  n ) 6 =  X  f n , since  X  f n is one realization of the gen-erative model. What our algorithm aims to learn is a generative not E (  X  n ) . (2) Therefore, our simulation dataset is always gen-erated from the sigmoid link model. However, it is reasonable to use the beta-exponential link model for inference to eliminate the inconsistency. It has been mentioned previously the expectation of beta-exponential is virtually an approximation logistic regression. An EM like algorithm can perform a good point estimation for this expectation, which in turn would be an estimator of the sigmoid link. (3) Another way to make the beta-exponential generative and the inference process work is to sample  X  n , X  n , X  n both individu-ally and dynamically, i.e.  X  n,t , X  n,t , X  n,t . A number of realizations are sufficient to learn the true generative distribution, though the new inference algorithm will necessarily become more difficult.
Another interpretation of  X  n In above two extensions, it is im-plicitly assumed that  X  n means the individual infection probability from another person within the network, is as given in Equation (3). From the biological side, the contagiousness of the infected person varies, meaning that  X  n can be interpreted as the probabil-ity of spreading illness to any other person in the social network. This interpretation results in a slightly complicated mathematical calculation (details in EM algorithm section), since both the total count of infectious contacts and specific diffusion sources are re-quired for Equation (4).

P ( x n,t +1 = 1 | x n,t = 0) = 1  X  (1  X   X  n )(1  X   X  n ) C
P ( x n,t +1 = 1 | x n,t = 0) = 1  X  (1  X   X  n ) Y where the nodes set of infection contacts is defined as S { n 0  X  [ N ] : ( n,n 0 )  X  E t ,x n 0 ,t = 1 } .
The inference process is designed to invert the generative model and to discover the  X  and X that best explain G and Y . In our hi-erarchical extension, however, a fully conjugate prior is not present and it has been mentioned that knowing what the right prior is can be difficult. Thus an approximate conjugate is developed by in-troducing the auxiliary variable R n,t , representing the non-specific infection source (inside or outside networks). The idea is to decom-pose infection probability 1  X  (1  X   X  n )(1  X   X  n ) C n,t into the sum-mation of three terms,  X  n (1  X   X  n ) C n,t , (1  X   X  n )(1  X  (1  X   X  and both respectively. R n,t follows categorical distribution: The exact distribution of R n,t is still difficult to use. Thus by taylor expansion we have P ( R n,t = 2) P ( x n,t +1 = 1 | x 0)  X  C n,t (1  X   X  n )  X  n and P ( R n,t = 3) P ( x n,t +1 0)  X  C n,t  X  n  X  n . The two approximations attain the fact that lo-cal full conditionals can be analytically obtained by discarding  X  temporarily. In practice the term involving P ( R n,t = 3) can be approximated as 0 for Gibbs sampling. Because of the biological application,  X  n and  X  n are both the positive real value close to 0, resulting in their product being quite small. Even if this probability is taken into consideration in the Gibbs sampling, there is a very small chance that R n,t = 3 . This approximation allows the poste-rior distribution of  X  n , X  n to be much easier to compute given the current value of  X  . Concretely, we have the following posteriors, which will benefit the EM algorithm described later:  X  n  X  Beta e z  X  n  X  Beta e z  X  n  X  Beta ( e z where the count notations are defined as follows.

Note that auxiliary variable R did not appear in the posterior of  X  , which is exactly computed due to conjugacy. Utilizing these approximate posteriors, the complete likelihood P ( X,R, X  | Z ) is obtained by integrating out the infection parameters.
 = P (  X  ) Y where B (  X  ) is beta function, and P (  X  ) is a multinomial Gaussian distribution. The integral result enables the analytical computation of the gradient  X   X  and Hessian  X  2 of the log-likelihood, then con-tributing to Newton X  X  method.
Sampling Infection States Given all  X  n , X  n , X  n , the generative model implies a conjugate prior for x n,t . The unnormalized poste-rior probability of x n,t = i can be represented as p i n,t where the normalized posterior of p ( x n,t = 1) is p 1 n,t needs to be some caution of the boundary condition since x and x n,T do not have this form. x n, 1 is generated by x pends on the initial event occurrence rate  X  , further requiring some mild modification. The full conditional of  X  can be computed.  X  | X  X  Beta a  X  + X For state x n,T , the posterior is easily computed since terms associ-ated with t + 1 cancel out immediately.

Sampling Missing Observation For real world data, a missing value problem commonly arises because of underreporting in data collection. Bayesian schemes can successfully fill in missing val-ues by drawing y n,t,s according to the distribution Bernoulli (  X  if they are NA . Sampling y n,t,i , the posterior of  X  i,s from a beta distribution.  X  i,s | X,Y  X  Beta a i + X
As far as we know, previous works on CHMMs or GCHMMs have not included the sampling scheme for global parameters  X  . One possible solution is the Metropolis Hastings (MH) algorithm due to the approximate likelihood in Equation (6); however, the transition kernel is difficult to choose for MH, and running large numbers of iterations is usually required to achieve good mixing.
In this section, we propose a fast algorithm based on expectation-maximization. Expected sufficient statistics are computationally intractable since there is no closed form in our case. Stochastic Approximation (SA) EM [7] is an alternative introduced to sim-ulate the expectation, and able to obtain convergence to a local minimum with a theoretical guarantee under mild conditions. The basic idea of this computation is using a Monte Carlo sampling ap-proximation; however, we replace this step with Gibbs sampling by utilizing the approximate conjugacy property.
 The true expectation integration Q ( k ) (  X  ) is approximately calcu-lated by a stochastic averaging in a burn-in representation taking advantage of Gibbs sampling with form (11). During each Gibbs sampling step, infection parameters are in fact always up-dated at each inner iteration, thus making the latent variables X,R update based on different posterior distributions at each sampling, which disagrees with SAEM. Therefore the samples at later iter-ations are closer to the true posterior given current  X  ordinary SAEM, latent variables are sampled from a fixed poste-rior, which is the reason why burn-in modification is not necessary. From this perspective, the burn-in Gibbs sampling in E-step may accelerate the convergence rate in the next maximization step. M-step : Maximize with respect to  X  , i.e. arg max  X  However, directly optimizing  X  Q ( k ) (  X  ) will suffer from the same drawback as in standard EM. Pathological surfaces of the log-likelihood may be present via saddle points and local optima, meaning that the algorithm is sensitive to initialization. [7] argued that the aug-can avoid this problem partially, where  X  Q ( k ) (  X  ) usually takes one sample to introduce a stochastic property, and  X  ( k ) is a small posi-tive step size, essentially requiring the conditions in (10) The intuition to solve this intractable objective lies in [4], showing that this optimization can be updated by  X  ( k +1) = (1  X   X   X  Monte Carlo (MC) EM [22] with large sampling size, and  X  ( k +1) is the special case of MCEM in a unique sample.

Generalizing MC to Gibbs sampling, we formalize Algorithm 1, where  X  Q bGEM takes the sample average of Gibbs algorithm and  X  Q SEM takes the last sample.  X  Q SEM is a stochastic perturbation of EM, and is expected to search more stable points. The algorithm starts from the completely optimized  X  Q SEM with  X  (1) = 1 , making the search area large for the first few steps. Then it focuses more weight on optimizing  X  Q bGEM . Theorem 1 provides a theoretical guarantee, and can be proved by using two convergence bounds; Birkhoff Ergodic theory [10] and Theorem 7 in [7].

T HEOREM 1. Under certain conditions with exponential family for log-likelihood function and the step size constraint (10), the sequence generated by bGEM for sufficient large J converges a.s to a local maximizer, whatever the initial point (convergence towards saddle point is avoided with probability 1).

P ROOF . Sketch: With abusing notations,  X  Q SEM ( x ;  X  ) means it depends on the single sample and parameter optimized parameter at previous step, where s denotes all latent variables. The conditions follow the definition appearing in [7, 14] and we have Lemma 1.
Conditions: (1) The complete data likelihood function is expo-where functions  X , X ,S are twice continuously differentiable. (2) The expected log-likelihood l (  X  ) is continuously differentiable and  X  Cov  X  (  X  Q SEM ( x, X  )) is continuous wrt  X  . (4) The stationary points of l (  X  ) are isolated: any compact subset contains only a finite number of such points.

L EMMA 1. Assume that above listed conditions hold and the sequence {  X  k } converge to some proper maximizer  X   X  . If in ad-the N (0 ,  X ) I (lim k  X  X  X  k  X  ( k )  X   X   X  k = 0) , where  X  = [  X  )  X   X  L (  X  s (  X   X  ))][  X  2  X  l (  X   X  )]  X  1 In our algorithm we pick up the single sample every J iterations as  X  Q ( k ) SEM and use the burn-in J  X  B samples to compute  X  to approximate the true Q (  X  |  X  ( k  X  1) ) = E [log P ( X |  X  )] . Thus we only need to argue that  X  Q ( k ) bGEM ( J  X  B )  X  X  X   X  X  X  X  X  X  X  X  X  X  X  X  Q (  X  |  X  Birkhoff-Khinchin Ergodic theorem [10] ensures this conclusion.
Faster version of binary latent variable Because the first or-der derivative with respect to  X  has no analytical root, the inverse
Data : Z , Y , G , sampling size J , burn-in iteration B , step size Result :  X  and X
Initialize coefficient parameter  X  (0) ; repeat until  X  ( k ) Convergence ; of the Hessian matrix is computed with computational complex-ity O ( K 3 ) . The dimensionality of H is K independent of N , and a PCA preprocessing will reduce it significantly, leading to a lower matrix inverse computation. Though K is small in most cases, there may still be a high cost to computing the Hessian itself ( O ( JK 2 ) ) for matrix addition, unless there is a parallelized im-plementation. [18] prove a theorem to address the exchangeablity of the derivatives and expectations for random Gaussian variables. [19] implemented this idea in a non-Gaussian posterior likelihood and obtained good performance. An improved SAEM coupled with MCMC is discussed in [13], which argued that only one sample is required in the E-step if an appropriate Markov transition kernel is also used.

Consequently, we follow these two ideas to design our single sample algorithm by taking the posterior mean. Technically, using the fact that P ( R = 3)  X  0 , latent R is also considered as bi-nary variable without harm. Therefore, at the k th iteration of EM, the pseudo-sample can be constructed via a Bayesian decision rule based on the burn-in posterior mean in Gibbs sampling, i.e. This means that a unique set (  X  X,  X  R ) is sufficient to approximate  X  Q ( k ) (  X  ) , that is to say, log( P (  X  X,  X  R, X  ) | Z, X   X  Q bGEM . This trick applied on non-Gaussian variables is not the-oretically guaranteed but has been broadly used in EM or other optimization problems, by assuming a fully factorized joint distri-bution. In our binary variable case we found that it made no signifi-cant difference on accuracy whenever this trick applies, in practice.
Optimization To optimize  X  ( k ) *EM at the k th M-step, the update formula by Newton-Raphson Method is briefly outlined in this para-graph, excluding the analytical gradient G and Hessian H compu-tation. For efficiency, we update parameters as follows, with a few iterations. where *EM varies according to different estimators, bGEM or SEM. It is unnecessary for there to be complete convergence in order to ation is mentioned in [14]. The step size  X  ensures that the Wolfe conditions [16] are satisfied. The intuition in adding in step size here is, compared with gradient descent, Newton X  X  Method tends to make more progress in the right direction of local optima, due to the property of affine invariance. This probably leads an update where the step size is too large, so it is better for stochastic algo-rithms to enlarge the search domain at first then shrink later.
As has been previously discussed, a sigmoid link function ben-efits from model simplicity and hiding infection parameters with-out integrating them out. The likelihood P (  X ,X | Z ) can thus be exactly computed as Equation (12). It means that, in parameter estimation, we can either apply standard SAEM by getting rid of latent variable R immediately, or bGEM by introducing R as well in E-step and faster version M-step by keeping  X  X alone. P (  X  )
In the second biological interpretation of  X  n (probability of in-fecting others), transition function  X  n,x the extra parameter set {  X  n 0 : n 0  X  S n,t } . Consequently, the pos-terior of each  X  n requires both a count number and source tracking (like the concept of a "pointer" in the C programming language). However, the likelihood of the beta-exponential model can be sim-plified to integrate out these parameters due to the auxiliary vari-able R as well, corresponding to the new categorical distribution in Equation (13), though P ( R ) in Equation (5) can also have this formulation.
 P ( X,R, X  | Z ) = P (  X  ) Y R n,t takes the value { 0 , 1 ,...,C n,t } , where 0 means there is an out-side network source and other integers mean specific infection in-network sources. The categorical distribution makes the beta prior for the infection parameters conjugate in the posterior. However, the integral for the likelihood is actually difficult and needs some algebraic tricks, especially for  X  n because of the source tracking. We show the result of the beta-exponential model in 14, while the sigmoid model is straightforward and obtained without too many tricks. The new count notations are listed below.

In this section we illustrate, on simulated data, the performance of our approach, hGCHMMs and the burn-in Gibbs EM algorithm on three datasets for the purposes of predicting the hidden infec-tious state X , filling in missing data  X  observation Y , and infer-ring an individual X  X  physical condition based on parameter estima-tion. Further application on the public real world Social Evolution Dataset [15] and our mobile apps survey dataset are also shown.
Differing from completely simulated data or a totally artificial setting, we employed a generative model to synthesize X , Y based on the real dynamic social network G t and covariates Z from the real Social Evolution dataset. The predefined X then plays the role of ground truth, making evaluation for all above points possible.
Real Part Public MIT Social Evolution dataset contains the dy-namic networks G including 84 participants over 107 days, G dexes 1 to 107, and covariates z n exist for each participant, includ-ing 9 features, weight, height, salads per week, veggies fruits per day, healthy diet level, aerobics per week, sports per week, smok-ing indicator, and default feature 1. The quantity per week is fre-quency. Weight and height are taken as real values. Healthy diet includes 6 levels ranging from very unhealthy to very healthy based on self evaluation. Smoking indicator is literally a binary variable. Real symptoms Y are temporarily discarded since the true infection states X are unavailable for this dataset.

Synthesized Part X and Y are then generated based on a Sig-moid link generative model. It is noticed that hyperparamter  X  needs to be predefined, which means synthesized infection param-eters  X  n , X  n , X  n are known because of the sigmoid function. Only synthesized data Y with 6 symptoms is given to learning model, but the evaluation is done on other variables. The proportion of miss-ing values in Y is set to 0.5, i.e, the observations y n,t,s probability 0.5. Our generated X (an 84  X  108 matrix, including initial states) is shown in Figure 3(a). Each row vector represents a person X  X  infection states during the entire observation period.
We ran the algorithm 10 times. The prediction performance on latent variable X is the byproduct of the E-step, and when x larger than the threshold 0 . 5 the person is diagnosed as being in-fected. Since X is completely unknown to the algorithm, held-out test data prediction is unnecessary but all X is used to evaluate pre-diction accuracy. Figure 3(a-c) shows the difference between the truth and the inferred results from each of the two linked models. The posterior mean from Gibbs sampling for prediction, in both beta-exponential and sigmoid models, leads to a real value in the interval [0 , 1] . Figure 3(d) reveals a quantitative measurement on accuracy with standard deviation. As mentioned before, a two-step algorithm including standard GCHMM and further logistic regres-sion is also implemented and compared to. The rightmost error bar in Figure 3(d) shows its predictive performance. GCHMM needs to run at least 2000 iterations of Gibbs sampling to obtain good mix-ing, while in our approach, we only run about 50 inner iterations in E step and less than 10 outer EM iterations.

Figure 3(e-g) display the predictive error of the forecasted infec-tion parameters. Since the infection parameters are individual spe-cific, the estimation is in fact a vector of length N . Therefore we used the 2-norm of the error vector for comparison. It is apparent that the sigmoid model shows the best performance on latents X or  X  , X  n , X  n , in terms of the generative model. The Beta-exponential Model, mentioned in Sec. 2, as an approximated substitute for lo-gistic regression on infection parameters, proves its competitive for parameter estimation. However, standard GCHMM with logistic regression, as two independent parts of the sigmoid model, pro-vides an unreliable prediction on individual-specific parameters, albeit its excellent latent variable inference. All three inference methods use Gibbs sampling to infer X . This is most likely the reason why they share equivalent performance.
From the perspective of general health care or disease control for large populations,  X  is of concern (discussion on a real biological dataset later). However, as for individual treatment and personal medical advice,  X  n , X  n , X  n should be more significant for physical health. Better immunity usually indicates a smaller  X  n , X  larger  X  n . In our model, these parameters are designed to correlate with personal health habits by using a link with influence coeffi-cient  X  . The prediction of the infection parameters on raw data Z is shown in Figure 3(h-j). This illustration is consistent with the er-ror bar plot in Figure 3(e-g). The predicted values of our proposed models are distributed with higher concentration on the diagonal ( y = x ), while standard GCHMM + logistic regression has rela-tively larger variance. The underlying linear slope for  X  inconsistent with y = x . This phenomenon can be blamed on the colinearity of Z if taking the names of covariates literally. Thus, we apply Principal component analysis (PCA) on Z , and then se-lect the first 4 components (explaining 99.9%) and the default fea-ture 1. We next run the program again and obtain the scatter plot of Figure 4: Colinearity elimination on  X  n : PCA justification on Figure 3 (h) is to obtain the regressed slope close to 1. Figure 5: Epidemics state inference on real Data: (a) shows the true reported symptoms by 84 participants at day 5; (b) gives the one step ahead prediction of (a); (c) is predicted infection.  X  n (Figure 4). Result imply that PCA can eliminate the colinearity effectively.
This real world dataset [15] is collected from a college dormi-tory building by web survey and contains the dynamic graphs G covariates Z , and daily symptoms Y , where y n,t is a 6 dimen-sional vector including sore throat and cough, runny nose, conges-tion and sneezing, fever, nausea, vomiting and diarrhea, sadness and depression, and openly stressed. The proportion of missing values Y is about 0.6. The purpose is to infer latent variables X and infection parameters, and making tentative health suggestions to students. Even if we cannot evaluate the performance on the true X s, the Google search of "flu" [9] implies a underlying correlation with this result. Since Y can be partially observed (no NA ), one step ahead prediction on Y is possible, and obtains an accuracy at 92.09% (threshold is also 0.5). Results are shown in Figure 5.
Evaluation on the public MIT dataset seems only partially useful, since true diagnoses are unavailable. We describe the design, study population characteristics, and social network structure of a chain referral sample of 590 students living in University of Michigan residence halls who were randomized to an intervention of isolation over a 10-week period during the 2013 influenza season. In our experiment, diagnoses are recorded immediately at onset. 590 students living in six eligible residence halls on the Uni-versity of Michigan campus enrolled in the eX-FLU study during a chain referral recruitment process carried out from September 2012-January 2013. 262 of these, as "seed" participants, nomi-nated their social relations to join the study as well. The rest, 328, were nominees that enrolled. Participants have to fill out weekly surveys on web apps about their health behaviors and social in-teractions with other participants, and a symptoms indicator report of influenza-like illness (ILI). A subsample of 103 students were provided with smartphones with a mobile application, iEpi [12], which is able to collect location sensor and contextually-dependent survey information, implying social contacts that are used in our computational model. This sub study experiment perfectly fits our proposed model, so the main evaluation will be performed on this sub dataset. Generally speaking, the underlying cumulative distri-bution of degree for the overall social network on 590 students is shown in Figure 6. The distribution of three degree measurements (in, out, or total), were heavily right-skewed and over-dispersed. Consequently, the network appears scale-free, with a log-log plot and linear trend line ( R 2 = 0 . 91 ) illustrating the approximately power-law distribution for total degree. 103 (17.5%) students of the 590 enrolled participants were equipped with provided smartphones and joined the iEpi sub-study. They were required to use their iEpi smartphone and could report their symptoms, meeting the study criteria for ILI. A total of 4843 contextually-based surveys were administered on all sub-study smartphones (mean 62.09/day), 1743 (36.0%) of which were responded to by iEpi sub-study participants (mean 22.35/day). There were a total of 60131 Bluetooth contacts between smartphones within the iEpi sub-study, and 148,333 total Bluetooth contacts with other devices of any kind, averaging 7.48 contacts/phone/day and 20.95 contacts/person/day, respectively.

The bluetooth detector can automatically collect contacts occur-ring between iEpi installed smartphones, or to other smart devices. Each node (circle) in Figure 7 represents an individual in the sub-study, and the links (edges) between nodes represent bluetooth de-tections between smartphones of individuals within the sub-study networks. Node size is proportional to the total number of con-tacts detected by bluetooth data (equivalent to degree), and the link thickness indicates the contact duration between the two nodes Figure 7: iEpi Bluetooth network (N=103). Network of Blue-tooth contacts between smartphones in the iEpi sub-study Figure 8: Dynamic Social Networks derived from Figure 7. 103 dots uniformed distribute as a large circle. Contacts within the network account for edges between solid dots. (equivalent to weight on edge). During the experiment period, we also conducted a comparison test. Some participants (yellow nodes which means no social contacts during these period.

The next step is to extract daily social networks. We use the 77 days of the iEpi survey data which is relatively complete, and its corresponding bluetooth data to construct dynamic networks. Fig-ure 8 illustrates 4 independently sampled sub-networks, i.e. G t = 2 , 27 , 52 , 77 . To make more sense of the edges, only the blue-tooth data showing the total contact duration between two partic-ipants lasting more than 10 minutes will contribute to an edge on that day. The threshold of 10 minutes can be adjusted to make the graph denser or sparser, thus leading to a higher or lower computa-tional cost.

Gender 1 means female; Alc_Day: average times of hand wash-ing by sanitizer; Vacc_Ever: take vaccination before; Flushot_Yr: take vaccination this year; Act_Days: exercise in broad sense per day; Wash_Opt: whether wash hands exceeding 20s; High_Risk: contact with impaired immunity patient.
 Figure 9: Left is true Onset and its Duration. Right is predicted by Sigmoid Model.

Feature 1 Recovery  X  r Outside Infect  X  a Inside Infect  X  Default = 1 -1.3022  X  0.0146 -5.1517  X  0.0024 -4.1619  X  0.0281 Gender -0.1575  X  0.0118 -0.2428  X  0.0074 -0.1457  X  0.0078 Age 0.0074  X  0.0082 -0.2376  X  0.0051 -0.0181  X  0.0017 Alc_Day 0.1090  X  0.0078 -0.1534  X  0.0003 -0.0410  X  0.0018 Vacc_Ever -0.0698  X  0.0104 0.1092  X  0.0095 0.0382  X  0.0085 Flushot_Yr 0.0769  X  0.0092 -0.3209  X  0.0073 0.0837  X  0.0055 Smoker -0.1080  X  0.0029 -0.0536  X  0.0008 0.0773  X  0.0021 Drinker -0.1335  X  0.0092 0.0628  X  0.0030 0.1408  X  0.0029 Act_Days 0.0356  X  0.0099 0.0054  X  0.0063 -0.0622  X  0.0078 Sleep_Qual 0.0225  X  0.0069 -0.3686  X  0.0051 -0.0162  X  0.0077 Wash_Opt 0.0024  X  0.0103 0.0816  X  0.0132 -0.0714  X  0.0048
High_Risk -0.1274  X  0.0116 -0.1252  X  0.0058 -0.0727  X  0.0007
Available illness onset diagnoses in our experiment allows for the evaluation of inferred infection states. We tried all three models, Sigmoid link, Beta-exponential link and standard GCHMMs+LogReg on this dataset. Because of the specific quantized distribution of di-agnosed flu onset (see red short pattern of left graph in Figure 9)), the three methods perform stably, but give different results over 10 runs with no standard deviation. Though they all heavily rely on Gibbs sampling, the sigmoid link model can detect more short term patterns than the other two. Table 1 gives both precision and recall for prediction, since the proportion of positive instances, un-like our simulation, is about one tenth. Even the sigmoid model missed some very short patterns. Two reasons may contribute to this phenomena; the first is that HMMs are a long distance depen-dent model; second is that we find symptom reports for short period disease courses are always low severity.

In contrast to other models, and serving as the mainstay and nov-elty of this paper, we aimed to learn how personal features (first column in Table 2) were associated with individual flu vulnera-bility, i.e. coefficients  X  . A Sigmoid transform on  X  will imme-diately give infection parameters. Larger  X  n implies better body resistance, while larger  X  n , X  n indicates more vulnerability. Be-cause body resistance or vulnerability is not an experimental quan-tity (difficult to measure in real world dataset), we prefer to evaluate coefficients  X  (Table 2) rather than actual infection parameters. The right three columns are the estimated  X  s associated with different biological meaning (indicated by their subscripts) in the Sigmoid model X  X ossessing the best performance in both the simulation and real cases. Looking at the feature column, we can see that females seems suffer from a slower recovery but are not as likely to catch a cold. Another important factor is an indicator of participants ad-dicted to alcohol. Drinkers significantly aggravate body immunity. However, whether or not one washes their hands for more than 20s, interestingly, seems not to be significant to the model, especially to the recovery rate. This may blamed on an overly long washing duration X 20s in the experimental design. Overall, the sign consis-tency with respect to  X  makes sense, with the exception of a few counter intuitive relationships. For the sigmoid function, positive coefficients will enlarge infection parameters, and vice versa.
We propose hierarchical GCHMMs to simultaneously predict in-dividual infection and physical constitution by observing how flu spreads within dynamic social networks. The heterogeneous model is validated on semi-synthetic data and epidemiological tracking data in college dormitories, and outperforms existing GCHMMs (plus logistic regression). On semi-simulation data, we evaluate our model on a number of metrics, including on the ability to correctly infer parameters. On the MIT social evolution data, we mainly focus on one step ahead prediction of the observed states (or symp-toms). In our eX-Flu study, we successfully discovered the under-lying social network pattern and personal feature relationships with respect to influenza vulnerability.

The variant of the EM algorithm we developed for inference proved to work well both from a theoretical view and in experimen-tal results. Future research might explore belief propagation and variational inference methods for parameter estimation. Another possible area of future research would be to implement Remark (3) or investigate infection network learning by detecting the disease spread path (auxiliary variable R ). We can further relax the het-erogeneity assumption to a cluster assumption. Inspired by HDP-HMMs [21], this tradeoff can be realized by constructing a non-parametric version GCHMMs, enforcing similar HMMs to share the same parameters. We would like to thank Dylan Knowles, under the supervision of Dr. Nathaniel Osgood and Dr. Kevin Stanley, and the aid of other students and fellows developed the iEpi application and helped oversee the iEpi app smartphone upload, data collection proce-dures, and trouble shooting for the eXFLU study. This work was supported by Duke NSF grant #3331830. Any opinions, findings and conclusions or recommendations expressed in this material are the authors X  and do not necessarily reflect those of the sponsor. [1] R. Beckman, K. R. Bisset, J. Chen, B. Lewis, M. Marathe, [2] D. M. Blei, T. L. Griffiths, and M. I. Jordan. The nested [3] M. Brand, N. Oliver, and A. Pentland. Coupled hidden [4] G. Celeux, D. Chauveau, J. Diebolt, et al. On stochastic [5] J. Chang, D. M. Blei, et al. Hierarchical relational models for [6] R. M. Christley, G. Pinchbeck, R. Bowers, D. Clancy, [7] B. Delyon, M. Lavielle, and E. Moulines. Convergence of a [8] W. Dong, B. Lepri, and A. S. Pentland. Modeling the [9] W. Dong, A. Pentland, and K. A. Heller. Graph-coupled [10] R. Durrett. Probability: theory and examples . Cambridge [11] A. Gruber, Y. Weiss, and M. Rosen-Zvi. Hidden topic [12] D. L. Knowles, K. G. Stanley, and N. D. Osgood. A [13] E. Kuhn and M. Lavielle. Coupling a stochastic [14] K. Lange. A gradient algorithm locally equivalent to the em [15] A. Madan, M. Cebrian, S. Moturu, K. Farrahi, and [16] J. Nocedal and S. Wright. Numerical optimization, series in [17] J. Paisley, C. Wang, D. M. Blei, and M. I. Jordan. Nested [18] R. Price. A useful theorem for nonlinear devices having [19] D. J. Rezende, S. Mohamed, and D. Wierstra. Stochastic [20] M. Salath X , M. Kazandjieva, J. W. Lee, P. Levis, M. W. [21] Y. W. Teh, M. I. Jordan, M. J. Beal, and D. M. Blei. [22] G. C. Wei and M. A. Tanner. A monte carlo implementation
