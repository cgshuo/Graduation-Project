
Multi-instance multi-label learning (M IML ) deals with the problem where each training example is associated with not only multiple instances but also multiple class labels. Previous M IML algorithms work by identifying its equiva-lence in degenerated versions of multi-instance multi-label learning. However, useful information encoded in training examples may get lost during the identification process. In this paper, a maximum margin method is proposed for M IML which directly exploits the connections between instances and labels. The learning task is formulated as a quadratic programming (QP) problem and implemented in its dual form. Applications to scene classification and text catego-rization show that the proposed approach achieves superior performance over existing M IML methods.
Multi-instance multi-label learning ( M IML ) is a newly proposed framework, where each example in the training set is associated with multiple instances as well as multiple labels [32, 33]. Many real-world problems involving am-biguous objects can be properly formalized under M IML . For instance, in image classification, an image generally contains several naturally-partitioned patches each can be represented as an instance, while such an image can corre-spond to multiple semantic classes simultaneously, such as clouds , grassland and lions ; In bioinformatics, an gene se-quence generally encodes a number of segments each can be expressed as an instance, while this sequence may be asso-ciated with several functional classes, such as metabolism , transcription and protein synthesis ; In text categorization, each document usually consists of several sections or para-graphs each can be regarded as an instance, while the docu-ment may be assigned to a set of predefined topics, such as sports , Beijing Olympics and even torch relay .

The traditional supervised learning , i.e. single-instance single-label learning ( S ISL ), can be viewed as a degener-ated version of M IML . In S ISL , each example is restricted to have only one instance and only one label. Existing ap-proaches solve M IML problem by identifying its equiva-lence in S ISL via problem reduction. Although this kind of identification strategy is feasible, the performance of the acquired algorithm may suffer from the loss of information incurred during the reduction process. Therefore, one open problem for M IML is that whether this learning framework can be tackled directly by exploiting connections between the instances and the labels of an M IML example [32]. In this paper, a novel algorithm named M 3 M IML , i.e. Maximum Margin Method for Multi-Instance Multi-Label learning, is proposed. Briefly, M 3 M IML assumes a linear model for each class, where the output on one class is set to be the maximum prediction of all the M IML example X  X  instances with respect to the corresponding linear model. Subsequently, the outputs on all possible classes are com-bined to define the margin of the M IML example over the classification system. Obviously, each instance is involved in determining the output on each possible class and the cor-relations between different classes are also addressed in the combination phase. Therefore, the connections between the instances and the labels of an M IML example are explicitly exploited by M 3 M IML .

The rest of this paper is organized as follows. Section 2 gives the formal definition of M IML and reviews the related works. Section 3 proposes the new M IML approach. Sec-tion 4 reports experimental results on two real-world M IML data sets. Finally, Section 5 concludes and indicates several issues for future work. Let X = R d denote the input space of instances and Y = { 1 , 2 , . . . , Q } the set of class labels. The task of M is to learn a function f M IML : 2 X  X  2 Y from a set of M IML training examples { ( X i , Y i ) | 1  X  i  X  N } , where X n i is the number of instances in X i and l i the number of labels in Y i . The M IML framework is closely related to the learning frameworks of multi-instance learning [10], multi-label learning [18, 21] and traditional supervised learning.
Multi-instance learning [10], or multi-instance single-label learning ( M ISL ), was coined by Dietterich et al. in their investigation of drug activity prediction problem. The task of M ISL is to learn a function f M ISL : 2 X  X  X  +1 ,  X  1 } from a set of M ISL training examples { ( X i , y i ) | 1  X  i  X  and y i  X  X  +1 ,  X  1 } is the binary label of X i . After the sem-inal work of Dietterich et al. [10], numerous M ISL learning algorithms have been proposed [2, 8, 16, 19, 25, 26, 29] and successfully applied to many applications especially in im-age categorization and retrieval [6, 7, 17, 30]. More works on M ISL can be found in [31].

Multi-label learning [18, 21], or single-instance multi-label learning ( S IML ), originated from the investigation of text categorization problems. The task of S IML is to learn a function f S IML : X  X  2 Y from a set of S IML training ex-amples { ( x i , Y i ) | 1  X  i  X  N } , where x i  X  X  is an instance with x i . A number of S IML learning algorithms have been proposed by exploiting the relationships between different labels [5, 12, 15, 28, 34]. S IML techniques have been suc-cessfully applied to applications including text and image categorization [3, 14, 18, 21, 24]. More works on S IML can be found in [23].

According to the above definitions, it is clear that tra-ditional supervised learning ( S ISL ) can be regarded as a degenerated version of either M ISL or S IML . Further-more, S ISL , M ISL and S IML are all degenerated versions of M IML . Therefore, an intuitive way of solving M problem is to identify its equivalence in S ISL , using either M
ISL or S IML as the bridge. Actually, while formalizing the M IML framework, Zhou and Zhang [32] adopted this strategy and proposed two M IML algorithms named M IML -B one using M ISL as the bridge. Specifically, M IML B OOST firstly transforms the original M IML task into an M ISL one by converting each M IML example ( X i , Y i ) into |Y| num-[ X i , y ] contains n i instances { ( x i 1 , y ) , . . . , ( x i by concatenating each of X i  X  X  instance with label y , while  X [ X i , y ] = +1 if y  X  Y i and  X  1 otherwise. After that, M
IML B OOST solves the derived M ISL problem by employ-ing a specific algorithm named M I B OOSTING [26]. This algorithm deals with M ISL problem by reducing it into an S
ISL one under the assumption that each instance in the bag contributes equally and independently to a bag X  X  label. In contrast to M IML B OOST , M IML S VM reduces the M IML problem into an S ISL one using S IML as the bridge. Firstly, M IML S VM transforms the original M IML task into an S IML one by converting each M IML example ( X i , Y i maps a bag of instances X i into a single instance z i using constructive clustering [32], where k -medoids clustering is performed on  X  = { X 1 , X 2 , . . . , X N } at the level of bags and components of z i correspond to the distances between X i and the medoids of the clustered groups. After that, M
IML S VM solves the derived S IML problem by employ-ing a specific algorithm named M L S VM [3]. This algorithm deals with S IML problem by decomposing it into multiple S
ISL problems (one per class), where instance x i associ-ated with label set Y i will be regarded as positive instance when building classifier for class y  X  Y i while regarded as negative instance when building classifier for class y /  X  Y
Obviously, the above approaches solve the M IML prob-lem by reformulating it into its degenerated versions, while useful information encoded between instances and labels may get lost during the reduction process. Next we will present the M 3 M IML algorithm which explicitly exploit the connections between instances and labels.
Given an M IML training example ( X i , Y i ) , let ~ Y note the category vector for X i whose l -th component ~ Y equals +1 if l  X  Y i and  X  1 otherwise. Suppose the classifi-cation system is composed of Q linear models { ( w l , b l Y} , each corresponding to a possible class label. Here, w l  X  R d is the weight vector for the l -th class and b l  X  R is the corresponding bias.
 on the l -th class is determined by the maximum prediction kind of strategy has been successfully employed to handle objects with multi-instance representations [1, 16]. There-fore, for an unseen bag X  X  X , its associated label set is determined via:
Based on the output, we define the margin of ( X i , Y i ) on the l -th class as: Here,  X  X  ,  X  X  calculates the dot product between two vectors and k  X  k denotes the vector norm. Then, the margin of ( X i , Y i ) with respect to the classification system is set to be the minimum margin of ( X i , Y i ) over all classes:
Consequently, the margin of the whole training set S = { ( X i , Y i ) | 1  X  i  X  N } (denoted as  X  S ) with respect to the classification system corresponds to: Suppose that all training examples in S can be perfectly classified by the classification system, we can normalize the parameters { ( w l , b l ) | l  X  Y} such that  X  i  X  { 1 , . . . , N } and l  X  X  , the following conditions are satisfied: Furthermore, for each l  X  Y , the equality will hold for at rewritten as follows: Note that maximizing min ing 1 2 max optimization problem can be formulated as: Problem 1 subject to :  X  i  X  X  1 , . . . , N } , l  X  X  such that Here Y i denotes the complementary set of Y i in Y . Note that the constraint ~ Y i ( l )  X  max in Eq.(5) has been expressed in cases of ~ Y i ( l ) = +1 and ~ Y ( l ) =  X  1 respectively. The above optimization problem is difficult to solve which involves the max(  X  ) function in both the objective function and constraints. To simplify the problem, note that: Therefore, Problem 1 can be approximated as: Problem 2
In order to deal with practical situations where training set can not be perfectly classified, slack variables are in-troduced for all constraints to accommodate classification error. This leads to the specific optimization problem con-sidered by M 3 M IML in its primal form: Problem 3 min Where S l = { i | 1  X  i  X  N, l  X  Y i } is the index set for those M IML examples associated with label l . Corre-spondingly, S l = { i | 1  X  i  X  N, l  X  Y i } is the index set for those M IML examples not associated with label l . W = [ w 1 , . . . , w Q ] is the matrix comprising all weight vectors while b = [ b 1 , . . . , b Q ] is the vector comprising all bias values. Similarly,  X  = {  X  il | 1  X  i  X  N, l  X  Y i } and  X  = {  X  ilj | 1  X  i  X  N, l  X  Y i , 1  X  j  X  n i } are the set of slack variables. In addition, constant C in the objective function trades off the classification system X  X  margin and its empirical loss on the training set. So far we have only assumed linear models to deal with M
IML learning task. Note that the primal form of M 3 M IML is a standard quadratic programming (QP) problem, which has convex objective function and linear constraints. There-fore, by solving Problem 3 in its dual form, nonlinearity can be incorporated into it via the well-known kernel trick . The Lagrangian of Problem 3 is: L ( W, b ,  X  ,  X  , A, B,  X  ,  X ) = 1 2  X   X  Here A = {  X  il | 1  X  i  X  N, l  X  Y i } , B = {  X  ilj | 1  X  i  X  N, l  X  Y i , 1  X  j  X  n i } ,  X  = {  X  il | 1  X  i  X  N, l  X  Y  X  = {  X  ilj | 1  X  i  X  N, l  X  Y i , 1  X  j  X  n i } are the set of nonnegative dual variables for different constraints.
To get the dual form of Problem 3, the derivatives of Lagrangian (8) with respect to the primal variables { W, b ,  X  ,  X  } are set to be zero. Consequently, setting  X  w l = 0 ( l  X  X  ) yields: Finally, setting  X  L  X  X  yields:
Substituting Eqs.(9) to (12) back into Lagrangian (8) gives rise to the Lagrangian dual form of Problem 3: Problem 4 subject to :  X  i  X  X  1 , . . . , N } , l  X  X  such that Here the dual objective function  X ( A, B,  X  ,  X ) is:  X ( A, B,  X  ,  X ) =  X  1 2 + In Problem 4, the first constraints (the inequalities) are in-herited from the nonnegative properties of dual variables to-gether with Eqs.(11) and (12), while the second constraints (the equalities) are inherited from Eq.(10).
 As same as Problem 3 (primal form), it is evident that Problem 4 (dual form) also falls into the category of QP problems. Note that the constraints in Problem 4 only bound dual variables with intervals and linear equalities , such kind of QP problem can be solved by an efficient iter-ative approach named the Franke and Wolfe X  X  method [13]. The fundamental idea of this method is to transform the difficult QP problem into a sequence of simpler linear pro-gramming (LP) problems. Due to page limit, the Franke and Wolfe X  method is not elaborated here while its detailed de-scription can be found in [12, 13]. To apply this method, the gradients of the dual objective function are indispensable:  X   X   X   X 
After solving Problem 4 with the Franke and Wolfe X  X  method, parameters of the classification system can be determined with the help of Karush-Kuhn-Tucker (KKT) conditions [9]. Concretely, the weight vectors w l ( l  X  Y ) are calculated using Eq.(9). One way to compute the bias values b l ( l  X  X  ) is as follows: b =  X  ( i, l ) = 1  X  Here ( i, l ) is an index pair with l  X  Y i and 0 &lt;  X  il
Resorting to Eqs.(1), (9) and (16), the label set Y for an unseen bag X is determined as:
Y = { l | max
X In addition, in case of Y being empty, the label with highest (least negative) output is then assigned to X . This is actu-ally the T -Criterion [3] used to treat learning problems with multi-label outputs.

To sum up, in training phase, parameters of M 3 M IML are learned by solving Problem 4 using the Franke and Wolfe X  X  method 1 . In testing phase, the label set of unseen M example is determined via Eq.(17). To have the non-linear version of M 3 M IML , it suffices to replace the dot products  X  X  ,  X  X  with some kernel function k (  X  ,  X  ) over X  X X .
In this section, the performance of M 3 M IML is eval-uated with applications to two real-world M IML learning tasks. The first task is scene classification which was stud-ied by Zhou and Zhang [32, 33] in their investigation of the M
IML framework. The scene classification data contains 2,000 natural scene images collected from the C OREL im-age collection and the Internet. All the possible class labels are desert , mountains , sea , sunset and trees and a set of la-bels is manually assigned to each image. Images belonging to more than one class comprise over 22% of the data set and the average number of labels per image is 1.24  X  0.44. Each image is represented as a bag of nine 15-dimensional instances using the S BN image bag generator [17], where each instance corresponds to an image patch.
 In addition to scene classification, we have also tested M 3 M IML on text categorization problems. Specifically, the widely studied Reuters-21578 collection [22] is used in ex-periment [33]. The seven most frequent categories are con-sidered. After removing documents whose label sets or main texts are empty, 8,866 documents are retained where only 3 . 37% of them are associated with more than one class labels. After randomly removing documents with only one label, a text categorization data set containing 2,000 doc-uments is obtained. Around 15% documents with multi-ple labels comprise the resultant data set and the average number of labels per document is 1.15  X  0.37. Each docu-ment is represented as a bag of instances using the sliding window techniques [2], where each instance corresponds to a text segment enclosed in one sliding window of size 50 (overlapped with 25 words).  X  X unction words X  on the S
MART stop-list [20] are removed from the vocabulary and the remaining words are stemmed. Instances in the bags adopt the  X  X ag-of-Words X  representation based on term fre-quency [11, 22]. Without loss of effectiveness, dimension-ality reduction is performed by retaining the top 2% words with highest document frequency [27]. Thereafter, each in-stance is represented as a 243-dimensional feature vector. Table 1 summarizes characteristics of both data sets. M
IML S VM , both of which are set to take the best pa-rameters as reported in [32]. Concretely, the number of boosting rounds for M IML B OOST is set to 25, and Gaussian kernel with  X  = 0 . 2 2 is used to implement M IML S VM For fair comparison, Gaussian kernel function is also used to yield the non-linear version of M 3 M IML . Note that although parameters of M IML B OOST and M IML S VM are carefully chosen, on the other hand, those of M 3 M IML are not specifically tuned in any way. In particular, the values of C (cost parameter as shown in Problem 4) and  X  are both set to the default value of 1. Actually, in preliminary experiments, M 3 M IML shows similar performance with  X  ranging from 0.6 to 1.4 by step 0.2.

Since M IML algorithms make multi-label predictions, the performance of each compared algorithm is evaluated according to five popular multi-label metrics, i.e. hamming loss , one-error , coverage , ranking loss and average preci-sion . As for average precision , the bigger the value the bet-ter the performance. While for the other four metrics, the smaller the value the better the performance. Due to page limit, details on these metrics can be found in [21, 28].
Next, we will make comparative studies among M IML algorithms with two series of experiments. The first series concerns how the algorithms perform under different num-ber of training examples. The other series investigates how the algorithms learn from data sets with varying percentage of examples associated with multiple labels.
To investigate the performance of each algorithm learned with different number of training examples, we create the training and test data as follows. For either of the scene or Reuters data, a test set is created by randomly choosing 1,000 examples from the original data set. The remaining 1,000 examples is then used to form the potential training set , where training set is formed by randomly picking up N examples from the potential training set. In this paper, N ranges from 200 to 800 with an interval of 100. For each value of N , ten different training sets are created by repeat-ing the pickup procedure. The average test performance of each algorithm trained on the ten training sets is reported.
Figure 1 illustrates the performance of each compared algorithm on the scene classification data in terms of the five multi-label evaluation metrics as well as the time spent in training. For each algorithm, when the training set size is fixed, the average and standard deviation out of ten in-dependent runs are depicted. Note that in Figure 1(e), we plot 1  X  average precision instead of average precision such that for all subfigures, the lower of one algorithm X  X  curve the better its performance. Furthermore, the training time (measured in seconds) shown in Figure 1(f) is plotted in log-linear scale. Accordingly, Figure 2 reports the experi-mental results on the Reuters categorization data.
It is evident from Figures 1 and 2 that, on both data sets, M 3 M IML consistently outperforms M IML B OOST and M
IML S VM in terms of each evaluation metric. As expected, the performance of each algorithm improves as the num-ber of training examples increases. It is interesting to see that, as more training examples become available, the per-formance gap between M 3 M IML and its compared counter-
Table 2. The win/tie/loss counts for M 3 M IML against M IML B OOST and M IML S VM with vary-ing training set size.

Evaluation M IML B OOST M IML S VM metric Scene Reuters Scene Reuters hamming loss 7/0/0 7/0/0 7/0/0 7/0/0 one-error 7/0/0 7/0/0 7/0/0 7/0/0 coverage 7/0/0 7/0/0 7/0/0 7/0/0 ranking loss 7/0/0 7/0/0 7/0/0 7/0/0 average precision 7/0/0 7/0/0 7/0/0 7/0/0 parts tends to increase on the scene data but decrease on the Reuters data (while still remarkably large). Furthermore, when more and more training examples are used in classifier induction, the performance of M IML S VM would gradually approaches that of M IML B OOST on both data sets.
Pairwise t -tests at 0.05 significance level are conducted to statistically measure the performance difference between the compared algorithms. The win/tie/loss counts based on pairwise t -test are reported in Table 2. For each metric, a win (or loss) is counted when M 3 M IML is significantly better (or worse) than the compared algorithm on a specific training set size out of 10 runs. Otherwise, a tie is recorded.
As shown in Table 2, it is rather impressive that in terms of each multi-label metric, M 3 M IML is statistically supe-rior to M IML B OOST and M IML S VM on both data sets un-der any number of training examples. As shown in Fig-ures 1(f) and 2(f), although M IML S VM runs greatly faster than both M 3 M IML and M IML B OOST , it has the worst per-formance among all the compared algorithms. In addition, M
IML B OOST usually consumes 2 to 4 times of training pe-riod than M 3 M IML in order to complete the learning pro-cedure. The above results reveal that, compared to other M IML algorithms, M 3 M IML is a better choice for solving M
IML problems with balanced effectiveness and efficiency.
It is interesting to study the influence of the percentage of multi-label data (or equivalently the average number of la-bels per example) on the algorithms, so we do another series of experiments. We derive seven data sets from the scene data which contains around 22% images with multiple la-bels. By randomly removing some single-label images, we obtain a data set where 30% (or 40% , 50% , 60% , 70% ) images belong to multiple classes simultaneously; by ran-domly removing some multi-label images, we obtain a data set where 10% (or 20% ) images belong to multiple classes the curve the better the performance. simultaneously. Note that the derived data set with high per-centage of multi-label images would have a relatively small size, since during its generation process more single-label images are removed from the original scene data. Simi-larly, we also derive seven data sets with P % percentage of multi-label documents from the Reuters data, here P % ranges from 10% to 70% with an interval of 10% .

Ten times of hold-out tests are performed on each de-domly divided into two parts with equal size. Algorithms are trained on one part and then evaluated on the other part. Figure 3 illustrates the performance of each compared algo-rithm on data sets derived from the scene classification task. For each algorithm, when the percentage of multi-label ex-amples is fixed, the average and standard deviation out of ten independent hold-out tests are depicted. The same as Subsection 4.2, we draw 1  X  average precision instead of average precision and plot the training time (measured in seconds) in log-linear scale. Accordingly, Figure 4 reports the experimental results on data sets derived from the text categorization task.
 It is evident from Figures 3 and 4 that, in most cases, M 3 M IML is superior to M IML B OOST and M IML S VM . Specifically, on data sets derived from scene classification task, M 3 M IML is indistinguishable from M IML B OOST and
Table 3. The win/tie/loss counts for M 3 M IML against M IML B OOST and M IML S VM with vary-ing percentage of multi-label examples.

Evaluation M IML B OOST M IML S VM metric Scene Reuters Scene Reuters hamming loss 5/1/1 7/0/0 7/0/0 7/0/0 one-error 6/1/0 7/0/0 7/0/0 7/0/0 coverage 3/4/0 7/0/0 7/0/0 7/0/0 ranking loss 3/4/0 7/0/0 7/0/0 7/0/0 average precision 4/3/0 7/0/0 7/0/0 7/0/0 slightly outperforms M IML S VM in terms of coverage . In terms of other evaluation metrics, M 3 M IML performs con-sistently better than M IML S VM , while the performance gap between M 3 M IML and M IML B OOST gradually ceases to-ward zero as the percentage of multi-label examples ap-proaches 70% ; On data sets derived from text categorization task, M 3 M IML achieves consistently superior performance over M IML B OOST and M IML S VM in terms of all evalua-tion metrics. In addition, as the fraction of multi-label ex-amples increases, the performance gap between M 3 M IML and its compared counterparts tends to steadily increase . curve the better the performance.

The same as Subsection 4.2, the win/tie/loss counts based on pairwise t -test are reported in Table 3. For each evaluation metric, a win (or loss) is counted when M 3 M IML is significantly better (or worse) than the compared algo-rithm on a specific percentage of multi-label examples out of 10 hold-out runs. Otherwise, a tie is recorded.
As shown in Table 3, it is quite impressive that in terms of each multi-label metric, M 3 M IML statistically outper-forms M IML S VM on both scene and text learning tasks. M 3 M IML also performs statistically better than M IML B
OOST on the text categorization task. On the scene clas-sification task, our approach is inferior to M IML B OOST terms of hamming loss in only one case, while it is superior or at least comparable to M IML B OOST on the other metrics. The series of experiments reported in this subsection further confirm the superiority of our proposed approach.
In this paper, a novel M IML approach named M 3 M IML is proposed. This method directly considers the connec-tions between the instances and the labels of an M IML ex-ample through defining a specific margin on it. The corre-sponding maximum margin learning task is formulated as a QP problem and solved in its dual form with kernel imple-mentation. Comparative studies with existing M IML algo-rithms are carried out with applications to scene classifica-tion and text categorization. Experimental results show that M 3 M IML achieves significantly better performance than existing methods together with a good balance between ef-fectiveness and efficiency.

Designing other kinds of M IML algorithms and perform comparative studies on more and larger M IML data sets are important issues for future work.

This work was supported by NSFC (60635030, 60721002), 863 Program (2007AA01Z169), JiangsuSF (BK2008018), and Startup Foundation for Excellent New Faculties of Hohai University.

