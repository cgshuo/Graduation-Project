 Given the potential ethical and security risks as-sociated with deceitful interactions, it is important to build computational tools able not only to detect deceivers but also to provide insights into the na-ture of deceptive behaviors. In particular, informa-tion related to the demographics of the deceivers could be potentially useful, as recent studies have shown that online users lie frequently about their appearance, gender, age or even education level.
There are multiple scenarios where it would be desirable to identify deceivers X  demographics; for instance, identifying the age and gender of SMS senders or Twitter users might help improve parental controls, spam filtering, and user X  X  secu-rity and privacy.

In this paper, we present a study on deception detection in an open domain, and also present an analysis of deceptive behavior in association with gender and age. Unlike previous studies, where domain-specific conversational transcripts and re-views have been used, this research targets the identification of deceit in short texts where domain and context are not available. We aim to build deception, age, and gender classifiers using short texts, and also explore the prediction of gender and age in deceptive content. Moreover, we present an analysis of the topics discussed by deceivers given their age and gender based on the assumption that, when lying in an open domain setting, deceivers will show natural bias towards specific topics re-lated to gender and age. To date, several studies have explored the iden-tification of deceptive content in a variety of do-mains, including online dating, forums, social net-works, and consumer reviews. (Toma and Han-cock, 2010) conducted linguistic analyses in on-line dating profiles and identified correlations be-tween deceptive profiles and self references, nega-tions, and lower levels of words usage. A study for deception detection on essays and product re-views is presented in (Feng et al., 2012). (Ott et al., 2011) addressed the identification of spam in consumer reviews and also studied the human capability of detecting deceptive reviews, which was found not better than chance. In a follow-ing study, (Ott et al., 2013) presented an analy-sis of the sentiment associated to deceitful reviews focusing particularly in those containing negative sentiment as it largely affects consumer purchase decisions. More recently (Yu et al., 2015) pre-sented a study where authors analyze the role of deception in online networks by detecting decep-tive groups in a social elimination-game.

This previous work has shown the effectiveness of features derived from text analysis, which fre-quently includes basic linguistic representations such as n-grams and sentence counts statistics (Mihalcea and Strapparava, 2009; Ott et al., 2011) and also more complex linguistic features derived from syntactic context free grammar trees and part of speech tags (Feng et al., 2012; Xu and Zhao, 2012). Other studies have focused on deception clues inspired from psychological studies. For instance, following the hypothesis that deceivers might create less complex sentences (DePaulo et al., 2003), researchers have incorporated syntactic complexity measures into the analysis. (Yancheva and Rudzicz, 2013) presented a study based on the analysis of syntactic units and found that syntac-tic complexity correlates with deceiver X  X  age. Psy-cholinguistics lexicons, such as Linguistic Inquiry and Word Count (LIWC) (Pennebaker and Fran-cis, 1999), have also been used to build deception models using machine learning approaches (Mi-halcea and Strapparava, 2009; Almela et al., 2012) and showed that the use of semantic information is helpful for the automatic identification of deceit.
While there is a significant body of work on computational deception detection, except for (Yancheva and Rudzicz, 2013) who considered the relation between syntactic constructs and de-ceivers X  age, to our knowledge there are no com-putational analyses of demographics in deceptive content. However, there have been a number of psychological studies on the role of gender and age in deceptive behavior. These studies have found interesting associations between deception and gender. For instance, (Toma et al., 2008) iden-tified differences in self-presentation among gen-ders. In this study men were found to lie more about their height and women lied more about their weight. (Kaina et al., 2011) found that fe-males are more easily detectable when lying than their male counterparts. (Tilley et al., 2005) re-ported that females are more successful in decep-tion detection than male receivers. We started our study by collecting a new open do-main deception dataset consisting of freely con-tributed truths and lies. We used Amazon Me-chanical Turk and asked each worker to contribute seven lies and seven truths, on topics of their own choice, each of them consisting of one single sen-tence. In an attempt to obtain truths and lies that represent everyday lying behavior, we asked our contributors to provide plausible lies and avoid non-commonsensical statements such as  X  X  can fly. X  Since we did not enforce a particular topic, resulting truths and lies are open domain. Sample truths and lies are presented in Table 1. Note that the collected lies might include statements that are somehow unrealistic, even if plausible, e.g.,  X  X  own two Ferraris, one red and one black X . We decided to also include these statements in order to aid the identification of differences in deceivers and true-tellers language, as we hypothesize that they might help reveal topics that naturally occur in truths and lies.

Additionally, we collect demographic data from the contributors, including their gender, age, coun-try of origin, and education level. To avoid spam, contributions were manually verified by one of the paper authors. The final dataset consists of 7168 sentences from 512 unique contributors. Since each contributor provided seven lies and seven truths the dataset contains a total of 3584 truths and 3584 lies respectively. Participant X  X  ages range from 18 to 72 years, with an average age of 34.14 and a standard deviation of 12.67. In this section, we describe the sets of features ex-tracted, which will then be used to build our clas-sifiers.
 Unigrams We extract unigrams derived from the Shallow and deep syntax features These fea-Lie Truth
I won 1 billion dollars in the Illinois state lottery last year and gave it all away to my mother.
My daughter is my best friend in the whole wide world, and i would give my life for hers.

On my last birthday i turned 119 years old and went sky diving as a gift to myself.

I graduated with a degree in information systems 10 years ago and still can X  X  find a good job. I X  X  allergic to alcohol Giraffes are taller than zebras. Lie Truth
Barak obama was my guest last night; he offered me the administrative assistant job at white house in Washington.

Internet is one of the greatest invention of his-tory of humankind with its ability to speed up the communication.
 Semantic features These features include the 80 Readability and Syntactic Complexity features Our first experiment seeks to evaluate whether de-ception detection can be conducted using the open domain deception dataset described above. We performed the evaluations at user level, by collaps-ing all the lies from one user into one instance, and all the truths into another instance.

We build deception classifiers using the SVM performed a five-fold cross-validation, by training each time on 80% of the users and testing on the remaining 20%. During our evaluations truths and lies pertaining to a particular user were either on the training or testing set. Classification results on individual and combined sets of features are pre-sented in Table 3. The best performing set of fea-Figure 1: Learning curves for deception detection using five feature sets tures are the POS tags, followed by features de-rived from production rules. The remaining sets of features achieved accuracy values ranging from 54% to 65%, which still represent a noticeable im-provement over the random baseline. Note that we experimented with a few more feature sets combi-nations, including the use of all the features to-gether, however we did not observe significant im-provements.

To analyze the impact of the amount of data on the classifier learning process, we plot the learn-ing curves on the different sets of features using incremental amounts of data as shown in Figure 1. Evaluations were conducted using five-fold cross validations on each incremental fraction of data. The learning trend suggests that most classifiers benefit from increasing amounts of training data. Gender Age Table 2: Class distribution for gender and age Feature set Deception Gender Age Baseline 50.00% 58.00% 62.00% Unigrams 60.89% 54.25% 51.12% Semantic 60.21% 57.28% 61.83% POS 69.50% 49.95% 52.39% CFG 65.39% 52.19% 54.74% Readability 54.44% 58.16% 62.26% Uni+Semantic 62.17% 63.04% 51.51% Table 3: SVM classifiers trained for three predic-tion tasks: deception, gender, and age.
 However, except for the POS features, the overall performance seems to stabilize when using 90% of the training data.

As a second experiment, we evaluate the abil-ity of the classifier to predict gender and age in short open domain deceptive texts. Given the con-tributors X  age distribution, which lies mainly in the range of 30-45 years, we opted to cluster the par-ticipants age into into two groups: young (  X  35 years) and middle-aged/elder ( &gt; 35 years). Class distributions for age and gender are shown in Ta-ble 2. We performed the age prediction task on the two groups using the different sets of features and SVM classifiers. Classification accuracies are shown in Table 3. Reported baselines consist of a majority class baseline. Results show low to moderate improvement over the baseline for gen-der classification, with the combination of seman-tic features and unigrams being the best perform-ing feature set. However, our classifiers performed poorly in the age prediction task, with accuracies below the majority class baseline.

Overall, the results suggest that age and gender prediction are challenging tasks when conducted in open domain deception data. One possible ex-planation for this is that the lack of context intro-duces noise into the analysis. For instance, the fol-lowing sentence:  X  X  X  X  50 years old X  can belong to either a male or a female, and it might be a lie for younger people or a truth for older people. Table 4: Results from LIWC word class analysis for short open domain truths and lies. In order to explore language differences among deceivers and true-tellers, we use the linguis-tic ethnography method (Mihalcea and Pulman, 2009) and obtain the most dominant semantic word classes in the LIWC lexicon associated to truth and lies provided by males and females. Re-sults are shown in Table 4. From this table, we observe interesting patterns in word usage that are shared among genders. For instance, spon-taneous lies often include negation , certain , and you words, which is in line with previous work on domain-specific deception (Mihalcea and Strappa-rava, 2009) that suggested that liars try to rein-force their lies through the use of stronger word-ing and detachment from the self. On the other hand, people appear to be less likely to lie when talking about their family , religion , and describing positive experiences. There are also LIWC classes associated to a specific gender. Male lies contain references to friends and others, while female lies contain references to money and future. Similarly, female true-tellers use metaphor words while male true-tellers use words related to sports and music. Table 5: Results from LIWC word class analysis for short open domain truths and lies.

We also evaluate differences in word usage that might be attributed to deceiver X  X  age. Resulting dominant classes and their scores are presented in Table 5. The analyses show interesting differences for deceiver X  X  word usage across age. For instance, regardless of their gender, older deceivers use ref-erences to anxiety , money , and motion . On the other hand, younger deceivers language includes anger , negate , and death words. These differences suggest that indeed gender and age play a role on people words choices while fabricating lies. In this paper, we presented our initial experiments in open domain deception detection. We target-ted the deception detection on short text to address the cases where context is not available. In real settings, this can be useful when receiving a text message or when looking at anonymous posts in forums. We collected a new deception dataset con-sisting of one-sentence truths and lies, along with the demographics of the deceivers. Through sev-eral experiments, we showed that this data can be used to build deception classifiers for short open domain text. However, the classifiers do not per-form very well while trying to predict gender and age. We further explored linguistic differences in deceptive content that relate to deceivers gen-der and age and found evidence that both age and gender play an important role on people X  X  word choices when fabricating lies.

The dataset introduced in this paper is publicly available from http://lit.eecs.umich.edu.
 This material is based in part upon work sup-ported by National Science Foundation awards #1344257 and #1355633, by grant #48503 from the John Templeton Foundation, and by DARPA-BAA-12-47 DEFT grant #12475008. Any opin-ions, findings, and conclusions or recommenda-tions expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation, the John Tem-pleton Foundation, or the Defense Advanced Re-search Projects Agency.

