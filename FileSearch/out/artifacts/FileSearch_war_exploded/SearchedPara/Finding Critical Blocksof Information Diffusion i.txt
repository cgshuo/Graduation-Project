 The Web media, which generates and propagates huge amounts of information, is generally admitted as the fourth media after newspapers, broadcasting and TVs. The widely used web applications, especially the online social networks, such as micro-blog (e.g. Twitter) and SNS (e.g. Facebook), have many benefits to serve as a medium for fast, widespread information diffusion platforms. These platforms provide faster access than tra ditional mass media, including almost every aspects of events, vary from national policy to stars X  privacy. But among all the information, there are many misinformation [6]. So it is desired if such diffusion of misinformation can be prevented at a small cost.

But unfortunately, the process of the diffusion is very complicated. And it is impossible to tell whom to be controlled directly. We focus on the study of the information diffusion over online social networks, we call them diffusion networks. In this work, we treat the problem of controlling the diffusion as to find the critical blocks of diffusion network. The critical blocks are sets of nodes in the network, and they play an important role in network structure, as illustrated in Fig 1(a). At first glance, node e has the largest degree, so it is a critical node in the network, if we remove node e (and its attached edges), it will dramatically change the network structure. We call such nodes with large degree is trivial critical nodes, for it is easy to find and we consider such nodes compose trivial critical blocks . It is should be noticed that node d is another critical node, since it is a bridge connecting the left part (left to dotted line 1) and the right part (right to dotted line 2), if we remove the node d , the network will be divided into two parts, and the network structure will also have a great change. Although node d only has a small degree, it is a critical node of the network. Removing node d can make the diffusion be confined in left part (or right part), for example, node a , b , c may form a community, node e , f , g , h , i , j may form another community, and node d may join both communities, if there is no node d , the information in left community will not flow to the right community, and vice versa. We call node d composes a non-trivial critical block , in this paper, we mainly focus on non-trivial critical blocks.

It should be mentioned the critical blocks in network is similar to structural holes [7] a little, which refer to the absence of ties between two parts of a network. The concept of structural hole is develop ed by sociologist Ronald Burt. And some following works [2, 5, 14] focus on how to use the structural holes to enhance ones competitiveness through person to person interaction. To the best of our knowledge, none of the existing work formally addressed the problem of finding the critical blocks to limit the diffusion at a small cost.

In this paper, we present an algorithm called FCB (Finding Critical Blocks) to find critical blocks of the network effectively. We consider if we can affect these blocks, we can interrupt the diffusion with smaller cost. But it can be seen, as the number of nodes in network increases, the structure of the network will become very complex too, so an effectiv e and efficient algorithm is needed. For simplicity, we assume that the network structure stays stable and does not change over time. We implement our algorithm based on the spectral graph theory [21] with following steps: first we build a Laplacian matrix based on the structure of the network; then we compute its eigenvectors corresponding with some smallest eigenvalues, and we show the relationship between the critical blocks and these eigenvectors, thus we can efficiently locate the critical blocks under the help of these eigenvectors. Since computing the eigenvalues and eigenvectors is a mature technology, we can easily solve them and we develop some heuristic algorithms basedonthem.

The rest of this paper is organized as follo ws. Section 2 introduces some related works. Section 3 gives the preliminaries. In Section 4 we formulate this problem and prove its NP-completeness and give our solution of finding critical blocks in details. In Section 5, our experimental results are reported. We make a conclusion and point out some future resea rch directions in Section 6. The online social network analysis has attracted many researchers [1, 6, 9, 11, 15]. Among all the research directions, the research about information diffusing and tracking has received significant atte ntion [6, 9, 11, 15]. In their studies, P. Pinto et al. [8] tried to locate the source of diffusion in network, J. Leskovec et al. [15] tried to track the memes of the web media. M. G. Rodriguez et al. [11] tried to infer the networks of diffusion and influence, they proved it is a NP-hard problem and gave a greedy algorithm called NetInf to solve it.

There is also a research area related to our work called social influence analy-sis, it has various real word applications, for example, influence maximization in viral marketing [12]. How to identify the influential users has received significant attention. Early works focused on heuristics using node degree and distance cen-trality [16]. The works in [15] improved the heuristics to detect influential nodes and gave solutions to such problem, they showed that this problem has a sub-modularity property and give their solution. Budak et al. [6] tried to limit the spread of misinformation using some heuristic greedy algorithms.

Our method is based on the Laplacian matrix theory of network graph, which is also called spectral graph theory. There are extensively research about this theory [21]. Laplacian matrix and its variations are useful tools in clustering [18] and graph partition [17, 19]. [21] gave detailed descriptions about the theory and applications. [9] is Fielder X  X  work, which showed that the second smallest eigenvalue of Laplacian matrix can represent the algebraic connectivity and gave some properties. [18] gave detailed implementations of the spectral clustering, both showed good performance on clustering. The works in [17] and [19] both used Laplacian matrix theory to partitioned a network. A social network can usually be modeled as an undirected graph G=(N,E) , where N represents the nodes, and E represents the edges connecting N . n u  X  N and n v  X  N are said to be neighbors if there is an edge e u,v connecting them, noted as E(u,v) = 1 . In the context of social network, N can be treated as users and E can be treated as relationship be tween them, such as friendship, or colleague relationship.
 Given a subset S  X  N of a graph, we denote its complement N S as S . Generally, if there exist k nonempty connected sets S 1 ,S 2 ,  X  X  X  ,S k ,theycompose a partition of the graph G if S i The Laplacian matrix L is defined as: where A is the adjacency matrix of the graph and D is its diagonal matrix. L has many properties, the reader can refer [3 ], here we list some helpful properties to better understand our algorithm.
 Proposition 1. L is symmetric and positive semi-definite. And for any vector x, Proposition 2. There exists at least one 0 eigenvalue of L and its corresponding eigenvector is the constant vector 1 =(1 , 1 ,  X  X  X  , 1) T .
 Proposition 3. L has n non-negative, real-valued eigenvalues 0=  X  1  X   X  2  X   X  X  X  X   X  Proposition 4. The multiplicity of 0 as an eigenvalue of L is equal to the num-ber of disconnected components of G. In this section, firstly we will describe our problem formally, then we propose our algorithm to solve the problem of finding critical blocks effectively and efficiently. 4.1 Problem Formulation While there has been a substantial amount of work in the field of influence max-imization, how to restrict the misinfor mation diffusion has not received much attention. We regard this problem as to find the critical blocks in the diffusion network, critical blocks can be seen as some subgraphs which contain  X  X nfluen-tial X  nodes. Here we give a descriptive definition of a critical block. Critical block . Critical block is a set of nodes, and these nodes can partition the whole graph evenly at a small cost.

Considering this problem carefully, we can see such critical blocks should fit three conditions: the first condition is critical blocks should partition the whole network into several disconnected components, such that the information cannot diffuse from one part to another; the second one is that any critical block itself should be small enough, that means we can influence diffusion without affect too much nodes; the third one is the partition caused by critical blocks should be  X  X alanced X , which means none of thes e disconnected components should be too small nor too big, see Fig 2. We can see if we choose node i to compose a critical block and cut the rightmost edge, we can partition the whole network into two parts and the cost is small, but the influence to the whole network is small too. So the rightmost node i is a  X  X ad X  critical block, instead, node e composes a  X  X ood X  critical block for it s atisfies the above three conditions. It should be noticed that it does not mea n  X  X alanced X  parts have equal size.
How to evaluate a critical block  X  X ood X  or  X  X ad X ? There may not exist a ground truth to measure the results, but at first sight, a critical block partitions the whole graph into two subsets S and S under the constraints that the critical block size (denoted as CBS ( S, S )) itself should be small, then the problem to find the critical block is to find a partition which minimizes the CBS ( S, S ). But as illustrated in Fig 2, if we only want to find a partition which minimizes CBS ( S, S ), it may soon sink into the problem that a critical block separates one individual node from the rest of the graph. What we want is to partition the graph evenly, so either part should be  X  X arge enough X  to balance the separation. Inspired by the RationCut [17] and Ncut [19], we give a criterion to measure the results as: Unfortunately, finding such critical blocks is NP-Complete.
 Theorem 1. Finding a critical block defined in equation (1) is NP-complete. Proof. To prove the NP-completeness, we have to prove two things, first we have to prove this problem belongs to NP class, then we have to prove it via reduction from a known NP-complete problem. It is obvious that this problem  X  NP, since a nondeterministic algorithm needs only t o test a found critical block satisfying the constrains in polynomial time. Now we show that this theorem can be proved via reduction from a known NP-complete problem of Partition problem. Given an instance of Partition problem: find a partition into two subsets S 1 ,S 2 such that max ( sum ( S 1 ) ,sum ( S 2 ))is minimized. Given a graph, if we can partition it into two parts P1, P2 evenly, we can assign a node i in P 1 corresponding to an element in S 1 , and assign a node j in P 2 corresponding to an element in S 2 ,so if the finding critical block can be solved efficiently, then the Partition problem must be solvable. Also we can see the assignment can be done in polynomial time, so finding critical block is a NP-complete problem.
 Since finding critical blocks is a NP-complete problem, it is infeasible to get an exact solution, and we develop an eff ective way to find them approximately.
In this paper, we find all critical blocks hierarchically, we first find a critical block which partition the whole network into two parts, then we find other critical blocks of the two partitioned parts, we repeatedly do it until we reach a certain threshold. 4.2 Effective Solution Our goal is to solve the optimization prob lem of finding critical blocks, see equa-tion (1). To solve this problem, we use a hierarchy way and first we try to find the nodes which cut the whole graph into two parts. We first introduce an entry vector v =( v 1 ,v 2 ,  X  X  X  ,v n ) T , the element v i in v is defined as [21]: The vector v has two important properties:  X  The first property is that the inner product of v and 1 is zero, we can get  X  The second property is th at the Euclidean norm of v satisfies % v % = In the equation (5), ( N ) stands for number of nodes, for a given network, it is a constant number. So solving equation (1) can be equivalently to minimize v
Lv . Our goal can be equivalently rewritten as: Algorithm 1. Finding Critical Blocks Recall a fact about the Rayleigh quotient [10]: Let M be a real symmetric ma-trix. Under the constraint that x is orthogonal to the i-1 smallest eigenvectors x ,x 2 ,  X  X  X  ,x i  X  1 , the Rayleigh quotient x T Mx x T x is minimized by the next smallest eigenvector x i and its minimum value is the corresponding eigenvalue  X  i .
For a given Laplacian Matrix L, the smallest eigenvalue  X  1 is 0 and its corre-sponding eigenvector is 1 from Proposition 2. From the above equation we can see that vector v is orthogonal to the const vector 1 . So the second smallest eigenvector corresponding to  X  2 of L gives a solution that we are looking for. In fact, the second smallest eigenvector is also called Fiedler Vector, due to the pioneer work by M. Fiedler. After computin g the second smallest eigenvector, we can get our critical blocks using a heuristic algorithm, the nodes which partition the graph usually lie in the middle of the sorted Fiedler Vector, see Fig 1(b).
In Fig 1(b), we mark the Fiedler Vector value for each node of the network in Fig 1(a). The nodes left to the green node have negative value, while nodes right to the green node have positive value, and the green node itself composes a critical block, which divide the whole graph into two parts. Notice that green node has a relatively small Fiedler Vector value(in magnitude) compared with other nodes.

A similar process can go on using the third smallest eigenvector to give op-timal partition for the first two divided parts. In fact, we can compute all the eigenvalues and the corresponding eigenvectors, each time partition the former divided parts using the next smallest eigenvector. However, since we use an iter-ative algorithm to compute eigenvalues and eigenvectors, the accumulate errors is large, and the results may become not so accurate. To avoid the unreliable phenomenon, we can restart the next computing individually.
 Our algorithm FCB (Finding Critical Blocks) is summarized in Algorithm 1. Line 1 and line 2 in Algorithm 1 can be executed at the same time, we filter out the trivial critical block nodes at the time we set up Laplacian matrix. After the filtration, the graph may become unconnected, but from Proposition 4, we know we get a  X  X ature partition X , and it does not affect the last result. In line 4, we proposed three heuristic algorithms to get critical blocks. a). finding the nodes corresponding to the median values of eigenvector, usually these nodes compose the critical block; b). using signs of the values of eigenvector to partition the network, and the nodes in the cut set compose the critical block; c). sorting the values of eigenvector, whereby a  X  X arge X  gap in the sorted vector can give a partition for the network.
 The Complexity Analysis. The most expensive part of our algorithm is to compute some smallest eigenvectors , solving the eigensystem has a complexity of O( n 3 ), where n is the number of nodes in a graph. As n increases, it will be slow to solve the eigensystem, but our algorithm has the following properties: 1. The graph we faced is sparse. It has been verified that network connection 2. We do not need to compute all the eigen values and eigenvectors, there are 3. We use an iterative algorithm, and we don X  X  need a high precision result, the Solving the eigensystem is a well studied problem, and lots of algorithms have been proposed, such as Trace Minimization algorithm and Lanczos method. Lanczos method is acknowledged as an excellent way to solve eigensystem of large scale sparse matrix, especially for the some largest and smallest eigenvec-tors. If matrix A is sparse, and A  X  x can be computed in k  X  ntimes(k n), Lanczos method can guarantee all the e igenvalues can be computed in O (mn) times, and be stored in O(m) storage space, where m depends on many factors, since our matrices are very sparse, A  X  x can be computed in k  X  n time, k n. So the complexity of our algorithm is O(mn).
 The Limitations of Algorithm 1. Algorithm 1 is not effective for all types of graph, e.g. clique (complete graph) or k-clique. Because for a clique(or k-clique), all the nodes have the same structure, so the values of Fiedler Vector are all equal. But as illustrated in [4, 11, 23], social networks show community structures, and our algorithm can work well for such type graphs. We evaluate the performance of our algorithm both on synthetic data and real word datasets, Twitter. The experiments are performed on IBM X3500 with double Xeon Quad core CPU, the memory is 16 GB, and the OS we used is 64 bit CentOS. Our program is written in R language, and the package for computing eigenvectors is ARPACK 1 , Fig 3 is plotted using pajek 2 . 5.1 Experiments on Synthetic Data The goal of our experiments on synthetic data is to testify the effectiveness, we visualize the graph for small size graph, for it is not so easy to observe critical blocks for large scale graph intuitivel y. We proceed as follows: first, we generate some types of networks varying from around 800 to 1,000 nodes; then, we run our algorithm for these networks; we plot the results using pajek at last. Data. We generate two types of networks. The first type is a balanced network, the degree distribution of the network obeys power law distribution. Since social networks have a close-knit form, the network we generated mainly form two parts, that is, there are two  X  X ight X  parts and a small number of nodes connect them, and these connecting nodes comp ose the critical block. The size of two parts are almost equal, they are balanced. See Fig 3(a).

The second type networks we generate are highly skewed. There are two  X  X ight X  parts but one part has much more nodes than the other. See Fig 3(b). Results. We run our algorithm and mark each node as follows: the nodes in critical block is marked with green color, and for the two partitioned parts, we mark them with red and yellow colors separately, for clarity, we do not label the value of Fiedler Vector value for each node in the figure. The experiment results show that the nodes in the critical block found by our algorithm is exactly the connecting nodes we generated, that is, our algorithm is very effective. The experimental results are illustrated in Fig 3.

In Fig 3(a), the data we generated form two parts, one part has 450 nodes, the other has 400 nodes and less than 20 nodes connect them, the two parts are about balanced. In Fig 3(b), the network is highly skewed, which also has two parts, the first part has 900 nodes, and the second part has 100 nodes, less than 20 nodes connect them. We can see that our algorithm is effective for not only balanced network but also for skewed network. For skewed network, our algorithm do not partition the two parts with equal size but in a more reasonable way. 5.2 Experiments on Real World Datasets We also run our algorithm on real word datasets, Twitter. The data we used is anonymous and there is no privacy problem. The experiments on real world data are mainly to testify the scalability of our algorithm.
 Dataset Description. Twitter is a famous micro-blog website, and it is re-ported that the registered users are almost 500 million, and the number is in-creasing every day. The da ta we downloaded contains only a small part of the whole network 3 . We sample the social networks with about 100,000, 200,000, 500,000, 1,000,000 nodes separately. For every network, we filter out trivial nodes (we filter out the from top 0.1  X  to top 0.2  X  trivial nodes, which take away many edges).
 Some Measurements. Since there is no objective ground truth to measure the results we the found, here we use three measurements. clustering coefficient [20, 22]. Also called transitivity . Clustering coefficient is a measurement of degree to which nodes in a graph tend to cluster together. Evidence suggests that in social networks, nodes tend to create tightly knit groups characterized by a relatively high density of ties [23]. And there are two types of clustering coefficient, glob al clustering coefficient GCC and local clustering coefficient LCC. The GCC is defined as [22]: Where a triplet consists of three node s that are connected by either two (open triplet) or three (closed triplet) undirected ties.
 The local clustering coefficient LCCi for a node i is defined as [20]: The local clustering coefficient of a node in a graph quantifies how close its neighbors are to being a clique (complete graph).
 Based on LCC, we also define average LCC for (called ACC) as: diameter . The diameter of a graph is the length of the longest geodesic. number of nodes in critical blocks . Denoted as # in CB.

We run our algorithm on the four datasets only for the first partition, that is, every network is divided into two parts. The Laplacian matrix is stored us-ing sparse matrix format. We record the parameters of # in CB, GCC, ACC, diameter for the original network and for the divided two parts. The results are shown in Table 1. Results and Analysis. In Table 1, the GCC column and ACC column and di-ameter column are split into two columns,  X  X efore X  column and  X  X fter X  column, respectively. Because our algorithm partition the network into two parts, the  X  X efore X  column record the p arameters for the original network, and the  X  X fter X  column record the parameters for the t wo divided parts. In Table 1, we can see that the number of nodes in critical blocks is relatively small, that means we don X  X  need affect too many nodes to limit the diffusion over the network. We divide the whole network into two parts, and the GCC and ACC of  X  X efore X  column represent the origin al network, and in the  X  X fter X  column they represent the parameters for two divided parts separately. GCCs are small numbers (in 10  X  4 ), for social network is sparse, and filtering out trivial nodes make the net-work more sparse, and GCC calculates number of closed triplets over number of connected triplets of nodes, for sparse n etwork, it is usually small. We can see both GCC and ACC are improved, that means we divide the network with the  X  X eakest X  connected nodes and edges. The diameters show that we have divided the network into two parts, and they are balanced. It should be mentioned that since we have filtered out trivial nodes, our diameters are larger than six, but it does not mean that our social networks disobey  X  X ix degree of separation X . In this paper, we have investigated the problem of finding critical blocks to limit the diffusion over social networks. We solve such problem as to find critical blocks, then we proved that such a problem is NP-complete and proposed an effective and efficient solution based on spectral theory and analyzed its com-plexity. The experimental results both on synthetic data and real world datasets showed that there did exist critical blo cks connecting different components and our algorithm could find them effectively.

In the future work, we will study on the dynamic social networks. Since the network structure changes all over the time, what we are facing is an evolutionary graph. Another direction we will study is how to implement our algorithm on weighted and directed graph, and how to quantify the weight of two nodes is still a big challenge facing us. Acknowledgments. This research was supported by the NSFC (Grant No. 61025007, 60933001 and 61100024),National Basic Research Program of China (973, Grant No. 2011CB302200-G)and MOE-Intel Special Fund of Information Technology (MOE-INTEL-2012-06).

