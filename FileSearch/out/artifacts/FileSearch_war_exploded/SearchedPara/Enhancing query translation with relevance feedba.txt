 1. Introduction
With vast amount of multilingual information on the Web, it is natural for users to issue queries in one language, and access documents in another language. This so called Cross-Language Information Retrieval (CLIR) often utilize translation to cross the language barriers between a query and the documents ( Oard &amp; Diekema, 1998 ). Due to the simplicity and flex-ibility of translating queries, query translation based CLIR (QT-CLIR) has been the most dominate form of CLIR in the liter-ature. However, the problems of not knowing which translation alternatives are appropriate for the current query (called translation ambiguities) are much more pervasive in query translation. Researchers have developed various methods to han-dle translation ambiguities. These include methods for reducing the impact of translation ambiguities such as the structured Croft, 1998; Liu, Jin, &amp; Chai, 2005 ) and parallel corpus ( Xu, Fraser, &amp; Weischedel, 2001 ).

One focus of this paper is on query translation and translation disambiguation. However, first, we want to discuss the translations inside QT-CLIR. As discussed in iCLEF experiments (such as in ( Oard &amp; Gonzalo, 2001 )), and as demonstrated by Google X  X  cross-language search engine inside Google Translate back so that the user can perform relevance judgment or document usage. This setting is different to that in common informa-tion retrieval evaluation frameworks like Text REtrieval Conference (TREC), Cross-Language Evaluation Forum (CLEF) and NTCIR because those frameworks only concentrate on examining the returned ranked lists of documents without worrying about whether those documents are understandable by users. Such narrow view of CLIR is reasonable for testing retrieval algorithms,
Therefore, there are two translation processes in TLIR  X  one is for translating queries, and the other is for translating re-turned documents. The translations of returned documents can be the outputs from machine translations (MT) ( He et al., 2003 ), from noun phrase based translations ( L X pez-Ostenero, Gonzalo, Penas, &amp; Verdejo, 2001 ), or from word-by-word gloss translations ( Wang &amp; Oard, 2001 ). Since most TLIR systems rely on an existing MT system to provide the translation of re-turned documents, the translation resources used in the two translation processes are often different. Therefore, there is an advantage for certain translation information to be exchanged between the two translation processes.

Another focus of this paper is on relevance feedback in TLIR. To improve CLIR effectiveness, researchers borrow tested techniques from monolingual IR. One example is query expansion (QE) based on relevance feedback (RF). In CLIR and thus
TLIR, there are pre-translation QE that performs before translating the query with the help of an extra document collection at the query language side, post-translation QE that performs after the query is translated, and the combination of pre-trans-lation and post-translation QE.

Although query expansion has shown to be effective for improving CLIR performance ( McNamee &amp; Mayfield, 2002 ), it is not the only possible method for using RF information in multilingual setting, especially in TLIR. We believe that users X  feed-back on relevant documents in TLIR can be viewed as the confirmation of the translation relationships expressed by the terms in the original returned relevant documents and their translations in the translated documents. Therefore, naturally, these translation relationships can be applied back to the query translation process to remove translation ambiguities, just like using translation relationships obtained from a parallel corpus for the same purpose. The difference here is that the translation relationships obtained through RF have been extracted from relevant document set. In addition, the extracted translation relationships can sometimes produce better quality or even new translations that do not exist in the original dic-tionary. We call this new usage of RF information  X  X  X ranslation enhancement X  (TE).

Our goal in this paper, therefore, is to examine the usage of TE as a relevance feedback technique in TLIR. Our research has the following four objectives:
First, through studying several methods of extracting translation relationships based on RF information, we want to exam-ine whether TE is an effective method for using pseudo RF (PRF) information in TLIR.

Second, because TE and QE are actually working on different parts of the TLIR process, it is important to know whether TE and QE can be integrated for further improvement.
 Third, we will study whether TE is still an effective technique for dealing with interactive RF (IRF) information.
Fourth, with the help of translation enhancement, we believe that the translations of some out-of-vocabulary terms can be found. We want to study this effect.
 In the remainder of this paper, we will first review the related work on RF in monolingual and CLIR in Section 2 ; then in
Section 3 , we talk about TE in detail with the focus on our current methods for implementing TE in TLIR process. Then, we will talk about basic experiment setup and the research questions in Section 4 . From Section 5 to Section 8 , we conducted several experiments in order to obtain answers to the four research objectives respectively. Finally, we will conclude with discussions about TE, the relationship between TE and QE, and future works. 2. Related work
Using relevance feedback to improve retrieval effectiveness has a long history. It was initially introduced in the mid-1960s, and some of the early important work was achieved in vector space model using the SMART system ( Rocchio, 1971; Salton &amp; Buckley, 1990 ). Since then, relevance feedback has also been explored in probabilistic modeling ( Harper, resents a recent attempt to directly model relevance based on RF information. There are two ways to obtain RF information. sumes that the top N returned documents are all relevant so that users do not have to make judgments ( Buckley, Salton, Allan, &amp; Singhal, 1994 ).

In monolingual IR, it has been well studied about the issues of how exactly RF information can be extracted, and how such information should be applied in query reformulation. There are basically two methods of applying RF information in query reformulation. Term reweighting adjusts the relative importance of the query terms (e.g., their associated weights) based on 1995 ) for Boolean retrieval system, and using Rocchio X  X  methods ( Rocchio, 1971 ) and Ide X  X  improvements ( Ide, 1971 ) in vec-tor space retrieval model. Query Expansion (QE), on the other hand, adds more terms into the query with the hope that the users X  information needs are more closely represented ( Harman, 1992 ). Between the two, QE is more effective and has re-ceived well deserved attentions. For example, based on examining several algorithms for QE, Harman (1992) found that it was better to consider all the relevant documents than only consider documents that contain query terms. Voorhees (1994) used lexical semantic information in improving QE, and Xu and Croft (2000) studied local and global context for machine learning ( White, Kules, Drucker, &amp; Schraefel, 2006 ) have also been studied in QE.

Term mismatch is a difficult problem in monolingual IR, but it is significantly more serious in CLIR. This is because CLIR users have to identify the right query terms whose translations rather than the terms themselves would match to the critical words used by the authors of the relevant documents ( Oard, He, &amp; Wang, 2008 ). Therefore, RF has been applied in CLIR to cope with this problem too.

The usage of RF in CLIR can be classified into three aspects. First, vast majority of RF studies in CLIR concentrated on pseu-do-relevance feedback based query expansion. Carbonell and colleagues (1997) developed a pseudo RF method for CLIR using a bilingual corpus. They first found the top-ranking documents for a query in the source language, then substituted the corresponding documents in the target language using the parallel corpus, and used these documents in the target lan-guage side to form the final expansion query. Among the three available QE in CLIR, Ballesteros and Croft (1997) demon-strated that post-translation QE was more effective in improving CLIR performance, whereas McNamee and Mayfield (2002) found that the combination of the two actually performed better particularly when the translation resources were not of a high quality. Ballesteros and Croft (1998) later demonstrated that pre-translation QE created a stronger base query by adding terms that emphasized query concepts, post-translation reduced the effects of irrelevant query terms by adding more context specific terms, and the combined QE had the advantages of both methods.
 Second, researchers have integrated RF into the statistical language modeling for CLIR. Hiemstra, Kraaij, Pohlmann, and
Westerveld (2001) provided a formula for applying RF back to a unigram statistical language model for CLIR. The cross-lan-guage relevance models proposed by Lavrenko, Choquette, and Croft (2002) used either parallel corpora or a bilingual lexicon for estimating a relevance model between two languages so that the relevance model can be used for QE and disambiguation.
Nie, Simard, Isabelle, and Durand (1999) described the usage of a probabilistic translation model to CLIR, and how that model was enhanced by automatically gathered parallel texts from the Web. However, except briefly mentioned in ( Hiemstra et al., 2001 ), no study in the CLIR literature has focused on examining whether and how RF can directly affect the quality of query translation, and whether and how the enhanced query translation can be integrated with query expansion.

Third, some researches in CLIR focused on interactions with users, including interactive RF based on users X  relevance judg-ments. The issues of studying users in CLIR environments have been addressed in part by the Interactive Track at the Cross-
Language Evaluation Forum (iCLEF), which provides a common framework for participating groups to evaluate important aspects of query (re)formulation and translation, and the relevance assessments on the returned documents ( Oard, Gonzalo,
Sanderson, Lopez-Ostenero, &amp; Wang, 2004; Oard et al., 2008 ). The usage of MT in translating returned documents for users X  found that users relevance judgments on translated documents were in good quality. Orengo and Huyck (2006) confirmed the same findings in a different experiment setting.

Although the reviewed literature demonstrates that RF is an effective method in CLIR, and MT of returned documents can facilitate relevance assessment in CLIR environment, no study has yet examined how to use RF information directly in improving query translation. The experiments described in this paper aim to examine the usage of both pseudo and inter-active RF information in improving query translation directly. 3. Translation enhancement: a new RF approach in TLIR
As stated in Section 1 , in addition to translating queries to the document language side, a TLIR system also translates the returned documents back to the query language side in order to facilitate users to seamlessly search and utilize documents in foreign languages. Therefore, the relevance judgments on the returned documents are actually performed on the translated documents (i.e., at the query language side) rather than on the original documents (i.e., at the document language side).
Based on this observation, our TE modeling makes the following two assumptions: 1. RF information obtained in TLIR not only tells us which query terms can be useful for QE, but also informs us about the users X  intended translation relationship between a word in the translated relevant documents and the corresponding term in the original relevant documents. 2. Regardless of the translation resources used in the translation of both the queries and the returned documents, it still makes sense to apply the translation relationships obtained through RF to the query translation in order to improve retrieval effectiveness.

Based on these two assumptions, we will design a TE method. In this method, we think that there are two core issues: how to extract the intended translation relationships from a set of relevant document pairs, and how to apply such relation-ships to query translation. 3.1. Extracting intended translation relationships from relevant documents pairs
When obtaining relevance feedback from users, the relevance judgments can be performed on various granularities of documents. Researchers in the HARD track of TREC have explored RF on terms, named entities, passages, and documents, and found that they each have their own advantages and limitations ( Allan, 2003 ). Because feedback on documents involves the least effort from users, it is the most commonly used RF approach. In this study, all our RF methods were performed at the document level. However, the developed TE techniques can be easily applied to other RF granularities. extracting various other types of translationrelationships,suchas importantnamed entities,potential QE terms,andphrases,etc.
Since the set of relevant documents and their translations can be viewed as a small scale parallel corpus, it is natural to relationships is to establish sentence alignment within the document pairs. Sentence alignment helps to achieve better extraction accuracy because it gives us a much narrower searching space to look for intended translation relationships.
Although sentence alignment sounds trivial here, in practice, it is very important, because MT output contains lots of noises and errors, such as skipping one sentence, mixing several sentences together, repeating some paragraphs, etc., which could cause problems in downstream processes.

Based on the sentence alignment of document pairs, we designed four methods to extract intended translation relation-ships. In all four methods, we extended the back-off translation approach ( Resnik, Oard, &amp; Levow, 2001 ) to maximize the search for instances of query terms and their translations in the relevant document set. The first three methods only rely on sentence aligned document pairs, whereas the fourth one (TWA) assumes that word alignment information is available or can be easily obtained.

Keep all translations (KAT) : This approach only requires a set of document pairs aligned at sentence level and a dictionary query language side (i.e., those MT documents). Then, it utilizes the sentence alignment information to search inside the doc-uments at the document language side (i.e., those original documents) for all the instances of the translation alternatives of the query term. All the found instances of the query terms and their translation alternatives in the same sentence pairs are treated as the intended translation relationships. For example, suppose term  X  X  X ank X  in the dictionary has four translations with decreasing probabilities:  X  X   X , X   X , X   X , X   X , and all of these translations are identified in the sentence pair, then all of them will be selected as the intended translations.

Keep one-best translation (K1T) : Viewing all found translation alternatives in a sentence pair as the intended translation relationships, KAT approach may introduce lots of noise, especially when the dictionary is automatically generated with many translation alternatives being noise. Following one of the heuristics often used in CLIR community, the K1T approach assumes that, among all translation alternatives found in the sentence pair, the one with the highest translation probability in the dictionary is probably the most plausible meaning in the relevant feedback. Therefore, K1T selects only that translation alternative among all of the translation alternatives returned by KAT. For example, still with the term  X  X  X ank X  and its four translations with decreasing probabilities:  X  X   X ,  X  X   X ,  X  X   X ,  X  X   X . If  X  X   X ,  X  X   X  and  X  X   X  are found in the sentence pair, KIT method would only select the translation with the highest dictionary probability, which is  X  X   X .

Keep most-frequent translations (KFT) : Like K1T, this approach is based on KAT, but with a different assumption. Borrowing the heuristics used in word sense disambiguation ( Yarowsky, 1995 ), KFT assumes that the correct translation of a query term is consistent in a discourse (say in a relevant document) therefore that correct translation would be the most frequently mentioned one in the discourse comparing to other randomly generated translation alternatives. As the result, KFT only keeps the translation that has the highest frequency in a relevant document. For example, this time we found two transla-tions for the term  X  X  X ank X  in the document, and the identified frequency for  X  X   X  is higher than that of  X  X   X , KFT method would select  X  X   X  rather than  X  X  . X 
Translations based on word alignment (TWA) : Regardless of using KAT, K1T or KFT, the search space is the whole sentence, where lots of noises may be introduced. To obtain more accurate identification of translation relationships, we used word alignment tools that have been widely used in a parallel corpus setting for extracting translation relationships. The tool we used was GIZA++ ( Och &amp; Ney, 2003 ). After obtaining word level alignments for each sentence pair in the relevant doc-ument set, it is straightforward to extract the translation relationships. All the found instances of the query terms and their translation alternatives identified by word alignment in the relevant document set are treated as the intended translation relationships for translation enhancement later. 3.2. Enhancing query translation with extracted translation relationships
Translation probabilities have been demonstrated to be very important in CLIR. This is why we think that, by enhancing the translation probabilities used in query translation, TLIR effectiveness can be improved. However, we do not think that the extracted translation relationships can replace the translation probabilities in the dictionary because the feedback from the users could sometimes be incomplete or even inaccurate. Our approach, therefore, is to first convert the extracted translation ities in the original dictionary to obtain the final enhanced translation probabilities.

To estimate the translation probability of a query term based on the extracted translation relationships, we use the fre-document set is calculated as in formula (1) : tf and tf a,b are the frequency of translation alternative j or a in document k or b ; N is the relevant document set; M of unique translation alternatives identified in the document set N for term i ; w which takes 1 (relevant) or 0 (irrelevant) for binary relevance judgments, but w vance assessments.

We then use weighted linear interpolation to integrate the extracted translation probabilities with their corresponding original translation probabilities in the dictionary (see formula (2) ):
P different weights between the extracted probabilities and the original ones.
 is the set of unique translation alternatives in the dictionary for term i ,so M malize the enhanced probabilities of each translation alternative j of term i so that the sum of the normalized probabilities
P is 1 (see formula (3) ): 3.3. Translation enhancement and query expansion
Both TE and QE are relevance feedback techniques. QE improves retrieval effectiveness by introducing new terms into the query, with the hope that the terms would provide highly content related information. Pre-translation QE expands the ori-ginal query at the query language side, whereas post-translation QE adds terms to the translated query at the document lan-guage side. TE, on the other hand, mainly concentrates on improving the translation resources used for query translation without necessarily introducing new query terms at both language sides. The improvement of TE often comes from better An interesting research question is whether or not it is beneficial to combine TE and QE in TLIR.

Because QE alone is not the focus of this paper, we directly adopted a state-of-the-art QE implementation, which is Lav-renko X  X  relevance-based language model ( Lavrenko &amp; Croft, 2001 ) implemented inside the Indri search engine. The rele-vance-based language model explicitly integrates the relevance concept and the relevance model into the retrieval calculation. It is a novel technique for estimating probabilities of words in the unknown set of documents relevant to the query. Formula (4) summarizes the implementation of relevance-based language model in Indri, where I is the original query, r is a term to be considered for query expansion, and D is a document. The details of this implementation can be found online at http://ciir.cs.umass.edu/~metzler/indriretmodel.html .
 4. Basic experiment setup 4.1. Research questions
The goal of our experiments is to examine the effectiveness of the proposed TE approaches. In particular, we are inter-ested in the following research questions: 1. Is TE an effective pseudo RF technique in TLIR? Here the effectiveness is measured by comparing to the non-RF TLIR and monolingual baselines. We are also interested in differentiating the effectiveness of the four translation relationship extraction methods: KAT, K1T, KFT, and TWA. 2. Is it beneficial to combine TE with QE in pseudo RF? Here, we want to compare it against TE alone and QE alone, and examine how TE can be integrated with QE. 3. Can TE still be effective in interactive RF? Here, we want to examine the extent to which TE can perform when RF is gath-ered from users. 4. What is the role of TE in handling out-of-vocabulary (OOV) terms? In addition, how the effectiveness of TE is when compared with traditional CLIR methods equipped with OOV resolution capabilities? 4.2. General experiment resources
All our experiments were performed on English X  X hinese TLIR where English queries were used to retrieve Chinese doc-uments. The document collections used in the experiments were TDT4 and TDT5 Multilingual News Text corpora ( Cieri et al., 2002 ). The English and Chinese news articles in these corpora were collected daily from 20 news sources in two time peri-ods: October 2000 to January 2001 and April to September 2003. In total the corpora contain 83,627 Chinese documents and 306,498 English documents. For each original Chinese document, there is an output from the MT system developed by the
Information Sciences Institute (ISI) at the University of Southern California. We acknowledge that our TE approach depends on the quality of machine translation on documents. The better the translation is, the better our TE result would be. The ISI X  X 
MT output we used had been the state-of-the-art when the TDT collection was created. But comparing to current MT systems icantly improved if we use current state-of-the-art MT systems.

Three reasons motivated us to use TDT4&amp;5 collections rather than the collections from CLEF or NTCIR. First, TDT4&amp;5 col-lections are standard CLIR collections too. They have been used in multilingual Topic Detection and Tracking (TDT) experi-ments from 2002 to 2005 ( Allan, 2004 ). The second reason, which is more important in our TE experiments, is that we needed English translations of Chinese documents in our study of TE, but we did not have a machine translation system.
The TDT collections just happen to have English translations for the Chinese documents even though these translations are not at the state-of-the-art quality. The last reason was that our study of pre-translation QE needed a comparable English collection besides the Chinese target collection. The TDT collections again contain an English comparable document collec-tion from the same time period. Because of these reasons, we selected the TDT collections for our current experiments. Of course, we acknowledge that the TDT collections are not large comparing to other collections like CLEF or NTCIR. However, since TE technique only examines the top returned documents, which is irrelevant to the size of whole collections, we be-or NTCIR collection using a machine translation system. However, this is much more expensive and subject to the availability of a reliable machine translation system/service for us to use.

We selected 44 English topics which each has more than 20 relevant Chinese documents inside TDT4&amp;5 corpora. We then manually translated those topics into Chinese to obtain Chinese topic statements. We reorganized TDT topics into the TREC topic style with a title, a description, and a narrative field (see Fig. 2 ) on these topics: short length queries that contain titles only (T query), medium length queries with title and description (TD TD queries (27 terms), and TDN queries (127 terms).

The bilingual dictionary we used was an English-Chinese lexicon compiled by training GIZA++ on multiple sources includ-ing the Foreign Broadcast Information Service (FBIS) corpus, HK News and HK Law, UN corpus, and Sinorama, etc. ( Wang &amp; native. The translation probabilities were obtained based on the normalized frequency of an English word and a Chinese word being linked together by the word alignment. All Chinese texts and queries were segmented using the Stanford Chinese stem English texts, queries and the dictionary when necessary. Stop words were removed using a Chinese stopword list ment. The breaker uses punctuation, such as periods, question marks, exclamation points, and ellipses, to identify sentence boundaries. It also compares the sentence length line by line between the sentence pairs based on the assumption that the If the difference exceeds a certain amount (6 terms 5 in our study), we combined the shorter sentence with its next one.
For query translation in the baseline, to remove low probability translations which often are noises, we fixed a threshold called Cumulative Probability Threshold (CPT) to select translations from the dictionary. This is done by ranking the trans-lations in decreasing order of their normalized probabilities, then iteratively selecting the translations top-down until the cumulative probability of the selected translations is firstly reached or exceeds the threshold. A threshold of 0 thus corre-sponds to using the single most probable translation (a well-studied baseline) and a threshold of 1 corresponds to the 2004 ) to perform the document retrieval.

The main evaluation measure was mean average precision (MAP). Statistical significance tests were two tailed paired samples t -test. 5. Experiments on TE with pseudo RF 5.1. Experiment runs
In total, we performed seven runs in testing TE with pseudo RF. The pseudo RF was performed on the top 20 documents from the original ranked lists.

Monolingual baseline (MONO-BASE) : A run of retrieving Chinese documents using the queries generated from the manually translated Chinese topics.

TLIR baseline (TLIR-BASE) : A run using English queries to retrieve Chinese documents without using any RF techniques. In order to fully cover the dictionary, we adopted a four-stage back-off translation strategy ( Resnik et al., 2001 ). First, the surface form of an input English term is matched to the surface forms of the English terms in the dictionary. If it fails, the input English term is stemmed, and then is matched to the surface forms of the English terms in the dictionary again. If this still fails, the dictionary is stemmed, so that the surface form of the input term is matched to the stems of the terms in the dictionary. If all these fail, match the stem of the input term to the stems of the terms in the dictionary.
 Higher TLIR baseline (TLIR-QE) : We performed pre-translation QE, post-translation QE, and the combination of the two over
TLIR-BASE. Top 20 expanded terms were selected from the top 20 returned documents (these parameters were obtained through our previous experiments using the TDT collections). We selected the best performance of the three QE methods as the higher TLIR baseline TLIR-QE.
 TLIR translation enhancement using all translations (TLIR-KAT) : A TE run using KAT approach as stated in Section 3.1 . TLIR translation enhancement using one-best translation (TLIR-K1T) : A TE run using K1T approach as stated in Section 3.1 . TLIR translation enhancement using most-frequent translation (TLIR-KFT) : A TE run using KFT approach as stated in Section 3.1 .
 TLIR translation enhancement using word alignment (TLIR-TWA) : A TE run using TWA extraction approach as stated in Section 3.1 .

To get a better idea of the effectiveness of translation enhancement, we compared the results from all seven runs at dif-ferent CPT from 0.0 to 1.0 with an increment of 0.1 at each time. We acknowledge that this way of selecting parameters is rather ad hoc. However, we did exhaustively test all combinations of parameters for each experiment conditions such as TE, QE, baseline, etc., then we chose the best combinations of CPT and lambda in formula (2) for each condition and present in
Table 1 . 5.2. Result analysis and discussions
As shown in Table 1 , all four TE approaches performed better than the lower TLIR baseline TLIR-BASE. The smallest improvement came from TLIR-KAT, and TLIR-TWA performed the best among the four TE methods. However, only
TLIR-TWA significantly outperformed TLIR-BASE with all three types of queries. Only at the short (T) and medium query (TD) conditions, did TLIR-KFT perform significantly better than TLIR-BASE. Only at the long query (TDN) condition, did
TLIR-K1T perform significantly better than TLIR-BASE. All these demonstrate that TE is a valid and effective RF technique for improving TLIR performance.
 Compared to the higher TLIR baseline TLIR-QE, the TE approach TLIR-TWA outperformed TLIR-QE when the queries were
TD and TDN. However, only the improvement obtained with TDN queries was statistically significant. When we further examined the specific QE methods (i.e., pre-translation, post-translation and combined, see Table 1 ), all four TE methods ob-tained better results than the pre-translation QE approach with the TD and TDN queries. It should be noted that the TE methods were mostly comparable to post-translation QE and the combined QE methods except that TLIR-TWA with TD and
TDN queries were better than the QE methods. Besides the difference between QE and TE, our results also confirm the finding in the literature that post-translation QE and combined QE are generally better than the pre-translation QE method ( McNa-mee &amp; Mayfield, 2002 ).

With TE alone, the TLIR performance could not outperform the corresponding monolingual baselines MONO-BASE. How-ever, all four TE methods met at least 75% of the monolingual effectiveness, with TLIR-TWA matching 93.61% of the effec-tiveness of MONO-BASE under the TDN queries.

The quality of the extracted translation relationship can affect the TE performance significantly. With extra resources such as word alignment, TWA method could extract much better translation relationships, and better extracted translation rela-tionships helped TLIR-TWA to outperform the other three runs consistently. The average number of unique translations per word extracted via word alignment was 16. The differences between TLIR-TWA and TLIR-KAT were statistically significant under all three query types. The difference between TLIR-TWA and the remaining two runs (TLIR-K1T and TLIR-KFT) were significant under TD and TDN queries.

There could be some concern about using word alignment for TE: it might be too time consuming to conduct word align-ment on the fly when users are waiting for their search results, or it may be difficult to obtain a word alignment tool at all.
However, there are solutions to the concerns. For example, word alignment can be done offline on the whole collection as soon as the translations of the documents are ready. This means that word alignment does not have to wait until users issue their queries. Therefore, when the document set from relevance feedback is selected, the alignment information of the doc-uments has already been available. Another more systematic approach is that many modern statistical machine translation systems can easily produce translation relationships at the word or phrase level. These translation relationships can then be transformed into word alignment information needed in our TWA based TE approach. Therefore, it is reasonable to rely on word alignment information for TE.

The three less effective TE methods all have their weakness respectively. KAT is unstable particularly when the transla-tions in the dictionary contain a great deal of noises. K1T pays much attention to the information in the dictionary, and could one translation. Like K1T, this could be too restricted.
 In both monolingual and cross-language retrieval, query length is a factor that affects the performance of RF techniques.
For example, as shown in Fig. 3 , QE obtained the highest MAP improvement over the corresponding baselines TLIR-BASE with short T queries, and the improvement decreased with longer TD and TDN queries. When the query is a long query, pre-trans-lation QE even obtained negative improvement. TE is affected by query length too. However, the effect is different. TLIR-TWA performed better with longer TD and TDN queries, and the differences were significant to that of the short T queries. There-fore, it seems that query length has different effects on TE and QE. This is another motivation to combine these two RF methods.
 6. Experiments on integrating TE and QE with pseudo RF 6.1. Experiment runs
Our goal in this set of experiments is to study whether it is beneficial to integrate TE and QE in TLIR. Same as the exper-iments in Section 5 , our studies only concerned pseudo RF. In this set of experiments, we conducted additional two runs with the same resources stated in Section 4.2 :
Integrated TE and QE run (TLIR-TEQE) : A run combined the best methods of TE, which is the word alignment approach, with the best QE method, which is post-translation QE.

Higher monolingual baseline (MONO-QE) : A monolingual baseline run with query expansion. 6.2. Result analysis and discussions
As shown in Table 2 , and then further elaborated in Table 3 , it makes sense to combine TE and QE in TLIR. First, the com-bined run TLIR-TEQE outperformed TLIR-BASE with significant improvement under all three types of queries. So it is evident that the combination works. More importantly, TLIR-TEQE also outperformed runs with TE or QE alone (i.e., TLIR-TWA and
TLIR-QE respectively). Again, some of these improvements were statistically significant (with TE under T and TD queries and with QE under TD and TDN queries).

The combination of TE and QE (TLIR-TEQE) achieved comparable results to the monolingual baseline MONO-BASE for all three types of queries. In the case of T and TD queries, TLIR-TEQE even exceeded the monolingual run. Of course, these runs still could not outperform the higher monolingual baseline MONO-QE.

Another interesting point is that TLIR-TEQE showed relatively stable performance with all three types of queries. Different to TE that works better with long queries than short queries, and to QE that works well with short queries but is losing per-formance with long queries, the combined run performed consistently comparable to the monolingual run with all three types of queries. It seems that the combination helped to use one X  X  advantages to overcome the limitations of the other. Therefore, we can conclude that it is beneficial and effective to combine TE with QE.

There could be questions about the improvement obtained by TE over the simple TLIR baseline. For example, one criticism could be that the reason that TE obtained significant improvement is because the TLIR baseline TLIR-BASE is rather low. We acknowledge that TLIR-BASE is a simple baseline that only adopted CPT as a threshold and used probabilistic structured query method to control the translation noises. Without any other performance enhancement methods, the performance of TLIR-BASE is lower than the state-of-the-art of TLIR performance which often includes many other performance enhance-ment methods. However, we have also established several higher baselines (such as TLIR-QE and MONO-BASE). The perfor-mance of TE has been comparable to TLIR-QE, and close to MONO-BASE even it is based on the simple TLIR baseline. More isolation, but rather to integrate it with other RF techniques such as QE. The combinations of TE and QE have achieved the state-of-the-art TLIR performance, which is around 95% of monolingual retrieval. In addition, it is important to know that TE can help to resolve OOV terms too, which is another often used performance enhancement method in the CLIR literature. We will explore TE and OOV problem in Section 8 . 7. Experiments on TE with interactive RF 7.1. Experiment setup
Through Sections 5 and 6 , we have established that TE is a valid and effective RF method for TLIR. However, all those experiments were conducted using pseudo-relevance feedback (PRF) information. We do not know whether it would make therefore tested the TE methods with IRF information. Because our interests are on TE X  X  effectiveness, we adopted the eval-uation ideas tried in previous TREC HARD experiments ( Allan, 2003 ). In such experiment design, the utilized evaluation mea-sures are on judging ranked retrieval results rather than on more user-oriented results.
 To do the experiments under the IRF environment, we implemented an interactive TLIR system whose name is ICE-TEA. The system is developed to utilize the RF information from users to conduct TE, QE, and the integration of them to improve TLIR results ( Wu &amp; He, 2008 ). The architecture of the system is shown in Fig. 4 .

The test collections and the TLIR resources used in this experiment were the same as in the previous PRF experiments. To elicit relevance judgments from users, we again followed the HARD experiment design. Instead of asking users to issue que-ries to obtained initial search results, we asked users to perform relevance judgments on the top 20 documents generated by our system. To resemble more closely the real search process where users X  queries are short, we only used the results from short T queries. We also only examined the TE method based on word alignment (i.e., TWA method).

We had to reduce the number of topics to 40 because the remaining 4 topics had zero relevant documents in the top 20 returned documents. It makes no sense to ask users to select relevant documents from those results.

Eight native English speakers from the University of Pittsburgh were recruited to participate in the experiment. Six of them were master students, one was a PhD student, and one was an undergraduate. Five were female, and the average age was 24.6 years old. Five of them had taken IR course before. The average time they spent on online searching was 2 h per day. The average degree of how confident they felt in being able to locate specific information was 4 with 5 as the highest confidence value and 1 as the lowest.

The whole experiment lasted for 120 min for each participant. Every participant was given 10 topics to judge. To help the participants perform relevance judgments, we provided them a printed-out version of the TDT topics which include every-thing we put into TDN field as shown in Fig. 2 . Their tasks were to go through the 20 retrieved documents to assign one of the three possible judgments:  X  X  X ot relevant X ,  X  X  X omewhat relevant X , and  X  X  X ighly relevant X . The default value is  X  X  X ot judged X .
They had a maximum of 10 min to finish a topic. Topic allocation was carefully designed so that each topic was judged by 2 participants, and Latin square method was used to arrange the topic presentation sequence so that the learning and fatigue effects can be balanced and overcome. There was also time allocated for training, breaks, and completion of question-naires. Our logging ability included using the screen capture tool Camtasia Studio
Our system interface (see Fig. 5 ) provided adequate cues to the participants. The cues include topic descriptions for users to consult during judgments, the current query displayed at the query input box, and the translated English surrogate of each returned document. The surrogate consists of three sentences that contain the most query terms extracted from MT docu-ment, and the sentences were displayed according to their original sequences in the documents. Query terms inside the sur-rogates were highlighted. If the participants requested it, the full text of the returned documents and their corresponding MT version were displayed in a pop-up window. Query terms and their translations were highlighted in the pop-up window too.
In our handling of IRF information for TE, we took advantage of the facts that we had two relevance judgments on each document for a given topic, and that the judgment had three levels of relevance degree. Formula (5) shows how we assigned weight w k to a relevant document k . where N high is the number of users who judged  X  X  X ighly relevant X  for document k ; N  X  X  X omewhat relevant X ; N none is the number of users who judged  X  X  X ot relevant X ; S highly relevant document; S some is the score (set as 1) given to a somewhat relevant document; S 0) given to a non-relevant document.

Before we performed TE on IRF data, we further removed another three topics because none of the participants marked any document in the results of these three topics. Therefore, the reports presented below are from the remaining 37 topics. For this part, three additional runs were performed:
TLIR baseline with IRF (USER-TLIR-BASE) : An IRF run that used 37 English queries to retrieve Chinese documents without employing any QE or TE technique.
 TLIR TE with IRF (USER-TLIR-TE) : An IRF run with TE using word alignment (TWA).

TLIR TE with PRF (BLIND-TLIR-TE) : A PRF run that is identical to TLIR-TWA but the results reported here are based on the 37 topics. 7.2. Result analysis and discussions
In studying the results obtained from this experiment, we used multiple measures to check on the results. First, we cal-the number of user identified relevant documents that are truly relevant documents according to the ground truth over the number of user identified relevant documents. Recall is the ratio of the number of user identified relevant documents that are truly relevant documents over the number of truly relevant documents based on the ground truth in the top 20 docu-ments. When calculating the numbers of user identified relevant documents, we followed the  X  X  X trict X  and  X  X  X oose X  relevance judgment approach of converting three levels of relevance judgments into two levels ( He, Wang, Oard, &amp; Nossal, 2002 ):  X  X  X trict X  relevance judgment treats  X  X  X omewhat relevant X  documents as the part of the  X  X  X ot relevant X  documents, whereas  X  X  X oose X  relevance judgment treats  X  X  X omewhat relevant X  documents as the part of the  X  X  X elevant X  documents. As shown in
Table 4 , because the calculations of both the strict and loose relevance methods generate precision and recall values greater than 0.7, it is reasonable to state that the RF from users is in good quality.

Second, because each document in our experiment was judged by two participants and each participant judged the doc-ument based on their own experience, therefore, we used statistic Kappa Coefficient to test whether the participants X  judg-ments are reliable. In this experiment, we had 800 judged documents and got the Kappa value which was 0.483, which indicated that the strength of agreement is  X  X  X oderate X .
 Finally, for the TE result on IRF data, as shown in Table 5 , similar to TE based on PRF, the TE run based on IRF (USER-TLIR-TE) outperformed the corresponding TLIR baseline (USER-TLIR-BASE), and the improvement was statistically significant.
Comparing to the TE run using PRF information (BLIND-TLIR-TE), USER-TLIR-TE also earned a level of 2.65% relative improve-ment, although the difference was not statistically significant. This demonstrates that TE is a valid and effective method for interactive RF, too, and that the users X  relevance judgments may be a better RF source for TE. 8. Experiment on TE and out-of-vocabulary resolution 8.1. Experiment setup
We have demonstrated in Section 5 that TE is a valid and effective RF technique for improving TLIR performance, and among all four TE approaches, TLIR-TWA performs the best. Besides extracting much better translation relationships than other TE methods, TWA can sometimes identify the translations for some out-of-vocabulary (OOV) terms with the help of word alignment information.
 The biggest group of OOV terms, which was observed to be as many as half of the whole observed OOV terms in ( Demner-
Fushman &amp; Oard, 2003 ), belongs to a group called named entities (NEs). They are the expressions in human languages that explicitly link notations in languages to the entities in the real world. Different to common nouns, NEs, especially proper nouns, are open words, where there already exists large quantity of them, and at the same time people are creating new
NEs every day. This is the reason that, no matter how large the coverage of a dictionary is, many NEs still do not have their translations in the dictionary. At the same time, NEs are critical information in search requests. Not only almost all search topics in CLEF 2000 X 2003 contain at least one or several NEs ( Mandl &amp; Womser-Hacker, 2005 ), these NEs plays important roles in locating relevant documents. When correct translations of NEs are available, it seems that the  X  X  X ccurrence of named entities in topics makes them  X  X asier X  for retrieval systems X  ( Mandl &amp; Womser-Hacker, 2005 ).

Another reason that we want to test how TE handle NE problem is that the collection used in our experiments is TDT col-lections that were built for event driven information exploration. Therefore, it contains more NEs than other CLIR collections like CLEF and NTCIR. Using the data from Mandl et al. X  X  study ( Mandl &amp; Womser-Hacker, 2005 ), we compared the NE distri-butions inside TDT collections and that of the CLEF collections. As shown in Table 6 , our TDT topics have much higher num-bers of NEs (unique) in each topic.

To answer research question 4 in Section 4.1 , we specifically enhanced TLIR-BASE with a series of techniques for obtaining following runs that have the capabilities of handling OOV (NEs):
TLIR run with basic NE translation (TLIR-NE-1) : A run that uses the same CLIR resources as TLIR-BASE but with one enhance-ment. It used an NE identification component build on information extraction techniques. This NE component is designed to provide two functions in our TLIR process. The first one is to identify NEs in a given text, which could be queries, doc-uments, or any parts of queries and documents. The NE component used the NYU English and Chinese HMM-based name taggers trained on several years of ACE (Automatic Content Extraction types of names (Person, GPE, Location, Organization, Facility, Weapon and Vehicle) and achieve about 87 X 90% F -measure on newswire ( Ji et al., 2007 ). The second function of the NE component is to handle the translations of identified NEs. This function was supported by the NYU name translation system ( Ji et al., 2007 ), which used Wikipedia, parallel corpora and Web mining to locate translations.

TLIR run with weighted NE translation (TLIR-NE-2) : A run that is the same as TLIR-NE-1 but with one exception: the NE translations have accompanied weights obtained through a Web search. The weight was calculated as the follow: where weight(NE i , tran i,j ) is the weight for translation j of NE
NE i , and tran i,j ; |NE i | is the number of returned pages containing NE ing tran i,j , a is a constant to adjust the score in case the weight is too small.

TLIR run with weighted NE translation plus Web OOV resolution (TLIR-NE-3) : A run that is the same as TLIR-NE-2 but with the extension of finding the translations on the Web for OOV NE that cannot be handled by TLIR-NE-1. We developed two simple patterns that look for the English NEs either appearing in brackets after a Chinese word (i.e., ... Chinese word (Eng-many Chinese web pages would give the English translation when a new NE is introduced. Our search was performed on baidu.com which is the most popular Chinese search engine. 8.2. Result analysis and discussions
As we anticipated, TWA method can resolve the translations of some OOV terms. Table 7 shows 11 OOV terms and their translations found by TWA method. Almost all these terms are NEs of people names, locations, etc. This is consistent with to identify translationsfor some OOV NEs. Of course, as shown in Table 7 , some of the found translationsare wrong (such as the translationsforNos.3and5)whichistheresultofwordalignmenterrors.However,thefactthatmajorityfoundtranslationsare correctindicatesthatitisreasonablyreliabletouseTWAmethodforresolvingsomeOOVterms.AlthoughsegmentingNEisstill a problem for some Chinese segmenters, the Stanford Chinese word segmenter we used can correctly recognize many named entities. For example, sentence  X  X   X  in document
XIN20030505.1530.0174 contains a location named entity  X  X   X , and it was correctly segmented. Then with the help of wordalignmentinTWA,itstranslationislateridentifiedas X  X  X ingol X ,whichiscorrect. Table7 showsotherexamplesofresolved OOVtermswiththehelpofwordalignmentinTWA.However,wedoacknowledgethatthesegmentermayincorrectlysegment NEs, which resolves to wrong translations for OOV terms (such as the translations for Nos. 3 and 5 in Table 7 ).
The comparison between TLIR-TWA and the three TLIR-NE runs is shown in Table 8 . After query translation in TLIR-NE-1 and TLIR-NE-2, there were in total 25 OOV NEs among the 44 topics. With the help of TLIR-NE-3, 14 out of these 25 OOV NEs found their translations. Because of this, TLIR-NE-3 is consistently better than TLIR-NE-1 and TLIR-NE-2, but the difference is not statistical significant. TLIR-NE-2 is consistently better than TLIR-NE-1 too, showing that weights for NE translations are useful too. However, even with these extra enhancements in handle OOV problems, as shown in Table 8 , these NE runs still all cannot exceed our TLIR-TWA approach. These results further demonstrate that our TE method is an effective method. 9. Conclusion and future work
In this paper, we proposed translation enhancement as a novel RF technique for TLIR. This is a natural approach consid-ering that both queries and returned documents are translated using certain (maybe different) translation resources in TLIR.
Based on our experiment results, all four TE approaches have been found to be effective. However, only the TWA approach achieved competitive performance as compared to QE, the most commonly used RF technique in CLIR. The limited capability of KAT, K1T, and KFT methods to find translation relationships accurately in relevant documents is probably the reason that these three methods showed relatively small improvements. TWA relies on word alignment to provide more accurate trans-lation relationships, which increased its effectiveness. The effectiveness of TE was examined using both interactive RF and pseudo RF information, and the improvement of TE is actually higher with interactive RF.

Although both TE and QE are RF techniques, they actually improve TLIR performance at different retrieval stages. In addi-tion, our studies show that TE is more suitable for long queries, whereas QE is more useful for short queries. Therefore, the integration of TE and QE is beneficial not only because more RF information is used, but also because the retrieval system is OOV terms.
 Our future work on TE is in the following areas. First, we will explore the usage of alignment information in MT outputs. Applying word alignment on the returned documents and their machine translations is actually not the optimal approach.
Current statistical machine translation systems often generate outputs with such information that the alignment relation-ship can be easily established without full scale word alignment. Second, we will explore TE at phrase level. Improving trans-lation relationship at word level certain helps, but modern phrase MT systems can give us many phrase level translation information. Previous CLIR studies demonstrated the usefulness of phrases translation ( Ballesteros &amp; Croft, 1997; Lopez-
Ostenero, Gonzalo, &amp; Verdejo, 2005 ). Third, two of our current TE methods based on sentence alignment only extract one translation for each query term. We will examine the usage of extracting n-best translations or top n most-frequent trans-interactive retrieval, and will use user-oriented evaluation measures to examine the true benefits of TE to the users. Acknowledgement
The authors would like to thank Jianqiang Wang from the State University of New York at Buffalo for providing us the dictionary, and Heng Ji and Ralph Grishman from New York University for providing us the NE translations. This work is par-tially supported by National Science Foundation of USA under the agreement NSF/IIS 0704628 and National Social Science Foundation of China under the agreement 09CTQ026.
 References
