 Social network such as MySpace, Facebook, Orkut, LiveJournal and Bebo have attracted millions of users [1], some of these networks growing at a rate of more than 50 percent during the past year [2]. Recent statistics have suggested that social networks have overtaken search e ngines in terms of usage [3]. This shows how Internet users have integrated social networks into their daily practices.
Many social networks, including LiveJournal online services [4] are focused on user interactions. Users in LiveJournal can tag other users as their friends. In addition to tagging friends, users can also specify their demographics and interests in this social network. We can see LiveJournal as a graph structure with users (along with their specific information, e.g. user interests) corresponding to nodes in the graph and edges corresponding to friendship links between the users. In general, the graph corresponding to a social network is undirected. However, in LiveJournal , the edges are directed i.e., if a user  X  X  X  specifies another user  X  X  X  as its friend, then it is not necessary for user  X  X  X  to be the friend of user  X  X  X . One desirable feature of an online social network is to be able to suggest potential friends to its users [8]. This task is known as the link prediction problem, where the goal is to predict the existence of a friendship link from user  X  X  X  to user  X  X  X . The large amounts of social network da ta accumulated in the recent years have made the link prediction problem possible, although very challenging.
In this work, we aim at using the ability of machine learning algorithms to take advantage of the content (data from user profiles) and graph structure of social network sites, e.g., LiveJournal , to predict friendship links. User profiles in such social networks consist of data that can be processed into useful information. For example, interests specified by users of LiveJournal act as good indicators to whether two users can be friends or not. Thus, if two users  X  X  X  and  X  X  X  have similar interests, then there is a good ch ance that they can be friends. However, the number of interests specified by users can be very large and similar interests need to be grouped semantically. To achieve this, we use a topic modeling ap-proach. Topic models provide an easy and efficient way of capturing semantics of user interests by grouping them into categories, also known as topics, and thus reducing the dimensionality of the proble m. In addition to using user interests, we also take advantage of the graph structure of the LiveJournal network and extract graph information (e.g., mutual friends of two users) that is helpful for predicting friendship links [9]. The contributions of this paper are as follows: (i) an approach for applying topic modeling techniques, specifically LDA, on user profile data in a social network; and (ii) experimental results on LiveJournal datasets showing that a) the best performance results are obtained when in-formation from interest topic modeling is combined with information from the network graph of the social network b) the performance of the proposed approach improves as the number of users in the social network increases.
 The rest of the paper is organized as follows: We discuss related work in Section 2. In Section 3, we review topic mo deling techniques and Latent Dirichlet Allocation (LDA). We provide a detailed description of our system X  X  architecture in Section 4 and present the experimen tal design and results in Section 5. We conclude the paper with a summa ry and discussion in Section 6. Over the past decade, social network sites have attracted many researches as sources of interesting data mining problems. Among such problems, the link prediction problem has received a lot of a ttention in the social network domain and also in other graph structured domains.

Hsu et al. [9] have considered the problems of predicting, classifying, and an-notating friendship relations in a social network, based on the network struc-ture and user profile data. Their experimental results suggest that features constructed from the network graph and user profiles of LiveJournal can be effectively used for predicting friendships. However, the interest features pro-posed in [9] (specifically, counts of indi vidual interests and t he common interests of two users) do not capture the semantics of the interests. As opposed to that, in this work, we create an implicit interest ontology to identify the similarity be-tween interests specified by users and use this information to predict unknown links.

A framework for modeling link distributions, taking into account object fea-tures and link features is also proposed in [5]. Link distributions describe the neighborhood of links around an object and can capture correlations among links. In this context, the authors have proposed an Iterative Classification Algorithm (ICA) for link-based classification. This algorithm uses logistic regression models over both links and content to capture the joint distributions of the links. The authors have applied this approach on web and citation collections and reported that using link distribution improved accuracy in both cases.

Taskar et al. [8] have studied the use of a relational Markov network (RMN) framework for the task of link prediction. The RMN framework is used to define a joint probabilistic model over the entire link graph, which includes the attributes of the entities in the network as well as the links. This method is applied to two relational datasets, one involving university web pages, and the other a social network. The authors have reported that the RMN approach significantly improves the accuracy of the classification task as compared to a flat model.
Castillo et al. [7] have also shown the importance of combining features computed using the content of web docu ments and features extracted from the corresponding hyperlink graph, for web spam detection. In their approach, sev-eral link-based features (such as degree related measures) and various ranking schemes are used together with content-based features such as corpus precision and recall , query precision , etc. Experimental results on large public datasets of web pages have shown that the system was accurate in detecting spam pages.
Caragea et al. [10], [11] have studied the usefulness of a user interest ontology for predicting friendships, under the assumption that ontologies can provide a crisp semantic organization of the user information available in social networks. The authors have proposed several approaches to construct interest ontologies over interests of LiveJournal users. They have reported that organizing user in-terests in a hierarchy is indeed helpful for predicting links, but computationally expensive in terms of both time and memor y. Furthermore, the resulting ontolo-gies are large, making it difficult to use c oncepts directly to co nstruct features.
With the growth of data on the web, as new articles, web documents, social networking sites and users are added daily, there is an increased need to ac-curately process this data for extracting hidden patterns. Topic modeling tech-niques are generative probabilistic models that have been successfully used to identify inherent topics in collections of data. They have shown good perfor-mance when used to predict word associ ations, or the effects of semantic as-sociations on a variety of language-processing tasks [12], [13]. Latent Dirichlet Allocation (LDA) [15] is one such generative probabilistic model used over dis-crete data such as text corpora. LDA has been applied to many tasks such as word sense disambiguation [16], named entity recognition [17], tag recommen-dation [18], community recommendation [19], etc. In this work, we apply LDA on user profile data with the goal of producing a reduced set of features that capture user interests and improve the a ccuracy of the link prediction task in social networks. To the best of our knowledge, LDA had not been used for this problem before. Topic models [12], [13] provide a simple way to analyze and organize large vol-umes of unlabeled text. They express semantic properties of words and docu-ments in terms of probabilistic topics, which can be seen as latent structures that capture semantic associations among words/documents in a corpus. Topic models treat each document in a corpus as a distribution over topics and each topic as a distribution over words. A topic model, in general, is a generative model, i.e. it specifies a probabilistic way in which documents can be generated.
One such generative model is Latent Dirichlet Allocation, introduced by Blei et al. [15]. LDA models a collection of dis crete data such as text corpora. Fig-ure 1 (adapted from [15]) illustrates a simplified graphical model representing LDA. We assume that the corpus consists of M documents denoted by D = { d words denoted by d i =( w i 1 ,w i 2  X  X  X  w iN i ), where each word w ij belongs to a vo-cabulary V .Awordinadocument d i is generated by first choosing a topic z ij according to a multinomial distribution and then choosing a word w ij according to another multinomial distribution, conditioned on the topic z ij . Formally, the generative process of the LDA model can be described as follows [15]: 1. Choose the topic distribution  X  i  X  Dirichlet (  X  ) . 2. For each of the N i words w ij : From Figure 1, we can see that the LDA model has a three level representation. The parameters  X  and  X  are corpus level parameters, in the sense that they are assumed to be sampled once in the p rocess of generating a corpus. The variables  X  i are document-level variables sampled once per document and the variables z ij and w ij are at the word level. These variables will be sampled once for each word in each document. For the work in this paper, we have used the LDA implementation available in MALLET, A Machine Learning for Language Toolkit [20]. MALLET uses Gibbs sampling for parameter estimation. As can be seen in Figure 2, the architect ure of the system that we have designed is divided into two modules. The first module of the system is focused on iden-tifying and extracting features from th e interests expressed by each user of the LiveJournal . These features are referred to as interest based features . The second module uses the graph network (formed as a result of users tagging other users in the network as  X  X riends X ) to calculat e certain features which have been shown to be helpful at the task of predicting friendship links in LiveJournal [9]. We call these features, graph based features . We use both types of features as input to learning algorithms (as shown in Section 5). Sections 4.1 and 4.2 describe in detail the construction of interest based and graph based features, respectively. 4.1 Interest Based Features Each user in a social network has a profile that contains information character-istic to himself or herself. Users most o ften tend to describe themselves, their likes, dislikes, interests /hobbies in their profiles. For example, users of LiveJour-nal can specify their demographics and interests along with tagging other users of the social network as friends. Data from the user profiles can be processed into useful information for predicting/recommending potential friends to the users. In this work, we use a topic modeling technique to capture semantic informa-tion associated with the user profiles, in particular, with interests of LiveJournal users. Interests of the users act as good indicators to whether they can be friends or not. The intuition behind interest based features is that two users  X  X  X  and  X  X  X  might be friends if  X  X  X  and  X  X  X  have some similar interests. We try to capture this intuition through the feature set that we construct using the user interests.
Our goal is to organize interests into  X  X opics X . To do that, we model user in-terests in LiveJournal using LDA by treating LiveJournal as a document corpus, with each user in the social network repr esenting a  X  X ocument X . Thus, interests specified by each user form the content of the  X  X ser document X . We then run the MALLET implementation of LDA on the collection of such user documents. LDA allows us to input the number of inherent topics to be identified in the collection used. In this work, we vary the number of topics from 20 to 200. In general, the smaller the number of topics, the more abstract will be the inherent topics identified. Similarly, the larger the number of topics, the more specific the topics identified will be. Thus, by varying the number of topics, we are implicitly simulating a hierarchical ontology: a pa rticular number of topics can be seen as a cut through the ontology. The topic probabilities obtained as a result of modeling user interests with LDA provide an explicit representation of each user and are used to construct the interest based features for the friendship prediction task, as described in what follows: suppose that A [1  X  X  X  n ] represents the topic distri-bution for user  X  X  X  and B [1  X  X  X  n ] represents the topic distribution for user  X  X  X  at a particular topic level n. The feature vector, F ( A, B ) for the user pair ( A, B )is feature vector is meant to capture the intuition that the smaller the difference between the topic distributions, the more semantically related the interests are. 4.2 Graph Based Features Previous work by Hsu et al. [9] and Caragea et al. [10], [11], among others, have shown that the graph structure of the LiveJournal social network acts as a good source of information for predicting friendship links. In this work, we follow the method described in [9] to construct graph-based features. For each user pair ( A, B ) in the network graph, we calculate in-degree of  X  X  X , in-degree of  X  X  X , out-degree of  X  X  X , out-degree of  X  X  X , mutual friends of  X  X  X  and  X  X  X , backward deleted distance from  X  X  X  to  X  X  X  (see [9] for detailed descriptions of these features). This section describes the dataset used in this work and the experiments de-signed to evaluate our approach of using LDA for the link prediction task. We have conducted various experiments with several classifiers to investigate their performance at predicting friendship links between the users of LiveJournal . 5.1 Dataset Description and Preprocessing We used three subsets of the LiveJournal dataset with 1000, 5000 and 10,000 users, respectively, to test the performance and scalability of our approach. As part of the preprocessing step, we clean the interest set to remove symbols, num-bers, foreign language. Interests with frequency less than 5 in the dataset are also removed. Strings of words in a multi-word interest are concatenated into a single  X  X ord, X  so that MALLET treats them as a single entity. For example, the interest  X  X rtificial neural networks X  is transformed into  X  X rtificialNeuralNet-works X  after preprocessing. Users whose in-degree and out-degree is zero, as well as users who do not have any interests d eclared are removed from the dataset. We are left with 801, 4026 and 8107 users in the three datasets, respectively, and approximately 14,000, 32,000 and 39,700 interests for each dataset after prepro-cessing. Furthermore, there are around 4,400, 40,000, 49,700 declared friendship links in the three datasets. We generate topic distributions for the users in the dataset using LDA; hyper-parameters (  X ,  X  ) are set to the default values.
We make the assumption that the graph is complete, i.e. all declared friendship links are positive examples and all non declared friendships are negative examples [10], although this assumption does not hold in the real world. The user network graph is partitioned into two subsets with 2 / 3 rd of the users in the first set and 1 / 3 rd of the users in the second set (this pro cess is repeated five times for cross-validation purposes). We used the subset with 2 / 3 rd of the users for training and the subset with 1 / 3 rd of the users for test. We ensure that the training and the test datasets are independent by removing the links that go across the two datasets. We also balance the data in the training set, as the original distribution is highly skewed towards the negative class. 5.2 Experiments The following experiments have been performed in this work. 1. Experiment 1 : In the first experiment, we test the performance of several 2. Experiment 2 : In the second experiment, we t est several predictive models 3. Experiment 3 : In the third experiment, graph based features are used We repeat the above mentioned experiments for the 5000 user dataset. The corresponding experiments are referred to as Experiment 4 , Experiment 5 and Experiment 6 , respectively. For the 10,000 us er dataset, we build predictive models using just interest based features (construction of graph features for the 10,000 user dataset was computationally infeasible, given our resources). This experiment is referred to as Experiment 7 . We use results from Experiments 1 , 4 and 7 to study the performance and the scalability of the LDA approach to link prediction based on interests, as the number of users increases. For all the experiments, we used WEKA implementations of the Logistic Regression, Random Forest and Support Vector Machine (SVM) algorithms. 5.3 Results Importance of the Interest Features for Predicting Friendship Links.
 As mentioned above, several experiments have been conducted to test the use-fulness of the topic modeling approach on user interests for the link prediction problem in LiveJournal . As expected, interest feature s (i.e., topic distributions obtained by modeling user interests) combined with graph features produced the most accurate models for the prediction task. This can be seen from Tables 1 and 2. In both tables, we can see that interest+graph features with 50% known links outperform interest or graph features alone in terms of AUC values 1 ,for all three classifiers used. Interesting re sults can be seen in Table 2, where inter-est features alone are better than graph features alone when only 10% links are known, and sometimes better also than interest+graph features with 10% links known, thus, showing the importance of the user profile data, captured by LDA, for link prediction in social networks. Furthermore, a compa rison between our results and the results presented in [21], which uses an ontology-based approach to construct interest features, shows that the LDA features are better than the ontology features on the 1,000 user dataset. As another drawback, the ontology based approach is not scalable (no more than 4,000 users could be used) [21].
Figure 3 depicts the AUC values obtain ed using interest, graph and inter-est+graph features with Logistic Regression and SVM classifiers across all num-bers of topics modeled for the 1,000 and 5, 000 user datasets, respectively. We can see that the AUC value obtained using interest+graph features is better than the corresponding value obtained using graph features alone across all numbers of topics, for all scenarios of known links, in the case of the 5000 user dataset. This shows that the contribution of interest features increases with the number of users. Also based on Figure 3, it is worth noting that the graphs do not show significant variation with t he number of topics used.
 Performance of the Proposed Appr oach with the Number of Users.
 In addition to studying the importance of the LDA interest features for the link prediction task, we also study the performance and scalability of the approaches considered in this work (i.e., graph-based versus LDA interest based, and com-binations) as the number of users increases. We are interested in both a) the quality of the predictions that we get for the LiveJournal data as the number of users increases; and b) the time and memory requirements for each approach.
From Figure 4, we can see that the predi ction performance (expressed in terms of AUC values) is improved in the 5,000 user dataset as compared to the 1,000 user dataset, across all numbers of topics modeled. Similarly, the prediction performance for the 10,000 user dataset is better than the performance for the 5,000 user dataset, for all topics from 20 to 200. One reason for better predictions with more users in the dataset is that, when we add more users, we also add the interests specified by the newly added users to the interest set on which topics are modeled using LDA. Thus, we get better LDA probability estimates for the topics associated with each user in the dat aset, as compared to the estimates that we had for a smaller set of data, and hence better prediction results. However, as expected, both the amount of time it takes to compute features for the larger dataset, as well as the memory required increase with the number of users in the data set. The amount of time it took to construct features for the 10,000 user dataset for all numbers of topics modeled in the experiments is around 14 hours on a system with Intel core 2 duo processor running at 3.16GHz and 20GB of RAM. This time requirement is due to our complete graph assumption (which results in feature construction for 10,000*10,000 user pairs in the case of a 10,000 user dataset) and can be relaxed if we rel ax the completeness assumption. Still the LDA feature construction is more efficient than the construction of graph features, which was not possible for the 10,000 user dataset used in our study. We have proposed an architecture, which takes advantage of both user profile data and network structure to predict friendship links in a social network. We have shown how one can model topics from user profiles in social networks using LDA. Experimental results suggest that the usefulness of the interest features constructed using the LDA approach increases with an increase in the number of users. Furthermore, the results sugge st that the LDA based interest features can help improve the prediction perfo rmance when used in combination with graph features, in the case of the LiveJournal dataset. Although in some cases the improvement in performance due to interest features is not very significant compared with the performance when grap h features alone are used, the fact that computation of graph features becomes intractable for 10,000 users or beyond emphasizes the importance of the LDA based approach.

However, while the proposed approach is effective and shows improvement in performance as the number of users increases, it also suffers from some limita-tions. First, adding more users to the dataset increases the memory and time requirements. Thus, as part of the future work, we plan to take advantage of the MapReduce framework to support distributed computing for large datasets. Secondly, our approach takes into account, the static image of the LiveJournal social network. Obviously, this assumption does not hold in the real world. Based on user interactions in the social network, the graph might change rapidly due to the addition of more users as well as friendship links. Also, users may change their demographics and interests regularly. Our approach does not take into ac-count such changes. Hence, the architecture of the proposed approach has to be changed to accommodate the dynamic nature of a social network. We also spec-ulate that the approach of modeling user profile data using LDA will be effective for tasks such as citation recommendation in scientific document networks, iden-tifying groups in online scientific communities based on their research/tasks and recommending partners in internet dating, ideas that are left as future work.
