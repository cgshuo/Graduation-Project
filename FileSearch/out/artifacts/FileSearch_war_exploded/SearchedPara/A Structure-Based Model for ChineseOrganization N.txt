 YUFENG CHEN and CHENGQING ZONG Institute of Automation, Chinese Academy of Sciences 1. INTRODUCTION Named entity (NE) expressions are words or phrases that name a specific en-tity [Chinchor and Marsh 1997]. Named entities X  X specially named persons, locations, and organizations X  X eliver essential meaning in human languages. Therefore, NE translation plays a very important role in multilingual process-ing, such as statistical machine translation (SMT) and cross-lingual informa-tion retrieval.

Generally, NEs occur very frequently in texts. Although many studies have been conducted on NE recognition and NE alignment, little research has been devoted to NE structure formulation and translation. As an essential com-ponent in multilingual processing systems, NE translation deserves greater attention than it receives as it is implemented by the traditional SMT system. One reason is that words or phrases extracted from bilingual sentence pairs are often inapplicable for NE translation, and the words contained in NE are domain specific and often need transliteration. The other reason is that an NE is not as sophisticated as a sentence because its denomination must follow a certain regulation. It is ineffective to translate NEs through exhaustive search during decoding, which would lead to spurious ambiguity.

There are two strategies for NE translation. One is to mine NE transla-tion pairs from the Web and extract NE pairs from the parallel or comparable corpora. This is essentially the same as translating an NE by searching its equivalence. The other is to directly translate an NE by word/phrase trans-lation or transliteration. Most previous studies focused on the first strategy, including the work by Huang et al. [2003], Feng et al. [2004], and Lee et al. [2006], all of which are limited by the coverage of the used corpus and the Web resource. Researchers using the second strategy for translation have com-monly adopted approaches similar to SMT without considering the particular structure of NEs. This approach is evident in Zhang et al. X  X  work [2005a].
Using the second strategy, we focus on directly translating NEs according to their inherent structures. Since different NEs types have different translation structures, different translation models for the different NE types need to be applied in order to achieve the desired outcome. Person name (PN) tends to be transliterated based on phonetic similarity or heterography; location name (LN) tends to be transformed by both semantic translation and phonetic transliteration [Chen et al. 2003]. The keyword of LN is usually translated based on its meaning, and the remaining words require transliteration. Because the structure of PN and LN is relatively simple, the reordering of their inside words is easy to be decided in translation, and the transliteration problem becomes the major problem. However, organization name (ON) is totally different. The structure of ONs is complex and usually nested, including PN, LN, or sub-ON. Therefore, ON is the most difficult to handle among all the NE types.

In this article, we aim to analyze the ON structure and learn the translation rules from the bilingual ON corpus and subsequently to build a translation model that can perform ON translation between Chinese and English.

In Chinese, ONs are numerous and diverse in their structures. Moreover, new ONs are constantly being created. Based on the statistics of Chinese news text released by the Linguistic Data Consortium (LDC2005T06 corpus), we found that 64% of ONs contained in the text are out of the NE dictionary (LDC2005T34 NE list), whereas these NEs usually contain frequently occur-ring words and only 8% of the words are out of vocabulary (LDC2002L27 lex-icon). Hence, the extraction of NE equivalence from the parallel/comparable corpus is insufficient for ON translation. It often fails to translate ONs that do not appear in the corpus or NE dictionary, even though they may contain very commonly used words. This leads us to believe that it is very important to understand how the Chinese words contained in an ON are organized in the English counterpart. This study is therefore different from traditional SMT by adding ON-specific linguistic information for ON translation.

As for SMT, there have been many effective translation models for sentence translation [Zong and Seligman 2005]. But these models are not suitable for NE translation. The phrase-based model can effectively perform translations but it is restricted to phrases that are common and short (generally, shorter than seven Chinese words), and it fails to satisfactorily deal with long-range reordering. Recently researchers,  X  for example, Wu [1997], Chiang [2005], and Liu et al. [2006]  X  have focused on syntax-based methods that attempt to achieve reordering at different levels by modeling the source or target sentence with syntactic information.

Inspired by the syntax-based model for sentence translation, this article addresses the structure-based ON translation by proposing a special ON translation model independent of the translation models used for common sentences. We analyze the parallel ON corpus and find the inherent structure of ONs.  X  X hunk X  is the unit required to construct an ON. Three types of ON chunks are defined according to the alignment of the Chinese-to-English ON pair, and then a chunk-reordering formula is observed. Therefore, we propose a hierarchical structure-based translation model for Chinese organization names. It will be evident that this newly proposed model can be integrated into an SMT system to improve the overall quality of translation.

The structure-based ON translation model is composed of an automatic chunking model and a chunk-based synchronous context-free grammar (CFG) model. In this training process, we aim to estimate the chunking model para-meters and extract CFG rules for the translation model.

The remainder of this article is organized as follows: Section 2 reviews related works. In Section 3, we analyze the ON structure by defining three types of chunks and explain the rationale for a structure-based translation model. In Section 4, we propose a structure-based ON translation model. The training process is described in Section 5. Section 6 presents various experiments as well as the corresponding discussion. Finally, the conclusion is drawn in Section 7. 2. RELATED WORK In the past few years, researchers have proposed many approaches to NE translation, such as word/subword translation or transliteration [Stalls and Knight 1998]. Unfortunately, applying the word-based source-channel model to NE translation usually leads to unsatisfactory results. As a consequence, recent studies have focused on NE alignment (translingual equivalence ex-traction). Moore [2003] developed an approach to learning phrase translations from the parallel corpus based on a sequence of cost models. Huang et al. [2003] described a multifeature NE alignment model to extract NE equiva-lences, based on which NE translation dictionary was constructed. Kumano et al. [2004] proposed a method for extracting English-Chinese NE pairs from a content-aligned corpus. A maximum entropy model for NE alignment was presented by Feng et al. [2004]. Sproat et al. [2006] investigated the Chinese-English NE transliteration equivalence with comparable corpora. Lee et al. [2006] proposed a new approach to aligning bilingual NEs in a bilingual corpus by incorporating a statistical model with multiple sources. The translation approach that depends on NE alignment and dictionary construction has achieved relatively high accuracy on frequently occurring NEs. However, it fails to cover NEs that do not occur in the bilingual corpus. Further, the performance of ON alignment is always unsatisfactory because a distinguishing characteristic of an ON lies in its highly complex structure, which involves great variety.

There still exist many issues surrounding NE translation that call for fur-ther investigation. In an effort to assemble rare NEs, Al-Onaizan and Knight [2002] established a Web resource to rescore translation candidates. Huang et al. [2004] developed an approach combining phonetic and semantic sim-ilarity with a view to translate rarely occurring NEs. Shao and Ng [2004] presented a hybrid method to mine new translations from Chinese-English comparable corpora, combining both transliteration and context information. Zhang et al. [2005b] mined translations of out-of-vocabulary (OOV) terms from the Web through cross-lingual query expansion. Chen and Chen [2006] devel-oped a three-step approach based on the Google search engine to deal with the backward Chinese-to-English translation.

Obviously, an NE dictionary based on extraction of NE equivalences will never provide a complete rendering of the NE translation from English to Chi-nese. In order to solve this problem, automatic translation and translitera-tion methods are adopted in company with the equivalence extraction. For transliteration modeling, Meng et al. [2001] and Gao et al. [2004] studied a phoneme-based transliteration model for the English-Chinese NE equiva-lence. Transliteration rules were trained from a large bilingual transliteration lexicon [Oh and Choi 2005]. Li et al. [2004, 2007] presented a joint source channel model for transliteration, and automated the semantic translitera-tion process for personal names. For the automatic translation, Zhang et al. [2005a] proposed a phrase-based context-dependent joint probability model for automatic translation, which was similar to phrase-level translation models in SMT.

However, little research has been focused on NE inherent structure that can be utilized to translate NEs. Chen et al. [2003, 2006] studied formu-lation and transformation rules for English-Chinese NEs. They adopted a frequency-based approach to extract keywords of NEs with or without dictio-nary assistance, and constructed transformation rules from the bilingual NE corpus. Their study focused on transformation rules with a view to distin-guishing translated parts from transliterated parts. But the performance of the rule-application in NE translation was not described where they pointed out that the keyword pairs of organization names were too numerous to allow the formulation of suitable rules. In an attempt to resolve this difficulty, we further investigate the structure of organization names. This, in turn, leads to the next step of extracting the translation rules and developing a structure-based model for ON translation. 3. ANALYSIS OF THE STRUCTURE OF ORGANIZATION NAMES 3.1 Statistical Characteristics of Organization Names For statistical analysis of ONs, we first follow the division in Chen and Chu [2004] where one ON is divided into two parts: the name part and the keyword.
This article adopts Chinese-to-English name entity lists (LDC2005T34) for analysis that were released by the Linguistic Data Consortium (LDC). The lists contain two ON corpora. One has 54,000 industry proper-name pairs (Indus corpus is short for  X  X dc propernames industry ce v1.beta.txt X ), including vast numbers of corporation names, hotel names, and various business entities. ONs of this type are simple in structure and the name part is best served by transliteration, such as ~ ) l  X  (Cadbury Company) X , in which the name part ~ ) is transliterated. The sec-ond corpus has 30,000 organization proper-name pairs (Org corpus is short for  X  X dc propernames org ce v1.beta.txt X ), containing mostly state institution names and names of local authorities. ONs of this type are more complex in structure, because the name part often contains many more modifiers.
Based on the two corpora, we get some raw statistical data whose differ-ences are summarized in Table I.  X  X hn-ON-Length X  denotes the length range and the average length for a Chinese ON in words and in characters. In the case of a single ON pair, if the Chinese ON is translated into English word by word in order, we consider the Chinese-to-English word alignment of the ON pair to be monotonic. Otherwise we consider the alignment to be a reordering list.  X  X eordering Count X  denotes the count of the Chinese ONs that need the reordering operation when they are translated into English.  X  X ransliteration Proportion X  denotes the proportion of the words that need to be transliterated among the words contained in ONs.

As shown in Table I, only 6% of ONs in the Indus corpus need reorder-ing. Moreover, the reordering is relatively simple because the keyword of an industrial ON usually tends to locate in the rightmost or leftmost positions, that is, at the end or the beginning of the name when translated into Eng-lish. For example, in - X   X  L (Bank of China), X  the keyword  X  L (Bank) X  is translated first, followed by - X  (China) X  in translation. Nevertheless, 44% of ONs in the Org corpus need reordering when they are translated into English. The name parts of ONs in the Org corpus contain many modifiers and usually need reordering in translation. We hypothesize that the words needing reordering in translation is a consequence of the inherent structure of an ON.
On the other hand, the transliteration proportion in the Indus corpus is much higher than that in the Org corpus. The reason is that ONs in the Org corpus are usually composed of frequently occurring words or phrases that do not need transliteration. But many industrial names in the Indus corpus usually need transliteration and the transliteration is often heterographic, as in ~ ) ( JiBaiLi , Cadbury) X , where the italicized word is the Chinese pinyin transcription. Most transliterations of the inclusive words can be referred to an NE dictionary or Web resource.
 Drawing upon the statistics, it is possible to find that the ONs in both the Org corpus and Indus corpus have inherent structures that can be utilized for translation, even though the structure of the latter is relatively simple. As for an ON, its transliteration problem is a part of the whole structure, which can be separately considered. Since the transliteration model has been given much attention in previous research, it is worthwhile to investigate the ON structure and propose a translation model. 3.2 Structural Analysis of Organization Names Organization name belongs to a compound noun with the  X  X ttribute + keyword X  type. Compared with PN and LN, ON is much more complex in structure. At present, there is no uniform definition and translation criterion for organization name. From our analysis, a typical structure of Chinese ON is shown in Backus-Naur Form (BNF) as follows:
ON ::= { [location name] [suborganization name] [ordinal | cardinal number] [person name] [other modifiers] } * &lt; organization keyword &gt;
Here, square brackets  X  X   X  ] X  denotes the optional item 1 ;  X  &lt;  X  &gt;  X  indicates the required item;  X  {  X  }  X  indicates that none or several items will be selected. Each item included in {  X  } * is a modifier for the keyword, and  X  X ther modifiers X  repre-sents other characteristics of an organization: for example,  X  (industrial) X ,
Y  X  (educational) X , etc. Furthermore,  X  X rganization keyword X  is the last or-ganization appellation. For example: (a) { [  X   X  ;  X  ' f (Chongqing Medical University)] [ , (the first)]
As Example (a) shows,  X   X  ;  X  ' f (Chongqing Medical University) X  is the inclusive suborganization name; , (the first) X  is the ordinal number; D ^ (affiliated) X  is the modifier, and ; b (hospital) X  is the keyword. According to the BNF, Chinese ONs can be classified into two categories. The first category is multi-keyword-ON that contains a suborganization name. Therefore, it usually contains more than one keyword. For instance, Example (a) includes two keywords, ' f (university) X  and ; b (hospital) X . The second category is single-keyword-ON that does not contain a suborganization name. One multi-keyword-ON can be divided into several single-keyword-ONs (the division is described in Section 4.1). The structural analysis below is based on
Based on the word alignment of Chinese-English ON pairs, we analyze the translation rules between Chinese ONs and their English equivalences. Because words contained in Chinese ONs are mostly content words, each of them corresponds to some words in the English part. First, a definition is given for convenience.

Definition 1. Given a source-target ON pair { S , T } , there is a source word sequence s j i that ranges from i to j . For any sequence included in s j i ranging from positions k 1 to k 2 ( i  X  k 1  X  k 2  X  j ), its corresponding equivalence ranges ered as a monotone phrase 3 . Meanwhile, both the monotone source phrase s j i the word alignment within this kind of phrase is monotone.
 According to Definition 1, we can extract phrase pairs from one ON pair. phrases of Example (b). (b) - X  X  E  X   X  A - X  (China International Center for Exchange with For-
As shown in Figure 1,  X  X   X  ] X  denotes one phrase. Based on the alignment, four phrase pairs are found: { - X  X  E , China International } , {  X  , with Foreign Countries } , {  X  A , Exchange } , and { - X  , Center for } . Therefore, which may be treated as a translation pattern. We randomly select 10,000 Chinese-English ON pairs from the Org-corpus, and sum up the translation patterns by calculating their corresponding frequency. The top seven patterns with high frequency are displayed in Table II.

Theoretically, there exist numerous translation patterns. However, these patterns could be simplified, differing from sentence translation, because an ON is  X  X ttribute + keyword X  type in a definite structure. The semantic relation-ship between the contained words determines their corresponding positions in the target ON. By considering the locations of the phrase pairs in each transla-tion pattern, it is possible to find that the span of each phrase pair is restricted within a certain range. Therefore, the source ON can be divided into several chunks, where the word reordering is limited within each chunk during trans-lation, and then the chunks are reordered to obtain the translation output.
Based on the analysis, we propose a  X  X hunk X  unit to analyze the inherent ON structure. According to the syntactic function of different phrases in one ON, three types of chunk pairs are designated to sum up all the ON translation patterns. Namely, an ON comprises three potential chunks according to the following definition.

For an ON pair, three types of chunks in the Chinese part are identified in turn according to Definition 2 based on its phrase pairs. Note that one or two types of chunks may be absent in the ON.

Definition 2. (1) Regionally Restrictive Chunk (RC). It is the supreme modifier whose align-(2) Keyword Chunk (KC). It states an essential appellation for the ON and its (3) Middle Specification Chunk (MC). This is the second important modifier
According to Definition 2, the potential chunk sequences of Chinese ONs are (5) C RC ; (6) C MC ; and (7) C KC , where C X denotes the chunk in the Chinese part. At the same time, the corresponding chunks E X in the English part are also identified. Therefore, each ON pair is divided into several chunk pairs (at most three). Generally, an ON contains more than one chunk, yet the instances of (5), (6), or (7) usually appear under the condition that these ONs are abstract, abbreviated, or partially recognized.

Actually, each type of chunk clusters words semantically for translation, ac-cording to the words reordering range in the alignment. The decomposition of ON in terms of the  X  X hunk X  units covers all different ON translation patterns. For instance, if the order of chunks and the inclusive words are all preserved in translation, this translation pattern is monotone, { s , t } , that is, there is only one phrase pair which is the dominating translation pattern with the highest frequency. Table III shows the structural analysis of the examples, according to Definition 2.

After identifying the three types of chunks, we consider the positions of the three chunks in different translation patterns. As Table III illustrates, it is possible to find the chunk-reordering formula based on a large number of bilin-gual ON pairs: the position of RC is the first to be allocated, because it is put at the beginning or the end of the translation result. The position of the MC and the KC is always adjoining. Moreover, if there is reordering between two chunks, the translation usually needs a preposition to link them, such as  X  X or X  or  X  X f. X  This above finding can be adopted as the guideline for the ON transla-tion model.
 3.3 Motivation for the Structure-Based Translation The definition of the three chunks well describes the structure information of ON and represents the words X  division in translation. Different chunks have different translation characteristics, and the chunk-reordering formula for their combination achieves the whole translation. In other words, the reorder-ing of chunks and their words follows a certain formula in the English part.
As shown in Figure 2, the translation process of Example (b) is transformed into three stages: (1) the ON is divided into RC ( - X  X  E ), MC (  X   X  A ), and KC ( - X  ); (2) the words are translated and reordered inside each chunk (for example,  X  is transposed with  X  A in MC); and (3) the chunks are reordered.

On the basis of this observation, we propose a structure-based transla-tion for Chinese ONs by the following steps: and (1) the Chinese ON is automatically chunked; and (2) each chunk is translated and reordered by syn-chronous CFG rules.

The chunking parameters and CFG rules are learned from the training process. We apply Definition 2 to training data (ON pairs) for structural analysis X  X hat is, identifying chunk pairs X  X nd then estimate chunking pa-rameters as well as extract CFG rules.

The next section introduces the structure-based ON translation model. 4. STRUCTURE-BASED TRANSLATION MODEL FOR ORGANIZATION NAME On the basis of our discussion thus far, our approach to Chinese-to-English ON translation may be decomposed using two submodels: the chunking model and the chunk-based CFG model. Therefore, our proposed ON trans-lation method first divides the source ON into chunks by the chunking model (Section 4.1); and second, translates and reorders chunks by the chunk-based CFG model (Section 4.2), where the CFG rules are described (Section 4.2.1) and the CFG derivation is presented (Section 4.2.2). The framework of the structure-based translation model will be presented in Section 4.3. 4.1 Chunking Model As we have mentioned, there are two categories of ONs. A multi-keyword-ON should be divided into single-keyword-ONs according to the keywords it contains. To do this, the decomposition module works on a multi-keyword-ON from left to right. If a keyword is identified, the keyword with previous words is extracted as one single-keyword-ON. In Example (a),  X   X  ;  X  ' f , D ^ ; b (The First Affiliated Hospital of Chongqing Medical University) X  is divided into  X   X  ;  X  ' f (Chongqing Medical University) X  and , D ^ ; b (The First Affiliated Hospital), X  according to the two organization keywords ' f (university) X  and ; b (hospital) X .
 Let O denote a Chinese single-keyword-ON, which is composed of n ( n  X  1) Chinese words (Performed segmentation) or characters (unsegmented), o , o 2 ,. . . o n . The task of chunking is to find the most likely sequence of chunks: C * = C 1 ... C m ( m  X  3, C i  X  { C RC , C MC , C KC } ) that maximizes the probability p ( C | O ). Here, the Bayesian rule is applied to rewrite p ( C | O ) as:
Now it is possible to make two assumptions for chunking phrases: (1) the chunk-tag sequence could be modeled with the first-order Markov chain, and (2) words inside each chunk are independent of other chunks and only depend on their associated chunk-tag. So the chunking model can be specified as the following equation: where p ( C ) is the chunk contextual model. All parameters of Equation (1) are trained from bilingual ON pairs, described later in Section 5. 4.2 Chunk-Based CFG Model 4.2.1 Chunk-based CFG Rules. The model is formally based on a syn-chronous CFG grammar [Lewis and Stearns 1968; Aho and Ullman 1969]. Following the synchronous CFG presented in Chiang [2005], the elementary structure of synchronous CFG is rewriting rules with aligned pairs of right-hand sides: where X is a nonterminal, and  X  and  X  are both strings of terminals and nonterminals. In our model,  X  and  X  contain terminals and one nonterminal in the chunk unit, and  X   X   X  is a one-to-one correspondence between chunk nonter-minal occurrences in  X  and the one in  X  . Rewriting begins with a pair of linked start symbols. At each step, two corresponding nonterminals are rewritten using the two components of a single rule.

Thus according to the bilingual alignment, it is possible to formalize the chunks of Example (b) in a synchronous CFG as:
For differentiation, CFG rules (2) and (3) take one chunk as the terminal respectively, which are regarded as common rules, whereas the last rule, (4), takes two chunks as the terminal, which can be considered as a template with a variable Hu et al. [2006]. To highlight the contrast with common rules, we call a rule with two chunk terminals as a template .

A log-linear model used here is based on the model of Och and Ney [2002] to estimate the weight of the above rules by minimum error rate training.
Let  X  i denote features defined on rules. In this model, four features are used:  X  X he probability distribution of the rule, p (  X  |  X  ) and p (  X  |  X  ).  X  X he lexical weights, p w (  X  |  X  ) and p w (  X  |  X  ) [Koehn et al. 2003]. Templates and common rules with weights are generated from a bilingual ON corpus without any syntactic information. However, the following five types of rules need to be added:
Rule (5) and Rule (6) are  X  X lue X  rules with weight one. Rule (5) is applied to multi-keyword-ONs, of which their contained single-keyword-ONs should be rewritten separately. Native Chinese speakers always regard the preceding ON as more general, so they usually place it at the end of the translation out-put. For example, Example (a) is translated as  X  X he First Affiliated Hospital of / Chongqing Medical University. X  Thus Rule (5) describes the inversion. Rule (6) combines a sequence of chunks to form an ON, and  X  O  X  is the start-symbol for the adopted CFG.

Rules (7), (8), and (9) are three special decomposed chunk-based rules, ap-plying to the case when no such rule for RC, MC, or KC is found in the training data. In these formulas, the reordering of chunks is manually defined and the the best translation output of C RC , C MC , and C KC on the word level. These three rules suggest that the positions of nonoccurring chunks are monotone in translation by our definition.

Whether the translation of words in the RC is monotone or reordered de-pends on the translator X  X  preference. For convenience, in our approach it is set as monotone, as shown in Rule (7). The equation is expressed as follows:
Where, C RC = c RC part of c RC ONs.

Word translation in MC is not always monotone. Hence, it is necessary to reorder the words in the MC according to the reorder model in Rule (8). The model follows the distortion model [Koehn et al. 2003] with an appropriate value for the parameter  X  = exp(-1) in the given experiment. The reorder model is described as the following formula: where a i is the start position of the Chinese words that are translated into the i
English word e i in the MC, and b i  X  1 denotes the end position of the Chinese words translated into the ( i -1) th English word e i  X  1 in the MC. In Rule (9), the translation of the KC is also fixed to be monotone as the RC. So, we have:
The common rules and templates are generated from the corpus. Moreover, by adding special rules, all possible conditions are satisfactorily covered. 4.2.2 CFG Derivation. Most words or chunks that constitute an ON in the bilingual corpus are infrequent, so there is a problem of sparse data severely hampering the language model. Hence, the language model is not adopted in our ON translation model. The CFG derivation is based on each rule with highest probability, according to the chunk-reordering formula observed in the structural analysis. The aim is to choose each rule with the highest-probability weight to yield the highest-probability derivation following certain steps.
As a whole, the entire CFG rule set contains four types of rules: common rule, template,  X  X lue X  rule, and special rule. All of them are based on  X  X hunk X  unit but they are hierarchical in derivation. For instance, a template contains more items than a common rule and only the translation of the variable needs to be confirmed, the template matching ensures a correct translation more quickly and efficiently, which will be shown in the experiment. In this model, a template is therefore considered more preferential than a common rule in derivation.
 As shown in Table IV, the hierarchy gives the model the option during the CFG derivation: beginning with the  X  X lue X  rules, it first matches the templates, and then common rules. If they all fail, the model falls into word-level trans-lation by special rules.
 Given an ON, we list five steps for its translation by CFG derivation in Figure 3, and these steps are defined as the ON derivation algorithm. The derivation is hierarchical according to different types of rules, and steps 3-5 are based on the chunk-reordering formula described in Section 3.2.
The ON derivation algorithm covers translation of all the ONs, of which the chunk sequences have seven potential types, as mentioned in Section 3.2. Practically speaking, this hierarchical derivation shows significant advantage for the ONs that contain more than one chunk. However, translation for the ON that contains only one chunk uses the special rules, the same as a normal word-based translation approach. For example,  X   X   X   X   X  W  X  (Russia is our home) X  is chunked as the  X  X C X , which is translated by Rule (8).
Figure 4 shows the derivation of Example (b) following the ON derivation al-gorithm, under the condition that template matching fails and there are three available common rules for derivation. If one ON does not contain RC, MC, or KC, its derivation elides their corresponding steps.

Restricted by these steps, the model requires few decoders, but achieves a highly accurate translation, because the process of detecting the three chunks and following the above steps is the same as pruning the search space, with the same aim: finding the best derivation. The chunking and derivation process is somewhat similar to monolingual parsing constraints in other grammar-based models [Wu and Wong 1998]. However, it is based on the chunk-reordering formula of the ON inherent structure.

As a whole, the chunk-based CFG derivation with five steps is an attempt to effectively determine the optimal route of ON translation according to its typical structure. 4.3 Framework for Structure-Based ON Translation Model A Chinese ON is translated as shown in Figure 5. Figure 5 summarizes the framework of the overall process for ON translation, which is performed via a two-stage model. The proposed model integrates hierarchical CFG rules,  X  X lue X  rules, templates, common rules, and special rules, by a defined ON deriva-tion algorithm. The CFG rules are ranked according to the covered unit, from chunk to word level, which can most completely cover the Chinese ON trans-lation. The CFG model is similar to the hierarchical phrased-based model [Chiang 2005]; however, the model we propose here is based on the ON struc-ture, the proposed chunk-unit, and the hierarchical derivation according to a five-step process. 5. TRAINING The aim of the training process is to obtain the parameters for both the chunk-ing model and CFG rules. Figure 6 illustrates the overall training architec-ture. Based on ON pairs, we first perform word alignment, and then iden-tify the three types of chunk pairs according to structural analysis, which we described in Section 3.2. Based on the chunk pairs, we can determine the chunking parameters, and extract templates and common rules. The genera-tion of word-based probability follows the former method [Koehn et al. 2003]. On the whole, there are two main tasks to be handled: (1) word alignment of ON pairs (see Section 5.1); and (2) templates and common rules extraction (see Section 5.2).
 5.1 Word Alignment of ON Pairs Word alignment of ON pairs is somewhat different from word alignment of bilingual sentences, mainly due to the difficulties caused by abbreviations and transliteration problems. In this study, we tried two approaches with the aim of achieving high-quality word alignments. Approach I is similar to traditional phrase extraction for SMT, but it adds an alignment hypothesis. Approach II is a frequency-based method that combines the result of Approach I in order to improve the alignment quality. 5.1.1 Alignment Approach I. Starting with a bilingual ON pair list, we ran GIZA++ toolkit [Och and Ney 2002] on the corpus in both directions: Chinese-to-English and English-to-Chinese. This produces two word alignments in both directions. As a test, GIZA++ was applied to the 4,000 ON pairs from the Org corpus as described in Section 3. The result, after a manual dou-ble check of the alignments, was that more than 50% alignments made by GIZA++ were wrong. This was especially evident in the English-to-Chinese alignment.
 With further analysis it became clear that words included in Chinese ONs are always content words, as was seen in Examples (a) and (b). Each content word has a concrete meaning that should be translated into at least one English word, but in the GIZA++ operation on English-to-Chinese, at most one English word is allowed to be aligned with a Chi-nese word. So alignment errors are inevitable. However, the alignment in the English-to-Chinese translation is more satisfactory when it deals with words that need transliteration or are wrongly segmented. For example,  X  (Xiao) / d (Tang) / q (Shan), X  denotes a segmentation symbol. The three Chi-nese characters should be one word but are segmented with error. In the English-to-Chinese translation, the three characters were correctly aligned as one English word,  X  X iaotangshan X , whereas in the Chinese-to-English trans-lation they failed.

Because some words used in an ON occur infrequently in the whole corpus, some word alignment errors may result in numerous mistakes. Obviously, selecting correct alignments and discarding incorrect alignments to achieve the utmost precision is a problem that requires attention.

Considering the fact that ONs always contain content words, we propose a pretreatment that will filter the alignments: In the Chinese-to-English translation, a specific alignment should be considered as a hypothetically cor-rect alignment, in which each Chinese word is aligned to one or several con-secutive English words. The same holds for English-to-Chinese translation. In Example (b), each Chinese word aligns to one or several consecutive English words. Hypothetically, this is a correct alignment. According to this hypothe-sis, we need only select the hypothetically correct alignment from the respec-tive results of the Chinese-to-English translation and the English-to-Chinese translation of GIZA++. Thereafter, both alignments can be reconciled.
For an ON, if its alignments in the two translations are both hypothetically correct, it is now possible to apply a heuristic approach [Koehn et al. 2003] to unite the two alignments. This allows greater assurance for the alignment of the pairs, but the quantity of such alignments is insufficient. Consequently, Alignment Approach II based on Alignment Approach I must be applied to improve the overall performance. 5.1.2 Alignment Approach II. Segmentation errors and alignment errors are inevitable through GIZA++. Furthermore, the abbreviations that common-ly occur in ONs cannot be captured by Approach I, which means we must invoke Alignment Approach II to obtain higher quality. In Approach II, we calculate the scores of all candidate segment alignments within ON pairs, and then obtain the optimal word alignment for a given ON pair with a maximum score.

First, to measure the alignment score of each Chinese segment and its Eng-lish equivalent, we borrow the tf  X  id notion from information retrieval. Fol-lowing Chen et al. X  X  [2003] formula, let { O , E } denote one ON pair from the bilingual ON corpus. In this case, some Chinese segment o  X  O should be aligned to some English segment e  X  E . If some functional words, such as  X  X he, X   X  X or, X   X  X f, X  etc., occur in the English translation, they will be set with their adjoining words as a single segment, in order to ensure that each Eng-lish word aligns with a Chinese segment. Because Chinese segmentation has problems, it is more efficient to start the frequency computation from the Eng-lish ON. Let us assume there are N English segments, and the term frequency ( tf ) of a Chinese ON segment o in e is described by the number of occurrences of o in e . ( df ) of o is the number of English segments into which o is trans-1), and | o | denotes the length of the Chinese ON segment. In addition, p ( o | e ) and p ( e | o ) are the probability results from the hypothetically correct alignment described in Section 5.1.1, and we can add lexicons. Those three factors of fre-quency featuring within the square bracket of  X  1 are directly adopted from the research of Chen et al. [2003]. Here, in order to combine the frequency feature and translation probability feature, we use a general log-linear model: where  X  1 ,  X  2 ,  X  3 are empirically chosen to discriminate correct and incorrect alignment to achieve better accuracy and are set as 0.5, 0.25, and 0.25 respectively in our experiments. o i is one of all possible Chinese segments in e . Based on the score of each possible segment pair, the optimal alignment A opt between Chinese and English in one ON pair is obtained by the following greedy approximation algorithm [Huang and Vogel 2002]: (1) Initialize ON-Aligned as an empty set, and set all possible ( o , e ) segment-(3) Move the topmost pair ( o , e ), that is the pair with the maximum score, from (4) Remove all ( o ,  X  ) and (  X  , e ) from the segment-pairs. (5) Repeat from step 3 until the set of segment-pairs is empty. Then the opti-Empirically, this algorithm usually finds the word alignment of an ON pair with a maximal score. 5.2 Generating Chunk-Based CFG Rules from ON Pairs 5.2.1 Chunk Identification. To extract chunk-based CFG rules (templates and common rules), chunk pairs should be generated in advance. This process is the same as ON structural analysis, detailed in Section 3.2. Based on the word alignment of an ON pair, we obtain its monotone phrase alignment ac-cording to Definition 1, and then identify the three types of chunk pairs ac-cording to Definition 2. To determine the Chinese location name and keyword, we match a location name list and a keyword list, which are extracted from the LDC corpus and lexicons using a frequency-based approach [Chen et al. 2006], partially via manual checking.

Actually, within all the training data of ON pairs, Chinese chunks are iden-tified and their English equivalent, are respectively fixed in the ON pair ac-cording to Definition 2. If words in the English chunk are not inconsecutive, we utilize these ON pairs to extract templates only. ON pairs of this type are less than 0.1% of all the training data.
 chunking model are generated. 5.2.2 Extraction of CFG Rules. Based on the chunk-identified ON pairs, we can generate the common rules and templates by applying Procedure 1 and Procedure 2 respectively.
 Procedure 1. Given an ON pair { O , E } after chunk identification, O = C RC C MC C KC , E is the combination of E RC , E MC , and E KC . Here, C RC , C MC , and C KC denote the RC, MC, and KC, which are possibly contained in the source ON, and E X denotes the corresponding English translation of C X . (3) If { C KC , E KC } is an initial pair of the KC, then the preceding chunk is to be Procedure 2. Given an ON pair { O , E } after chunk identification, O = C RC C MC C KC , E is the combination of E RC , E MC , and E KC . If { C X , E X } ( X  X  ( RC , MC , KC ) is an initial chunk pair, such that  X  =  X  1 C X  X  2 and  X  =  X  1 E X  X  2 , then sequences or null.
 For example, there is an ON pair { C RC C MC C KC , E MC E KC E RC } , where { C RC , E
RC } , { C MC , E MC } , and { C KC , E KC } are the three contained initial chunk
Templates are not as flexible as common rules, but in some cases, generat-ing templates will avoid errors introduced by segmentation or alignment. For example, {  X  / RC -/ MC ; f b / KC , Beijing/ RC College of/ KC Traditional Chinese Medicine/ MC } is an ON pair after chunk identification, where -; (Tradi-tional Chinese Medicine) X  should be one word, but were aligned in error. So the chunk identification and extracted CFG common rules are both wrong: By following Procedure 2, the template is generated as X  X  &lt; X -; f b , X College of Traditional Chinese Medicine &gt; . It turns out to be right, avoiding the alignment error.

According to the above scheme, the common rules and templates are gener-ated from ON alignments. Such rules based on chunking are refined without any ambiguity. Therefore, there is no filter for the grammar. The probability and lexical weight of the extracted rules are estimated by the maximum like-lihood estimation algorithm following Koehn et al. X  X  [2003] method. 6. EXPERIMENTS AND DISCUSSION Two set of experiments were conducted for Chinese-to-English ON translation. In the first, we evaluated the proposed ON structure-based model by evaluat-ing the translation accuracy in a blind test set, using two training methods respectively. In the second, we assessed the improvement of the SMT system X  X  translation quality by adding the ON translation model. 6.1 Translation Model for Organization Names The first experiment used Chinese-English bidirectional Name Entity Lists v1.0 (LDC2005T34) released by the LDC. (The bilingual NE corpus is com-piled from Xinhua X  X  database, including the person names, location names, and organization names, etc.) Since person and place names are mostly translit-erated, we only extracted the categories of organization, industry, press, and international organization to form a training set. First, we performed a quick proofreading to correct some errors and remove the following types of entries:  X  X he duplicated entry  X  X he entries whose English translation contains one or more non-English words
We thus obtained a total of 68,960 ON Chinese-English pairs as the final training set. The number of Chinese words contained in one ON ranges from one to fourteen, most of which fall in the range of two to seven. We ran the training process described in Section 5 on the training set and then compared the two alignment approaches. In Approach I, source ONs were presegmented using an in-house segment system with an 81,000-word list. Table V shows the results using the two approaches. GIZA++ outputs are proved so unsatis-factory that only hypothetically correct alignments were considered, hence the extracted rules based on Alignment Approach I are considerably fewer. Conse-quently, Approach II predominates. The alignment result would directly affect the translation performance.

Moreover, we obtained a keyword list from the training data based on Align-ment Approach II, which contained 2,840 unique entries. A location name list included 150,200 entries, which were extracted mostly from both the training data and the place name entries in the LDC2005T34 corpus. The two lists, covering almost all the keywords and the location names in the training data partially via manual checking, were prepared for chunk identification in train-ing. As entities are countless and new words occur all the time, the lists could not cover all keywords and location names; consequently, some chunking er-rors occur. However, these errors are minimal and affect the translation per-formance only indirectly because the ON translation model is hierarchically based on word, chunk, or template.

For evaluation purposes, we used the meaning adequacy metric for subjec-tive evaluation. Here,  X  X dequacy X  refers to the degree to which the translation preserves the original information or meaning in the source ON. Four degrees of the metric are shown in Table VI with short explanations.

For the Chinese ONs in the test data, only one reference translation is avail-able, and it is very difficult to achieve a completely identical result in English even using manual translation. It means the 4th degree alone is not capable of assessing the accuracy. Results achieved with the 3rd or 4th degree can both be regarded as satisfactory. Results of the 1st and 2nd degrees are considered wrong. Two human evaluators to judge the result according to the meaning adequacy metric in Table VI. The kappa coefficient (K) for human agreement rate is 0.92, which is adequate.

There were 432 ONs randomly selected from the LDC2005T34 corpus as the test data, not overlapping with the training data. Each of the ONs contained between 2 and 9 words. The ONs consisted of a total of 1,506 Chinese words. Although the ON structure is finite in chunk units, the vocabulary it contains is large, making it necessary to add the LDC Chinese-English Translation Lex-icon (Version 3.0) to cover more word translations via special rules. Next, we tested the ON translation model, and measured each English output accord-ing to the four degrees. Finally, we calculated the proportion of each degree, resulting in the average of the measurements.

First, we chunked the test data, with an accuracy of 92% (segmented) and 96% (unsegmented). Second, we conducted experiments on the data with CFG rules produced by Alignment Approach I and Approach II. The phrase-based MT system developed by a local laboratory was our baseline system so we could show the superiority of the proposed ON translation model. The baseline system was based on a log-linear model with the following features, analogous to Pharaoh X  X  default feature set: Phrase translation probabilities, and length penalty [Koehn et al. 2003]. The parameters of this system were trained by a minimum error rate training method using the same training data. We made a comparison by gauging the difference between the translated result with ON word segmentation and the one without word segmentation. Furthermore, we considered the preference of templates to use in the experi-ment, to validate the efficiency of hierarchical derivation.

Table VII shows the accuracy and error rate for each degree on experiments with Alignment Approach I. Similarity, Table VIII shows the accuracy and er-ror rate for each degree on experiments with Alignment Approach II. Table IX compares the translation performance with and without template preference. In these tables,  X  X aseline + Lex X  denotes the baseline performance adding the lexicon;  X  X N X  means using only the ON translation model;  X  X N + Lex X  means using the ON translation model and the lexicon to assist in word translation;  X  X eg X  means performing segmentation on the ON before translation, whereas  X  X nseg X  means an unsegmented translation.

From the results presented in Tables VII, VIII, and IX, the following facts are clear: (1) The performance of the proposed model is measurably better than the base-(2) The performance of the model with Alignment Approach II is remarkably (3) Comparing the results between the ON model and ON + Lex model, it can (4) Performance without word segmentation is better than that with word seg-(5) The model with preferential template matching achieves better perfor-
As shown in Table VIII, the ON translation model reaches an accuracy of 93.75%, assisted by lexicon. We analyzed 27 erroneous translation results, and Table X shows the top four error types with their corresponding percentages.
According to our analysis, primarily the following error types attribute the wrong results:
In Example 1 of Table X, the proposed model tends to translate literally, but ONs cannot always be translated literally. There may be some insertion or deletion operations in translation. In the reference translation,  X   X   X  is removed and  X  X n Charge of  X  is inserted. This type of error is the majority of all translation errors.

In Example 2,  X   X   X  X   X   X   X  should be the Keyword Chunk, so  X  X ational X , the translation of  X   X   X  , X  should be connected with  X  X aboratory X , whose trans-lation is  X   X   X   X  . X  However, the chunking model incorrectly set  X   X   X   X  as the Middle Chunk. An ambiguity sometimes occurs between chunks, and then a chunking error will affect the subsequent CFG derivation and, consequently, the final output.

In Example 3,  X   X   X  is the abbreviation of  X   X  ~  X , but it was translated to  X  X tation X  by error. Many ONs contain OOVs or common words that cannot be accurately translated with their precise meaning. To illustrate with another example, the common word  X   X  (ministry/ department) X  in  X   X   X   X   X   X  (State Ministry of Justice) X  is translated as  X  X inistry X , but the same word in  X  .  X  (Sales Department) X  should be translated as  X  X epartment X . This phenom-enon is very common in NE translation and deserves further investigation.
In Example 4,  X  f  X  P  X   X  was correctly set as the Middle Chunk, but the included words have been wrongly reordered due to the distortion model. This is similar to word reordering errors found in the phrase-based SMT system.
The vocabulary range of the training data and lexicon limits the ON trans-lation model. Furthermore, alignment errors that occur in the training process bring errors to the final translation. Most of errors are caused either by im-plicit or unknown expressions at the word level or by an ambiguity between chunks, rather than being caused by the whole chunk-based structure. The structure-based synchronous CFG derivation, limited to five steps, has proved to be effective.

To eliminate some of the errors, we will follow the latest SMT research to im-prove the distortion model with insertion or deletion on the word level. More-over, we need pay more attention to distinguishing different expressions of word in an NE and try to confirm its real meaning by considering the word relationships. In other words, the structure-based translation model could be combined with further minor structure information at the word level to achieve a better performance.

In addition, nonobjective ONs, journal names, or some transliter-ated parts are more appropriate for equivalence extraction than direct translation because they usually contain special meanings, for example,  X  w ~ K  X  (zahia al-khaleej). X  In future work, we will specifically address the approach to translating such types of ONs. 6.2 Improving Translation Quality by Adding a Translation Model for the The ON translation model is integrated into an SMT system in the following process: First, it requires the word segmentation and named entity recognition toolkit developed by our lab to segment the sentences and recognize NEs, in which ONs are labeled as variables in the sentences. Then the SMT system is run to translate the sentences with ON variables. Finally, ONs are translated by the structure-based translation model, and the variables in the sentences are replaced by the outputs of ON translation.

We take a sentence for example:  X   X   X   X   X   X  X  X  , w W  X   X   X   X  s  X  w  X   X   X   X  P  X  \  X   X  (Discipline Inspection Committee announced that Supervision Office of Hainan Province will update the latest anti-corruption news from today onward). X  Here,  X   X   X   X   X   X  X (Discipline Inspection Committee) X  and  X  w W  X   X   X  (Supervision Office of Hainan Province) X  are recognized as ONs and replaced with variables  X  X N1 X  and  X  X N2 X  respec-tively.  X  X iscipline Inspection Committee X  and  X  X upervision Office of Hainan Province X  are the translation outputs of the ON translation model. Figure 7 shows the flowchart of integrated translation. The underlined words denote the location of ONs.

To clearly reflect how much the translation quality could be improved by using our proposed approach when an ON is embedded  X  besides applying the test on a widely adopted NIST data set to be specified next  X  an additional 120 sentences have been collected specifically for this purpose and tested. This small data set has been selected from the evaluation corpus of the National High-Tech Program of China (named the 863 Program) in 2004. The selection criterion is that each sentence includes at least one ON, and the ON contains more than two words. The set includes more than 3,000 Chinese words in all, and the average length of the sentences is 53 characters, around 24 words. There are 127 ONs included in total, of which the average length is 7.5 Chinese characters. The baseline system that we use for comparison is a phrase-based SMT system. Our evaluation metrics are fully automatic, including the BLEU (Bilingual Evaluation Understudy) score [Papineni et al. 2002] with default settings. Adding the ON model yields a statistically significant BLEU score beyond the baseline system.

The BLEU score of the baseline system is a little low because most of the sentences in the test data are too long. From Table XI, we can see that our integrated system achieves a relative improvement of 38.8% over the baseline system. Clearly, the ON translation model gives significant assistance to the SMT system.

To validate whether the ON translation model is sensitive to the domain, we also conducted experiments on the 2005 NIST test set (1,082 sentences) except for 108 sentences, which we used as the development set. ON recognition and variable substitution were performed on both the test set and the development set. There are 473 recognized ONs with a total of 1,811 words. As Table XII shows, the system with the 4-gram and ON translation model achieves the best performance, and the BLEU score increases by 0.03 when ON identification and translation were introduced. 7. CONCLUSION Traditional NE translation focuses on extracting NE pairs from a paral-lel/comparable corpus or Web resource. Such an approach cannot yield sat-isfactory results for organization names that contain high levels of compacted information and are complex in structure. Taking into account the character-istics of Chinese organization names, in this article we have adopted a  X  X hunk X  unit to analyze the ON structure based on the alignments of ON pairs, and pro-posed a structure-based approach for translating ONs directly. The structure-based model includes a chunking model and a chunk-based CFG model with defined derivation. The CFG rules are classified into four types:  X  X lue X  rules, templates, common rules, and special rules according to their hierarchical derivation rank. Templates and common rules are learned from bilingual ONs without any syntactically annotated training data; special rules, which are defined in CFG format based on word level, are applied to cover more ON translation.

The contributions of this article are summarized as follows. First, by an-alyzing the inherent ON structure, we showed that ON components follow a definite formula that allows the designation of three types of chunks. This chunk-unit can sum up different ON translation patterns and provide the ra-tionale for a chunk-based translation model. Second, the model contributes to flexibility and accuracy for ON translation, because a whole ON has been divided into chunks. The defined derivation of five steps follows the hierarchy of CFG rules, and conforms to the reordering formula of three chunks. Our experiments have proved that the proposed structure-based translation model achieves high levels of accuracy. Third, in the training process we developed a novel alignment approach for the word alignments of ON pairs and then gen-erated numerous, high-quality synchronous CFG rules. Finally, the ON trans-lation model demonstrated a significant improvement in translation quality when it was integrated into an SMT system.
 We have built a translation foundation for ON according to its structure. It is important to note that the proposed structure-based translation model is flexible by hierarchical derivation. Moreover, lexicons and a translitera-tion model can be added via special rules to improve the performance. But it remains clear that the model requires more high-precision synchronous CFG rules and explicit word meanings for ON translation. In this article, we pro-posed a training architecture and compared two alignment approaches. Ap-proach II proved to be more effective. Our future research will focus on how to obtain high-quality rules representing semantic clusters and relations, in order to achieve acceptable English expressions for ONs.

We believe that recognizing and understanding the ON X  X  inherent structure is necessary for its translation; it requires a special translation model other than traditional SMT. The structure-based model presented here translates Chinese ONs into English with an accuracy of 93.75% and achieves signifi-cant improvement over the baseline SMT system. The experiments verify the validity of the model as well as the performance improvement when the ON translation model is added to an SMT system.
 The authors extend sincere thanks to professor Keh-Yih Su for his keen in-sights and suggestions. Thanks are also given to the authors X  associate, Chun-guang Chai, for his great help on the comparison work using the phrase-based SMT system, and to Dr. Fei Huang for his careful proofreading and beneficial suggestions.

