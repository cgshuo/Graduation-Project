
University of Minnesota, Duluth 1. The Sad Tale of the Zigglebottom Tagger  X  X urrah, this is it! X  you exclaim as you set down the most recent issue of Computational
Linguistics .  X  X his Zigglebottom Tagger is exactly what I need! X  A gleeful smile crosses your face as you imagine how your system will improve once you replace your tagger from graduate school with the clearly superior Zigglebottom method. You rub your hands together and page through the article looking for a way to obtain the tagger, but nothin gis mentioned. That doesn X  X  dampen your enthusiasm, so you search the
Web, but still nothing turns up. You persist though; those 17 pages of statistically significant results really are impressive. So you e-mail Zigglebottom asking for the tagger.
 toreleaseademoversionsoon,staytuned... X  X rperhaps: X  X edon X  X normallydothis, butwecansendyouacopy(informally)oncewecleanitupabit... X  X rmaybe: X  X e can X  X  actually give you the tagger, but you should be able to re-implement it from the article.Justletusknowifyouhaveanyquestions... X 
Zigglebottom Tagger. Despite three months of on-and-off effort, the end result provides just the same accuracy as your old tagger, which is nowhere near that reported in the article. Feelin gsheepish, you conclude you must have misunderstood somethin g, or maybe there X  X  a small detail missing from the article. So you contact Zigglebottom again and explain your predicament. He eventually responds:  X  X e X  X l look into this right away andgetbacktoyou... X 
Meeting of the Association for Computational Linguistics (ACL). You angle for a seat next to him durin ga ni ght out, and you buy him a few beers before you politely resume your quest for the tagger. Finally, he confesses rather glumly:  X  X y student
Pifflewhap was the one who did the implementation and ran the experiments, and if he X  X  only respond to my e-mail I could ask him to tell you how to get it working, but he X  X  graduated now and is apparently too busy to reply. X  you the version of the code I have, no promises though! X  And true to his word, what he sends is incomplete and undocumented. It doesn X  X  compile easily, and it X  X  engineered so that a jumble of programs must be run in an undisclosed kabalistic sequence known only to (perhaps) the elusive Pifflewhap. You try your best to make it work every now and then for a few months, but eventually you give up, and go back to using the same old tagger you used before. 2. The Paradox of Faith-Based Empiricism
The tale of the Zigglebottom Tagger is one of disappointment, not just for you but also for Zigglebottom himself. While his work achieved publication, it must gnaw at his scientific conscience that he can X  X  reproduce his own results. The fact that you can X  X  reproduce those results either raises questions, but those are resolved with a shru gof your shoulders and by giving the benefit of the doubt to Zigglebottom. He X  X  not a fraud; there X  X  just some crucial detail that is neither recorded in the article nor in the software, which can X  X  be installed and run in any case.
 our publications don X  X  provide enough space to describe our elaborate 21st century empirical methods in sufficient detail to allow for re-implementation and reproduction of results. This is true despite the generous page allowances in ComputationalLinguistics and even more so in our much more constrained conference proceedings.
 reviewers the article should be published. This is particularly troubling given the highly empirical nature of the work reported in so many of our publications. We publish page after page of experimental results where apparently small differences determine the perceived value of the work. In this climate, convenient reproduction of results establishes a vital connection between authors and readers.
 available via open access as soon as possible (e.g., via the ACL Anthology the supportin gcorpora and lexical resources will be made available even if at some cost (e.g., via the Linguistic Data Consortium 2 ). Yet, we do not have the same expectations regarding our software. While we have table after table of results to pore over, we usually don X  X  have access to the software that would allow us to reproduce those results. This cuts to the core of whether we are engaged in science, engineering, or theology:
Scientists reproduce results; engineers build impressive and enduring artifacts; and theologians muse about what they believe but can X  X  see or prove.
 in gexperiment. Randomly select one of your own publications from a year or two a go and think about what would be involved in reproducin gthe results. How lon gwould it take, assumin gyou would be able to do it? If you can X  X  reproduce those results, why do you believe them? Why should your readers? reviewers and readers accept highly empirical results on faith. We do this routinely, to the point where we seem to have given up on the idea of being able to reproduce results. This is the natural consequence of faith-based empiricism, and the only way to fight that movement is with a little bit of heresy. Let X  X  not accept large tables of empirical results on faith, let X  X  insist that we be able to reproduce them exactly and conveniently.
Let X  X  insist that we are scientists first and foremost, and agree that this means that we must be able to reproduce each other X  X  results. 466 3. A Heretic X  X  Guide to Reproducibility
In many cases the failure to release software that allows results to be reproduced is not a conscious decision, but rather unintentional fallout from how we manage projects and set priorities in guiding our careers. What follows are a few simple ideas that any researcher can adopt to make it much easier (and more likely) to produce software that can not only be released but that will allow users to reproduce results with minimal effort. As more of us use and release such software, our expectations as a community will rise, and we X  X l eventually see software releases as a natural part of the publication process, much as we now view data sharing. 3.1 Release Early, Release Often
The single greatest barrier to releasing software is that we don X  X  think about doing it early enough. It X  X  only when we get that first e-mail asking for the implementation of a method discussed in ComputationalLinguistics that the issue arises, and by then it X  X  too late. At that point the task of convertin gour code into a well-documented and easy to use package is often nearly impossible.
 turnover in project members, there can even be legal concerns. When projects do not plan to release software, it X  X  often the case that system development will include stages based on helter-skelter cuttin gand pastin gof code from other sources. The effect of this is to erase all traces of the origin of that code and the terms under which it was made available. Once you have gone down this route, it X  X  very hard to consider releasing the resultin gsoftware.
 be guided by considerations that are important to your potential audience. You will choose licenses, hardware platforms, and programming languages that avoid any obvi-ous barriers to distribution and use. You will develop an infrastructure of Web services, software repositories, and mailin glists that will evolve with your project. You will avoid haphazard development methodologies that lead to disorganized and impossible-to-maintain code. The prospect of havin gactual external users of your software will inspire a discipline and orderliness on your development and deployment processes that will likely result in much better software than if you developed it for internal use only.
 hand to guide system development, and that X  X  a skill that many researchers don X  X  think they have. However, it X  X  really quite simple to develop. All you must do is play the part of a demandin gyet naive client from time to time from the very start of the project.
Insist that the code be easy to install and use and that the results that come from it be easy to understand and absolutely reproducible. If the project is too large for you to play this role yourself, assign it to one or more members of your team, and make sure they play the part as if they are a new user encounterin gthe system for the first time.
 you end up with much better documentation and software, and a system that can be easily and conveniently used to reproduce results both by outside users and by yourself after the passage of some time. 3.2 Measure Your Career in Downloads and Users
Researchers sometimes fall into the trap of seein gsoftware and reproduction of results as frills, and not essential components in their career development:  X  X s much as I would like to, I don X  X  have the time to produce distributable code. Besides, my promotion will bebasedonpublicationsandgrants,notsoftwarereleases... X  or you can spend it writin g grant proposals and papers, but not both. This overlooks a very happy side-effect that comes from creatin greleasable code X  X ou will be more efficient in producin gnew work of your own since you can easily reproduce and extend your own results.
 cycle:  X  X  X  X e worked on this for X years, why would I just give it away? X  This ignores the fact that  X  X iving it away X  will make it easier for others to use your work, because if you don X  X  make your code available, who is really going to spend years re-implementing what you did? writin gand reviewin gpapers that are rejected and eventually abandoned. In a similar vein, we should all think about the time we cost our community when we don X  X  release software and make anyone who is interested in usin gor validatin gour work do their own implementation.
 copyright (e.g., the GNU General Public License 3 or the Mozilla Public License there is little danger of your work being misappropriated, and you will build a reservoir of good will within our community. Most users don X  X  want to steal from you; they simply want to use your code to build their own system while giving you all the credit that is your due. As your software acquires a following, you can use that as a foundation for offerin gtutorials and workshops and other means of dissemination that will increase your visibility in the research community, thereby enhancin gthe credibility and impact of the work you have done. 3.3 Ensure Project Survivability By Releasing Software
Released software can allow your project to sustain itself despite turnover in personnel and the passage of time. There is no greater satisfaction than opening up a software release that has not been used for a few years and immediately bein gable to start producing meaningful results, without having to reverse engineer it or trace through code line by line. The more time passes, the more you become just like every other potential user of your software; so, as you are creatin git, remember that in a few years your memory of all the details that now seem so obvious will have faded, and you will be grateful for a job well done, and that will translate into time saved as you begin to use that software again.
 this software, read the documentation, install it, run the script that reproduces our ACL experiments, and then we can start talkin gtomorrow about how you are goin gto extend thatwork... X  X hislo wers the bar for entry to your project for new colleagues, and saves 468 your existin gteam considerable time when introducin ga new member to the work of your group.
 students will graduate, post-docs will move on, employees will resign, and you might even find a better job somewhere. Havin gpublicly released software helps clarify what rights former project members have once they have left a project. This is a painfully murky area, and it can lead to many misunderstandings and bad feelings that take time and energy to deal with as they arise.
 project simply because they feel they don X  X  have the right to participate, and in fact in some cases they may not even have access to or copies of the very system they spent all those months or years workin gon. This difficult situation is absolutely avoided if you release the software: Your former colleagues will have exactly the same rights as anyone else. They can remain a part of the community of users, testers, and developers, and can often provide valuable continuity in a project even if they have moved to a new project or organization. The same is true for you. Suppose you move from the academic world to a position in industry: If your project code has already been released prior to this move, then you can safely continue to use it without fear of losin gcontrol of it to your new employer. 3.4 Make The World A Better Place
Finally, although this viewpoint may seem quaint or naive, a great deal of our research is funded by public tax dollars, by people who make ten dollars an hour waitin gtables or standin gbehind a counter in a convenience store for 12 hours at a time. We are fortunate to do what we do: even if it takes many hours and causes great personal stress, in the end the work is challenging and satisfying, and compared to how most people in the world live and work, we are leadin gcharmed and privile ged lives.
 nin gour code, they ou ght to have that opportunity. And who knows, maybe when their children take a Computational Linguistics or Artificial Intelligence class they will run across a piece of our publicly available code that will cause them to pause and think, and maybe inspire them to try somethin gnew or different, maybe even make them think about becomin gone of our community. It X  X  not the most likely scenario, but it seems like we really ought to try to give back as much as we can to the greater public good. 4. What should ComputationalLinguistics Do?
We seem as a community to have accepted a very curious state of affairs. As reviewers and readers of ComputationalLinguistics and the proceedings of ACL conferences, we in-sist upon extensive, rigorous, and fine-grained evaluations, where the difference in per-formance between competin gmethods is sometimes rather small. However, we don X  X  expect to be able to reproduce these results or modify these experiments in any way. reached a point where we don X  X  expect our data to be reproducible due to the arbitrary results they provide. Kilgarriff (2007) argues,  X  X oogleology is bad science, X  to which we would simply add  X  X ecause it is not reproducible. X  the bigger picture, to focus on the ideas and not the software, as those are just  X  X m-plementation issues. X  This is a debilitatin gparadox, because results must be supported experimentally with great precision and detail and are judged according to harsh em-pirical standards, but we as readers and reviewers are asked to accept that these results are accurate and reproducible on faith.
 studies, then we must also believe in havin gaccess to the software that produced those results as a necessary and essential part of the evidentiary process. Without that we are asked to re-implement methods that are often too complicated and underspecified for this to be possible, or to accept the reported results as a matter of faith. stringent standards that focus on evaluation and comparisons of empirical results; to approach things more with a focus on bigger ideas, and less on statistically significant empirical results. This is not necessarily a bad thing, and might address concerns such as those raised by Chuch (2005) about very conservative reviewin gin our field and the resultin gtendency to prefer incremental improvements.
 studies must be reproducible to be credible, and that it is unreasonable to expect that reproducibility be possible based on the description provided in a publication. Thus, releasin gsoftware that makes it easy to reproduce and modify experiments should be an essential part of the publication process, to the point where we might one day only accept for publication articles that are accompanied by workin gsoftware that allows for immediate and reliable reproduction of results.
 Acknowledgments References
