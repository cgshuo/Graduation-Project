 Detecting emerging trends and field evolving in scientific disciplines can signifi-cantly improve the ability of researchers to catch the wave in a timely manner. Most existing works [1, 2] use statistical topic models such as Latent Dirichlet allocation (LDA) [3] for topic extrac tion and analysis. Recent work has been concerned with temporal doc uments [4, 5]. These works can create fine-grained, immediately interpretable topics that are robust against synonymy and poly-semy. However, the topic models need a pre-specified number of latent topics, and have to be done through manual topic labeling, which is usually a labor intensive process. More importantly, it is difficult to show the different topics which make up different fields and how these topics evolve and develop from a global view. Mannila et al [6] tried to find one or a (small) set of partial orders that fit the whole data set accurately from an optimization point of view. Due to complexity, only series-parallel order s [7] were considered in [6]. Furthermore, the Global Partial Orders (GPO) is a qualitative model, local information was sacrificed for global benefits.

In this paper, we attempt to detect how a research field evolves by analyzing the publication track records of authors, especially new authors. The global model constructed from these sequentia l track records can give us a macro-view of field evolving trend, since  X  X  burst of authors moving into a conference C from some other conference B are actually drawn to topics, which are currently hot at C  X  as the results in [8]. This could be considered as a graph mining task but we focus on constructing a probabilistic graphical models from sequential data set.

In this paper, we use the Dynamic Bayesian Networks (DBN) [9], which ex-tends the graphical models to accommodate temporal processes represented in the sequential data. We can control th e model complexities according to the users X  request. With such a method, more detailed information can be obtained in comparison with the GPO model.

However, the current DBN models with the first-order Markov transition can not catch all the information in field evolving trend and it is infeasible if high-order Markov transitions are considered due to the complexity. In this paper a transitive closure method is proposed to capture the evolving across several time slices. This global model constructs a sequential publication record of new authors to highlight how the research field evolves macroscopically. The model is constructed using information from different time periods and this allows a general publication trend to be captured. Finally, this model can be combined with a topic model and topic description to give a user a better understanding of a research field. Research community is important for academic communications, and many re-search communities have their individual associations to best foster academic research and collaborations. For example, as the first society in computing, ACM (Association for Computing Machinery) has 34 distinct Speciate Interest Groups (SIGs) 1 in a variety of research fields to a ddress different research inter-ests. They organize and sponsor a larg e number of leading conferences in many research fields, such as SIGGRAPH, SIGMOD, SIGKDD, SIGIR, etc. Most of these premier conferences represent the fr ontier of their corresponding sub-fields in computer science, such as SIGGRAPH for computer graphcs, SIGKDD for knowledge discovery and data mining, etc. These conferences attract not only the researchers in their local fields but also large proportion of top researchers from other fields, who publish their research outputs in those top conferences. Through investigating these top conferences, it is possible to gain an understand-ing of the evolution of a particular research field.

According to the difference of duration time, in one time slot, members in a community can be divided into three types: new author: authors who publish papers in this community for the first time; regular author: regular contributors to the community; retiring author: authors who may leave the community soon.
 Though regular authors may shape the r esearch field, the new comers are more important in order to sense the emerging research topics. They often not only bring in new resources and thoughts into a community, but also participate in the hottest topics. Especially, in rising and developing fields, the role and influence of new authors are more obvious. Through analyzing this type of new authors by their publication records, we can obtain an understanding of how a research field evolves, and reveal the trend through comparing the models in different time periods. 2.1 Publication Track Records The objective of this paper is to discover a global model based on the sequential publication records of new authors in the interested community. The definition of the publication track records is as the following.
 Definition 1. The author X  X  publication track records (APTC) is defined conference set we analyzed, essentially denoting the field. This sequence shows the conference attending history of an author ordered by year.
 An APTC records the research sequence of an author, and this sequence rep-resents their research field during different period. In this paper, we focus on those premier conferences in which the au thors or research g roups are generally stable, and the authors in those conferences are generally quite focused on their research area, and seldomly publish their papers everywhere.
 Definition 2. For one target conference, the new author X  X  publication track records (NAPTC) is a sequence, of the new comer X  X  publishing track before he or she first published a paper on that conference. 2.2 Problem Formalization In analyzing, we assume that each NAPTC is generated independently. Since our goal is to analyze the field evolving, we assume each conference focus on one research field. This is usually true in reality for majority of conferences. Especially, in the computer science, mo st famous conferences focus on one field. Thus, we can use the conference name to represent its research field.
The formal definition of the problem can be denoted as: given the target conference and time, with the new au thors X  publication track sequence S = {
S namic Bayesian Network (DBN) [10]. The model learned from data aims to find the best model of the joint probability distribution of all conferences C under-lying the temporal process. This is a structural learning process. In the next section, we present an unified probabilistic approach to the constructing of a global model.
 DBN, represents both the inter-slice conditional independence assumptions, and the intra-slice conditional independence assumptions. Among which we only care about the inter-slice links. In this section, we first preprocess the data, then introduce some methods to improve model constructing, and give an algorithm process, finally interpret the model discovered. 3.1 Preprocessing When the target conference and time are given, the publishing track of new comers compose a subset of C . It often contains hundreds of conferences so the computing will be intractable due to the complexity of BN structure learn-ing. Moreover, there are many conferences that appear only once or twice. This largely increases the computing complexity, but gains little benefit and even de-stroys the conciseness of the resul t. Therefore we only focus on top k conferences according to the support number.
 is the random variable that denotes the value of the attribute c i at time t ,and C [ t ] is the set of random variable c i [ t ].

In the NAPTC listings, many conferences have multip le representations for each year the conference has run. As such, many feedback loops can emerge which can impact the expression and understanding of the final result. Also when a researcher publishes a paper in one conference, it usually means that he has involved in the corresponding field. As such, in this paper we will only record the first participating. 3.2 Transitive Closure of sequence data. The total number of sequences is 1000 and the number of appearance of each node a , b , c , d , e , f and g is 100. In the remaining part of a sequence, there are no one time slice transitions which is the same as Table 1, such as a  X  c, a  X  d, f  X  b,  X  X  X  . With a greedy search and BDeu score, we construct DBN. In the result, no transition is significant enough to appear in DBN model so the resulting graph is a set of isolated nodes. This loses one important information the transition from a to b . The reason is that the model can only deal with transitions for consecutive time slices . However, this transition is valuable for our problem. Considering when a scholar published a paper in ICML 2000, this research field may affect his following research, not only the immediate ones. To solve this problem, we introduce the idea of transitive closure and use Property 1 to modify the definition of time slices in the first-order markov model.
 Property 1. The transition probability of any two random variables across any { 1 ,  X  X  X  ,k } ,t  X  [1 ,t  X  1].
 In our track record sequences, the data is sparse and the sequence is usually short, showing the time span is not large. Further more, a conference represents one field only. In this situation, the field transitions almost remain stable, even if spanning limited time slices. Thus, in our two time slice model we define time slice 0 to mean the start of a transition and time slice 1 to mean the destination. The transition can cover any time slices. Instead of dividing the state sequences into a set of one time slice transitions, we now need to generate the transitive closure about the set of one time slice transitions. The state sequence C 1 C 2 C 3 C 4 will generate a set of candidate transition pairs C 1  X  C 2 ,C 1  X  C 3 ,C 1  X  C 4 ,C 2  X  C ,C 2  X  C 4 ,C 3  X  C 4 . With the transitive closure, the DBN constructed from Table 1 has the transition a  X  b . This property improves the model accuracy. 3.3 The Prior Model In transitive closure, the first-order extension can not capture all possible tran-sition probabilities, especially in sequence data and the activities occur with sequence, such as P ( C t | C t  X  2 ,C t  X  1 ) (the second-order markov process) and the P ( C t | C t ,  X  X  X  ,C t )( t&gt;t &gt;t ). For a better representation of the sequence, we need to consider these tra nsitions. However, considering all these transitions increases the complexity. The model d oes not need to be an exact match to, or model all features of, real sequence data, so long as it captures many of the important sequence features. Some methods consider the top k transition. The value of k is hard to define and may lose some important information. Using the global partial order as the prior model, we can effectively obtain the sequence.
As a generative model, global partial or der describes a set of sequences using a mixture model of partial orders. The likelihood of a given partial order producing a sequence compatible with it is inversely proportional to the number of total orders compatible with the partial order. The method tries to find a set of partial orders that are specific enough to capture significant ordering information contained in the data. Through using the tr ivial partial order and an unrestricted partial order, the global optimization model can be found. Using the results to initialize a search over unrestricted partial orders with DBN, we can obtain a good result. Due to the high complexity of global partial order constructed, we restrict the model learning to a small number of nodes h ( &lt; = k ). 3.4 The Procedure of Constructing DBN With the descriptions mentioned above, we can construct our DBN as Algo-rithm 1. In model learning the objective is to maximize the posterior probability P ( M | S )of M given S ,where S is our sequence data set and M is the model. Since with small amounts of data in our problem, BIC/MDL is known to over-penalize, we use the BDeu scorin g metrics [11] in this paper.
 Algorithm 1. The procedure of DNB constructing In step 1, we preprocess the sequence and hold the top k conference variables. Step 2 constructs the global partial order from SS with the top h variable, then uses this as the prior model. With step 3, the conference sequences are transformed with the transitive closure. In step 4, based on the transitive closure and the prior model, we can construct the Dynamic Bayesian Network. In the search process, we use the greedy search with random restarts [12], which can restart from another random graph to escape the local maximum. In step 5, we draw the DBN with the top score value model as a brief graph, and interpret the model through the CPT or influence scores [13]. 3.5 Network Interpretation In the network interpretation we only care about the field (conference variable) evolving represented by inter-slice links. Thus in the brief graph the nodes are defined as the random variables and the links are defined as the inter-slice links. At a quantitative level, relationships between variables are described by a family of joint probability distributions (conditional probability table, CPT) that are consistent with the independence assertions embedded in the graph. Sometimes, people usually want to know the influence that a parent gives to its child, we consider the influence score [13] as an alternative choice. The influence score is arranged between -1 and 1. Positive numbe rs represent activating relationships of a parent on a child, while negative numbers represent repressing relationships.
In our model based on DBN, in general, each slice can have any number of state variables. If there is a node conn ected by several nodes, we need to carefully explain it as the value of the node is influenced by those nodes connected to it. The quantitative analysis of the influence should rely on the CPTs and with the help of influence score.

Additionally, in our graph, positive correlation in some degree means the high probability of the sequential appearance comparing with negative correlation and independence. So from the positive correlations a set of binary orders of the nodes covering one time slice can be cr eated, and with concatenating these binary orders together a global order can be generated. Therefore the nodes on the bottom of the global order usually appear later than the nodes above them. We apply the method presented in Section 3 to construct our DBN model. We also use the LDA model 2 for topic discovery. Empiri cal results show that our model provides a compact representation, which is better than global partial order model and current DBN method. Through our model, we can provide a potential source for understanding the sequential data deeper and catching how a research field evolves and develops better. 4.1 Data Preparation In the experiments, we use the two data sets, the first is the DBLP set of datasets 3 . Through DBLP(by October 2006), we can extract the publication track sequence of authors. In these data, the duplicate names are only a tiny part of the whole dataset, thus will not be a problem in our model construction.
The second data set consists of the abst racts in SIGKDD conference proceed-ings from 2001 to 2006. Through these data, we can extract the topics for better explaining our model X  X  advantage. All the abstracts were crawled from the ACM digital library 4 . For better discovering the topic, we filter some phases, such as  X  X he X ,  X  X  X , etc., which may affect the accuracy of the results. 4.2 Global Model This section compares the all global models as the following: 1. Global partial order (GPO); 2. D ynamic B ayesian N etwork (DBN); 3. DBN with T ransitive C losure (DBN-TC); 4. DBN with T ransitive C losure and P rior N etwork (DBN-TCPN); The GPO model is constructed based on [6], the others DBN, DBN-TC and DBN-TCPN are constructed based on Dy namic Bayesian Network. The DBN model constructed without the transitive closure is based on the first-order markov. The DBN-TC model is based on DBN with the transitive closure. The DBN-TCPN is the model proposed in this paper, with transitive closure and prior network GPO. The sequence data are gathered from publication track se-quences of new authors in SIGKDD 2006. The prior network presents the global partial order model with top 12 confer ence variables. And the DBN models are constructed from the top 20 conference variables.

Fig.1 shows the four models. Classifying the edges into positive and negative correlation according to the influence score [13], all three DBN models have no negative edges. The DBN (DBN, DBN-TC and DBN-TCPN) models all present more information than GPO model. In the following, we describe our model DBN-TCPN and use it to understand how research field evolves. 4.3 Model Detail In this subsection, we describe this model in detail, including both the topology and probabilistic table. Fig.1(d) or Fig.2(d) represents the topology of publica-tion track records with new comers in SIGKDD 2006. As the model does not have negative correlations. This is quite convenient for us to gain the sequential feature of the conferences. The figure shows many application fields. Especially www based research conferences appear in the low level in the network, such as SIGIR, CIKM, WWW, APWeb. It also indicates how the KDD research field develops and is enlarged, due to the emergence of ICDM and PAKDD, two other conferences in the KDD field.

From the part of the corresponding probability table shown in the Fig.1(d), it is evident that many people change res earch field from theory conference to application conference, such as the CPT for the WWW conference node, the value  X 1 X  means that researchers of the discrete algorithm symposium SODA, a famous forum focusing on discrete problems, bring their research into WWW when they have no Expert Systems field. And from the CPT for the ICDM conference node, multimedia domain is related positively to the data mining ICDM. 4.4 Comparision with Topic Model In this section, we use our DBN-TCPN model (DBN with T ransitive C losure and P rior N etwork) constructed in different period in SIGKDD conference to reveal the evolving and trend in data mining and knowledge discovery. For better explanations, we also compare it with the topic model.

In the model construction, the prior network is with top 12 conference vari-ables. And the DBN-TCPN models are constructed with top 20 variables except for the 2002 year with top 22 (This is due to that the conference variable support counts are difficult to be distinguished). From the models in Fig.2, where isolate variables have not been shown, we can find that the model constructed is more and more sparse gradually as shown by the statistical property shown in Fig.2. Such as in the 2000, 2004 and 2006 year, the variable number is all 20, but the edge number decreases from 30 to 25 to 18. This shows that the effect of the KDD field is larger and larger, attrac ting various fields X  researchers.
Analyzing the figure closely, Fig.2(a) indicates that new comers in 2000 usu-ally come from the database field (SIGMOD, ICDE, PODS, VLDB), artificial intelligence (AAAI/IAAI, IJCAI, UAI) and machine learning (ICML). These conferences appear in the low-level in th e graph. This indicates that they have some other domain background, and the research field evolves from theoretical computing to DB, AI and ML, with further transforms to DM and knowledge discovery (KDD). In that period, the DM and KDD fields where in their in-fancy, and many algorithmic and theoretic problems needed to be studied. In 2002 (Fig.2(b)) the DB field maintains a presence in KDD, and the KDD field has developed, some forums (PAKKD and ICDM) have also attracted the re-searchers from other fields. Additionally, the field closed to SIGIR emerged. In 2004, KDD continues developing, and application fields play an important role in KDD, they introduce the web application to web mining using a machine learn-ing method, and this trend continues in 2006. Moreover, the number of KDD applications has increased in relation to other research topics such as multimedia (ACM Multimedia), SIGIR and WWW.
For a better comparison, we used the y early data of a targ et conference to analyze trends in topics over time based on topic model. Using the topic ob-tained earlier, the documents were part itioned by year, and for each year all the documents were assigned to the topic using the model. These fractions pro-vide useful indicators of rela tive topic popularity in res earch literatures in recent years. And for better analysis, we respectively compute the one of all authors and new authors.

Table 2 lists the 10 topics analyzed based on SIGKDD abstract data from 2001 to 2006.

For convenience, we combine the relate d topics, such as topic No. 0 (classifi-cation), topic No. 6 (clustering) as machine learning topics, topic No. 2 and No. 5 for web mining, and average their topic intensity. Figure 3 shows topic inten-sity of all papers by new authors and all authors in Machine Learning (ML), Algorithm Design (AD) and Web Mining (WM). To represent the results, we use a polynomial function to show that the data fit the line in Figure 3. The results indicate that the topics of new authors are consistent with that of all authors, and this is consistent with our assumptions and model described above. However, we cannot see KDD development and other related field evolving in-formation from how a topic changes, which makes it difficult to understand how a particular research field evolves. If t hese topic models can be integrated with a global model, the quality of prediction can be improved. Understanding how a research field evolves is essential for scientists, analysts and decision makers to identify emerging tr ends in the body of scientific literature. This paper provides a method to help researchers understand unfamiliar subject areas and guide them toward hot topics and trends using a global model. This was accomplished by combining a Dynamic Bayesian Network with the proposed transitive closure property, to more accurately model the temporal features of how a research field evolves. Through the introduction of Global Partial Order (GPO) model (a good global model), we can synthesize the ordering informa-tion. Models constructed are compared in order to identify change as a sign of an emerging trend. The experimental r esults with SIGKDD show our model is effective. Also the models c onstructed represent the research trend accurately in data mining and knowledge discovery field. Especially with the comparative analysis between our model and topic model in the experimental data set, the result shows the consistent and our model can reveal more trend information than topic model.

