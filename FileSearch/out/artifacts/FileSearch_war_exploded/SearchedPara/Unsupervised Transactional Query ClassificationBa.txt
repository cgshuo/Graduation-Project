 Query type classification aims to classify search queries into categories like navigational, informational and transactional, etc., according to the type of information need behind the queries. Although this problem has drawn many research at-tentions, previous methods usually require editors to label queries as training data or need domain knowledge to edit rules for predicting query type. Also, the existing work has been mainly focusing on the classification of informational and navigational query types. Transactional query classifi-cation has not been well addressed. In this work, we propose an unsupervised approach for transactional query classifica-tion. This method is based on the observation that, after the transactional queries are issued to a search engine, many users will click the search result pages and then have interac-tions with Web forms on these pages. The interactions, e.g., typing in text box, making selections from dropdown list, clicking on a button to execute actions, are used to specify detailed information of the transaction. By mining tool-bar search log data, which records the associations between queries and Web forms clicked by users, we can get a set of good quality transactional queries without using manual labeling efforts. By matching these automatically acquired transactional queries and their associated Web form con-tents, we can generalize these queries into patterns. These patterns can be used to classify queries which are not cov-ered by search log. Our experiments indicate that transac-tional queries produced by this method have good quality. The pattern based classifier achieves 83% F 1 classification result. This is very effective considering the fact that we do not adopt any labeling efforts to train the classifier.  X  This work is done when the first author is visiting Microsoft Research Asia.
 H.3.3 [ Information Storage and Retrieval ]: Informa-tion Search and Retrieval; H.4.m [ Information Systems Applications ]: Miscellaneous Experimentation, Measurement Query Type Classification, Transactional Query, Unsuper-vised Learning
Search engines are widely used to search information on the Web. According to [25], about 70% of web searchers set search engines as their main entry point to the Internet. Popular search engines like Google, Yahoo! and Bing will receive a large number of search queries each day. Due to the fierce competition in search market, it is critical for search engine companies to return desired search result pages to end users.

Search engine users have different types of information needs. In [4], Broder divides queries into three categories based on the type of search intent: navigational, informa-tional and transactional. This classification is also widely used in subsequent research work: Figure 1: A Query Associated with A Webpage Form and Pattern Generalization Example
Understanding the type of search intent will be helpful for improving search engine relevance. For example, the au-thors of [5, 19, 2] proposed to optimize search results by adopting specific methods to deal with different types of search queries. However, how to automatically predict query type is challenging and this problem is not well addressed in literature. The authors of previous research work mainly focused on classifying queries into informational and naviga-tional categories. Transactional query classification problem is not well studied. In fact, transactional queries are impor-tant for search engine users. According to the studies of Broder [4] and Rose [24], over 25% queries of a commercial search engine are transactional, as shown in Table 1 1 .In literature, when supervised learning algorithms are used for query type classification [17, 16, 22, 20], human efforts are required for labeling queries to train the classifier, which is usually time-consuming. Some researchers adopted rules to predict query types [13]. The drawback is that compiling rules depends on domain knowledge and it is usually hard to enumerate all feasible rules. The dependencies of exist-ing query type classification methods block them from being widely used in practice. INF: Informational Query, NAV: Navigational Query, TRA: Transactional Query Table 1: The Percentage of Queries Belonging to Different Types
In this paper, we will focus on transactional query classi-fication problem and target to reduce the dependency on manual efforts. According to our observation, after the transactional queries are issued to search engine, many users will click the search result links and then have interactions with forms on the corresponding websites. For example, the search engine user may type in text box to fill in the form, select items from the dropdown list and click on a button to execute actions associated with the form. In this way, the information need of the user is satisfied. Such interactions are very common when users have online transactions, e.g., booking hotel, buying movie tickets, or finding dealers of used car. The user clicks can be used to associate search queries with webpage forms. Figure 1 gives an example of a user query with its associated form from the AirTran Air-ways website ( http://www.airtran.com/ ). Therefore it is reasonable to assume that, if a query is frequently associated with many forms of different web sites (i.e., corresponding with many form clicks), most likely the query belongs to transactional type. This assumption is consistent with the transactional query type definition given by [4].

Although many transactional queries are frequently asso-ciated with form clicks, not all queries with form clicks be-long to transactional type. For example, the user may first input a navigational query (e.g.,  X  X nited airline X ) to search for the corresponding website ( http://www.united.com ), and then have form clicks on that website. Also, not all forms are designed for users to complete transactions, e.g, the form which only contains a search box. In this work, we first analyze the distribution of form clicks and get a group of high quality transactional queries by mining toolbar log which conveys the relations between queries and their clicked forms. With these transactional queries as training data, we match them with the information contained in forms to help generalize these queries into patterns. A brief illustration of pattern generalization is shown in Figure 1. The patterns will be used to classify the queries which are not covered by log data. Compared with previous methods, our classi-fier is learnt from user log data instead of manually labeled queries. Experiments show that this unsupervised method achieves 83% F 1 classification result. This is very effective considering it is a fully unsupervised approach, although the performance is slightly worse than a supervised approach which requires many labeled data for training.

According to our knowledge, this is the first work of using form clicks to help transactional query classification. We are also the first to use webpage form information to help understand the structure of associated queries. Besides the direct benefit of classifying transactional queries, we have also identified a list of forms associated with each query. They are useful for simplifying user transactions, for exam-ple, the forms can be placed on the search result page thus users can directly finish transactions on them.

The following contents are organized as follows. In Sec-tion 2, we introduce the data source used in this work. In Section 3, we give framework of our solution and three key components. Two possible optional solutions to improve the classification performance are given in Section 4. Sec-tion 5 gives our experimental results. Section 6 discusses some work related to query type classification and form ex-traction. We conclude the paper in Section 7.
In this section, we will first introduce the data sources used in this research, including web forms and toolbar log data.
A form refers to all contents between the html tags X  &lt; form &gt;  X  and  X  &lt; /form &gt;  X . In this work, we model a form as the con-tainer of slots . Each slot corresponds with one component of a form , which is provided for users to interact with, e.g. fill in some value or select a value from a given list. A form also contains a button for submission. Figure 2 gives an example form and describes the slots contained by this form. A slot has three properties: label, type and a list of values. The label gives a description of the slot .5typesofslots areusedinthisresearch: text , select , radio , checkbox and button .The text type refers to the text input box, select refers to a dropdown selection list, radio refers to a group of radio buttons, checkbox refers to a group of check boxes and button refers to a button used for submission. Except for text slot, each slot has a list of pre-set values ( none is usedtoreferanemptylistinthiswork).

A form has four properties: a label to describe the form, a collection of slots contained in this form , from-url which is the URL of the page containing the form, and to-url which is the URL where users will visit after the form is submitted. In the following sections, slot is denoted by s . L ( s )and V ( s ) are used to denote the slot label and the set of values of this slot respectively. A form is denoted by f . L ( f )and S ( f ) are used to denote the form label and the set of slots in this form respectively.
Toolbar log is widely used by search engine companies to record the behaviors of users. When a user submits a query to search engine, a list of search result pages will be returned to the user. Then the user may browse one result page of interest and click on hyperlinks contained by that page. The following information recorded by toolbar log will be used in our research: user id , search query , clicked result page URL , further clicked page URL in result page .
With help of toolbar log, we can construct a virtual bi-partite graph with nodes corresponding with query and form respectively. For each query issued by search engine user, we can analyze the contents of its result page. When the re-sult page contains a form, we can use its { from-url, to-url values to match with { clicked result page url, further clicked page url in result page } of toolbar log. If the two URL pairs can be successfully matched, we can add one virtual link between the query and form nodes, which means that the query is associated with the corresponding form click. If a query can be matched with a form for several times, the frequency will be used as weight of the virtual link.
The framework of our unsupervised transactional query classification solution is shown in Figure 3. It contains three components: 1) Analyze the query-form graph to get a group of high quality transactional queries and use them as training data. 2) Match training queries with their corresponding form properties to generate transactional query patterns. 3) Adopt transactional query patterns to predict types for new search queries.
With the query-form click graph as input, we propose two score functions to measure how likely a query belongs to transactional type: click entropy and click ratio .
Considering the click distribution on the query-form bi-partite graph, we show three typical types of queries in Fig-ure 4. For query q a , users usually go to one specific website and have interactions with a fixed form of that website. This query very likely belongs to transactional type. For query q , users usually go to the same website but have interac-tions with many forms of that website. According to our observation, many users usually use a search engine to find the website of interest and then browse different pages on that website. Such query may belong to navigational type although it is associated with many forms. Query  X  X merican airlines X  belongs to such case. The third type of query, q associated with many forms from different websites. Most likely such query also belongs to transactional type, e.g.,  X  X heap flight X .
 Figure 4: Three Types of Queries in Query-Form Graph
We define a click entropy score function to measure how likely the query q is transactional: In Equation 1, Site ( q ) denotes the set of URLs which have virtual links with q while s i is the i -th URL in Site ( q ). Note that there might be multiple forms in a single webpage s i Click ( q,s i ) refers to the link frequency between q and s which equals sum of link frequency between q and all forms in s i . Click ( q ) is the total link frequency of q . Herewedefine two kinds of click distribution for query q : p site and p p site denotes the click distribution for a query at webpage level, where p site ( s i )  X  Click ( q,s i ). While p s i click distribution of forms in specific webpage s i . E ( p )is the entropy computed with the distribution p ,asshownin the following equation: where distribution p may refer to either p site or p s i ,and x denotes a webpage s i or a form in s i which has virtual links to q , respectively.

It is apparent that, the bigger ClickEntropy ( q )is,the more likely that query q is transactional. We can find queries q ,q b ,q c of Figure 4 satisfy ClickEntropy ( q c ) &gt;ClickEntropy ( q a ) &gt;ClickEntropy ( q This is consistent with our observations discussed at the be-ginning of this sub-section.
 Click ratio score function is defined by: where Click ( q ) is the frequency of query q associated with form clicks, while Impression ( q ) is the impression number of q in toolbar log, which is the frequency of q  X  X  appearance. The log function is adopted to smooth the distribution. The click ratio score function can be used to distinguish between informational queries and transactional ones.

By combining both click entropy and click ratio functions, we use the following equation to estimate how likely a query is transactional: In practice, the queries with high score are regarded as trans-actional. We will discuss an algorithm for improving quality of training data collected in Section 4.1.
In this subsection, we will introduce how to generalize query patterns with the collected training data. The idea is to match query content with properties of clicked forms. Figure 1 gives an example. We first give some definitions related to the process of query pattern generalization:
Attribute: An attribute a has a textual description label and a list of possible values V ( a ). In the following sections, we present attribute a as  X  X  label ] X . We could easily transform a slot s in a form to an attribute a , where the label of s could be textual description of a and slot values of s could be possible values V ( a ).

Query Pattern: A query pattern p is a sequence of terms &lt;t 1 ,...,t n &gt; ,whereeach t i could be a word w or an at-tribute a , such that at least one of the terms is an attribute , i.e. ,  X  j  X  [1 ,n ]forwhich t j is an attribute .Anexampleof query pattern is X  X lights to [city] X , where attribute  X  X city] X  X as possible values V ( a )= { seattle, new york, ... } .
Given a list of attributes A = { a 1 ,a 2 ,...,a m } and a query q , presented by a sequence of words W = &lt;w 1 ,...,w n aim to generalize q with the help of A in order to generate a candidate pattern p ,where t i  X  W  X  A for all terms in p .In the query-form graph, we could use a pair of query and form to generalize query patterns by easily transforming slots in the form to a list of attributes .

Generally, if we could find a possible value of an attribute appearing in a query, we will replace the value with the attribute to generalize the query to a query pattern. In many cases, the query may fail to be exactly matched with attribute values, especially when there exists spelling errors or abbreviations in users X  queries. Therefore, we adopt a fuzzy string matching function for comparing a candidate string s with an attribute value v : where EditDistance ( s, v ) measures the edit distances of two strings[21] and | v | is the length of string v .
We adopt a greedy algorithm for matching query contents with attribute values for query pattern generalization. The algorithm is described in Algorithm 1.  X  m is a pre-defined threshold score for fuzzy string matching.
 Algorithm 1 Query Pattern Generalization Input: A = { a 1 ,...,a m } ,q = { w 1 ,...,w n } where w Output: p = { t 1 ,...,t k } ,where t i  X  W  X  A . 1: Set p = q = { t 1 ,...,t n } ,where t i = w i . 2: for u =1 to m do 3: compute Match ( p, a u ) 4: end for 5: find the most matchable attribute with 6: if Match ( p, a max ) &gt; X  m then 7: replace t i ,...,t j in p with a max 8: remove a max from A 9: m  X  m  X  1 10: n  X  n  X  ( j  X  i ) 11: go to step 2 12: else 13: return p 14: end if
We could obtain a list of candidate query patterns through each pair of query and form in the query-form click graph. Finally we count all patterns and calculate a confidence score for each of them: where p is a pattern, Q ( p ) is the set of transactional queries which can be generalized to p ,and Score ( q i )isthetrans-action score of query q i , which is computed in Section 3.1. | Slot ( p ) | is the number of slots in pattern p .
Intuitively, if a pattern is generated from transactional queries with high quality, it will also have high quality. Also, if a pattern can be matched with many form slots, it is more likely to be a transactional pattern.
Query patterns are put in use for judging if a new query is transactional. Both pattern quality and how well queries fit with patterns are considered in classification process. We find patterns which well match with query q using: where p i is a transactional query pattern and P is the set of all patterns. Fit ( p i ,q ) indicates how well query q fits pat-tern p i . Then we adopt the following equation to calculate transactional score for q : where ScoreQP ( p i ) is the transactional score of each pattern computed with Equation 6.

The larger ScoreQ ( q ) is, the more likely query q is transac-tional. In practical applications, we will compare this score with a threshold value  X  predict and predict q as transactional or not-transactional. In order to determine the fitness be-tween query and pattern, we use slot values associated with the pattern to match with the query sub-string. If the match is successful, the substring will be removed from the query. Finally, we compute a textual similarity between the pattern and remaining words of the query. The fitness measurement of query q and pattern p will consider both the number of successful matches and the similarity score, as shown in the following equation: where SlotMatch ( p, q ) is the number of slot matches be-tween pattern p and query q . | Slot ( p ) | is the number of slots in pattern p . p and q refer to the remaining text after the matched slots are removed. The Cosine similarity is measured using their bags-of-words representations.
In the previous section, we have described our unsuper-vised transaction query classification algorithm. In this sec-tion, we will discuss two possible solutions to improve the classification performance. Both solutions are optional and we will study their impacts on classification performance in Section 5.
We have defined Equation 4 to measure how likely a query is transactional. Considering the relations between query and form, we can use an iterative algorithm to re-score them according to how likely they are transactional. The idea is based on the mutual reinforcement principle 2 : Basedonthequery-formrelationsencodedbythebipar-tite graph, the transactional scores for query, Score ( q ), and form , Score ( f ) are updated iteratively, following equations: where F ( q j ) is the set of forms associated with q j ; Q ( f is the set of queries associated with f j . Click ( q i ,f quency of q i clicking on f j . ClickEntropy ( q i )and ClickRatio ( q i ) can be calculated using Equation 1 and 3, respectively.

The algorithm terminates when the scores for queries and forms are converged (the property of converging can be proved according to [18]). The queries with high scores will be con-sidered as transactional queries.
In reality, different websites may contain forms for com-pleting the same transaction. If we can group them together and merge attributes transformed from all forms belonging
Similar principles are incorporated in HITS[18]. to the same cluster, it will increase the possibility of suc-cessful matches between query and attributes . This obser-vation also applies to form slots, since the slots with same functionality may have different names on different websites. Grouping them according to functionalities will increase the amount of possible values for the attribute transformed from the slot, thus help pattern generalization.

We adapt the clustering algorithm of [27] to cluster forms and slots in this work. A two-step clustering method is used: first we adopt a hierarchical agglomerative method to cluster all slots using their content information (labels and list of values) and the co-occurrence information with other slots. In the second step, the same method is used to cluster forms using their labels and slots .

The similarity between two slots , denoted by Sim ( s i ,s is calculated by: where  X  and  X  are two weight coefficients, which are used to balance different similarity measures.

The label similarity is calculated with a Cosine function on two term vectors, each of which corresponds with bags-of-words representation of the slot label: LSim ( s i ,s j Cosine ( L ( s i ) ,L ( s j )). The value similarity is based on the matching between values in V ( s i )and V ( s j ). The value similarity of two slots are calculated with Dice X  X  function [6]: VSim ( s i ,s j )=2 | C | / ( | V ( s i ) | + | V ( s j ) of matching pairs.

The Co-occurrence similarity is proposed by us to consider the co-occurrence information of two slots . P ( s i | s j the probability of s i appearing in a form if s j already ap-pears in the same form . P ( s i | s j ) can be calculated in the form extraction phase. For each slot ,wecanhaveavec-tor to measure the co-occurrence of other slots: CoV ( s i larity is computed by Cosine function on co-occurrence vec-tor: CoSim ( s i ,s j )= Cosine ( CoV ( s i ) ,CoV ( s j )).
The hierarchical agglomerative clustering for slot can be depicted in Algorithm 2. A slot cluster merging similarity threshold  X  slot is adopted in this algorithm.
 Algorithm 2 Pseudo Codes for Slot Clustering 1: treat each slot as a cluster 2: calculate the similarity of all pairs of clusters 3: if MaxSim ( c i ,c j ) &gt; X  slot then 4: merge c i and c j into a new cluster, go to step 2 5: else 6: return 7: end if
We extend this slot clustering algorithm to cluster forms using form label and the set of slots contained by the form. The similarity between two forms, f i and f j ,iscalculated by considering both the label similarity and the slot set sim-ilarity:
Sim ( f i ,f j )=  X LSim ( f i ,f j )+(1  X   X  ) SSim ( f i ,f
After the slot clustering step, each slot will belong to a cluster. We can build a slot cluster vector for all slots be-longing to a form. Assuming there are total n slot clusters Table 2: Statistics of Log Data Used in Our Exper-iments (denoted by sc ) after previous step, the slot cluster vec-tor of form f i can be denoted by ScV ( f i )=( c 1 ,c 2 ,...,c where c k is the number of slots in slot cluster sc k . Therefore, the slot set similarity can be computed by: SSim ( f i ,f Cosine ( ScV ( f i ) ,ScV ( f j )). The form clustering algorithm is similar to previous one for slot in Algorithm 2 but a dif-ferent cluster merging similarity threshold  X  form is used to decide whether to merge two forms.
In this section, we will introduce the data set used in our experiments and the effectiveness of our unsupervised trans-actional query classification approach, including the perfor-mances of all three components: training data collection, query pattern generalization, transactional query classifica-tion.
We use a set of toolbar log data collected by a commercial search engine company. The log spans a month, from De-cember 1 to 31 of 2009. It contains 100 million log records, 30 million unique queries issued by 7 million unique users. In order to conduct experiments efficiently, we use Bing Local taxonomy 3 to help reduce the experimental scale. We crawl home pages of all Web sites belonging to three categories,  X  X ravel / Airlines &amp; Airline Ticket Agencies X ,  X  X ravel / Car Rentals X  and  X  X ravel / Hotels &amp; Accommodations X . Since our transactional query classification approach is category-independent, we merge all the crawled pages together in our experiments. We also filter the toolbar log by only keeping the records which have clicks on these pages. Table 2 shows the details about the data set.

We process HTML codes of each page and extract Web forms. In order to remove obviously non-transactional forms, we apply the following rules in form extraction: 1)The HTML code of a form should be shorter than 75% of the whole page; 2) The number of slots contained in a form is less than 15; 3) A form should contain at least one button for submission; 4) A form should contain an attribute named  X  X ction X  which is used to declare the submission URL of this form. Finally we build a query-form bipartite graph, consisting of 155 forms and 20,934 queries. The log data of the last 7 days are held out for testing purpose. http://www.bing.com/local/YPDefault.aspx Figure 5: Top K Precision of Transactional Query Identification Figure 6: Top 250 Precision with Iteration Number
In order to evaluate the performance of the transactional query collection component, we invited 5 human judges to label the queries produced by this component. We manu-ally labeled about 3,000 queries which are pooled from top-ranked queries by each method. Among them, 1,269 queries are labeled as transactional while the remaining ones are labeled as not-transactional.

As discussed in Section 4.1, the mutual reinforcement prin-ciple based iterative algorithm can help remove noisy queries. In this section, we will also study the influence of this algo-rithm.

Since all queries in query-form graph are ranked according to their likelihood of belonging to the transactional type, we can evaluate the result by computing top K precision. The result is shown in Figure 5, where  X  X asic-approach X  means the iterative algorithm is not used while  X  X ith mutual rein-forcement X  corresponds with the result of mutual reinforce-ment approach after the algorithm converges. We can see that the mutual reinforcement approach achieves a precision of 89% at top 100 and maintains a precision of 85% at top 500. In addition, it is better than the basic method for al-Figure 7: The Number of Patterns Generalized from slot -cluster-based Method and the Average Quality of Top 50 Patterns Figure 8: The Number of Patterns Generalized from form -cluster-based Method and the Average Quality of Top 50 Patterns most all K values. For example, when K is 50, the mutual reinforcement approach can achieve 90% precision while the basic method can only achieve 72% precision. Those results indicate that the iterative algorithm incorporating mutual reinforcement principle is indeed effective to identify high quality transactional queries.

In addition, the mutual reinforcement iterative algorithm can converge quickly. Figure 6 shows the top 250 precision with iteration number. We can see that the result converges to the maximum after only 5 iterations. We have similar observations on the other settings, but we do not report the results due to space limitation.
In this experiment, the top 8,000 queries ranked by the mutual reinforcement approach in last step are used to gen-eralize patterns.
As mentioned in section 3.2, the content in web forms will be used to generate query patterns, and a basic solution is proposed: use slots and values of clicked forms (Direct-match). In Section 5.2 we discussed that by clustering slots and forms, the possibility of successful matching between query and form slots will be increased. Thus we can get slots and values of clicked forms, then use slot clustering results to include more slot and value pairs (Slot-cluster-based). We can also get slots and values of clicked forms, then use form clustering results to include more slot and value pairs (Form-cluster-based).

In order to evaluate the quality of query patterns, we man-ually rate the top 50 patterns generalized by each method. Each pattern is given one of four ratings: 4 (accurate and good generalization), 3 (accurate but bad generalization), 2 (incorrect and good generalization) or 1 (incorrect and bad generalization). We compute an average score for each group of 50 patterns.
 There are several parameters in the clustering algorithm. Weight coefficients such as  X  ,  X  and  X  in Equation 12 and 13 are decided based on our experiment experience. Both  X  and  X  are set to be 0 . 33 and  X  is set to be 0 . 5inour experiment. The threshold score  X  m of fuzzy matching in Section 3.2 is set to be 0.75.

Other parameters which affect clustering results include the threshold score used to merge slot clusters in Algorithm 2,  X  slot , and the one used to merge form clusters,  X  form conduct a study here on the effects of both parameters on the quality and quantity of query patterns.

Figure 7 shows the effect of the slot clustering similarity threshold on the number of patterns extracted using slot -clusters and the average quality of the top 50 patterns. We can see that as the increase of  X  slot the number of extracted patterns tends to decrease. It makes sense since a larger  X  will produce a smaller number of clusters, i.e. less slot and value pairs will be used for generalizing patterns. We can also see that the quality of patterns varies according to the change of the slot clustering similarity threshold. Basically, we can get that the quality of patterns is poor when there are excessive or inadequate patterns extracted. It also makes sense since a large number of patterns may include more noise, while a small number of patterns may cause to lose high quality patterns. According to this experiment, we set  X  slot to be 0.3.

After setting a proper  X  slot , we continue to study the effect of form clustering similarity threshold  X  form .Figure8shows the number of patterns extracted using form-clusters and the average quality of the top 50 patterns when the threshold of form clustering similarity changes. Like the effect of  X  slot similar observations can be made about  X  form .Weset  X  form to be 0.4 in the following experiments.

After choosing the optimal parameters, we compare the pattern generalization approaches using different sets of slot and value pairs, X  X irect-match X , X  X lot-cluster-based X  X nd X  X orm-cluster-based X . Figure 9 shows the comparison results with regard to both pattern number and pattern quality. We can see that, form -cluster-based method has the best average pattern quality. As expected, this method also generates more patterns than the other two approaches. According to our observation, form -cluster-based method indeed gen-eralizes better patterns. Some values in query cannot be matched by clicked forms. However, in many cases, such mis-matchproblemcanbeaddressedby slots from other forms in the same form cluster.

We present top query patterns generalized from form-cluster-based method for three domains, flight, car and hotel respectively, in Table 3.
In this section, we evaluate the performance of the pattern based transactional query prediction approach.

The patterns learnt from the previous section by using the form -cluster-based method are utilized for prediction here. We construct test data set by randomly sampling some queries from last 7 days X  log. After removing the queries which occur in the queries that are used for pattern learning, we get 324 transactional queries and 319 not-transactional queries labeled by human judges. In this experiment, Preci-sion, Recall and F 1 which are frequently used in classification problems are selected as the evaluation measures.

As we mentioned in Section 3.3, in prediction, threshold parameter  X  predict is used to determine whether a query be-longs to transactional category or not. In this experiment, we firstly tune  X  predict on a tuning data set (it contains 200 transactional queries and 200 not-transactional queries and there is no overlap between the tuning data set and the test data set). According to our experiment,  X  predict =0.5pro-duces the highest F 1 . Therefore, we set  X  predict to be 0.5 andthendotherestofexperiments.

Table 4 (the row named X  X attern-based X ) shows the trans-actional query classification results of the pattern-based clas-sification approach. 83% F 1 is achieved, which indicates the effectiveness of this approach.

Moreover, we compare the performance of our unsuper-vised pattern-based method with a supervised learning ap-proach for transactional query classification. We build a training data set for the supervised learning approach: 884 transactional queries and 864 not-transactional queries la-beled by human judges. A binary classifier with uni-gram features is trained based on the training set. (We adopt SVM algorithm and use SVM-Light [14] in this experiment).
Table 4 (the row named X  X upervised-approach X ) shows the transactional query classification results of the supervised [departure] to [destination] [make] [model] [year] [city] hotels Table 4: Comparison of Performance with Super-vised Approach Figure 10: Comparison of Performance for Different Feature Settings approach. We can see that the supervised approach is slightly better than our approach in terms of F1 measure. We also found that our pattern-based approach has a higher preci-sion (85%) than the supervised approach (79%) on trans-actional category, but lower recall (80% compared to 95%). This is reasonable, since the performance of pattern-based approach is limited to the coverage of patterns. In this ex-periment, some queries in test data can not be covered by any pattern, thus the pattern-based approach has a low re-call comparing with the supervised approach.

Furthermore, we examine whether our unsupervised pattern-based approach can help supervised learning approach. Be-sides uni-gram features used in the SVM classifier, we incor-porate  X  X attern matching X  as a new feature. Particularly, we add a new feature named  X  X ATTERN X . For a query, if it is classified into transactional query by the pattern-based approach, the value of  X  X ATTERN X  for this query is set to be 1, otherwise, 0. Figure 10 shows the F 1 values when different percentages of training data are used for two fea-ture settings:only uni-gram features(uni-gram feature) and including pattern as feature (with pattern feature). We can see that including pattern matching feature improves the classification performance, particulary when small amount of training data are used. The improvement becomes larger while less training data are used. This is reasonable, since supervised learning approaches rely on the amount of train-ing data. More training data can produce better result. The smaller the scale of training data is, the more valuable other information is.
By studying user behavior in search engine logs, Broder [4] and Rose [24] divide user queries into three different cate-gories, informational, navigational and transactional (noted as resource type by Rose). Several previous works [5, 19, 2] show that it is feasible to optimize search engines X  per-formance by adopting specific strategy and ranking method for informational and navigational queries. However, how to predict query type is an open research problem and many re-searchers have proposed different methods to tackle it. Kang and Kim [17] focus on the classification of informational and navigational queries. They manually separate documents into two sets, content pages and site entry pages. The dif-ference of query term distribution, mutual information, an-chor text usage rate and Part of Speech (POS) tagging in-formation over these two document sets are used to predict query type. The authors also extend their method to classify transactional queries in [16]. They use a supervised learning approach with the help of webpages whose title or linked anchor text contains the query. Jansen et al. [13] conduct a comprehensive study on query type using different search en-gines X  log. They adopt Broder X  X  classification of query types and further propose a three-level hierarchy classification for user search intents. Furthermore, they manually derive rules for each category to support the automatic query type clas-sification. Lee et al. [20] propose two groups of features to predict if the user goal is informational or navigational. They use user-click log to compute the click distribution and the average number of clicks per query. They also use the distribution of anchor text which contains the query to be classified. Later, Liu et al. [22] extend Lee X  X  work [20] and extract another two click features from search engine click throughlog:NClicksSatisfiedevidenceandTopnResults Satisfied evidence. A decision tree method is adopted for learning the model and prediction on new queries. As we have mentioned in the previous section, most of the existing methods rely on manual efforts to prepare training data.
In this work, we leverage user clicks on webpage forms to classify transactional queries. In database area, the webpage form is regarded as query interface of Deep Web database. There exist some research work of integrating multiple databases, such as WISE [11, 12] and MetaQuerier [10]. In [15, 23], query interface is modeled as a flat collection of fields. Each field is regarded as a triple tuple with a label, field type, and a finite collection of values. Later on, [23] proposes to use attributes to group sets of related fields together. [7] uses a hierarchical approach by building a hierarchy tree for each query interface in order to have the structured repre-sentation. The matching of Web query interface has also been extensively studied. Generally, there are two kinds of matching methods. [27] uses content information of fields in the query interface, e.g., labels, names and domain values to compute the similarity between two fields. Next, a cluster-ing algorithm is used to group similar fields together. [8, 9] adopt a correlation mining approach to match fields. They calculate the co-occurrence relationship between fields and infer the matching relationship between them.

There are many log mining research works incorporating toolbar log data. For example, [3] mines toolbar log data to suggest authoritative websites for search queries. In this work, we leverage the relationship between search query and online forms clicked by users after they examine the search results. According to our knowledge, we are the first to exploit form click information from tool bar log and use it to do transactional query type classification.

The concept of query pattern, also known as query tem-plate, is used in a few recent works. Agarwal et al. [1] mines query templates in a specific domain, with domain attributes and seed queries manually provided. In [26], Szpektor et al. uses query templates to provide recommendations for long-tail queries. Unlike these works, our work aims to automati-cally generate query patterns and further use these patterns as a classifier for transactional queries.
In this work, we proposed an unsupervised method for transactional query classification. The method is based on the relationship between search queries and online forms on webpages. By mining the query-form click graph which is built from toolbar log data, we were able to identify a set of high quality transactional queries. Also, by leveraging the contents contained by forms, we generalized the identified transactional queries into patterns, which were then used to predict queries not covered by log data. Experiments conducted on real data set showed that our method can identify high quality transactional queries effectively. The patterns extracted from the transactional queries and forms were also promising in predicting the type of unseen queries.
In future, we plan to optimize search engines X  performance by considering Web forms in search result ranking. We also plan to build a system to help users directly complete their transactions with Web forms, instead of using search engine.
