 1. Introduction XML has been widely accepted as the standard data representation for information exchange on the web.
XML stream systems in particular have attracted more interest recently [4,7,8,11,9,14] because of the wide range of potential applications such as sensor networking, online auctions, customized news delivery, and e-business processing. XML data that appears in XML documents or XML streams frequently tend to be recur-sive. In the study of [2] , 35 of 60 analyzed DTDs were recursive. This shows that recursive XML schemas are rather common in real world applications. Furthermore, queries may also be recursive as the descendant axis (//) is often used in path expressions.

Among the current XML stream processing systems, some of them consider only XPath queries [8,14,5] , while others support XQuery expressions yet typically over non-recursive data [11,4] . While YFilter [7] and
Tukwila [9] both support XQuery expressions over recursive data, they adopt the naive method of simply keeping all context information. Therefore, they cannot guarantee that the joins are triggered at the earliest possible moment, thus leading to extra storage.

One technique for processing XQuery is to model the query semantics as a combination of automata and algebra [16] , as also done in [7,9] . Let us first examine how the pattern retrieval is modeled as an automaton in Raindrop. Automata are naturally suited for matching path expressions over token sequences (a token being a start tag, an end tag or a PCDATA data item) since they were inherently designed for matching regular expressions over alphabet sequences. Tokens that match the patterns are extracted from the stream and composed into XML element nodes, that is into XML tree fragments. These nodes are then wrapped into tuples and sent to an algebra-based query processor for further manipulation, such as filtering or restructuring.

As mentioned before, one of the key differences between Raindrop and systems such as YFilter and Tukw-ila is that in Raindrop, the joins are invoked at the earliest possible moment using automaton-based invoca-tion. This results in the optimization of both storage and computation. Let us examine this feature of
Raindrop with an example. Consider the XQuery Q1 given below. This query finds all its name descendants for each person.

Q1: for $a in stream( X  X  X ersons X  X )//person
Consider document D1 shown in Fig. 1 . When we see the end tag for the first person (token 7), we have seen the entire content of this person element, along with all its name descendants. At this moment we can  X  X  X oin X  X  and output the person and all the name elements collected so far. Thereafter, the buffer for storing person and can again be used when we see the end token of the second person element (token 12).
 If invoked at the proper moments, the just-in-time structural join mentioned above can perform a simple
Cartesian product on person and name elements collected so far without actually having to evaluate the join predicates among the person and name pairs. However this simple Cartesian product will not work when the data is recursive. To explain this, consider document D2. Here the second person element (tokens 6 X 10) is a descendant of the first person element (tokens 1 X 12). We call such XML data recursive. Note that the second name element (tokens 7 X 9) is a descendant of both person elements, and thus should be combined with each to form a join output tuple. As a second criteria of correctness, the first person ele-ment and its descendant name elements need to be output before the second person element and its descen-dant name elements, based on the order restrictions imposed by XQuery. After the end tag of the first person element (token 12) has been encountered, we can join the two person elements with the  X  X  X ppropri-ate X  X  name elements, and output the results. Now the two person elements and the two name elements can be purged.

Since memory and CPU costs are both critical issues in XML stream processing, our goal is to optimize the storage and computation performance for handling XQuery, including recursive queries over XML streams.
To process recursive queries over recursive data, the following questions arise: 1. How best is the dual automata and algebra plan enhanced to support recursive queries? Since our automaton can retrieve patterns with descendant axis, it is naturally suitable to support recursive
XQuery. Clearly, we must thus change the algebra operators to let them cope with the recursive data. 2. How can we process recursive queries while keeping both memory and computation costs as low as possi-ble? Our goal is to enable Raindrop to process recursive queries on recursive data as well as recursion-free data while keeping the cost minimal in both cases. 3. Lastly, given a recursive schema and a recursive query, how can we identify which operators of the final query plan can still be mapped to non-recursive and thus cheaper query operators? 1.1. Our recursive Raindrop approach
Our solution to deal with recursive XQuery includes the following features: (a) For recursive queries, we keep the ID information and level information to determine ancestor X  X escen-(b) To process recursive XQuery expressions, a recursive structural join strategy must be employed that (c) Lastly, we also develop an algorithm that analyzes schema, when available, to check whether an XPath
Our contributions include: (1) We propose a new class of stream algebra operators for efficient recursive XQuery stream processing. We (2) We propose a context-checking algorithm at runtime that turns a join to be switched from the efficient (3) We have two modes for each operator: the cheaper recursion-free mode and the more expensive recursive (4) We propose an algorithm based on schema analysis that is able to check which mode of operator we (5) Our experiments illustrate that invocation mechanism of the structural join at the earliest possible 2. Raindrop basics
Raindrop uses an automaton-based model for supporting pattern retrieval on tokens and an algebra query model for processing filtering and reconstruction on sets of tuples. The query processing in Raindrop is com-posed of two phases. In the first phase, tokens are processed by an extended automaton-based engine to extract patterns out of the incoming token stream. When the tokens are scanned and recognized, they are passed to the upper layer of the engine, the algebra operators. In the second phase, these algebra operators create objects from these tokens, organize them into tuples, and then perform further operations on these tuples. 2.1. Retrieving patterns using automata
Our automaton model is based on a non-deterministic finite machine (NFA). It encodes the path expres-sions present in the query. For instance, the automaton corresponding to query Q1 is shown in Fig. 2 . Here states s2 and s4 are final states, corresponding to the two path expressions in Q1.

Our automaton is augmented with a stack, which keeps track of the context of the tokens. Given a stream of input tokens (the XML data), our automaton works as follows. Each final state in the automaton marks the sider all the states to which any of the states in S can transit to by consuming this token. These will form the token, then an empty set is pushed onto the stack. If the next token is an end tag, the current stack top is popped. The stack is then restored to the status before the matching start tag had been encountered. If the next token is a PCDATA item, this token is skipped.
Let us examine how patterns in document D1 in Fig. 1 are retrieved using the above automaton. Before the first token is seen, we have {s0} in the stack. When we see the start tag of person (token 1), we push {s1, s2} the corresponding algebra operators are now invoked, as will be discussed below.

Now, let us consider the start tag of the name element (token 2). We push {s1, s3, s4} onto the stack. s4 is again a final state, and the corresponding algebra operators will thus be invoked. The next token (token 3) is a PCDATA item, in which case no action is taken for automaton. However, the content of this PCDA-
TA item will be saved if it is the element to be returned in the query. Then we see the end tag of the name element (token 4). This prompts us to pop the top of the stack. Any corresponding algebra operators asso-ciated with s4 for the end tag of name will also be invoked. This process continues, and we identify all patterns. 2.2. Algebra plan
For any query, Raindrop generates an algebra plan that composes the tokens into tuples, and performs further operations on these tuples [16] . The algebra operators that are relevant for explaining the main issues related to recursion are: Navigate, ExtractUnnest, ExtractNest and StructuralJoin operators. The description of each operator is shown in Fig. 4 . These algebra operators in the query plan are invoked by the respective final states in the automaton. The algebra plan for query Q1 is shown in Fig. 3 .

Navigate path ! $ col is invoked when an element that matches path is identified by the automaton. This oper-ator keeps track of the start and end of this element. It also submits these events to its downstream Extract operators. For instance, op 1 keeps track of the start and end tag of person elements, and notifies the Extract operator, op 4, about the occurrence of any of these events. ExtractUnnest start tag by its upstream Navigate operator, starts collecting all tokens until it is notified about the arrival of end tag by its upstream Navigate operator. Being encountered on the input, op 4 will form one tuple for each person element. ExtractNest $ col is similar to ExtractUnnest one tuple. For instance, op 3 forms one tuple consisting of all the descendant name elements of a person. Struc-turalJoin $ col is invoked when an end tag of $ col token is encountered by the  X  X  X orresponding X  X  Navigate oper-ator. It combines (by performing Cartesian product) the tuples from its branch operators. For instance, op 5is invoked whenever the end tag of person is seen by op 1. It combines the person tuple from op 4 and the set of names grouped into one tuple from op 3, and outputs this result. 2.3. Plan execution
Let us examine how Raindrop utilizes both the automata and the algebra based techniques to execute a query and obtain the results. Consider again query Q1 executed on document D1. When the start tag of person that eventually will be put together to form one tuple. When the start tag of name (token 2) is seen, the states {s1, s3, s4} are pushed onto the stack. s4 is a final state. Thus it invokes operator op 2, which in turn invokes op 3. op 3 now starts collecting tokens.

When the end tag of name (token 4) is seen, we pop the top of the stack which happens to be {s1, s3, s4}. s 4 is a final state, it invokes op 2, and op 2 informs op 3 to stop collecting tokens. When the end tag of person (token 7) is seen, we pop {s1, s2} from the stack. s2 is a final state, thus it invokes op 1. op 1 in turn informs op 4 to stop collecting tokens. After this op 1 invokes op 5, which performs the join over the branch operators. In this case, there is one tuple in the output buffer of op 3 and one tuple in the output buffer of op 4. These two are combined, and then output. Also the output buffers of op 3and op 4 are cleared. The same process is again repeated for the second person element. Two features observed here are: (a) the invocation of the structural join is done at the earliest possible time, thus ensuring buffers are cleaned up early; and (b) this structural join does a simple Cartesian product, without requiring to evaluate and analyze the content of the two data items, nor requiring any join comparisons among the respective join partners.

The logic invoked by the start tag and the end tag is described in Algorithm 1. 2.4. Issues for recursive XML data
As Table 1 indicates, the basic Raindrop query processing techniques mentioned above cannot process recursive queries on recursive data for various reasons. For non-recursive data, the Navigate operator invokes the structural join whenever the corresponding end tag is encountered. This does not work for recursive XML data, such as document D2. Note that when we see the end tag of the second person (token 10) in document
D2, we have not yet seen the first person entirely. Nonetheless the first person needs to be output before the second person according to the XQuery semantics. Hence invoking the just-in-time StructuralJoin operator for the second person element and then purging the output would cause a problem. This means the Navigate operator should invoke the structural join only after the end tags for all the nested person elements have been seen (that is, token 12 is seen).

Algorithm 1. Pseudocode of Automaton
Also for non-recursive data, the ExtractNest operator performs the grouping of all the name elements it has collected. This was possible because for D1 any name element will join with at most one person element. Cer-tainly this need no longer be true for recursive data. For instance, the second name element (tokens 7 X 9) joins with both person elements. Therefore, one possible solution could be that the ExtractNest does not perform the grouping; instead the grouping is performed by the downstream structural join.

Furthermore note that the structural join for non-recursive data performs a simple Cartesian product of all its input branch operators. However, for recursive data such as D2, two person elements have been extracted by op 4, and two name elements have been extracted by op 3. We cannot simply perform a Cartesian product anymore, as that would lead to incorrect results. Instead we have to check the ancestor X  X escendant (or par-ent X  X hild) relationships between these person and name elements. This requires additional information to be associated with the elements.

In the next section, we will examine in detail how Raindrop executes recursive queries over recursive data.
 3. Recursive-mode operators
The problems mentioned above arise when both the query and the data are recursive, which is a case we will now tackle in this section to enable Raindrop to process recursive queries over recursive data. We will first describe how we will associate additional information with each element. We will then investigate how each of the four algebra operators mentioned in Section 2 are modified to handle recursive data. 3.1. Associating IDs with elements
Each element is associated with a triple (startID, endID, level). Here, the startID of an element is given by the tokenID of the corresponding start tag, and its endID is given by the tokenID of the corresponding end tag. For instance, the startID of the first name element in D2 is 2, and the endID of this element is 4. The level of an is 1. This numbering scheme is similar to the DFS traversal numbering, as also used in other works [10] .
Given two elements and their corresponding triple encodings, we can determine ancestor X  X escendant and parent X  X hild relationships. For instance, consider the first person element in D2 whose triple is (1,12,0), and the first name element in D2 whose triple is (2,4,1). We can determine that the first name element is a descen-dant (also a child) of this person element because (2,4) is contained in (1,12,0) and the level difference is exactly 1. 3.2. Features of recursive Navigate operators The recursive Navigate operator functions differently from the non-recursive Navigate in several ways.
First, the recursive Navigate operator now need to generate the triple for each corresponding element. These triples are kept in the order they arrive, which is the startID of the corresponding elements. For instance, con-sider document D2, and op 1in Fig. 3 . Corresponding to the two person elements, op 1 will keep the following when the start tag is seen, and then its endID will be recorded when the end tag is seen. At that time, we know that the whole person element has been seen.

Secondly, the non-recursive Navigate operator will call its structural join operator, whenever the end tag of the element is seen. The recursive Navigate operator on the other hand will call its structural join operator only then all the triples in this Navigate operator are  X  X  X omplete X  X , which means that we have seen the entire data for every one in that list. For instance, when we see the end tag of the second person (token 10), op 1 will triple is added later, we know that the triples are already ordered according to the time when they are created.
Note that the first person element is not complete. Therefore, op 5 is not invoked. When the end tag of the first complete, and therefore op 5 will now be invoked.

Thirdly, the recursive Navigate operator needs to pass the triple information to the structural join in the order in which they are kept. Let us examine why the Navigate needs to pass this triple information by looking at the example query Q2.

Q2: for $a in stream( X  X  X ersons X  X )//person
The algebraic plan for Q2 is similar to that shown in Fig. 3 , except that op 4 is now replaced by a Navigate and an ExtractNest operator that extract the mothernames for each person. When the structural join receives the mothernames and names for multiple person elements, it needs to know the person triples for determining which mothernames and names should join with which person elements. 3.3. Features of recursive ExtractUnnest operators The non-recursive ExtractUnnest operator blindly extracts the tokens when being invoked by its upstream
Navigate operator, forms tuples from these tokens, and passes these tuples to its downstream StructuralJoin operator. The recursive ExtractUnnest operator, in addition to extracting the tokens and forming tuples from the data, also adds the (startID, endID, level) information for every element to its corresponding tuple. For instance, consider query Q3 below.

Q3: for $a in stream( X  X  X ersons X  X )//person, $b in $a//name
The plan for Q3 will look similar to the plan in Fig. 3 , except that op 3 is replaced by ExtractUnnest consider the two tuples corresponding to the two name elements in document D2 formed by op 3. In short, op 3 will be used by op 5 while performing the structural join. The algorithm for the ExtractUnnest operator is shown in Algorithm 2.

Algorithm 2. Pseudocode of ExtractUnnest 3.4. Features of recursive ExtractNest operators The non-recursive ExtractNest operator groups all the tokens that it has collected into one single tuple.
However, for recursive data, such blind grouping is not correct anymore. Let us consider document D2, it is not feasible as the ExtractNest operator op 3 stores the information only regarding the name elements.
But the first name element (tokens 2 X 4) does not join with the second person element (6 X 10), also the second name element (tokens 7 X 9) joins with both the person elements. In order to do correct grouping, we have to know the triple information from person element. Therefore instead of op 3 performing the grouping, Rain-drop will move the grouping operation to the downstream structural join, op 5 in this case.

The recursive ExtractNest in Raindrop is therefore similar to ExtractUnnest, that is, it extracts tokens into tuples, adds the (startID, endID, level) information for every element to its corresponding tuple, and passes this information to the downstream StructuralJoin operator, which will perform the grouping, as further explained below. 3.5. The recursive StructuralJoin operator
As compared to the non-recursive StructuralJoin operator, the recursive StructuralJoin operator has to per-form additional operations, including: (a) ID-based comparison among its branch operators; and (b) grouping when its upstream operator is an ExtractNest operator. In this section, we will examine the invocation mech-anism and other features of this recursive StructuralJoin. 3.5.1. Invocation mechanism of recursive StructuralJoin
For non-recursive data, the StructuralJoin $ person operator ( op 5) in Fig. 3 is invoked whenever the end tag of $ person is encountered. Such invocation mechanism causes problems when processing recursive data.

For example, when we process the data shown in document D2 in Fig. 1 , the end tag of the second person (token 10) is encountered first. Based on this encounter of the end tag, op 5 is invoked. This StructuralJoin generates the output tuple composed of the second person element (tokens 6 X 10) and the second name element (tokens 7 X 9). Then this person element and name element would be cleaned because they have already both been output by op 5. When the end tag of the first person element (token 12) is encountered, op 5 is invoked again. This time, the first person element (tokens 1 X 12) would not be joined with the second name element because this name element has already been deleted from the buffer. This happens for recursive data, because one name element can be descendant of multiple ancestor person elements. We do not want to delete the data which we may use later.

A second problem of this invocation mechanism is that the output does not conform to the correct stream order because the second person element is output first. To address this, suppose we have two person elements, one of which is a descendant of the other element, then we need to keep the person element and invoke op 5 only after the end of the outermost person element. Then we can guarantee that: (a) we will not lose any data that will be needed later; and (b) the data can be output in the correct order.

Now the first question we face is how can we know that the end of the outermost person element has been reached? Recall that in Raindrop the StructuralJoin operator is invoked by the corresponding Navigate oper-ator. We now observe that the Navigate operator has been modified to first check whether the endIDs of all its op 5 only after seeing token 12. This ensures that the end of the outermost person element has indeed been reached. 3.5.2. Algorithm for recursive StructuralJoin
Consider StructuralJoin $ col ; let its branch operators be B ={ bop recursive StructuralJoin is given in Algorithm 3. The StructuralJoin is invoked by its corresponding Navigate operator. This Navigate operator may have one or more complete triples at this point. The StructuralJoin iter-branch operators (lines 02 X 16). If the branch operator bop find the element corresponding to this triple t by performing ID comparison, and add it to the output list o operator bop i (lines 03 X 06). Otherwise, we check whether bop
If it contains //, this means we need to determine ancestor X  X escendant relationship between t and every ele-ment e in the output buffer of bop i by performing ID comparison. The descendants will be added to the output list o i (lines 08 X 10). If bop i does not contain //, it means we need to determine parent X  X hild relationship between t and every element e in the output buffer of bop o (lines 12 X 14).
After the above ID comparison, o i contains the set of elements corresponding to the current triple, for this branch operator. Now for the ExtractNest operators among the branch operators, we need to group all the elements in o i to form one tuple (lines 15 X 16). At this stage, we would have obtained the set of elements cor-responding to the current triple. We can simply perform the Cartesian product of these o the output for the current triple t . We continue to iterate over the remaining triples. After we have iterated over all the triples, the output buffers of all the branch operators are purged. Observe that the output tuples
Algorithm 3. Pseudocode of Structural Join 3.5.3. Differences between recursive structural join and non-recursive structural join
Above we have described the algorithm for recursive structural join logic. Comparing the recursive struc-tural join with the non-recursive structural join, the following differences can be observed: (1) The invocation mechanisms are different. In the non-recursive structural join, the structural join will be (2) The processing of data kept in the buffer of each branch operator is different. In the non-recursive struc-3.6. Context-aware StructuralJoin operators
As discussed before, the recursive structural join needs to perform an ID comparison and thus is more expensive than the just-in-time structural join which only performs a simple Cartesian product. To reduce the cost of the overall plan, we want to use the cheap structural join whenever possible.

We note that at run-time we can determine whether the current data fragment is recursive or not by checking the number of triples passed to the StructuralJoin from the Navigate operator. If only one triple is buffered in the Navigate operator, this implies that the current element is not recursive. In this case, the
StructuralJoin operator will execute the just-in-time structural join that has no ID comparison and thus is faster. If there are more than one triple stored in the Navigate operator, we have to perform recursive struc-tural join. We incorporate this context-dependent decision of plugging in the most appropriate functionality at runtime into the StructuralJoin operator itself, which we call the context-aware StructuralJoin. The con-text-aware StructuralJoin is capable of at run-time switching from the efficient just-in-time join strategy for elements that are recognized to be non-recursive to the more powerful ID-based structural join strategy for elements that are identified to be recursive. The execution process of the context-aware StructuralJoin is shown in Fig. 5 .
 From Fig. 5 , we can see that when an appropriate end tag is recognized by the automaton, it informs the
Navigate operator. This Navigate operator in turn invokes the context-aware StructuralJoin operator, if all the triples in the Navigate operator are filled. The context-aware StructuralJoin first checks whether this data fragment is recursive or not, by checking whether there are multiple triples in the Navigate operator. This is shown as the Context Check step in Fig. 5 . If the data is not recursive, then the just-in-time structural join strategy is called; otherwise, the recursive structural join strategy is called. These results are then output, and the joined tuples are then completely purged.
 4. Optimized plan configuration based on schema analysis 4.1. Motivation of schema analysis
As we have discussed in Section 3 , the StructuralJoin operator is the most expensive one because we need to do ID-based comparison. Thus, in the plan generation, we hope to generate as few context-aware Structural-
Join operators as possible by investigating both query and schema. In many cases, even if the schema is recur-sive and the query is recursive, it may not be necessary to generate the recursive StructuralJoin operator.
For instance, given the schema as below: h !ELEMENT a (a,b) i h !ELEMENT b (d) i h !ELEMENT d (#PCDATA) i
For the XPath expression/ a / b // d , the query and the schema are both recursive. However, we do not need to generate a context-aware StructuralJoin since we know the  X  X  X  X  X  element cannot be recursive. If query result can be shown to be not recursive in advance, we can generate just-in-time structural join. Since structural join corresponds to  X  X  X or X  X  clause in the XQuery, we need to investigate the question that, given a recursive XQuery and the schema knowledge, which type of structural join would be sufficient for the  X  X  X or X  X  expressions? 4.2. Optimizing generated plan based on query and schema Next, we will examine how based on the query and the schema, we can generate more efficient plans.
The determination of which mode operators to generate in the plan is achieved by a two-step checking pro-cedure. The first step checks the query to see whether it is recursive. If the query is not recursive, then inde-pendent of the schema being recursive or not, we can generate the plan exclusively composed of recursion-free mode operators. On the other hand, if it is recursive, the second step must be performed. The second step ana-lyzes the schema for recursion, and then compares schema and query with matching. If the query is recursive and schema is not recursive (QR/SNR), this implies that data will not be recursive. Then clearly the result cannot be recursive either. In this case, we can generate the plan which includes only recursion-free mode oper-ators. If both the query and schema are recursive, this falls into  X  X  X R/SR X  X  case. We will analyze the schema to see what kind of structural join we need to generate for each XPath expression in the  X  X  X or X  X  clause. After that we can decide to generate which mode for each type of operator in the optimized plan. The final form of opti-mized plan for the four cases is described in Fig. 6 .
 (1) The first step is to check the query to see whether the query is recursive. This can be done by: (2) Check whether the schema is recursive. This step is done by checking the automaton representing schema 4.2.1. Schema analysis algorithm
The schema for query Q5 and its corresponding automaton are shown in Fig. 8 . A construction of such an automaton is straightforward and the automaton depicts every possible path in an XML document instance.
We construct an automaton corresponding to each XPath expression in the  X  X  X or X  X  clause. Here we consider every XPath expression which corresponds to binding of each variable in each  X  X  X or X  X  clause. We construct an automaton based on each XPath. We classify the XPath expressions into two categories: the XPath expres-sions which do not contain any predicate, and the XPath expressions which contain existence predicates. 4.2.1.1. The  X  X  X or X  X  clause without predicates. For the XQuery, in query Q5, we have the following three path there is a corresponding StructuralJoin operator. In query Q5, since we have three XPath expressions, we need to construct three automata. These three automata are shown in Fig. 9 . The construction of the automata fol-lows [15] .

After constructing the automaton for the schema and the automata of all the  X  X  X or X  X  clauses, the process of judging which mode StructuralJoin operators to generate is described as follows: (1) Assume the automaton for schema is S and we have k XPath expressions P (2) Finally we need to check whether there is a loop existing on the path from the root to the terminal state 4.2.1.2. The  X  X  X or X  X  clause with existence predicates. In the above example, we only consider the query which does not contain predicates in the  X  X  X or X  X  clause. However, it is very common to have existence predicates in the XPath expressions. Let us consider XPath  X  X //a//b[d][e]//c X  X . Here we must further check whether the ele-ment b can have the branch d and e. If these two branches do not exist in the schema, we can conclude that there will never be any output for this query. Hence, it is possible to check two things with schema: (1) For each XPath expression, what kind of structural join we need to generate in the plan; and (2) will the predicates in XPath expressions of  X  X  X or X  X  clause be disqualified by checking the schema? Suppose the general form of an XPath expression with existence predicates is given in the form of: P := Q / Q j Q // Q j e Q := aR R := T j RT j e T :=[ x ] j [ y ] j [ z ] j ...
 Here a , x , y , z and e are terminals. P , Q , R and T are non-terminals.

We can use the algorithm described in Section 4.2.1 . For checking predicates, the most intuitive solution would be to check the predicates one by one in the schema graph.

For the predicate in one XPath expression, if any path fails when checking the schema graph, we can say that this predicate is impossible to be satisfied. Thus this XPath expression is never reachable. Furthermore, if any XPath fails, we know that the query will not generate any output. Such a non-satisfied query does not need to be executed. On the other hand, if we do not find failed predicates, we can then generate the corre-sponding structural join by following the same step as in the discussion about  X  X  X or X  X  clause without predicates. 4.3. Algorithm of plan generation based on schema analysis
In summary, we now put the optimized plan generation algorithm based on the above schema analysis together.

First, we will generate an initial plan based on checking the query. If the query contains a// in the  X  X  X or X  X  clause, this query is said to be recursive. In this case we will generate an initial plan composed of all recur-sive-mode operators. Then we conduct the schema analysis. For a non-recursive query, we do not need to gen-erate any recursive output. Thus we generate directly a recursion-free mode plan. The schema analysis phase below then would be skipped.
 The schema analysis is composed of the following steps:
For each XPath, we conduct the following tasks: (1) Check whether it contains predicates, if yes, continue. Else jump to step 3. (2) For each predicate in the XPath, check the schema graph to see if any predicate guarantees to fail. If yes, (3) Construct the product automata of the automata for XPath and the schema. Check if there is any loop After the above three steps have been applied to each XPath, we traverse the plan in a top X  X own manner. responding Navigate operator of this child StructuralJoin as recursive Navigate operators to pass up ID information.
 Finally we instantiate the rest of the operators in the plan as recursion-free mode operators. After this schema analysis, a new plan has been generated as shown in Fig. 11 .

Note that only op 1 need to be recursive among three StructuralJoins in the plan in Fig. 11 because the result perform ID comparison. However, op 2 is a non-recursive StructuralJoin operator. To make its parent, op 1 work correctly, we instantiate op 4 as recursive Navigate operator. Thus op 2 can get the ID information of b from op 4 and then pass up its ID as well as its output up to op 1. Therefore, if a recursive StructuralJoin has any non-recursive StructuralJoin operator as its child, we need to instantiate the corresponding Navigate operator for this child StructuralJoin as recursive Navigate operator.
 5. Related work
Refs. [13,3] evaluate XQuery expressions over XML streams using a two-phase approach which separates
Recursion could be handled in such an approach in the second phase, i.e. using the well-studied algebraic query evaluation methods typically applied to (static, i.e. non-stream) XML data. However, such a two-phase solution does not fit well with the requirements of stream processing applications which require continuous query evaluation and immediate data purging to preserve memory.

Ref. [5] proposes to apply an encoding scheme in order to handle recursion. However, only XPath expres-sions have been considered in their work. In XQuery, careful synchronization between the pattern retrieval and query execution would need to be designed in order to achieve acceptable performance for recursion handling.
Ref. [11] uses a transducer model for evaluating XQuery over streaming XML. They do not consider recur-sive schemas. Transducers are simply FSA, augmented with buffers where you can store data which can be output later. However, FSA without stack are not sufficient for handling recursion.
 YFilter [17] follows the algebraic paradigm, introducing node-label trees for on-the-fly XQuery evaluation.
Their main focus is on the evaluation of multiple queries. However, the approach of YFilter is not optimal for handling streaming XML input. This is because the proposed whole-path loading approach causes storage redundancy and extra join cost. Also, the evaluation strategy for the join operator cannot guarantee that the structural join will always be executed at the first possible moment  X  which is a desirable property to aid us in purging the buffer immediately and avoiding output delay.
 The goal of [4] is to minimize the buffer size. Again, recursion handling is not considered in their work.
Their focus is on an orthogonal issue; they study when a token can be output at the earliest. Raindrop can incorporate their techniques to generate fast output as well.
 Another algorithm similar to our recursive structural join strategy is the tree-merge join algorithm in [1] .
However, they do not consider the streaming scenario; therefore the performance benefits of invoking the structural join at the earliest possible time is not their focus. Another algorithm mentioned in [1] is the stack-tree join algorithm. Here, they use two lists: an ancestor list and a descendent list, and they use a stack to keep the ancestor X  X escendent relationship among the elements in the ancestor list. So whenever an element at the top of the stack matches a descendent candidate, they can conclude that all the elements in the stack can also match that descendent candidate. But these generated tuples can not be output immediately because they do not conform to the document order. To solve this problem, this algorithm uses two extra lists for every the join results of its descendants among the ancestor list elements. The disadvantages of the stack-tree join large storage space is needed. 6. Experimental results
We use ToXgene [6] , an XML data generator, to generate XML documents. All the experiments are run on a 2.8 GHz Pentium processor with 512 MB memory. We perform three sets of experiments. The first one shows that when joins are invoked at the earliest possible time, we require less memory for query processing.
The second set of experiments shows that the context-aware structural join is more efficient than always using recursive structural join. The final set of experiments shows the benefit of our plan generation method, where we use recursion-free mode operators whenever possible. 6.1. Advantages of early invocation of structural join
In this set of experiments, we study the memory usage when we invoke structural join at different times. We use query Q1, where the earliest time the structural join can be invoked is when we see the end tag for an outermost person. We measure the memory usage by counting the number of tokens we need to hold in the buffer before we shows the average number of tokens stored in the buffer (defined by the expression below) for five cases: zero-is invoked one token later than the earliest possible time); two-token delay; three-token delay; and four-token delay. Note that four-token delay causes about 50% more tokens to be stored than the zero-token delay. The definition of the average number of tokens stored in the buffer is given by:
Here, b i is the number of tokens stored in the buffer after we see token i ; n is the total number of tokens we have processed so far.

Fig. 12 shows only the buffer savings when structural join is invoked at the earliest possible time, i.e., zero-token delay. Actually computation is also saved as fewer ID comparisons need to be performed when there is a zero-token delay. 6.2. Efficiency of context-aware StructuralJoin The experiments reported in this section illustrate the performance benefits of using the context-aware StructuralJoin rather than always using the recursive structural join. Context-aware StructuralJoin uses just-in-time structural join strategy when it finds that this data fragment is not recursive; otherwise, it uses recursive structural join strategy. For this set of experiments, we generate data sets, each of which has a size of about 30 MB, with varying percentage of recursive data from 20% to 100%. A data set with say 20% recur-sive data is generated as follows. We generate the recursive data portion of about 6 MB and the non-recursive data portion of about 24 MB separately using ToXgene; then we compose these two data portions into one XML file.

The query we use is query Q3. Q3 tries to find for every person element, its name descendants, and for each such name, it returns the person element, and this name element.

When 100% of the data is recursive, the context-aware StructuralJoin will always use the recursive struc-tural join strategy, and hence has no extra benefit. Note that there is a small overhead, caused by the fact that the context-aware StructuralJoin has to check every time whether the data is recursive or not. However when the percentage of recursive data is less than 100%, there is always benefit in using context-aware structural join, as shown in Fig. 13 .

To further test the impact of the overhead of context-aware StructuralJoin, we run the second set of exper-iments on data of varying recursion level. The query we use is query Q2 and the data files are about 10 MB. Q2 tries to find for every person element, its mothername descendants and name descendants. Note that when the The execution time of running data with different recursion level is shown in Fig. 14 .

Fig. 14 shows that the execution time increases quickly when the recursion level increases. This is because we need to compare more person elements with mothername elements and name elements for each  X  X  X omplete X  X  nested person fragment. The context-aware StructuralJoin wins when recursion level is 1. Note that even when the recursion level increases up to 20, the overhead of context-aware StructuralJoin is still very small. 6.3. Advantage of using recursion-free mode operators
In this section, we study the benefits of our clever plan generation, where we analyze the query, and try to use as many recursion-free mode operators as possible. Recursion-free mode operators are more efficient than recursive-mode operators even if they operate on the same data. The queries we use for this set of experiments are Q6 and Q7 given in Fig. 15 . Note that one StructuralJoin operator will be generated in the plan of Q6.
However, Q7 is more complicated. Three structural join operators corresponding to three XPath expressions in  X  X  X or X  X  clause will be generated in the plan for Q7.

When we analyze the query Q6 and see that the path expression corresponding to $a has no //, we would generate a plan where all operators would be recursion-free mode. For instance, we would have a just-in-time structural join on $a in Q6. And we would have three just-in-time StructuralJoin operators in Q7. If we had not performed this query analysis, we would have used recursive-mode operators; for instance, we would have a context-aware structural join on $a in Q6. Fig. 16 shows the execution time difference between using recur-sion-free mode operators, and recursive-mode operators for Q6 and Q7. We are running experiments on non-recursive data from 6 MB (that outputs 2 K tuples) to 42 MB (that outputs 14 K tuples). Observe that using recursion-free mode operators saves between 10% and 40% of the total execution time. 7. Conclusion
We propose a new class of stream algebra operators for efficient recursive XQuery stream processing. In egy that efficiently processes joins when the XML substreams are non-recursive; and (b) the recursive struc-tural join strategy supports structural joins with ID comparisons when the XML substreams are recursive.
In this paper, we have proposed a context-aware structural join. This context-aware structural join uses the recursive structural join strategy when the data is recursive. When the data is not recursive, it switches to time, leading to less memory usage. In addition, in the plan generation, we discussed how to analyze the schema to generate as many recursion-free mode operators as possible. Our experiments illustrate the perfor-mance gain achievable by each of the above techniques.

As part of our future work, we are currently investigating how to optimize the plan if the schema is changed at runtime. For instance, switching the plan of recursion-free mode operators to the plan with recursive-mode operators when we derive the schema is recursive at runtime. Also the schema can be used for outputting tokens and invoking structural join earlier. In addition, we only consider forward axes in this paper. We can extend our work to incorporate backward axes in the future.

References
