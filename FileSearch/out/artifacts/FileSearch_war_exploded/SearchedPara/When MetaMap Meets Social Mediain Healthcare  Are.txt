 Hongkui Tu 1( Health forums like HealthBoards and MedHelp enable patients to learn and communicate on health issues online. A major advantage of such medical forums is that patients are able to get advices from peers, and sometimes professionals. Compared with traditional medical data ( e.g., electronic health records), online social platforms are able to provide a large amount of streaming data contributed by millions of users. Mining such large scale user generated content (UGC) helps us better understanding of users and patients on many health related topics. In many studies conducted on the medical forum data [ 3 , 4 ], Unified Medical Language System (UMLS) has been introduced to identify the medical words, as a pre-processing. The most popular tool for recognizing UMLS concepts in text is MetaMap. 1 on UGC in medical forum. Therefore, the correctness of the word labels by directly applying MetaMap on forum data may not be high enough to support the next level studies. We further illustrate this point by using two example sentences taken from a medial forum and the corresponding word labels assigned by MetaMap.  X  Welcome back [Body Location or Region] , thanks [Gene or Genome] advice [Health Care Activity] .  X  X  [Inorganic Chemical] have exactly the same [Qualitative Concept] calf pain [Sign or Symptom] when sitting [Physiologic Function] In the example sentences, the words or phrases that are identified by MetaMap are underlined, and the assigned semantic types are in square brackets. Observe that, words like  X  X  X ,  X  X hanks X  are commonly used in online medical forums. However, these words are often wrongly assigned to incorrect semantic types by MetaMap. The words that are closely related to medical domain like  X  X alf pain X  are assigned to correct semantic types. For the professional textual documents, it is very rare to have phrases like  X  X elcome back X . On the contrast, in the UGC from social media, such informal phrases frequently appear. Here, we focus on the evaluation of the words and phrases that are  X  X ecognized X  by MetaMap, and recall is not considered in this study, because manually labeling a large number of words and phrases from social medical data is not practical.
 sentences from a popular medical forum HealthBoards, 2 which was launched in 1998 and it now consists of over 280 message boards for patients. The anonymized dataset is released by the authors in another study [ 5 ]. tate the correctness of the word labels by MetaMap on 100 randomly selected posts covering different message boards. These posts consist of 665 sentences and MetaMap returns 3758 word labels. 4 After manually annotating the correctness of the word labels assigned by MetaMap, we make five observations in Sect. 2 . various types of free text. Stewart et al. [ 7 ] compare the precision of MetaMap and MGrep for medical lexicons mapping on a medical mailing list dataset. Denecke et al. [ 1 ] do a qualitative study with MetaMap and cTakes on  X  X ealth Day News X  and blog postings from  X  X ebMD X . Compared with social forums, the language of News and Blogs is relatively more formal. Most relevant to our study, Park et al. [ 6 ] characterize three types of failures when applying MetaMap to online community text related to breast cancer. The authors further incorporate Stanford POS tagger and parser with some handcraft rules to revise the outputs. Our study complements the study reported in [ 6 ] as we focus on a different dataset ( i.e., posts from HealthBoards) and the data covers a wide range of topics. We make observations on the correctness of labels by MetaMap based on their semantic types. We also show that the labels of several semantic types have relative high precision, which could benefit next stage study, depending on the task. Data Annotation and Observations. We randomly selected 100 posts from the data set and split them into sentences with NLTK. 5 We get 665 sentences in total. Then all words in the sentences are labeled with all the semantic types using the Java API of MetaMap 2014 Windows version. 6 In using the API, the word sense disambiguation option was selected and the other options/parameters were set to their default values. As the result, 3758 words are labeled by MetaMap and there are 1383 unique words. We recruit 2 graduated students to annotate the 665 sentences and compute the Kappa coefficient (  X  =0 . 889), which suggests that annotators can reach a high agreement.
 Observation 1. The precision of the word labels by MetaMap with all semantic types is fairly low at 43.75 % only.
 With all the 135 semantic types in consideration, the precision we obtained on the 3758 word labels is 43.75 %, which is not promising. The low precision suggests that MetaMap is very unlikely to assign correct semantic types to words obtained from social medical data. We also observe that some semantic types ( e.g., Reptile, Cell Function) are not used to label any words. It is understood that because of the extremely wide coverage of the UMLS concept space, not all concepts are discussed in medical forums. Either the semantic types are not of interests of the patients ( e.g., Reptile) or the semantic types are too domain-specific for discussions among non-experts ( e.g., Cell Function).
 Observation 2. The precision on the semantic types of general concepts is rel-atively high and much lower for the word labels of concepts in (narrow) domain-specific semantic types.
 As not all semantic types are covered in forum discussion, we now study the largest 38 semantic types ranked by the number of instances in the annotated data. Each of the 38 semantic types, listed in Table 1 , has at least 20 word labels. Observe that the semantic types obtaining high precisions ( e.g., greater than 85 %) are mostly general types such as [Entity] ( e.g., things), ( e.g., people, women), [Daily or Recreational Activity] ( e.g., read, speaking), Part, Organ, or Organ Component] ( e.g., ears, hair). Concepts in these semantic types, however, are less related to healthcare in many cases. However, Symptom] ( e.g., tired, sleepless) got a precision at 89.58 %. The words assigned with this type are seemingly of less ambiguity. Among the 6 semantic types that have higher precision than 85 % and with lots of instances is type is more likely to be assigned to words like  X  X hink X  and  X  X ope X , which are words that are widely used in online discussions and may not be specifically for communicating medical related issues. There are five semantic types where the word labels are of extremely low precisions, below 10 %. They are and [Gene or Genome] . As the names suggest, the concepts in these semantic types are very domain-specific. Without considering the context of the words, the word labels assigned by MetaMap are of very low quality. In particular, the word  X  X  X  is assigned to [Inorganic Chemical] , which is also highlighted in [ 6 ]. It is understood that this word may not appear many times in medical literature or medical records; when dealing with content directly contributed by patients, the usage of this word could be extremely high, but not referring to inorganic chemical. Observation 3. Most semantic types with a large number of instances are not medical or healthcare related.
 In Table 1 , the semantic types each has more than 50 instances are in bold-face. Other than [Inorganic Chemical] which contains most appearance of the wrongly labeled word  X  X  X  as discussed above, the semantic types with a large number of instances are mostly general concepts, e.g., [Qualitative Concept] names of these semantic types are self-explanatory, and the words are obviously not specifically related to healthcare or medical. The other large semantic types include [Idea or Concept] containing words like  X  X ife X , and taining words like  X  X utside X  and  X  X n X . Both semantic types have low precision at 30 % or below.
 Observation 4. Limiting to a selected subset of (more medical related) seman-tic types does not necessarily lead to much higher quality word labels on medical forums.
 As mentioned before, the semantic type [Sign or Symptom] related to medical and healthcare, has a relatively large number of instances with a precision of 89.58 %. Example words assigned to this semantic type include  X  X leep-less X ,  X  X nsomnia X  and  X  X iredness X . In [ 2 ], the authors selected 14 semantic types which are more related to medical and health topics in our understanding. These 14 semantic types are [Antibiotic] (3), [Clinical Drug] (1), (9), [Disease or Syndrome] (65), [Drug Delivery Device] (0), [Experimental Model of Dis-(0), [Finding] (135). [Injury or Poisoning] (16), [Mental or Behavioral Dysfunction] (29), [Pharmacologic Substance] (77), [Sign or Symptom] (48), peutic or Preventive Procedure] (37), and [Vitamin] (0). The numbers following each semantic type are the number of word labels in the annotated data. The total number of instances under these 14 semantic types is 437. Observe that, there are three semantic types have no words assigned to them. Nevertheless, in the follow-ing discussion, we will simply use the selected 14 semantic types to refer to this set of semantic types without taking out the three with no instances.
 The precision of the word labels assigned to these 14 semantic types is 56.75 %, which is better than the overall precision computed on all the 135 semantic types, but remains low. In other words, the quality of word labels on the selected set of more medical related semantic types is not promising. Observation 5. Removing the high-frequent words may not necessarily be a good choice in pre-processing.
 In [ 2 ], the authors filter out the popular words from their data which are ranked among the top-2000 in Google N-Grams. 7 Following this idea, we filter from the 3758 labeled words the top-2000 Google N-Grams, resulting in 1688 word labels. Removing more than half of the identified word labels suggests that there exists a big overlap between the set of words identified by MetaMap and the popular words in Google N-Grams. The precision computed on the remaining 1688 word labels is 58.77 %. Although this is a much better value compared to 43.75 % before the filtering, there remain about two fifth incorrect word labels after the filtering. We argue that, simply removing the most frequent words based on Google N-Gram may not be a good choice in pre-processing.
 wrongly labeled, e.g.,  X  X  X  labeled to [Inorganic Chemical] ing to evaluate the quality of the word labels after removing some most frequent words. The precisions computed after removing the top-K most frequent words (1  X  K  X  20) are plotted in Fig. 1 (a). For all semantic types, removing the most frequent words does help to improve the precision to the maximum of 53.38 %. The plot of the precision values on the 14 selected semantic types, however, is not very smooth. As shown in Table 2 , some frequent words are indeed medical related, e.g., pain, tired, and depression. Removing such words leads to decrease in precision because of their large frequencies. We evaluate the quality of word labels by MetaMap on text from a medical forum HealthBoards. Our study shows that directly applying MetaMap on social media data on healthcare leads to low quality word labels. One of the main reasons is that MetaMap is designed for processing medical data written by professionals rather than UGC in online forums. We hope the negative results obtained in our study will motivate more research on the effective application of MetaMap on social media data in healthcare.

