 Jos  X  e Miguel Hern  X  andez-Lobato 1 JMH 233@ CAM . AC . Neil Houlsby 1 NMTH 2@ CAM . AC . UK Zoubin Ghahramani ZOUBIN @ ENG . CAM . AC . UK University of Cambridge, Department of Engineering, Cambridge CB2 1PZ, UK Many machine learning methods have been developed for modeling matrices with a large number of missing entries. Amongst these, matrix factorization (MF) approaches (Sre-bro et al., 2005; Koren, 2008) are probably the most suc-cessful because of their simplicity and often superior pre-dictive performance. These methods assume that the par-tially observed data matrix X is well approximated by a low rank matrix UV T . The objective is then to find the two matrices U and V given X . There is extensive liter-ature on MF methods, so in this paper we focus on prob-abilistic approaches. Probabilistic methods are an attrac-tive solution to the MF problem because i) they are robust to overfitting (Salakhutdinov &amp; Mnih, 2008), ii) they can account for non-continuous matrix entries such as ordinal values (Stern et al., 2009; Paquet et al., 2012) and iii) they can produce estimates of uncertainty in their predictions. Fast approximate inference is usually implemented using variational Bayes (Lim &amp; Teh, 2007; Raiko et al., 2007; Nakajima et al., 2010). These variational algorithms are computationally efficient because their cost depends only on the number of entries observed in X , which is usually low, and not on the size of X which can be large.
 Many real-world datasets are binary, that is, the entries of X take values in { 0 , 1 } . Some examples include market basket data, click-stream data, network data or file data in complex software systems. In these cases X is fully ob-served and the aforementioned probabilistic approaches for solving the MF problem are infeasible in practice. This is because these methods are based on batch variational algo-rithms that require processing all the entries in X before producing even a single update to the variational parame-ters. An alternative is to use a likelihood function for con-tinuous data instead of one for binary data (Nakajima et al., 2010). In this case, an analytic solution exists which scales with the number of ones in X . However, this solution is restricted to zero-mean spherical priors on U and V and homoscedatic Gaussian likelihood functions for X . These restrictions lead to poor predictions when X is binary. We address the problem of scalable learning with proba-bilistic MF models that are accurate enough to produce state-of-the-art predictions on large binary matrices. To meet this challenge we propose a novel stochastic infer-ence algorithm. Stochastic methods have the advantage that, with large datasets, they can make reasonably good predictions before a batch algorithm has generated a sin-gle parameter update. Our approach is based on stochastic variational inference (SVI) (Hoffman et al., 2013). Exist-ing implementations of SVI do not directly extend to MF models, which present specific challenges that are not en-countered in models currently addressed by this inference algorithm, such as topic models. This is because in MF models we subsample individual matrix entries instead of complete data instances, e.g. an entire document in a topic model. In standard SVI all the variational parameters are updated each time a data instance is subsampled. With matrices, we have different parameters for each row and column in X and each time we subsample a matrix en-try, we update only the variational parameters associated with the corresponding row and column. This makes the data sub-sampling strategy important because it determines which parameters are updated and how often. Therefore we develop novel data subsampling strategies with differ-ent sampling probabilities across the rows and columns of X . These methods outperform standard uniform subsam-pling. Furthermore, parameter estimates in MF models of-ten exhibit heavy-tailed empirical distributions (Lakshmi-narayanan et al., 2011). These heavy-tails can significantly reduce the convergence rate of stochastic algorithms. A solution is to use minibatches to reduce the effect of out-liers in the noisy estimates of the gradients. However, the best minibatch size S can be dataset-dependent. To avoid having to hand-tune S to each dataset, which is common practice (Orr &amp; M  X  uller, 1998), we propose a method that adjusts the value of S online.
 We scale probabilistic MF methods to large binary matri-ces whilst maintaining strong empirical performance. We validate our method experimentally, demonstrating faster convergence than batch alternatives (Raiko et al., 2007) and yielding more accurate solutions than existing scal-able variational methods (Nakajima et al., 2010; Seeger &amp; Bouchard, 2012; Paquet &amp; Koenigstein, 2013). While we focus on improving the state-of-the-art in probabilis-tic MF methods, we also compare to one of the best non-probabilistic techniques for MF (Rendle et al., 2009). Al-though we do not attempt to beat every possible solution, our method also performs favorably. In summary, our al-gorithm has the following advantages: 1. We handle fully observed matrices and learn by sub-2. We use likelihood functions for binary data and not 3. Flexible priors and additional bias parameters can be 4. We use improved subsampling strategies and propose We describe a probabilistic model for an L  X  M sparse binary matrix X . A common approach in matrix modeling is to assume a matrix factorization model (Salakhutdinov &amp; Mnih, 2008). Let U  X  R L  X  D and V  X  R M  X  D be two low-rank matrices, where D min ( L,M ) . Then X =  X [ UV T + z + E ] , where  X [  X  ] applies the Heaviside step function to each entry of a matrix, z  X  R is a global bias parameter and E is an L  X  M additive noise matrix whose entries e ij are i.i.d. with c.d.f. given by the logistic function  X  ( x ) = 1 / [1 + exp(  X  x )] . The likelihood function is then where u i and v j are the i -th and j -th rows of U and V . We use fully factorized Gaussian priors for U , V and z : density with mean m and variance v . In our experiments we used priors with zero-mean and unit variance. We also incorporate a local bias to each row and column by fixing one column in each of U and V to a vector of ones. The posterior distribution for U , V and z is We can make predictions about the possible value x ? i,j that an entry x i,j in X could have taken during the generation of X from U , V , b and E . For this, we use Equations (2) and (3) are intractable and approximations must be used. We now show how to use variational Bayes (Jordan et al., 1998) for computing approximations to (2) and (3). 2.1. Variational Bayes for Binary Matrices Variational Bayes approximates the exact posterior (2) with a simpler, tractable distribution q ( U , V ,z ) . We choose q ( U , V ,z ) to be a fully factorized Gaussian, where  X  = {{{  X  u i,d ,  X  u i,d , } L i =1 , {  X  v j,d are variational parameters that are adjusted so that q ( U , V ,z ) is as similar as possible to p ( U , V ,z | X ) by minimizing the KL divergence between (4) and (2). Once q ( U , V ,z ) has been optimized, we approximate (3) by first approximating the posterior distribution of u i v T j + z with a Gaussian with mean  X  i,j = P d  X  u i,d  X  v j,d +  X  z , and vari-we approximate the logistic function with a rescaled probit function that has the same slope at the origin as the logistic function  X  (  X  ) (MacKay, 1992). This yields where  X  ( x ) = (1 +  X x/ 8)  X  1 / 2 .
 Equivalently, in variational Bayes q ( U , V ,z ) is opti-mized by maximizing the evidence lower bound or ELBO, L ( X ) = E q [log p ( U , V ,z, X )]  X  E q [log q ( U , V ,z )] . However, E q [log p ( U , V ,z, X )] is analytically intractable. To address this we use the Gaussian lower bound on the lo-gistic function described in (Jaakkola &amp; Jordan, 1997). We choose this approximation because it yields Gaussian com-plete conditional distributions. A complete conditional is the conditional distribution of a variable given all of the other variables and observations. Exponential family com-plete conditionals will allow us to use stochastic inference methods based on natural gradients, which improves con-vergence rates (Hoffman et al., 2013). We lower bound where  X  (  X  ) = (0 . 5  X   X  (  X  )) / (2  X  ) and  X  is adjusted to make the lower bound tight at a =  X   X  . When we replace each p ( x i,j | u i , v j ,z ) in (1) with an instantiation of (6) that in-cludes its own parameter  X  i,j , we obtain a new lower bound and  X  ( a,b,c,d ) =  X  0 . 5  X  0 . 5 log a/b +[( c  X  d ) 2 One could tune q by the alternative maximization of L 0 with respect to  X  and  X  . Given  X  ,  X  is optimized by setting Given  X  ,  X  can be optimized by doing an iteration of gra-dient descent (Raiko et al., 2007). This work contains a state-of-the-art batch algorithm for the optimization of the ELBO in MF models with Gaussian likelihood. Although effective with small datasets, the resulting batch algorithm is infeasible when X is very large because each iteration re-quires the examination of all of the entries in X before up-dating any parameters. For massive matrices, we propose to use stochastic optimization (Robbins &amp; Monro, 1951). These techniques can produce parameter updates after ex-amining only a reduced fraction of the data. The following section describes a stochastic method for optimizing L 0 in (7) based on stochastic variational inference (SVI) (Hoff-man et al., 2013). 2.2. SVI for Binary Matrices Stochastic optimization methods follow noisy estimates of the gradient of the target function. This function is of-ten constructed by summing over a large number of terms. Noise in the gradient arises because the target function is approximated by a cheaper, noisy estimate which is ob-tained by summing over a reduced set of randomly sub-sampled terms. To optimize the correct objective function the subsampled terms must be re-scaled so that the expec-tation of the gradient of the noisy estimate is equal to the gradient of the original target function.
 We apply stochastic optimization to L 0 ( X ) = max  X  L 0 ( X  ,  X ) . For this, we iterate over the following steps. Firstly, we randomly select indexes i  X  { 1 ,...,L } and j  X  { 1 ,...,M } with probability p ( i,j ) . Secondly, we optimize  X  i,j by setting  X  i,j = [  X  2 i,j + s 2 i,j ] Thirdly, we compute a noisy estimate of L 0 ( X ) : where c  X  i,j is a re-scaling constant. Finally, we update  X  small step in the direction of the gradient of (9). Intuitively, (9) is an appropriately re-scaled version of (7) that includes only those terms which have the same indexes i and j as the subsampled matrix entry x i,j . Importantly, the constant c is chosen to guarantee that the expectation under the data-sampling strategy p ( i,j ) of the gradient of (9) with respect to the elements of  X  i,j is the same as the gradient of L That is, when we update  X  u i,d or  X  u i,d we set c  X  i,j c i,j = p ( i,j ) .
 Instead of standard gradients, one can achieve much faster convergence using natural gradients (Amari, 1998). For this, we work with the natural parameters of (4): and similarly for  X  v j,d ,  X  v j,d ,  X  z and  X  z . Let  X  u and let  X  X  0 (  X  u i,d ) denote the natural gradient of (9) with respect to  X  u i,d . When the model has exponential family complete conditionals (as provided by the Gaussian ap-proximation in (6)) then  X  X  0 (  X  u i,d ) =  X  u ? i,d  X   X  u  X  u i,d = (  X  u when all the other natural parameters are fixed at their cur-rent values. Note that  X  u ? i,d is a noisy estimate of the max-imizer of the exact ELBO (7) with respect to  X  u resulting stochastic update for  X  u i,d is where  X  u i is the size of the step taken in the direction of the natural gradient. The corresponding updates for  X  v j,d and  X  z are similar, see the supplementary material for details. The resulting Stochastic Inference method for Binary Ma-trices (SIBM) iterates over the following two steps: i) ran-domly subsample an entry x i,j from X with probability p ( i,j ) and ii) make a small update to the variational pa-rameters that approximate the posterior distribution of the i -th row of U , the j -th row of V and the global bias z . In practice, each time we sample the indices i and j , we first update  X  z , then all the  X  v j,d and finally all the  X  u of these operations is performed using the updated param-eter values produced by the previous operations. We also recompute the optimal value for  X  i,j whenever any of the natural parameters change. 2.3. The Sampling Distribution We investigate the performance of different choices of p ( i,j ) , the probability distribution used to subsample the entries of X . A common objective for binary matrix fac-torization is to predict the location of entries in X that would have taken value one but were flipped to value zero by the additive noise matrix E . Real-world binary matrices are usually sparse, as illustrated in Figure 1. This means that when the sampling strategy p ( i,j ) is uniform (denoted S-Uniform), p ( i,j ) = 1 / ( LM ) , most of the sampled en-tries x i,j will take value zero. As a result, SIBM may take many iterations to converge to a good solution. We propose smarter strategies that subsample the more useful entries of X so that the model converges rapidly. This resembles  X  X c-tive learning X  (Settles, 2010). However, unlike in active learning, we must eliminate the bias introduced by our spe-cific choice of p ( i,j ) , that is, we must select c  X  i,j that the expected gradient of (9) is the same as the gradi-ent of (7). Therefore, we propose two simple strategies for which we can compute the appropriate rescaling c  X  i,j . To ensure that we see enough ones, a better alternative (S-Balanced) is to sample zeros and ones with equal probabil-ity, regardless of the empirical frequencies in X , where I [  X  ] is the indicator function. Now, each time that an entry is sampled we obtain a zero or a one with equal proba-bility. However, another characteristic of real-world binary matrices is that the frequency of ones and zeros can vary considerably across the rows and columns. For example, the matrix in Figure 1 presents a few columns with a large number of ones and many with very few ones. A similar pattern is observed in the rows, although in this matrix the effect is smaller. In practice, it takes SIBM longer to model accurately the ones located in rows or columns with many zeros. Any entry sampled from these rows/columns will usually take value zero which is unlikely to be useful be-cause SIBM can learn quickly that these rows/columns are very sparse. Therefore, we propose a strategy (S-Biased) to account for this by biasing S-Balanced so that the prob-ability of sampling a one at location ( i,j ) is proportional to i) the number of zeros found in the i -th row and ii) the number of zeros found in the j -th column. An equivalent bias is introduced for the zeros. The result is the sampling distribution where r (0) i and r (1) i are the number of zeros and ones in the i -th row of X and c (0) j and c (1) j are the number of zeros and ones in the j -th column. These counts are thresholded to take a minimum value of 1 so that p ( i,j ) 6 = 0 . 2.4. Minibatches, Learning Rates and Minibatch Size Stochastic methods often use minibatches to reduce the variance of the noisy estimates of the gradient and help the algorithm converge faster. Instead of updating the varia-tional parameters after subsampling a single matrix entry, the updates are averaged over a minibatch of data. When using a minibatch of size S , we first subsample S entries from X . Then for each subsampled entry x i,j , we store the parameter values  X  u ? i,d and  X  v ? j,d that would have been pro-duced during the execution of SIBM without minibatches. After subsampling S entries, we update each  X  u i,d if at least one of the entries in the minibatch belongs to the i -th row of X . The minibatch update rule follows from (10), n ( i ) is the number of entries in the i -th row found in the minibatch and  X  u ?,s i,d is the value of  X  u ? i,d produced when the s -th of those entries appearing in the i -th row is subsam-pled. The minibatch update rule for  X  v j,d is similar. An important question is how to choose the minibatch size S . The value of S is particularly important when work-ing with matrix factorization models where parameter dis-tributions are often heavy tailed (Lakshminarayanan et al., 2011). In our stochastic method this results in heavy tailed noisy estimates of the natural gradients. The choice of S governs a trade-off between reducing these heavy tails and slow convergence due to excessively large minibatches. To avoid having to hand-tune S to each dataset or run expen-sive cross validation searches, we propose an algorithm that selects S appropriately to the statistics of the data during learning. In particular, we choose S so that we bound the magnitude of the error in the noisy estimate of the optimum of the ELBO. Let  X  u ?,? i,d be the value of  X  u i,d that maximizes the exact ELBO (7). We obtain a probabilistic bound on the relative error of  X  u ?, avg i,d in (11) with respect to the global maximizer of the ELBO,  X  u ?,? i,d , using Markov X  X  inequality, where Var [  X  u ? i,d ] is a vector with the variances of the entries in  X  u ? i,d , p ( i ) is the probability of sampling an element from the i -th row of X , that is, p ( i ) = P j p ( i,j ) . We have ap-proximated E [1 /n ( i )] by 1 / [ p ( i ) S ] and we have used the a minibatch size that approximately limits the probability that the relative error of  X  u ?, avg i,d is larger than  X  : Intuitively, the minibatch size increases with the inverse of the signal to noise ratio (SNR) in the estimate  X  u ? i,d global maximizer of the exact ELBO in (7). If the SNR decreases, (13) chooses large minibatches to mitigate the large relative errors.
 This approach requires choosing a single dataset-independent parameter, the product of  X  and  X  , as opposed to hand-tuning S to each dataset. By making  X  X  small we limit the expected deviation of  X  u ?, avg i,d from  X  u (13) requires knowing E [  X  u ? i,d ] and Var [  X  u ? i,d these quantities online using exponentially weighted mov-ing averages. Equation (13) provides a different minibatch size for each of the  X  u i,d and the rule for each of the  X  v is similar. Therefore we select S to be the mean minibatch size selected for each  X  u i,d and  X  v i,d , details are in the sup-plementary material. The contribution of  X  z to the minibatch size S is very small and so is ignored in practice. The step sizes  X  u i ,  X  v j and  X  z should be reduced each time  X  u i,d ,  X  v j,d and  X  z are updated. For this, we use a simple Robbins-Monro schedule (Robbins &amp; Monro, 1951). The full SIBM routine is summarized in Algorithm 1.
 Algorithm 1 Stochastic Inference for Binary Matrices SVI has been applied to other probabilistic models (Hoff-man et al., 2010; Wang et al., 2011; Bryant &amp; Sudderth, 2012). In these cases there is a clear distinction between local and global variational parameters. Local parameters are updated only when a particular data point is subsam-pled. Global parameters are updated whenever any data point is subsampled. In MF models, we have variational parameters that are partially global , that is, they are only updated when elements in the corresponding row or col-umn are subsampled. This makes the data sub-sampling strategy more important because it determines which pa-rameters are updated and how often. Other non-uniform sampling strategies have been proposed for networks, an instance of binary matrices, (Gopalan &amp; Blei, 2013). The stochastic blockmodel for networks used here differs to our general binary MF model.
 An alternative stochastic MF algorithm just subsamples the zeros (Paquet &amp; Koenigstein, 2013). However, unlike SIBM, this method does not correct for the bias introduced by the subsampling process and hence yields poorer solu-tions. Instead of stochastic schemes one could use the an-alytic solution described in (Nakajima et al., 2010). How-ever, this is only applicable when i) the likelihood (1) is Gaussian with equal variance across matrix entries, ii) U and V have zero-mean isotropic priors, and iii) there are no bias parameters. These constraints have a large nega-tive effect in predictive performance. An iterative scheme has been proposed to extend this approach to logistic like-lihoods (Seeger &amp; Bouchard, 2012) at the cost of making crude approximations to the logistic likelihood function. In practice, this method tends to produce only small gains with respect to (Nakajima et al., 2010) with binary matri-ces. Very recently, an MF model with a Poisson likelihood has been proposed (Gopalan et al., 2014). This algorithm is applicable to binary matrices and scales with the number of ones, although the Poisson likelihood is less specific than the logistic function for binary data.
 A large number of alternative non-probabilistic algorithms have been proposed for MF. One of the best performing is Bayesian Personalized Ranking (BPR) which optimizes a ranking loss function. BPR has shown state-of-the-art results on item recommendation tasks (Rendle et al., 2009; Dror et al., 2012).
 Our minibatch size S selection algorithm is similar to one in (Byrd et al., 2012). However, their method selects S to be inversely proportional to the SNR of the noisy estimate of the gradient. Since the gradient tends to zero at con-vergence, the value of S selected by their method quickly diverges. We do not have this problem because we use the SNR of the noisy estimate of the global maximizer of (7), which does not converge to zero. SIBM is evaluated in experiments with synthetic and real-world binary matrices. All the code and data used is pub-licly available 1 . We consider six datasets that include a syn-thetic dataset generated by sampling X from the generative model assumed by SIBM. We fix D = 10 and generate U and V by sampling all the u i,d and v j,d independently from N (0 , 1) . The global bias is fixed to z =  X  7 . 5 , yield-ing binary matrices with about 98% sparsity. We consider two real-world datasets from the FIMI repository: purchase data from a retail store (retail) (Brijs et al., 1999) and click data from an online news portal (Kosarak). We include two datasets from the 2000 KDD Cup (Kohavi et al., 2000; Zheng et al., 2001), point of sale data from a retailer (POS, originally BMS-POS) and click data from an e-commerce website (WebView, originally BMS-WebView-2). Finally, we include the Netflix data, treating 4-5 star ratings as ones. We pre-process the original datasets so that we can com-pare to the computationally expensive batch approach. We keep the 1000 columns with the highest number of ones and discard rows with fewer than 10 ones. We consider small and large versions of each dataset. We subsample 2000 rows for the small and 40,000 rows for the large datasets, except in retail and WebView, where we use approximately the maximum number of rows for the large datasets, 10,000 and 5000, respectively.
 Each matrix is randomly split into a training matrix and a set of test entries with value one. The training matrix is generated by randomly removing an entry with value one from each row in the original matrix and adding it to the test set. Predictive performance is evaluated using recall at N , a popular metric for recommendation tasks (Gunawar-dana &amp; Shani, 2009) (equivalent to precision when a single one is held out from each row). For this, we iterate over the rows, using (3) to compute the probability of each zero entry actually taking value one. We select the top N zero entries with highest probability in that row. Recall is com-puted as the average number of times that the test entry appears in this list. We use N = 10 and repeat the experi-ment 25 times on each small dataset, and 10 times on each large one. 4.1. Sampling Strategies and Automatic Minibatch The top of Figure 2 shows results for SIBM when using the sampling strategies S-Uniform, S-Balanced and S-Biased on the small Netflix dataset. To eliminate the dependence of these strategies on the minibatch size, we select the value of S for each strategy using cross-validation. We find that S-Biased performs best, and both S-Biased and S-Balanced improve over S-Uniform. Similar results are obtained on the other datasets, see the supplementary material. The plot in the bottom of Figure 2 shows the evolution of the minibatch size S on each small dataset. We fixed  X  X  = 2 in (13) in all of our experiments. We fixed the minimum value for S to max ( L,M ) = 2000 . This value is selected with the retail dataset. Similar results are obtained with the large datasets. This plot shows that the optimal value of S varies greatly across datasets. Interestingly, for some datasets S grows as learning progresses, but for others it shrinks.
 4.2. Comparison with Batch and Alternative Methods We compare the full SIBM algorithm that selects the mini-batch size S automatically (SIBM-auto) to a version in which S is selected via cross-validation to maximize re-call on a validation set (SIBM-recall). We also compare to a version of SIBM-recall that finds the Maximum a Posteri-ori (MAP) solution using stochastic gradient ascent (MAP-recall), see the supplementary material for details. On the small datasets we compare to the batch algorithm (batch) that maximizes (7) (Raiko et al., 2007). This method is too expensive with the large datasets. In these cases, we run it by subsampling zeros, keeping only 20 times as many zeros as ones.
 We compare our method to the analytic solution with a Gaussian likelihood (Nakajima et al., 2010) (Nak10) and the extension of this method to binary matrices (Seeger &amp; Bouchard, 2012) (See12). We also evaluate the scheme de-scribed in (Paquet &amp; Koenigstein, 2013) (Paq13). Finally, we compare to one of the best performing non-variational Bayesian algorithms, BPR (Rendle et al., 2009). 4.3. Results Figure 3 shows the average recall obtained by each method versus the number of entries from X that are observed (sampled). Other than the analytic solutions (Nak10 and See12), all algorithms have linear cost in the number of observations. It is hard to quantify the number of entries observed by Nak10 and See12 which are based on itera-tive calls to an SVD subroutine. Therefore, we assume that they run instantaneously and their performance is presented as a constant line 2 . Tables 1 and 2 show the average recall and average negative ELBO (7) (cost) after taking 10 7 sam-ples with the small datasets and WebView and Retail large datasets, and 10 8 on the others. With the large datasets computing the ELBO is too expensive so we do not report cost. Bold typeface indicates the best results (and those statistically indistinguishable), underlining denotes the sec-ond best. Tables 1, 2 show that in terms of recall, the best method is SIBM-recall, with SIBM-auto coming close. Re-garding the ELBO, SIBM-auto yields the best results. Figure 3 shows that SIBM converges faster than batch and sometimes to better solutions, such as with the WebView dataset. SIBM-auto produces the greatest improvements during the first iterations of learning. These first iterations are the most relevant iterations for large scale learning. With massive data, only a few passes over the available data are possible. It is in these cases that stochastic methods are most useful. The results of SIBM-auto are very close to those of the gold-standard, SIBM-recall, and MAP-recall performs worse in general than the variational methods SIBM-auto and SIBM-recall. MAP-recall seems to overfit since its performance sometimes deteriorates during later iterations. The analytic algorithms (Nak10, See12) obtain poor results due to the simplistic modelling assumptions that they make. Paq13 can perform poorly because this method subsamples the zeros and does not account for the bias introduced by the subsampling process. As a result, it converges to suboptimal solutions. BPR converges to worse solutions than SIBM and batch. On the large datasets the relative performances are similar, see the supplemen-tary material.
 Figure 4 shows recall versus wall-clock time for the small Kosarak dataset. Plots for the other datasets are in the supplementary material. This plot is implementation-dependent (all methods are coded in C) and so is less ob-jective than Figure 3 which uses the number of entries ob-served. Nevertheless, the results for recall vs. time and recall vs. number of observed entries are similar. The main difference is that SIBM-recall, MAP-recall and BPR are penalized due to the additional time required to run cross validation searches for selecting the minibatch size (SIBM-recall and MAP-recall) and regularization parame-ters (BPR). We have proposed a new stochastic inference method for efficient factorization of large binary matrices. Our ap-proach extends stochastic variational inference (SVI) to matrix factorization models, a class of models not previ-ously addressed by SVI. The proposed method has the fol-lowing advantages with respect to existing probabilistic so-lutions for binary matrix factorization: i) we can handle fully observed matrices, ii) learning occurs by subsampling the matrix entries, iii) we use likelihood functions for bi-nary data instead of for continuous data, iv) flexible priors and additional bias parameters can be incorporated into the method easily. The resulting technique achieves faster con-vergence than an alternative batch approach and has better predictive performance than other state-of-the-art scalable solutions or analytic methods based on the SVD decom-position. Good performance in this domain requires smart data subsampling mechanisms and the use of minibatches. Therefore we have provided a novel non-uniform data sub-sampling strategy and a technique to adjust the minibatch size adaptively to the data. Our minibatch selection algo-rithm could be used more generally with other SVI algo-rithms.

