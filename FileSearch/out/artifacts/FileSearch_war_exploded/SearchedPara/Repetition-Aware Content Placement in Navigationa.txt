 Arguably, the most effective technique to ensure wide adop-tion of a concept (or product) is by repeatedly exposing in-dividuals to messages that reinforce the concept (or promote the product). Recognizing the role of repeated exposure to a message, in this paper we propose a novel framework for the effective placement of content: Given the navigational patterns of users in a network, e.g., web graph, hyperlinked corpus, or road network, and given a model of the relation-ship between content-adoption and frequency of exposition, we define the repetition-aware content-placement ( RACP problem as that of identifying the set of B nodes on which content should be placed so that the expected number of users adopting that content is maximized. The key contri-bution of our work is the introduction of memory into the navigation process, by making user conversion dependent on the number of her exposures to that content. This depen-dency is captured using a conversion model that is general enough to capture arbitrary dependencies. Our solution to this general problem builds upon the notion of absorbing random walks, which we extend appropriately in order to address the technicalities of our definitions. Although we show the RACP problem to be NP-hard, we propose a gen-eral and efficient algorithmic solution. Our experimental results demonstrate the efficacy and the efficiency of our methods in multiple real-world datasets obtained from dif-ferent application domains.
 H.2.8 [ Database Management ]: Database Applications X  data mining Optimization, Markov chains, Navigational networks  X  Motivation: There is ample evidence in the literature that the probability of internalizing a concept or buying a prod-uct (user conversion) is dependent on the number of times that an individual user is exposed to information or adver-tisement related to that concept or product. As Artistotle put it  X  X t is frequent repetition that produces a natural ten-dency X . In education, repetition is recognized as an effective pedagogical tool; repetition deepens and hastens students X  engagement and understanding processes [5, 22]. In mar-keting, repeated exposure to a product is key to the success of marketing campaigns [17]. In politics, repeating specific messages in stump speeches or in mass media advertisements is effective in influencing public opinion, and thus critical to the success of political campaigns [1, 21]. The effects of rep-etition are not always positive: while repeated exposure to a message increases one X  X  ability to internalize a concept in an educational setting, it may yield undesirable outcomes in a different setting  X  for example, the probability of purchas-ing a product decreases dramatically with repeated exposure (more than twice) of the product to a customer 1 .
 Problem: Motivated by the role that repeated exposure to content plays in these various settings, in this paper we define and study the repetition-aware content-placement (RACP) problem in navigational networks , i.e., networks in which the (directed) edges represent the potential of users to transition from one node to another as they navigate through the network. Broadly speaking, given the naviga-tional patterns of users in such a network, and given the relationship between the level of user exposure to content and the probability of user conversion, the RACP problem is that of identifying the set of k nodes on which content should be placed so that the expected number of users adopting the content ( i.e., the conversion rate) is maximized.
 Applications: Instances of RACP occur in multiple do-mains. For example, consider the problem of superimposing content on the navigational network defined by the hyperlink structure of the web. Here, the challenge is the identification of the set of k web pages (nodes of the navigational graph) on which content should be placed in order to maximize the impact of an advertisement campaign, e.g., placement of slogans that raise awareness about a social issue, or place-ment of advertisement about a product or a political party. As another example, consider the problem of providing rec-ommendations for additional content to readers of on-line http://www.mediabizbloggers.com/bill-harvey/ 50150992.html corpora. Here, the reader (a student) navigates a body of knowledge (an on-line textbook)  X  not necessarily serially  X  by following links that underscore dependencies between units of the corpus (e.g., sections and chapters), and the challenge is to identify the best set of units where addi-tional content (further readings, references, exercises) could be linked or recommended so as to maximize the probability of access to such additional content. The RACP problem is applicable to offline physical navigational networks as well  X  the canonical example being road networks. Here users nav-igate a set of interconnected locations, and the challenge is the placement of billboard advertisements at the right loca-tions, so as to maximize the impact on travelers/commuters. Model: The main components of our setting are the user X  X  navigational and conversion models. The navigational model assumes that user X  X  navigation through the nodes of the net-work is modeled by a Markov chain, i.e., a random walk over the navigational graph. The conversion model specifies the probability of a user adopting content as a function of the number of times that content is shown to the user within a single walk over the navigational network. Our incorpora-tion of a conversion model fundamentally changes the nature of content placement by making user conversion dependent on the number of times that content is shown to the user. Said differently, the novelty of our work is the introduction of memory into the navigation process. In our work, rather than focusing on a particular type of relationship between number of views and probability of content adoption, we consider generic conversion models that handle arbitrary de-pendencies between the number of views and the probability of content adoption.
 Contributions: Problems of picking important (or target) nodes in networks have been studied extensively in the past, both in information-flow (or social) networks [7, 9, 11, 16], in transportation [2, 3, 13, 14, 20] and in navigational net-works [6, 8]. A thorough examination of this related work is presented in Section 2. The key difference between that prior work and ours is that the former assumes memoryless navi-gation or information flow processes, and as a result has an implicit conversion model that presumes the independence of number of views and conversion probability. The explicit modeling of this dependence and the flexibility of our model to capture arbitrary forms of this dependency makes our work more general in the sense that prior work represents a subset of the scenarios that are possible to consider using our approach. Another salient feature of our work is that our formulation and algorithmic treatment of the RACP problem are general in the sense that they apply to any conversion model as long as the conversion probability can be expressed as a function of the number of times content is presented to the user in a single random walk over the navigation graph. The incorporation of an arbitrary con-version model (memory) into a navigation (random walk) process raises new modeling as well as computational chal-lenges, which comprise the main technical contributions of our paper. We address this new class of problems by build-ing upon the notion of random walks with absorbing states. More specifically, we propose solutions to our RACP prob-lem based on analysis using absorbing random walks, and we demonstrate that our techniques are scalable and thus useful for real-world data-analysis tasks. To the best of our knowl-edge we are the first to leverage such techniques not only in the context of content placement in navigational networks, but also in the context of node-selection in general.
Although, to the best of our knowledge, we are the first to propose and solve the RACP problem, which encompasses both a navigational and a general conversion model, our work is related to a large body of existing work on informa-tion, transportation and online navigational networks. Information networks: Recently, there has been a lot of work in the computer-science literature on identifying a set of nodes of a social network to advertise a product or to immunize so that the spread of the product or the spread of an epidemic in the network is maximized or minimized. Dif-ferent assumptions about how information items propagate in the network has led to a rich literature of node-selection methods [7, 9, 11, 16, 18, 19]. The key difference between our work and all these methods is that the latter assume that the underlying network is an information network on which items (rather than users) propagate. As a result, the models adopted in such existing work are information-propagation models and thus, cannot be used to model the navigation of users in a navigational network. Hence, despite the fact that at a high level we also need to pick a subset of the nodes of our network, our objective  X  i.e., the maximization of users X  conversion rate  X  does not have an analogue in the social-network literature. More specifically, the models we propose here are specific to navigational networks and lead to problem definitions that require the development of new machinery in order to be solved.
 Transportation networks: Related to ours is the work on the flow-capturing location allocation problem (FCLA) in transportation networks. This problem has originally been introduced in 1990 by Hodgson [13]. In the FCLA prob-lem, the input consists of a network as well as the customer traversals in the form of flows between source and destina-tion pairs. The objective is to locate facilities in a set of k nodes so as to maximize the number of customers who encounter at least one facility in their flow through the net-work. In his original paper, Hodgson proves that this version of the location-allocation problem is NP-hard, but empiri-cally shows that a greedy algorithm can be quite efficient in solving it. The problem we study here is different from this original version of the FCLA problem in three ways: First, while in FCLA the repetition of interceptions (i.e., multiple encounters of customers with facilities) is ignored, our work focuses on optimizing the interception of the users X  naviga-tion given the impact that repetitions have on the users X  tendency to convert. Second, Hodgson assumes that the in-terception of a flow is a deterministic process, i.e., a flow is either intercepted or not, hence set-cover type of reasoning works for his approach. In our case the paths of users is only intercepted in a probabilistic sense. Third, in our work we assume the navigation model is Markovian, while in FCLA the navigation paths of users from sources to destinations are a priori known and deterministically defined. As a re-sult, both our model as well as the computational challenges we need to resolve are different from those that arise in the FCLA problem.

Even in the domain of transportation networks, the as-sumption that all source-destination flows are known a pri-ori proved impractical. As a result, there exists work on variants of the original FCLA problem where partial flow information is assumed [2, 3]. In these cases, the available navigation information specifies the fraction of flows that pass through every node and its neighbors. Despite the fact that this navigation model resembles ours, existing work still ignores the effect of repetitive interceptions on users. As a result, the underlying combinatorial problems that appear in existing work [2, 3] are different from ours. After all, the al-gorithms used for solving these existing variants of FCLA are based on non-linear integer programming and total-reward Markov decision processes, while our solution is based on deploying Markov chains with absorbing states.
 Navigational networks: More recent work on node -se-lection in online navigational networks includes the work of Chierichetti et al. [8] and Charikar et al. [6]. In their work Charikar et al. [6] assume a similar propagation model and objective to ours, in that users traverse a Markov chain and the ultimate goal is to assign content to certain states in this chain. Despite the similar objective function, the underly-ing problem they solve is completely different from ours; in their setup users can either be in a targeted or non-targeted population and the goal is to intercept the largest possible fraction of the targeted population. In their setting, inter-ception of users X  is deterministic and repetition does not play any role. As opposed to this, in our work users are only intercepted with some probability in chosen states and this probability may change with the number of times an interception happens.

Chierichetti et al. [8] assume a user-navigation model sim-ilar to ours and their goal is to find an optimal placement of online advertisements. In their setting, ads are placed to the nodes of the navigation network and there is a util-ity assigned to a user seeing an ad, that depends both on the state and the specific ad that is shown. When an ad is shown the user may stop with some probability (go to an exit state of the chain) or continue traversing. While the user propagation model of Chierichetti et al. is similar to ours, their conversion model is different. In special, they do not distinguish between the first and subsequent views of the same ad. They propose a very elegant LP solution for their problem. However, the method they derive is in-adequate to solve the RACP problem. Due to the fact that in our setting the conversion probabilities are affected by repeated traversal through the same state, the size of the corresponding LP program in their solution would blow up.
The input to our problem consists of the navigational and the conversion model. The navigational model is a network; the nodes of this network correspond to entities; the user navigates through the entities by following the links of the underlying graph (directed or undirected) based on prob-abilities associated with the links. The conversion model quantifies the relationship between the number of times a user views a particular content and the probability of her adopting the content (or converting to the content). The objective of our work is to place content in the network at locations so as to maximize the probability of conversion.
Throughout the paper, we assume as input a navigational graph G = ( S ,E ), which is a directed or undirected graph with nodes S , edges E and | S | = n .
 Navigational model: We assume that the users X  traversal of the network follows the traditional Markov model; users navigate between a set of states in a randomized way, tran-sitioning between states with given probabilities, such that the transition probabilities define a Markov chain on this set of states. Let M =  X  S , P  X  denote this Markov chain, set S contains n states S = { s 1 ,s 2 ,...,s n } and P contains the transition probabilities P ( i,j ) of a user moving from state s to state s j . We think of P as an n  X  n matrix, that is the transition matrix of M . Note that the state space S of the Markov chain is simply the set of nodes of the navigational graph G = ( S ,E ).

For the rest of the discussion, we will assume that M is irreducible and aperiodic, and thus has a stationary distribu-tion  X  2 . Finally, in order to make our model more realistic, we assume that there is an upper bound on the maximum number of hops the user is taking, i.e., this bound encodes that the user quits his navigational session in finite time. We denote this bound by M max .
 Conversion model: This model depicts the user X  X  behav-ior upon being exposed to some content in one of the states. Upon viewing content c the user has two possible actions: either convert ( i.e., click on the link, adopt some view or buy the advertised product) and quit the traversal of the network or continue without taking any action. The con-version model provides the probability with which the user chooses in any given situation between these two options. Note, that a user may only quit the navigation by either converting or by exceeding the maximum number of hops.
In this paper, we focus on memory-full conversion mod-els, i.e., conversion models for which the probability of a user converting to the content c depends on the number of times she has been exposed to this content before  X  while it does not depend on the specific path that the user has fol-lowed. To describe this model in more detail we introduce the notion of levels .

Definition 1. We say that a user is in level ` if she has been exposed to content c exactly ` times.

A result of the above definition is that the user is in level 0 when she has not seen the content yet. That is, every user starts her traversal of the network in level 0. When a user, who is at level ` is exposed to the content but decides not to convert, she moves to level ( ` + 1).

The probability that a user converts to content c , when presented with it in state s , depends on the state itself as well as on the user X  X  level ` , but not on the user X  X  path during her navigation. We denote this probability by C ( `,s ). Naturally, the probability that a user continues the traversal  X  without converting  X  is (1  X  C ( `,s )). We call C ( `,s ) the conversion probability in state s at level ` .

Note that the probability C ( `,s ) can be any arbitrary function of s and ` . For example, if the number of repe-titions of the content X  X  viewings increases (resp. decreases) the probability of adoption, then we will assume that C ( `,s ) is monotonically increasing (resp. decreasing) with ` . How-ever, such monotonic relationship is not necessary for our framework. Our intuition is that the probability of the user X  X  conversion increases for the first couple of exposures to the content and then it decreases.
In fact, our method only makes use of the irreducibility property of Markov chains. In our experiments we compute the PageRank with a dampening factor [4] of states instead of the stationary distribution.
The only assumption we make with respect to the de-pendency of C ( `,s ) on ` is that there is a sufficiently large number K , such that if the user did not convert after level K , then the probability of conversion becomes infinitesimal small. That is, C ( `,s )  X  0 for `  X  K and for any s . This assumption also ensures that the number of different con-version probabilities per state is at most K .

The dependency of C ( `,s ) on the state s may also be arbitrary. In some cases, the conversion probability C ( `,s ) may depend on the relevance of the content c , which we are placing to the node s , and the content of the node s itself. For example, an ad X  X  placement on a webpage depends on the topic of the page. In other cases, the conversion probability C ( `,s ) may only depend on factors irrelevant to the content or the node.
 Expected conversion rate: The objective in the RACP problem is to maximize the expected probability of a user converting to content c , given the navigational and conver-sion models. We are now ready to give the formal definition of this objective function.
 For this, let M X  S , P  X  be the user X  X  navigational model. Moreover, if L = { 1 , 2 ,...,K } is the set of all possible levels of a user then let C : L  X  S  X  [0 , 1] denote the input conver-sion model. Finally, let R ( `,s ) denote the probability that the user is encountering content c for the ` -th time when she is visiting state s . Note that since the user has not yet quit the navigation she has neither converted to c , nor has she reached the maximum number of steps M max . Although the definition of R ( `,s ) is conceptually easy, computing the value of R ( `,s ) is computationally challenging. In order to maintain the smoothness of the flow of the paper, we assume for now that R ( `,s ) can be computed and we give the details of this computation in Section 4.2.
 If copies of content c are placed on a subset of states A  X  S , then the expected conversion rate of content placement A is given by the formula: Note that Equation (1) is the probability that a user reaches a state s  X  A and converts to content c , after having en-countered content c for ` times in the past, where `  X  L .
Since our goal is to actually find the content placement A for which Equation (1) is maximized, we define the RACP problem as an optimization problem as follows: Problem 1 (RACP ). Given the navigational model M =  X  S , P  X  , the conversion model C ( `,s ) for every `  X  L and s  X  S , and a budget B , assign content to at most B states A  X  S so that the expected conversion rate CR ( A ) is maximized.
 Theorem 1. The RACP problem is NP-hard.

Proof. We prove the theorem by reducing the decision version of the Vertex Cover problem [12] to the decision version of the RACP problem.

The decision version of the Vertex Cover problem takes as input a graph G 0 = ( V 0 ,E 0 ) and asks whether there exists a set of vertices U  X  V 0 of size at most k such that every edge in E 0 is incident to at least one of the vertices in U .
We transform the above instance of Vertex Cover to an instance of the decision version of our problem as follows. We assume that our navigation graph G = ( S ,E ) has the same nodes as G 0 (i.e., S = V ) and the same set of edges as E 0 (the undirected edges in E 0 become bidirectional edges in E ). Our navigational model is a simple Markov chain defined on G . Further, we define our conversion model as follows: for any state s  X  S , the user converts to content c the first time she encounters c . That is, for every s  X  S we have that C (0 ,s ) = 1. We can now show that there exists a vertex cover of size k in G 0 iff in the above instance of the RACP problem there exists a set of k nodes A  X  S such that for M max = 1 the expected conversion rate for A is equal to 1, i.e., CR ( A ) = 1.
In this section, we give a greedy algorithm for solving the RACP problem. We also identify the connection of our problem to random walks with absorbing states and demon-strate how this connection is exploited within the implemen-tation of our algorithm.
Our greedy algorithm, which we call Greedy , forms solu-tion A iteratively; at each iteration it adds the node that causes (locally) the most increase in the objective function. More specifically, Greedy starts from an empty set A =  X  . At iteration i , a new state s is added to A , such that CR ( A  X  { s } ) is maximized. The algorithm terminates when either the budget B of states for content placement is exceeded, or there is no state that increases the expected conversion rate. In many applications, not all states are available for content placement. For this reason, we keep a set of candidate states S  X  S and only consider states in S to add to A . The pseudocode of the Greedy algorithm is given in Algorithm 1. Algorithm 1 The Greedy alorithm for the RACP problem. Input: Markov chain M X  S , P  X  , budget B , candidate list
S and conversion rates C ( `,s ) for every `  X  { 0 ,...,K } and every s  X  S .
 Output: set of states A and CR ( A ).
 A  X  0
CR ( A )  X  0 for i = 1 ...B do A = A  X  X  s } S = S\{ s }
In terms of running time, the most computationally ex-pensive step of Greedy is the computations done inside the for loop, i.e., computing CR ( A  X  X  s 0 } ) (line 4 of Algorithm 1). If the time required for computing function CR () is T , then the running time of Greedy is O ( B |S| T ), which in the worst case (i.e., when S = S ) is O ( BnT ).

Note that at each iteration of the for loop in line 4 all candidates need to be evaluated in order to choose the one with the largest marginal benefit. Although this can be time consuming, we observe that the evaluation of each can-didate can be done independently of the rest. Therefore, we have implemented a parallel version of Greedy , which we call Par-Greedy , and which evaluates each candidate separately. Thus Par-Greedy is O ( n/q ) times faster than the serial ver-sion of Greedy shown in Algorithm 1, where q depends on the number of cores of the underlying hardware.
The details of how we evaluate CR ( A ) for any A  X  S are given in the next paragraph.
The computation of CR ( A ) for any A requires the eval-uation of Equation (1). Since C ( `,s ) for any level ` and any state s is provided as part of the input (i.e., the conver-sion model), the main challenge in the evaluation of Equa-tion (1) stems from computing the values of R ( `,s ) for ev-ery `  X  { 0 ,...,K } and every s  X  S . Next, we show how these computations can be done using the notion of absorb-ing Markov chains [10, 15].
 Absorbing Markov chains: Given an underlying graph H = ( X ,Q ), consisting of nodes X and edges Q , an absorb-ing Markov chain C =  X  X , Q  X  defines an absorbing random walk on H . The statespace of this walk is X (i.e., the nodes of H ) and there are two types of states in X : absorbing and transient . A state x  X  X is absorbing if the random walk transitions into this node, but not out of it (and thus, the random walk is absorved in state x ). Let B  X  X denote the set of absorbing states. The remaining states U = X \ B define the set of non-absorbing or transient states.
Given this partition of the states, the transition matrix of this random walk can be written as follows: If | X | = N , then in the above equation, I is an ( N  X  X  U | )  X  ( N  X  X  U | ) identity matrix and 0 a matrix with all its entries equal to 0; Q UU is the | U | X | U | sub-matrix of Q with the transition probabilities between transient states; and Q UB is the | U | X | B | sub-matrix of Q with the transition proba-bilities from transient to absorbing states.

An important quantity of an absorbing random walk is the expected number of visits to a transient state y when starting from a transient state x , before being absorbed. The probability of transitioning from x to y in exactly ` steps is the ( x,y ) entry of the matrix Q ` UU . Finally, the matrix is an | U | X | B | matrix, with Q UB ( x,y ) being the probability that a random walk which starts at a transient state x ends up being absorbed at state y  X  B .
 Absorbing Markov chains and the RACP problem: In order to illustrate how absorbing random walks can be leveraged by our problem, let us consider the navigational graph G = ( S ,E ) and the corresponding navigational model M =  X  S , P  X  and conversion model C ( `,s ) for `  X  X  0 ,...,K } and s  X  S . Further assume that a subset of states A  X  S have been selected for placing content c .

Given the above we will define the extended navigational graph b G = ( b S , b E ) as follows: for every node s  X  S \ A there exist a node s 0  X  b S , and for every node s  X  A we create two copies of it in b S  X  one denoted by s t and the other denoted by s b . We call s t the transient copy of s and s b the absorbing copy of s . For the rest of the discussion, we will use A A b to denote the set of all transient copies and the set of all absorbing copies appearing in b S due to states s  X  A . Clearly, | A t | = | A b | and | b S | = | S | + | A | . The edges among the nodes in S \ A are the same both in G and b G . Finally, the transient copy s t of s  X  A maintains all the outgoing edges of node s , while the absorbing copy s b of s maintains all the incoming edges of s .

Given b G , we also define the absorbing Markov chain c M =  X  b
S , b P  X  . In this Markov chain, the nodes A b are absorb-ing and all other nodes in b S are transient. The transition matrix b P of such an absorbing random walk is defined as follows: the transition probability from a transient state s to an arbitrary state s 0  X  b S is identical to that in M , thus b P ( s,s 0 ) = P ( s,s 0 ). For absorbing state s  X  A b the proba-bility of transitioning to any other state s 0  X  b S is zero and thus, b P ( s,s 0 ) = 0. To make b P a proper transition matrix (i.e., ensure that all its rows sum up to 1) we set b P ( s,s ) = 1 for all absorbing states s  X  A b . Note that matrix b P has the same structure as matrix Q described in Equation (2).
A transformation from the original Markov chain M to the absorbing Markov chain c M is shown in Figures 1 and 2. The former figure shows the original Markov chain which corresponds to the navigational graph G = ( S ,E ). The highlighted nodes in the figure correspond to the set A on which content c is placed. The highlighted graph of Figure 2 shows the absorbing Markov chain c M =  X  b S , b P  X  , which cor-responds to graph b G = ( b S , b E ). The highlighted nodes here are the absorbing states of the chain.

Note that the extended graph b G and the corresponding absorbing Markov chain c M capture the navigational journey of a user at a single level, e.g., level ` . At this level, the user navigates according to her navigational model and once it encounters content c placed in one of the level X  X  absorbing nodes, the random walk of the user gets absorbed.

In order to capture the journey of the user across levels holistically, we need to create one copy of c M at every level ` = { 0 ,...,K } ; we denote such copies by c M ` . Now, when the user gets absorbed at s b at level ` (i.e., while she was at random walk c M ` ), she directly enters random walk c M ( ` +1) the starting point of this random walk is node s t . We call this set of connected absorbing Markov chains a sequence of absorbing Markov chains . The transition of the user from c M ` to c M ( ` +1) is shown in Figure 2 and is captured by the dotted arrows that connect nodes from different levels.
In practice, we never actually construct this sequence of absorbing Markov chains, neither do we need to do any com-putation on the sequence itself. However, the above descrip-tion provides a nice intuition and a conceptual understand-ing of the computations that follow. F igure 1: Markov chain M =  X  S , P  X  , with A = { s,s picked as states on which content c is placed.
 Computing CR : In this paragraph we compute CR ( A ) as given in Equation (1). Observe, that as C ( `,s ) is part of the Level ` Level ` + 1 F igure 2: A sequence of absorbing Markov chains c  X  b
S , b P  X  . For each state s  X  A of Markov chain M shown in Figure 1 two states are created: s b (absorbing) and s (transient). The transient and the absorbing copies of the same state are drawn as superstates. input, we only need to compute R ( `,s ) where s is one of the states in A .

Given the above discussion though, R ( `,s ) is identical to the probability of the user being absorbed in the absorbing copy of s , i.e., node s b , in c M ` . Since the user only enters from transient states t  X  A t then R ( `,s ) can be computed as the sum over all states in t  X  A t of probabilistic paths of length at most M max ending in s b and starting at all possible entry points t  X  A t .

The probability of a path of length of exactly i between any two states s 1 and s 2 can be computed as the appropriate cell in the i -th power of the transition matrix as Pr i ( s b P ( s 1 ,s 2 ). Hence, the probability of a path of length at most M max from any state t  X  A t to state s b is
Speedup: The computation of Equation (4) can be compu-tationally demanding. After all, it requires evaluating the M max -th power of the matrix b P . However, since we only need to know the absorption probabilities of the states in A b  X  b S , we can obtain a significant speedup as follows: first we define an auxiliary matrix F of size | b S | X | A columns of this matrix correspond to the absorbing states A b of chain c M while the rows of the matrix correspond to all states b S of M . Each column of F has one non-zero element: for s b  X  A t we set F ( s t ,s b ) = 1. That is, there is an 1 in a cell of F if the row and the column of the cell correspond to the transient and the absorbing copies of the same state.
Observe now that b P  X  F is of the same size as F , and contains at cell ( s 0 ,s b ) the probability that a random walk starting in state s 0 will be absorbed in one step in state s Moreover, if we set F 0 = F and apply the recursion the probability that a random walk that starts at s 0 gets ab-sorb at s b . From the theory of random walks with absorbing states, we can observe that matrix F and Recursion (5) al-lows us to compute the analogue of matrix Q UB (described in Equation (3)) for the absorbing Markov chain c M .
Despite the fact that Equation (5) still involves a matrix multiplication, it is much more efficient to compute in prac-tice, when compared to Equation (4). This is not only be-cause F is of much smaller size than b P , but also because the sparsity of b P is maintained and thus the running time of the computation only depends on the number of non-zero entries of b
P (i.e., the number of edges | E | of the input navigational graph). Thus, for an absorbing state s b and transient state t we can compute the probability of a user being absorbed in that state after at most M max steps by
Using the above machinery, we can to compute the proba-bilities R ( `,s ). Observe that R ( `,s ) depends on two things: the probability that the user will end up at level ` , and the probability that the user will be absorbed in the absorbing ` = 1 ...K can be computed by the recursion:
R ( `,s ) = X Level 0 is slightly different since at this level the user can start his random walk in the Markov chain in any state. Assuming that the probability of starting at any state is proportional to the state X  X  stationary probability we have that Since C ( `,s ) is a-priori given as an input, we can now com-pute CR ( A ) using its definition given in Equation (1). Running time of computing CR ( A ) : Regardless of the maximum number of levels, we only need to compute the absorption probabilities in Equation (6) once, since they are identical in every level. Evaluating this takes as much time as multiplying b P with F , M max times. Since | A | X  B and K and B are constants, then the total running-time for com-puting CR ( A ) only depends on the non-zero entries of b is thus O ( | E | ); in practice | E | n 2 and thus, the time required for this computation is sub-quadratic.
 Running the Greedy algorithm: Having described the underpinnings of the computation of CR ( A ), we can now describe the details of the Greedy algorithm, shown in Al-gorithm 1. The algorithm starts from an empty set A and, given constant integer budget B , it runs for B iterations. At every iteration, a new element is added to A such that CR ( A  X  X  s } ) is maximized. This maximization step is achieved by computing CR ( A  X  X  s } ) for every candidate state s and choosing the one which gives the highest CR . If all nodes in S are considered as candidates for content placement, then CR is computed nB times in Greedy . Plugging in the run-ning time of computing CR , this yields a total running time of O ( n | E | ). Again, the parallel version of the Greedy algorithm can attain lower running times. The degree of speedup de-pends on the degree of parallelism allowed by the hardware. In this section, we give an experimental evaluation of the Greedy algorithm on real datasets. All our implementations are in Matlab and we conducted our experiments using a 12 CPU cores (Intel Xeon E5-2680 processors, operating at 2.7 GHz) machine with 256GB of 1333 MHz DDR3 RAM. Datasets: In our experiments, we use real-world datasets. For our experiments with real navigational graphs, we pick graphs that come from domains where the RACP problem is applicable. Further, the choice of datasets is such that they help us demonstrate the scalability of our algorithms. We describe the characteristics of the datasets we use below.
The Road dataset: This is the road network of the state of Minnesota 3 The links in the network are undirected and correspond to roads in Minnesota, while nodes correspond to road intersections. The dataset contains 2642 nodes, and 6600 edges. Since this network depicts actual roads it is not only very sparse but the node degree distribution is also quite homogeneous, with degrees ranging from 1 to 10, but most degrees being at most 5. Content placement in this setting can correspond to placing billboards along the roads.
The Web dataset: This dataset contains the hyperlink structure of the stanford.edu domain in 2001 4 . Nodes of the graph correspond to web pages and the directed edges correspond to hyperlinks between them. The graph con-tains 10 K nodes and 36 K edges. The degree distribution of the graph is power-law with degrees ranging from 1 to 500. Placing content in nodes can correspond for example to advertising educational content, link to online tutoring resources as well as online advertising.

The Science dataset: The Science dataset 5 contains of the citation network of articles that appeared in the domain of high-energy physics. The nodes in the network correspond to papers and the edges correspond to one paper citing the other. The purpose of this dataset is to depict the learning process of a person, who wants to obtain knowledge in high-energy physics. The person might read a paper and then based on the reference list of this paper choose his next read. Since this process does not necessary imply reading the papers in chronological order, we make edges bidirectional and from the resulting graph we pick the largest connected www.cise.ufl.edu/research/sparse/matrices/Gleich/ minnesota.html www.cise.ufl.edu/research/sparse/matrices/Gleich/ wb-cs-stanford.html snap.stanford.edu/data/cit-HepTh.html component. The end result of this preprocessing is a graph with 27K nodes and 704K edges.
 The navigational models: Our navigational models are defined by the graph datasets described above. More specif-ically, using these graphs we define the navigational model for each dataset to be the corresponding PageRank Markov chain on the graph defined by the dataset. In these Markov chains, the user that is at node x chooses with probabil-ity  X  one of the outgoing links of x uniformly at random; with probability (1  X   X  ) the user jumps to a random node of the input graph. Note that our framework works for any Markov chain defined on the input navigational graphs, as long as the chain is ergodic. Our choice of the PageRank Markov chain [4] guarantees the ergodicity of our naviga-tional models, even when the input graph is disconnected. For all our experiments we use  X  = 0 . 8.
 The conversion model: For all of our datasets we use a conversion model generated along the same principles. We first assign the initial CR values C (0 ,s ) to states in level 0. We obtain the CR rates C ( `,s ) on subsequent levels with help of a function f ( ` ) based on formula (9)
The initial assignment of C (0 ,s ) to states is done by as-signing to every state s value C (0 ,s ) chosen randomly among are exponentially decreasing and capture our intuition that there will be small number of states with high probability of affecting the conversion of the users. Experiments with different conversion values showed quite similar results; due to lack of space we do not report them.
 For our experiments, we pick five different functions f . The types of functions depict our intuition of different pos-sible user behaviors; one is linear increasing with ` , another is exponentially decreasing, and the last three are first in-creasing and then decreasing with different rates (linear, ex-ponential, or a combination of the two). Every state s is assigned one of the above functions, which is then used for computing C ( `,s ) for that state. Baseline algorithms: In order to better judge and un-derstand the performance of our Greedy and Par-Greedy algorithms, we compare them with the following baselines. Stationary : Given the navigational model M and budget B on how many states content can be place, the Stationary algorithm picks the B states with highest stationary distri-bution (highest PageRank).
 Rank : The Rank algorithm is an extension of Stationary . That is, it first finds the stationary probability distribution  X  ( s ) (i.e., the PageRank score) for every state s . Then, it computes the rank of each state s as rank ( s ) =  X  ( s )  X  C (0 ,s ). Given budget B the Rank algorithm picks the B nodes with the highest rank ( s ) score.

Degree : For budget B , the Degree algorithm picks the B highest indegree states.

Basic : For budget B , we rank states s  X  S in decreasing order of C ( `, 0), i.e., the probability of a user being converted at every state at level 0. Then, the Basic algorithm reports the top-B states from this order.

Note that comparison with Rand (i.e., the algorithm that network selects random B nodes) is omitted since its performance is many orders of magnitude worse than any other algorithms.
In this section, we report the experimental results on the three real datasets we described above. Our results demon-strate the superior quality of the solutions obtained by Greedy (and Par-Greedy ) and the scalability of our algorithms rea-sonably large datasets.
 Qualitative evaluation: For the qualitative evaluation of our framework we run the Greedy algorithm as well as all the baseline algorithms (i.e., Rank , Stationary , Degree and Basic ) for all our datasets and report the expected conver-sion rate of the solutions they obtained as a function of the budget B = { 1 ,..., 200 } .

Results for the Road and Web datasets: The results ob-tained for the Road and the Web graph are shown in Fig-ures 3(a) and 3(b). For both datasets we observe that Greedy gives clearly the best results when compared to all other baseline algorithms. Also in both datasets the ranking of the rest of the heuristics is consistent: Basic and Rank are the second best, with Stationary and Degree to follow with so-lution with much lower expected conversion rates. The fact that Rank gives better results than Stationary is expected since the former takes both the stationary distribution and the conversion probability of each node into account when forming its solutions, while the latter only looks at the sta-tionary probability. Moreover, the relatively poor perfor-mance of Degree is also expected since the degree of the nodes is not necessarily correlated neither with its conver-sion probability nor its stationary distribution. Finally, the fact that Basic and Rank have almost identical performance is due to the fact that the C ( `,s ) values are much larger (in scale) than the stationary probability values and, therefore, the choices of the two algorithms are very similar.
Although the general trends observed in both the Road and the Web datasets are similar, one can also observe some high-level differences. More specifically, for the Road net-work (Figure 3(a)) the expected conversion rate of the so-lutions obtained by Greedy increases almost linearly with the size of the solution B . On the other hand, for the Web dataset (Figure 3(b)) the increase appears to be steeper, i.e., the Greedy solutions appear to benefit tremendously by the addition of new nodes in the solution. We conjecture that this effect is a result of the  X  X iversity X  of the nodes in the Web graph. That is, in the Road network there are no  X  X pecial X  nodes  X  after all nodes simply correspond to road intersections with an (average) degree equal to four. On the other hand, the nodes of the Web dataset have larger di-versity and the in-degrees of the nodes are distributed in a power-law fashion.

Results for the Science dataset: We also evaluate the per-formance of our methodology on even larger networks, we have experimented with Science dataset, which is an order of magnitude (in terms of the number of edges) larger than the other two. For this experiment, we have restricted our set of candidate nodes to a set of approximately 500 nodes sampled from the set of nodes in the graph with probabil-ity proportional to their in-degree. The expected conversion rate achieved by the solutions of the different algorithms are shown in Figure 3(c). For this experiment, we use the par-allel implementation of Greedy , which we call Par-Greedy .
Although the superiority of our method is clear in this dataset as well, the relative performance of the other heuris-tics is different in Science ; to see this compare the ranking of the baseline algorithms as indicated by the results in Fig-ure 3(c) with the ranking obtained by the results for the Road and Web datasets  X  shown in Figures 3(a) and 3(b). We can observe that for Science the performance of De-gree is clearly the second best, giving solutions between than Rank and Stationary . Clearly part of this change is due to the fact that we are only considering a subset of the nodes as candidates for content placement. More over, this subset is selected in such a way that is biased towards nodes with high in-degree. As a result, among those can-didates there are not so many nodes with high stationary probability and high conversion probability and, as a result, neither the Rank nor the Stationary algorithms perform as well as Degree . In fact, when we ran the experiment using all nodes as candidates, we would have obtained the same relative ranking for all baselines.

It is important to observe that in Figure 3(c) the expected conversion rate of the solutions obtained by our algorithm increases steeply as a function of the size of the solution. This steep increase resembles the results we obtained for the Web dataset  X  shown in Figure 3(b). The explanation we had in that case, applies here as well: the nodes in the science graph (as well as the candidate nodes) have diverse degrees following a power-law like distribution.
 Running times: In order to give an idea of the actual com-putational time required to run our experiments, we report here the running time required for executing one step of the Greedy algorithm, i.e., the execution of the for loop shown in line 3 of Algorithm 1.

Table 1 shows the running times of this execution both for the Greedy and Par-Greedy algorithms. Recall that Par-Greedy executes the searching over the candidates in a par-allel fashion. All the experiments were conducted using the configuration we described in the beginning of this section.
The results demonstrate that the parallel version of our algorithm offers an order-of-magnitude speedup to its cor-responding serial implementation. Even further, the evalu-ation of our candidate set for the Science network was im-possible to execute in the serial implementation of Greedy , but it was done in less than an hour using Par-Greedy . Table 1: Running time of Greedy and Par-Greedy for the selection of the first node of their solution.

In this paper, we introduced the RACP problem in nav-igational graphs, we studied its complexity and designed practical algorithms for solving it. The distinguishing fea-ture of our work when compared to other existing work in in-formation, transportation and navigational networks is that we consider memory-full user navigation, where the proba-bility of a user adopting a content depends on the number of times she has seen the same content in the past.
The main technical contribution of the paper is the de-velopment of a framework for solving the RACP problem, while taking into account both the users X  navigational and conversion models. The first model describes how the users navigate in the graph, while the other models the impact that repetition has on their inclination to adopt content placed on the graph nodes. The algorithmic framework we introduced here is flexible and can work for any navigational model that is described by a Markov chain and any conver-sion model that models the probability of a user adopting a content as a function of the state of the user and the number of her encounters with the content. Our algorithms exploit a connection between our model and random walks with absorbing states and provide a practical solution to the RACP problem. Our experimental evaluation on real datasets demonstrated the efficacy of these algorithms in multiple settings.
 Acknowledgments: This research was supported in part by NSF grants CNS-1017529, IIS-1218437, CAREER-1253393, CISE/CNS-1239021, CISE/CNS-1012798 and ENG/EFRI-0735974 as well as gifts from Microsoft and Google. [1] D. Agarwal, B.-C. Chen, and P. Elango.
 [2] O. Berman, D. Krass, and C. Wei Xu. Generalized [3] O. Berman, D. Krass, and W. Xu. Locating [4] S. Brin and L. Page. The anatomy of a large-scale [5] R. F. Bruner. Repetition is the first principle of all [6] M. Charikar, R. Kumar, P. Raghavan, S. Rajagopalan, [7] N. Chen. On the approximability of influence in social [8] F. Chierichetti, R. Kumar, and P. Raghavan. Markov [9] P. Domingos and M. Richardson. Mining the network [10] P. Doyle and J. Snell. Random walks and electric [11] E. Even-Dar and A. Shapira. A note on maximizing [12] M. Garey and D. S. Johnson. Computers and [13] M. J. Hodgson. A flow-capturing location-allocation [14] M. J. Hodgson, K. Rosing, A. Leontien, and [15] J. Kemeny and J. Snell. Finite Markov chains . [16] D. Kempe, J. Kleinberg, and E. Tardos. Maximizing [17] P. Kotler and G. Armstrong. Principles of Marketing . [18] J. Leskovec, A. Krause, C.Guestrin, C.Faloutsos, [19] M. Richardson and P. Domingos. Mining [20] K. Tanaka and T. Furuta. Locating flow capturing [21] J. S. Trent, R. V. Friedenberg, and R. E. J. Denton. [22] C. J. Weibell. Principles of learning: A conceptual
