 This paper develops a graph-theoretic framework for esti-mating comprehension in classroom. To deal with imprecise data gathered in classroom, we propose multi-step compre-hension propagation over a semantic graph. Random walks on the graph measure students X  comprehension with proba-bilities absorbed at student nodes.
 Categories and Subject Descriptors: H.3.3 [Informa-tion Search and Retrieval] General Terms: Human Factors, Measurement
Monitoring comprehension is essential for understanding the learning process in classroom. However, a task of judg-ing comprehension is often subjective and depends on ex-perience of observers. Moreover, it is difficult to monitor comprehension collectively at more abstract level. Tests or exams are, therefore, developed to measure students X  com-prehension at this abstract level, which otherwise becomes difficult to be directly observed in classroom. It is, however, often too late to remedy comprehension problems after the exams. Hence, the ability to recognize the problems early is needed. Appropriate intervention thereafter would reduce learning failure as well as dropout rates.

The objective of this paper is to make the monitoring pro-cess, which was once made implicit and subjective, explicit and systematic. We distinguish comprehension at two levels of lecture materials (e.g., slides) and concepts. Henceforth, we use slide(s) comprehension and concept(s) comprehen-sion to refer to students X  comprehension of a slide(s) and students X  comprehension of a concept(s), respectively. Iden-tifying concepts comprehension is the target of this paper.
To avoid confusion with complicated ideas, our research begins with a simple step to estimate comprehension. Imag-ine a device which connects to a database and allows a stu-dent to report his or her own slides comprehension real-time in classroom. A sample of data gathering is illustrated in Fig. 1. To estimate concept comprehension, teachers need to specify the percentage of content coverage as how much each slide explains a target concept. Concept comprehension is calculated by summing slides comprehension weighted by content coverage, e.g., in Fig. 1, 0.2  X  0.3+0.6  X  0.7.
There remain two difficulties to be solved. First, how to deal with imprecise data we gather from students? Specif-ically, inconsistency may arise when students report their own slides comprehension. For example, 5% is reported for a prerequisite slide for understanding a target concept while 90% is inconsistently reported for a later slide that explains the concept. Second, how to estimate content coverage? Manually estimating content coverage is time consuming and labor-intensive. Moreover, content coverage is difficult to be judged consistently by a teacher or among different teachers.
Our basic idea to address the consistency problem relies on a following assumption. Concept comprehension depends not only on slides that explain the concept but also on those that indirectly explain the concept. Those prerequisite slides might help, to some extent, compensate for the error esti-mated from directly relevant slides alone.

We approximate content coverage with document rele-vance calculated by an IR technique. Each concept is formu-lated as a keyword-based query executed against the collec-tion of slides. Content coverage percentage is approximated by relevance scores measured between slides and a query.
We borrow a technique of information propagation to esti-mate comprehension. Propagating test scores under the cri-terion of comprehension distinguishes our work from others which mostly deal with the relevance criterion (e.g., ranking web images against keyword-based queries [2], suggesting video clips relevant to user preference [1], and identifying experts pertinent to specific knowledge and skills [4]). Figure 1: Example of comprehension data reported via a device or a questionnaire. Content coverage is needed to estimate concept comprehension.
We formulate the problem of estimating comprehension as how to rank students according to their concept compre-hension. With this view in mind, we model a graph such that information about comprehension can be propagated. Entities are not difficult to be identified. They include real-world resources in the classroom such as students, slides, and concepts. On the other hand, care should be taken to select relationships among entities. We argue that it is the criterion of comprehension enhancement that allows us to carry information about comprehension along graph edges or links. Specifically, we create links such that every time we follow a link in the graph, comprehension of a start node must be increased. Starting at a concept node, we will finally reach nodes of students who most comprehend the start node. Probability distribution over those nodes allows us to rank students based on their comprehension. Figure 2 shows an example of such a graph we call cognitive graph .
A cognitive graph has a following interpretation. A stu-dent begins with a concept he tries to understand. The concept later leads him to find a relevant slide that explains it (represented by explainedBy ). While reading such a slide, he might find some other concepts unfamiliar to him (repre-sented by referTo ). To resolve this situation, he again be-gins the search for slides that explain those concepts (repre-sented by explainedBy ). Alternatively, to enhance his slide comprehension, he may directly ask a student who under-stands the slide well (represented by understoodBy ).
Assume that graph nodes are already determined. We add an ideal learner node for normalizing comprehension of other students. Ideal learner (IL) is the one who always obtains maximum comprehension levels for all slides and concepts. The role of IL is to enable the absolute comprehension mea-surement. Graph edges with weights  X  [0,1] are constructed by the following steps in order: 1. understoodBy is established for each pair of student 2. We use tf-idf scoring to measure similarity between 3. We create a lookup table that maps each concept to 4. Given a dictionary containing all concepts in the graph,
Let us explain how to estimate comprehension from a viewpoint of test scores propagation. Comprehension can be at best thought of as test scores. Given a start point of propagation, we are interested in the quantity of test scores as discrete particles that students absorb. The number of particles absorbed at student nodes indicates comprehension level of the start point. Edge weights determine the number of particles to be propagated along the links.

Figure 2 shows an example of propagating test scores from concept C 3 to students L 1, L 2, and IL . Given all edge weights already determined, we propagate 20 particles start-ing from C 3 at time t=0. At the steady state (t=  X  ), L 1, L 2, and IL receive 7, 3, and 10 particles, respectively. To be independent from the initial number of particles, we use probability value instead as the comprehension measure. For example, L 1 X  X  comprehension of C 3 is 7 7+3+10 =0.35. After normalization against IL , we can interpret that L 1 and L 2
From a mathematical viewpoint, test scores propagation on a cognitive graph corresponds to a Markov random walk .
We propose a random walk model, called ComprehEnRank (Compreh ension En hancement Rank ing) , for ranking stu-dents based on their comprehension levels. Our random walk model contains absorbing states which are nodes that once we enter, we cannot leave them. Absorbing states can be thought of as target objects to be ranked. Given a start node on a graph (at time t=0), a random walker will eventually (at t=  X  ) stay at one of the absorbing states. In this respect, we turn student nodes to absorbing states. We define transi-tion probability P ( j | i ) = n 1 if j = i and j  X  AS w where k ranges over all nodes, w ij is the edge weight from node i to node j , and AS is a set of nodes that have no out-going edges. Note that the first condition alters the graph topology by adding self-transition edges (with the transi-tion probabilities of one) to all absorbing nodes. These self transitions are important to make the transition probability matrix , C , stochastic (rows sum up to one).

Our random walk model proceeds until it reaches the sta-tionary distribution. From the theory of absorbing Markov chains [3], we know that the stationary distribution matrix is C  X  = h I 0 B 0 i where B = NR is the absorption proba-bility matrix , N = ( I  X  Q )  X  1 is the fundamental matrix , and C is arranged into the canonical form of C = h I 0 R Q that all absorbing nodes are ahead of non-absorbing ones.
The absorption probability matrix B alone, which con-tains all probabilities absorbed at student nodes, is enough to answer all quantities of interest. For example, in Fig. 2, we measure L 1 X  X  comprehension of C 1 by P ( L 1 | C 1)=[ B ]
Readers might notice that slides comprehension can also be measured by, e.g., P ( L 1 | S 1)=[ B ] S 1 ,L 1 . What is the dif-ference between P ( L 1 | S 1) and the weight of understoodBy , w
S 1 ,L 1 ? We distinguish two types of slides comprehension: real-time and collective . While w S 1 ,L 1 is slide comprehen-sion at a particular moment (reported real-time by students in classroom), P ( L 1 | S 1) is collective slide comprehension af-ter L 1 has seen n slides where n is the number of slide nodes. That is, P ( L 1 | S 1) is calculated after n slides are available to the random walk model.
We elucidate certain key characteristics of our random walk model through simple synthetic graphs. The ideal learner is omitted in the graphs. We make a note that the effect of referTo is suppressed by an increasing number of student nodes (data not shown). Our current guideline is to have only one student (and the ideal learner) in the graph.
Let Ci , Cj and Ck be concepts, and i 6 = j 6 = k . Ci is a direct prerequisite of Cj if there exists a directed path, in the cognitive graph, from Cj to Ci , and the path length is 2. Ci is an indirect prerequisite of Ck if Ci is a direct prerequisite of Cj , and Cj is a direct prerequisite of Ck .
To understand the effect of a prerequisite on a target con-cept, three scenarios are elaborated as shown in Fig. 3a-3c. The slide order is assumed, and the distance between two slides S 1 and S 2, measured in a sequential order, is D . The three graphs differ as how a concept is referenced. The first is when concept C 1 is backward referenced by C 2 (Fig. 3a). We investigate to what extent W 1 affects P ( L | C 2). Figure 4 shows that when D =1, P ( L | C 2) relies on W 1 as much as W 2. This reflects our assumption for addressing the issue of weights inconsistency. That is, if one does not understand S 1, one should not understand S 2 either. No matter how high W 2 is, P ( L | C 2) is penalized considerably when W 1 is low. A prerequisite C 1, however, has less effect on a target concept C 2 when S 1 and S 2 are far apart. As D tends to infinity, P ( L | C 2) no longer depends on W 1. Note that our random walk model behaves like a naive method (see Sect. 1) when D =  X  or referTo disap-pears. That is, we completely trust the value of W 1 and W 2 reported by student L as if S 1 and S 2 are independent. Our model subsumes this special case, and is adaptive in general, depending on the distance D or the lecture structure.
The second scenario is when concept C 1 references C 2 (Fig. 3b). Figure 5 shows that as D increases, W 2 has less impact on P ( L | C 1). Similar to the first case, S 1 and S 2 become independent when both slides are far apart.

The third scenario is when concepts C 1 and C 2 are cross-referenced (Fig. 3c). Interestingly, cross reference shows an implicit effect of (slightly) increasing the distance between S 1 and S 2. When W 1 increases, for example, the deci-sion region of P ( L | C 2) changes more slowly than it does for the case of backward reference alone (compare Fig. 6 with Fig. 4). Similarly, W 2 has lesser impact on P ( L | C 1) than the case of forward reference alone (compare Fig. 6 with Fig. 5). As a result, the two slides become more slightly independent. From a viewpoint of random walk, cross refer-ence creates a path that links back to a referencing concept, thereby reinforcing the importance of the concept.

The graph in Fig. 3d is developed to examine the effect of an indirect prerequisite C 0 on a target concept C 2. Figure 7 shows that the impact of W 1 on P ( L | C 2) increases as D increases. This is reasonable when we consider the chain of prerequisites. As D increases, W 0 has less impact on C 1 (i.e., the impact of a direct prerequisite), and even lesser im-pact on C 2. The lesser the impact of W 0 on C 2, the greater the impact of W 1 on C 2. In addition, the decision regions of P ( L | C 2) become brighter as W 0 increases. However, this is not the case when D =  X  . This is simply because S 0 stays too far from S 1 and S 2 so W 0 has no effect on the deci-sion regions. (each of the rightmost plots of Fig. 7 matches exactly with the bottom-left of Fig. 4)
The graph in Fig. 3e aims to answer an important ques-tion: to what extent our model provides a reasonable re-sult? After the weight of W 1 is reported for slide S 1, W 2 is reported, on average, for the next slides. We apply a random walk every time each new slide is included so we Figure 3: Cognitive graphs to investigate the impact of prerequisite slides. Figure 4: Impact of backward reference (Fig. 3a). Contours of P ( L | C 1) and P ( L | C 2) are plotted on two dimensions of W 1 and W 2 . The brighter the inten-sity, the greater the value of P ( L | C 1) and P ( L | C 2) .
Figure 5: Impact of forward reference (Fig. 3b). Figure 7: Impact of indirect prerequisite (Fig. 3d). Figure 8: Impact of prerequisite over time (Fig. 3e). can plot P ( L | C 1) and P ( L | C 2) on the time line. Figure 8 shows comprehension over time when W 1=0 and W 2=1. Initially, it makes sense that P ( L | C 2) is penalized by W 1 because W 2 is contradicted to W 1 (through the prerequi-site assumption). However, when t =3, it seems that L really understands C 2. This may lead to a conclusion that L also understands the prerequisite C 1. However, our model can only boost P ( L | C 2) up in the long run but not P ( L | C 1). Moreover, the distance D makes the situation worse by de-creasing the impact of W 2 on P ( L | C 1). Similarly, when W 1=1 and W 2=0, P ( L | C 1) does not drop down to zero de-spite the fact that P ( L | C 2) tends to zero in the long run (data not shown).

This limitation in both cases is due to the fact that our random walk model is predictive, not deductive. This be-comes clearer when we consider a simpler network in Fig. 3a. Figure 4 shows that P ( L | C 1) does not change at all no matter how W 2 increases. However, this is not always the case in reality. A student may finally understand C 1 after understanding C 2 or understanding both of them simulta-neously. We shall leave this issue for future study.
Since concept comprehension can be measured directly through tests or exams, we shall validate our results against students X  test scores. In addition, we are developing a method to replace tedious data gathering in classroom. Our pre-liminary result on learning weights of understoodBy from  X  X lide X  X  presentation features X  (e.g., word count, image count, slide position, slide duration) is encouraging.
