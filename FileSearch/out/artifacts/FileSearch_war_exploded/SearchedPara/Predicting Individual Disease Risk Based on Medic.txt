 The monumental cost of health care, especially for chronic disease treatment, is quickly becoming unmanageable. This crisis has motivated the drive towards preventative medicine, where the primary concern is recognizing disease risk and taking action at the earliest signs. However, universal test-ing is neither time nor cost efficient. We propose CARE, a C ollaborative A ssessment and R ecommendation E ngine, which relies only on a patient X  X  medical history using ICD-9-CM codes in order to predict future diseases risks. CARE uses collaborative filtering to predict each patient X  X  greatest disease risks based on their own medical history and that of similar patients. We also describe an I terative version, ICARE, which incorporates ensemble concepts for improved performance. These novel systems require no specialized in-formation and provide predictions for medical conditions of all kinds in a single run. We present experimental results on a Medicare dataset, demonstrating that CARE and ICARE perform well at capturing future disease risks.
 I.2.1 [ Artificial Intelligence ]: Applications and Expert Systems X  Medicine and science ; I.5.1 [ Pattern Recogni-tion ]: Models X  statistical ; J.3 [ Computer Applications ]: Life and Medical Sciences X  Medical information systems Algorithms, Experimentation collaborative filtering, disease risk prediction, ensemble, prospec-tive health care Corresponding Author
Medical care and research are literally the most vital part of science for humans, as none of us are immune to phys-ical ailments and biological deterioration. Annual health care expenditure in the U.S. alone is an overwhelming sum, with a strong majority of this money used for chronic dis-ease treatment. Experts expect the burden on the system to continually increase in coming years. The rapidly increasing medical concerns of the baby boomer generation is one ma-jor factor stressing the health care system. A CDC study estimates that 880.5 million visits were made to physician offices, about 3.1 visits per patient, in 2001 [3]. Since 1992, the average age increased to 45 years, and the visit rate for persons 45 years of age and over increased by 17% from 407.3 to 478.2 visits per 100 persons [3].

Health care, thus, needs to become more proactive than reactive in recognizing the onset of disease and risk. How-ever, the combinatorial problem generated by the different disease factors and the previous medical history of a pa-tient is so complex that no single health care professional can fully comprehend it all. Currently, physicians can use family and health history and physical examination to ap-proximate the risk of a patient, guiding laboratory tests to further assess the patient X  X  stage of health. However, these sporadic and qualitative  X  X isk assessments X  generally focus on only a few diseases and are limited by a particular doctor X  X  experience, memory, and time. Therefore, current medical care is reactive, stepping in once the symptoms of a disease have emerged, rather than proactive, treating or eliminating a disease at the earliest signs.

Today the prevailing model of prospective heath care is firmly based on the genome revolution. Indeed, technolo-gies ranging from linkage equilibrium and candidate gene association studies to genome wide associations have pro-vided an extensive list of disease-gene associations, offering us detailed information on mutations, SNPs, and the asso-ciated likelihood of developing specific disease phenotypes [4]. The underlying hypothesis behind this line of research is that once we catalogue all disease-related mutations, we will be able to predict the susceptibility of each individual to future diseases using various molecular biomarkers, ush-ering us into an era of predictive medicine. Yet, these rapid advances have also unraveled the limitations of the genome based approaches [12].

Given the weak signals that most disease associated SNPs or mutations offer, it is increasingly clear that the promise of the genome based approaches may not be realized soon. Does this mean that prospective approaches to health care will have to wait until the genomic approaches sufficiently mature? Our aim here is to show that phenotype and dis-ease history based approaches offer the promise of rapid ad-vances towards disease prediction. Recent literature further justifies the move towards a more prospective medical care system [9, 16].

Related research has largely focused on computer-aided medical prediction systems. One very widely used system is the Apache III [17], a prognostic scoring system for predict-ing inpatient mortality. Apache uses a combination of acute physiological measurements, age, and chronic health status. There are also a number of systems developed for predicting risk of individual diseases, such as specific heart conditions [5], hepatitis [15], Alzheimer X  X  disease [11], etc.
Our approach is distinctly different in that we are trying to build a general predictive system which can utilize a less constrained feature space, i.e. taking into account all avail-able demographics and previous medical history. Moreover, we rely primarily on ICD-9-CM (International Classification of Diseases, 9th revision, Clinical Modification) insurance codes (see Section 1) for making predictions to account for the previous medical history, rather than specialized test results.
This research seeks to aid the development of a predictive system by examining the use of medical history to examine information about disease correlations and inexpensively as-sess risk. An effective proactive approach requires an under-standing of disease interdependencies and how they translate into a patient X  X  future. Due to common genetic, molecular, environmental, and lifestyle-based individual risk factors, most diseases do not occur in isolation [1, 4, 13]. Shared risk and environmental factors have similar consequences, prompting the co-occurrence of related diseases in the same patient. Therefore, a patient diagnosed for a combination of diseases and exposed to specific environmental, lifestyle and genetic risk factors may be at considerable risk of devel-oping several other genetically and environmentally related diseases.

How can we exploit such interconnections and gen-erate predictions about the future diseases a patient may develop? The underlying thesis of our work is to generate a patient X  X  prognosis based on the experiences of other similar patients. We attempt to build on these rela-tionships across millions of patients to effectively determine a prediction for a patient. Our goal is to provide every pa-tient with an personalized answer to the question: What are my disease risks?
We approach this problem using collaborative filtering methodology. Collaborative filtering is designed to predict the preferences of one person (active user) based on the pref-erences of other similar persons (users). The technique is based on the intuitive assumption that people will enjoy the same items as their similar peers, or more specifically, having some common preferences is a strong predictor of additional common preferences. Predictions are based on datasets consisting of many user profiles, each containing information about the individual user X  X  preferences. This has made a significant impact on marketing strategies. We draw an analogy between marketing and medical prediction. Each user is a patient whose profile is a vector of diagnosed diseases. Using collaborative filtering, we can generate pre-dictions on other diseases based on a set of other similar patients. However, the ratings in our case are binary  X  a pa-tient either has a disease (1) or does not have a disease (0). There is no ordinal set of ratings as is typically observed in movie or music data. Another difference is that the users choose to rate movies and music, while the diseases are not a patient choice, per se.

Key contributions in this work include the following: 1. A novel application of collaborative filtering in the 2. The collaborative filtering employed, while building 3. A case study is provided as a real-world example of
Our entire database comprises the Medicare records of 13,039,018 elderly patients in the United States with a to-tal of 32,341,348 hospital visits. Such Medicare records are highly complete and accurate, and they are frequently used for epidemiological and demographic research [10, 14]. Our data is completely anonymized; that is we have no mean to identify the patient or the hospital the patient visited. The input for our methods consists of each patient X  X  diagnosis history, provided per inpatient visit. Each data record rep-resents a hospital visit, represented by a patient ID and a list of up to ten diagnosis codes, as defined by the Inter-national Classification of Diseases, Ninth Revision, Clini-cal Modification (ICD-9-CM). The International Statistical Classification of Diseases and Related Health Problems pro-vides codes to classify disease and a wide variety of signs, symptoms, abnormal findings, social circumstances, and ex-ternal causes of injury or disease. It is published by the World Health Organization. Each disease or health condi-tion is given a unique code, and can be up to 5 digits long. However, the 5 digit codes can be collapsed for some disease to fewer characters for identifying a family of diseases. In the Medicare data, the first code is the principal diagnosis, followed by any secondary diagnoses made during the same visit. A sample patient medical history is shown in Table 2; each line represents one hospital visit.

The number of visits per patient ranges from 1 to 155, with a median of 2. Also, though up to ten diagnosis codes are permitted, the average is only 4.32 per visit. There are a total of 18,207 unique disease codes expressed in the database. However, only 169 diseases occur at 1% or more in the population (across visits for patients). Table 1.1 shows the 20 most prevalent diseases in our database.

Demographic data was also available and was used to ex-amine CARE X  X  predictive power. Figure 1 shows the distri-bution of patients across the demographics of age, gender, and ethnicity. The different races are coded as 0 through 6 in our database. In spite of being a relatively homogeneous database (all senior citizens), there is still significant diver-sity in the age, gender, and ethnicity distribution. Since these factors are known to influence certain medical condi-tions, we use them to partition our database and perform experiments on the demographic-specific subsets.
Before detailing the individual components, a high-level preview of the entire CARE framework is provided in Fig-ure 2. The dotted lines represent optional methods. As shown, both testing and training data enter the system at the same time. We form a cluster of relevant patients based on the  X  X nown diseases X  of the testing patient. Collaborative filtering is performed on the resulting cluster, generating predictions for the future visits of the testing patient. Each component is further defined in the subsequent sections. In the case of ICARE, this process is performed multiple times for each patient, with each iteration using a different basis for clustering. These different clusterings are combined to form an ensemble. The output after CARE and ICARE is a ranked list of diseases in the subsequent visits of the testing patient, ranked in order from the highest risk score to the lowest. If desired, the output can be easily collapsed into less specific groups of medical conditions due to the hierarchical nature of the disease codes.
Our collaborative filtering technique is derived from the vector similarity algorithm presented by [2]. Traditionally, collaborative filtering is used to make a prediction p ( a,j ) of the likelihood of user a , the active user (testing), on item j based on the similarity between user a and every member of the set I j who have previously rated that item. The sim-ilarity w ( a,i ) between users a and i is calculated by vector similarity; that is, J i is the set of items rated by user i . The prediction and similarity weight takes into account the average vote v i each user to account for personal differences. A normalizing constant  X  is added so that the sum of weights is equal to 1, constraining the prediction within the range of possible votes (in this case, 0 and 1). Thus, the general collaborative filtering equation is:
However, this equation will not suffice for the proposed application in the medical domain. The user in this case is a patient and the items are diseases. Each patient i either has ( v i,j = 1) or does not have (no vote) disease j . Since every vote is 1, it is easy to see that every v term will be one, and the algorithm then predicts that every user has every disease with a likelihood of 1, an obvious error. The pro-posed changes modify the general equation to incorporate binary the diagnoses and remove the effect of the range of ratings. The general equation 2 is also modified to be de-pendent on the average number of occurrences, or random expectation, of each disease. This average is referred to as the baseline prediction about the disease, v j . Thus, the like-lihood of the active patient a on disease j can be expressed as follows: with the normalizing constant
Intuitively, the equation treats the random expectation v as the baseline expectation of each patient having disease j , and adds additional risk based on similarity to other patients with disease j .
We further extended Equation 1 to include inverse fre-quency (IF), which gives lower weights to very common dis-eases in the training set, based on the intuition that sharing a rare disease has more impact on similarity than sharing a common disease. For instance, individuals sharing a rare genetic disease are assumed to be more similar than two patients with general hypertension. Furthermore, two pa-tients with the same disease are considered more similar if they share a specific type of complication. This is particu-larly influential in our medical database. There can be many medical diagnoses shared between patients but most impor-tant contributions arise from uncommon connections. The inverse frequency of disease j is defined as where n is the number of patients in the training set, and n is the number of patients who have j. This is incorporated into the similarity weighting equation by multiplying each disease vote by the corresponding IF factor. The resulting equation for w ( a,i ) is No changes to the general equation are needed. All of the ex-perimental results discussed were found using this method, which we call inverse frequency vector similarity ( IFVS ).
We cluster patients on the basis of shared diseases. Before each application of collaborative filtering, clustering is ap-plied to the training set to discover connected components of patients. This serves to remove the influence of patients who have little or no similarity with the testing patient for whom predictions are being made. This is determined by the number of diseases which the patients have in common. In the most basic case, patients are removed only if they have no diseases in common with the active patient. It can be seen in Equation 5 above that these patients have a weight of zero and do not contribute to the prediction scores. Thus, removing these patients does not result in loss of informa-tion, but effectively reduces the runtime of the algorithm. In practice, we cluster such that all patients in the training set have two or more diseases in common with the known diagnoses of the active patient.

Introducing the constraint that clustering patients in the training set must have at least two common diseases with the active (testing) patient enforces stronger similarities for all patients influencing the predictions. Essentially, we build a network of patients that are connected by at least two diseases and then perform collaborative filtering in this net-work. In theory, this helps to avoid the noise resulting from common diseases that introduce a very high number of weak influences. The clustering provides an additional benefit by reducing the number of diseases predicted on, which both simplifies and improves the collaborative filtering results. This effect will be further discussed in the next chapter. It is important to note that the frequency of diseases is dif-ferent within the cluster than the overall occurrence in the entire dataset. We will refer the global v j as the  X  X aseline X  of disease j and the new v cj after clustering as the  X  X luster baseline X  of disease j . In all experiments where clustering is employed, the cluster baseline is used in the IFVS equation.
Even with the double-overlap clustering method combined with IFVS, we still observed that common diseases can dom-inate the effect of collaborative filtering since they account for the majority of the patients in the cluster. Ideally, we want to capture the effect of each individual disease with minimal noise from other diseases, but without the loss of information due to removing them. To meet this goal, we developed an iterative version of CARE using ensembles of individual-disease clusters. Specifically, for each disease j developed by the test patient a , collaborative filtering is ap-plied only to the cluster of training patients with disease j . As before, the collaborative filtering scores build onto the cluster baselines. Each component of the ensemble is a round of collaborative filtering on an individual disease clus-ter, and it follows that the number of components is equal to the number of unique diseases which patient a has had. Within each component, the collaborative filtering still uses the entire past disease vector of patient a. Thus, each dis-ease has a chance at making a strong impact individually, but all disease interactions are preserved. The ensembles are combined by taking the maximum prediction score for each disease, that is where C is the set of clusters c . We choose the maximum since diseases are generally not protective against each other, with few exceptions. In other words, additional unrelated diseases do not lessen the probability of developing a disease. Such ensembles can be easily run in a distributed fashion as each cluster evaluation is independent of the other.
In order to reduce the number of predictions and the run-time of the ensembles, we only predict on diseases for which the cluster baseline is significantly higher than the popula-tion baseline. That is, if the population baseline is larger than the cluster baseline, then the disease being predicted on does not have a good set of predictive diseases in the cluster. We determine the significance of a disease in the cluster using a difference of proportions test. This statistical test determines whether the difference between two sample proportions taken from different populations is significant. The null hypothesis is always that the two proportions are equivalent, and the alternative hypothesis is that they are not equivalent. A z score is then found using the equation Here, p 1  X  p 2 is the difference between the sample proportions and S is the associated standard error determined by the equation where p is the weighted average of p 1 and p 2 , while n 1 are the respective sizes of the samples. In our formulation, p is the cluster baseline, p 2 is the population baseline, n the number of patients in the cluster, and n 2 is the number of training patients. We use a 95% confidence interval. In some cases, it is desirable for all 4 or 5-digit ICD-9-CM codes to be collapsed into more general 3-digit codes, which represent small groups of related or similar diseases. In general, these groups are not based on comorbidity; they are often comprised of specific forms or complications of the same disease or injury. The grouping is based entirely on the structure of the ICD-9-CM coding scheme. For exam-ple, the ICD-9-CM code of 426 corresponds to Conduction disorders . The specific version of 426.0 corresponds to Atri-oventricular block, third degree ; this can be further specified as (426.11) Atrioventricular block, first degree ; (426.12) Atri-oventricular block, Mobitz II and (426.13) Atrioventricular block, Wenckebach X  X  .

Such 4 or 5 digit codes can be truncated to 3 digits ei-ther before (pre-collapse) or after (post-collapse) applying collaborative filtering. In the first case, collaborative filter-ing is applied to vectors of already shortened codes. This significantly reduces the number of diseases being predicted, consequently reducing the runtime. However, pre-collapsing results in loss of all information provided by the more de-tailed codes, since only one composite prediction is made for each 3-digit disease group. When post-collapsing, the collaborative filtering is run normally on the original codes, and the results are merged after completion. The 3-digit code group adopts the highest prediction score given to one of the members. That is, the likelihood of having a gen-eral disease is equal to the highest likelihood of having some specific instance of the disease.

Post-collapsing can be done in a hierarchical manner, so that the detailed results provided by specific ICD-9-CM codes are preserved. Collapsing the ICD-9-CM codes is beneficial in multiple ways. In the case of pre-collapsing, algorithm efficiency is improved. In both cases, the reduced number of diseases predictions makes the results simpler to evaluate and interpret. Also, collapsing reduces the negative effects of assuming that all undiagnosed diseases are not present. For example, a high score for diabetes will be evaluated as a successful prediction of diabetes with a specific compli-cation. Without collapsing, the relationship between the two diabetes codes could not be directly considered, and the rareness of the complication could cause the diabetes diag-nosis to be overlooked or highly underrated. This is particu-larly relevant since Medicare data does not reliably capture complications [14]It is important to note that post-collapsing the codes does not change the performance of collaborative filtering; this method primarily serves to make evaluation of the performance more accurate, giving the medical prac-titioner the choice to conduct further tests to identify the specific nature of the disease.
CARE and ICARE generate predictions only on  X  X uture X  visits of a patient in the testing set based on the medical history provided; that is, we only want to evaluate perfor-mance on diseases which happen on a later date than those that the collaborative filtering algorithm was given (akin to leave-one-out testing). For this reason, the collaborative fil-tering algorithm is given information about the active user one visit at a time, and performance is measured only in terms of those diseases which occur in the following visits. The reported metrics are averaged across all future visits predictions across all testing patients.

It is difficult to determine whether an individual predic-tion is successful or not, since setting a threshold on the prediction score is unreasonable in this domain. The high-est risk scores for one patient might be relatively low for another patient with more obvious concerns. We determine performance based on the overall list of predictions, ranked in order from the most likely to the least likely. Specifi-cally, the diseases are given a rank k in order from highest prediction score p to the lowest, with the highest score hav-ing k = 0 . Note that a baseline ranking can also be deter-mined by ordering the diseases by their prevalence in the overall population. The performance measures on the base-line ranking serve as a benchmark for experiments; that is, a good collaborative filtering method should produce a signif-icantly better ranking than one based solely on knowledge of disease prevalence. The baseline ranking is essentially the best guess for a patient for which no further information is known, or alternately, who is assumed to be equally similar to everyone in the database. Since our data is from a tar-geted group (senior citizens), the likelihoods of diseases are more meaningful than in a general database. We use three metrics to assess the baseline ranking and the prediction lists generated by CARE and ICARE.

The first performance metric is list coverage . A method X  X  coverage is defined as the percentage of diseases for which a prediction is made and ranked. This is necessary since test patients occasionally express diseases which never occur in the training set, and significance testing can cause some diseases to be dropped from consideration. Obviously we wish to capture as many future diseases as possible, so high coverage is preferred. The average rank of future diseases is also used as an evaluation metric, since it is desirable for future diseases to have low rank positions. Ideally, the diseases which a patient actually develops should be near the top of the list, where they are most likely to be noticed and used.

The last metric is also based on this concept. Referred to as half-life accuracy [8], this metric is intended to measure the expected utility of the ranked list [7]. Based on the rank k , p ( k ) is defined as the probability that a user reading the list would consider the disease in position k before stopping. The scenario is, given a long list, a user would start with the highest risk diseases, but will not read the entire list due to lack of time or further interest. Thus, p ( k ) is an exponentially decaying function defined where a is a user-defined constant that determines the speed of decay. For our experiments, we use a = 5. The utility of the list is then , where  X  k = 1 for future diseases, and  X  k = 0 otherwise. Intuitively, this means that utility is entirely based on how highly future diseases are ranked. The half-life accuracy is then defined as the average over all test patients i of the expected utility of the ranked list of predictions for i divided by the utility of a perfect ranking for i , where all future diagnoses are in the highest possible rank positions. That ID Visit 1 Round 1: ID Visit 1 ID Visit 2  X  Round 2: ID Visit 1  X  Visit 2 ID Visit 3 Round 3: ID Visit 1  X  Visit 2  X  Visit 3 Figure 3: Example of how patient visits are pro-cessed by the IFVS algorithm. ID refers to a patient ID. is, where N is the number of test users, R i is the number of items that are predicted on for user i , and M i is the number of diseases in R i such that  X  ik = 1 . The denominator of the half-life accuracy measure is a per-user normalization, which takes into account the varying number of patient diagnoses.
As implied above, a doctor may not have time or interest for looking at the entire list of predictions, which can contain thousands of prediction scores in the worst case. A more at-tainable goal would be to consider only the top 20 or top 100 predictions. In addition to overall performance, we also consider the coverage, average rank, and half-life accuracy within those ranges. The performance on the top 20 or top 100 ranks is a much stronger measure of realistic usefulness than the overall results. Coverage is particularly important in these limited ranges. A doctor could conceivably consider all diseases on a list of 20, making actual rank less mean-ingful. However, each additional  X  X orrect X  prediction on the list could have a substantial impact. There is some tradeoff between average rank and coverage, since higher coverage captures less obvious diseases with lower rank.
For our experiments, we selected patients that had at least five visits recorded in our database to allow for sufficient patient history for both training and evaluation. We then randomly created equal sized training and testing sets; each testing patient was further evaluated using leave-one-visit-out validation. We first present and compare the perfor-mance of the baseline ranking, CARE, and ICARE. Then, we show the impact of collapsing of ICD-9-CM codes on the predictive performance. Finally, we analyze the effect of demographic-based segmentation.
The predictions were generated on the future visits of a patient. Since the order of disease occurrence is necessary for making meaningful predictions, the testing set was left in the original format, with each visit as a separate record. Both CARE and ICARE make one round of predictions for each visit, adding the diagnoses of the next visit in each successive round while retaining all diagnoses from previous visits. The idea is that on round i , the algorithm  X  X nows X  all diagnoses up through visit i , and is evaluated on ability to predict diagnoses which occur in visits i + 1 and on. Figure 3 provides a pictorial explanation of this process.
Table 3 presents the analysis. The baseline method corre-sponds to a list of the diseases ranked in order from highest baseline prevalence to lowest. As mentioned earlier, results on the top 100 and top 20 ranks are more meaningful, since Table 3: Evaluation of performance of CARE and ICARE compared with the baseline ranking. a medical practitioner or other user is unlikely to consider a very large portion of the list. CARE shows significantly better performance than baseline across the board overall and in the top 100 ranks. In the top 20 ranks, CARE covers 6% more diseases than the baseline method with minimal impact on the average rank.

ICARE shows very substantial improvement over both the baseline and CARE in all cases. This method captures about 13% more of the future diseases than the baseline method in the top 20 rankings alone, while the average rank of 5.77 sug-gests that most of these captured diseases are in the first few positions on the list. It is particularly powerful that both av-erage rank and coverage improve simultaneously, since there is some tradeoff between the two metrics. The most impres-sive result is that ICARE predicts more than 41% of all future diseases in the top 20 ranks, a list of a manageable size for use by a doctor or other medical professional.
It merits explanation that the half-life accuracy overall and in the top 100 are the same, although actually not iden-tical at higher precision. This happens because of the way half-life accuracy is defined, where the utility decreases as a future disease moves down the list. The exponential decay is such that information beyond the top 100 ranks has minimal impact on the half-life accuracy. By modifying the a value defined in 4 to slow the decay, these accuracies could be forced to diverge. Regardless, it seems unreasonable that a medical professional would seriously consider the list beyond 100 diseases, making the equal utility realistic.
After the initial results, we also performed experiments using both the pre-and post-collapsing methods described earlier for condensing the disease codes. Our initial ex-periments showed the two methods tend to perform very similarly. Since the hierarchical nature of post-collapsing preserves all information, we determined it to be the bet-ter method and present results from post-collapsing. We believe that post-collapsing is a more amenable method to the eventual use of the system  X  it still provides a medi-cal practitioner a choice to retrieve the complete resolution of ICD-9-CM code. If we pre-collapse the ICD-9-CM codes and then run CARE, the full resolution is lost. The results of our methods on the 3-digit ICD-9-CM codes are shown in Table 4.
 Table 4: Evaluation after post-collapsing ICD-9-CM codes.

The relative performance of the three methods shows very similar trends to those in Table 3. This is reasonable, since post-collapsing is actually a post-processing step applied to the earlier results. Post-collapsing results in an improvement in ranking and coverage across the board. ICARE shows a slight dip in the half-life accuracy measure. We believe this arises because of multiple high-ranking diseases collapsing to a common code, eliminating the dominance in the top ranks. Since, the half-life accuracy metric is strongly dependent on the highest ranks, the decrease occurs.

These results from collapsing of ICD-9-CM codes are very encouraging, with nearly 49% of future disease  X  X amilies X  among the top 20 predictions. Still, it is an important dis-tinction that the collapsed results are not necessarily better than the original 5-digit results if measured in terms of gran-ularity. They are a more condensed but less detailed version of exactly the same results. However, this list could con-ceivably be used to present a medical practitioner with a greater breadth of predictions in the same concise format. The details could then be selectively considered, based on the hierarchy preserved by the post-collapsing method.
In addition to overall performance, we experimented to see if demographic information can be used to improve the predictive performance of the CARE framework. It is well known that many biological, social, and environmental fac-tors can influence health, so we hypothesized whether using more homogenous data sets would be beneficial. The demo-graphics explored were age, gender, and race. The specific categories include both genders, 5 racial groups, and 7 age groups spanning 5 years each. We partitioned the training and testing sets based on the considered demographic cate-gories. New experiments were run on each partition of the testing set using the corresponding training set. We present only the results on the top 20 ranks after using ICARE, as this method was shown in the previous section to be consis-tently superior and the highest ranks are most meaningful.
The demographic categories, prevalence statistics, and ex-perimental results are shown in Table 5. We point out that we did not consider races 4, 5, and 6, since they had low prevalence rates of 0.13%, 0.26%, and 0.04%, respectively. For comparison, we also present the results on each demo-graphic segment when the original data was used in the en-Data) and the demographic specific segments (Demographic Training Data). tirety. These are displayed under  X  X riginal Training Data X  in Table 5. There is clearly a marginal difference in the rela-tive performance of the global method across the partitions. The older population and females generally have a higher coverage. Race 2 performs relatively better than the other races, while race 3 is the lowest across all the segments.
Application of ICARE after the demographic segmenta-tion resulted in dip in performance, interestingly. The ho-mogeneity of the group offered by demographic split does not seem to add any improvement to the performance of ICARE. We believe this is due to the  X  X luster ensemble X  effect of ICARE that intrinsically identifies more similar groups.
Since each cluster in ICARE is simply a group of all pa-tients expressing a disease, the demographic distribution for that disease is expressed within the cluster. For example, if it clusters on prostate cancer, this eliminates all the fe-male patients and already generates a more homogeneous cluster of patients, reflective of the demographic of males. However, if one clusters on heart disease and the patient is a woman, the cluster could still carry prostrate cancer as the clustering constraint was heart disease and no gender information was implied. But we conjecture that because we are clustering on each individual disease in the history of the patient, some of the demographic distribution will begin to emerge with ICARE. Also, while the actual prevalence of a disease may vary within different demographic groups, the relative ordering of the diseases tends to be fairly similar across the categories, especially for common diseases. This means that a disease usually will have fairly similar baseline rank despite the demographic. Since we evaluate on rela-tive rankings rather than thresholds, the actual prevalence percentage matters less than relative baseline ranking.
To demonstrate the CARE process proposed and applied in this work, we present case studies which place the algo-rithm results in the context of real patients. We look at the ranked list of disease predictions generated for a cancer pa-tient after each of 3 subsequent hospital visits. This study was done using ICARE, which is demonstrated to be our best method. The patient diagnoses and top 10 predictions are provided in Figure 6.

We point the reader to the most prevalent diseases in Ta-ble 1.1. These are relevant to the case study since they pose the greatest challenge for other future diseases to overcome. It is worth noting that many of these diseases have been linked with one another in other medical studies. In fact, 4 out of the 10 are forms of heart disease, which has known links with hypertension and diabetes. This only serves to increase their influence.

Figure 4(a) shows the actual diseases developed by the patient. It is evident that we are dealing with a cancer pa-tient. The first visit has the initial diagnosis of esophagal cancer, which spreads into secondary malignancies in the fol-lowing visits. Since cancer is not a quickly treated disease, the original diagnoses recur in later visits. Since predicting these diseases is not interesting, we don X  X  include them in the top 10 lists. In the final visit, the diagnoses diversify to include hypertension, regional enteritis, and a mineral defi-ciency. Figure 4(b) shows the results after applying ICARE to the first visit. Even from the first visit, we are able to predict the two locations of cancer spread with rank 3 and 4.

Figure 4(c) shows the prediction after the second visit is observed. Upon adding an additional form of cancer in the second visit, we see little change except for a slight reorder-ing of the list. The space left after removing liver cancer was filled by urinary tract infection. This is a good exam-ple of prevalent diseases overtaking others once they make it through the significance test. Despite the fact that hy-pertension is the most prevalent disease in the database, we are not able to predict the occurrence in visit 3. This does not necessarily imply a mistake. Hypertension did not appear anywhere on the prediction list for visits 1 and 2. Considering the significance testing, this implies that it is not strongly connected to the cancers and thus should not be predictable. A similar argument applies for the enteri-tis. The disorder of mineral metabolism does appear in the rankings after the first two visits, at 71 and 83 respectively. 1 cancer, bronchus/lung 2 anemia 3 urinary tract infection 4 secondary cancer, lymph nodes 5 disorder of fluid/elecrolyte balance 6 pneumonia 7 secondary cancer, unspecified 8 pleurisy 9 cancer, ovary 10 disease of white blood cells (c) ICARE Prediction After Visit 2 This acknowledges a significant link to the disease,placing it still within the top 100 but not among the strongest con-cerns. The predictions in Figure 4(d) cannot be validated, since we only have ground truth up to visit 3. Nevertheless, these predictions are interesting because they exemplify list reaction when a patient has more than one type of condition. Two of the predictions are still cancers. The list now has a digestive condition, attributable to the enteritis. However, the strong links associated with hypertension are by far the dominant effect in this final list; that is, the heart conditions become the strongly predicted diseases after this visit.
From this case study, we can see that ICARE is able to make reasonable and intuitive predictions. When multiple unrelated conditions are introduced simultaneously, the list is able to diversify. In the case of this conflict, the more common or heavily linked condition is dominant, securing a higher percentage of the ideal rank positions.
The goal of our work was to come up with a system that can assist a medical practitioner in decision making. If a sampling of future diagnoses can be provided to a practi-tioner, appropriate medical tests can be ordered sooner and lifestyle adjustments can be adopted by the patient proac-tively. This will not only result in improving the quality of life for the patient, but also in reducing the health care costs. To that end, we proposed CARE, a collaborative recom-mendation engine for prospective and proactive healthcare. CARE relied solely on the ICD disease codes, which are a standard across insurance and medicare databases. This exploitation of ICD codes by CARE allows for a seamless integration with a variety of electronic healthcare systems that use or will embrace the standard of ICD. Also, as the medical community moves toward comprehensive electronic records, CARE becomes increasingly relevant.
ICARE X  X  use of ensembles clearly demonstrated that iso-lating significant relationships and controlling high-prevalence diseases is essential for making better predictions. The im-pressive future disease coverage of ICARE represents more accurate early warnings for thousands of diseases, some even years in advance. In its most conservative use, the rank lists can provide reminders for conditions that busy doctors may have overlooked. Applied to full potential, the CARE framework can be used to explore broader disease histories, suggest previously unconsidered concerns, and facilitate dis-cussion about early testing and prevention
Incorporating demographic information did not positively influence the predictive power of ICARE, in general. While additional work is necessary before making a judgement about the potential usefulness of this information, the cur-rent results suggest that a randomly sampled training set reflecting the distribution of the entire population is suffi-cient for testing patients of most demographic groups.
Our development and evaluation of CARE has shown that collaborative filtering is a strong and viable approach to disease prediction. However, there are still many interest-ing avenues for future work. While In this paper, CARE is limited to ICD-9-CM data, the underlying collaborative framework has no such limitation. While it is an advan-tage that our system doesn X  X  require test results or special information, such advanced results when available can add further value. CARE could exploit this information through similarity metrics that are appropriately modified for more complex representations of medical history. It is part of our future work to incorporate such prognostic and diagnostic information about patients.

The current implementation of CARE captures an aspect the temporal information available in the data. The experi-mental setup limits prediction to future disease, an obvious necessity. However, other temporal data is implicit, such as the length of time between visits or the absolute order or disease occurrence in each patient. Developing methods to harness this information could lead to more precise predic-tions and even estimated time of disease onset.

We are also incorporating clinical use by collaborating with medical professionals. A longer term study with ex-plicit testing (where reasonable) and monitoring for pre-dicted conditions would be the gold standard.
 Center of Research Computing at the University of Notre Dame for the high performance and distributed computing resources for this work. This work was partially supported by the Arthur J. Schmitt Fellowship at Notre Dame. [1] A.-L. Barabasi. Network medicine  X  from obesity to [2] J. S. Breese, D. Heckerman, and C. Kadie. Empirical [3] D. K. Cherry, C. W. Burt, and D. Woodwell. A [4] W. T. C. Consortium. A national ambulatory medical [5] O. Cord  X on, F. Herrera, J. de la Monta  X na, A. S  X anchez, [6] N. C. for Health Statistics. International Classification [7] D. Heckerman, D. M. Chickering, C. Meek, [8] J. L. Herlocker, J. A. Konstan, L. G. Terveen, and [9] J. Langheier and R. Snyderman. Prospective medicine: [10] D. S. Lauderdale, S. E. Furner, T. P. Miles, and [11] Y. Liu, L. Teverovskiy, O. Lopez, H. Aizenstein, [12] J. Loscalzo. Association studies in an era of too much [13] J. Loscalzo, I. Kohane, and A.-L. Barabasi. Human [14] J. B. Mitchell, T. Bubolz, J. E. Paul, C. I. Pashos, [15] F. Piscaglia, A. Cucchetti, A. Orlandini, E. Sagrini, [16] R. Snyderman and R. S. Williams. Prospective [17] D. T. Wong and W. A. Knaus. Predicting outcome in
