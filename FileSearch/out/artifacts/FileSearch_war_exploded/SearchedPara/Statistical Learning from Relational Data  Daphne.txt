 Much of the data in the world is relational in nature, involving multiple objects, related to each other in a variety of ways. Examples include both st ructured databases such as customer transaction data, semi-structured data such as hyperlinked pages on the world-wide web or networks of interacting genes, and unstructured data such as text. In this talk, I will describe a statistical framework for learning from relational data. The approach is based on probabilistic models, which have been applied with great success to a vari ety of machine learning tasks. Generally, this framework has been applied to da ta represented as fixe d-length attribute-value vectors, or to sequence data. I will describe the language of probabilistic relati onal models (PRMs), which extend probabilistic graphical models wi th the expressive power of object-relational languages. PRMs model the uncertainty over the at tributes of objects in the domain as well as uncertainty over the existence of relations between objects. I will pr esent techniques for automatically learning PRMs directly from a relational data set, and applicati ons of these techniques to various tasks, such as: collective classification of an entire set of related entities; clustering a set of linked entities into coherent groups; and even predic ting the existence of links between entiti es. The talk will demonstrate the applicability of the techniques on several domains, such as web data and biological data. We discuss some recent trends and events, e.g., the dot com meltdown, and some ways for the field to respond to the challenges, and the opportunities.
