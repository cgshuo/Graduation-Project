 We propose a novel system TEXplorer that integrates keyword-based object ranking with the aggregation and exploration power of OLAP in a text database with rich structured attributes available, e.g., a product review database.

TEXplorer can be implemented within a multi-dimensional text database, where each row is associated with structural dimensions (attributes) and text data ( e.g., a document). The system utilizes the text cube data model, where a cell aggregates a set of documents with matching values in a subset of dimensions. Cells in a text cube capture different levels of summarization of the documents, and can represent objects at different conceptual levels.
Users query the system by submitting a set of keywords. Instead of returning a ranked list of all the cells, we propose a keyword-based interactive exploration framework that could offer flexible OLAP navigational guides and help users identify the levels and objects they are interested in. A novel significance measure of di-mensions is proposed based on the distribution of IR relevance of cells. During each interaction stage, dimensions are ranked accord-ing to their significance scores to guide drilling down; and cells in the same cuboids are ranked according to their relevance to guide exploration. We propose efficient algorithms and materialization strategies for ranking top-k dimensions and cells. Finally, exten-sive experiments on real datasets demonstrate the efficiency and effectiveness of our approach.
 H.3.3 [ Information Systems ]: Information Storage and Retrieval Algorithms
Nowadays the web is deeply integrated with database technolo-gies, and one important trend is that much more free texts generated on the web are associated with structured attributes which are ei-ther automatically extracted or recognized by human experts. For example, many shopping websites display technical attributes of their products, e.g., Brand, Model, Price, along with customer re-views about the products, so users can conveniently specify those structured attributes to refine their results. Structured data coexist with texts also in many other domains, such as medical reports, sys-tem bug reports, etc . Therefore, developing novel systems that can efficiently manage such multidimensional textual data and provide effective methods for users to explore and understand the data has become a demanding need.

Intuitively, users should be able to query multi-dimensional text databases by specifying values that match the dimensions and key-words that match the texts. Keyword search has been developed in RDBMSs [4], and traditional key word search systems are effec-tive if users only care about the top relevant tuples, but when the relevant results are many, it could be difficult for users to digest the results and come up with more accurate queries to refine the re-sults. However, if rich structured dimensions are available, they can be naturally utilized to organize the results and give users possible refinement. One example is faceted search systems [15, 17, 6, 11, 12, 10, 2], which show structured facets that are associated with rel-evant documents in their interfaces, and facets can be interactively selected by users to further refine the search results. Moreover, to further guide user exploration, some systems [17, 6, 11] rank facets based on their proposed measures to promote those dimensions and attributes that are more effective in helping users navigate to their desired results. For example, DynaCet [17] focuses on minimizing the number of facets users need to select to reach the most relevant documents.

Faceted search offers users much more flexibility to explore the results by specifying various facet refinement, however, we should notice in faceted search attributes are mainly treated as filtering conditions and the results displayed to users are still individual rel-evant tuples, which means the relevance computation, if there is any, still stays at the tuple level. However, individual tuples may not be exactly what users are looking for in many scenarios, in-stead, users may be more interested in finding the relevance ob-jects, which can be represented by certain aggregation of the tuples. For example, when a user searches for  X  X ight-weighted laptop X  on Amazon, usually she is not looking for specific review documents that mention the keywords, but some laptop brands or models that reviewers generally think are light-weighted. In this case, faceted search that returns the relevant documents may not be very helpful, instead, we need a framework that supports object-level relevance and navigation.

Past works on entity and object search [5, 1, 3] have justified the effectiveness of aggregating relevant tuples into high-level objects. And recently, [7, 22] target on supporting more flexible aggrega-tion in multidimensional databases, i.e., any combination of the structured attributes correspond to an object at a certain level. In data cubes built on top of the databases, [22] searches for the mini-mum cells covering the query, while TopCells [7] ranks all the cells based on IR relevance functions. However, all these systems out-put results in a ranked list, which as we have argued is not ideal for user digestion and exploration, and the fact that ranked objects are in different levels could give more difficulties to users. Therefore, an exploration mechanism suitable for higher-level objects needs to be developed.

With such motivation, in this work we propose TEXplorer, a keyword-based interactive OLAP framework that incorporates key-word search with the aggregation and exploration functionalities that are essential in OLAP systems (Figure 1 compares TEXplorer with existing keyword search systems). In TEXplorer, we adopt the strengths of object search and faceted search by utilizing structured attributes in two aspects: first, as in object/entity search they rep-resent high-level objects which individual tuples can be aggregated into; and second as in faceted search they are ranked and displayed to users to facilitate informative navigation of the results.
Moreover, to enable smooth exploration experience, TEXplorer employs a text cube data model as presented in [7], so that objects, i.e., cells in the cube, at different levels can be efficiently aggre-gated. When a keyword query comes, the relevance of each objec-t/cell is aggregated from the relevance scores of tuples belonging to the cell, so that objects in same dimension subspaces can be or-dered by relevance, and we further propose a significance measure for ranking different dimension subspaces, which indicates to users which subspaces are more likely to contain desired objects. To in-teractively explore the results, users can drill down to a dimension with high significance to look at the objects in the corresponding subspace, then they can select an object with high relevance and advance to the next interaction stage, where sub-objects are com-puted only from tuples belonging to the selected object. Example 1.1 explains the user interaction with concrete details.

E XAMPLE 1.1. (Motivating Example) Given a customer review database of laptops, each review document is associated with sev-eral structural attributes of the laptop being reviewed, e.g., Brand, CPU, Screen, OS, Video Card and Weight, etc .
 Figure 2 shows a running example of TEXplorer. A customer Kate wants to buy a powerful laptop suitable for gaming. Using our system, she could submit a keyword query  X  X owerful, gaming X .
Suppose at the beginning, the system returns Kate a list of di-mensions ordered by significance: Screen, Brand, Video Card, etc . The Screen dimension will be on the top if we infer from review data it is the most important factor for choosing gaming laptops. Within the Screen subspace different screen objects are ranked ac-cording to relevance, e.g. 15" LED will be the most relevant one if reviews about laptops with this screen have the highest aggregated relevance score.

Kate can drill down the Screen dimension and select 15 X  LED, then in the second stage, the rest dimensions and objects in each di-mension are re-ranked only based on reviews for laptops that have the selected screen type. Then this time she could drill down to the top 2  X  X ideo Card X  dimension if she feels video cards are more im-portant to her, after which she will be prompted to the third stage to make more refinements. At each stage, Kate can modify her key-word query and the system will re-rank the current records based on the updated query; Kate can also choose to roll back to any previous stages and explore other subspaces.

To summarize, we identify the contributions of this paper are:  X  We propose a keyword-based interactive exploration framework ,  X  We introduce a novel measure, significance , to effectively rank  X  We identify the major computational challenges in our system Organization We will introduce the data model, text cube ,and identify the major tasks of TEXplorer in Section 2. Section 3 intro-duces our significance measure. Section 4 proposes pre-omputation strategies and efficient algorithms for ranking dimensions and cells. Section 5 reports experimental study. Section 6 discusses related work, and finally Section 7 concludes this paper. In this section, we first introduce the text cube data model, in Section 2.1, then define the problems we need to address in Sec-tion 2.2.
In an n -dimensional text database DB , each tuple t can be repre-sented by a document d and an object with n structural dimensions A , A 2 , ... ,and A n , i.e., t =( a 1 ,a 2 ,...,a n , d ) . Each dimension corresponds to one attribute of the object, e.g., Brand, Model, etc . We l et t A i = a i ,and t D = d denote the value of dimension and document of the tuple respectively.

A text cube can be built on top of the multidimensional text database in order to support OLAP operations on the text data. The model was first introduced in [16]. Our system utilizes text cube so we briefly introduce several important concepts as follows.
A cell in the text cube is denoted as C =( v 1 ,v 2 ,...,v where v i  X  X  i  X  { X  X  . v i =  X  means the dimension A i is aggre-gated in C ( v i can take any value in A i ). D is the set of documents in the tuples of DB whose dimension values match C . We call this set D the aggregated document of the cell C .Let C A i denote v and C D denote D . A cell is called empty if C D =  X  .
 A cuboid is a group of cells having the same non- X  dimensions. A cuboid with m non- X  dimensions is called an m -dim cuboid .Cell C is a child of cell C iff  X  i ,s.t. C A i =  X  ,and C A i  X  j = i : C A j = C A j . Specifically, if A is the only one dimension that is aggregated in C but has non- X  value in C , we call C the A -child of C .Let chd ( C ) denote the set of (non-empty) children of C ,and chd A ( C ) denote the set of (non-empty) A -children of C .
After introducing our data model, in this section we will formally define the major tasks of TEXplorer. As explained in Example 1.1 and Figure 2, at any interactive stage, if users would like to further drill down to a more detailed level, they need to decide: (i) which dimension to drill down; and (ii) which cell in the drilled down cuboid to further explore. Hence, two major tasks of TEXplorer are (i) ranking candidate dimensions by the significance measure; and (ii) for each dimension, ranking children cells in the corresponding subspace by relevance. We give formal definitions of these two problems as follows:
Given a cell C (being explored by the user), for any aggregated dimension A i of C ,wedefinethe significance of A i w.r.t. the keyword query q , denoted by Sig A i ( q ,C ) . Our goal is to rank all the aggregated dimensions of C according to Sig A i ( q ,C ) ,or provide the top-k ones.

E XAMPLE 2.1. Consider the example in Figure 2. When the cell (Screen = 15.0 X  LED) is being explored and query is  X  X am-ing, powerful X , the drilling down dimensi ons are ranked as Brand, Video Card, CPU, .... This implies, for laptops with 15.0 X  LED screens, Brand, Video Card and CPU are the most important fac-tors that are related to gaming experience. The user can choose a dimension to drill down based on the system outputs as well as her own intention and preference.

Providing a ranked list of top-k significant dimensions is impor-tant, especially when the number of dimensions is large, to help users explore the data more effectively. Otherwise, users who do not have much knowledge about the domain, e.g., laptops, could waste a lot more time looking into all possible subspaces. Even for domain experts, such data-oriented ranking can also benefit the analysis of the correlation between structured attributes and key-words in the texts. For example, in a TEXplorer built on aviation report databases, aviation safety analysts can query specific prob-lems mentioned in pilot reports by several keywords and find what dimensions, e.g., location, weather, time, etc , are the most impor-tant factors that are potentially related to the problem.
Note that although the roles are similar, the significance measure in TEXplorer is designed with quite different intuitions from facet ranking measures in faceted search systems. Since we focus on the ranking and exploration of relevant objects rather than individual tuples given a keyword query, our significance measure is more ap-propriate for this goal by exploiting the distributions of relevance scores of objects and tuples. We will formally define the signifi-cance measure in Section 3.
Given a cell C (being explored by the user) and an aggregated dimension A i of C , we want to rank all the A i -children of C ac-cording to the relevance Rel( q ,C ) efficiently, or provide the top-k relevant ones.

E XAMPLE 2.2. Consider the second stage in Figure 2, when the user decides to drill down from the cell C : (Screen = 15.0 X  LED), for C  X  X  Brand-children, we need to rank them according to their relevance to the keyword query, in the order of, e.g., (Screen = 15.0 X  LED, Brand = HP), (Screen = 15.0 X  LED, Brand = Dell), and so on. Similarly, we also rank C  X  X  Video Card-children, CPU-children, and so on. Note we only rank cells within the same cuboid.
Different from [22, 7], where all the cells in the whole cube are ranked together, we focus on ranking cells (objects) in the same cuboid (subspace), which not only makes the ranking more mean-ingful in semantics, but also enables our system to adopt much more IR relevance models that could potentially increase accuracy.
Recall a cell C aggregates the documents in C D ,sotherele-vance of C w.r.t. a query q , i.e., Rel( q ,C ) , is actually the relevance of a set documents. Previous studies in IR [8] propose two general relevance models for this problem. The first one is called  X  X arge document model X : simply concatenating all the documents in the set into a pseudo document, and computing the relevance of such pseudo document. The second is  X  X mall document model X : com-puting the relevance of each individual document and aggregating the scores using an aggregate function, e.g., the average function: where | C D | is the number of documents in C D ,and rel( q , d ) is the relevance of a document d w.r.t. q .

The two relevance models have their own advantages. One limi-tation of previous methods [22, 7] is that they are restricted to spe-cific relevance functions. For example, TopCells [7] can only sup-port the  X  X mall document model X  due to its efficiency issue. But in TEXplorer, we can efficiently support both models. In the rest of the paper, we will use the average model (Equation 1) to denote the relevance of a cell only for the ease of explanation.
For the document relevance rel( q , d ) , TEXplorer is not restricted to a specific form of document relevance function either. We sup-port the class of document relevance in a more general form of: where IDF w is the inverted document frequency factor of term w q , TFW w, d is the term frequency factor of w in document d ,and QTW w, q is the query term frequency factor of w in q .

Most state-of-the-art relevance functions fit into the above form, such as Okapi BM25, pivoted normalization, and some language modeling approaches [21]. Moreover, user relevance models [12] can also be implemented in TEXplorer to take users X  interaction as feedback and make the ranking more personalized. For example, documents in a cell may be less relevant if a user rolls up after vis-iting the cell. We will not explain more details since the relevance function for ranking documents and objects is not the contribution of this paper, since we intend to design a general framework that can utilize any IR relevance measure.
In this section, we introduce a novel significance measure to help users determine which dimension to drill down when exploring a cell. For a cell C and an aggregated dimension A i , A i of C are obtained by drilling down A i from C . The significance of drilling down dimension A i w.r.t. a keyword query q is defined based on the following two intuitions. i) How distinctive are top relevance cells? The overall relevance ii) How consistent are documents within each cell? Now con-documents are consistent w.r.t. q , i.e., they are either all rele-this cell is of high confidence. For example, if we drill down dimension Color from a cell (Brand = Lenovo), and documents in every children cell are not very consistent w.r.t. the query { X  X attery X ,  X  X ong X ,  X  X ime X  X , then it probably means Color is not a very meaningful dimension to drill down. Figure 3 illustrates the significance scores for two dimensions. The height of the bars indicate the relevance of the documents and cells. In the first dimension, top cells are more distinguished from others and documents are more consistent within each cell, and therefore the first dimension will have higher significance score.
Now we can formally introduce the significance measure. To capture our first intuition, we define cell variance CV A how much the relevance of each of C  X  X  A i -children deviates from the relevance of C , weighted by the number of documents in each A -child, since intuitively larger cells should have higher weights: CV A i ( q ,C )=
To capture our second intuition, we define the document vari-ance DV A i ( q ,C ) as how much the relevance of each document in C deviates from the relevance of the A i -child of C which contains that document. And inverted document variance IDV A i ( q ,C ) is the reciprocal of DV A i ( q ,C ) , so higher IDV implies higher con-sistency of documents within each A i -child of C:
IDV A i ( q ,C )=
If the average relevance model (Equation 1) is used, treating each cell as a document group, CV is actually the variance of group means ,and DV is the mean of with-in group variances .Wedefine a more general form here so other relevance models can also be plugged in.
 We will consider a dimension more significant if the CV and IDV are both high. On the other hand, a dimension with higher CV is also more likely to have lower IDV , since the documents in this cuboid tend to be inconsistent. Therefore, similar to the well-known TF-IDF mechanism, we penalize high CV scores based on IDV scores by using the product of the two as our measure, i.e., we define the significance as: Statistical Meaning of Sig Actually our proposed significance mea-sure Sig A i has some intrinsic relationship to the F-ratio ,whichis oftenusedin ANOVA test [13] in statistics. All the documents in a cell C are partitioned into its A i -children for a drilling down dimension A i . If we associate each of the A i -children with a rele-vance distribution, we can regard the relevance scores of documents in each of the A i -children as samples drawn from this distribu-tion. If the average relevance model (1) is used, Sig A i (5) is actually the F-ratio , which measures how significantly these relevance distributions are different from each other. The higher F-ratio is, the more significantly these distributions are different. And in this paper we generalize its form so other relevance models can also be used to compute Sig A i .
In this section, we focus on designing efficient algorithms for the two computational tasks: ranking most significant dimensions and most relevant cells in each dimension. In the previous section, we can see that our significance measure depends on the relevance scores of children cells in each dimension, so the ranking of rele-vant cells can be naturally implemented within the framework of ranking dimensions. Therefore, in the discussion of our proposed algorithms we mainly focus on computing the top-k significant di-mensions. We identify two major computational challenges of this problem and proposed the corresponding solutions:  X 
Each document belongs to one children cell in each drill-down dimension. Therefore, in order to rank children cells in ev-ery dimension and compute the Sig score, every relevant doc-ument needs to be aggregated multiple times to different cells.
However, we find the cell relevance scores are pre-computable , therefore we can materialize some statistics offline in the Text
Cube, so that online query-dependent aggregation can be per-formed very efficiently.  X 
The Sig measure requires aggregated statistics from all the rele-vant documents. Hence, to compute the exact scores all relevant documents need to be scanned, which could be costly on large scale corpus. To solve this problem, we focus on finding top-k solutions, i.e., if only top-k significant dimensions are desired
The first algorithm is the baseline approach. Equation (3) and (4) show that, given the cell C (currently visited by users) and the keyword query q ,the Sig score of dimension A i depends on: i) rel-evance of C, and every A i -child of C; ii) relevance of every docu-ment in C, i.e., rel( q , d ) ; iii) some query independent factors: | C D | ,and | chd A i ( C ) | .

For the query independent factors, we can pre-compute and ma-terialize them in the Text Cube, so that we do not have to scan all the documents in C on-the-fly. However, we still need to scan every relevant document when the query comes. Moreover, each relevant document should be aggregated to all the cells C it belongs to for computing Rel( q ,C ) . After we scan all the relevant documents, exact significance scores can be computed and the dimensions with top-k highest scores will be output. Because multiple aggregation operations are performed for each relevant document, we call this algorithm MultiAccess .
 Algorithm 1 MultiAccess Algorithm Input: keyword query q , starting cell C , parameter k . 1: d = FetchNextRelevant( q , C ); 2: while d is not NULL do 3: Update C with d ; 4: for each aggregated dimension A i of C do 5: Update d  X  X  cell C  X  chd A i ( C ) with d ; 6: d = FetchNextRelevant( q , C ); 7: for each aggregated dimension A i of C do 8: Compute Sig A i ( q ,C ) ; 9: Output dimensions A i with the top-k highest Sig A i Analysis Suppose there are m different aggregated dimensions in C ,and n relevant documents, then the time complexity of the Mul-tiAccess algorithm is O ( m  X  n ) .When n is very large, this al-gorithm runs very slow. Also notice that if we do not pre-compute the query-independent factors like the number of documents in C, then those factors can only be computed by scanning all docu-ments in the cell, meaning the time complexity for every query is O ( m  X | C D | ) , which is not acceptable.
One major overhead of the MultiAccess algorithm is that mul-tiple aggregation operations are performed for each relevant doc-ument. To alleviate this problem, we naturally exploit the pre-computability of the scores by materializing some statistics about the terms offline in the Text Cube, so that when online queries come, the scores can be computed based on materialized results very efficiently.

From Equation (5) we can see the only factor that causes multiple aggregation of documents is the relevance of children cells of C, i.e., Rel( q ,C ) . Since users could query on any cell in the Cube, we now discuss how to precompute relevance signals for any cell in the Text Cube.
 Precomputation of Relevance To compute the relevance of a cell C w.r.t. a keyword query q , without any precomputation, we need to scan each document in C D at least once. In the following, we show that, for the general form of cell relevance defined in Sec-tion 2.2.2, we need only O (1) space per term in each cell for pre-computation, so that the relevance of the cell C , Rel( q ,C ) , can be computed in O ( | q | ) time.

For the  X  X mall document X  cell relevance model defined in (1), we can rewrite it as follows: Rel( q ,C )= 1 | Let TFW w,C = pute IDF w , and in each cell C , we precompute TFW w,C , then from the above equation, Rel( q ,C ) can be computed in O ( | q
For the  X  X arge document model X , the precomputation is straight-forward: we concatenate the documents in each cell offline and store the pseudo document in the cell. Computing Rel( q ,C ) is then equivalent to computing the relevance of the pseudo docu-ment, which takes O ( | q | ) time.

The precomputaion needs O(1) space per term for each cell, so the total space cost of the text cube is O ( | V | X | |
V | is the size of the vocabulary, and | Cube | is the number of non-empty cells in the Cube, bounded by 2 m  X  #(Base Cells), m is the number of dimensions. For a text database that does not have very high number of dimensions, e.g., 10 dimensions, but have a large number of documents, the number of non-empty cells is compa-rable to the number of documents, so the extra space needed is comparable to the size of inverted index built on the document col-lection, which is quite affordable.

Moreover, there have been extensive studies on reducing the space cost and supporting efficient query processing in a partial materi-alized cube [16, 20], where only some cells of the cube are precom-puted and the rest ones can be efficiently computed online based on them. Those techniques can be easily implemented in our system to further save the storage, since the measures stored in the text cube satisfy the distributive property [16]. In the remainder of the pa-per, however, we assume our cube is fully materialized since how to reduce the space is not the main focus of this work.
 Online Computation We have showed with precomputation the relevance of cells can be computed very efficiently on-the-fly. And based on those scores we can compute the cell variance CV ( q ,C ) (3) directly. Next, we further decompose the IDV ( q ,C ) and rewrite Equation (5): Sig A i ( q ,C )= CV A i where S C =
S C is the sum of the relevance scores of documents in cell C ,so it can also benefit from the precomputation. In fact, S C to |
C D | X  Rel( q ,C ) if the average relevance model (1) is used. Then the only factor left unknown in Sig is SS C , the sum of squares of each document X  X  relevance score. And this factor can not be easily pre-computed unless bigrams are considered, which would cause too much storage overhead. Therefore, in the online query processing we still need to scan all relevant documents, but this time we only need O (1) operation for each document to compute SS C . We call this algorithm OneAccess .
 Algorithm 2 OneAccess Algorithm Input: keyword query q , starting cell C , parameter k . 1: Compute Rel( q ,C ) ; 2: for each aggregated dimension A i of C do 3: for each C  X  chd A i ( C ) do 4: Compute Rel( q ,C ) ; 5: d = FetchNextRelevant( q , C ); 6: while d is not NULL do 7: SS C = SS C +rel( q , d ) 2 ; 8: d = FetchNextRelevant( q , C ); 9: for each aggregated dimension A i of C do 10: Compute Sig A i ( q ,C ) using SS C , etc ; 11: Output dimensions A i with the top-k highest Sig A i Analysis Since for each relevant document OneAccess only needs O (1) operation, the time complexity is O ( n + m ) ,ifthereare n relevant documents and m dimensions. When m or n is large, OneAccess will be significantly faster than MultiAccess .An-other benefit of OneAccess is that the relevance of cells can be computed without scanning any document, so the ranking of top cells in each dimension can be performed very efficiently.
OneAccess needs to scan all relevant documents once in order to compute the exact significance scores. However in the case only top-k dimensions are desired by users, we do not have to compute the exact scores if the top-k is guaranteed.

Specifically, in OneAccess+ we progressively fetch documents in the descending order of their relevance scores, which can be eas-ily supported by the underlying full text search component. Then we can estimate the upper and lower bounds of the scores, and rank all dimensions in two lists: L UB and L LB , based on their upper bounds and lower bounds respectfully. We update the bounds and the ranked lists every time we fetch new documents. When the top-k dimensions with highest values in L UB and L LB are the same, and the k -th lower bound is greater than or equal to the ( k +1) -th upper bound, it means no dimension in L UB that ranks lower than k could eventually win any top-k dimension in L LB , i.e., the top-k is guaranteed and the algorithm can stop.
 Upper and Lower Bounds of Sig As we have discussed in the OneAccess algorithm, all factors in (6) can be computed effi-ciently from offline materialized scores without scanning any rele-vant documents, except the sum of squares of document relevance scores SS C = calculated as constants, it is easy to see the Sig score monotonically decreases with SS C . Also we know the documents can be fetched in a non-increasing order of their relevance. Based on these facts, we can derive the upper and lower bounds of Sig as follows.
Suppose at the current step we are accessing the i -th document, then an obvious lower bound SS C is given by the current SS scorewehaveaggregated: Then the Sig score computed by using lower bound SS C upper bound.

To derive the upper bound of SS C , we first need to know the number of relevant documents for the current query. While the ex-act number is not easy to get without scanning all the relevant doc-uments, the total number of documents in the current starting cell C
D is obviously too loose. The solution is we can offline compute and materialize the document frequency of w in C, i.e., number of documents in C that contain w , denoted as df w,C . Then for each w in the query q ,thesumof df w,C gives an upper bound of the number of relevant documents. And since we know the relevance of future documents is not greater than the current rel( q , d upper bound of SS C can be estimated by: SS And the lower bound of Sig can be computed using SS C .
 Algorithm 3 OneAccess+ Algorithm L
UB and L LB : ranked lists of dimensions (in the non-increasing order of upper bound and lower bound of Sig ( q ,C ) respectfully) Input: keyword query q , starting cell C , parameter k . 1: Compute Rel( q ,C ) ; 2: for each aggregated dimension A i of C do 3: for each C  X  chd A i ( C ) do 4: Compute Rel( q ,C ) ; 5: d = FetchNextRelevant( q , C ); 6: while d is not NULL do 7: Update SS C and SS C ; 8: for each aggregated dimension A i of C do 9: Update Sig A i ( q ,C ) using SS C ; 10: Update Sig A i ( q ,C ) using SS C ; 11: Update L UB and L LB ; 12: if L UB [1 ..k ]== L LB [1 ..k ] and L LB [ k ] .score 13: break ; 14: d = FetchNextRelevant( q , C ); 15: Output top-k dimensions L UB [1 ..k ] ; Analysis OneAccess+ exploits upper and lower bounds of the significance scores to enable early termination of the algorithm when top-k is guaranteed. When the bounds are tight, and k is small, it could lead to more efficient execution than MultiAccess and OneAccess . However, every time we get a new relevant doc-ument, the upper and lower bounds for each dimension should be updated, which takes O ( m ) , and the ranked lists may need to be adjusted, which takes expected O ( m log m ) time. Hence the time complexity of OneAccess + is O ( n  X  m log m ) for n relevant docu-ments and m dimensions, which is worse than OneAccess . Several heuristics could be applied to improve the running time, e.g., only updating the bounds after fetching a batch of t documents.
OneAccess+ deploys standard top-k stop conditions which work for general ranking functions [3]. However, our top-k problem is quite different from previous top-k aggregation problems [3, 1, 14]. In previous problems, each object is aggregated from a set of tuples in the database, and to get the top-k objects, the algorithms give higher priorities to the promising objects so that their exact scores can be computed first. However, in our problem, the Sig scores for different dimensions depend on all relevant documents in the cell. Computation of the exact scores requires scanning all the relevant documents, which is what we want to prevent.

More specifically, for the Sig score in Equation (6), if all pre-computable factors are already calculated, they can be treated as constant. Therefore, the significance scores for different dimen-sions can be simplified as a series of functions with different pa-rameters but the same variable, which is the unknown factor SS (it is unknown before all relevant documents are scanned):
Then we can exploit a good property of this family of functions to achieve stronger pruning power.
 P ROPERTY 1. f 1 , f 2 , ..., f n are a series of functions of x . For any two functions f s and f t ( 1  X  s&lt;t  X  n ), there exists no x &lt;x k &lt;x j ,s.t. f s ( x i ) &lt;f t ( x i ) , and f f ( x k ) &gt;f t ( x k ) .

Property 1 says if the values of any two functions at x i in the same order, then such order remains for the values of the two functions at any point between x i and x j . It is equivalent to say that any two functions do not cross more than once between any x and x j .

According to Equation (9), Sig A i ( SS C ) represents a family of functions of SS C . And it is easy to verify that any two functions in this family with different parameters can only have at most one intersection, i.e., Sig A i ( SS C ) satisfies Property 1.
Now we give the lemma which is the key of this OneAccess++ algorithm.

L EMMA 1. Given a series of functions of x : f 1 , f 2 , ..., f that satisfy Property 1. If x is bounded between lower ( x ) and upper ( x ) , and f functions with top-k highest values at lower ( x ) are the same as f functions with top-k highest values at upper ( x ) ; then the top-k remain the same at any point x between lower ( x ) and upper ( x ) .

P ROOF . Let us assume the lemma is not true, i.e., there exists a function f ,s.t. f is not in top-k either at lower ( x ) nor at upper ( x ) , but in top-k at some point x which is between lower ( x ) and upper ( x ) . Then there must exist a function f which is in top-k at both lower ( x ) and upper ( x ) ,but f ( x ) &lt;f ( x ) .On the other hand, since the values of f are greater than f at both lower ( x ) and upper ( x ) , and Property 1 is satisfied for all func-tions in the series, we can derive that f ( x ) &gt;f ( x ) . Contradic-tion.
 Since Sig A i ( SS C ) is a series of functions of SS Property 1, and SS C is bounded by its lower bound SS C and up-per bound SS C . Therefore the real top-k Sig A i ( SS C achieved when SS C reaches the exact value, which is some point between SS C and SS C . Lemma 1 tells us, if the top-k dimensions A i with highest Sig A i ( SS C ) and Sig A i ( SS C ) are the same, then they are the real top-k dimensions.

Therefore, our OneAccess++ algorithm is generally the same as OneAccess+ . The only difference is the stop-condition for top-k . OneAccess++ stops as soon as the top-k dimensions in the lower bound and upper bound lists ar e the same. The condition that the k -th lower bound is greater than or equal to the k +1 -th upper bound is no longer required. Since t he stop conditio n is relaxed, OneAccess++ is guaranteed to be more efficient than OneAc-cess+ . Also note that OneAccess++ will generate the exactly same top-k results as OneAccess+ .
 Algorithm 4 OneAccess++ Algorithm L
UB and L LB : ranked lists of dimensions (in the non-increasing order of upper bound and lower bound of Sig ( q ,C ) respectfully) Input: keyword query q , starting cell C , parameter k . 1: Compute Rel( q ,C ) ; 2: for each aggregated dimension A i of C do 3: for each C  X  chd A i ( C ) do 4: Compute Rel( q ,C ) ; 5: d = FetchNextRelevant( q , C ); 6: while d is not NULL do 7: Update SS C and SS C ; 8: for each aggregated dimension A i of C do 9: Update Sig A i ( q ,C ) using SS C ; 10: Update Sig A i ( q ,C ) using SS C ; 11: Update L UB and L LB ; 12: if L UB [1 ..k ]== L LB [1 ..k ] then 13: break ; 14: d = FetchNextRelevant( q , C ); 15: Output top-k dimensions L UB [1 ..k ] ; Analysis Since OneAccess++ is generally the same as OneAc-cess+ except the stop condition is different, the time complexity of the two algorithms are identical. But in practice, OneAccess++ is guaranteed to be faster.
In this section, our goal is to (i) verify the effectiveness of our ranking mechanisms and (ii) analyse the performance of our pro-posed algorithms, and storage of the text cube.
 Dataset We crawled customer reviews for laptops from Google Products 1 . The dataset has 26,418 reviews, 920 laptops, and 11 dimensions: Audio Card, Battery Run Time, Brand, Screen Type, Color, Weight, Operating System, CPU, Hard Drive, Main Memory and Video Card.
 Environment Setup All experiments were done on a machine run-ning Windows 7 Professional, with a Inter Core Duo T9300 pro-cessor, 4GB main memory, and 80G hard disk. The algorithms were implemented in C++ and compiled with Microsoft Visual C++ 2008.
In this section we focus on studying the effectiveness of our pro-posed significance measure for ranking dimensions. For the rel-evance functions of documents and cells, there have been exten-sive studies in the field of information retrieval, and TEXplorer can http://products.google.com flexibly adopt most state-of-the-art relevance models. Therefore we will not focus on evaluating different relevance functions. In the following experiments, we use Okapi BM25 [21] for document relevance and the average model (Equation 1) for cell relevance, which work quite well on our dataset.
 Measures in Faceted Search We compare our significance mea-sure with the dimension ranking functions in two recent faceted search systems [17, 6] defined as follows: i) [17] targets on building decision trees with minimum height on the tuples, so that users X  efforts to reach each individual tuple can be minimized. The Indg score of dimension A i measures the number of indistinguishable pairs of tuples if choosing the root, and the algorithm greedily selects the dimension with minimum Indg to build the tree.
 Indg A i ( q ,C )= ii) [6] estimates the probability of the query results using a hyper-geometric distribution :let | C D | be the number of documents in
C D ,and | C D ( q ) | be the numbers of relevant documents w.r.t. q in C D .Foran A i -child of C ,say C , if we randomly sam-ple | C D ( q ) | documents from C D ,the p -value of getting at least |
C D ( q ) | documents from C D in the sample can be written as:
A smaller p -value indicates it is less likely to get the results by chance, and therefore the cell C is more interesting .Andthe overall interestingness of a dimension A i is the aggregation of p -values of the top-k interesting A i -children of C :
We can see the two measures defined above more focus on the tuple level results. Indg targets on distinguishing individual tuples, which may not be very effective for users to understand the data if they are more satisfied with higher level aggregated results. The p -value and Intr utilize the distribution of result tuples, but the rele-vance scores of tuples and cells are not considered at all. Therefore, these two measures may not be well suited for our tasks in TEX-plorer.
 Case Studies We issue a keyword query  X  X tylish beauty cool fash-ion X  on all documents in our dataset. The top-1 dimension ranked by Sig is Brand, and the corresponding top relevant cell is (Brand = Apple), which is quite reasonable since Apple laptops are well-known for the stylish design. However, the Brand dimension only ranks the 9th and the 10th according to Indg and Intr respectively, while the top-1 dimensions according to those two measures are Weight and CPU, which are quite difficult to interpret.
 Figure 4 plots the documents and cells for each top-1 dimension. Height of red and blue bars indicates the relevance of documents and cells, and the green bar represents the average relevance of all the documents, which remains the same. Width of the blue bars rep-resents the number of documents in the cells. In Figure 4(a), we can see the top (Brand=Apple) cell dominates other cells and the docu-ments are rather consistent compared to the other two dimensions, and therefore its Sig score is very high. Figure 4(b) shows Indg tends to give higher scores to dimensions that have more cells but each cell has less documents, so that the number of filtered tuples is maximized after users select one cell. However, the results lack semantic interpretation if users prefer higher level objects rather than individual tuples. Intr does not utilize the relevance scores at all. Although in our experiments cell (Brand=Apple) has quite high p -value compared to other Brand-children, more CPU-children get higher p -values and thus the CPU dimension ranks top-1, which is not very meaningful either.
 slow response Processor OS Video (Celeron M353)
We can show the effectiveness of our method using several more queries. The top-1 dimensions given by the three measures Sig , Indg and Intr are put in Table 1. For our proposed Sig measure we also show the top relevant cell in the corresponding subspace. Results of Sig are generally more meaningful than the other two measures. Take the first query for instance, Screen Type is very im-portant to gaming, and the top relevant cell is a fairly large screen, meaning users who bought this screen mentioned gaming experi-ence more frequently in their reviews. However, Indg and Intr still rank Weight and Processor as the top-1 dimensions, same as the results of a quite different query in Figure 4, which is probably be-cause these two measures do not utilize much the distribution of the relevance scores.
 Quantitative Evaluation To quantitatively justify the effectiveness of our method, we adapt the most popular IR evaluation mecha-nism: labelling dimensions as relevant or non-relevant for a given query and compute several measures such as precision and MAP against the results. We want to compare with other state-of-the-art systems and see whether our system can provide immediate help-ful guides, so in this experiments, we evaluate the first stage of the exploration (immediately after keyword query issued). To get the ground truth, we choose 20 common queries and ask 3 users to label which dimensions are meaningful w.r.t. the queries. Then we take the intersection of their labelled sets as the ground truth, which is quite conservative but can ensure us labelled dimensions are really relevant. Actually, we found the 3 users agree on more than 90 per-cent of the dimensions, which means the meaningful dimensions are quite obvious given a certain keyword query. For example, for the query  X  X tylish X , Brand is obviously a relevant dimension.
Then we compute two most important measures in IR evalua-tion: mean average precision (MAP) and the precision at top 3 against the dimensions output by Sig , Indg ,and Intr measures. Ta-ble 2 shows the averaged results over 20 queries: unsurprisingly Sig achieves the best MAP and precision among the three mea-sures by a significant margin; the MAP of Intr and Indg are close while the precision of Intr is higher than Indg . Now we analyse the performance of the proposed algorithms. In the experiments we issue 10 queries of length 3 and compare the average running time and visited documents of each algorithm. Note that for fair comparison we do not count the time of loading index and fetching relevant documents, since all algorithms assume it is efficiently supported by underlying full text search modules. We also loop the algorithms for multiple times and take the average in order to measure the running time more accurately.
 Efficiency vs. Number of Documents To verify the scalability of the algorithms, we take 4 samples of 4901, 9802, 14703, 19604 documents from our dataset and run the algorithms on the 4 sam-ples and the whole dataset with 26418 documents. All 11 dimen-sions are considered, and the k is set to 3 for top-k algorithms. If we look at the number of visited documents in Figure 5(b). MultiAccess and OneAccess always visit all the relevant doc-uments as expected, which grow linearly with the number of all documents in the database. OneAccess+ visits less documents by utilizing t he upper and lower bounds of Sig to compute the top-k dimensions, and the documents OneAccess+ accesses grow slower than the total number of relevant documents, which means the pruning power of OneAccess+ becomes stronger as the size of the database increases. OneAccess++ visits significantly less documents than all the other three algorithms, and the number is al-most stable. This verifies the unique property of our top-k problem does deliver stronger pruning power. Also note that top-k algo-rithms OneAccess+ and OneAccess++ also has a good property that they may actually visit less documents when the total number of document increases, because when there are more relevant doc-uments it is possible that the gap between top-k results and the rest becomes larger, so the algorithms can confidently stop earlier.
For the running time shown in Figure 5(a), MultiAccess is slower than OneAccess even they visit the same number of documents, since multiple aggregation is performed for each document in Mul-tiAccess . Also notice that OneAccess+ is also slower than OneAc-cess on the smallest samples because of the overhead for updat-ing the bounds and maintaining the top-k lists. When the size of the database is large, the pruning power begins to dominate and therefore OneAccess+ becomes slightly faster than OneAccess . OneAccess++ is consistently the fastest as expected, and it gener-ally runs more than 10 times faster than OneAccess and OneAc-cess+ except for the first two smaller samples. This again verifies the good performance of OneAccess++ .
 Efficiency vs. Top-k In this experiment, we vary the length of the top list, i.e., k , and evaluate the efficiency for each algorithm. All the documents in the dataset and all 11 dimensions are considered. We evaluate 10 queries of length 3 and report the average running time and number of visited documents in Figure 6.
First Figure 6(b) shows MultiAccess and OneAccess always visit all the relevant documents, which do not change for different k . The number of documents OneAccess+ accesses fluctuates, since it may be difficult to predict the stop condition of OneAc-cess+ ,but OneAccess+ still visits less documents than MultiAc-cess and OneAccess . Among all the algorithms, OneAccess++ accesses the least documents, and the performance is quite stable for different k compared to OneAccess+ . The running time in Figure 6(a) shows the same trend as Figure 6(b), and the running time of OneAccess++ is consistently the fastest among all the al-gorithms.
We now examine the space overhead of the text cube in our sys-tem. We use all the 11 dimensions and vary the number of docu-ments to build the cube, and compare its size with inverted index built on the document collection (Figure 7). Although the size of text cube is several times larger, it increases much slower w.r.t. the number of tuples, which means the summarization power of text cube becomes stronger when the size of original databases gets larger. Given in our experiments we are only able to get a small portion of the real world customer review data, we could image the size of text cube would be comparable with inverted index on much larger datasets, in which sense our solution is quite scalable.
Also notice there have been extensive studies on saving the space of a data cube using partial materialization [16, 20]. Since it is not the main focus in this paper, we construct the full cube in the experiments. However, those techniques can be easily applied to reduce the space substantially. Faceted Search Faceted search systems [17, 6, 11, 12, 10, 2, 15] al-low users to flexibly select structured attributes to refine the search results. Facets are ranked based on number of associated docu-ments [10], estimated user effort [17, 11], or p-value of the results [6]. Some systems dynamically generate facets from data [2, 15] or build personalized relevance models [12]. As we have mentioned, TEXplorer is different from previous faceted search systems be-cause it focuses on keyword-based ranking and exploration of ag-gregated objects rather than individual documents. None of the previous facet ranking measures consider the distribution of IR rel-evance scores as we do and our experiments show the proposed Sig measure is more effective for our task.
 Discovery-driven OLAP Systems In traditional data cubes, dis-covery driven OLAP mechanisms [18] can find surprising or unex-pected cells in the cube. [19] further supports matching candidate subspaces by keywords and then dynamically suggests facets by measuring surprising or correlated aggregates of categorical or nu-merical attributes. TEXplorer is different in the sense that we care about the relevance of cells and correlated dimensions, rather than the distribution of categorical or numerical values in the database. And we target on the most common search behaviors: we suppose users who issue the keyword queries are always interested in the most relevant objects rather than surprising ones, because objects with rather low relevance could still get high surprise scores. Object Ranking in Database Ranking of aggregated documents for keyword queries have been developed in relational databases [1, 3] and data cubes [22, 7]. TEXplorer ranks objects in the same subspaces so that the comparison is more meaningful, and the in-teractive exploration framework organizes different subspaces and rankings in an effective way.

Our algorithms of ranking top-k dimensions are related to top-k query processing in database [9, 14, 3]. [14] supports ad-hoc rank-ing aggregation for the group-by operations in SQL. The mecha-nism of progressively aggregating scores to each group is proposed so that the top-k groups can be computed efficiently. [3] also pro-poses aggregation-based top-k generation and pruning strategies. We identify the unique property of our top-k problem and our algo-rithms achieve stronger pruning power.
In this work, we propose a novel system TEXplorer that allows users to perform keyword search and OLAP-style aggregation and exploration of the objects in a text cube built on a multidimensional text database. A novel significance measure is proposed to rank di-mensions. Top relevant objects/cells in each dimension subspace are also ranked for users to select. We develop top-k algorithms and materialization strategies to accelerate the ranking. Extensive experimental studies verify th e scalability of our methods and the effectiveness of our proposed significance measure. TEXplorer can be potentially implemented on top of many text databases like Amazon to improve user experience. The work was supported in part by HP Lab Innovation Award, NASA NRA-NNH10ZDA001N, and the U.S. Army Research Lab-oratory under Cooperative Agreement No. W911NF-09-2-0053 (NS-CTA).
