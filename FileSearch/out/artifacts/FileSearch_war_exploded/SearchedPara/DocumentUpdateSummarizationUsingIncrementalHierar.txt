 Document summarization has become a hot topic in recent years. However, most of existing summarization methods work on a batch of documents and do not consider that documents may arrive in a sequence and the correspond-ing summaries need to be updated in real time. In this paper, we propose a new summarization method based on an incremental hierarchical clustering framework to update summaries as soon as a new document arrives. Extensive experimental results demonstrate the effectiveness and effi-ciency of our proposed method.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Clustering ; I.2.7 [ Artificial Intelli-gence ]: Natural Language Processing X  Text clustering Algorithms, Experimentation, Performance Update Summarization, Incremental Hierarchical Clustering
The number of documents on the Internet is continuously increasing with the mass of online sources available, e.g., News and blogs. To help readers to extract their inter-ested information from large numbers of texts efficiently, document summarization has been receiving much atten-tion recently. Most document summarization techniques performinabatchmode. Givenacollectionofdocuments, clustering-based summarization methods usually group the sentences contained in the documents into clusters using cer-tain similarity calculation, and the centroid sentences are selected to form the summary [18, 23, 15, 19]. And graph-based methods are also widely used for document summa-rization [6, 22]. This type of methods usually constructs a sentence graph, in which each node is a sentence in the document collection, and if the similarity between a pair of sentence is above a threshold or the sentences belong to the same document, there is an edge between the sentence pair. The sentences are selected to form the summaries by voting from their neighbors. However, as popular online publishers generate numerous documents daily, the summaries need to be updated periodically. Thus, updating summaries using current batch document summarization methods requires repeatedly processing previous existing documents, which is time consuming and would cause a waste of operations. In some real applications, e.g., disaster management, the time delay is unacceptable since the disaster evolves quickly and the newest reports need to be summarized in time. To address this issue, we study the problem of updating sum-maries as soon as new documents arrive.

A potential solution is to design incremental summariza-tion algorithms. One type of straightforward methods is to rank the sentences in the documents according to their scores calculated by a set of predefined features, such as term frequency-inverse sentence frequency (TF-ISF) [18, 14, 24] and number of keywords, which does not involve re-calculating the older sentences. However, these heuristic ranking methods based on simple features could hardly per-form well because they assume the sentences are completely independent and existing sentences are not influenced by newly coming sentences at all, which is not practical in many real world scenarios. In t his paper, we integrate docu-ment summarization techniques into an incremental hierar-chical clustering framework to re-organize sentence clusters immediately after new documents/sentences arrive so that the corresponding summaries can be updated efficiently. In the meanwhile, the hierarchical relationship among the sen-tences can also be displayed and re-constructed in real time.
The rest of the paper is organized as follows. Section 2 dis-cusses the related work of current methods in multi-document summarization and incremental clustering. In Section 3, we introduce our incremental hierarchical clustering based up-date summarization system. Extensive experimental results are shown in Section 4. Finally Section 5 concludes.
Traditional multi-document summarization aims to gen-erate a generic or query-focused summary which delivers the major or topic-relevant information of the original document collections. Currently, the most widely used summarization methods are clustering based [18, 14, 23] and graph-ranking based [6, 16, 22]. Clustering-based summarization meth-ods usually perform various clustering techniques on the term-sentence matrices formed from the documents. After the sentences are grouped into different clusters, a centroid score is assigned to each sentence based on the average co-sine similarity between the sentence and the rest of the sen-tences in the same cluster. Finally, the sentences with the highest scores in each cluster are selected to form the sum-mary. Graph-ranking based su mmarization methods have become more and more popular recently. This type of meth-ods usually constructs a sentence graph, in which each node is a sentence in the document collection, and if the similar-ity between a pair of sentence is above a threshold or the sentences belong to the same document, there is an edge between the sentence pair. The sentences are selected to form the summaries by voting from their neighbors. Erkan and Radev [6] propose an algorithm called LexPageRank to compute the sentence importance based on the concept of eigenvector centrality (prestige) which has been successfully used in Google PageRank. Other graph-based summariza-tion methods have been proposed in [16] and [22]. Other techniques, e.g., non-negative matrix factorization [17], con-ditional random file [21], hidden Markov model [3], and la-tent semantic analysis [9] have also been applied to docu-ment summarization.

However, with the rapid growth of documents over the In-ternet, there is a great necessity to update the existing sum-maries when new documents arrive. The traditional docu-ment summarization methods are not suitable for this task for the following reasons. (1) Most of the methods work in a batch way, thus all the documents need to be process again once new documents come, which causes inefficiency. (2) An alternative is that only newly coming documents are sum-marized and fused into the existing summary, however, this kind of solution would raise the redundancy issue, which is also hard to deal with.
TAC recently organizes a special summarization compe-tition called update summarization [1]. The task of TAC update summarization track is that we generate a summary of a multi-document data set based on the assumption that the user has already read a given set of documents. Here the definition of  X  X pdate summarization X  is a little bit dif-ferent from ours in this paper, since they only consider the newly coming document sets while we work on all the doc-uments at hand. And also in their tasks, they only update the documents once while we assume documents arrive in a sequence, which is more practical in real applications. Since our definition is more general, we can easily adapt our work into the TAC task, and we will show the performance of our adapted method in the experiments.
There exist many efforts on incr emental text clustering al-gorithms [2, 11, 10], whose main task is to efficiently detect new events or novelty when new documents arrive. In com-parison, in this paper, we aim to (1) build a sentence hier-archical tree to fully explore the relationship among events; (2) summarize the whole story of the development of events at current timestamp. Figure 1 demonstrates the framework of our approach. First of all, the sequence of documents is preprocessed. Then an incremental hierarchical clustering method is performed to obtain the sentence hierarchy, and a sentence selection scheme is conducted to obtain the most representative sen-tence at each tree node. Finally based on the requirement of summary length, the summary at current timestamp is created.
Given a collection of documents, we first decompose them into sentences. Then the stop-words are removed and words stemming is performed. After these steps, a sentence-term matrix is constructed and each element is the term fre-quency.
In our update summarization system, we use an incre-mental hierarchical clustering (IHC) method to build the sentence hierarchy of the document collections. The poten-tial benefits of the IHC method are: (1) As an incremental algorithm, the method can efficiently process the dynamic documents in the sense that new documents are continuously added to the data set. (2) A hierarchy is built to facilitate users to explore the structure and relationship between the sentences. (3) The number of clusters is not pre-defined so that users can cut the hierarchy tree at any level based on their needs.
The IHC method used in this paper is COBWEB proposed by Fisher [7, 8], which is one of the most popular incremental hierarchical clustering algorithms. The algorithm performs in a top-down fashion to create a concept tree where each node refers to a concept and contains a probabilistic descrip-tion of that concept.

The Cobweb algorithm operates based on a heuristic mea-sures called Category Utility (CU) as the criterion function to determine the partitions in the hierarchy. Give a partition {
C 1 ,C 2 , ..., C K } , CU is defined as: where A i = V ij is an attribute-value pair and C k is a clus-ter [7]. CU can be interpreted as the increase in the ex-pected number of corrected guesses of attribute values given the partition { C 1 ,C 2 , ..., C K } over the expected number of correct guesses without such knowledge.

When a new element comes, the COBWEB algorithm tra-verses the tree top-down starting from the root node. At each node, the COBWEB algorithm performs one of the four possible operations based on the criteria of maximizing the CU scores. (1) Insert: add the sentence into an existing cluster. (2) Create: create a new cluster. (3) Merge: com-bine two clusters into a single cluster. (4) Split: divide an existing cluster into several clusters.
Sahoo et. al. [20] claim that the original COBWEB algo-rithm using normal attribute distribution is not suitable for text data, and suggest to use Katz distribution [12] as the word occurrence distribution. Documents are usually repre-sented in the  X  X ag of words X  form where terms are attributes, and it has been shown that Katz X  X  distribution works better than other distributions on text data. Thus, [20] proposes a new CU calculation using Katz X  X  distribution as follows.
In Katz X  X  model, assuming word i occurs k times in a document, then and
From Equation 1, for each attribute i , we need to compute where the attribute value f = V i j takes 0, 1, ... as the word occurrence count. Substituting Equation 2 and 3 into Equation 4, then where p 0 and p can be estimated using MLE estimation.
In this paper, we follow the above Katz X  X  distribution based COBWEB algorithm in [20] to create the sentence hierarchical tree incrementally.
In our update summarization system, we try to select the most representative sentences to summarize each node and its subtrees during the process of the hierarchy generation. Note that the leaves in the hierarchy tree are represented by themselves since each leaf node is one sentence. Once a new sentence arrives, the sentence h ierarchy is changed by either of the four operations as described in Section 3.3.1, and in the meanwhile, the representative sentences for the affected nodes are dynamically updated in the following way. } .

When all the documents/sentences arrive, the hierarchy and the selected sentences can clearly display the structure of the texts, and also users can cut the hierarchy tree at their desired layers to obtain a summary at that height. For example, a user can determine the cutting level based on the length requirement of the summary.
The procedure of the hierarchy generation and summary update is listed as Algorithm 1. The CheckRelevance () function used in Algorithm 1 is described in Algorithm 2. Algorithm 1 Incremental Hierarchical Clustering based Update Summarization (IHCUS)
Input: a query/topic the user is interested in
Output: a sentence hierarchy 1: Read one sentence and check if it is relevant to the given 2: If relevant, initialize the hierarchy tree with the sen-3: repeat 4: Read in the next sentence, start from the root node; 5: If a leaf node is reached, create a new leaf node and 6: until the stopping condition is satisfied. 7: Cut the hierarchy tree at one layer to obtain a summary Algorithm 2 CheckRelevance() Input: Q: the query-term vector
Output: result = 1 indicates the sentence is relevant 2: If Sim ( S, Q ) &gt; 0, result=1; Otherwise 0.
In order to evaluate the quality of the generated sum-maries by different methods, we use human generated sum-maries as references. For Hu rricane data, we hire 10 hu-man labelers to manually create summaries based on the documents released until the end of each hurricane phase. There are totally 10 queries obtained from the most fre-quent questions asked in a hurricane disaster management system. Each query is given to 5 different annotators, and each annotator is asked to read all the reports released until the end of each hurricane phase and create three 100 words summaries for each query. For TAC08 data, since it is a benchmark data from Text Analysis Conference (TAC), the human summaries are already provided by the conference. There are four standard summaries written by four human labelers, and these human generated annotations are used for our experimental evaluation.
We implement the following widely used multi-document summarization methods as the baseline systems. Since some of the systems are designed for generic summarization, for fairness we filter the sentences which are not relevant to the given queries by calculating the cosine similarity between the sentences and the queries. And since these systems are designed to work in a batch mode, we run these baseline systems one more time as a new document arrives.
In the evaluation, we will compare the results by differ-ent methods with the human created summaries using the following evaluation measures.
 ROUGE toolkit To compare with the human summaries, we use ROUGE [13] toolkit (version 1.5.5), which is widely applied by Document Understanding Conference(DUC) for document summarization performance evaluation. It mea-sures the quality of a summary by counting the unit over-laps between the candidate summary and a set of refer-ence summaries. Several automatic evaluation methods are implemented in ROUGE, such as ROUGE-N, ROUGE-L, ROUGE-W and ROUGE-SU. ROUGE-N is an n-gram re-call computed as follows.
 where n is the length of the n -gram, and ref stands for the set of the reference summaries. Count match (gram n )isthemax-imum number of n -grams co-occurring in a candidate sum-mary and the reference summaries, and Count(gram n )isthe number of n -grams in the reference summaries. ROUGE-L uses the longest common subsequence (LCS) statistics, while ROUGE-W is based on weighted LCS and ROUGE-SU is based on skip-bigram plus unigram. Each of these evalua-tion methods in ROUGE can generate three scores (recall, precision and F-measure). As we have similar conclusions in terms of any of the three scores, for simplicity, in this pa-per, we only report the average F-measure scores generated by ROUGE-1, ROUGE-2, ROUGE-L, and ROUGE-SU to compare our proposed method with other implemented sys-tems. Intuitively, the higher the ROUGE scores, the similar the two summaries.
First, we show an example using the Hurricane data. In this example, the query is X  X hat are the situations of Miami-Dade County services including public transit, airport infor-mation and public schools X . For better illustration in figures, we sampled 150 reports from the original dataset in this ex-ample. These documents are released in time sequence and Figures 2  X  4 show the hierarchical trees and sample sen-tences selected at the end of each phase respectively.The three-sentence summaries for the documents released until the end of each time phase are listed in Table 1.
From the sentence hierarchical trees and the generated summaries in this example, we have the following obser-vations. (1) The hierarchy dynamically changes once new documents arrive. (2) From the three sentence structures, we clearly observe the evolution of events along with the growth and reduction of the hurricane. (3) At each time, the sentence best reflecting the new information of each
Phase 1 All Miami-Dade County services continue
Phase 2 Miami-Dade transit bus and rail service
Phase 3 Miami-Dade transit bus and rail service Table 1: Three-sentence summaries for each phase. cluster/subcluster is selected as the most representative sen-tence. (4) The created three-sentence summaries can briefly describe the situations asked in the query in each hurricane evolution phase.
In this set of experiments, we compare our incremental hi-erarchical clustering based update summarization (IHCUS) method with the implemented baselines on Hurricane data using Rouge toolkit. For each query and the documents col-lected in each phase, each system generates one summary. Therefore, there are 10 summaries created by each system for each phase, and 30 in total. The scores reported in this section are the average Rouge F -scores for the 10 summaries of each phase. The experimental result are shown in Tables 2  X  4.
 Table 2: Overall performance comparison on phase 1 of Hurricane data.
 Table 3: Overall performance comparison on phase 2 of Hurricane data. Table 4: Overall performance comparison on phase 3 of Hurricane data using R OUGE evaluation meth-ods.

To better demonstrate the results, Figure 5 visually illus-trates the comparison. As we have similar conclusion on different ROUGE scores, we only show the ROUGE-1 re-sults in the figure. And the average scores for all the 30 summaries in all the phases are shown in Figure 6.
From the comparison results, we have the following obser-vations: Figure 5: Overall summarization performance on Hurricane Data using ROUGE-1.
Now we examine the weight parameter  X  used in Case 1 in Section 3.2. When  X  = 1, the sentence most similar to the query/topic is selected. And when  X  = 0, the cen-troid sentence is selected as the representative sentence. We gradually adjust the value of  X  from 0.2 to 0.8, and Figure 7 demonstrates the influence of  X  . Due to the similar obser-vations and space limit, we only show the summarization results on the documents collected at the end of phase 3.
One of the motivations for using incremental hierarchical clustering based summarization method is to efficiently ap-ply dynamic updates to the summaries when new documents come. Therefore, the efficiency of the algorithm computa-tion is an important factor. Table 5 shows the comparison in terms of time spent by each summarizer given one query. Our evaluations are performed by Java running on a Linux machine with quad-core Intel Xeon CPU 2.66GHz and 8Gb memory.

From the experimental results, we clearly observe that (1) traditional centroid-based ranking method performs very slow on large text data; (2) although graph-based summa-rizer can efficiently generate a summary given a batch of Table 5: Comparison on time spent for generating summaries in each phase given one query. documents, for the update, it still needs to perform the sum-marization many times, and the total time is accumulated. Since current online data on the web are updated very of-ten, the batch mode algorithms are not able to deal with the frequent updates; (3) the results demonstrate the high efficiency of our system on update summarization.
The task of TAC update summarization is to summarize the last 10 documents under the assumption that the reader has already read the first 10 documents. Each summary is no longer than 100 words. As discussed in Section 2, this task is different with the update summarization problem we defined in this paper since in our definition, we do not require the Figure 6: Average summarization performance on Hurricane Data using ROUGE-1. pre-reading assumption. However, our method can easily adapt to the TAC task by only selecting the sentences from the last 10 documents. Thus in this set of experiments, we compare our method for the TAC task with the implemented baselines and also the TAC participants. To produce the update summaries in TAC tasks, most of the participants use anti-redundancy techniques because of the assumption given in the task. Many teams rank sentences according to the probability of sentence given the query or the pre-Figure 7: Weight Parameter Tuning on Hurricane Data using ROUGE-1. defined distance/similarity between sentences and the query. In the meanwhile, centroid based clustering methods are also widely used in this task. Table 6 demonstrates the overall summarization evaluation. Note that TAC creates a baseline summarization method (denoted as TAC Baseline) to select the first few sentences of the most recent document in the relevant document set, and  X  X AC Best X  represents the best results from TAC participants. Table 6: Overall performance comparison on TAC08 data with TAC update summarization task.
 From the results, we confirm most of the observations in Section 4.5.1, and we also some new findings: our method slightly outperforms the best team in TAC. Since we relax the assumption that users have already read the documents in the first batch of documents, we do not perform any par-ticular post processing on redundancy removing, although our method itself can deal with information updates auto-matically. And since the best team of TAC performs exhaus-tive enumeration of sentence combinations in their work, it is not suitable for large-scale online data.
In this paper, we propose an incremental hierarchical clus-tering based approach to update document summaries in real time when new documents arrive. Our system gener-ates a sentence hierarchical tree to demonstrate the com-plete structure of the documents, and in the meanwhile a summary of contents at current time point is created. Com-prehensive experiments on real-world disaster management data and TAC benchmark data show the effectiveness and efficiency of our update summarization approach.
The work is partially supported by the FIU Disserta-tion Year Fellowship and NSF grants IIS-0546280 and HRD-0833093. [1] http://www.nist.gov/tac/. [2] M. Charikar, C. Chekuri, T. Feder, and R. Motwani. [3] J. Conroy and D. O X  X eary. Text summarization via [4] C. Ding and X. He. K-means clustering and principal [5] C. Ding, X. He, and H. Simon. On the equivalence of [6] G. Erkan and D. Radev. Lexpagerank: Prestige in [7] D. H. Fisher. Knowledge acquisition via incremental [8] J.H.Gennari,P.Langley,andD.Fisher.Modelsof [9] Y. Gong and X. Liu. Generic text summarization [10] S. Guha, N. Mishra, R. Motwani, and [11] C. Gupta and R. Grossman. A single pass generalized [12] S. M. Katz. Distribution of content words and phrases [13] C.-Y. Lin and E.Hovy. Automatic evaluation of [14] C.-Y. Lin and E. Hovy. From single to multi-document [15] I. Mani. Automatic summarization .JohnBenjamins [16] R. Mihalcea and P. Tarau. A language independent [17] S. Park, J.-H. Lee, D.-H. Kim, and C.-M. Ahn. [18] D. Radev, H. Jing, M. Stys, and D. Tam.
 [19] B. Ricardo and R. Berthier. Modern information [20] N. Sahoo, J. Callan, R. Krishnan, G. Duncan, and [21] D. Shen, J.-T. Sun, H. Li, Q. Yang, and Z. Chen. [22] X. Wan and J. Yang. Multi-document summarization [23] D. Wang, T. Li, S. Zhu, and C. Ding. Multi-document [24] W.-T. Yih, J. Goodman, L. Vanderwende, and
