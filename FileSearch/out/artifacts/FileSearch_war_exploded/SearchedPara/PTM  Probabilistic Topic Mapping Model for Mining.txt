 Many applications generate a large volume of parallel document collections. A parallel document collection consists of two sets of documents where the documents in each set correspond to each other and form semantic pairs (e.g., pairs of problem and solu-tion descriptions in a help-desk setting). Although much work has been done on text mini ng, little previ ous work has attempted to mine such a novel kind of text data. In this paper, we propose a new probabilistic topic model, called Probabilistic Topic Mapping (PTM) model, to mine parallel document collections to simultane-ously discover latent topics in both sets of documents as well as the mapping of topics in one set to those in the other. We evalu-ate the PTM model on a parallel document collection in IT service domain. We show that PTM can effectively discover meaningful topics, as well as their mappings, and it X  X  also useful for improving text matching and retrieval when there X  X  a vocabulary gap. H.2.8 [ Database Management ]: Database applications X  Data Min-ing Algorithms, Experimentation Probabilistic topic mapping, Mining parallel document collections
The dramatic growth of text data in recent years presents both opportunities for text data mining to discover useful knowledge to facilitate decision making and challenges for designing effec-tive and efficient text mining algorithms that can work generally on many different kinds of text data. In this paper, we study how to mine a novel kind of text data which we call a parallel document collection . A parallel document collection consists of two sets of documents, source and target , such that a document of source set is associated with a document of target set.

Such parallel document collections naturally occur in many ap-plication domains. For example, service providers such as help desks deploy workflow systems that track the lifecycle of problem records from occurrence to resolution. Over time, a large num-ber of these records would be collected by the provider, which constitute the core knowledge base for IT problems and solutions. Such records naturally form a parallel document collection where the source set includes all the problem records, while the target set has all the solution records, and each problem record and solution record form a semantic pair.
 Table 1 shows an example ticket data from an IT service provider. One particularly interesting goal is to discover the major problem areas, major solution strategies and what solution strategies can be applied to what problem areas. A general mining problem here can be abstracted as follows: given a parallel document collection, discover two different sets of topics from source and target docu-ment sets, respectively, and map each topic from the source set to potentially multiple topics in the target set.

This novel mining problem poses two major challenges: (1) How to simultaneously mine two sets of topics and their correlations while there is a vocabulary gap existent between the source and target document sets? E.g., in the above example, although a so-lution record is associated with an IT service problem, the vocab-ularies are often very different. Thus if we first mine two sets of topics and then match them based on the content of the topics, we may not capture interesting mappings between the topics. (2) How to handle the different granularities of topics in source and target sets? E.g., similar IT problems can lead to very different solutions. It is important to allow flexible mapping between source and target topics.

To address these challenges, we propose a new probabilistic topic model, called Probabilistic Topic Mapping (PTM) model, to mine parallel document collections to simultaneously discover latent top-ics in both source and target collections as well as the mapping from source topics to target topics. We evaluate the PTM model on a parallel document collection from an IBM IT service prob-lem management system. Evaluation results show that PTM can effectively discover meaningful topics and mappings on the data set. We also show that the discovered topic mappings can be used to improve text matching when there X  X  a vocabulary gap.
To the best of our knowledge, no previous work has addressed the problem of mining parallel document collections to discover latent topic mappings. However, our work is related to two lines of existing work, which we will briefly review.

First, topic models [5, 1] and their variations have been widely studied in various applications. Among them, the most relevant ones to our work focus on topic modeling on correlated text corpus, including authors and publications [12], citation documents [8], web pages and tags [9, 15], and poly-lingual corpus [7]. The main difference between our work and these existing topic models is that our model mines different sets of topics from two different but cor-related corpora and at the same time analyzes the mappings be-tween these two sets of topics, while previous efforts either mine one set of topics from the publications with authors [12] or focus on mining one set of topics from one single corpus (with citation structure) [8]. [9], [15] and the bilingual study in [7] are similar to a special case of our model, where we set the same number of topics for both source and target documents and let those topics have one-to-one correspondence. However, without imposing the one-to-one mapping constraint, PTM is more general.

Another related research area is Question-Answering (QA), and most related work can be found in TREC [4]. QA tasks are spread across different applications such as online forums [2], FAQ re-trieval [11, 3], and email summarization [10]. In [13], the authors studied using word-to-word translation probabilities to improve the retrieval models for QA archives. This is similar to one application of PTM for matching the source and target documents. However, the difference is that our PTM learns  X  X opic-to-topic X  translation probabilities instead of word-to-word translations. We now define our problem formally.
 allel Document Collection C is a set of text document pairs, i.e., C = { ( s 1 ,t 1 ) , ( s 2 ,t 2 ) ,..., ( s N ,t N ) } ,where s text documents referred to as a source document and target doc-ument , respectively; N is the total number of document pairs in the collection. We also refer to ( s i ,t i ) as a parallel document , and denote it by d i .

Given a parallel document collection D , we also refer to the set of all source documents as the source set , C s = { s 1 ,s 2 ,...,s and similarly, the set of all target documents as the target set , C { t 1 ,t 2 ,...,t N } . Thus, we may also regard the entire parallel doc-ument collection C as { C s ,C t } . For example, Table 1 shows a set of parallel documents, each of which contains a Problem field (source document) and a Solution field (target document).
D EFINITION 2(T OPIC ). A topic in a text collection (either a source set or a target set) is a pr obabilistic distribution over words, which characterizes a semantically coherent topic in the collection. Formally, a topic is represented by a unigram language model  X  , i.e. a word distribution { P ( w |  X  ) } w  X  V s.t. w  X  V Here, V denotes the whole vocabulary of our corpus.
 parallel corpus C = { C s ,C t } , the goal of mining topic mapping (MTM) from C is to mine K s topics {  X  i } K s i =1 from the source set C s and K t topics {  X  j } K t j =1 from the target set C t K s  X  K t topic mapping probab ilities from the source to the target document set, i.e. P (  X  j |  X  i ) for i =1 ,...,K s and j =1 ,...,K which satisfy K t j =1 p (  X  j |  X  i )=1 for all i =1 ,...,K
For example, in the ticket data described in Table 1, MTM can be expected to mine topics like  X  X apacity Problem X  and  X  X ard-ware Problem X  from the source set (i.e., problem set) and topics like  X  X eletion Operation X  and  X  X eplace Operation X  from the target set (i.e., solution set), as well as topic mappings to indicate which solution topic is the most appropriate one for a problem topic. For example, the  X  X eletion Operation X  could be the best solution for the  X  X apacity Problem X . An example of the mining result is shown in Figure 1. In this section, we present a novel probabilistic topic model called Probabilistic Topic Mapping (PTM) model to solve the problem of mining topic mappings from a parallel document collection. The basic idea of PTM is to introduce two sets of word distributions to model the topics in a source set and a target set, respectively, use a set of possible topic mapping probabilities to model the topic map-ping relation, and then assume a parallel document collection is a sample drawn from a mixture model involving these word distribu-tions and topic mapping probabilities.

Formally, let {  X  i } K s i =1 be K s topics in the source set C {  X  j } K t j =1 be K t topics in the target set C t ,where p ( w p ( w |  X  j ) are word distributions for each topic  X  i and  X  ( i =1 ,...,K s and j =1 ,...,K t ) denote the probability that topic  X  i of the source set should be mapped to topic  X  j set. These probabilities essentially encode the major knowledge we would like to discover from a parallel document collection.
Now we assume that a parallel document d =( d s ,d t ) ( d d are the source and target documents) is generated word by word in the following way: (1) To generate a word w in the source document d s : 1. Pick a topic z s =  X  i with probability P (  X  i | d ) 2. Sample a word w from the multinomial distribution P ( w (2) To generate a word w in the target document d t : 1. Pick a topic from the source set, z s =  X  i with probability P (  X  i | d ) 2. Pick a topic in the target set,  X  j , according to the topic map-ping probability distribution P (  X  j |  X  i ) 3. Generate a word w from the multinomial distribution P ( w
Based on the generative process described above, given all the documents in a parallel document collection, the log-likelihood of the whole parallel document collection C is where c ( w,d s ) and c ( w,d t ) are the count of w in d  X  X  source document d s and target document d t , respectively.

The proposed PTM model has the following parameters, which we will denote by  X  : (1) source topics: { P ( w |  X  i ) } topics: { P ( w |  X  j ) } V  X  K t ; (3) topic mapping: { P (  X  and (4) coverage of source topics in each parallel document d : {
P (  X  i | d ) } K s  X  N . We estimate the parameters  X  using the maxi-mum likelihood estimator, which selects parameter values that max-imize the data log-likelihood. That is, our estimate would be given by where L ( C |  X ) is the log-likelihood of the parallel document col-lection C given in Equation 1. We use the Expectation-Maximization (EM) algorithm to estimate the parameters with the following for-mulas: E-step : M-step :
We used a ticket data set collected from IBM X  X  IT service prob-lem management system to evaluate the proposed PTM model. Ev-ery day, thousands of tickets are delivered to this IT service prob-lem management system. Once a problem ticket is resolved, the agent will document the solution for future references. All these archived data need to be analyzed for further improving the whole IT services for the customers. Our PTM model can serve as a pow-erful tool for analyzing this data, where we treat each ticket X  X  prob-lem and solution as a parallel document pair. For different experi-ment purposes, we use subsets of different sizes collected from this largedataarchive.
The output format of PTM model is as shown in Figure 1. Here, in Table 2 we show some sample mining results for two source top-ics and their corresponding target topics mined from the problem-solution ticket data. The topic numbers were set empirically. For each topic, we show the top k words with the highest probabilities in the word distribution of that topic (i.e., p ( w |  X  ) or p ( w The first three columns consist of the source topic  X  X apacity Problem X  and its two target topics with high mapping probabili-ties. We see that they are intuitively very meaningful, showing that disk space is a major problem in this data set and its common solu-tions are to delete temporary files to free up disk space or scan the filesystem with antivirus softwares. Similarly, the two columns la-beled as  X  Hardware Problem and Hardware Solution  X  are another pair of source topic and target topic with high mapping probability.
To quantitatively evaluate the quality of the discovered topics and their mappings by PTM, we study an interesting application of PTM for matching a document in the source set with documents in the target set. Such an evaluation will help us indirectly measure the quality of the mining results of PTM. Specifically, we will use the source document (ticket problem description) as a query q ,and use the KL-divergence retrieval model [6] to rank possible targets (ticket solutions). With this retrieval model, one critical issue is how to construct a query language model for q , and we will use PTM to improve the construction of the query language model. We experimented with three different methods: (1) Baseline retrieval method : we define a query language model for q as P ( w | q )  X  c ( w,q ) ,where c ( w,q ) is the count of word w in q . (2) PLSA-based approach : to make the source description more informative, PLSA model can be used to help expand the original query language model P ( w | q ) [14]. The smoothed query language model is calculated as follows: where P ( w | q ) is the original query language model, { are topics estimated from a set of archived source documents, and {
P (  X  i | q ) } K s i =1 are topic coverage in q estimated by the folding-in method proposed in [5]. (3) PTM-based approach : both the baseline method and the PLSA-based approach would fail if the source document does not have much overlap in vocabulary with a target document. PTM can alle-viate this problem through expanding the query with related topics and their mappings to the target topics, which presumably helps  X  X rossing the source-target boundary X . The smoothed query lan-guage model is calculated as follows: where the parameters { P ( w |  X  i ) } K s i =1 and { P ( w mated from a set of training parallel documents. The correspond-topic mapping probabilities { P (  X  j |  X  i ) } j =1 ...K t in approach).

Since there is no relevance judgement data available for eval-uating the retrieval performance, we opted to use the following simulation strategy. First, we randomly selected 2500 tickets as our training data and randomly selected another 200 tickets as our test data. Both PLSA and PTM models are estimated based on the training data. Second, we treat the source document in each testing parallel document pair as a query, and treat its corresponding target document as the true answer to be retrieved. We put all the target documents into a pool, including target documents in both training and testing parallel document pairs, and using the three methods to rank all the targets based on each source query. We use the rank of the true targets to evaluate these three methods. The results are shown in Table 3.
 Model  X  Easy Difficult Model  X  Easy Difficult Table 3: Improving Difficult Cases in Document Matching (a smaller rank value indicates better accuracy)
To analyze the effectiveness of PTM in bridging the vocabulary gap between source and target document sets, we divided all the test cases into two groups: easy and difficult. If one test case X  X  source document and target document do not have vocabulary gap and are very similar to each other, then the test case will be put into the easy group, otherwise it will be put into the difficult group. Here, we use cosine similarity to compare the similarity between a source document and a target document. If the similarity is above 0.2, we assume that there is not significant vocabulary gap between the two documents. In this way, 80 test cases are classified as easy cases and the others as difficult cases. For each group, we then calculate the average rank of the true target of all the test cases in this group. For both PTM and PLSA, we also vary the value of the combination weight  X  which controls the weight of the original source document in the expanded query. If it is set too small, both PLSA and PTM will get worse results because the expanded query is too different from the original source document.

From Table 3, we can see that PTM indeed improves over the baseline for difficult cases consistently. However, its performance on the easy cases is often not as good as the baseline, which is ex-pected because by bringing latent topics to smooth the query lan-guage model, we may lose discriminativeness. Indeed, the trend along the parameter variation shows clearly this tradeoff: if we trust the baseline model more, we would do better on easy cases, but worse on difficult cases. With appropriate setting of the weighting parameter, it X  X  possible for PTM to do better for both easy cases and difficult cases. However, on the other hand, we did not see clear improvement of PLSA on the difficult cases over the baseline method. This indicates that smoothing the query language model with only the source topics is not effective enough for bridging the vocabulary gap between the source and target documents. In this paper, we proposed a novel approach called Probabilistic Topic Mapping (PTM) model for mining parallel document col-lections. Our experimental results show that PTM can effectively discover meaningful topics and their mappings from parallel docu-ment collections. We also use applications to demonstrate PTM X  X  capability of improving text matching and retrieval when there is vocabulary gap. As for future work, how to make PTM scalable enough to mine millions of parallel documents and apply it in other domains are both interesting to explore. [1] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet [2] G. Cong, L. Wang, C.-Y. Lin, Y.-I. Song, and Y. Sun. Finding [3] A. Corrada-Emmanuel and W. B. Croft. Answer models for [4] H. T. Dang, D. Kelly, and J. Lin. Overview of the trec 2007 [5] T. Hofmann. Unsupervised learning by probabilistic latent [6] J. Lafferty and C. Zhai. Document language models, query [7] D. Mimno, H. M. Wallach, J. Naradowsky, D. A. Smith, and [8] R. M. Nallapati, A. Ahmed, E. P. Xing, and W. W. Cohen. [9] D. Ramage, P. Heymann, C. D. Manning, and [10] L. Shrestha and K. McKeown. Detection of question-answer [11] R. Soricut and E. Brill. Automatic question answering using [12] M. Steyvers, P. Smyth, M. Rosen-Zvi, and T. Griffiths. [13] X. Xue, J. Jeon, and W. B. Croft. Retrieval models for [14] C. Zhai and J. Lafferty. Model-based feedback in the [15] D. Zhou, J. Bian, S. Zheng, H. Zha, and C. L. Giles.
