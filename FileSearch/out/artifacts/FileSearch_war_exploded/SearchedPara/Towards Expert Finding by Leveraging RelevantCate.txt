 How to improve authority ranking is a crucial research prob-lem for expert finding. In this paper, we propose a novel framework for expert finding based on the authority infor-mation in the target category as well as the relevant cat-egories. First, we develop a scalable method for measur-ing the relevancy between categories through topic models. Then, we provide a link analysis approach for ranking user authority by considering the information in both the tar-get category and the relevant categories. Finally, the ex-tensive experiments on two large-scale real-world Q&amp;A data sets clearly show that the proposed method outperforms the baseline methods with a significant margin.
 H.3.3 [ Information Search and Retrieval ]: Search pro-cess; H.3.5 [ Online information services ]: Web-based services Algorithms, Experimentation Authority Ranking, Expert Finding, Category Relevancy, Topic Models
A critical challenge in knowledge sharing social networks, such as online forums and Question Answering (Q&amp;A) com-munities is how to find experts, i.e., a group of authoritative users with special skills or knowledge for a specific category. Indeed, the problem of expert finding has attracted a lot of attention in the literature and a central issue of expert finding is how to perform effective authority ranking.
However, when performing authority ranking for expert finding, most of the state-of-the-art works only take the in-formation in the target category into consideration. Indeed, every target category usually has some very relevant cate-gories. The information in these relevant categories might be exploitable for improving the performance of authority ranking for the target category.

To this end, we propose to exploit the information in both target and relevant categories for improving the performance of authority ranking. The first task along this line is to mea-sure category relevancies. In this paper, we propose to ex-ploit topic models for representing categories as topic distri-butions and then measure the relevancies between categories by normalized Kullback Leibler (KL) divergence. In addi-tion, we develop a link analysis approach, which is based on the Topical Random Surfer model [4], to collectively exploit the information in both target and relevant categories for au-thority ranking. Finally, we perform extensive experiments on two large-scale real-world data sets collected from two major commercial Q&amp;A web sites. The results demonstrate the efficiency and effectiveness of the proposed approach.
In this paper we propose a new framework for expert find-ing, namely, category relevancy based authority ranking. To be specific, here we first introduce the traditional authority ranking problem, and then formally define the problem of category relevancy based authority ranking.
 Traditional Authority Ranking: Given a category set C = { c 1 ,c 2 ,...,c n } and a user set U = { u 1 ,u 2 ,...,u category link graph G c ( c  X  C ) for a given knowledge sharing social network S is denoted as G c = ( V c ,E c ,W c ), where
Given a knowledge sharing social network S , the task of the traditional authority ranking for category c is to find top K authoritative users from G c . In this way, only the information in target categories are taken into account. In contrast, we introduce a new approach for authority ranking by exploiting the information in both target and relevant categories. Next, we first present some notations as follows. Fi gure 1: An example of extended category link graph in a Q&amp;A community. A node denotes a user, and an edge from user u i to user u j denotes that u j has answered a question posted by u i .
 Definition 1. (Extended Category Set, Extended Category Link Graph). An extended category set  X  c = { c } X  R c , where R c denotes the set of relevant categories of category c .

An extended category link graph G c = ( V c ,E c ,W c ) is the extension of the category link graph G c , where V  X 
Figure 1 illustrates an example of extended category link graph in a Q&amp;A community. With above notions, the prob-lem of category relevancy based authority ranking is for-mally defined as follows.

Definition 2. (Category Relevancy based Author-ity Ranking). Given a category c , the task of category rel-evancy based authority ranking is to build the extended category link graph G c and then nd top K authoritative users for category c in G c .

Therefore, the problem of category relevancy based au-thority ranking can be divided into two sub-problems as fol-lows. The first problem is how to find the relevant category set R c to extend the original category link graph G c . The second problem is how to rank user authority for category c in the extended category link graph G c . In the following sections, we present the technical details of our solutions for the two sub-problems, respectively.
In this paper, we propose to leverage topic models for in-ferring category relevancies. The basic assumption is that two categories are relevant because their probabilities of be-longing to the same latent topic are similar. For example, the categories  X  X inging X ,  X  X op Music X  and  X  X nstruments X  are related because they all belong to the latent topic Music .
Topic models assume that there are several latent topics for a corpus D and a document d in D can be represented as a bag of words { w d;i } which are generated by these la-tent topics. We first define a user interactive log consists of a set of category labels where the user made or replied the posts with these category labels and the corresponding frequencies. Then intuitively, if we take category labels as words, take user interactive logs as documents we can di-rectly take advantage of topic models for inferring latent topics of categories. Then we can represent each category c as a conditional probabilistic distribution P ( z | c ) which de-notes the probability of category c being labeled with topic z .
 Among several existing topic models, we use the Latent Dirichlet Allocation model (LDA) [2] in our approach. Ac-cording to LDA, a user interactive log L i is generated as fol-lows. Firstly, a prior topic distribution  X  i is generated from a prior Dirichlet distribution  X  . Secondly, a prior category distribution  X  i is generated from a prior Dirichlet distribu-tion  X  . Therefore, for the j -th category c j in L i , the model generates a topic z i;j from  X  i and then generates c j from  X 
The main requirement for our approach is to estimate the probability P ( z i | c ), which cannot be obtained directly from LDA. However, according to the Bayes formula we can cal-P ( z i ) can be obtained from LDA. In this paper, we use Gibbs sampling method to estimate P ( c | z i ) and P ( z i ). After sev-eral rounds of Gibbs sampling, we can get the estimated value e P ( c | z i ) by e P ( c | z i ) = n ( c ) i + the frequency that category c has been assigned to topic z n i indicates the frequency that any category is assigned to topic z i , and | C | indicates the total number of unique categories. Similarly, the estimated value e P ( z i ) can be cal-
LD A model needs a predefined parameter Z to indicate the number of latent topics. How to select an appropriate Z for LDA is an open question. In terms of guaranteeing the performance of expert finding, in this paper we utilize the method proposed by Bao et al [1] to estimate Z . F igure 2: Category relevancy matrix generation.

By utilizing LDA, each category c can be represented as a Z -dimension vector of topic distribution P ( z | c ). Thus, the task of estimating category relevancy is converted to calculate the distance between vectors. In this paper, we propose to use normalized Kullback Leibler (KL) divergence, which is an asymmetric measure, for measuring category relevancies. The KL-divergence from category c i to category c is computed by KL ( c i || c j ) =
Th en we calculate the relevancy between categories c i and c denotes the maximum KL-divergence from other categories to category c j . The bigger Rel ( c i || c j )  X  [0 , 1], the more relevant c i is for c j .

After calculating the relevancies between each pair of cat-egories, we can obtain the category relevancy matrix M C = { m ij = Rel ( c i || c j ) } , where i,j  X  [1 ,n ]. Figure 2 illustrates an example of generating the category relevancy matrix. F rom M C , we can easily find the relevant categories for a given category through a predefined relevancy threshold  X  . In Section 6, we analyze the robustness of expert finding when given varying parameters  X  and Z .
By finding relevant categories from the category relevancy matrix, we can build the extended category link graph for a target category. Compared with a normal category link graph, in an extended category link graph the authority propagation in the target category between two users may be impacted by their different original expertise in the tar-get category before authority propagation. To this end, we extend the Topical Random Surfer (TRS) model [4] to rank user authority in extended category link graphs for consid-ering their different original expertise in the target category.
The TRS model is originally proposed for web page rank-ing. Its basic idea is similar to the  X  X andom surfer X  process described in PageRank model and the special property is that the  X  X andom surfer X  is sensitive to different topics of web pages. Specifically, in the TRS model, there are two possible ways to move to another web page v  X  for a web surfer who is browsing a web page v for the interesting topic z . The first is with probability (1  X  d ) to follow a outgoing link on the current page v (e.g., clicking a hyper-link). An-other is with probability d the surfer will jump to a random page from the entire web W (e.g., directly typing an url in the address field). Moreover, for each new page v  X  , the surfer will browse it either because of the same interesting topic z with probability  X  v;z or any other interesting topic z  X  probability (1  X   X  v;z ). Therefore, there are total three rea-sons for the web surfer to browse a new web page v  X  , namely, 1) following a link for the same interesting topic z , 2) fol-lowing a link for any other interesting topic ( z  X   X  = z ) and 3) jumping to another page for any interesting topic z  X  . To facilitate expression, TRS model names these three reasons as  X  F S  X ,  X  F J  X  and  X  J J  X , respectively.

To utilize TRS model for our authority ranking problem, we take the extended category link graph G c as a web page link graph G , let each u  X  G c correspond to a web page v and let the original expertise of each user in different categories (without considering the authority propagation) correspond to different topics of a web page. Moreover, in our problem  X  F S  X ,  X  F J  X  and  X  J J  X  denote 1) following a link to select the next user as the authoritative user for the same category c , 2) following a link to select the next user as the authoritative user for any other interesting category c ( c  X   X  = c ), and 3) randomly select a user as the authoritative user for any category c  X  , respectively. Therefore, we have the following equations according to the TRS model. where P (  X  X  u,c ) denotes the conditional probability of next choice of the surfer denoted as  X  given that the surfer has se-lected u as the authoritative user for category c , P ( u denotes the conditional probability of selecting u  X  as the au-thoritative user for category c given that the surfer selected u as the authoritative user for category c previously and then selected the choice  X  , D ( u,u  X  ) = w u,u  X   X   X  the LDA model trained in the stage of calculating category relevancies.

According to above equations, we can calculate the joint probability P ( u  X  ,c  X  ) which denotes the probability that the surfer is selecting user u  X  as an authoritative user for cate-gory c  X  by P ( u  X  ,c  X  ) = f ( F S ,F J ,J J )
Therefore, we can iteratively calculate P ( u,c ) for each user u for the target category c . In the first round of prop-agation, we let P ( u  X  ,c  X  ) = 1 | V converge after several rounds of propagation. Therefore, we can rank all users X  authority in G c for category c by P ( u,c ).
In this section, we demonstrate the experimental results of 1) the performance comparison between our C ategory R elevancy based A uthority R anking (CRAR) approach and baselines, 2) robustness analysis of parameter setting.
Data Sets. The data sets used in the experiments are collected from two major commercial Q&amp;A web sites. The first one is a public data set collected from Yahoo! Answers ( http://answers.yahoo.com ) by Liu et al. [3]. There are 100 categories, 216,563 questions, and more than 1.9 million answers posted by 171,266 users in this data set. Another data set was collected from a major Chinese Q&amp;A service web site named Tianya Wenda ( htpp://wenda.tianya.cn ). This data set contains 595 categories, more than 1.3 million questions, and 5.5 million answers posted by 274,896 users. In both data sets, all questions are resolved questions which contain a best answer voted by the question author. More-over, each data set contains a predefined two-level category taxonomy. To avoid category overlap, we only use the leaf categories in the taxonomy in the experiments. In total, there are 94 leaf categories in the Yahoo! Answers data set and 595 leaf categories in the Tianya wenda data set.
Benchmark Methods. To evaluate the performance of the CRAR, we chose three baseline methods as follows. De-gree is a simple statistical measure which ranks user author-ity in the order of the in-degrees of the according user node in the category link graph. HITS is an iterative approach which assigns two scores for each node in the category link graph, namely, hub score and authority score. ExpertiseR-ank [5] is extended from PageRank. TRSO stands for TRS for original category link graph. It is an topical link analysis approach by leveraging TRS model in the original category link graphs but not the extended category link graphs.
Evaluation Metrics. To evaluate the performance for exp ert finding, we used three widely-used metrics as follows. Average Precision@K (Avg. P@K) denotes the average ra-tio of real experts in top K identified authoritative users for each category. In the experiments, K is 10. Mean Reciprocal Rank (MRR) is the multiplicative inverse of the rank of the first mined authoritative user in each category. Mean Aver-age Precision (MAP) is the mean of the average precision scores for each category.

Since both data sets have no principle benchmark for who are real authoritative users for a given category, we manu-ally inspect the expert finding results. To be specific, firstly we carry out each measuring approach to find top K users as expert candidates for all target categories. Then, for each mined expert candidate u for category c , we ask three hu-man evaluators to check whether u is a real expert for the category c by comprehensively considering the interactive history of u including the number of posted answers, the number of best answers, the voting from another users for the posted answers. Each identified authoritative user is voted by three evaluators with label Yes (the user is a real expert) or No (the user is not a real expert). It is worth noting that when the evaluators count the answers of a user for category c , they are asked to manually check each answer in the history of the user whether it is relevant to category c other than only consider the answers with the category c .
Ov erall Results of Expert Finding. According to the method introduced in [1], the numbers of topics Z are set to be 30 for the Yahoo! Answers data set and 100 for the Tianya Wenda data set. The two parameters  X  and  X  were empirically set to be 50 /Z and 0.2. We randomly select 100 categories in Tianya Wenda to test the overall performance of our approach and other baselines for expert finding. For the Yahoo! Answers data set, we evaluate the performance for all categories. In addition, as PageRank usually does, d is set as 0.15 here [4]. Table 1 shows the average experi-mental results for all test categories with respect to different metrics. From this table we can see that our approach con-sistently outperforms other baselines with respect to varying metrics on both data sets. Moreover, we also observe that the topical analysis in original category link graphs can only slightly improve the performance of expert finding than Ex-pertiseRank. It is because that the number of relevant users to the target category are limited in the original category link graphs, thus the topical related information from other users cannot be fully taken advantage of.

Robustness Analysis. The CRAR approach needs two parameters, namely, the latent topic number Z and the ex-tension rate  X  of categories. Figure 3 (a) and (b) show the Avg. P@10 of CRAR with varying topic numbers and exten-Figure 3: The Avg. P@10 of expert nding versus varying numbers of topics and extension rates in (a) Yahoo! Answers, (b) Tianya Wenda. sion rates for each data set, respectively. From these figures we can see that the setting of Z in this paper estimated by perplexity is reasonable. Moreover, we also can find that the performance of CRAR for expert finding is stable for extension rates with the large topic numbers. However, if a small topic number is used, the extension rate can dramat-ically impact the performance of CRAR. The phenomenon is reasonable because large topic numbers will cause stricter relevancy metrics while small topic numbers will make the relevancy metric weak. Then, a number of the irrelevant categories will be involved as noise information and will dra-matically impact the performance of expert finding. In an-other case, if the relevancy metric which are strict enough the benefit from other relevant categories is very limited and the performance of CRAR is similar as the TRSO.
In this paper, we investigated how to exploit the infor-mation in both target and relevant categories for enhancing authority ranking in expert finding. Specifically, we first provided a method for measuring category relevance by uti-lizing topic models and KL-divergence. Then, a multiple-category-based link analysis approach was extended from the TRS model for ranking user authority in extended cat-egory link graphs. Finally, we performed extensive exper-iments on two large-scale real-world Q&amp;A data sets and results clearly show that our CRAR approach can signif-icantly improve the performance of authority ranking for expert finding.
 Acknowledgement. This work is supported by grants from Natural Science Foundation of China (No. 61073110), Key Program of National Natural Science Foundation of China (No. 60933013), National Major Special Science &amp; Tech-nology Projects (No. 2011ZX04016-071), Research Fund for the Doctoral Program of Higher Education of China (No. 20093402110017) and Nokia.
