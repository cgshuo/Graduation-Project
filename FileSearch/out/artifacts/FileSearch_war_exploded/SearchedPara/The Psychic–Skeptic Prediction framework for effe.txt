 1. Introduction
Commercial relational database management systems (DBMSs) are used for a range of applications from data warehous-ing through on-line transaction processing. As a result of this demand, DBMSs have continued to grow in terms of their size and the functionality they provide. This growth reciprocally creates additional overhead in the associated system complexity and administration costs [18] and makes the task of manually tuning the performance of these systems virtually impossible.
Autonomic computing systems, which are systems that are self-configuring, self-optimizing, self-healing, and self-protect-ing, are a promising approach to solving these problems of cost and complexity [1]. In order to effectively tune a DBMS, the database administrator (DBA) must understand the workload placed on that system, which makes automatic workload char-acterization a prerequisite for automatic tuning. Our work focuses on the specific workload characterization problems of (1) specifically whether it is Online Transactional Processing (OLTP) or Decision Support System (DSS), is an important criterion for tuning [4,6,10] . Memory resources, for example, are allocated very differently for OLTP and DSS workloads. OLTP workloads contain a large number of small transactions that involve retrievals of individual records based on key values and updates. There are relatively few sorts and joins. DBAs therefore typically allocate memory to areas such as the buffer pools and log buffers while minimizing the sort heap. DSS workloads, on the other hand, contain a small number of large transactions that involve scans, joins, and sorts. There are very few, if any, updates. DBAs therefore typically allocate more memory to the sort heap and the buffer pools. Once the dominant workload type is recognized and detected, the DBMS can adopt well known rule-of-thumb tuning strategies that experts found effective in practice (for examples of tuning strat-egies see [4,5,7,10] ).

To that end, in [17] we developed an automatic workload classifier , briefly described below, for identifying the type of a workload put on a DBMS. However, a new challenge has been observed as the type of a workload tends to vary over time.
Many organizations experience daily, weekly or monthly processing cycles that mirror the cycle of tasks performed by the organization. A bank, for example, may experience an OLTP workload during normal business hours, a DSS-like workload overnight while the previous day X  X  business is analyzed, and a heavy DSS workload at the end of the month when financial reports and executive summaries are issued. DBAs must therefore recognize the significant shifts in the workload and recon-figure the system accordingly in order to maintain acceptable levels of performance.

If we keep the workload classifier activated all the time in order to capture significant shifts in the type of the workload then we will impose undesirable overhead and perturbation on the system due to incessantly probing the DBMS engine for real-time statistics. This on-line analysis of the workload classifier and the constant monitoring may even undermine the benefits the workload classifier is supposed to contribute to the performance of the DBMS. By comparing the throughput of our DBMS, DB2, with and without using the workload classifier tool, we empirically found that running the workload clas-sifier reduced the throughput of by 10% on average [17]. 1 ever, if each new autonomic feature does not take care of reducing its operational cost, then the incremental introduction of features and functions could lead to accumulative overhead that threatens to undermine the very benefits autonomic comput-ing aims to provide. 1.1. Solution and contribution
Therefore, and in order to mitigate such undesirable overhead, we suggest to predict when a change in the workload type the main focus of this work.

Our key contribution in this paper is defined by presenting the Psychic X  X keptic Prediction (PSP) framework, which allows an autonomic DBMS to efficiently learn about a workload X  X  dynamic behavior over time and to forecast when a change in the workload might occur in order to proactively reset the DBMS parameters to suit the new situation. The PSP framework is equipped by two categories of predictions: off-line (long-term) prediction, and on-line (short-term) prediction.
Based on a comprehensive analysis for the entire workload, the off-line prediction learns about the long-term pattern of the workload and, consequently, it can produce a complete schedule of anticipated shifts in the workload type. However, it is risky for the DBMS to base its reaction on mere prediction. As a safety net, the PSP framework counts on the on-line predic-well planned workload sampling in order to be adaptive and keep its prediction models up to date in case the workload starts mizes the overall performance of the DBMS.

While we specifically demonstrate the effectiveness of the PSP framework in combination with the workload type clas-sifier, we claim that our framework is generic in the sense that it can be used in other instances where workloads exhibit some trend that makes them relatively predictable. PSP could be used to automate many other DBMS tasks such as deter-mining when to make incremental backups, re-build indexes and refresh materialized views, update statistics, or reorganize data on disk.

The remainder of the paper is structured as follows. We first review related work in autonomic DBMSs in Section 2.We then outline our previous work on workload classification in Section 3. Section 4 introduces our Psychic X  X keptic Prediction framework. Section 5 evaluates the performance of our framework using a set of simulation experiments. We summarize our paper and outline possible directions of future research in Section 6. 2. Autonomic database management systems
DBAs increasingly face more challenges brought about by the growing complexity of DBMSs, which stems from several sources [16]:
Increased emphasis on Quality of Services (QoS) . A DBMS must provide service guarantees in order that the overall system can satisfy the end-to-end QoS requirements.

Advances in database functionality, connectivity, availability, and heterogeneity . DBAs must grapple with complex decisions about hardware platforms, schema design, constraints and referential integrity, primary keys, indexes, materialized views, the allocation of tables to disks, and shared-nothing, shared-everything, or SMP-cluster topology.
Ongoing maintenance . Once designed, databases require substantial human input to build, configure, test, tune, and operate.

Burgeoning database size . Popular applications such as SAP typically create more than 20,000 tables and support thousands of users simultaneously.

E-Service era . Web-based applications present the DBMSs with a broader diversity of workloads in terms of type and intensity.

Autonomic computing systems, which shift the responsibility of managing the system from the system administrator onto the system itself, have emerged as a promising approach to dealing with this complexity [1]. A system is considered tecting. There has been a significant amount of research related to providing these capabilities in DBMSs. The performance of a DBMS depends on the configuration of the hardware and software components. An autonomic
DBMS should provide users with reasonable  X  X  X ut of the box X  performance and dynamically adapt its configuration to provide acceptable, if not optimal, performance in light of constantly changing conditions. It must understand the composition and intensity of its workload in order to make the appropriate adjustments. Current DBMSs typically provide static configuration provide an advisor (DB2 X  X  Design Advisor [3], SQL Server X  X  Index Wizard [7], and Oracle X  X  Index Tuning Wizard [9]) to rec-ommend a suitable set of indexes and materialized views.

Self-optimization is one of the most challenging features to include in a DBMS. It allows a DBMS to perform any task and execute any service utility in the most efficient manner given the present workload parameters, available resources, and environment settings. The system must understand the composition, intensity and priorities of the workload and be able to recognize shifts in the workload in order to effectively allocate resources. Work on this aspect has focused on issues such as the automatic collection and generation of operation statistics [8,13] , more sophisticated cost models [7,8,11] , and dy-namic adjustment of query plans [24]. Our work in this research is a prerequisite for any optimization models that deem the characteristics of the workload as input parameters to these models. Many database internal parameters are set differ-ently depending whether the workload is OLTP or DSS. OLTP business applications (such as PeopleSoft, Siebel, and SAP) sup-port multiple users who require very rapid response times. Frequently, the database serves thousands of concurrent users. Response time may include CPU, sort, locking, and I/O times. The majority of SQL statements in an OLTP workload are
SERT , UPDATE , and DELETE that require contention management and locking strategies. Yet, some OLTP applications include batch-processing components and probably some concurrent decision support queries.

In contrast, DSS users ask complex business questions relevant to the available data requiring complex SQL queries. Re-sponse times in a DSS environment are typically measured in minutes rather than seconds. However, response time require-ments vary significantly based on business needs. DSS workloads are mostly read-only queries. Parallelism (both CPU and I/ allelism (by which we mean intrapartition parallelism on a single SMP server) is neither necessary nor desirable.
These differences inevitably entail different settings of the configuration parameters in order to ensure that the DBMS has sufficient resources to perform the processing required. Detailed discussion on how to tune each database parameter (e.g., size of sort heap, number of I/O cleaners, log size, min. number of commits, etc.) upon distinguishing whether the workload is OLTP or DSS can be found in [5] and the technical manuals of DBMSs (e.g., [4,7,10] ).

A self-healing DBMS automatically detects, analyzes, and repairs problems. It must understand the normal patterns and archive the database and be able to use the logs and backups to recover from failure. Ideally, it should recognize when a full or incremental backup is necessary and perform these operations with minimal system disruption. In the event of cata-strophic failure, a self-healing DBMS should be able to retrieve the most recent backup, restore to the consistent point just before the failure and then resume its halted operations after handling the exceptions. Oracle currently provides the ability to resume operations (such as a batch load) following corrective action (such as the addition of more disk space) [9]. DB2 X  X  Recovery Expert is a recovery tool that analyzes the recovery assets available and recommends a technique to be selected.
DB2 X  X  Automatic Incremental Restore mechanism uses the backup history for automatically searching for the correct backup images.

A self-protecting DBMS automatically defends itself against malicious attacks. It must therefore understand the normal patterns and levels in the workload in order to detect possible security threats from outside sources. Database protection implies support for database security, privacy, analytical auditing mechanisms, data encryption, and admission control strat-egies. Current DBMSs all provide authentication and access control mechanisms. The DB2 Query Patroller [4] and the Oracle
Resource Manager [9] are examples of admission control tools used today. 3. Workload classification
The above examination of autonomic DBMSs reveals that workload characterization is an important prerequisite for all used to tune a system. We have decomposed the problem of identifying the type of a workload into the two sub-problems of classifying the workload and predicting when the type changes. The prediction problem is the focus of this paper. Our back-ground work on classifying workloads is described elsewhere [14,15,17] and is summarized below.

We view the problem of classifying DBMS workloads as a machine-learning problem in which the DBMS must learn how to recognize the type of the workload mix. We use data mining classification techniques, specifically Decision Tree Induction techniques such as neural networks.

We base our analysis on dynamic data collected by DBMS performance monitors because the dynamic data includes fre-quency information that is not available from static sources, it captures the variability of the workload over time, and it is easier to analyze than SQL statements or access plans. We first analyze attributes available from performance snapshots with respect to their suitability for differentiating between DSS and OLTP and derive a set of attributes to be used in our classi-fication process. We next build a model (or classifier ) to describe a predetermined set of data classes.
As shown in Fig. 1 , the model is constructed by analyzing a training set of data objects that constitute two thirds of the object as either OLTP or DSS. The data objects needed to build the classifier are performance snapshots taken whilst the data-base processes the workload. Each snapshot reflects the workload properties at some time during the execution. The learned model is represented in the form of a decision tree embodying the rules that can be used to categorize future data objects.
In our experiments, we constructed workload classifiers from two pairs of representative workloads. The first pair con-sisted of the TPC-C [21] and TPC-H [22] benchmarks as the OLTP and DSS workloads, respectively. TPC-C simulates a com-plete order-entry environment where a population of terminal operators executes transactions that include entering and delivering orders, recording payments, checking the status of orders, and monitoring the level of stock at the warehouses.
It represents any industry that must manage, sell, or distribute a product or service. On the other hand, TPC-H is a decision support benchmark whose workload examines large volumes of data, executes queries with a high degree of complexity, and gives answers to critical business questions.

The second pair consisted of the Browsing and Ordering profiles defined in the TPC-W benchmark [23] as the DSS and OLTP workloads, respectively. TPC-W comprises a set of basic operations designed to exercise transactional web system function-ality in a manner representative of internet commerce application environments. These basic operations have been given a acterized by extensive browsing and searching activities. The Shopping profile exhibits some product ordering activities but browsing is still dominant. The Ordering profile has a majority of ordering activities. Therefore, the ultimate difference be-tween these profiles is the browse-to-order ratio.

We ran each pair of workloads on IBM X  X  DB2 Universal Database system (DB2) [4] and obtained performance data for a variety of attributes using the DB2 Snapshot Monitor. For each pair of workloads we analyzed the data to obtain a minimal set of attributes that differentiated OLTP from DSS requests. The attributes selected for the TPC-W profiles, for example, in-cluded attributes such as the proportion of queries (versus updates) in the workload, the average number of pages read per request, the average number of rows selected by a request, the number of locks held by a request and the average sort time of a request. We found that attributes that are more independent of the system configuration, such as the queries ratio, the pages scanned and the rows selected, are more influential in determining the type of a workload than attributes that are dependent on the configuration. We therefore further grouped the attributes according to their dependence on the system configuration and assigned higher weights to the more independent groups. The classification model (decision tree) created for the TPC-W Browsing and Ordering profiles is shown in Fig. 2 . The DSSness , which is the metric reported by this DSS/OLTP workload classifier, represents the percentage of the DSS type versus OLTP. Thus, if DSSness is closer to its maximum value (100%) it means that the workload is mostly DSS; if it is closer to its minimum value (0%) it means that the workload is mostly OLTP. A middle value of DSSness indicates a mixed (MIX) workload. The goal of our prediction framework discussed below is to efficiently predict how the DSSness fluctuates over time. 4. Psychic X  X keptic framework
The type of the workload typically changes over time but keeping the workload classifier tool running all the time in order efficient solution by which the DBMS can learn about a workload X  X  dynamic behavior over time and forecast when a change in the workload type might occur in order to proactively reset the DBMS parameters to suit the new workload.
Fig. 3 illustrates how the Workload Classifier and Workload Predictor integrate in order to provide an efficient workload identification solution. The workload classifier assesses the DSSness of the workload at a given time. The Workload Predictor, after it analyzes a time series of DSSness, forecasts major shifts in the DSSness and alerts the DBMS of these shifts. Major shifts are formed when the DSSness reaches predefined thresholds that warrant reconfiguring the DBMS. For the purposes of this paper the thresholds divide the DSSness range into three zones that lead to the identification of three main workload types: OLTP, MIX, and DSS. 4.1. Overview
Prediction techniques are typically classified as either on-line or off-line [12]. On-line prediction techniques are more accurate than off-line approaches but require continuous monitoring of a system. Off-line prediction techniques, on the other hand, involve little overhead but are less accurate since they do not account for unexpected variations in a workload.
The Psychic X  X keptic framework combines features of both on-line and off-line approaches to provide effective prediction. An system.

As depicted in Fig. 4 , the Psychic X  X keptic Predictor (PSP) consists of three main components: the Psychic , the Skeptic , and the TrainingDataModel . The Psychic analyzes a daily time series of DSSness values stored in the TrainingDataModel and produces an off-line prediction model, polynomial f ( x ), that can estimate major shifts in the DSSness with respect to some specified thresholds. The estimates are passed to the Skeptic which validates the shifts by performing on-line, short-term prediction using linear regression. If the Psychic advises that a shift is due at time t , the Skeptic monitors and analyzes the system for some time interval centered around t . The Skeptic does not instruct the DBMS to reset its parameters unless it confirms the trend of the shift using the linear model. Note that the Skeptic uses the linear regression as a short-term prediction model because: it is computationally a light-weighted tool to use at run-time, easy to discern the trend by simply examining the sign of the slope of the line, and it only needs at least two sampled points in order to construct the model.

The Skeptic also performs regular sampling for the DSSness throughout the day in order to keep all prediction models up to date. It sends the results of the monitoring, which we call DSSness patching samples, to the TrainingDataModel in order to update the stored training data. The Psychic then refreshes its off-line prediction model and its forecasted shift schedule accordingly. This regular update guarantees the adaptability of the PSP and makes it less vulnerable to changes in the work-load pattern. Without lack of generality, and for the sake of simplicity, we assume a day to be the time window over which our prediction framework operates. Therefore, the time scale consists of 1440 min (24 h). However, the same concepts are applicable to any other time window such as weeks or months. We also assume the existence of some seasonality in the
DSSness values over time. 4.2. PSP parameters
The PSP framework exhibits a good degree of flexibility by counting on a number of configuration parameters that can be adjusted to suit the IT environment. Table 1 summarizes these parameters and categorizes them as either global or Training-
DataModel-specific parameters. Most of these parameters are automatically estimated by the PSP or obtained from the DBMS monitoring tools.
 The global parameters are used across several modules in the PSP and include the following: Model Update Mechanism (MUM) is a switch parameter that can be set to ON or OFF to respectively enable or disable the
Model Update Mechanism feature of the framework. In general, if the daily pattern is trusted to remain stable, the MUM parameter can be OFF. Setting MUM to ON entails a small overhead but guarantees that the prediction models are kept up to date and provides immunity against changes in the workload pattern. monCost is the percentage of performance (throughput) degradation caused by running the workload classifier on-line.
This percentage needs to be empirically determined once and remains constant afterwards. oltp _ threshold and dss _ threshold determine the DSSness ranges for the three types of workload (DSS, OLTP, and MIX):
We empirically found that 30 and 70 are good estimates for the oltp_threshold and dss_threshold, respectively. performanceMatrix is a matrix of performance factors, each has a value range of 0 X 1.0. If x and y are workload types (OLTP,
MIX, or DSS), then the matrix entry ( x , y ) denotes the relative performance of processing x , while the DBMS is tuned to process type y , to the performance of the DBMS, while it is tuned to process type x (i.e., the ideal tuning). These perfor-mance factors are empirically determined by running different combinations of workloads and DBMS settings. Table 2 shows the empirically estimated performance factors that we use in our experiments. min _ check _ time is the minimum number of minutes needed by the Skeptic to execute on-line in order to validate the Psy-chic X  X  forecasted shift. This value determines the number of the DSSness samples that will be used to build the linear model at run-time. Throughout our experiments, we found that 30 min, which constitutes 2% of the time scale of the day ( max _ time _ scale = 1440 min), is a reasonable start. The final duration is eventually determined by the Psychic upon analyzing the training data. 4.3. The training data model
The TrainingDataModel stores historical samples, or Scenarios , to train the Psychic and the Skeptic. It maintains a number ( numScenarios ) of chronologically ordered scenarios. Each scenario consists of a time series, ( t the DSSness reading reported by the workload classifier at time t a weight 2 k that is normalized to the range [0,1], which ensures that the more recent observations have a larger impact than the older ones.

In order to verify the existence of a predictable, cyclic DSSness pattern over the numScenarios days stored in the training model, we view the DSSness samples of all days as a single time series and then use the autocorrelation coefficient, r the predictability of the DSSness using the following formula [20]: ples collected over a number ( numScenarios ) of days, N = numScenarios where i  X  1 ; ... ; N ; D is the mean of the DSSness samples, that is, values occurring at the same time within each day. A positive value of r a negative value indicates an inverse trend. Therefore, a larger positive r is more applicable due to the existence of a predictable pattern in the given workload. In our experiments, we found that r 0.65 on average.

For the computation purpose, the rest of the PSP components deal with a consolidated scenario that summarizes all the information from the training model as a single average day. The consolidated scenario is constructed by calculating the weighted average of all samples collected at time t across all scenarios:
The PSP adapts to pattern changes using a Model Update Mechanism ( MUM ) that patches the training data. Patching is a function by which the Skeptic can gradually update the historical data in order to keep the underlying prediction models up to date. It occurs by propagating the DSSness samples of a particular scenario to the next older scenario. A DSSness sample of day d at time t replaces DSSness ( d 1, t ) for d =1, ... , numScenarios 2. DSSness cent scenario in the TrainingDataModel, is patched by the new DSSness samples collected by the Skeptic.

Selecting the value of numScenarios is a tradeoff between the quality of the off-line model and the pace by which the en-work less vulnerable to isolated changes or spikes in the workload behavior (e.g., generating an unscheduled annual report). PSP will require a longer time to discern the observed changes as a new pattern).

Experimentally, we found that numScenarios = 3 is a reasonable size that produces good prediction quality and high adaptability. 4.4. The Psychic
The Psychic is primarily responsible for producing an off-line prediction model by tapping the cyclic pattern that occurs during the day. More specifically, it carries out five main tasks in the following sequence: 1. Off-line model construction . The Psychic analyzes historical data stored in the TrainingDataModel and produces a polyno-mial model to fit the data. 2. Finding shifts . The polynomial model is used to find the potential workload shifts by finding intersection points of this polynomial with the dss _ threshold and oltp _ threshold . the Skeptic needs a timeframe during which it monitors the workload and eventually decides whether to endorse this shift or to disregard it. The Psychic estimates the start and end times of the timeframe for each shift. ing it is more beneficial to overall system performance. 5. Configuring the MUM parameters . The MUM assures the validity of prediction models used in this framework by making them less vulnerable to possible changes in the workload pattern over time. 4.4.1. Off-line model construction There are many tools that can be used for time series prediction such as neural networks, ARMA/ARIMA (Autoregressive Moving Average/Autoregressive Integrated Moving Average) models, DPLL (Digital Phase Locked Loop), digital filters, or
Fourier series [20]. These models can be used to predict the DSSness (dependent variable) at a given time (independent variable). However, the Psychic needs to predict when (i.e., time) the DSSness reaches a specific threshold. This requires dealing with the inverse of the prediction function, which is not always easy to derive using the above prediction tools.
The Psychic therefore uses polynomial regression, which allows for straightforward geometric manipulation (i.e., it is easy to find where the polynomial intersects with certain thresholds) and is an intuitive, compact representation of the workload trend. In our experiments, the off-line models are mostly third and fourth degree polynomials. 4.4.2. Finding shifts
The Psychic uses the generated polynomial model to find the times at which the DSSness index intersects with the f ( t ) oltp _ threshold = 0. We must be careful to exclude the points that are minima and maxima as they almost touch the threshold levels and do not actually embody real shifts. These false shifts are identified by checking the slope of the curve using the first derivative, f 0 ( t ). If f 0 ( t ) 0, then shift t must be discarded.
 A shift can be one of four types depending on its trend: OLTP_UP_TO_MIX, MIX_UP_TO_DSS, DSS_DOWN_TO_MIX, or or declination (slope &lt; 0). Fig. 5 sketches the algorithm for detecting shifts. 4.4.3. Estimating shift check time
The Psychic must also determine the shortest period of time during which the Skeptic must run to validate a forecasted shift. This goal is achieved in two steps: 1. Determining shift bounds . The extreme bounds that delimit a shift are determined by the nearest local maximum and local minimum surrounding the shift time as illustrated in Fig. 6 . They represent the search space, [ a ... b ], for estimating the earliestCheckTime and latestCheckTime period (denoted in the figure as e and l , respectively), as explained in step 2 below.
The first and last shifts may become special cases. If the first shift is not preceded by a minimum or maximum, the lowerBoundCheckTime is set to zero, which is the beginning of the day. If the last shift is not followed by any minimum or maximum then the upperBoundCheckTime is set to the last minute of the day ( max _ time _ scale ). Fig. 7 describes how to find the [ lowerBoundCheckTime , upperBoundCheckTime ] period.

CheckTime ], within the [ lowerBoundCheckTime , upperBoundCheckTime ] of a shift. This is imperative as it reduces the time needed by the Skeptic to validate a shift at run-time.
 Fig. 8 describes how to estimate [ earliestCheckTime , latestCheckTime ] by analyzing the training scenarios stored in the TrainingDataModel. Initially, the Psychic starts with earliestCheckTime = t ( min _ check _ time /2), and latestCheck-Time = t +( min _ check _ time /2), where t denotes the expected shift time. This interval is incrementally expanded until the
Skeptic X  X  linear model applied to the consolidated scenario agrees with the trend of the shift. Expansion is performed by decrementing earliestCheckTime and incrementing latestCheckTime such that the conditions earliestCheckTime P lowerBound-
CheckTime and latestCheckTime 6 upperBoundCheckTime are not violated. 4.4.4. Filtering shifts
Reacting to some of the detected shifts might not be beneficial to system performance. For example, a shift might be too short and it is not cost-effective to reset the DBMS X  X  configuration parameters. The Psychic performs a cost-benefit analysis ference between the two cases where the shift is accepted and where it is discarded. Note that filtering is not needed if we have fewer than two shifts. The cost-benefit computation analysis is ultimately based on the global parameters perfor-manceMatrix and monCost . 4.4.5. Estimating Model Update Mechanism (MUM) parameters
The MUM aims to ensure that all prediction models are up to date, which makes the prediction accuracy less vulnerable to vals throughout the day.

The MUM views a day as a number of equal, ordered time zones , where each zone is further divided into a number of equal, ordered time slots . Given n slots in a zone, the Skeptic ensures uniform coverage of the daily workload by monitoring over a cycle of n days where slot i (0 6 i 6 n 1) of each zone is monitored on day i of the cycle.
 as follows:
Day denotes the day number throughout the model update process. Initially, Day is set to 0 in the first day and it is incre-mented at the end of each day. Zone denotes the current zone number. It is reset to 0 at the beginning of each day and is incremented at the end of each slot. SlotSize and ZoneSize are constants denoting the size of the slot and the zone, respec-tively, where
CompleteUpdate is a parameter that specifies the number of days by which the first scenario in the training set is fully re-freshed. Its value ranges from fastUpdateDays to slowUpdateDays , where fastUpdateDays denotes the minimum number of days that the MUM needs in order to complete the update while the performance of the framework remains superior, and slowUpdateDays is the maximum number of days needed to update the model such that one slot is sampled every day. It is until the prediction framework outperforms the other operation modes (Section 5) by an arbitrary percentage PERF _ GAIN , datePerf are the performance measures associated with setting numDaysToCompleteUpdate to fastUpdateDays and slowUp-dateDays , respectively. Therefore, numDaysToCompleteUpdate creates a tradeoff between the pace at which the framework can fully update a training scenario and the performance level. Setting numDaysToCompleteUpdate to fastUpdateDays leads to a faster update, but with a relatively lower performance due to the incurred run-time monitoring. Setting numDaysToCom-pleteUpdate to slowUpdateDays leads to the maximum DBMS performance but a longer time is required to update the model.
In general, the framework has the ability to estimate the DBMS X  X  performance for any value assigned to numDaysToComple-teUpdate and vice versa. Fig. 9 gives the algorithm to estimate the MUM parameters and Table 3 summarizes the variables used in the algorithm. 4.5. The Skeptic
Fortunately, we almost covered all technical aspects that explain how the Skeptic works through the discussion of the details of the PSP framework in the sections above. However, it is worth reminding the reader in this final subsection of main functions of the Skeptic.
 As we have seen, the Skeptic is responsible for validating the Psychic X  X  forecasted shifts. For each upcoming shift, the
Skeptic samples the workload from earliestCheckTime to latestCheckTime . The workload samples are analyzed to confirm whether the trend of a shift conforms to the Psychic X  X  prediction. To that end, the Skeptic builds an on-line prediction model run-time. If the on-line prediction model confirms the shift, the DBMS X  X  settings are reset to suit the upcoming workload type. Otherwise, the DBMS resets its settings to the default, which is the safest resort and can sub-optimally handle MIX workloads of OLTP and DSS.

The Skeptic has also another vital functionality that warrants that the prediction models of the PSP framework does not become stale. Whether the MUM is enabled or disabled, the Skeptic samples collected during the validation process, which are deemed the most recent observations of the day during that interval, are passed on to the MUM component in order to patch the historical data stored in the TrainingDataModel. 5. Evaluation
Our evaluation has two main goals. First, we validate the Psychic X  X keptic Prediction framework performance of a DBMS running under the framework with the performance of that system running in alternative opera-tion modes. Second, we show that our approach is robust and able to adapt to changes that may occur in the workload pattern.

In our evaluation, we assume that a DBMS can run in one of the following operation modes: 1. Out-of-the-box (Default) mode . This is a trivial operation mode in which the DBA chooses to run the DBMS with out-of-the-box default settings that suit a mixed workload. These settings remain static and do not respond to any changes in the workload type nor adapt to the dominancy of a particular workload type. 2. Dominantworkload mode . The consolidated scenario obtained by the TrainingDataModel is analyzed in order to determine the dominant workload type. This is done by measuring the total time (in minutes) that each workload type lasts throughout the day. The workload type that runs for the longest accumulated time is deemed dominant, and the DBMS is configured to suit this dominant workload. This configuration is static and does not change. The performance obtained from this mode is always expected to outperform the Default Mode described above. However, it is not expected to pro-vide the best performance as it is not adaptable. 3. Continuousmonitoring mode (MA). This mode takes full advantage of the Workload Classifier by performing on-line, short-term prediction using the moving average (MA) [2] where d t +1 is the DSSness forecast value for the period t +1, y the difference between the forecast and actual values. The mean squared error (MSE) is given by
MSE. We arbitrarily use MAX = 10 as a maximum value for n . Detecting a shift using a single MA value leads to instability as needed by the Skeptic to validate shifts by sampling before and after the expected shift time. In this MA technique we need to check before the expected start time of the shift, and therefore, we use half of the interval. Continuous mode is advanta-geous as it is responsive to changes in the workload. However, it involves the undesirable, on-line overhead of running the
Workload Classifier. In general, this mode is very adaptive but costly. 4. Psychic X  X keptic mode . The use of the classifier is governed by the PSP framework. 5.1. Experimental setup
We test our framework using artificially generated data, which give us the flexibility of examining any hypothetical work-
Scenarios and ScenarioDescriptors .A ScenarioDescriptor can be perceived as a template for generating many scenarios that ex-
DSSness values on the final DSSness curve. time is a minute during the day so its domain is [0,1440] (24 h a day), and DSSness ranges from 0 to 100. These anchors enable us to direct and shape the trend of the DSSness in any way we desire. In order to generate a scenario out of this descriptor, a series of DSSness values are automatically generated between every two consec-utive anchors. In order to make our scenarios more realistic, we inject a  X (0 X 5)% of random noise in the DSSness , and  X (0 X 2)% of random noise in the time , which is equivalent to  X (0 X 30) min. Noise injected in the time dimension affects when a shift section with the threshold lines.

In each experiment, we simulate the execution of a DBMS run under each of the four operation modes for 30 days. The performance of the Psychic X  X keptic framework is evaluated when the MUM is enabled and when it is disabled. We use the default parameter settings described in Table 1 , unless otherwise indicated. We report both absolute performance and rel-ative performance. By absolute performance, we mean the performance achieved as a percentage of the theoretical maxi-mum performance that can be achieved by matching the DBMS settings with the workload type on a minute-by-minute basis. The maximum theoretical performance is obtained by extrapolating upon the results of empirical observations of the response time performance of a real DBMS under real workloads and configurations. By the relative performance we re-fer to the percentage of performance improvement (or degradation) of any operation mode with respect to the Default Mode. 5.2. Experiment 1: pattern A Fig. 10 shows an instance scenario of the daily pattern (pattern A) used in the first experiment. The workload is mostly
OLTP in the first 2 h of the day; it changes to a mixed workload over the next 12 h; it returns to a dominant OLTP workload for the next 9 h and then shifts back to a mixed workload. The autocorrelation coefficient, r which indicates a predictable cycle of DSSness across multiple days.

The Psychic X  X  off-line prediction model for this daily pattern, which is the solid line shown in Fig. 10 ,is
A so the performance obtained under the Dominant Mode is equivalent to the Default Mode. Table 5 summarizes the per-formance statistics observed with the pattern A workload using the four operation modes, while MUM is ON and OFF.
Fig. 11 shows the DBMS X  X  absolute performance under different operation modes when the MUM is off. The best perfor-mance is achieved under the Psychic X  X keptic framework (avg. 97.08%), followed by the MA Mode (avg. 87.39%), then the Dominant Mode (avg. 76.23%), which is equivalent to Default Mode. Fig. 12 shows DBMS X  X  relative performance when the MUM is off. The Psychic X  X keptic framework achieved an average of 27.37% performance improvement over the Default
Mode compared to 14.65% performance improvement achieved by the MA Mode. All performance estimates are based on workload classifier overhead of 10% ( monCost = 10%).

Figs. 13 and 14 show the performance the DBMS achieved in PSP mode with the MUM turned on to numDaysToComple-teUpdate = 7, that is, a complete daily scenario will be updated after one week. Fig. 13 shows that the DBMS in PSP mode achieves the best performance (avg. 94.54%), followed by the MA Mode (avg. 87.37%), then the Dominant Mode (76.23%), which is equivalent to Default Mode. The absolute performance achieved in PSP mode with the MUM on is only slightly less than the performance achieved with the MUM off. This indicates that the additional overhead required by the MUM, which ensures that the system can adapt to changes in the workload pattern, is not excessive. Fig. 14 shows the relative perfor-mance of the PSP mode with MUM enabled. We see that the PSP mode achieves an average performance improvement of 24.03% over the Default Mode compared to 14.63% achieved by the MA Mode. 5.3. Experiment 2: pattern B
Fig. 15 shows an instance scenario of another workload pattern (pattern B). The DBMS experiences a workload that is mostly mixed in the first 8 h of the day. The workload becomes more DSS over the next 10 h. In the next 6 h, it seems to be more of a MIX, and then it shifts to an OLTP for the rest of the day. The autocorrelation coefficient ( r indicates a predictable cycle of DSSness across multiple days.

The Psychic X  X  off-line prediction model for this daily pattern is performance under the Dominant and the Default modes is equivalent. Table 6 summarizes the performance statistics ob-served with pattern B while MUM is ON and OFF, using the four operation modes.

Fig. 16 shows the DBMS X  X  absolute performance under the different operation modes when the MUM is off in the PSP mode. The best performance is achieved under PSP (avg. 95.95%), followed by the MA Mode (avg. 87.74%), then the Dominant
Mode (avg. 74.04.23%), which is equivalent to the Default Mode. Fig. 17 shows that the PSP mode achieves an average of 27.24% performance improvement over the Default Mode compared to 18.50% achieved by the MA Mode. All performance estimates are based on workload classifier overhead of 10% ( monCost = 10%). The Skeptic invalidated the shift that is sup-posed to occur at minute 1193 in the fourth day. This prediction error, as shown in Fig. 16 , causes significant performance degradation on that day. Another shift invalidation occurs at minute 929 in the 15th day but it has insignificant impact on the performance.

Figs. 18 and 19 compare the performance of the DBMS under the four operation modes when the PSP mode has the MUM turned on with numDaysToCompleteUpdate = 7, that is, a complete daily scenario is updated after one week. PSP mode, as shown in Fig. 18 , still outperforms the others (avg. 94.14%), followed by the MA Mode (avg. 87.74%), then the Dominant
Mode (74.04%), which is equivalent to the Default Mode. The additional overhead caused by the MUM is again relatively small for pattern B. Fig. 19 shows that the PSP mode achieves an average performance improvement of 27.24% over the De-fault Mode compared to 18.50% achieved by the MA Mode. The Skeptic invalidates the shift that is supposed to occur at min-ute 933 in the 6th and 20th days. These incorrectly predicted shifts cause no severe impact on the performance. However, the has a significant impact on the overall performance in that day. 5.4. Adaptability: pattern A changes to pattern B
The goal of this experiment is to demonstrate one of the vital features of the PSP framework, namely its adaptability to changes in the daily pattern. We run the DBMS under pattern A, described above, for 30 days. We then swiftly switch to pat-tern B, under which the behavior of the DBMS is examined for another 30 days. This sudden shift in the daily pattern is unre-alistic as changes usually happen gradually over several days. We advertently made such a swift change in order to push the framework to its limits and observe the worst case scenario. The MUM is active all the time and numDaysToCompleteUpdate is set to 7.
 The performance of the DBMS during the first month is assessed with respect to the expected performance under pattern
A. Similarly, the DBMS performance during the second month is assessed with respect to the expected performance under pattern B. The results indicate how much the observed DBMS performance deviates from the mean of the expected perfor-mance. Since the means of the two performance indices can be different, we normalize the differences in the performance by expressing them as percentages, as follows:
Fig. 20 shows the percentage of the performance deviation from the expected one. During the first 30 days as the DBMS han-dles workload of pattern A, the mean observed performance is 94.50%, as compared to the expected performance of 94.54%.
At the end of the first 30 days processing pattern A, we expose the DBMS to a new workload matching pattern B. On day 31, the performance dramatically drops to 56.3% of the expected performance (94.19%), which is a 40% decrease in performance.
With the MUM enabled, however, the performance gradually improves over the 7-day updating period. By the end of this period, the performance reaches 93.90%. The mean performance over the period ending the update to the end of the second month (i.e., 21 days) is 93.57%, which is close to what we expect, 94.19%. This shows that the system is able to return to its stable state. 6. Summary
Systems monitoring and constant on-line analysis incur performance penalties that may hinder the adaptation of tools such as the workload classifier described in this paper. Luckily, the overhead of such tools can be mitigated by exploiting characteristics in the workload. In this paper, we introduce the Psychic X  X keptic Prediction (PSP) framework. The Psychic ana-lyzes historical data and produces a shift schedule. Each shift indicates whether the workload is heading to the DSS, OLTP, or
MIX region. These regions are delimited by two DSSness thresholds. The DBMS does not place its full trust in the off-line predicted shifts and asks the Skeptic to validate each shift at run-time by sampling the workload for a small interval around new workload type.

The framework is self-optimizing as the majority of its parameters are automatically estimated and are transparent to the database administrator. The framework adapts to changes in the workload pattern using the Model Update Mechanism (MUM), which samples the workload at regular times in order to patch historical data and keep prediction models up to date.
It is worth mentioning that the way the PSP framework is designed enables it to discard outlier events that may happen spo-radically by some maintenance operations, backup invocation, or unplanned queries submission or data loads. This has been possible because (1) the MUM module uses a multi-layer historical data that does not count solely on the last data collected, (2) the Psychic adopts smoothing in its prediction models, and (3) the Shift Filtering mechanism of the Psychic factors out (outlier) shifts that will not positively contribute to the system performance.
 The experiments described here accomplish two goals. The first goal is to assess the performance of the DBMS using the
PSP framework. Experiments show that the prediction framework outperforms other normal modes of operation. The second goal is to demonstrate the adaptability of the framework. Our experiments show that the framework is robust against changes in the workload pattern. Although we experimented with a pattern transition that was swift and dramatic, PSP is able to learn the new pattern within the expected period of time. We consider the MUM to be a self-healing mechanism since by experimenting with a number of scenarios generated by different scenario descriptors.

Our main contribution in this work is the PSP framework, which takes advantage of the low volatility and the cyclic pat-terns in a workload in order to allow a DBMS to follow proactive tuning strategies. The framework has the following strengths:
It is efficient as it obviates the overhead caused by the expensive use of on-line prediction techniques that demand con-tinuous monitoring for the system.

It can estimate the best and worst performance under different modes of operations and, therefore, it can recommend the best mode suitable for a particular computing environment. Having prior knowledge about the expected perfor-mance helps in detecting performance violations (e.g., a DBMS can alert DBAs by paging or emailing them if perfor-mance drops).

It is generic as we speculate that this approach can be effective in other systems where their workloads exhibit some trend that makes them relatively predictable. Our methodology could be used to automate many other DBMS tasks such as determining when to make incremental backups, re-build indexes and refresh materialized views, update statistics, or reorganize data on the disk.

The framework itself exhibits two important autonomic features. It is self-optimizing , as almost all of its internal param-eters are determined automatically, and it is self-healing , as it adapts to new trends that may occur in the workload in order to retain the good performance.

The use of our framework does not impose radical changes to the DBMS infrastructure, which promises a high degree of applicability to today X  X  large commercial DBMSs.
 Possible future research directions include the following:
Investigating the feasibility of using the Psychic X  X keptic framework to solve other types of database problems such as:  X  System backup and restore . Depending on the forecasted start and length of the idle period, the system may automat- X  Data defragmentation and reorganization . The system could anticipate the time periods at which it experiences low I/Os  X  Updating statistics . In DBMSs, query planning, optimization, and execution depend heavily on up to date statistics of the  X  Updating indexes and views . Auxiliary data structures such as indexes and materialized views can immensely improve
Tuning the DBMS parameters as a function of the intensity of each workload type. Presently, DBMSs are tuned based on determining the dominant workload (e.g., either OLTP or DSS) using rule-of-thumb tuning strategies. An interesting research area would be to develop tuning strategies that take into account the intensity of each workload type (e.g., the DSSness degree) in the overall workload mix.
 Conducting an empirical study in which a feedback mechanism is established between the workload classifier and the
DBA, which would allow the DBA to understand and correlate the currently observed performance with the workload type reported by the classifier. This would help the DBA develop better performance-tuning strategies. Furthermore, the feed-back would allow DBAs to corroborate the workload type reported by the classifier and to determine if any retraining is necessary in order to improve the classifier X  X  prediction accuracy.

In conclusion, we trust that the workload put on the system is an important input to it. Therefore, system engineers and designers should not solely focus on the optimization of the system X  X  architecture and its comprising components but they also should look for interesting characteristics in the workload that can be exploited to boost the performance of the system. Trademarks
The following terms are trademarks or registered trademarks of International Business Machines Corporation in the Uni-ted States, other countries, or both: DB2, IBM, Universal Database.

References
