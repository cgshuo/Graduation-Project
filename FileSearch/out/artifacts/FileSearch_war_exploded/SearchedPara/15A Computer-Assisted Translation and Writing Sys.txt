 Many natural language sentences (e.g.,  X   X ) are submitted to machine translation (MT) systems on the Web every day for translation and language learning purposes. In fact, language professionals and learners exploit an increasing number of online translation systems to grasp the meaning of sentences and produce texts to communicate in many languages.

Web translation systems, such as Google Translate 1 and Bing Translator offer top-1 translations based on statistical machine translation frameworks. However, lower-ranked translation fragments or sentences may actually be of the user X  X  interest and may be more accurate than those shown to the user. The benefits of a machine in computer-assisted translation and language learning could be better examined if we considered the translation process as a collaborative sequence of system suggestions and user choices. That is, the user learns and chooses from machine-generated sugges-tions of next-in-line grammar and lexical options and, in turn, the machine adapts to the user X  X  acceptance or rejection of options.

Consider the source sentence  X   X  (translation: we played an important role in sealing this deal). Current MT systems do not offer particu-larly good results (e.g., Google Translate returns single top-1 translation  X  X e conclude this transaction plays an important role X ). A writing assistant that gives the user di-rect control over the target text and offers grammar and text predictions on the side might constitute a good learning and working environment. Take the preceding source text and its translation prefix  X  X e play an important role X , for example. The assis-tant might suggest the grammar pattern Prep(in) V + ing as well as the specific lexical translation  X  X n closing X . Intuitively, by learning the pattern play and the translation V( , close ), we can offer on-the-fly grammar and text assistance for ongoing incomplete translations through a translation-based writing framework.
We present a new system, TransAhead , that automatically learns to inform the user of the grammatical constructs and lexical translations expected to follow the transla-tion prefix of a source text. Figures 1(a) 3 and 1(b), respectively, show the TransAhead responses to the source  X   X  and its two partial tar-get translations  X  X e X  and  X  X e play an important role X . For each of the prefixes, TransAhead has determined the probable grammatical constructions and lexically translated constituents and presents them in pop-up menus. Specifically, TransAhead learns that a present tense verb (i.e., VBP in Figure 1) and an article or determiner (i.e., DT in Figure 1) tends to follow  X  X e, X  the preposition  X  X n X , and a gerund (i.e., IN (in) VBG in Figure 1) tends to follow play  X  role , the Chinese term is frequently translated as  X  X lay X , and is translated as  X  X lose X  or  X  X nd X . TransAhead learns these grammar patterns (Figures 1(c) and 1(d)) and translations (Figure 1(e)) during training by analyzing a collection of monolingual and parallel texts. We describe the TransAhead training process in more detail in Section 3.

At runtime, TransAhead accepts a source sentence submitted by the user (e.g., level, and the character-level translation candidates form a set of active vocabulary in the target language. TransAhead then iteratively interacts with the user through a sequence of offering predictions of lexically translated grammar patterns following the current inputted translation prefix, and adapting to the user X  X  translation choices to resolve ambiguities (e.g., word segmentation and word sense ambiguity) in the source sentence, since the user may accept or override TransAhead suggestions. In this way, the user and machine collaborate to compensate for each others X  insufficiencies. In our prototype, TransAhead mediates between users and the automatic modules to boost quality and productivity in writing and translation. Alternatively, the resulting trans-lation pairs can be used as input to build a segmentation system suitable for machine translation, that is, find word boundaries for translation purpose. Computer-assisted translation (CAT) has been an area of active research. Recently, an increasing number of CAT tools have been developed to help users improve productivity. In our work, we address an aspect of computer-assisted translation that directly focuses on the language learning of novice or student translators. This section first reviews the literature on CAT followed by the literature review on word usage in computer-assisted language learning (CALL). Previous work on collaborative CAT focuses on the role of the user in helping the MT system [Brown and Nirenburg 1990; Kay 1973; Whitelock et al. 1986]. The user, typically a professional translator, helps to identify ambiguities in the source text and tries to resolve them. In contrast, our work aims to assist novice translators (i.e., those with limited vocabulary and language knowledge) and improve their translation and writing performance via on-the-fly pattern and translation suggestions. To be specific, we consider a general class of assistant systems in CAT and CALL.

More recently, some interactive MT systems have begun to shift the user X  X  role from analyzing source texts or editing machine output to collaborating with the machine to produce target translations. The TransType project [Foster et al. 1997, 2002; Langlais and Lapalme 2002; Langlais et al. 2000] describes a pioneering system that supports word completion and next-few-word translation predictions. Along a similar line, Koehn [2009] develops a Web-based CAT tool, Caitra, which displays one phrasal translation at a time and offers alternative phrasal translations. The main differences between their work and ours are that we make no assumptions about the user skill and experience as a translator, and we further display grammar patterns to provide the general usages of predicted translations, allowing the user to increase his/her language proficiency.

Recent work has exploited fully-fledged statistical MT systems to produce target hypotheses completing user-validated translation prefixes in the interactive MT (IMT) paradigm. For example, Barrachina et al. [2008] investigate the applicability of MT kernels of alignment templates, phrase-based models, and stochastic finite-state transducers within the IMT framework. Nepveu et al. [2004], Ortiz-Martinez et al. [2010, 2011] further leverage user feedback to improve their IMT systems. Nepveu et al. incorporate adaptive language and translation models trained on recent user in-put histories for better user experience, while Ortiz-Martinez et al. use user-validated translation pairs and an online learning algorithm to incrementally re-train MT models. Rather than be triggered by user correction, our method is triggered by word delimiters, such as spaces, and is designed to assist in source sentence translation and target language learning.

In a study more closely related to our work, Albrecht et al. [2009] introduce a collabo-rative framework in which users who do not understand the source language are asked to correct MT translation errors with the help of a visualization of multiple language resources. Mediating between automatic system and users, we set up an environment for nonnative speakers of the target language.

In contrast to the previous research in CAT, we present a writing assistant that auto-matically suggests translation texts in syntactic patterns based on users X  translation prefixes. The assistant iteratively collaborates with users, with the goal of reducing their effort to make their own grammatical and lexical choices and of enhancing their writing performance in terms of productivity and correctness. Word usages of collocations and phrases have received much attention from applied linguists and computational linguists alike. In our framework, we summarize these usages or phraseological tendencies using pattern grammar [Hunston and Francis 2000]. The summary is to cover usages of common error sources in learner writing [Nicholls 1999], especially those of article and preposition (our pilot study indicates 80% of learners X  article usages are wrong, while more than half prepositions are used improperly). More specifically, our proposed model suggests article, preposition, and other usages surrounding word sequences (e.g., the contiguous word sequence  X  X ook forward to X  or non-contiguous  X  X lay  X  role X ) for reducing writing errors in English as a foreign language (EFL) learners X  sentences.

In the early days, linguistic phenomena, such as collocations, and their effects in language were compiled manually [Benson et al. 1986; Firth 1957; Lewis 2000; Nation 2001; Sinclair 1987]. With large-scale corpora and powerful computers, it has become computationally feasible to automatically extract collocations [Smadja 1993], correct EFL learners X  miscollocations [Liu 2002], and develop collocation checkers for EFL learners [Chang et al. 2008].

Recently, many online systems have been designed to identify collocations for the purposes of lexicography and language learning. Among these, Sketch Engine [Kilgarriff et al. 2004] is the most famous, which summarizes a word X  X  grammatical and collocation behavior. JustTheWord 4 clusters co-occurring words for single-word search queries, while TANGO [Jian et al. 2004] accommodates cross-language single-word searches. An interesting approach presented by Cheng et al. [2006] describes how to retrieve mutually expected words via concgrams allowing for constituency (e.g.,  X  X B X  in constituents of  X  X CB X  and  X  X CDB X ) and positional variants (e.g.,  X  X B X  and  X  X A X ). In contrast, we go one step further to syntactically summarize the regularities of the contexts of a single-or multiword query and, at the same time, the context representation is not pre-determined and not limited to certain collocation types (e.g., adjective-noun, verb-noun, and verb-noun-preposition).

Recent work has been done on incorporating word class information into the analy-ses of context preferences. Other than the two extremes lexical n-grams [Stubbs 2002] and part-of-speech (POS) n-grams [Feldman et al. 2009; Florian et al. 2003; Gamon et al. 2009], Stubbs [2004] introduces phrase-frames base on lexical n-grams with one variable slot (e.g., a phrase-frame  X  X  of X  covers n-grams  X  X  number of X ,  X  X  lot of X , and so on). Moreover, Wible and Tsao [2010] describe a reference tool, StringNet, with lexicogrammatical patterns to simultaneously encode lexical and grammatical infor-mation. Their methods are similar in spirit to our pattern suggestion module, but our grammar patterns are directly anchored with querying words and generalize querying words X  contexts via parts-of-speech. In addition to the lexically-open constructs (e.g., play  X  role Prep ( in ) V + ing ), we also present their corresponding lexically-fixed idioms (e.g., play  X  role in shaping ) or sometimes semantic relations (e.g., PERSON in pro-vide Noun of PERSON Prep ( with )) to provide more informative descriptions which we typically see in learner dictionaries.

In contrast to the previous research in word usage learning, we present a pattern suggestion module that automatically generates and summarizes the contexts of query word sequence with the help of POS tags and displays the representative ones to the user. The usage summary is organized in a general-to-specific hierarchy consisting of abstract grammatical constructions and concrete lexical phrases expected to help language learners in sentence composition and translation. Submitting source text (e.g., ) to MT systems such as Google Translate for the purpose of translation and language learning often does not work very well. Although MT systems have made tremendous progress in recent years, they still make mistakes in grammar and word choices, and translators or language learners are forced to accept these erroneous translations and are given little opportunity to learn the target language or translation skills in the process. A promising learning framework is to incorporate the user into the translation process during which the user is provided with subsequent grammar and text choices for the translation prefix, entered by the user, of the source text. For the purposes of CAT and CALL, we focus on predicting a set of grammar patterns with lexical translations that are likely to follow the current ongoing target translation of a source text. These predictions are iteratively triggered and updated as the user enters more text. The returned predictions will be evaluated directly by a human user who may accept, ignore, or override them to complete the translation. Therefore, the size of the grammar and text predictions must be restricted to avoid overwhelming the user. Overall, our goal is to return a reasonable-sized set of predictions/suggestions that, at the same time, contain suitable word choices and grammatical patterns for effective translation and learning assistance. We now formally state the problem that we are addressing.

Problem Statement. We are given a target-language reference corpus C National Corpus), a parallel corpus C st (e.g., Hong Kong Parallel Text), a source-language text S ,and S  X  X  current translation prefix T p entered by the user. Our goal is to generate a set of predictions based on C t and C st translation of S . For this, we transform S and T p into sets of n-grams that the predominant grammar constructs and probable lexical translations following T p are likely to be determined.

In the rest of this section, we describe our solution to this problem. First, we define a strategy for acquiring lexicalized grammar patterns for consecutive and inconsecu-tive word sequences (Section 3.2). This strategy relies on a collection of grammatically analyzed well-formed target sentences and will be evaluated as applied to computer-assisted language learning (we discuss the evaluation in more detail in Section 4.2). In this section, we also describe our method for automatically learning high-confidence lexical translation pairs. Finally, we show how TransAhead integrates these patterns and translations to offer writing or translation suggestions at runtime (Section 3.3). We attempt to find grammar patterns and lexical translations expected to translate the source text and characterize the subsequent contexts of the current translation prefix. Our learning process is shown in Figure 2.

In the first three stages of the learning process (from Steps (1) to (3) in Figure 2), we generate a good and representative set of syntactic patterns for frequent word se-quences, whether contiguous or not, in the target-language reference corpus C three steps make up our pattern suggestion module or writing suggestion module and are elaborated upon next.

In the first stage, we lemmatize each sentence in the reference corpus C erate its most probable part-of-speech sequence. For example, the following sentence  X  X he British Section refugee office has played a leading role in this area of work X  is lemmatized and tagged as  X  X he/DT British/JJ Section/NN refugee/NN office/NN have/VBZ play/VBN a/DT lead/VBG role/NN in/IN this/DT area/NN of/IN work/NN. X 
Lemmatization is aimed at reducing the impact of word variants on statistical anal-yses, while POS tagging generalizes the contexts of words. In fact, POS tags are often used for general descriptions in dictionaries and grammar books, such as  X  X ne X  X  X  (i.e., possessive pronoun) in the phrase  X  X ake up one X  X  mind X , the superlative adjective (e.g., happiest) in  X  X he most superlative adjective  X , the  X  X neself X  (i.e., reflexive pronoun) in  X  X njoy oneself very much X , the NN (i.e., noun) and VB (i.e., base form of a verb) in  X  X nsist/commend/demand that NN VB  X .

In the second stage of the learning process, we build up inverted files of the lemmas in C t for quick search. We also keep lemmas X  surface forms and POS tags for pattern grammar generation and language understanding or learning.

After the lemma-to-sentence mappings and syntactic analyses on sentences are obtained, we generate the usage summary of a contiguous or non-contiguous word sequence (e.g.,  X  X lay  X  role X  and  X  X ook forward to X ) using the procedure in Figure 3.
In Step (1) of the algorithm in Figure 3, we reformulate the query into a set of new queries, queries , if necessary. The first type of query reformulation concerns the language used in the query . If it is not in the same language as C query into its probable translations and append these translations to queries as if they were submitted by the user. The second type of reformulation concerns the length of the query. Single words may be ambiguous in word senses but contexts or grammar patterns are related to meanings [Hunston and Francis 2000]. Therefore, we transform a single-word query into a collocation query, and collocation finders, such as TANGO, can be used for this purpose.

We then initialize a set responses to collect usage summaries for queries (Step (2)) and exploit inverted files to extract and generate each query  X  X  syntax-based patterns (Step (3) to (7)). In Step (3), we identify the sentences which contain all query words (lemmas to be exact) in query . These sentences must satisfy the window size limit proximity set for any two query words. Note that the sentences may contain query words whose orders are not the same with those in query . In other words, positional variants (e.g.,  X  role to play  X  X nd X   X  role played by  X  for the query  X  X lay role X ) are allowed.
Once we identify the sentences containing the query , we construct its context sum-mary as follows. For each sentence , taking the form ([wordPosi(w sentence ) which denotes the positions of query  X  X  lemmas in the sentence , we generate pattern grammar involving replacing words in positions wordPosi(w and replacing the rest of the words in the sentence with POS tags. Inspired by Gamon and Leacock [2010], we extract fixed-window segments surrounding query from the transformed sentence. The result is a set of grammatical patterns (e.g., play Prep ( in ) V + ing of word sequence  X  play role  X ) with frequencies in the reference corpus.
The procedure finally returns the top N predominant syntactic patterns and their most frequent lexical realizations (e.g., play  X  role in shaping for the pattern play role Prep ( in ) V + ing ) as output (Step (8)). Our writing suggestion module collects usage summaries across the target language, in our case for more than 100K common word sequences, and they are stored for runtime reference to accelerate EFL learners X  language learning as well as to assist users in writing and translation. Note that since collocation learning plays a vital role in language learning, more than 50% of the word sequences are collocations (including verb-noun, adjective-noun, and verb-noun-preposition collocations, and so on).

In the fourth and final stage of the learning process (Step (4) in Figure 2), we obtain translation equivalents in the source and target languages from the parallel corpus C st . Our translation suggestion module is based on a number of steps, namely, leveraging the IBM model 1 to model 5 implemented in GIZA to word-align the bitexts of C st , smoothing the saw-toothed word alignments produced by the IBM directional word alignment model and collecting unaligned words via the standard grow-diagonal-final procedure, and using the consistent block approach [Koehn et al. 2003] to extract bilingual translation pairs.

Automatic approaches are used to acquire translations rather than a manual bilin-gual dictionary for better translation coverage and variety. Moreover, we filter out less probable or insignificant translation equivalents by applying the pruning techniques described in Johnson et al. [2007]. Overall, we aim for an accurate and small but diverse set of translation pairs to help the user in translation and language learning. Take the Chinese words , ,and for example. Their high-confidence English translations include  X  X lay X  and  X  X ave X ,  X  X ole X  and  X  X haracter X , and  X  X lose X  and  X  X nd X , respectively. Once the word usage preferences for word sequences, that is, writing suggestion mod-ule and translation equivalents, that is, translation suggestion module, are learned, they are stored for the real-time and real-world CAT system, TransAhead. TransAhead then predicts/suggests the grammar and text which immediately follow a translation prefix of the source text using the procedure in Figure 4.

In Step (1), we first split the source text S into character-based n-grams, denoted by { s i } . On the other hand, we find the word-level n-grams of the translation pre-fix T p the user has entered (Step (2)). But this time we concentrate on the n-grams ending with the last word of T p since, intuitively, these n-grams predict well the grammatical contents that are likely to follow T p , or the subsequent grammar pat-terns. Take the translation prefix  X  X e play an important role X  in Figure 1 for instance. sliceToWordNgramWithPivot( T p ) will identify the pivotal n-grams of  X  X ole, X   X  X mportant role, X   X  X n important role, X   X  X n role, X  and  X  X lay role. X  Notice that both consecutive and inconsecutive n-grams have an influence on predicting representative contexts. Con-sequently, the sliced n-grams include skipped ones such as  X  X lay role X  and  X  X n role X , as before.

Step (3) acquires the translation equivalents of source n-grams in translation suggestion module in Section 3.2. There are two aspects worth mentioning. First, to handle the word segmentation issue in MT [Bai et al. 2008; Ma et al. 2007], TransAhead breaks the word boundary in the source text, finds source character n-grams X  translations, and interacts with the user while he/she translates along to segment the source text in bilingual sense and to complete the translation. In other words, the word boundary in our system is at first nondeterministic and is determined only when the corresponding translation is chosen by the user. Consider the Chinese (translation:  X  important  X ) in Figure 1. Although it is possible to translate the characters and individually, after the user keys in the translation  X  important  X , its counterpart emerges as a word. The system and the user benefit from each other X  X  knowledge and compensate for each other X  X  insufficiencies. Second, an out-of-vocabulary (OOV) module [Huang et al. 2011b] that exploits constituent or character translations can be incorporated in Step (3) to reduce the impact of OOV on the system and the user, language learner in particular. Since the user directly interacts with TransAhead, the OOV module is of great importance.

While the active vocabulary, TranslationOptions, in Step (3) is used to translate the source text, n-grams in { t j } is used to extract syntactic patterns via the writing suggestion model described in Section 3.2. Notice that the translation prefix reflects source segments that had been translated. Whenever the user enters a translation, the active vocabulary is altered and shrunk accordingly. Also, TransAhead may exploit a user X  X  vocabulary of preference (due to the user X  X  domain of knowledge or errors of the system) to improve system performance and user experience [Nepveu et al. 2004; Ortiz-Martinez et al. 2010].

Standard MT submodels can be utilized to rank TransAhead writing and translation predictions. These include source-to-target and target-to-source translation models, target-language language model, word alignment model (i.e., considering alignment positions of source words and target translations), and distortion model (i.e., consider-ing the word orders of translations). In our case, the quality of grammar patterns may also be used. Besides system performance, the success of a CAT or CALL assistant fur-ther lies in user satisfaction, which closely correlates with the response time during user typing while translating, namely, the time delay between a user trigger and the return of TransAhead suggestions. To juggle speed and performance, our framework exploits language and directional translation models, the essential models in MT, in candidate ranking.

Specifically, we first evaluate and rank the translation candidates via the following formula. where  X  i is linear combination weight,  X  i sums to one, P referred to as the directional translation model and language model, and t is one of the translation candidates under S and T p . Afterwards, we integrate the lemmatized translation candidates according to their ranks into suitable grammar constituents in GrammarOptions . For example, we include the lemma close in the pattern play Prep ( in ) V + ing as play  X  role Prep ( in ) V + ing [ close ], hear in the pattern look forward to V + ing as look forward to V + ing [ hear ], and important in the pattern play an Adj as play an Adj [ important ]. Currently, priority is given to the predominant grammar pattern for accuracy and usage coverage.

Finally, the algorithm outputs representative grammar patterns with high-confidence translations (e.g., play  X  role Prep ( in ) V + translated grammar patterns expected to follow the current translation prefix for the source text and help language learning during the translation process. The algorithm is triggered each time a word delimiter (i.e., space) is entered, and the word boundary and the translation of the source text are determined along the way until the user submits the complete translation. Figure 1 shows example responses to the source text and two translation prefixes  X  X e X  and  X  X e play an important role X  in our working prototype, as applied in an interactive CAT and CALL environment. TransAhead was designed to predict suitable text completions with grammatical patterns that are likely to further translate the source text. As such, TransAhead will be trained and evaluated over the translation task. Furthermore, since the goal of TransAhead is to find a good set of prediction candidates for the purpose of computer-assisted translation and computer-assisted language learning, novice trans-lators X  writing performance (i.e., translation quality) with and without on-demand TransAhead assistance are compared. In this section, we first present the details of training TransAhead for the evaluation (Section 4.1). Then, Section 4.2 examines the effectiveness of usage summaries from our component writing suggestion module in the language learning task of sentence composition. Finally, we report the automatic and human evaluation on novice translators X  translation quality (i.e., translation accuracy, productivity, collocation usage, and so on) in Section 4.3. We used the British National Corpus (BNC) and the Hong Kong Parallel Text (HKPT) as our target-language reference corpus and parallel corpus, respectively. BNC is a 100 million word collection of samples of British English from a wide range of sources, including newspapers, journals, academic books, popular fiction, university essays, and so on. We used the GENIA tagger 5 developed by Tsujii Laboratory to syntacti-cally analyze, that is, POS tag and lemmatize the sentences in BNC, and it follows the Penn Treebank tagset. All sentences therein (approximately 5.6 million sentences) were used to construct inverted files and used as examples for grammar pattern ex-traction, that is, writing suggestion module. And since collocation learning plays an important role in language learning, we adopted the collocation extraction methods of Kilgarriff et al. [2004], Jian et al. [2004], and Chang et al. [2008] in our framework. HKPT, on the other hand, is an English-Chinese parallel text collection from the Hong Kong Special Administrative Region, composed of three subcorpora X  X ong Kong Hansards, Hong Kong Laws, and Hong Kong News. In total, there were approximately 2 million sentences pairs in HKPT, and they were exploited to build up our translation suggestion module. To evaluate our writing suggestion module, we introduced its Web-based version WSM 6 to novice translators, language learners in particular, and set up a language learning task for them. Specifically, WSM was shown to two classes of Chinese EFL (first-year) college students (32 and 86 students in each class), and they were trained to use WSM , which generates a general-to-specific usage summary likely to depict the contexts of a search query. Figure 5 shows example general patterns and specific lexical phrases for a word sequence  X  X lay role X , where frequency is enclosed in parentheses. Recall that the extracted patterns and phrases are targeted for language understand-ing and learning.

After the participants were trained, they were instructed to perform a sentence com-position task made up of a pretest and a posttest. In the 30-minute pretest, partici-pants were to complete 15 English sentences with Chinese translations as hints. Then they spent 20 minutes familiarizing themselves with word usages of the provided test candidates by consulting traditional tools or WSM . The task ended with a 30-minute posttest in which participants completed the same English sentences. The experiment was constrained to the same test items except for their order.

Example test items are shown in Table I, and each contains one or two blanks. In the table, the first item is supposed to test learners X  knowledge on the adjective and prepo-sitional collocate of  X  X ave impact X , while the second tests the verb collocate  X  X ake X , the preposition  X  X n X , and the preceding article  X  X  X  of  X  X ecord profit X . The third tests the ability to produce the adjective enrichment of  X  X n future X , and the fourth the in-between article  X  X  X  or possessive  X  X is X , as well as the following infinitive of  X  X n attempt X . Note that although existing collocation reference tools (e.g., TANGO) can easily retrieve collocates, they typically ignore function words like articles and determiners, which are frequent error sources in learner texts [Nicholls 1999], and fail to provide an overall picture of word usage, a task at which our writing suggestion module is particularly good.

Twenty collocations and phrases 7 were manually selected (by professors in computa-tional linguistics) from the 200 most frequent collocations in BNC and were provided to the learners between the pretest and posttest. In experiment, half of the participants were instructed to use WSM for learning (i.e., experimental group denoted by WSM), and the other half used traditional tools (i.e., control group denoted by TRAD). Par-ticipants in group TRAD could use any available traditional tools in their favor, such as online dictionaries, machine translation systems like Google Translate and Yahoo! Babel Fish, and search engines like Google Search. We observed the following. Sixty percent of the participants primarily used online dictionaries for their reference, and the most popular two were the online Longman and Macmillan dictionaries. Thirty percent of the participants primarily used Google Translate, while the rest primarily used Google Search. We say  X  X rimarily X  because some used more than one traditional tool: 20% utilized online dictionaries and Google Translate, and 4% utilized online dic-tionaries and Google Search.

Figures 6 and 7 show two participants X  answers to the blanked test items using WSM and traditional reference tools, respectively. Table II summarizes participant perfor-mance on the pretest and posttest (participants X  answers to test items were manually graded based on collocation usages and word choices). Notice that since the numbers of the students in class 1 and class 2 are different, the combined performance is not exactly half of those of class 1 and class 2.

Table II shows that (1) the partition of the classes was quite random, since the perfor-mance difference between WSM and TRAD was insignificant in the pretest; (2) WSM summaries of words X  contexts were more helpful in language learning (across class 1, class 2, and combined). To be specific, in the class 1 column, WSM helped to boost student achievement by 15.5%, which was nearly three times the gain obtained using TRAD (15.5 vs. 5.6); (3) the effectiveness of WSM in language learning was not con-fined to students at a certain level in that both high-(class 2) and low (class 1)-level learners benefited from WSM.
 We further sampled 30 participants (half in group WSM and the other half in TRAD) and analyzed their graded answer sheets. Table III reports error reduction rate between pretest and posttest in each group with respect to article, preposition, and adjective usages. Misuse between  X  X /an X  and  X  X he X , missing articles when needed, and redundant articles counted as article errors, while preposition and adjective errors were misuses within their respective part-of-speech category. Note that the word form usage following a preposition was considered in preposition usage. Therefore, the confusion between an infinitive  X  X o X  and a particle  X  X o X  counted as a preposition error.
In Table III, we found that WSM helped to reduce learner article and preposition errors by 28% and 7%, compared to a much smaller error reduction rate, 7% and 2%, observed in TRAD group. The comparably small improvement in preposition of WSM indicates that preposition usage and their following word form usage trouble language learners more, even with WSM assistance, and a different human-computer interac-tion approach ought to be adopted: highlighting the prepositions and beyond to catch users X  eyes. Additionally, the benefits of WSM extended to learner adjective usage: fewer participants left test items unfilled, and participants felt more confident in adjec-tive choices (revealed by our post-experiment interview), and the accuracy did improve.
On the other hand, an experiment was conducted in which Chinese EFL students were asked to perform the same task using WSM as well as WSM with translation information. 8 With Chinese translation, we observed an additional 5% increase in stu-dent test performance. This suggests that learners, to some extent, depend on their first language in learning and first-language information may serve as another quick navigation index, even when English-only WSM is presented. Now that we have examined the applicability of our word usage summaries in computer-assisted language learning, we now evaluate the overall TransAhead gram-mar and text prediction modules for computer-assisted translation. The evaluation and analysis are based on the automatic measurement of BLEU [Papineni et al. 2002], human grading (e.g., grading in collocation usages and more), and users X  log files. In this experiment, we introduced the Web-based writing assistant to a class of 34 Chinese college freshmen learning English as a foreign language. Designed to be ac-cessible and intuitive to the general public X  X specially language learners or novice translators without the knowledge of human language technologies X  X he user train-ing tutorial took only five minutes, during which the participants were not allowed to explore the system on their own.

After the tutorial, the participants were asked to translate 15 Chinese texts one by one, half with TransAhead assistance (experimental group) and the other with-out any system help whatsoever (control group). Table IV displays the source Chinese sentences. Automatic evaluation shows that the experimental group achieved much better translation quality than the control group with an average BLEU score of 35.49 versus 26.46. Note that BLEU measures translation precision against gold standards, and in our experiment, each and every one of our source sentences had at least four translation gold standards for diversity (i.e., to cover good translations).
A bilingual English teacher, on the other hand, graded all participants X  translations manually. Four rubics on a scale of one to five, one being the lowest, were adopted in evaluation: collocation usage/word choice (CW), grammar (G), fluency (F), and confor-mity to source sentence (CS). The professor also recorded the number of correct collo-cations (CC) in each translation. Table V summarizes the grading of the experimental and control group with respect to these five measurements, where CC is averaged over participants and translations. In Table V, the experimental group was on average, 0.5 points (i.e., relatively 13%) above the control group and had, on average, 0.4 (i.e., relatively 33%) more correct collocations in the translation than the control group. Not only the statistics but the teacher X  X  reports also indicate that, generally speaking, one group (i.e., the one with TransAhead assistance) translated the sentences more gram-matically, fluently, precisely, used more collocations, and used collocations and chose words more accurately than the other group (i.e., the one on their own). In fact, the now discernible performance difference originally did not exist, because we partitioned the class based on the participants X  previous academic achievement in English. Figure 8 shows an EFL participant X  X  translations of the aforementioned Chinese sentences with TransAhead translation and writing assistance, whereas Figure 9 shows another participant X  X  translations without. We can easily tell them apart based on quality.
We also analyzed the translation log files of each group. Log files contained the time stamps of keystrokes and the time stamps of beginning and finishing the trans-lation of our participants. Table VI shows that, on average, the participants without TransAhead suggestions spent more time spent on translation. With relatively 10% and 11% less time spent on a word and on a sentence, the experimental group still did a better job in translation than the control group. Tables V and VI suggest that TransAhead helped EFL learners to achieve better productivity (namely, less time on translation and better translation quality).

All in all, the automatic and manual evaluations show that, encouragingly, the translations between the experimental and control group differ in quality in terms of user productivity, translation accuracy, word/collocation choice, usages of collocations, grammar, fluency, and consistency to source sentences. The benefits of TransAhead for novice translators or language learners are clear and obvious in sentence translation and composition, or language generation.
 Admittedly, the MT system Google Translate produced translations with a higher BLEU score of 44.82. No previous work in CAT has used Google Translate for compari-son, since it obviously has much more parallel training data. Although the experimen-tal group using TransAhead did not outperform Google Translate, TransAhead helped to bring the translation quality closer, and with TransAhead assistance, language learners performed better in translating some source sentences. Take the source sen-tence  X   X  in Figure 1 for example. A total of 80% of the participants in the experimental group produced more grammatical and fluent translations (see Figure 10) than that by (less interactive) Google Translate, which yielded  X  X e conclude this transaction plays an important role X . In comparison, 50% of the source X  X  translations from the control group were error-prone and nonnative-like.
In addition to the encouraging improvement in users X  translation quality and pro-ductivity, post-experiment surveys are also positive in a number of aspects. First, the participants found Google Translate lacking effective human-computer interac-tion in language learning, while TransAhead is a more intuitive, natural platform for language learning, where translation and writing assistance are provided along the translation process. They also found TransAhead grammar and translation predictions useful for their immediate translation task and language learning. Third, human-computer interactivity made translation and language learning a fun process (quite in spirit to the interactive image tagging game of von Ahn and Dabbish [2004]). Last but not least, most of the participants would recommend TransAhead to their friends and would like to use it again in future translation tasks.

Based on the evaluations and surveys, TransAhead does successfully provide an interactive, human-computer collaborative, real-world environment where CAT and CALL meet. To the best of our knowledge, we are the first in CAT to aim for novice translators or language learners and the first in CAT to cater for simultaneous multi-ple user access and short response time during user typing while translating. Many avenues exist for future research and improvement of our system. For exam-ple, existing error suggestion and correction methods, such as those of Chodorow and Leacock [2000], Gamon et al. [2009], and Huang et al. [2011a] could be integrated for post-translation assistance. Machine translation paraphrases, as in Marton et al. [2009] and Mirkin et al. [2009], and constituent translation, as in Huang et al. [2011b], could be combined into our translation suggestion module for better translation cov-erage and variety (especially for out-of-vocabulary words). Due to the fact that words X  contexts may vary with their parts-of-speech, we could augment POS information into grammar patterns. For instance, the present tense verb  X  X iscuss X  is a transitive verb and typically followed by determiners and nouns, while its passive iteration is often followedbythepreposition X  X n X ,asin X ...isdiscussedinChapterone. X  X hef requencies of grammar patterns, on the other hand, could be taken into account in making writing and translation predictions. Additionally, an interesting direction to explore is exploit-ing user feedback [Nepveu et al. 2004; Ortiz-Martinez et al. 2010, 2011] to improve our system and the overall user experience. Yet another direction of research would be to investigate the possibility of using the translation pairs generated by human-computer collaboration to re-train word boundaries suitable for machine translation, that is, to find word boundaries in a bilingual sense.

In summary, we have introduced a method for learning to provide grammar and text predictions expected to assist the user in translation, writing, and language learning. The method involves grammatically and literally describing the word usages of consec-utive and inconsecutive word sequences and evaluating subsequent grammar and text suggestions for the current incomplete translation of a source text through language and translation models. We have implemented and thoroughly evaluated the method as applied to CAT and CALL. In both the automatic and manual evaluations, we have shown that our intuitive translation and writing assistant substantially improves novice users X  or EFL learners X  performance (i.e., productivity and translation quality) in sentence translation and composition. And the promising results further push us to evaluate and improve our system more extensively (e.g., with respect to human-computer interaction, users X  productivity, and users X  certain key use, such as delete and backspace , which indicate hesitation in making grammar and lexical choices).
