 With the Web 2.0 technology encouraging more and more people to participate in online comments, recent years have wi tnessed the opinion explosion on Web. As large scale of user comments accumula te, it challenges both the merchants and customers to analyze the opinions or make further decisions. As a result, opinion mining which aims at determining the sentiments of opinions has become a hot research topic.

Additionally, besides the simple overall evaluation and summary, both cus-tomers and merchants are b ecoming increasing ly concerned in certain aspects of the entities. Take a set of restaurant reviews as example. Common restau-rant aspects include  X  X ood X ,  X  X ervice X ,  X  X alue X  and so on. Some guests may be interested in the  X  X ood X  aspect, while some may think highly of the  X  X alue X  or  X  X ervice X  aspect. To meet these perso nalized demands, we need to decompose the opinions into different aspects for better understanding or comparison.
On the other hand, it also brings out perplexity for merchants to digest all the customer reviews in case that they want to know in which aspect they lack behind their competitors. As pointed out in [12], the task of aspect-based summarization consists of two subtasks: the first is Aspect Identification (AI), and the second is sentiment classification and summarization. The study in this paper mainly focuses on the first task, which aims to accurately identify the aspect terms in the reviews for certain type of entities.

AsshowninFigure1,thereare3review s on different hotels, where the de-scription for the same aspect is staine d in the same color. One of a recent works in this area argues that it is more sensible to extract aspects from the phrase level rather than the sentence level since a single sentence may cover different aspects of an entity (as shown in Figure 1, a sentence may contain different col-ored terms) [5]. Thus, Lu et al. decompose reviews into phrases in the form of ( head , modifier ) pairs. A head term usually indicates the aspect while a modifier term reflects the sentiment towards the a spect. Take the phrase  X  X xcellent staff X  for example. The head  X  X taff X  belongs to the  X  X taff/front desk X  aspect, while the pairs, they explore the latent topics embedded in it with aspect priors. In other words, they take the these 2-tuples as input, and output the latent topics as the identified aspects.

In this study, we observe that besides the (head, modifier) pairs each review is often tied with an entity and its overall rating. As shown in Figure 1, a hotel name and an overall rating are given for each review. Thus, we can construct the quad-tuples of which indicates that a phrase of the head and modifier appears in the review for this entity with the rating . For example, the reviews in Figure 1 include the following quad-tuples, With these quad-tuples from the reviews for a certain type of entities, we further argue that they contain more co-occurrence information than 2-tuples, thus pro-vide more ability in differentiating terms. For example, reviews with the same rating tend to share similar modifiers. Additionally, reviews with the same rating on the same entity often talk about the same aspects of that entity (imagine that people may always assign lowest ratings to an entity because of its low quality in certain aspect). Therefore, incorporating entity and rating into the tuples may facilitate aspect generation.

Motivated by this observation, we propose a model of Quad-tuple PLSA (QPLSA for short), which can handle two more items (compared to the pre-vious 2-tuple PLSA [1,5]) in topic modeling. In this way we aim to achieve higher accuracy in aspect identificatio n. The rest of this paper is organized as follows: Section 2 presents the problem definition and preliminary knowledge. Section 3 details our model Quad-tuple PLSA and the EM solution. Section 4 gives the experimental results to validate the superiority of our model. Section 5 discusses the related work and we conclude our paper in Section 6. In this section, we first introduce the problem, and then briefly review Lu X  X  solution X  X he Structured Probabilistic Latent Semantic Analysis (SPLSA) [5]. The frequently used notations are summarized in Table 1.
 2.1 Problem Definition In this section, we give the problem definition and the related concepts. Definition 1 (Phrase). A phrase f =( h, m ) is in the form of a pair of head term h and modifier m . And SPLSA adopts such (head, modifier) 2-tuple phrases for aspect extraction.
 Definition 2 (Quad-tuple). A quad-tuple q =( h, m, r, e ) is a vector of head term h ,modifier m ,rating r and entity e . Given a review on entity e with rating r , we can generate a set of quad-tuples, denoted by { ( h, m, r, e ) | Phrase ( h, m ) appears with rating r in a review of entity e } . Aspect Cluster. An aspect cluster A i is a cluster of head terms which share similar meaning in the giv en context. We represent A i = { h |G ( h )= i } ,where G is a mapping function that maps h to a cluster aspect A i .
 Aspect Identification. The goal of aspect identification is to find the mapping function G that correctly assigns the asp ect label for given head term h . 2.2 Structured PLSA Structured PLSA (SPLSA for short) is a 2-tuple PLSA based method for rated aspect summarization. It incorporates the structure of phrases into the PLSA model, using the co-occurrence information of head terms and their modifiers. Given the whole data X composed of (head, modifier) pairs, SPLSA arouses a mixture model with latent model topics z as follows, rithm by solving the maximum log likelihood problem in the following, where  X  denotes all the parameters. And the prior knowledge of seed words indicating specific aspect are injected in the way as follows: where z 0 denotes the priors corresponding to the latent topic z ,and  X  is the confidential parameter of the head term h belonging to aspect z 0 .Andeach h is grouped into topic z with the largest probability of generating h , which was the aspect identification function in SPLSA: A ( h ) = arg max z p ( h | z ). 3.1 QPLSA In SPLSA, aspects are extracted based on the co-occurrences of head and mod-ifier, namely a set of 2-tuples. Next, we will detail our model X  X PLSA, which takes the quad-tuples as input for more accurate aspect identification.
Figure 2 illustrates the graphical model of QPLSA. The directed lines among the nodes are decided by the understandings on the dependency relationships among these variables. Specifically, we assume that given a latent topic z , h and m are conditionally independent. Also, a reviewer may show different judgement toward different aspects of the same entity. Thus, rating r is jointly dependent on entity e and latent topic z . From the graphic model in Figure 2, we can write the joint probability over all variables as follows: Let Z denote all the latent variables, and given the whole data X , all the param-eters can be approximated by maximizing the following log likelihood function, log p ( X |  X  ) = log derivation of EM algorithm is detailed in next subsection. 3.2 Deriving the EM Solution Traditionally, the Expectation-Maximization(EM) algorithm is utilized for opti-mization of PLSA based methods. In our model, we also adopt the EM algorithm to maximize the log likelihood function in Equation (5). Specifically, the lower bound (Jensen X  X  inequality) L 0 of (5) is: where q ( z ) could be an arbitrary function, and here we set q ( z )= p ( z | h, m, r, e ;  X  old ) and substitute into (6): E Step: Constructing L . For the solution of (5),we have: L = where M Step: Maximizing L . Here we maximize L with its parameters by La-grangian Multiplier method. Expand L and extract the terms containing p ( h | z ). equation: we have Note that  X  p ( h | z ) should be normalized via Similarly, we have: 3.3 Incorporating Aspect Prior For specific aspect identification, we may have some domain knowledge about aspects. For instance, the aspect  X  X ood X  may include a few seed words such as  X  X reakfast X ,  X  X otato X ,  X  X rink X  and so on. Specifically, we use a unigram language model p ( h | z ) to inject the prior knowledge for the aspect z .Take the aspect  X  X ood X  as an example, we can assign the conditional probability bility  X  (e.g.,  X  (0  X   X   X  1) is a pre-defined threshold).

Similarly with the method in Lu et al. [5], we introduce a conjugate Dirichlet prior on each unigram language model, parameterized as Dir (  X p ( h | z )+1),and  X  denotes the confidence for the prior knowledge of aspect z . Specifically, the prior for all the parameters is given by: where  X  = 0 if we have no prior knowledge on z . Note that adding the prior can be interpreted as increasing the counts for head term h by  X  +1timeswhen estimating p ( h | z ). Therefore, we have: 3.4 Aspect Identification Our goal is to assign the head term h to a correct aspect label, and we follow the mapping function G as SPLSA [5]: where we select the aspect which generates h with the largest probabilty as the aspect label for head term h . In this section, we present the experimental results to evaluate our model QPLSA. Firstly, we introduce the data sets and implementation details, and then give the experimental results in the following subsections.
 4.1 Data Sets We adopt two different datasets for evaluation, which are detailed in Table 2. The first dataset is a corpus of hotel reviews provided by Wang et al. [14]. The data set includes 246,399 reviews on 1850 hotels with each review associated with an overall rating and 7 detailed ratings about the pre-defined aspects, and the value of the rating ranges from 1 star to 5 stars. Table 2 also lists the prior knowledge of some seed words indicating specific aspects.

The other dataset is about restaurant reviews from Snyder et al. [11], which is much sparser than the previous one. This dataset contains 1609 reviews on 420 restaurants with each review associated with an overall rating and 4 aspect ratings. For both of the datasets, we decompose the reviews into phrases utilizing a set of NLP toolkits such as the POS tagging and chunking functions 1 . 4.2 Implementation Details terms and manually label them as knowledge base. Specifically, for the hotel reviews we select 408 head terms and categorize them into 7 specific aspects. While for the restaurant reviews, we select 172 head terms and label them with 4 specific aspects. The details of the categorization are summarized in Table 3, and A1 to A7 corresponds to the aspects in Table 2. Here we only evaluate the results of specific aspect identification and compare our model QPLSA with SPLSA.
 4.3 Experimental Results Aspect Identification. We present the accuracy of aspect identification of all the head terms in Table 3. Since we focus on specific aspect extraction, our discussions only detail the results on specific aspects. In the table, A i denote the i -th specific aspect as described in Table 2, and  X  X 1-7 X  and  X  X 1-4 X  denote the sum of the specific aspects for hotel reviews and restaurant reviews, respectively.
In Table 3, Q-accuracy denotes the a ccuracy of QPLSA, and S-accuracy rep-resents that of SPLSA. From the results reported in Table 3, apparently, QPLSA achieves better performance compared to SPLSA. As can be s een, the accuracy of QPLSA for all the reviews is much higher than that of SPLSA, which indicates that quad-tuples exploits more information for specific aspect generation as op-posed to 2-tuples. All the experimental r esults demonstrate the effectiveness of incorporating entity and its rating for aspect identification.

To further validate the superiority of QPLSA over SPLSA, we conduct sys-tematic experiments on different data sets of hotel reviews for comparison. We carry out experiments on different numbers of hotels (e.g., 300, 600, 900, 1200, 1500 and 1850), and all the results are shown in Figure 3.

As illustrated in Fig. 3, in particular, the performance of QPLSA varies for different aspects due to the skrewness of co rpse over specific topics. Nevertheless, for different numbers of hotels, that the overall accuracy of QPLSA always out-performs that of SPLSA strongly supports that Aspect Identification of QPLSA can benefit from the additional information of entity and its rating. Representative Term Extraction. Table 4 lists representative terms for the 7 specific aspects of hotel reviews and the 4 aspects of the restaurant reviews. For each aspect, we choose 20 head terms with the largest probability, and the terms that are correctly associated with the a spects are marked with bold and italic. Totally, for the 7 aspects of hotel revi ews, there are 105 head terms accurately selected by QPLSA compared to 64 by SPL SA. Also for the 4 aspects of restau-rant reviews, more correct words are captured by QPLSA than SPLSA. In all, QPLSA extracts 136 correct terms compared to 108 of SPLSA. All these results demonstrate that incorporating entity and its rating for aspect identification(or extraction) is effective.

Note that both QPLSA and SPLSA obtain much better results on dataset hotel reviews than those on restaurant reviews. The reason is that both methods are based on generative model that models the co-occurrence information. As we know, hotel review dataset is much more dense, and thus can provide enough co-occurrence information for learning. This section details some interesting study that is relevant to our research. Pang et al. [8] give a full overview of opinion mining and sentiment analysis, after describing the requests and challenges, they outlined a series of approaches and applications for this research domain. It is pointed out that sentiment classifica-tion could be broadly referred as binary categorization, multi-class categoriza-tion, regression or ranking problems on an opinionated document.

Hu and Liu [2] adopt association mining based techniques to find frequent features and identify the polarity of opinions based on adjective words. However, their method did not perform aspect clustering for deeper understanding of opinions. Similar work carried out by Popescu and Etzioni [10] achieved better performance on feature extraction and sentiment polarity identification, however, there is still no cons ideration of aspects.

Kim et al. [3] developed a system for sentiment classification through combin-ing sentiments at word and sentence levels, however their system did not help users digest opinions from the aspect pers pective. More approaches for sentiment analysis could be referred to [9,13,15,7], although none of these methods attach importance to aspects.

Topic models [14,4,6,5] are also utilized to extract aspects from online re-views. Lu et al. adopt the unstructured and structured PLSA for aspect identi-fication [5], however, in their model, there is no consideration of rating or entity in the aspect generation phase. Wang et al. [14] proposed a rating regression ap-proach for latent aspect rating analysis on reviews, still in their model they do not take account of entity. Mei et al. [6] defined the problem of topic-sentiment analysis on Weblogs and proposed Topic-Sentiment Mixture(TSM) model to capture sentiments and extract topic lif e cycles. However, as mentioned before, none of these topic models extracts aspects in view of quads.

A closely related work to our study could be referred to Titov and McDon-ald X  X  [12] work on aspect generation. They construct a joint statistical model of text and sentiment ratings, called the Multi-Aspect Sentiment model(MAS) to generate topics from the sentence level. They build local and global topics based on the Multi-Grain Latent Dirichlet Allocation model (MG-LDA) for bet-ter aspect generation. One recent work [4] by Lakkaraju et al. also focused on sentence level aspect identification. Ho wever, according to our observation, a single sentence may address several diffe rent aspects and therefore we generate aspects from the phrase level, while they extract topics from the sentence level. Moreover, in their model, there is no consideration of entity. In this paper, we focus on aspect identification in opinion mining and propose a quad-tuple PLSA based model which novelly incorporates the rating and entity for a better aspect generation. Compared to traditional 2-tuple(head, modifier) PLSA based modeling methods, our model exploits the co-occurrance informa-tion among quad-tuples(head, modifier, rating, entity) and extract aspects from a finer grain. After formally describing our quad-tuple PLSA(QPLSA) and ap-plying the EM algorithm for optimization, we carry out systematic experiments to testify the effectiveness of our algorit hm. Experimental results show that this method achieves better performance in as pect identification and representative term extraction compared to SPLSA(a 2-tuple PLSA based method). Our future work will focus on aspect rating predic tion and sentiment summarization. Acknowledgement. We would like to thank Ping Luo from the H.P.(Hewlett-Packard) Labs China. Besides, our work is supported by the National Natu-ral Science Foundation of China (No. 60933004, 60975039, 61035003, 60903141, 61072085), National Basic Research Priorities Programme (No.2007CB311004) and National Science and Technol ogy Support Plan (No.2006BAC08B06).
