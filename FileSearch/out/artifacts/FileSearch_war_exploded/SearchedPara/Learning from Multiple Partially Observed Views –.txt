 multilingual document collections, where documents may be available in different languages, but each document in a given language may not be translated in all (or any) of the other languages. Our framework assumes the existence of view generating func tions which may approximate miss-ing examples using the observed ones. In the case of multilin gual corpora these view generating functions may be Machine Translation systems which for each document in one language produce observed examples obtained from multiple sources into the c lassical multi-view learning. The con-number of training examples, the number of views and the abil ity of view generating functions to generated views may lead to substantial performance gains. We then show how the agreement of approach yields improved classification performance in bot h the supervised and semi-supervised settings.
 In the following two sections, we first define our framework, t hen the learning tasks we address. Section 4 describes our trade-off bound in the Empirical Ris k Minimization (ERM) setting, and shows how and when the additional, artificially generated vi ews may yield a better generalization describes experimental results that support this approach . setting of artificially generated representations. 2.1 Observed and Generated Views resentation of the same object in different sets X tion of a document written in a given language (e.g. English , German , French ). pens, for instance, when documents may be available in diffe rent languages, yet a given document may only be available in a single language. Formally, our obs ervations x belong to the input set according to a fixed, but unknown distribution D over X X Y , such that P all views are always observed (i.e. P dataset where only one view is available for each example (i. e. P originality of our setting is that we assume that we have view generating functions  X  X generating functions are Machine Translation systems. The se generating functions can then be used the completed observation x is obtained as: In this paper, we focus on the case where only one view is observed for each example. This setting corresponds to the problem of learning from comparable corpora , which will be the focus of our experiments. Our study extends to the situation where two or more views may be observed in a to induce the missing views from the observed ones. 2.2 Learning objective drawn according to some distribution D as described above. Following the standard multi-view framework, in which all views are observed [3, 13], we assume that we are given V deterministic classifier sets ( H of functions h classifiers C , there is a function  X  For simplicity, in the rest of the paper, when the context is c lear, the function x 7 X   X  will be denoted by c generalization error, defined as: semi-supervised learning. on how the generated views are used at both training and test s tages, we consider the following learning scenarios: -Generated Views as Additional Training Data: The most natural way to use the generated We now analyze how the generated views can improve generaliz ation performance. Essentially, learning, but can also be of lower quality, which may degrade learning.
 tion class capacity used here is the empirical Rademacher complexity [1]. Proof is given in the supplementary material.
 Theorem 1 Let D be a distribution over X X Y , satisfying P Let S = (( x i , y loss, and let ( H size m Baseline setting: for all 1 &gt;  X  &gt; 0 , with probability at least 1  X   X  over S : (the baseline setting) or preferable to use the view-genera ting functions in the multi-view Gibbs classification setting: we should use the former when 2 P H v , S v ) +  X  of the distribution. inf situation, the quality of the generating functions will be s ufficient to make  X  small. The terms depending on the complexity of the class of functio ns may be better explained using orders of magnitude. Typically, the Rademacher complexity for a sample of size n is usually of order O ( 1  X  Assuming, for simplicity, that all empirical Rademacher co mplexities in Theorem 1 are approxi-that m Choose the Multi-view Gibbs classification setting when: d q V This means that we expect important performance gains when t he number of examples is small, the representations that allow to correctly discriminate betw een classes.
 Majority voting One advantage of the multi-view setting at prediction time i s that we can use a majority voting scheme, as described in Section 2. In such a c ase, we expect that  X  ( c mv in general, though, since, in general, we can not prove any be tter than  X  ( c mv (see e.g. [9]). examples may naturally be taken into account in a semi X  X uper vised learning scheme, using existing approaches for multi-view learning (e.g. [3]).
 the notion of disagreement between the various view-specific classifiers, defined as the expected variance of their outputs: that needs be considered in the supervised learning stage is reduced to: as the train error is usually close to 0 .
 Theorem 3 of [11] provides a theoretical value B (  X ,  X  ) for the minimum number of unlabeled ex-amples required to estimate Eq. 8 with precision  X  and probability 1  X   X  (this bound depends on Gibbs classifier when unlabeled data are available. The proo f is similar to Theorem 4 in [11]. Proposition 2 Let 0  X   X  1 and 0 &lt;  X  &lt; 1 . Under the conditions and notations of Theorem 1, assume furthermore that we have access to u  X  B ( / 2 ,  X / 2) unlabeled examples drawn i.i.d. according to the marginal distribution of D on X .
 Then, with probability at least 1  X   X  , if the empirical risk minimizers h set, we have: taking semi-supervised learning into account. Using order s of magnitude, and assuming that for each view,  X  R becomes: Choose the mutli-view Gibbs classification setting when: d p V /m  X  d Thus, the improvement is even more important than in the supe rvised setting. Also note that the more views we have, the greater the reduction in classifier se t complexity should be. Notice that this semi-supervised learning principle enfor ces agreement between the view specific the semi-supervised setting. In our experiments, we address the problem of learning docum ent classifiers from a comparable corpus. We build the comparable corpus by sampling parts of t he Reuters RCV1 and RCV2 collec-tions [12, 14]. We used newswire articles written in 5 languages, English , French , German , Italian and Spanish . We focused on 6 relatively populous classes: C15 , CCAT , E21 , ECAT , GCAT , M11 .
 For each language and each class, we sampled up to 5000 documents from the RCV1 (for English ) or RCV2 (for other languages). Documents belonging to more t han one of our 6 classes were as-uments (respecting class and language proportions) for tes ting. For each document, we indexed cessing, we lowercased, mapped digits to a single digit token, and removed non alphanumeric 5 documents.
 Documents were then represented as a bag of words, using a TFI DF-based weighting scheme. The PORTAGE, a statistical machine translation system develop ed at NRC [15]. Each document from the comparable corpus was thus translated to the other 4 languages. 2 supervised learning, using various amounts of labeled exam ples. We rely on linear SVM models as base classifiers, using the SVM-Perf package [8]. For comparisons, we employed the four learning strategies described in section 3: 1  X  the single-view baseline sv additional training data gv voting mv thus be seen as a baseline approach, as opposed to the last two strategies ( mv Note also that in our case ( V = 5 views), additional training examples obtained from machin e sv Table 2: Test classification accuracy and F Gibbs ( mv according to a Wilcoxon rank sum test ( p &lt; 0 . 01 ) [10].
 Strategy C15 CCAT E21 ECAT GCAT M11 Acc.
 mv m .716 .521 .708 .478 .693 .405 .636 .441 .860 .642 .820 .644 information that compensates the lack of labeled data. Alth ough the multi-view Gibbs classifier performance to the gv purposes. Multi-view majority voting reaches the best perf ormance, yielding a 6  X  17% improve-ment in accuracy over the baseline. A similar increase in per formance is observed using F suggests that the multi-view SVM appropriately handles unbalanced classes.
 Figure 1 shows the learning curves obtained on 3 classes, C15 , ECAT and M11 . These figures show labeled examples, additional generated views do not provid e more useful information for learning than what view-specific classifiers have available already.
 view Gibbs and majority vote strategies should have the same performance. In order to enforce unanimously (pseudo-)labeled ones. Key differences betwe en this algorithm and co-training are the number of views used for learning ( 5 instead of 2 ), and the use of unanimous and simultaneous labeling. the self-training paradigm [16]. Prediction from the multi -view SVM models obtained from this self-learning multiple-view algorithm is done either usin g Gibbs ( mv s These results are shown in table 3. For comparison we also tra ined a TSVM model [7] on each view model mostly out-performs the supervised baseline sv This suggests that the TSVM has trouble handling unbalanced classes in this setting. Table 3: Test classification accuracy and F and multi-view self-learning using either Gibbs ( mv s baseline and multi-view majority voting performance for su pervised learning.
 Strategy C15 CCAT E21 ECAT GCAT M11 Acc.
 mv s g . 772 . 586 . 762 . 538 . 765 . 470 . 691 . 504 . 903 . 729 . 900 . 764 mv s m .773 .589 .766 .545 .767 .473 .701 .508 .905 .734 .901 .766 and F classes. As expected, the performance of both mv s The contributions of this paper are twofold. First, we propo sed a bound on the risk of the Gibbs our target application of learning text classifiers from a co mparable corpus. We showed that our bound may lead to a trade-off between the size of the training set, the number of views, and the the previous trade-off becomes even much tighter. Empirica l results on a comparable multilingual corpus support our findings by showing that additional views obtained using a Machine Translation there are few labeled data available for training.
 Acknowlegdements This work was supported in part by the IST Program of the Europ ean Com-munity, under the PASCAL2 Network of Excellence, IST-2002-506778.
 [1] P. L. Bartlett and S. Mendelson. Rademacher and gaussian complexities: risk bounds and [2] J. Blitzer, K. Crammer, A. Kulesza, F. Pereira, and J. Wor tman. Learning bounds for domain [3] A. Blum and T. M. Mitchell. Combining labeled and unlabel ed sata with co-training. In COLT , [4] K. Crammer, M. Kearns, and J. Wortman. Learning from mult iple sources. Journal of Machine [5] J. D. R. Farquhar, D. Hardoon, H. Meng, J. Shawe-Taylor, a nd S. Szedmak. Two view learning: [8] T. Joachims. Training linear svms in linear time. In Proceedings of the ACM Conference on [9] J. Langford and J. Shawe-taylor. Pac-bayes &amp; margins. In NIPS 15 , pages 439 X 446, 2002. [10] E. Lehmann. Nonparametric Statistical Methods Based on Ranks . McGraw-Hill, New York, [11] B. Leskes. The value of agreement, a new boosting algori thm. In COLT , pages 95 X 110, 2005. [12] D. D. Lewis, Y. Yang, T. Rose, and F. Li. RCV1: A new benchm ark collection for text catego-[13] I. Muslea. Active learning with multiple views . PhD thesis, USC, 2002. [14] Reuters. Corpus, volume 2, multilingual corpus, 1996-08-20 to 1997-08-19. 2005. [15] N. Ueffing, M. Simard, S. Larkin, and J. H. Johnson. NRC X  X  PORTAGE system for WMT. In
