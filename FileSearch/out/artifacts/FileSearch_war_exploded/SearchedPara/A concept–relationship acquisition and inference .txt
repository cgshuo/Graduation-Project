 Eric Tsui, W.M. Wang, C.F. Cheung, Adela S.M. Lau * 1. Introduction of the information indexed by the tags.
 initial step or general investment in managing organizational information. Chosky &amp; Carol, 2006; Connelly, 2007 ).
 nomies with publicly accessible folksonomies for enhanced organizational knowledge navigation. 2. Taxonomy construction ular deals with the automatic method of constructing taxonomy. 2.1. Automatic taxonomy construction tionship according to which a certain term t 1 is more special than a term t t appears.
 sition of hyponym relations from Grolier X  X  American Academic Encyclopedia. These patterns include: 1. NP 0  X  X  X uch as X  NP 1 ,NP 2 , ... , (and | or) NP n 2.  X  X  X uch X  NP 0 as NP 1 ,NP 2 , ... , (and | or) NP n 3. NP 1 ,NP 2 ... , (and | or) other NP 0 4. NP 0 (including | especially) NP 1 ,NP 2 , ... , (and | or) NP
They imply for all NP i , i &gt; 1, hyponym(NP i ,NP 0 ), NP
Berland (1999) proposed for learning part of relations. They proposed other five patterns: 1. NN 0  X  X  NN 1 2. NN 1 of (a | and | the) NN 0 3. NN 1  X  X  X n X  (a | and | the) NN 0 4. NN 1 sofNN 0 s 5. NN 1 s  X  X  X n X  NN 0 s They imply part of (NN 1 ,NN 0 ), where NN stands for a noun.
 among tags is outside the scope of this paper. dictionaries. 3. Proposed methodology rules analysis is applied prior to the concept X  X elationship acquisition algorithm. 3.1. Heuristic rules analysis in a timely and effective manner. We apply three basic heuristic rules as shown below: (b) Rule 2: A rule to detect abbreviations. Given two terms t 3.2. Concept X  X elationship acquisition and inference ships among tags can be deduced based on their appearances in the raw text documents. be achieved by continuously updating the case base.
 as following: least one occurrence.
 determined as follows: where m is the number of inputs, w j is the weighting of the j th POS, that of the retrieved cases, sim  X  v o j ; v r j  X  is the similarity function for the j th POS as follows: which is separated by commas and semicolons to form the concept X  X elationship X  X oncept propositions. the corresponding concepts are classified into corresponding relationship. For example, c c =  X  X ontent Protection X  and the relationship between c 1 and c concepts.
 based on the hierarchy by two kinds of rules as defined below: (a) Rule 1: IF parent( t 1 , c 1 ) AND {parent( c 1 , c 2 (b) Rule 2: IF r 1 ( t 1 , t 2 ) AND r 1 ( c 1 , t 1 ) AND r
In some cases, the relationships parent( t 1 , t 2), parent( t 2 parent( t 1 , t 2 ) and parent( t 2 , t 1 ) are set in a higher priority than neighbor( t strictly inferred than that of the neighbor relationship. For parent( t number of counts (evidences) is always selected. 4. Evaluation 4.1. Evaluation methodology of evaluations. Examples of the relations are provided in Fig. 7 . number of documents ends up with less than the number of tags.
 and precision rates are measured based on the following equations: ular algorithm. S a lg orithm is the number of relations suggested by a particular algorithm. 4.2. Result and discussions
With the LSA method, a tag-document occurrence matrix is formed and decomposed by singular value decomposition neighbor relationship only, the recall for is-parent relation is 0.
Using Hearst method, the following four syntactic patterns are used to detect is-parent relations: 1. NP 0  X  X  X uch as X  NP 1 ,NP 2 , ... , (and | or) NP n 2.  X  X  X uch X  NP 0  X  X  X s X  NP 1 ,NP 2 , ... , (and | or) NP n 3. NP 1 ,NP 2 , ... , (and | or) other NP 0 4. NP 0 (including | especially) NP 1 ,NP 2 , ... , (and | or) NP
They imply for all NP i , i &gt; 1, hyponym(NP i ,NP 0 ), NP compared with the other approaches.
 ture under different branches.
 parent relations is around 16 X 25% and 2 X 6% recall in classifying is-neighbor relations. method (0.1610), WordNet has a very low recall compared with that of proposed method. ation and standard error of the proposed approach all perform better than that of LSA. 5. Conclusions proaches for testing. The results showed that the combination leads to increased in both recall and precision. advantages can be leveraged.
 Acknowledgements contributions towards the experimentations and feedback on several versions of this paper.
Appendix A. tag set 1. cc: coordinating conjunction 2. cd: cardinal number 3. det: determiner 4. ex: existential there 5. fw: foreign word 6. in: preposition or subordinating conjunction 7. jj: adjective 8. jjr: adjective, comparative 9. jjs: adjective, superlative 10. ls: list item marker 11. md: modal 12. nn: noun, singular or mass 13. nns: noun, plural 14. nnp: proper noun, singular 15. nnps: proper noun, plural 16. pdt: predeterminer 17. pos: possessive ending 18. prp: personal pronoun 19. prp$: possessive pronoun 20. rb: adverb 21. rbr: adverb, comparative 22. rbs: adverb, superlative 23. rp: particle 24. sym: symbol 25. to: to 26. uh: interjection 27. vb: verb, base form 28. vbd: verb, past tense 29. vbg: verb, gerund or present participle 30. vbn: verb, past participle 31. vbp: verb, non-3rd person singular present 32. vbz: verb, 3rd person singular present 33. wst: wh-determiner 34. wp: wh-pronoun 35. wp$: possessive wh-pronoun 36. wrb: wh-adverb References
