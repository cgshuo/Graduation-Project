 1. Introduction
Spatial Data Infrastructures (SDI) are special types of information infrastructures consisting of the relevant base collection of spatial data (also known as geographic information) were the core component of Geographic Information Systems (GIS), which is the term commonly used to refer to the software packages that allow one to capture, store, check, integrate, manipulate, analyze and display them. However, the potential of spatial data as an instrument to facilitate decision-making and resource management of GIS into the broader concept of SDI [1] .

One of the main elements for the success in the development of SDI or any other type of information infrastructure is the appropriate annotation of resources to be accessed and distributed by means of metadata. Metadata constitute the mechanism to enable other users and applications to make use of such data and services. However, due to the heterogeneity of contents in information infrastructures, it is not possible to consider a unique metadata model or schema.

The diversity of metadata standards has been a critical issue for the development of SDIs. During the last fifteen years, standardization bodies have proposed different metadata standards such as the Content Standard for Digital Geospatial Metadata application profiles and extensions of these standards. The Dublin Core Metadata Initiative [4] defines a Metadata Application
Profile as a declaration of the elements (either selected from the standard, or new elements) that an organization or user community employs in their metadata, and how these elements have been customized to a particular application domain. Within data [7,8] , or the customization of general metadata standards such as Dublin Core [9] .

In parallel to the definition of this wide range of geographic metadata standards, there has been an increasing need for desktop or web-based metadata editors able to manage these complex standards (hundreds of elements with different data types organized in hierarchical entities) and providing, among other functionalities, an internationalized interface, online help, it can be verified that the development of these metadata editors has been highly promoted during the last years: about 50 tools have been published by different organizations and software companies. At the beginning, these tools were developed to support a unique metadata model. However, these first tools based on fixed structures became rapidly out-of-date. In contrast, nowadays current editors enable as well the configuration of the model using some kind of schema language.

From a software engineering perspective, we could say that annotation tools in the SDI context have moved towards a higher level of abstraction: the focus is now on the management of metamodels. According to ISO/IEC 11179 mechanism for understanding the precise structure and components of the specified models, which are needed for the successful sharing of the models by users and/or software facilities. Although the available documentation of most editors does not reveal a conscious interest on metamodels, the key component of these tools is the mechanism to describe the different metadata standards that can be used later to customize dynamically the software for editing metadata in conformance to these standards.
The need for flexibility and the consequent increase of model abstraction is leading the development of metadata editors to a stage that, although not directly intended, is close to the software engineering paradigm of Model Driven Engineering (MDE).
MDE focuses on models as the primary artifact in the development process, with transformations as the primary operation on models, used to map information from one model to another [12] . However, in order to avoid ad-hoc and un-efficient implementations of this MDE paradigm, it is important to follow a systematic and acknowledged methodology such as the one defined by the Model Driven Architecture (MDA), the OMG instantiation of MDE [13,19] . Although in the SDI context MDA has been considered for interoperability issues and data access services [14 metadata editors. The objective of this work is to provide the guidelines and framework to accomplish the development of metadata editors according to MDA in order to facilitate their rapid development, decreasing the development effort and, at the same time, augmenting their efficiency and flexibility. This paper presents the different domain specific languages and transformations required to define and transform the models involved in the development of a metadata editor: the Platform
Independent Model (PIM) for the representation of supported metadata schemas; the Platform Specific Models (PSM) for the transformation of PSM models into code.

The rest of this paper is structured as follows. Section 2 presents our proposal to apply an MDA approach in the development of metadata editors. Following this proposal, Section 3 describes how this proposal has been used in CatMDEDit, an open-source metadata editor, for the support of different metadata standards and profiles. Then, Section 4 describes the related work in the development of annotation tools from a metamodeling perspective, and discusses the benefits from applying an MDA development approach. Finally, Section 5 draws some conclusions and outlines future work. 2. Development of metadata editors according to an MDA approach 2.1. Overview
As stated by Djuri  X  et al. [17] , if we look back to the history of software development, we can see a notable increase in model evolution allows domain experts to focus on defining reusable models of the real world, alleviating them from acquiring the knowledge about specific computer systems. Two examples of this evolution are the methodologies known as Model Integrated
Computing (MIC) [18] and Model Driven Engineering (MDE). MIC was a precursor methodology for generating application programs automatically from multi-aspect models. Nowadays, MDE encompasses the software modeling methodologies which focus on creating and exploiting domain models (through successive transformations), rather than on the concepts of a specific computing platform.
Model Driven Architecture (MDA) is the OMG instantiation of MDE [19] . MDA separates the specification of system functionalities from the specification of this functionality on a specific technology platform. MDA defines three viewpoints on a system: a computation independent viewpoint, a platform independent viewpoint, and a platform specific viewpoint. Each viewpoint is represented by means of a viewpoint model (also called view). A Computation Independent Model (CIM) is a view of a system that does not show details of the structure of systems. A CIM is sometimes called a domain model and focuses on representing the environment and the requirements of the system. A Platform Independent Model (PIM) is a view of a system that focuses on the operation of a system while hiding the details necessary for a particular platform. It shows the part of the system specification that does not change from one platform to another, i.e. it is the specification of a system for a technology-neutral virtual machine. Finally, a Platform Specific Model (PSM) combines the specification in the PIM with the details that specify how that system uses a particular type of platform.

A crucial issue to allow the transformation between models in MDA is the appropriate definition of the domain specific languages, which are used in turn to build models. A domain specific language consists of three elements: an abstract syntax to define the concepts of the language, a concrete syntax to provide a graphical or textual notation, and a description of the semantics of the language [20] . The abstract syntax of a domain specific language is defined by means of a metamodel, which can be considered as an explicit description (constructs and rules) of the way to build a domain-specific model. Metamodeling allows strict and agile automatic processing of models and metamodels. Models in the MDA approach are based on the four-layer metamodeling pattern [21] : a meta-metamodel (M3) layer that provides concepts to define metaclasses of arbitrary conceptual schema languages (e.g., Class or Association for UML); a metamodel (M2) layer that defines the concepts used in a conceptual schema language (e.g., the concepts used in UML language); a model (M1) layer that contains models of the real world, which are represented by concepts defined in the corresponding metamodel at M2; and an instance (M0) layer that contains the things from the real world.

Fig. 1 presents our approach for adopting an MDA methodology in the development of metadata editors. In this approach, the following steps are considered:  X 
Analysis of metadata standards in terms of their original conceptual schema languages: the definition of a geographic metadata standard can be understood as the CIM model that originates the transformation between models towards the development of the metadata editor for such standard. For instance, Fig. 1 shows ISO 19115 from the perspective of the four-layer meta-modeling architectural pattern.  X 
Definition of PIM models in terms of a common metamodel: the previous CIM models are transformed into a PIM model, whose metamodel takes into consideration features that may arise in different metadata standards such as ISO 19115, Dublin Core and other ones.  X 
Generation of derived PSM models: the previous PIM models are transformed into PSM models that describe, in an abstract way, the GUI of the metadata edition forms. Additionally, the controlled vocabularies (e.g., codelists or enumerations) are transformed into the SKOS language [22] , a domain specific language proposed by W3C for the standardized representation of knowledge organization systems such as thesauri, taxonomies and other controlled vocabularies.  X  interpreted and executed ona specific platform.As a possible alternativefor the transformation PSM GUI-based models, we propose the serialization of the GUI-based models into an XML serialization, which can be parsed by a library to generate dynamically the edition forms implemented, for example, as a Java desktop application. With respect to the SKOS representation of vocabularies, their transformation into an SKOS-RDF encoding is proposed.
These steps are detailed in next subsections. With respect to the implementation of this approach, we have used the tools provided by the Eclipse Modeling Framework (EMF) [23] , which is currently used in many model driven approaches [16,24] . EMF is an open source Java implementation of a core subset of the Meta-Object Facility (MOF) specification [13] , a specification promoted by OMG to create an MDA framework for constructing and managing technology neutral metamodels. The MOF-like core metamodel in EMF is called Ecore. Additionally, EMF provides different tools for the transformation between models. In the case of the transformation from PIM to PSM models, the Atlas Transformation Language (ATL) [25] has been selected. ATL is a hybrid language that combines declarative and imperative constructs for the definition of transformation rules from source to target models. Finally, the transformation of PSM models to code (text serialization) has been designed using the MOFScript language, one of the most extended languages for model-to-text transformation [26] . For the sake of space only selected excerpts code of the metadata models in Ecore format, and the ATL/MOFScript transformations is provided, of the input and output models of these transformations. 2.2. Analysis of metadata standards (CIM models) Nowadays, there are three main families of metadata standards and profiles to describe geographic information resources:
Content Standard for Digital Geospatial Metadata (CSDGM) [2] , ISO 19115 Geographic Information still used and integrated in many GIS tools. ISO 19115 is the metadata standard that it is currently world-wide accepted and has been adopted by the great majority of national standardization bodies and thematic communities in the domain of geographic information. Finally, although Dublin Core is a general-purpose metadata standard, it is also widely used in the domain of geographic information to establish minimum discovery mechanisms and to promote interoperability [27] .

By its inherent nature, the definition of a metadata standard or a metadata profile can be considered as a CIM model of an generated through this system. In order to illustrate the features of these metadata standards and their correspondence with the four layer metamodeling perspective, this section describes the case of ISO 19115.
 The conceptual schema language used for expressing the comprehensive model of ISO 19115 metadata and their profiles is
UML. Additionally, several stereotypes have been defined for expressing special features of metadata models. Some of these form a list of named literal values; CodeList , a more open enumeration where the list of values can be extended if necessary; or Union , a set of alternative classes/types that can be used without the need to create a common super-type/class. For instance,
Fig. 2 shows a UML diagram with the definition of the class MD_Metadata , which is the root class in ISO 19115 for describing a geographic resource. The figure also shows a containment relationship with the MD_Identification class and its derived classes.
Additionally, UML static diagrams are accompanied with a data dictionary in tabular form, whose rows define UML classes,
Maximum occurrence , Data type , and Domain ). Fig. 2 includes two rows of the data dictionary describing the MD_Metadata class and one of its attributes. This example will be used to illustrate the MDA approach along this work.

The XML encoding of this metadata standard is specified through the ISO 19139 technical specification [28] , which establishes the rules to map the UML structure of the standard into an XML serialization through a series of XML Schemas. Trying to establish the parallelism among all these documents for the definition of the standard and the four layer meta-modeling perspective (see
Fig. 1 ), the UML metamodel and the XML metamodel would be at M2; ISO 19115 standard document and the associated ISO 19139 XML Schemas would be at M1; and ISO 19139-compliant XML metadata files would be at M0.

The other two metadata standards, CSDGM and Dublin Core, are described by means of other conceptual schema languages and artifacts: BNF (Backus  X  Naur-Form) and a DTD (Document Type Definition) for the syntax and XML encoding in the case of CSDGM; and the DCMI abstract model document [29] and RDF Schemas for specifying the constructs and RDF encoding of Dublin
Core. Although the mechanisms to express these standards are different, a parallelism can be established between UML classes and BNF production rules or RDF Schema descriptions. 2.3. De fi nition of PIM models in terms of a common metamodel set of heterogeneous documents. Some of these documents are UML models or schemas in conformance with a schema language (e.g., XML-Schema or DTD), but in other cases these documents are just plain text documents (e.g., documents with a description of elements organized into different sections, or data dictionaries not provided in tabular format that must be manually extracted). However, in order to apply MDA for the automated development of metadata editors we need a machine-readable definition of metadata standards and in one unique and compact document. For instance, analyizing the case of ISO 19115, we could have considered that the UML profile established in ISO 19103 language (DSL) for PIM models. Nevertheless, there are three main reasons not to recommend it. First, some problems found in the models of the ISO 19100 series (which includes ISO 19115) like the disregarding of the UML specification or some conflicting data types are an obstacle for the direct integration of these models in an MDA development [14] . Second, the automatic serialization of metadata in XML format cannot be directly inferred from the ISO 19115 model. Issues such as the URI for XML namespaces or XML attributes are not explicitly included in the UML model. Third, the ISO 19115 UML model does not include for a multilingual metadata editor with on-line help. Therefore, due to these weaknesses, we decided to propose a new DSL to define PIM models. Additionally, as many metadata standards and profiles are needed in this context of geographic information, our DSL is flexible enough to support at least the family of metadata profiles derived from ISO 19115, CSDGM and Dublin Core standards.

Fig. 3 shows the proposed common metamodel for the PIM models, i.e. the abstract syntax of the DSL. This metamodel has been built by means of the Ecore metamodeling language. The Package class is an auxiliary containment class that consists of a series of related standards (represented by the Standard class) and their derived metadata profiles (represented by the Profile class). The Term class represents any of the components that may be found in a metadata profile, e.g. an entity, an element, or a These possible modifications are stored in the intermediate class called TermInProfile .

All these classes have some attributes and peculiarities that should be noted:  X  namespace of the standard elements in an XML encoding.  X  used in the encoding of a metadata instance; and a one-to-many property association with the Property class to store additional information (i.e., label , definition , example ,or condition ) in multiple languages.  X  The Term class can be specialized into different classes:  X 
Entity : it represents a set of metadata elements describing the same aspect of data. The kind of entity is indicated by the attribute type , which may be: dataType (entity that represents a data type), class (entity that represents a class of the standard), and abstractClass (entity that represents an abstract class).  X 
Element : it represents an element that belongs to an Entity and has additional attributes: the obligation attribute identifies whether the element is mandatory , optional ,or conditional (i.e., mandatory under certain conditions expressed in a property different subclasses according to the data type of the information stored in a metadata record: SimpleDataTypeElement for well-known data types such asstrings,numeric types, dates or geometries (see the dataType attribute); ComplexDataTypeElement for data types defined by means of another Entity ;and VocabularyDataTypeElement for values that belong to a controlled vocabulary (see the Vocabulary class).  X  Attribute : it represents an additional element to characterize an Entity or an Element . This type of term is very common in the
XML representation of metadata standards. Although they are not explicitly mentioned in the documents defining the metadata standards, they are frequently required in their XML encoding.  X 
Vocabulary : it represents a controlled vocabulary. The type attribute indicates the specific type of controlled vocabulary: enumeration (a list of named literal values), codelist (a more open enumeration with a flexible list of named literal values), or thesaurus .  X 
VocabularyTerm : it represents an element of a controlled vocabulary that may be identified with a specific code .  X 
The TermInProfile class allows the redefinition of some of the features of a term contained in a metadata application profile. On be used to override additional information such as labels or definitions.

Tables 1 and 2 describe the mapping between CIM and PIM metamodels, i.e. the transformation rules between CIM and PIM models. Table 1 shows the association between the concepts of ISO 19115 UML and the PIM metamodel. Table 2 shows how the data dictionary attributes of ISO 19115 are directly included in the concepts of the PIM metamodel. Fig. 4 (left side) shows an excerpt of the ISO 19115 model in terms of the PIM metamodel, which has been edited with the EMF sample reflective Ecore model editor. According to the aforementioned CIM to PIM mapping, this excerpt corresponds with the UML diagram already shown in Fig. 2 . However, since CIM models can be expressed in very different conceptual schema languages (UML, BNF, XML
Schemas, RDF Schemas) and accompanying documents (with data dictionaries, additional information, etc.), it is not possible to propose a unique method for the transformation of CIM models into PIM models. Anyway, programs to parse, for instance, the ISO derived metadata profiles, in terms of a concrete syntax such as the TCS textual notation [30] . 2.4. Generation of derived PSM models
The next step in the MDA methodology is the transformation of PIM models into PSM models, which are closer to the final implementation of a metadata editor for a specific platform. An important decision in this step is to generate two distinct PSM models from the source PIM model. The first model enables the definition of the edition forms for the different entities of metadata records. The second model is focused on the representation of controlled vocabularies (codelists, enumerations or thesauri) that are imposed by metadata standards. Since there are well-known domain specific languages to represent and manage these vocabularies, our proposal is to reuse them instead of integrating these vocabularies within the language for defining edition forms. Additionally, this decision increases the flexibility of metadata editors for the semantic annotation of resources with well-known knowledge sources already available in SKOS format [31] . 2.4.1. A PSM model for edition forms
Before deciding which would be the most appropriate domain specific language for the definition of the edition forms that should enable the update of a metadata record in conformance to a specific profile, a set of functional requirements were established:  X 
The edition interface of a metadata profile should consist of a synchronized set of edition forms, each of them focused on a particular entity of the profile.
  X 
An edition form should only show those elements that belong to the metadata profile.  X 
An edition form should avoid the complexity of inheritance hierarchies between entities. An edition form should facilitate the edition of both the own elements of the entity and the elements inherited from its super-entities (i.e. the parentEntity association in the PIM metamodel).  X 
An edition form should avoid the recursive hierarchical relations between entities and sub-entities, i.e. the complexDataType association of ComplexDataElements that belong to an entity in the PIM metamodel (see Fig. 3 ). In the case of editing a
ComplexDataElement , a subordinate edition form should be opened.  X 
An edition form should provide enough internationalized information to understand the meaning and features of elements.  X  An edition form should be able to parse and generate the XML encoding of an entity.

Taking into account these requirements, we considered first the adoption of existent GUI description languages like XUL,
SwingML (Swing Markup Language) [32] or SwiXML. 4 All these languages allow the possibility of defining a user interface by main problems for the adoption of these languages. On the one hand, there is a big semantic difference between the high-level concepts of the PIM model and the low-level GUI widgets provided by these GUI languages. For instance, one could consider that a single data element of a PIM model could be easily transformed into a set of widgets provided by these languages consisting of: richer GUI constructs are needed to take into account the obligation of an element, introduce appropriate masks according to the data type (e.g., masks for dates, numbers or geometries), or provide internationalized information. edition forms should embed enough information to deal with the XML encoding of an entity. Although the metadata editor does not need to show the XML tags (and their attributes) to the final user, this information should be stored in some kind of special hidden GUI artifacts, not directly supported by these languages.

Therefore, due to the difficulties to adapt these languages for the required functional requirements, the final decision was to define a new domain specific language. Fig. 5 shows the metamodel of the proposed language. In this metamodel, a metadata form of an entity. In turn, these EntityContainer objects contain ContentElement objects, which represent a GUI widget for the edition of a metadata element. This proposed language fulfills the required functional requirements, but still provides enough flexibility to transform a user interface based on this language into a final code implementation that may operate on different platforms (desktop or web applications). The objective of this language is to provide an intermediate step for the final forms. The ContentElement class is the superclass of a hierarchy of subclasses according to the data type and multiplicity of elements. The aim of this inheritance hierarchy is to facilitate as much as possible the model-to-text transformations.
Table 3 shows the mapping between the concepts in the PIM and GUI-based PSM model. This mapping has been implemented using the ATL language. For the sake of space Fig. 6 only presents the rule to transform Entities of the PIM model into
EntityContainers of the PSM model. Among other things, this rule makes use of helper functions to identify its internationalized
ATL resolve algorithm. Fig. 4 (right side) shows an excerpt of the ISO 19115 MD_Metadata entity in terms of the PSM model (using the EMF sample reflective Ecore model editor), which has been derived from its corresponding PIM model. This figure exemplifies of MD_Metadata is not present in the Core profile); the EntityContainer objects include elements from super-entities ( MD_DataIdentification includes the elements from MD_Identification ); every EntityContainer and ContentElement has its own URI. 2.4.2. Using SKOS for the representation of controlled vocabularies
SKOS (Simple Knowledge Organization System) is a family of formal RDF-based languages for representing controlled structured vocabularies, including thesauri, classification schemes, taxonomies and subject-heading systems [22] . SKOS is currently developed within the W3C framework and has been widely accepted by the research community and the industrial sector since the initial proposal of this language in the SWAD-Europe research project. This wide acceptance was mainly due to thesauri (ISO 2788 and ISO 5964) did not include a standardized representation format. Currently, these norms already include a
XML-based representation format. However, in contrast to RDF-based languages such as SKOS, this XML representation limits its applicability for the publication of controlled vocabularies using Semantic Web technologies. Therefore, given the wide acceptance of this SKOS language for publishing well-acknowledged vocabularies (e.g., GEMET, AGROVOC, and other well-known thesauri used for the annotation of SDI resources are available on the Web in SKOS format), and the availability of multiple software libraries 6 for managing SKOS vocabularies, we decided to select the SKOS language as the domain specific language for representing controlled vocabularies in metadata editors.

Fig. 7 shows the main elements of the metamodel of the SKOS language. A controlled vocabulary consists of a set of concepts (represented by the Concept class) grouped in a concept scheme ( ConceptScheme class). Each concept is linked to its textual notations (e.g., ISO 19115 provides a numeric code for each member of a code list or enumeration that could be represented in the among concepts: the related association is used to denote any type of connection between two concepts; the broader and narrower associations are used to establish hierarchical relations (i.e., one concept is more general than another). Fig. 7 also shows an example of controlled vocabularies defined as PIM models and how they can be converted by means of ATL transformations into the SKOS language. The figure shows the main transformation rules that map Vocabularies to
ConceptSchemes ( Vocabulary2ConceptScheme rule), and VocabularyTerms to Concepts ( VocabularyTerm2Concept rule). 2.5. Text generation
The last step proposed in the MDA methodology is the transformation of PSM models into textual representations that can be parsed by software libraries to generate the metadata edition forms, in the case of GUI models, and browse the terms from controlled vocabularies, in the case of SKOS models.
 is shown in Fig. 8 . The transformation is quite immediate as each element from the GUI model has a unique correspondence with a 19115 MD_Metadata entity is shown on the right-hand side.

An equivalent MOFScript rule is used to transform the SKOS vocabularies into SKOS-RDF files (see Fig. 9 ). It generates a separate file for the SKOS-RDF encoding of each ConceptScheme . An example of the generated RDF for the MD_ScopeCode codelist is shown on the right-hand side of Fig. 9 .

Based on these XML and SKOS-RDF encodings, Fig. 10 shows the design of a prototype implementation for a software library the graphical components of the Java Swing library. The EditionFormRenderer class is in charge of the dynamic generation of the
EntityContainer class of the PSM metamodel (i.e., the edition form for the root entity in the metadata standard). Apart from providing methods to parse and generate the XML encoding of a metadata entity, the EntityContainer class holds a containment association with the ContentElement class, which is in turn the Java implementation of the corresponding class in the PSM metamodel. This class and its subclasses are in charge of creating the appropriate GUI widgets for rendering the values and or derived classes from MultipleSimpleContentElement ) hold a reference to a JTable component to manage multiple occurrences of retrieve codelists and enumerations represented in SKOS. This SKOS-RDF API may wrap the access to a generic library for RDF management such as Jena or Sesame, or SKOS-specific libraries such as ThManager [33] .

Fig. 11 displays a screenshot of this prototype implementation, enabling the edition of a metadata record that describes a view of the tree structure, which is modeled with the GenericTree and GenericTreeNode classes connected with the EntityContainer must be filled with a value from a controlled vocabulary. Apart from providing a JTable component to manage multiple occurrences special conditions for obligation or examples. Fig. 11 also shows the XML encoding that would be parsed or generated for this metadata element ( getXML and setXML methods of ContentElement class in Fig. 10 ). 3. Testing the MDA approach in CatMDEdit
CatMDEdit is a Java-based Open Source tool for the semantic annotation of geographical information. Initial versions of this tool were directly implemented around the logical model of an extended version of the CSDGM metadata standard. However, with the approach was costly and error prone. Since version 3.7, the development team decided to adopt the MDA approach that has been with the software components to manage them, became the essential core of the architecture of this metadata editor.
Fig. 12 shows an architectural view of CatMDEdit, which follows the module viewtype of the
A module viewtype partitions the system in code units (modules) with certain responsibilities. Additionally, viewtypes can have a on the main features of the application and those modules related to the MDA approach (highlighted in yellow), Fig. 12 provides a hybrid style module view with UML notation that combines the following styles: decomposition , which shows the structure of modules and submodules; use , which indicates functional dependency relations among modules; and generalization , which indicates specialization relations among modules. There are three main modules in the application: a UserInterface module aggregating the submodules providing the main functions of the application with GUI interaction; a KernelLibrary module providing core support to the UserInterface submodules; and a DataAccess module in charge of the accessing the data, metadata and vocabularies, which are managed or produced by the application.

The Resource Browser submodule contains the code of the main browser that enables the navigation of resources organized in different repositories. It is a specialization of the generic Browser submodule in the KerneLibrary ,whichusesthe
MetadataAccessManager to have access to metadata repositories. Additiona lly, it invokes the rest of the functions available in the application: a resource viewer, and a metadata editor. The resource viewer ( ResourceViewer submodule) facilitates the connection with external applications (e.g., GIS tools such as JGISView or gvSIG represented as submodules in DataAccess module) through an application manager ( ApplicationManager submodule) [35] . The metadata editor ( MetadataEditor submodule) facilitates the edition of the metadata describing a resource thanks to the integration of a MetadataFormRenderer , which facilitates the dynamic configuration of metadata edition forms according to the metadata standard/profile followed by each metadata record.

The MetadataFormRenderer submodule is a specialization of the EditionFormRenderer submodule of KernelLibrary , which files, which are accessed through the EditionFormSpecificationAccessManager . This submodule also uses submodules of ThManager [33] , an implementation of the technology required for accessing and displaying controlled vocabularies in SKOS-RDF format.
Finally, it must be noted that the MetadataEditor submodule makes use of other two submodules: ContactDirectory , which to a browser of available thesauri to select keywords/topics for the classification of resources. These two submodules apply the same pattern used in resource metadata for browsing and rendering the edition forms. Both submodules integrate specializations of the generic Browser and EditionFormRenderer submodules to navigate and edit contact information and thesaurus metadata in conformance with Dublin Core metadata profiles.

Once we have introduced the architecture of the tool, Table 4 shows the 11 metadata profiles for the annotation of geographic information resources (derived from ISO 19115 and Dublin Core), whose edition forms and vocabularies have been generated using the MDA approach and integrated in CatMDEdit. The table columns present: the name of the profile; the standard from multilingual information ( Prop ) found in the PIM metadata model; and the different languages supported. Additionally, although
CatMDEdit is primarily intended for editing geographic metadata, it can be also customized to support new standards and metadata profiles according to different user needs. Table 5 shows a list of 9 metadata profiles that have been included in resources.

In order to validate the benefits from adopting this MDA approach, we have compared it with the development approach of new logical model to support the persistence of metadata according to this new standard and a specific GUI to support the edition of metadata records according to this profile. For this comparison between approaches, the following dimensions have been considered: development effort, legibility, modularity, ease of maintenance, and extensibility (similar dimensions have been considered in other MDA works for comparison [46] ).

With respect to the development effort, using the old approach the implementation of the ISO 19115 comprehensive profile, which includes all entities in the ISO 19115 standard (126 entities and 345 elements, see Table 4 ), involved the programming of a minimum number of 252 Java classes. Each standard entity required two classes: one class taking part in the logical model of the application and in charge of handling the XML encoding of an entity and its elements; and, at least, another class (usually coordination with the logical model, internationalization, etc.). For a metadata profile including a big number of entities, this development process was error-prone as it required a long phase of testing to verify the correct XML encoding or the no omission of any element. In contrast, using the MDA methodology, the inclusion of a new metadata profile involves no programming at all. The developer (metadata profile designer) just focuses on introducing the features of this new standard using the domain specific language proposed for the PIM models. Additionally, if the information of the base standard has been previously introduced for other profiles, the developer only needs to indicate which entities and elements belong to this new profile.

About legibility, in the old approach the structure of the metadata standard was scattered in multiple separate classes, both for to understand the code if the programmer had not followed a strict programming policy (e.g., arrange classes in different language for defining the PIM models is a high-level language, easy to understand because it incorporates the same concepts that are used in the documents describing the standards and metadata profiles.

Regarding modularity, when using the old approach, similar pieces of code were repeated in the classes of the logical model application. In contrast, with this new approach each element type is rendered and serialized by a unique software component (see hierarchy of ContentElements in Fig. 10 ).

With respect to the ease of maintenance, any modification introduced by a new version of a metadata standard (and its XML encoding) required new updates in the old approach software: new classes if new entities had been proposed; or the update of existing classes if some new elements had been added or removed. On the opposite side, using the new approach we just need to introduce the modifications in the PIM models and generate automatically a new version of XML files describing the edition forms. The software code does not require any update or compiling.

Finally, regarding extensibility and as already discussed, the support of new metadata profiles in the old approach required a hard effort of coding. In contrast, the incorporation of new metadata profiles based on supported standards is quite immediate: the metadata expert just needs to create a new PIM model picking the elements of the profile and modify, if necessary, some of definition in the PIM model of a complex data type element (see ComplexDataTypeElement in Fig. 3 ), whose complexDataType is promote the ergonomics and ease of use of the metadata editor, the developers can consider the creation of new GUI widgets specialized on these data types. Although this last alternative requires a higher development effort, this effort is located in well-identified parts of our MDA approach: define a new data type in the DataTypeCode codelist of the PIM metamodel; define a new type of ContentElement in the GUI PSM metamodel; program a new GUI widget for the edition form renderer; and add small modifications in ATL and MOFScript transformation rules. Additionally, this effort is quickly recovered if new metadata profiles and standards have the same requirement. 4. Related work
Given the increasing importance of geographic metadata, numerous software packages (dedicated tools or plug-ins in GIS tools) have appeared during the last decade for the creation of metadata. The Wisconsin Land Information Clearinghouse (WiscLINC) [10] and the Federal Geographic Data Committee [47] provide detailed reviews of edition tools based on CSDGM (the old North American standard) and ISO 19115 metadata standards. Without being exhaustive, the first review, last updated in 2006, reports 24 metadata edition tools (21 compliant with CSDGM and 6 compliant with ISO 19115), 10 metadata utilities, and 4 metadata servers. The second review, made between 2007 and 2009, is focused on a thorough analysis of eleven ISO 19115 metadata editors.

The purpose of this section is not to make another review of metadata editors, but to analyze some of them from a metamodeling perspective and how this aspect may affect their flexibility to satisfy new requirements. Tables 6 and 7 review 13 metadata editors with respect to the metamodeling layer they are based on (see metamodeling layers in Section 2.1 ). Being an
M1-layer based tool (6 tools in Table 6 ) means that the logical model of this tool has a direct correspondence with the standard it supports. On the contrary, being an M2-layer based tool (7 tools in Table 7 ) means that the tool is able to understand a metamodel and parse different metadata standards expressed in terms of this metamodel. Additionally, apart from showing the layer category, these tables show other features: distributor, platform (and interface), year of first and last known releases, standards supported, and an explanation for being included w ithin the M1 or M2 category. The tables only report metadata editors about which we have clear evidence from their source code or from literature about their design approach. This is the reason to exclude three tools from the study (MetaD, Preludio, terraCatalog) that are included in the review of ISO metadata editors [47] .

As it can be observed in Table 6 , only one M1-layer based tool (ArcCatalog) from the CSDGM era has been able to evolve and support partially the complexity of ISO 19115. Obviously, one of the reasons for this lack of maintenance may be the change of company objectives in a ten-year frame. But probably, the most important reason can be found in the approval of ISO 19115 as an international standard in 2003 and the convergence of national initiatives such as CSDGM towards this international standard [58] . The high costs involved in adapting old metadata editors to the complexity of this international standard (more than 400 elements organized in hierarchical and recursive structures) can explain the decision of abandoning the maintenance. The WiscLINC review [10] identified 23 historical tools (or utilities) compliant with CSDGM whose maintenance had been stopped.
Even ArcCatalog, the M1-layer tool providing support for both CSDGM and ISO 19115, only offers a partial coverage of the ISO logical model of this tool supports the CSDGM metadata elements, some ESRI-defined elements, and a partial set of ISO 19115.
CSDGM, ESRI and partial ISO 19115 content coexist in parallel in the metadata XML documents maintained by ArcCatalog v9.3 [60] .

In general, it can be stated that the life-time of the analyzed M1-layer tools is potentially shorter than the M2-layer ones higher costs involved in upgrading M1-layer based tools to satisfy new standard requirements can be observed even for those tools initially developed to support ISO 19115. KaR Metadata Toolkit is no longer available, and MetaGenie only covers a partial in 2006, the appearance of different ISO 19115 profiles, and the continuous flow of XML encoding proposals before the publication of ISO 19139 have made the upgrading of M1-layer based tools extremely complicated.
 As a conclusion, there is a clear tendency towards the implementation of metadata editors using the metamodeling concept. does not differ too much from similar M2-layer tools. However, the real advantages of applying our proposed MDA approach are the tools and infrastructure provided by MDA. Using textual or graphical notations such as TCS [30] or GMF (Graphical Modeling
Framework 7 ), the metadata designer can define PIM models using a high-level domain specific language which is very close to the concepts expressed in the documents delivered by standardization bodies. Once these PIM models have been defined, it is possible to generate automatically the configuration files that are required by a specific metadata editor software. To our knowledge after reviewing the literature of tools in Table 7 , none has applied the MDA methodology to transform a high-level definition of the metadata standard into a set of low-level configuration files, which are usually hard to understand for a non-expert developer.
 Additionally, the adaptation of the MDA approach proposed in Section 2 can be easily applied to any of the tools described in
CatMDEdit, the proposed framework (domain specific languages and transformations proposed in Section 2 ) can be adapted to metadata editor software. Besides, using this approach, the internationalization of the metadata standard concepts (e.g., labels, technical level (e.g., by means of multiple instances of external property files). 5. Conclusions
This paper has presented the guidelines to apply an MDA approach for the development of annotation tools, which can be customized to different metadata standards and profiles with minimum effort. Applying this approach, experts in metadata standards (without any special programming skills) can focus their efforts on the definition of new metadata models using a domain specific language (the one used to define PIM models), whose abstraction level is close to the way of expressing metadata standards in the documents provided by standardization bodies. After this high-level definition, the PIM models are automatically platform for annotating resources.

The feasibility of these guidelines for applying MDA has been tested with CatMDEdit, an open source metadata editor supporting multiple metadata standards and profiles. Following this MDA approach, 11 metadata profiles derived from ISO 19115 and Dublin Core have been incorporated in CatMDEdit for the annotation of geographic information resources. Anyway, this metadata profiles have been integrated in the tool for the annotation of a wide range of resources such as photographs, services, maintenance and extensibility), it has been proven that the adoption of this MDA approach outperforms the initial versions of
CatMDEdit, which did not follow this development philosophy. The initial versions of this tool, as well as other M1-layer based tools, were implemented around a logical model (directly hardcoding the structure of the metadata standards) and were very sensitive to any upgrade of metadata standards and profiles.

Another issue that must be taken into account is that this MDA approach is not only applicable for the development of desktop applications like CatMDEdit. For instance, this MDA approach has been successfully applied for the development of a Web application for editing metadata for geographic web services [61] .ThewholeinfrastructurefortheprocessingofPIMand
GUI-based PSM models was reused. The only thing created specifically was a renderer for Web edition forms, which was customized to the specific features of GWT (Google Web Toolkit) technology. A similar adaptation of the approach could be also applied to improve the efficiency of other metadata editors using a metamodeling perspective (i.e., M2-layer based tools where supported metadata standards can be configured). The domain specific languages and transformations presented in this paper would provide the users of these tools with the appropriate MDA infrastructure to focus the development effort on defining reusable models of metadata standards, and alleviating them from the technical details of configuration files.
As future work, we will work on the evaluation of different concr ete syntax notations (visual and textual) for the definition of PIM models. In order to test these different syntaxes, we plan to integrate them in a new release of CatMDEdit. This would allow final users to define metadata standards and profiles i n a more expressive way, and hide the details of model-to-model and model-to-text transformations (which would be executed automatically). Additionally, instead of using the Ecore metamodeling language for defining the PIM metamodel, we will study the use of other languages with more expressive power (e.g., PVS or Eiffel [62] ), which could help us to check automatically the conformance to some special constraints of metadata profiles (e.g., a profile can only impose a more stringent obligat ion on existing metadata elements), not fully expressed with Ecore.

References
