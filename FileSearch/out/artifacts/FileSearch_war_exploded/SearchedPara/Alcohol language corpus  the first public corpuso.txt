 Abstract The Alcohol Language Corpus (ALC) is the first publicly available speech corpus comprising intoxicated and sober speech of 162 female and male German speakers. Recordings are done in the automotive environment to allow for the development of automatic alcohol detection and to ensure a consistent acoustic environment for the alcoholized and the sober recording. The recorded speech tration measurements are provided for all speakers. A transcription according to SpeechDat/Verbmobil standards and disfluency tagging as well as an automatic phonetic segmentation are part of the corpus. An Emu version of ALC allows easy access to basic speech parameters as well as the us of R for statistical analysis of selected parts of ALC. ALC is available without restriction for scientific or com-mercial use at the Bavarian Archive for Speech Signals.
 Keywords Speech corpus Alcohol detection Intoxication Speaker features and forensic phonetics 1 Introduction It is a widely accepted hypothesis that alcoholic intoxication as other factors such as studies during the last decades have investigated this hypothesis from different points of view: looking for reliable acoustic (Cooney et al. 1998 ;Ku  X  nzel and Braun 2003 ) or behavioristic (Behne et al. 1991 ; Hollien et al. 2001 ; Sobell et al. 1982 ; Trojan and Kryspin-Exner 1968 ) features that may indicate intoxication, studying the physiological effects of alcohol on the articulators (Watanabe et al. 1994 )or even pursuing forensic questions (Braun 1991 ; Klingholz et al. 1988 ;Ku  X  nzel and Braun 2003 ; Martin and Yuchtman 1986 ) such as in the infamous case of the captain of the Exxon Valdez (Johnson et al. 1990 ). Unfortunately, all these studies have in common that the analyzed empirical speech data are not available for other research groups.

To our knowledge up to this point nobody has ever seriously claimed to be able to detect the grade of intoxication from the speech signal by means of automatic methods alone. However, if researchers are ever to develop such a method, they will first need a corpus of intoxicated speech produced not only in the lab but also in a possible real life situation.
 This article describes a new speech resource at the Bavarian Archive for Speech Signals (BAS) 1 containing speech recordings from sober and intoxicated speakers. The Alcohol Language Corpus (ALC) was recorded over a time period of 30 months (2007 X 2009) in close cooperation with the Institute of Legal Medicine, Munich, and the German  X  X und gegen Alkohol und Drogen im Strassenverkehr X  2 (BADS). ALC comprises alcoholized and sober speech of 162 male and female German speakers aged between 21 and 64 who were tested by breath and blood samples, recorded outside the laboratory and with a variety of speech styles.
There were three main motivations to produce ALC: 1. Forensic speech sciences: Former investigations of alcoholized speech report 2. Phonetic sciences dealing with speaker characteristics/biometrics: In the last 3. Alcohol detection in the automotive environment: Alcoholic intoxication (AI)
Aside from these primary motivations the resulting corpus may be used for other investigations/applications such as:  X  automatic speech recognition in the automobile  X  human machine dialogue design in the automotive environment  X  discourse analysis
The remaining article is structured as follows: In Sects. 2 and 3 we will give some considerations regarding the corpus design and describe the recorded speech items of ALC followed by Sect. 4 which describes the recording procedure including all factors that might have an influence on the speech signal and how they have been registered for the corpus. Section 5 gives an overview about the transcription and tagging schema. In Sect. 6 the post-processing of the raw data will be outlined including the automatic segmentation into words and phonemic segments while Sect. 7 gives a brief description of the resulting Emu database. Section 8 lists speaker and recording statistics as well as information about accessibility before we conclude with a list of some of the ongoing projects based on ALC in Sect. 9 .
 2 Corpus design with regard to previous studies There are some inherent questions to be answered when dealing with speech from intoxicated persons before starting the actual data collection: 1. How to measure the intoxication? 2. Which persons are to be tested? 3. How many speakers? 4. What type of speech should be analyzed? 5. How to evoke realistic speech from intoxicated persons? Ethical considerations 6. Which acoustic environment? The acoustic environment should be as realistic
The next two sections will give the details of the recorded content and the recording procedure used in ALC, which more or less directly result from the considerations above. 3 Recorded speech ALC contains a variety of speech styles: read, spontaneous and command and control speech in various forms. Table 1 lists all recording types for the intoxicated case (set A =  X  X lcoholized X ) and the sober case (set N =  X  X on-alcoholized X ). 5 While designing the read speech part, combinations of sounds were emphasized that have been reported as being affected by alcoholic intoxication (e.g. Ku  X  nzel et al. 1992 ), such as /s/ in contrast to / contrast to their voiced counterparts /b/, /d/, /g/ as well as the nasals /m/ and /n/. Digit strings are represented by telephone, credit card and license plate numbers. intoxicated speakers increase their articulation errors. The selected tongue twisters are of rare types that are not generally known to avoid the case where speakers are able to speak them by heart. Read commands were taken from a real automotive voice control application. Addresses are real addresses selected from a geo database which are either difficult to pronounce (e.g.  X  X chwester-Hermenegildis-Strasse X  )or contain interesting sound combinations as pointed out above (e.g.  X  X adapaka-German cities.

The picture description, question answering and dialogues have a maximum recording time of 60 s. Speakers are not forced to fill the 60 s time slot to avoid unnatural silence intervals. Each speaker described six examples taken from a collection of psychological test pictures. Then she/he answered/discussed the following questions/topics:  X  X hat was the nicest present you ever received? X   X  X ell me about your last vacation. X   X  X hat do you think of Christmas? X   X  X iscuss the previous intoxication experiment. X 
Particularly the question answering and the dialogues evoke spontaneous speech that comes fairly close to real-life-situations.

Spontaneous commands are control commands from the same scenario as the read command items formulated by the speaker herself following directions on 2006 ).

Items are presented in a fixed randomized order except that all the command and control type items (1/3 in each set) are grouped together at the end of each session, during which the engine of the car is switched on. 4 Recording procedure All speakers voluntarily participated in an intoxication test supervised by staff of the Institute of Legal Medicine. These intoxication tests are organized on a regular basis by the BADS. Beside the speech recordings for ALC these intoxication tests are intended to enhance the sensitivity of legal professions, medical personnel and law enforcement officers to the possible influence of alcoholic intoxication.
Each speaker participating in ALC signs a legal form stating that she/he gives her/his consent for the scientific and technical use of the recorded speech, under the condition that the corpus contents may not be associated with personal data.
Before the actual test each speaker chooses the blood alcohol concentration range is between 0 : 3 and 1.5 &amp; . To estimate the required amount of alcohol we use the Widmark formula (Widmark 1932 ): where c is the alcohol concentration (in &amp; ), V is the amount of consumed alcohol (in g), m is the body mass (in kg) and r is the reduction factor, depending on gender, age and body mass.

To estimate r we apply the extended Watson formulas (Watson and Watson 1980 ) for the body water content of females and males where t is the age (in years) and h is the body height (in cm), and combine g with the density of blood q b  X  1 : 055 g cm 3 and the fraction of water in blood f = 0.8: Inserting ( 3 )in( 1 ) yields the necessary amount of alcohol (in g): Finally V has to be re-calculated into amounts of beer or wine respectively.
After having consumed the estimated amount of alcohol within the maximum time period of 2 h, the speaker has to wait another 20 min before undergoing three tests: BAC, BRAC and speech recording.

We use two different BRAC testers of the same technology: Dra  X  ger Alcotest conversion from mg/l BRAC to &amp; BAC, and an Envitec Alcotest, similar in construction. The BAC is determined by Head-Space Gaschromatography as used in forensic analytics but without ADH-method averaging over repeat determination. To avoid any significant changes (saturation, decomposition) of the measured BAC the speaker is asked to perform the ALC speech test immediately after the alcohol tests, which lasts no longer than 15 minutes. After a minimum of two weeks later the speaker is required to undergo a second recording in sober condition, which takes about 30 min and includes two times as many prompts as the test in intoxicated condition. A randomly selected group of 10 male and 10 female speakers is recorded for a third time after another delay of at least 1 week under the exact same recording condition as the first test but without being intoxicated. This control group provides data to check for unknown factors that may influence the speech signal beside the effects of intoxication.

To factor out other influences, in all tests the speaker is interviewed beforehand about any pathological or psychological events that may affect her/his speech. If any such factors are evident, the test is either postponed or the speaker is not included in ALC at all.

All the recordings take place in one of two standard cars 6 , to ensure the same acoustic environment for the different recording locations. The engine is switched off for 2/3 of the recordings and switched on for the application speech to create a realistic ambience for voice control commands. For security reasons no recordings are performed in the moving car. Each test, in intoxicated and sober state, is supervised by the same member of the ALC staff, who at the same time acts as the respective task is prompted on the display. For all text-prompted recordings (read speech), the text prompt is not visible before the speaker hits the record button. To compensate for early recording stops (that is, the speaker hits the stop button while still speaking) SpeechRecorder was configured to delay the recording by another 500 ms. Speakers are not allowed to repeat a recording unless there is a technical problem. In cases where there are two or more versions of a recording item, the first recording containing a serious attempt is selected for the corpus.
 The speech signal is captured by two microphones: one headset Beyerdynamic Opus 54.16/3 and one AKG Q400 mouse microphone, frequently used for in-car microphones are connected to an MAUDIO MobilePre USB audio interface where the analog signal is converted to digital and transferred to the laptop. The sampling rate is 44,1 kHz, 16 bit, PCM.

Aside from the speech signal we collected a number of meta data about speakers and recording conditions to allow statistical cross testing for other factors than the main factor sober/intoxicated. Table 2 summarizes these meta data. Meta data are provided in SpeechDat compatible (SpeechDat Deliverable 2010 ) speaker and session tables. A pronunciation dictionary lists the citation form of each word token found in ALC coded in SAM-PA (Wells 1997 ). 5 Transcription and tagging All recordings are annotated and tagged using the web-based annotation tool WebTranscribe (Draxler 2005 ) and applying SpeechDat transcription conventions (specified in SpeechDat Deliverable 2010 ) extended by a subset of the German Verbmobil (e.g. Burger et al. 2000 ) conventions as summarized in Table 3 .
The following additional guidelines were applied in the transcription:  X  the orthographic transcription is as close to the spoken material as possible, even  X  no punctuation marks are used  X  spelled words are transcribed with space-separated capital letters  X  speech of the dialogue partner as well as cross-talk is not transcribed
Aside from the transcript the annotator counts irregularities which occur within a recording. 7 The irregularity count is supposed to be a gold standard for the detection of disfluencies: if this counter does not show significant differences between intoxicated vs. sober speech, it does not make sense to work on automatic means for phenomena within the speech signal that can be considered not to be part of error-free fluent speech:  X  tagged silence interval if it can be considered as a hesitation  X  abnormal word lengthening  X  filled pause  X  wrong pronunciation or word truncation  X  correctional truncation  X  repetition or stutter
Where more than one repetition or stutter is observed after another, this group of including other irregularities are also counted as one irregularity. Hesitations occurring before correctional truncations are dealt with separately and thus result in attributed to the truncation and in this case only one irregularity is counted.
Additional switches for each recording are set by the annotator for the perceived condition of the subject: inconspicuous, lightly intoxicated, heavily intoxicated ;in cases where the recording contains no speech it is marked as useless .
Finally, in each recording the beginning and end of speech is marked on the time line to improve further automated processing. Thus, pauses that occur at the marked in the transcription.

The described ALC annotation is performed as a one-pass process, that is no second manual verification of the annotation is applied. Unclear cases are marked as such by the individual annotator, and then discussed among annotators in regular meetings. Three different annotators participated in the ALC transcription. 6 Post-processing Figure 1 depicts the data flow of the post-processing after the completed annotation and tagging.

After a consistency check on sound and annotation files word tokens are harvested from the annotation and cross-checked against the ALC pronunciation dictionary. If an unknown word token 8 is found, a citation form pronunciation coded in SAM-PA (Wells 1997 ) is inserted into the lexicon either by lexicon lookup from PHONOLEX (Large German Pronunciation Dictionary PHONOLEX. URL http:// www.bas.uni-muenchen.de/Bas/BasPHONOLEXeng.html .Cited 2012 )orbyapply-ing the text-to-phoneme method BALLOON (Reichel and Schiel 2005 ).

BAS Partitur Format files (BPF) 9 are created for each recorded sound based on the annotation and tagging described in Sect. 5 . They comprise the tiers orthography (ORT), pronunciation (KAN, derived from the dictionary) and recording segmen-tation (TRN, derived from the annotation).

The KAN and TRN tiers serve as basis for the automatic phonetic segmentation and labeling performed by the Munich AUtomatic Segmentation system (MAUS, Schiel 1999 ). In a validation on German face-to-face dialogue speech (Kipp et al. 1997 ) the MAUS segmentation scored a label accuracy of 93.8% of the inter-labeler agreement, while the segmental boundary accuracy (deviations of &lt;20 ms) was about 90.3% of inter-labeler agreement. As with all automatically performed segmenta-tions the MAUS segmentation can serve to localize anchor points such as word boundaries and syllable nuclei, but not for fine-grained phonetic duration analysis such as voice onset time. MAUS segmentations of dialogue recordings should not be used without prior manual checking, since cross-talk may affect the segmentation quality. No formal validation on the segmentation quality was performed in the ALC project due to budget reasons. However, informal random checks on longer spontaneous speech recordings and dialogue speech in intoxicated speech of ALC showed no deterioration compared to the segmentation of normal speech. 7 ALC Emu database filtering of unwanted versions, an Emu database of ALC is added to the corpus distribution (Cassidy and Harrington 2001 ). In contrast to the base corpus the Emu database contains only one validated recording for each prompt item. See also Table 7 for detailed figures derived of the ALC Emu database.

Emu annotation files are derived from the phonetic MAUS segmentation and stored on the phonetic layer. The segmental information is propagated up to the word layer, which carries an additional label describing the canonical pronunciation form of each word (cano). 10 The word segments are then integrated into the utterance layer which also contains a complete set of meta data labels as listed in Table 4 .

The label irreg contains a string of nine counters based on the manual transcript as described in Table 5 . The labels type and content allow a rough classification of the recording into speech type and content classes as depicted in Table 6 .
Since an Emu database can be queried across hierarchical layers this mechanism allows very elegant grouping and participation of the whole dataset according to meta data values. Via the R language (R Development Core 2005 ) interface of Emu the same queries can be used to load labels, segmental information as well as derived feature signals (e.g. fundamental frequency, energy, formats) into R for further analysis. 8 ALC in numbers This section summarizes the most prominent figures of ALC and provides some statistics based on the actual corpus that might be useful for the prospective user. 8.1 Detailed numbers In its present state the ALC corpus covers the alcoholized and non-alcoholized speech of 77 female and 85 male speakers. 86% of all speakers were born in southern German states and also attended the first 4 years of school there; 96% have an university degree; 22% are smokers.
 The ALC distribution totals in 30Gbyte and is distributed on DVD-R via the ELRA or BAS. 11
Table 7 lists the absolute numbers and percentages regarding speakers, recordings, duration, word tokens, lexicon size, phone tokens and tagging of the three data groups alcoholized, non-alcoholized and control . Please note that the numbers for the sub-groups read, spontaneous and command and control do not add up to 100% since the latter consists of both read and spontaneous speech.
The percentages given in Table 7 are either with regard to a total (marked as group. For instance 2.27% of all word tokens recorded in the alcoholized condition are hesitations. In case of the tag irregularity this base number differs from those of the remaining tags because the tag irregularity was applied only to a subset of recordings.

Tags showing a highly significant difference ( p &lt; 0.0001) between alcoholized and sober condition are marked with  X * X . 8.2 Some Interesting Cases The number of word tokens in the sub-group spontaneous speech reveals that in average speakers utter more words per recording item in sober condition than being intoxicated (set N: 50.84 vs. set A: 46.74 , t = 3.9, p = 0.0001688 12 ) which correlates with findings about a higher speech rate of sober speakers reported in a recent study (Schiel et al. 2010 ). This was rather unexpected since the common stereotype is that speakers speak more under the influence of alcohol. One possible explanation for both effects might be the experimental setting seen as a  X  X est situation X , where speakers try to articulate as clearly as possible to camouflage their intoxication.

The reverse effect can be observed in the sub-category command and control ,in which the speakers were asked to read or formulate commands to the automobile (set N: 5.00 vs. set A: 6.03 words per item). Again this is not what we expected to see, since the higher mental load required to think of new commands was expected to be diminished under the influence of alcohol and hence the number of words to be less than in the sober state.

Table 8 illustrates some selected numbers across genders and recording behavior:  X  number of word tokens in spontaneous speech: while female speakers utter the  X  male speakers exhibit a higher proportion of irregularities per word token in  X  male speakers produce fewer silence intervals [ 1s ( long pause ) than female  X  on the other hand female speakers exhibit more pronunciation errors than their  X  finally, male speakers seem to correct themselves more often than female
Whether these preliminary findings can be exploited in any way to detect intoxication from the speech input automatically remains to be clarified. 8.3 Alcohol concentration The measured alcoholization BAC in the intoxicated recordings ranges from 0.00023 to 0.00175; the histograms in Fig. 2 depicts the distribution of measure-ments for both genders. Since both distributions appear to be uni-modal, measured speech features (speaker independent) may be tested for correlation against the BAC values. 9 Conclusion and ongoing projects A new corpus of speech recordings under the influence of alcohol has been presented. The corpus is available to everyone who is interested to repeat published findings about alcoholized speech or conduct new investigations.

Aside from already distributed copies to other researchers the ALC corpus as described in the previous sections is being used for a number of ongoing phonetic studies at the BAS. Investigated features to separate intoxicated from sober speech are longterm fundamental frequency (F0), F0 in lexically accented, tense vowels , F0 trajectories , several rhythm parameters based on the CVCV.. . speech pattern, long term formant values and formant trajectories and a variety of disfluencies in spontaneous and read speech . Selected samples from ALC are being used in perception experiments to yield a baseline of what humans achieve in a simple discrimination task and to verify the common stereotype that intoxication correlates with audible speech markers.

Detailed results from these studies are being published elsewhere; here we give just a coarse summary of some preliminary results.

Previous studies of longterm F0 in intoxicated speech were inconsistent: some authors reported falling, some rising F0; some suggested a non-linear behavior: first falling then rising with increasing BAC. A study based on 46 speakers of the ALC corpus reveals that F0 as well as F0 range rises significantly in the intoxicated case, although some speakers show opposing behavior. We found no indication for a non-linear relationship of F0 and BAC. F0 in tense vowels did not discriminate better than the overall F0, but significant differences were confirmed for the vowels /a:/, consistent way than male speakers (Dhillon 2009 ).

To our knowledge rhythm features, except for speech rate, have not been investigated in intoxicated speech so far. Speech rate has been reported to rise as automatic phonetic segmentation showed significant differences in the standard deviation of the duration of vowels clusters ( d V.sd, Ramus et al. 1999 ), the average durational difference of consecutive vowel clusters (nPVI-V, Grabe and Low 2004 ) and the short pause rate per syllable based on 82 speakers of the ALC corpus (Schiel and Heinrich 2009 ). A newer study based on the energy patterns ( RMS rhythmicity ) of 128 speakers (Schiel et al. 2010 ) indicates that speech rate is in fact decreasing significantly with intoxication.

Tagged disfluencies were investigated on a subset of 93 speaker of the ALC corpus: Filled pauses tend to have a significant longer duration in intoxicated speech, at least in spontaneous speech; for read speech the results are inconclusive across genders. Furthermore the rate of filled pauses , the rate of pauses longer than 1s , the number of wrong pronunciations and the occurrence of stutter show significant differences (Barfu  X  sser and Schiel 2010 ). This is consistent with earlier were reported to rise with intoxication.
 References
