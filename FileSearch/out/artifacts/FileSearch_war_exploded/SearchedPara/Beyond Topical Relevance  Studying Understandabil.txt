 Nowadays people rely on search engines to explore, under-stand and manage their health. A recent study from Pew Internet states that one in each three adult American Inter-net users have used the Internet as a diagnosis tool [2].
Retrieving incorrect or unclear health information poses high risks as people may dismiss serious symptoms, use inap-propriate treatments or escalate their health concerns about common symptomatology [1,9]. A number of studies have shown that the average user experiences difficulty in un-derstanding the content of a large portion of the results re-trieved by current search engine technology, for example, see [3]. Other studies have examined how poor the quality of health information on the web can be, for example, see [4].
In the context of consumer (non-experts) health search, search engines should not only retrieve relevant information, but also promote information that is understandable by the user and that is reliable/trustable and verified [9].
The focus of my Ph.D. is to go beyond topical relevance and study understandability and reliability as two important facets of relevance that must be incorporated into search sys-tems to increase user satisfaction, especially in the context of consumer health search. For ease of comprehension, we divide this work into five steps to be accomplished: 1. Estimate the user expertise level. 2. Estimate how hard is to understand a document. 3. Estimate how reliable the content of a document is. 4. Integrate the understandability and reliability estima-5. Evaluate the relevance of documents not only con-
The first step aims to promote easy-to-read material with reliable content to non-experts, while experts are not both-ered with basic content. This step was completed in the first years of my Ph.D., using the logs of different search engines to better understand how and what users search in the med-ical domain, as well as to automatically infer user expertise based on user behaviour [5,8].

The second and third steps are bound to the document content, and need labor-intensive resources to be done (e.g., annotated data, assessments, user preferences). For that, I take advantage of CLEF eHealth task 1 , which proposes to foster research in the consumer health search domain. In the 2015 task, besides the topical relevance assessment, we collected understandability assessments, asking assessors to judge whether they would recommend documents for their patients to read based on how technical documents were [6]. Given the success of the task, we are collecting assessments for reliability as well as topical relevance and understand-ability in 2016. These assessments provide the grounds for working in the fourth and fifth steps of the list above.
Our first experiments exploring the potential of integrat-ing understandability in a personalised retrieval model (part of the fourth step) will be presented at this conference [7].
Finally, I aim to extend and explore the potential of eval-uation metrics that integrate understandability and reliabil-ity into a single evaluation framework, based on very recent research [10].
 https://sites.google.com/site/clefehealth/
