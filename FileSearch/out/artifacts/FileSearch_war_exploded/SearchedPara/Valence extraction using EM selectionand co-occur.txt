  X ukasz De  X bowski Abstract This paper discusses two new procedures for extracting verb valences from raw texts, with an application to the Polish language. The first novel technique, the EM selection algorithm, performs unsupervised disambiguation of valence frame forests, obtained by applying a non-probabilistic deep grammar parser and some post-processing to the text. The second new idea concerns filtering of incorrect frames detected in the parsed text and is motivated by an observation that verbs which take similar arguments tend to have similar frames. This phenomenon is described in terms of newly introduced co-occurrence matrices. Using co-occurrence matrices, we split filtering into two steps. The list of valid arguments is first determined for each verb, whereas the pattern according to which the arguments are combined into frames is computed in the following stage. Our best extracted dictionary reaches an F -score of 45%, compared to an F -score of 39% for the standard frame-based BHT filtering.
 Keywords Verb valence extraction EM algorithm Co-occurrence matrices Polish language 1 Introduction The aim of this paper is to explore two new techniques for verb valence extraction from raw texts, as applied to the Polish language. The methods are novel compared to the standard framework (Brent 1993 ; Manning 1993 ; Ersan and Charniak 1995 ; Briscoe and Carroll 1997 ) and motivated in part by resources available for this language and in part by certain linguistic observations.
 The task of valence extraction for Polish invites novel approaches indeed. Although there is no treebank for this language on which a probabilistic parser can valence dictionaries have been compiled by formal linguists (Polan  X  ski 1992 ; S  X  widzin  X  ski 1994 ; Ban  X  ko 2000 ). Those dictionaries are potentially useful as a gold standard in automatic valence extraction but two of them, Polan  X  ski and Ban  X  ko, are printed on paper in several volumes, whereas S  X  widzin  X  ski X  X  dictionary, though rather entries whereas 6,000 entries can be found in COMLEX, a detailed syntactic dictionary of English (Macleod et al. 1994 ).

The information provided by Polish valence dictionaries is of comparable complexity to information available in COMLEX. Verbs in the dictionary entries select for nominal (NP) and prepositional (PP) phrases in specific morphological cases (seven distinct cases and many more prepositions). Valence frames may contain subject, which also contributes to the combinatorial explosion. For instance, S  X  widzin  X  ski ( 1994 ) provides 329 frame types for the 201 test verbs described later test verbs and there are 183 hapax frames.

Such lack of computational data is a strong incentive to develop automatic valence extraction as efficiently as possible. Thus we have devised two procedures. The first one, called the EM selection algorithm, performs unsupervised selection of alternative valence frames. These frames were obtained for sentences in a corpus by applying the parser S  X  wigra and some post-processing. In this way, we cope with the lack of a probabilistic parser and of a treebank.

The EM selection procedure, to our knowledge described here for the first time, assumes that the disambiguated alternatives are highly repeatable atomic entities. The procedure does not rely on what formal objects the alternatives are but it only takes their frequencies into account. Thus, the EM selection looks like an interesting baseline algorithm for many unsupervised disambiguation problems, e.g. part-of-speech tagging (Kupiec 1992 ; Merialdo 1994 ). Computationally, the algorithm is far simpler than the inside X  X utside algorithm for probabilistic grammars (Chi and Geman 1998 ), which also instantiates the expectation-maximization scheme and is used for treebank and valence acquisition (Briscoe and Carroll 1997 ; Carroll and Rooth 1998 ).

The second novel technique concerns filtering of incorrect valence frames detected in the parsed text. Despite a large number of distinct frames occurring in the available Polish valence dictionaries, verbs which take similar arguments tend to have similar frames. This phenomenon was surveyed in particular by De  X bowski Sect. 2 . The cited authors proposed that sets of verbal frames be described in terms of argument lists, which strongly depend on a verb, and pairwise combination rules for arguments, called co-occurrence matrices, which are largely independent of a verb.

In this article, we recall this formalism and propose an analogous two-stage approach to filtering incorrect frames. The list of arguments is filtered for each verb filtering methods that resemble those used so far for whole frames. We will show that verbal frames are easier to extract when decomposed into simpler entities than when treated as atomic objects. The qualitative analysis of errors is also easier to perform.

Verb valence frames have been learned as atomic entities in all previous valence extraction experiments (see also: Sarkar and Zeman 2000 ; Przepio  X  rkowski and Fast 2005 ; Fast and Przepio  X  rkowski 2005 ; Chesley and Salmon-Alt 2006 ) although recent research exploits certain correlations among the verb meanings, diathesis, and subcategorization (McCarthy 2001 ; Korhonen 2002 , Chap. 4; Lapata and Brew 2004 ; Schulte im Walde 2006 ). This line of computational experiment is more and more inspired by formal research in semantic classes of arguments, verbs, and frame alternations, cf. Levin ( 1993 ) and Baker and Ruppenhofer ( 2002 ).

Our unorthodox less resource-and theory-intensive approach to decomposing valence frames stems from an independent insight into their distribution and structure, built on the preliminary valence extraction experiment for Polish by ically extracted dictionary reached about 40%, whereas the F -score of two gold-other equalled 65%. This apparently low agreement between manually compiled dictionaries and the lack of explicit information about semantic classes inspired us scheme.
 The experiment described in this paper differs from both of the works by Przepio  X  rkowski in several aspects. Firstly, we explore whether it is better to filter frames in two steps or in one step as done previously. Secondly, we extract all kinds of arguments occurring in the gold-standard dictionaries, whereas only non-subject NPs and PPs were considered in the two previous works. Thirdly, we compare our extracted dictionaries with three gold-standard dictionaries simultaneously and grammar and the EM algorithm to parse raw texts, whereas Przepio  X  rkowski and Fast applied a very simple regular grammar of 18 rules. We analyze fewer texts but we analyze them more thoroughly, which means higher precision but not necessarily lower recall. The final difference is that our test set covers twice as many verbs (201 lemmas) as considered by Przepio  X  rkowski and Fast.

The frame-based binomial hypothesis test (BHT, Brent 1993 ) is assumed in this work as a baseline against which our new ideas of filtering are compared, since it reapplied several known frame filtering methods: the BHT, the log-likelihood ratio test (LLR) (Gorrell 1999 ; Sarkar and Zeman 2000 ), and the maximum likelihood threshold (MLE) (Korhonen 2002 ). Applying the one-stage BHT to our data, we obtain 26% recall and 75% precision ( F = 39%). To compare, the dictionary obtained by applying the novel two-stage filtering of frames to the same counts of parses exhibits 32% recall and 60% precision ( F = 42%). The set-theoretic union of both dictionaries combines their strengths and features F = 45%. These statistics relate to extracting whole frames, whereas Przepio  X  rkowski and Fast obtained similar values for the simpler task of extracting only NPs and PPs. We find our results to be an encouraging signal that similarities of frame valence frame sets should be exploited across different verbs as much as possible, and also in an algorithmic way. The method introduced here allows various extensions and modifications.

The rest of this article describes our experiment in more detail. In Sect. 2 , a brief introduction to co-occurrence matrices is provided; Sect. 3 presents the verb valence extraction procedure; the obtained dictionary is analyzed in Sect. 4 ; Sect. 5 contains the conclusion. Three appendices follow the article. Appendix 1 gives additional details for the co-occurrence matrix formalism; Appendix 2 describes the initial corpus parsing; Appendix 3 introduces the EM selection algorithm. 2 The formalism of co-occurrence matrices Let us introduce the new description of valence frames which is applied to valence extraction in this paper. To begin with a more usual formal concept, consider a prototypical entry from our gold-standard valence dictionary. It consists of the set of valence frames for the verb przy X apac  X  (= to catch somebody red-handed ). The symbol sie denotes the reflexive marker sie  X  and na ? np(loc) is a prepositional phrase with preposition na (= on ), which requires a nominal phrase in the locative case. The notations for cases are as in the IPI PAN Corpus tagset: nom (inative), gen (itive), dat (ive), acc (usative), http://korpus.pl/. For simplicity, it is assumed that no argument type can be repeated in a single valence frame. This restriction can be overcome by assigning unique identifiers to repetitions.

There are two subtleties which concern our implementation of notation (1) and are worth exposing to avoid possible confusion later: (i) We treat the reflexive marker sie  X  as an ordinary verb argument rather than as a (ii) A valence frame may lack the subject np(nom) . According to the analysis Summarising our remarks, there are many specific verbs such that sie or np(nom) (a) present or omitted, affecting the occurrence of other arguments. Similar interactions involving the reflexive marker and the subject have been studied in valence acquisition for other languages (Mayol et al. 2005 ; Surdeanu et al. 2008 ).
De  X bowski and Wolin  X  ski ( 2007 ) proposed an approximate description of complex interactions within the frame set F ( v ) in terms of three simpler objects: the set of possible arguments L ( v ), the set of required arguments E  X  v  X  L  X  v  X  ; and the argument co-occurrence matrix M  X  v  X  : L  X  v  X  L  X  v  X ! ; ! ; $ ; ; ? fg : The definitions of the first two objects correspond to the following naming convention. required for v if it occurs in all frames. Thus we have For instance,
To define the co-occurrence matrix, let us denote the set of verb frames which contain an argument type a as h a i : = { f [ F ( v )| a [ f }. Next, we will introduce five implicitly verb-dependent relations: Then the cells of matrix M ( v ) are defined via the equivalence for the verb arguments a , b [ L ( v ). The symbol ? that denotes  X  X  X ormal X  X  independence was chosen intentionally to resemble the symbol ? ? ; which is usually applied to denote probabilistic independence.
 For the discussed example we obtain: This unconventional approach to describing verb valences appears quite robust. For example, consider an observed agreement score (cf. Artstein and Poesio 2008 ) taneously in two compared dictionaries. Formally this agreement score equals where f M i  X  v  X j v 2 V i g ; i  X  1 ; 2 ; are the two compared collections of co-occurrence matrices and De  X bowski and Wolin  X  ski ( 2007 ).

De  X bowski and Wolin  X  ski noticed also that the values of the matrix cells M ( v ) ab for fixed arguments a and b tend not to depend on the verb v . The latter fact appears favourable for automatic valence extraction. We may learn objects L ( v ), E ( v ), and M ( v ) separately with much higher accuracy and restore the set of frames F ( v ) from these by approximation. For example, consider the maximal set F  X  v  X  2 L  X  v  X  of frames that contain all required arguments in E ( v ) and induce the co-occurrence matrix M ( v ). Precisely, where in Sect. 4.3 . In our application, however, the number of frames introduced by using conveniently also for syntactic parsing of sentences. Typically, a grammar parser checks whether a hypothetical frame f of the parsed sentence belongs to the set F ( v ), defined by a valence dictionary linked to the parser. If F  X  v  X  rather than F ( v ) is used for parsing, which enlarges the set of accepted sentences, then there is no need to however, the reconstructed set F  X  v  X  is needed explicitly for dictionary evaluation. Thus we provide an efficient procedure to compute F  X  v  X  in Appendix 1 . 3 The adjusted extraction procedure 3.1 Overview Our valence extraction procedure consists of four distinct subtasks. 3.1.1 Deep non-probabilistic parsing of corpus data The first task was parsing a part of the IPI PAN Corpus of Polish to obtain a bank of reduced parse forests, which represent alternative valence frames for elementary described in Appendix 2 .

The obtained bank included 510 743 clauses which were decorated with reduced parse forests like the following two examples (correct reduced parses marked with a X  ?  X ):  X  Kto zast c api piekarza? X   X  X   X  Who will replace the baker? X   X   X  zast c api c :np:acc: :np:nom: zast c api c :np:gen: :np:nom:  X  Nie p  X  aka  X  na podium :  X   X  X   X  He did not cry on the podium :  X   X   X  p  X  aka c :np:nom: :prepnp:na:acc: X   X   X  p  X  aka c :np:nom: :prepnp:na:loc: X  Reduced parses are intended to be the alternative valence frames for a clause plus the lemma of the verb. In contrast to full parses of sentences, reduced parses are highly repeatable in the corpus data. Thus, unsupervised learning can be used to find approximate counts of correct parses in the reduced parse forests and to select the best description for a given sentence on the basis of its frequency in the whole bank. 3.1.2 EM disambiguation of reduced parse forests disambiguated to single valence frames per clause. It is a standard approach to disambiguate full parse forests with a probabilistic context-free grammar (PCFG). However, reformulating S  X  widzin  X  ski X  X  metamorphosis grammar as a pure CFG and the subsequent unsupervised (for the lack of a treebank) PCFG training would take too much work for our purposes. Thus we have disambiguated reduced parse forests by means of the EM selection algorithm introduced in Appendix 3 . Let A i be the set of reduced parse trees for the i th sentence in the bank, i = 1, 2, ... , M . We set the initial p j (1) = 1 and applied the iteration (11) X (12) from Appendix 3 until n = 10. sampled at random.

Just to investigate the quality of this disambiguation, we prepared a test set of 190 sentences with the correct reduced parses indicated manually. Since the output of our disambiguation procedure is stochastic and the test set was small, we performed 500 Monte Carlo simulations on the whole test set. Our procedure chose the correct reduced parse for 72.6% sentences on average. Increasing the comparison, sampling simply a parse j with the largest p ji ( n ) yielded an accuracy of 72.4%, sampling a parse with the minimal length was accurate in 57.5% cases, whereas blind sampling (assuming equidistribution) achieved 46.9%. The differ-our results, we prefer using shorter parses. 3.1.3 Computing the preliminary dictionary from parses Once the reduced parse forests in the bank had been disambiguated, a frequency table of the disambiguated reduced parses was computed. This will be referred to as the preliminary valence dictionary. The entries in this dictionary looked like this:  X  przy  X  apa c X  )f  X  np  X  acc  X  ; np  X  gen  X  ; np  X  nom  X   X  ) 1 ;  X   X  X a  X  np  X  loc  X  ; np  X  nom  X  ; sie X  ) 1 ;  X  na  X  np  X  loc  X  ; np  X  gen  X  ; np  X  nom  X   X  ) 1 ;  X   X  X p  X  acc  X  ; np  X  nom  X   X  ) 4 ;  X  adv ; np  X  nom  X   X  ) 1 ;  X   X  X a  X  np  X  loc  X  ; np  X  acc  X  ; np  X  nom  X   X  ) 3 g The numbers are the obtained reduced parse frequencies, whereas the correct valence frames are marked with a  X  ?  X , cf. (1). Notice that the counts for each parse are low. We chose a low frequency verb for this example to make it short. Another natural method to obtain a preliminary dictionary was to use Mp j ( n ) coefficients as the frequencies of frames. This method yields final results that are 1% worse than for the dictionary based on the frequency table. 3.1.4 Filtering of the preliminary dictionary The preliminary dictionary contains many incorrect frames, which are due to parsing or disambiguation errors. In the last subtask, we filtered this dictionary using supervised learning, as done commonly in related work.

For example, the BHT filtering by Brent ( 1993 ) is as follows. Let c ( v , f ) be the count of reduced parses in the preliminary dictionary that contain both verb v and valence frame f . Denote the frequency of verb v as c ( v ) = retained in the set of valence frames F ( v ) if and only if where a = 0.05 is the usual significance level and p f is a frequency threshold. The minimal error rate against the training dictionary. In the idealized language of statistical hypothesis testing, p f equals the empirical relative frequency of frame f for the verbs that do not select for f according to the ideal dictionary.

We have used the BHT as the baseline, against which we have tested a new procedure of frame filtering. The new procedure applied the co-occurrence matrices presented in Sect. 2 . It was as follows: 1. Compute L ( v ) and E ( v ) via Eq. 2 from the sets of valence frames F ( v ) given by 2. Correct L ( v ) and E ( v ) using the training dictionary. 3. Reconstruct F ( v ) given the new L ( v ) and E ( v ). This reconstruction is defined as 4. Compute M ( v ) from F ( v ) via Eq. 3. 5. Correct M ( v ) using the training dictionary. 6. Reconstruct F ( v ) given the new M ( v ). This reconstruction consists of 7. Output F ( v ) as the valence of verb v .
 Steps 2 and 5 are described in Sects. 3.2 and 3.3 respectively.

In our experiment, the training dictionary consisted of valence frames for 832 S  X  widzin  X  ski X  X  dictionary except those included in the test set introduced in Sect. 4 . 3.2 Filtering of the argument sets For simplicity of computation, the correction of argument sets L ( v ) and E ( v ) was done by setting thresholds for the frequency of arguments as in the maximum likelihood thresholding test for frames (MLE) proposed by Korhonen ( 2002 ). Thus a possible argument a for verb v was retained if it accounted for a certain proportion of the verb X  X  frames in the corpus. Namely, a was kept in L ( v ) if and only if Parameter p a was evaluated as dependent on the argument but independent of the verb. The optimal p a was selected as a value for which the classification rule (7) yielded the minimal error rate against the training dictionary.

The difference between the BHT and the MLE is negligible if the count of the verb satisfied in our application but we preferred MLE for its computational simplicity and its lack of need to choose an appropriate significance level a . In a preceding subexperiment, we had also tried out the more general model c ( v , a ) C p a c ( v ) ? t a majority of a  X  X  then we set constant t a = 1 for all verb arguments later.
Since the same error rate could be obtained for many different values of p a ,we applied a discrete minimization procedure to avoid overtraining and excessive searching. Firstly, the resolution level N := 10 was initialized. In the following loop, we checked the error rate for each p a := n / N , n = 0, 1, ... , N . The number of distinct p  X  X  yielding the minimal error rate was determined and called the degeneration D ( N ). was returned as the median of the D ( N ) distinct values that allowed the minimal error rate. Selecting the median was inspired by the maximum-margin hyperplanes used in support vector machines to minimize overtraining (Vapnik 1995 ).

Similar supervised learning was used to determine whether a given argument is strictly compulsory for a verb. By symmetry, an argument a that was found possible with verb v was considered as required unless it was rare enough. Namely, a [ L ( v ) was included in the new E ( v ) unless where p : a was another parameter, estimated analogously to p a . 3.3 Correction of the co-occurrence matrices Once we had corrected the argument sets in the preliminary dictionary, the respective co-occurrence matrices still contained some errors when compared with the training dictionary. However, the number of those errors was relatively small and it was not so trivial to propose an efficient scheme for their correction.
A possible approach to such correction is to develop statistical tests with clear null hypotheses that would detect structural zeroes in contingency tables counts of frames. Relations ; ! ; $ ; and 9 correspond to particular configura-tions of structural zeroes in these tables.

Constructing structural zero detection tests appeared to be difficult under the common-sense requirement that the application of these tests cannot diminish the agreement score (4) between the corrected dictionary and the training dictionary. We have experimented with several such schemes but they did not pass the aforementioned criterion empirically. Eventually, we have discovered successful correction methods which rely on the fact that values of matrix cells for fixed arguments tend not to depend on a verb, see Sect. 2 .

In this paper we compare three such correction methods. Let us denote the value of a cell M ( v ) ab after Step 4 as S. On the other hand, let R be the most frequent relation for arguments a and b given by the training dictionary across different verbs. We considered the following correction schemes: (A) M ( v ) ab is left unchanged (the baseline): M  X  v  X  ab S : (B) M ( v ) ab becomes verb-independent: M  X  v  X  ab R : (C) We use the most prevalent value only if there is enough evidence for a verb-
There were only a few relation pairs S ) R for which method (C) performed substitutions M  X  v  X  ab R when applied to our data. These were: ) ; !) ; ?) ; ?)! ; and ?) : Unlike the case of argument filtering, the optimal t S ) R was equal to 1 only for one relation pair, namely ?) : The evaluation of methods (A), (B) and (C) against an appropriate test set is presented in Sect. 4.3 . 4 Evaluation of the dictionary 4.1 Overview Having applied the procedures described in Sect. 3 , we obtained an automatically extracted valence dictionary that included 5,443 verb entries after Step 6, which is parameters were trained on frame sets provided by S  X  widzin  X  ski ( 1994 ) for 832 verbs. In contrast, the valence frames in our test set were simultaneously given by S  X  the training verbs. Except for 5 verbs missing in Polan  X  ski and one missing in Ban  X  ko, each verb in the test set was described by all dictionaries and we kept track of which dictionary contributed which frame.

We preferred to compare the automatically extracted dictionary with three reference dictionaries at once to sort out possible mistakes in them. In particular, the majority voting (MV) of the three dictionaries was also considered. The verbs for the test set were selected by hand for the following reasons: Firstly, each reference manually and interpreted by an expert since these authors often described arguments abstractly, like the  X  X  X dverbial of time/direction/cause/degree X  X , rather than as NPs, PPs or adverbs. Thirdly, verbs taking rare arguments were intentionally overrep-resented in our test set. Although we could not enlarge or alter the test set easily to perform reasonable n -fold cross-validation, the variation of scores can be seen by comparing different automatically extracted dictionaries with different gold-standard dictionaries. We find this more informative for future research than the standard cross-validation.

The evaluation is divided into three parts. We analyze some specific errors of our two-stage approach, each stage assessed separately. In the following, we relate our results to previous research. 4.2 Analysis of the argument filtering ( 1994 ) for the 201 test verbs. The notations in the column titles are: P is the number of positive outcomes in the automatically extracted dictionary after Step 3 of dictionary filtering (one outcome is one verb taking the argument), GSP is the number of gold-standard positive outcomes in S  X  widzin  X  ski (GSP = P -FP ? FN), FN is the number of false negatives, FP is the number of false positives, and E is the number of errors (E = FN ? FP). We have 0 B FN,FP B GSP,P,E B 201. The notations for certain arguments in the table rows are: sie is the reflexive marker sie  X  , x ? np(y) is the prepositional phrase introduced by preposition x requiring a noun in case y , ZE is the clause introduced by _ ze  X  X  that  X  ; PZ is the clause introduced by czy (= whether ), and BY is the clause introduced by _ zeby  X  X  so as to  X  :
Although the overall precision of single argument extraction is high (it reaches 89%, see the (verb, argument) scores in Table 2 below), all numerical values for this task depend heavily on the type of extracted argument. The case of frequency higher for arguments that can be used as NP modifiers, e.g. adj(nom) and np(gen) ,or verbal adjuncts, e.g. adv and w ? np(loc) . In general, the errors concentrate on low-frequency arguments. That occurs probably because the frequency of tokens coming from parsing errors does not depend systematically on the argument type. Thus this frequency dominates the frequency of tokens coming from well parsed sentences for low-frequency types. Except for the extraction of a direct object np(acc) and adverbial phrase adv , gold-standard positive outcomes (GSP) outnumber the positive ones (P). Put differently, false positives (FP) are fewer than false negatives (FN) X  X lthough the learning objective was set to minimize the error rate (E = FP ? FN). The same phenomenon appears in Brent ( 1993 ).

We have also noticed that the extracted valences are better for less frequent verbs. We can see several reasons for this. Firstly, there are more types of infrequent verbs than of frequent ones, so thresholds p a get more adjusted to the behaviour of less frequent verbs. Secondly, the description of infrequent verb valences given by fails to cover less frequent arguments that are harder to extract. Unfortunately, the small size of our training and test data does not enable efficient exploration of how thresholds p a could depend on the frequency of the verb. According to Table 1 , about half of the argument types were acknowledged in the test data for just a few verbs.

The arguments that we found particularly hard to extract are the adverbs ( adv ), with inequality P &gt; GSP, and a group of arguments with P much smaller than GSP. The latter include several adjunct-like prepositional phrases (e.g., w ? np(loc) , w means in ), certain clauses ( PZ and BY ), and the possible lack of subject np(nom) (= non-required np(nom) ), which corresponds roughly to the English expletive it . The inequality P &gt; GSP for adverbs probably reflects their inconsistent recognition as verb arguments in the gold standard.

The climbing of clitics and objects was another important problem that we came across when we studied concrete false positives. Namely, some arguments of the sentence. In contrast to Romance languages, this phenomenon concerns not only clitics. Unfortunately, S  X  widzin  X  ski X  X  grammar does not model either object or clitic climbing and this could have caused the following FPs:
There were no FPs that could be attributed to the climbing of the reflexive marker sie  X  , although this clitic climbs most often. For no clear reason, the optimal threshold p a for sie  X  was much higher for the training dictionary than for the test dictionary.
These three frequent arguments also featured relatively many FPs that were due to omissions in the test dictionary:  X  1 of 9 outcomes for np(acc) : skar _ zy c (= accuse) ,  X  6 of 11 outcomes for np(dat) : ciec (= flow ), dostosowac  X  (= adjust ), dr _ ze c As we can see, almost all FPs for these arguments are connected either to clitic and object climbing or to omissions in the test set. There is room for substantial improvement both in the initial corpus parsing and in the test dictionaries. 4.3 Evaluation of the co-occurrence matrix adjustment We obtained the following agreement scores for the three methods of co-occurrence matrix adjustment defined in Sect. 3.3 : S  X  (C) gave the best results so it is the only method considered subsequently.
In more detail, Table 2 presents scores for all manually compiled dictionaries and the automatically extracted dictionary at several stages of filtering: AE is the preliminary dictionary, AE-A is the dictionary after correcting the argument sets (Step 3), AE-C is the one where co-occurrence matrices were corrected using method (C) (Step 6), and AE-F is the baseline filtered only with the frame-based binomial hypothesis test (6). We have constructed several dictionaries derived from these, such as set-theoretic unions, intersections, or majority voting, but present only the best result X  X he AE-C ? F, which is the union of frames from the two-stage filtered AE-C and the one-stage filtered AE-F. The displayed MV is the majority and S  X  wi.

Each cell of two triangular sections of Table 2 presents the number of pairs, (verb, frame) or (verb, argument), that appear simultaneously in two dictionaries specified by the row and column titles counted for the 201 test verbs. The displayed recall, precision, and F -score were computed against the MV dictionary. Recall and precision against other dictionaries can be computed from the numbers given in the triangular sections.
 Although a large variation of precision and recall can be observed in Table 2 , the F -scores do not vary so much. Assuming the F -score as an objective to be maximized, the two-stage filtering is better than the frame-based BHT. Namely, we have F = 42% for the AE-C whereas F = 39% for the AE-F, the scores referring to pairs (verb, frame). The set-theoretic union of both dictionaries, AE-C ? F, exhibits even a larger F = 45%. In the case of not displayed dictionaries, we have observed the following triples of recall/precision/ F -score: (a) 20%/81%/32% for the intersection of AE-A, AE-C, and AE-F, (b) 33%/61%/43% for their majority voting, (c) 39%/45%/42% for their union, and (d) 39%/46%/42% for the union of just AE-A and AE-F.

The precision of both AE-C and AE-F with respect to the MV is equal to or higher than that of manually edited dictionaries, whether we look at single arguments or at frames. A word of caution is in order, however. Very high precision against the MV test dictionary, provided the recall is sufficient, is a desirable feature of the automatically extracted dictionary. The converse should be expected for the contributing sources of the MV dictionary. These should be favoured for presenting contributing sources should feature very high recall and relatively lower precision against their MV aggregate. Exactly this can be observed in Table 2 .

In general, through the correction of co-occurrence matrices in Step 5 and the frame reconstruction (5), more frames are deleted from the AE-A dictionary than added. The AE-A contains 338 pairs (verb, frame) which do not appear in the obtained AE-C dictionary, whereas only 13 such pairs from the AE-C are missing in the AE-A. The sets of pairs (verb, argument) are almost the same for both dictionaries.
A problem that is buried in the apparently good-looking statistics is the actual shape of co-occurrence matrices in the AE-C dictionary. In Step 5 of dictionary filtering, many matrix cells are reset as independent of the verb. This affects verbs such as dziwic  X  (= surprise/wonder ). The correct set of frames for this verb is close to The subordinate clause ZE excludes subject np(nom) when sie  X  is missing but it excludes direct object np(acc) when sie  X  is present (for there is a reflexive diathesis, dziwic  X  sie  X  = be surprised ).
The reconstruction (5) does not recover the frame set (10) properly for two reasons. Firstly, clause ZE excludes np(acc) and implies np(nom) for the majority of verbs. Secondly, the co-occurrence matrix formalism cannot model any pairwise exclusion that is conditioned on the absence or presence of another argument. However, we suppose that such an argument interaction is very rare and this deficiency is not so important en masse. 4.4 Comparison with previous research The scores reported in the literature of verb valence extraction are so varied that fast conclusions should not be drawn from just a single figure. For example, Brent ( 1993 ) achieved 60% recall and 96% precision in the unsupervised approach. This was done for English and for a very small set of extracted valence frames (the set counted only 6 distinct frames). English-based researchers that evaluated their extracted valence recall/precision: 36%/66% (Briscoe and Carroll 1997 )againsttheCOMLEXand ANLT dictionaries, 43%/90% (Manning 1993 )against The Oxford Advanced Learner X  X  Dictionary , and 75%/79% (Carroll and Rooth 1998 ) against the same dictionary.
Other factors matter as well. Korhonen ( 2002 , p. 77) demonstrated that the results depend strongly on the filtering method: BHT gives 56%/50%, LLR X 48%/42%, MLE X 58%/75%, no filtering X 84%/24%, all methods being frame-based and applied to the same English data. For Czech, a close relative of Polish, Sarkar and Zeman ( 2000 ) found the recall/precision pair 74%/88% but these were evaluated against a manually annotated sample of texts rather than against a gold-standard valence dictionary. Moreover, Sarkar and Zeman acquired valence frames from a manually disambiguated treebank rather than from raw data, so automatic parsing did not contribute to the overall error rate.

The closest work to ours is Fast and Przepio  X  rkowski ( 2005 ), who regarded their own work as preliminary. They also processed only a small part of the 250-million-word IPI PAN Corpus. Approximately 12 million running words were parsed but sentence parsing was done with a simple 18-rule regular grammar rather than with S  X  widzin  X  ski X  X  grammar. Moreover, the dictionary filtering was done according to several frame-based methods discussed in the literature and the reference dictionary used was only a small part of S  X  widzin  X  ski ( 1994 ) X 100 verbs for a training set and another 100 verbs for a test set. In contrast to our experiment, Fast and Przepio  X  rkowski extracted only non-subject NPs and PPs. They ignored subjects, np(nom) , since almost all verbs subcategorize for them. The best score in the complete frame extraction they reported was 48% recall and 49% precision ( F = 48%), which was obtained for the supervised version of the binomial hypothesis test (6).

So as to come closer to the experimental setup of Fast and Przepio  X  rkowski, we reapplied all frame filtering schemes to the case when only non-subject NPs and PPs were retained in the preliminary dictionary AE and the three manually edited dictionaries. The statistics are provided in Table 3 . Under these conditions our two-stage filtering method added to the frame-based BHT is better again than any of these methods separately; F = 57% for the AE-C ? F vs. F = 53% for both the AE-F and AE-C. The AE-C ? F is not only better than the AE-F and AE-C with respect to F -score but it also contains 15 to 38% more frames. Much higher precision of all these dictionaries than reported by Fast and Przepio  X  rkowski ( 2005 ) disambiguation. The best recall remains almost the same (47%) for the AE-C ? F dictionary, although we extracted valences from a four fold smaller amount of text. 5 Conclusion Two new ideas for valence extraction have been proposed and applied to Polish language data in this paper. Firstly, we have introduced a two-step scheme for filtering incorrect frames. The list of valid arguments was determined for each verb first and then a method of combining arguments into frames was found. The two-stage induction was motivated by an observation that the argument combination rules, such as co-occurrence matrices, are largely independent of the verb. We suppose that this observation is not language-specific and the co-occurrence matrix formalism can be easily tailored to improve verb valence extraction for many other languages and special datasets (also subdomain corpora and subdomain valence dictionaries). The second new idea is a simple EM selection algorithm, which is a natural baseline method for unsupervised disambiguation tasks such as choosing the correct valence frame for a sentence. In our application it helped high-precision valence extraction without a large treebank or a probabilistic parser.

Although the proposed frame filtering technique needs further work to address the drawbacks noticed in Sect. 4.3 and to improve the overall performance, the developing. In future work, experiments can be conducted using various schemes of decomposing the information contained in the sets of valence frames and, due to the scale of the task, this decomposition should be done to a large extent in an algorithmic way. The straightforward idea to explore is to express the verb valence information in terms of n -ary rather than binary relations among verbs and verb arguments, where n &gt; 2. Subsequently, one can investigate the analogous learning problem and propose a frame-set reconstruction scheme for the n -ary relations. Are ternary relations sufficient to describe the valence frame sets? We disbelieve that relations of irreducibly large arities appear in human language lexicons since, for example, Halford et al. ( 1998 ) observed that human capacity for processing random n -ary relations depends strongly on the relation arity.

Knowing algebraic constraints on the verb argument combinations is important also for language resource maintenance. Because our test dictionaries do not list valid argument combinations extensively, many false positive frames in the two-stage corrected dictionary were in fact truly positive. Thus, it is advisable to correct gold-standard dictionaries themselves, for example using a modification of the reconstruction (5). However, prior to resetting the gold-standard in this way, it must implausible frames. Also for this reason, the effective complexity of verb-argument and argument-argument relations in natural language should be investigated thoroughly from a more mathematical point of view.
 Appendix 1: A faster reconstruction of the frame set Although there is no need to compute F  X  v  X  defined in (5) to verify condition f 2 F  X  v  X  for a given f , the reconstruction F  X  v  X  can be computed efficiently if needed for other purposes. A naive solution suggested by formula (5) is to search through all elements of the power set 2 L ( v ) and to check for each independently whether it is an element of F  X  v  X  : However, we can do it faster by applying some dynamic programming.
 j f 2 F  X  v  X g and B n ={ b 1 , b 2 , ... , b n }.
 In fact, there is an iteration for this chain: Appendix 2: Parsing of the IPI PAN Corpus The input of the valence extraction experiment discussed in this paper came from the 250-million-word IPI PAN Corpus of Polish ( http://korpus.pl/ ). The original automatic part-of-speech annotation of the text was removed, since it contained too parser (Wolin  X  ski 2004 , 2005 ), see also http://nlp.ipipan.waw.pl/ * wolinski/swigra/ Technically, S  X  wigra utilizes two distinct language resources: (1) Morfeusz X  X  dictionary of inflected words (a.k.a. a morphological analyzer) programmed by Wolin  X  ski ( 2006 ) on the basis of about 20,000 stemming rules compiled by Tokarski ( 1993 ), and (2) GFJP X  X he formal grammar of Polish written by S  X  widzin  X  ski ( 1992 ). S  X  widzin  X  ski X  X  grammar is a DCG-like grammar, close to the format of the meta-morphosis grammar by Colmerauer ( 1978 ). It counts 461 rules and examples of its used a fake valence dictionary that allowed any verb to take none or one NP in the nominative (the subject) and any combination of other arguments.
 Only a small subset of sentences was actually selected to be parsed with S  X  wigra. The following selection criteria were applied to the whole 250-million-word IPI PAN Corpus: 1. The selected sentence had to contain a word recognized by Morfeusz as a verb 2. The selected sentence could not be longer than 15 words. (We supposed that the 3. Maximally 5000 sentences were selected per recognized verb. (We supposed
In this way, a subset of 1,011,991 sentences (8,727,441 running words) was chosen. They were all fed to S  X  wigra X  X  input but less than half (0.48 million sentences) were parsed successfully within a preset time of 1 minute per sentence. Detailed statistics are given in Table 4 below. All mentioned thresholds were introduced in advance to compute only the most useful parse forests in the pre-S  X  wigra was applied to more than several hundred sentences. The parsing actually took 2 months on a single PC station.

Not all information contained in the obtained parse forests was relevant for valence acquisition. Full parses were subsequently reduced to valence frames plus verbs, as in the first displayed example in Sect. 3 . First of all, the parse forests for compound sentences were split into separate parse forests for elementary clauses. Then each parse tree was reduced to a string that identifies only the top-most phrases. To decrease the amount of noise in the subsequent EM selection and to speed up computation, we decided to skip 10% of clauses that had the largest number of reduced parses. As a result, we only retained clauses which had B 40 reduced parses.

To improve the EM selection, we also deleted parses that contained certain syntactically idiosyncratic words X  X ostly indefinite pronouns to (= this ), co (= what ), and nic (= nothing ) X  X r highly improbable morphological word interpretations (like the second interpretation for albo = 1. the conjunction or ;2. the vocative singular of the noun alb  X  X  kind of liturgical vestment). The stop list of improbable interpretations consisted of 646 word interpretations which never occurred in the SFPW Corpus but were possible interpretations of the most common words according to Morfeusz. The SFPW Corpus is a manually POS tagged 0.5-million-word corpus prepared for the frequency dictionary of 1960s Polish (Kurcz et al. 1990 ), which was actually commenced in the 1960s but not published until 1990.
 Our format of reduced parses approximates the format of valence frames in S  X  ( 2006 ). To convert a parse in Przepiorkowski X  X  format into ours, the transformations must be performed as follows: 1. Add the dropped personal subject or the impersonal subject expressed by the 2. Remove one nominal phrase in the genitive for negated verbs. (An attempt to 3. Transform several frequent adjuncts expressed by nominal phrases. 4. Skip the parse if it contains pronouns to (= this ), co (= what ), and nic 5. Remove lemmas from non-verbal phrases and sort phrases in alphabetic order.
The resulting bank of reduced parse forests included 510,743 clauses with one or more proposed valence frames. We parsed successfully only 3.4 million running words of the whole 250-million-word IPI PAN Corpus X  X our times less than the 12 results in the valence extraction task indicate that skipping a fraction of available empirical data is a good idea if the remaining data can be processed more thoroughly and the skipped portion does not provide different efficiently usable information. Appendix 3: The EM selection algorithm a sequence of discrete random variables and let Y 1 , Y 2 , ... , Y M be a random sample ( Y estimate if we treat the values of Y i as atomic entities. We have to solve the task via some rationally motivated assumptions.

Our heuristic solution was iteration plausibly identified with the conditional probability P ( Z i = j | Y i = A i ).
Possible applications of iteration (11) X (12), which we call the EM selection algorithm, cover unsupervised disambiguation tasks where the number of different values of Y i is very large but the internal ambiguity rate (i.e., the typical cardinality | Y |) is rather small and the alternative choices within Y i (i.e., the values of Z i ) are highly repeatable. There may be many applications of this kind in NLP and bioinformatics. To our knowledge, however, we present the first rigorous treatment of this particular selection problem.

In this appendix, we will show that the EM selection algorithm belongs to the class of expectation-maximization (EM) algorithms. For this reason, our algorithm resembles many instances of EM used in NLP, such as the Baum-Welch algorithm for hidden Markov models (Baum 1972 ) or linear interpolation (Jelinek 1997 ). However, normalization (11), which is done over varying sets A i  X  X nlike the typical case of linear interpolation, is the singular feature of EM selection. The local maxima of the respective likelihood function also form a convex set, so there is no need to care much for initializing the iteration (11) X (12), unlike e.g. the Baum-Welch algorithm.
To begin with, we recall the universal scheme of EM (Dempster et al. 1977 ; Neal and Hinton 1999 ). Let P ( Y | h ) be a likelihood function, where Y is an observed variable and h is an unknown parameter.

For the observed value Y , the maximum likelihood estimator of h is When the direct maximization is impossible, we may consider a latent discrete variable Z and function which is a kind of cross entropy function. The EM algorithm consists of setting an initial parameter value h 1 and iterating P ( Y | h n ) but EM is worth considering only if maximization (13) is easy. Having outlined the general EM algorithm, we come back to the selection problem. remains to be determined. We may suppose from the problem statement that it factorizes into P  X  Z ; Y j h  X  X  Assume now for h = ( p j ) j [ J and a parameter-free function g ( ) satisfying where A and 0 B q B 1 is a fixed number not incorporated into h . Then the cardinalities of form of g ( A ), however, is not necessary to satisfy (16). The model (14) X (15) is quite speculative. In the main part of this article, we need to model the probability distribution of the reduced parse forest Y i under the assumption that the correct parse Z i h ) is like if j is a semantically implausible parse. We circumvent the difficulty by saying in (14) that this quantity is the same as if j were the correct parse.
Assumption (14) leads to an EM algorithm which does not depend on the specific choice of function g  X  X  : Therefore the algorithm is rather generic. In fact, (14) assures that P ( Y i = A i | h ) = g ( A i ) P ( Z i [ A i | h ) and
In consequence, iteration (13) is equivalent to where p ji ( n ) = P ( Z i = j | Z i [ A i , h n ) is given exactly by (11). If the Lagrange multiplier k is assigned the value that satisfies constraint p j  X  = 1 then Eq. 18 simplifies to (12). Hence it becomes straightforward that iteration (11) X (12) maximizes locally the log-likelihood
Moreover, there is no need to care for the initialization of iteration (11) X (12) since the local maxima of function (19) form a convex set M ; i.e., h ; h 0 2M) q h  X  X  1 q  X  h 0 2M for 0 B q B 1. Hence that function is, of course, constant on M : To show this, observe that the domain of log-likelihood (19) is a convex compact set P X  h : The second derivative of L reads Since matrix { L jj  X  } is negative definite, i.e., concave. As a general fact, a continuous function L achieves its supremum on a compact set P (Rudin 1974 , Theorem 2.10). If additionally L is concave and its domain P is convex then the local maxima of L form a convex set MP ; where L is constant and achieves its supremum (Boyd and Vandenberghe 2004 , Sect. 4.2.2). References
