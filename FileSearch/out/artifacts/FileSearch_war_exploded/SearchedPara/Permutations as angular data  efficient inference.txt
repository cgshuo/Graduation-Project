 and Vince D. Calhoun  X  X  X 
In this paper, we consider the problem of approximate representation and statistical inference for permutation s.
Practically, permutations are important objects to data mining because they arise in many data analysis problems with structured output spaces. For example, permutations have been used to develop statistical models of domains as diverse as object tracking [1], election result modeling [2 ], and Bayesian network structure search [3].

The data mining challenge arises from the combinatorial structure of permutation spaces. To exactly represent a general probability distribution over all permutations of n objects requires n !  X  1 parameters, which is infeasible for all but trivially small domains. Thus, most work in the field of permutation inference boils down to finding efficient and effective approximations.

We believe that much of the challenge of permutation modeling arises from the mathematical disparity between discrete, combinatorial spaces (such as permutation space s) and continuous spaces (such as Euclidean real space). The former are, a priori, fairly unstructured and expensive to manipulate  X  little more can be done than explicitly enu-merate the elements of the space. The latter, however, come endowed with properties like continuity, convexity, derivatives, and so on, on which are built most of the infrastructure of optimization and representation.
We attempt to exploit some of the strengths of continuous spaces for reasoning about permutations. Our key contribu-tion is a polynomial time mapping between the space of permutations and the hypersphere in Euclidean real space, via the convex polytope known as the permutohedron [4]. Once we can map a sample of permutations to the surface of the hypersphere, we can apply techniques from the rich field of directional statistics [5] to represent and manipul ate probability distributions there. This provides Bayesian p os-terior distributions over permutations. From there, we can reverse our mapping to take points back to permutation space, providing MAP estimates or efficient permutation sampling (e.g., for an MCMC algorithm).

Prior approaches have worked by approximating a general probability distribution with a restricted set of basis fun c-tions [1], or by embedding the permutation space only im-plicitly, and working with a heuristically chosen probabil ity distribution [6].

We show that our approach provides efficient, accurate permutation inference by...  X  We demonstrate an embedding of the n ! permutation  X  We demonstrate a bridge between directional statis-
In this work we use the widespread vector-based repre-sentation of permutations, where a permutation on n objects is denoted by a permuted version of the vector (1 , 2 , , n ) . These n -element vectors are elements of R n . We will call such vectors permutation vectors and denote them p . A. Representation
We show how to embed a permutation set consisting of n ! elements onto the surface of a d -hypersphere, S d , embedded in R n  X  1 , where d = n  X  2 consequently.

Our representation takes advantage of the geometry of the permutohedron , which is defined as an ( n  X  1) -polytope formed by the convex hull of n ! permutation vectors [7]. The convex hull of the n ! permutations of the vector (0 , 1 , , n  X  1) is sometimes called the regular permu-tohedron and is known to be the most symmetric among the family of permutohedra [4], which also applies to the permutohedron we are considering.

Next, we obtain a result (summarized in Lemma 1) that the rest of the section is based on.
 Lemma 1. The extreme points of the permutohedron are located on the surface of a hypersphere of radius centered at the center of mass of all n ! permutation vectors. show that each permutation is located at an equal distance from this center.

The center of mass for all the permutation vectors is defined in R n as c M = 1 n ! number of permutation vectors for which p 1 = 1 is ( n  X  1)! . Additionally there are n possible values for p 1 , and, by symmetry, this is true for any element of p . To say it in a different way, it means that across all permutations, ever y object occurs at a given vector index the same number of times. This observation leads to an expression of an element of the center of mass
To see that all permutations are equidistant from the center of mass, we observe that since the actual order of elements in p is irrelevant for the L 2 -norm, the following holds Summing the above series we arrive at (1).

The permutohedron is located on a hyperplane in R n [4]; consequently the sphere that inscribes it is also defined in that hyperplane, i.e. in R n  X  1 . A translation, scaling, and a basis change is required to get the zero-centered unit-radi us hypersphere in R n  X  1 .
 B. Transformations
Our goal is to use approaches from continuous mathemat-ics to develop probability distributions on this hypersphe re. That will allow efficient representation and inference over the set of permutations. However, this will only be useful in practice when there is a way to efficiently transform elements of one space to the other. Next we show how this can be achieved in polynomial time.

We want to efficiently map vectors between the discrete n ! space of permutations and the continuous space of S d This will require two different maps: 1) one-to-one function from n ! permutation space to S d 2) many-to-one function from S d to n ! permutation space
Item 2 poses a considerably more challenging problem than item 1, because it requires finding the nearest discrete point (permutation vector) to a continuous point, while the former is already described in Lemma 1. We develop re-quired transformations in the proof to the following lemma. Lemma 2. Transformation of a single point between the discrete n ! permutation space and the surface of the origin-centered ( n  X  1) -dimensional hypersphere takes no more than polynomial time.
 proceed. Let us denote by  X  an arbitrary vector in R n restricted to the surface of the hypersphere inscribing the permutohedron, and by  X  S its image on the hypersurface . We also employ an orthogonal matrix e Q = [ Q ; Q ort ] whose rows span R n , where the row Q ort is collinear to the c
M , and n  X  1 rows of Q project into R n  X  1 space containing the permutohedron. 1 Now we construct transformations for both directions.
From the permutation space to S d the transformation requires only a short sequence of linear operations, as it is made possible by Lemma 1: 1) Put the center of mass at the origin by shifting the 2) Change the basis by projecting into the R ( n  X  1) sub-3) Rescale by the radius to obtain a unit length vector Since size of Q is n  X  ( n  X  1) , the projection operation in step 2 takes O ( n 2 ) time. Note that the basis can be obtained Figure 1: A step-by-step demonstration of how an arbitrary p oint on by the QR factorization of the center of mass vector c M , which is O ( n 2 ) in this case, and needs to be computed only once for a given n .

From S d to the permutation space the transformation is more challenging. Now we have to linearly transform the point from S d to R n and then, among n ! possibilities, find the permutation that is the closest, in L 2 sense, to the projection. (Since we are considering the points on the surface of a hypersphere, the points closest in L 2 sense will also be the closest with respect to the geodesic distance. Th is is true because a hypersphere is a closed convex manifold of a constant curvature.) The transformation is easily done by inverting the order of operations for going from R n to S d (inverting an orthogonal transformation basis only requir es a matrix transpose): which amounts to O ( n 2 ) operations. Next, we show how to efficiently find the permutation vector closest to the transformed point.

Given an arbitrary point  X  in R n , corresponding to a point on S d , from expression (7), we introduce an auxiliary matrix W :
An example for n = 3 is shown in Figure 1a. The hypersphere in this case is a R 2 circle embedded in R 3 . Permutation vectors are the vertices of the hexagon inscrib ed in this circle. Point  X  is denoted by a star (its coordinates in R 3 are shown in Figure 1b). Figure 1b shows construction of the corresponding cost matrix W .

We constructed W such that finding the permutation p closest to the point  X  amounts to finding a p that minimizes
This is the same as matching every column and each row to a single counterpart so that the sum of matching weights (elements of W ) is minimal. Figure 1c shows a matching result as a 3  X  3 matrix, where column 1 is matched to row 1, and column 2 is matched to row 2, and column 3 is matched to row 3, signifying the permutation p closest to  X  . This figure should also make it clear that the result of the minimization is a permutation matrix, that automatical ly provides us with the closest permutation vector.

If we treat the row indices of W as graph nodes, the column indices as a separate set of graph nodes, and the entries of W as edge weights connecting them, then our goal is to find the minimum weight set of edges that connects every row node to exactly one column node, and vice versa. This is the familiar minimum weighted bipartite matching problem [8]. This observation allows us to apply a minimum weighted bipartite matching algorithm and obtain the permutation p closest to  X  .

The running time of the widespread Hungarian algo-rithm [8] for solving this problem is O ( n 2 log n + n 2 where e is the number of edges in the bipartite graph. Since the number of edges (roughly on the order of nonzero entries in W ) in our case can easily be n 2 , the running time effectively becomes O ( n 4 ) , which is the dominating term in the developed transformations.

When each permutation on the permutohedron surface is labeled with the corresponding ordering (inverse of this permutation), then its neighbors (with respect to the per-mutohedron) are those who are one step away in Kendall tau distance [9]. Developments of this section allows us to establish a continuous probability density on S d . Coupling the probability representations to the transformation ope r-ations bridges the gap between the discrete, combinatorial space of permutations and the continuous, low-dimensional hypersphere. This allows us to lift the large body of results developed for directional statistics [5] directly to permu ta-tion inference. The next section demonstrates how this is done.

A number of probability density functions on S d have been developed in the field of directional statistics [5]. A detailed account is given for an interested reader in [5, Chapter 9]. The directional statistics framework allows us to define quite general classes of density functions over permutations. In the rest of the paper, we use one of the basic models to demonstrate the usefulness of our representation and the model as well.
 A. von Mises-Fisher distribution
This is a m -variate von Mises-Fisher 2 (vMF) distribution of a m -dimensional vector x , where k  X  k = 1 ,  X   X  0 and m  X  2 : with normalization term where I r ( ) is the r th order modified Bessel function of the first kind and  X  is called the concentration parameter. Examples of this distribution in S 2 are shown in Figure 2 for various values of  X  and  X  , which also demonstrates how to establish a continuous density over permutations of 4 objects.

In terms of a pdf on permutations the vMF establishes a distance-based model, where distances are geodesic on S d The advantage of the formulation in a continuous space is the ability to apply a range of operations on the pdf and still end up with the result on S d . This advantage is realized in the inference procedures which we establish next. B. Efficient inference in a state space model
The results presented above establish a framework in which it is possible to define and manage in reasonable time probability densities over permutations. An importan t application of this framework is in the probabilistic data association (PDA) [10]. In PDA we are interested in main-taining links between objects and tracks under the noisy tracking conditions. Ignoring the underlying position est i-mation problem we focus on the part related to the identity management, as in [11], which boils down to tracking a hidden permutation (identity assignment) under a noisy observed assignment.

In order to perform identity tracking of permutations in the context of recursive Bayesian filtering (which we are going to do) we need to define the following components: 1) A transition model, P ( x t | x t  X  1 ) ; 2) An observation model, P ( y t | x t ) where y t is the noisy 3) A way to perform the following operations:
Avoiding transformation overhead we restrict all of the above to S d . Hence, x and y are S d representations of their respective hidden and observed permutations. We define both transition and observation models as vMF functions centere d at the true permutation. Due to similarity of the vMF model to the multivariate Gaussian density, it seems natural to vi ew this recursive filter as an analogy of the Kalman filter. In thi s view, the result of this sections is porting a widely success ful tracking model to the discrete n ! permutation space.
To further stress the analogy with the Kalman fil-ter, we show that projection operation can be computed analytically in a closed form and marginalization oper-ation can be efficiently approximated with good accu-racy [5, 12]. In the following, we use subscripts obs , tr and pos to attribute a parameter to observation, transi-tion, and posterior distributions respectively. For obser vation model P ( y t | x t )  X  vMF ( y t ,  X  obs ) and posterior model P ( x t | y t tion results in a vMF for P ( x t | y t ) parametrized as In the case of a vMF transition model, the marginalization can be performed with a reasonable accuracy and speed using the fact that a vMF can be approximated by an angular Gaussian and performing analytical convolution of angular Gaussian with subsequent projection back to vMF space [5]. Resulting vMF P ( x t | y t  X  1 ) is parametrized as: The ratio of modified Bessel functions required for this approach can be efficiently computed with high accuracy by using Lentz method based on evaluating continued frac-tions [13].
 C. Partial observations
Analytical computation of the Bayesian recursive filtering presented above relies on the fact that permutations are observed completely. In tracking problems that would mean the algorithm has to receive observations (up to noise) of (3,1,2,4) (3,2,1,4) (4,1,2,3) (4,2,1,3) Figure 3: An example of a fallback to a lower dimensional permutohedron that needs to be integrated out when a partial observation becomes available: in this case object 1 was observed at track 3. identities of every tracked object. This is a rare setting an d most commonly observations are available only partially.
When a partial observation of o objects becomes available, the dimension of the unknown part of y is reduced from n to ( n  X  o ) . The mechanism of this is shown in Figure 3, where we show what happens when an object identity 1 is observed at track 3, while no other observations are available. The unknown part of the representation of p on S d needs to be marginalized out to obtain the likelihood used in (12). Figure 3 shows that this marginalization is straightforwar d in
R n space. Unfortunately, to implement (13), we need to marginalize on the surface of the sphere, S d  X  R ( n  X  1) much more difficult task.

We project a permutation vector p into the R n  X  1 subspace by: In the case of a partial observation, we know which elements of the vector being projected are consistent with the obser-vation and are not going to change and which elements can have any possible value. This allows us to split the resultin g vector y into where y  X  and y ? respectively denote the observed and unobserved parts.

The likelihood with the unknown observations marginal-ized out becomes: 1 Z
Some details make computing the integral in (22) not totally trivial: x , y  X  , and y ? are of different length; although x is fixed, y  X  and y ? are not allowed to take any possible angle in R ( n  X  1) . We omit the details of the derivation dealing with these difficulties and just state the parameter s of the resulting vMF likelihood function: Thus, in the case of vMF we can execute a recursive Bayesian filter using only analytical computation even in the cases when only partially observed data is available. This makes the state space model applicable in a much wider range of scenarios than our initial model presented in Section III-B.

To demonstrate correctness of our approach, we show inference of a fixed hidden permutation from its noisy partia l observations. Figure 4 shows results of this inference on dataset of 10, 30 and 50 objects. In these first, synthetic data, experiments, we first randomly chose a true (hidden) permutation, p true . Figure 4 shows 9 cases of fully observed data with various levels of noise (the plot of observation error provides an idea of the difficulty of each problem). Noisy observations were drawn from vMF( p true ,  X  ). There are 3000 observations per plot. Values of  X  are listed. To also have a sanity check we provide a plot of the error for the case when noisy observation vectors are simply averaged, computing cumulative average at each point, and then the closest permutation vector is found. By the error in this section we mean the ratio of incorrectly identified objects t o the total number of objects. As Figure 4 shows, our approach always outperforms the averaging and quickly arrives at the true underlying permutation, although larger n requires more iterations to do so (e.g. for the case of n = 50 the method does not converge within the displayed 3000 steps).
To demonstrate the behavior of our approach in the missing data case, p m , was generated by hiding m percent of entries from the noisy observation matrix, chosen uniforml y at random without replacement. Figure 5 shows that our representation of the n ! discrete permutation space is func-tional and the approach can gracefully handle large number of objects, partial observations and observation noise.
A significant advantage of our embedding approach is its execution speed. We demonstrate it by comparing to the run-ning time of the exact HMM inference that takes O (( n !) time. As Figure 6 shows, the polynomial complexity of our approach makes a difference that allows to handle large values of n in reasonable time.
 Figure 6: Comparing wall-clock running time of our algo-rithm based on treating permutations as angular data (PAD) to the exact O (( n !) 3 ) approach for 1000 observations.
The above simulations were generated with the noise model used by the inference and did not have a temporal component, although it was applied to a really large state space. Next we show experiments on a tracking dataset with a non-vMF transition model. We use a dataset of planar locations of aircraft within a 30 mile diameter of John F. Kennedy airport of New York. The data, in streaming format, is available at http://www4.passur.com/jfk.html . The complexity of the plane routes and frequent crossings of tracks in the planar projection make this an interesting dataset for identity tracking. Identity tracking results o n this dataset, in the context of the symmetric semigroup approach to permutation inference, were previously reported in [11] . Replicating the task reported in [11], we show results on tracking datasets of 6 and 10 flights, dropping the 15 flights dataset (but see below).

The dataset comes prelabeled and identities of flights is always a sorted list as in the identity permutation vector ( 1 , 2 , . . . , n ). The dynamical behavior is introduced by randomly swapping identities of flights i and j at their respective locations x i and x j with probability p swap exp (  X  X  x j ( t )  X  x i ( t ) k s = 0 . 1 are strength and scale parameters respectively.
We then generated observation and hidden identity noise in the same way as for the prior experiment. Figure 7 shows results of applying our identity tracking method to th e air traffic control dataset for various levels of observatio n noise and amount of missing identity observations. Each point on the figure shows the identity error (percentage incorrect) averaged across all observations in the given time period. Thus, although we have explicitly used our temporal tracking model of Section III-B, only aggregate performance measures are shown (for a similar evaluation approach see [11]).

It is difficult to compare the performance to the method of [11] applied to the same dataset, since it is not clear how observation noise levels correspond to each other. However , error values reported in [11] were 0.12 to 0.17 on the 6 flights dataset and 0.2 to 0.32 on the 10 flights dataset. In the 6 flights case, this is comparable to what we get with our approach for observation error below 20%, even when 20% of the flight identities are unobserved. The case of 10 flights is more difficult and we get results comparable to [11] only for the fully observed case, but for the level of observation error of 10%, 20% and 30%. Results of the application of our state space model to this dataset indicate robustness of the model to the choice of the transition model (at least in the cases where noise level below 30%) which was different from the generative model of our tracking inference engine.
The main result of this work is embedding permutations into a continuous manifold, thus lifting a body of results from directional statistics field [5] to the fields of rank-ing, identity tracking and others, where permutations play essential role. Among many potential applications of this embedding we have chosen probabilistic identity tracking and were able to set up a state-space model with efficient recursive Bayesian filter that produced results comparable with the state of the art techniques very efficiently. There remains much to be done in this direction. However, a simple model, that can be thought of as a continuous generalization of the Mallows model [6, 14], equipped with results from the field of directional statistics has efficiently produced res ults of a reasonable accuracy. This is promising and encour-ages further development of more complicated probability distributions for permutations: further exploration of th e problem is indeed difficult and cannot be solved by a simple approach. exponential family already developed in the field [5] as well as developing more complex representations using spherical harmonics representations.

We thank Risi Kondor for generously providing the air traffic control dataset. This work was supported by NIH under grant numbers NCRR 1P20RR021938 and NIBIB 1R01EB000840. Dr. Lane X  X  work was supported by NSF under Grant No. IIS-0705681.
 [1] J. Huang, C. Guestrin, and L. Guibas,  X  X ourier theo-[2] J. Huang and C. Guestrin,  X  X earning hierarchical riffle [3] N. Friedman and D. Koller,  X  X eing bayesian about identities is unobserved. [4] A. Postnikov,  X  X ermutohedra, associahedra, and be-[5] K. V. Mardia and P. E. Jupp, Directional Statistics , [6] M. Meila, K. Phadnis, A. Patterson, and J. Bilmes, [7] P. Gaiha and S. K. Gupta,  X  X djacent vertices on a per-[8] D. B. West, Introduction to graph theory . Prentice [9] G. L. Thompson,  X  X eneralized permutation polytopes [10] C. Rasmussen and G. D. Hager,  X  X robabilistic data as-[11] R. Kondor, A. Howard, and T. Jebara,  X  X ulti-object [12] A. Chiuso and G. Picci,  X  X isual tracking of points as [13] W. J. Lentz,  X  X enerating bessel functions in mie scat-[14] M. A. Fligner and J. S. Verducci,  X  X istance based rank-
