 academic researcher social network. By researcher social network extraction, we are aimed at finding, extracting, and fusing the  X  X emantic X -based profiling information of a researcher from the Web . Previously, social network extraction was often undertaken separately in an ad-hoc fashion. This paper first gives a formalization of the entire problem. Specifically, it identifies the  X  X elevant documents X  from the Web by a classifier. It then proposes a unified approach to perform the researcher profiling using Conditional Random Fields (CRF). It integrates publications from the existing bibliography datasets. In the integration, it proposes a constraints-based probabilistic model to name disambiguation. Experimental results on an online system show that the unified approach to researcher profiling significantly outperforms the baseline methods of using rule learning or classification. Experimental results also indicate that our method to name disambiguation performs better than the baseline method using unsupervised learning. The methods have been applied to expert finding. Experiments show that the accuracy of expert finding can be significantly improved by using the proposed methods. much attention on the Web recently. As a typical online system, e.g., Facebook.com and MySpace.com, the user is required to enter a profile by her-or himself. The manual method can be used to construct a user-centered network, for example sending messages or focused communities such as music communities. Unfortunately, the method is not sufficient for mining in the Web 2.0 and Semantic Web. The information obtained solely from the user entered profile is sometimes incomplete or inconsistent. For example, users do not fill some information merely because they are not willing to fill the information. instance extraction of user profiles, is a promising solution to the problem, esp ecially in some specific domains such as the research er social network. This paper intends to conduct a thorough investigation on the issue of social netw ork extraction of academic researchers. Specifically, it focuses on studying how to extract the profile for a researcher and how to disambiguate the researchers having the same name. example, drawn from an actual case of extracting researcher profiles in our developed system ( http://www.arnetminer.org ), which is also the initial motivation of the work. In this system, we intend to construct a  X  X emantic X -based social network for academic researchers. Specifi cally, we extract the basic information, contact information, and educational history of a researcher from the Web and create a researcher profile. We integrate the publication information into the profile from DBLP. automatic extracting information from the Web can benefit many Web mining and social network applications. For example, if all the profiles are correctly extracted, we will have a large collection of well-structured data about real-world researchers. We can utilize the  X  X emantics X -based profiles to help enhance the mining such as expert finding. extraction. The left part shows a researcher homepage which includes typical researcher profile information and a DBLP page which contains his published papers. The ideal extraction/integration results are shown in the right part of Figure 1. challenges: (1) How to extract the profile information from the Web and (2) how to integrate the profile information extracted fro m different sources. manual entering mean for each researcher is obviously tedious and time consuming. Recent work has shown the feasibility and promise of information extraction technologies for extracting the structured data from the Web, and it is possible to use the methods to extract the profile of a researcher. However, most of the existing methods employed a predefined rule or a specific machine learning m odel to identify each type of information independently. It is highly ineffective to use the separated methods to do researcher profile extraction due to the natural disadvantages of the method: (1) For each property in the profile, one has to define a specific rule or supervised learning model. Therefore, there may be many different rules/models, which are difficult to maintain; (2) The separated rules/models cannot take advantage of dependencies across different properties. The properties are often dependent with each other. For instance, in Figure 1 identifying the text  X  Electrical Engineering  X  as Msmajor will greatly increase the probability of the text  X  Delft University of Technology  X  to be identified as Msuniv . Consequently, how to effectively identify the profile information from the Web becomes a challenging issue. different sources, we focus on the name disambiguation problem. Existing methods include heuristic rules, classification-based supervised method, and clustering-based unsupervised method. However, it is also not effective to directly employ the existing methods in researchers X  profile integration. This is because: (1) The heuristic rule based method requires the user to define a specifi c rule for each specific type of ambiguity problem, which is not adaptive for different situations; (2) The supervised method trains a user-dependent model for a certain person and thus cannot be adapted to the other person; and (3) The clustering based unsupervised method can deal with different persons simultaneously, however, it cannot make use of the supervised information. investigation on the problem. First, we formalize researcher network extraction as a process of identifying relevant Web pages, extracting profile information, and fusing the profile information from different sources. Secondly, we employed a classifier to identify the relevant Web pages. Then we propose a unified approach to extract the profile information from the identified Web pages on the basis of tagging. Specifically, we view the pr oblem as that of assigning tags to the input texts, with a tag representing one profile property. Furthermore, we propose a constraint-based probabilistic model to name disambiguation. The model can incorporate any types of domain background knowledge or supervised information (e.g., user feedbacks) as constraints to improve the performances of disambiguation. We define six types of constraints. To the best of our knowledge, research profiling in a unified approach and name disambiguation using a constraint-based probabilistic model have not been investigated previously. significantly outperforms the methods of using separated models for profile extraction. Experimental results also indicate that our disambiguation method can significantly outperform the unsupervised method. We applied our methods to expert finding. Experimental results show that our methods of profile extraction and name disambiguation can indeed enhance expert finding (+22% in terms of MAP). formalization of the problem of researcher network extraction, (2) proposal of a unified tagging approach to researcher profiling, (3) proposal of a constraint-based probabilistic model to name disambiguation, and (4) empirical verifi cation of the effectiveness of the proposed approaches. Section 2, we formalize the extraction problem. In Section 3, we explain our approaches and in Section 4 we give the experiments. Before concluding the paper in Section 6, we introduce related work. study. The system aims at providing a social networking platform for academic researchers. It has gathered 448,289 researchers. Our statistical study on the half million researchers shows that about 70.60% of the researchers have at least one homepage or a Web page that introduces them, which implies that extraction of the profile from the Web is feasible . For the ambiguity problem, we have examined 30 random person names and found that more than 60% of the names have the ambiguity problem. shown in Figure 2), by extending the FOAF ontology [5]. (Cf. Figure 1 for sample instances.) In the profile, two classes, 24 properties and two relations are defined. extraction from the Web. We here describe the two key issues we are going to deal with: researcher profile extraction and name disambiguation. statistics on randomly selected 1K researchers. We observed that 85.6% of the researchers are faculties of universities and 14.4% are from company research centers. For researchers from the same company, they often have a template-based homepage. However, different companies have absolutely different templates. For researchers from universities, the layout and the content of the homepages vary largely depending on the authors. We have also found that 71.9% of the 1K Web pages are researchers X  homepages and the rest are pages introducing the researchers. Characteristics of the two types of pages significantly differ from each other. Figure 2 . The schema of the researcher profile found that about 40% of the profile properties are presented in tables or lists and the others are presented in natural language. This also means a method without using the global context information in the page would be ineffective. Statistical study also unveils that (strong) dependencies exist between different profile properties. For example, there are 1325 cases (14.5%) in our data that the property label of the tokens need use the extraction results of the other tokens. An ideal method should consider processing all the subtasks together. extraction of publications directly from the Web. Instead, we integrate the publication data from existing online data source. We chose DBLP bibliography (dblp.uni-trier.de/), which is one of the best formatted and organized bibliography datasets. DBLP covers approximately 800,000 papers from major Computer Science publication venues. In DBLP, authors are identified by their names. For integrating the researcher profiles and the publications data, we use researcher names and the aut hor names as the identifier. The method inevitably has the ambiguity problem (different researchers have the same name). disambiguation task in our context. Given a person name a , we denote all publications containing the author named a as P ={ p 1 , p 2 , ..., p publication p i , it has six attributes as shown in Table 1. a ( 0 ) as the principal author and the others secondary authors . Suppose there existing k actual researchers { y 1 , y 2 , ..., y k } having the name a , our task is to assign these n publications to their real researcher y i . correspondingly a constraint set C ={ c 1 , c 2 , ..., c say a pair of publication p i and p j satisfies a constraint c if they satisfy the rule r l , i.e. from several digital libraries, e.g., IEEE, Springer, and ACM. We used heuristics to perform the extraction. identification, researcher profiling, and publication integration. In relevant page identification, given a researcher name, we first get a list of web pages by a search engine (we used Google API) and then identify the homepage/introducing page using a classifier. unified approach. The a pproach can incorporate dependencies between different types of profile properties to do better extraction. based probabilistic model to name disambiguation. explained in Section 5. The latter two issues have not been thorough investigated previously and are the main focus of our work. Both of the two proposed approaches to researcher profile extraction and name disambiguation are based on the theory of Markov Random Field. distribution of labels (hidden variables) that obeys the Markov property. It can be formally defined as follows. MRF Definition. Let G = ( V , E ) be a graph such that Then ( X , Y ) is a Markov random field in case , when the random variable Y v obeys the Markov property with respect to the graph : p ( Y v |Y w , w  X  v ) = p ( Y where w  X  v means that w and v are neighbors in G . example, Conditional Random Fields (CRFs) [17] and Hidden Markov Random Fields (HMRF) [3]. 3.2.1. Process. The approach consists of two steps: preprocessing and tagging. In preprocessing, (A) we separate the text into tokens and (B) we assign possible tags to each token. The tokens form the basic units and the pages form the sequences of units in the tagging problem. In tagging, given a sequence of units, we determine the most likely corresponding sequence of tags by using a trained tagging model. (The type of the tags corresponds to the property defined in Figure 2.) In this paper, as the tagging model, we make use of Conditional Random Fields (CRFs). Next we describe the steps (A) and (B) in detail. heuristics. We define five types of tokens:  X  X tandard word X ,  X  X pecial word X ,  X &lt; image&gt; X  token, term, and punctuation mark. Standard words are unigram words in natural language. Special words [21] include email, URL, date, number, percentage, words containing special symbols (e.g.  X  X h.D. X  and  X .NET X ), unnecessary tokens (e.g.  X === X  and  X ### X ), etc. We identify special words by using regular expressions.  X &lt;image&gt; X  tokens are  X &lt;image&gt; X  tags in the HTML file. We identify it by parsing the HTML file. Terms are base noun phrases extracted from the Web pages. We developed a tool based on technologies proposed in [26]. the token type. For example, for standard word, we assign all possible tags (each tag represents a property). For special word, we assign tags: Position , Affiliation , Email , Address , Phone , Fax , and Bsdate , Msdate , and Phddate . For  X &lt;image&gt; X  token, we assign two tags: Photo and Email (an email is likely to be shown as an image). possible tags. Using the tags, we can perform most of the profiling processing (conducting 16 subtasks defined in Figure 2). We do not conduct research interest extraction using the proposed approach, although we could do it in principle. There are two reasons: first, we observed only one fifth (21.3%) of researchers provide the res earch interest on homepages; secondly, research interest is usually implied by the other profile properties, e.g., papers published by the researcher or research projects he/she is involved in. 3.2.2. CRF model. We employ Conditional Random Fields (CRF) as the tagging model. CRF is a special case of MRF. CRF is a conditional probability of a sequence of labels y given a sequence of observations tokens [18]. In tagging, the CRF model is used to find the sequence of tags Y * having the highest likelihood Y * = max Y P ( Y | X ), with the Viterbi algorithm. and by means of an iterative algorithm based on Maximum Likelihood Estimation. 3.2.3. Features. Three types of features were defined: content features, pattern features, and term features. 1. Content features the current token contains a word or not. morphologies of the token, e.g. whether the token is capitalized. content features include: image. the ratio of the height to the width of the current image. the image (e.g.  X  X PG X ,  X  X MP X ). the  X  X nique color X  used in the image and the number of bits used for per pixel (e.g. 32, 24, 16, 8, and 1). image contains a person face. We use a tool from http://opencvlibrary.sf.net to detect the face in a picture. the image filename contains the research name. attribute of the  X &lt;image&gt; X  t oken contains the research name. indicate whether the image filename contains positive keywords like  X  X yself X  and  X  X iography X . indicate whether the image filename contains negative keywords like  X  X ogo X ,  X  X anner X , and  X  X ds X . 2. Pattern features the current token contains positive fax keywords like  X  X ax: X , positive position keywords like  X  X anager X . current token is a special word. if the current token contai ns the researcher name. 3. Term features the term contains a base noun phrase or not. whether the term contains a word in a dictionary. above into our model by defining Boolean-valued feature functions. In total, 108,409 features were used in our experiments. 3.3.1. Process. Our method is based on a probabilistic model using Hidden Markov Random Fields (HMRF). This model incorporates constraints and a parameterized-distance measure. The disambiguation problem is cast as assigning a tag to each paper with each tag representing an actual researcher y i . as the objective function. We aim at optimizing the objective function. We incorporate six types of constraints into the objective function. If one paper X  X  label assignment violates a constraint, it will be penalized in some sense, which in turn affects the disambiguation result. 3.3.2. Formalization using HMRF. A HMRF based semi-supervised framework is first introduced by [3]. HMRF is a generative model, which describes the joint probabilities. Based on Bayesian rule, the posterior probability of researcher labels Y can be written as: P ( Y ) can be expressed as: where c k ( y i , y j ) denotes a constraint of x the parameter; Z 1 is the normalization factor. exponential form [3]: where D ( x i , y i ) is the distance between the paper x its assigned researcher y i ; Z 2 is the normalization factor. where Z = Z 1 Z 2 . effectively performing the disambiguation task. 3.3.3. Constraint selection. We define six types of constraints based on the characteristic of publication dataset. Table 2 shows the constraints. papers p i and p j . The first constraint c 1 means the principal authors of two papers are from the same organization. Constraint c 2 means two publications have a secondary author with the same name, and the constraint c 3 means whether a paper cites another paper. Constraint c 4 means whether principal authors of the two publications have the same email address (this is a stronger constraint than the others). Constraint c 5 denotes user interaction. Table 2 . Constraints used in our approach 6 w 6  X  -CoAuthor one common author in  X  extension Suppose p i has authors  X  X avid Mitchell X  and  X  X ndrew Mark X , and p j has authors  X  X avid Mitchell X  and  X  X ernando Mulford X . If  X  X ndrew Mark X  and  X  X ernando Mulford X  also coauthor one publication, then we say p i and p j have a 2-CoAuthor constraint. We construct a matrix M (as shown in Figure 3) to test whether two papers have a  X  -CoAuthor constraint. p . authors , i =1,2,... n , i.e. matrix M p indicates the relationship between p matrix M pa , an element on row p i and column a The matrix M ap is symmetric to M pa . Sub matrix M indicates the coauthorship among a 1 , a 2 ,..., a only if a i and a j coauthor one publication in our database (not just limited to p 1 , p 2 ,..., p n ), otherwise 0. element on row p i and column p j becomes 1 if they have at least one common secondary author. Thus, M shows 1-CoAuthor constraints between papers. constraints between papers. Likewise for the  X  -CoAuthor constraints. If p i and p j have both  X  CoAuthor and  X  2 -CoAuthor (  X  1 &lt;  X  2 ) constraint, we only consider the  X  1 -CoAuthor constraint. empirically. For example, we assign c 2 constraint Co-Author a relatively high weight and assign w 6 as the  X  unique identifiers for people, so we assign w 4 the largest value. User X  X  feedback is another strong constraint. The larger th e weight, the greater the impact of that constraint is. In our experiment, we set w ~ w 6 as 0.5, 0.7, 0.6, 1.0, 0.9, 0.7  X  respectively. 3.3.4. EM framework. Three tasks are executed by the Expectation Maximization method: learning parameters of the distance measure, re-assignment of paper to researchers, and the update of researcher representatives y h . follows: here A is a parameter matrix. For simplification, we define it as a diagonal matrix. the E-step, given the current researcher representatives, every paper is assigned to the researcher by maximize p ( Y | X ). In the M-step, the re searcher representative y is re-estimated from the assignments to maximize p ( Y | X ) again, and the distance measure is updated to maximize P ( Y | X ). cluster publications into disjoint groups based on the constraints over them, i.e. if two publications have a constraint, then they are assigned to the same researcher. Therefore, we first get  X  groups. If  X  is equal to our actual researcher number k , then these  X  choose ( k - X  ) random assignment. If  X  &gt; k , we cluster the nearest group until there are only k groups left. researchers are updated to maximize the p ( Y | X ). A greedy algorithm is used to sequentially update the assignment for each paper. The algorithm performs assignments in random order for all papers. Each paper x is assigned to y h that maximize the function: keeping assignments of the other papers fixed. The assignment process is repeated after all papers are assigned. This process runs until no paper changes its assignment between two successive iterations. updated by the arithmetic mean of its points: parameters on the diagonal) 4.1.1. Data sets. For profiling experimentation, we randomly chose in total 1K researcher names from our researcher network system. We used the method described in Section 3 to find the researchers X  homepages or introducing pages. The F1-score of the process is 92.39%. If the method cannot find a Web page for a researcher, we remove the researcher name from the data set. We finally obtained 898 Web pages. the Web pages. A spec was created to guide the annotation process. For disagreements in the annotation, we conducted  X  X ajority voting X . 86.41% of the Web pages contain at least five properties and 96.44% contain four. We omit the details due to space limitation. from our database, namely Abbreviated Name dataset and Real Name dataset. The first dataset was collected by querying 10 abbreviated names in our database. All the abbreviated names are created by simplifying the original names to its first name initial and last name, for example,  X  X heng Chang X  to  X  X . Chang X . The simplifying form is popular in bibliographic records. Statistics of this dataset is shown in Table 3. person names  X  X ing Zhang X  and  X  X i Li X . The purpose of constructing the small dataset is to analyze contributions of the six types of constraints we defined.  X  X ing Zhang X  has totally 54 publications by 25 different researchers and  X  X i Li X  has 42 publications by 22 different researchers. 4.1.2. Evaluation measures. In the experiments, we conducted evaluations in term s of precision, recall, and F1-measure (for definitions, see for example [25]). By comparison of the other work, we also give statistical significance estimates using Sign Test [13]. 4.1.3. Implementation of baseline methods. We defined baselines for researcher profile extraction and name disambiguation. learning based approach and the classification based approach as baselines. For the former approach, we employed the Amilcare system [6]. The system is based on a rule induction algorithm, called LP 2 . For the latter approach, we trained a classifier for identifying the values of each property. We employed Support Vector Machines (SVM) [9] as the classification model. We used the same features as those in our unified model. each profile property independently. When there is a conflict between the outcomes of two classifiers, we adopt the result with higher predicting score. of properties affect the performance of profiling, we also conducted experiments using the unified model by removing the transition features (Unified_NT). based on previous work [22] (except that [22] also uses a search engine to help the disambiguation). The baseline uses a hierarchical clustering algorithm to group the papers together. Then we view the grouped papers as the disambiguation results. We suppose that the number of persons k is provided empirically. 4.2.1. Results. Table 4 shows the five-fold cross-validation results. Our method outperforms the baseline method. We can also see that the performance of the unified method decreases when removing the transition features (Unified_NT). improvements of Unified over Amilcare, SVM, and Unified_NT are statistically significant ( p &lt;&lt; 0.01). 4.2.2. Contribution of features. We investigated the contribution of each feature ty pe in profile extraction. We employed only content features, content+term features, content+pattern features, and all features to train the models and conducted the profile extraction. extraction with different feature types. We see that solely using one type of features alone cannot accomplish accurate profile extr action. The results also unveil the reason of the high performance in the extraction achieved by our method. 4.2.3. Discussion. Our method outperforms Amilcare and SVM in most of the subtasks, especially in the subtasks that have strong de pendencies with each other. the dependencies between the subtasks. For example, there were 337 cases (25.41%) in which Address identification needs to use the results of Affiliation . However, the baselines cannot make use of the dependencies, as it conducts all the subtasks independently. Our method be nefits from the ability of modeling dependencies between subtasks. Table 4 shows that by leveraging the dependencies, our method outperforms the method without using (Unified_NT) by 10.28% in terms of F1-score. we omit the details here due to space limitation and will report them in an expanded version. 4.3.1. Results. The performances of our method and the baseline method on the Abbreviation Name dataset are shown in Table 5. Table 5 . Results on Abbreviate Name Dataset method by 8.0% in terms of F1-measure. 4.3.2. Contribution of constraints. We investigated the contribution of each type of constraints in name disambiguation. Figure 5 shows the F1-score of  X  X ing Zhang X  and  X  X i Li X  on the Real Name dataset with various combinations of constraints. We can see that the CoAuthor constraint contributes a lot to the results. It can be also seen that a ll the constraints we defined can enhance the final performance. we applied it to expert finding. The task of expert finding is to identify persons with some given expertise or experience. In this task, we intend to test if the extracted profiles and the disambiguation results can be used to enhance expert finding. extraction (RPE) and disambiguation (ND) and the results by adding them one by one (+RPE and +ND). We selected 12 topics for finding experts from the system. We conducted evaluation in terms of P@5, P@10, P@20, P@30, R -prec, mean average precision ( MAP ), bpref , and mean reciprocal rank ( MRR ) [10]. that significant improvements can be obtained by using our methods. For example, in terms of mean average precision (MAP), 20% improvements can be obtained using profile extraction results (+RPE). With our name disambiguation method (+ND), MAP can be again improved by 2%. extracting profile information of a person. For example, Yu et al. propose a cascaded information extraction framework for identifying personal information from resumes [27]. In their approach, a resume is first segmented into consecutive blocks attached with labels indicating the information type. And then, the detailed information such as Address and Email , are identified in certain blocks. The Artequakt system [1] employed a rule based extraction system called GATE [11] to extract entity and relation information from the Web. However, most of the previous works view the profile extraction as several separate issues and conduct a more or less ad-hoc manner. To the best of our knowledge, no previous work has been done on researcher profiling using a unified approach. of contact information from emails or the Web. For example, Kristjansson et al . developed an interactive information extraction system to assist the user to populate a contact database from emails [17]. Tang et al. propose a cascaded method for detecting signatures from emails [23]. See also [2]. Contact information extraction is a subtask of profile extraction, thus it significantly differs from profile extraction. for papers, for example, scholar.google libra.msra, citeseer.ist.psu, and dblife. cs.wisc. However, all the systems are focusing on providing services for searching publications rather than person. proposed. Hidden Markov Model (HMM) [12], Maximum Entropy Markov Model (MEMM) [19], Conditional Random Field (CRF) [18], Support Vector Machines (SVM) [9], and Voted Perceptron [8] are widely used models. See [24] for an overview. name disambiguation in different domains. different persons with the same name. They present two unsupervised frameworks for solving this problem: one is based on link structure of the Web pages and the other uses Agglomerative/Conglomerative double clustering method. See also [20]. The methods are based on unsupervised clustering. They cannot incorporate all types of constraints. disambiguation in publication data. For example, Han et al. propose an unsupervised learning approach using K-way spectral clustering method [16]. They calculate a Gram matrix for each name dataset and apply K way spectral clustering algorithm to the Gram matrix to get the result. See also [22]. The type of method uses a parameter-fixed distance metr ic in their clustering algorithm, while parameters of our distance metric can be learned during the disambiguation process. on Na X ve Bayes and Support Vector Machines respectively. For a given name, the methods learn a certain model from the train data and use the model to predict whether a new citation is authored by the author. However, the method is user-dependent. It is impractical to train thousands of models for all individuals in a large digital library. In contrast to supervised methods, our method is more scalability. clustering, e.g. [3] [7]. [3] proposes a probabilistic model for semi-supervised clustering based on Hidden Markov Random Fields. Their model combines the constraint-based and di stance-based approaches. Compared with [3], we define six kinds of constraints and our method generates the constraints automatically. researcher social network extraction, an important issue for mining social networks. We have formalized the extraction problem. We have then proposed a unified approach to perform the profile extraction task and a constraint-based probabilistic model to perform name disambiguation in integration. Experimental results show that our approaches outperform the baseline methods on both of the two issues. When applying it to expert finding, we obtain a significant improvement on performances. 
