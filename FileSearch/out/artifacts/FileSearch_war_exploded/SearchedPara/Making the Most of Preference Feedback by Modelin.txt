 Conversational recommender systems help users navigate through the product space by exploiting feedback. In con-versational systems based on preference-based feedback, the user selects the most preferred item from a list of recom-mended products. Modelling user X  X  preferences then be-comes important in order to recommend relevant items. Sev-eral existing recommender systems accomplish this by as-suming the features to be independent. Here we will attempt to forego this assumption and exploit the dependencies be-tween the features to build a robust user preference model. H.3.4 [ Information Storage and Retrieval ]: Systems and Software Algorithms, Experimentation, Performance Conversational recommendation systems, Preference-based feedback, User preference model
Conversational recommendation is a knowledge-based ap-proach to recommendation where the system engages in a chat with the user about his requirements from the product much like a human shopkeeper. Since most users do not have complete information about the domain, they do not know the product that is best suited for them. Conversational systems improve their recommendations by requesting for some sort of feedback on them from the user. Preference-based feedback is one way to elicit feedback in which the user is asked to choose the product that she prefers from a small set of recommendations.
 c
In order to recommend relevant products, the system needs to understand the priorities of the user. It needs to know which of the features the user is willing to compromise to get an improvement in the others. We demonstrate in this paper how this can be achieved by abandoning the feature inde-pendence assumption. We shall see later that the proposed algorithm results in a significant reduction in the number of interactions to reach the desired product.
In this section, we shall look at a few conversational rec-ommender systems that use preference-based feedback to recommend a better set of products in the subsequent iter-ations.
The MLT ( More Like This ) approach proposed by McGinty et al. [3] modifies the query for the next iteration by simply selecting all the features of the chosen product. In the sub-sequent iteration, the system returns products that are most similar to the modified query. The obvious drawback of the MLT approach is that it assumes every feature in the chosen product to be important to the user which, in general, is not true.
 The wMLT ( weighted More Like This ) approach attempts to solve this by assigning weights to the features such that if a feature value is present in the rejected products along with the chosen product, it is given a lower weight. These weights are used in calculating similarity between the prod-ucts as given by the weighted similarity model , where, sim i is the similarity between the i th features of the products and w i is the weight associated to the i th feature. Smyth et al. [5] provide a novel way of including diversity in the recommendations without compromising on similar-ity and their algorithm MLT-AS ( Adaptive Selection )was shown to perform better than other MLT based approaches. Zhang and Pu [6] introduced a method based on Multi Attribute Utility Theory (MAUT) to generate compound critiques. One of the simplest ways to calculate utility of a product is given by, where n is the number of features, w i is the weight associ-ated with each feature and V i is the value function of the feature value x i .
 In each cycle of Critique-MAUT, the critiques are gener-ated based on the products with maximal utility. Chen and Pu [1] also used MAUT-based preference model but intro-duced a novel critique generation approach using Apriori algorithm. The weights of the features in both these meth-ods are adjusted for the next cycle by a factor  X  according to the difference between the old and the chosen value of the feature.
 The recommender systems discussed above assume the fea-tures to be independent while forming the new query or while updating the feature weights. The proposed method addresses this fundamental issue with these systems. While there have been past efforts to model constraints made ex-plicit by the user in the context of example critiquing [4], this paper presents a novel and practical approach to model user preferences by exploiting feature tradeoffs implicit in preferences expressed by the user. Both similarity based approaches like wMLT and utility based approaches like Critique-MAUT can be extended with our algorithm.
Let us assume that the set of cameras shown in Table 1 is recommended in a particular iteration to a user. For the sake of this discussion, we consider only three features for each camera -Price, Zoom and Resolution. Now, say the user chooses product 1 over the products 2 and 3. Our aim is to learn about the preferences of the user based on this choice.

Product Price ($) Zoom (X) Resolution (M pixels) For illustration, values in Table 1 are not normalized. For the rest of the discussion assume that all values are range normalized.
Consider products 1 and 2 in Table 1. The user prefers product 1 over product 2 thereby compromising price for getting better zoom and resolution. Lets denote the dif-ference in the normalized feature values by  X  12 P , X  12 Z  X  point to note here is that Zoom and Resolution are  X  X ore-is-better X  (MIB) features whereas Price is a  X  X ess-is-better X  (LIB) feature. Thus, we consider a positive difference in Zoom and Resolution a gain but a positive difference in Price a loss. In order to make it consistent, we negate the  X  X  X  that correspond to LIB features.
 In a uniform scenario, we would expect that the net gain (i.e., simple addition of the gains and losses) the user obtains by choosing product 1 is positive. This might not be true in general as different users have different priorities over fea-tures. In order to model such priorities, we assign, for every user, a set of preference weights corresponding to the feature set. Now, we hypothesize that the net gain weighted with these preference weights should be positive, given that the user prefers one product over the other. Mathematically, where w p , w z and w r are the preference weights associated to Price, Zoom and Resolution respectively. Although it is possible to combine the user preferences in a more flexible way, we adopt a linear combination in order to limit the number of weights to a feasible total. Notice that there is a negative sign in front of  X  12 P in the above equation since Price is an LIB feature. In our example,  X  12 P&gt; 0 ,  X  0 ,
 X  12 R&gt; 0. Let us rewrite inequality (3) as, representing the fact that the compensation obtained from Zoom and Resolution is higher than what the user is com-promising in Price. Now, if the difference in price is very high, then we can infer that the weight associated with price should be low so that the above inequality is satisfied. Similarly, another inequality can be obtained from the fact that the user has chosen product 1 over product 3 as well. In general, we can obtain k  X  1 inequalities where k is the number of products recommended in each iteration. Since these weights represent the user X  X  priority over the fea-tures, we require them to be such that, where w i refers to the i th feature ( w p , w z and w r in our example).
Our aim now is to obtain the preference weights from these inequalities. In order to choose one among infinite sets of weights, we need to make some assumption about the gen-eral behaviour of users. One possible assumption is that a user X  X  preferences do not change substantially over multi-ple interactions. Hence, we assume that the optimal set of weights lies close to the one obtained from the previous iter-ation. This gives way for an appropriate objective function. We use Augmented Lagrangian method [2] to solve the non-linear optimization problem described above. It adds the constraints along with a penalty factor to the original ob-jective function giving rise to a new unconstrained objective function. In case the inequalities have no common solution, the algorithm will try to satisfy as many inequalities as pos-sible.
 Now, using this kind of an objective function has a key limi-tation. If the set of weights obtained from previous iterations already satisfy the current set of inequalities, then there is no change in the weights for the next cycle. Consequently, the products recommended in the next cycle are very similar to the products recommended in the current cycle. Hence, thesystemislikelytogetstuckwiththesamesetofweights for several iterations. Another drawback arises when the user wishes to change his priorities during the course of his interactions. In this case, it might take a few cycles just to abandon the weights from previous interactions. Algorithm 1: CDPM-Util and CDPM-Sim 10 currWts  X  Optimize ( objFunc , ineqConst , 11 if recommendationType is Utility then 12 Rec  X  GenKMaxUtilityProducts ( DB , 14 newQuery  X  choice ; 15 Rec  X  FindClosestKProducts ( DB , newQuery , 18 DB  X  DB -Rec ; We call our approach Compromise Driven Preference Model (CDPM) since it attempts to exploit dependencies between features and learn weights that provide explanations for com-promises the user may have made in the course of making preferences.
The user preference weights obtained after optimization can be used as feature weights either in the weighted sim-ilarity model defined by (1) or in the MAUT based model defined by (2). We will refer to the resulting algorithms as CDPM-Sim and CDPM-Util respectively. Algorithm 1 pro-vides a condensed description of these two methods. Now we shall see how our approach makes use of the de-pendencies between the features to obtain better preference weights. Consider the example given in Table 2.
 Table 2: Example : Importance of feature dependencies
Product Price ($) Zoom (X) Resolution (M pixels) Say a particular user chooses product 2 over product 1. This should, intuitively, increase the weight of Resolution to a large value because the user is willing to spend 100$ for just 0.2MP increase in Resolution, which is what happens in our approach. The weight of a particular feature obtained from our approach is not just dependent on the difference in value of that feature but on that of every other feature as well. In the above example, the weight of the feature Resolution is affected by every other feature including Price. Here we took an extreme example to illustrate our point but the same is true for a general scenario as well.
We evaluate our system on three datasets -Camera , PC and Used Cars .The Camera dataset consists of 210 cam-eras with 6 numeric features and 4 categorical features. The PC dataset consists of 120 PCs with 5 numeric features and 3 categorical features. The Used Cars dataset is a larger dataset consisting of 960 cars with 6 numeric features and 5 categorical features.

We use a utility function for each categorical attribute that assigns a normalized numeric value for every attribute value. Every iteration, the utility of the attribute value present in the chosen product is boosted. Hence, the value of the categorical attribute that is preferred by the user is given a higher utility than others. These utilities can be used in the inequalities described in  X  3.1, effectively han-dling categorical features.
 We evaluate our solution by employing the approach com-monly used to analyse the effectiveness of preference-based feedback recommender systems [3, 5]. We simulate the in-teraction with the recommender system using an artificial agent. We start with a random product, remove it from the database and form a partial query by eliminating values for some of the features. Three types of queries were formed containing value for 1 feature (Q1), 3 features (Q3) and 5 features (Q5) respectively.
 In an intermediate cycle the artificial agent chooses a prod-uct from the k products recommended. We experimented with two selection strategies -Optimal and Noisy. In the Optimal strategy, the agent chooses the product with high-est similarity to the original product. In the noisy strategy, the similarity values to the original product are perturbed to some extent. Here, the agent might choose suboptimal products, mimicking the way real users behave. We define the target product as the one still in the database with high-est similarity with the original product. Thus, the job of the recommendation system is to reach this target product from the partial query and the intermediate interactions in as few cycles as possible.
 We repeat this process multiple times with different initial products and record the number of cycles taken to reach the target product. We generated 3000 random queries for each dataset and compared the performance of our algorithms with MLT, wMLT and Critique-MAUT.
The average number of cycles taken by the algorithms to reach the target product for the three datasets is shown in Figure 1. In Camera dataset, CDPM-Util takes only 16.77 cycles on average for query type Q1 whereas Critique-MAUT takes 21.18 cycles. Similarly, in query types Q3 and Q5, there is 22.2% and 26.4% reduction in the number of cycles respectively. There is upto 35.2% and 53% reduction in cy-cles as compared to Critique-MAUT in PC and Used Cars datasets respectively.
 CDPM-Sim outperforms the other similarity-based algorithms like MLT and wMLT by a significant margin. In Camera dataset, CDPM-Sim takes 7.47 and 2.12 cycles on aver-age for query type Q3 and Q5 whereas wMLT takes 9.52 and 4.55 cycles respectively. This translates to 21.5% and 53.35% reduction in cycles for Q3 and Q5 types when com-pared with wMLT. Similar improvements can be observed for PC and Used Cars datasets as well. It was observed that these trends were preserved in the Noisy selection strategy (the deviations with respect to Optimal selection in improve-ment percentages were of the order of 1%-4% for the Camera dataset, 3%-8% for the PC dataset and 3%-5% for the Used Cars dataset). The experiments were done on a system with Intel i5 pro-cessor, 2.53GHz clock speed, 3MB cache and 6GB memory using R environment. On an average, MLT, wMLT and Critique-MAUT take 8-16ms per iteration whereas CDPM-Util and CDPM-Sim take around 136ms and 345ms per iter-ation respectively. This increase in time is adequately com-pensated by CPDM X  X  reduction in number of cycles, since each cycle involves manual screening which not only adds to cognitive load but is slower by orders of magnitude. Having said this, we need to devise faster optimization schemes to improve CPDM X  X  current time performance.
 As discussed before, the present objective function might cause the system to remain stuck with the same weights for several iterations. Let us look at two variations of our approach that attempt to solve this issue.
We hypothesized, in  X  3.1, that if a product is chosen over the other, then the weighted net gain should be positive. Now, we propose that the net gain should be greater than a small positive value (  X  ) that represents the user X  X  confidence while choosing one product over the other. This reduces the feasible region for the optimization algorithm thereby low-ering the chances of the old set of weights satisfying the new constraints.

Confidence (  X  ) CDPM-Util-C CDPM-Sim-C Q1 Q3 Q5 Q1 Q3 Q5 Improvements obtained for different values of the confidence parameter,  X  , is presented in Table 3. A confidence value of 0 . 05 performs best in almost all cases. We observe close to 20% and 30% further reduction in number of cycles for CDPM-Util-C and CDPM-Sim-C when compared with their respective counterparts with no confidence factor. A further increase in the confidence parameter leads to over-pruning of the search space and hence, adversely affects performance.
Diversity in recommendation ensures that the user X  X  choice provides more information about his preferences. We use the Adaptive Selection approach mentioned in [5] to construct two new algorithms -CDPM-Util-AS and CDPM-Sim-AS . These algorithms recommend the product chosen in the pre-vious iteration again along with the new set of recommen-dations. If the user selects the same product again, it is assumed that the user is not being given enough alterna-tives and the strategy is modified to include more diverse products. The scores for products is calculated by a linear combination of the diversity introduced by the product and its utility/similarity value with weights  X  and 1  X   X  respec-tively. The improvements obtained for different values of are shown in Table 4.
 CDPM-Util-AS performs only marginally better than CDPM-Util . On the other hand, CDPM-Sim-AS takes 30-40% fewer cycles than CDPM-Sim across different query types. This is because, unlike CDPM-Util-AS , CDPM-Sim-AS also uses the diversified recommendation as query for the next itera-tion along with the updated weights.
Many recommender systems based on preference-based feedback like Critique-MAUT and wMLT assume the prod-uct attributes to be preferentially independent of each other. In this paper, we presented a recommender system that ex-ploits the dependencies between the features and reported empirical findings that suggest significant performance im-provements over these recommender systems. [1] L. Chen and P. Pu. Preference-based organization [2] M. R. Hestenes. Multiplier and gradient methods. [3] L. Mc Ginty and B. Smyth. Evaluating [4] P. Pu and B. Faltings. Decision tradeoff using [5] B. Smyth and L. McGinty. The power of suggestion. In [6] J. Zhang and P. Pu. A comparative study of compound
