 A hashtag is a set of words prefixed by a # (or #xxx# for Chinese hashtag) symbol in a post on micro-blogging systems. Hashtag is always generated to present a topic that aims to make posts easily understandable by other relevant users and facilitate conver-sations among the users with its rich sentiment information. Hashtag recommendation in nature is to predict users X  interests and provide possible preferred hashtags to users that they have not yet considered.

Current work introduces simple yet incomplete one or two features to rank items for recommendation, while some other important factors are neglected, i.e., item popular-ity and user interest evolution [2] [3] [5]. Correspondingly, people other get a recom-mended list only with breaking events, or only with personal user interest when applied with traditional methods. While our proposed approach would provide fascinating re-sults. Our contributions in this paper can be summarized as follows. (1) We introduce the first work on hashtag recommendation with three features: hash-tag popularity, hashtag textual information, and hashtag time factor. All the proposed features are theoretically and experimenta lly demonstrated important for hashtag rec-ommendation. (2) We scheme a novel hashtag recommendatio n approach considering personalized and evolutionary aspects. We model user preference for recommendation based on the three features, and a hybrid recommendation approach is introduced to extract the top N hashtags.
 In our hashtag recommendation method, we balance three features: hashtag popular-ity, hashtag textual information, hashtag time factor to model user preference and its evolution, and take several steps t o get the final recommendation results. 2.1 Hashtag Popularity Intuitively, if a hashtag is a hot one on a micro-blogging system, it will attract more users involved in, which also brings higher popularity of the hashtag. According to this observation, we use the following equations to measure the hashtag popularity and score the final recommendation.
 First, we define hashtag hotness as follows: where Count users is the count of users that use the current hashtag, MAX users is the maximum count of users involved in a hashtag, and MIN users is the minimum count of users involved in a hashtag.
 The hashtag hotness works well if all hashta gs are generated to reflect user interest. Whereas, as we observed, there exist parts of unfavorable hashtags from advertisers or with sale information. These hashtags are with massive referred posts, while with few people involved in, which are valueless for recommendation and should be ignored. We borrow the concept  X  X uthorship entropy X  [1] to measure the hashtag authorship. where l is the count of users that involve in the current hashtag, n is the number of posts associated with the hashtag, and c i is the count of posts that the i th user creates. Thus we get the final score of hashtag popularity for recommendation:
After hashtag popularity computation, the hashtags would be ranked with their hot-ness degrees. Correspondingly, hashtags expressing breaking events would come out at the top of the ranking list. 2.2 Hashtag Content Similarity To predict personal user preference on hashtags, we model the relationship between personal user interest and visited hashtags as text similarity. That is, user interest (la-beled as D user ) can be presented with the textual documents of all posts related with the current user, and each post associated with the current hashtag (labeled as D hashtag ) can be viewed as another document. Thus personal user preference on hashtags can be calculated with a similarity function. We take two steps to calculate text similarity 1) Topic probability distribution genera tion. We adopt Latent Dirichlet Allocation (LDA) to calculate the probability distribu tion. LDA is one of the increasingly popular tools for summarization and discovery with the capability of automatically extracting the topical structure of large document collections. We first calculate keywords w dis-tribution on topics to , and topics to distribution on posts pd with LDA computation equations.

We train the LDA parameters to generate a set of probability distributions: P pd to that is topics to n probability distribution on post pd ,and P to w is keywords w probability distribution on topic to n .Thenweuse P to w to determine D user and D hashtag proba-bility distributions on each topic labeled as P user and P hashtag respectively. P user = { P
U ( to 1 ) ,P U ( to 2 ) , ..., P U ( to k ) Where k is the total number of topics, and we set k = 200 . 2) Similarity calculation. We use negativ e symmetric Kullback-Leibler divergence function to measure the similarity between D user and D hashtag .
 a non-symmetric measure of the difference between two probability distributions P user
With this step, most of hashtags reflecting p ersonal user interest would be promoted in the ranking list. Still the ranking list rarely provides time-insensitive hashtags pre-senting long-term user interest. We then add hashtag time feature to capture user interest evolution, and promote the importance of time-insensitive hashtags. 2.3 Hashtag Time Factor As described above, hashtags can be categori zed into two classifications: time-sensitive hashtags and time-insensitive hashtags. User interest would evolve when time changes, e.g. football fans would like to attend football match events for a long time, whereas they may watch live webcast on #World Championships in Athletics in Moscow dur-ing the competitions. We take two steps to calculate the contribution of hashtag time adapting to short-term and long-term user interest. 1) Hashtag classification. We first address t he classification strategy according to hashtag time. Hashtag, especially time-sensitive hashtag exists the phenomenon of micro-meme. As we observed, most of time-sensitive hashtags have a hot period within a week. On the other hand, time-insensitive hashtags represent long-term user interest, which are almost time independence. We view this problem as a sequence classification problem and simplify the approach introduced in [4]. For each hashtag H ,werank all associated posts within a time period  X t (  X t =1 day in this paper), and then get a ranked set of posts: S ( H )= { N 1 ,N 2 , ..., N k } .Where N k is the count of posts at k th day after the hashtag is created. We set k =7 since time-sensitive hashtags have a hot period within a week. If a hashtag is created less than 7 days, we just set N i =0 for the days before its creation. We then transform S ( H ) to a 7-dimensional vector: V Vector Machine) using RBF(Radial B asis Function) kernel with feature V S H based on the libsvm toolkit. We label 428 hashtags manually for the training set (253 for posi-tive classification, and 175 negative one), and verify with 5-cross-validation approach, which gets 82 . 3% accuracy. 2) The contribution of hashtag time. We introduce a decay factor TF hashtag to cal-culate the contribution of hashtag time, which aims to reduce the importance of time-sensitive hashtags.
 where  X  is a constant attenuation coeffcient. We set parameter  X  =0 . 3 through heuristic learning approach. t is current day, t max is the day with the maximum count of posts, and the unit of t is one day. When we calculate TF hashtag at the day of hashtag creation, we just set TF hashtag =1 for simplicity. Also we make TF hashtag =1 if the hashtags are time-insensitive. 2.4 Hashtag Recommendation Hashtag recommendation gives top N candidates for users with a combination function utilizing three features, including hashta g content, hashtag popularity and hashtag time factor: where Sim c and Score hashpop would be normalized into [0 , 1] . For each user, top N candidate hashtags would be ranked with RecH ( U, H ) as final recommendation results.

After this step, the recommendation list would include those hot hashtags, personal short-term interest and long-term interest hashtags. That means the recommendation results appeal to a broader constituency.

