 Jens Allwood  X  Stefan Kopp  X  Karl Grammer  X  Elisabeth Ahlse  X  n  X  Elisabeth Oberzaucher  X  Markus Koppensteiner Abstract Communicative feedback refers to unobtrusive (usually short) vocal or bodily expressions whereby a recipient of information can inform a contributor of information about whether he/she is able and willing to communicate, perceive the information, and understand the information. This paper provides a theory for embodied communicative feedback, describing the different dimensions and fea-tures involved. It also provides a corpus analysis part, describing a first data coding and analysis method geared to find the features postulated by the theory. The corpus analysis part describes different methods and statistical procedures and discusses their applicability and the possible insights gained with these methods.
 Keywords Communicative embodied feedback Contact Perception Understanding Emotions Multimodal Embodied communication 1 Introduction The purpose of this paper is to present a theoretical model of communicative feedback, which is to be used in a VR agent capable of multimodal communication. Another purpose is to briefly present the coding categories which are being used to obtain data guiding the agent X  X  behavior. Below, we first present the theory.
The function/purpose of communication is to share information. This usually takes place by two or more communicators sequentially and sometimes simulta-neously contributing new information. In order to be successful, this process requires a feedback system to make sure the contributed information is really shared. Using the cybernetic notion of feedback of Wiener ( 1948 ) as a point of departure, we may define a notion of communicative feedback in terms of four functions that directly arise from basic requirements of human communication: Communicative feedback refers to unobtrusive (usually short) vocal or bodily expressions whereby a recipient of information can inform a contributor of information about whether he/she is able and willing to (i) communicate (have contact), (ii) perceive the information (perception), and (iii) understand the information (understanding). In addition, (iv) feedback information can be given about emotions and attitudes triggered by the information, a special case here being an evaluation of the main evocative function of the current and most recent contributions (cf. Allwood et al. 1992 , Allwood 2000 , where the theory is described more in detail). To meet these requirements, the sender continuously evokes (elicits) information from the receiver, who, in turn, on the basis of internal appraisal processes connected with the requirements, provides the information in a manner that is synchronized with the sender.

The central role of feedback in communication is underpinned already by the fact that simple feedback words like yes , no and m are among the most frequent in spoken language. A proper analysis of their semantic/pragmatic content, however, is fairly complex and involves several different dimensions. One striking feature is that these words involve a high degree of context dependence with regard to the features of the preceding communicative act, notably the type of speech act (mood), its factual polarity, information status and evocative function (cf. Allwood et al. 1992 ). Moreover, when studying natural face-to-face interaction it becomes apparent that the human feedback system comprises much more than words. Interlocutors coordinate and exchange feedback information by nonverbal means like posture, facial expression or prosody. In this paper, we extend the theoretical account developed earlier to cover embodied communicative feedback and provide a framework for analyzing it in multimodal corpora. 1.1 Dimensions of communicative feedback Communicative feedback can be characterized with respect to several different dimensions. Some of the most relevant in this context are the following: (i) Degrees of control (in production of and reaction to feedback) (ii) Degrees of awareness (in production of and reaction to feedback) (iii) Types of expression and modality used in feedback (e.g. audible speech, (iv) Types of function/content of the feedback expressions (v) Types of reception preceding giving of feedback (vi) Types of appraisal and evaluation occurring in listener to select feedback (vii) Types of communicative intentionality associated with feedback by producer (viii) Degrees of continuity in the feedback given (ix) Semiotic information carrying relations of feedback expressions These dimensions and others (cf. Allwood 2000 ) play a role in all normal human communication. Below, we will describe their role for embodied communicative feedback. Table 1 shows how different types of embodied feedback behavior can be differentiated according to these dimensions. The table is discussed and explained in the eight following sections (cf. also Allwood 2000 , for a theoretical discussion). 1.1.1 Degrees of awareness and control and embodiment Human communication involves multiple levels of organization involving physical, biological, psychological and socio-cultural properties. As a basis, we assume that there are at least two (human) biological organisms in a physical environment causally influencing each other, through manipulation of their shared physical environment. Such causal influence might to some extent be innately given, so that there are probably aspects of communication that function independently of awareness and intentional control of the sender. Other types of causal influence are learned and then automatized so that they are normally functioning automatically, but potentially amenable to awareness and control. Still other forms of influence are correlated with awareness and/or intentional control, on a scale ranging from a very low to a very high degree of awareness/control. In this way, communication may involve (1) innately given causal influence (2) potentially aware and intentionally controllable causal influence (3) actually aware and intentionally controlled causal influence.
 Human communication is thus  X  X  X mbodied X  X  in two senses; (i) it always relies on and exploits physical causation (physical embodiment), (ii) its physical actualization occurs through processes in a biological body (biological embodiment). The feedback system as an aspect of human communication shares these general characteristics. The theory has a perspective on communication and feedback, which implies processes occurring on different levels of organization or put differently as can be seen in Table 1 as implying processes that occur with different levels of awareness and control (intentionality). In addition to this, the theory also involves positing several qualitatively different parallel concurrent processes. 1.1.2 Types of expression and modality used in feedback Like other kinds of human communication, the feedback system involves two primary types of expression, (i) visible body movements and (ii) audible vocal sounds. Both of the two types can be discrete (e.g. a head nod or a word) or more continuous (e.g. an emotional facial expression or type of prosody). Normally, discrete and continuous means are used in combination. Furthermore, both means of expression can occur on the different levels of awareness and control discussed above. That is, there is feedback, which is mostly aware and intentionally controllable, like the words yes, no, m or the head gestures for affirmation and negation/ rejection. There is also feedback that is only potentially controllable, like smiles or emotional prosody. Finally there is feedback behavior that one is neither aware of nor able to control, but that is effective in establishing coordination between interlocutors. For example, speakers tend to coordinate the amount and energy of their body movements without being aware of it. 1.1.3 Types of function/content of the expressions Communicative feedback concerns expressive behaviors that serve to give or elicit information, enabling the communicators to share information more successfully. Every expression, considered as a behavioral feedback unit, has thus two functional sides. On the one hand it can evoke reactions from the interlocutor, on the other hand it can respond to the evocative aspects of a previous contribution. Giving feedback is mainly responsive, while eliciting feedback is mainly evocative. Each feedback behavior may thereby serve different responsive functions. For example, vocal verbal signals (like m or ye s) inform the interlocutor that contact is established (C) that what has been contributed so far has been perceived (P) and (usually also) understood (U). Additionally, the word yes often also expresses acceptance of or agreement (A) with the main evocative function of the preceding contribution. Thus, four basic responsive feedback functions (C, P, U and A) can be attached to the word yes. In addition to these functions, further emotional, attitudinal information (E) may be expressed concurrent to the word yes . For example, the word may be articulated with enthusiastic prosody and a friendly smile, which would give the interlocutor further information about the recipient X  X  emotional state. Similarly, the willingness to continue (facilitating communication) might be expressed by posture mirroring. Because of conceptual and theoretical difficulties in making a distinction between emotion and attitude, we view emotions and attitudes as a continuum, which can be more or less relational (1 place or 2 place). Compare examples like he is angry , he is angry with her , he believes her , where we move from emotions to emotional attitudes to epistemic attitudes. 1.1.4 Types of reception As explained above, feedback behavior is a more or less aware and controlled expression of reactions and responses based on appraisal and evaluation of information contributed by another communicator. We think of these reactions and responses as produced in two main stages: First, an unconscious appraisal is tied to the occurrence of perception (attention), emotions and other primary bodily reactions. If perception and emotion is connected to further processing involving meaningful connections to memory, then understanding, empathy and other further emotions and attitudes might occur. Secondly, this stage can lead to more conscious appraisal (i.e. evaluation) concerning the evocative functions (C, P, U) of the preceding contribution and especially its main evocative function (MEF), which can trigger attitudinal and emotional reactions, like belief, disbelief, surprise, skepti-cism, hope or joy and be accepted, rejected or met with some form of intermediary reaction, (often expressed by modal words like perhaps , maybe etc). We distinguish between these two types of reception and use the term  X  X  X eactive X  X  when the behavior is more automatic and linked to earlier stages in receptive processing, and the term  X  X  X esponse X  X  when the behavior is more aware and linked to later stages. For example, vocal feedback words like yes , no and m as well as head gestures are typically responses associated with evaluation, while posture adjustment and facial gestures are more reactive and linked more directly to appraisal and perception. 1.1.5 Types of appraisal and evaluation Responses and reactions with a certain feedback function occur as a result of continuous appraisal and evaluation on the part of the communicators. We suggest that the notion of  X  X  X ppraisal X  X  be used for processes that are connected to low levels of awareness and control, while  X  X  X valuation X  X  is used when higher levels are involved. The functions C, P, U all pose requirements that can be appraised or evaluated as to whether they are met or not (positive or negative). Positive feedback in this sense can be explicitly given by the words yes and m or head nod (or implicitly by making a next contribution), and negatively by words like no or headshakes. The attitudinal and emotional function (E) of feedback is more complex and rests upon both appraisal, i.e. processes with a lower degree of awareness and control, as well as evaluation processes. What dimensions are relevant here is not clear. One possibility is the dimensions suggested by Scherer ( 1999 ), where it is suggested that the appraisal dimensions most relevant are (i) novelty (news value of stimulus), (ii) coping (ability to cope with a stimulus), (iii) power (how powerful does the recipient feel in relation to the stimulus), (iv) normative system (how much does the stimulus comply with norms the recipient conforms to), (v) value (to what extent does the stimulus conform to values of the recipient). The effect of appraisal that runs sequentially along these dimensions is a set of emotional reactions, which may include certain prosody or other behavioral reactions, but primarily is expressed through prosody and facial display. Additionally, there will be a cognitive evaluation of whether or not the recipient is able and/or willing to comply with the main evocative function of the preceding contribution (A), i.e. can the statements made be believed, the questions answered or the requests complied with. 1.1.6 Types of communicative intentionality Like any other information communicated by verbal or bodily means, feedback information concerning the basic functions (C, P, U, A, E) can be given on many levels of awareness and intentionality. Although such levels almost certainly are a matter of degree, we, in order to simplify matters somewhat, here distinguish three levels from the point of view of the sender (cf. Allwood 1976 ): (i)  X  X  X ndicated information X  X  is information that the sender is not aware of, or intending to convey. This information is mostly communicated by virtue of the recipient X  X  seeing it as an indexical (i.e., causal) sign. (ii)  X  X  X isplayed information X  X  is intended by the sender to be  X  X  X howed X  X  to the recipient. The recipient does not, however, have to recognize this intention. (iii)  X  X  X ignaled information X  X  is intended by the sender to  X  X  X how X  X  the recipient that he is displaying and, thus, intends the recipient to recognize it as displayed. Display and signaling of information can be achieved through any of the three main semiotic types of signs (indices, icons and symbols, cf. Peirce 1955/ 1931 ). In particular, we will regard ordinary linguistic expressions (verbal symbols) as being  X  X  X ignals X  X  by convention. Thus, a linguistic expression like It X  X  raining , when used conventionally, is intended to evoke the receiver X  X  recognition not merely of the fact that  X  X  X t X  X  raining X  X  but also of the fact that he/she is  X  X  X eing shown that it X  X  raining X  X . 1.1.7 Type of semiotic information carrying relation Following Peirce X  X  semiotic taxonomy, where indices are based on contiguity, icons on similarity and symbols on conventional, arbitrary relations between the sign and the signified, we can find different types of semiotic information expressed by feedback, i.e. there is indexical feedback (e.g. many body movements), iconic feedback (e.g. repetition or behavioral echo (see below)) and symbolic feedback (e.g. feedback words). 1.2 Falsification and empirical content A relevant question to ask in relation to all theories is the question of how the theory could be falsified. Since the aspect of the theory that has been presented in this paper mainly consists of a taxonomy of the theoretical dimensions of the theory, falsification in this case would consist in showing that the taxonomy is ill-founded, i.e. that it is not homogeneous, that the categories are not mutually exclusive, not perspicuous, not economical or not fruitful. Since the question of whether the above criteria are met or not can be meaningfully asked, we conclude that the theory has empirical content, i.e. can be falsified. For more details about the connection between falsifiability and empirical content, see Popper ( 1959 ). 2 Methods In order to investigate the theory we have studied feedback in naturally occurring interactions with an analysis framework adjusted to the nature of feedback. To explore the empirical basis for some parts of our theoretical framework and to study its adequacy and usability in analyzing multimodal corpora, we have started to gather and analyze data on 30 video-recorded dyadic interactions with two subjects in standing position. The dyads were systematically varied with respect to sex. The subjects were university students and their task was to find out as much as possible about each other within 3 min. We hoped this task would elicit a lot of feedback expressions. For the multimodal corpora 30 (10 male X  X ale, 10 male X  X emale, 10 female X  X emale) dyads of strangers (mean age 22.4) were filmed with a video camera for 3 min. Subjects were told that they should try to find out as much as possible about the other person, as the purpose of the experiment was to find out how well communication works. Participation was voluntary and subjects did not receive compensation.

Extractions of one minute from the video-recordings were transcribed and coded, according to an abbreviated version of the MUMIN coding scheme for feedback (Allwood et al. 2005 ) and the coding program Anvil. The coding schema identifies two types of expression and modality used in feedback (either vocal verbal or visible body movement), which are coded for function type (giving, eliciting) and attitudes (continued contact, perception, understanding; acceptance of main evocative function; emotional attitudes). It further captures the following visible body movements: posture shifts, facial expressions, gaze, and head movements. As a special case of feedback giving, we have studied  X  X  X ehavioral echo X  X , i.e. showing the same behavior as the interlocutor just has. An adjustment of the MUMIN coding schema was done after a first inspection of the corpus, covering behavior like posture, arm movements and non-verbal sounds, which were not in the MUMIN coding schema, in order to get a more complete picture of the behavior shown. Figure 1 shows a snapshot of the annotation board during a data coding session.
Finally, subjects were asked to fill in a questionnaire about their socio-cognitive perception of the other (e.g. rapport) covering the following topics. This was done in order to get an independent variable of situation perception and to explore the effects of feedback on situation perception.  X  social success : an assessment of the likelihood of the interaction partner  X  pleasure : if the subject found the interaction pleasant  X  compliance : if the subject him-/herself would give his/her telephone number to  X  mutual agreement : if the subject found that they both agreed on the discussed  X  dominance : if the subject believed that he or she dominated the interaction  X  target desirability : if the subject found the other subject attractive or desirable as All questionnaire items were rated on 1 X 7 point Likert scales.

Only the second minute of the interaction was analyzed with the help of Anvil. In an ad lib observation a behavior repertoire of 43 feedback related behavior categories was established, including categories, sounds, facial expression, gaze, head movements, postures and arms (gestures). After transcribing the verbaliza-tions, the start and end points of the behaviors were coded. Percentage agreement of reliability was 78%. In addition we calculated Cohen X  X  kappa (0.72), which seems to be sufficient given a coding scheme with 44 items.

Statistical analysis was carried out in SPSS and lag sequential analysis was done with GSEQ (Bakeman and Quera 1995 ). 3 Results 3.1 Evaluation of the situation In order to find out how the subjects evaluated the situation we correlated the items from the questionnaire. The results (Fig. 2 ) show that the evaluation of mutual agreement is in the center of the situation perception (n for all correlations is 60, Spearman X  X  rho).

When we calculate the correlations between the subjects, we find that they share the perception of dominance ( n = 30 rho =-.39, p = 0.04), mutual agreement ( n = 30, rho = 0.38, p = 0.05), pleasure ( n = 30, rho = 0.39, p = 0.04) and compliance ( n = 30, rho = 0.43, p = 0.03). A comparison of the correlations suggests that mutual agreement is central for the interactions X  X nd that most of the evaluations are shared between subjects. 3.2 Vocal verbal feedback During one minute of interaction subjects produced on average 12.5 utterances ( SD = 3.7) and talked for 27.3 seconds ( SD = 9.8) using 91.7 words ( SD = 30.92). Vocal verbal feedback occurred on average 4.3 times ( SD = 2.8).

We observed N = 258 one word and two word utterances, among which  X  X  X a X  X  (17.4%),  X  X  X hm X  X  (15.9%),  X  X  X o X  X  (4.3%),  X  X  X ihi X  X  (4.3%) were most frequent, but these four amount to only 41% of all feedback utterances, indicating the great variety of utterances that can be used.

The only relation between the evaluation of the situation and the verbal utterances that could be found was for the variable give/elicit feedback with mutual agreement ( n = 60, rho = .297, p = 0.02). Thus verbal feedback demonstrates mutual agreement, but only partially, as we would expect from the different functions of feedback. Feedback was related only to mutual agreement among the socio-cognitions X  X his could indicate that this is its main function.
 3.3 Behavior Feedback behavior exhibits both intrapersonal and interpersonal patterns and dependencies. Since these patterns are complex and depend on many factors, we are only able to report on a few of them at the present time (cf. also Grammer et al. 1999 ). 3.3.1 Behavioral echo For the analysis of behavioral echo (an iconic feedback expression, probably associated with low degree of intentionality and awareness) we first applied a more or less crude approximation. We calculated the time lag between the beginning of behaviors and then identified how often two similar behaviors followed each other. This does not exclude that two behaviors might overlap. We chose this method since it prevents an inflation of the data that is associated with calculating the number or duration of overlaps. This means if a smile follows exactly after a smile this would be one instance of a behavioral echo (Grammer et al. 2000 ).

Behavioral echo occurs at a mean rate of 1.25 ( SD = 1.17). As compared to an average of 20.51 ( SD = 6.98), for change of main contributor (speaker change) in the dyads, echo is generally rare, occurring only in 6.1% of all speaker changes. In addition, we find no correlations between the situation evaluation and simple echo. The same result was found by Grammer et al. ( 2000 ). Thus simple echoing seems to be peripheral for the implementation as a feedback device X  X nd feedback itself seems to be more complicated. We thus tried to analyze the rhythmical structure of utterance, behavior and verbal feedback as proposed by Grammer et al (2007). 3.3.2 Time patterns In order to find out whether rhythmical patterns occur in the sequences, the behavior events were further processed by the use of Theme (Magnusson 1996 , 2000 ), which is a software specifically designed for the detection and analysis of repeated non-random behavioral patterns hidden within complex real-time behavior records. Each time-pattern is essentially a repeated chain of a particular set of behavioral event-types (A B C D ... ) characterized by fixed event order (and/or co-occurrence), and time distances ( C 0) between the consecutive parts of the chain that are significantly similar in all occurrences of the chain (Magnusson 1996 , 2000 ). In this context, an important aspect of this pattern type is that its definition does not rely on cyclical organization, i.e. the full pattern and/or its components may or may not occur in a cyclical fashion. In order to perform Theme-analyses on the behavior performed by each individual, the number of interactants was two in this study. A minimum of two repeated pattern occurrences throughout the one-minute sampling period and a 0.05 significance level were specified.

We looked for one pattern type: Patterns were both interactants contributed something (interactive patterns) and verbal feedback was part of the pattern.
The organization of the detected patterns can be described by pattern frequency, the number of behavior codes (pattern length) and their complexity (hierarchical organization). The number of patterns and their organization thus will give us an estimate of the amount of general rhythmic coupling (a repeated pattern of interactive behavior) in the dyad and rhythmic coupling generated by feedback itself.
 The following figure (Fig. 3 ) gives an example for a complex feedback pattern. Note that in this approach both beginnings and ends of behaviors are the events used by Theme .

In (a) the hierarchical organization of the pattern is shown, which consists of 14 member events in time. Y and X denote the interactants, b and e the end of a behavior. The pattern starts with Y starting (y,b,aut) and ending automanipulation (y,e,aut), followed by the same person ending a second automanipulative behavior (y,e,aut). This is followed by a brow raise (y,b,bra; y,e,bra) and the end of a first utterance (y,e,utt). X responds with a repeated head nod (x,b,rno), one word verbal feedback (x,e,giv) and Y (y,b,utt) and later X start producing an utterance (x,b,utt). X during his utterance starts looking at Y (x,b,ilo), automanipulates (x,b,aut) and ends the utterance (x,e,utt). Finally Y starts looks away from X (y,e,ilo). This complex pattern is created twice (c) in the same time configuration (b). Theme thus can reveal hidden rhythmic structures in interactions.

On average the subjects produced 2.26 ( SD = 0.26) utterance X  X erbal feedback patterns per one-minute interactions X  X his means that there are at least 4 rhythmical patterns per interaction which are interactive and where verbal feedback is involved. We can compare this to the average of verbal feedback of 8.0 ( SD = 3.9) per interaction. This means that every third instance of verbal feedback enters rhythmical patterns. Thus feedback seems to be a part of a rhythmical time structure in interactions.

The average length of the patterns was 5.1 items ( SD = 1.7) and the average level of nodes reached was 2.9 ( SD = 0.76). As reported previously by Grammer et al. ( 2000 ) only the composite score of perceived pleasure correlates positively with pattern length (rho = 0.35, p = 0.05) but negatively with the average number of patterns (rho =-0.45, p = 0.01). This suggests that a few long patterns contribute to the perception of the interaction as pleasant. It further means that rhythmic patterning without regard of the content of the behaviors contributes to the perception as pleasant in contrast to simple behavior echo. For the rest of the socio-cognitions no relation to patterns and pattern structure was found.

In order to determine the structure of the patterns we analyzed which other behaviors form the patterns with vocal verbal feedback. Patterns are based mainly on the following behaviors:  X  X  X rms Cross X  X  (0.19),  X  X  X ead Down X  X  (0.85),  X  X  X ook At X  X  (0.41),  X  X  X ead Jerk (0.35),  X  X  X ove Forward (0.18),  X  X  X ead Right X  X  (0.17),  X  X  X ead Tilt X  X  (0.41),  X  X  X mile X  X  (0.40) and  X  X  X ead Up X  X  (0.20). The numbers in brackets tell how often a behavior formed a pattern with vocal verbal feedback relative to its frequency of occurrence.

The results indicate that rhythmic structuring in feedback X  X oth vocal verbal and other feedback behavior X  X lays a major role for rapport and pleasantness. Thus as a last step we tried to find out the transition probabilities between these behaviors and their distribution in time relative to verbal feedback. 3.3.3 Sequential organization As a last analysis we tried to figure out the time relations between other feedback behavior and vocal verbal feedback. Here, we treat any behavior that is no vocalization of a word as other behavior, i.e. face, head and body movements. We have also included non-verbal sounds in this category.

We proceeded the following way. At first we determined what the speaker was doing before vocal verbal feedback was given by the listener. Figure 4 shows the results. Time zero in the figures is the start of vocal verbal feedback. The behaviors are represented as a range: The start is the average start and the end is average start plus average duration. The figure indicates that vocal verbal feedback occurs on average very early in utterances. This suggests that simulation systems, which produce feedback at the end of utterances, are not very natural. Generally before feedback occurs, the speaker orients his body towards the listener and looks at him/ her. Figure 5 gives the results of listener behaviors that start immediately before vocal verbal feedback. Again you can see that orientation is toward the speaker X  but the feedback giver might also turn away during feedback. In Fig. 6 we show listener behaviors that start immediately with or after giving vocal verbal feedback X  X he results indicates that verbal feedback might be accompanied by many small behaviors.

How do these behaviors relate to vocal verbal feedback and how is vocal verbal feedback embedded in other behavior? To answer this question we calculated the transition probabilities for feedback and utterances, which will answer the question what actually leads to verbal feedback and follows it and what follows an utterance or precedes it. This was done in GSEQ (Bakeman and Quera 1995 ) calculating conditional transition probability at lag one. Note that this analysis differs from the THEME analysis considerably. The lag analysis describes what immediately follows or precedes a behavior as a state X  X HEME in contrast reveals hidden rhythmic patterns without a direct relation in time space between two behaviors, like A follows B. In THEME any behavior can occur in between pattern members.

The following table shows the conditional probabilities of verbal feedback following after a behavior and of a certain behavior following feedback. Again like in the THEME analysis it becomes clear that verbal feedback is embedded in a sequence of behaviors and is not only related to longer utterances. (Table 2 )
The combination of the results from the sequential analysis together with the transition probabilities will then allow us to model verbal feedback in simulations. 4 Conclusions These results suggest that a combination of feedback analysis with situation perception can provide new insights regarding the general function and structure of vocal verbal feedback. Rhythmic patterning in vocal verbal feedback and other behavior seems to promote mutual agreement and intrinsic pleasantness of an interaction.

Analyzing the patterns and structure of vocal verbal feedback is only the very start X  X his only gives information about when and how feedback is given. The next question, which we are currently evaluating on a new data set, is how the different functions of feedback affect the specific rhythmic patterning and structure of feedback by relating behavior observations to linguistic analysis. This will help us to determine the exact nature of events of feedback.

While in this article we concentrated on vocal verbal feedback, in the future, we will also investigate the differences between vocal verbal and other feedback behavior, i.e. any behavior other than articulated words.

Our first analysis also shows that in order to answer these questions more reliably it seems necessary to extend the multimodal corpus X  X urrently we are sampling more interactions in order to get more data for analysis.

One of the most interesting results of this analysis is the fact that vocal verbal feedback can occur in highly rhythmically structured patterns, which are idiosyn-cratic to each dyad. This phenomenon will be the basis for simulation of feedback using embodied agents, which can be tested in interaction with a user. If the implementation is correct, then rhythmic temporal structures like in natural interactions should emerge.

Our analysis also shows that simple implementations of feedback, which just start at the end of an utterance, are not the solution for simulation X  X ocal verbal feedback is usually initial in utterances and combined with many small behaviors.
We have presented a theory for communicative feedback, describing the different dimensions involved. This theory provides the basis of a framework for analyzing embodied feedback behavior in natural interactions. We have started to design a coding scheme and a data analysis method suited to capture some of the features that are decisive in this account (such as type of expression, relevant function, or time scale). Currently, we are investigating how the resultant multimodal corpus can be analyzed for patterns and rules as required for a predictive model of embodied feedback. We also want this model to support simulation in a state-of-the-art embodied conversational character.

The results from our empirical study suggest that feedback is a multimodal, complex, and highly dynamic process X  X upporting the differentiating assumptions we made in our theoretical account.

In ongoing work, we are building a computational model of feedback behavior that is informed by our theoretical and empirical work, and that can be simulated and tested in the embodied agent  X  X  X ax X  X . Max is a virtual human under development at the A.I. Group at Bielefeld University. The system used here (see Kopp et al. 2005 for a detailed description) is applied as a conversational information kiosk in a public computer museum (Heinz-Nixdorf-Museums Forum) where Max engages visitors in face-to-face small-talk conversations and provides them with information about the museum, the exhibition, and other topics. Users can enter natural language input to the system using a keyboard, whereas Max responds with synthetic German speech accompanied by nonverbal behaviors like manual gestures, facial expressions, gaze, or locomotion.

In extending this interactive setting to more natural feedback behavior by Max, we explore two major lines. First, we are implementing a  X  X  X hallow X  X  feedback model using a Bayesian network whose local conditional probabilities are directly derived form the probabilities found for sequential organizations in the data. This is akin to previous technical approaches, which tried to identify regularities at a behavioral level and cast them into rules to predict when a feedback behavior would seem appropriate. This technique proved viable for very specific feedback mechanisms, like nodding after a pause of certain duration or specific prosodic cues (e.g., Ward and Tsukahara 2000 ). Our empirical analysis, however, showed that none of the various behaviors we have looked at does reliably trigger feedback (irrespective of which kind of feedback). This suggests that the richness of human multimodal feedback cannot be accounted for solely in terms of formulating probabilities over sequential pairs of behavior from different speakers, neither theoretically nor technically for mere simulation purposes. We are thus taking a broader approach and explore in how far our theoretical model can inform a  X  X  X eeper X  X  simulation model comprising incremental processes of appraisal and evaluation of information (Kopp et al. 2008 ). These processes give rise to the different responsive functions differentiated in our theoretical model, which can then be mapped onto different types of feedback expressions that realize these functions, where a further analysis of our multimodal corpora remains a prerequisite for simulation in an embodied agent.
 References
