 Panos Toulis ptoulis@fas.harvard.edu Edward Kao edwardkao@fas.harvard.edu In causal inference, there is interference among units of analysis when a treatment or intervention on a unit has an effect on the response of another. These effects are known as spillover effects in economic theory, but when the units are humans and the effects originate from a unit X  X  peers, e.g., friends or classmates, they are known as peer influence effects . The recent rise in adoption of social media has focused attention on how to quantify peer influence, and thereby raised techni-cal challenges for causal inference when interference is present.
 Recent works in statistics, for instance, account for peer influence (i.e., interference) as nuisance when esti-mating classical average treatment effects. In contrast, our work focuses on estimating the peer influence effect itself. Rosenbaum (Rosenbaum, 2007) takes a non-parametric approach, assuming only the existence of a baseline uniformity trial in which there may be interac-tions but there is no real treatment (placebo). To un-cover the treatment effects under the  X  X uisance X  of in-terference, one can compare the relative responses be-tween treated and control units across groups or clus-ters of units. In (Hudgens &amp; Halloran, 2008), Hudgens and Halloran consider the problem of estimating causal effects from vaccination under interference and identify these effects by comparing two reference groups: one group with low vaccination percentage and one group with a high percentage, under the key assumption of no interference among groups. A survey of the relatively thin literature on causal inference under interference is given by Tchetgen &amp; VanderWeele (2012). A related line of research in the social sciences aims at estimating peer influence effects in the absence of a true causal framework. Here, identifying whether a unit X  X  outcome is a result of the social ties to peers (social contagion) or a result of similarity (homophily) to peers remains challenging (Manski, 1993). Applica-tions of peer effects research have spanned many ar-eas such as behavioral science/public health (Mednick et al., 2010), advertisement (Parker, 2011), network security (Shah &amp; Zaman, 2011), and economics (Ace-moglu et al., 2010). The effect of interference in these works is captured by a parameter in the model (e.g. in structural equation models), which nearly always lacks well-defined causal interpretation.
 Applications for this problem abound. In (Bakshy et al., 2012), Facebook users were shown ads with and without their friends X  product affiliation. The goal was to understand peer influence and, specifically, estimate the probability of sharing an  X  X ndorsement X  condition-ing on the strength of the friend ties. In (Bond et al., 2012) a massive randomized experiment on Facebook investigated peer influence effects on voting turnout. In a different setting, where peer effects can be  X  X rans-mitted X  through an integrated market, (Ostrovsky &amp; Schwarz, 2010) perform a large on-line randomized ex-periment to assess the impact of reserve prices in to-tal revenue of Yahoo! ad auctions. Lacking a gen-eral methodological framework, most studies including the aforementioned ones, assume away interference for the sake of simplicity. The risk of this assumption is demonstrated in (Sobel, 2006). Examining hous-ing mobility studies in which households in poor ar-eas are financed to relocate to better neighborhoods, Sobel shows that ignoring interference can lead to en-tirely wrong conclusions about the effectiveness of the program.
 Recently, the potential outcome framework is gain-ing traction in this problem space. Unpublished work by Ugander et al. (2012), for example, targets esti-mands related to ours with a different estimation pro-cedure. Aronow &amp; Samii (2013) perform inference us-ing the Horwitz-Thompson estimator, assuming a net-work sampling design is in place and that the sampling inclusion probabilities can be computed. Our work dif-fers in that (i) we propose a causal estimand that is well-defined and tightly-connected to the underlying network, (ii) we insist on sequential randomization de-signs which we believe are more appropriate for this problem and (iii) we consider a linear Bayesian model that can accommodate network uncertainty and in-crease precision under suitable conditions. 1.1. Causal frameworks &amp; potential outcomes The Rubin causal model (Rubin, 1974; 1990), based on potential outcomes, is the most widely-used causal framework in statistics and the social sciences. This approach is rooted in a fundamental question: How would we define a causal effect if we had all the data? For the simplest scenario, assume two units, indexed by i , who are about to receive a treatment, say, an aspirin. Denote with Z i  X  { 0 , 1 } whether unit i re-ceived the treatment ( Z i = 1) or not ( Z i = 0) and Z = ( Z 1 ,Z 2 ) the entire assignment vector. Also de-note the response to the treatment, say, severity of headache, with Y i ( Z i ) (see Table 1). The fundamental assumption that enables us to write Y i ( Z i ) is that of no interference , also known as SUTVA (Stable Unit Treatment Value Assumption); that is, the outcome of individual i is only a function of its treatment Z i . In an  X  X deal X  world, we would observe all the possible outcomes (left part of table). In this ideal scenario, we define the causal estimand by pretending that we have access to outcomes for all possible treatment assign-ments. For example, a natural definition of the causal effect of taking aspirin would be: In the real world, however, only one outcome can be observed for each unit, because one cannot both take and not-take the aspirin, whereas the other will be missing (denoted with  X ? X  in the table). A de-sirable feature of the potential outcomes framework is the ability to define causal estimands in terms of individual-level potential outcomes X  X ven though only typical (e.g. average) causal estimands are estimable in practice.
 Estimation proceeds in two ways. In randomization-based inference, treatment is randomized and esti-mates are obtained as functions of the observed out-comes. Here, if aspirin assignment was randomized, and unit 2 received aspirin, then a natural estimate would be Y 2 (1)  X  Y 1 (0), and such an estimate would be unbiased 1 . In a model-based approach, the outcomes can be modeled conditioned on the assignment and the observed values e.g., assume Y i ( Z i ) is normal with mean  X  +  X Z i . An alternative causal framework is that of causal graphical models (Pearl, 2000; Spirtes et al., 2001), which uses directed acyclic graphs (DAGs) to represent causal dependencies. This framework is pop-ular in computer science, however, it is not well suited to our problem since we do not aim at estimating a causal structure but rather the  X  X arginal X  peer influ-ence causal effects through a randomized experiment. Interestingly, identifiability of causal effects from ob-servational data (even under fixed causal graphs) has recently been challenged (Shalizi &amp; Thomas, 2011). 1.2. Contributions This paper introduces a new and well-defined causal estimand for peer influence effects in Section 2.1, by extending potential outcomes to allow for interference in a social network. We then develop two ways to estimate this causal estimand, first through sequen-tial randomization and second via a model-based ap-proach, and then demonstrate their trade-offs. Section 2.2 describes the randomization approach and charac-terizes the subtlety of this problem by introducing the idea of manipulability of a network. Sections 3.1 and 4.1 characterize the trade-off between manipulability and possible bias of a randomized design. Theorem 1 shows that this bias is intertwined with network-specific properties (e.g. the sharing index ). Section 2.3 describes the model-based approach under a spe-cific additivity assumption. Section 3.2 shows how to optimize asymptotic expected performance through assigning the treatment vector to maximize Fisher in-formation, thus providing insights for experimental de-sign. We denote a network as G = ( V,E ), where V is the vertex set, | V | = N , and E is the edge set. For a node i  X  V , we define as N i to be its neighborhood, excluding i . Node i has n i = |N i | neighboring nodes. The N  X  1 treatment assignment vector is denoted by Z , where Z i = 0 or 1 if node i is assigned to control or treatment, and for a subset S  X  V , let Z S be the assignment vector for the nodes in S . Thus, Z N i is the assignment vector of the neighbors of i . Also, let V k be the set of nodes that have at least k neighbors and M ik be the set of neighbors of node i  X  V k who are also neighbors to at least one other node in V k . Define M k = S i M ik as the set of shared neighbors . Denote also m ik = |M ik | i.e., the # of neighbors of i who are shared with other nodes in V k as well.
 We say that a node, or equivalently an experimental unit i is treated if Z i = 1 and it is in control if Z i = 0. When Z i = 1, unit i is said to have primary effects . Furthermore, we say that a unit i is exposed to peer influence effects if at least one neighbor is treated. A unit i  X  V k is k -exposed if exactly k neighbors are being treated and the corresponding treatment assignment is called a k -level assignment . We say that a unit is non-exposed when Z i = 0 and Z N i = 0 i.e., the unit i and all its neighbors are in control. Also, denote with D i the set of all assignments Z N i that make node i to be k -exposed.
 The response of unit i (potential outcome) under treat-ment Z is denoted by Y i ( Z )  X  Y i ( Z i , Z  X  i ), where Z is the vector of assignment Z excluding i  X  X  assignment. Define Z ( N i ; k ) to be the set of all assignments on N in which exactly k neighbors of i get treated (total k such assignments). Define Z 1 ( N i ; k ) as the set of all assignments in Z ( N i ; k ) for which  X  j,Z j = 1 and j  X  M ik , i.e., at least one of the shared neighbors exposed and all shared neighbors are put in control. Notice that it holds, Z 0 ( N i ; k ) S Z 1 ( N i ; k ) = Z ( N disjoint and form collectively the entire set of k -level assignments.
  X  ity of one random k -level assignment for unit i and  X  0 ,i is the probability of a random assignment given that i  X  X  shared neighbors are put in control. Note that | Z 0 ( N i ; k ) | = 1 / X  0 ,i and | Z 1 ( N i ; k ) | = 1 / X  2.1. Causal estimands for treatment effects In the classical potential outcomes framework, SUTVA is assumed: Y i ( Z ) = Y i ( Z i ), meaning that the out-come of unit i depends only on the treatment it re-ceives and not on the treatment other units receive. This is clearly violated in the presence of interference. We replace SUTVA with the following, more relaxed, assumption: Assumption 1. We assume  X  i , Y i ( Z ) = Y i ( Z i , Z N i.e., a unit X  X  response can be affected by the treatment it receives and by the treatments received by its neigh-bors.
 Formally, the response function of a node i can be de-noted by Y ( Z i , Z N i ) and is a map { 0 , 1 } X { 0 , 1 } D y , where D y is the domain of potential outcomes. For brevity, we denote the response Y i (0 , Z N i = 0 ) by Y ( 0 ).
 Definition 1. [Estimand for primary effects] Define as  X  the causal estimand of primary effects as follows. Definition 2. [Main estimand for peer influence ef-fects] Define as  X  k the causal estimand of k -level effects as follows:  X  Definition 3. [Additional peer influence effects esti-mands] In the following sections, we describe methods to esti-mate our causal estimands. One key concept is that of the valid causal estimate, which is a measure of treat-ment balance : Definition 4. [Valid causal estimates] A causal es-timate from a randomization is valid if at least one node was assigned to the prescribed treatment and at least one node was assigned to control. Otherwise, the estimate is not valid.
 Estimation of  X  is straightforward through a typical randomized experiment. However, estimation of  X  k is more involved 2 because of interference. In the follow-ing sections, we will focus on estimation of  X  k . Note that, by the definition of  X  k , any randomization needs to set Z i = 0 for nodes i  X  V k and randomize treat-ment only within their neighborhoods. 2.2. Causal inference through randomization We start with a simple sequential design: 3 Algorithm 1 Estimation of  X  k : Simple Sequential Randomization SSR ( G, Z ) Input : G network, Z current treatment vector Output : Z treatment vector (in-place) 1: while i  X  sample { i : i  X  V k &amp; s ( Z N i )  X  k } do 2: T i = { j  X  X  i : Z j 6 = NA } 3: W  X  sample { W : W  X  X  i &amp; W T i = Z T i } 4: Z N i  X  sample { W , 0 } 5: Z i  X  0 6: V k  X  V k \{ i } 7: end while The SSR algorithm assigns nodes in V k to a non-exposure or k -level exposure status. Specifically, in Line 3, a k -level assignment is sampled among those that maintain the treatment status of units who have already been assigned treatment. In Line 4, either a k -level assignment or non-exposure is finally chosen at random. Intuitively, SSR extends sequential random-ization by taking into account the constraints of  X  However, the algorithm may come up with estimates that are not valid (see Definition 4). To illustrate, we refer to the  X  X andy X  network in Figure 1 (right). There are two nodes in V k (orange nodes). Clearly, we can only get causal estimates when one node is k -exposed, the other is non-exposed, and we compare between the two observed outcomes. However, this can only hap-pen when all middle nodes (shared neighbors) are put in control. The probability of this happening through SSR is very small 4 .
 A simple design that can alleviate this problem is pre-sented in Algorithm 2. The randomization is essen-tially the same as SSR, but as a first step it puts x % of shared neighbors into control: Algorithm 2 Estimation of  X  k : Insulated Neighbors Randomization INR x ( G ) Input : G network Output : Z treatment vector 1: Z i  X  NA,  X  i 2: S  X  sample { n= x  X |M k | , M k } 3: Z S  X  0 4: SSR(G, Z ) The idea behind INR is to increase the  X  X ausal infor-mation X  acquired by a randomization at the expense of increased bias. We believe that this trade-off is key to estimating peer effects and we discuss more in Sections 3 and 4.
 2.3. Causal inference through linear model The randomization based procedure above has the ad-vantage of making no assumption about the node re-sponse functions Y i ( . ). However, it assumes complete knowledge of the network. Furthermore, depending on the network topology, it may have trouble find-ing enough valid causal estimates. Moreover, treat-ment assignments may be difficult to administer in real world scenarios.
 The complementary model-based procedure addresses these issues by adopting a linear network treatment model that assumes additivity of the primary effects and peer influence effects in their contribution to the treatment response mean. The additivity assump-tion of various effects is also made by previous works, such as Manski X  X   X  X inear in means X  model (Manski, 1993). Our model is inspired by and similar to Parker X  X  (Parker, 2011). As edges in real world networks of-ten represent an uncertain quantity of interactions be-tween two individuals, we extend it by considering weighted random networks.
 The linear model assumes, in general, a weighted, undirected network G among units, with adjacency matrix A . We model the individual potential outcomes as: in which a i is the i -th column vector of the adjacency matrix A (in-links to unit i ). This can be written in compact form as: where y = ( Y i ), the N  X  1 vector of responses, X is the N  X  3 design matrix such that X = [ Z ,A 0 Z , 1 ],  X  = (  X , X , X  ) 0 is the 3  X  1 parameter vector and the N  X  1 vector  X   X  X  ( 0 , X  2 I ) is iid noise. Note that the network affects the likelihood only through the quan-tity A 0 Z i.e., the quantity S = A 0 Z is the network sufficient statistic with respect to  X  . Thus, S repre-sents the amount of exposure to peer influence for each node. 2.3.1. Causal estimands under linear model Under the linear model, the causal estimands are sim-plified and this helps bridge our two estimation proce-dures: The k -level peer influence effects estimand  X  k reduces to a scaled  X  : where W i is the average weight on the incoming edges to unit i . Thus, estimating the causal estimands under the linear model amounts to inferring  X  and  X  . 2.3.2. Modeling network uncertainty Real world networks are often uncertain, as true inter-actions between individuals may be either unobserv-able, or measured and estimated with error (Butts, 2003). Inspired by Perry X  X  model for interaction net-works (Perry &amp; Wolfe, 2010), we model each edge weight ( i,j ) as a Poisson distributed random variable with rate  X  ij 5 .
 A key idea here is that, while the network G is random, we need to impute only its sufficient statistic S , and thus inference can be efficient. In particular, we model S as follows: where  X  =  X Z , and  X  is the N  X  N  X  X nteraction rate X  matrix. Assuming we know the treatment assignment, the interaction rates and the unit responses, we arrive at the Bayesian model depicted in Figure 2.
 Naturally we propose a joint inference procedure by treating the sufficient statistic S as the  X  X issing data X , and performing inference iteratively through MCMC with Gibbs sampling as shown in Figure 3. More de-tails on this inferrential step are available in the sup-plementary material. 3.1. Randomization performance analysis It was argued in Section 2.2 that the network topology is important in getting causal estimates for  X  k . As an-other extreme example, consider the case of a complete graph (all units connected). Clearly, no causal esti-mate can be drawn from such a graph since as soon as a unit gets k -exposed no other unit can be non-exposed. Equivalently, for networks with isolated nodes, it is always possible to draw causal estimates through a completely randomized experiment. In other words, we can think of networks as having varying degrees of manipulability . We formalize this notion by the fol-lowing definition: Definition 5. [Manipulability] The manipulability of a network G under randomization R is the average proportion % of valid causal estimates that R will get when ran on G .
 Referring back to the previous examples, the complete graph has 0% manipulability and the isolated graph has 100% manipulability. Note that under our As-sumption 1, interference happens through the shared neighborhood M k . Intuitively, the bigger M k is with respect to the entire graph G the stronger the interfer-ence effects should be 6 . We formalize this notion by defining the sharing index of a network.
 Definition 6. [Sharing index] For a given network and given k , the sharing index  X   X  [0 , 1] is defined by: Intuitively, a high sharing index means that whenever a node is k -exposed or non-exposed, it will affect more of the remaining nodes, making the graph less manipu-lable 7 . Interestingly, the bias of the estimate provided by INR 1 . 0 is exactly proportional to the sharing index: Theorem 1. If  X  i, X  i =  X  and  X  0 ,i =  X  0 , such that  X / X  0 = 1  X   X   X  1, then it holds: The bias of INR 1 . 0 estimates come from two sources: The first is from the sharing index of the network. The second comes from the difference of the influence that nodes in M k (shared neighbors) exert compared with nodes in V \M k . If for some reason (e.g. because of their better positioning on the network) the shared neighbors are more (or less) influential, our estimates will become biased. The following corollary summa-rizes these observations: Corollary 1. For an ego-centric network with no commonly shared nodes (  X  = 0 ), the estimate from INR is unbiased. Furthermore, if peer influence ef-fects are invariant to permutations of node ids (and so  X  k, 0 =  X  k, 1 ) the estimate from INR is unbiased. 3.2. Linear model performance analysis Other than bias, the performance of the inference pro-cedure is typically characterized by the variance of the estimate. Here we show how the structure of the network and treatment assignment play a role in the variance through the Fisher information matrix and the Cram  X er-Rao bound. From our Bayesian regression model, the likelihood is:
L y (  X  , S , X  2 |  X  , Z ) = Y To ease our calculations, we approximate the Poisson through a normal i.e., Poisson(  X  i )  X  X  (  X  i , X  i ) and in-tegrating out the nuisance parameter S by the normal representation, we take the log likelihood and compute the Fisher information matrix:
I (  X  , X  2 ) =  X  E where  X  i =  X  2 +  X  2  X  i . The diagonal entries of the matrix reveal the information source for each param-eter. Being mostly interested in the causal estimands  X  and  X  , we focus on I(1,1) and I(2,2). Since the rate of peer influence exposures  X  are relatively large, the first term in I(2,2) dominates the second term. So we I(2,2). Not surprisingly, the information content for  X  comes from the treated nodes but is discounted by the rate of peer influence it receives. On the other hand, the information content for  X  comes from hav-ing large amount of peer influences. This presents a tug of war between minimizing the variance on  X   X  and  X   X  . Interestingly, trying to meet both objectives leads to a treatment assignment where the hubs are treated to maximize overall peer influence while controlling their neighbors to minimize the peer influence to the treated nodes. These  X  X solated X  treated hubs results in a treatment assignment strategy that is very similar to the INR randomization! While the Cram  X er-Rao bound ( I  X  1 ) is complicated and does not readily render intuition, one can com-pute it numerically and find the expected estimation variance. This can be used to numerically determine the minimal variance treatment assignment. Later we demonstrate empirically a reduction in estimation variance by using  X  X ptimal X  treatment assignments (LMO) instead of random assignments (LMR). 4.1. Manipulability The main idea behind INR is to increase manipulabil-ity of a network at the cost of introducing more bias. Consider, for example, the candy network on Figure 1. Under SSR, there is at most 2 / 2 k k  X  4  X  k probability of getting a valid causal estimate. In contrast, INR 1 . 0 will get causal estimates in 50% of the randomizations since all middle nodes (shared neighbors) will be put under control right away. As a further illustration, we test on Zachary X  X  karate club network (Zachary, 1977). The summaries of SSR and INR 1 . 0 (in 10,000 samples, k = 5 , X  k = 2 . 542) are shown below: Design Point Estimate Manipulability se SSR 2.516 66.5% 1.022 INR 1 . 0 2.495 71.5% 1.062 INR 1 . 0 , by fixing nodes under control, introduces more bias (first column) and more varied estimates. On the other hand, it obtains 5% more valid causal estimates on average than SSR thus increasing the manipulabil-ity of a rather dense social network. 4.2. Randomization vs model-based method To introduce variety, we tested with 8 100-node net-works, each with different type of topologies commonly seen in real-world networks. Two underlying response functions to the treatment are tested. The first one (Table 3) is based on the proposed linear response model Y i =  X  +  X Z i +  X S i +  X  i and the second one (Table 4) adds a quadratic term  X S 2 i to the response, signifying the phenomenon that somehow the peer in-fluences reinforce each other. We pick the level-4 peer influence effects causal estimand,  X  4 , as the objective. The true values for each response parameter were set to  X  = 10,  X  = 0 . 5,  X  = 3,  X  i  X  X  (0 , 1),  X  = 0 . 05. The results for two levels of INR 8 , the linear model with 15 random treatments (LMR) and 15 optimal treatments (LMO), are summarized in Tables 3 and 4.
 Table 3 shows that when the model assumption is correct, the model-based approach out-performs the randomization-based approach, both in estimate bias and variance. LMO consistently achieves smaller vari-ance than LMR, which is consistent with the theoret-ical result of Section 3.2. Table 4 shows that, when the model assumption is incorrect, the attempt to capture nonlinear effects in linear terms result in bi-ased estimates for the model-based approach. Here, the randomization-based approach is the better choice resulting in estimates much closer to the true value. Last, notice that INR 0 . 6 is more biased compared to SSR and in general is worse as a point estimator. How-4 SSR INR 0 . 6 LMR LMO 4 SSR INR 0 . 6 LMR LMO ever, it generally achieves higher manipulability (see Section 4.1). Adopting the potential outcomes framework for causal inference, we define a novel k -level estimand for peer influence effects and propose a randomization-based and a model-based approach to estimate it. Our ran-domization, namely INR, is a simple generalization of a sequential randomized design. INR aims to get more causal information (increase manipulability; see Table 2) at the expense of increased bias (see Tables 3,4), especially in dense networks.
 The model-based approach performs efficient causal estimation in the presence of network uncertainty, when the additivity assumption holds. Furthermore, the model informs optimal assignment through maxi-mizing Fisher information.
 This work is a preliminary version of our research in the causal estimation of network effects, and it focuses mainly on introducing the problem and highlighting its conceptual challenges. A more refined version is forth-coming (Airoldi et al., 2013). Our future extensions include a formal statistical analysis of estimators aris-ing from sequential randomizations (such as INR) and a more nuanced Bayesian analysis for optimal exper-imental design. Finally, we are actively applying our theory in two concrete problems that involve (i) peer influence in medical treatment compliance and (ii) in-teractions between modules in distributed computing systems.
 The authors wish to express gratitude to Edoardo M. Airoldi and Donald B. Rubin for extensive discussions and support. This work was also supported by the Google U.S./Canada Fellowship in Statistics (2012-2013) and the Department of Defense (DoD) via the National Defense Science &amp; Engineering Graduate Fel-lowship (NDSEG).
 Acemoglu, Daron, Ozdaglar, Asuman, and Parande-hGheibi, Ali. Spread of (mis)information in social networks. Games and Economic Behavior , 70(2): 194 X 227, 2010.
 Airoldi, Edo, Toulis, Panos, Kao, Edward, and Ru-bin, Donald B. Estimation of causal peer influence effects. Forthcoming , 2013.
 Aronow, P. M. and Samii, C. Estimating average causal effects under general interference. working paper , 2013.
 Bakshy, Eytan, Eckles, Dean, Yan, Rong, and Rosenn,
Itamar. Social influence in social advertising: Evi-dence from field experiments. CoRR , abs/1206.4327, 2012.
 Bond, Robert M, Fariss, Christopher J, Jones, Ja-son J, Kramer, Adam DI, Marlow, Cameron, Settle,
Jaime E, and Fowler, James H. A 61-million-person experiment in social influence and political mobi-lization. Nature , 489(7415):295 X 298, 2012.
 Butts, C.T. Inference, error, and informant (in)accuracy. Social Networks , 25:103 X 140, 2003. Hudgens, M.G. and Halloran, M.E. Toward causal inference with interference. Journal of the American Statistical Association , 103(482):832 X 842, 2008. Manski, C.F. Identification of endogenous social ef-fects: The reflection problem. The Review of Eco-nomic Studies , 60(3):531 X 542, 1993.
 Mednick, S.C., Christakis, N.A., and Fowler, J.H. The spread of sleep behavior influences drug use in ado-lescent social networks. PLoS One , 5(3):e9775, 2010. Ostrovsky, M. and Schwarz, M. Reserve prices in inter-net advertising auctions: A field experiment. Avail-able at SSRN 1573947 , (2054), 2010.
 Parker, B.M. Design of network experiments. available at http://www.newton.ac.uk/programmes/DAE/ seminars/090111301.pdf, 2011.
 Pearl, Judea. Causality: models, reasoning and infer-ence , volume 29. Cambridge Univ Press, 2000. Perry, P.O. and Wolfe, P.J. Point process modeling for directed interaction networks. In arXiv:1011.1703v1 [stat.ME] , 2010.
 Rosenbaum, P.R. Interference between units in ran-domized experiments. Journal of the American Sta-tistical Association , 102(477):191 X 200, 2007. Rubin, D.B. Estimating causal effects of treatments in randomized and nonrandomized studies. Journal of Educational Psychology; Journal of Educational Psychology , 66(5):688, 1974.
 Rubin, D.B. [on the application of probability theory to agricultural experiments. essay on principles. sec-tion 9.] comment: Neyman (1923) and causal infer-ence in experiments and observational studies. Sta-tistical Science , 5(4):472 X 480, 1990.
 Shah, Devavrat and Zaman, Tauhid. Rumors in a net-work: Who X  X  the culprit? IEEE Transaction on Information Theory , 57(8):5163 X 5181, 2011.
 Shalizi, C. and Thomas, A. Homophily and contagion are generically confounded in observational social network studies. Sociological Methods and Research , 40:211 X 239, 2011.
 Sobel, M.E. What do randomized studies of housing mobility demonstrate? Journal of the American Statistical Association , 101(476):1398 X 1407, 2006. Spirtes, Peter, Glymour, Clark, and Scheines, Richard.
Causation, prediction, and search , volume 81. MIT press, 2001.
 Tchetgen, E.J.T. and VanderWeele, T.J. On causal inference in the presence of interference. Statistical Methods in Medical Research , 21(1):55 X 75, 2012. Ugander, J., Karrer, B., Backstrom, L., and Kleinberg, J. Network exposure to multiple universes. In NIPS
Workshop: Social network and social media analy-sis: Methods, models and applications , Lake Tahoe, NV, 2012.
 William, Aiello, Chung, Fan, and Lu, Linyuan. A ran-dom graph model for power law graphs. Experimen-tal Mathematics , 10(1):53 X 66, 2001.
 Zachary, W.W. An information flow model for conflict and fission in small groups. Journal of anthropolog-
