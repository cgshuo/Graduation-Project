 Research in the areas of privacy preserving techniques in databases and subsequently in privacy enhancement tech-nologies have witnessed an explosive growth-spurt in recent years. This escalation has been fueled by the growing mis-trust of individuals towards organizations collecting and dis-bursing their Personally Identifiable Information (PII). Dig-ital repositories have become increasingly susceptible to in-tentional or unintentional abuse, resulting in organizations to be liable under the privacy legislations that are being adopted by governments the world over. These privacy con-cerns have necessitated new advancements in the field of distributed data mining wherein, collaborating parties may be legally bound not to reveal the private information of their customers. In this paper, we present a new algorithm PriPSeP ( Pri vacy P reserving Se quential P atterns )forthe mining of sequential patterns from distributed databases while preserving privacy. A salient feature of PriPSeP is that due to its flexibility it is more pertinent to mining op-erations for real world applications in terms of efficiency and functionality. Under some reasonable assumptions, we prove that our architecture and protocol employed by our algorithm for multi-party computation is secure.
 Categories and Subject Descriptors: H.2.8 [Database Applications]: Data Mining General Terms: Algorithms.
 Keywords: Privacy Mining. The increasing use of multi-database technology, such as  X  email: vkapoor@cse.iitd.ernet.in. This work was performed as part of an internship at the LGI2P Research Center.  X  emails: { Pascal.Poncelet,trousset } @ema.fr  X  email: teisseire@lirmm.fr Copyright 2006 ACM 1-59593-433-2/06/0011 ... $ 5.00. computer communication networks and distributed, feder-ated and homogeneous multi-database systems, has led to the development of many large distributed transactional da-tabases. For decision-making, large organizations might need to mine these multiple databases located at disparate bran-ches and locations. Particularly, as the Web is rapidly be-coming an information flood, individuals and organizations can take into account low-cost information and knowledge on the Internet while making decisions. Although this large data enables in the improvement of the quality of decisions, it also generates a significant challenge in the form of effi-ciently identifying quality knowledge from multi-databases [20, 25].
 Therefore, large corporations may have to confront the mul-tiple data-source problem. For example, a retail-chain with numerous franchisees might wish to collaboratively mine the union of all the transactional data. Each of the smaller transactional databases could contain information regarding the purchasing history of the same set of common customers transacting through online portals or real stores. However, the greater challenge of these computations can be the ad-ditional constraint of adhering to stringent privacy require-ments laid down by the formulation of new laws such as HIPAA [15]. These regulatory policies have been the driv-ing force behind the increased consciousness in organizations towards the protection of privacy. Consequently, there has been a paradigm shift towards the creation of privacy-aware infrastructures, which entail all aspects, ranging from data-collection to analysis [3].
 Conventionally, data mining has operated on a data-ware-housing model of gathering all data into a central site, then running an algorithm against that data. Privacy considera-tions may prevent this generic approach. Hence, privacy pre-serving data mining has gained recognition among academia and organizations as an important and unalienable area, es-pecially for highly sensitive data such as health-records. If data mining is to be performed on these sensitive datasets, due attention must be given to the privacy requirements. However, conventional sequential pattern mining methods based on support do not preserve privacy and are ineffective for global pattern mining from multiple data sources. Traditionally, Secure Multi-Party Protocols (SMC) have been employed for the secure computation for any generic func-tions. However, the complexity and overhead of such se-cure protocols would be prohibitive for complex data mining tasks such as the discovery of sequential patterns. Hence, to alleviate the communication and bandwidth overhead of the Oblivious Transfer (i.e. the protocol by which sender sends some information to the receiver, but remains oblivious as to what is sent) required between parties in an SMC, we employ an alternative architecture consisting of semi-honest and non-colluding sites [12]. This tradeoff between secu-rity and efficiency is reasonable as none of the participating sites learn the intermediate or the final results of the calcu-lus. Furthermore, due to the uniform random noise in the datasets, the private information of any individual is also guarded from any possible leak.
 In this paper, we present an alternative privacy preserving data mining approach -PriPSeP , for finding sequential pat-terns in the distributed databases of a large integrated orga-nization. Our novel algorithm, PriPSeP is useful for min-ing sequential patterns via collaboration between disparate parties, employing the secure architecture, performing the secure operations via the underlying protocols.
 Organization : The remainder of this paper is organized as follows. Section 2 goes deeper into presenting the problem statement and provides an extensive description of the prob-lem at hand. In Section 3, we present an overview of the related work and give our motivation for a new approach. Section 4 describes our proposed solution with the descrip-tion of the architecture and the algorithms for secure multi-party protocols. Finally, Section 5 concludes the paper with a roadmap for future work. In this section, we give the formal definition of the prob-lem of privacy preserving collaborative sequential pattern mining. First, we provide a brief overview of the traditional frequent pattern mining problem by summarizing the formal description introduced in [1] and extended in [18]. Subse-quently, we extend the problem by considering distributed databases. Finally, we formally define the problem of pri-vacy preserving sequential pattern mining. Let DB be a database containing a set of customer trans-actions where each transaction T consists of a customer-id(CID), a transaction time(TID) and a set of items involved in the transaction.
 Let I = { i 1 ,i 2 ...i m } be a set of literals called items. An itemset is a non-empty set of items. A sequence S is a set of itemsets ordered according to their timestamp. It is denoted by &lt;s 1 s 2 ...s n &gt; ,where s j ,j  X  1 ...n ,isanitemset. Inthe rest of the paper we will consider that itemsets are merely re-duced to items. Nevertheless all the proposal could be easily extended to deal with itemsets. A k -sequence is a sequence of k items (or of length k ). A sequence S = &lt;s 1 s 2 ... s a subsequence of another sequence S = &lt;s 1 s 2 ... s m noted S  X  S , if there exist integers i 1 &lt;i 2 &lt; ... i such that s 1  X  s i 1 , s 2  X  si 2 , ... s n  X  si n . All transactions from the same customer are grouped to-gether and sorted in increasing order and are called a data sequence. A support value (denoted supp ( S )) for a sequence gives its number of distinct occurrences in DB . Neverthe-less, a sequence in a data sequence is taken into account only once to compute the support even if several occurrences are discovered. In other words, the support of a sequence is de-fined as the fraction of total distinct data sequences that con-tain S . A data sequence contains a sequence S if S is a sub-sequence of the data sequence. In order to decide whether a sequence is frequent or not, a minimum support value (de-noted minsupp ) is specified by the user, and the sequence is said to be frequent if the condition supp ( S )  X  minsupp holds. Given a database of customer transactions, the prob-lem of sequential pattern mining is to find all the sequences whose support is greater than a specified threshold (mini-mum support). Each of these represents a sequential pat-tern, also called a frequent sequence. Let DB be a database such as DB = DB 1 For simplicity, we consider that all databases DB 1 ,DB 2 DB D share the same number of customers (CIDs), which is N . We also consider that for each customer in the databases, the number of transaction times (TIDs), K ,isthesame 1 .As we extend the data representation scheme from the SPAM approach [2], we consider that all transactions are depicted in the form of vertical bitmaps, which we denote as vectors for clarity in mathematical formulae.

Definition 1. Let V j i be a vector where j and i corre-spond respectively to the i th item and the j th database. V defined as follows: V j i =[ C i,j 1 ...C i,j N ] where for u C action list of the customer u , from the database DB j and the item i .Itisa K length bit string that has the v th bit as one if the customer u has bought the item i from the database DB j .
 Given a set of databases DB 1 ,DB 2 ...DB D containing cus-tomer transactions, the problem of collaborative sequential pattern mining is to find all the sequences whose support is greater than a specified threshold (minimum support). Fur-thermore, the problem of priva cy-preserving collaborative sequential pattern mining is to discover sequential patterns embedded in the union of databases by considering that the parties do not want to share their private datasets with each other.
 In order to illustrate this further, let us consider the follow-ing example.
 Example 1. Let us assume that three retail franchisees Alice, Bob and Carol wish to securely extract the sequen-tial patterns in the union of their databases without disclos-ing the identities of any individual customers. Each item is provided with its timestamp (C.f. table 1).
 Table 1: An example of distributed databases sorted by CID Let us assume that the minimal support value is set to 50%. From the three distributed databases, we can infer that item (1) is not frequent in any one of the individual databases.
This constraint has been considered purely for readability reasons. All the described algorithms could be easily ex-tended to incorporate customer sequences that do not have the same number of TIDs. Table 2: Sequences for each customer in the union of all databases However, by considering the union of all databases (C.f. table 2 where the superscript depicts the original database, where the item is derived from), we obtain that the sequence &lt; (1)(2)(3) &gt; is frequent. By considering the constraints for privacy, this sequence has to be obtained by considering Alice, Bob and Carol are not at liberty to disclose the private transactional history of any of the customers. In this section we focus on the various research work closely related to the domain of privacy preserving data mining and sequential patterns.
 Sequential Patterns: Since its introduction, more than a decade ago, the sequential pattern mining problem has re-ceived a great deal of attention and numerous algorithms have been defined to efficiently find such patterns (e.g. GSP [18], PSP [14], PrefixSpan [16], SPADE [23], FreeSpan[10], SPAM [2]). Our data representation scheme has been ex-tended from the SPAM algorithm [2], wherein for efficient counting, each customer X  X  transactions are represented by a vertical bitmap.
 Privacy Preserving Data Mining: Recently, there has been a spate of work addressing privacy preserving data mining [17, 5]. This wide area of research includes clas-sification techniques [7], association rule mining [8], and clustering [11] with privacy constraints. In early work on privacy-preserving data mining, Lindell and Pinkas [13] pro-pose a solution to privacy-preserving classification problem using oblivious transfer protocol, a powerful tool developed by SMC research. The techniques based on SMC for effi-ciently dealing with large data sets have been addressed in [19], where a solution to the association rule mining prob-lem for the case of two parties was proposed. Recently, a novel secure architecture has been proposed in [12], where the security and accuracy of the data mining results are guaranteed with improved efficiency.
 Secure Multi-Party Computation: A Secure Multi-party Computation (SMC) problem deals with computing any func-tion on any input, in a distributed network where each par-ticipant holds one of the inputs, while ensuring that no more information is revealed to a participant in the computation than can be inferred from that participants input and out-put. Secure two party computation was first investigated by Yao [21, 22] and was later generalized to multi-party com-putation (e.g. [6, 9, 4]). It has been proved that for any polynomial function, there is a secure multiparty computa-tion solution [9, 4]. The approach used is as follows: the function f to be computed is firstly represented as a com-binatorial circuit, and then the parties run a short protocol for every gate in the circuit. Every participant gets corre-sponding shares of the input wires and the output wires for every gate. While this approach is appealing in its general-ity and simplicity, the protocols it generates depend on the size of the circuit. This size depends on the size of the input (which might be huge as in a data mining application), and on the complexity of expressing f as a circuit (for example, a naive multiplication circuit is quadratic in the size of its inputs). Hence this approach, is highly impractical for large datasets and complicated computations necessary in com-plex data mining tasks. Our shift away from a traditional SMC approach has been motivated by [12], describing the limitations of highly secure, yet practically unviable proto-cols.
 Previous Work: The research area of privacy preserv-ing sequential pattern mining lies largely unexplored with only one seminal paper [24]. Zhan et al. have proposed an approach, which entails the transformation of the databases of each collaborating party, followed by the execution of a secure protocol, which results in the preservation of privacy, as well as the correct results. Theoretically, the approach is robust and secure, however, it has serious limitations relat-ing to the initial constraints assumed while developing the approach. It has been proposed that each of the collabo-rating parties carri es a unique inventory. For instance, con-sidering our previous example and not taking into account the possibility of items being shared among the distributed parties, we do not arrive at the complete results. An item such as (1), which is not supported by enough customers in one individual database will not appear in the final re-sults. This assumption causes serious limitation for real ap-plications where item sharing between different databases is imperative as well as a fundamental requirement as shown earlier. Moreover, employing their new data representation scheme for sequential data, the same customer buying the same item more than once from the same database but with a different TID is not permissible. One other drawback of mapping each item to a unique code is the additional over-head incurred while sorting the databases, which might be significant for large databases. In this section, we propose our novel approach for privacy preserving sequential pattern mining in distributed and col-laborative databases. Firstly we focus only on collaborative sequential pattern mining in order to clearly explain our methodology. This approach is extended in the next section in order to consider privacy requirements and finally we pro-pose a new algorithm and underlying protocols within the secure architecture. As previously seen in Section 2, the challenge with collab-orative mining lies in the fact that we have to deal with different databases where the order of items is not known beforehand (e.g. item (7) of the CID 1 in Carol X  X  database occurs before item (3) in Alice X  X  database).
 For brevity, we consider the Data Miner performing the gen-erating and verifying phases of candidate sequences similar to the Apriori-based algorithms. We assume that the can-didate generation is performed conventionally by combining the k -1 frequent sequences in order to generate k -candidate sequences (e.g. C.f. GSP [18] generation phase). We extend the verification phase as follows. As we have to deal with disparate distributed databases, we assume that the Miner could request information from the D original databases in order to obtain a vector corresponding to the specific item i , i.e. V [1 ..D ] i for any candidate sequence. Let us consider that we are provided with two databases, namely DB 1 and DB 2 . These databases contain transac-tions for three customers and each customer has five transac-tion times or TIDs. The process aims at finding the support value for the sequence &lt; (1)(2) &gt; in the set of all customers of the two databases. First, we extract from DB 1 ,thevec-tor corresponding to the item (1), i.e. V 1 1 ,andfrom DB the vector V 2 1 (left part of figure 1). From the given vec-tors, two key operations have to be performed: (i) bitwise OR of the two vectors, and (ii) transforming the result in order to check if it could be followed by (2). These two vectors are merged together by applying a bitwise operator (  X  ): V 1 1  X  V 2 1 . For the second operation, similar to the S-step process of the SPAM algorithm, we consider a function that transforms the vector(bitmap). For each customer, fol-lowing the occurrence of the first bit with value one, every subsequent bit in the vector is flagged as one. However, since we have to deal with different databases as well as efficiency issues, we consider that these two operations are performed through the f function defined below to obtain a new vector Z 1 = f ( V 1 1  X  V 2 1 ).

Definition 2. Let us consider a vector V j i for a database j and an item i . V j i is defined as follows: V j i =( C where for u  X  X  1 ..N } , C i,j u =( T i,j,u 1 , ..., T i,j,u for the number of TIDs and N corresponds to the num-ber of CIDs. For brevity, we denote this vector as V .Let f :[0 , 1] N  X  K  X  [0 , 1] N  X  K be a function such that: f ( V )= f ( C 1 ...C N )=[ f c ( C 1 ) f c ( C 2 ) ...f c ( C N )] .Foreach u we have: f c ( C u )= where  X  is a bitwise operator. We can notice that Card ( V )= N  X  K , Card ( C u )= K , Card ( f ( V )) = N  X  K . Let g :[0 , 1] N  X  K  X  [0 , 1] N be a function such that: g ( V )= g ( C 1 ...C N )=[ g c ( C 1 ) g c ( C 2 ) ...g c ( C N )] .Foreach u we have: g c ( C u )=1 if there exists at least one bit with value 1 in the customer transactions. It can be noted that Card ( g ( V )) = N .
 In conjunction with the computation of the function f ,the vectors corresponding to the item (2) are extracted from DB 1 and DB 2 ( V 1 2 and V 2 2 respectively). Similar to the previous step the vector ( Z 2 = V 1 2  X  V 2 2 ) is computed. Fol-lowing that, the bitwise operator  X  is used to calculate Z 1  X  Z 2 and the g function is used to calculate the count for each customer, for the sequence &lt; (1)(2) &gt; , i.e. Z a cardinality corresponding to the number of customers, i.e. N , the last operation to be performed is a summation of the number of bits with the value 1 in the vector Z 3 .Thisis performed by the The Collaborative Frequency algorithm (see Algorithm 1) has been developed as follows. For each item i of the can-didate sequence to be tested, a new vector X i is generated by applying the  X  bitwise operator on all the corresponding vectors from the original databases. Hence, by considering the result of the previous operation, the f function is ap-plied, followed by the bitwise operator  X  for each item. At the end of this iteration, a new vector Z of cardinality N is produced. Consequently, the g function is applied to the intermediate result for generating a vector of cardinality N , i.e. Y . Finally, the number of bits which are 1 in Y are summated to compute the final value of support.
 Algorithm 1: The Collaborative Frequency algo-rithm Data : S = &lt;it 1 ... it q &gt; a sequence to be tested;
Result : The support of the sequence S in DB . foreach i  X  1 .. | S | do
Z  X  X 1 ; foreach i  X  2 .. | S | do
Y  X  g ( Z ); return Complexity: Let V s = N  X  K be the size of the vectors which are sent and S be the candidate sequence to be veri-fied. The transfers that are performed by the algorithm are: ( V s  X  D  X | S | )for and performed by f .If f is already available, i.e. precomputed and stored, we have ( N ) operations are performed by g . In this section we describe an architecture where secure multi-party techniques developed in the cryptographic do-main can be easily extended for data mining purposes[12]. Previous work [9] has described that Secure Multi-party pro-tocols can be used directly to solve with total security, any generic data mining task. However, the drawback is the complexity of the protocol and the requirements that all parties need to be online during the entire duration of the lengthy process. Hence, it is potentially unviable for com-plex data mining tasks, particularly relating to cases with a large number of participants. The communication com-plexity prohibits efficient scalability and for situations that all parties cannot remain online for the entire process, the SMC protocols are rendered useless.
 Hence, as proposed in [12], we deploy a safe architecture for performing the data mining task without leaking any useful or sensitive information to any of the intermediate parties. These independent sites collect, store and evaluate informa-tion securely. PriPSeP requires three non colluding and semi honest [9] sites which follow the protocol correctly but can utilize the information collected by them. In effect, all  X  parties correctly follow the protocols, but then are free to use whatever information they see during the execution of the protocols in any way. These are also referred to as hon-est but curious sites.
 The detailed functions of each of these sites are described: Let us consider Figure 2 illustrating the sites and, for each operator, the different exchanges performed between the sites. Initially the following preprocessing steps are per-formed on the databases individually: 1. Each database DB 1 ,DB 2 ...DB D adds the same num-2. Let  X  be a random number. Each database permutes 3. One of the collaborating parties is randomly elected to At the end of the preprocessing we are provided with databases having fake customer transactions and permuted list of ver-tically aligned vectors. Subsequently, the Data Miner can apply an Apriori-like algorithm for generating candidate se-quences as previously mentioned in Section 4.1. This step is immediately followed by the counting phase. For sim-plicity, let us take the case of counting the value of sup-port for the two-length sequence &lt; (1)(2) &gt; .Now,each database DB j sends its V j 1 vector to NC 1 and NC 2 (dashed arrows numbered 1 in figure 2). In order to minimize the risk of network attacks, we propose a hypothetical function Send S  X  DB d ( it ) which securely transmits the item vector V it from database DB d to NC 1 and NC 2 .Furthermore, in order to make sure that NC 1 and NC 2 receive minimal information, for each database DB i , we generate a random vector R DB i having the same size than V it andthencalcu-late a vector: Z DB i = V it NC 1 and R DB i to NC 2 or vice versa. A similar approach is used in [5] for other data mining tasks. In this case, for NC 1 and NC 2 sites we have some R DB i vectors and since the other vectors are XOR-ed are indistinguishable from a uniform random distribution. Similar to Algorithm 4.1, the bitwise operator (  X  )hastobe applied between every vector. As these vectors are shared by NC 1 and NC 2 , we consider a new protocol numbered 2 in Figure 2) aiming at computing a bitwise OR between the different vectors. This is performed by send-ing XOR-ed randomized values from NC 1 and NC 2 to PS . Then PS also garbles the resulting vectors in order to divide the result between NC 1 and NC 2 . The calculation continues by computing the f and g functions (subsequently referred to as f S and g S ) in a similar way and results are also stored between NC 1 and NC 2 (arrows numbered 3 in Figure 2). Finally, in order to compute the number of bits which are in 1 ( laborate to append their resultant vector with randomized values and then reorder the new vector. PS then calculates the summation of the number of bits and returns part of the result to NC 1 and NC 2 . NC 1 removes their initial random noise and then return those final results to the Data Miner (arrows numbered 4 in Figure 2). At this step, DM only has to combine the result from NC 1 and NC 2 and then remove the  X  value corresponding to random customers added in the preprocessing phase. i 4
PS Architecture In the following sections, we will explain in detail the various protocols, functions and algorithms necessary for PriPSeP Firstly, we introduce some notations that are used for de-scribing the algorithms. As our functions employ bitwise op-erators, we first present new protocols for securely perform-ing bitwise operations. Continuing, we will show how the functions f , g and tively to incorporate security aspects. Finally, we present the Secure Collaborative Frequency algorithm. As the main goal of our approach is to preserve privacy of the individual users and do not divulge any information about the final result to any of the sites, we will show that at the end of the process, NC 1 , NC 2 and PS will only learn a up-per bound on the support count of sequences and will not have any information about the private inputs of any of the individual customers. In the next subsections, we will consider the following nota-tions. Let ( + X |  X  X )  X  h S ( calculation of any function h S between NC 1 , NC 2 and PS where NC 1 owns half of the input cess. The final result is the logical bitwise XOR ( sends tially, NC 1 transforms its inputs addition of uniform random noise and securely sends these transformed Y to PS . Symmetrically, NC 2 also sends its garbled inputs to PS . At the end of the computation both the sites receive their share of the noisy result from PS . Henceforth, this intermediate result can be used as the inputs for further computations. In this section, we define two basic algorithms ( gorithm 2) and which is used to securely compute the bitwise operators. The underlying fundamental principle that the algorithms oper-ate upon is the addition of uniform random noise to the data which can be removed from the result by the data-owners. The protocol initiates with both NC 1 and NC 2 perturbing their data by XOR-ing it with random values. Subsequently, the randomized data is sent (e.g. for NC 2 ,  X  X =  X  X the puts and calculates + C = + X also adds random noise to both the intermediate results in order to avoid that either NC 1 or NC 2 have the whole re-sult. At the end of the protocol, non colluding sites can then calculate the final result for their own part by remov-ing the initial noise. For instance, for NC 1 , the following operation: A R = A PS ( R B part ( + X , + Y and R A ) and random numbers from NC 2 ( R R B ). Hence, the final results A R L L ( )
L Due to the boolean property R desired result: A R symmetrically divided result lies with both NC 1 and NC 2 Theorem 1. The operand from learning NC 2  X  X  private data and vice versa. Moreover, the third party PS learns none of their private inputs. Algorithm 2: The Result :( A R | B R )aresuchthat A R Proof : From the protocol, B PS is all that NC 2 learns related to the private data of NC 1 . Due to the randomness and secrecy of R PS , NC 2 cannot find out the values of + X or As the roles of NC 1 and NC 2 are interchangeable, the same argument holds for NC 1 not learning the private inputs  X  any information to PS is achieved by randomizing the inputs before transmitting them to the Processing Site. Due to the randomization performed during the initial step, it just infers a stream of uniformly distributed values, and cannot distinguish between a genuine and a random value. Complexity: For the be performed (6 are performed for the computations. For each bits. From NC 1 or NC 2 ,2  X  1bitsaresentto PS and one bit returned. Furthermore, both NC 1 and NC 2 calculate 2 random bits while 1 random bit is generated by PS . In this section, we extend the f and g functions in order to incorporate security (see Algorithm 4). As previously mentioned, the SPAM algorithm X  X  S-step Process requires that the vectors corresponding to every customer contain all 1 X  X  after the date of the first transaction for that customer. Hence, the f S function recursively employs the to securely compute the resultant vector. The inputs of the Algorithm 3: The Result :( A R | B R )aresuchthat A R 1..5. The first 5 steps are the same as Algorithm 4: The f S function foreach c  X  0 .. ( | + X | /K )  X  1 do function are the randomly distorted customer data and the secure cessive bits residing at the two sites NC 1 and NC 2 . Similar to the previous algorithms, the final result of the operation is split into two parts with the Processing Site oblivious of the correct answer.
 Similarly, the g S function (see Algorithm 5) securely com-putes the existence of at least one bit with value  X 1 X  in the vector of each customer transaction. It reduces the vector to a single bit of value either  X 0 X   X 1 X  depending on whether the sequence is supported at least once. This function is useful in calculating the support value at the penultimate step of the Algorithm 7.

Theorem 2. The functions f S and g S aresecureandre-stricts NC 1 , NC 2 and PS from inferring each other X  X  pri-vate data.
 Proof : From the algorithms, it is apparent that the secure operation As proved in Theorem 1, no private information is shared while the execution of this operation. Hence, both the func-tions f S and g S are also secure and no site infers any infor-mation about any individual customer. Algorithm 5: The g S function foreach c  X  0 .. ( | + X | /K )  X  1 do Remark : In fact, calculating g S ( + X ,  X  X )  X  ( + Y , turned while calculating f S ( + X ,  X  X )  X  ( + Z ,  X  Z )because can easily be obtained from ( following relation: ( Theorem 3. The functions and does not reveal the final value of support for the candi-date sequence to either NC 1 , NC 2 or PS .
 Proof : Two random vectors R 1 and R 2 are appended to the inputs of NC 1 and NC 2 to prevent PS from distinguish-ing between genuine and random values. The final com-puted result is divided by PS between the two sites NC 1 and NC 2 . Hence the final computation is performed by the Data Miner, which receives the correct result.
 Complexity: In Algorithm 6, the number of bits is increased by a value  X  2 N for security reasons. Let us consider that we set this value as follows t =  X  [2 ..K ]. For NC 1 and NC (2 N (2 t + 1)) operations are performed while (2 N ( t +1)) op-erations on PS . Furthermore we have N ( t +1) operations for randomizing. The number of transfers between NC 1 and NC 2 is (2 tN ). To exchange the permutation  X  between NC and NC 2 , we actually need N ( t + 1) transfers. Nevertheless, if NC 1 and NC 2 share a common set of random values gen-erator, they only need to exchange a number and a seed. So it could be neglected. Finally between NC 1 / NC 2 and PS , N ( t + 1) bits are transferred. 4.2.5 The Secure Collaborative Frequency algo-The Secure Collaborative Frequency algorithm (see Algorithm 7) extends the Algorithm 1 in order to perform all operations securely. It is applied after the preprocessing step and thus considers the original database having fake transactions. For each item i of the sequence to be tested, all noisy vectors are sent by Send S to NC 1 and NC 2 in order to securely apply an OR between each vector ( function followed by the bitwise operator At the end of this loop we are thus provided with a new and NC 2 . Then we apply the g S function for generating Algorithm 6: The
Result :Anumberwhichissharedintwoparts: ( ( the Data Miner party. To get the real and final result, the miner has just to calculate + R +  X  R (integer summation) and has to remove the initial random noise, i.e.  X  ,theyhave added at the beginning of the process.

Theorem 4. The randomization, performed at each level (original databases, NC 1 , NC 2 and PS ), does not affect the accuracy of the result.
 Proof : The first randomization is performed by the original databases while inserting fake transactions, i.e.  X  ,andper-muting the list customers according to the value of  X  .As, DM is elected from the original databases, this information about the noise is available to DM and hence can easily be removed. The second randomization is performed by NC 1 and NC 2 while sending the transaction vectors to PS for the secure computation of noise is removed at the end of each computation from NC 1 and NC 2 when they receive results from PS by performing an XOR operation with the initial random values. More-over, we have also proved that no private information about any individual could be learnt by any of the sites (C.f. The-orems 1,2, and 3). Finally, for the computation of the function, NC 1 and NC 2 add random noise in their data, i.e. N
R , and also permute their vector according to a  X  value. Algorithm 7: The Secure Collaborative Fre-quency algorithm Data : S = &lt;it 1 ...it q &gt; a sequence to be tested; DB =
Result : The support of the sequence S in DB with foreach i  X  1 .. | S | do foreach i  X  2 .. | S | do PS also randomizes its integer value and this noise is re-moved by sending opposite parts to NC 1 and NC 2 .The N
R value is removed by NC 1 and NC 2 when returning the result to DM . Finally, when combining results from NC 1 and NC 2 , the only operation to be performed by DM to know the real result is to remove the initial  X  . Complexity: In the secure protocol, each database has to send 2 NK data bits instead of NK . Each DB has also to calculate NK random bits and perform ( NK ) ations. According to the previous results on the number of operations performed by the secure operators, the time complexity is O (12 NK ) for binary operations and O (7 NK ) for randomizing operations. Hence, it could be bounded by O (20 NK ). Let us now consider the communication com-plexity of the protocol. Let p = D  X | S | X  N  X  K .The complexity of the Algorithm 1, i.e. without considering se-curity, is linear. Let us consider C or = O ( p ). As the secure algorithm considers the same structures as well as the same order of the operations, we have the complexity of 20  X  C The number of transfers required is at most four times the complexity of the transfer of the 1.
 The secure architecture could be further redefined in order to improve the communication cost between NC 1 , NC 2 and PS . Furthermore, all the functions could be parallelized. By considering that operations performed on a new archi-tecture could be done securely by a multiple of 20, we could very easily remove this overhead. The last overhead is the communication cost incurred during the transfer between original databases and NC 1 / NC 2 . The overhead of the all systems could thus be only 2. We notice, that by consider-ing SMC protocols, no such optimizations are possible, and hence for scalability issues, our alternative approach could be beneficial. For analyzing the security, let us examine the information divulged to each site participating in the protocol. Note that during the entire process, the random numbers are securely generated and the communication infrastructure is robust and intrusion free. In this paper, we have addressed the problem of privacy pre-serving sequential pattern mining in distributed databases. We have presented a novel secure extension of the SPAM algorithm for mining patterns. We also prove, that under reasonable assumptions, our algorithm and the underlying operations, protocols and architecture for multiparty com-putation is secure. There are various avenues for future work. Firstly, in this paper we have only focused on the S-step process of the SPAM algorithm, i.e. we only consid-ered the problem of discovering sequences reduced to a list of items. As we have proposed a series of secure functions, our approach could be easily improved to also consider I-step process, i.e. a list of itemsets instead of items. In the same way, the algorithms and underlying protocols could be easily improved by considering that the number of TIDs is differ-ent between the customers. In this case, the only constraint to be considered is that databases share the same number of customers or CIDs. Furthermor e, in the current version of PriPSep , results are directly returned to the DM party as well as the original databases. In order to improve the whole process, we plan to extend the role of DM wherein, it could store the lexicographic tree and could expand each node in the tree by considering that intermediate results could be stored in shared arrays between NC 1 and NC 2 .Hence,in-cremental mining could be possible and unlike our current approach, previous results need not be recomputed. The storage of results would also be made secure by ensuring that each site has only noisy data or random values. [1] R. Agrawal and R.Srikant. Mining sequential patterns. [2] J. Ayres, J. Flannick, J. Gehrke, and T. Yiu. [3] J. Bhattacharya, S. Gupta, V. Kapoor, and R. Dass. [4] D. Chaum, C. Crepeau, and I. Damgard. Multiparty [5] C. Clifton, M. Kantarcioglu, X. Lin, J. Vaidya, and [6] W. Du and M. J. Atallah. Secure multi-party [7] W. Du, Y. Han, and S. Chen. Privacy-preserving [8] A. Evfimievski, R. Srikant, R. Agrawal, and [9] Oded Goldreich. Secure multi-party computation. [10] J. Han, J. Pei, B. Mortazavi-asl, Q. Chen, U. Dayal, [11] G. Jagannathan and R. Wright. Privacy-preserving [12] M. Kantarcioglu and J. Vaidya. An architecture for [13] Y. Lindell and B. Pinkas. Privacy preserving data [14] F. Masseglia, F. Cathala, and P. Poncelet. The PSP [15] United States Dept. of Health &amp; Human Services. [16] J. Pei, J. Han, H. Pinto, Q. Chen, U. Dayal, and M.C. [17] B. Pinkas. Cryptographic techniques for privacy [18] R. Srikant and R. Agrawal. Mining sequential [19] J. Vaidya and C. Clifton. Privacy preserving [20] X.Wu and S. Zhang. Synthesizing high-frequency rules [21] A. C. Yao. Protocols for secure computations. In Proc. [22] A. C. Yao. How to generate and exchange secrets. In [23] M.J. Zaki. SPADE: An efficient algorithm for mining [24] J. Zhan, L. Chang, and S. Matwin. Privacy-preserving [25] N. Zhong, Y. Yao, , and S. Ohsuga. Peculiarity
