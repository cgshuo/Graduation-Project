 Digital camera becomes increasingly popular. People now can take digital photos by the digital camera embedded in the mobile phone as well as the conventional digital cameras. As opposed to the conventional film-based photo shots, it is almost free of cost to take a digital shot, since we can easily delete the digital photos any time without consuming any memory space. This makes people to take less serious consideration in making every shot, leaving many multiple and redundant ones. This also makes it tedious to browse the entire shots in the flash memory. One way to alleviate this difficulty is to retrieve similar looking images from the stored image database and discard those that are duplicates. Since people tend to take pictures with an identical background but different persons or with a group of similar persons but different background, it should be able to retrieve images in terms of partial region similarity in the image space. This is also achieved by the region-of-interest (ROI) queries [3].
 matching for the whole image space, the ROI query method is to seek images with similar objects in the image. Once the ROIs are similar each other, then the ROI query does not care about the remaining regions in the image space. Of course, to make this ROI query possible, image segmentation extracting ROIs should be done beforehand. However, it is well known that an automatic ob-ject segmentation with semantic meaning is an unsolved problem. Instead, each meaningful object in the image can be automatically divided into multiple homo-geneous regions. In region-based image matching, visual features such as color, texture, shape, and size of the homogeneous regions are compared to measure the similarity [1]. Again, the performance of this method is sensitive to the seg-mentation result.
 delineate the ROI in the image space. With this user interaction, the ROI is extracted from the image and is compared to those regions in the image database. In [3], 16  X  16-pixel blocks are sampled and are used to select ROIs in the image space. Although this sample matching method can take the arbitrary shape information into the similarity matching, the selecting 16  X  16-pixel blocks for the identification of ROI requires user X  X  careful attention. In this paper, to solve this problem, we divide the image space into larger 4  X  4 sub-images and then, on this 4  X  4 image grid, the sub-images covering the ROI are selected for the query regions. In the selected sub-images, we extract visual features for the similarity matching. Visual features extracted from each sub-image for the similarity matching includes edge histogram descriptor (EHD) and color layout descriptor (CLD) of MPEG-7. Thus, our image retrieval method is compliant to the MPEG-7 standard. 2.1 EHD The EHD (Edge Histogram Descriptor) of MPEG-7 visual descriptors [2] rep-resents the distribution of 5 edge types, namely vertical, horizontal, 45-degree diagonal, 135-degree diagonal, and non-edge types. We generate 16 edge his-tograms, each one represents the edge distribution for each of 16 sub-images (see Figure 1 for the definition of sub-image). That is, an image is divided into non-overlapping 4x4 sub-images. Then, each sub-image serves a basic region to generate an edge histogram, which consists of 5 bins with vertical, horizontal, 45-degree diagonal, 135-degree diagonal, and non-directional edge types. Since it is required to extract the non-directional edge as well as the four directional ones, a small image block rather than a pixel is needed to extract an edge type [4]. To this end, we further divide the sub-image into non-overlapping image blocks with a small size. Note that the image block may or may not have an edge in it. If there is an edge in the block, we increase the counter of the corresponding edge type by one. Otherwise, the image block has monotonous gray levels and no histogram bin is increased. After examining all image blocks in the sub-image, the 5-bin values are normalized by the total number of blocks in the sub-image. Thus the sum of the normalized 5 bins is not necessarily 1. Finally, the nor-malized bin values are quantized for the binary representation. Since there are 16 (4  X  4) sub-images, each image yields an edge histogram with a total of 80 (16  X  5) bins. These normalized and quantized 80 bins constitute the EHD of the MPEG-7. That is, arranging edge histograms for the sub-images in the raster catenated to have an integrated histogram with 16  X  5 = 80 bins. Let us denote E ij ( k ) as a normalized and quantized bin value for a sub-image at ( i, j ) where  X  = { ( i, j ); 0  X  i  X  3 , 0  X  j  X  3 } is a set of indices for sub-images and k  X  X  1 ,  X  X  X  , 5 } indicates one of 5 edge types. 2.2 CLD The Color Layout Descriptor (CLD) of MPEG-7 visual descriptors [2] is designed to represent spatial distribution of color features in the image. To satisfy this requirement, the CLD is obtained by applying DCT (Discrete Cosine Transform) on a 2-D image space. Specifically, as shown in Figure 2, the image space is first divided into 8  X  8 non-overlapping blocks and a representative color for each block is determined. Adopting Y-Cb-Cr color space, three 8  X  8representative color components are applied to obtain three 8  X  8 DCT components of Y-Cb-Cr. Then, some of low frequency DCT components for each Y-Cb-Cr planes are selected and quantized for the CLD. Now, the indexed CLD can be used for the similarity matching. Note that, considering the 4  X  4 grid structure for the EHD, we further take the 8  X  8 IDCT (Inverse DCT) to the CLD to obtain the localized 8  X  8 color values. Then, these 8  X  8 IDCT vaues, instead of the quantized 8  X  8 DCT coefficients of CLD, can be spatially grouped together such that one sub-image of the EHD overlay 2  X  2ofthe8  X  8 IDCT values (see Figure 3). Then, in each sub-image, we can extract the color information as well as the edge histogram. Now, let us denote Y ij , Cb ij ,and Cr ij as the IDCT values (i.e.,
CLD on 8x8 DCT Plane the recovered spatial image data) for Y , Cb ,and Cr components at the block ( i, j ), respectively, where, 0  X  i  X  7 , 0  X  j  X  7. Since the EHD and the IDCT coefficients of the CLD are based on 4  X  4and 8  X  8 grids, respectively, there exists a locational correspondence between the sub-image of the EHD and 2  X  2 IDCT values of the CLD. That is, as shown in Figure 3, the neighboring 2  X  2 IDCT values correspond to one sub-image of the EHD. So, supposing that a sub-image of the EHD is selected as a ROI, the similarity measure between the query image and the test image can be formulated with both the EHD and IDCT of the CLD. That is, S EHD ij , the similarity measure of EHD between the sub-image of the query and that of the test image at ( i, j )  X   X  , is as follows where superscripts Q and T l represent the query and the l th test images, respec-tively. Also, S EHD max is a normalizing constant such that where L is the total number of test images. This implies that S EHD ij ( l )isnor-malized such that 0  X  S EHD ij ( l )  X  1. Similarly, we have the similarity of CLD as follows Finally, combining equations (1) and (3), we have a combined similarity as follows Now, smaller S ij ( l ) value means higher similarity between the two regions. Cal-culating (4) for all test images and for all sub-images  X  in the test image, we can find the best matching regions in test images. Suppose that there are photos with three people standing with different back-ground. In this case, as shown in Figure 4, we may want to retrieve all photos with those three men. To achieve this goal, we may choose 3  X  3 bottom-left sub-images as shown in the upper and left-most photo. Thus, this upper and left-most photo is the query image and the 3  X  3 bottom-left sub-images are the ROI. Applying the similarity measure of (4) for all selected sub-images and for all test images, we can retrieve photos with the best matching regions and display them from top-left to bottom-right with the decreasing order of the similarity. As shown in the figure, photos with three same men but different background are ranked for the top-four photos. Another retrieval result is shown in Figure 5. In this figure, the ROI is the central 2  X  2 sub-images and the highest ranked 4 images have the same ROIs but different background.
 ages are selected. Figure 6 shows the selected query images and their query regions. For each query image region, a number of ground truth images with similar ROIs are also manually determined. Then, the performance of the pro-posed algorithm is evaluated in terms of ANMRR [2]. The proposed algorithm yields ANMRR=0.1255 for the 20 query images. A region-based image retrieval method has been proposed. A subset of 4  X  4 sub-images covering the ROI is selected as a region for the similarity matching. Then, the EHD and the IDCT values of the CLD in the selected sub-images are used as the features for the similarity matching. Thus, the proposed region-based retrieval method is MPEG-7 compliant. Experimental results show that the proposed method can retrieve the same foreground but different background or vice versa quite well.
 This work was partially supported by the Korea Science Engineering Founda-tion (KOSEF) under the ERC program through the MINT research center at Dongguk University, Seoul, Korea.

