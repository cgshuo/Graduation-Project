 1. Introduction need for new proficient infrastructures facing large-scale compu-tational problems have prompted Grid computing as a promising platform ( Foster and Kesselman, 2003 ). A computational grid is made up of a set of heterogeneous and geographically distributed resources sharing theirs capabilities with the aim of achieving a common goal. Resources may belong to different administrative domains considering their own access policies and security constraints, and their coordination and cooperation is considered critical for the harnessing of grids potential ( Foster and Iamnitchi, 2003 ). In this sense, a major challenge is given by the efficient allocation of users jobs to resources or scheduling problem ( Christodoulopoulos et al., 2009 ). It should be noted that resources within a grid environment are diverse and they can unpredictably join or leave the system. Moreove r, jobs computational needs and requirements are unknown apriori ( Kalantari and Akbari, 2009 ). general form and a lot of research has been done to obtain efficient solutions ( Garey and Johnson, 1979 ; Klusacek et al., 2008b ). Queued-based techniques such as EASY-Backfilling ( EASY-BF )or
Earliest Deadline First ( EDF ), are extensively used in today X  X  produc-tion systems (i.e. Condor, Thain et al., 2005 or Grid Service Broker,
Venugopal et al., 2004 ) and their main advantage is given by its simplicity and short algorithms runtimes ( Klusacek and Rudova, 2008 ). However, queue-based methods are not able to guarantee most of QoS demanding features such as job turnaround and start time or resources utilization since decisions are taken considering a current known state of the grid. On the other hand, scheduled-based methods such as EGS ( Earliest Gap ), allow a more accurate schedul-ing plan by the consideration of up-to-date grid state information ( Klusacek, 2008 ). It must be underlined here that the grid available information is mostly imprecise due to the inner system dynamism and uncertainty. That is, an efficient scheduling strategy must also be able to faster react to environment changes. Thus, the new trends are focused on the development of so-called adaptive scheduling ( Xhafa and Abraham, 2008 , 2010 ). In this area, it is relevant to point out the role of Fuzzy Rule-Based Systems (FRBSs).

FRBSs are expert rule-based systems where Fuzzy Logic (FL) is employed as a way of representing the system knowledge and the interaction between variables ( Cordo  X  n et al., 2001 ). These systems base theirs decisions on  X  X  X F-THEN X  X  rules where antecedents and consequents represent fuzzy statements for the variables featur-ing the system state, and in this way, they are able to cope with complex problems where there exist vagueness and uncertainty. Hence, the reasoning strategy is founded on the definition of Knowledge Bases (KBs) that include the fuzzy rule semantics or fuzzy sets, Data Bases (DBs) and linguistic rules or expert knowl-edge, Rule-Bases (RBs). FRBSs have been successfully applied to a wide set of areas such as speech and music discrimination and they are proving to be an efficient alternative for adaptive scheduling ( Franke et al., 2008 ; Prado et al., 2010c , 2009 ). However, as it can be inferred, the scheduling performance using FRBSs strongly depends on the quality of its knowledge and thus, with the learning strategy. Since the incorporation of an expert knowledge is not a feasible option in most areas of application of FRBSs, automatic strategies are needed. One of the most extended techniques for the evolution of RBs are Genetic Algorithms (GAs) ( Garcia et al., 2009 ; Hoffmann et al., 2007 ). GAs are global optimization techniques providing quasi-optimal solutions in complex search spaces that make use of genetic operators such as selection and crossover for the searching of the best suited individuals. Specifically, there exist two successful approaches for rules learning with GAs, namely Pittsburgh ( Smith, 1980 ) and Michigan approach ( Booker et al., 1989 ; Carse et al., 1996 ). Whereas Pittsburgh approach considers a whole RB as an indivi-dual, within Michigan approach each fuzzy rule represents a candidate that competes to be included in the next generation. Both strategies are known to be able to find near optimal solutions. Nevertheless, given the dependence of FRBSs with the knowledge acquisition process, the design of faster and more accurate learning strategies is relevant.

In this work, we suggest the use of FRBSs for the design of a meta-scheduler for computational grids that incorporates a novel learning strategy inspired by Swarm Intelligence. To be precise, the learning strategy consists of the adaptation to rule represen-tation of Particle Swarm Optimization (PSO) ( Kennedy and Eberhart, 1995 ). PSO was first introduced with the aim of simulating the birds movement within a flock and it has been widely applied to optimization of multidimensional discontinu-ous problems in several fields such as electromagnetics ( Robinson and Rahmat-Samii, 2004 ) and wireless communications ( Huang et al., 2009 ). Further, it has been used for scheduling in grids as a population-based heur istic in works such as ( Liuetal.,inpress ). A major advantage of PSO is the convergence control and simplicity. In contrast to genetic strategies, PSO requires a reduced number of fixing operators and convergence is driven by particles internal velocities updating, what notably decreases the number of required communications and computational effort. However, in the authors knowledge, PSO has not been applied for rules evolution in grids. Thus, Knowledge Acquisition with a Swarm Intelligence Approach ( KASIA ) is suggested in this work for the improvement fuzzy rule-based meta-schedulers performance in grid computing. KASIA was introduced in Prado et al. (2010b) , where its efficiency as a general learning strategy for FRBSs and feasibility for its application to grid computing scheduling was shown. In this work, KASIA robustness as an expert knowledge acquisition strategy for grid computing environment is proved in terms of several optimization criteria. Furthermore, a wide range of classical scheduling strategies, including genetic fuzzy rule-base d schedulers, are considered for comparison and many relevant grid performance indexes are used for its analysis.

The remainder of the paper is organized as follows. Section 2 presents an overview of scheduling strategies in grids and the existing learning strategies for FRBSs. The proposed meta-scheduler structure and general operation together with the definition of the knowledge acquisition method for expert grid computing schedulers, KASIA are introduced in Section 3 . Section 4 focuses on simulations results of the proposed schema and it provides a comparison with traditional schemas. Finally, Section 5 concludes the paper. 2. Background
The capability of providing QoS is one of the striking aspects of grid scheduling. As stated in Xhafa and Abraham (2008) , a grid is a fully dynamic environment with uncertainties , i.e., the grid state is subject to changes at any time and little assumption can be made in relation to future resources and jobs parameters. In grids machines actually running jobs may suddenly fall down or new machines appear, jobs execution time may be wrongly estimated in their submission or resources sharing policies may change with time ( Foster and Kesselman, 2003 ). Hence, any acquired knowl-edge of the system state is inherently imprecise and guaranteeing certain levels of QoS in terms of time (i.e. flow-time , tardiness , slowdown , average weighted response time, average weighted wait-ing time ), resource utilization (i.e classic usage , weighted usage )or jobs constraints (i.e. jobs deadlines ) is a major challenge.
Most of today X  X  production systems such as LSF ( Xu, 2001 ), PBS ( Nitzberg et al., 2003 ), Condor ( Thain et al., 2005 ) and other grid meta-scheduling systems like Grid Service Broker ( Venugopal et al., 2004 ) or GridWay ( Huedo et al., 2005 ), found their planning on queue-based scheduling strategies. Queued-based scheduling have proved to be able to satisfy simple performance objectives in grids and they are consolidated as the de facto standard nowa-days. However, at the advent of the growing demand for complex
QoS performance criteria, such as the ones mentioned above, queued-based strategies have been forced to resort to other supporting techniques such as advanced reservation ( Klusacek and Rudova, 2008 ). Nevertheless, queued-based schedulers are unable to cope with a large amount of reservations. Specifically, it is studied that the number of reservations overtaking a system established boundary leads to a resource usage detriment and the starvation of jobs with no reservation requirements. Hence, more flexible scheduling strategies are pursued. Adaptive scheduling techniques suggest the consideration of both current and future state of the grid in order to avoid and prevent performance degradation ( Xhafa and Abraham, 2008 ). In this sense, sched-uled-based techniques base their planning on the consideration of a  X  X  X nown X  X  actual state of the grid environment and this way, allows a more accurate mapping of jobs and meeting of
QoS requirements. The  X  X  X nown X  X  actual state refers to available resources capabilities, jobs computational needs or even to the number of jobs. However, it is worthy highlighting here the grid state is imprecise by nature and that the advanced knowledge of these features is impossible, at least in a precise way. This uncertain state generally leads to schedule plans that do not correspond to real conditions. Notwithstanding, it is stated that a scheduling strategy aiming to provide a certain level of QoS has to consider a more or less accurate information of the grid state ( Klusacek, 2008 ). From here it can be derived that techniques able to react to the environment changes and imprecisions may be convenient, since obtaining a precise knowledge of the system parameters is not a feasible option.

When dealing with uncertainty, the role of FL has to be underlined. FL is essentially based on the idea that the human reasoning is naturally approximate and it provides a methodology for the representation of this fuzzy or imprecise knowledge in situations where a certain degree of vagueness must be tolerated ( Cordo  X  n et al., 2001 ). In this regard, FRBSs represent an extension of traditional rule-based systems that try to accommodate the classical engineering techniques precision and artificial intelli-gence interpretability and flexibility. FRBSs have been success-fully applied to a wide range of fuzzy modeling, control and classification problems ( Alcala  X  et al., 2005 ; Exposito et al., 2007 ) and they have recently attracted the researchers attention for their application to large-scale scheduling ( Franke et al., 2008 ; Prado et al., 2009 , 2010 ). One of the major advantages of FRBSs is associated to their capability to manage noisy or imprecise information which is available in dynamic systems.
 ( Cordon et al., 2001 ). Generally, the knowledge representation consists of the definition of linguistic variables and linguistic values in the form of fuzzy sets for the system variables.
Moreover, the available knowledge related to the efficient scheduling behaviour in the considered system appears in the form of fuzzy rules. A fuzzy rule is made up of an antecedent and consequent part.
On the one hand, antecedents represent the system input features and their associated linguistic label. As stated above, linguistic labels are assigned to every input feature among the ones described for the variable and these labels are associated to membership functions.
Note that the same input variab le may correspond to various possible linguistic labels, as it may belong to several differentiated fuzzy areas described by the membership functions. Hence, the fuzzy assignment takes into account the uncertainty associated to system input variables. On the other han d, consequents represent the output features linguistic labels that define the desired contribute decision of the rule. Furthermore, the connector joining antecedents (i.e., additive or exclusive operator) must be defined for a fuzzy rule.
As it can be inferred, the successful performance of FRBSs strongly depends on the quality of their knowledge or fuzzy RBs. Since the derivation of RBs though experts is not always possible in most of existing applications, due to the lack of experts in the field or because they provide a partial or incomplete description of the system, automatic learning strategies have been extensively studied.
Several approaches based on neural networks and evolutionary strategies have been applied. In the field of evolutionary learning strategies, the importance of GAs is to be underlined ( Alcala  X  et al., 2009 ; Chung et al., 2009 ; Garcia et al., 2009 ). Genetic Fuzzy Rule-Based Systems (GFRBSs) ( Cordo  X  n et al., 2001 ) employ
GA-based strategies for the evolution of theirs fuzzy rules such as Pittsburgh ( Smith, 1980 ) and Michigan approaches ( Booker et al., 1989 ).
 fuzzy rule-based scheduler is suggested in order to faster and more accurately provide of high quality RBs. Specifically, the suggested learning strategy consists of the adaptation of the well-known Swarm Intelligence strategy known as PSO ( Kennedy and
Eberhart, 1995 ). PSO is a stochastic optimization technique initially introduced as a way of representi ng birds choreography within a flock. The goal is to find the position for each individual, known as  X  X  X article X  X , within the consi dered search space where a fitness function f describing the desired behaviour of the system is optimal: f : R N -R  X  1  X 
Hence, at the beginning of the alg orithm, particles are randomly distributed within the n-dimensional search space R N in position x and they are associated an initial velocity v . At every iteration k the fitness function f is calculated for every particle i and its position and velocity are updated on the basis of this value. To be precise, the velocity of every particle is modified considering three different components; the inertial component , the self-recognition term or inner tendency to return to its best position and the social component or tendency to reach the best position found by its neighbours. In a mathematical way, this can be expressed as follows: where d 1 , d 2 are constant weight factors, Pb i represents the best position achieved so long by particle i , Gb i is the best position found by the neighbours of particle i , r 1 , r 2 denote random factors in the [0,1] interval and o represents the inertial weight. It is worth mentioning here that the advantages of PSO over GAs are two fold. On the one hand, PSO configuration is much simpler. In contrast to
GAs where the combination of genetic operators, namely, selection rate, cross-over and mutation, leads to a wide range of configura-tions, PSO performance is uniquely driven by velocity ( Carlisle and
Dozier, 2001 ). This way, the reduction of parameters is generally translated to a reduced computational effort and setting time. On the other hand, the ability of PSO to control convergence has to be underlined ( Robinson and Rahmat-Samii, 2004 ). It is known that inertial weight o can control the converge and stagnation level.
Whereas in GAs strategies stagnation occurs where every individual present the same genetic code and genetic operators have no effect,
PSO can prevent or even control this situation. Specifically, high values for o allow particles to remain in a sawing motion around its final position and near optimal positions may be found. In the following section, a scheduling s chema for grid computing based on FRBSs and its associated learning strategy founded on PSO are described. 3. Fuzzy meta-scheduler based on knowledge acquisition with a swarm intelligence approach (KASIA)
The goal of the fuzzy rule-based meta-scheduler is to allocate domains RD j within a grid virtual organization VO  X f RD 1
RD 2 , ... , RD G g . Each RD j is made up of a set of H j heterogeneous computational machines RD j  X f r j , 1 , r j , 2 , ... , r lers driving theirs internal scheduling processes and access policies. Jobs may differ in the requested number of processors, requested memory, deadline times and other machines features, such as the operating system or CPU types. Moreover, jobs may dynamically appear (i.e., different submission times) and they must be included into the schedule. On the other hand, resources nodes or domains RD j are characterized by the number of machines H j , the total number of CPU, operating system and
RAM size of each machine. Also, resources may fail down or new ones offer their capabilities during the schedule. The meta-scheduler is responsible for the assignment of jobs to the different domains and performance is evaluated in consideration of several criteria. Specifically, in this work, the schedule performance is measured from the point of view of users and resource adminis-trators. QoS in the perspective of users considers the achieved results in terms of makespan , flow-time , average weighted response time ( awrt ), average weighted slowdown ( awsd ), slowdown , tardi-ness, wait time and number of delayed jobs whereas resources administrator performance evaluation attends to classic and weighted usage of machines.

The operation of the proposed FRBS-based meta-scheduler is founded on the fuzzy reasoning applied to the system available information or system state with the aim of coping with the inherent uncertainty of the grid and obtain a more precise knowledge of the environment. In this sense, the problem of efficiently describing the grid state must be firstly discussed.
There may exist many features in a grid system that can be relevant to the scheduling process and this way the system state for the fuzzy scheduler may be characterized considering several features. In this work, we suggest seven variables for describing the grid actual conditions as shown in Table 1 . It is observed that every resource domain state at every schedule is given by variables concerning both actual state of machines usage (i.e. FPE or RE) and results provided through the scheduling time up to the moment (i.e PT, RM, RT, PS and RS). Thus, not only each resource domain is characterized by the actual resource condi-tions but also by performance evolution of such resources over time. This way the fuzzy meta-scheduler has a broader and more flexible description of its domains than the consideration of the processing elements availability. It is to be noted that a more exhaustive description of the grid system may require the consideration of a wider number of features. However, the difficulty of finding good rules increases with a high number of features, i.e., with the expansion of the search space. With the considered input variables, this work tries to reconcile a precise description of the dynamic grid system state and the effort of the learning processes.

The general structure of the fuzzy meta-scheduler follows the classical schema of Mamdani fuzzy logic systems ( Cordo  X  n et al., 2001 ). There exist three main components: the fuzzification system , the inference system and defuzzification system . The joint operation of these systems provides a resource domain selector factor y o for every resource domain RD j on the basis of its state shows the level of suitability for its associated RD selection. Initially, the fuzzification interface addresses the task of convert-ing the crisp input values characterizing the RD state into fuzzy values to be used in the inference phase. Specifically, in the fuzzification interface, the initial steps are to consider inputs and to obtain the degree to which these inputs belong to each rule fuzzy sets through the use of membership functions. A member-ship function m  X  x  X  A is generally described as a curve that specifies the mapping of each point from the input space to a degree of membership in the range from 0 to 1 and describes contour of its corresponding fuzzy set in A i . Thus, the fuzzification operation can be formulated as follows: A  X  F  X  x o  X  X  4  X  where x o denotes the crisp values for the input features x  X  x , ... , x n  X  X  X  FPE , PT , RM , RT , PS , RS , RE  X  for RD input set of the possible ones A i  X  X  A i , 1 , A i , 2 , ... , A identifier and n the considered number of input features for the fuzzy meta-scheduler. To be precise, in this work n  X  7. Also, F corresponds to the fuzzification operator. The fuzzification operator allows the mapping from crisp input values to fuzzy sets defined in the universe of discourse of that input. To be precise, Point wise fuzzification is one of the more extended fuzzification operators, generally presented in Eq. (4), and it is considered here, where the fuzzy sets A i  X  X  A i , 1 , A i , 2 built as singletons with support x o ( Cordo  X  n et al., 2001 ), i.e., it presents the following form: A  X  x  X  X  Besides, the inference phase is responsible for the mapping of rules associated input fuzzy sets A i to output fuzzy sets. Once the inputs are fuzzified, the degree of membership to which every antecedent component is satisfied for every rule m  X  x m  X  In the inference stage, a conjunctive fuzzy operator is applied to determine a membership value that indicates the overall result of the membership values previously obtained in the fuzzification step and the output is a single value or membership for every rule. This operation can be formulated as: m  X  rule i and T represents the conjunctive fuzzy operator ( Cordo  X  n et al., 2001 ). After a truth value has been associated to each rule the implication operator is responsible for reshaping rules consequents. A consequent is a fuzzy set described by a member-ship function that weights the linguistic labels that are associated to it in the antecedent. Thus, the input to this process consists of a single membership value (obtained in the intersection process) m  X  and the rule consequent associated membership function m  X  , and the output is a fuzzy set B 0 i described by membership m  X  is pursued for every rule i : m  X  where y denotes the output variable and I represents a fuzzy implicator operator. Next, converting the output sets into a final crisp value y o or RD selector factor is entailed by the defuzzification system. As described above, decisi ons are founded on the analysis of every rule of the expert system knowledge base as individual.
However, in order to obtain a final crisp decision, rules contribution must be first joined. The combinat ion of output fuzzy sets of every rule into an overall output fuzzy set, is done in the aggregation process. The input for this process is made up of the output sets obtained in the implication process for each rule B 0 i (described by single fuzzy set B 0 (described by membership function m  X  y  X  output variable. Since in this work, the fuzzy meta-scheduler only considers one output variable, a single fuzzy set is obtained at the end of the process. The a ggregation operation can be formulated as: m  X  where G represents the aggregation operator. To be precise, the defuzzification system of the fuzzy meta-scheduler considers the
A-FATI strategy ( Cordo  X  netal.,2001 ) (i.e. first aggregate each rule contribution, then infer output). That is, the individual membership m  X  by means of a fuzzy aggregation operator G , before the final crisp value is obtained. Finally, a defuzzification method is applied in other to obtain a crisp output value y o from the resulting member-y  X  D  X  m  X  y  X  B 0  X  X  9  X 
In this work, we suggest the  X  X  X enter of gravity X  X  D defuzzifica-tion method since it is extensively used in literature ( Cordo  X  n et al., 2001 ): y o  X 
As stated before, the crisp output value y o represents the selection factor for the considered RD. Selection factors for the rest of RDs are calculated in following iterations and the process is repeated in every schedule step. The meta-scheduler organization is depicted in Fig. 1 . As it is shown, the KB drives the reasoning stage and its composition is considered critical for the whole scheduler successful performance. In this sense, two major problems are distinguished. On the one hand, fuzzy sets for the system variables must be specified. On the other hand, the variables relations or fuzzy rules must be learned. Next subsections address these two issues. Furthermore, in order to clarify the operation of the meta-scheduler an example of application is presented. 3.1. Knowledge representation antecedent part corresponds to the rules activation condition whereas the consequent represent s the output contribution to the final selection factor for RD j . Within this work, we consider the output to be conducted by fuzzy sets, i.e., a Mamdani codification is considered for the rules and no analytical functions are employed in consequents as in the case of Takagi, Sugeno and Kang approach ( Takagi and Sugeno, 1985 ). A rule R i is represented as
R i  X  IF x 1 is A i , 1 and = or ... x n is A i , n THEN y is B where  X  x 1 , ... , x n  X  denotes the input grid features and A the associated fuzzy sets for feature x m and output for rule i , respectively. As it can be inferred, A i , m and B i correspond to one of the possible NF in fuzzy sets for input and NF out for output, respec-tively. System features were described in Table 1 .Furthermore, features descriptions are given by the definition of their member-ship functions. In this work, we consider Gaussian functions which are generally formulated as: m  X  i  X  z  X  X 
As it is shown, these membership functions are driven by two aimthatbringsustouseGaussianfunctionsisgivenbythesmooth transition between different fuzzy areas. Moreover, Gaussian area of influence is extended to all the universe of discourse, as derived from the properties of gaussian functions. This is a desirable characteristic forthesysteminordertobeablet oprovideacontributioninawide range of syste m conditions ( Franke et al., 2008 ). Fig. 2 represents the fuzzy sets for the normalized input features and output. Note that inputs variables are characterized by three fuzzy sets representing low , medium and high values within the input domain whereas output or selector factor relevance is described by five fuzzy areas, namely very low , low , medium , high and very high . Hence, a rule can be mathematically expressed as
R  X f m  X  x 1  X  i  X  x  X  , m  X  x 2  X  i  X  x  X  , ... , m  X  x n  X  where O i denotes the recommendation vector, that includes the associated output set, input sets connective and rule weight. 3.2. Example of application
In order to clarify the fuzzy reasoning strategy of the scheduler and the concepts introduced above, an example and a diagram are included. Let the RB of the expert system consist of two rules ( Table 2 ) with the structure presented in Eq. (11) for input variables shown in Table 1 . Also, let the meta-scheduler input be x 0.335, 0.652, 0.3416, 0.5693, 0.2402, 0.7206) corresponding to the seven considered input features describing a RD state. First, the fuzzification stage is responsible for obtaining the degree of member-ship of every input with respect to rules antecedents. The associated associated degree of membership in Table 3 )consideringthesets presented in Fig. 2 . Next, the min or AND method ( T operator) is used to obtain a truth value for every rule in the RB considering every antecedent contribution and results in Table 4 are obtained (Eq. (6)). Then, the inference system applies the implicator operator on each individual linguistic rule to obtain the inferred fuzzy sets 0  X  y  X  as shown in Table 5 (Eq. (7)), where min is the implicator I operator. The operation of the inference engine is graphically shown in Fig. 3 which depicts the membership functions m B from the inference step. Finally, the defuzzification interface aggre-gates the two individual output fuzzy sets by means of the maximum aggregation operator (Eq. (8)) as indicated in Table 6 .Andit defuzzifies the resulting aggregated fuzzy set by means of the  X  X  X enter of gravity X  X  strategy, as presented in Eq. (10), thus obtaining the final value y o  X  0 : 638 that indicates the level of suitability for the considered RD to be selected (vertical bar in Fig. 3 ). The whole fuzzy reasoning process is illustrated in Fig. 3 . Once the rules codification and reasoning of the fuzzy scheduler have been presented, a new method for automatically learning fuzzy rules is described. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.2 0.4 0.6 0.8 1 m m m 3.3. Knowledge acquisition novel strategy: knowledge acquisition with a swarm intelligence approach ( KASIA ). The learning strategy is based on the adaptation of PSO to the evolution of fuzzy rules in fuzzy rule-based meta-scheduler. Within this approach the swarm is made up of NP particles, each particle P i representing a whole RB and the goal is to find the optimum position for particles or higher quality RB.
I.e., the rule set that obtains the optimal value of a selected fitness f which is desirable for the scheduling system. Every rule base RB or particle P i within this approach is formulated as:
P i  X  where every row represents the codification of a fuzzy rule and n , m denotes the number of input variables and rules, respectively.
Antecedents a i j , k are encoded as a entire number in the interval: a i j , k A  X  NF in , NF in , j A f 1 ; 2 , ... , m g , k where NF in represents the number of fuzzy sets for input j , corresponding to three in the proposed schema. Analog reasoning can be followed for the consequents b j i with NF out representing the number of output sets (i.e. five in this work): b i j A  X  NF out , NF out , j A f 1 ; 2 , ... , m g X  16  X  NF in , NF out A N  X  17  X  Moreover, the connectives are encoded considering two values.
AND connective is depicted by  X  X 1 X  X  and  X  X 2 X  X  represents the OR operator: c i j A f 1 ; 2 g X  18  X 
At the beginning of the algorithm each particle or RB is randomly generated and it is also associated to a random velocity matrix V .

In PSO, velocity is employed as to update the particles position. In this work, velocity matrix conducts each RB modification:
V  X  v where V min and V max represent the boundaries for velocity. Some remarks must be made about V min and V max . As can be derived from Eqs. (2) and (3) every particle in PSO updates its position on the basis of its own inertia, its own experience, the social experience, within the search space. To be precise, particles look for solutions in the search space in a bounded range  X  s , s .In our approach, space is divided into three subsections as it is shown in particle or RB representation, Eq. (14), corresponding to antecedent, consequent and connector search spaces. Thus, the search space is specified by Eqs. (15), (16) and (18) for each component of the RB, respectively. Furthermore, with the aim of effectively guiding particles in the search space, the maximum movement velocity in a single iteration must be limited to a range [ V and Kennedy (2002) , explosion has traditionally been contained through implementation of a V max parameter, which limits step size or velocity. This way, velocity must satisfy ( Liuetal.,inpress ): v The value for V max is generally defined as p s ,with0 : 1 r p r 1 : 0.
Within our approach, we select p in a way that V max equals the unity for every element in the matrix, i.e., p  X  1 = 3forantecedents, p  X  1 = 5 for consequents and p  X  1 = 2forantecedents.

Algorithm 1. Knowledge acquisition with a swarm intelligence approach, KASIA.

Initialization 1. Swarm: Num_particles, RB_Num_rules ( m ), 2. Random setting of RB-Swarm position 3. Random setting of velocity. 4. Velocity Constraints. Eq . (20) 5. Initialize Gbest( P n )/Pbest( P # ) for (Num_iter) for (Num_particles) endfor
Update Gbest ( P n ) for (Num_particles) endfor iter  X  X  endfor Return solution: Gbest ( P n ) Hence, at every iteration t  X  1, a fitness is obtained for every RB and the velocity matrix is recalculated by the following expression: V  X  t  X  1  X  X  w V i  X  t  X  X  c 1 n r 1  X  X  P #  X  t  X  P i  X  t  X  X  where and denote the multiplication and sum of matrices, respectively, P #  X  t  X  represents the best acquired RB of particle P and P n  X  t  X  depicts the best RB found in the whole swarm through iterations in terms of the considered fitness f . This way, each particle P i , updates its position considering the actual value of its RB or inertial factor and the global and local best suited RB stored though swarm evolution: P  X  t  X  1  X  X  P  X  t  X  i V i  X  t  X  1  X  X  23  X  This process must be repeated until the stopping condition is fulfilled. As can be found in literature about Fuzzy Rule-Based Systems learning in massive parallel processing environments, determining the stopping condition of evolutionary algorithms is generally based on statistical analysis of the system behaviour within the specific environment ( Franke et al., 2007 ). Within this approach the stopping condition is set to a number of iterations. Also, it is relevant to underline that antecedents, consequents and connectives may exceed the search space as a consequence of the updating process. Thus, in order to keep the RBs coherence a set of constrains are imposed for these components at the end of every iteration: a b c  X  Also, as it can be derived from Eqs. (22) and (23) the proposed strategy involves the usage of fixed size RBs which must be initialized at the beginning of the algorithm. Finally, two remarks must be made. On the one hand, rules considering no premise part are considered to be nonsense (i.e. they suggest a controller response independently of the grid system state). Hence, in the advent of this occurrence, rules must be initialized: if
On the other hand, it must be stated that this algorithm does not consider the fuzzy sets alteration. Therefore, the rules inter-pretability is not modified through the learning process. The suggested schema is summarized in Algorithm 1.

As it can be derived from this section, the grid inherent dynamism and uncertainty is addressed in two ways. On the one hand, the meta-scheduler makes a fuzzy characterization of the grid state and on the other hand, it considers its adaptation to changing conditions by a learning mechanism. As introduced in
Section 2 , in order to provide some QoS degree grid scheduling, the scheduling process must concern the state of resources.
However, the dynamic nature of grids makes it no feasible to obtain an accurate characterization of this state. In part, this uncertainty may result from the fact that resources sharing policies may change over time according to several criteria imposed by organization they belong to, failures, or dynamic applications that may also be running in its associated resource domain (note resources are generally non-dedicated resources for a VO they participate in). This way, a grid scheduler can greater benefit from fuzzy logic. On the other hand, the dynamism of grid structure and applications is considered in the learning process of the meta-scheduler. In the grid it is possible that the character-istics of jobs associated to applications vary over time and also that the structure is altered either by the absence or addition of domains or resources, changes in access policies or failures.
Thereby, a significant modification of environmental conditions with respect to those the system had been trained with can lead to a loss of quality of the expert system knowledge. Hence, the proposed scheduler has been provided with the ability to adapt to this dynamism by considering learning processes that are able to improve the quality of its scheduling. 4. Simulation results and discussion 4.1. Scenario specification
Several tests have been conducted to evaluate the proposed scheduling scheme. Specifically, t he scheduler is tested through simulations with Alea software ( Klusacek et al., 2008a )inits 2.1 version, released in October 2009. Alea is a grid scheduling simulation toolkit based on GridSim that allows the utilization of grid scenarios and traces from real world. In our tests, the grid environment is based on Czech Na tional Grid Infrastructure
Metacentrum project (  X  Sustr et al., 2009 ). Metacentrum is a CESNET (operator of academic network of the Czech Republic -National
Research and Education Network , NREN) project whose goal is to allow the development of a virtual supercomputer or distributed high performance computing infrastructure by the sharing of a number of academic and research ins titutions resources around the world. Its activities include research on resources virtualization and management of grids. Moreover, Metacentrum has cooperated in international Grid projects such as EGEE III, EuAsiaGrid and EGI_DS. In our simulations, 14 Metacentrum nodes made up the grid system.
Table 7 shows the cluster nodes main features. It is observed that the grid integrates 806 CPUs of heterogeneous types (i.e. Opteron and Xeon) and speed (i.e. 1500 X 3200 MHz) distributed in 210 machines running Linux with RAMs capability ranging from 1,005,000 to 131,182,840 KB. Furthermore, machines queues configuration parameters, machines maintenance and reservation behaviour, and jobs characterization are obtained from traces of
Metacentrum facilities collected from January to May 2009 that are available at ( Infrastructure, 2009 ). This way, different priority queues are included in the scheduling for the incoming jobs where different time limits are considered following Metacentrum setting ( Infrastructure, 2009 ). Thus, if a job execution time exceeds the queue limit it is rejected. Also, machines or nodes may fall down, become dedicated or reserved during the simulation.
 simulations by the consideration of Maintenance &amp; Reservations &amp; Dedicated machines traces obtained from the Metacentrum facilities. Maintenance &amp; Reservations &amp; Dedicated machines trace include information about the changes in performance of every grid machine through time due to failures, reservation, dedication or unavailability caused by changing condition or sharing policies. To be precise, these traces specify the time when a machine becomes failed/reserved/dedicated/unavailable, the name of the associated cluster or resource domain, the duration of the failure/reservation/dedication/unavailability and the iden-tifier of the machines that are affected by the failure/reservation/ dedication/unavailability within that cluster. This way, the uncer-tainty and vagueness of the grid is given by the changing performance of machines through time that is retrieved from real conditions in the grid.
 required properties for the target resource in order to satisfy compatibility such as the time limit for the execution (given by the queue or user), the required machine architecture, the demanded software licenses, the operating system, the network type or the file system. Thus, a job represents a user X  X  application associated to an arrival time and computational need which can require a single (i.e., sequential) or more CPUs (i.e, parallel).
Several machines within the same cluster or site can be co-allocated to execute a given parallel job but machines belong-ing to different clusters can not be co-allocated to process the same parallel job. To be precise, jobs featuring is obtained from jobs traces that indicate the following parameters of every considered job: job identifier (job ID), associated job user or owner priority, list of properties to be met in the target machine (i.e. number of CPU, CPU type, operating system, etc.) and arrival spite of the fact that the used traces are those provided in
Infrastructure (2009) , involving a total of 103,656 jobs (which include a 5-month period from January to May 2009), the number of jobs has been limited to 2000 to reduce computational effort.
Specifically, jobs are retrieved in chronological order of Metacen-trum traces starting on 1st January 2009. This choice allows evaluating the scheduling system in diverse load conditions of the grid system, i.e., periods of low, moderate and high load and further, Maintenance &amp; Reservation &amp; Dedicated machines traces are available, what makes it possible to simulate real grid conditions. Hence, bearing in mind learning and validation processes analysis and jobs and Maintenance &amp; Reservations &amp;
Dedicated machines traces, four different traces are used in this work. Specifically, in validation, jobs traces are modified, i.e., load on the grid is increased by a 16.17%, 2400 jobs) and traces of
Maintenance &amp; Reservations &amp; Dedicated machines are altered, thus changing the grid dynamism. 4.2. Optimization criteria
Since the fuzzy scheduling strategy performance highly depends on the quality of its RB, firstly the training of the meta-scheduler by the proposed learning strategy, KASIA, is addressed.
For the learning process, two performance indexes are consid-ered; makespan and average weighted response time ( awrt ). Hence, on the one hand, the minimization of the latest job finalization time or makespan is pursued in this stage ( Xhafa and Abraham, 2008 , 2010 ) where T j indicates the time when job J j finishes, Sched represents all the possible schedules and J denotes the set of considered jobs as presented in Section 3 . On the other hand, the fuzzy meta-scheduler is also learned with awrt as performance index: with o j and R j representing the weight and submission time associated to job j , respectively. Makespan is a general productiv-ity indicator index. Reduced values for this index are translated into good and efficient scheduling of jobs to resources ( Xhafa and
Abraham, 2008 , 2010 ). Furthermore, this metric is selected as performance index in the learning strategy since it is easy to graphically represent this index together with extended used performance criteria such as cluster usage, number of waiting/ running jobs or machine usage and thus to analyze the overall grid system performance bearing in mind the learning index, as it will be shown later. On the other hand, awrt is a critic metric for interactive grid applications and it is selected to prove the scheduling strategy efficiency when the expert system is trained with an index with opposed interests to makespan . Hence, as it can be inferred, the fuzzy meta-scheduler is analyzed not only in case the productivity or throughput is the scope of the grid scheduling but also in case it is relevant to provide a schedule with an acceptable QoS. The joint selection of these metrics in scheduling can be found in literature ( Monte and Pattipati, 2002 ; Xhafa and Abraham, 2008 , 2010 ). 4.3. Analysis of the learning of the scheduler performance
First, it must be pointed out that to test the efficiency of fuzzy scheduling with KASIA, a comparison to fuzzy scheduling concern-ing a fuzzy genetic strategy, namely, Pittsburgh approach, is made. Thus, this paper presents a comparison of presented fuzzy rule-based meta-scheduling sys tem with KASIA learning with a fuzzy rule-based scheduling system with Pittsburgh learning. Note the choice of this comparison has been founded on the works of Franke et al. (2007) where a fuzzy rule-based scheduling system based on the genetic learning of rules with Pittsburgh for massively parallel computing environments is proposed. Also, the comparison is based on authors previous works ( Prado et al., 2010c , 2009 )where fuzzy rule-based schedulers with Pittsburgh learning are presented for grid computing specifically. Also, note that contrary to other genetic learning strategies such as Michigan, where a single RB is evaluated at every generation, a selected population of RBs is evaluated at every generation in Pittsburgh approach. This is also the case of KASIA where a fitness value for the set of particles or RBs making up the swarm is obtained at every iteration. Therefore, the evolution of learning during the training can be fairly compared at every iteration in terms of compu tational effort. Computational effort in this work is measured in number of RB evaluations. Pittsburgh learning strategy evaluates the whole population in the first generation and then it evaluates a number of individuals in consideration of selection rate l . Computational effort for Pittsburgh approach can be formulated as follows: CE
Pitts  X  PS  X  PS n l n  X  num iter 1  X  X  30  X  where PS denotes the number of individuals or RB population size, l represents the selection factor and num iter is the number of iterations or stopping condition. On the other hand, in KASIA every particle is evaluated at every iteration and thus computational effort can be expressed as: CE with NP denoting the size of the swarm. It must be underlined here that the presented computational effort is associated to the learning strategy. However, as stated in previous section, the execution cost of the proposed meta-scheduler str ategy in runtime corresponds to that of fuzzy logic systems.

Tables 8 and 9 summarize the setting for KASIA and Pittsburgh learning strategies, respectively. The swarm within KASIA comprises 18 RBs of 10 rules and inertial weight o is fixed to 0.9.
Also, random factor r follows a decreasing exponential expression: where r denotes random factors r 1 and r 2 , r 0 represents the maximum value for r (fixed to 1), c is constant fixed to 5 in our simulations ( c  X  5 makes it possible for o to achieve a reduced value just in the last iterations what helps to prevent the early stagnation of particles in the global search at the same time it allows to make a fine search of good solutions around final positions or local search in the last iterations, and this way, global search are favored at first iterations and a deepest exploration of the reached locations is allowed at the end of the iterations). As it is shown in Table 9 ,
Pittsburgh learning is configured with elitist selection operator, two-point crossover and decreasin g mutation rate. Training with both strategies is done for 100 iterations where the scheduler has to address the allocation of 2000 jobs in Metacentrum scenario. As introduced in Section 3.3 , the KASIA learning strategy requires a fixed size for the particles which must be initially determined. Furthermore, the specification of the boundaries for the size of
Pittsburgh bases is needed. It must be pointed out that initialization of these parameters is based on pr evious works in the configuration of the learning of fuzzy schedulers in grid contexts ( Prado et al., 2010a ). Also, the stopping condition has been determined by the analysis of convergence of the learning strategies.

The learning evolutions for the different strategies are shown in Figs. 4 and 5 . These figures illustrate the learning process considering makespan and awrt as fitness where values corre-spond to the best solution average of 30 experiments at every iteration. It can be observed that converge behaviour of both genetic and swarm-based strategies are very similar in the beginning of the learning process. However, from this point on,
KASIA quickly converges to its final value in both learning processes with makespan and awrt as fitness. To be precise, in the knowledge acquisition process with makespan , Fig. 4 ,
Pittsburgh approach requires 78 generations to achieve its final convergence value. In contrast, KASIA requires 64 iterations to converge. Thus, on average, KASIA needs 252 RB evaluations less than the genetic strategy what is translated in a more reduced computational effort and training time. Further, KASIA final result outperforms Pittsburgh approach in 2.23% on average as presented in Table 10 .

Also, the best makespan achieved by KASIA improves the best achieved by Pittsburgh by 4.61%. That is, the fuzzy scheduler with
KASIA learning is able to complete the submitted jobs in approxi-mately 20 h and 52 min before than the fuzzy scheduler with genetic learning. Moreover, the better performance of the KASIA strategy is supported when the fuzzy meta-scheduler is learned with an index presenting an opposite scope to makespan , i.e., awrt , and results are analyzed as follows. As shown in Fig. 5 , KASIA requires approximately 54 iterations to reach convergence whereas Pittsburgh needs 69 generations. Hence, KASIA compu-tational effort reduces Pittsburgh X  X  in 15 iterations or 270 RB evaluations. Also, as presented in Table 11 KASIA improves
Pittsburgh final result by 1.04% and 2.99% on average and best result, respectively. Thus, it is shown that KASIA learning strategy accomplishes a deeper exploration of the search space in compar-ison to the genetic strategy and provides a faster learning and more accurate RBs. 4.4. Validation 4.4.1. Analysis of the fuzzy scheduler performance
With the aim of more exhaustively evaluating the meta-scheduler performance within the grid environment, test the quality of the obtained RBs and validate results, the fuzzy scheduler is tested in eleven metrics, namely, makespan, flow-time, number of delayed jobs, weighted usage, classic usage, tardiness, wait time, slowdown, awrt and awsd in a modified Metacentrum scenario. To be precise, load obtained from
Metacentrum data sets 2009 ( Infrastructure, 2009 ) is increased by 16.67% (a total of 2400 jobs) and a modified machines failure and reservation behaviour is considered for the new Metacentrum-based scenario. Specifically, the validation scenario is based on a ran-dom modification following the study of Klusa  X  c  X  ek and Rudova  X  (2010) in a way that its objectivity is not compromised or it favors any of the different scheduling strategies. First, performance is presented for the fuzzy scheduler considering the 30 acquired RBs from by genetic-based and swarm-based learning processes in both makespan and awrt configurations. Table 12 shows average results (30 RBs) achieved by the fuzzy scheduler in both learning strategies and index configuration. As in the previous setting, the fuzzy scheduler with KASIA knowledge improves makespan and awrt results. With respect to meta-scheduler learned with make-span as fitness, it is observed that KASIA obtained makespan is 1.58% smaller than the one achieved by the fuzzy scheduler with
Pittsburgh. However, it is also observed that through KASIA learning the fuzzy meta-scheduler is not only capable of improv-ing the Pittsburgh training fitness, showing the strategy ability to achieve a deeper exploration, but also it outperforms on average in terms of weighted and classic usage by 3.66% and 4.77%, respectively. This is reasonable if it is considered that the learning process has been designed as to minimize makespan and the fuzzy scheduler learned with KASIA achieves a more accurate result.
Further, it is observed that a decrease in makespan is accompanied by an increase in resource utilization rates in every experiment.
On the other hand, as expected, there exists no significant difference between fuzzy scheduling with Pittsburgh and KASIA acquired knowledge in terms of flow-time , awrt or tardiness since they are not objectives of the learning process and present conflicting interests. Note an analog reasoning can be followed with awrt as optimizer. As shown in Table 12 , KASIA outperforms
Pittsburgh in validation scenario in terms of awrt . Furthermore, as it could be expected, the results of awrt obtained with the system trained with awrt as optimizer and KASIA improve the results in terms of awrt when the meta-scheduler is trained with makespan as optimizer and KASIA. However, as in the case of makespan as optimizer, this training goes in detriment of other metrics such as weighted and classic usage of resources and makespan . 4.4.2. Comparative with other classical scheduling strategies: grid performance criteria
The fuzzy rule-based scheduling trained with KASIA learning strategy (with both makespan and awrt as fitness) is compared to some of the most extended strategies in current grid systems, namely, EASY-BF, FCFS ( First Come First Served ), Earliest Deadline Fitness-Awrt (s) First-Backfilling ( EDF-BF ), ESG , ESG  X  Local Search ( ESG  X  LS ) and ESG  X  LS periodical ( Klusacek et al., 2008a , b , Klusacek and Rudova, 2008 ). Table 13 summarizes these scheduling strategies results in relation to the same metrics used to evaluate the fuzzy schedu-lers. First, results are analyzed bearing in mind makespan as optimizer. It is shown that the fuzzy meta-scheduler average performance in the training fitness, makespan , is 6.62% lower than the best of the other considered strategies in relation to this metric, EASY-BF and EDF-BF, and it reaches a 15.97% and 17.20% improvement in comparison to FCFS and ESG-based strategies, respectively. I.e., the training process through KASIA successes in providing a high quality RB in terms of the considered fitness as validation results prove. Further, it also improves weighted and classic usage by 7.71% and 20.81%, respectively, with respect to the best competitor in these metrics, EASY-BF . However, as expected, that makespan optimization causes a detriment in performance of metrics, such as flow-time , slowdown or tardiness . Moreover, results are analyzed considering KASIA meta-scheduler trained with awrt index. It is shown that awrt in this scheduler setting improves the rest of strategies at least by 25.82% (best competitor FCFS ). However, as expected, this result is translated into a reduction in fuzzy scheduler improvement in other metrics such as weighted and classic usage and makespan with respect to the non-fuzzy scheduling strategies.
 demonstrate the robustness of the acquired knowledge in dynamic conditions. It is shown that the fuzzy scheduler performs a more efficient scheduling than other traditional scheduling methods even when the workload is increased by 16.67% and the availability of systems for grid resources (i.e., failures, main-tenance and reservation behaviour) has been altered with respect to training. In any case, the incorporation of a learning system for the meta-scheduler prevents the loss of quality of the scheduling strategy at the advent of major changes in the conditions of the grid system. 4.4.3. Comparative with other classical scheduling strategies: time evolution of the scheduling strategies
Also, the evolution of the grid performance is graphically examined through the whole simulation in validation scenario.
Figs. 6 X 13 show the evolution of cluster usage , number of waiting and running jobs , number of request and used CPU and average usage for the suggested fuzzy meta-scheduler with best acquired
RB with KASIA, EASY-BF, FCFS, EDF-BF , ESG, ESG  X  LS, ESG  X  LS period-ical and fuzzy Pittsburgh scheduling strategy, respectively. To be precise, it must be pointed out that the fuzzy best knowledge is taken from the learning process considering makespan as perfor-mance index, since it can be presented simultaneously with the mentioned grid performance indicators in a direct way (horizon-tal axis of every graph corresponds to execution time where makespan can be differentiated). It is observed that the fuzzy approach achieves a high distribution of jobs among domains. As shown in Fig. 6 a, the majority of clusters reaches a high rate of utilization at least once during simulation and load is not concentrated in a set of clusters as it is the case of EASY-BF, FCFS and EDF-BF , Figs. 7 X 9a . Note that clusters 5 and 13 are not employed at all during the whole EASY-BF and EDF-BF scheduling processes. Also, it can be appreciated that the case when a whole cluster suddenly becomes available during the simulation has been considered. As it can be observed in Figs. 6 X 13a , cluster 11 initiates its operation in a given moment in day 14. Thus, the vagueness of sites as whole entities in addition to the uncertainty in single machines performance within clusters is borned in mind to test the performance of the schedulers.
 able to more efficiently cope with peaks of workloads than the rest of queue-based and scheduled-based strategies. An example of this can be found, in days from 8 to 11 where these strategies increment the number of waiting jobs. This can also be observed in days from 6 to 7 in the case of FCFS strategy, Fig. 8 b. In contrast, the fuzzy meta-scheduler is able to provide a schedule for a wider set of jobs when this peak appears. This is shown by the fact that no waiting jobs increment is experimented in that periods in contrast to the rest of strategies, Fig. 6 b. On the other hand, it can also be observed that when the workload is significantly high, such as in days from 13 to 15, there is no relevant difference among the different strategies behaviour. Further, as shown in
Fig. 6 a, the number of used CPUs matches the requested number of CPU in the fuzzy strategy up to the workload peak, that is from day 1 to 13, in contrast to FCFS, ESG, ESG  X  LS and ESG  X  LS periodical where an occurrence of a CPU request outranging available resources appears even not in the most demanding conditions, as observed in Figs. 8c, 10 X 12c . With respect to machine utiliza-tion per day, it is shown that the fuzzy KASIA meta-scheduler reaches its maximum at the event of workload peak (i.e. days 13 X 15), as it is also the case of the rest of strategies. However, it is to be noted that, that KASIA converge faster to this maximum than EASY-BF , EDF-BF and ESG (see Figs. 6d, 7d, 9d and 10d ), what proves the fuzzy scheduler adaptability to changing conditions.
Finally, the fuzzy scheduler with Pittsburgh knowledge results are presented in Fig. 13 . As shown, its evolution in terms of cluster usage , number of waiting and running jobs , number of request and used CPU and average usage approximately follows the patterns of the fuzzy scheduler with KASIA, Fig. 6 , what confirms the fuzzy schedul-ing strategy good general properties in spite of this learning strategy offering a less accurate performance in terms of the optimization criteria than the proposed swarm-based learning. 5. Conclusions
In spite of the existence of a large diversity in literature related to scheduling algorithms in computational grids, there are only a few efficiently dealing with the inherent uncertainty and dyna-mism of resources and applications of these systems. Further-more, the interest in satisfying both users and providers QoS requirements, such as tardiness or resource utilization, is increas-ingly demanding new adaptive scheduling strategies that considers both current and future state of the grid environment. Fuzzy Rule-Based Systems are knowledge based systems that are recently emerging as an alternative for the development of grid scheduling middleware. Their main strength resides in their adaptability to environment changes and their ability to model vagueness of grid state. However, since their performance strongly depends on the quality of its acquired knowledge, new automatic learning strategies are pursued. In this work, a FRBS-based scheduler for scheduling jobs in computational grids is suggested that incorporates a knowledge acquisition method based on Swarm Intelligence and learning results are compared with those of the classical genetic knowledge acquisition strategy, Pittsburgh approach. Further, conflicting performance indexes, makespan and average weighed response time have been used to train the expert system. It has been shown that KASIA reduces Pittsburgh convergence time with the same computational effort at the same time it improves its accuracy by 2.23% and 1.04% with respect to makespan and average weighed response time, respec-tively. Moreover, the fuzzy scheduling strategy has been com-pared to six extended scheduling systems in current installations, EASY-BF, FCFS, EDF-BF, EGS, EGS  X  LS and EGS  X  LS periodical and with a Pittsburgh FRBS scheduler. Resul ts show that the fuzzy scheduler outperforms the best of classical st rategies in the training fitness by at least 6.62% and it is able to achieve 7.71% and 20.81% higher rates of classical and weighed machine utilization, respectively. Acknowledgements
This work was supported by the Andalusian Business, Science and Innovation Council under project P07-TIC-02713, FEDER and the Spanish Ministry of Science and Innovation under Project TEC2009-14414-C03-02. The Metacentrum workload log was generously provided by the Czech National Grid Infrastructure Metacentrum.
 References
