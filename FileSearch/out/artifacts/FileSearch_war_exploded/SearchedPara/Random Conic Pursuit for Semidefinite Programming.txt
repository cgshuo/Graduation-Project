 Many difficult problems have been shown to admit elegant and tractably computable representations programs (SDPs) have appeared as the basis for many procedures in machine learning, such as sparse PCA [8], distance metric learning [24], nonlinear dimensionality reduction [23], multiple kernel learning [14], multitask learning [19], and matrix completion [2].
 While SDPs can be solved in polynomial time, they remain computationally challenging. General-purpose solvers, often based on interior point methods, do exist and readily provide high-accuracy solutions. However, their memory requirements do not scale well with problem size, and they typi-cally do not allow a fine-grained tradeoff between optimization accuracy and speed, which is often a desirable tradeoff in machine learning problems that are based on random data. Furthermore, SDPs in machine learning frequently arise as convex relaxations of problems that are originally compu-tationally intractable, in which case even an exact solution to the SDP yields only an approximate solution to the original problem, and an approximate SDP solution can once again be quite useful. Although some SDPs do admit tailored solvers which are fast and scalable (e.g., [17, 3, 7]), deriv-ing and implementing these methods is often challenging, and an easily usable solver that alleviates these issues has been elusive. This is partly the case because generic first-order methods do not apply readily to general SDPs.
 In this work, we present Random Conic Pursuit, a randomized solver for general SDPs that is simple, easily implemented, scalable, and of inherent interest due to its novel construction. We consider general SDPs over R d  X  d of the form where f and the g j are convex real-valued functions, and denotes the ordering induced by the PSD cone. Random Conic Pursuit minimizes the objective function iteratively, repeatedly randomly sampling a PSD matrix and optimizing over the random two-dimensional subcone given by this matrix and the current iterate. This construction maintains feasibility while avoiding the compu-tational expense of deterministically finding feasible directions or of projecting into the feasible set. Furthermore, each iteration is computationally inexpensive, though in exchange we generally require a relatively large number of iterations. In this regard, Random Conic Pursuit is similar in spirit to algorithms such as online gradient descent and sequential minimal optimization [20] which have illustrated that in the machine learning setting, algorithms that take a large number of simple, inexpensive steps can be surprisingly successful.
 The resulting algorithm, despite its simplicity and randomized nature, converges fairly quickly to useful approximate solutions. Unlike interior point methods, Random Conic Pursuit does not excel in producing highly exact solutions. However, it is more scalable and provides the ability to trade off computation for more approximate solutions. In what follows, we present our algorithm in full detail and demonstrate its empirical behavior and efficacy on various SDPs that arise in machine learning; we also provide early analytical results that yield insight into its behavior and convergence properties. Random Conic Pursuit (Algorithm 1) solves SDPs of the general form (1) via a sequence of sim-ple two-variable optimizations (2). At each iteration, the algorithm considers the two-dimensional cone spanned by the current iterate, X t , and a random rank one PSD matrix, Y t . It selects as its next iterate, X t +1 , the point in this cone that minimizes the objective f subject to the constraints g ( X t +1 )  X  0 in (1). The distribution of the random matrices is periodically updated based on the current iterate (e.g., to match the current iterate in expectation); these updates yield random matrices that are better matched to the optimum of the SDP at hand.
 The two-variable optimization (2) can be solved quickly in general via a two-dimensional bisection search. As a further speedup, for many of the problems that we considered, the two-variable opti-mization can be altogether short-circuited with a simple check that determines whether the solution X force  X  +  X  = 1 and therefore require only a one-dimensional optimization.
 Two simple guarantees for Random Conic Pursuit are immediate. First, its iterates are feasible for (1) because each iterate is a positive sum of two PSD matrices, and because the constraints g j of (2) are also those of (1). Second, the objective values decrease monotonically because  X  = 1 , X  = 0 is a feasible solution to (2). We must also note two limitations of Random Conic Pursuit: it does not admit general equality constraints, and it requires a feasible starting point. Nonetheless, for many of the SDPs that appear in machine learning, feasible points are easy to identify, and equality constraints are either absent or fortuitously pose no difficulty.
 We can gain further intuition by observing that Random Conic Pursuit X  X  iterates, X t , are positive weighted sums of random rank one matrices and so lie in the random polyhedral cones Thus, Random Conic Pursuit optimizes the SDP (1) by greedily optimizing f w.r.t. the g j constraints within an expanding sequence of random cones {F x t } . These cones yield successively better inner approximations of the PSD cone (a basis for which is the set of all rank one matrices) while allowing us to easily ensure that the iterates remain PSD.
 In light of this discussion, one might consider approximating the original SDP by sampling a random cone F x n in one shot and replacing the constraint X 0 in (1) with the simpler linear constraints X  X  X  x n . For sufficiently large n , F x n would approximate the PSD cone well (see Theorem 2 below), yielding an inner approximation that upper bounds the original SDP; the resulting problem would be easier than the original (e.g., it would become a linear program if the g j were linear). However, we have found empirically that a very large n is required to obtain good approximations, thus negating any potential performance improvements (e.g., over interior point methods). Random Conic Pursuit Algorithm 1: Random Conic Pursuit [brackets contain a particular, generally effective, sampling scheme] Input : A problem of the form (1) Output : An approximate solution X n to (1) p  X  a distribution over R d [ p  X  X  (0 ,  X ) with  X  = (1  X   X  ) X 0 +  X I d ] for t  X  1 to n do end return X n successfully resolves this issue by iteratively expanding the random cone F x t . As a result, we are able to much more efficiently access large values of n , though we compute a greedy solution within n rather than a global optimum over the entire cone. This tradeoff is ultimately quite advantageous. We assess the practical convergence and scaling properties of Random Conic Pursuit by applying it to three different machine learning tasks that rely on SDPs: distance metric learning, sparse PCA, and maximum variance unfolding. For each, we compare the performance of Random Conic Pursuit (implemented in MATLAB) to that of a standard and widely used interior point solver, SeDuMi [21] (via cvx [9]), and to the best available solver which has been customized for each problem. To evaluate convergence, we first compute a ground-truth solution X  X  for each problem instance by running the interior point solver with extremely low tolerance. Then, for each algorithm, we of the amount of time required to generate each iterate. Additionally, for each problem, we plot the value of an application-specific metric for each iterate. These metrics provide a measure of the practical implications of obtaining SDP solutions which are suboptimal to varying degrees. We evaluate scaling with problem dimensionality by running the various solvers on problems of different dimensionalities and computing various metrics on the solver runs as described below for each experiment. Unless otherwise noted, we use the bracketed sampling scheme given in Algorithm 1 with  X  = 10  X  4 for all runs of Random Conic Pursuit. 3.1 Metric Learning Given a set of datapoints in R d and a pairwise similarity relation over them, metric learning extracts a Mahalanobis distance d A ( x,y ) = p ( x  X  y ) 0 A ( x  X  y ) under which similar points are nearby and dissimilar points are far apart [24]. Let S be the set of similar pairs of datapoints, and let  X  S be its complement. The metric learning SDP, for A  X  R d  X  d and C = P ( i,j )  X  X  ( x i  X  x j )( x i  X  x j ) 0 , is To apply Random Conic Pursuit, X 0 is set to a feasible scaled identity matrix. We solve the two-variable optimization (2) via a double bisection search: at each iteration,  X  is optimized out with a one-variable bisection search over  X  given fixed  X  , yielding a function of  X  only. This resulting function is itself then optimized using a bisection search over  X  . Figure 1: Results for metric learning. (plots) Trajectories of objective value error (left) and Q (right) on UCI ionosphere data. (table) Scaling experiments on synthetic data (IP = interior point, RCP = Random Conic Pursuit, PG = projected gradient), with two trials per d for RCP and times in seconds. For d = 100 , third column shows f after 20 minutes.
 learning goal has been achieved: similar datapoints should be near each other, and dissimilar To examine convergence behavior, we first apply the metric learning SDP to the UCI ionosphere dataset, which has d = 34 and 351 datapoints with two distinct labels ( S contains pairs with identical labels). We selected this dataset from among those used in [24] because it is among the datasets which have the largest dimensionality and experience the greatest impact from metric learning in that work X  X  clustering application. Because the interior point solver scales prohibitively badly in the number of datapoints, we subsampled the dataset to yield 4  X  34 = 136 datapoints.
 dimensional data set, we first generate mixture centers by applying a random rotation to the elements from N (0 ,I d ) and assign it uniformly at random to one of two clusters. Finally, we set the first two components of x i to a random element of C k if x i was assigned to cluster k  X  { 1 , 2 } ; these two components are perturbed by adding a sample from N (0 , 0 . 25 I 2 ) .
 The best known customized solver for the metric learning SDP is a projected gradient algorithm [24], for which we used code available from the author X  X  website.
 Figure 1 shows the results of our experiments. The two trajectory plots, for an ionosphere data problem instance, show that Random Conic Pursuit converges to a very high-quality solution (with high Q and negligible objective value error) significantly faster than interior point. Additionally, our performance is comparable to that of the projected gradient method which has been customized for this task. The table in Figure 1 illustrates scaling for increasing d . Interior point scales badly in part because parsing the SDP becomes impracticably slow for d significantly larger than 100. Nonetheless, Random Conic Pursuit scales well beyond that point, continuing to return solutions with high Q in reasonable time. On this synthetic data, projected gradient appears to reach high Q somewhat more quickly, though Random Conic Pursuit consistently yields significantly better objective values, indicating better-quality solutions. 3.2 Sparse PCA Sparse PCA seeks to find a sparse unit length vector that maximizes x 0 Ax for a given data covariance matrix A . This problem can be relaxed to the following SDP [8], for X,A  X  R d  X  d : where the scalar  X  &gt; 0 controls the solution X  X  sparsity. A subsequent rounding step returns the dominant eigenvector of the SDP X  X  solution, yielding a sparse principal component.
 We use the colon cancer dataset [1] that has been used frequently in past studies of sparse PCA and contains 2,000 microarray readings for 62 subjects. The goal is to identify a small number of Figure 2: Results for sparse PCA. All solvers quickly yield similar captured variance (not shown here). (plots) Trajectories of objective value error (left) and sparsity (right), for a problem with d = 100 . (table) Scaling experiments (IP = interior point, RCP = Random Conic Pursuit), with two trials per d for RCP. microarray cells that capture the greatest variance in the dataset. We vary d by subsampling the readings and use  X  = 0 . 2 (large enough to yield sparse solutions) for all experiments. To apply Random Conic Pursuit, we set X 0 = A/ tr( A ) . The trace constraint (5) implies that tr( X t  X  1 ) = 1 and so tr(  X Y t +  X X t  X  1 ) =  X  tr( Y t ) +  X  = 1 in (2). Thus, we can simplify the two-variable optimization (2) to a one-variable optimization, which we solve by bisection search. The fastest available customized solver for the sparse PCA SDP is an adaptation of Nesterov X  X  smooth optimization procedure [8] (denoted by DSPCA), for which we used a MATLAB imple-mentation with heavy MEX optimizations that is downloadable from the author X  X  web site. We compute two application-specific metrics which capture the two goals of sparse PCA: high captured variance and high sparsity. Given the top eigenvector u of a solution matrix X , its captured qualitative inspection of the raw microarray data covariance matrix A .
 The results of our experiments are shown in Figure 2. As seen in the two plots, on a problem instance with d = 100 , Random Conic Pursuit quickly achieves an objective value within 4% of optimal and thereafter continues to converge, albeit more slowly; we also quickly achieve fairly high sparsity (compared to that of the exact SDP optimum). In contrast, interior point is able to achieve lower objective value and even higher sparsity within the timeframe shown, but, unlike Random Conic Pursuit, it does not provide the option of spending less time to achieve a solution which is still relatively sparse. All of the solvers quickly achieve very similar captured variances, which are not shown. DSPCA is extremely efficient, requiring much less time than its counterparts to find nearly exact solutions. However, that procedure is highly customized (via several pages of derivation and an optimized implementation), whereas Random Conic Pursuit and interior point are general-purpose. The table in Figure 2 illustrates scaling by reporting achieved objecive values and sparsities after the solvers have each run for 4 hours. Interior point fails due to memory requirements for d &gt; 130 , whereas Random Conic Pursuit continues to function and provide useful solutions, as seen from the achieved sparsity values, which are much larger than those of the raw data covariance matrix. Again, DSPCA continues to be extremely efficient. 3.3 Maximum Variance Unfolding (MVU) MVU searches for a kernel matrix that embeds high-dimensional input data into a lower-dimensional manifold [23]. Given m data points and a neighborhood relation i  X  j between them, it forms their centered and normalized Gram matrix G  X  R m  X  m and the squared Euclidean distances d 2 ij = G ii + G jj  X  2 G ij . The desired kernel matrix is the solution of the following SDP, where X  X  R m  X  m and the scalar  X  &gt; 0 controls the dimensionality of the resulting embedding: To apply Random Conic Pursuit, we set X 0 = G and use the general sampling formulation in Algo-rithm 1 by setting p = N (0 ,  X (  X  f ( X t ))) in the initialization (i.e., t = 0 ) and update steps, where Figure 3: Results for MVU. (plots) Trajectories of objective value for m = 200 (left) and m = 800 (right). (table) Scaling experiments showing convergence as a function of m (IP = interior point, RCP = Random Conic Pursuit, GD = gradient descent).
  X  truncates negative eigenvalues of its argument to zero. This scheme empirically yields improved performance for the MVU problem as compared to the bracketed sampling scheme in Algorithm 1. which preserves PSDness and ensures feasibility. The two-variable optimization (2) proceeds as before on  X  Y t and becomes a two-variable quadratic program, which can be solved analytically. MVU also admits a gradient descent algorithm, which serves as a straw-man large-scale solver for the MVU SDP. At each iteration, the step size is picked by a line search, and the spectrum of the iterate is truncated to maintain PSDness. We use G as the initial iterate.
 To generate data, we randomly sample m points from the surface of a synthetic swiss roll [23]; we set  X  = 1 . To quantify the amount of time it takes a solver to converge, we run it until its objective curve appears qualitatively flat and declare the convergence point to be the earliest iterate whose objective is within 1% of the best objective value seen so far (which we denote by  X  f ). Figure 3 illustrates that Random Conic Pursuit X  X  objective values converge quickly, and on problems where the interior point solver achieves the optimum, Random Conic Pursuit nearly achieves that optimum. The interior point solver runs out of memory when m &gt; 400 and also fails on smaller problems if its tolerance parameter is not tuned. Random Conic Pursuit easily runs on larger prob-lems for which interior point fails, and for smaller problems its running time is within a small factor of that of the interior point solver; Random Conic Pursuit typically converges within 1000 itera-tions. The gradient descent solver is orders of magnitude slower than the other solvers and failed to converge to a meaningful solution for m  X  400 even after 2000 iterations (which took 8 hours). Analysis of Random Conic Pursuit is complicated by the procedure X  X  use of randomness and its handling of the constraints g j  X  0 explicitly in the sub-problem (2), rather than via penalty functions or projections. Nonetheless, we are able to obtain useful insights by first analyzing a simpler setting having only a PSD constraint. We thus obtain a bound on the rate at which the objective values of Random Conic Pursuit X  X  iterates converge to the SDP X  X  optimal value when the problem has no constraints of the form g j  X  0 : Theorem 1 (Convergence rate of Random Conic Pursuit when f is weakly convex and k = 0 ) . Let f : R d  X  d  X  R be a convex differentiable function with L -Lipschitz gradients such that the minimum of the following optimization problem is attained at some X  X  : Let X 1 ...X t be the iterates of Algorithm 1 when applied to this problem starting at iterate X 0 (using the bracketed sampling scheme given in the algorithm specification), and suppose k X t  X  X  X  k is bounded. Then for some constant  X  that does not depend on t . Proof. We prove that equation (8) holds in general for any X  X  , and thus for the optimizer of f in particular. The convexity of f implies the following linear lower bound on f ( X ) for any X and Y : The Lipschitz assumption on the gradient of f implies the following quadratic upper bound on f ( X ) for any X and Y [18]: X  X  . In particular, the choice  X  Y t :=  X  t ( x t ) x t x 0 We will bound the defect f ( X t +1 )  X  f ( X  X  ) at each iteration by sub-optimally picking  X   X  t = 1 /t ,  X   X  The first inequality follows by the suboptimality of  X   X  t and  X   X  t , the second by Equation (10), and the third by (9).
 variance of  X  Y t , and the second term is bounded by assumption. Taking expectation over X t gives the Despite the extremely simple and randomized nature of Random Conic Pursuit, the theorem guar-antees that its objective values converge at the rate O (1 /t ) on an important subclass of SDPs. We omit here some readily available extensions: for example, the probability that a trajectory of iterates violates the above rate can be bounded by noting that the iterates X  objective values behave as a finite difference sub-martingale. Additionally, the theorem and proof could be generalized to hold for a broader class of sampling schemes.
 Directly characterizing the convergence of Random Conic Pursuit on problems with constraints ap-pears to be significantly more difficult and seems to require introduction of new quantities depending on the constraint set (e.g., condition number of the constraint set and its overlap with the PSD cone) whose implications for the algorithm are difficult to explicitly characterize with respect to d and the properties of the g j , X  X  , and the Y t sampling distribution. Indeed, it would be useful to better understand the limitations of Random Conic Pursuit. As noted above, the procedure cannot readily accommodate general equality constraints; furthermore, for some constraint sets, sampling only a rank one Y t at each iteration could conceivably cause the iterates to become trapped at a sub-optimal boundary point (this could be alleviated by sampling higher rank Y t ). A more general analysis is the subject of continuing work, though our experiments confirm empirically that we realize usefully fast convergence of Random Conic Pursuit even when it is applied to a variety of constrained SDPs. We obtain a different analytical perspective by recalling that Random Conic Pursuit computes a solution within the random polyhedral cone F x n , defined in (3) above. The distance between this cone and the optimal matrix X  X  is closely related to the quality of solutions produced by Random Conic Pursuit. The following theorem characterizes the distance between a sampled cone F x n and any fixed X  X  in the PSD cone: Theorem 2. Let X  X  0 be a fixed positive definite matrix, and let x 1 ,...,x n  X  R d be drawn i.i.d. from N (0 ,  X ) with  X  X  X  . Then, for any  X  &gt; 0 , with probability at least 1  X   X  , See supplementary materials for proof. As expected, F x n provides a progressively better approxima-tion to the PSD cone (with high probability) as n grows. Furthermore, the rate at which this occurs depends on X  X  and its relationship to  X  ; as the latter becomes better matched to the former, smaller values of n are required to achieve an approximation of given quality.
 The constant  X  in Theorem 1 can hide a dependence on the dimensionality of the problem d , though the proof of Theorem 2 helps to elucidate the dependence of  X  on d and X  X  for the particular case when  X  does not vary over time (the constants in Theorem 2 arise from bounding k  X  t ( x t ) x t x 0 t k ). A potential concern regarding both of the above theorems is the possibility of extremely adverse dependence of their constants on the dimensionality d and the properties (e.g., condition number) of X  X  . However, our empirical results in Section 3 show that Random Conic Pursuit does indeed decrease the objective function usefully quickly on real problems with relatively large d and solution matrices X  X  which are rank one, a case predicted by the analysis to be among the most difficult. Random Conic Pursuit and the analyses above are related to a number of existing optimization and sampling algorithms.
 Our procedure is closely related to feasible direction methods [22], which move along descent direc-tions in the feasible set defined by the constraints at the current iterate. Cutting plane methods [11], when applied to some SDPs, solve a linear program obtained by replacing the PSD constraint with a polyhedral constraint. Random Conic Pursuit overcomes the difficulty of finding feasible descent directions or cutting planes, respectively, by sampling directions randomly and also allowing the current iterate to be rescaled.
 Pursuit-based optimization methods [6, 13] return a solution within the convex hull of an a priori -specified convenient set of points M . At each iteration, they refine their solution to a point between the current iterate and a point in M . The main burden in these methods is to select a near-optimal point in M at each iteration. For SDPs having only a trace equality constraint and with M the set of rank one PSD matrices, Hazan [10] shows that such points in M can be found via an eigenvalue computation, thereby obtaining a convergence rate of O (1 /t ) . In contrast, our method selects steps randomly and still obtains a rate of O (1 /t ) in the unconstrained case.
 The Hit-and-Run algorithm for sampling from convex bodies can be combined with simulated an-nealing to solve SDPs [15]. In this configuration, similarly to Random Conic Pursuit, it conducts a search along random directions whose distribution is adapted over time.
 Finally, whereas Random Conic Pursuit utilizes a randomized polyhedral inner approximation of the PSD cone, the work of Calafiore and Campi [5] yields a randomized outer approximation to the PSD cone obtained by replacing the PSD constraint X 0 with a set of sampled linear inequality constraints. It can be shown that for linear SDPs, the dual of the interior LP relaxation is identical requires impractically many sampled constraints to ensure that the problem remains bounded and yields a good-quality solution. We have presented Random Conic Pursuit, a simple, easily implemented randomized solver for general SDPs. Unlike interior point methods, our procedure does not excel at producing highly exact solutions. However, it is more scalable and provides useful approximate solutions fairly quickly, characteristics that are often desirable in machine learning applications. This fact is illustrated by our experiments on three different machine learning tasks based on SDPs; we have also provided a preliminary analysis yielding further insight into Random Conic Pursuit.
 Acknowledgments We are grateful to Guillaume Obozinski for early discussions that motivated this line of work.
