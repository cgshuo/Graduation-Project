 ORIGINAL PAPER Adrien Delaye  X  Cheng-Lin Liu Abstract We present a new system for predicting the seg-mentation of online handwritten documents into multiple blocks, such as text paragraphs, tables, graphics, or math-ematical expressions. A hierarchical representation of the document is adopted by aggregating strokes into blocks, and interactions between different levels are modeled in a tree Conditional Random Field. Features are extracted, and labels are predicted at each tree level with logistic classifiers, and Belief Propagation is adopted for optimal inference over the structure. Being fully trainable, the system is shown to properly handle difficult segmentation problems arising in unconstrained online note-taking documents, where no prior knowledge is available regarding the layout or the expected content. Our experiments show very promising results and allow to envision fully automatic segmentation of free-form online notes.
 Keywords Document segmentation  X  Online documents  X  Unconstrained note-taking  X  Handwriting  X  Conditional random fields 1 Introduction While the recent years have witnessed the rise of pen-enabled devices such as smart phones, tablets, or digital whiteboards, the automatic understanding of handwritten content that can be freely composed on such devices is still a largely unsolved problem to date. Analysis of unconstrained online notes is a very challenging problem due to the lack of prior knowledge about the content or the layout of the documents, in addition to the ambiguity inherent in their handwritten nature. In the past, several methods have been proposed toward automatic understanding of such documents, most of them dealing with the problem of separating textual content from non-textual content [ 2 , 12 , 42 ]. Most recent progress showed highly reli-able results on a realistic dataset, with error rates below 3% [ 6 , 9 ]. However, typical notes can contain a variety of objects such as text paragraphs, tables, lists, drawings and diagrams, or scientific notations (see an example of online document in Fig. 1 ). These objects need to be segmented and correctly categorized in order to progress toward higher-level interpre-tation of the documents.

In this paper, we present a new method to predict multi-class segmentation of online documents into independent objects. We exploit the text/non-text stroke classification from our previous work [ 9 ] and design a tree Conditional Random Field (CRF) model to predict the segmentation. Offering a hierarchical representation of the document, the model encodes observations at different levels and their inter-actions, all of which are jointly considered for estimating the segmentation. The choice of tree structures for the CRF guar-antees that its parameters are fully trainable, an important property for dealing with unconstrained documents where little prior knowledge is available. We apply our system to the segmentation of documents from the IAM-OnDo data-base [ 14 ] and report results for stroke-level and block-level segmentation that demonstrate a significant progress for the recognition of unconstrained handwritten notes.

In the next section, we first present research works related to the online document segmentation problem, then specif-ically review the use of hierarchical Conditional Random Fields for image segmentation as our main source of inspira-tion. Section 3 presents an overview of the system we propose in order to address document segmentation as a structured learning problem with a hierarchical conditional model. Sec-tion 4 introduces the detailed formalization of the model and the algorithm for inference and parameter training. Section 5 is dedicated to the implementation choices for application of this model to online document, including the strategy for building an initial hierarchical representation. Experimental results for the segmentation task at the stroke level and at the block level are presented in Sects. 6 and 7 respectively. 2 Related works 2.1 Online document analysis methods Several methods have been proposed for the analysis of unconstrained online notes, often dealing only with a spe-cific aspect of the problem. We present three categories of systems in this section: the ones dedicated to separation of text from non-text content in the document, the ones focus-ing on the extraction of a particular type of regular structures, and the attempts toward more general multi-class document segmentation. 2.1.1 Text/non-text separation Text is usually more stable than other types of content in unconstrained documents, and its extraction is often regarded as a necessary preliminary step to the processing of hetero-geneous documents.

Considering online documents as sets of strokes (a stroke is an individual ink element captured from one pen-down to the next pen-up), researchers have focused on the classifi-cation of strokes as being text elements or not. Jain et al. [ 15 ] have proposed an isolated classification system based on stroke features. More sophisticated approaches have been proposed later, taking into account the temporal context of bination of those [ 6 ] in a structured classification problem. In our recent works [ 9 ], we introduced a Conditional Ran-dom Field model that highlights the interest of combining a variety of contextual sources to reach a superior recognition rate of 97.23% with the IAM-OnDo dataset [ 14 ].

However important, text/non-text separation is only a first steptowarddocument structureunderstanding, as text strokes can appear in several types of objects (e.g., text block, table, list, diagram) and so do non-text strokes (e.g., diagram, draw-ing, table). This illustrates the need for higher-level docu-ment segmentation into meaningful and categorized blocks of strokes before applying appropriate recognition methods (e.g., text recognizer, table analyzer, diagram interpreter). 2.1.2 Extraction of regular structures Many works have dealt with the segmentation of text strokes into meaningful blocks such as words, text lines and para-graphs [ 3 , 23 , 32 , 40 ], but most of them can not handle hetero-geneous documents (i.e. presenting a mix of text and non-text elements). An exception is the work of Zhou et al. [ 43 ] where stroke classification, text line grouping and string recognition processes interact with one another to provide a robust seg-mentation into text lines.

Methods have also been proposed for segmentation of tables from ink notes, for example, by detecting ruling lines based on some empirically defined thresholds [ 21 ]orby detecting vertical and horizontal alignments of items with a matrix model [ 41 ].

For extracting regular structures such as text or tables, some available knowledge about the expected structure can be leveraged to design efficient methods. In addition, text recognition tools can be employed to confirm the segmenta-tionhypothesesofwords,lines,ortablecells.Onthecontrary, no such external knowledge is available when dealing with general segmentation of unstructured objects. 2.1.3 Toward generic multi-class segmentation A notable effort toward multi-class segmentation of hetero-geneous online documents was presented by Jain et al. [ 15 ]. After stroke-level text/non-text classification, the segmenta-tion strategy is based on the Minimum Spanning Tree (MST) of the non-textual strokes. Cutting the MST at edges identi-fied as inconsistent leads to a segmentation of the document into blocks that can be ultimately identified as text blocks, tables (rules or unruled) or diagrams. Whereas the reported results are good on a small dataset of relatively clean docu-ments, the method is likely to fail on more challenging data. Indeed, it relies on empirically defined thresholds and it is based on the assumption that segments can be retrieved from the MST of the stroke graph, which is not verified in more realistic documents (such as in Fig. 1 ).

To address general multi-class segmentation of hetero-geneous online documents, new methods need to be intro-duced. Contrary to text blocks or tabular structures, no prior knowledge is available about handwritten objects in general. For example, diagrams and drawings present highly vari-able characteristics, a wide variety of shapes and structures, and generally have no identifiable segmentation units such as words or cells [ 8 ]. In addition, there is no prior knowledge regarding the presence of some elements or the expected structure of the document, hence top-down methods are not easily applicable.

Rather than with a two-step approach as the one of Jain et al. [ 15 ], we consider that the problems of segmentation and of block categorization should be addressed simultaneously in order to offer more robust systems. We present below a brief review of the works proposed for joint segmentation and recognition in the field of natural image understand-ing. Specifically, we focus on Conditional Random Fields, as these models offer a direct way to deal with bidimensionnal segmentation-recognition problems formulated as structured labeling prediction tasks. 2.2 Conditional random fields for 2D signal segmentation We review here the use of Conditional Random Fields for solving segmentation/recognition problems. The image seg-mentation problem is somehow similar to the online docu-ment structure understanding task: like free-style documents, images contain an unknown number of objects that present complex shapes and where rule-based approaches are inop-erant. CRF models can be efficiently trained from data to fit an objective task without requiring much prior knowledge, and they have been successfully applied to several computer vision problems. We introduce the classical formulation of the image labeling problem as a CRF, then review some hier-archical extensions that were proposed to solve image seg-mentation tasks. 2.2.1 General formulation Typically, Conditional Random Fields are used to pre-dict labels over sites attached to pixels or image patches, resulting in a segmentation where objects are homogeneous sets of neighboring patches. CRFs can efficiently predict foreground-background segmentation [ 30 ], object detection [ 29 ], or full scene segmentation [ 28 ]. In the CRF framework, assigning a label to a site is influenced not only by local evi-dence from the patch but also by interaction with labels of neighboring sites. Formally, a CRF models the conditional probability of a labeling y given a set of observations x [ 19 ]. It can be expressed as a product of potential functions defined over the maximal cliques of the graph G that describes the label interactions p ( y | x ) = Here, c denotes a maximal clique on the graph G ,  X  c is the potential attached to the clique, and Z ( x ) is a normalization function defined as a sum over all the possible labelings In most cases, G is considered to only contain two types of cliques: single-site cliques (i.e., nodes of the graph) and pair-wise cliques (i.e. edges), such that the formulation becomes p ( y | x ) = with C 1 and C 2 the sets of unary and binary cliques, and  X  1 and  X  2 the parameters attached to clique templates. For many tasks (image restoration, binarization, denoising), unary potentials act as local classifiers and pairwise poten-tials act as smoothing constraints encouraging neighboring patches to share the same labels [ 4 ]. 2.2.2 Hierarchical conditional random fields For solving high-level labeling problems (as object detection or scene understanding), connections between neighboring sites can not bring enough contextual information [ 11 ], and hierarchical extensions of CRF have been introduced as a way to encode long-range dependencies through multi-scale multi-scale contextual modeling is also well documented in the document image analysis literature [ 20 , 25 , 31 ].
Montreuil et al. have proposed a CRF with multi-scale information to perform physical and logical segmentation of textual elements in freely handwritten offline documents [ 24 , 25 ]. They first designed a flat model with features extracted from several scales, explicitly describing influence of global context over local predictions but neglecting long-range dependencies between labels [ 24 ]. More recently, they proposed a hierarchy of CRFs successively applied to con-nected components, words, lines, and text blocks [ 25 ]. This method explicitly includes multi-scale information and mod-els hierarchical dependencies between labels, but the CRFs are trained and applied independently from each other, so errors can be propagated across the levels and the informa-tion from different scales is not jointly considered. Reynolds and Murphy proposed to exploit tree-shaped CRFs [ 30 ] for predicting the foreground/background label-ing of natural images. A tree is built from several hypothetical segmentations of the image, with nodes attached to regions of varying granularity. The CRF formulation is similar to the one of Eq. ( 2 ), with unary potentials encoding local affin-ity between a label at a node of the tree and an observation. Pairwise potentials describe the edges of the tree, encourag-ing the same label to be assigned to a node and its parent. Tree structure has the advantage of guaranteeing efficient and optimal algorithms for parameter training and model inference, while this is often impossible in loopy structures. Overall, the tree CRF permits to jointly consider local evi-dence and long-range label dependencies for labeling predic-tion, thus resulting in more context-aware segmentation deci-sions. Extensions were developed and applied to structured object detection [ 1 ] and multi-class image segmentation [ 26 , 28 ].

CRFs constitute an efficient probabilistic framework for structured prediction and provide a natural way to jointly solve segmentation and recognition of bidimensional signals. If the simpler design (with smoothing behavior) presents some limitations, tree CRFs with a hierarchical representa-tion better handles image segmentation problems while sup-porting efficient training and inference algorithms. We pro-pose in this work to adopt tree-CRF representation as a fully trainable hierarchical model to solve multi-class segmenta-tion of unconstrained online documents. 3 System for multi-class segmentation of online documents In this section, we first highlight the particularities of uncon-strained online documents with regard to the segmentation problem. Then, we give an overview of our segmentation sys-tem based on a hierarchical representation of the documents as Tree CRFs. 3.1 Particularities of online documents Analysis of freely unconstrained handwritten documents presents a number of specific challenges. Unlike for nat-ural scenes where some universal prior knowledge can be leveraged [ 38 ], no assumption can be afforded regarding expected prior distribution of classes or their co-occurrences, or regarding the absolute or relative location of objects in free-form documents.

Online documents are composed of strokes that constitute a natural segmentation unit. We observed on the IAM-OnDo database that a stroke belongs to one object only, and that the number of strokes in a document is quite small, typically a few hundreds. Strokes are, therefore, an excellent choice for defining the CRF sites, guaranteeing perfect expressivity with a reasonable computational load. As temporal and spa-tial collections of points, strokes are also rich structures from which informative local features can be extracted (see [ 5 ]).
Strokes are spread irregularly over space and time, have a variable size and can present complex relationships (e.g., intersection, parallelism) [ 10 ]. Intricate neighboring situa-tions can occur, for example, long strokes that cross a large part of the document can have neighbors located in areas that are far from each other. Consequently, we consider that interaction potentials should be trained from data (rather than follow a predefined smoothing behavior). This strongly sup-ports our choice to adopt flexible and fully trainable structure such as the tree CRF.

At last, how to group strokes into meaningful segments while taking into account their rich spatial and temporal inter-actions is a difficult problem. An analysis of the IAM-OnDo dataset revealed that objects of interest (such as tables, text blocks or diagrams) are not written in contiguous temporal sequences, their strokes being usually interleaved in time. In the spatial dimensions, we also noted that the bounding boxes of objects can largely overlap with each other, and intersec-tion between strokes from different objects are not rare. In Sect. 5.1 we propose a method, free of temporal or spatial contiguity constraints, to build a hierarchical document rep-resentation based on a clustering algorithm with a learned distance. 3.2 System overview Figure 2 presents the main elements of our system in a flow-chart. The left and right parts of the diagram, respectively, illustrate the training and exploitation modes of the system. For a document to be processed, the first step consists in applying the text/non-text classifier presented in our previous work [ 9 ]: its stroke-level predictions are used as features in the subsequent steps of the system. Then, two main process-ing steps are distinguished at the core of the segmentation system: the tree construction step and the CRF step. The first step takes as input documents as sets of strokes and outputs their hierarchical representation as trees. The construction of trees involves a distance measure with trained weights and a clustering algorithm that relies on the trained distance. The second step takes as input the tree representation of the docu-ments that support the CRF model. CRF weights are trained from ground-truthed documents trees. At test time, a CRF is built on the document tree according to trained parameters and its inference outputs a labeling of the document strokes (i.e., a segmentation hypothesis). Finally, a post-processing step is applied on the stroke labeling to provide a block-level segmentation of the document.
 In the next section, we give a formal definition of the tree CRFs. The following section (Sect. 5 ) presents application-dependent choices about the first step of the flowchart (seg-mentation of the document into a hierarchical representa-tion with distance learning and clustering), as well as fea-ture engineering and description of the final block-level post-processing step. 4 Tree CRF system for segmentation prediction In this section, we present the formal definition of the tree-CRFmodelanditspotentialfunctions,thendescribethealgo-rithms for inference and parameter training. 4.1 Tree conditional random fields formalization Let x be a set of observations from an online document. We adopt a hierarchical view of the document, resulting in mul-tiple sites defined at different levels of granularity (how we compute the hierarchy of segments is the topic of Sect. 5.1 ) x ={ x 0 Here, x 0 i denotes an observation from stroke i and S 0 indexes the strokes, while x k i for k &gt; 0 denote observations from a block of level k and S k indexes blocks at this level. Each block or stroke is attached to a site , and each site from levels k = 0 ... h  X  1 is connected to a parent site at level k + 1, such that the document is represented as a tree of sites defined at different levels attached to their corresponding observations x . To each site, we associate a label y k i defined in a label set L . A stroke-level labeling of the document is formulated as a partial configuration  X  y 0 of the labels over the tree leaves only, i.e.  X  y 0 ={ X  y 0 i } . 4.1.1 Conditional probability If the document tree has h + 1levels(seeEq. 3 ), we express the CRF distribution by introducing 2 h + 1 clique templates , i.e. families of cliques that share common parameters and are repeated across the tree p ( y | x ) =
Z ( x )
Cliques of templates A p describe association potentials for the sites attached to the observations x p i at level p . Cliques of templates I p describe the interaction potentials over the edges of the tree, between a site at level p and its parent at level p + 1.  X  c and  X  c indicate potential functions on clique c parametrized by  X  p or  X  p . We give their formal definitions in the next paragraph. 4.1.2 Expression of potential functions Association potentials These potentials are attached to single-site cliques and describe the affinities between local observation, from a stroke or a higher-level block, and the labels from L . We adopt for these potentials a logistic multi-class classifier formulation, defined as follows  X  ( x with  X  =
In the above definitions, x c is a vector of K p features, and each  X  l p for l = 2 ... L p is a vector of K p weights (as in Eq. 4 , p denotes the level of the single-site clique c in thetreehierarchy). L p is the number of labels that can be assigned to a node, hence for stroke level, we have L 0 =| L | For internal nodes of the tree, we add a new label so that L of features x c that are extracted at each level are described in Sect. 5.3 .In( 5 ), one of the classes (empirically chosen as l = 1 here) is not associated with weights but is indirectly defined such that the sum of output probabilities is one.
Interaction potentials A flexible definition for the inter-action potentials is very important in our system. The ini-tial tree representation of the document is not guaranteed to match with the actual objects boundaries, and the inevitable initial segmentation errors need to be corrected in the final segmentation prediction. In other words, it is vital that the interactionpotentialscantolerateinconsistenciesinthelabel-ing of related nodes at different levels of the tree, so that the boundaries of initial blocks can be adjusted at inference time. Intuitively, we can expect that interaction potentials should act as soft constraints encouraging same labels to be shared between children and their parent. However, we decide to adopt a perfectly flexible and fully trainable definition (as opposed to predefined, data-independent smoothing interac-tion potentials), as follows:  X  ( x In this definition, y c denotes the pair of labels y s , y with an edge in the tree representation. We define K = K p features x k that are extracted from the pair of observations x t , so that the functions f k p 1 associate condition cond ( y ) is true, and to 0 otherwise. According to this definition, only half of the functions are activated (non-zero) for each configuration of labels y s Such kind of definition is widely adopted in the CRF lit-erature [ 33 ]. Each feature contributes to the potential with a weight that is learnt from training data. The nature of features x c is explicited in Sect. 5.3 . 4.2 System inference with belief propagation The tree structure adopted for our CRF model permits to applyoptimalandefficientinferencealgorithms.BeliefProp-agation is a message-passing algorithm that computes the marginal probabilities P ( y i | x ) at each node under the sum-productaggregationrule(see[ 16 ]formoredetails).Thesame algorithm applied with the max-product rule yields the Max-imum A Posteriori labeling over the tree  X  y = arg max We experimentally found that the MAP labeling provides consistently better results than the max-marginal labeling, and hence, we adopt the max-product rule in the Belief Prop-agation algorithm for inference. 4.3 Parameter training Model training consists in optimizing the weights  X  and  X  (see Eq. 4 ). Thanks to the tree structure of the CRFs, it is pos-sible to find the optimal solution of the conditional likelihood maximization problem over training data. Considering that A p and and that Z ( x ) is a normalization over the whole database, the objective function to be maximized is the conditional log likelihood expressed as: l ( X ,  X ) = This function is convex, hence we apply the LBFGS gradi-ent ascent method [ 22 ] to obtain its global optimum. It only requires computing of the first order gradients of the objec-tive function with respect to the weights and to evaluate the objective function iteratively. For computation of the log par-tition function Z , we follow the Bethe energy method [ 39 ].
From Eq. ( 5 ), the gradient of l with respect to a weight j ranges in { 1 ... K p } )is  X  l  X ( X  k  X  is defined as in Eq. ( 6 ) and y  X  c is the ground truth labeling of a unary clique c . p ( y c | x ) is the marginal probability over the clique, and it is computed exactly with the sum-product Belief Propagation algorithm. The gradients of l with respect to the pairwise potential parameters are as follows:  X  l and with notations similar as in Eq. ( 11 ).

To avoid overfitting the training data when optimizing a large number of parameters, we adopt the commonly used L 2 regularization, so the actual objective function becomes  X  l ( X ,  X ) = l ( X ,  X )  X  where K  X  and K  X  are the total number of parameters in vec-tors  X  and  X  and  X  is a penalization constant. 5 Application to online document segmentation This section presents the implementation details for apply-ing the presented tree-CRF system to segmentation of online documents. We first focus on the tree construction algorithm with the training of an appropriate distance. We also expose the features extracted from strokes, segmented blocks and pairs of objects to feed the CRF model. Finally, we present the block segmentation method that operates over the output of the CRF. 5.1 Tree construction from stroke clustering Before applying the CRF model for detecting the presence of graphical elements, a tree of the document has to be built. We consider that the initial segmentation should be as much as possible compatible with the actual segmentation of the document. Without loss of generality, we assume that strokes from the same object should be close to each other, where we propose to learn an appropriate definition of close (see Sect. 5.2 ). Supposing an appropriate distance, we apply an agglomerative clustering with average linkage criterion over the strokes. The tree of segments of variable granularity is obtained by cutting the resulting dendrogram at h distance thresholds t i with t 1 &lt;  X  X  X  &lt; t h . By construction, the seg-ments of different levels are compatible with each other. Fig-ure 3 gives an illustration of the tree CRF resulting from a 4-levels segmentation of an online document. Note that in this case, the segmentation results in two disconnected trees.
For training the CRF parameters, each block needs to be assigned a label. If the block is pure , i.e. all its strokes belong to the same ground truth object, it is assigned the appropri-ate class label from L . Otherwise, it is assigned a special additional label for mixed blocks. 5.2 Compound distance learning There are many ways to describe the distance between online strokes, including measures from their spatial and tempo-ral relationships. While it is unclear which distance crite-rion should be used, we have the intuition that the segments obtained by the clustering algorithm should be as much as possible compatible with the boundaries of the actual objects in the document. Then, more reliable block-level observations would be extracted and we expect that the tree CRF would perform better. Therefore, we propose a train-ing scheme that learns a new distance function defined as a linear combination of simple distance measures. Consider the following set of functions d i , i = 1 ... 4 that describe under different aspects the distance between two strokes x and x 0 b  X   X   X   X   X   X   X   X   X   X   X  d 1 ( x 0 a , x 0 b ) =|| c a  X  c b || d 2 ( x 0 a , x 0 b ) = max ( t a , t b )  X  min ( t a , t c denote the strokes centroid and t i their starting date (taken as a timestamp for each stroke 1 ), and || . || is the Euclidean distance between 2D points. s a and s b denote the text/non-text labels affected to the strokes by the dedicated classifi-cation system. All the measures are thresholded and linearly rescaled between 0 and 1. We define the compound distance as d ( with weights w i to be trained from data. From training docu-ments, we extract a large number of strokes pairs x 0 a , strokes can belong to the same object or to different objects. However, not all the pairs of strokes from the same object are equally close to each other: for example, two text elements from a text paragraph can be far away if they belong to differ-ent text lines. These different situations can be appreciated as the ground truth annotation of the documents follows a tree structure, with objects containing objects of finer gran-ularity (e.g., a paragraph is made of text lines). To model the various situations, we empirically define different penal-ization constants  X  for pairs of training strokes depending if they belong to different objects at the highest level of the annotation hierarchy, or to same objects, or to same parts of objects. The choices for values of  X  was determined exper-imentally (see Sect. 6.2 ). For training the weights w i ,we define the following regularized objective function to be min-imized g = where T is the set of all pairs of strokes extracted from the training documents. This compound distance with trained weights is then used by the agglomerative clustering algo-rithm to build the tree representation of the documents. 5.3 Feature definitions We present here the choices for the sets of features used in the definitions of unary and pairwise potentials of the tree CRF.
 Strokes features We extract K 0 = 27 features for the local stroke-level potential. As no feature set was proposed before for classifying strokes into content categories, we com-bine several sets of features describing various aspects of the strokes. A very important one is a binary text/non-text feature obtained from the dedicated classification sys-tem [ 8 ]. Thirteen other features describe properties of the stroke itself: size (half-perimeter normalized by the median stroke height in the document), length (number of points after resampling), aspect ratio of its bounding box, 9-bins histogram of directions, stroke temporal duration. Thirteen additional features describe an empirical spatial neighbor-hood around the stroke of interest: number of intersect-ing strokes, number of neighbors, proportion of textual strokes among neighbors, relative size of the neighbor-ing strokes, 9-bins histogram of directions of neighboring strokes.
 Block-level features For block-level unary potentials, we define a larger set of K l &gt; 0 = 53 features. Features include geometrical properties of the block (4 features: normal-ized aspect ratio, height, width, proportion of area with respect to the one of the document), proportion of text strokes in the block (1), ratio of the maximal and aver-age stroke dimensions to the box dimensions (4), average width and height of text and non-text strokes (4), block-level zoning (9) and histogram of directions (9). Other 22 features describe the statistics of some stroke-level fea-tures that are averaged over the strokes (or offstrokes) con-tained in the block (11), as well as the associated standard deviations (11): closure, curvature, average direction, width and height, stroke length, time duration, offstroke width and height, offstroke average direction, and offstroke dura-tion.
 Interaction features between strokes and blocks For an edge linking a stroke to a first-level block, we extract nine features: the inverse of the number of strokes in the block and eight features from the comparison of the stroke and the block (ratio of durations, ratio of areas, ratio of dimensions, dis-tance between centroids, pairwise offsets of the left, right, top and bottom boundaries).
 Interaction features between blocks For edges connecting blocks, we extract 15 features: 9 geometrical measures from their bounding boxes (ratio of areas, 2 ratio of dimensions, ratio of their aspect ratio, 4 boundaries offsets, centroid dis-tance) and 6 measures from comparisons of their content (ratios of text/non-text proportions, stroke density, number of strokes, average stroke length, average dimensions of their strokes). 5.4 Final block-level segmentation The tree-CRF system presented in the previous section is dedicated to the prediction of stroke labels. However, further document processing tasks (such as content recognition and indexation) require the document to be segmented into actual blocks.

From the output of the CRF system, we consider the strokes labeled with each type of content independently from the other types. The document is thus viewed as several sets of strokes S c ={ x 0 i so that  X  y i = c } , with c indexing the categories (e.g., graphic, text, table, list, math), and  X  predicted label for the stroke x 0 i . For each set S c , we propose to spatially cluster the strokes into sub-blocks. First, the Min-imum Spanning Tree (MST) over the graph of strokes in S c is built, according to the minimum spatial distance between strokes (i.e., distance d 3 from Sect. 5.2 ). Then, edges of the MST that weigh more than a predefined threshold T c are removed,withinamaximumof N c cuts.Valuesforthethresh-olds and number of cuts for each category are determined experimentally. 6 Stroke labeling experiments 6.1 Experimental data We evaluate the proposed segmentation system over the IAM-OnDo database, a publicly available collection of freely handwritten online documents [ 14 ]. It contains 1,000 docu-ments that present a mix of handwritten text, drawings, dia-grams, formulas, tables, lists, and marking elements arranged in an unconstrained way. Figure 4 a presents the structure of the documents annotations (the original figure is taken from [ 14 ]).

The representation from Fig. 4 a illustrates our choices for object definition from the structured annotations of the IAM-OnDo dataset. We consider that each stroke of the document belongs to an object at the highest level of the annotation tree. Its class can be graphic (including elements labeled as drawing , diagram and structure categories), math , table , list ,or text . We chose to ignore the minor categories garbage and marking . The finer levels of the trees are not considered, hence strokes from a math object that is included in a top-level diagram object are all considered as graphic strokes. This is because we are primarily interested in recovering the segments of highest level that should be segmented com-pletely from each other. For example, when isolating a table , we need to extract both the structure of the table and the text from its cells. Figure 4 b shows an example of document with ground truth blocks identified in different colors and their bounding boxes.

Notice how the bounding boxes of different blocks largely overlap with each other. The document contains a table and a text block , as well as four graphic objects: one diagram , one drawing , and two elements of structure (a diagonal line and a box surrounding the table). Some marking elements are iden-tified in purple over the text block. This example illustrates how the ground truth segmentation can sometimes be subjec-tive: the box around the table is seen as a standalone structure element, whereas it could be considered as part of the table .
Throughout our experiments, we follow the traditional data partitioning of the database (see [ 14 ]). Documents from set0 and set1 constitute the training set (for training the dis-tance weights and the CRF parameters), set2 is the validation set (for optimizing the parameters of block-level segmen-tation method) and set3 is the independent evaluation set. Table 1 presents the number of strokes per category in each set.

As exposed in Sect. 2 , no results were published before on the task of online document segmentation (except for the seminalpaperofJainetal.[ 15 ]thatexploitsaprivatedataset). The IAM-OnDo dataset offers a good ground for comparison of segmentation methods, but so far only results on the task of discriminating text from non-text strokes have been reported. For completeness, we present in Table 2 the results published on this task for IAM-OnDo documents. 6.2 Pre-segmentation analysis We present here statistics on the pre-segmentation of vali-dation documents by the agglomerative clustering equipped with the compound distance trained on the training set. For determining good values of  X  ab constants (see Sect. 5.2 ), we fixed the cutting thresholds of clustering algorithm at t ={ 1 , 1 . 5 , 2 , 2 . 5 } , then experiment with  X  in { 0 , 1 , 2 ,..., 20 } .Wefoundexperimentallythatthefollow-ing choices of  X  ab values define a good trade off between the size of the segments and their level of purity: if two strokes belong to different objects at the highest level of the annota-tion hierarchy, we set  X  ab = 10; if they belong to the same object but to different sub-objects, then  X  ab = 5; if they belong to the same sub-object, then  X  ab = 0. Table 3 reports the number of segments and the proportion of pure blocks obtained in the validation set for these choices of training distance meta-parameters and the chosen values of cutting thresholds.

The proportion of pure segments is very high thanks to the trained compound distance, so that most of the pre-segmented blocks are consistent with the true objects bound-aries. Obviously, the proportion of pure segments diminishes when the size of blocks increases, but it remains above 80% for all the values of thresholds. We also report in Table 3 a block classification performance, obtained with isolated logistic classifiers based on the block features presented in Sect. 5.3 (a different classifier is trained for each thresh-old). The classifiers are trained from documents in set01 and applied on documents in set2 . Results show that the precision of block classification ranges between 80 and 85% depend-ing on the block sizes. Meanwhile, we obtained a classifica-tion rate of 75.92% at the stroke level, with a logistic clas-sifier based on the 27 stroke-level features (see Sect. 5.3 ). Overall, this analysis shows that the combination of classi-fiers at multiple levels in the hierarchy is likely to improve the stroke-level classification. In accordance with our intu-ition, it appears that blocks are easier to classify than isolated strokes. 6.3 CRF Tree structure comparisons The Table 4 reports the results of our experiments with dif-ferent tree-CRF structures. We compare trees with different depths and with varying values of segmentation thresholds at each level. For each system, the CRF parameters were trained on the training dataset and the prediction scores are measured over the final evaluation dataset.

The study of different tree structures highlights the inter-est of considering multi-level information for the multi-class labeling of strokes. The simplest systems, with a single level of internal nodes in the tree, only predict stroke labels with a precision between 85 and 88%. However, including a second level of internal nodes permits to boost the precision to above 92% (system 5). Overall, the best precision rate is obtained with the system 9, that integrates 4 levels of internal nodes in the tree, and yields 93.46% of correct stroke classification. Experimenting with a more complex tree does not permit to improve this performance.

As no alternative method for multi-class segmentation of online documents was reported before in the literature, no baseline performance is available for comparison. To demon-strate the superiority of the tree-CRF architecture, we build an alternative CRF system (system 11). Based on the same multi-level representation as system 9, we insert additional intra-level links. Strokes attached to the same first-level block are connected to each other based on the Minimum Spanning Tree of their pairwise distances. Sibling blocks are also con-nected, and pairwise potentials of the form of Eq. ( 7 )are defined with specific sets of features (4 features for inter-stroke, 10 for inter-blocks potentials). To train the loopy model, we adopt an approximate objective function (Pseudo-Likelihood, see for example [ 9 ]). The Loopy Belief Propa-gation algorithm is used for inference. The obtained result is far below the performances of tree-CRF systems, which con-firms the interest of performing optimal training and infer-ence algorithms.

More insight into the results of the best system (system 9) are given in Table 5 that reports the confusion matrix for the strokes of the evaluation set. For each class of content, the recall and precision levels are reported.

This table shows that each class of strokes can be appro-priately recognized in the documents, with the recall rates over 74% for all types of content. The strokes from list type are the most easily missed, mostly because they are confused with text , graphics , and tables .The table class has a similar recall rate, resulting from confusions with the same classes. Note that the table type is quite general, since it covers ruled tables, but also partially ruled or unruled tables. If ruled tables can present resemblances with graphics (as both types con-tain text and non-text strokes), unruled tables can be easily confused with lists or text , because they only contain textual strokes arranged in a regular layout. Interstingly, the recall for math objects is rather high, while a lot of them visually look similar to text . The separation of graphics from text is very reliable, with almost no confusion between the two classes. The precision of predicted labels range from 75.8% (for tables ) to 96.9% (for text ).

In Fig. 5 , the stroke labeling computed for several doc-uments are represented, following the color convention defined in Fig. 4 a. In Fig. 5 a, strokes from an unruled table are mislabeled as list . A part of the math object in Fig. 5 bis classified as text , and the list strokes in Fig. 5 c are classified as graphic elements. The document in Fig. 5 d is perfectly labeled. In Fig. 5 e, several objects ( math and list ) are missed and labeled as text .InFig. 5 f, an element from a graphic is seen as a text object. 7 Block segmentation experiments 7.1 Evaluation of block segmentation The block-level evaluation requires to define a set of specific measures, considering the correctness of segmentation and of classification. The ground truth segmentation of a document is seen as a collection of blocks B ={ b i } , i = 1 ... N , with each block b i defined as a set of strokes b s i associated with a category label b l i in L . The sets of strokes b s i together form a partition of the document. Similarly, the output of the block segmentation process explained in Sect. 5.4 is a partition of the strokes into predicted blocks D ={ d i } , i = 1 ... M , where each d i is a labeled set of strokes. For comparing a predicted segmentation to the ground truth, we define four sets of measures, characterizing, respectively, the segmenta-tion recall, the recognition recall, the segmentation precision and the recognition precision.

Inspired from [ 43 ], we define the following segmentation situations for a ground truth block b , regardless of the pre-dicted label of the segments.  X  g1-1 :  X  d i  X  D , d s i = b s , is the case where a detected  X  g1-n :  X  d i ,..., d k  X  D , d s i  X  X  X  X  X  d s k = b s , is the case  X  gn-1 :  X  d i  X  D , b s = d s i and b s  X  d s i , is the case where  X  gnh-1 : is a special case of gn-1 where b and the merged
The following situations for a ground truth block consider both the segmentation and the predicted label.  X  g1-n X  :  X  d i ,..., d k  X  D , d s i  X   X  X  X   X  d s k = b s  X  gnh-1 X  :  X  d i  X  D , b s = d s i and b s  X  d s i and  X  b
Symmetrically, we define segmentation situations for a detected block d .  X  d1-1 : d matches exactly a ground truth block,  X  dn-1 : d is one of the blocks in a g1-n situation,  X  d1-n :  X  b i ,..., b k  X  B , b s i  X  X  X  X   X  b s k = d s , is the case  X  d1-nh : is a special case of d1-n where the merged ground Additionally, the following cases are distinguished when considering the labeling of the detected block.  X  d1-1 X  : d matches exactly a ground truth block and is prop- X  dn-1 X  : d is one of the blocks form the over segmentation  X  d1-nh X  : d is the merging of several ground truth blocks
In the sequel, the designation of each case denotes the number of its occurrences over a dataset. Based on these notations, we define several indicators for the performance of a segmentation method.  X  Segmentation Recall: SR = g1-1 | B | and SR = g1-1 X  | B  X  Tolerant Segmentation Recall: TSR = g1-1 + g1-n + gnh-1  X  Segmentation Precision: SP = d1-1 | D |  X  Pure Segmentation Rate: PSR = d1-1 + dn-1 + d1-nh | D |  X  Segment Recognition Rate: SRR X  = d1-1 X  + dn-1 X  + d1-nh X 
The Tolerant Segmentation Rate (TSR) is defined in addi-tion to the strict Segmentation Rate (SR) to account for acceptable segmentation errors, for example, when an over-segmentation occurs, or when a block is merged with another block of the same type. These errors can sometimes be imputable to inconsistent ground truth choices, for example, due to variations in the granularity of text blocks or graphics blocks definition. 7.2 Block segmentation experiments The parameters of the block segmentation strategy (thresh-olds values and number of cuts) are optimized for each category of content over the validation dataset. The max-imum number of cuts N c is set to 3 for the text category and to 2 for the other ones. The Table 6 presents segmen-tation statistics obtained with the system 9 (see Table 4 ) and subsequent block segmentation process (as explained in Sect. 5.4 ).

This table shows that the different types of blocks are not equally difficult to segment properly. Math and text are easier to segment (with SR above 80%) than diagrams and tables (SR under 62%), probably because their structure present more regularity. The table blocks are the most difficult to segment and recognize properly, notably because we found that their strokes are often partly mislabeled: for example, the table header is sometimes seen as a text block, or one of the columns of an unruled table is confused as a list . Overall, the strict measure of correct segmentation is above 70%. The proportionofgroundtruthblocksthatareproperlysegmented and classified is just around 2 3 . Adopting a more tolerant view on segmentation results (TSR), the proportion of segments that are correctly retreived and labeled can be considered to be around 3 4 .

The two Tables 7 and 8 give another view on the same results, by providing statistics on detected blocks. Table 7 reports the precision-based segmentation and recognition measures over the predicted blocks. Then, Table 8 presents the confusion matrix for the classification of pure segments, with the recall and precision rates for each class.
Figure 6 illustrates some of the most frequent errors, by presenting a few documents with their predicted segmenta-tion and the associated ground truth. It also gives the number of occurrences of each segmentation situation.

In the example from Fig. 6 a, the graphics and the text block in the bottom are not properly segmented, as the caption of the diagram is merged in the text block below, resulting in two incorrectly segmented blocks. All the other ground truth blocks are correctly segmented, but the two list blocks are misclassified as graphics and text . In the case of Fig. 6 c, the table and one graphic blocks are retrieved and correctly clas-sified. The text block at the top is over-segmented, and its seg-ments are all correctly classified. The second graphic block is also over-segmented into two segments, one of which is misclassified as a math block. In Fig. 6 e, the three text blocks and the math block are perfectly segmented and labeled. Two over-segmentations also occur, with a part of the graphic block labeled as text and a part of the table split and labeled as graphic . Finally, in Fig. 6 g, a list block is well recognized and the two graphics are partly merged, leading to two bad segmentations, while all of their components are properly labeled. 7.3 Block level post-processing Form our block-level segmentation experiment, we noticed that a few obvious segmentation errors could be solved by simple post-processing heuristics to merge or relabel some of the detected blocks. We noticed that graphic and table objects seem to be easily over-segmented. Sometimes only a small part of their strokes are mislabeled, resulting in an sur-numerous segment that overlaps with the bigger object they normally belong to (see for example the graphic Fig. 6 eis split in two blocks). Hence, whenever a block bounding box is included in the box of a graphics or table , while only cov-ering a small area of the bigger block (less than 10%), the two blocks are merged and assigned the type of the bigger one.
In order to better appreciate the segmentation of the actual content of the document, we chose in our final experiment to ignore the elements of the structure category. As we showed earlier in Fig. 4 b, structure elements sometimes constitute disputable segmentation cases while they do not bring mean-ingful content to the document. Actually, many of the stand-alone structure elements are added at the very end of the doc-ument composition and could be better considered as a kind of marking elements. We believe that these types of content would be better handled in an interactive analysis scenario where structure elements would be added by the user to refine or correct the segmentation prediction made by the system (for example, to split a merged segment into two objects).
The Tables 9 and 10 report the segmentation statistics obtainedwiththefinalsystem,includingtheblock-levelpost-processing and excluding the structure blocks from the data.
The comparison with previous results shows that our post-processing and the removal of structure elements permits to better segment and recognize the documents. The overall Segmentation Recall rate is well above 80% and above 75% if we consider the labels of segments.

While the processing time was not a major concern in the development of this system, we measured as an indica-tion that the average runtime of the complete system (includ-ing initial clustering, feature extraction, tree-CRF inference and block-level post-processing) for processing documents in the evaluation dataset is about 2.5s on a desktop computer equipped with 2.4GHz processor. A finer analysis shows that most of the computing effort is spent in the segmentation and feature extraction computing, while the tree-CRF inference only requires a minor portion of this time. However, we also measured that it can vary from 0.05 to 0.5s in average when the number of levels in the tree increase from 1 to 4. 8 Conclusion In this work, we have presented a new system for the multi-class segmentation of unconstrained online handwritten doc-uments. As it is based on a fully trainable model formulated as a Tree Conditional Random Field, no prior knowledge is required to perform the stroke labeling. An initial segmenta-tion is built with a clustering algorithm based on a trained dis-tance to provide a multi-level representation of the document. The inference of the CRF model then combines the local evi-dence with long-range interactions over the different levels for computing the stroke-level labeling. We experimentally demonstrated on a realistic database that the system can cor-rectly predict stroke labels from 5 classes with a precision of about 93.5%. We extended the system with a method for seg-menting the documents into labeled blocks with promising recall and precision rates. Overall, we consider that our work constitutes a significant step toward automated segmentation of free-form online documents.

As the limitation of the method lies in the two-stage nature of the approach, a possible extension of this work is to inte-grate the building of hierarchical representation within the graphical model, such as with the help of hidden entities in Hidden CRF [ 34 , 35 ]. A more direct alternative is to com-bine several hypothesized initial segmentations that could be considered jointly in the graphical model to increase its robustness.
 References
