 Differential privacy has recently become a de facto standard for pri-vate statistical data release. Many algorithms have been proposed to generate differentially private histograms or synthetic data. How-ever, most of them focus on  X  X ne-time" release of a static dataset and do not adequately address the increasing need of releasing se-ries of dynamic datasets in real time. A straightforward applica-tion of existing histogram methods on each snapshot of such dy-namic datasets will incur high accumulated error due to the com-posibility of differential privacy and correlations or overlapping users between the snapshots. In this paper, we address the prob-lem of releasing series of dynamic datasets in real time with dif-ferential privacy, using a novel adaptive distance-based sampling approach. Our first method, DSFT, uses a fixed distance threshold and releases a differentially private histogram only when the cur-rent snapshot is sufficiently different from the previous one, i.e., with a distance greater than a predefined threshold. Our second method, DSAT, further improves DSFT and uses a dynamic thresh-old adaptively adjusted by a feedback control mechanism to capture the data dynamics. Extensive experiments on real and synthetic datasets demonstrate that our approach achieves better utility than baseline methods and existing state-of-the-art methods.
 H.2.7 [ Database Administration ]: [Security, integrity, and protec-tion]; H.2.8DatabaseApplications[Data mining] Theory, Performance, Experimentation Differential privacy; adaptive sampling; dynamic dataset release c  X 
Sharing dynamic private data while providing privacy guaran-tee enables many important data mining and knowledge discovery applications. Consider the examples below:
Medical research: A hospital gathers data from individual pa-tients every day. The dynamic datasets, e.g. the daily datasets of individual patients with fevers, coughs, and different demographic attributes can be shared with researchers for cohort discovery, med-ical research, and seasonal epidemic outbreak monitoring.
Traffic Monitoring: A GPS service provider gathers data from individual users about their locations, speeds, mobility, etc. The dy-namic datasets, e.g., the numbers of users at different regions dur-ing each time period, can be mined for commercial interest, such as congestion patterns on the roads.

A common scenario of such applications is that a trusted server gathers data from a large number of individual subscribers. The ag-gregated data can be then continuously shared with other untrusted entities for various purposes. The trusted server, i.e. publisher, therefore must ensure that releasing the data does not compromise the privacy of any individual who contributed data. The goal of our work is to enable publishers to share a series of dynamic private datasets over individual users while guaranteeing their privacy.
The current state-of-the-art standard for privacy preserving data publishing is differential privacy [9, 27], which requires that the output released by a data provider be perturbed by a randomized algorithm A , so that the output of A remains roughly the same even if any individual tuple in the input data is arbitrarily modi-fied. Given the output of A , an adversary will not be able to infer much about any individual tuple in the input, and thus privacy is protected.

Most existing works on differentially private data release focus on  X  X ne-time" release of static data (e.g. [20, 29, 26, 7, 17], etc). In this paper, we study the problem of releasing histograms for dy-namic datasets while guaranteeing user-level differential privacy, i.e., protecting the presence of a user in the entire series of dynamic datasets. In the worst case, a user may be present in all datasets in the series. A straight-forward application of the standard dif-ferential privacy mechanism or existing histogram method to each snapshot of the dataset will lead to a very high perturbation error O ( N ) in the order of the number of datasets or snapshots N in the series, due to the composition theorem [22].

A set of related works have studied the problem of releasing ag-gregate time series and stream statistics. The works in [12, 6] pro-posed differentially private continual counters over a binary stream. However, both works adopt an event-level differential privacy, which protects the presence of an individual event, i.e. a user X  X  contri-presence or contribution to the entire series. The works in [25, 13, 14] studied the problem of releasing aggregate time-series with user-level differential privacy. Both works consider temporal cor-relations of the time-series. The paper [25] uses a Discrete Fourier Transform approach and is not applicable to real-time applications when data needs to be released at each time point. Other works [13, 14] take a model based approach which assumes original data is generated by an underlying process and uses the model based pre-diction to improve the accuracy of the released data. The limitation is that the model needs to be assumed or learned from public data with similar patterns and the method may not be effective when the real data deviates from the model.

The recent work [18] studies the problem similar to ours and represents the state-of-the-art. It proposed a novel w-event privacy framework by combining user-level and event-level privacy, which essentially guarantees user-level privacy within any window of w timestamps. When w is set to the number of time points in the se-ries of data, or infinity for infinite data streams, it converges to user-level privacy. In addition, it proposed a sampling approach with various privacy budget allocation schemes to release data. How-ever, in their schemes, privacy budgets may be exhausted prema-turely or not fully utilized, still leading to suboptimal utility of the released data.
 Our contributions. In this paper, we present a novel and princi-pled adaptive distance-based sampling approach for releasing mul-tiple histograms for a series of dynamic datasets in real time. We summarize the contributions and features of our approach below. 1). We propose a distance-based sampling approach to address the dynamics of evolving datasets under user-level differential pri-vacy. Instead of generating a differentially private (DP) histogram at each time stamp, we only compute new histograms when the up-date is significant, i.e., the distance between the current dataset and the latest released dataset is higher than a threshold. Both the dis-tance computation and threshold comparison are designed to guar-antee differential privacy. The key observation is that datasets may be subject to small updates at times. Distance-based sampling al-lows us to release a new histogram only when the datasets have significant updates, hence saving the privacy budget and reducing the overall error of released histograms. In contrast to [18], we use an explicit threshold to determine the sampling points, inspired by the sparse vector technique [15] originally proposed for releasing DP counts only when the counts are greater than a threshold. The explicit threshold based sampling provides two advantages: 1) we can predefine a threshold based on the expected update rate of the data if there is prior domain knowledge, 2) we can dynamically adjust the threshold in a principled way based on data dynamics. Another important feature of our approach is that it is orthogonal to the histogram method used for each time point, i.e. it can use any of the state-of-the-art static differentially private histogram re-lease method (e.g. [9, 28, 7, 26, 7, 17, 24, 20, 21, 30]) as a black box, which is efficient and effective for generating  X  X ne time" his-tograms. 2). We present two methods for defining the threshold. The first method, DSFT ( Distance -based Sampling with Fixed Thresh-old ), uses a predefined threshold T. The second improved method, DSAT ( Distance -based Sampling with Adaptive Threshold ), ap-plies a feedback control mechanism to adaptively adjust the thresh-old T. Real world dynamic datasets may exhibit varying update be-haviors across different settings. The adaptive threshold mecha-nism allows us to dynamically adjust the threshold T without hav-ing to rely on prior knowledge to tune the threshold. We use a PID (Proportional, Integral, and Derivative) controller [2] to detect the dynamics and adaptively adjust the threshold such that the privacy budget is not depleted prematurely due to high update and sampling rates or insufficiently utilized due to low update and sampling rates. 3). We present formal analysis of differential privacy guaran-tees, complexity, and utility for DSFT and DSAT. In our approach, each released DP histogram has either a perturbation error O ( C ) at sampling points, where C is the maximum number of released DP histograms ( C &lt;&lt; N ) or an update error with an upper bound (see Section 6). We also show a formal analysis of how to select optimal algorithmic parameters given a required utility guarantee. 4). In addition to standard user-level differential privacy, we fur-ther extend our methods under the framework of w-event privacy [18], so it can work with infinite series of evolving datasets. 5). Finally, we present extensive experiments using both syn-thetic and real datasets. Experiment results demonstrate that our methods significantly outperform the baseline approaches and ex-isting state-of-the-art techniques [18].

We state the problem setting of releasing dynamic datasets under differential privacy in Section 3 and introduce w-event privacy and existing state-of-the-art solutions. We present our methods DSFT and DSAT while provide formal privacy analysis in Section 4, then follow by the utility analysis in Section 5. We extend our tech-niques to w-event privacy framework in Section 6. We include de-tailed experimental evaluation of our algorithms in Section 7 and conclude in Section 8.
Several mechanisms (e.g. [12, 6], etc) focus on event-level pri-vacy in releasing counters, i.e. in publishing the number of event occurrences at every time point since the commencement of the system. These mechanisms consider the data stream as a bit string and at each time point they release the number of 1 X  X  seen so far. A set of related work focus on releasing aggregate time series or stream statistics under differential privacy as we discussed earlier [25, 13, 14]. The work in [25, 13] releases aggregate time-series with user-level differential privacy. Both works have some limi-tations as we discussed earlier. [31] releases dynamic transaction data under user-level privacy, and set an upper bound to limit the maximum number of updates to handle infinite updates. But it can only handle insertions updates.

The most recent work that is closely related to our work is Kel-laris et al. [18] which deals with differentially private release of events or histograms for infinite stream. It proposes a w-event pri-vacy framework by combining user-level and event-level privacy, which protects any event sequence occurring within any window of w timestamps. It is event-privacy with w = 1 and converges to user-level privacy with w = infinity. They also proposed two mech-anisms, Budget Distribution (BD) and Budget Absorption (BA), to allocate the budget within one w-timestamp window. The key dif-ference between our work and [18] is that our methods detect the data dynamics and adaptively adjust the distance threshold for sam-pling such that the privacy budget is not depleted prematurely due to high update and sampling rates or insufficiently utilized due to low update and sampling rates. In [18], privacy budgets may be depleted prematurely, especially when w is very large, or not fully utilized during the w timestamps. In addition, our method is inde-pendent of the histogram method used for each time point and can utilize any state-of-the-art histogram methods designed for static data release as a blackbox. In our experiments, we compare our methods with BD and BA in [18], since they represent the state-of-the-art and have been shown to perform better than other existing work.
Our distance threshold based sampling builds on top of the sparse vector technique [15] originally proposed for releasing differen-tially private counts only when the counts are greater than a thresh-old. The sparse vector technique has also been used in [19] for releasing top-k frequent itemsets given a static transaction dataset and a threshold derived from the kth frequent itemsets. In our work, we use the sparse vector technique in a novel way to enable dif-ferentially private distance based sampling for releasing dynamic datasets while adaptively adjusting the distance threshold.
In this section, we formally define the problem of releasing se-ries of real-time dynamic histograms or datasets and introduce def-initions on user-level differential privacy and w-event privacy. We summarize all frequently used notations in Table 1.

Let N denote the total number of time points. Let D denote a series of original dynamic datasets and D i be a dataset snapshot at time stamp t i . We assume all snapshots have the same domain universe U , the product of domains of all attributes. For every t we are to release a private dataset  X  D i . Over the N time stamps, the series of privately released dynamic datasets  X  D = {  X  N } should guarantee user-level -differential privacy.

In this paper, we call H as a series of original dynamic his-tograms (corresponding to D ) with H i as a snapshot at t a series of released private dynamic histograms with  X  H snapshot at t i . Since a dataset can be transformed to a histogram, and a synthetic dataset can be constructed from a histogram, D and H are interchangeable in this paper.
Intuitively, a randomized mechanism A is differentially private if its outcome is not significantly affected by the removal or ad-dition of any record. -differential privacy is formally defined as Pr [ A ( D )  X  O ]  X  e Pr [ A ( D 0 )  X  O ] , where O is any arbi-trary set of possible outputs of A , D and D 0 are two neighbouring datasets differing in at most one record (i.e. D can be obtained from D 0 by adding or removing at most one record). In our prob-lem definition, an adversary should learn approximately the same information about any individual user given  X  D , irrespective of its presence or absence in D , and one individual can be present in up to N snapshots in D . Two series of dynamic datasets D and user-level neighbors if one can be obtained by adding or removing one individual (including all its occurrences in the snapshots) from the other. Then user-level -differential privacy is defined as below. Let A be a randomized mechanism over two user-level neighbors D , and  X  D which differ in one user X  X  presence in the entire series, and let O be any arbitrary set of possible outputs of A . Algorithm A satisfies -differential privacy iff the following holds Laplace Mechanism. Dwork et al. [11] show that -differential privacy can be achieved by adding i.i.d. Laplace noise to query (  X  1 ,..., X  M ) 0 , where  X  i  X  Lap (0 , GS ( q ) ) , for i = 1 ,...,M , and M is the dimension of q ( D ) .  X  i follows a Laplace distribu-tion with mean zero and scale GS ( q ) , where GS ( q ) denotes the global sensitivity [11] of the query q . The global sensitivity is the maximum L 1 distance between the results of q from any two neighbouring datasets D and D 0 , formally defined as GS ( q ) = sensitivity of any two user-level neighbors D and  X  D is formally de-fined as
For a sequence of DP mechanisms, the sequential composition theorem [22] guarantees its overall privacy as follows: quence of n mechanisms M 1 ,...,M n and each M i provides differential privacy, the sequence of M i will provide ( P ferential privacy.
 Hence, one way to achieve epsilon-differential privacy for the entire series of D is to apply Laplace mechanism for each D i with noise Lap ( N ) , which leads to O ( N ) noise. (  X , X  ) -usefulness. We use a formal utility metric (  X , X  ) -usefulness [3] to analyze the utility of each snapshot  X  D i in  X  D .
D EFINITION 3.2 ( (  X , X  ) -USEFULNESS ). A randomized mech-anism A is (  X , X  ) -useful for queries in class C if with probability 1  X   X  , for every query Q  X  C and a dataset D , A ( D ) = | Q ( D )  X  Q (  X  D ) | X   X  .
W-event privacy [18] is proposed as an extension of differential privacy to address release of infinite streams. It guarantees user-level -differential privacy for every sub sequence of length w (or over w timestamps) anywhere (i.e. it can start from any timestamp) in the original series of dynamic datasets. w-neighboring series of dynamic datasets, D w , and  X  D w , can be defined as the user-level neighbors under any sub sequence of length w anywhere. w-event privacy can be formally given as below: A be a randomized mechanism over two w-neighboring series of dynamic datasets D w , and  X  D w , and let O be any arbitrary set of possible outputs of A . Algorithm A satisfies w-event -differential privacy (or, w-event privacy) iff the following holds
Given our problem of releasing dynamic datasets under user-level privacy, we review some baseline and existing state-of-the-art methods which will motivate our approach. We will also compare our approach with these methods in the experiment section.
Baseline method. A baseline method is to apply existing  X  X ne time X  DP histogram release methods to the dataset at every time point. If each released DP histogram preserves N -differential pri-vacy, the series of N dynamic datasets guarantee -differential pri-vacy by sequential composition theorem. This results in an overall noise of O ( N ) which can be extremely large for large N . In an unbounded setting with N being infinite, this method will not be useful.

Fixed-sampling method. Another potential solution is to re-lease N I DP histograms periodically given a sampling interval I . Privacy budget / N I is allocated to each dataset at the sampling time point, and the entire private dataset series preserve -differential privacy. Unfortunately, the pre-defined sampling interval may not accurately capture the update pattern in the original series of dy-namic datasets, leading to either high perturbation errors if sam-pling too frequently or large update errors if sampling not frequently enough or at wrong time points.

Approaches in w-event privacy. [18] proposes a sampling ap-proach which computes the noisy distance between the dataset at the current time point and the original dataset at the latest sampling point, and then compares the noisy distance with the perturbation noise to be added if current dataset is to be released. If the distance is greater than the perturbation noise, a noisy dataset is released at current time stamp. The perturbation noise is determined by their privacy budget allocation schemes, Budget Distribution (BD) and Budget Absorption (BA), that allocate the budget to different times-tamps in the w-event window. BD allocates the privacy budget in an exponentially decreasing fashion, in which earlier timestamps obtain exponentially more budget than later ones. BA starts by uniformly distributing the budget to all w timestamps, and accu-mulates the budget of non-sampling timestamps, which can be al-located later to the sampling timestamps. A main drawback of their approach is that the privacy budget may be exhausted prematurely (sampling too frequently in the beginning) or not fully utilized dur-ing all w timestamps (sampling not frequent enough), leading to suboptimal utility of the released data.
We propose an adaptive distance-based sampling approach to ad-dress the dynamics of evolving datasets under user-level differential privacy. Instead of generating a differentially private histogram at each time stamp, we only compute new histograms when the up-date is significant, i.e., the distance between the current dataset and the latest released dataset is higher than a threshold. The key ob-servation is that datasets may be subject to small updates at times. Distance-based sampling allows us to release a new histogram only when the datasets have significant updates, hence saving the pri-vacy budget and reducing the overall error of released histograms. In contrast to [18], we use an explicit threshold for distance com-parison to determine the sampling points, which provides two ad-vantages: 1) we can predefine a threshold based on the expected update rate of the data if there is prior domain knowledge, 2) we can dynamically adjust the threshold in a principled way based on data dynamics.

In this section, we first present the basic method, DSFT, which uses a predefined fixed threshold. This will allow us to analyze its privacy property which also applies to our adaptive method and fa-cilitate our description of the adaptive method. We then introduce our adaptive method, DSAT, which dynamically adjusts the thresh-old in a principled way to adapt to the data dynamics.
DSFT (Distance-based Sampling with Fixed Threshold) uses a fixed threshold and is divided into two steps at each time point ti: decision and sampling. The decision step computes a noisy dis-tance between the original dataset H i at current time stamp and the latest released histogram  X  H j and determines if it is larger than a noisy threshold  X  T . If yes, the sampling step generates a new DP histogram  X  H i , otherwise it outputs the previous  X  H privacy budget is divided between the decision ( 1 ) and sampling ( ) steps which are designed to guarantee differential privacy as we will analyze later.

Algorithm 1 presents DSFT. Line 1-4 initializes the privacy bud-get for the two steps, computes the noisy threshold, and releases a DP histogram at the first time stamp. Line 5-11 carry out the deci-sion (line 7-8) and sampling (line 8-9) steps for each time point t if the number of released histograms is below the cutoff point C , and releases the last histogram with all remaining budget. For the distance d ( H i ,  X  H j ) , we use the L 1 distance in our implementation and other distance metrics (e.g. KL divergence) can be also used. Algorithm 1 Distance-based Sampling with Fixed Threshold Al-gorithm (DSFT) Input: D = { D i | 1  X  i  X  N,i  X  Z } , T , C and .
 Output:  X  D = {  X  D i | 1  X  i  X  N,i  X  Z } 1: Set 1 = k , 2 =  X  1 , k is computed due to theorem 5.4; 2: Set  X  T = T + Lap ( 2 X  3: For D 1 , release a DP dataset  X  D 1 with 2 C privacy budget; 4: Set count = 1 , and j = 1 ; 5: for each time point t i with i  X  2 do 6: if count  X  C , then set  X  D i =  X  D j continue ; 7: Set  X  d ( D i ,  X  D j ) = d ( D i ,  X  D j ) + Lap ( 8: if  X  d ( D i ,  X  D j )  X   X  T , then release  X  D i at t 9: else use  X  D j as the release of D i ; 10: if i == N and count &lt; C , then release  X  D N with all 11: end for
In DSFT, a prior knowledge on D is needed for the user to de-termine an appropriate value T . Suppose there exists an optimal value of T which can enable the algorithm to exactly generate C DP histograms. If the threshold T is higher than the optimal value, there will be remaining privacy budgets that are not utilized. On the contrary, if T is smaller than the optimal value, the privacy budget will be exhausted prematurely, resulting in update errors for remaining time points. In this section, we present DSAT, Distance-based Sampling with Adaptive Threshold, that releases a series of DP dynamic histograms while adaptively adjusting the threshold T for each time point, based on data dynamics. With DSAT, we do not have to find an optimal value of T, which may be difficult in practice.

Figure 1 illustrates the framework of DSAT. Intuitively, we wish to have C sampling points over N time points, hence our target sampling rate is C N . Suppose we have released C i histograms at t . If C i i &lt; C N , we need to decrease the threshold to allow more sampling time points, and vice versa. For each t i , we adjust the threshold based on the feedback error between the update ratio at t i and the target ratio C N , which is formally defined below.
D EFINITION 4.1 (F EEDBACK E RROR ). We define the feedback error E i at t i as follows: where C i means the number of sampling time points till t cutoff point, and N is the total number of time points.

DSAT adopts a PID (Proportional-Integral-Derivative) [2], a generic control loop feedback mechanism, to dynamically adjust the thresh-old T over time. Under our problem setting, we redefine the three correcting terms, Proportional , Integral , and Derivative , with the feedback error defined in Equation (1). These three terms are summed to compute the output u i of PID controller at t i . The final PID al-gorithm is defined as: where  X  P ,  X  I ,  X  D are respectively the proportional gain, the integral gain, and the derivative gain, e  X  is the error at t  X  , t time point, t j is the latest sampling time point.

Proportional term : The first proportional term produces an out-put value that is proportional to the current error e i . The propor-tional term can be amplified by the proportional gain  X  P context, the error e i at the current time point t i is calculated by where E i is the feedback error defined in equation (1), parameter  X  is the set point for E i . We assume  X  is 5% in our empirical studies, i.e. the maximum tolerance for the feedback error is 5% . It can be determined by users according to specific applications. The proportional term is defined as  X  P  X  e i .

Integral term : The integral term is to eliminate the cumulated offset through multiplying the sum of the instantaneous error over time by the integral gain. We define the integral term as  X  P  X  = t i  X  w +1 e  X  , where  X  I is the integral gain and w represents the integral time window denoting how many recent errors are taken.
Derivative term : The derivative term determines the slope of error over time and changes the PID output in proportion to this rate of change via the derivative gain  X  D . It is defined as  X  Given the PID error u i , a new threshold T i produced at the current time point t i can be determined as follows: T i  X  1 is the threshold produced at the previous time point t rameter  X  determines the magnitude of impact of PID error on the T . sign ( . ) is a sign function, indicating that if the update ratio is larger than the target ratio C N , we need to increase T less DP histograms and reduce the update ratio, and vice versa. Our DSAT uses only the proportional term in equation 2 in our experi-ment setting, for simplicity. That means, we set  X  P = 1 ,  X   X  D = 0 , and u i is the same with e i as defined in equation (3). Algorithm 2 Distance-based Sampling with Adaptive Threshold Algorithm (DSAT) Input: D = { D i | 1  X  i  X  N,i  X  Z } , T , C and .
 Output:  X  D = {  X  D i | 1  X  i  X  N,i  X  Z } 1: Run step 1,2,3,4 in Algorithm 1; 2: Skip the first M timestamps; 3: for each time point t i with i &gt; M do 4: if count  X  C , then set  X  D i =  X  D j 5: Set  X  d ( D i ,  X  D j ) = d ( D i ,  X  D j ) + Lap ( 7: if count t  X  C N  X  0 , then set  X  T i = max { 0 ,  X  T 8: else set  X  T i = min { 2 ,  X  T i  X  1 + u i } ; 9: if  X  d ( D i ,  X  D j )  X   X  T i then 10: release a DP dataset  X  D i at t i with 2 C budget, and set 11: else 12: release  X  D j ; 13: end if 14: if i == N and count &lt; C then 15: release  X  D N with all remaining privacy budget; 16: end if 17: end for
Algorithm 2 presents DSAT. We use T i to denote the produced threshold at t i and other notations are the same as Algorithm 1. In Line 1, T 1 is set to be T + Lap (  X   X  1,  X  1 is a tiny privacy budget because the initial value T significant in DSAT. We only need to bound it between 0 and 2, which is the domain of the L1 distance. Line 2 uses  X  D first M time points where M is a small integer number to allow a burn-in period and enough discrepancy to be accumulated, avoiding frequent updating of T i during the beginning time periods. M can be user-specified and is not a sensitive parameter besides that it is much smaller than N . The algorithm from Line 3 to Line 12 is similar to Algorithm 1 except Line 6 to Line 8 which use the PID control to adaptively adjust and generate a new threshold T Sensitivity analysis of L 1 Distance. In the sensitivity analysis, we use n p ( n q ) to denote the sum of all histogram bin counts of the histograms H p ( H q ). U is the number of histogram bins. Since the L 1 distance of Algorithm 1 and Algorithm 2 is computed using one private histogram and one original histogram, we only need to protect privacy for the original histogram.

L EMMA 4.1. The sensitivity of L 1 distance d (  X  H p ,H  X  1 , where togram bin counts as n p ( n q ). (Proof omitted due to space limita-tion) Privacy guarantee. Inspired by Hardt et al. [15], we formally provide the proof of privacy guarantee for the decision stage below. The intuition behind theorem 4.1 is that, the noises on both sides of d ( D i ,  X  D j ) + Lap ( 2 C  X  decision stage to be differentially private, even though T is publicly known.

T HEOREM 4.1. In algorithm 1, the decision stage guarantees -differential privacy.

P ROOF . D is a series of dynamic datasets with D = ( D 1 over N time points.  X  D is the user-level neighbor of D , which is  X  D = (  X  D 1 ,...,  X  D N ) . We say  X  D is the user-level neighbour of D if we can obtain  X  D by removing or adding only one individual user from D by the definition in section 3.2.
 beginning with i = 2 , which is the true distance between D where  X  D j is the private dataset released in the latest sampling time point t j . Let  X  d i denote  X  d ( D i ,  X  D j ) , which is the DP L
For all pairs of user-level neighbours D and  X  D , and the corre-sponding L 1 distance vectors d = ( d 1 ,...,d N ) , we need to prove: Because d i is affected only by d i  X  1 at the previous time point, we have Pr D [ d i =  X  d i |  X  d i  X  1 ] = Pr  X  D [ d i = and S C = { i :  X  d i  X   X  T } be the set of indices of  X  sampling time points, we have log( Pr D [ d =  X  d ] Pr P
Now we need to bound the two sums respectively. For the first sum, we can see that (1) independent Laplace noise with Lap ( putation of each L 1 distance needs to access the original histogram once, and (3) | S |  X  C due to the algorithm, so we can obtain the following equation due to sequential composition theorem: X
For the second sum, let A Z ( D ) be the set of all values of the noise variables (  X  1 ,..., X  N  X  1 ) that cause  X  d i  X   X  when the mechanism runs on D , conditioning on  X  T = Z and d  X  d for all i  X  S . Since from D to  X  D , all distances may be increased by at most  X  (i.e.  X  = 2 n  X  1 for the L 1 distance due to lemma 4.1), which will cause each distance to remain less than  X  T if we increase  X  T by  X  . But the distances larger than  X  T may become less than  X  Z 2 = T +  X  +  X  2 , we have:
T HEOREM 4.2. Algorithm 1 and 2 preserve -differential pri-vacy.

P ROOF . For Algorithm 1, the decision stage preserves 1 privacy due to theorem 4.1. Since releasing at most C DP his-tograms guarantees 2 -differential privacy, algorithm 1 preserves + 2 = -differential privacy due to theorem 3.1. For Algorithm 2, since adaptively adjusting threshold (Line 6 to Line 8) uses no raw data, it does not influence differential privacy guarantee, thus Algorithm 2 guarantees -differential privacy.
We analyze the utility of DSFT and DSAT using (  X , X  ) -usefulness in definition 3.2 and show the conclusions in theorem 5.1 and 5.2. Since we assume LPA as the DP histogram release method, the conclusions can be heuristically used as the upper bound when new methods better than LPA are employed. Here d ( H i ,H j ) denotes L 1 distance between H i and H j .
 Error quantification of DSFT. The utility of released datasets at sampling time points are analyzed based on lemma 5.1. The error of datasets at non-sampling time points are obtained via the error bound of the decision stage in lemma 5.2.

L EMMA 5.1. (Sum of Independent Laplace variables [6]) Sup-pose that X 1 ,...,X n are independent Laplace random variables, with each X i following a Lap ( b i ) distribution. Denote Z = P and b M = max i b i . Then for all  X   X  p P n i =1 b 2 i and 0 &lt;  X  &lt; L EMMA 5.2. In Algorithm 1, for any 0 &lt;  X  &lt; 1 , we can obtain This means, with probability greater than 1  X   X  , we can set t non-sampling time points. (Proof omitted due to space limitation.)
T HEOREM 5.1. For a range count query covering m histogram bins on  X  H k , and 0 &lt;  X  &lt; 1 , if k is a sampling time point, we have that Pr {| A k  X   X  A k |  X   X  2 k is a non-sampling time point, we have that Pr {| A k  X  T + 4  X  A k are the query answers on the original histogram H k and the DP histogram  X  H k . Therefore, each released histogram algorithms maintains (  X , X  ) -usefulness for range count queries. Error quantification of DSAT. We analyze the utility of DSAT based on theorem 5.2, and give the conclusion as below.

T HEOREM 5.2. For a range count query covering m histogram clusion is the same as theorem 5.1 and if k is a non-sampling time point, we have Pr {| A k  X   X  A k | X  T k + P k i =1 I i u (1  X   X  ) 2 , where I i is a value being 1 or -1, and dependent on the data, and u i is defined in equation (2). Therefore, each released histogram  X  H k of our algorithms maintains (  X , X  ) -usefulness for range count queries. (The conclusion can be obtained via equation (5) and we omitted the full proof.) Lower bound of the data cardinality. Since the injected noise in the decision stage is related with data cardinality, we analyze the lower bound of data cardinality to guarantee a relatively small injected noise compared to the true L 1 distance. This lower bound can be used to maintain a high accuracy at the decision stage.
T HEOREM 5.3. In DSFT, in order to satisfy (  X , X  ) -usefulness and guarantee the utility of the decision stage, it requires that n  X  be deducted from lemma 5.2) Select the value of k in DSFT. Our algorithm requires to be di-vided between 1 and 2 with 1 = k . We now analyze how to se-lect k . Assume H = ( H 1 ,...,H N ) corresponds to D . For each i , we analyze the incurred noise variance of L 1 distance between H and  X  H i when i is (1) a sampling time point and (2) a non-sampling time point.
 L EMMA 5.3. The noise variance of the L 1 distance between H j and  X  H j , is  X   X  1 = O ( UC P ROOF . We skip this proof due to space limitation.

T HEOREM 5.4. If we use L 1 distance and LPA, the k value can
P ROOF . Since k is only used when analyzing the distance at non-sampling time points, we can obtain the upper bound of noise variance at a non-sampling time point due to lemma 5.3 with 1) By setting  X  k f ( k ) = 0 , we can obtain the value of k as: k = q value of k when f ( k ) arrives at the minimum. Simultaneously, we must require the privacy budget of each sampling time point to be no less than that of each time point in the baseline method, which leads to 2 C  X  N , and k  X  1  X  C N . Therefore, we can obtain that DSAT under w-event privacy. Algorithm 3 presents DSAT under w -event privacy. For the first w time points, we run DSAT normally and record the privacy budget 2 ,i for every time point i , i.e. if i is a sampling point and 2 ,i = 0 otherwise. For time points w + 1 to N , if the remaining privacy budget rm for the current w -window is larger than zero, we compare the distance between H i and  X  H j , modify the threshold and release a private histogram when the private distance is larger than the threshold; if no privacy budget is left, we skip the current time point and go to the next one. Privacy guarantee. The first w time points guarantees -differential privacy. The condition in Line 4 of Algorithm 3 guarantees that if there is no remaining privacy budget ( i.e. rm  X  0 ) for the current w window from time point t i  X  1 to t i  X  w +1 , no new private datasets will be released. Therefore, for any w-length window beginning with any time point, at most privacy budget will be used. This leads to the conclusion that Algorithm 3 satisfies w-event privacy.
We implemented our methods on top of two static histogram methods, LPA in Matlab and PSD [7] in Python. All the experi-ments are performed on a PC with a 2.9GHz CPU and a 8GB mem-ory. Table 2 summarizes the parameters and their default values in the experiments.
 Algorithm 3 DSAT under w-event privacy Input: Output: 1: Run DSAT for the first w time points; 2: for i = ( w + 1) to N do 4: if rm  X  0 then 5: Set  X  D i := D j , where j is the time point of last release; 6: else 7: Set count = P 8: Compute  X  d ( D i ,  X  D j ) = d ( D i ,  X  D j ) + Lap ( 11: else set  X  T i = min { 2 ,T i  X  1 + u i } ; 12: if  X  d ( D i ,  X  D j )  X   X  T i , then set 2 ,i = 2 13: else set  X  D i := D j ; 14: end if 15: end for Datasets. We conducted our experiments with three datasets: the US census ( http://ipums.org ), the Taxi-Drive trajectory data ( http://research.microsoft.com/apps/ ) and the Old-enburg traffic data [5].

The US census dataset contains six attributes, Age , Gender , Ed-ucation , Health insurance , Marital status and Income with 3M tu-ples and domain sizes of 96 , 2 , 12 , 2 , 2 , 3 . Each tuple represents an individual user. In order to avoid the sparsity of histograms, we convert Income into a categorical attribute: values smaller than 0 (mapped to 1), values between 0 and 28K (mapped to 2), and val-ues larger than 28K (mapped to 3). 28K is a median value. Values smaller than 0 means the tuples have ages smaller than 20. The number of histogram bins are the product of the domain sizes of all attributes.

We generate a series of dynamic datasets as follows. D i is the original dataset at t i . D 1 has 500K tuples randomly sampled from the original 3M tuples. A public pool is initiated using the remain-ing tuples. D i ( i  X  2 ) is obtained by deleting m tuples from D while inserting m tuples randomly selected from the public pool to simulate the user updates. m is sampled from N (  X , X  2 ) , where  X  is is the data cardinality of D i and datasets at all time points have the same data cardinality. The time points are partitioned into 10 periods with different values of m to simulate varying update pat-terns. All experiments use US census data by default since we can generate various datasets under different parameter settings.
The Taxi trajectory dataset has a one_week trajectories of 10 , 357 taxis during the period of Feb. 2 to Feb. 8, 2008 within Beijing. We transfer the time dimension to 168 time points with 24  X  7 . The total number of points in this dataset is about 15 million and the total distance of the trajectories reaches 9 million kilometers. We partition the longitude and latitude into 10  X  10 grids. We am-plify the number of taxis to 110 , 357 by sampling dummy points on extremely sparse time points and geographical areas while still keeping the patterns of original data.

We generated Oldenburg traffic data with the Brinkhoff gener-ator [5]. The input of the generator is the road map of Oldenburg in Germany, and the output is a set of moving objects on the road net-work. We created the data set with 1000 discrete timestamps, with 500,000 objects at the beginning. A 2D grid with 1024  X  1024 cells is used to record the locations of the moving objects.
 Comparison. We evaluate the utility of the private DP histograms of dynamic datasets by answering random range count queries. The query accuracy of DSAT is compared with three solutions de-scribed in Section 3: the baseline Laplace mechanism, the fixed-sampling method, and the state-of-the-art w-event privacy methods. LPA and PSD [7] are used to generate DP histograms at sampling time points. We note that our proposed sampling framework can utilize any state-of-the-art static histogram method at each sam-pling point. Here we just use, as an example, the standard LPA method as well as the PSD method [7] which is a state-of-the-art static histogram method that uses spatial partitioning. The goal is to compare our proposed methods and the three solutions. We also include the non-private methods to compare the update errors of DSAT and fixed-sampling.
 Metrics. For the US census dataset, we generated random range-count queries with random query predicates on each attribute de-fined in the SQL format as  X  X elect COUNT(*) from D , Where A 1  X  I 1 and A 2  X  I 2 and ... and A m  X  I m ". I i is a random interval generated from the domain of attribute A i . For the traffic data, query rectangles with various sizes are randomly generated. In each experiment run, 5000 random queries are generated and the average absolute error over 10 runs is reported, which is defined as E  X  A i is the noisy answer. Here we use the range-count query to mea-sure the utility since it composes data histograms, and the range counts can be used for many significant mining tasks, e.g. dynamic stream clustering, outlier detection of time-series data, etc.
In all experiments, we compare our methods with the baseline and fixed-sampling methods, which are denoted by  X  X aseline" and  X  X ixed" in figures. Unless specified, we use LPA by default as the underlying histogram method for the sampling point. We also use  X  X SAT-true" and  X  X ixed-true" to denote the non-private versions of DSAT and fixed-sampling.
 Absolute error vs. k. Figure 2 investigates how utility changes with various k values, which specify the budget allocation ratio be-tween 1 and 2 for the decision and sampling stages respectively. With the value of C being 10, we compute k to be 0.0532 due to theorem 5.4. From Figure 2, we can observe that the empirical re-sult matches the theoretical result well and the utility reaches the optimal value with k between 0.01 and 0.1. The error increases as k becomes larger or smaller than 0.1 or or 0.01, respectively. This is reasonable because larger k may lead to more perturbation error while smaller k values result in more update error.
 DSFT and DSAT. In this experiment, we compare our proposed two methods DSFT and DSAT. From figure 3, we can observe that the error of DSFT is very sensitive to the threshold value T. As T initially increases, the error decreases thanks to the decreased per-turbation error. As T further increases, the error increases back up due to the increased sampling error which becomes the dominant error. Without prior knowledge, it is difficult to determine the op-timal T. However, the average absolute error of DSAT is close to the lowest error of DSFT with the optimal threshold T value being around 0 . 025 . Here the initial value of T for DSAT can be arbi-trarily selected. Thus, the DSAT method with the PID control can effectively adjust T to an optimal one. In the remaining experi-ments, we only use DSAT to compare with other methods. Absolute error vs. differential privacy. Figure 4 compares DSAT with other methods under various privacy budgets. The larger the privacy budget is, the closer the query accuracy is to non-private versions. Since the baseline performs one order of magnitude worse than other methods in most experiments, we do not include them for better readability of the graphs. The perturbation errors for fixed-sampling and DSAT are almost similar as the number of re-leased DP histograms are the same. DSAT outperforms fixed-sampling because DSAT has much less update error, which can be seen from the comparison of non-private versions. Figure 4(b) uses the taxi trajectory dataset and Figure 4(c) uses PSD to release DP histograms with 3D US data. We can see that by using PSD, errors are gener-ally improved compared to the ones using LPA. This further con-firms that our methods can take advantage of any state-of-the-art static histogram methods for each sampling point.
 Absolute error vs. update rate. We study the impact of the up-date rate r (defined in section 7.1) on the query accuracy for dif-ferent methods, as shown in Figure 5. All methods remain stable for various update rates. The DSAT performs better than both non-private and private fixed-sampling methods. This is because the up-date error of non-private DSAT is much less than non-private fixed-sampling. This further verifies that our DSAT with PID controller succeeds in adaptively adjusting the threshold and the location of the sampling time point, leading to better performance.
 Absolute error vs. dimensionality. Figure 6 examines the ab-solute error with various numbers of dimensions in the US dataset. DSAT again outperforms both non-private and private fixed-sampling methods with the dimensionality from 3 to 6 . One interesting phe-nomena we observe is that the performances of non-private and private fixed-sampling methods improve sharply after five dimen-sions. This can be explained by the fact that a higher dimensionality results in a larger number of histogram bins. Given a threshold T , if the L 1 distance between two datasets D i and D i  X  1 is below T, the previously released histogram will be used which incurs an up-date error. Given the same L 1 distance between two histograms, a larger number of bins would result in a smaller measured update error since the average difference for each histogram bin is smaller. Hence the fixed sampling methods show a dramatic drop in the er-ror which is dominated by the update error. The DSAT methods are less sensitive to the number of dimensions because they already mitigate the update error by tuning the threshold adaptively. Hence the non-private DSAT shows a slight drop in the update error while the private DSAT shows a slight increase due to the dominating perturbation error.
 Query accuracy vs. query range size. We study the impact of the query range size on the query accuracy for different methods. For each query range size, we randomly generated queries such that the product of the query ranges on each dimension equals the given size. Figure 7 presents the impact of various query range sizes on query accuracy in terms of relative error and absolute error. The where s is the sanity bound to mitigate the effect for A DSAT outperforms the private fixed-sampling method. The differ-ence of relative errors between all methods is not obvious because of the large data cardinality in the US data. For all methods, the relative error gradually degrades as the query range size increases while the absolute error has the opposite trend. The reason is that when the query size is small, the true answer A k i is also small which may incur a small absolute error but large relative error. In this ex-periment, the sanity bound s is set to 1 . Query accuracy vs. parameter w . We use the Oldenburg traffic data in this experiment, since it contains 1000 timestamps that is sufficient to investigate the impact of w. We compare DSAT with BD and BA in [18] under w-event privacy framework while vary-ing w values. BD and BA are implemented by using column par-titioning technique and setting 1 = U as recommended in [18]. From figure 8, we can see that the gap between DSAT and BD or BA expands greatly as w increases. This is because our technique adaptively adjusts the threshold and allocates the privacy budget more appropriately. In contrast, BA and BD may not fully utilize or in advance exhaust most budget during w timestamps.
 Query accuracy vs. differential privacy. In this experiment, we set w to be 800 using Oldenburg traffic data with 1000 timestamps. Figure 9 compares DSAT with BA and BD under various privacy budgets. We can see that BA degrades dramatically and the gap between BA and DSAT greatly expands as we reduce the privacy budget . This is because BA starts by uniformly distributing the budget to all w timestamps, and more perturbation error will be incurred when is small and w is large. Our DSAT performs well since the perturbation error of released datasets depends only on C .
In this paper, we have proposed an adaptive distance-based sam-pling approach to address the challenges of releasing a series of differentially private dynamic datasets in real time. With an upper bound to limit the number of DP data releases, our methods incur much smaller errors. We apply an adaptive control mechanism to dynamically adjust the threshold value. We also provide privacy and utility analysis for our method. Experiments on real and syn-thetic datasets show that our algorithm outperforms the baseline and existing state-of-the-art techniques. As future work, we would like to study update models and incorporate them into our sampling framework. We are also interested in applying the adaptive sam-pling framework for releasing other types of dynamic data with dif-ferential privacy, e.g. frequent patterns for dynamically changing transactional data and dynamic graph patterns in social networks. This work is supported by the National Institute of Health (NIH) under award number R01GM114612, the Patient-Centered Out-comes Research Institute (PCORI) under award number ME-1310-07058, and the National Science Foundation (NSF) under award number 1117763, and partly supported by NLM (R00LM011392), NLM (R21LM012060), and NHLBI (U54HL108460). The content is solely the responsibility of the authors and does not necessarily represent the official views of the funding agencies.
