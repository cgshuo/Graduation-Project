 World steel trade becomes more competitive every day and new high international quality standards and productivity levels can only be achieved by applying the latest compu-tational technologies. Data driven analysis of complex pro-cesses is necessary in many industrial applications where analytical modeling is not possible. This paper presents the deployment of KDD technology in one real industrial problem: the development of new tinplate quality diagnos-tic models.

The electrodeposition of tin on steel strips is the most crit-ical stage of a complex process that involves a great amount of variables and operating conditions. Its optimization is not only a great commercial and economic challenge but also a compulsion due to the social impact of the tinplate product -more than 90% of the production is used for food packaging. The necessary certification with standards, like ISO 9000, requires the use of diagnostic models to minimize the costs and the environmental impact. This aim has been achieved following the multi-stage DM methodology CRISP-DM and a novel application of pro-active maintenance methods, as FMEA, for the identification of the specific process anoma-lies. Three DM tools have been used for the development of the models. The final results include two ANN tinplate quality diagnostic models, that provide the estimated qual-ity of the final product just seconds after its production and only based on the process data. The results have much bet-ter performance than the classical Faraday X  X  models widely used for the estimation.
 Categories and Subject Descriptors: I.5.2 [Pattern Recognition]: Design Methodology General Terms: Algorithms, Management, Design.
 Keywords: Tinplate quality, ANNs, CRISP-DM, FMEA.
Steel is one of the leading materials used for attractive, convenient and cost-effective packaging today. There are several types of packaging steel for different container ap-plications and the most commonly used is the tinplate. Its name derives from the thin layer of tin that is electrolytically applied to a low carbon steel base. In this process the steel strip passes trough several tanks increasing its tin coating thickness. These tanks contain the electrolyte and the pure tin anodes so when there is a voltage difference between the tin anodes and the steel cathode, the tin plating takes place.
The thickness of this microthin layer of tin is crucial. It depends on the type of application varying from the lowest values  X 0.9 g/m 2  X  to the highest ones  X 14 g/m 2  X . Too low tin coating thickness accelerates corrosion which may spoil the food packed in steel cans with undesirable conse-quences for public health. On the other hand, the effects of too high coating thickness are not so dramatic but it makes difficult the following stages of production and increases the cost dramatically.

However, coating thickness measurement for diagnosis pre-sents many difficulties. The on-line systems, based on ra-diographic techniques, provide a precise measure of several features along the strip but they have two main problems: they are very expensive and they require many safety and maintenance checks.

So being the coating thickness a critical parameter of the tinplate quality requirements, this paper propose a novel quality diagnostic model that meets the new ISO-9000 stan-dards and it is just based on the process data with no other additional measurements.

The paper is organized as follows. In section 2, a brief description of a tinplate line is given. Then, it is intro-duced the necessity of control of the coating thickness, the currently on-line measurement systems and the different ex-isting models. Section 3 shows in detail the data mining process carried out for obtaining the new models and fol-lowing the multi-stage methodology CRISP-DM 1 . Finally, section 4 concludes the paper.
CRoss-Industry Standard Process for Data Mining
Currently, tinplate is used for a variety of consumer and commercial applications. It offers particular advantages for packaging such as strength, workability, corrosion resistance and weldability. It is also environmental friendly being com-pletely recyclable and having an energy-efficient production process [1]. 1. Entry section which levels the coil through a com-2. Pre-treatment section which realizes the cleaning of 3. Treatment section (tinplating) with nine vertical 4. Exit section with a differential marking treatment,
In general, metallic coating is defined by its thickness, porosity, adhesion and resistance to service conditions. In the case of tinplate, the tin coating determines both the ca-pacity of isolation and the following treatments of the ma-terial (lacquers, oils, etc.). These treatments improve the external image of the product and protect the contents from the environment.

In the past decades, average tinplate thickness has been reduced both for economic and environmental reasons in-creasing the process complexity. An important effort in terms of R&amp;D devoted to the tinplate production is focused on improving the coating thickness applied.

At the same time, industrial enterprises are increasingly aware of the need to improve product quality and productiv-ity developing and implementing appropriate quality man-agement system solutions. New edition of ISO 9001:2000 [3], increases emphasis on the determination and use of not only statistical methods as SPC (Statistical Process Control) but also predictive based on:
Radiometric gauging is the most widespread option for on-line measurement of coating thickness. This kind of gauges operate by means of gamma radiation. Their main draw-backs are the impossibility of locating the obtained measure-ments with a high degree of accuracy, due to the off-center strip movements, their high price and its requirement of fre-quently calibration.

Most of the approaches to improve the final coating qual-ity are based on the Faraday X  X  law of electrolysis. It states that the amount of material deposed in the cathode (steel strip for us) in the electrolysis process is proportional to the electrical charge and the equivalent weight of the substance (tin in our case). Due to other non-metallic substances (like Hydrogen) the final amount of substance on the strip is not the theoretically expected.

The thickness model takes into account all these factors in one K with a set value for each thickness. The given formula is I = K  X  a  X  v , in which I is the current in the rectifiers, v is the line speed, a the strip width and K the coating factor.

Other models try to overcome the excessive simplicity of the Faraday X  X  law with the integration of the main principles of the mass movements equations. These methods manage extremely complex equations, usually solved with FEM, so are not an adecuate answer to the plan necessity for quick diagnosis. This section describes in detail each phase of the Data Mining process that was carried out following the multi-stage methodology CRISP-DM [4].
Previous knowledge . The most important factor for the coating is the current applied. At present, it is deter-mined based on the customer order data, by applying the generic Faraday formula with a specific factor fixed experi-mentally. The advantages of this system are its simplicity, calculation speed and excellent expert knowledge. The dis-advantages are that the system is not adaptive and it does not take into account all the influences that are relevant to the problem.

Business objectives . Classification of coils by average coating thickness, based on process conditions. This pro-vides an increased quality for customers with very specific requirements, increased productivity thanks to higher pro-cess speeds, improved environmental performance, reduced costs thanks to a reduction in the amount of tin deposited on the strip and decrease rejections.

Success criteria . 95% of the coils classified within the correct range. The determination of the relevance of certain process variables which have a notable environmental impact (cleaning and pickling) in order to minimise them as well as better capability to meet certification requirements.
Resources . On-line process data recorded at three dif-ferent process levels. The sources of knowledge used are the expert knowledge of the technical team and the mainte-nance staff, the performance reports, the description of the production line and the FMEA 2 analysis of the facility.
Risks and contingencies . There are both market-related risks, resulting from competition, and technical risks, mainly
Failure Mode Effect Analysis due to the potential unreliability of some of the data and to the many factors external to the line that influence the pro-cess, as was observed in the FMEA analysis [5], [6]. Another key issue is the communication between the various operational levels, where data synchronization is an essential requirement.

Benefits . The implementation of a new formula for cal-culating the setpoint enabling the excess coating to be re-duced by 30% could lead to savings estimated at 0.5 MEu-ros/year. The indirect benefits include minimisation of the environmental impact and an enhanced understanding of the production process.

DM objectives and success criteria . For 95% of the cases, an error of less than 10% in the predicted average quantity of tin deposited on the coil, for given conditions of relevant variables. The success of the project will be assessed by comparing two models: the classical Faraday model and the model adjusted by the technical team.

Planning . The task distribution entailed about two years X  work. The critical points were the definition of objectives, proper data understanding and collection, adequate prepa-ration and classification of the operating standards for train-ing the models, and a realistic implementation on-site.
Tools and techniques . From among the various DM tools available, the solution selected was Data Tools , based on versatility and cost criteria. It is a tool developed by BFI supported on Matlab toolboxes and proprietary algorithms.
Data acquisition : There is a data log corresponding to six months X  production, amounting to 3Gb of information. The selection criterias were:
Data description : From all the variables available, the proposed list of 21 most relevant ones, drawn-up in collab-oration with the facility staff, is the following:
Betriebsforschungsinstitut GmbH
Data quality verification : In order to study the plausi-bility of the data it is necessary to apply a series of physical ranges for the key variables. The main alarms are those related to concentrations, temperatures and currents.
A particularly important point is the evolution of the cur-rent variable as a function of its setpoint values [7]. It shows a certain hysteresis that prevents a linearization between the current setpoint value and the measured one. The variation observed in the data involved in this relationship (which should be linear) led to the implementation of a contingency plan in collaboration with the maintenance department, re-sulting in the launch of a new data acquisition campaign.
After a preliminary analysis of the data, the TEMP E1 vari-able was rejected in view of the low quality of the input data. The physical plausibility tests for the rest of the variables were valid.

Data exploration : The basic statistical analysis of the data shows the suitability of the study, in view of the differ-ences existing between the target and the actual thickness measured, the low quality of the data for the voltage-related variables and the limited variability observed in some of the electrolyte variables [8], [9].

Figure 2 shows the high degree of correlation existing be-tween some of the data that characterise the electrolyte: these are basically the electrolyte concentrations, tempera-tures and levels. A high degree of correlation is also observed between the actual and target coating, and between the cur-rent applied on each side of the strip. Logically, there is also an inverse correlation between the coatings applied on the top and bottom side of the strip and the speed of the line.
The identification of data sets is based on the analysis of the target variables TARG T and TARG B . As can be seen in fig-ure 3, the distribution of coating thicknesses varies with the
Figure 4: Target vs actual coating histogram. strip side: medium and low coating thicknesses are mostly observed on the bottom side whereas low and high ones are more predominant on the top side. This implies that the major operating limitations of the line (speed) are usually determined by the setpoint values of the top side.
In figure 4, the histograms of the target variable TARG T are displayed according to the equivalent histograms of the variable COAT T classified according to five groups generated with C-means . The circles indicate the three zones of low, medium and high coating thickness observed in the other variable.

This type of analysis applied to different groups of vari-ables led us to the following conclusions:
The clustering tasks required for downstream tools, GAs and DT s algorithms applied deal with discrete target vari-ables, were also carried out in this stage. By using a knowl-edge processing similar to that applied in the Delphi method-ology, a classification into three groups of high, medium and low thicknesses homogeneous in terms of volume and with regard to the three basic variables (current, target values and speed) was achieved.
 Mathematical selection of relevant variables : The Self-Organizing Map (SOM) method is a powerful algorithm for the visualization of high-dimensional data [10], [11]. Par-ticularly insightful are the so called component planes rep-resented in figure 5, that provide us with a big picture of the input values distribution. Similar maps show an analogous behavior and, therefore, a redundancy in the information. This leads to the following conclusions: TARG T and COAT T projected in the same way in the visualization space. The same applies to COND , TEMP E1 , TEMP T1 , LEVEL T1 and TEMP E2 and to pH , TEMP T2 and LEVEL T2 .
For the variable selection criteria, the three main sub-groups created were used, and genetic algorithms ( GAs ) and decision trees ( C 4 . 5 &amp; OC 1) were applied. The aim is to identify the combination of variables that contain more in-formation about our target variables and subsequently those that show the best classification performance. The algo-rithms results are shown in figure 6 as a histogram with the most frequently selected variables for growing the trees and the most important ones used in the GAs individual input combination, thus leading to the following 12 key variables: Figure 6: DTs &amp; GAs algorithms variables selection.
Starting with several dozens of variables, the problem was reduced to twelve inputs. Having selected the relevant vari-ables, the available cases are filtered according to their rel-evance for the analysis eliminating tuples that affected by some contained in the FMEA document. With the above re-strictions, the number of cases to be processed is reduced to a data set of about 1300 coils which means a 50% reduction on the initial number of cases.
The desired output of the model is a forecast of the tin coating, enabling us to determine, for any condition that may arise in the production line, whether the final coating will be excessive, adequate or insufficient.

Description : The plan for the design of new models in-cluded the following phases: in a first phase, we worked with all the variables requested by the technical team (21); then, we eliminated the variables showing a linear correla-tion greater than 0.99 (18 variables remained); next, the variables previously considered as not highly relevant were eliminated, leaving 12 and then the first 8 variables of figure 6. Finally, a minimal model is drawn-up with the 4 inputs of Faraday X  X  law.

Using this sequence of (21/18/12/8/4) inputs, we start with a linear regression model that serves as a base compar-ison, evolving to Multilayer Perceptron (MLP) models with Bayesian learning features and sigmoidal activation func-tions. The whole data set is balanced split: 50% for train-ing, 25% each for validation and testing. Then, the models obtained are run on 250 coils that cover the whole product-mix, enabling us to reproduce their behaviour under real conditions. Figure 7 shows the evolution of the errors rates for some cases. Those models calculated using the eight in-puts preselected in section 3.2 show the best performance in terms of error rates. Then, we look through them.
Models : Figure 8 shows the results obtained from check-ing the linear model. As it can be seen in (1), the average value is not bad, but shows very high residues (2) and a single output for high values (3). Then, MPL models were formulated. The results achieved when checking the MLP 8G-I model (see figure 9) are very promising and show a 35% improvement on the linear model; in this case, the problems lie in the presence of residues of very high values (2) and, especially, in the area of low coating thicknesses outside the safety band (3) [12].

In view of the good results achieved with the previous model, tests were performed using another learning algo-rithm. The result in average values (see figure 10) was good: an 85% improvement on the performance of the linear mod-els and a 21% improvement on the best previous model. It explains 99 . 7% of the cases (LCC) and its behaviour in terms of absolute and relative residues is optimal, enabling us to configure the forecast in a much narrower range than origi-nally targeted for medium and high coating thicknesses. The only drawback appears in three coils with medium coating thickness, where problems arise. In view of the high perfor-mances of the model, we study these specific cases.
Among the average coating thickness verification vari-ables, a series of atypical cases were observed in the cur-rent variable and these cases coincide with the maximum errors of the model. These three values, which lie outside the system logic were the cause of the outliers of the model. The results obtained for the bottom side coating model are very similar to that of the top side coating, as it could be expected [12].

Finally, the model proposed by Data Tools was validated by comparing it to two other tools, namely Clementine and MARS , for the selection of variables and modeling. The model proposed is also a MLP with the same selection of variables. A high degree of consistency was shown in all the results obtained.
The main conclusion to be drawn from this work is the development of two tinplate quality diagnostic models (one for each side) that provide the estimated quality of the final product just based on the process data. Both of them are multilayer-layer perceptron networks with Bayesian learning and sigmoidal activation functions. These models improve the accuracy of classical Faraday X  X  linear models explaining 99 . 7% of the cases and showing a good performance in terms of absolute and relative residuals. The economical impact of this model is, beyond any doubt, very important.
Another excellent output has been to show the relevance of a set of variables, not taken into account before, by means of the application of both classical and advanced statisti-cal data analysis techniques and other structured processes for collecting and distilling knowledge. The list of relevant variables was also a combination of expert knowledge pro-vided by maintenance (FMEA) and production experts. Fi-nally, this aim has been achieved following the CRISP-DM methodology and according with new ISO 9000 standards. [1] E. de la Toba. El Proceso Siderurgico . ACERALIA, [2] V. Ferrari, F. Sanfilippo, N. Di Biase, E. Musella, [3] Iso 9000 international standards for quality [4] P. Chapman, J. Clinton, J. Hejlesen, R. Kerber, [5] D. Stamatis. Failure mode and effect analysis. 1996. [6] S. Keplinger. A new plant-wide system for quality [7] N. de Abajo, S. Peregrina, J. A. Gonzal  X alez, and [8] H. Peters, T. Heckenthaler, and N. Holzknecht. [9] H. Peters, T. Heckenthaler, and N. Link. Application [10] S. R. Cuesta, I. D  X  X az, A. A. Cuadrado and A. B. Diez. [11] A. A. Cuadrado, I. D  X  X az, A. B. Diez, F. Obeso, and [12] N. de Abajo. Optimizaci  X on mediante Data Mining de
