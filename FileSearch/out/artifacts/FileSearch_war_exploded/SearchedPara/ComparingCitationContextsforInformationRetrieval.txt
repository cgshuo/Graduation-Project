 In previous work, we have sho wn that using terms from around citations in citing pap ers to index the cited pap er, in addition to the cited pap er's own terms, can impro ve re-triev al e ectiv eness. Now, we investigate how to select text from around the citations in order to extract good index terms. We compare the retriev al e ectiv eness that results from a range of con texts around the citations, including no con text, the entire citing pap er, some xed windo ws and sev eral variations with linguistic motiv ations. We conclude with an analysis of the bene ts of more complex, linguisti-cally motiv ated metho ds for extracting citation index terms, over using a xed windo w of terms. We speculate that there migh t be some adv antage to using computational linguistic techniques for this task.
 H.3.3 [ Information Searc h and Retriev al ]: Information Searc h and Retriev al; H.3.1 [ Con ten t Analysis and In-dexing ]: Linguistic Pro cessing Measuremen t, Exp erimen tation IR evaluation, Citation con text analysis
Citation information has been used for IR since the early days of the eld, with a tradition of using citation metho ds that are statistical in nature. For instance, two of the core principles used are bibliographic coupling [11], where two documen ts are said to be coupled if they share one or more The rst author gratefully ackno wledges the supp ort of Microsoft Researc h through the Europ ean PhD Scholarship Programme.
 references, and co-citation analysis [26], where the similar-ity between documen ts A and B is measured by the num ber of documen ts that cite both A and B. There has been a recen t resurgence of interest in using citations, both in IR and further a eld. However, while the poten tial usefulness of the text used in asso ciation with citations ( citation con-text analysis ) has been noted in relation to, e.g., text sum-marization [30, 25], thesaurus construction [24] and other tasks, recen t work in IR has con tinued to focus on statis-tical citation data, like citation coun ts and PageRank-st yle metho ds, e.g., [28, 6, 14]. We have previously sho wn that full-text IR on scien ti c pap ers can be impro ved with cita-tion information, by using terms from the citing documen t to additionally describ e (i.e., index) the cited documen t [23]. This idea of using terms external to a documen t for index-ing, coming from a `citing' documen t, is also used in Web IR. Citations are quite like hyperlinks and link structure, in-cluding anc hor text, has been used to adv antage in retriev al tasks [13, 7]. In this comparable situation, web pages are of-ten poorly self-descriptiv e [2], while anc hor text is often an external description of the pointed-to page. Thus, beginning with [13], there is a trend of propagating anc hor text along its hyperlink to asso ciate it with the link ed page, as well as that in whic h it is found. Google, for example, includes anc hor text as index terms for the link ed page [2].
We now explore how best to nd the terms asso ciated with a citation in order to index them. No explicit anc hor text exists in scien ti c pap ers, unlik e in web pages, where there are HTML tags to delimit the text asso ciated with a link. Iden tifying whic h terms are asso ciated with a ci-tation is an interesting, complex problem, whic h has been discussed in depth [17, 22]. These indep enden t case stud-ies, on di eren t domains, have eac h pro vided evidence to suggest that computational linguistics (CL) techniques may be useful for more accurately locating these citation terms, e.g., using topic shift detection to indicate when the text has moved on from the sub ject of the citation. However, it does not necessarily follo w that a practical metho d based on these observ ations would be any more successful than sim-pler techniques, e.g., using a xed windo w. In order for any real impro vemen t in retriev al e ectiv eness, the documen t represen tation would have to be signi can tly altered by ci-tation terms. Enough terms, in particular rep eated terms, would have to be successfully found via citations for suc h a quan titativ e impro vemen t. With a new test collection of sci-enti c pap ers with citation information, we are now able to exp erimen tally investigate whether CL techniques will im-pro ve over the statistical e ects of redundan t data.
Previously , we have indexed the terms from the sen tence that con tains the citation; this is only one of man y possi-bilities. In other related work, Bradsha w used terms from a xed windo w around citations [1], while Dunlop and van Rijsb ergen used the abstracts of citing pap ers [5]. In this pa-per, we investigate the issue of nding good index terms for IR around citations and whether terms found using linguis-tically motiv ated metho ds can result in better retriev al per-formance. We do not attempt a comprehensiv e exploration of CL techniques here: that is beyond the scop e of our inves-tigation. We do, however, compare a num ber of alternativ e con texts that range in size and complexit y, some of whic h are very basically linguistic in nature (e.g., use kno wledge of sen tence boundaries), to pro vide evidence for the question of whether CL techniques can help impro ve citation-based IR, in practice. The con tributions of this pap er are:
The idea of taking the terms that citing authors use to describ e a cited work and using them as index terms for the cited pap er is not new, predating the analagous use of anc hor text in Web IR. In 1982, O'Connor motiv ated the use of words from citing statements as additional terms to augmen t an existing documen t represen tation [17]. More re-cen tly, Bradsha w implemen ted Refer ence-Dir ected Indexing (RDI), whereb y a scien ti c documen t is indexed by the text that refers to it in citing documen ts [1], instead of by the text in the documen t itself, as is typical in IR. The theory behind RDI is that, when citing, authors describ e a docu-men t in terms similar to a searc her's query for the informa-tion it con tains. Thus, this refer ential text should con tain good index terms for the documen t and Bradsha w sho ws an increase in precision over retriev al by the documen t terms alone, using a standard vector-space mo del implemen tation; 1.66 more relev ant documen ts are retriev ed in the top 10 in a small evaluation on 32 queries.
 However, a num ber of issues may be raised with RDI. Firstly , referen tial text is extracted using CiteSeer's citation context (a windo w of around one hundred words around the citation). This metho d is simplistic: the terms that are def-initely asso ciated with a citation are variable in num ber and in distance from the citation, so a xed windo w will not accurately capture the citation terms for all citations. In-deed, Bradsha w states the dicult y in extracting good in-dex terms automatically from a citation, echoing O'Connor. However, Bradsha w's exp erimen t is limited by the use of the Citeseer data and he does not compare with any alternativ es to the xed windo w. Secondly , RDI only indexes referen tial text, and not the terms from the documen ts themslev es, so a documen t must be cited at least once (by a documen t available to the indexer) in order to be indexed. This has particular consequences for recen tly published documen ts, as it tak es time for works to be disseminated, resp onded to and eventually cited. RDI mak es no `fall-bac k' pro vision for uncited documen ts; Bradsha w's evaluation excluded any documen ts that were not cited and does not disclose how man y of these there were.

Dunlop investigated a similar technique with a di eren t application in mind (i.e., retriev al of non-textual documen ts, suc h as image, sound and video les [5]). Dunlop's retriev al mo del uses clustering techniques to create a description of a non-textual documen t from terms in textual documen ts with links to that documen t. In order to establish how well descriptions made using the mo del represen t documen ts, the metho d was applied to textual documen ts, indeed, to the CA CM test collection, where the links between docu-men ts were citations. The exp erimen t compared retriev al performance using the cluster-based descriptions against us-ing the documen ts themselv es; the cluster-based descriptions achiev ed roughly 70% of the performance from using the documen t con ten t. Again, however, Dunlop did not mea-sure the performance using the cluster-based descriptions in com bination with the documen t con ten t. Additionally , the text tak en from the citing pap ers was simply the abstract and not speci cally the text used in asso ciation with the citations.
 O'Connor's study is closest to our own work. Though O'Connor did not have mac hine-readable documen ts, pro ce-dures for `automatic' recognition of citing statemen ts were dev elop ed and man ually carried out on a collection of chem-istry journal articles. Pro ceeding from the sen tence in whic h a citation is found, a set of hand-crafted, mostly sen tence-based rules were applied to select the parts of the citing pa-per that con veyed information about the cited pap er. The selected statemen ts (min us stop words) were added to an existing represen tation for the cited documen ts, compris-ing human index terms and title and abstract terms, and a small-scale retriev al exp erimen t was performed. A 20% increase in recall was found using the citing statemen ts in addition to the existing index terms, though in a follo w-up study on biomedical pap ers, the increase was only 4%; O'Connor attributes this to a lower average num ber of cit-ing pap ers in the biomedical domain [18]. O'Connor con-cluded that citing statemen ts can aid retriev al but notes the inheren t dicult y in iden tifying them. Some of the selec-tion rules were only semi-automatic (e.g., required human iden ti cation of an article as a review) and most relied on kno wledge of sen tence boundaries. Sen tence bounda y de-tection is a non-trivial computational problem in itself, par-ticularly in scien ti c text, whic h is rife with form ulae, unit abbreviations and textual place holders. Nowada ys, tools for sen tence boundary detection are widely available (e.g., [15]) and a solution to the problem of automatically iden tifying review articles is also within reac h: Nan ba and Okum ura presen t a metho d for detecting surv ey articles in a multilin-gual database [16].

The complexities in correctly determining whic h terms in a citing pap er refer to whic h of its citations has been dis-cussed in depth elsewhere [22]: the amoun t of text that refers to a citation can vary greatly , multiple citations in close pro ximit y can interact with eac h other and a ect the `own-ership' of surrounding terms; likewise, sen tence boundaries (as well as paragraph and section boundaries) can indicate a change of `ownership', as they signal topic shifts. This study on 24 citations to one pap er highligh ted the great num ber of `noisy' terms that would be introduced to the documen t represen tation by a xed windo w: almost 400 terms from only 24 citations and some with high IDFs, that could neg-ativ ely impact on the documen t represen tation. Therefore, CL techniques may be useful in solving this problem. Before the problem can even be tackled, the citations themselv es must rst be located: in domains where non-n umeric cita-tion styles are used, how to iden tify citations in the running text and asso ciate these with items in the reference list is a task in itself, for whic h high precision metho ds have been dev elop ed [21, 19].
We previously introduced a test collection suitable for a broad range citation-based exp erimen ts [21, 20] , since no existing test collection satis es our requiremen ts. The newswire articles in traditional collections do not con tain citations. CA CM con tains abstracts and the GIR T collec-tion [12], likewise, consists of con ten t-bearing elds, not full documen ts. The earlier TREC Genomics collections consist of MEDLINE records, con taining abstracts but not full pa-pers [8, 9]. In the 2006 trac k, a new collection of full-text documen ts was introduced but this was designed for passage retriev al for a QA task, not documen t retriev al [10]. Our test collection allo ws us to conduct not only the exp erimen ts we rep ort here, but a wider range of exp erimen ts using di eren t com binations of information from citing and/or cited docu-men ts.

The test collection is cen tred around the ACL Anthology 1 digital archiv e of CL researc h pap ers. The documen t collec-tion is a 9800 documen t subset of the archiv e; roughly , all documen ts published in 2005 or earlier, with non-pap ers re-moved (e.g., letters to the editor, tables of con ten ts). Our query set consists of 82 researc h questions from CL pa-pers, with an average of 11.4 judged relev ant documen ts per query [20] , suc h as:
The test collection was built using a metho dology based on the Cran eld 2 design [4]. The principle behind the metho d is that researc h pap ers are written in resp onse to researc h questions, i.e, information needs, and that the references in a pap er are documen ts that are relev ant to that need. Thus, pap ers are a source of queries (the researc h questions) and relev ant documen ts (the references). For our queries, the au-thors of accepted pap ers for two upcoming CL conferences were ask ed, by email, for the researc h question or questions underlying their pap ers. By asking for queries from recen t conference authors, we aimed for a query set that is a realis-tic mo del of searc hes that represen tativ e users of the docu-men t collection would mak e; gen uine information needs from man y di eren t people with man y di eren t researc h interests from across the CL domain. They were also ask ed to mak e relev ance judgemen ts for their references. Due to the rel-ativ e self-con tainedness of the CL domain 2 , we exp ected a signi can t prop ortion of the relev ance judgemen ts gathered http://www.aclweb.org/anthology/ 2 We empirically measured the prop ortion of collection-internal references in Anthology pap ers to be 0.33, compared to an estimated 0.17 for a `comparable' set of genetics jour-nals. in this way to be for documen ts in the ACL Anthology and, thus, useful as test collection data.

Based on some analytical exp erimen ts [21] , there were too few relev ance judgemen ts at this stage; we executed a second stage to obtain more judgemen ts for our queries, in line with Cran eld 2. The Anthology is too large to mak e complete judgemen ts feasible. Therefore, we used the pool-ing metho d to iden tify poten tially relev ant documen ts in the Anthology for eac h of our queries, for the query authors to judge. First, for eac h query , we man ually searc hed the An-thology using its Google searc h facilit y. We then ran the queries through three standard retriev al mo dels, as imple-men ted in the Lem ur Toolkit 3 : Okapi BM25, KL-div ergence (both with relev ance feedbac k using the existing relev ant documen ts) and Cosine similarit y. We pooled the results from the man ual and automatic searc hes, including all man-ual searc h results and adding non-duplicates from eac h of the automatic rankings in turn until 15 documen ts were in the list. Our pool is very shallo w compared to TREC-st yle pools; our metho d relies on volun teer judges and therefore we needed to keep the e ort ask ed of eac h judge to a min-imum. The list of poten tially relev ant documen ts was sen t to the query author, with an invitation to judge them and materials to aid the relev ance decision.

For the exp erimen ts in this pap er, we use the tok eniser from a statistical natural language parser [3] to segmen t the text into sen tences. Giv en a citation con text (see 3.2), we add it as a text string to an XML represen tation of the full-text documen t before indexing. We build one in-dex from the XML documen ts alone and another from eac h of the documen t-plus-citation-con text represen tations. We index our documen ts using Lem ur, speci cally Indri [29], its integrated language-mo del based comp onen t, using stop-ping and stemming. Our queries are likewise stopp ed and stemmed. We use the Cosine, Okapi, KL-div ergence and Indri retriev al mo dels with standard parameters to test our metho d. We also performed retriev al runs using KL with relev ance feedbac k 4 (KL FB). In eac h run, 100 documen ts were retriev ed per query; this is already far greater than the num ber of relev ant documen ts for any query . For evaluation, we use the TREC evaluation soft ware, trec_eval 5 .
We pre-pro cess the documen ts, using metho ds based on regular expressions to annotate the reference list, to iden-tify citations in the running text and to asso ciate these with items in the reference list. This is a non-trivial task, for whic h high precision metho ds have been dev elop ed indep en-den tly [19]. Our approac h is more simplistic but nev ertheless performs well: from a small study of 10 journal pap ers, we found and correctly matc hed 388 out of 461 citations with their corresp onding reference (84.2%). Errors mostly occur due to noise from the PDF to XML con version.

Next, we use the reference information to iden tify whic h references are to documen ts in the ACL Anthology; we ex-tract con texts from the citations asso ciated with these refer-ences to a database. Speci cally , we de ne a citation con text in the follo wing nine di eren t ways. The brac keted num bers http://www.lemurproject.org/ 4 We do not rep ort results using Okapi with relev ance feed-bac k: the Lem ur documen tation notes a susp ected bug in the Okapi feedbac k implemen tation. http://trec.nist.gov/trec_eval/trec_eval .8.1.t ar.gz indicate the average num ber of words in the left and righ t portions of these con texts, resp ectiv ely, in the corresp onding index. none No citation con text. [0,0] 1sent The sen tence con taining the citation. [13.6,10.6] 3sent The sen tence con taining the citation plus one sen-1sentupto The sen tence con taining the citation, truncated 3sentupto The 3sent con text, truncated at the next cita-win50 A windo w of up to 50 words on eac h side of the cita-win75 A windo w of up to 75 words on eac h side of the cita-win100 A windo w of up to 100 words on eac h side of the full The entire citing pap er.

The average num ber of terms in the win100 con texts is notably di eren t from the maxim um allo wed by its design. This is because the database eld from whic h the windo w con texts are tak en consisted of a xed num ber of sen tences around the citation and, for some citations, this group of sen tences will not include as man y as 100 words on either side. This is an unfortunate error in the database design, whic h took place before the scop e of these exp erimen ts was realised.
 The rationale behind this range of con texts is as follo ws. We start with the basic assumption that the words that are used to describ e the cited pap er will occur close to the cita-tion and that, further away, words are less likely to be about the pap er. We also supp ose that the citing author will have constructed their text according to grammatical and rhetor-ical con ventions, so sen tence boundaries should demarcate logical units of related text. Intuitiv ely, then, the sen tence that con tains the citation is a good rst appro ximation of the exten t of its descriptiv e terms and, therefore, this is our default con text, called 1sent . We also consider whether de-scriptiv e terms migh t be found outside the citing sen tence, and investigate the con text of the three sen tences immedi-ately around the citation, 3sent . The 1sentupto and 3sen-tupto con texts are devised to investigate whether neigh bour-ing citations migh t be an e ectiv e indicator of the end of the text asso ciated with the original citation. Then, in con trast to these linguistically motiv ated con texts, we look at some xed windo w con texts, to compare the e ectiv eness of sim-pler metho ds of taking terms from around citations: win50 , win75 and win100 . The terms that are de nitely asso ciated with a citation are variable in num ber and in distance from the citation, so any xed windo w will not accurately cap-ture the citation terms for all citations. Figure 1 sho ws an example citation con text and how a 100 term windo w picks up terms that are not asso ciated with the cited pap er. Fi-nally , we include in the comparison the two extreme cases of adding no citation con text, none , and adding the entire citing pap er as the citation con text, full .

The database con tains terms from over 20,000 citations to over 3200 pap ers. Figure 1: Example citation con text. (W ords out with the 3sent con text but within win50 are in italics .)
In eac h row of Table 1, we compare the performance of a given retriev al mo del with the 1sent con text to its per-formance with another con text. We compare with 1sent , as opp osed to none , since we have previously sho wn that adding 1sent to the base documen t represen tation gives an impro vemen t in performance; we hence treat 1sent as the baseline for this comparison of citation con texts. We con-sider the values of a range of standard performance mea-sures, implemen ted in trec_eval and de ned in the asso ci-ated documen tation, and t-test for statistical signi cance of 1sent 's versus the other con text's performance. The di er-ence between 1sent 's and the other con text's performance is given in the righ t hand side of eac h column; positiv e dif-ferences indicate that 1sent 's performance was higher and di erences highligh ted in bold are signi can t for p 0.05 and underlined di erences are signi can t for p 0.01. There are 200 equiv alen t pairwise comparisons between all nine con-texts and this generates a further sev en tables like Table 1. For brevit y, we summarise this information in the con text rankings given in Tables 2 and 3. Our notation is as follo ws: a) con texts are rank ed by absolute performance values, in ascending order from left to righ t; b) denotes the dif-ference between a pair of con texts is signi can t for p &lt; 0.01, &lt; denotes signi cance for p &lt; 0.05 and denotes statistical insigni cance; and c) we assume a subsumptiv e, transitiv e signi cance relation in the ranking, i.e., if C A C B C C (or C A C B &lt; C C ) then C A C C etc. We note excep-tions to this general ranking in the righ tmost column; these anomalies are indep enden t of eac h other and a ect only the listed pair of con texts so, e.g., if C A C B C C C D has the exception C A &lt; C C , it does not follo w that C A A rst notable outcome from these results is that they con-rm that adding citation terms impro ves retriev al e ectiv e-ness. E ectiv eness is generally better on the indexes with citation terms than on the none index: none is rank ed low-est in 14 of the 25 rankings (i.e., com binations of retriev al mo del and evaluation measure). In 185 of 200 pairwise com-parisons with other con texts, none is rank ed lower and, in 107 of these, the di erence is signi can t. In the 11 rank-ings where none is not the lowest rank ed con text, the lowest is full ; in ve of these cases the di erence between none for p 0.05 and those underlined for p 0.01) and full is signi can t, all with Okapi. In the remaining 10 of the 15 comparisons where none is rank ed above another con text, the di erence is insigni can t.
 Looking in further detail at the retriev al e ectiv eness achiev ed by adding the entire citing pap er, full is rank ed higher and lower than none in almost equal measure: higher in 14 rank-ings, only four of whose di erences are signi can t, and lower in 11 rankings, ve of whose di erences are signi can t. The ma jorit y of di erences between full and none are insigni -can t. In con trast to the ve rankings where full is rank ed lowest overall, it is rank ed highest three times; in one of these, the di erence between full and every other con text is signi can t. Thus, it app ears that the e ect of full is un-predictable and that, overall, there is no adv antage to addi-tionally indexing the citing pap er over indexing the cited pa-per alone. Now comparing full with the restricted citation con texts, full app ears to be less e ectiv e. The di erence between full and 1sent is marginal: full is rank ed below 1sent in 12 rankings, of whic h sev en di erences are signi -can t, compared to 11 rankings where it is rank ed higher, of whic h only two di erences are signi can t. The di erence is more mark ed between full and the windo w con texts: full is rank ed above, e.g., win50 in ve rankings, in only one of whic h the di erence is signi can t, compared to 19 rankings where full is rank ed lower, in 10 of whic h the di erence is signi can t. The gap is even wider between full and the longer windo w con texts. Using terms from a limited con text around citations is, thus, more e ectiv e than using the entire citing pap er, reinforcing our second observ ation that index-ing the entire citing pap er is not a worth while metho d. This is not a surprising conclusion: intuitiv ely, the vast ma jorit y of the words in the citing pap er will not refer to the cited pap er and will probably not be appropriate index terms for it. Moreo ver, this large num ber of `bad' index terms could poten tially dro wn out the `good' ones, not only from the cit-ing pap er but from the cited pap er itself; this will esp ecially be a problem for pap ers whic h have man y citations to it. 219 Thirdly , we observ e a general trend that the longer the ci-tation con text, the greater the retriev al e ectiv eness. Com-paring the sen tence-based con texts, 3sent is rank ed above 1sent in 21 rankings, in 14 of whic h the di erences were signi can t, compared to three rankings in whic h 1sent is rank ed higher, nev er signi can tly. The truncated versions of the sen tence-based con texts are usually rank ed lower: 1sen-tupto is below 1sent in 20 rankings, 10 times signi can tly, and above it in two rankings, neither of whic h are signi can t; 3sentupto is below 3sent in 21 rankings, 11 signi can t, and above it in three rankings, none signi can t. Thus, using neigh bouring citations to delimit a citation's con text does not app ear to be helpful; at least, not in the simplistic way we have tried here.

Finally , the windo w con texts also exhibit this trend: win50 is usually rank ed lowest of all the windo w con texts, being rank ed beneath win75 in 21 rankings (10 times signi can tly) and beneath win100 in 22 rankings (nine times signi can tly), and is nev er signi can tly better than either win75 or win100 ; win75 is rank ed lower than win100 in 20 rankings, though the di erence is only signi can t in two of these. In accor-dance with the trend, one of the longer windo w con texts, win75 or win100 , is usually rank ed highest: in 19 out of 25 rankings. In ve of the remaining six rankings, the di er-ence between win75 and win100 and the top rank ed con text is insigni can t. In the anomalous sixth case of Cosine bpref, only full is rank ed signi can tly higher than either win75 or win100 . At a rst glance, it app ears that the increase in e ectiv eness with increasing windo w length is tailing o between win75 and win100 , as the impro vemen t between these con texts is sligh tly smaller than between win50 and win75 . However, the di erence between the average num ber of terms in win75 and win100 is smaller than that between win50 and win75 (42.0 versus 28.6) so the reduced impro ve-men t may simply be the result of the reduced increase in windo w size. Nev ertheless, this trend of increasing e ectiv e-ness with increasing con text length does not con tinue indef-initely , since e ectiv eness is decreased again by the time the entire citing pap er is tak en as the citation con text: an op-timal length of citation con text exists somewhere between between none and full , though the con texts investigated here do not de nitely sho w that optim um.
 We now consider the relativ e e ectiv eness of the sen tence-based and windo w con texts. Firstly , win50 is usually rank ed above 1sent , in 19 of the 25 rankings, though the di erence is usually insigni can t (in 12 cases). Compared to 3sent next, win50 is rank ed higher in sligh tly few er (14) rankings and, in all 25 rankings, the di erence between win50 and 3sent is insigni can t. This initially seems to suggest that there is no adv antage to making use of sen tence boundaries for delimiting citation con texts: equiv alen t e ectiv eness can be achiev ed using a simple windo w metho d. However, the more e ectiv e win50 is also longer on average than 3sent (26.3 versus 98.4 terms) and, as we have seen, longer con-texts tend to be more e ectiv e. Therefore, it is quite pos-sible that sen tence-based con texts are more e ectiv e than windo ws of equiv alen t length and that a longer sen tence-based con text would outp erform win50 and even the longer windo w con texts. Hence, as the e ectiv eness of increasingly longer windo w con texts tails o , the optimal con text may, in fact, be a sligh tly shorter one constructed from sen tences; this requires further investigation.
 Table 4 sho ws how the ve retriev al mo dels are rank ed ac-cording to di eren t performance measures, for eac h of the con texts. using the same signi cance notation as explained previously . For all ve evaluation measures, Okapi is usu-ally rank ed lowest, follo wed by Cosine, then Indri, KL and, nally , KL FB is rank ed highest. For nine com binations of measure and con text, Indri is rank ed above KL but the di erence is signi can t in only three of these. Overall, the ma jorit y of di erences between mo dels are statistically sig-ni can t. The ranking pro duced by our test collection is sta-ble across performance measures and the di erences between mo dels are generally signi can t. This indicates that, though the absolute e ectiv eness scores of the mo dels are low, our test collection is successfully distinguishing between the dif-feren t mo dels' performance: the collection is a useful tool for IR evaluation, despite the fact that the incomplete relev ance judgemen ts.
We have broac hed the issue of how to nd the terms as-sociated with a citation in order to index them. Iden tifying whic h terms are asso ciated with a citation in a scien ti c pap er is an interesting, complex problem, since there is no explicit anc hor text nor HTML tags to delimit the text asso-ciated with a link, unlik e in web pages. We exp erimen t with the com bination of terms from both cited and citing docu-men ts, where previous exp erimen ts have commonly tested metho ds using only one or the other. We exp erimen t on a new test collection of scien ti c pap ers in the computational linguistics domain, particularly suited for exp erimen ts with citations.

Our results con rm that adding citation terms to the terms from the documen t itself impro ves retriev al e ectiv e-ness: performance is (usually signi can tly) better using ci-tation terms in addition to the documen t terms. We have also sho wn that varying the con text from whic h the citation terms are tak en has a signi can t e ect on retriev al e ec-tiveness. The range of citation con texts we have compared sho ws a general trend that the longer the con text, i.e., the more citation terms are indexed, the better the performance.
Our exp erimen ts have certainly not exhausted this avenue of researc h. In particular, the results here have not sho wn an `optimal' con text: the optimal con text seems to exist some-where between the citing sen tence and the full citing pap er but the con texts we have exp erimen ted with do not sho w at what point e ectiv eness plateaus and further investiga-tion is needed to establish more precisely where. It will be interesting to extend the range of con texts in future work, looking at both longer xed windo ws and sen tence-based con texts. It is quite possible that sen tence-based con texts are more e ectiv e than windo ws of equiv alen t length and that longer sen tence-based con texts migh t eventually out-perform the windo w con texts. Hence, as the e ectiv eness of increasingly longer windo w con texts tails o , the optimal con text may, in fact, be a sligh tly shorter one constructed from sen tences.

We would also like to extend our comparison of citation con texts to include more linguistic metho ds. In particu-lar, a comparison with O'Connor's metho ds for accurately ference is signi can t for p &lt; 0.05, : di erence is insigni can t) iden tifying citation con texts would mak e a worth while ad-dition to the comparisons we have presen ted here; it would be interesting to see whether O'Connor's metho ds can, after all, be implemen ted fully automatically , now that mac hine-readable pap ers are widely available and problems suc h as sen tence boundary detection and review article iden ti ca-tion are practically `solv ed'. Thus, it remains to be seen whether the optimal citation con text is determined by sen-tence boundaries or yet more detailed linguistic cues, or whether simpler metho ds, like a xed windo w, are generally sucien t to capture the useful con text around citations.
More generally , there is scop e for a much broader com-parison of metho ds for nding and extracting useful index terms from citing pap ers, including beyond the immediate con text of the citation. We would like to conduct a wider comparison with previous work; in particular, with Brad-sha w's and Dunlop's metho ds, i.e., constructing documen t represen tations from citation con texts alone and from the abstracts of citing documen ts alone, resp ectiv ely. Our test collection, with full text of both citing and cited pap ers, allo ws us to conduct a wide range of exp erimen ts using dif-feren t com binations of information from citing and/or cited documen ts.

Our metho d is an application of citation content analy-sis [27] to information retriev al: we tak e the explicit, con-ten tful words from citation con texts and index them as part of the cited documen t. Citation con ten t analysis is part of a broader family called citation context analysis , that could also be put to use in IR. For instance, an examination of the retriev al rankings from our exp erimen ts migh t sho w that only con texts from certain types of citation con tribute use-ful index terms, while some migh t be better o excluded from the indexing or treated di eren tly, e.g., given a dif-feren t weigh t. Automatic citation classi cation (e.g., [30]) migh t impro ve our metho d by allo wing us to discriminate between how di eren t sort of citations are used. [1] S. Bradsha w. Reference directed indexing: Redeeming [2] S. Brin and L. Page. The anatom y of a large-scale [3] E. Brisco e and J. Carroll. Robust accurate statistical [4] C. Clev erdon, J. Mills, and M. Keen. Factors [5] M. D. Dunlop and C. J. van Rijsb ergen. Hyp ermedia [6] A. Fujii. Enhancing paten t retriev al by citation [7] D. Hawking and N. Crasw ell. The very large collection [8] W. Hersh and R. T. Bhupatira ju. Trec genomics trac k [9] W. Hersh, R. T. Bhupatira ju, L. Ross, P. Johnson, [10] W. Hersh, A. M. Cohen, P. Rob erts, and H. K. [11] M. M. Kessler. Bibliographic coupling between [12] M. Kluc k. The GIR T data in the evaluation of CLIR [13] O. McBry an. GENVL and WWWW: Tools for taming [14] E. Meij and M. de Rijk e. Using prior information [15] A. Mikheev. Tagging sen tence boundaries. In [16] H. Nan ba and M. Okum ura. Automatic detection of [17] J. O'Connor. Citing statemen ts: Computer [18] J. O'Connor. Biomedical citing statemen ts: Computer [19] B. Powley and R. Dale. Evidence-based information [20] A. Ritc hie, S. Rob ertson, and S. Teufel. Creating a [21] A. Ritc hie, S. Teufel, and S. Rob ertson. Creating a [22] A. Ritc hie, S. Teufel, and S. Rob ertson. How to nd [23] A. Ritc hie, S. Teufel, and S. Rob ertson. Using terms [24] J. Schneider. Veri c ation of bibliometric metho ds' [25] A. S. Schwartz and M. Hearst. Summarizing key [26] H. Small. Co-citation in the scien ti c literature: A [27] H. Small. Citation con text analysis. In B. Dervin and [28] T. Strohman, W. B. Croft, and D. Jensen.
 [29] T. Strohman, D. Metzler, H. Turtle, and W. B. Croft. [30] S. Teufel, A. Siddharthan, and D. Tidhar. Automatic
