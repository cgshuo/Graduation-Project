 In this paper, we propose a ne w phrase-based IR model, which experiments show its high potential to produce large improvements in retrieval effectiveness. H.3.3 [ Information storage and retrieval ]: Information Search and Retrieval  X  Retrieval Models Algorithms, Performance, Experimentation, Theory. Keywords : Language model, Phrase model, Inseparability. Although many terms are dependent in natural languages, most current Information Retrieval (IR) approaches assume independence between them, leadi ng to the so-called bag-of-word models. These models are unable to consider the specific meaning of compound terms such as  X  computer architecture  X  and  X  hot dog  X . A number of studies have tried to integrate term dependencies within IR models . For example, phrases, word proximity and term co-occurrences have been integrated into IR models (e.g. [1][2][3][6]). Howeve r, we notice that these models usually combine a phrase/depende ncy model with a traditional unigram model in a fixed manner, i.e. the same combination is used for all phrases. For example, [6] uses the same interpolation weights for combining all phras es and single words. Similar studies have been performed for IR Asian languages, which try to integrate different segmentation results [5][7]. Even if the weights are tuned to their best, the same weight cannot correctly reflect the variable inseparability of terms. For example, if we separate the phrase  X  hot dog  X  into single words, the meaning of the phrase will be heavily altered. This phras e is inseparable. On the other hand,  X  crude oil  X  is more separable, because  X  oil  X  is often used to refer to  X  crude oil  X . Therefore, documents containing separate words  X  crude  X  and  X  oil  X  could have a higher chance to answer the query on  X  crude oil  X  than a document containing  X  hot  X  and  X  dog  X  for a query on  X  hot dog  X . This leads to the following intuition for IR: the more a phrase in a query is inseparable, the more one should rely on the phrase model for its retrieval. In this paper, we integrate this notion of inseparability of phrases into IR model, so that the interpolation between the phrase model and the word model becomes dependent on the inseparability of the phrase. Our model has been tested on se veral test collections in both English and Chinese. Our expe riments show steady, although small, improvements over the existing methods. In this paper, our primary focus is on the method to integrate the phrases in retrieval. We start this study with a simplified setting: we will only consider phrases that are identified using an existing tool. Furthermore, we only c onsider phrases formed by consecutive sequences of words, and do not consider overlapping phrases. This setting is taken for the sake of simplicity and more complex phrase identification processes will be investigated in our future studies. Given a query Q=w 1 ,...w n formed by a sequence of words, some phrases can be identified in it. Without loss of generality, we will assume that a phrase can be formed by several consecutive words or by a single word. Therefore, the query can also be considered to be formed by a sequence of phrases Q= r 1 ,...,r m , where m  X  n . A phrase formed by several words is represented as | | 1 ... where | r i | is the number of words in r i . We thus have two possible expressions of the query: by words and by phrases, which could be evaluated separately usi ng language modeling as follows: above two models become equivalent . This is to say that if every phrase is considered to be comple tely separable into single words, the phrase model degenerates to the traditional word model. As we mentioned earlier, some phrases can be separated into single words more than some others. Therefore, we propose to determine a phrase-dependent parameter  X  i to denote the inseparability of the phrase r i . For each phrase, we take into account the above two possible representations of it according to  X  i . In this paper, we propose to use the weighted geom etric mean to combine them, i.e., i Notice that the method proposed in [6] and [4] can be roughly recast as the above model, but with the same  X  i The key question is how to determine  X  i for a phrase r methods can be used, such as mu tual information, log likelihood ratio, etc. Here, we propos e a simple method based on idf . idf is a measure of discriminativity. Our intuition is that if a phrase has a higher discriminativity than the separate words, then it is more useful to consider the phrase as a whole, than being separated, in the retrieval process. We use the normalized difference of idf:  X  where t 1 and t 2 are two thresholds set on x i value of i  X  varies between 0 and 0.9  X  the lowest and the highest weight attributed to phrases. In our experiments, we use t and t 2 = 0.4, which are determined according to the queries 1-100 on AP collection. In some cases, rare phrases, which are not useful for IR, will have a high idf value. To prevent from assigning a high phrases, we further filter out phrases using pointwise mutual information: Only phrases with mu tual information larger than a threshold (1 in our case) are deemed to be meaningful. The above idf -based measure has been compared to those based on mutual information and log-lik elihood ratio in our experiments and the idf -based measure performs better. A possible reason is that mutual information and log-likelihood ratio measure how strongly the words within a phrase are dependent, without taking into account of the discriminativity of the phrase, which is an important aspect in IR. The idf -based measure can integrate the discriminativity. Simpler words and more complex phrases co-exist in any language. In Chinese, single characters could be considered to be similar to English single words and compound words to phrases. We will perform a series of experiments on both English and Chinese collections. For English, we use a phrase dictionary (Termium) built for machine translation to identify phrases. We limit to phrases of length 4 or less, which amount to about 10 000 phrases. For Chinese, we use a word segmentation tool (ICTCLAS  X  http://ictclas.org/) to identify compound words summarized in Tables 1 and 2, where 1-150 ph means the subset of queries containing phrases. Tables 3 and 4 describe the expe rimental results on English and Chinese collections respectively. We compare the approaches using words (or Chinese characters) alone (Uni), using phrases alone (P), using a method similar to that of [6] (PU) with fixed interpolation weights, and usi ng the method proposed in this paper (PM). We can see that our PM model can steadily outperform the unigram model on both English and Chinese collections, although the improveme nts are usually small. When we look at the queries which contain phrases (1-150 see a larger improvement. This shows that the small improvements are due to the fact that only some of the queries we used contain phrases, and are thus affected by our model. For the other queries, the effectiv eness remains unchanged. outperforms the PU model with a fi xed interpolation weight. This comparison shows the importance to consider the variable inseparability of phrases, and the potential of integrating such a measure in IR. AP88/9 Associated Press:88-89 479 164,597 240 WSJ Wall Street Journal:87-92 517 173,252 240 SJM91 San Jose Mercury News 291 90,257 220 Trec9Ch Trec9 Chinese Collection 532 127,938 226 NTCIR6 CIRB040 1081 901,446 207 #query 49 50 50 39 25 50 #q. phr. 8 16 15 39 25 50 avg. len 2.9 3.4 3.8 3.2 6.2 8.1 In this paper, we proposed a ne w phrase-based IR model, which takes into account the inseparability of phrases. Our preliminary experimental results show that this model has a high potential to further improve the retrieval effectiveness of the existing models. In this paper, we have focused on the integration of phrases, and used phrases determined by existing resources/tools. More complex processes can be used to better identify useful phrases. This is an aspect we will inve stigate in our future studies. [1] W.B. Croft, H.R. Turtle, D. D. Lewis. The use of phrases and [2] D.A. Evans and C. Zhai. Noun-Phra se Analysis in Unrestricted [3] J. L. Fagan. Automatic phrase indexing for document retrieval: [4] J. Gao, J. Nie, G. Wu, G. Ca o, Dependence language model for [5] K.L. Kwok. Comparing representa tions in Chinese information [6] D. Metzler and W.B. Croft. A Markov random field model for [7] L. Shi, J.Y. Nie, G. Cao, Relating Dependent Indexes using 
