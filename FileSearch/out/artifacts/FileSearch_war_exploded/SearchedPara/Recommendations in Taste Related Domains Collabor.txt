 We investigate how social networks can be used in recom-mendation generation in taste related domains. Social Fil-tering (using social networks for neighborhood generation) is compared to Collaborative Filtering with respect to predic-tion accuracy in the domain of rating clubs. After reviewing background and related work, we present an extensive em-pirical study where over thousand participants from a social networking community where asked to provide ratings for clubs in Munich. We then compare a typical traditional CF-approach to a social recommender / social filtering approach where friends from the underlying social network are used as rating neighborhood and analyze the experiments statisti-cally. Surprisingly, the social filtering approach outperforms the CF approach in all variants of the experiment. The im-plications of the experiment for professional and private-life collaborative environments and services where recommen-dations play a role are discussed. We conclude with future perspectives on social recommender systems, especially in upcoming mobile environments.
 H.5.3 [ Group and Organization Interfaces ]: Collabo-rative Computing; H.3.3 [ Information Search and Re-trieval ]: Information Filtering; H.3.5 [ Online Informa-tion Services ]: Data Sharing Design, Experimentation, Human Factors
Platforms and communities on the web offering services based on explicit social networking models have become a major trend. In this article we will investigate, how models for social relations can be incorporated into recommender systems. Having reviewed basic notions in social network analysis and recommender systems in sections 2 and 3, we Copyright 2007 ACM 978-1-59593-845-9/07/0011 ... $ 5.00. present in section 4 a detailed empirical study on how so-cial relations can improve traditional collaborative filtering based recommenders in a taste related domain. In sections 5 and 6 we will take a look at future perspectives and dis-cuss how social relation models may be incorporated into information systems.
The main subject of social network analysis is to inves-tigate properties of networks comprised of actors and re-lations. Actors re typically persons or groups of persons (teams, organizations, nations etc.) and relation-types in-clude individual evaluations (e.g. friendship), transfer of resources, movement (physical or social), roles, kinship etc. [28].

According to [7]  X  X elations [...] are characterized by con-tent, direction and strength. X  Most of the existing social network platforms offer only very few if not only one type of relation (one type of content), do not allow to specify strengths (weight) for relations and usually only provide for undirected relations between the actors.

The sum of all relations between two individuals is usually referred to as a tie:  X  X  tie connects a pair of actors by one or more relations. X  [7][9].

Considering groups a usual definition is given in [29]:  X  X  group is a social network whose ties are tightly-bounded within a delimited set and are densely-knit so that almost all network members are directly linked with each other. X 
Usually, social relations are mathematically modeled as a graph. a undirected uni-mode network with only one (unweighted) relationship type would be modeled as sim-ple graph G ( V, E )with E  X  U 2 . For multiple types of relations one would have to use multigraphs, directed and weighted edges are also straightforward to model.
For modeling groups, the most intutive model are maxi-mal cliques [14][28] but other locally dense subgraphs such as LS-sets, k-clans, k-clubs and k-plexes are also possible [14][28]. [4] gives an overview of data which are provided by In-ternet users (without even realizing it) and which can be used for the purpose of analyzing relationships. E.g. several research projects have been conducted about the usage of computer-networks as a source of relationship data. [13] use websites as sources of social network data by scanning for co-occurrences of names. Newsgroups and discussion forums were e.g. analyzed by [25] and [26]. Apart from names, the hierarchical structure of reply relations can be used to derive relationships ([10]).

Furthermore, Orkut [17] and Multiply [19] are examples of large online-communities where users have the possibility to state several aspects about their personal relationships. While Orkut offers friend-list services, group membership and rating of other users in three categories (trusty, sexy, cool), Multiply steps ahead by allowing users to define re-lationships in a more detailed way (three main categories -family, friends and professional contacts -with several sub-categories each). Content may be shared based on rela-tionship degrees the possible recipients need to be within in order to be able to access the shareable content.
Recommender systems record a user X  X  and other user X  X  past preferences in profiles in order to (mostly pro-actively) recommend new items to the user (see e.g. [5]). Montaner et al. [15] provide a useful taxonomy of existing recommender systems. The first large classification dimension is profile maintenance with the subfields representation of profiles and profile data generation (initial and adaptational). Having an operational profile for each users, one has to exploit these profiles in an appropriate way. For profile exploitation there are, again, several sub-dimensions: type of information fil-tering (e.g. demographic filtering, content-based filtering or collaborative filtering), profile matching (via keywords, cosine-similarity, nearest neighbors etc.), neighborhood cre-ation (if applicable)(e.g. correlation thresholding or best-n-neighbors) and prediction computing (e.g. most-frequent-item recommendation or weighted average).

A general disadvantage of recommender systems is the portfolio effect: A user is recommended items which he al-ready knows or which are too similar to those he already knows (see [1] for a workaround). Social recommenders are a possibility to cope with this (see 5).

In this article, we will mainly focus on collaborative filter-ing. The basic idea is to let users rate items and predict for an active user ratings of previously unrated items by deter-mining a neighborhood of other raters which have exhibited a similar rating behavior to the active user [11]. Its bene-fits are that in contrast to content-based filtering, it is (to a certain extend) able to create cross-genre or serendipitous recommendations [11], because it does not rely on item spe-cific similarities (as in content-based filtering) but on user-rating-similarities. Nevertheless, social recommenders are even more capable of this type of recommendations (see 5). As a drawback, collaborative filtering can exhibit a severe cold-start/early-rater problem. If not enough ratings are available the results will be poor, thus nobody will enter new ratings and so forth.
Human decision making is (contrary to what classical util-ity theory suggests) more often based on heuristics than on pure logic and mathematically weighing advantages and dis-advantages. [31] describes types of heuristics on which hu-man decision making is based. Furthermore,  X  X he use of ad-vice is a fundamental practice in making real-life decisions X  ([30]).  X  X enerally, advice-seeking is seen as a problem of combining and weighting different information sources to come to a final conclusion X  ([2]). Decision making (e.g. on the usefulness of items) and recommending are inherently intertwined social processes. Especially in taste related do-mains, it is beneficial to know the advice-givers / recom-mending persons in order to perform this  X  X ombining X  and  X  X eighting X  on the basis of e.g. social estimations. Thus, for recommender systems trust is an important goal to achieve ([21][8]). [8] shows how to improve trust in a movie rec-ommender system by listing and weighting movie ratings of friends and non-friends separately.

With respect to decision making in groups two aspects are important: normative influence, which is based on the desire to conform to the expectations of others, or informational influence, which is based on the acceptance of information from others ([6]). Group members may strongly identify with their group and may fear isolation if they act against the group. This behavior is explained in detail by the spiral of silence model introduced by [20].

Previous work on social recommender systems include [24] and [2]. [24] compares the recommendations of online rec-ommender systems to recommendations made by the user X  X  friends regarding books and movies. In an empirical study they discover that friends are preferred over online recom-mender systems considering good (recommendations of in-terest) and useful (recommendations of interest which have not been experienced yet) recommendations. [2] investigates the nature of taste-related recommendations (movies) by an empirical study and find users to prefer recommendations from people they know regarding this domain. Further-more, they make several proposals on how and why to com-bine social networks with recommender systems. We will now investigate the influence of social relations on recom-mender systems in more detail with the help of a empirical study, where we will compare a collaborative filtering ap-proach (neighborhoods for recommendation generation are computed on the basis of rating similarity) with a social filtering approach (neighborhoods for recommendation gen-eration are computed on the social network).
In this section we will first describe the data set of our empirical study and then we discuss two experiments on the collected data set corresponding to two research questions: (1) Is rating behavior statistically dependent on friendship and if so: How strongly does rating behavior correlate with the size of the social structures investigated? (2) How does a social filtering approach perform compared to a collabo-rative filtering approach? The German community Lokalisten [18] is a Munich-based German language virtual community, which was founded in May 2005 and has (April 2007) approximately 700000 users all over Germany [18]. A very large and active local part of the user community is still based in the Munich area. The focus of the community is best described as communication-and spare-time-oriented. Central feature of the community is a simple social network model where two-way-handshake confirmed personal friendship relations can be created man-aged and visualized by the users. Besides  X  X  X riendship X  no further types of relations exist. No weighting of relations is provided.

As a possible domain of interest, clubs in the Munich area where chosen. Lokalisten well correlated with the goal to investigate social recommenders and their relation to usual collaborative filtering recommenders in such a taste-related domain because it offered a social network representation and has a strong Munich user base that potentially know the clubs and have interest in them.

Using a breadth first search starting from one user (one of the authors), the friendship graph was traversed until depth 4 which in our experiment led to 4249 users. Their publicly available information (nicknames, friendship-relations and supplemental profile data) were downloaded and stored in a relational database. We only used nickname and friendship relations for our experiment.

In order collect suitable data to be able to compare collab-orative filtering with social filtering operating on the taste related domain of clubs in Munich, an online-survey was constructed where users where asked to rate 82 clubs in the Munich area on a discrete scale from 0 to 10 where 0 (which was preselected) indicates that a user does not know the club. Thus 1 is the worst rating and 10 is the best rating. The users were sent a URL pointing to the Online-survey questionnaire contained in a message asking them to rate all the clubs they know.

Of the contacted users, 1012 users (aged between 16 and 47) completed the Online-questionnaire. 524 (51.8 %) of them were male, 488 (48.2 %) were female. Thus we received 82  X  1012 = 82948 ratings. Table 1 shows the distribution of the ratings.
The social relationship graph G ( U, E ) (nodes U corre-spond to users and undirected edges E  X  U 2 to friendship relations) is stored in an adjacency matrix A ij ( A ij =1if { u i ,u j } X  E , A ij =0if { u i ,u j }  X  E ).

Denoting a 82-dimensional rating vector of a user u i as with each element r ( u i ) k  X  [0 , 10], we can build a 82 rating Matrix M ur with these rating vectors as columns.
We can build a user-user-similarity matrix S ij = sim ( u with respect to ratings only by or respectively.

Using the cosine instead of the Pearson correlation (rec-ommended for neighborhood-based CF in [11]) has two ad-vantages: it is easier to compute and does not inadequately include  X  X issing data X  (the zero values in M ur ). According to [22] both approaches should be equivalent.
 weight as it is called in [11]) is introduced to account for the fact that e.g. two vectors with only one item rated equally and all other items not rated at all r ( u i ) = r ( u (0 , 0 ,..., 0 ,x, 0 ,..., 0) would yield sim ( u i ,u j ) = 1 while two vectors with lots of co-occurring very similar but not iden-tical ratings might yield sim ( u i ,u j ) &lt; 1. That is, the simi-larity X  X  trustworthiness should increase with the number of times the same item is rated by both users. For the sake of simplicity we incorporate the co-occurrence weight into the similarity.

Following in principle the suggestions in [11] the co-oc-currence weight introduces a linear decrease w co ( r ( u = is below the average number of co-occurrences co =1 / 0 . U (
In the first experiment we investigate the statistical de-pendence of the rating behavior of the users and their social relations (groups and pairs).

As has been discussed in 2, we assume cliques in the re-lationship graph as good models for social groups. We have to compute sufficiently many cliques for our experiments. How this can be done and how time-complex state of the art algorithms are, is explained in appendix A.

For the social network in our experiment retrieved the number of cliques shown in table 2. In the following sections Table 2: quantity of groups extracted from relation-ship data we will first analyze whether the rating behavior in groups of friends is more similar than in arbitrarily chosen groups of people who do not know each other. To be more precise such a group of  X  X trangers X  are usually called independent. We can find such independent sets or  X  X nti-cliques X  by searching for cliques in the complement graph of G .
First we will investigate whether the independent variable  X  X ating similarity X  is statistically dependent of the variable  X  X ocial relationship X  (friends or no friends). In order to do this, we will use the  X  2 Test ([3]). We partition the con-tinuous variable rating similarity X  X  domain r  X  [0 , 1] into 11 partitions, each having a similar number of total cases (friend-pairs and non-friend pairs). The results are shown in table 4 1 . The content of this table is visualized in the upper sub-figure of figure 1. The H 0 Hypothesis is The rating-similarity is independent from the social relationship between rater-pairs. For the crosstable 4 1 ,a  X  2 value of 173.401 was computed. To accept the null hypothesis on a level  X  =0 . 01 with 10 degrees of freedom, the computed  X  2 should not be greater than 29 . 59. Since 173 . 401 &gt; the null hypothesis is rejected. Thus the two variables are statistically dependent. In order to verify the strength of Figure 1: Comparison Chart of Friend-Pairs to Non-Friend Pairs (upper subfigure), Cliques(3) to Non-Friends(3)(middle subfigure) and Cliques(4) to Non-Friends(4) (lower subfigure) the statistical dependency, we compute a Pearson correla-tion coefficient [3] the range of which is [  X  1 , 1]. A value of 0 indicates no correlation while any absolute value near 1 indicates strong correlation. From table 4 1 we get a value of  X  0 . 397 indicating a rather strong negative correlation be-tween ratings and friends. The coefficient is negative since a higher value for the first variable (rating similarity) is cor-related with a lower value for the second variable (relation type) (friend-pairs are mapped to 0, non-friends to 1).
Since the small number of present cliques larger than 4 is statistically not significant, we confined ourselves to inves-tigating the rating similarity in cliques of sizes 3 and 4 and comparing it to groups of non-friends (independent sets) of the same sizes.

The H 0 Hypothesis is The rating-similarity is independent from the social relationship between rater-groups.
In order to compare ratings of sets of users we have to define an average rating similarity  X  U for a group U as Table 3: Pearson Correlation Results: Pairs, Cliques(3) and Cliques(4)
The values 164.2 (computed  X  2 ) and 18.5 (threshold  X  2 ) from table 5 show that the H 0 hypothesis is again rejected (  X  =0 . 001) and table 3 shows that the correlation between the average rating similarity and the variable differentiating between 3-cliques and 3-anti-cliques is even stronger than in case of the 2-cliques (pairs of friends) case from above.
Investigating the same dependencies for cliques of size 4 we find similar results (103.0 (computed  X  2 ) and 18.5 (threshold  X  2 ) from table 5  X  H 0 hypothesis is again re-jected (  X  =0 . 001)). Table 3 and lower sub-figure of figure 1 show that the correlation is even stronger for the case of 4-cliques than for 3-cliques.
Arguably, the data set is not completely unbiased, since we started from one user only and crawled the graph of friendships from there. The missing  X  X otal X  representative-ness of the chosen set of people is nevertheless not a big problem in the experiment since we can assume that for mea-suring the connection between social relatedness and rating behavior the overall taste- X  X ias X  possibly present in the set does not influence the investigated differences. The possi-ble bias or  X  X idden X  social relations in the set could even have been expected to influence the results in the other di-rection compared to what has been observed. Furthermore, the community chosen is definitely not night-life or club-centered per se.

Considering [28] p.256, the distribution of cliques that we found is congruent to what is usually observed in social net-work data, where the number of large cliques tends to be small.

From tables 4 1 -3 and the corresponding visualisations in figure 1 and from the Pearson correlation in table 3, we can very clearly see that groups of friends are more similar in ratings of taste related domains than groups of people that do not know each other (independent sets). This is in correspondence to observations in [2] and [30]. Even more so, the correlation becomes increasingly stronger when the number of people in the groups is raised from 2 to 3 to 4. The overall similarity average of cliques(4) of 0.556 is the highest observed value compared to cliques(3) with 0.526 and friend-pairs with a mean value of 0.485.
It may well be the case, that considering taste related do-mains with a lower  X  X ocial X  relevance, the results may differ. But considering that for example clothing-, tv-, cinema-, and music-tastes also have a significant social component it may be difficult to find taste related domains without such a  X  X ocial X  relevance.

Groups being  X  X enters of taste X  is a phenomenon which has been reviewed in [10] and is well known in social sciences [10]. Among other reasons this is due to a  X  X ormative X  effect that group-taste may have on members of the group [10].
To sum it up, with the necessary caution considering gen-eralizing, several conclusions may be drawn from these em-pirical results:
In this part of the experiment X  X  analysis we investigate how a classical collaborative filtering algorithm performs in comparison to a social filtering or social recommendation algorithm.

As has been explained in section 3, in a classic collab-orative approach, we have to perform three basic steps: computing similarities (matching), correlation-thresholding (neighborhood creation) and weighted average ratings (pre-diction computing). We can then compare the generated predictions (in our case predictions of club-ratings) with the true values (the true ratings). We will apply the same three step procedure also for a simple social filtering approach. The only difference will be in the neighborhood creation step, where social relations are used instead of correlation-thresholding.

Before we present the details of both approaches and the results of the experiment, we have to note down some basic preliminaries.
As has been explained above, each user u i has provided a [0 , 10]. A recommender system can (in principle) predict every one of these ratings. Thus the predicted rating for a user can be denoted as with 0  X  k  X  81.

We will have to distinguish between adequate , inadequate and novel predictions. An adequate prediction is a predic-tion for a club-rating r ( u i ) j  X  1 (that is for a club the user knows and has  X  X ctively X  rated) that is close to that original club-rating. A novel prediction is a prediction for a club-rating that was r ( u i ) j = 0 (that is for a club the user does not know).
 Formally this is expressed as:
A prediction pr ( u i ) j is adequate (denoted as pr ( u i if A prediction pr ( u i ) j is inadequate (denoted as pr ( u if A prediction pr ( u i ) j is novel (denoted as pr ( u i ) The tolerance  X  is a free parameter.

In our experiment, we distinguished, with respect to  X  ,be-tween favorite clubs and non-favorite clubs. The logic is that favorite clubs need to be more precisely predicted (smaller  X  (denoted as  X  f ) by the algorithm in order to call the al-gorithm X  X  performance  X  X ood X  than the less favored clubs (larger  X  (denoted as  X  r ). Thus we determined for every user her (at most) three favorite clubs to be able to compute for
We furthermore define the set of all  X  X dequately predictable X  ratings R ap as the set of all the original ratings of all users  X  1.

We can then define precision , recall , f-measure , and mean absolute error (MAE) of a total run for the recommender system in a standard way: If we let the set A = { ( i, j ) | pr ( u i ) j  X  P n } denote the set of all user-club-combination-indices for which the recom-mender actually produces a non-novel prediction, the mean absolute error is defined as: (see [12] for an detailed discussion of these measures).
As has been explained above we implemented two variants of the recommender system: A conventional collaborative filtering system and a social recommender.
The conventional CF system X  X  threshold-based neighbor-hood creation is governed by a parameter  X  . All users u which have a rating similarity S ij =sim( u i ,u j )  X   X  to user u i are taken into account when computing the predictions (recommendations) for that user u i . Thus the neighborhood N coll is defined as Note the following: In contrast to the first experiment where we (for the sake of simplicity) used equation (2) for S ij the second experiment we use the co-occurrence weighted similarity (equation (3)) following the suggestions in [11] for a good CF algorithm.

In our experiment, depending on  X  these sets can be much larger than the set of friends of a user Thus we took as a socially defined neighborhood the friends of a user together with the friends of these friends: Having defined the neighborhoods we can easily compute the prediction-vector for a user u i in a standard way. Instead of simply averaging the ratings within the neighborhood we compute the predictions as similarity weighted average over the rating-vectors of the users in his neighborhood: The average rating for a user u is denoted by r ( u ) .
This approach takes into account that different users my have a substantially different rating bias (Thus the difference from the average rating is used in the sum). We weight this difference with the co-occurrence weighted rating similarity. These suggestions are due to [11]. In case of N social we would naturally substitute the rating similarity with the strengths of the respective social relations, which is not present in our data set. To have a fair comparison between the two approaches, we also compute predictions using no similarity weighting:
A Recommender System can be viewed as a classifier where training phase and classification phase are united in one step. We can thus think of the set of ratings as a  X  X rain-ing X  set, allowing the recommender system to guess a rating for a user (make a prediction or recommendation). We created  X  X parse versions X  of our original rating matrix M ur (containing 25418 non-zero ratings). Randomly choos-ing n  X  1000 ratings ( n  X  X  1 , 2 ,..., 25 } we constructed 25  X  X parse versions X  of M ur with decreasing sparseness in order to investigate the influence of sparseness on the two recom-mender variants. In order to be able to better compare the collaborative results with the social results we consid-ered for every run of the sparse training data (that is for every n  X  [1 , 25]) the best of the ten runs for the collabora-tive recommender (that is the best out of all runs for each
Furthermore, in order to be not to generous considering the quality of the predictions we chose to set very strict values for the parameter(s) controlling the adequateness of predictions (  X  f =0 . 5,  X  r =1 . 0).

To be better able to understand the MAE values from table 6 we computed an MAE resulting from a continuous Figure 2: Comparison of mean absolute error(MAE) for social and collaborative predictions Figure 3: Comparison of F-measure for social and collaborative predictions uniform random distribution for pr on [0,10] and a discrete uniform random distribution for r on { 0 , 1 ,..., 10 } . Simple calculations show that in this random case we would get a MAE of  X  3 . 35. This also confirms that our recommenders perform reasonably.
The collaborative results (table 6: 1 , 2 and 3 (visual-ized in figures 2 and 3)) show relatively low best-thresholds returning the best f-measure for a specific training set: Start-ing with 0.1 for n = 1 and n = 2 the maximum best thresh-old level was found from n = 21 upwards with a value of 0.6.

The observation of relatively low collaborative thresholds returning the best results was also made by [27] and [12]. A high similarity between the users in the neighborhood and the target user does not imply an equally high similar-ity among the neighborhood users themselves. As a result, their potential disagreement about some items and the small neighborhood size due to high correlation values lead to pre-dictions which deviate to a great extent from the target users original rating ([27]).

Considering the f-measure results from table 6 which are visualized in figure 3, some interesting aspects show up: First of all, the social neighborhood with simple averaging prediction calculation (eq. (16)) is best by far for few rat-ings (high sparseness), being then beaten for low sparseness (many ratings) by social neighborhood with non-similarity weighted (eq. (18)) and similarity weighted (eq. (17)) pre-dictions computing (which then almost coincide)). The simi-larity weighted version is substantially worse at high sparsity (few ratings) than the other two social approaches. Since ac-cording to [11] the similarity weighted collaborative filtering approach with similarity weighting that we use is one of the best neighborhood based filtering algorithms known, the so-cial approach works excellently.

The social neighborhood with simple averaging predic-tion calculation (eq. (16)) is substantially better at high sparseness (cold-start-situations) than the social neighbor-hood with non-similarity weighted (eq. (18)) and especially than the similarity weighted (eq. (17)) versions. While the peer group of friends and friend-friends as a whole (on aver-age) is obviously a good indicator of personal taste even in very sparse situations, the single friends and friends-friends may have a slightly different taste then the active user which becomes especially apparent in the highly sparse situations where few ratings are available. Another explanation for the similarity weighted approaches (both social and collabora-tive) being worse than non similarity weighted approaches is that the similarity measure becomes increasingly unreliable with increasing sparseness.

The collaborative approach (both sim.-weighted (eq. (17)) and non-sim.-weighted (eq. (18))) is only slightly better than the worst social version (simple averaging) but only when the sparseness is very low (many ratings). As has been confirmed by [11], simple averaging (eq. (16)) is not an option for collaborative filtering which shows up in our experiments too.

Another aspect is that the collaborative approach is very sensitive to the  X  -threshold. We  X  X enerously X  took the values of the best run (w.r.t. to  X  ) for the collaborative approach. Deviating from this best  X  by only 0.2 delivers devastatingly bad results in all 4 quality measures (Precision, Recall, F-measure, MAE). While fine tuning  X  may be possible by observing the system, the optimal  X  value increases substan-tially with decreasing sparseness and in a real recommender system may be very hard to determine. This also strongly speaks in favor of the social approach.

Considering the MAE results from table 6 which are visualized in figure 2, we find very similar results. Only the collaborative approaches with appropriate prediction calcu-lation (both similarity weighted (eq. (17)) and non-similarity weighted (eq. (18)) are as accurate than the social approach for most levels of sparseness. But the accuracy comes at a price: The collaborative approach (all three versions) start with a very low  X  (a large neighborhood) being able to make many novel predictions which are extremely in-accurate. At lower levels of sparseness (more ratings) and thus at higher  X  (smaller neighborhoods) the number of novel predictions is substantially lower (by almost a factor of 25 %) than in case of the social approach (stable neighborhood) which, in turn starts with comparatively few novel predictions (high sparseness) and substantially increases this number. This is a clear advantage for the social approach.

Another more general criticized aspect of collaborative fil-tering systems is the lack of transparency. Collaborative systems today are black boxes, computerized oracles which give advice but cannot be questioned [15]. This lack of transparency can be overcome by a social recommender be-cause the origin of recommendations (the set of users used) is transparent, which can to some extent be used to indicate to the user why a certain recommendation was made (see e.g. [8] for an example). Social recommendations may thus induce a higher level of trust in the system itself.
So besides mere  X  X erformance X  (e.g. with respect to F-measure) where do the social approaches have their partic-ular strengths with respect to applications ?
Social environment-models (such as cliques) can certainly represent valuable ordering and filtering primitives in case no other such criteria are present. For example, designing a mobile application which aims at bridging the gap between public transport (no personalization (e.g. w.r.t. to the travel destinations and travel times) cheap and environmentally acceptable) and individual transport (maximum personal-ization but expensive and environmentally not acceptable with a mid term future perspective). Such approaches could function like an agency for arranged lifts: Automatically of-fering an arranged lift, every time a user enters her desti-nation into her navigation system. Other persons are the automatically informed if their personal context (travel des-tination, time etc.) matches the offer. Since not everybody is willing to take every person with her in her car, social groupings may be a more suitable target for the offering.
In general, sharing parts of the personal information space, as it is the case with any recommender system, is an inter-esting application for social models. It can be subjectively more appropriate to be presented elements from other user X  X  information space (e.g. ratings) if these users have a social relation to the active user.

But quality of information is usually judged in a sense  X  X he system should provide me with ratings (or more gen-eral with information) as close to what i would have rated (or more general information that i would have chosen) if i had known this in advance X . Obviously this is not the only way in which an information could be useful . we can also imagine information to be useful which is of poor  X  X uality X  (in the above sense). Think of novel recommendations that fall out of the scope of items that you would normally think of as being interesting but that would nevertheless broaden your horizon . As an example think of drinking beer: Most children would consider beer to be just bitter, but never-theless once have grown up to adults many of them start drinking beer occasionally. If their beverage recommenda-tions would solely have been based on their former tastes, most adults would still be mainly be drinking hot choco-late or fruit juice. So how do these new influences come into their lives? One important mechanism is due to social recommendations.

In other words your social groupings provide you all the time with horizon broadening information. That is novel information that is not just novel in the sense defined in the previous sections (a novel prediction was a prediction that  X  X ou would have done yourself that way X ) but that is hori-zon broadening (a prediction/rating/information that  X  X ou would not have done/found yourself that way X ). As another example think of information retrieval and the difference between useful information that you find and that you have been searching for and of useful information that you did not search for. (see [10] for more on that).

Thus a group X  X  recommendation also have a normative effect on the group members [10], which is not all bad, since everybody has (to a certain extent) a tendency to behave in a way that she is accepted in a group. Thus knowing what others of your group know or like is beneficial.

Without social recommenders, such an effect could not be reached because we would lack criteria on how to chose these horizon broadening recommendations.

In order to use that social structures for context-aware recommendation generation, we are currently working on an agent-based mobile peer-to-peer framework for generating not only context-aware recommendations but to generate social-sensitive AND context-aware recommendations.
We have shown that social networks can be used to in recommender systems in taste related domains With good success. As we have seen, the study we have conducted hints that social recommenders perform as good as the best CF approaches (in some situations (e.g. sparsity) and under some aspects (e.g. novel predictions) even clearly better). Future work will have to continue and deepen the investiga-tion of how social models in general can be used to improve recommenders and information systems in general. [1] D. Billsus and M. J. Pazzani. Learning collaborative [2] P. Bonhard and M. A. Sasse.  X  X nowing me, knowing [3] J. Bortz. Statistik . Springer, Heidelberg, 2005. [4] D. Boyd. Faceted id/entity: Managing representation [5] R. Burke. Hybrid recommender systems: Survey and [6] M. F. Caplan and C. E. Miller. Group decision [7] L. Garton, C. Haythornthwaite, and B. Wellman. [8] J.A.Golbeck. Computing and applying trust in [9] M. S. Granovetter. The strength of weak ties. The [10] G. Groh. Ad-Hoc-Groups in Mobile Communities -[11] J. L. Herlocker, J. A. Konstan, and J. T. Riedl. An [12] J. L. Herlocker, J. A. Konstan, L. G. Terveen, and [13] H. Kautz, B. Selman, and M. Shah. Referralweb: [14] S. Kosub. Local density. in: U. Brandes, T. Erlebach [15] M. Montaner, B. Lopez, and J. L. de la Rosa. A [16] J. W. Moon and L. Moser. On cliques in graphs. Israel [17] N.N. www.google.com/orkut. May 2007. [18] N.N. www.lokalisten.de. May 2007. [19] N.N. www.multiply.com. May 2007. [20] E. Noelle-Neumann. The theory of public opinion: the [21] J. O X  X onovan and B. Smyth. Trust in recommender [22] D. M. Pennock, E. Horvitz, S. Lawrence, and C. L. [23] H. A. Shuji Tsukiyama, Mikio Ide and I. Shirakawa. A [24] R. Sinha and K. Swearingen. Comparing [25] M. Smith. Invisible crowds in cyberspace: Measuring [26] M. A. Smith and A. T. Fiore. Visualization [27] E. G. Vozalis and K. G. Margaritis. Recommender [28] S. Wasserman and K. Faust. Social Network Analysis : [29] B. Wellman. An electronic group is virtually a social [30] I. Yaniv. Receiving other people X  X  advice: Influence [31] P. G. Zimbardo and R. J. Gerrig. Psychologie .
In an undirected graph with n vertices (nodes) a naive upper bound for the number of cliques is obviously 2 n .A theorem By Moon and Moser [16][14] gives a tighter upper bound ( X  X n undirected graph with n vertices has at most 3 3 maximal cliques X ), but thus one will have to expect, in general, an exponential number of cliques, which will, in the general case, prevent the existence of a polynomial time algorithm for the enumeration of all maximal cliques. An obvious naive approach is exhaustive search, for the time complexity of which a simple upper bound is O ( n 2 2 n ).
Even searching for specific cliques is generally computa-tionally hard. Deciding for a given Graph and a number k  X  N whether there is a clique of lat least size k is an NP-complete problem [14].

But there are easy other problems which can be solved for a graph G ( V, E )intime O ( | V | + | E | ). E.g. determining for a set U  X  V if it is a clique in G or determining for a clique U  X  V if it is maximal or (assuming an ordering on V )determiningforaclique U the lexicographically smallest clique containing U . See [14] for details.

Modern algorithms for the enumeration of all maximal cliques exist that run in polynomial total time. That is these algorithms output all  X  existing maximal cliques in a time bounded by a polynomial in | V | and  X  [14]. If the num-ber of maximal cliques in the graph is comparatively small (the nodes have small neighborhoods on average) then these algorithms can be expected to deliver all maximal cliques in reasonable time.

Since we are only interested in computing  X  X nough X  cliques to test the connection between rating behavior and social relations, we want an algorithm that will not run a long time before putting out cliques. Thus we are interested in a polynomial total time algorithm with polynomial delay. Polynomial delay means that the delay until the first output, the delay between consecutive output and the delay until the last output are polynomially bound [14].

Such an algorithm was published in [23]. It enumerates all maximal cliques of a graph with polynomial delay O ( n 3 using O ( | V | + | E | ) space. It works like this [14]:
First construct a binary tree with | V | = n levels hav-ing leaves only at level n . The nodes at level i represent all the maximal cliques of the induced graph G [ { v 1 ,...,v Thus the leaves of the tree represent all maximal cliques of
G [ { v 1 ,...,v n } ]= G . Thus a suitable tree traversal that outputs all leaves does the job.

In order to construct the tree we will have to do the following: Considering level i and a maximal clique U (in G [ { v 1 ,...,v i } ]) on that level. When determining the at most two children of U on level i + 1, two cases arise: (1) Either all vertices of U are adjacent to v i +1 in G .Thus U  X  X  v i +1 } is a maximal clique in G [ { v 1 ,...,v i ,v then has only this one child U  X  X  v i +1 } . (2) Or there are vertices in U not adjacent to v i +1 . Cer-tainly U itself is then a maximal clique in G [ { v 1 ,...,v 1 } ]. If the clique U \  X  N ( v i +1 )  X  X  v i +1 } (where  X  N notes all the nodes not adjacent to v i +1 ) is maximal (which does not necessarily needs to be the case) it is also a po-tential child for U . Since this node could potentially be the child of many other nodes on level i we place it under the lexicographically smallest U on level i (if it is maximal). A simple further consideration yields the delay estimation O ( n 3 ) and the space complexity O ( n + | E | ) [14]. Thus if we have  X  maximal cliques in the graph we have a polynomial total time complexity of O ( n 3  X  ).

In our case, the average neighborhood of a node (the av-erage number of friends is 2 . 48 thus we expect not too many cliques and will therefore be able to enumerate all of them in reasonable time.
 Table 5:  X  2 -Test -Friend-Pairs, Cliques(3) and 2 4 6
