 University of Haifa
We introduce finite-state registered automata (FSRAs), a new computational device within the which are presently not optimized for describing this kind of phenomena. We first define the model and discuss its mathematical and computational properties. Then, we provide an extended by providing several examples of complex morphological and phonological phenomena, which are elegantly implemented with FSRAs. 1. Introduction
Finite-state (FS) technology has been considered adequate for describing the morpho-logical processes of the world X  X  languages since the pioneering works of Koskenniemi (1983) and Kaplan and Kay (1994). Several toolboxes provide extended regular expres-(FSAs) and transducers (FSTs) (Karttunen et al. 1996; Mohri 1996; van Noord and
Gerdemann 2001a). While FS approaches to most natural languages have generally been very successful, it is widely recognized that they are less suitable for non-concatenative phenomena; in particular, FS techniques are assumed not to be able to efficiently account for the non-concatenative word formation processes that Semitic languages exhibit (Lavie et al. 1988).
 straightforwardly described using concatenation as the primary operation, the main word formation process in such languages is inherently non-concatenative. The stan-dard account describes words in Semitic languages as combinations of two morphemes: a root and a pattern. 1 The root consists of consonants only, by default three (although created by interdigitating roots into patterns: The first consonant of the root is inserted into the first consonantal slot of the pattern, the second root consonant fills the second morpho-phonological alternations take place, which may be non-trivial but are mostly concatenative.
 whereby some elements that are related to each other in some deep-level representation (e.g., the consonants of the root) are separated on the surface. While these phenomena do not lie outside the descriptive power of FS systems, na  X   X vely implementing them in are inefficient to process, as the following examples demonstrate.
 Example 1 We begin with a simplified problem, namely accounting for circumfixes. Consider three
Hebrew patterns: ha a a , hit a a ut ,and mi a , where the empty boxes indi-cate the slots in the patterns into which the consonants of the roots are inserted. Hebrew orthography 2 dictates that these patterns be written h a, ht ut ,and m ,re-can be viewed as circumfixes). An automaton that accepts all the possible combinations of three-consonant stems and these three circumfixes is illustrated in Figure 1. with the number of stems and circumfixes. The number of arcs in this automaton is three circumfixes have the same body, which encodes the stems. An attempt to avoid the duplication of paths is represented by the automaton of Figure 2, which accepts the language denoted by the regular expression ( ht + h + m )( root )( ut + a + ). The number of states here is 2 r + 4, i.e., is independent of the number of circumfixes. The number also reduced. Obviously, however, such an automaton over-generates by accepting also invalid words such as m ut . In other words, it ignores the dependencies which hold between prefixes and suffixes of the same circumfix. Since finite-state devices have no 50 memory, save for the states, there is no simple and space-efficient way to account for such dependencies.
 Example 2
Consider now a representation of Hebrew where all vowels are explicit, e.g., the pattern hit a e . Consider also the roots r.g.z, b.$.l ,and g.b.r . The consonants of a given root are inserted into the  X   X  slots to obtain bases such as hitragez, hitba$el ,and hitgaber .The finite state automaton of Figure 3 is the minimized automaton accepting the language; it has fifteen states. If the number of three letter roots is r , then a general automaton accepting the combinations of the roots with this pattern will have 4 r + 3 states and 5 r + 1 arcs. Notice the duplicated arcs which stem from copying the pattern in the different paths.
 Example 3
Another non-concatenative process is reduplication: The process in which a morpheme or part of it is duplicated. Full reduplication is used as a pluralization process in Malay and Indonesian; partial reduplication is found in Chamorro to indicate intensivity. It can also be found in Hebrew as a diminutive formation of nouns and adjectives: keleb klablab $apan $panpan zaqan zqanqan $axor $xarxar dog puppy rabbit bunny beard goatee black dark qatan qtantan little tiny trans-regular, therefore no finite-state automaton accepts it. However, the language
L natural languages can in most cases be bounded by some n of reduplication in natural languages is practically limited. Therefore, the descriptive constructing L n for a small number of different n s). An automaton that accepts L be constructed by listing a path for each accepted string (since  X  and n are finite, the number of words in L n is finite). The main drawback of such an automaton is the growth in its size as |  X  | and n increase: The number of strings in L state techniques can account for limited reduplication, but the resulting networks are space-inefficient.
 mentation, introduced by Kornai (1996).
 Example 4
The goal of this example is to construct a transducer over  X = transducer that performs addition by 1 on binary numbers has only 5 states and 12 arcs, but this transducer is neither sequential nor sequentiable. The problem is that since the input is scanned left to right but the carry moves right to left, the output of the first bit has to be delayed, possibly even until the last input bit is scanned. Thus, for an n -bit binary incrementor, 2 n disjunctions have to be considered, and therefore a minimized states and a similar number of transitions.
 medium-distance dependencies such as interdigitation and reduplication in an efficient way. Our main motivation is theoretical, i.e., reducing the complexity of the number of states and arcs in the networks; we show that these theoretical contributions result in practical improvements. In Section 3 we define the model formally, show that it is equivalent to FSAs and define many closure properties directly. define a regular expression language for denoting FSRAs. In Section 5 we provide dedi-cated regular expression operators for some non-concatenative phenomena and exem-plify the usefulness of the model by efficiently accounting for the motivating examples.
In Section 6 we extend FSRAs to transducers. The model is evaluated through an actual implementation in Section 7. We conclude with suggestions for future research. 2. Related Work
In spite of the common view that FS technology is in general inadequate for describing non-concatenative processes, several works address the above-mentioned problems in various ways. We summarize existing approaches in this section.
 menting non-concatenative morphology. Two-Level Morphology was used by Kataja and Koskenniemi (1988) to create a rule system for phonological and morphophonolog-ical alternations in Akkadian, accounting for word inflection and regular verbal deriva-tion. As this solution effectively defines lexical representations of word-forms, its main disadvantage is that the final network is the na  X   X ve one, suffering from the space com-plexity problems discussed above. Lavie et al. (1988) examine the applicability of Two-52
Level Morphology to the description of Hebrew Morphology, and in particular to verb inflection. Their lexicon consists of three parts: verb primary bases (the past tense, third person, singular, masculine), verb prefixes, and verb suffixes. They attempt to describe Hebrew verb inflection as a concatenation of prefix+base+suffix, implementable by the
Two-Level model. However, they conclude that  X  X he Two-Level rules are not the natural waytodescribe ... verb inflection process. The only alternative choice ... is to keep all bases ... it seems wasteful to save all the secondary bases of verbs of the same pattern. X  without extending their expressivity. The traditional two-level model of Koskenniemi (1983) is expanded into n -tape automata by Kiraz (2000), following the insight of Kay (1987) and Kataja and Koskenniemi (1988). The idea is to use more than two levels of expression: The surface level employs one representation, but the lexical form employs multiple representations (e.g., root, pattern) and therefore can be divided into different levels, one for each representation. Elements that are separated on the surface (such as the root X  X  consonants) are adjacent on a particular lexical level. For example, to describe circumfixation using this model, a 4-tape automaton of the form surface, PR pattern, circumfix, stem is constructed, so that each word is represented by 4 levels. The surface
R the root letter X  X  position), e.g., PRRRP . The circumfix and stem levels represent the circumfix and the stem respectively.
 the 4-level representation shown in Figure 4. Notice that the symbols representing the circumfix in the PR pattern level (i.e., the occurrences of the symbol  X  X  X ), the circumfix symbols in the circumfix level, and the circumfix symbols in the surface level are located in correlating places in the different levels. The same holds for the stem symbols. In this way, it is clear which symbols of the surface word belong to the circumfix, which belong to the stem, and how they combine together to create the final form of the word.
The 4-tape automaton of Figure 5 accepts all the combinations created by circumfixing roots with the three circumfixes of Example 1. Each arc is attributed with a quadruplet, consisting of four correlating symbols in the four levels. Notice that as in FSAs, the paths encoding the roots are duplicated for each circumfix, so that this automaton is as space-inefficient as ordinary FSAs. Kiraz (2000) does not discuss the space complexity of this model, but the number of states still seems to increase with the number of roots and patterns. Moreover, the n -tape model requires specification of dependencies between symbols in different levels, which may be non-trivial.
 using finite-state methods. The idea is to enrich finite-state automata with three new operations: repeat , skip ,and self loops . Repeat arcs allow moving backwards within a forwards in a string while suppressing the spell out of some of its letters; self loop arcs model infixation. In Walther (2000b), the above technique is used to describe Temiar reduplication, but no complexity analysis of the model is given. Moreover, this tech-nique does not seem to be able to describe interdigitation.
 constructing FSTs, which involves reapplying the regular-expression compiler to its own output. The compile-replace algorithm facilitates a compact definition of non-concatenative morphological processes, but since such expressions compile to the na  X   X ve networks, no space is saved. Furthermore, this is a compile-time mechanism rather than a theoretical and mathematically founded solution.
 (1985, 1989) presents a model, called Register Vector Grammar, introducing context-sensitivity by representing the states and transitions of finite-state automata as ternary-valued vectors, which need not be fully specified. No formal properties of this model are discussed. In a similar vein, Kornai (1996) introduces vectorized finite-state automata, be unknown (free). In this way information can be moved through the transitions by the overwriting operation and traversing these transitions can be sanctioned through
Kornai (1996) shows it can efficiently solve the problem of 32-bit binary incrementor (Example 4). Using vectorized finite-state automata, a 32-bit incrementor is constructed then, using unification, the result is calculated where the carry can be computed from model can solve it efficiently. The formalism presented by Kornai (1996) allows a that it significantly deviates from the standard methodology of developing finite-state devices, and integration of vectorized automata with standard ones remains a challenge.
Moreover, it is unclear how, for a given problem, the corresponding network should be constructed: Programming with vectorized automata seems to be unnatural, and no regular expression language is provided for them.

Mohri, Pereira, and Riley (2000). They introduce an object-oriented library for manipu-54 lating finite-state devices that is based on the algebraic concepts of rational power series and semirings. This approach facilitates a high degree of generality as the algorithms are defined for the general algebraic notions, which can then be specialized according to the needs of the user. They exemplify the usefulness of this library by showing how to specialize it for the manipulation of weighted automata and transducers. Our work can be seen as another specialization of this general approach, tailored for ideally dealing with our motivating examples.
 lems or motivated by different considerations. Krauwer and des Tombe (1981) refer to transducers with a finite number of registers when comparing transducers and transducers. However, they never formally define the model and do not discuss its ability to efficiently implement non-concatenative natural languages phenomena. More-over, they do not show how the closure properties can be implemented directly on these registered transducers, and do not provide any regular language denoting such transducers.
 putational model which extends finite state automata to the case of infinite alphabets. while maintaining closure under Kleene star and boolean operations, with the excep-tion of closure under complementation. The familiar automaton is augmented with registers, used to store alphabet symbols, whose number is fixed for each automa-ton and can vary from one automaton to another. The model is designed to deal with infinite alphabets, and therefore it cannot distinguish between different symbols; it can identify different patterns but cannot distinguish between different symbols with finite memory (registers) in a restricted way, but we avoid the above-mentioned language alphabet, allowing the information stored in the registers to be more mean-dard one in FSAs, rendering our model a conservative extension of standard FSAs and allowing simple integration of existing networks with networks based on our model.
 separated morphemes in words. He proposes a method, called flag diacritics , which adds features to symbols in regular expressions to enforce dependencies between separated parts of a string. The dependencies are forced by different kinds of unification actions.
In this way, a small amount of finite memory is added, keeping the total size of the network relatively small. Unfortunately, this method is not formally defined, nor are its mathematical and computational properties proved. Furthermore, flag diacritics are manipulated at the level of the extended regular expressions, although it is clear that they are compiled into additional memory and operators in the networks themselves.
The presentations of Beesley (1998) and Beesley and Karttunen (2003) do not explicate plexity. Our approach is similar in spirit, but we provide a complete mathematical and computational analysis of such extended networks, including a proof that the model dedicated regular expression operations for non-concatenative processes and show how they are compiled into extended networks, thereby accounting for the motivating examples. 3. Finite-state Registered Automata
We define a new model, finite-state registered automata (FSRA), aimed at facilitating the expression of various non-concatenative morphological phenomena in an efficient way. The model augments finite-state automata with finite memory (registers) in a restricted way that saves space but does not add expressivity. The number of registers automaton to  X  X emember X  a finite number of symbols. In addition to being associated designated register. In this section we define FSRAs and show that they are equivalent to standard FSAs (Section 3.1). We then directly define several closure operations over
FSRAs (Section 3.2) and provide some optimizations in Section 3.3. We conclude this section with a discussion of minimization (Section 3.4). 3.1 Definitions and Examples Definition
A finite-state registered automaton (FSRA) is a tuple A = Q , q 56 Definition A configuration of A is a pair ( q , u ), where q  X  and u represents the registers content). The set of all configurations of A is denoted by
Q c . The pair q c first component in F are called final configurations. The set of final configurations is denoted by F c .
 Definition
Let u = u 0 u 1 ... u n  X  1 and v = v 0 v 1 ... v n  X  1 . Given a symbol  X  ( t , v ), iff either one of the following holds: move from c 1 to c 2 when scanning the input  X  (or without any input, when  X  = )inone tions must be equal, and in particular the contents of the designated register in the two configurations should be the expected symbol (  X  ). If the register operation is W , then the contents of the registers in the two configurations is equal except for the designated reg-ister, whose contents in the produced configuration should be the expected symbol (  X  ). Definition
A run of A on w is a sequence of configurations c 0 , ... , c for every k ,1  X  k  X  r , c k  X  1  X  there exists a run of A on w .Noticethat | w | may be less than r since some of the  X  be .The language recognized by an FSRA A , denoted by L ( A ), is the set of words over
 X   X  accepted by A .
 Example 5
Consider again example 1. We construct an efficient FSRA accepting all and only the possible combinations of stems and circumfixes. If the number of stems is r , we define an FSRA A = Q , q 0 ,  X  ,  X  ,2,  X  , { q f } where:
This automaton is shown in Figure 6. The number of its states is 2 r + 4 (like the FSA of Figure 2), that is, O ( r ), and in particular independent of the number of circumfixes. circumfixes, to O ( r + p ).
 Example 6
Consider again example 2. The FSRA of Figure 7 also accepts the same language. This automaton has seven states and will have seven states for any number of roots. The number of arcs is also reduced to 3 r + 3.
 has an equivalent FSRA: Every FSA is also an FSRA since every transition ( s ,  X  , t )inan FSRA is a shorthand notation for ( s ,  X  , R ,0,#, t ). The other direction is also simple. Theorem 1 Every FSRA has an equivalent finite-state automaton.

We prove this by constructing an equivalent FSA toagivenFSRA . The construction is based on the fact that in FSRAs the number of registers is finite, as are the sets  X  and
Q , the register alphabet and states, respectively. Hence the number of configurations is finite. The FSA X  X  states are the configurations of the FSRA, and the transition function simulates the  X  X roduces X  relation. Notice that this relation holds between configurations depending on  X  only, similarly to the transition function in an FSA. The constructed FSA is non-deterministic, with possible -moves. The formal proof is suppressed. states when constructing A from A might be in the worst case exponential in the num-ber of registers. In other words, the move from FSAs to FSRAs can yield an exponential reduction in the size of the network. As we show below, the reduction in the number of states can be even more dramatic.
 is determined for each automaton separately. The register operations are defined as a sequence (rather than a set), in order to allow more than one operation on the same 58 register over one transition. This extension allows further reduction of the network size for some automata as well as other advantages that will be discussed presently. Definition
An order-k finite-state registered automaton (FSRA-k) is a tuple A = Q , q k ,  X  , F , where: Definition
Given a  X  Actions  X  n we define a relation over  X  n , denoted u u a v where u = u 0 ... u n  X  1 and v = v 0 ... v n  X  1 iff the following holds:
This relation is extended to series over Actions  X  n . Given a series a where p  X  N , we define a relation over  X  n denoted u define u a Definition
Let u , v  X   X  n . Given a symbol  X   X   X   X  X  } and an FSRA-k A , we say that a configuration ( s , u ) produces a configuration ( t , v ), denoted ( s , u ) ( Actions  X  n ) p for some p  X  N such that ( s ,  X  , a 1 , ... , a Definition
A run of A on w is a sequence of configurations c 0 , ... , c every l ,1  X  l  X  r , c l  X  1  X  exists a run of A on w .The language recognized by an FSRA-k A , denoted by L ( A ), is the set of words over  X   X  accepted by A .
 Example 7
Consider the Arabic nouns qamar (moon), kitaab (book), $ams (sun), and daftar (note-book). The definite article in Arabic is the prefix al , which is realized as al when pre-ceding most consonants; however, the  X  X  X  of the prefix assimilates to the first consonant of the noun when the latter is  X  X  X ,  X $ X , etc. Furthermore, Arabic distinguishes between definite and indefinite case markers. For example, nominative case is realized as the suffix u on definite nouns, un on indefinite nouns. Examples of the different forms of
Arabic nouns are: the above nouns. In order to account for the assimilation, register 2 stores information about the actual form of the definite article. Furthermore, to ensure that definite nouns occur with the correct case ending, register 1 stores information of whether or not a definite article was seen.
 60 an equivalent FSRA-k: Every FSRA is an FSRA-k for k = 1. The other direction is also simple.
 Theorem 2 Every FSRA-k has an equivalent FSRA.

We show how to construct an equivalent FSRA (or FSRA-1) A given an FSRA-k A . Each transition in A is replaced by a series of transitions in A X , each of which performs one operation on the registers. The first transition in the series deals with the new input transition minus one. The formal construction is suppressed.
 be referred to as FSRA-1. For the sake of emphasis, however, the term FSRA-k will still be used in some cases.
 ordinary finite-state automata can be encoded efficiently by the FSRA-2 model. Given a finite-state automaton A , an equivalent FSRA-2 A is constructed. A has three states initial state. The register alphabet consists of the states of A and the symbol  X # X . Each arc in A has an equivalent arc in A with two register operations. The first reads the current state of A from the register and the second writes the new state into the register. If the source state of a transition in A is a final state, then the source state of the corresponding transition in A will be the final states representative; if the source state of a transition in A is a non-final state, then the source state of the corresponding transition in A will be the non-final states representative. The same holds also for the register. In this way A simulates the behavior of A . Notice that the number of arcs in A equals the number of arcs in A plus one, i.e., while FSRAs can dramatically reduce the number of states, compared to standard FSAs, a reduction in the number of arcs is not guaranteed.
 Theorem 3
Every finite-state automaton has an equivalent FSRA-2 with three states and two registers.
 Proof 1
Let A = Q , q 0 ,  X  ,  X  , F be an FSA and let f : Q  X  q f by Construct an FSRA-2 A = Q , q 0 ,  X  ,  X  ,2,2,  X  , F , where:
The formal proof that L ( A ) = L ( A ) is suppressed. 3.2 Closure Properties
The equivalence shown in the previous section between the classes of languages recog-nized by finite-state automata and finite-state registered automata immediately implies guages. Applying the regular operations to finite-state registered automata can be easily done by converting them first into finite-state automata. However, as shown above, such a conversion may result in an exponential increase in the size of the automaton, invalidating the advantages of this model. Therefore, we show how some of these operations can be defined directly for FSRAs. The constructions are mostly based on the standard constructions for FSAs with some essential modifications. In what follows, let A 1 = Q 1 , q 1 0 ,  X  1 ,  X  1 , n 1 , k 1 ,  X  1 , F 1 registered automata. 3.2.1 Union. Tw o F S R A s , A 1 , A 2 , are unioned into an FSRA A inthesamewayasinFSAs: by adding a new initial state and connecting it with -arcs to each of the (former) initial states of A 1 , A 2 . The number of registers and the maximal number of register operations per arc in A is the maximum of the corresponding values in A any specific run of A , the computation goes through just one of the original automata; therefore the same set of registers can be used for strings of L ( A 3.2.2 Concatenation. We show two different constructions of an FSRA A = Q , q by leaving only the accepting states of the second automaton as accepting states and adding an -arc from every accepting state of the first automaton to the initial state of the second automaton. Doing just this in FSRA is insufficient because using the same registers might cause undesired effects: The result might be affected by the content left in the registers after dealing with a substring from L ( A is used with care. The first alternative is to employ more registers in the FSRA. In this way when dealing with a substring from L ( A 1 )thefirst n moving to deal with a substring from L ( A 2 ) the next n alternative is to use additional register operations that clear the content of the registers before handling the next substring from L ( A 2 ). This solution may be less intuitive but will be instrumental for Kleene closure below. 62 3.2.3 Kleene Closure. The construction is based on the concatenation construction.
Notice that it cannot be based on the first alternative (adding registers) due to the fact that the number of iterations in Kleene star is not limited, and therefore the number of registers needed cannot be bounded. Thus, the second alternative is used: Register op-erations are added to delete the content of registers. The construction is done by turning states to the initial state with an -arc that is associated with a register operation that deletes the contents of the registers, leaving them ready to handle the next substring. 3.2.4 Intersection. For the intersection construction, assume that A (we show an algorithm for removing -arcs in Section 3.3.1). The following construction simulates the runs of A 1 and A 2 simultaneously. It is based on the basic construction for their behavior. Each transition is associated with two sequences of operations on the registers, one for each automaton. The number of the registers is the sum of the number of registers in the two automata. In the intersection automaton the first n are designated to simulate the behavior of the registers of A simulate the behavior of A 2 . In this way a word can be accepted by the intersection au-tomaton iff it can be accepted by each one of the automata separately. Notice that register operations from  X  1 and  X  2 cannot be associated with the same register. This guarantees that no information is lost during the simulation of the two intersected automata. 3.2.5 Complementation. Ordinary FSAs are trivially closed under complementation.
However, given an FSA A whose language is L ( A ), the minimal FSA recognizing the complement of L ( A ) can be exponentially large. More precisely, for any integer n &gt; 2, there exists a non-deterministic finite-state automaton (NFA) with n states A , such that any NFA that accepts the complement of L ( A ) needs at least 2 plementing an FSRA would be to convert it into FSA and complement the latter. We therefore do not provide a dedicated construction for this operator. 3.3 Optimizations 3.3.1 -removal. An -arc in an FSRA is an arc of the form ( s , , a , t ) where a is used as a meta-variable over Actions  X  n + (i.e., a represents a vector of register operations).
Notice that this kind of arc might occur in an FSRA by its definition. Given an FSRA that might contain -arcs, an equivalent FSRA without -arcs can be constructed. The construction is based on the algorithm for -removal in finite-state automata, but the requires some care. The resulting FSRA has one more state than the original, and some additional arcs may be added, too.
 here such loops can be associated with register operations which must be accounted for.
The number of possible sequences of register operations along an -loop is unbounded, sequences: Two sequences are in the same equivalence class if and only if they have the same effect on the state of the machine; since each machine has a finite number of configurations (see theorem 1), there are only finitely many such equivalence classes. -path from q 1 to q 2 with the register operations a over its arcs, and an arc ( q where  X  = ,andan -path from q 3 to q 4 with the register operations c over its arcs, then the equivalent -free network will include the arcs ( q ( q in Figure 9. Notice that if q 1 and q 2 are the same state, then states q connected by two parallel arcs differing in their associated register operations; the same holds for states q 2 and q 4 . Similarly, when q 3 and q 4 empty word is accepted by the original automaton. The formal construction is similar in spirit to the -removal paradigm in weighted automata (Mohri 2000), where weights along an -path need to be gathered. Therefore, we suppress the formal construction and the proof of its correctness. 3.3.2 Optimizing Register Operations. In FSRAs, traversing an arc depends not
Sometimes, a given series of register operations can never be satisfied, and thus ( q and 3.3.1 might result in redundant states and arcs that can never be reached or can never lead to a final state. Moreover, in many cases a series of register operations can
Therefore, we show an algorithm for optimizing a given FSRA by minimizing the series of register operations over its arcs and removing redundant arcs and states. i -th register. Define a total function sat i : Actions  X  64 sat executed successfully. Determining whether sat i ( a ) = true by exhaustively checking all the vectors in  X  n may be inefficient. Therefore, we show a necessary and sufficient condition for determining whether sat i ( a ) = true for some a be checked efficiently. In addition, this condition will be useful in optimizing the series of register operations as will be shown later. A series of register operations over the i -th register is not satisfiable if either one of the following holds: Theorem 4
For all a = ( op 1 , i ,  X  1 ), ( op 2 , i ,  X  2 ), ... ,( op only if either one of the following holds: 1. There exists k ,1  X  k &lt; s , such that op k = W and there exists m , k &lt; m 2. There exists k ,1  X  k &lt; s , such that op k = op k + 1 the series are the same operation, which is ( R , 0, #); and this operation can never fail.
In addition, if all the operations in the series are write operations, then again, by the definition of FSRAs, these operations can never fail. If none of the two conditions of the theorem holds, then the series of register operations is satisfiable.
 following way: Definition
Define a function min i : Actions  X  n + | i  X  X  X  Actions  X  n  X  ) .If sat i ( a ) = true then: of a is suppressed.
 min : Actions  X  n +  X  X  X  Actions  X  n +  X  X  null } . For all a where b is obtained from a by:
Q , q 0 ,  X  ,  X  , n ,  X  , F = Opt ( A ) where Opt ( A ) is optimized with respect to register operations.
 final state. These states (and their connected arcs) can be removed in the same way they are removed in FSAs. In sum, FSRA optimization is done in two stages: 1. Minimizing the series of register operations over the FSRA transitions. 2. Removing redundant states and arcs.
 duction in the size of the network when performing the second stage. For a given FSRA
A , define OPT ( A ) as the FSRA obtained from Opt ( A ) by removing all the redundant 66 states and transitions. An FSRA A is optimized if OPT ( A ) = A (notice that OPT ( A )is unique, i.e., if B = OPT ( A )and C = OPT ( A ), then B = C ). 3.4 FSRA Minimization
FSRAs can be minimized along three different axes: states, arcs, and registers. Reduc-tion in the number of registers can always be achieved by converting an FSRA to an deterministic (see the discussion of linearization below), their minimization is related to the problem of non-deterministic finite-state automata (NFA) minimization, which is known to be NP-hard. 6 However, while FSRA arc minimization is NP-hard, FSRA state minimization is different. Recall that in theorem 3 we have shown that any FSA has an equivalent FSRA-2 with 3 states and 2 registers. It thus follows that any FSRA has an equivalent FSRA-2 with 3 states (simply convert the FSRA to an FSA and then convert it to an FSRA-2 with 3 states). Notice that minimizing an FSRA in terms of states or registers can significantly increase the number of arcs. As many implementations of in such minimization is limited. Therefore, a different minimization function, involving corresponding proof on NFA, we suppress it.
 Theorem 5 FSRA arc minimization is NP-hard.
 state automata, this is achieved by determinizing the network, ensuring that the lation does not guarantee linear recognition time, since multiple possible transi-
FSRA A = Q , q 0 ,  X  ,  X  , n , k ,  X  , F , and some q , q ( q ,  X  , ( W ,1, a ) , q 1 ), ( q ,  X  , ( W ,1, b ) , q 2 transition relation. However, they do imply that for the state q and for the same input symbol (  X  ), more than one possible arc can be traversed. We use deterministic to denote
FSRAs in which the transition relation is a function, and a new term, linearized, is used to denote FSRAs for which linear recognition time is guaranteed.
 transition relation includes two arcs of the form ( q ,  X  , a , q b must be a contradicting series of register operations. Two series of register operations are contradicting if at most one of them is satisfiable. Since the FSRA is optimized, each series of register operations is a concatenation of subseries, each operating on a differ-ent register; and the subseries operating on the i -th register must be either empty or ( W , i ,  X  ) or ( R , i ,  X  ) or ( R , i ,  X  1 ), ( W , i ,  X  ( R , i ,  X  1 ), ( W , i ,  X  2 ) . ( R , i ,  X  ) and ( R , i ,  X  Definition all ( q ,  X  , a , q 1 ), ( q ,  X  , b , q 2 )  X   X  such that a = b , where a = ( op i ,  X  1 k ) and b = ( op 2 1 , i 2 1 ,  X  2 1 ), ... ,( op 2 exists j 2 ,1  X  j 2  X  m , such that op 1 j an exponential increase in the network size. As the following theorem shows, FSRA linearization is NP-complete.
 Theorem 6 FSRA linearization is NP-complete.
 Proof 2 Evidently, given an FSRA A , it can be verified in polynomial time that A is linearized. Therefore, FSRA linearization is in NP.
 that L ( A ) = { } if  X  is satisfiable, otherwise L ( A ) =
Let x 1 , ... , x n be the variables of  X  . Define A = Q , q  X   X  = { ( q
For example, for the CNF formula ( x 1  X  x 2  X  x 5 )  X  ( x Figure 10 is constructed. Observe that the number of states and arcs in this FSRA is
O ( mn ). Now, linearize A into an FSRA A and assume this can be done in polynomial time. By the definition of linearized FSRA, A does not contain -arcs. Therefore, of A is also a final one. 4. A Regular Expression Language for FSRAs
Regular expressions are a formal way for defining regular languages. Regular language operations construct regular expressions in a convenient way. Several toolboxes (soft-ware packages) provide extended regular expression description languages and compil-68 ers of the expressions to finite-state devices, automata, and transducers (see Section 1).
We provide a regular expression language for constructing FSRAs, the denotations of whose expressions are FSRAs. In the following discussion we assume the regular expression syntax of XFST (Beesley and Karttunen 2003) for basic expressions. Definition
 X  is the register alphabet. If R is a regular expression and a register operations, then the following are also regular expressions: a R , a R , a R , and a R .
 expression whose denotation is the FSRA A ,andlet a  X  Actions of a R is an FSRA A obtained from A by adding a new node, q , which becomes the initial node of A , and an arc from q to the initial node of A ; this arc is labeled by and associated with a . Notice that in the regular expression a R , R and a can contain operations on joint registers. In some cases, one would like to distinguish between the registers used in a and in R . Usually, it is up to the user to correctly manipulate the usage of registers, but in some cases automatic distinction seems desirable. For example, if R includes a circumfix operator (see below), its corresponding FSRA will contain register operations created automatically by the operator. Instead of remembering that circumfixation always uses register 1, one can simply distinguish between the registers of a and R via the a R operator. This operator has the same general effect as the previous one, but the transition relation in its FSRA uses fresh registers that are added to the machine.

Using these additional operators, it is easy to show that every FSRA has a corresponding regular expression denoting it, by a trivial modification of the construction presented by Kleene (1956).
 Example 8
Consider the case of vowel harmony in Warlpiri (Sproat 1992), where the vowel of
A simplified account of the phenomenon is that suffixes come in two varieties, one with  X  X  X  vowels and one with  X  X  X  vowels. Stems whose last vowel is  X  X  X  take suffixes of the first variety, whereas stems whose last vowel is  X  X  X  or  X  X  X  take the other variety. The following examples are from Sproat (1992) (citing Nash (1980)): 1. maliki+kil . i+l . i+lki+ji+li 2. kud . u+kul . u+l . u+lku+ju+lu 3. minija+kul . u+l . u+lku+ju+lu
An FSRA that accepts the above three words is denoted by the following complex regular expression: define LexI [m a l i k i]; % words ending in  X  X  X  define LexU [k u d u]; % words ending in  X  X  X  define LexA [m i n i j a]; % words ending in  X  X  X  ! Join all the lexicons and write to register 1  X  X  X  or  X  X  X  ! according to the stem X  X  last vowel. define Stem [&lt;(W,1,i)&gt; LexI] | [&lt;(W,1,u)&gt; [LexU | LexA]]; ! Traverse the arc only if the scanned symbol is the content of ! register 1. define V [&lt;(R,1,i)&gt; i] | [&lt;(R,1,u)&gt; u]; define PROP [+ k V l V]; % PROP suffix define ERG [+ l V]; % ERG suffix define Then [+ l k V]; % suffix indicating  X  X hen X  define Me [+ j V]; % suffix indicating  X  X e X  define They [+ l V]; % suffix indicating  X  X hey X  ! define the whole network define WarlpiriExample Stem PROP ERG Then Me They; (LexI, LexU, LexA), one for each word ending ( X  X  X ,  X  X  X , or  X  X  X  respectively). The separate the symbols  X  X  X ,  X  X  X  should be scanned and allows traversing the arc only if the correct symbol is scanned. Note that this solution is applicable independently of the size of the lexicon, and can handle other suffixes in the same way.
 Example 9
Consider again Example 7. The FSRA constructed for Arabic nominative definite and indefinite nouns can be denoted by the following regular expression: ! Read the definite article (if present). ! Store in register 1 whether the noun is definite or indefinite. ! Store in register 2 the actual form of the definite article. 70 define Prefix [&lt;(W,1,indef)&gt; 0] | [&lt;(W,1,def),(W,2,l)&gt;  X  X l] | ! Normal base -definite and indefinite define Base [ [&lt;(R,2,l)&gt; 0] | [&lt;(R,1,indef)&gt; 0] ] ! Bases beginning with $ -definite and indefinite define $Base [ [&lt;(R,2,$)&gt; 0] | [&lt;(R,1,indef)&gt; 0]][$ams]; ! Bases beginning with d -definite and indefinite define dBase [ [&lt;(R,2,d)&gt; 0] | [&lt;(R,1,indef)&gt; 0]][daftar]; ! Read definite and indefinite suffixes. define Suffix [&lt;(R,1,def)&gt; u] | [&lt;(R,1,indef)&gt; un]; ! The complete network. define ArabicExample Prefix [Base | $Base | dBase] Suffix; in which the definite article (if present) is scanned and information indicating whether the word is definite or not is saved into register 1. In addition, if the word is definite
Other variables ($Base, dBase) denote nouns that trigger assimilation, where for each assimilation case, a different lexicon is constructed. Each part of the lexicon deals with both its definite and indefinite nouns by allowing traversing the arcs only if the register whether the noun is definite or indefinite. This is possible using the information that was stored in register 1 by the variable Prefix. 5. Linguistic Applications
We demonstrated in examples 5 and 6 that FSRAs can model some non-concatenative phenomena more efficiently than standard finite-state devices. We now introduce new regular expression operators, accounting for our motivating linguistic phenomena, and show how expressions using these operators are compiled into the appropriate FSRA. 5.1 Circumfixes
We introduce a dedicated regular expression operator for circumfixation and show how expressions using this operator are compiled into the appropriate FSRA. The operator of which is a pair of regular expressions (prefix, suffix). It yields as a result an FSRA defined such that the circumfixes can be arbitrary regular expressions.
 Definition
Let  X  be a finite set such that , { , } , , ,  X  /  X   X  . We define the the form where: m  X  N is the number of circumfixes; R is a regular expression over  X  denoting the set of bases; and  X  i ,  X  i for 1  X  i  X  m are regular expressions over  X  denoting the prefix and suffix of the i -th circumfix, respectively.
 erator, let A  X  i , A  X  i be the FSRAs denoted by  X  i ,  X 
FSRA constructed by concatenating three FSRAs. The first is the FSRA constructed from the union of the FSRAs A  X  1 , ... , A  X  m , where each A by adding a new node, q , which becomes the initial node of A use of register 1. The second FSRA is the FSRA denoted by the regular expression R first one, the only difference being that the FSRAs are those denoted by  X  and the associated register operation is ( R ,1,  X  i operation, defined in Section 3.2.2, adjusts the register operations in the FSRAs to be operation to concatenate the three FSRAs, leaving register 1 unaffected (to handle the circumfix).
 Example 10
Consider the participle-forming combinations in German, e.g., the circumfix ge-t .A simplified account of the phenomenon is that German verbs in their present form take an n suffix but in participle form they take the circumfix ge-t . The following examples are from Sproat (1992): s  X  auseln  X  X ustle X  ges  X  auselt  X  X ustled X  br  X  usten  X  X rag X  gebr  X  ustet  X  X ragged X 
The FSRA of Figure 11, which accepts the four forms, is denoted by the regular expression
This regular expression can be easily extended to accept more German verbs in other forms. More circumfixation phenomena in other languages such as Indonesian and Arabic can be modeled in the same way using this operator.
 72 Example 11
Consider again Example 5. The FSRA accepting all the possible combinations of stems and the Hebrew circumfixes h-a, ht-ut, m-can be denoted by the regular expression
R  X  X  h a ht ut m } where R denotes an FSA accepting the roots. 5.2 Interdigitation expressions, representing a set of roots, and a list of patterns, each of which containing exactly n slots. It yields as a result an FSRA denoting the set containing all the strings created by splicing the roots into the slots in the patterns. For example, consider the He-brew roots r.$.m, p.&amp;.l, p.q.d and the Hebrew patterns hit a e ,mi a ,ha a a . inputs, the new operator yields an FSRA denoting the set { mir$am, mip&amp;al, mipqad, har$ama, hap&amp;ala, hapqada Definition the form
For the sake of brevity,  X  i and  X  i are used as shorthand notations for  X  and  X  i 1  X  i 2 ... X  in , respectively.

 X   X  X  } for 1  X  i  X  k and 1  X  j  X  n + 1. In this case the splice operation yields as a result an FSRA-1 A = Q , q 0 ,  X  ,  X  ,3,  X  , F , such that L ( A ) = i  X  m ,1  X  j  X  k } , where: pattern and register 2 remembers the root. Notice that the FSRA will have 3 registers and 2 n + 2 states for any number of roots and patterns. The number of arcs is k machine has a constant number of states and O ( k + m )arcs.
 construction of the FSRA denoted by this operation is done in the same way as in the case of circumfixes with two main adjustments. The first is that in this case the final
FSRA is constructed by concatenating 2 n + 1 intermediate FSRAs ( n FSRAs for the n parts of the roots and n + 1 FSRAs for the n + 1 parts of the patterns). The second is that here, 2 registers are used to remember both the root and the pattern. We suppress the detailed description of the construction.
 Example 12
Consider again the Hebrew roots r.$.m, p.&amp;.l, p.q.d and the Hebrew patterns hit a e , mi a ,and ha a a . The splice operation 74 drawing.
 there is no systematic way to determine when such combinations will be realized binations exist. Furthermore, even when such a characterization is difficult to come by, the splice operator can be used, in combination with other extended regular expres-sion operators, to define complex expressions for generating the required language.
This is compatible with the general approach for using finite-state techniques, imple-menting each phenomenon independently and combining them together using closure properties. 5.3 Reduplication
We now return to the reduplication problem as was presented in example 3. We extend the finite-state registered model to efficiently accept L reduplication in natural languages. Using FSRAs as defined above does not improve space efficiency, because a separate path for each reduplication is still needed. Notice
Therefore, FSRAs are extended in order to be able to identify a pattern without actually distinguishing between different symbols in it. The extended model, FSRA*, is obtained from the FSRA-1 model by adding a new symbol,  X * X , assumed not to belong to  X  ,and by forcing  X  to be equal to  X  . The  X * X  indicates equality between the input symbol and symbols.
 Definition
Let  X  /  X   X  .An FSRA* is an FSRA-1 where  X = X  (and thus includes  X # X ) and the tran-sition function is extended to be  X   X  Q  X   X   X  X  ,  X  X  X {
 X   X  X  X  X  X  Q . The extended meaning of  X  is as follows:
L : The number of registers is n+1. Registers 1, ... , n remember the first n symbols to be duplicated. Figure 14 depicts an extended registered automaton that accepts L 4. Notice that the number of states depends only on n and not on the size of  X  . Figure 15 schematically depicts an extended registered automaton that accepts L
The language { ww || w | X  n } for some n  X  N can be generated by a union of FSRA*, reduplication, the resulting automaton is manageable, and in any case, considerably smaller than the na  X   X ve automaton. 5.4 Assimilation
In example 7, FSRAs are used to model assimilation in Arabic nominative definite nouns. Using the FSRA* model defined above, further reduction in the network size can be achieved. The FSRA* of Figure 16 accepts all the nominative definite forms of the Arabic nouns kitaab , qamar ,and daftar (more nouns can be added in a similar way).
Register 1 stores information about the actual form of the definite article, to ensure that assimilation occurs when needed and only then. Notice that in this FSRA, in contrast to 76 the FSRA of Figure 8, the definite Arabic article al is not scanned as one symbol but as two separate symbols. 6. Finite-state Registered Transducers
We extend the FSRA model to finite-state registered transducers (FSRT), denoting relations over two finite alphabets. The extension is done by adding to each transition an output symbol. This facilitates an elegant solution to the problem of binary incrementors which was introduced in Example 4.
 Example 13
Consider again the 32-bit incrementor example introduced in Example 4. Recall that a sequential transducer for an n -bit binary incrementor would require 2 similar number of transitions. Using the FSRT model, a more efficient n -bit transducer last four transitions output the result (in case the input is 1 -arcs. In the same way, an n -bit transducer can be constructed for all n a transducer will have n registers, 3 n + 1 states and 6 n arcs. The FSRT model solves the incrementor problem in much the same way it is solved by vectorized finite-state automata, but the FSRT solution is more intuitive and is based on existing finite-state techniques.
 counterparts. It immediately implies that FSRTs maintain the closure properties of regular relations. As in FSRAs, implementing the closure properties directly on FSRTs is essential for benefiting from their space efficiency. The common operators such as implementation of FSRT composition is a na  X   X ve extension of ordinary transducer com-operations in Cohen-Sygal (2004). 7. Implementation and Evaluation
In order to practically compare the space and time performance of FSRAs and FSAs, we have implemented the special operators introduced in Sections 4 and 5 for circumfix-ation and interdigitation, as well as direct construction of FSRAs. We have compared
FSRAs with ordinary FSAs by building corresponding networks for circumfixation, interdigitation, and n -bit incrementation. For circumfixation, we constructed networks for the circumfixation of 1,043 Hebrew roots and 4 circumfixes. For interdigitation we constructed a network accepting the splicing of 1,043 roots into 20 patterns. For n -bit incrementation we constructed networks for 10-bit, 50-bit, and 100-bit incrementors.
Table 1 displays the size of each of the networks in terms of states, arcs, and actual file size. 78 could not construct an n -bit incrementor FSA for any n greater than 100 as a result of memory problems, whereas using FSRAs we had no problem constructing networks even for n = 50, 000.
 we used the circumfixation, interdigitation, 10-bit incrementation, and 50-bit incremen-tation networks to analyze 200, 1,000, and 5,000 words. As can be seen in Table 2, time performance is comparable for the two models, except for interdigitation, where FSAs outperform FSRAs by a constant factor. The reason is that in this network the usage of registers is massive and thereby, there is a higher cost to the reduction of the network size, in terms of analysis time. This is an instance of the common tradeoff of time versus space: FSRAs improve the network size at the cost of slower analysis time in some cases. networks become too large to be practical. In such cases, using FSRAs can make network size manageable. Using the closure constructions one can build desired networks of reasonable size, and at the end decide whether to convert them to ordinary FSAs, if time performance is an issue. 8. Conclusions
In this work we introduce finite-state registered networks (automata and transducers), an extension of finite-state networks which adds a limited amount of memory, in the model several non-concatenative morphological phenomena, including circumfixation, root and pattern word formation in Semitic languages, vowel harmony, and limited reduplication.
 show that every FSA can be simulated by an equivalent FSRA with three states and two registers. For the motivating linguistic examples, we show a significant decrease in the number of states and the number of transitions. For example, to account for all the possible combinations of r roots and p patterns, an ordinary FSA requires O ( r arcs whereas an FSRA requires only O ( r + p ). As a non-linguistic example, we show a transducer that computes n -bit increments of binary numbers. While an ordinary (sequential) FST requires O (2 n ) states and arcs, an FSRT which guarantees linear recog-nition time requires only O ( n ) states and arcs.
 of their expressive power, to ordinary finite state networks. We provide an algorithm for converting FSRAs to FSAs and prove the equivalence of the models. Furthermore, we provide direct constructions of the main closure properties of FSAs for FSRAs, including concatenation, union, intersection, and composition.
 a regular expression language denoting FSRAs. In particular, we provide a set of extended regular expression operators that denote FSRAs and FSRTs. We demonstrate the utility of the operators by accounting for a variety of complex morphological and phonological phenomena, including circumfixation (Hebrew and German), root-and-pattern (Hebrew), vowel harmony (Warlpiri), assimilation (Arabic), and limited redu-state calculi, thereby providing a complete set of tools for the computational treatment of non-concatenative morphology.
 is the conversion of FSAs to FSRAs. While it is always possible to convert a given FSA to an FSRA (simply add one register which is never used), we believe that it is possible to automatically convert space inefficient FSAs to more compact FSRAs. A pre-requisite is a clear understanding of the parameters for minimization: These include the number of states, arcs, and registers, and the size of the register alphabet. For a given FSRA, the number of states can always be reduced to a constant (theorem 3) and registers can be done away with entirely (by converting the FSRA to an FSA, Section 3.1). In contrast, minimizing the number of arcs in an FSRA is NP-hard (Section 3.4). A useful conversion of FSAs to FSRAs must minimize some combination of these parameters, and while it may be intractable in general, it can be practical in many special cases. In particular, the case of finite languages (acyclic FSAs) is both of practical importance and  X  we conjecture  X  can result in good compaction.
 lar, we did not address issues such as sequentiality or sequentiability for this model.
FSRA  X  s can be done in a similar way to FSRAs, with the exception of intersection. For in-tersection, we believe that the use of predicates (van Noord and Gerdemann 2001b) can be beneficial. Furthermore, the use of predicates can be beneficial for describing natural language reduplication where the reduplication is not as bounded as the example we deal with in this work. In addition, the FSRA  X  model can be extended into transducers. 80 constructing a network for describing the complete morphology of a natural language containing many non-concatenative phenomena, e.g., Hebrew. A morphological ana-lyzer for Hebrew, based on finite-state calculi, already exists (Yona and Wintner 2005), but is very space-inefficient and, therefore, hard to maintain. It would be beneficial to compact such a network using FSRTs, and to inspect the time versus space tradeoff on such a comprehensive network.
 Acknowledgments References
