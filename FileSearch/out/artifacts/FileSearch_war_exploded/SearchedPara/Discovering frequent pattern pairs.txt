 Department of Computer Science, University of Houston, Houston, TX, USA 1. Introduction
This work focuses on the generalization of OLAP cubes [14] and association rules [5,13,15] to dis-cover frequent pattern pairs. Cubes are generally used to perform exploratory ad-hoc analysis in a mul-tidimensional manner, but they also have the potential to find predictive patterns. Association rules [15], on the other hand, are frequent patterns within a data set found by an exhaustive level-wise algorithm. Constrained association rules [12,15] exploit search constraints to filter and reduce the number of rules as well as to accelerate processing. The exhaustive search behind association rules and cubes makes it possible to discover specific relationships between predictive attributes (cube dimensions) and target attributes (cube measures). However, based on a specific predictive pattern (cube cell or association rule), it is difficult to determine which specific attribute plays a more important role in the implication (i.e., analogous to variable selection in regression). This fact motivates defining pairs of highly similar patterns isolating such  X  X rigger X  attribute.

Our contributions can be separated into two main areas: frequent pattern pairs and efficient algo-rithms. On the pattern discovery side, we introduce pattern pairs for both cubes and association rules as fundamental new patterns to understand predictive relationships between two subsets of attributes. We carefully study the reliability of such pattern pairs and introduce four complementary propositions to compare pattern pairs with each other. These propositions cover all potential cases when both tech-niques agree or disagree. Moreover, we provide a guideline to accept or reject pattern pairs based on those cases. Finally, we introduce a reliability metric based on cross-validation, which enables an ob-jective experimental comparison. From an algorithmic perspective, we propose novel query-based tech-niques for both techniques so that only significant pattern pairs are discovered. We exploit the fact that the level-wise algorithms to explore cubes are highly similar to those used to discover association rules. First, cube statistical tests are extended with search constraints, mainly to mine a similar set of patterns to constrained association rules. With association rules we introduce novel post-processing techniques to match highly similar association rules on the same attributes, where one attribute in the antecedent triggers a major change in the value of the attribute in the consequent (i.e. similar to variable selection).
This paper is organized as follows. Section 2 explains state of the art and closely related work. Def-initions and a running example are introduced in Section 3. Section 4 presents efficient algorithms to discover patterns pairs with cubes and association rules. Reliability is studied from a statistical per-spective in Section 5. Section 6 presents experiments with real data sets studying reliability, number of patterns, pattern set overlap and algorithm efficiency. Section 7 provides general conclusions along with directions for future research. 2. Related work Association rules and cubes are deeply related, both being combinatorial pattern search techniques. However, association rules [1] came before cubes [9,11]. The cube operator was proposed in the seminal paper [6]. Most cube research has focused either on efficiently building a data cube [18] or on evaluating simple aggregations such as sums on individual subgroups of the cube [2]. More recently, constraints have been applied in cubes to further improve both running time and reduce the number of patterns. We exploit constraints not only to improve performance, but for trimming the number of patterns. Recently, cubes were also used to classify cancers in [23]. In previous research, we proposed an algorithm that embeds statistical tests into OLAP cubes to discover specific trigger dimensions that cause significant changes in one or more of the measure attributes [4]. However, as with the original association rules, we can often find a large number of patterns from small data sets. Therefore, it was necessary to incorporate search constraints into cubes to reduce the number of patterns. On the other hand, in [16] association rules are shown to be better than decision trees to predict multiple target attributes; the main reasons behind are tree overfit, data fragmentation and automated attribute binning. In short, cube pairs represent an advance over association rules and decision trees to understand multiple target attributes and to isolate predictive attributes.

Prediction cubes [3] store on each cube cell summaries based on a predictive model. Each cell stores information such as accuracy that can then be used to predict results when the dimensions are known. In [19], a new way of exploring the data cube is developed. This discovery-driven approach analyzes a cell value compared with the common trends of the neighboring cells to pinpoint exceptions, which can be used by the user as hints of areas requiring further analysis. Our research differs from these two papers in that we are able to pinpoint trigger dimensions by observing pairs of similar cells. Instead of attempting to predict the measure columns when given a set of dimensions, we are looking to find the specific dimensions whose change causes the measure values to change as well. Notice that our goal is not to create a predictive model, but to narrow down the search to those important dimensions that are causing significant changes.

Association rules [1,15] have been used on many problems including disease prediction [15]. Search constraints were applied on association rules to both decrease the number of rules and to improve the running time of the algorithm [15,17]. In these works, rules are analyzed individually and conclusions are based on each rule. Filtering out spurious rules is studied in [7], which proposes improved confidence and lift metrics which are more robust to noise in the data set. It is well known there is a tradeoff between rules with high support and rules with high confidence [20]; this work proposes an algorithm that mines the best rules under a Bayesian model. However, no search constraints are considered to find predictive rules. The idea of grouping association rules together to discover information that would otherwise be hidden was explored in [10]. The authors used OLAP cube operations to group association rules together and explored the context information provided by such grouping. Instead of finding global context information, our research approaches rule context from a variable selection viewpoint to find single dimension. Thus, though we also group rules, the method by which this is accomplished is widely different. 3. Definitions
In this section, we introduce definitions and a small example, used throughout the paper. Since cube pairs and rule pairs require different input data set and produce different patterns, we must present separate definitions for each. However, we provide a unifying framework for both techniques. 3.1. Cube pairs
In cube pairs, we begin with the raw data set X ( X 1 ,X 2 ,...,X p Y 1 ,Y 2 ,...,Y q ) with n records, p independent attributes, and q dependent attributes. This data set is transformed into the fact table F with n records, d dimensions, and e measure attributes [8], to compute multidimensional aggregations. The d dimensions are discrete while the e measure attributes are numerical. The mathematical structure of the OLAP cube is represented by a lattice. The lattice contains all possible combinations of dimensions ( 2 d ). In this paper, each combination (e.g. { D 1 ,D 2 } or { D 1 ,D 3 } ) is called a node. A node is further divided into groups, with each group representing a specific combination of values of the dimensions (e.g. { D 1 =1 ,D 2 =0 } , { D 1 =1 ,D 2 =1 } ). In a cube pair there is a single dimension that has a different value to identify a  X  X rigger X  attribute. We do not consider cube pairs differing in two or more dimensions because it makes difficult identifying predictive relationships. To reduce the number of patterns, the cube size constraint k , determines the maximum number of dimensions that can appear in a cube pair. 3.2. Rule pairs
We now define a pair of association rules, which is simply called a rule pair. In rule pairs, we begin dependent attributes. Then, we transform X into D with n transactions and m binary dimensions. The binary dimensions data set D must then be transformed into a transaction format. Thus, pre-processing is required in the form of binning the dimensions into two buckets and pivoting the data set to create the transaction data set T with n transactions and I items. T would take the form of T = { T 1 ,T 2 ,...,T n } with I ={ i 1 ,i 2 ,...,i m }, where T i  X  I . Note that since negation is required, I would contain twice as many items. We call any subset of I an itemset.

An association rule is a predictive pattern of the form A  X  B ,where A and B are two itemsets such that A  X  I , B  X  I and A  X  B =  X  . In these rules, the antecedent is A with j items and the consequent is B with w items. Rules are often limited by a maximum number of items, k , that can appear. Association rules are evaluated using two metrics: support s () and confidence c () . Support s ( A  X  B ) is the fraction of transactions that contain A  X  B . Confidence is defined as c ( A  X  B )= s ( A  X  B ) /s ( A ) .Foran association rule to be considered valid, it must pass two user-defined thresholds: confidence threshold  X  and support threshold  X  . A rule pair is the combination of two association rules which differ in one dimension in the antecedent and have items coming from the same attribute on the consequent. We do not consider rules differing in two or dimensions. 3.3. Example Let us now discuss a data set that we will use throughout this paper. Figure 1 shows a medical data set, X with n = 10, p = 4, and q = 1, where we show both mathematical notation and attribute names. This data set is in its raw format and needs to be preprocessed. In X , there are four independent attributes X technique, we need to transform it. The same figure also shows the transformed data set, F ,thatisused as a fact input table for cube pairs. Finally, the figure shows the transaction input table T for rule pairs. Notice how attribute values and ranges were transformed into items in T . 4. Frequent pattern pairs
The algorithms we now present extend and combine previous work on cube statistical tests [4] and constrained association rules [15], used to discover frequent patterns. Basically we study how to build pairs of patterns from both techniques: pairs of cube groups and pairs of association rules, as defined in Section 3. To achieve such goal, we first study how to incorporate search constraints into cubes. On the other hand, we study how to build pairs of rules so that patterns from both techniques can be compared. We start by discussing an algorithm to get cube pairs and based on the same framework we then explain how to compute rule pairs. Figure 2 presents an overview of our algorithms. 4.1. Cube pairs algorithm
In previous research, we developed the cube statistical tests algorithm [4] which combines OLAP cubes and parametric statistical tests to discover patterns in data sets. The statistical test is used to com-pare two similar populations (similar cube dimensions), and return the significance of mean difference in a measure attribute.

Even though a cube algorithm does not return as many patterns as constrained association rules [15], it still can return thousands of patterns for a relatively small data set: the main reason is the lack of search constraints. Thus we first study how to incorporate such search constraints into our algorithm. In this case, we are using search constraints in OLAP cube statistical tests to reduce the set of discovered patterns. We approached this task by first analyzing the three main constraints used in constrained as-sociation rules [15]: item filtering, antecedent/consequent (AC), and item grouping. The first designates which items will be used to form the itemsets. We can apply this constraint in cube pairs by removing dimensions that will be filtered. The second constraint determines the location of items in an association rule: either in the antecedent or in the consequent. We emphasize this constraint is not applicable in cube pairs because dimension attributes can only appear on the  X  X ndependent X  side of the patterns, whereas those designated as measures will only appear on the  X  X redicted X  side. The third constraint places items into groups and restricts them from appearing in the same itemset. Since the cube pairs algorithm did not have this feature, we added optional input criteria and further changed the dimension grouping step. This optional input informs the algorithm of which dimensions or measures are in the same group. With this knowledge, we altered the dimension grouping step to avoid all nodes that contain dimensions belonging to the same group. We call this new algorithm cube pairs , which is the technical term we will use in the remainder of the paper. The main steps of the algorithm are as follows: 1. Aggregate the fact table F into cube C , at the finest granularity by aggregating measures based on 2. Compute sufficient statistics per cube group for each cuboid up to size k d (i.e. a subset of all 2 d 3. Compute the mean  X  and standard deviation  X  from sufficient statistics per group. 4. Build pairs of cube groups differing in one dimension. 5. For each cube pair evaluate statistical test on all measure attributes to determine significance level 6. Filter cube pairs that are deemed significant (whose p-value is lower than a given threshold).
In this algorithm, when comparing a pair of populations, we consider them to be significantly different if the null hypothesis, H 0 , can be rejected. We assume that we are dealing with two independent popula-to find all pairs of data subsets in which we can reject H 0 with high confidence, thus accepting H 1 .In this case, high confidence is equal to 1  X  p-value, where p-value depends on a user-defined threshold. In general, p-value has thresholds of 0.10, 0.05, or 0.01 [21]. The smaller p-value, the higher the confidence toward rejecting H 0 . In this algorithm, the calculation of the p-value comes from the means comparison parametric test, a statistical test that compares two populations based on their mean and variance. Con-sidering variance is fundamental because it provides discrimination in cases when the distance between  X 
EXAMPLE: Fig. 3 shows several examples of pattern pairs from cube pairs. Pair (1) can be translated to mean there is a significant change in the Blockage attribute value between the populations with age less than 60 and those greater than or equal to 60. 4.2. Rule pairs algorithm
The constrained association rules algorithm [15] was developed to reduce the large amount of rules and to reduce processing time. The basis behind this algorithm is the use of search constraints to filter rules and items, as explained in Section 4.1. Nevertheless, association rules lack specific information about predictive attributes. We only know the antecedent implies the consequent, but we cannot identify which item(s) cause a change in the consequent.

In order to provide constrained association rules with the ability to isolate predictive attributes, we developed a rule pairs algorithm which builds pairs of similar association rules. In developing this algo-rithm, we assume that if we discover two rules with similar antecedents, but complementary consequents on the predicted attribute (an attributed binned into two ranges), then we can pinpoint specific  X  X redic-tive X  items. Accomplishing this requires three main steps: (1) Analyzing a pair of rules, r A and r B and checking  X  and  X  . (2) Determining if r A is similar to r B , as explained below. (3) Storing the rule pair. To determine whether the two rules are similar, we ensure the following properties: (1) both rules have the same number of items in the antecedent; (2) all items in the antecedent, except one, are the same; (3) the total number of differing items in the antecedent is one, and those two different items come from the same attribute. (4) both rules involve the same attribute on the consequent. We exclude generalizations to two or more different items.

EXAMPLE: Fig. 3 contains several potential rule pairs. Pairs (1) and (2) illustrate cases when both association rules pass all user thresholds. The final three pairs fail for a variety of reasons. Pair (3) and pair (4) are not accepted because at least one of the association rules has a confidence below the threshold of  X  =0 . 7 , while pair (5) differs in two items in the antecedent.
 4.3. Differences between both types of pattern pairs
Even though cube pairs and rule pairs are similar due to our extensions, there exist two major differ-ences between them. First, there is a fundamental difference in the representation of k , depth constraint for cube pairs and itemset length for rule pairs. For instance, when cube depth is set to k , it limits the patterns for cube pairs to a maximum of k dimensions. On the other hand, when the itemset length is set to k , it restricts the length of the frequent itemset, not the size of association rules. However, since the itemsets for antecedent and consequent are both obtained from long itemsets, the sum of their lengths cannot be greater than the length of the long itemset. Therefore, the sum of the number of items in the antecedent and consequent cannot be greater than k . Since each association rule will always have at least one item in the consequent, cube pairs will be able to find longer patterns than rule pairs for the same k .
The second major difference is found in  X  , the minimum  X  X upport X  threshold for cube pairs and the support threshold for rule pairs. For cube pairs, this threshold applies only to dimension combinations, excluding measures. On the other hand, rule pairs applies this threshold on the itemset which is the union of the antecedent and consequent, as defined before. Specifically, X  X  Y will pass the  X  threshold only if there are at least  X n transactions containing both X and Y (i.e. with support  X  ). Thus, for the same  X  on both techniques, we expect cube pairs to find more patterns than rule pairs because the former restricts only to side X of the pattern as opposed to both sides X and Y . 5. Reliability analysis
We start by defining a reliability metric. We then compare the reliability between cube pairs and rule pairs. We first explain cases where both techniques agree. Then we explain cases in which the two techniques disagree. Finally we provide a recommendation guideline to choose one technique as the most reliable. 5.1. Measuring reliability
After carefully studying alternatives, we determined the best way to measure reliability is with the train and validate approach, traditionally used in statistical learning. Specifically, we use a 2-fold cross validation procedure to determine which patterns are found in both the train and validate data sets. The first step is to split the raw data set, X , into two groups: a train data set, X t , and a validate data set, X v . These two data sets are later transformed into F t and F v for cube pairs and T t and T v for rule pairs, respectively. The respective algorithms are then applied to each data set to obtain the list of final pattern the number of pairs found when computing cube pairs on the data set F t .

Once we have obtained the pattern pairs from both sets, we compute a reliability metric by computing the ratio of number of patterns found in both the train and validate sets and the number of patterns found only in the training set. In other words, we compute an intersection and then a division to obtain the percentage of pattern pairs appearing in the validation set (the closer to 1 the better). The equation for computing our reliability metric for cube pairs is shown in Eq. (1).
The equation for rule pairs is analogous to cube pairs (basically exchanging patterns and data set), This is a valuable metric because it is necessary to know if the discovered patterns will actually appear again in a new data set or they are just local patterns. With each validation run, the train and validate sets, then the technique is not robust towards changes in the data set. On the other hand, if the metric shows little variability then we conclude the technique is robust.

The overall goal of our reliability metric is to compare the quality of patterns discovered by both techniques. To obtain an average of this metric, we use a 2-fold cross validation process. The steps are as follows: (1) Partition input data F into two groups: F t ,F v . (2) Compute patterns P on both F t and F v F t and F v , recompute patterns and recompute Eq. (1). (5) The final reliability metric is the average of the two metrics found in both iterations. By using the 2-fold cross validation, we are randomizing the train and validate data sets to avoid any unexpected bias that could lead to wrong conclusions. A larger number k&gt; 2 of groups cannot be used, as in k -fold cross validations, because data subsets become too small (fragmented) for either technique to effectively discover frequent patterns. Under a uniform experimental setup, we will apply 2-fold cross validation on both cube pairs and rule pairs. 5.2. Impact of confidence and p-value on pattern pairs
We will now analyze, in a general manner, the effect that confidence and p-value thresholds have on final results. Let us assume that we are observing two cube groups from F (i.e., populations in statistical terms), as shown in Fig. 4. Suppose data subsets A and B from F are being compared based on the measure value M . Subset A , can be further divided into two peaks, X A 1 and X A 2 while B can also be separated into two peaks, X B 1 and X B 2 . The x-axis represents M , while the y-axis indicates the size of y that the measure value is binned into two sections that are separated at S M . We must emphasize the p-value may be sensitive to noise in the data, especially when the support threshold is low. In terms of rule pairs, we consider A to contain the set of items, I A ,while B contains the item set, I
B . Figure 4 represents two different rules: r A For the remainder of this section, we consider c ( r A ) and s ( r A ) to be the confidence and support of r A and c ( r B ) and s ( r B ) to be the same for r B . Notice that we assume I A and I B differ in one item. As a result, if c ( r A )  X  , s ( r A )  X  , c ( r B )  X  ,and s ( r B )  X  , then we can form the rule pair of [ { I A } X  X  M&lt;S M } ; { I B } X  X  M S M } ] .

For cube pairs, we are able to compute z-test and p-values as follows: As we can observe, the z-test given in Eq. (2), can be computed from  X  and  X  of the populations. Equation (3) shows the integration of the normal distribution curve in order to obtain the p-value [22]. The sum can be truncated at n =4 , giving good precision since this series converges fast, as shown in Eq. (3). 5.3. Propositions comparing r eliability of pattern pairs
We now introduce four complementary propositions for pattern pairs in terms of confidence  X  and p-value indicating in parenthesis if the respective pair is accepted or rejected. We also provide examples obtained from the running example given in Section 3.3 to better illustrate our cases. Notice that we use the same  X  (support threshold) for both techniques to avoid confusion.

For all propositions let A  X  F,B  X  F represent two data subsets behind a cube pair. Let r A and r B be a rule pair, referring to the same (transformed) data subsets, as defined above.
 Propos ition 1
If c ( r A )  X  and c ( r B )  X  (ACCEPT) and p -value  X  (ACCEPT), then both techniques agree and techniques agree and we reject the pattern pair.

Proof sketch : This proposition states that if two techniques agree on whether a pattern pair should be accepted or rejected, then we have a reliable decision. Since both techniques agree, there is no reason to doubt the categorization of that pattern pair. Figure 4 shows a case when both cube pairs and rule pairs agree. In this case, we can see a clear separation between A and B . It is important to notice that knowing the p-value would provide a relative size of separation since smaller values would indicate greater dif-ferences between the two populations. Similarly, Fig. 5 shows a case in which both techniques reject the pattern pair. In this case, we can see that A and B are quite mixed, with no detectable separation. Once again, the p-value would provide a relative scale of s imilarity. For this proposit ion, there is little dif-ference in the reliability of both techniques since they agree. However, p-value does provide additional knowledge of the difference that is lacking for confidence.

EXAMPLE: In the pattern pairs from our example data set, Fig. 3, Pair(1) shows the case when both techniques agree. Thus the pair should be accepted. Propos ition 2 If c ( r A )  X  and c ( r B )  X  (ACCEPT) and p -value &gt; X  (REJECT), then we reject the pattern pair.
Proof sketch: This proposition covers the case when rule pairs accepts the pattern pair because both rules have confidences above  X  , the user-defined confidence threshold, while cube pairs rejects the pat-tern pair because the p-value is greater than the user-threshold. This situation is shown in Fig. 6. Since a majority of the points for each lies on the  X  X orrect X  side of the boundary point, S M , both c ( r A ) and c ( r B ) are above  X  . If we analyze the figure, we can see that A and B are fairly distributed along M , not separated as the confidence would lead us to believe. We see that a majority of the points are close to S
M . In fact, nearly 40% of the data is within 10% of S M . In this case, the p-value appears to be more reliable because it is less susceptible to clustered data.

EXAMPLE: Our example data set contains an example of this case in Fig. 3(2). A valid rule pair has been found, but the p -value is too high.
 Propos ition 3
If both c ( r A ) &lt; X  and c ( r B ) &lt; X  (REJECT) and p -value  X  (ACCEPT), then we accept the pattern pair.

Proof sketch: For this proposition, we consider the case when rule pairs reject a pattern pair based on low confidence in both rules while cube pairs accept the pattern pair based on a low p -value. Figure 7 shows such a scenario of when the p-value disagrees with rule confidence. Once again, we must analyze the probabilistic distribution of the actual data. We can see that a most data points are close to the S M boundary. This means that a minor change of the location of the S M boundary can change the value of the two confidences. It should be clear that A and B are quite separated from each another. The lack of a sense of probabilistic distance in confidence calculations prevents riles from catching this issue. On the other hand, the p-value used in cube pairs does consider the distance and distribution of the populations. Therefore, when both association rules in a pair have low confidences, then we must rely more on p-value.

EXAMPLE: Our example data set contains examples of this scenario as seen in Fig. 3. Pair (3) illus-trates the case when rule pairs rejects a pair due to low confidence, which is set at a threshold of 0.7. However, we can clearly see that cube pairs finds the p-value to be low enough to warrant acceptance. Further analysis revealed that cube pairs was indeed correct in accepting the pair because the distribution of the values placed some points very close to the threshold point of attribute Blockage .
 Propos ition 4
If c ( r A )  X  and c ( r B ) &lt; X  (REJECT) or c ( r A ) &lt; X  and c ( r B )  X  (REJECT) and p -value leq  X  (ACCEPT), then we are unable to determine if the pattern pair should be accepted or rejected.
Proof sketch: In this proposition, we are comparing the case when rule pairs rejects the pattern pair based on one of the rules having a low confidence while cube pairs accepts the pattern pair based on alow p -value. When this occurs, we are unable to determine which technique is more reliable based on available information. Figures 8 and 9 shows two situations where cube pairs fluctuates between accepting the pair and rejecting it. In the first case, we can see that the pattern does appear valid. A and B are quite different from one another. On the other hand, the second figure shows how p-value could be mistaken because even though the pair is marked as valid, the only difference between the two figures is a shifting of the values for A towards B . What we can deduce from these two examples is that p-value is only susceptible when A and B have very different distributions. When this occurs, the Gaussians of A and B have odd intersections. The problem is that with one narrow and one skewed Gaussian, the overlap may not be understood as much as it should be. Thus, we are unable to make a determination on the reliability of the techniques when the rules in a pair have conflicting confidences.

EXAMPLE: Our example data set also includes an example of this proposition. In this case, Fig. 3 contains pair (4), which contains the situation where rule pairs rejects this pair because one of the rules has a confidence, 0.67, below the threshold of 0.7. However, the same pair is seen to contain a very low p-value and it is accepted by cube pairs. In this case, the Gaussians were close to one another, but different, and cube pairs arrived at the correct result. 5.4. Combining cube pairs and rule pairs patterns
Based on the propositions introduced above, we devel oped the following rules to accept or reject patterns. Table 1 shows all possible combinations of both techniques. The first two columns cover low and high confidences of both association rules, while the third column shows the corresponding cube pair result. The last column shows a recommendation whether to accept or reject the pattern pair. In most cases, when the two techniques disagree, cube pairs is considered to be a more reliable technique. The cases when a cube pair is rejected occurs when the confidence of one association rule is high while the other one is low. That is, the pair is  X  X ncomplete X . On the other hand, if the cube pair is accepted, but a rule pair has low and high confidences then this is an indication the confidence threshold must be lowered or increased so that both rules agree. 6. Experiments
We now present an experimental validation with real data sets aiming to understand the quality and quantity of patterns as well as their reliability. Our experiments were performed on a DBMS server running Microsoft SQL Server with a 3.2 GHz CPU, 4 GB of RAM and 1TB of storage space. All our algorithms were programmed in Java and SQL. We begin by presenting the data sets. Then, we analyze reliability and experimentally verify our propositions . Finally, we evaluate algorithmic optimizations and time complexity. 6.1. Data sets
For our experiments, we used three real data sets. The first data set is a financial data set ( n = 3000, p = 8, q = 5) that deals with the costs before and after the opening of a new health center. Of the eight independent attributes, only one was not categorical and thus had to be pre-processed. In this case, the age of the patient was binned at 60. All five of the dependent attributes are numerical and were binned for use with association rules.

We analyzed two data sets from the UCI data set repository. The second data set ( n = 5984, p = 12, q = 3) comes from the UCI repository and contains thyroid disease data. We used twelve of the independent attributes and binned the age attribute at 60. These attributes include medical information, such as whether the patient is pregnant or currently on thyroid medication. Then the three dependent attributes represent measurements found through blood tests. The third data set ( n = 6495, p = 11, q = 2) contains data on various wines. The eleven independent attributes include various amounts of chemicals present in the wine as well as other specific chemical information such as pH and sulfates. All these attributes were numerical and were binned. On the other hand, the two dependent attributes represent the alcohol content and quality of each wine. 6.2. Matching rule pairs and cube pairs
The existing association rules algorithm discovers patterns involving cube dimensions and target at-tributes. By adding our new pairing procedure, we are able to pair two rules together to generate a new unified rule that can specifically point to one dimension as a probable cause of the rule consequent change. We now present interesting rule pairs using constrained association rules.
 We present a summary of all the rules and rule pairs that were found in the financial data set in Table 2. We can see that as the various thresholds increase, the number of rules and rule pairs drastically drop. For the confidence threshold, the drop in the number of rules is not as dramatic as with the support threshold. This is in line with previous work [15].

The overall purpose of cube pairs is to discover specific dimensions that cause a difference in some disease measure attributes. Like other data mining techniques, a more specific goal is to find results that are surprising to the domain expert. Recall there are two main thresholds for cube pairs: the population threshold and the p-value threshold. We must emphasize the p-value may be sensitive to noise in the data, especially when the support threshold is low. Table 3 shows a breakdown of the number of results found with this technique when both the population and the p-value are varied. Notice that the population threshold has the most important influence on the final number of results while the p-value threshold has a much lesser effect. 6.3. Understanding coverage of patterns
For rule pairs, both patterns in the pair must pass all thresholds to be valid. However, it is often the case that one pattern passes all thresholds, while its partner pattern does not. On the other hand, cube pairs internally compare population sets to obtain the same type of patterns. We mainly used p-value and population fraction (i.e. support) as the two thresholds. In the next sections, we will analyze the amount of coverage (overlap) between the two techniques and break down those discovered patterns into groups according to the propositions given in Section 5.2. We c onsider the coverage betw een the patterns found by rule pairs and cube pairs to be the set of results that appears in both techniques. In order for a pattern to be considered covered, both techniques must find the same item (rules) or dimension patterns (cubes) as well as have the same discriminating dimension.

In addition to the number of covered patterns, in order to have a complete analysis, we will also be analyzing the percentage of missed patterns. We calculate the percentage of missed patterns for tech-nique A as a ratio of the number of non-covered patterns found by technique B to the total number of patterns found by technique B. In other words, the missed percentage will allow us to judge how well one technique covers the patterns discovered by the other technique. For example, if technique A has a missed percentage of 60% to technique B, then it means that technique A was unable to find 60% of the patterns discovered by technique B.

Table 4 shows coverage between the two techniques. The first number represents the number of rule pairs results that were found by cube pairs, while the second number represents the number of cube pairs results that were found by rule pairs. For both coverage values, there are two general trends: (1) with a constant confidence threshold, the percent covered decreases as the p-value threshold decreases and (2) with a constant p-value threshold, the percent covered increases as the confidence threshold increases.
We will now analyze the reasons why such high coverage occur. First, we will focus on the patterns that were discovered by rule pairs but were discarded by cube pairs. Results are shown in Fig. 10. As explained above, the only reason for cube pairs to discard a pattern is due to the p-value being higher than the user-defined threshold. In our experiments, we found a total of 16 patterns discovered by rule pairs that were missed by cube pairs. To provide more detail, we have broken down the p-value threshold number of patterns while the last level contains the smallest. In most cases, when the p-value is very high, the confidence will be correspondingly low and would thus the pattern is discarded. Similarly, if a pattern has very low p-value, then the confidence will often be quite high.
 We know analyze the reasons why rule pairs was unable to find the patterns discovered by Cube Statistical Pairs. Let us assume that the confidence threshold is set at 0.5, the support threshold is set at 5%, and the p-value threshold is set at 0.01. Figure 10 shows a breakdown of the reasons why some cube pairs patterns were filtered out by rule pairs. Recall that in order for rule pairs to detect a pattern, both rules that make up the pattern must pass all user-defined thresholds. There are three cases where a pattern will be discarded by this technique: (1) at least one rule has low confidence; (2) at least one of the rules has a low support; (3) the number of dimensions in the pattern exceeds the maximum length of association rules. The first two cases are fairly straightforward and involve rules that do not meet the required thresholds. The third case involves the difference in meaning between rule length and the lattice depth in cube pairs, as described in Section 4.3. From our experiments, we detected 2895 patterns discovered by cube pairs were rejected by rule pairs. We can see that case one comprises a large majority of the reasons, which is precisely what we expected because of the large influence that confidence has on deciding whether a pattern can be filtered. We can further see that when a rule is missed due to confidence, it is twice as likely to have both rules fail as opposed to just one. We also found that for all the cases where support is too low, the confidence is below the threshold. As a result, we categorized those rules as missing the confidence threshold. In fact, nearly 65% of all missed rules has both a support and confidence that was below the user-defined thresholds. 6.4. Comparing reliability cases
We have now seen both similar and different patterns, discovered by the two techniques. In this section, we will separate patterns into the groups defined by the propositions introduced in Section 5.2. Since Proposition 1 is about the trivial case of when both t echniques agree, we will focus on the remaining propositions where there is disagreement.
 Propos ition 2
Proposition 2 stated that when both association rules that comprised a rule pair have confidence  X  , then the p-value is more reliable. In our experiments, we found a total of 603 patterns with confidence  X  for both rules. Of those patterns, cube pairs confirmed 587 patterns while rejecting 16 patterns.
We are mostly interested in understanding the 16 patterns where rule pairs and cube pairs disagree. We now show of these sixteen pattern pairs as follows: [{ AdmissionAfterOpen = 0, DischargeDisposition = 0 }  X  { NetMargin &lt; 0} ; { AdmissionAfterOpen = 0 , DischargeDisposition = 1 }  X  { NetMargin 0}]. This pattern was accepted by rule pairs, but was filtered out by cube pairs. Let us take a closer look at the breakdown of the populations to analyze why these two techniques disagreed. Figure 11 shows both the distribution of Net Margin within both of the population sets as well as the Gaussian from the populations. We can see that the majority of points are located near the middle, which is also where the boundary point lies for rule pairs. We can see from this setup that both association rules will pass the confidence threshold of 50% because each has a majority of data on one side of the boundary. As a result, rule pairs accept this pattern. On the other hand, if we use cube pairs to find the mean and standard deviations of the two population sets, we can see that the two populations are actually quite similar to one another. Thus this pattern is rejected.
 Propos ition 3
Proposition 3 is t he opposite of Proposition 2. It states th at when both rules have confidences &lt; X  ,then p-value is more reliable and should be treated as the final decision maker. For the financial data set, there are a total of 502 patterns in which both rules have confidences &lt; X  . In those, cube pairs confirmed the rejection of 153 patterns while the remaining 349 patterns were accepted. Figure 12 shows a breakdown of one of the 349 patterns in which cube pairs accepted the pattern and rule pairs rejected the pattern. This pattern is identified as: [{ DischargeDisposition = 0}  X  { NetMargin &lt; 0} ; { DischargeDisposition = 1}  X  { NetMargin 0}]. Once again, the majority of the distribution is spread around the boundary point, S M , of a Net Margin of 0. In this case, both association rules obtained confidences below the 50% threshold. However, since so many points are close to S M , we cannot be sure that the populations are similar or not. If we look at the Gaussian breakdown of these two populations, also shown in Fig. 12, we can see that they form two distinctly separate Gaussians. With such separation, cube pairs would accept this pattern.
 Propos ition 4
This proposition covers the remaining rule pairs patte rns, which are the cases when the two rules have disagreeing confidences with regard to  X  . In this case, neither of the two techniques can be considered more reliable. We found a total of 490 patterns of which cube pairs accepted 339 patterns while it rejected 151 patterns.

In this case, there is no clear cut winner between the two techniques. Figures 13 and 14 show two population breakdowns in which we have conflicting results. The two patterns are as follows: [{ OldAge = 0}  X  { TotalCost &lt; 0} ; { OldAge = 1}  X  { TotalCost 0}] and [{ OldAge = 1, InPatient = 0}  X  { TotalCost &lt; 0} ; { OldAge = 1, InPatient = 1}  X  { TotalCost 0}]. In both examples, rule pairs results in two conflicting rules. If we look at the Gaussian distributions of these two cases, then we can observe two different results. For example, Fig. 13 shows the two Gaussian curves for the first example. We can clearly see that there are two distinct  X  X ills X . However, the second example yields a different result, as shown in Fig. 14. Here, we see two different Gaussian, but the amplitudes are widely different. As such, we would accept the first example while rejecting the second. Such conflicting results means that we cannot determine which patterns are more reliable. 6.5. Reliability metric
Tables 5 and 6 show the percentage of validated patterns for both cube pairs and rule pairs on the three data sets at various confidence and p-value levels. These experiments show that in most cases, cube pairs retains more patterns between the train and validate sets. We conducted five separate 2-fold cross validation runs for each of the data sets. Each of the runs also includes different train and validate sets, each of which is randomly extracted from the full data set. We can observe that cube pairs consistently retains as much, if not more, of the training set patterns as rule pairs. This experiment shows that even with varying records within the training and validate sets, cube pairs is still able to maintain a better train-validate ratio. It is also important to note that the percent retained for cube pairs is more stable than for rule pairs. We see that for the two publicly available data sets (Thyroid and Wine), there are times when rule pairs has no pairs validated between the train and validate sets. After further analysis, we found that potential pairs were being discarded mainly due to one of the rules having a confidence that was slightly below the threshold of 0.5. The financial data set is also interesting in the sense that rule pairs actually beats cube pairs for the less restrictive thresholds of confidence at 0.5 and p-value at 0.05. This result appears to be because cube pairs found some erroneous results due to the  X  X oose X  high p-value limit. However, when we raised thresholds to confidence of 0.7 and p-value at 0.01, cube pairs again beats rule pairs by a wide margin. We would like to emphasize that these stringent thresholds are more commonly used than the looser thresholds. 6.6. Algorithmic optimizations and time complexity
We now analyze the impact of our algorithmic optimizations on running time. There were three main performance optimizations. For cube pairs, the main optimization was exploiting attribute grouping (simply called group) constraints, which will reduce both the number of results and running time. On the other hand, there were two optimizations for rule pairs: filtering and strategic numbering of the items.
For cube pairs, three constraints were embedded into the algorithm: item filtering, antecedent/ consequent (AC), and item grouping. Because the first two constraints were already embedded within the original OLAP cube test algorithm, we looked at the effect of the group constraint on performance time as shown in Table 7. The number of items grouped means that those items cannot appear in the same combination set. We can see that there is drastic improvement as we group more items together. This is expected because the more grouped items, the more nodes that can be excluded from the dimensions lattice.

For the filtering optimization, we observed that while filtering only marginally improves performance at high confidence thresholds (due to smaller number of rules), the algorithm becomes significantly faster as we decrease the confidence threshold. In fact, at high confidence thresholds, such as 0.7, this optimization improves performance by only 5%, but at a confidence threshold of 0.5, the improvement increases to 25%. These results confirm we are able to filter out many more rules.

For time complexity analysis, we varied k , the cube lattice depth constraint, to show how much restrict-ing the length of the pattern pairs impacts the final performance as shown in Fig. 15. Our experiments prove that the cube pairs algorithm has better performance than rule pairs. As k increases, cube pairs exhibits an almost linear increase while rule pairs exponentially increases with each k .Thesloweststep for cube pairs, taking over 35% of the execution time, is the actual grouping of the dimensions for the dimensional lattice. For rule pairs, the slowest step, taking nearly 70% of the execution time, was rule pair generation. 7. Conclusions
In this paper, we extended cubes and association rules to produce pattern pairs. On one hand, we used parametric statistical tests on cubes to compare highly similar cubes, to isolate one dimension triggering a significant change in some cube measure. On the other hand, we paired highly similar association rules differing on one item in the antecedent implying opposite ranges on an attribute binned into two inter-vals. We carefully compared their respective predictive metrics: p-value and confidence. We introduced four propositions to decide acceptance or rejection of pattern pairs based on when techniques agree or disagree. Also, we introduced a reliability metric based on two-fold cross validation, allowing a neutral and objective comparison. Basically, this metric compares the percentage of patterns discovered on the training data set that remain true on the validation data set. We introduced algorithmic optimizations to reduce the number of patterns and running time as well as to produce comparable sets of pattern pairs. We altered the cube algorithm with search constraints to reduce the number of patterns returned. On the other hand, we added a post-processing matching step to constrained association rules to ob-tain specific rule pairs. We then experimentally studied the reliability of the pattern pairs discovered by both techniques with our new reliability metric. We discovered that for almost all p-value and confidence threshold levels and data sets, cube pairs produced a higher number of patterns than rule pairs that passed thresholds on the validation set. We conclude that, based on our metric, cube pairs are more reliable than rule pairs.

Generalizing patterns into pairs introduces important research issues. We want to derive a single met-ric that summarizes support and confidence for a rule pair. We would like to understand how to isolate two predictive attributes, instead of one, giving them different weight depending on their impact on the predicted attribute. We want to understand if other different statistical tests can be combined with cubes. It is important to identify which search constraints work well with both kinds of patterns. Our proposed reliability metric based on cross-validation d eserves further study, considering tradeoffs be-tween p-value and confidence. Even though both cubes and association rules work in discrete space it is necessary to compare their predictive attribute identification with traditional variable selection from statistical learning models like regression or Bayesian classification.
 Acknowledgment This research work was partially supported by National Science Foundation grant IIS 0914861. References
