 Classical query expansion techniques such as the local context analysis (LCA) make use of term co-occurrence statistics to incorporate additional contextual terms for enhancing passage retrieval. However, relevant contextual terms do not always co-occur frequently with the query terms and vice versa. Hence the use of such methods often brings in noise, which leads to reduced precision. Previous studies have demonstrated the importance of relationship analysis for natural language queries in passage retrieval. However, they found that without query expansion, the performance is not satisfactory for short queries. In this paper, we present two novel query expansion techniques that make use of dependency relation analysis to extract contextual terms and relations from external corpuses. The techniques are used to enhance the performance of density based and relation based passage retrieval frameworks re spectively. We compare the performance of the resulting system s with LCA in a density based passage retrieval system (DBS) and a relation based system without any query expansion (RBS) using the factoid questions from the TREC-12 QA task. The re sults show that in terms of MRR scores, our relation based term expansion method with DBS outperforms the LCA by 9.81%, while our relation expansion method outperforms RBS by 17.49%. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval -Retrieval Models; I.2.7 [ Artificial Intelligence ]: Natural Language Processing; I.7.1 [ Document and Text Processing ] Algorithms, Measurement, Experimentation Query Expansion, Dependency Parsing, Passage Retrieval Query expansion is a widely researched topic in the field of information retrieval [1, 2, 10, 20]. It is a method for improving the effectiveness of information retrieval through the on the factoid questions 1 of TREC-12 QA task demonstrate that our approach is effective. The main contribution of this paper is in employing a relation based model to performing: (a) contextual term selection to enhance density based passage retrieval, and (b) relation extraction to enhance the fuzzy dependency relation matching approach. Also, in order to make the expansion process more robust, it extracts relations and terms from external corpus instead of relying only on the results obtained from a local corpus. This paper is organized as follows. In the next Section, we review related work on various query expansion techniques. Section 3 provides the details of our relation based query expansion technique. Section 4 presents our experimental results and analysis. Section 5 concludes the paper with directions for future work. Statistical based query expansion is one of the earliest and classical methods of introducing additional context into a question [20]. It does not involve any form of language analysis and there are three main types, namely, local analysis [4], local context analysis [19] and global document analysis [5, 10]. In local analysis [4], the most frequent non-stop words among the top ranked passages are counted and added to the original query. This method is highly dependent on the quality of the passages retrieved in the initial retrieval. In cases where the top ranked passages retrieved have little relevance to the question, this method will not work well and it may even introduce irrelevant terms into the question and degrade the performance. Instead of simply counting the most frequent words, local context analysis [20] counts terms in the top ranked passages that co-occur most frequently with the query terms. This method may appear to be better than local analysis as it introduces a further constraint that the expanded terms must co-occur frequently with the query terms. However, not all relevant terms for query expansion co-occur frequently with the original query terms, and that unrelated terms may co-occur very frequently with the query terms as well. Global document analysis [5, 10] counts the most frequent terms appearing in the top ranked documents and adds them to the query. However, this approach can be expensive in terms of computation time as term searching at the document level can be inefficient. Another more serious disadvantage is that there could be more noise among the terms introduced because the analysis is done at the document level. Within a document, a word may occur very frequently in the first paragraph, while the query term may occur only in the last paragraph. Hence, there may be a lack of proper relationship between a query term and the expanded term, which may turn out to be noise instead. A common problem with these query expansion methods is that the relationships between the original query terms and the expanded query terms are not considered. Recent studies by Katz and Lin [11] have shown that these relationships between terms are very crucial to the performance of a passage retrieval system. Therefore a good query expansion technique should make use of the relation information to provide additional contextual training phase and the query expansion phase. During the training phase, we use the training QA pairs to derive the weights of relations between query terms and expansion terms. The relation weights are stored in the relation score table. The query expansion phase implements two separate query expansion methods DRQET and DRQER. Both methods make use of the trained relation score table to measure the relevance of the expanded terms and relation paths from Web resources. There are two sources of information corpus from which query expansion may be carried out. They are: (a) the original corpus from which information is to be found, and (b) the parallel corpus from which relevant contextual information may be mined. Original corpus is the most obvious collection and is used by most query expansion techniques based on relevance feedback [2,6,20]. Parallel corpus, which means another corpus of the same time or topic domain, is another choice and it is often adopted by news video retrieval system using ASR (Automatic Speech Recognition). With the wide spread adoption of World Wide Web, web based query expansion is adopted by most IR and Question-Answering (QA) [3] systems. There are two major reasons for using the web as a parallel corpus for IR and open domain QA: (1) the content of the web is more complete than any other existing corpus, and (2) the content of the web is dynamic and constantly being updated. In our experiment, we use Google snippets as the basis for query expansion. We first send the queries to Google and collect the top k snippets. We adopt an approach similar to that of the local context analysis (LCA) method. In the LCA method presented in [20], top 200 passages are found to be the ideal size for query expansion. Since we are performing sentence based matching, each sentence is considered to be a passage while each snippet on average contains two complete sentences 2 . Therefore there are on average 2k passages contained in the top k snippets, and thus we set k to 100 in our experiment. There are two reasons for using snippets rather than complete html pages for passage retrieval systems. First, complete html pages can be very long and about multiple topics, it X  X  often the case that a term at the beginning and a term at the end of a long document do not have any dependency relations. Second, it is more efficient to use snippets because we can eliminate the cost of processing the unnecessary parts of the html pages. After we have collected the snippets, we use a sentence splitter to split the sentences within these snippets. We then parse the snippets using Minipar [14], a dependency grammar parser. We resulting set of passages (or sentences) derived from S as P:={p 1 ,p 2 ...p n } with the expected value of n to be around 200. We denote the set of parse trees of passages in P as T:={t 1 ,t 2 ...t n }. Figure 2 illustrates an example of dependency parsing. It shows the parse tree of a sample question (Q: When is Alaska purchased?) in Figure 2(a) and the pa rse tree of a sample answer snippet (s i : Alaska was purchased from Russia in 1876) retrieved local importance. After extracting the relation paths from web snippets, we have n dependency parsing trees in T which corresponds to n passages in P (see Section 3.1). The global importance is measured by the inverse document frequency (idf) of the expanded term, while the local importance of an expanded term is measured by its relat ion path linking to the query term. The overall importance of the relation path is a function of the importance of each individual relation, which is obtained through training. The assumption is that certain paths are more likely to infer a relevant expanded terms than other paths and these useful relation paths are obtained by training. The non-stop terms denoted as T k in the snippet set S are ranked according to the formula: where
T k is the term to be ranked; p j is the j th passage in the passage set P ; path(T k ,t,j) is the relation path in the dependency parsing tree of p j with start node T k and ending node t ; path_score (T k ,t,j) is the score of path(T k ,t,j) ; N is the number of passages in the snippet set S ; N Tk is the number of passages in P that contains term T k ;
N ti is the number of passages in P that contains term t i ; score(Rel i ) is the score of individual relation which is obtained through training, and  X  is set to 0.1 to avoid zero values. The above formula is a variant of the term ranking formula in local context analysis [20]. In our modified model, the global importance is still modeled in the same way as the LCA method. However, we use the importance of relation path to model the local importance instead of term co-occurrence. We treat a relation path, Path &lt;Start_Node, Rel 1 ... Rel k ...Rel m, End_Node&gt;, as a sequence of independent relation labels. We only consider the paths where the End_Node is a query term, and the Start_Node is the term that we want to rank. Therefore by considering only the relation labels in the path, we can treat the sequence just in the same way as a word sequence and apply language model on the relation sequence, where the vocabulary of the relational language model is all the 42 possible relation labels. Thus the score of a path is proportional to the probability by which a  X  X seful X  expansion term is inferred; and this probability is calculated using the formula  X  score(Rel i ) under the assumption that each relation in the sequence is independent of eath other. Finally, we formulate our new query Q X  t by adding the top k terms original query terms to be 1.0 and the weight of i th expanded token to be (1-0.9*i/k). The new query Q X  t is a bag of terms, that can be written as &lt;(word 1 ,weight 1 ),...(word i ,weight i )&gt;. We then issue the new query to any density based method (DBM) for passage retrieval to rank the set of passages. probability, i.e., relation mapping scores, which are given by a translation model learned during training, as described in [8]. As explained in the previous Section, the relevance of the expanded term T k is inferred by its relation paths linking it to the query terms. To avoid the data sparseness problem in training, we assume that each relation appears independently of the other relations in the same path. Hence, we have: Therefore for each type of relation in the dependency parsing tree, we need to estimate score(Rel i ) from the training corpus. To perform training, we use the TREC 8 and TREC 9 QA question-answer pairs as the training set. We denote each QA pair as ( Q i , A i ). We retrieve the top 100 snippets from Google for each question, perform sentence splitting and dependency parsing, and select the  X  X elevant X  paths from the set of parsing trees of the snippets. A path p in the snippets corresponding to Q i (denoted as paths are those inferring a useful term to the question. After collecting all the relevant paths, we employ a unigram language model [15] to train the weight of individual relations. Relation labels are treated as vocabularies in a language model. Therefore, the score of individual relation should be proportional to the probability of such a relation appearing in the training data set as shown in Equation (5). We use the smoothed probability to avoid zero values and take the log of frequency count to reduce the variance of the score. The eventual formula used to calculate the final score is given in Equation (6). and N is the total number of relation types. In this Section, we present the em pirical results to evaluate our query expansion techniques for passage retrieval. Our evaluations aim to verify three hypotheses as follows: (1) It is effective to incorporate dependency relation based query expansion technique to select high quality terms in a density based passage ranking framework. (2) The use of dependency relation based query expansion technique to extract relation paths further improves the precision of passage ranking when integrated with fuzzy relation matching technique. (3) As short queries with fewer key terms are more likely to have word mismatch problems when performing passage retrieval, the short queries will benefit more from dependency based query expansion. We employ three performance metrics: mean reciprocal rank (MRR), percentage of questions that have no correct answers and precision at the top one passage. The first two metrics are calculated based on the top 20 returned passages by each system. In the first experiment, we evaluate the overall performance of our query expansion techniques when integrated into different passage retrieval systems based on the 324 factoid questions selected from TREC-12. We apply LCA, DRQET on DBS and DRQER on RBS and list the evaluation results in Table 1. Fr om the Table, we draw the following observations: (1) By comparing the MRR scores between DBS and DBS+LCA, we observe a 23% improvement with the use of a term co-occurrence based query expansion technique. This confirms that query expansion can indeed improve the performance of passage retrieval. (2) We observe an additional 9.81% improvement in MRR when comparing the performance DBS+LCA and DBS+DRQET. This shows that dependency relation based term expansion (DRQET) significantly outperforms the local context method under a density based passage retrieval framework. (3) Under the relation based framework for passage retrieval, dependency relation based path expansion can further bring about a 17.49% improvement in MRR over fuzzy matching (RBS) of relation matching without any query expansion. This improvement is significant as RBS is already attaining a high performance of 0.4761 in MRR score. The use of relation path query expansion (DRQER) under RBS can further improve the MRR score to over 0.554, which is significantly better than the best reported results in [8] for RBS without query expansion. The reason why query expansion is more useful for short queries is that query expansion is employed to overcome the problems of the lack of context and word mismatch in passage retrieval. The severity of the problem tends to decrease as queries get longer, as there is more chance of some important words co-occurring in the query and relevant documents. So query expansion may be less effective in cases of longer queries with over six non-trivial terms. In this Section we aim to conduct a more comprehensive test on short queries comprising three or less non-trivial question terms to simulate web queries. For th is, we set up a query set D2, which comprises 356 short queries obtained from the factoid questions in TREC-11 [18] and TREC-12 QA task [16] after filtering out questions with more than three non-trivial terms. We use the same five comparison systems as described in Section 4.2 and present the result in Table 2. From Table 2, we can see that the improvement is even more significant on short queries. We observe a 16.7% of improvement in MRR by comparing DBS+DRQET with DBS+LCA. This indicates that even without considering language constructs in the question, relation based query expansion can still perform better than co-occurrence based query expansion. This result may have implications to Web queries which tend to be short and are not in natural language format. Therefore, future query expansion algorithms should incorporate some form of relation analysis rather than simply counting the co-occurrence between expansion terms and query terms. Interestingly, for short queries we find that relation matching without query expansion (RBS) performs worse than a density based passage ranking with dependency based query expansion (DBS+DRQET). This shows that query expansion is crucial for short queries as it is hard to extract word dependency information from the original query for RBS. With the use of relation path expansion, RBS+DRQER again performs the best among all the five systems for both short queries and long queries. This is because RBS+DRQER expands the query terms first and then resolve the dependency relations between query terms and the expansion terms. This result indicates that incorporating dependency relation analysis into both query expansion and passage ranking will boost the performance of passage retrieval. Analysis of results in term s  X % Incorrect X  and  X  X recision at top one passage X  shows similar trends as the MRR scores. In this Section, we will use two examples to illustrate the advantage of incorporating dependency relation analysis into query expansion. In the first example, we will illustrate that relation based term expansion is more effective than co-occurrence based term expansion. In the second example, we will show that relation path exp ansion is often necessary than merely performing term expansion. Example 1: Question:  X  X hat did George Washington call his house? X  Figure 3 shows the top 10 expanded terms by LCA (3(a)) and DRQET (3(b)). We observe from Figure 3 that the expanded terms provided by LCA are related to either the concepts  X  X eorge Washington X  or  X  X ouse X . However, very few The second technique extracts relation paths for query expansion in a relation based passage retrieval framework [8]. Evaluation results showed that our first technique used in conjunction with the density based frameworks produces a significant improvement of 9.81% in retrieval performance as compared to LCA. Also, our second technique used in conjunction with the relation based frameworks produced a 17.49% improvement over a corresponding relation based passage retrieval system without query expansion. In this paper, we also studied the relationship between query lengths and improvements by query expansion. Our experiment showed that short queries tend to benefit more from query expansion. To ascertain this, we conducted another experiment particularly for short queries. The result showed even more significant improvement: a 16.70% improvement over a density based passage retrieval algorithm with our first technique, and a 28.94% improvement over a passage retrieval system using dependency relation matching with our second technique. In the second experiment, we also observed the drawback of fuzzy dependency matching on short queries, which have very few relations between terms. Therefore we believed that additional contextual relations should be introduced in order to achieve better recall of matching. The experimental result showed that our second technique that expands queries in relation based frameworks (RBS+DRQER) again performs the best among all the five comparison systems. In the future, we will continu e our research work on relation based models for information retrieval. In particular, we will continue our research in the following directions: (1) explore the use of different models and their combinations for relation based query expansion for passage retrieval; and (2) conduct detailed analysis on the performance of dependency relation based query expansion on different types of queries. [1] G. Amati, C. Carpineto, G. Romano, Query Difficulty, [2] R. Attar, A. S. Fraenkel, (1977). Local Feedback in Full-Text [3] E. Brill, J. Lin, M. Banko, Susan T. Dumais, A. Ng: Data-[4] C. Buckley, A. Singhal, M. Mitra, G. Salton, New Retrieval [5] J. Callan, W. B. Croft, J. Broglio, TREC and TIPSTER [6] W. B. Croft, D. J. Harper, (1979). Using probabilistic 
