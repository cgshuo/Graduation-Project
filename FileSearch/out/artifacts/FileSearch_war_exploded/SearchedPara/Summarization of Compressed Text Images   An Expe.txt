 Automatic summarization of JBIG 2 coded textual images is discussed. Compressed images are partially decompressed to compute relevant features. The feature extraction method is free from using any character recognition module. Summary sentences are ranked. Experiment considers documents in Indic scripts that lack in having any efficient OCR sy stems. Script independent aspect of the approach is highlighted through use of two most popular Indic scripts. Sentence selection e fficiency of about 61% is achieved when judged against man-made summarization. A nonparametric (distribution-free) rank statistic shows a correlation coefficient of 0.33 as a measure of the (minimum ) strength of the associations between sentence ranking by machine and human. H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing  X  abstracting methods ; I.2.7 [ Artificial Intelligence ]: Natural Language Processing  X  text analysis ; I.7.m [ Document and Text Processing ]: Miscellaneous.
 General Terms: Algorithms, Design, a nd Experimentation. Keywords: Compression domain retrie val, Summarization, Textual images, JBIG2, Indic Script, Performance Evaluation. Automatic text summarization has of ten been viewed as important for information retrieval (IR) [1]. Though research in text retrieval has so far involved mostly machine-readable text, recently, IR from imaged text [2] has gained attenti on too. Design of a retrieval engine working in compressed domain [3] has also been proposed. However, summarization of docum ent images has not been well studied. The only work by Chen and Bloomberg [4] first addressed this problem for uncompressed im ages. This paper extends this research for JBIG2 [5] compressed text images. The present study considers document images in Indic scripts that are good examples of scripts for which efficient OCR systems are still not available. So conversion of Indic script documents into coded form still lacks in convenience. Therefore, storing the paper documents as scanned (compre ssed) images and designing of summarization, retrieval, etc.) is viewed as a viable alternative for providing digital access to Indian language documents. A compressed image [6] contains three streams: Header Stream (HS), Prototype Stream (PS) and Lo cation Stream (LS). HS contains information like image height, widt h, length (in bytes) of the PS, etc. and remains uncompressed to provide independent access to other streams. The PS part contai ns binary data representing the library symbols. The LS sec tion is a list of triplets ( X &lt; X , Y i &gt; pair represents position of a symbol ( S the j -th library symbol with which S i had been matched. For summarization purpose, the PS component, which is only 1%-3% of the entire image size, is decoded first and then the LS part. Experimentally, it is checked that this decompression takes less than 10% of the space that would have been required if a compressed file were fully decompressed. Physical and Logical Layout Analysis : Documents (newspaper articles have been considered) follow a particular layout: (a) header: contains 3 lines for date stamp, report title, and then reporter X  X  name and place of reporting. Body of the report contains one or more paragraphs. Fig. 1(a) shows a porti on of a typical sample document. Identification of the report title of the report is trivial as the second line from the top always represents the title. Similarly, identification of appropriate punctuation ma rk detects sentence boundaries. However, detection of paragra ph boundaries requires some extra computation [7]. First and last sentences of each paragraph are also marked at this stage. Word Clustering and Stemming : Words are represented by a sequence of their constituent prototypes (see Fig. 1(b)). Two sequences of two same words may vary because of the JBIG2 X  X  symbolic compression method. Also, two same-root words because of inflections and derivational mo rphology may vary in number of constituent prototypes. Word images are grouped into equivalent classes by following a classical unsupervised (complete linkage) 
Figure 1. (a) A sample document , (b) Prototype representation of three exam p le words ( ID of each p rotot yp e is g iven ) . clustering algorithm. The dist ance measure used for finding dissimilarity between two word im ages can be found in [8]. Word images in a cluster produce a (inexact) root word. Next, stop words considered to be content words. A small number of frequent content words are labeled as thematic words. Features for Sentence Selection : The features used in this experimentation are (i) F 1 : Sentence length  X  measured in terms of number of words and normalized (for the longest sentence it is 1.0), (ii) F 2 : Sentence position in a paragraph  X  a binary feature is used to indicate whether a sentence begins (or ends) a paragraph, (iii) F Thematic features  X  For each sentence thematic feature is computed from its content words. The sent ence is assigned a score based on the number of occurrences of each content word in it. (iv) F words  X  a sentence gets extra importance as a summary sentence, if one or more title words ( content words only) occur in it. An rank in the summary. Summary sentences are ranked (by a human). The feature F r of a sentence with rank i (  X  0) is assigned as 1/ i and for other ( N -K , N and K be the number of total and summary sentences) sentences F r is set to 0. Selection of Summary Sentences : A multi-layer perceptrons (MLP) is used for selection of summary sentences. Back propagation algorithm is used to train the MLP classifier. The trained network is then used to obt ain ranking of sentences in a test documents. For each sentence output node provides a score. Sentences are then sorted in descending order of their scores and sentences with top K scores are chosen as summary sentences. One hundred single page documents (newspaper articles) of Devanagari (Hindi) and Bengali sc ripts (50 for each script) are considered. Documents follow a fixed header format as shown in Fig. 1(a). Body parts of the reports vary in number of paragraphs as well as sentences. Average body length is about 40 sentences. A human summarizer summarizes each document by selecting 20% sentences (on average an 8-sentence summary) and ranks each sentence from 1 to K (1 being the most important). Document database is divided into five sets to realize a 5-fold cross validation technique. Documents in four sets ar e used in training and testing is conducted on the fifth set. Quantitative Evaluation : The performance of the summarizer is evaluated by directly matching m achine-generated sentences with those selected by the human. For a test document i , let v number matches. Then, an average efficiency (  X  ) of the machine is measured as, ) * /( 100 * ) ( number of test documents. Fig. 2 shows  X  values for 20 documents of a test run. An average  X  =63.8% is obtained for this test set. Similarly,  X  is computed for other four test runs and an overall average about 60.6% is obtained. Rank correlation : Let } ,..., , { 2 1 K 1 to K ) generated by human and machin e, respectively for the same test document. Each sentence, m i  X  M is checked in H and a penalty ( p ) is assigned: A correlation coefficient () ] * / ) [( 1 measured. The coefficient, r is computed for each test document. documents. Also, Fig. 2 compares r vs.  X  for the same set of documents. A correlation ( r ) of 0.33 [averaged over all five runs] is attained in the present experiment. A general framework for auto matic summarization of JBIG2 compressed text images is presented. Since the approach and the features are script independent, a similar method can directly be applied for summarization of JB IG2 coded documents in other scripts. Moreover, the method w ith little modification would work for summarization of uncompressed images too. The approach is especially useful for retrieving documents printed in scripts for which efficient OCR systems are not available. In addition, the technique functioning in the compressed domain is especially decompression of images may not be possible because of limited amount of memory space. [1] Wasson, M. 2002. Using Summaries in Document Retrieval. In [2] Doermann, D. 1998. The retrieval of document images: A [3] Lu, Y. and Tan, C.L. 2003. Document Retrieval from [4] Chen, F.R. and Bloomberg, D.S., 1998. Summarization of [5] ITU-T Recommendation T.88, 2000. Bilevel Image coding. [6] Garain, U. Mandal, A. Debnath , S. and Chaudhuri, B.B. 2003. [7] Garain, U. Datta, A.K. Bhattach arya, U. and Parui, S.K. 2006. [8] Majumder, P., Mitra, M., Parui, S. K., Kole, G., Mitra, P., and 
Figure 2. Summary generation: efficiency of machine and rank correlation between machine and human. 
