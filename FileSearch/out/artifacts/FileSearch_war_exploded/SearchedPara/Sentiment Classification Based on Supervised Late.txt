 In this paper, we propose an ef fi cient embedding for modeling higher-order ( n -gram) phrases that projects the n -grams to low-dimensional latent semantic space, where a classi fi cation function can be de-fi ned. We utilize a deep neural network to build a uni fi ed discrim-inative framework that allows for estimating the parameters of the latent space as well as the classi fi cation function with a bias for the target classi fi cation task at hand. We apply the framework to large-scale sentimental classi fi cation task. We present comparative evaluation of the proposed method on two (large) benchmark data sets for online product reviews. The proposed method achieves su-perior performance in comparison to the state of the art. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Information fi ltering ; I.2.7 [ Arti fi cial Intelligence ]: Natural Language Processing X  Text analysis Algorithms, Experimentation sentiment analysis, supervised embedding, deep learning
Sentiment analysis (SA) or polarity mining refers to identifying and extracting subjective information from natural language text. The problem of automatic sentiment analysis has received signi fi -cant attention in recent years, largely due to the explosion of online social-oriented content (e.g., user reviews, blogs, etc). As one of its main applications, sentiment classi fi cation targets to rate the polar-ity of a given text accurately towards a label or a score, predicting whether the expressed opinion in the text is positive, negative, or neutral.

In this paper, we will explore the use of high order n -grams for classifying the sentiment orientation of a given text at article level. The motivation is that longer phrases tend to be less ambiguous in terms of their polarity. The authors in [10] pointed out that a discriminating classi fi er combined with high order n -grams as fea-tures can achieve comparable, or better SA performance than state of the art on large-scale data sets. Indeed, e.g., while term  X  X ood X  is likely a positive sentiment,  X  X ot good X  or  X  X ot very good X  are less likely to appear in positive comments. Needless to say, mod-els such as bag-of-unigrams or bag-of-bigrams will possibly fail to deal with  X  X ot good X  and  X  X ot very good X , respectively. The other facet of SA is the degree of positivity or negativity of long phrases. As one such example, consider the compounding effect of the phrase  X ... terrible terrible terrible ... X  in contrast to three dispersed  X  X errible X  in a text. The use of n -gram features can pro-vide a remedy for such scenarios [10]. Unfortunately, this comes at a very high computational cost associated with modeling n -grams for n  X  3 . This is due to the extremely large parameter space asso-ciated to n -grams. For instance, assuming English word dictionary D of size |D| , then bigram representation of text relates to free parameters, while trigram relates to |D| 3 free parameters. This will become intimidating even for a dictionary of moderate size. When the number of training samples is limited, it can easily lead to over fi tting. If unigram dictionary has the size |D| =10 , 000 , we have |D| 2 =10 8 free parameters or |D| 3 =10 12 that need to be estimated, which is far too many for a small corpora. As more and more web-scale sentimental data sets become available, large corpora with sentimental labels could easily be accessible for researchers. The availability of large datasets also encourages us to explore n -grams. To the best of our knowledge, there are only a few experimental evaluations involving large-scale data sets [12, 8].

This paper partly motivated our idea and we believe that poten-tially, using higher order n -grams is bene fi cial in capturing senti-ments in the text. For example, term good commonly appears in positive reviews, but  X  X ot good X  or  X  X ot very good X  are less likely to happen in positive comments. If using bag-of-unigram,  X  X ot X  is separated from  X  X ood X , which does not have the ability to describe the  X  X ot good X  combination. Similarly using just bag-of-bigrams, the model can not represent the short pattern  X  X ot very good X  ei-ther. Another example is: if a product review uses the phrase  X  X er-rible Terrible Terrible X , it contains more negative opinion than three  X  X errible X  separately occur in the text. Building n -gram features is a method to remedy this issue [10], but it is computationally very dif fi cult to model n -grams (for n&gt; =3 ) raw features directly.
We utilize a multi-level embedding strategy to project n -grams into a low-dimensional latent semantic space where the projection parameters are trained in a supervised fashion together with the sentiment classi fi cation task.

In this paper, we present a novel approach for using high-order n -grams for sentimental classi fi cation problem. We will also devise a new embedding mechanism of n -grams, called  X  X atent n -grams X , that will enable us to deal with the curse of dimensionality. Next, the proposed embedding of n -grams to low-dimensional latent se-mantic space will be tied to a classi fi er, trained for sentiment anal-ysis tasks. Using a deep neural network allows one to learn the parameters for the latent space and the classi fi er jointly in one uni-fi ed discriminative framework. It is worth noting that performing dimensionality reduction in the original feature space is a common practice for various classi fi cation methods. However, as we dis-cuss in Section 3, methods that bias parameters of the embedding towards speci fi c classi fi cation task has not received much attention until recently. The proposed multi-layer embedding and classi fi ca-tion model provides two major advantages. First, the latent model greatly reduces the dimensionality and computational ef fi ciency in comparison to raw n -gram features. Moreover, the parameters of latent space are learned using supervised signals arising from the sentiment classi fi cation. Two clear advantages to use the proposed method involves that (1), the system utilizes an embedding space to greatly reduce the dimensionality of n -gram, and is thus much easier to model than n -grams raw features. (2), The n -gram embed-dings are learned using supervised signals with the main sentiment classi fi cation task which means they are optimized for the task and require little human labors in feature engineering.

We evaluate the performance of the proposed method along with several state of art baselines using two typical tasks relevant for SA: (1) binary classi fi cation, predicting binary (positive or nega-tive) sentiment of the text; and (2) multi-score sentiment classi fi -cation, predicting a range of scores on Likert-scale (e.g. 1-5 stars) that re fl ect both polarity and strength of the sentiment in the text. The presented empirical evidence demonstrate the superior perfor-mance of the proposed system on two major publically available benchmark datasets: Amazon 1 and TripAdvisor 2 .

The rest of this paper is organized as follows. Section 2 describe our method in details. Section 3 provides an overview of related work. In Section 4 we present the experimental results, and con-clude the paper in Section 5.
Sentiment classi fi cation can be stated as the general task of clas-sifying an input text-sequence into certain types or as rating the in-put text with a certain score. Feature extraction and feature-based representation are critical to the effectiveness of sequence analysis, since text sequences cannot be readily described as feature vectors. Traditional text categorization methods use feature vectors indexed by all possible words (e.g., the so-called  X  X ag-of-words X ) of a given dictionary to represent text documents. The bag-of-words strategy treats articles as an unordered set of features (words), for which the critical word ordering information is not preserved.
To take word ordering into account, text articles can be consid-ered as bags of short sequences of words with feature vectors cor-responding to all possible word n -grams ( n adjacent words from vocabulary D ). In the sequel, we will refer to this as  X  X ag-of-ngram X  (BON). [20, 10] showed that introducing 2-grams into the bag representation signi fi cantly improves the performance of sen-timent classi fi cation. However, adding higher order n -grams, for n  X  3 , into BON model can be prohibitively expensive, since the dimensionality of a BON vector grows exponentially as a function of n .

There are two possible approaches to remedy the curse of dimen-sionality associated with n -gram representation. First is the feature selection approach. To this ends, pre-selected n -gram patterns or short phrases (e.g. with certain semantic meaning) will be utilized for modeling the sequences. Another possible approach is the use of the dimensionality reduction to approximate the original space  X  e.g., latent semantic indexing (LSI), an embedding based on term-document matrix.

In this paper, we will use a supervised embedding strategy. We represent a document using its n -gram embedding, which in turn is built upon its word embedding. The step utilizes the supervised sig-nal and acts as feature learning for sentiment classi fi cation. Next, the document representation is fed into a perceptron classi fi er to learn a function mapping toward sentiment labels. The embed-ding feature learning and the sentiment classi fi cation are trained jointly in an end-to-end fashion, which can be illustrated using a multi-layer perceptron (MLP) network structure, as illustrated in Figure 1.
Formally, the basic bag-of-word representation for text applies a mapping  X  (  X  ) to strings of variable length into a feature space of fi xed dimension. It is in this space that a standard classi fi er such as linear perceptron or support vector machine can be applied. Let denote the underlying dictionary and S denote the set of all fi nite length sequences of words from D .Weuse | . | to denote the cardi-nality of a set. We will also assume the aforementioned mapping  X  : S X  R M maps words sequences in S to fi nite dimension fea-ture space. The sentiment labels will form a set Y = { 1 , ..., K e.g., K =2 denotes sentiment classes such as  X  X ositive X  or  X  X ega-tive X . We will also denote a labeled training-set with training labels quence of length N will be denoted as x =( w 1 ,...,w N ) ,where w j  X  X  .Let  X  denote the vocabulary of n -grams in the corpus, and  X  j =( w j ,w j +1 ,...,w j + n  X  1 ) ,where j indicates the j -th po-sition in x . Given the bag-of-unigram representation,  X  ( x ) maps the input x in a natural way as a (sparse) vector of dimensional-ity M = |D| . Similarly, In a bags-of-ngrams  X  ( x ) maps x to a M = |  X  | -dimensional representation, with |  X  | = O ( |D| n
Motivated by the fact that individual words carry signi fi cant se-mantic information, we learn a mapping of each word into a real-valued vector space, referred to as an  X  X mbedding X . Speci fi cally, each word w j  X  X  is embedded into an m -dimensional feature space using a lookup table LT E (  X  ) de fi ned as where E  X  R m  X |D| is a matrix with word embedding parameters to be learn. Here, E w j  X  R m is the embedding of the word w in the dictionary D and m denotes the target word embedding di-mensionality. It is important to note that the parameters of E are automatically trained during the learning process using backprop-agation.

In our framework, formation of n -grams will be carried through a sliding window of length n . As illustrated in Figure 1, setting n =3 ,the fi rst n -gram is ( w 1 ,w 2 ,w 3 ) , second n -gram will be ( w 2 ,w 3 ,w 4 ) , etc. Given an n -gram of adjacent words, we repre-sent its embedding based on the embedding of individual words it contains. Speci fi cally, given  X  j =( w j ,w j +1 ,...,w catenating embeddings of words in the n -gram  X  j , resulting in an nm -dimensional vector z  X  j . The embedding of the  X  j can then be de fi ned as where projection matrix F  X  R M  X  nm maps the vector z  X  j M -dimensional latent space, and h (  X  ) = tanh(  X  ) 3 .
Finally, we use the n -gram embeddings to form a vector repre-sentation for each input text document. Formally, the document representation will be de fi ned as where d x  X  R M and x =( w 1 ,...,w N ) . In other words, d centroid of the vector associated with n -grams of the document x . Intuitively, the sentiment of a document is related to the aggregated polarity of all its n -grams; that is, the more positive n -grams that the non-linear function tanh(  X  ) converts unbounded range of the input into [  X  1 , 1] exist in the document, it is more likely for it to express a positive opinion. While there are many possibilities for aggregation func-tion, mean value provides a good summarization of the document X  X  sentiment in this latent space. As suggested by [9], one can also use the max function that selects the maximum value along each latent dimension. Our empirical evidence indicate that the mean function is a more appropriate choice for the SA task.

Another fundamental reason for this formulation is that the num-ber of phrases in the sentence is variable depending on the sentence length n . Thus, we need a function to compress the information from these phrases into a fi xed length document embedding vector.
We will consider two types of sentiment classi fi cationinthispa-per. First, similar to most prior approaches, we will consider binary classi fi cation setting that classi fi es a document either as a positive or negative. Next, we try to predict the text polarity toward its star-scale score directly using ordinal regression. It is our believe that this setting will become more prominent in the future since most of the online evaluation system are utilizing Likert-scale (e.g. 1-5 stars).

Given the document representation d x de fi ned as above, the bi-nary sentiment classi fi cation learns a function by optimizing the following loss measure: where sgn( g (  X  ))  X  X  1 ,  X  1 } are the prediction obtained from the classi fi er, and y x  X  X  1 ,  X  1 } is the label of the document x .We chose a linear function for g ,where Linear classi fi ers have proven record of achieving the state of the art performance in previous sentiment classi fi cation results [19].
The Likert-scale classi fi cation problem belongs to the more gen-eral class known as  X  X rdinal Classi fi cation X  [1], where the class labels have orderings. Utilizing this ordinal information in the classi fi cation will achieve better performance than treating each class separately without the order. There exist different methods to tackle ordinal classi fi cation or regression. Here, we present a sim-ple marginal ordinal loss based strategy. We aim to learn a function g that optimizes the following loss: In this case, we are handling a L -likert-scale system. We have a set of boundaries  X  l for each class l  X  [1 ,L ] . These boundaries are in ascending order, i.e  X  i &lt; X  j ,  X  i&lt;j . The function g ( puts a score for a document vector d x . The discriminative train-ing estimates the parameters of function g (  X  ) and class boundaries  X  ,i  X  [1 ,L ] by minimizing the loss function L . 4 The fi nal classi-fi er g ( d x ) is de fi ned as:
The ordinal classi fi cation can be related to Rank Loss used in information retrieval society. Given a set of objects x i
For simplicity, we de fi ne  X  0 =  X  X  X  ,forthe fi rst class that does not need a lower boundary for g (  X  ) [1 , |S| ] , their corresponding labels y i  X  Y,i  X  [1 , |S| ] ,andascor-ing function, the rank loss can be de fi ned as: The objective is to learn function g (  X  ) while minimizing the loss function L (  X  ) . Clearly the score g (  X  ) will try to put the objects in the order just like their labels. This order is consistent with the ordinal classi fi cation objective.
We use the multi-layer perceptron network to implement the above modules in a uni fi ed framework. As illustrated in Table 1, the overall system can be represented in a 6-layer network architecture ( T =6 ):
We take advantages of the simple and ef fi cient backpropagation process to train this layered network. The stacked layers in our network can be written in a more general form of multi-level func-tions: where l x denotes the loss on a single example x , and the exact loss function f T is de fi ned in Equation 2 and Equation 3. For a layer f ,i  X  [1 ,T ] , the derivative for updating its parameter set using the delta rule: and the fi rst factor on the right can be recursively calculated: Note that f and  X  are usually vectors (the scalar loss l = f treated as an all 1 X  X  vector), so  X  f T  X  f ces, and  X   X   X  is matrix multiplication.

We can use stochastic gradient descent (SGD) method to to per-form training of parameters [7]. For a set of training samples, in-stead of calculating true gradient of the objective on all training samples, SGD calculates gradient and updates accordingly on each training sample. SGD is proved to be scalable and more ef fi cient than batch-mode gradient descent methods, especially when deal-ing with large-scale datasets. The training procedure is presented in Algorithm 2.3. The 3rd column in Table 1 specify the parameters that will be learned during this end-to-end learning process in each layer.
 Algorithm 1 End-to-End Training procedure for the proposed sys-tem for j =1 to MaxIter do end for
We also want to point out that when using  X  X eep learning X  net-work, unsupervised pre-training of lower-layers is a common prac-tice [3] and shows to improve the results. We adopt a similar strat-egy and use the projection matrix learned via LSI (using the term-doc matrix on a large unlabeled text set) to initialize the word em-bedding -E matrix, i.e. unsupervised pre-training, in our experi-ment.
Our proposed framework is closely related to the following areas and research topics.
An in-depth survey of the earlier methods for sentiment analy-sis has been presented in [20]. We will primarily focus on related works on polarity classi fi cation with similar objective tasks. The main approaches classify the polarity of a given text at either the word, sentence or paragraph, or document levels. In the most in-tuitive model, the polarity of an article can be related to the sen-timent orientation of its words [13]. Latent semantic analysis has been used in [23] to to calculate the semantic orientation of the extracted words according to their co-occurrences with the seed words, such as  X  X xcellent X  and  X  X oor X . The polarity of the arti-cle is then determined through averaging the sentimental orienta-tion of its corresponding words. Instead of limiting the sentiment analysis at the word level, the mainstream research community per-forms sentiment classi fi cation at the article level. Various methods based on this principle have been proposed. These methods can be contrasted in terms of features they use: utilizing either uni-gram features [20] and/or fi ltered bigrams [6]. It is claimed that unigram and bigram features beat other features in the evaluation of several small-scale benchmark data sets [10]. It should also be noted that [19] investigated the use of several inverse document frequency (IDF) weighting schemes as features. They observed that such features improve the accuracy of sentiment classi fi cation. The third noteworthy trend is based on capturing existing substruc-tures and their ordering in the text. In a recent paper, [22] used an HMM-based model to describe the dependency between local sub-structures to improve sentiment prediction. Similarly, [8] proposed a learning method for local content modeling (aspect-sentiment sense) using large-scale unsupervised data sets.
There exists a number of word-level embedding methods that are able to capture semantic similarity between word pairs. One of the earliest but widely used approaches is Latent Semantic Index-ing (LSI) [11]. LSI applies SVD to term-document co-occurrence matrix, producing a low-dimensional representation for both doc-uments (including unseen ones) and words, and enables ef fi cient computation of semantic similarity between them. LSI is consid-ered the pioneering work that inspired methods such as probabilis-tic LSI (pLSI) [14] and Latent Dirichlet Allocation (LDA) using a generative probabilistic framework [5].

There are also supervised variants that try to compute embedding by fi tting to the labeled data. Such approaches have been applied to a variety of information retrieval tasks such as link prediction, cross-lingual retrieval, and image annotations [2, 25]. Another variant of supervised embedding method was recently introduced by [21] that learns (128 bit) hash-coding for term-frequency vec-tors of documents in the corpus, enabling semantic similarity-based hashing.
Broadly speaking, the proposed method is applicable to the gen-eral string classi fi cation problem. A variety of methods have been proposed to tackle the string classi fi cation problem, including gen-erative (e.g., HMMs) or discriminative approaches, such as string kernel-based machine learning methods [15, 26]. The key idea of basic string kernels is to map text strings of variable length into a vectorial feature space of fi xed length. In this space a standard clas-si fi er such as a support vector machine (SVM) can then be applied. As SVMs require only inner products between examples in the fea-ture space, rather than the feature vectors themselves, one can de-fi ne a string kernel which implicitly computes an inner product in the feature space. String kernels are designed so that the high sim-ilarity value between two text documents indicates that they have numerous n -grams in common.

We note that our proposed method implements a variation of in-exact matching between n -grams which is also a critical compo-nent in the string kernel research, usually tackled by using different families of mismatch in the string kernel [16].
Lately,  X  X eep learning X  research grows to bring in attentions. As pointed out by [3], recent results have suggested that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g. in natural language, or vision), one would need deep architectures. Each layer in the architecture represents features at a different level of abstraction, de fi ned as a composition of lower-level features. Statistical language modeling is a key topic in natural language processing (NLP), where the dif fi culty is the curse of dimensionality, especially when modeling joint distribu-tion between many discrete random variables. [4, 18] proposed a language model based on the multi-layered neural networks, which tries to model a distributed representation for each word and the probability function for word sequences, simultaneously. Later, [9] utilized a single multi-layered convolutional neural network archi-tecture to handle multiple classic NLP tasks at the same time. The proposed uni fi ed framework provides an end-to-end system that, given a sentence, outputs a host of language processing predictions.
Our proposed method is motivated by the above approach and uses a multi-layer  X  X eep X  neural network to combine the n -gram embedding and sentiment classi fi cation in a single framework. It is our belief that the word embedding and n -gram embedding are feature learning in some sense.
We have evaluated the performance of the proposed method on two sentiment dataset, Amazon and TripAdvisor that were intro-duced by [6] and [24], respectively. The Amazon dataset contains customer reviews of 25 various categories including apparel, au-tomotive, baby, DVDs, electronics, magazines, tools and hardware, etc. The TripAdvisor data set contains customer reviews for various hotels across the globe. In addition to the overall reviewer X  X  senti-ment rating, this corpus contains scores for various aspects such as rooms, location, cleanliness, etc. However, sentiment scores for the speci fi c aspects are absent from a signi fi cant number of the reviews in the TripAdvisor data set, so In our experiments we only consider overall ratings for this data set. These are considered some of the largest SA data sets currently available. We note that, our approach requires training for a large number of parameters in comparison to a simple shallow BOW model. Consequently, the advantage of our model becomes more obvious on larger datasets (we will show the effect in section 4.3.3).

Both datasets contain user-generated reviews where an overall sentiment for each review is quanti fi ed with an integer 1 through 5 (a.k.a the 5 stars scale). A sentiment score of 1 star corresponds to the lowest (negative) sentiment, while the score of 5 stars cor-responds to the highest (positive) sentiment. For each dataset, we create a balanced version of the data that contains equal number of positive (4 and 5 stars) and negative (1 and 2 stars) reviews. Tri-pAdvisor data also contains neutral reviews (3 stars) that do not exceed the number of positive nor negative reviews, so we add the neutral reviews to the balanced version of the data as well. In ad-dition, we drop very small number of reviews from TripAdvisor with overall sentiment scores of zero stars, since the meaning of this sentiment rating is ambiguous. Statistics of both datasets can be found in Table 2.

We split balanced datasets with 70% / 30% ratio into training and testing sets, respectively. We sample positive, negative, and (op-tionally) neutral reviews separately. This results in equal number of positive and negative reviews in both training and testing sets. Furthermore, in the case of Amazon dataset, each of the 25 cat-egories is handled separately, resulting in balanced version of the data and splitting it into training/testing sets. This is done to ob-tain equally split sets in terms of polarity for each category, as the number of reviews varies signi fi cantly across the categories (e.g., from couple of hundreds to tens of thousands). Finally, once train-ing and testing sets are constructed, we sample the training sets to obtain subsets required for validation. We use 20 , 000 and 3 , 000 reviews for validation from the Amazon and TripAdvisor datasets, respectively. The datasets used in our experiments are made avail-able online. 5
We have evaluated the performance of sentiment prediction us-ing binary and ordinal classi fi cations described in Section 2. We also present comparative results between our method and linear classi fi ers on bag-of-word features (1-gram and 2-gram). The lat-ter approaches are considered to achieve the state of the art perfor-mance on sentiment prediction [19].

First, we outline the baseline procedure producing 1-gram and 2-gram features. We follow the method used by [6] to limit vocab-ularysizeto 10 , 000 terms with highest mutual information (MI), shared with the binary labels (positive or negative). As was men-Table 2: Selected statistics for Amazon and TripAdvisor data sets. The table lists the number of reviews for each star rating, as well as for training, testing and validation sets separately. In addition, total number of reviews in each data set is provided. Original dictionary size ( |D| ) for each data set is listed along with 1-gram (  X  1 ) and 2-gram (  X  2 ) vocabulary sizes. All of the numbers listed are obtained from the balanced versions of the datasets, containing equal number of positive and negative re-views. tioned earlier, Amazon dataset contains reviews for 25 categories of consumer products. As a result, the MI-based procedure for build-ing 1-and 2-gram vocabularies for the Amazon is performed on each category separately. In the interest of fairness, the MI-based procedure is performed only on the training data. Then 10 , 000 terms for each of the 25 categories are concatenated together to form the fi nal vocabulary that contains 54 , 334 unique terms. This vocabularyisthenusedto fi lter all three sets of data; training, test-ing, and validation, for both Supervised Latent n -gram Analysis (SLNA) input and BOW input.

In addition to selecting single terms with highest mutual infor-mation to form 1-gram vocabulary  X  1 , we perform the same proce-dure on both unigrams and bigrams to form 2-gram vocabulary  X  yielding 127 , 337 features. For the TripAdvisor corpus, we also use MI-based procedure to build 1-gram and 2-gram vocabularies. However, since there is only one category for this corpus, we sim-ply limit the vocabulary size to match the size of the corresponding vocabulary obtained from the Amazon training set. Table 2 lists 1-and 2-gram vocabulary sizes for both sentiment datasets.
We train the SVM classi fi er with linear kernel using LibLin-ear SVM tool 6 . Note that the size of the training data, as well as its dimensionality makes it impractical to use any non-linear kernel for the SVM classi fi er. This was previously pointed out by [19]. The SVM classi fi er is obtained using the entire training data, and its performance is evaluated on whole testing set. For each term, we used two weighting schemes, regular TF-IDF and  X  -IDF (we have implemented a  X ( t ) n variant). According to [19],  X  -IDF achieves state of art performance on a small subset of the Amazon dataset. The optimal value for the cost constant C was chosen using validation set with simple parameter grid search on C = { 2  X  7 , 2  X  6 ,..., 2 6 , 2 7 } . We found that for both datasets, setting C =32 and C = 1 32 for TF-IDF and  X  -IDF weighting schemes, respectively, yield the best validation performance.
The training of the perceptron classi fi ers is different under two representations: BOW linear or SLNA. Speci fi cally, we perform training and validation of the perceptrons simultaneously in batches, where each batch consists of training for 100 , 000 iterations fol-lowed by the validation testing on the entire set. Each iteration consists of one positive and one negative reviews selected at ran-dom from the appropriate set. We stop the training either after 250 batches were performed ( 25 , 000 , 000 training iterations), or when the running average validation error over the last 50 batches in-creased for the three consecutive batches. Following the training procedure, the classi fi cation error rate (reported in all of our exper-iments) is computed on the entire testing set using trained neural network. In our experiments, we set the dimensionality of the word embedding (Level 1 in Table 1) to m =50 , dimensionality of the n -gram embedding to M =30 (Level 2 in Table 1), and size of the window to n =5 words (reducing the window size increased error rate). Dimensionality of the word embedding ( m =50 )wasse-lected to match dimensionality of the LSI-based embedding, and is a common choice for the latter. Furthermore, reducing the dimen-sionality of the n -gram embedding to M =30 slightly improved classi fi cation accuracy in our preliminary evaluations. Thus, we chose to fi x this parameter throughout all experiments presented in Section 4.3.
The fi rst experiment that we performed was to evaluate the per-formance of the proposed Latent n -gram Analysis method for a binary classi fi cation task  X  predicting polarity of the review (posi-tive or negative). Binary classi fi cation setup was chosen, since it is the most common measure of performance for the sentiment pre-diction task. The binary classi fi cation error rates for Amazon and TripAdvisor datasets can be found in Table 3.

The results indicate that for Amazon dataset, SLNA initialized with LSI embedding achieved better performance in comparison to both 1-gram and 2-gram, including the SVM classi fi er using  X  -IDF. However, on TripAdvisor data, SLNA does not outperform the BOW methods. Our hypothesis is that this is due to the size limitation of the training data (60k) for the model. This will be further con fi rmed in Section 4.3.3. As a comparison of SLNA to an unsupervised embedding method, we also include results of a linear SVM trained on BOW LSI embeddings (BOW LSI SVM), and also a SLNA with fi xed lookup table: i.e., classi fi er and n -gram embeddings are trained, but word embeddings are fi xed to LSI embeddings (SLNA LT-FIX). Note that for BOW LSI SVM method, LSI-based document embedding was obtained in transduc-tive setting (i.e., using entire balanced dataset), and the best error rate for 5 -fold cross validation on each set is reported (cost param-eters used: C = { 2  X  7 , 2  X  6 ,..., 2 6 , 2 7 } ). It is clear from Table 3 that neither of these two methods reaches the level of SLNA. For a description of acronyms, please refer to Table 4. Table 5 shows the results on rank loss.
 Table 5: Average error when using margin ranking loss. For TripAdvisor dataset, the experiments were performed on the data containing neutral reviews.

Clearly, SLNA outperforms BOW approaches on both Amazon and TripAdvisor datasets. This is different from the results we observed for binary classi fi cations. We believe this behavior can be attributed to the fact that pair-wise training examples generates more training data than simple binary classi fi cation. Furthermore, the rank loss is consistent with the ordinal classi fi cation results pre-sented in Table 6, where SLNA yields the best performance in all scenarios. We are not aware of any prior art reporting results for ordinal classi fi cation on these two datasets, so direct comparisons is not possible. For the sake completeness, we calculated mean squared error (MSE) based on predictions with ordinal classi fi ca-tion. We obtained MSE =1 . 03 on Amazon dataset using SLNA LSI RL model, which is considerably better than previously re-ported MSE  X  1 . 5 on a small subset of Amazon dataset [17]. Table 6: Ordinal classi fi cation average error rate. The error rate for 5 star classi fi cation (i.e., including neutral reviews) are provided in parentheses.
In table 2, we train Amazon data on the binary classi fi cation task, while varying the size of the training data. We can see that as we in-crease the size of the training set, the gap between SLNA and BOW diminishes and eventually SLNA out-performs 2-gram BOW.
 Figure 2: Testing error on Amazon with different training set size.
It is our belief that an n -gram model, combined with latent repre-sentation, will produce an more suitable embedding for document-level classi fi cation tasks, such as sentiment polarity prediction. Our proposed embedding combines n -gram representation with a latent model to produce a simple and ef fi cient embedding for short seg-ments of text. Our experimental evaluation indicates that for binary classi fi cation and regression tasks, our method with 1-gram (i.e., single words) dictionary of size |D| achieves accuracy of BOW representation with a 1-and 2-gram dictionary of size |D| 2 thermore, we show that in a multi-class experimental setting (i.e., predicting star values for reviews) our embedding outperforms the baseline methods based on BOW with 2-gram dictionary.

One potential limitation associated with the proposed method is its need of large enough training set for model training. However, due the increasing availability of large scale SA datasets become available, this is not considered a major shortcoming. Moreover, our study indicates the model trained on mixed categories has ex-cellent performance on both mixed and separated categories. These are all indications of great potential of proposed method in senti-ment analysis. This model is not restricted to the task of sentiment classi fi cation and can potentially be applied for other document classi fi cation applications.
Ali Shokoufandeh and Dmitriy Bespalov gratefully acknowledges the support from the National Science Foundation Grant #0803670 under the IIS Division and Of fi ce of Naval Research Grant ONR-N000140410363. [1] A. Agresti. Analysis of Ordinal Categorical Data . John [2] B. Bai, J. Weston, R. Collobert, D. Grangier, K. Sadamasa, [3] Y. Bengio. Learning Deep Architectures for AI .Now [4] Y. Bengio, R. Ducharme, P. Vincent, and D. D. E. R. [5] D. Blei, A. Ng, and M. Jordan. Latent dirichlet allocation. [6] J. Blitzer, M. Dredze, and F. Pereira. Biographies, [7] L. Bottou. Stochastic learning. In O. Bousquet and U. von [8] S. Brody and N. Elhadad. An unsupervised aspect-sentiment [9] R. Collobert and J. Weston. A uni fi ed architecture for natural [10] H. Cui, V. Mittal, and M. Datar. Comparative experiments on [11] S. Deerwester, S. T. Dumais, G. W. Furnas, T. K. Landauer, [12] G. Ganu, N. Elhadad, and A. Marian. Beyond the stars: [13] V. Hatzivassiloglou and K. R. McKeown. Predicting the [14] T. Hofmann. Probabilistic latent semantic indexing. In [15] P. Kuksa, P.-H. Huang, and V. Pavlovic. Scalable algorithms [16] C. S. Leslie, E. Eskin, J. Weston, and W. S. Noble. Mismatch [17] Y. Mansour, M. Mohri, and A. Rostamizadeh. Domain [18] F. Morin. Hierarchical probabilistic neural network language [19] G. Paltoglou and M. Thelwall. A study of information [20] B. Pang and L. Lee. Opinion mining and sentiment analysis. [21] R. Salakhutdinov and G. Hinton. Semantic hashing. Int. J. [22] C. Sauper, A. Haghighi, and R. Barzilay. Incorporating [23] P. Turney and M. Littman. Measuring praise and criticism: [24] H. Wang, Y. Lu, and C. Zhai. Latent aspect rating analysis on [25] J. Weston, S. Bengio, and N. Usunier. Large scale image [26] J. Weston, C. Leslie, E. Ie, D. Zhou, A. Elisseeff, and W. S.
