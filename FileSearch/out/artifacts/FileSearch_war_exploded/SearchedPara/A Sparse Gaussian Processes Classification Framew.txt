 Tagged data is rapidly becoming more available on the World Wide Web. Web sites which populate tagging services offer a good way for Internet users to share their knowledge. An interesting problem is how to make tag suggestions when a new resource becomes available. In this paper, we ad-dress the issue of efficient tag suggestion. We first propose a multi-class sparse Gaussian process classification framework (SGPS) which is capable of classifying data with very few training instances. We suggest a novel prototype selection algorithm to select the best subset of points for model learn-ing. The framework is then extended to a novel multi-class multi-label classification algorithm (MMSG) that transforms tag suggestion into the problem of multi-label ranking. Ex-periments on bench-mark data sets and real-world data from Del.icio.us and BibSonomy suggest that our model can greatly improve the performance of tag suggestions when compared to the state-of-the-art. Overall, our model requires linear time to train and constant time to predict per case. The memory consumption is also significantly less than tradi-tional batch learning algorithms such as SVMs. In addition, results on tagging digital data also demonstrate that our model is capable of recommending relevant tags to images and videos by using their surrounding textual information. I.5.3 [ Pattern Recognition ]: Clustering X  algorithms ; H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Algorithms, Experimentation, Performance tagging system, gaussian processes, prototype selection, multi-label classification Copyright 2008 ACM 978-1-59593-991-3/08/10 ... $ 5.00.
The amount of web resources and data continues to grow with the emergence of Web 2.0 sites. As an example, del.icio.us and Flickr 2 have attracted a significant amount of Internet traffic, as well as millions of Internet users. Recent statis-tics indicated that del.icio.us gets roughly 150,000 posts per day while Flickr gets 1,000,000 photos per day. These web sites allow users to specify keywords or tags for resources, which in turn facilitates the organizing and sharing of these resources with other users. Since the amount of tagged data potentially available is virtually free and unlimited, inter-est has emerged in investigating the use of data mining and machine learning methods for automated tag suggestions, otherwise known as social annotation [1, 3, 7, 20].
Existing approaches to tag suggestion can be roughly clas-sified into two categories. By mining usage patterns from current users, collaborative filtering canbeappliedtosug-gest tags from users who share similar tagging behaviors [3, 7]. This approach requires a look-up table of between-user similarities, which is usually in the form of weighted ma-trices that are computed and stored in advance. Another approach is for the semantic meanings between tags to be leveraged to improve user experience by aggregating simi-lar tags into clusters as in [1, 20]. Here, tag co-occurrence and tag distributions are explicitly taken into account as measurements of tag similarities. The number of optimal clusters are usually tuned manually.

Unfortunately, while both effectiveness and efficiency need to be addressed for ensuring the performance of the tagging services, most of the existing work has focused on effective-ness [1, 3, 7]. Efficiency, while not being totally ignored, has only been of recent interest [20].

In this paper, we address the efficiency of tag suggestion from a machine learning perspective. We propose a novel sparse Gaussian processes (GP) framework for suggesting multiple tags simultaneously. The proposed model can be fit into any kind of multi-class classification tasks with the advantage of computation efficiency in both the training and test stages. Generally, our model consumes a very small amount of memory and takes linear time proportional to the number of samples for training. The prediction time is constant per case. The performance on tagged data in-dicates a better precision and less computational cost than the state-of-the-art [20]. http://del.icio.us/ http://www.flickr.com/
The reason of advocating GP for tag suggestion is multi-fold. First, GP have become an important non-parametric tool for classification. Unlike generative classifiers such like Naive Bayes, GP make no assumption on the form of class-conditional density of the data making it immune to any poor performance caused by a false model assumption. An-other advantage of GP is that the predicted result of the model yields a probabilistic interpretation, while traditional discriminative classifiers such like SVMs usually do not con-sider the predictive variance of test cases 3 . For tag sugges-tion where the tagged data (e.g., web pages) usually does not contain any class labels, the user-assigned tags can be used as labels. In this case, GP classifiers that inherit some level of uncertainty can provide a probabilistic classification which tolerates the limitations and possible errors caused by the tags. The predictive variance also offers flexibility of making predictions to new instances.

The other characteristic of tagged data is t he unbounded vocabulary. Research has shown a constant growth of the tag vocabulary for a major social bookmarking site CiteU-Like 4 [5]. Consequently, the tagged data sets used for empir-ical analysis are usually of high-dimensionality and sparse-ness [20]. In this case, the efficiency of the model training should also be considered in addition to the performance is-sue. Nevertheless, massive training data often requires large memory and high computational cost for most discrimina-tive approachs including SVMs. Ad-hoc methods have been developed to select subset for training but those approaches are somewhat heuristic and often performed outside of the model itself. Instead, the sparse GP framework we devel-oped directly selects a subset of most informative documents from all tagged data during training. The prototype selec-tion algorithm we developed requires no extra cost because it reuses the covariance function developed by the GP frame-work. Consequently, the GP model shows a very promising performance when limited training resources are available by comparing to SVMs. Details can be found in Section 4.
Our contributions consist of both new methodology and application to tag suggestion. Our major contributions are: 1. A novel prototype selection method for multi-class GP classification . In the literature of GP [19], opti-mizing the parameters and finding the best subset of points have been performed jointly. However, we propose a proto-type selection method to select the most informative points independently. Empirical results show that it performs bet-ter in the case of multi-class classification. 2. A novel multi-label method for tag suggestion . The proposed multi-class GP framework is naturally ex-tended to address the multi-label problem. We treat each associated tag as a label for the document and perform an effective label ranking algorithm for tag suggestion. 3. Comparison of classification with Support Vec-tor Machines . SVMs have been well-recognized as one of the best methods for classification. Yet research has shown a close correspondence between SVMs and GP [15]. Em-pirically, we investigate their performance when there exists
Though Platt suggested an ad-hoc prob. SVM in [14], it doesn X  X  consider the predictive variance of the function. http://www.citeulike.org/ very few training instances and conclude that our GP frame-work performs better in this case. 4. Comparison to other tag suggestion methods .
 We compare our framework with a most recent tag sugges-tion method [20] as well as SVMs on several real-world data sets and find improved tag suggestion performance.
In this section, we briefly review the recent development of tag suggestion methods, followed by the review of the basic Gaussian processes framework.
Though some still question the use of computer algorithms to generate tags for social bookmarking services [8], a num-ber of machine learning frameworks have been proposed to address the problem of automatic tag recommendation for both text and digital data on the web [3, 1, 12, 20]. Recent work has shown the effectiveness of leveraging user tags to improve language models [22].

In [3], the authors suggested a method named P-TAG for automatically generating personalized tags in a seman-tic fashion. They paid particular attention to personalized annotations of web pages. In a document-oriented approach, a web page is compared with a desktop document using ei-ther cosine similarity or latent semantic analysis. Keywords are then extracted from similar documents for recommenda-tion. The second keyword-oriented approach alternatively finds the co-occurrence of terms in different documents and recommends the remaining tags from similar desktop docu-ments to the web page. The third hybrid approach combines the previous two methods. From a collaborative filtering point of view, the first two methods can be interpreted as item-based CF with the item being documents and keywords respectively. Their methods, however, do not investigate the behaviors between different users for similar web pages.
A clustering-based approach was proposed in [1] to ag-gregate semantically related user tags in to similar clusters. Tags are represented as graphs where each node is a tag and the edge between two nodes corresponds to their co-occurrence in the same documents. Tags in the same cluster were recommended to the users based on their similarities. Similarly, an automatic annotation method for images was proposed in [12]. A generative model is trained by exploit-ing the statistical relationships between words and images. A discrete distribution (D2-) clustering algorithm was intro-duced for prototype-based clustering of images and words, resulting in a very efficient model for image tagging.
Recently, a method that combines the power of clustering and mixture models was proposed in [20]. The annotated documents were first represented into a triplet of (words, docs, tags) by two bipartite graphs, which were then clus-tered into topics by a spectral recursive embedding (SRE) [23]. To deal with the sparseness of the topic clusters, a two-way Poisson mixture model (PMM) [13] was applied to simultaneously group documents into components and clus-ter words. Inference for new documents was based on the posterior probability of topic distributions. Tags were rec-ommended according to the within-cluster tag rankings.
A Gaussian process (GP) is a stochastic process consists of a collection of random variables x , which forms a multi-Figure 1: One-dimensional illustration of Gaussian process construction for classification. (a) A latent function f ( X ) drawn from Gaussian Process, where f ( x i ) denotes the latent function value of point x i . (b) The class probability of X after scaling f ( X ) into (0 , 1) by a sigmoid function  X ( f i )=1+exp(  X  f i )  X  1 where P ( x i ) denotes the class probability at x i . variate Gaussian distribution specified by a mean function  X  ( x ) and covariance function k ( x , x ). For classification, the objective is to assign a new observation x  X  to one or more predefined classes denoted by y  X   X  X  1 , ..., C } . GPs can not be applied to the classification task directly because the val-ues of y are not continuous. Consequently, a latent func-tion f ( x ) is employed to infer the labels. The GP prior is therefore placed over f ( x ). Fig 1 (a) illustrates an one-dimensional case of the latent function with mean 0. To make a prediction given a new x  X  , one first determine the predictive distribution p ( f  X  | f ), where f is obtained from the training set, f | X train  X  X  ( 0 , K ), with K denoting the mul-tivariate covariance matrix. The class probability y  X  is then related to the latent function f  X  .
Denote a training data set D = { ( x i ,y i ) | i =1 , ..., N N training points X = { x i | i =1 , ..., N } drawn independent and identically distributed (i.i.d.) from an unknown dis-tribution, and the associated labels y = { y i | i =1 , ..., N where each point x i is a D dimensional feature vector, x R D and y i  X  X  1 , ..., C } . Following the convention in [15], we introduce a vector of latent function values of N training points for C classes, which has length CN where x i has C latent functions f i =( f 1 i , ..., f C i ther assume that the GP prior over f has the form f | X  X  N ( 0 , K ), where K represents the covariance matrix which is constructed from a pair-wise covariance function K ( x n , x [ K
N ] nn . Specifically, K is block diagonal of size CN  X  CN in the matrices K 1 , ..., K C ,whereeach K j represents the correlations of the latent function values within class j .A wide range of covariance functions can be chosen for GP classification [15].A commonly used function in the classifi-cation case is the squared exponential function, defined as: where  X  = { l,  X  2 } corresponds to the hyper-parameters .Given the training set D , we can compute the posterior of the la-tent function by plugging in the Bayes X  rule, which is non-Gaussian. In eq.(3), the conditional probability p ( y | f ) has not been decided yet. In the multi-class case, y is a vector of the length CN (which is the same as f ), which for each i =1 , ..., N has an entry of 1 for the class which corresponds to the label of the point x i and 0 for the rest C  X  1 entries. One of the choices is a softmax function:
To proceed, we compute the predictive distribution of the class probability given a new x  X  in two steps. First, compute the latent value f  X  by integrating out f : then y  X  can be computed by integrating out f  X  :
This method takes O ( N 3 ) to train due to the inversion of thecovariancematrix K .Arangeof sparse GP approxima-tions have been proposed [11, 16]. Most of these methods seek a subset of M ( M N ) training points which are in-formative enough to represent the entire training set. Con-sequently, the training cost is reduces to O ( NM 2 )andthe corresponding test cost to O ( M 2 ). Next we discuss a sparse way to reduce the computational cost in the multi-class case.
Our model involves several steps. First, we choose M ( M N ) points (denote as  X  X = {  X  x m } M m =1 ) from the train-ing set. Then we generate their latent functions  X  f from the prior. The corresponding f for the entire training set is thus drawn conditionally from  X  f . See Figure 2 for details. Figure 2: Graphical representation of our sparse multi-class GP model.  X  is the hyper-parameter that define the latent function f .  X  denotes the extra pa-rameter for placing a distribution over  X  .
 First, assume that the M points have already been chosen. Then place a GP prior on  X  X , which uses the same covariance function as shown in eq. (2), such that these points have a similar distribution to the training data,
Given a new x  X  , we utilize M latent functions  X  f for pre-diction. We compute the latent values f  X  by integrating the likelihood with the posterior: p ( f  X  | x  X  ,X, y ,  X  f ,  X  X )= where A represents the single data likelihood by applying to the reduced set of points. With  X  f determined, the likelihood can be treated as a bivariate normal distribution, which fol-lows a normal distribution: f  X  | x  X  ,  X  f ,  X  X  X  X  ( f  X  | k T x  X  K  X  1 M  X  f ,K where k x  X  = K (  X  x , x  X  )and[ K M ] ij = K (  X  x i ,  X  x
Nevertheless, the problematic form of posterior B does not follow a normal distribution and has to be approximated. Our method to approximate B in eq.(8) is based on the Laplace approximation, which were used in [15] for binary classification. Using the Bayes X  rule,
The detail of the derivation is long and omitted. The approximated mean and variance of eq.(10) is:
The final step is to assign a class label to the observation x , given the predictive class probabilities by integrating out the latent function f  X  : p ( y  X  | x  X  ,X, y ,  X  f ,  X  X )= which again cannot be solved analytically. One way to ap-proximate is to use cumulative Gaussian likelihood. In [15], the authors estimated the mean prediction by drawing S samples from the Gaussian p ( f  X  | y ), softmax and averaging the results. Once the predictive distribution of the class probability is determined, the final label of x  X  can be de-cided by choosing the maximum posterior (MAP):
It remains to optimize the parameters  X  = {  X ,  X  X } ,which contain the hyper-parameters ( l,  X  ) for the covariance ma-trix K as well as finding the subset  X  X of M points. Tradi-tionally, they are optimized jointly by optimizing the marginal likelihood of the training data. In our approach, we instead treat them individually.
The marginal likelihood of y can be obtained by integrat-ing out  X  f , p ( y | X,  X  X,  X ) = With a Taylor expansion of L (  X  f ) around  X   X  f we find
L (  X  f ) L (  X   X  f )+(  X  f  X   X   X  f )  X   X  f L (  X  f )
Therefore, the approximation of the marginal likelihood canbewrittenas exp( L (  X   X  f ))
The log marginal likelihood can be obtained by taking logarithm on both sizes of the above equation, log p ( y | X,  X  X,  X ) = L (  X   X  f )  X  CN which can be maximized w.r.t. the parameters  X  to obtain  X  l and  X   X  . Note that each  X  c is a D  X  D symmetric matrix, where D is the number of dimensions. We assume that each dimension is independent, thus simplifies  X  c to be a diagonal matrix. However, this still yields DC parameters to estimate for  X  . Therefore, we further assume that within each class c , the covariance of each dimension is the same, so that the total number of parameters for  X  c is reduced to C .
The original gradient calculation in eq.(16) is very com-plicated. However, we can simplify it with the assumption made on the covariance matrix. Since each  X  c is now inde-pendent of each other, we can estimate the locations of the active points regardless of the choices of l and  X  . We greed-ily find the locations of  X  X by stochastic gradient descent method. This is similar to finding the optimal prototypes for each class, which is a subset of points that contains enough information for each class. Our method for optimal proto-type search is parallel to [18], which is used for K -nearest neighbor classification. We select a set of M prototypes by minimizing the misclassification rate of the training set, L ( X,  X  X )= 1 where the indicator function I is 1 if the condition is hold and 0 otherwise. The likelihood P (  X  x m | x ) can be calculated by plugging in the normalized covariance:
We can further rewrite the loss function in eq.(17) by re-moving the indicator function: Figure 3: An example of prototype selection with M =2 . Left figure shows the original distribu-tion; right figure, contour-plots the results of de-scent where black dots are the starting points. where l m indicates the individual cost of misclassification, which is continuous in the interval (0 , 1). Therefore, it can be minimized by gradient descent w.r.t.  X  X , =  X  x m ( t )  X   X  ( t )  X   X  x m l m ( t ) =  X  x m ( t )+  X  ( t ) p (  X  x m | x )( I (  X  y m = y n =  X  x m ( t )+
Here  X  ( t ) &gt; 0 is a small enough number which specifies the step length of the descent. The program stops when a stopping criterion is reached. We further notice that only those points falling into a particular area of the input space can contribute to the update of the prototypes. This fact is explained as the window rule in [9]. So we can speed up the prototype updates by searching over those points only. Figure 3 shows an example of two prototypes. It can be seen that after three steps of descent, our algorithm successfully finds informative points for each class.

For brevity we hyphenate our method as S parse G aussian process with P rototype S election (SGPS).
In our sparse framework, o nly the covariance matrix K M for the M prototypes is required to be inverted. To be ex-act, K M needs to be inverted when calculating  X  , f , Q and P in eq.(11). For efficiency, Cholesky decomposition is often employed, which ensures that for N training points distributed in C classes, the training stage can be realized in O ( M 2 NC )time,with O ( M 2 C ) per prediction.
As for the cost of prototype selection, since the updates re-uses covariance matrix in eq.(18), no additional storage and computation are required. Therefore, the gradient descent can be efficiently updated in at most O ( NC )time.
So far, we have only considered the case that the each observation is single-labeled, i.e., belongs to only one class. In fact, many real-world problems are multi-labeled. In the case of tagged data, each tag associated with a document may be treated as a label, which may or may not refer to the same topic as other labels. Thus, the problem of tag sug-gestion can be transformed into a multi-label classification Algorithm 1 Multi-label Multi-class Sparse GP Classifica-tion (MMSG) for Tag Suggestion 2: M : number of prototypes 3: k : covariance function 4: begin training procedure 5: for i =1: N 7: end for 8: Train a GP classifier given { ( x i ,c i ) N 1 ,M, k } 9: Output :  X  X,  X  f 10: begin test procedure 11: Input: a test object x  X  13: for each category m  X  X  1 , ..., C } 16: end for 17: end for problem where the objective is to predict the probability of a document with all possible tags (labels) given a fixed tag vocabulary and associated training documents.

The problem of multi-label classification (MLC) is ar-guably more difficult than the traditional single-label clas-sification task, since the number of combinations for two or more classes is exponential to the total number of classes. For N classes, the total number of possible multi-labeled class is 2 N , making it unfeasible to expand from an algo-rithm for single-label problems. Much research has been devoted to increasing the performance of MLC and gener-alize the framework to single-label classification; see related work for more information[21].

As pointed out in [2], multi-label classification can be treated as a special case of label ranking, which can be re-alized if the classifiers provide real-valued confidence scores or a posterior probability estimates for classification out-comes. Thus, the multi-class SGPS model readily maps to this problem, since the output vector y  X  contains real-valued scores of the posterior class probabilities. Specifically, in the multi-label case, we assume that the class label of a train-ing instance x i is no longer a binary value, but rather a vector y i of binary values where each y ij denotes the exis-tence/absence of x i in class j . We further assume that these Figure 4: Example of document-tag graph. Each document is associated with multiple tags. Tag with the highest frequency is treated as the category of that document (shown in bold line). class probabilities can be ranked according to their values, where s ( y im ) &gt;s ( y in ) indicates that y im is preferred to y in . In the context of tags, the value of a tag is defined as the number of times it has been used to annotate the spe-cific object. So if a document d 1 (cf Figure 4) is tagged 4 times with game ,3timeswith fun and 5 times with xbox , we can rearrange the labels in the descending order, yield-ing, { xbox (5) ,game (4) ,fun (3) } . Note that normalization is usually required to ensure the well-defined class proba-bility, thus the class probabilities of the above case become { 0 . 42 , 0 . 33 , 0 . 25 } . Figure 4 shows an example of 4 documents and 5 tags with their categories in bold lines.

In this way we can transform multi-class multi-label classi-fication into multi-category single-label classification. Specif-ically, we first assign each x i into a single category c which corresponds to its top-ranked label (e.g., in the above case, the category is xbox ). Each category contains a set of la-bels that belong to the objects in that category. Intuitively, tags that belong to the same category are more semanti-cally related than tags in different categories, i.e., tags in the same category have a higher co-occurrence rate. How-ever, it should be noted that an individual tag could belong to multiple categories, e.g., in Figure 4, fun appears in two categories. The above two phenomenon can be roughly ex-plained by the behavior of polysemy and synonymy in lin-guistics. Table 1 shows three ambiguous tags and their cor-responding categories in one of our experiments. Table 1: Example of ambiguous tags from del.icio.us. of all possible labels are defined as where Z ( c ) is a normalization factor for category c .We summarize this approach in Algorithm 1,  X  K refers to the to-tal number of possible labels. During the training phase, we trainanSGPSmodelfor C categories, as well as calculating the within-category scores for all labels. In the test phase, we use the model first to determine the probabilistic distri-bution of the categories given a new test case. Then com-bine this evidence with the within-category scores of tags in a multiplicative fashion to obtain the final label distri-bution. The labels are sorted in descending order based on the estimated likelihoods, the top-ranked tags are used for recommendation. Figure 5 illustrates the process.
To assess the performance of the proposed framework, we first evaluate our GP framework SGPS with synthetic and bench-mark data, then measure the quality of the tag sug-gestion algorithm (MMSG) using real-world data sets. trained model Figure 5: The training and test processes of MMSG. Each d i is a document and each t i is a tag.
For comparison, we use the multi-class Laplace approxi-mation algorithm by Williams (GPLA)[15], to see how dif-ferently our sparse framework will perform against the full Gaussian model. We also include the sparse variational Bayesian method (VBGP)[6] and the multi-class informa-tive vector machines (IVM) 5 [16] as two of the sparse Gaus-sian process models. Three common metrics are employed for assessment: the marginal likelihood of the training set in eq.(16), the predictive error of the test set, and the algo-rithm running time . For the first metric, we fix the number of prototypes M to be 5%. For the other two, we examine the performance variation with the change of M .
Following [6], we generate a three-class synthetic data set which has ten-dimensions. Only the first two dimensions of the data are responsible for defining the three class labels, while the other eight dimensions are irrelevant. In order to compare with previous work, we use the same experiment setting as in [6]. i.e., we create 500 instances for training, and draw another 5,000 instances independently for testing.
In order to judge the change of the marginal likelihood, a common approach is to perform a range of experiments with different values of the hyper-parameters. In [10], the authors created a regular 21  X  21 grid for both hyper-parameters. Here, we fix M to be 5% (i.e., 25 training points) and inves-tigate the change of p ( y | X,  X  X,  X ) with  X  and l .
Figure 6 shows a contour plot of the marginal likelihood as a function of l and  X  . Usually, higher marginal likeli-hood yields better predictive performance. In this figure, we notice that the variation of marginal likelihood from our model SGPS preserves the shape of GPLA, with the change of parameters. The result just ifies the use of the sparse ap-
Somehow the code of multi-class IVM is not available, we thus use the binary version with one-vs-all classification. Figure 6: Contour plot of the approximated marginal likelihood, as a function of hyper-parameters l and  X  . The marginal likelihood reaches an optimum at l =1 . 38 ,  X =3 . 13 for GPLA, and l =1 . 15 ,  X =4 . 05 for our model SGPS. Figure 7: The performance of the toy data set. The full Gaussian model GPLA is used as a baseline.
 Our model (SGPS) achieves better predictions and requires less running time than VBGP and IVM. proximation SGPS of the full Gaussian model GPLA for the toy data set.
Figure 7(a) plots the prediction error of the 5,000 test points for the three methods. Our model SGPS incurs signif-icantly less error with M from 4% to 90%. Especially when M is quite small, our model exhibits its robustness. With only 4% of the training points, our model is capable of mak-ing more than 70% correctly predictions, which quickly con-verges to the performance of the full model GPLA. Whereas for VBGP and IVM, the outcome is not attractive in the lower region of M , although VBGP slightly outperforms (Er-ror = 3 . 96%) our model (Error = 4 . 01%) when M = 100%. Overall, our model exhibits better predictive performance. The training cost of the three methods are depicted in Figure 7 (b). The test result shows similar patterns thus ig-nored here. Results are averaged over 10 run with standard deviations eliminated for better interpretation. It is clear to see that our model requires much less time to train compared to VBGP and IVM, which is consistent with the theoretical foundation. Recall that for our sparse approximation, only O ( M 2 NC ) time is required for training, whereas the number Marginal likelihood -187.2 -33.1 -36.7 -31.8 Predictive error 3.7 5.8 6.4 5.2 Training cost 430.9 53.5 76.1 28.4 Test cost 204.2 35.3 48.4 17.1 Marginal likelihood -476.3 -122.4 -137.2 -98.1 Predictive error 4.5 12.5 13.8 6.8 Training cost 3854.2 983.2 1658.3 1032.4 Test cost 1777.5 542.2 590.2 472.5 Marginal likelihood -255.3 -78.5 -84.3 -65.2 Predictive error 3.8 13.2 10.5 5.3 Training cost 1572.3 665.3 853.2 501.3 Test cost 865.2 388.4 390.3 305.2 Table 2: Performance on three UCI data sets (C: number of classes, N: number of instances). is O ( M 2 NC 3 ) for the multinomial logit Laplace approxima-tion, both with M prototypes. Thus, when the number of classes become larger, SGPS can exhibit better performance.
We further assess the model performance using 15 stan-dard multi-class data sets from the UCI ML Repository 6 . Due to space limitations, we only report 3 data sets here. We randomly select 60% of the data for training and the rest 40% for test. The experiment is repeated 50 times and we report the average. The experimental results with means and standard deviations can be found in Table 2.

The predictive error of SGPS is consistently lower than the competitors. Meanwhile, our model requires less time to train and make predictions. For larger data sets (e.g., letter and pendigits), SGPS gains much better performance, which indicates a good scalability in practical uses. We also notice that VBGP often outperforms IVM. To justify the effectiveness of our multi-label algorithm MMSG, we empirically analyze its performance using both bench-mark and real-world data. We use SVM struct as the multi-label extension of SVM for comparison 7 . The Reuters2000 data set is employed as a bench-mark. The data contains 800,000 newswire stories, each of which belongs to a subset of 101 categories. The data is stored in TFIDF format with more than 47,000 features. For our ex-periment, we restrict the categories to three: topics, regions and industries . Four standard metrics are used: Precision, Rank Loss, Hamming Loss and One Error [4]. For preci-sion, higher percentage indicates better performance, while for the other three, low scores are generally better.
Table 3 shows that our algorithm has lower performance for all four metrics but is computationally much more effi-cient. A reduction of 13% of the precision required almost 80% less memory. The program run time is reduced from http://mlearn.ics.uci.edu/MLRepository.html http://svmlight.joachims.org/ only M =5% prototypes and outperforms PMM and SVM. 107.3 minutes to 32.5 minutes. We also trained a sparse SVM (denoted as S-S) by using 5% of the data. The result shown here is apparently worse than MMSG.
 Precision 0.69 0.59 0.48 R-Loss 0.26 0.32 0.38 H-Loss 0.25 0.27 0.33 O-Error 0.20 0.30 0.35 Table 3: Multi-label classification results on RCV1. For SVM struct , L 1 -loss function is used. MMSG and S-S use M =5% points for training.
We compare the performance of tag recommendation of our algorithm with two other approaches. We first use SVM to train a multi-label model and use the same ranking func-tion as in eq.(20) to return top ranked tags. We also com-pare to the tag suggestion method using the Poisson mixture model (PMM) [20], which often outperforms other existing tag suggestion methods.
We collected data from del.icio.us and BibSonomy 8 be-tween Oct 15 2007 and Jan 10 2008. For both data sets, we randomly sampled 50 tags from the tag lists. For each tag, we retrieved the content of bookmarks with related tags. A typical instance in our experiment contains title, content and tags. The titles and contents are treated with equal importance here 9 . Overall, the del.icio.us data contains 45,715 unique items with 93,215 words, while BibSonomy has 14,200 items with 37,605 words. The total numbers of tags are 8,792 and 6,321, respectively. Table 4 shows top 10 tags for both data sets.For training, the data is organized into 50 classes. Considering the temporal characteristics of tags, we ordered the data by time and used the earlier data for training and tested on later data. We performed exper-iments with training data from 10% to 90%. Due to space limitation, we only report the results of 50% splitting here. http://www.bibsonomy.org
We performed test by assigning higher weights to titles, with almost same results found.
Tag Name Frequency Tag Name Frequency technology 1543 computing 2294 photography 1375 web 1631 Table 4: Top 10 most popular tags in del.icio.us and BibSonomy with respective frequencies.

We present a summary of the experimental results in Ta-ble 5. Overall, our model is able to boost the tagging per-formance when comparing with PMM and SVM, by roughly 6% and 12% on average. Note that this is efficiently achieved by using only 5% of the training instances.

In addition, we also examined the performance of individ-ual tags by looking at the top 10 suggested tags. We are interested in the difference in performance between popu-lar tags (e.g., web, network, clustering) and rare tags (e.g., asp.net, latex, 3d). For each data set, we chose the top-5 most/least popular tags and averaged the suggesting results. Figure 8 depicts the results. It can be observed that MMSG outperforms PMM and SVM in most cases. The top-most suggested tag for del.ici.ous and BibSonomy from MMSG Figure 9: Comparison of tagging performance of SVM and MMSG. Two covariance functions used: SE = squared exponential, NN = neural network. gains 6% and 4% improvement over PMM for popular tags. While SVM is comparable to MMSG for popular tags, our algorithm shows a clear edge over SVM for rare tags, with more than 18% improvement. Since rare tags appear in fewer documents, this result gives credibility to the claim that MMSG works well with very few training instances. Model Selection for Tag Suggestion
Next we quantitatively show how the model selection re-flects the performance of tag suggestion. In our framework, model selection involves the decision of (1) the number of prototypes, (2) the covariance function and (3) the hyper-parameters. Since the hyper-parameters are often associated with the covariance function and can be chosen by optimiz-ing the marginal likelihood of the training data, we then fo-cus on how (1) and (2) affect the performance. A common covariance function used for classification is the squared ex-ponential function (SE) in eq.(2). An alternative function takes the form of neural network (NN):
K ( x , x )= 2 with  X  x being the augmented vector of the input x .
We compare the results of SVM and our model using these two covariance functions. Figure 9 demonstrates the results on the del.icio.us data (The results on BibSonomy are simi-lar). Wesetthenumberofprototypes M to be 5% , 10% , 20% and 50% respectively. It can be observed that MMSG gener-ally outperforms SVM by roughly 10% at each point. With the number of prototypes increases, the precision also soars up from 50% to 62% for MMSG. Meanwhile, by using neural network as the covariance function, both SVM and MMSG gain about 2% precision at each point. Overall, MMSG-NN shows the best performance.
 Optimal Prototype Selection for Tag Suggestion
To justify the use of the prototype selection (PS) algo-rithm, we compare with the criteria used in [17] which ef-ficiently includes points into the active set based on infor-mation gain (IG). We also include a random selection (RS) method as the baseline. Figure 10 presents the results on del.icio.us. Generally, prototype selection shows better pre-Figure 10: Tagging performance of three selection algorithms. Rand = random selection, Info = infor-mation gain, Proto = prototype selection.

Youtube name of related videos, videos from the \
Table 6: Side information for training the model. cision than IG in all four cases. Specifically, prototype selec-tion gains more than 10% performance improvement com-paring with information gain when M = 50%.
Finally, we also show the power of MMSG on tagging digital data by using surrounding textual information. We acquired data from Flickr and Youtube between Sep 15 2007 and Oct 21 2007, by subscribing to their RSS feeds of the top 30 most popular tags respectively. We then re-crawled each individual URL in the feeds to get the needed side in-formation listed in Table 6. Overall, the Flickr data contains 22,186 unique items with 10,341 tags whereas Youtube has 2,489 items with 6,724 tags.

For training, the data is organized into 30 classes. Over-all, the test results indicate a promising performance. On average, MMSG achieves a 41.6% precision for the two data sets, outperforms PMM and SVM by 5% and 9% respec-tively. Figure 11 lists several examples with good tagging results by our algorithm. For individual tags, the top-most suggested tags for Flickr have a 56.2% accuracy, compared with a 48.2% accuracy for PMM. Likewise, the top-most tags have 48.2% accuracy for Youtube, 2.3% better than PMM.
Since our algorithm for tag suggestion only leverages tex-tual information, for an image/video without any support-ing texts, our algorithm performs no better than a random guess. But since textual information is usually cheap and abundant, our algorithm can serve as a good complement for the content-based approach for digital tagging services.
We presented a sparse GP framework for multi-class tag classification. The framework was generalized for multi-label classification for tag suggestion. In particular, we gen-erated real-time tag suggestions for Del.icio.us, BibSonomy, Flickr and Youtube. Numerous experiments suggested that our method is capable of making good tag suggestion with little training data. Our model successfully outperformed the best tagging algorithm so far [20]. Future work could ac-cess how this framework can be extended to semi-supervised tag suggestions and investigate the issue of selecting the op-timal number of prototypes f or the sparse GP framework. Statistical significance tests will be performed to examine the generalization of our methods to other data sets.
