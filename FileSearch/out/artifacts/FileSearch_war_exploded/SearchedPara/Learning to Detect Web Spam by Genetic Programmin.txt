 With the explosive growth of information on the web, search engine has become an ranking is highly important in the search engine design. So some techniques are em-ployed to enable some web pages or sites to achieve undeserved relevance and impor-are generally referred to as Web spam [1]. People who make spam are called spam-mers. A spam page is a page that is either made by spammer or receives a substantial amount score for its ranking from other spam pages. Web spam seriously deteriorates search engine ranking results. Detecting web spam is considered as one of the top challenges in the research of web search engines. Web spam can be broadly classified into term (content) spam and link spam [2]. Term spam refers to deliberate changes in the content of special HTML text fields in the pages in order to make spam pages relevant to some queries. Link spam refers to unfairly gaining a high ranking on search engines for a web page by means of trickily manipulating the link graph to confuse the hyper-link structure analysis algorithms. Previous work on web spam identification mostly focused on these two categories. 
In the previous research, Ntoulas et al. [3] proposed to detect spam pages by build-ing up a classification model which combines multiple heuristics based on page content analysis. Gyongyi et al. [4] proposed the TrustRank algorithm to separate normal pages from spam. Their work was followed by much effort in spam page link [6], which is the first paper that integrates link and content attributes to build a system to detect Web spam, extracted transformed link-based features with PageRank, Trus-tRank , and Truncated PageRank etc. G. G. Geng et al.[7] proposed a predicted spa-micity-based ensemble under-sampling strategy for spamdexing detection. Within this strategy, many existing learning algorithms, such as C4.5, bagging and adaboost, can be applied; distinguishing information involved in the massive reputable websites were fully explored and solved the class-im balance problem well. Yiqun Liu et al. [8] proposed three user behavior features to separate web spam from ordinary ones. Na Dai et al. [9] used content features from hi storical versions of web pages to improve spam classification. 
However, once a type of spam is detected and banned, usually new Web spam techniques will be created instantly. Therefore to study how to detect Web spam automatically based on machine learning is very meaningful. In this paper we discuss how to detect web spam by Genetic Programming (GP) [10]. Since GP has been used because detecting Web spam is a special binary classification, where Web pages are labeled spam or normal. 
We define an individual as a discriminating function for detecting Web spam. The individuals are evolved based on the feature values of training set of the Web pages. Further the individuals are combined based on GP to generate an optimized discrimi-nant for Web spam detection. We study the key techniques in using GP to detect Web Spam, which include the representation of individual, e.g. the architecture and the GP Web spam and using multi-populations and combination to generate the discriminat-the individual in the GP evolution process and the efficiency of the combination. We carried out the experiments on WEBSPAM-UK2006 to evaluate the validity of the approach. The experimental results show that the new method can improve spam classification recall performance by 26%, F-measure performance by 11%, and accu-racy performance by 4% compared with SVM. 2.1 Individual Representation and Population paper we let an individual be represented as a binary tree. We use two kinds of termi-nals: feature terminals and numeric/constant terminals. Feature terminals are the degree/pagerank and so on. Constants are 11 predefined floating numbers which are 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0. The internal nodes denote the simple arithmetic operations, which include {+,  X  ,  X  ,  X  }. The + ,  X  , and  X  operators have their usual meanings, while  X  represents  X  X  X rotected X  X  division, which is the usual division operator except that a divide by zero gives a result of zero. Although we can use more operators, e.g. log, sin, cos etc al, it is shown that the classification accuracy of using only simple arithmetic operators is sufficient to achieve high accuracy and using sim-ple operators is capable of reducing computation cost [12]. In fact we did the experi-function is better than non-linear function for web spam dataset. Therefore we only use the four arithmetic operators. 
Unlike decision trees that are used in data classification, e.g., ID3, C4.5 [3], GP al-solution in a space of possible solutions. That means that some of the individuals in a population may not be able to detect spam pages accurately, however it is well known since GP can search the space to find an opt imal solution in its evolution process, the with high probability. 
The output of an individual in the standard tree-based GP system is a floating point number. In our approach for web spam detection, a population P is a set of individuals and denoted as } , , , { consider that I recognizes x as spam if 0 ) (  X  x I , otherwise normal. 2.2 The Features of Web Pages Considered in Web Spam Detection The features used in our experiments are the 138 transformed link-based features [7], which are the simple combination or logarithm operation of the link-based features. The 138 features can be divided into five categories: Degree-related features , PageR-ank-related features, TrustRank-related features, Truncated PageRank-related fea-tures and Supporter-related features. 2.3 Mutation Rate and Crossover Rate The genetic operators used in our experiments are reproduction, crossover, and muta-tion. They are performed according to predefined rates R r , R c and R m . The reproduc-tion operator keeps several selected individuals alive to the next generation. It mimics ing two individuals from p , selecting a subtree from each individual randomly and exchanging the two selected subtrees to generate two new individuals. The mutation operator was implemented in such a way that a randomly selected subtree is replaced by a new tree also created randomly. 
Because the mutation operator can generate individuals with new structures that mum. If R m is too high, the population tends to generate diverse individuals instead of discovering solutions from present individuals. If R m is too low, individuals may not have sufficient opportunity to mutate and the diversity is limited. In our experiments, ( R m ,R c ) is initialized to (0.2,0.8). In the g th generation, if the ratio of the fitness value Traditionally, GP works with a single population. Recently it is shown that Multi-population GP (MGP) is better than single GP in terms of finding the optimal solution [14]. Therefore we adopt MGP in finding the optimal discriminating function for detecting spam pages. It is pointed out that it is difficult to know the proper length of an individual before finding an optimal solution [13]. Different from the normal defi-number of available nodes of the individual. It is because the definition is more suit-Since a long function can be viewed as a composition of a number of small GP solu-tions, we generate an optimal solution by the combination of sub-solutions, i.e. we make use of multi-populations composed of some small-scale individuals and com-bine the selected best individual in every population to gain better result. 
Table 1 shows an example of the combination where F stands for features and H stands for Hosts. At first, we employ GP with two populations in which the depth of the individual is 3 and get two best discriminative functions F 1 -F 4 (The first best)and F -(F 3 +F 5 )(The second Best). From Table 1, the accuracy of the first best function is 60% and the accuracy of the second best function is 80%, but the accuracy of the As a result, it is likely that the combination might prove effective. The fitness function F( I j ) of an individual I j is denoted by Accu (I j , T) . where T is a data set. The best individual produced by a population P is denoted as BI . The evolution algorithm is a revised basic GP with multi-populations. The Vector Space Model is used to represent every page. We let T denote the training data set, N p be the total number of populations; the number of individuals and the maximum gen-eration of every population are stored in array N[N p ] and G[N p ] respectively; K is the maximum depth of the binary trees which represent the individuals; C is the times of evolution can be described as follows. Algorithm 1 (The evolution for finding the possible discriminating function) Input: T , C , N p , K , N[N p ] , G[N p ] N pc , Nc[N pc ] , Gc[N pc ] of the c th combination(1  X  c  X  C) 
Output: The best individual BI as the discriminating function. randomly generated by the ramped half-and-half method [11]. 
After all individuals in the i th population are evaluated by the fitness function, the algorithm evolves the i th population by applying genetic operators in order to gener-ate the best individual of the i th population. As a result, there are N p individuals. Then instance in T with the above N p individuals as new features, thus all the new instances can make up of a new data set T  X  ; the next step is to rep eat step (1)-(8) according to T  X  and the corresponding parameters N pc , Nc[N pc ] , Gc[N pc ] . We can continue to perform should be assigned to 1 in the last combin ation because we need a possible best dis-should be assigned to 0 and N p should be assigned to 1. 6.1 Data Set In our experiments, we use the publicly available WEBSPAM-UK2006 dataset [15]. cludes 77.9 million pages, correspondi ng to 11402 hosts, among which over 8000 hosts have been labeled as  X  X pam X ,  X  X on-spam(normal) X  or  X  X orderline X . We use the labeled hosts in webspam-uk2006-set1-labels  X  X omainOrTwoHumans.txt and web-spam-uk2006-set2-labels-DomainOrTwoHumans.txt, which can be downloaded from http://barcelona.research.yahoo.net/webspam/datasets/uk2006/, where 4948 hosts are marked normal and 674 hosts are marked spam. We select 470 spam hosts and 500 normal hosts as train set, 204 spam hosts and 300 normal hosts as test set. Each host is presented as a 139-dimensional vector incl uding 138 features and an associated class label. 6.2 Evaluations The evaluations used in our experiments are precision, recall, F-measure and accu-they belong to the target class and negative instances if they do not. Our target class is web spam. The confusion matrix is as follows: where TP represents the number of positive examples that are correctly classified as positive, FP represents the number of negative examples that are falsely classified as positive, FN represents the number of pos itive examples that are falsely classified as negative, TN represents the number of negative examples that are correctly classi-fied as negative. The evaluations are defined as following: tive by the classifier: Recall: the percentage of correctly classified positive examples out of all positive examples: 
F-measure: a balance between Precision and Recall: Accuracy: the percentage of correctly classified examples out of all examples: 6.3 Experimental Results Because of the randomicity of GP process, we perform every experiment 10 times and get the average value of every measure to compare. The experiments shown in Table tively. Their maximum generations are 50, 30 and 20 respectively. Then combinations are employed. The first combination also uses 3 populations. They have 20, 30 and 40 individuals respectively. Their maximum generations are 100, 50 and 50 respectively. The last combination uses 1 population. It has 50 individuals and its maximum gen-eration is 50. 
Table 3 shows the comparison between the linear function and the non-linear func-the linear function is better than the non-linear function. 
In order to present the effect of the depth of the binary tree, we perform experi-average accuracy are the best. When the depth of the tree is 8, the average F_measure is the best, the average accuracy is the second. However from Fig. 1, the running time when the depth of the tree is 8 is six times longer than that of when the depth of the tree is 4. From Fig.1, the running time increases exponentially with the increasing of when we use GP to learn a possible best discriminating function. 
In order to show the effect of the combination, we perform experiments when the number of individuals and the maximum generation are 50. In the experiments of one combination, the parameters are same to those of the experiments shown in Table 3-4 parameters are same to those of the experiments shown in Table 3-4. From Table 5, we can see that compared with the single population GP, the multi-population GP with two combinations can improve spam classification recall performance by 5.6%, F-measure performance by 2.25% and accura cy performance by 2.83%. The experi-mental results (the depth of the tree is 8) in Table 6 further confirm that the combina-tion can improve the classification performance. 
Table 7 shows the comparison between SVM and the multi-population GP with two combinations when the depth of the binary tree is 4(2CGP_4). From Table 7, we can find that 2CGP_4 improves spam classification recall performance by 26%, F-measure performance by 11% and accuracy performance by 4% compared with SVM. The precision of SVM is higher than GP_4, but the recall is too lower. detect web spam. We study the representation of an individual, the features of Web pages that are used to detect Web spam, the effect of the depth of the binary trees in the GP evolution process and the efficiency of the combination. We performed the experiments on WEBSPAM-UK2006 collection. Experimental results show that the method can improve the web spam detection performance effectively compared with SVM. However the method does not detect content spam because only the link based features are used. We also do not consider the problem of class imbalance. 
Future work involves using other proposed features in GP, e.g. the content features, finding better features by GP, considering the problem of class imbalance and propos-ing better classification method to detect web spam. This work is supported by the Natural Science Foundation of China (60970047), the Natural Science Foundation of Shandong Province (Y2008G19) and the Key Science-Technology Project of Shandong Province (2007GG10001002, 2008GG10001026). 
