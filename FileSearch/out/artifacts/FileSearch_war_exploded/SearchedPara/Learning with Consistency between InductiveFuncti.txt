 1 Department of Computer Science &amp; Engineering RLS -related work has the following problem: Over Penalization. For a constant function f = c , a nonzero term || f || diagram in Fig. 1. For such situations, there is an over-pena lization. function f ( x ) and the marginal P the sense that the expected difference on distribution P from this point of view, we name this work. x y while f is over penalized in || f || functions. Let X be a compact domain or manifold,  X  be a Borel measure on X , and K : X  X  X  X  R be a Mercer kernel, then there is an associated Hilbert space RK HS H the corresponding norm ||  X  || H functions on X with the scalar product  X  f, g  X  Given a Mercer kernel and a set of labeled examples ( x where V is some loss function.
 H form: and f ( x ) be an inductive function. We observe that, if ( x the function y = f ( x ) , then A Re-learned Function can be expressed as illustrated in the middle diagram in Fig. 1.
 Throughout this paper, we assume that R are normalized by K/ R compact, and the measure  X  is specified as P ( x ) . For a given kernel K and an inductive function f , L L
K ( f ) To obtain a Representer Theorem, we need one assumption. Assumption 1 Let f || f It is well-known that the operator L and by the Spectral Theorem [2, 3], its eigenfunctions e or there are infinitely many, in which case  X  f and similarly, f if that a  X  f Theorem 2 Let  X  0 } . Under Assumption 1, the minimizer of the optimization prob lem in Eq. (5) is Proof of the Representer Theorem. Any function f  X  H component f nent f and the fact that  X  f f ( x j ) =  X  f, K ( x j ,  X  )  X  =  X  coefficients {  X  It follows that the minimizer of Eq. (5) must have || f representation f  X  ( x ) = f 3.1 Partially-penalized Regularized Least Squares ( PRLS ) Algorithm In this section, we focus our attention in the case that V ( x larized Least Squares algorithm. In our setting, we aim to so lve: By the Representer Theorem, the solution to Eq. (7) is of the f ollowing form: By the proof of Theorem 2, we have f Assumption 1 and the fact that f where  X  = [  X  K  X  L
K ( K ( x i , x )) , L K ( K ( x j , x ))  X  K variable  X  = [  X  where  X  is an l  X  o matrix  X  to In the term || f  X  L 3.2 The PLapRLS Algorithm considered, and Eq. (5) is modified as f  X  = arg min where W the result in Theorem 2 can be modified slightly as: expansion [  X  1 ,  X  2 , . . . ,  X  l + u ]  X  rest 0 , and  X  is an ( l + u )  X  o matrix  X  4.1 Heat Kernels and the Computation of K 0 and K 00 facts about heat kernels are excerpted from [6], and for more materials, see [10]. Given a manifold M and points x and y , the heat kernel K following differential equation on a manifold M : a geometric manifold with initial conditions.
 C all x, y  X  M , with K K R
M K t ( x, y ) f 0 ( y ) dy P K Based on the fact that L 4.2 What should not be penalized? From Theorem 2, we know that the functions in the null space H R functions.
 not be penalized, because c = R kernels, if P ( x ) is uniformly distributed on M , then by Property 4 in Theorem 4, R is a constant, and so c should not be penalized.
 interval X = [0 1] and the uniform distribution on X , R under some distributions. The readers can deduce an example for p ( x ) such that R 1 happens to be a constant.
 Should linear function a T x be penalized? In the case when X is a closed ball B r when P ( x ) is uniformly distributed over B should not be penalized when r is big enough. 1 Since r is big enough, we have R and R Consequently || a T x  X  L be penalized. For other kernels, other spaces, or other P distributed, and so constant functions are considered to be in H linear functions are not considered to be in H diagram in Fig. 1. 5.1 UCI Dataset Isolet about Spoken Letter Recognition obtained with width  X  = 10 ,  X l = 0 . 05 ,  X  the results were obtained with width  X  = 4 ,  X l = 0 . 01 , and  X  corresponding counterparts on both unlabeled data and test set. 5.2 UCI Dataset Letter about Printed Letter Recognition 19,600 examples form the test set. The parameters are set as f ollows:  X  = 1 ,  X l =  X  and  X  heat kernels on a manifold. 5.3 A Counter Example in Handwritten Digit Recognition penalized, then we should use f  X  ( x ) = P l Section 4: if X is compact and R should not be penalized. learning scheme can achieve accuracy improvement in practi cal applications. Acknowledgments
