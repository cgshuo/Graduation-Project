 In stochastic optimization, a decision maker makes a decision and faces a random cost based on that decision. The goal is to choose a decision that minimizes the expected cost using information from previous observations. Stochastic optimization problems with continuous decision spaces have many viable solution methods, including function averaging and stochastic gradient descent [20]. However, in many situations conditions for the previous observations may not be the same as the current conditions; the conditions can be viewed as state variables. There are currently no general purpose solution methods for stochastic optimization problems with state variables, although they would be useful for finance, energy, dynamic pricing, inventory control and reinforcement learning applications.
 We consider the newsvendor problem, a classic inventory management problem, to illustrate existing Here, newspapers can be bought in advance for cost c , and up to D of them can be sold for price p , where D is a random demand; the goal is to determine how many papers should be ordered so as to maximize the expected profit. A state variable that contains information about the random demand may also be included. For example, a rainy forecast may correlate to a lower demand while a sunny forecast may correlate to a higher. A natural solution method would be to partition the previous observations into  X  X ainy X  and  X  X unny X  bins, and then solve the problem for each partition. This essentially models the problem as a single time period Markov Decision Process and solves the problem accordingly [16, 21]. Partitioning methods work when the state space can take a small number of discrete values. Two problems arise with partitioning methods when the state space becomes larger. First, the num-ber of states grows exponentially with the dimension of the state space. If there are 10 attributes, like weather, stock prices, days until an election, etc, and each can take 100 values, then there will be 10 20 individual states. Second, previous observations are sparse over these states; a vast number of observations must be gathered before there are enough to make a reasonable decision for a given state. Rather than partitioning, we propose using observations from  X  X imilar X  states to create a de-terministic decision-expected cost function, also called an objective function, that is conditioned on a particular state.
 Similar methods have been proposed in an approximate dynamic programming setting that use basis functions, such as linear and polynomial predictors, to construct approximate value functions [22, 14]. Basis functions, however, are hard to choose manually and automatic selection is an area of active research [12]. Moreover, basis functions do not guarantee that the approximate objective function is convex in the decision.
 We propose using nonparametric density estimation for the joint state and outcome distribution to group observations from  X  X imilar X  states with weights. These are then used to construct determin-results are a deterministic, convex math program. These can be efficiently solved by a number of commercial solvers, even with very large decision spaces (10 to 1,000+ variables and constraints). We give two methods to construct an approximate objective function using previous observations. The first is a function-based method. In some cases, entire random objective functions can be viewed retrospectively. For example, if the demand is known in the newsvendor problem, then the value of all decisions is also known. In these particular cases, the approximate objective function is mod-eled as a weighted average of the observed functions. The second method is based on stochastic gradients. In some cases, it is not possible to observe entire functions or observed functions may be too complex to manipulate. When this happens, we propose constructing a separable, piecewise linear approximate objective function. A piecewise linear, convex function is created in each deci-sion dimension by generating a slope function from a weighted, order-restricted regression of the gradients, and then integrating that function. The result is an approximate objective function that is not necessarily the same as the original objective function, but one that has the same minima. Both methods depend heavily on weights to capture dependence between the state and the outcome. We propose two weighting schemes: kernels weights and Dirichlet process mixture model weights. Kernels are simple to implement, but Dirichlet process mixture models have certain appealing prop-erties. First, they act as a local bandwidth selector across the state space; second, the weights are generated by partitions rather than products of uni-dimensional weights, so the results scale better to higher-dimensional settings.
 We contribute novel algorithms for stochastic optimization problems with a state variable that work with large, continuous decision spaces and propose a new use of Dirichlet process mixture models. We give empirical analysis for these methods where we show promising results on test problems. The paper is organized as follows. In Section 2, we review traditional function-based and gradient-based optimization methods and in each case present novel algorithms to accommodate an observ-able state variable. We present an empirical analysis of our methods for synthetic newsvendor data and the hour ahead wind commitment problem in Section 4 and a discussion in Section 5. Traditional stochastic optimization problems have the form where x  X  R d is the decision, Z :  X   X   X  is a random outcome, X is a decision set and F ( x,Z (  X  )) is a random objective function [20]. In the newsvendor problem, which we will use as a running example, x is the stocking level and Z is the random demand. Given x and Z (  X  ) , F is deterministic. When a state variable is inlcuded, we first observe a random state S  X  S that may influence F and the distribution of Z , then we make a decision x , and finally we observe the random variable Z . Eq. (1) becomes Traditional stochastic optimization techniques require us to sample from the conditional distribution density estimation for the joint distribution of ( S,Z ) to take into account that similar values of S affect Z and F in a similar way. We now describe new methods for function-based and gradient-based optimization for problems with an observable state variable. 2.1 Function-based optimization with an observable state variable Function-based optimization is used when a single outcome  X  can tell us the value of all decisions given that outcome [19]. For example, in the newsvendor problem, if the demand is known then the value of all inventory levels is known. Function-based optimization relies on sampling a set of scenarios,  X  1 ,..., X  n from  X  , to approximate Eq. (1): Since Eq. (3) is deterministic given  X  1: n , deterministic solution methods can be used. These meth-ods are well developed and are implemented in a variety of commercial solvers.
 When a state variable is introduced, we wish to solve Eq. (2) for a fixed query state s  X  X  . However, observations as in Eq. (3), we weight the observations based on the distance between the query state and the weights may change with the number of observations, n . Set The optimization problem becomes Eq. (5) can be solved with a commercial solver. We discuss weight functions in Section 3. 2.2 Gradient-based optimization with an observable state variable In gradient-based optimization, we no longer observe an entire function F ( x,S,Z (  X  )) , but only a derivative taken at x , Stochastic approximation is the most popular way to solve stochastic optimization problems using a gradient; it modifies gradient search algorithms to account for random gradients [17, 9]. The general idea is to optimize x by iterating, at x n and a n is a stepsize. Other approaches to gradient-based optimization have included construc-tion of piecewise linear, convex functions to approximate F ( x ) in the region where x is near the optimal decision, x  X  [15].
 function-based optimization. We run into difficulties because we choose x n given S n . When we is not trivial because the stochastic gradients depend on both x n and S n .
 Therefore, we propose modeling F ( x | s ) with a piecewise linear, convex, separable approximation. Even if F ( x | s ) is not itself separable, we aim to approximate it with a simpler (separable) function that has the same minimum for all fixed s . Approximating the minimum is easier than approximating the entire convex function [4, 15]. Moreover, convex regression is easier in one dimension than multiple dimensions. We approximate E [ F ( x,s,Z )] by a series of separable functions, Unlike the function-based method, the gradient-based method is a fundamentally online algorithm: x n is used to choose x n +1 . Given S n , we choose x n as follows, dient observations,  X   X  1: n . We use weights to group the gradients from states  X  X imilar X  to S n and a tions x k [0] ,...,x k [ n  X  1] , and then solve to find slopes for the decision-ordered space, for constructing  X  F n ( x | s ) is as follows: Details are given in the supplementary material. We now discuss the choice of weight functions. Like the choice of step size in stochastic approximation, the choice of weight functions in Eqs. (4) and (8) determines whether and under which conditions function-based and gradient-based opti-mization produce acceptable results. Weighting functions rely on density estimation procedures to density estimation weights observations from a joint distribution to create a conditional distribution. process mixture models. 3.1 Kernel weights Kernel weights rely on kernel functions, K ( s ) , to be evaluated at each observation to approximate the conditional density. A common choice for K with continuous covariates is the Gaussian kernel, K applicable weighting scheme is based on the Nadaraya-Watson estimator [10, 23]. If K ( s ) is the kernel and h n is the bandwidth after n observations, define Kernel estimators require a well sampled space, are poor in higher dimensions and highly sensitive to bandwidth size [5]. 3.2 Dirichlet process weights One of the curses of dimensionality is sparseness of data: as the number of dimensions grows, the distance between observations grows exponentially. In kernel regression, this means that only a handful of observations have weights that are effectively non-zero, producing non-stable estimates. Instead, we would like to average responses for  X  X imilar X  observations. We propose modeling the distribution of the state variable with a Dirichlet process mixture model, which is then decomposed into weights.
 Dirichlet process mixture models. A mixture model represents a distribution, g ( s ) , as a weighted p is the mixing proportion for component i . We can use a Dirichlet process (DP) with base measure G 0 and concentration parameter  X  to place a distribution over the joint distribution of ( p i , X  i ) , the mixture proportion and location of component i [6, 1]. Assume that data S 1 ,...,S n are iid with a distribution that is modeled by a mixture over distribution G (  X  ) , The distribution P drawn from a Dirichlet process is an almost surely discrete measure over param-eters, with the mixture proportion associated with  X  as the atomic weight. The hidden measure P in Eq. (9) can be integrated out to obtain a conditional distribution of  X  n |  X  1: n  X  1 [3] Here,  X   X  is the Dirac measure with mass at  X  . Eq. (10) is known as a Polya urn posterior; the variable  X  n has positive probability of assuming the value of one of the previously observed  X  i , but it also can take a new value drawn from G 0 with positive probability. The parameter  X  controls how likely  X  n is to take a new value. We now discuss how weights can be constructed from Eq. (9). Dirichlet process mixture model weights. A Dirichlet process mixture model can be used to model an unknown density, but it can simultaneously be used to produce a distribution of the parti-tion structure of observed data [13, 8]. This is shown in the Polya urn posterior of Eq. (10); each hidden parameter has positive probability of taking the same value as another parameter. If two hidden parameters have the same value, they are in the same partition/cluster. The partition structure induces weights on the observations, proportional to 1 if they are in the same cluster, 0 if not. that we know the partition p . Given p , we include the query state s into cluster C i with probability tioned on G 0 and the set of observations { S j : S j  X  C i } . Given p , the weighting function is the probability that the hidden parameter for s would be  X  i , the hidden parameter for S i , Eq. (11) is conditioned on a partition structure, but the Dirichlet process produces a distribution over Integrating of the partition posterior, we obtain unconditional weights, It is infeasible to integrate over all of the partitions; therefore, we approximate Eq. (12) by per-( p (9) with Gibbs sampling [11]. 4.1 Multi-product constrained newsvendor problem A multi-product newsvendor problem is a classic operations research inventory management prob-lem. In the two product problem, a newsvendor is selling products A and B . She must decide how much of each product to stock in the face of random demand, D A and D B . A and B can be be bought about D A and D B . The problem is, We generated data for Problem (13) in the following way. Demand and two state variables were generated in a jointly trimodal Gaussian mixture.The following methods were compared. Function-based with kernel and Gradient-based with kernel. Bandwidth is selected according to min(sd, interquartile range/1.349) [7].
 Function-based with DP and Gradient-based with DP. We used the following hierarchical model, Posterior samples were drawn using Gibbs sampling with a fully collapsed sampler run for 500 iterations with a 200 iteration burn-in with samples taken every 5 iterations.
 Optimal. These are the optimal decisions with known mixing parameters and unknown components. Results. Decisions were made under each regime over eight sample paths; 100 test state/demand pairs were fixed and decisions were made for these problems given the observed states/decisions in the sample path for each method. Results are given in Figure 2. The kernel and Dirichlet pro-cess weights performed approximately equally for each method, but the function-based methods converged more quickly than the gradient-based methods. 4.2 Hour ahead wind commitment In the hour ahead wind commitment problem, a wind farm manager must decide how much energy to promise a utility an hour in advance, incorporating knowledge about the current state of the world. The decision is the amount of wind energy pledged, a scalar variable. If more energy is pledged than is generated, the difference must be bought on the spot market, which is expensive with a price that is unknown when the decision is made; otherwise, the excess is lost. The goal is to maximize expected revenue. The observable state variable is the time of day, time of year, wind history from the past two hours, contract price and current spot price, W i  X  1 = wind speed an hour ago, W i = current wind speed, are not known until the next hour. We used wind speed data from the North American Land Data As-similation System with hourly observations from 2002 X 2005 in the following locations: Amarillo, TX. Latitude: 35.125 N, Longitude: 101.50 W. The data have strong daily and seasonal patterns. The mean wind level is 186.29 ( m/s ) 3 with standard deviation 244.86. Tehachapi, CA. Latitude: 35.125 N, Longitude: 118.25 W. The data have strong seasonal patterns. The mean wind level is 89.45 ( m/s ) 3 with standard deviation 123.47.
 Clean spot and contract price data for the time period were unavailable, so contract prices were generated by Gaussian random variables with a mean of 1 and variance of 0.10. Spot prices were generated by a mean-reverting (Ornstein-Uhlenbeck) process with a mean function that varies by time of day and time of year [18]. The data were analyzed separately for each location; they were divided by year, with one year used for training and the other three used for testing. The following methods were compared on this dataset: Known wind. The wind is known, allowing maximum possible commitment, x i = W i +1 (  X  i +1 ) . It serves as an upper bound for all of the methods. Function-based with kernel. Function-based optimization where the weights are generated by a Gaussian kernel. Bandwidth is selected according to the  X  X ule of thumb X  method of the np package for R, h j = 1 . 06  X  j n  X  1 / (4+ d ) , where  X  j is defined as min(sd, interquartile range/1.349) [7]. Function-based with DP. Function-based optimization with Dirichlet process based weights. We model the state distribution with the following hierarchical model, distribution over the unit sphere; the dispersion parameters,  X  D and  X  Y , are hyperparameters. The base measure was Normal-Inverse Gamma for P C i , P S i , W i and W i  X  1 and uniform for the means of T i and T all conjugate dimensions after a 1,000 iteration burn-in and 10 iteration pulse between samples. Ignore state. Sample average approximation is used,  X  F n ( x | s ) = 1 n P n  X  1 i =0 Y i +1 ( x ) . percentages of Known Wind for the other three methods. Both forms of function-based optimization outperformed the algorithm in which the state variable was ignored by a large margin (  X  45% of the best possible value). Dirichlet process weights outperformed kernel weights by a smaller but still significant margin (5.6 X 8.2% of best possible value). We presented two new methods to solve stochastic optimization problems with an observable state variable, including state variables that are too large for partitioning. Our methods make minimal as-sumptions. They are promising additions to areas that rely on observational data to make decisions under changing conditions (energy, finance, dynamic pricing, inventory management), and some communities that make sequential decisions under uncertainty (reinforcement learning, stochastic programming, simulation optimization). Our methods can accommodate much larger state and de-cision spaces than MDPs and other table lookup methods, particularly when combined with Dirichlet process mixture model weights. Unlike existing objective function approximation methods, such as basis functions, our methods provide convex objective function approximations that can be used with a variety of commercial solvers.
 Acknowledgments The research was funded in part by the Air Force Office of Scientific Research under AFOSR con-tract FA9550-08-1-0195, and the NSF under grant CMMI-0856153. David M. Blei is supported by ONR 175-6343, NSF CAREER 0745520, AFOSR-09NL202 and the Alfred P. Sloan foundation. [1] Antoniak, C. E. [1974],  X  X ixtures of Dirichlet processes with applications to Bayesian non-[2] Bennett, K. P. and Parrado-Hern  X  andez, E. [2006],  X  X he interplay of optimization and machine [3] Blackwell, D. and MacQueen, J. B. [1973],  X  X erguson distributions via Polya urn schemes X , [4] Cheung, R. K. and Powell, W. B. [2000],  X  X HAPE-A stochastic hybrid approximation proce-[5] Fan, J. and Gijbels, I. [1996], Local Polynomial Modelling and Its Applications , Chapman &amp; [6] Ferguson, T. S. [1973],  X  X  Bayesian analysis of some nonparametric problems X , The Annals of [7] Hayfield, T. and Racine, J. S. [2008],  X  X onparametric econometrics: The np package X , Journal [8] Ishwaran, H. and James, L. F. [2003],  X  X eneralized weighted Chinese restaurant processes for [9] Kiefer, J. and Wolfowitz, J. [1952],  X  X tochastic estimation of the maximum of a regression [10] Nadaraya, E. A. [1964],  X  X n estimating regression X , Theory of Probability and its Applications [11] Neal, R. M. [2000],  X  X arkov chain sampling methods for Dirichlet process mixture models X , [12] Parr, R., Painter-Wakefield, C., Li, L. and Littman, M. [2007], Analyzing feature generation for [13] Pitman, J. [1996],  X  X ome developments of the Blackwell-MacQueen urn scheme X , Lecture [14] Powell, W. B. [2007], Approximate Dynamic Programming: Solving the curses of dimension-[15] Powell, W. B., Ruszczy  X  nski, A. and Topaloglu, H. [2004],  X  X earning algorithms for separa-[16] Puterman, M. L. [1994], Markov decision processes: Discrete stochastic dynamic program-[17] Robbins, H. and Monro, S. [1951],  X  X  stochastic approximation method X , The Annals of Math-[18] Schwartz, E. S. [1997],  X  X he stochastic behavior of commodity prices: Implications for valua-[19] Shapiro, A., Homem-de Mello, T. and Kim, J. [2002],  X  X onditioning of convex piecewise linear [20] Spall, J. C. [2003], Introduction to stochastic search and optimization: estimation, simulation, [21] Sutton, R. S. and Barto, A. G. [1998], Introduction to reinforcement learning , MIT Press Cam-[22] Tsitsiklis, J. N. and Van Roy, B. [2001],  X  X egression methods for pricing complex American-[23] Watson, G. S. [1964],  X  X mooth regression analysis X , Sankhy  X  a: The Indian Journal of Statistics,
