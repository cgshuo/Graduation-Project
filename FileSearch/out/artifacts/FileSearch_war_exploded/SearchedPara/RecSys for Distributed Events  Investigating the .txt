 Distributed events are collections of events taking place within a small area over the same time period and relating to a sin-gle topic. There are often a large number of events on offer and the times in which they can be visited are heavily con-strained, therefore the task of choosing events to visit and in which order can be very difficult. In this work we in-vestigate how visitors can be assisted by means of a recom-mender system via 2 large-scale naturalistic studies ( n =860 and n =1047). We show that a recommender system can influence users to select events that result in tighter and more compact routes, thus allowing users to spend less time travelling and more time visiting events.
 H.3.3 [ Information Storage and Retrieval ]: Information search and retrieval X  Information filtering Mobile Assistance System, Distributed Events, Recommender
A distributed event is a collection of smaller, single events occurring at the same day and conforming to one overarching theme. Such events are growing in popularity all over the world. Well known examples include the Cannes Interna-tional Film Festival and the Edinburgh Festival Fringe. Typ-ically, the events are geographically (e.g. throughout a city) and temporally (e.g. during an evening) dispersed. While variety is the biggest selling point of these events, making the decision of which sub-events to visit is not straightfor-ward. Visitors have to discover which events are on offer and select a small subset from a list of hundreds that they find appealing. This decision depends on factors such as user preferences, time constraints, the location of the event and transport connections [5]. As a result of the sheer choice, people often feel overloaded and rely on tips from friends and on serendipitous discovery [6].

Recommender systems (RS) present a possible solution for narrowing down the amount of events visitors have to consider whilst still taking personal preferences into account. Recommenders have been explored in several domains e.g. e-commerce or leisure [3, 1]. However to the best of our knowledge no evaluation of RS in this particular type of leisure event domain exists. In this work we examine how different RS perform in the context of 2 distributed events. Specifically, we investigate how RS affect the events and routes users choose. The main contributions are: Our test collection is derived from transaction logs from an Android application developed for the Long Night of Music 2012 (LNMusic) and the Long Night of Munich Museums 2012 (LNMuseum). These are large popular events which take place in the city of Munich, where the user has a vast choice of things they can do and limited time to see them. The app offers the user four ways to locate events of inter-est them (browsing by route or topic, free-text search and by way of recommendations). Each feature has a separate tab as depicted in Figure 1:left. We focus here on the first tab ( Recommender ) which offers personalized recommenda-tions to the user, generated from a hybrid system com-bining content-based and collaborative filtering algorithms. Content-based algorithms require a user-profile, which can be specified via a slider interface to indicate interest in dif-ferent music genres (LNMusic) or topics (LNMuseums). For the collaborative filtering algorithm, the user profile consists of all the events the user has already selected. The ratings of all users are transferred to a central server that calculates a user-specific model and sends it back to the client. The 15 (as yet unrated) events with the highest scores from the RS are shown to the user. These events are also highlighted if they appear in the other tabs. Events can be rated in 3 ways:  X  X on X  X  want to visit X ;  X  X ould like to visit, if it fits into the route X ;  X  X ant to visit in any case X . For the RS we reduced these options into a binary rating: dislike event and like event.

Once the user has indicated the events they would most like to visit, the system creates an itinerary for the evening Figure 1: Event browser with recommender tab (left) and map screen with the planned route (right) containing a subset of the selected events, accounting for constraints such as start and end times of events and travel time between events based on public transport routes and schedules. This further processing of the selected events distinguishes our RS from typical RS problems.
 Both apps were available for download from the Google Play Store and advertised on the official LNMusic and LN-Museums web page. We recorded all interactions with the app from 860 and 1,047 users. This included tab changes, tour/event genre/topic selection, click-throughs, generated tours, modifications to tours, as well as all event ratings sub-mitted. In total we obtained 4,973 ratings (1,568 neg./3,405 pos.) for the LNMusic and 10,992 ratings (4,145 neg./6,847 pos.) for the LNMuseums. We use these ratings as a basis for the offline experiments described in the following section.
To ascertain which RS performs best in recommending events to visitors, we compare 6 different systems against each other as well as various combinations of these: 1. Random . Simply assigns a uniformly distributed score 2. Popularity . Each event is assigned a score relative to 3. Content-based (CB) . RS which uses the similarity be-4. SVD -based collaborative filtering algorithm which uses 5. BLITR . A modern, state-of-the-art collaborative fil-6. Temporal (Temp) -derived from a metric developed Table 1: Recall of different RS, offline evaluation. Evaluation. Our initial offline experiments are based on data from the LNMusic, which influenced our choice of rec-ommender for the online study for the LNMuseums (Section 4). We also include offline experiments with the LNMuseums data to allow online and offline results to be fairly compared.
To mitigate against the cold-start problem, we consider only users with 10 or more ratings (132 users on the LNMu-sic, 274 users on the LNMuseums) and run a 5-fold cross-validation [2]. Ratings for a user are chosen as test data with 20% probability, the remaining being used as training data. As some of the chosen algorithms are non-deterministic, we ran each of the tests 30 times and took the mean perfor-mance. Of the recommendations generated, we took the 15 highest scoring events and calculated the recall of these with respect to the test data. Recall was chosen as the evaluation metric as it best fits our application domain: Binary ratings render RSME, MAE or similar measurements of closeness between predicted score and actual user rating unsuitable. Ranking-based evaluation approaches are also inappropri-ate in this setting as only 15 recommendations are shown, meaning that all listed events are likely to be viewed.
The first section of Table 1 shows a summary of the recall performance of the RS listed above. The results were gen-erally (except for Temp ) better on the LNMuseums than on the LNMusic. This might be caused by the lower number of events and event locations available on the former (174 vs. 204 events, about 100 vs. 120 event locations). Popular-ity outperforms the other systems by a large margin. This is likely a result of the Zipf-like distribution of event popu-larity (being measured by the number of positive ratings). Despite this high level of performance, we don X  X  investigate this approach further because: 1) it does not deliver a per-sonalized recommendation (meaning all users get the same
Travel time is a much more crucial factor than distance [5].
To allow comparison this value is normalized by the number of events recommendations), 2) because our app offers other means of accessing popular events (e.g. the search tab) and 3) it is best to remove bias towards popular items [7]. While such bias is typical of RS, it is not favorable since it lessens serendipity and recommendations from the  X  X ong Tail X  are considered more valuable.

Of the two collaborative filtering algorithms SVD has a strong lead over BLITR . This contradicts what is reported in [2] where BLITR achieved a superior level of performance for the GroupLens dataset. We think that this might depend heavily on the amount of data as the GroupLens dataset used in [2] is a few orders of magnitude larger (about 10,000 vs. 10 million ratings). Lack of data can cause issues with the convergence of the Gibbs sampler.

CB aligns itself between the two collaborative filtering al-gorithms. Since this RS uses an explicitly stated user profile, it depends on the number of people entering their interests. On the LNMusic and on the LNMuseums this was only the case for 62.6% and 41.1% of the users.

Contrary to the other RS, Temp achieved better perfor-mance on the LNMusic than on the LNMuseums. This might be because on the LNMuseums more events take place at the same location, thus making location a less discrimi-native feature.

Hybrid RS. To increase the performance of RS a widely used technique (especially for event recommendations [1]) is to combine different approaches. We therefore ran a study with pairwise combinations of the above RS with the same evaluation method as before. There are many possible tech-niques for combining RS of which we chose the following: A weighted combination of the scores of two RS and a dy-namic weighting of the two RS based on the richness of the user-profile available to each RS. This dynamic weighting was chosen for combinations of CB and the collaborative fil-tering algorithms ( SVD and BLITR ). The weight of CB is determined by looking at how diverse the different dimen-sions of the profile vector are. The weight of the collabo-rative filtering algorithms is based on how many events the user has already selected. Figure 2: Structure of the hybrid recommender
Table 1:bottom shows the most interesting combinations of RS and their performance. Additionally we added a com-bination of three RS (see Figure 2): CB , one of the collab-orative filtering approaches and Temp . These results show that, in almost all cases, a combination of RS delivers better recall performance than those RS on their own.

Again, the difference between the two nights with respect to recall performance is obvious. However, when comparing different weights for a certain RS combination no large dif-ferences were found. The dynamic weighting increases the performance when combining CB with SVD but not when combining CB and BLITR . The dynamic weighting of CB and BLITR is still useful as it serves to alleviate the cold-start problem of new users having only a few ratings. Com-bining a RS with Temp has little effect, only a slight per-formance loss, if any, is noticeable. This is also true when comparing CB on its own with a combination of CB , one of the collaborative filtering algorithms and Temp . This sug-gests that while the TC of visited events is a major concern for visitors [5], our users do not seem to consider it when selecting events.
Helping users find events of interest to them is one part of our system, but our app goes beyond that and assists in the creation of routes throughout the evening. Thus, predicting whether or not a user will find an event interesting, as we did in Section 3, is only modelling a part of the problem. Arguably more important measures of system performance are whether or not recommended events appear in routes generated for the user and the properties of these routes. In this section we describe a classical A/B-Test with three different RS on the LNMuseums to evaluate these aspects: SysA -a classical RS 3 , SysB -which considers Temporal Contiguity (TC) and SysC -which is strongly influenced by TC (see Table 2). Users were randomly assigned to one of the three test groups resulting in 321, 355 and 371 users being allocated to the 3 systems.

We evaluate three aspects of performance in the online study:
User acceptance of recommendations was determined by counting how many events users selected (from all tabs) that had been recommended by the system (and thus high-lighted in the GUI). Users of SysA selected 35.6% (586 of 1,645) of highlighted events, whereas users of SysB and SysC selected only 33.9% (616 of 1818 events) and 32.1% (682 of 2123 events) respectively. These results show a significant difference 4 ( p =0 . 024) between SysA and SysC , indicating that weighting temporal contiguity higher resulted in lower user acceptance in the online study. A possible explanation is that users of SysA had more trust in the system, some-what contradicting the results of the offline study where all 3 systems had similar performance.

Probability of appearing in route is a means to in-vestigate if and how recommendations were actually used. As users could initiate multiple route generations we con-sidered the set E route of events which appeared in any of the generated routes. We then calculate the ratio of events selected by a user E sel that are in his/her E route set. The results of the three RS evaluated by this metric is depicted in the second column of Table 2.

Based on this metric we can see that the systems which include TC return better performance, comparing SysA and SysB this difference is significant ( p =0 . 029). Overall, con-sidering TC improves the chance of a selected event being included in the generated route by more than 3%. This find-ing seems to contradict the previous result where SysA had higher levels of acceptance.
Due to technical reasons we used BLITR instead of SVD though the later performed better in the offline evaluation.
Using a two-tailed test of population proportion
Examining Route properties shows how routes vary with different RS, for this we investigate 2 sets of generated routes. The first set considers all routes generated contain-ing at least 2 events ( n =960). The second looks at all routes that are based on a set consisting of more than 50% recom-mended events, as these likely reflect users who trust the RS ( n =419). We use the following route metrics which best rep-resent what visitors reported as important criteria to ensure a positive experience for distributed events [5]: Results for the three studied RS are shown in Table 2. When comparing the RS based on all route generations SysC per-forms best. Comparing generated routes based on more than 50% recommended events the two RS which consider TC consistently perform better, with SysB performing best over all three metrics. Regarding TC, SysB significantly ( p 0 . 01) outperforms SysA (by nearly 25%), reducing the necessary travelling time between events from 28 min to 21 min. Users who were allocated to SysB also had on aver-age an additional third of an event more in their generated routes, which is significant ( p =0 . 038). When looking at the proportion of time between visiting events and travelling, use of SysB results in nearly 5% more time spent at events, which is also highly significant ( p 0 . 01). Comparing TC and event time ratio between SysA and SysC also reveals significant differences ( p =0 . 011 and p =0 . 014), although no significant difference is observed for the number of events in the plan.

Based on these results, it seems that users have less faith in RS which account for TC. Nevertheless, users who accept recommendations from such systems are rewarded in that they can select fewer events, as their probability to be in-cluded in the generated routes increases. Furthermore, they will be given compact routes that contain more events, de-creased travelling times and increased time spent at events.
In this work we have compared a number of different rec-ommender algorithms for use within apps designed to as-sist users during distributed leisure events. We first ran an offline comparison based on previously acquired event ratings and tested a number of combinations of these rec-ommenders. We were particularly interested in the impact of temporal contiguity on the results, since this was deter-mined to be an important factor for visitors to such events. The results of the offline study showed that combining rec-ommenders produces good results, however that the level of TC appears to have little impact. Out of these we se-lected 3 promising approaches for an online study, two of which include the TC-based RS as a component, but with different weights. In contrast to the offline study, where all 3 systems performed similarly, in the online study the user acceptance decreased when TC was given a higher weight in recommendations. This also contradicts the usefulness of the recommended items: In the online study the greatest probability of an event being included in a route was when it was recommended by a RS accounting for TC. Consider-ing the generated routes, both RS factoring in TC resulted in better routes as measured by the three introduced met-rics: TC, number of events in the generated route and time spent at events. The third RS performed best when consid-ering all generated routes, although not significantly. When concentrating on route generations with more than 50% rec-ommended events, the second RS performed best, with a significant lead compared to the RS not considering TC.
In conclusion, it is indeed possible to influence users in a way that helps them to achieve a goal they state as being important (see [5]) but perhaps don X  X  consider yet when rat-ing events: Compactness of the generated route. This might be caused by the different objectives users want to achieve when visiting a distributed event: Events should be inter-esting, diverse and also make a tight plan feasible. The last objective might be too complex to consider when browsing the available events. This is also expressed in some of the comments about our app, where users asked for a small map to be shown along with the description of each event. We interpret this as a wish for assistance to help them finding contiguous events. However, we doubt such a map would be helpful in this case as spatial contiguity and TC are two very different concepts for people visiting distributed events (see [5]).

In future work we want to further study the optimal bal-ance between an interest-based RS and an approach consid-ering TC. The metrics used in this paper could be further improved by considering not just the routes generated, but also the actual events visited.
