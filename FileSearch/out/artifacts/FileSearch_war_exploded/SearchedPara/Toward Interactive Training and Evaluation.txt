 Machine learning often relies on costly labeled data, and this impedes its application to new classification and infor-mation extraction problems. This has motivated the devel-opment of methods for leveraging abundant prior knowledge about these problems, including methods for lightly super-vised learning using model expectation constraints. Building on this work, we envision an interactive training paradigm in which practitioners perform evaluation, analyze errors, and provide and refine expectation constraints in a closed loop. In this paper, we focus on several key subproblems in this paradigm that can be cast as selecting a represen-tative sample of the unlabeled data for the practitioner to inspect. To address these problems, we propose stratified sampling methods that use model expectations as a proxy for latent output variables. In classification and sequence labeling experiments, these sampling strategies reduce ac-curacy evaluation effort by as much as 53%, provide more reliable estimates of F 1 for rare labels, and aid in the speci-fication and refinement of constraints.
 I.2.6 [ Artificial Intelligence ]: Learning Algorithm, Experimentation, Measurement, Performance interactive training, stratified sampling, evaluation, lightly supervised learning
Machine learning often relies on costly labeled data, and this impedes its application to new classification and infor-mation extraction problems. However, even in the absence of labeled data we typically have a wealth of prior knowl-edge about these problems. For example, when extracting information from research papers, we know that the word ACM should usually be part of a journal or a conference . Though this knowledge does not yield labeled data, it does provide a desirable aggregate property of predictions for un-labeled data. Several methods incorporate such properties into learning by encoding them as constraints on the expec-tations of a probabilistic model [6, 9, 15, 16].

Building on this work, we envision an interactive training paradigm in which users perform evaluation, analyze errors, and specify and refine supervision in a closed loop. In con-trast to active learning [21], in this paradigm the system aids the user in understanding what the model is predicting, and the user leverages this insight to direct the learning process. There are at least two benefits to building this paradigm around methods for learning with expectation constraints. First, expectation constraints provide a flexible and powerful language for users to give feedback to the system. Second, interactive analysis may enable users to specify more accu-rate and useful constraints than would be possible otherwise.
In this paper, we focus on several key subproblems in our interactive training paradigm that can be cast as selecting a representative sample of the unlabeled data for the user to inspect. Specifically, we develop methods to assist the user in performing evaluation at multiple levels of granu-larity, and in specifying and refining constraints. Random sampling can be applied to these problems, but the resulting sample may not be representative. Instead, we develop sam-pling strategies based on stratified sampling [24], a method that has a long history in statistics [17]. In stratified sam-pling, points are grouped into strata, and random sampling is performed within each stratum. If the statistic of inter-est varies across the strata, then stratified sampling yields a lower variance estimator than random sampling. To per-form stratification, we use model expectations as a proxy for latent output variables. In classification and sequence label-ing experiments, these sampling strategies reduce accuracy evaluation effort by as much as 53%, provide more reliable estimates of F 1 for rare labels, and aid in the specification and refinement of constraints.
In contrast to active learning [21], in which the system queries the user, our interactive training paradigm allows the user to provide supervision based on error analysis, which may enable more efficient training. Our interactive paradigm and active learning with expectation constraints [7, 15] could also be combined, allowing a mixture of user-initiated and system-initiated interactions.
There is growing interest in interaction in machine learn-ing, including some work in interactive training and model selection. Huang and Mitchell [10] develop methods for in-teractive clustering, including allowing the user to provide features that indicate cluster membership, assign instances to clusters, or delete clusters. Roth and Small [18] develop interactive feature space construction , in which an annota-tor uses domain knowledge to iteratively modify model fea-tures. Culotta et al. [3] develop a method for interactively correcting errors of Conditional Random Fields (CRFs) [13] using constrained inference. Settles [22] develops an inter-face for interactive training in which users can label both instances and features. Kumar et al. [12] argue for an in-teractive classification framework in which annotation cost and both current and future utility are jointly optimized. In contrast, the proposed paradigm is based on learning with expectation constraints 1 , and assists the user in evaluation, analysis, and the specification and refinement of constraints.
Note that interactive machine learning often refers to learn-ing directly from interactions with the world, for example based on rewards received for taking context-dependent ac-tions [14]. Though we are interested in exploring this direc-tion in future work, in this paper learning is user-directed.
This paper focuses on developing sampling methods for various subproblems in interactive training. These methods are based on stratified sampling, discussed in Section 4.1, and use model expectations as a proxy for latent output variables. Stratified sampling using model predictions has also been applied to address specific evaluation problems in information retrieval [25]. More closely related, Bennett and Carvalho [1] develop a confidence-based stratified sam-pling method for estimating classifier accuracy. In contrast, we apply stratified sampling to rapid evaluation of classi-fiers and structured models trained using expectation con-straints. We propose an extension to the method of Bennett and Carvalho [1] that reduces error in this setting in Sec-tion 5.1. Additionally, we propose a general approach that is also applicable to other problems in interactive training. Alternatives to stratified sampling include methods based on importance sampling [19, 20]. We plan to consider these approaches in future work.
In this paper we train discriminative probabilistic models of output variables y conditioned on observed input vari-ables x . For classification tasks we use logistic regression models, also known as maximum entropy classifiers where  X  are parameters, f are model feature functions, and Z ( x ;  X  ) = P y exp  X  f ( x , y ) is the partition function, which ensures that P y p ( y | x ;  X  ) = 1.
 For sequence labeling tasks, we use first-order linear chain Conditional Random Fields (CRFs) [13] Settl es [22] uses a naive Bayes based method rather than GE (Section 3), but we hypothesize that GE will provide higher accuracy for complex, structured problems, and in settings where constraints have precise target expectations. where Z ( x ;  X  ) = P tition function and T is the sequence length. Inference is performed using the Viterbi and Forward-Backward algo-rithms. For more detail the reader is referred to [23].
Parameters  X  can be estimated to maximize likelihood if labeled data is available. However, we typically have an abundance of knowledge about the tasks we would like to solve that does not come in the form of labeled instances. For example, when extracting information from research pa-pers, we know that the word ACM should usually be part of a journal or a conference . Recently methods have been developed for estimating parameters with such knowledge and unlabeled data [6, 9, 15, 16]. Formally, these methods encode knowledge as preferences about the values of model expectations of constraint features  X  ( x , y ). Given unlabeled data D = { x 1 , . . . , x N } , the model expectation of  X  is In this paper we use the Generalized Expectation (GE) frame-work, though the methods we develop are also applicable to other frameworks such as Posterior Regularization [9]. GE expresses preferences with a score function S that evaluates model expectations of constraint features. A higher score signifies that the model complies with our preferences more closely. To estimate parameters, we solve GE has been applied to both logistic regression models [6] and linear chain CRFs [7, 16] 2 . GE provides a flexible and powerful framework for users to give feedback to the system during interactive training. Understanding the details of GE is not critical to understanding this paper, so for additional detail the reader is referred to the aforementioned papers.
As in previous work [6, 7, 16], in this paper we predom-inantly use input feature label distribution constraints. For text classification tasks, these constraints specify a target distribution over labels for documents that contain a par-ticular word. For sequence labeling tasks, these constraints specify a target distribution over labels for tokens for which a particular input feature fires. The constraint features  X  are designed so that their expectations are probability distri-butions, and we use the negative KL divergence from some target distribution  X   X  as the score function S . These con-straints can be obtained by having the user  X  X abel X  input features, and converting these labels to target distributions using simple heuristics [6, 7, 16]. For example, a user could label puck as hockey , or ACM as journal and conference .
We conduct text classification and sequence labeling ex-periments. For classification, the data sets are binary sub-sets of the 20 Newsgroups data set used in a previous appli-cation of GE to logistic regression [6]. The model features f ( x , y ) are word counts, after removing stopwords. To make the experiments in this paper more realistic, we use the in-put feature label distribution constraints that users provided in the experiments in [6]. We use models trained with these
Not e that an O ( |Y| 2 ) (rather than O ( |Y| 3 ) [16]) algorithm has been developed for GE training of linear chain CRFs [5]. constraints as starting points for performing interactive eval-uation, error analysis, and refinement. This simulates a sce-nario in which a user specifies constraints to train an initial model, and then improves the model interactively.

We also conduct experiments with the Cora citation ex-traction data set. The task is to extract 13 BibTex-like fields such as title and journal from research paper citations. We use a standard set of word, lexicon, and regular expression features, as well as context features in a window of  X  3 to-kens [7]. We again use input feature label distribution con-straints that were provided by users in previous work [7].
In this paper we aim to develop methods to assist the user in evaluation, error analysis, and the specification and refinement of constraints. We cast these problems as in-stances of the following more general problem: selecting a sample of the data for the user to inspect. In this section we summarize our stratified sampling approach to this problem.
We first review stratified sampling [24], a sampling method we use pervasively in this paper. We assume an iid un-labeled dataset D = { x 1 , . . . , x N } . We aim to compute the mean of a per-instance function r ( x j , y j ) that considers both the input variables and the true values of the latent output variables. To simplify notation in this section we define r j = r ( x j , y j ). The true mean is  X  r  X  = 1 Because the output variables y j are latent, evaluating r is costly. Rather than evaluating r for each instance, we choose a sample S of size n and use it to estimate the mean of r .
The most basic strategy is random sampling , in which n instances are selected uniformly at random from D . The estimate of the population mean is the sample mean  X   X  r
P n j =1 r j . This estimator is unbiased, meaning that the expected value of  X   X  r rs over all possible samples of size n is  X  r . However, when the sample size n is small,  X   X  r rs has high variance. With replacement 3 , the estimated variance of  X  is  X  V ar (  X   X  r rs ) = S 2 n , w here S 2 is the sample variance.
Stratified sampling has a long history in statistics [17]. In stratified sampling, instances are partitioned into m strata {D s 1 , . . . , D sm } , where each x j  X  D appears in exactly one stratum. To obtain a complete sample of size n , for each stratum i , n i instances are randomly sampled ( n = P m i =1 An estimate of the mean of r can be obtained using wher e r j i is r for the j th instance in the i th stratum, W N /N is the weight of the i th stratum, and  X   X  r i = 1 n i s the mean estimate for the i th stratum. This estimator is also unbiased. The estimated variance of  X   X  r ss is where  X  V ar (  X   X  r i ) = S 2 i /n i is the estimated variance of 1  X   X  confidence interval for  X   X  r ss is  X   X  r ss  X  z  X / 2
Wi thout replacement  X  V ar (  X   X  r rs ) = (1  X  n N ) S 2
For a given sample size n , we consider two methods for choosing the number of samples from each stratum. With proportional allocation , the sampling proportions are equal to the weights, n i /n = W i . It can be shown that the true variance of the proportional allocation estimator is lower than the true variance of the random sampling estimator: Equation 1 has implications in stratification, as it shows that the variance reduction is larger when strata means  X  r  X  high variance, or are very different from each other.
The second sample allocation method is optimal alloca-tion . In optimal allocation, per-stratum sample sizes n i not proportional to the size of the stratum. Instead, the idea is to use more samples in strata where r has higher variance. Formally, suppose that the true standard deviations  X  i for each stratum are known. Optimal allocation assigns samples to each stratum using the following equation Opti mal allocation can outperform proportional allocation when the variance of r varies across different strata.
Because the r j are latent, we must select proxy variables to stand in for them to perform stratified sampling. These proxy variables can be used for both stratification and esti-mating strata variances for optimal allocation.
In many applications of interest we need to estimate the means of several functions simultaneously, which we view as estimating the mean of a vector-valued function r instead of a scalar function r . Often a vector-valued function r is required because we are interested in estimating a non-linear function with the sample. A non-linear function is one that cannot be computed as the mean of a function on individual instances in the sample. For example, accuracy is the mean of a function that evaluates correctness on each instance, but F 1 is non-linear, as computing it requires the number of correct, predicted, and true instances in the entire sample. Vector-valued and non-linear functions have implications in stratification, sample allocation, and estimation. Stratification &amp; Sample Allocation: As described in Section 4.1, for scalar r strata should be selected so that stra-tum means  X  r  X  i are much different than the population mean  X  r . In the vector-valued r case, stratification is less straight-forward. Intuitively, the stratification should be helpful for estimating all elements of r , but note that for some non-linear functions certain estimates r i may be more important than others. We simply stratify so that a composite variable, correlated with r , varies across strata. Alternative methods for future study include multi-way [2] and clustering-based stratification. We also perform optimal allocation using the estimated standard deviation of a composite variable.
Estimation: A natural estimator of a non-linear func-estimate of  X r  X  ,  X   X  is not necessarily an unbiased estimate of  X  (  X r  X  ). Computing the variance of  X   X  is not straightfor-ward, as we only obtain one value of  X  from the sample. A general approach is to use re-sampling methods such as jack-kni fing, in which each instance is held out of the sample in turn, providing n different function values that can be used to estimate variance [8]. Jackknife estimates for stratified sampling have also been developed [11].
For each stratified sampling method we propose through-out this paper, we describe four components: the target function , the stratification function , the stratification scheme , and the sample allocation scheme . We next describe these components and our general approach to designing them.
As described in the previous section, in some cases we are not interested in the mean estimates  X   X r , but rather some non-linear function of the estimates  X  (  X   X r ). We refer to the non-linear function  X  as the target function . The target function varies in different applications. In the linear case the target function is the identity function.

The stratification function s computes a proxy value for each instance that can be used for stratification and sample allocation. Though the output variables y are latent, if we have a trained model we do have some information about the values of these variables. Our general approach is to use current model predictions as a proxy for latent output variables y . Specifically, a method we use pervasively is to stratify according to the expectation of some function of interest r  X  (often r  X  = r ) This approach makes the reasonable assumption that model predictions are correlated with the true output variables. This implies that the improvement provided by stratified sampling is bounded by accuracy of the current model.
When estimating a vector of means  X   X r , we take a simple approach and continue to use a scalar stratification function s ( x ), essentially defining a composite variable. One simple strategy is to use the expectation of a single element of the vector: r  X  = r i , s ( x ) = E p (
The stratification scheme takes as input the values com-puted by the stratification function and defines the strata. We use two methods for defining strata, which we discuss in detail in the following sections.

Finally, the sample allocation scheme defines how samples are allocated to strata. If optimal allocation is used, rather than proportional allocation, then a stratum variance esti-mator that defines a procedure for estimating the variance of strata must also be defined. We estimate within-stratum variances by using the sample estimates (for instances that have already been inspected), using model probabilities as a proxy for the latent output variables, or a combination. To use model probabilities, we advocate a simple strategy in which values for the latent output variables are sampled according to the model, r is computed, and the resulting sample variance estimates of r stand-in for true variances.
Note that, in general, inspecting individual instances to estimate a statistic could also yield labeled instances as a by-product. In future work we could perform training using both constraints and labeled instances.
Suppose we have an initial model for the task we would like to solve. Our goal is to interactively improve this model. A natural first step is to come to an understanding of what the model is predicting and how accurate it is, in order to decide where to focus analysis and provide supervision. Im-portantly, we want to do this with minimal effort. In this section we apply stratified sampling to choose sets of in-stances (with model predictions) for manual inspection. For concreteness and to allow thorough validation, we focus on the task of using the sample to estimate a performance met-ric such as accuracy. However, we also suggest that with appropriate adjustments to the sampling scheme, viewing a sample of instances selected by this method would provide accurate representations of other properties of interest.
Note that the methods described here, though motivated by interactive training, could also be used in a non-interactive setting to evaluate lightly supervised learning. This is an im-portant problem on its own, as in a lightly supervised setting there is typically no data available for evaluation.
We first estimate classification accuracy. Formally, we aim to estimate the mean of the correctness indicator function where  X  y is the predicted label,  X  y = argmax y p ( y | x ;  X  ), and 1 { p } returns 1 if the predicate p is true, and 0 otherwise. When computed with the true label, r c returns 1 if the model is correct, and 0 otherwise. We next devise several stratified sampling schemes for estimating  X   X  r c .

Target Function: Classification accuracy is a linear func-tion, as  X   X  r c is an estimate of accuracy. Consequently the target function  X  is simply the identity function  X  (  X   X  r
Stratification Function: Equation 1 suggests that strata should be defined to maximize the variance in individual stratum accuracies. Because the stratum accuracies are un-available, we instead stratify using the expectation of r Equation 2 shows that the model expectation of r c is the probability of the best label, or the model X  X  confidence in its prediction. Note that, using our general approach, we re-cover the stratification function of Bennett and Carvalho [1]. When applied to other tasks in interactive training our ap-proach yields different stratification functions.

Stratification Scheme: We use a uniform size stratifi-cation scheme . First, we sort unlabeled instances according to s c ( x j ). Then, we define strata by splitting the sorted list into m pieces, each containing the same number of instances.
Sample Allocation: Finally, we must allocate samples to the strata. With a uniform size stratification scheme, pro-portional allocation allocates n/m samples to each stratum. We additionally use optimal allocation , where the challenge is estimating the standard deviations in each stratum  X   X 
Bennett and Carvalho [1] propose online stratified sam-pling , in which the  X   X  i are re-estimated using the observed values r j i after each sample. As the number of samples in-creases, the estimates become more accurate, and savings increase. However, a potential disadvantage of this approach is that many samples may be required to obtain estimates that are accurate enough to be beneficial. Because we are especially interested in evaluation with minimal effort, we propose two additional methods for estimating  X   X  i that lever-age model predictions.

We can model each unobserved r j i in stratum i as a Bernoulli random variable c j i with p j i = p ( X  y | x j ;  X  ). Summing all c stratum i yields an expected accuracy random variable with a Poisson Binomial distribution 4 . We can use the variance of this distribution as an estimate of the stratum variance  X   X  i = P j p j i (1  X  p j i ). This method prioritizes strata where there are expected to be a mix of correct and incorrect pre-dictions over strata with expected accuracy near 0 or 1.
As n increases, we expect online stratified sampling to eventually provide better estimates than the above method. Consequently, we propose a novel compromise. In each it-eration, we sample a correctness value for each unlabeled instance c j i  X  p ( y j | x j ;  X  ), and treat these values as pseudo-observations of r j i that are down-weighted by parameter  X  . We then estimate  X   X  i as in online stratified sampling , com-bining the true and pseudo-observations.
We compare approaches for evaluating the accuracy of document classifiers for binary subsets of 20 Newsgroups (see Section 3.1). The classifiers are trained with GE us-ing constraints provided by users in previous work [6].
We compare random sampling ( random ) and stratified sampling approaches that use confidence stratification with m = 5 strata and different sample allocation methods: pro-portional allocation ( pro conf ), optimal allocation using on-line variance estimation ( opt online ) [1], and optimal alloca-tion using the combined confidence and online variance es-timation method ( opt conf online ). We also conduct but do not display experiments with confidence-based optimal allo-cation. In general, opt conf online outperforms this method more as n increases. We begin stratified sampling by allocat-ing two samples to each stratum. For the optimal allocation methods, we reestimate  X   X  i after each sample, and smooth the estimates with 10 pseudo-observations 5 ; for opt online these pseudo-observations are uniform, while for opt conf online the pseudo-observations are sampled correctness val-ues (i.e.  X  = 10 /N i ). To compute estimates of  X   X  r , we reveal the true labels for instances in the sample. We run 1000 tri-als, and report the mean absolute accuracy estimation error.
Figure 1 displays error vs. n . First, note that the strat-ified sampling approaches provide lower mean absolute er-ror than random sampling. We assess significance with a Mann-Whitney U test, the non-parametric counterpart of an unpaired t-test. Of the 216 possible comparisons between random sampling and a stratified sampling method (9 tasks  X  8 different sample sizes  X  3 stratified sampling methods), stratified sampling provides significantly lower error (signif-icance level  X  = 0 . 05) in 209 cases. Random sampling never significantly outperforms stratified sampling. Attaining the same mean absolute error with random sampling would of-ten require significantly more effort. For example, in the med-space task with User 1  X  X  constraints, a sample of size n = 20 using opt conf online gives error of 0.0406. Random attains comparable performance with 30 samples, giving an error of 0.0418. This is a 33% reduction in evaluation effort.
The sum is a Binomial random variable if p is the same for each instance.
We initially smoothed with 1 /  X  n i pseudo-observations as in [1], but this significantly increased error for opt online . We conclude that the accuracy of classifiers trained with GE can be estimated more efficiently using stratified sampling.
Opt conf online provides lower mean absolute error than any other method in 54 of the 72 cases (9 tasks  X  8 sample sizes). Of the 162 reductions in these 54 cases, 133 are signif-icant. Opt conf online significantly outperforms opt online 43 times, and is significantly outperformed by opt online only once. Error analysis reveals that opt online tends to overestimate the differences in variance between strata. Ad-ditional smoothing reduces error with large n , but increases error with small n , as opt online approaches pro conf as the amount of smoothing increases. We conclude that opt conf online is preferable for minimal effort evaluation.
We next propose stratified sampling methods for evaluat-ing token accuracy for sequence labeling models. We esti-mate the mean of the vector-valued function r sc defined where T is the length of the sequence and t indexes positions in the sequence. The function r sc returns the number of cor-rectly predicted labels in the first position, and the length in the second. We describe the components of several stratified sampling schemes.

Target Function: While instance accuracy and average token accuracy are linear, token accuracy is non-linear. To-ken accuracy is defined  X  ta (  X   X r sc ) =  X   X  r sc 0 /
Stratification Functions: We propose two stratification functions. The first is the expectation of r sc 0 . This can be interpreted as the expected number of correct tokens, where p ( X  y t | x j ;  X  ) is the marginal probability of the predicted label at position t . The stratification function s conf is the expectation of a function that returns 1 only if the labeling of the entire sequence is correct. The expectation is the probability of the predicted label se-quence. This can be interpreted as model confidence.
Stratification Scheme: We use the uniform size strati-fication scheme , described in Section 5.1, for this task.
Sample Allocation: We use both proportional and op-timal allocation. In optimal allocation, we allocate sam-ples using estimates of the standard deviation of r sc 0 ( x This is preferable to using the standard deviation of 1 {  X  in the applications we explore here, as complete instance accuracy is low. As in Section 5.1, we use both online es-timation of the variance with the samples, and a combined method. In the combined method, pseudo-observations of token correctness are sampled according to the marginal
We could use the population mean length in place of  X   X  r Stratified sampling provides even larger improvements with this estimator, but the estimates have higher error due to discrepancies between the population mean length and  X   X  r This may result in accuracy &gt; 1, for example. Therefore, in this paper we estimate all arguments to  X  from S . Figure 2: Stratified sampling methods significantly outp erform random sampling for evaluating token accuracy on the Cora data set. probabilities of the predicted labels p ( X  y t | x j ;  X  ), and these pseudo-observations are combined with the labeled sample estimates, as described in Section 5.1. This experiment uses the Cora data set as described in Section 3.1. The model is trained with the constraints pro-vided by User 3 in [7], and an additional constraint with weight 10 that specifies that 80% of transitions between la-bels should be self-transitions. In this task each sequence is a complete citation. To enable precise sampling, we split citations into smaller subsequences. However, using very short subsequences would obscure helpful context, making the user X  X  task more difficult. Consequently, we split cita-tions into subsequences of maximum length 10.

The sampling strategies for this experiment are random , s conf stratification with proportional allocation ( pro conf ), s exc stratification with proportional allocation ( pro ex ), s stratification with online optimal allocation ( opt online ), and s conf stratification with combined optimal allocation ( opt ex online ). We do not report results with s exc strat-ification and optimal allocation. The results are similar to opt ex online , but with higher error. For opt online , we used the same smoothing strategy as [1], which performed better than a fixed value of 10 for this task (the opposite was true in Section 5.2). We did not tune  X  for opt ex online , keep-ing  X  = 10 /N i , giving an advantage to opt online . We use m = 5 strata, and conduct 1000 trials. To simulate rapid evaluation, we use 100-500 tokens (  X  10-50 subsequences).
Figure 2 displays the results. The x-axis is the total num-ber of tokens evaluated. All stratified sampling methods significantly outperform random sampling (Mann Whitney U test with significance level  X  = 0 . 05). Opt ex online out-performs all methods significantly at each point on the graph except for pro conf at 300, and pro conf and opt online at 500. At 200 tokens, the mean absolute error with opt ex online is 0.0309. Random sampling does not attain a com-parable error of 0.0311 until n = 425. This is a savings of 225 tokens, or 53% of total evaluation effort.

In this experiment pro conf outperforms pro ex . Note that s exc  X  T . Error analysis shows that s exc yields strata that are more correlated with T than s conf .
In Section 5, we found that stratified sampling methods can provide significantly more accurate estimates of over-all performance than random sampling. One possible next step in interactive training is to drill down and perform fine-grained evaluation, with the goal of using this information to refine or provide new supervision. In this section, we pro-pose a stratified sampling approach to fine-grained evalua-tion and error analysis. As an example error analysis task, we consider computing token F 1 for a particular label of interest  X  for sequence labeling tasks. This is an important problem because in a particular application some labels may be more important than others. Additionally, awareness of low F 1 for  X  provides a path for improving the model.
The function of interest, r f X  , is defined as In words, the first element is the number of correctly pre-dicted labels whose value is  X  , the second element is the number of predictions of  X  , and the third element is the number of true labels whose value is  X  .

Target Function: The F 1 target function for label  X  is
Stratification Function: The stratification function is the expectation of r f X  2 This can be interpreted as the expected number of  X  tokens.
Stratification Scheme: We again use the uniform size stratification scheme . However, we find that the density of r f X  2 is less uniform than the density of the stratification functions used for overall evaluation. There are often a few x j for which s f X  2 is large, and many x j for which s f X  2 very small. This occurs when  X  is infrequent, for example.
Consequently, we also experiment with non-uniform size stratification. A standard method for determining stratum boundaries is the cum within-stratum variance. Performing stratification accord-ing to the cum i nto k initial sorted classes, where C i denotes the i th class. Next, the cumulative function c of the square root of the class frequencies is computed. The str atum width w is then computed as w = c ( k ) /m . Finally, the initial classes are grouped into strata of equal width w using the cum
Sample Allocation: We allocate two initial samples to each stratum (to enable computing  X  V ar (  X   X  r ss ) if needed), and allocate the remaining samples proportionally. When n = 2 m , thi s can be viewed as optimal allocation with  X   X  i inversely proportional to the stratum sizes,  X   X  i = 1 /N scheme is appropriate because in this setting large strata are likely to have small s f X  2 values, and consequently we expect few occurrences of  X  in those strata.
We use the same data set and initial model as in Sec-tion 5.4. Citations are again split into subsequences of max-imum length 10. To simulate obtaining a rapid estimate of token F 1 for  X  , we evaluate using n = 10 subsequences.
We compare random sampling, sampling proportionally from equal-sized strata using s f X  2 ( ex uniform ), and sam-pling proportionally from strata determined by the cum rul e using s f X  2 ( ex cum cum fixed-width segment of the range of s f X  2 (i.e. one class is all x with s f X  2 ( x )  X  [0 , 0 . 5]). In some cases with k = 20 initial classes less than m of them contain instances  X  empirical evidence of the statement above that the density of s f X  2 be highly non-uniform. In this case we multiply k by 10 iteratively until we have at least m + 1 non-empty classes.
Table 1 reports the results. We evaluate both the mean absolute error in the F 1 estimate ( F 1 err ) and the percent-age of wasted trials ( waste ). A wasted trial occurs when none of the 10 subsequences contain a true occurrence of the label of interest. In this case it is not possible to obtain a meaningful recall estimate 7 . Bold denotes that a method gives the lowest F 1 err or waste . A  X  in the F 1 err column denotes statistical significance (Mann Whitney U test with significance level  X  = 0 . 05).

The ex cum the other methods. In terms of F 1 , it always significantly outperforms random , and significantly outperforms ex uni-form in all cases except title and date . The ex cum me thod also avoids a wasted sample in 1000 trials in all cases except for note . Using non-uniform strata with s f X  2 typically results in a small stratum with instances that are very likely to contain  X  . This greatly reduces waste. However, strati-fied sampling also samples other instances, ensuring that we obtain an unbiased estimate of  X  r  X  even if model predictions are poorly correlated with the true labels. This illustrates the utility of stratified sampling for targeted evaluation.
Thus far we have focused on evaluation and analysis. We now shift our focus to improving the model. Users could specify new constraints manually, or select from candidate constraints [6, 7]. In this section we propose a new paradigm in which the user specifies constraints while inspecting data. For example, after inspecting [ journal : Transactions ] [ title : on Pattern Analysis ] . . . , the user may choose to add new constraints that specify that Transactions should almost al-ways be labeled journal , and that transitions from journal to title are extremely unlikely. This paradigm can help the user specify more accurate constraints, find constraints that are particularly useful, and may suggest constraints to the user that they may not have considered otherwise. Note
Follo wing standard conventions, recall is 1 if there are no true occurrences of  X  in the sample, and precision is 1 if there are no predicted occurrences of  X  in the sample. Table 1: Using n = 10 subsequences to evaluate token that constraints apply to the entire data set, and hence pro-vide more supervision than labeling data [6, 7]. However, in future work we plan to allow both types of supervision. We focus on targeted improvement of the model. In this section we aim to improve token F 1 for a particular label  X  . We can view this as an estimation problem as follows. Based on their prior knowledge, the user has some set of candidate constraints that they are capable of specifying. For each instance, the function r simply returns the number of times each candidate constraint is applicable with respect to the targeted improvement task. Note that computing r is expensive, since the user must manually inspect instances. The user decides which constraints to add based on the mean candidate constraint estimate  X   X r . When applying stratified sampling to improve label  X  , we use the same sample alloca-tion and cum We use the same data set and constraints as in Section 5.4. Initial models are trained with either the full set of 108 constraints or a random subsample of 52 constraints ( small ).
We simulate the specification of new constraints so that we can conduct a large number of trials. To simulate user prior knowledge, we use labeled data to define constraints as in previous work [6, 7, 15]. Candidate constraints include input feature label distribution constraints of the form used in [7] for input features that occur at least 10 times and have label distribution entropy  X  0 . 7. In addition, there are candidate constraints that discourage unlikely label transi-tions 8 . In this experiment unlikely transitions are those that do not occur in the labeled data. Candidate constraints are applicable if they apply to a token with true or predicted label  X  . Any constraint i with  X   X  r i  X  0 is then added. For input feature label distributions, the target distribution is assigned using the  X  X abeling X  method used in [7].

We evaluate the targeted improvement of three moder-ately infrequent labels in the Cora data set: institution , journal , and location . We use n = 10 sub-sequences of length at most 10 to find constraints, and subsequently retrain the model with the augmented set of constraints. Results com-
The probability of taking any transition in the unlikely set is encouraged to be close to 0 using KL divergence. To balance this constraint with the others, its weight is set to the number of labeled feature constraints. Table 2: Using stratified sampling to find new con-paring random and stratified sampling with 100 trials are presented in Table 2. In all cases, stratified sampling yields significantly higher token F 1 for  X  . The improvement is the result of finding additional applicable constraints. While specifying these constraints takes additional time, when  X  is infrequent, we expect finding appropriate constraints to dominate the time required to specify them. As in Sec-tion 6, this method encourages the sample to contain a mix of correct predictions of  X  , false positives, and false negatives. Other sampling strategies do not provide this coverage. For example, uncertainty sampling may miss true occurrences of  X  , and certainty sampling method may miss false negatives.
Input feature label distribution constraints typically use target distributions over labels that are set with simple heuris-tics [6, 7, 16]. It is known that as these target distributions become more precise, the resulting model becomes more ac-curate [16]. Additionally, users occasionally make mistakes when specifying constraints. For example, in the baseball-hockey task, User 1 mistakenly provided the constraint that Devils 7 X  baseball . The user was likely thinking of the Tampa Bay Devil Rays, rather than the New Jersey Devils (a hockey team). Such incorrect constraints can be detrimental to GE.
Incorrect constraints can be corrected and imprecise con-straints can be refined by having the user view a few occur-rences of the constraint feature  X  in context. Mann and Mc-Callum [16] found that this target estimation method gave higher accuracy than traditional sequence labeling with the same number of labels. In this section we use stratified sam-pling to ensure that the small number of occurrences con-sidered by the user are representative. Note that these ideas could be applied to other expectation estimation problems.
The specific task we consider is estimating a distribution over labels for a particular input feature q . The function of interest returns a vector with the count of q with each label. For a classification task, the function r q is For a sequence labeling task, the function r q is
Target Function: We aim to estimate the distribution over labels for each input feature. Consequently  X  ex (  X   X r simply returns  X   X r q normalized to sum to 1.

Stratification Functions: We need only consider x j where q ( x j )=1, or q ( x j , t )=1 for some t . For binary classi-fication tasks, the stratification function is the expectation of r q 0 , where 0 refers to one of the labels. Table 3: Stra tified sampling provides lower error tar-where again we only consider x j with q ( x j )=1.
For a non-binary task we stratify according to the index of the most frequently predicted label  X  max . In ongoing work we are developing improved, clustering-based methods for stratification for expectation estimation.
Stratification Scheme and Sample Allocation: We use the cum ti on, and the same sample allocation scheme.
For this experiment we use the same data sets and con-straints as the experiments in Section 5.2. We use m = 2 strata, 4 samples per constraint, and repeat the experiment 1000 times with different random seeds. We evaluate using the mean absolute expectation estimation error ( err ), and the accuracy of the logistic regression model after re-training with the refined constraints ( rt acc ). Table 3 displays results comparing random sampling and stratified sampling with cum sampling always provides more accurate expectation esti-mates, and provides higher accuracy when the model is re-trained with the refined constraints in all cases except one. Cases in which stratified sampling significantly outperforms random sampling are indicated with a  X  .
Finally, we refine User 3 X  X  constraints for Cora with n =4 and n = 10 samples of the constraint occurring in context. We use m = 2 strata for n = 4, m = 5 strata for n = 10, and conduct 100 trials. We use the same initial model as in Sec-tion 5.4, which has accuracy of 82.8%. Note that here strata with low s  X  max values do not necessarily have low variance. Therefore, in this experiment we avoid over-stratifying, al-lowing &lt; m strata if there are fewer non-empty initial classes.
Using random sampling gives mean absolute expectation estimation error of 0.259 with n =4 and error of 0.171 with n = 10. Using proportional allocation with s qmax and cum  X 
F stratification gives error of 0.215 with n = 4, a 17% error reduction, and error of 0.136 with n =10, a 20% error reduc-tion. Retraining the model with the refined constraints ob-tained using random sampling gives accuracy of 82.5% with n = 4 and accuracy of 86.3% with n = 10, while retraining the model with refined constraints using stratified sampling gives statistically significantly higher accuracy of 84.0% with n = 4 and accuracy of 87.2% with n =10. Random sampling requires n =16 samples per constraint to match the accuracy of stratified sampling with n =10, a 37.5% reduction.
The user may instead use the sample to specify their own target expectation. In this case, we want the sample to include as many labels as possible, to remind the user of the input feature X  X  uses. Random sampling with n =4 finds 61.1% of the labels input features occur with, whereas strat-ified sampling finds 70.4%. With n = 10, random sampling finds 69.5%, whereas stratified sampling finds 82.9%.
We also conjecture that in applications where the target label distributions have higher entropy, reductions in target estimation error will yield larger accuracy improvements.
In this paper we addressed subproblems in interactive training that can be cast as selecting a representative sam-ple for the user to review. In this section we discuss future opportunities in interactive training. In addition to the di-rections below, we are interested in stratification schemes that additionally consider the input variables, and in devel-oping a complete interactive training system.

Model Prediction Rationales: In addition to helping the user understand what the model is predicting, it may be beneficial to help the user understand why the model is making a prediction. For example, knowing why the model is making a mistake could help a user add the necessary constraints to fix it. We conjecture that a user could under-stand a model prediction by inspecting similar contexts and studying the way the prediction changes with the input.
Summarizing Differences between Models: We are interested in developing sampling methods for summarizing the similarities and differences between two models. This could help the user understand how the model is changing with the addition of new constraints.

Detecting Incorrect Constraints: In some cases we suspect that incorrect constraints could be automatically de-tected, as we have observed that constraints whose targets are poorly matched during training are often incorrect. This method could assist the user in prioritizing refinement. online typically outperforms all other methods.
