 FREDERICK JELINEK 1. Introduction This article concerns the relationship between linguistics and the work carried out during 1972 X 1993 at IBM Research in automatic speech recognition (ASR) and natural language processing (NLP). Many statements I will make will be incomplete: I am not that conversant with the literature. I apologize to those whomI mayoffend.Conceivablyit wouldhavebeenmuch better toleavethings alone, stay silent. Hopefully this journal will be willing to devote some of its pages to Letters to the Editor to correct the record or air opposing views. a linguist our system performance improves . I have hoped for many years that this quote was only apocryphal, but at least two reliable witnesses have recently convinced me that I really stated this publicly in a conference talk (Jelinek, 1998). Accepting then that I really said it, I must first of all affirm that I never fired anyone, and a linguist least of all.
 IBM ever had any hostility to linguists or linguistics. In fact, we all hoped that linguists would provide us with needed help. We were never reluctant to include linguistic knowledge or intuition into our systems: if we didn X  X  succeed, it was because we didn X  X  find an efficient way to do include it. 2. The Beginning of ASR/NLP Data Driven Methods When our Continuous Speech Recognition group started its work at IBM Research, the management wanted to make sure that our endeavors were guided by strict scientific principle. They therefore placed into the group two linguists who were going to guide our progress. Both linguists were quite self-confident, sure that fast progress will be possible. For instance, when we (trained as engineers or physicists) were at a loss how to construct a language model, one of the linguists declared  X  X  X  X  X l just write a little grammar. X  X  recognition paradigm was a follows: 1. Segment speech into phone-like units 2. Use pattern recognition to identify the segments 3. On the basis of confusion penalties determined by experts, find the least penalized utterance fitting the identified segment string.
 generated by the so called Raleigh Finite State Language (see Figure 1). For every word we hand-crafted a pronunciation baseform (string of phones from an alphabet of about 50 phones) and carried out a recognition experiment using a trained speaker. Confusion statistics obtained by a standard EM approach easily beat those estimated by our experts (25% versus 65% error rates).
 experiment we replaced the phonetic baseforms by orthographic baseforms (e.g., the word ought was described by the 5 units long string OUGHT rather than by the phonetic O  X  T. Thus from the system X  X  point of view the G  X  X  X ound X  X  in OUGHT was the same as the G sound in GENERAL or in GO !). This orthographic experiment turned out to have  X  X  X nly X  X  a 57% error rate, superior to the 65% error rate based on confusion penalties determined by experts.
 their basic research, and we were free to pursue our self-organized, data driven, statistical dream. This is the reality to which referred the admittedly hyperbolic word fire in my quote.
 (1971 X 1976) was started. Before that time, researchers in the speech understand NLP/ASR field routinely presented results achieved on training data. Most participants in the ARPA project estimated the difficulty of their recognition tasks by the somewhat vaguely defined concept of branching factor that took no statistics into account 1 and was essentially equal to the arithmetic average of the number of words between which the recognizer had to decide at each decision point (all tasks were then finite state). To combat this fallacy and yet stay in the realm of decisions between words, we intro-duced the concept of perplexity (Bahl et al., 1997) directly related to the mathematically traditional cross entropy .
 the famous and influential AT&amp;T communications engineer J.R. Pierce published his warning (Pierce, 1969) that certainly slowed down investment in ASR research. Here are some quotes from his article:  X  X  ... ASR is attractive to money. The attraction is perhaps similar to the attraction of schemes for turning water into gasoline, extracting gold from the sea, or going to the moon. X  X  26  X  X  X ost recognizers behave not like scientists, but like mad inventors or untrustworthy engineers. X  X   X  X  ... performance will continue to be very limited unless the recognizing device understands what is being said with something of the facility of a native speaker (that is, better than a foreigner fluent in the language). X  X   X  X  X ny application of the foregoing discussion to work in the general area of pattern recognition is left as an exercise for the reader. X  X  3. The NLP/ASR Situation in the 1970s In the 1970s NLP and ASR research was dominated by an artificial intelli-gence approach. Programs were rule-based, expert systems were beginning to take over. Noam Chomsky, a very respected (and rightly so) though con-troversial figure, felt that statistics had no place in linguistic research. His demonstration that language is not finite state (Chomsky, 1962) was con-sidered decisive, and its applicability to NLP was over-estimated. The purest linguists based their work on self-constructed examples, not on the preva-lence of phenomena in observed data.
 frequently ignored. Grammars were being written that applied to less than dozen verbs.
 Only 3 or 4 people out of 10 had any previous experience with speech. None had graduate training in that field. But several of us had a background in Information Theory and that influenced our thinking. Because of that background it was natural for us to come up with the Communication Theory formulation of ASR (see Figure 2). Our creed was as follows: 28 language translation problem (see below). We were always accused of reluctance to use linguistic information, and when we did, remarks were made like  X  X  X he IBM group is coming around. They admit the need for a linguistic approach. X  X  Well, we always wanted linguistics, only we didn X  X  know how to incorporate them.
 problem was of no direct research interest. Of course, there were other lin-guists, such as Geoffrey Leech or Henry Kucera, who were very interested in data, and as soon as we could we sought cooperation with them.
 tion of resources to be exploited by NLP/ASR. 4. Availability of Linguistic Resources Linguistic resources pre-dated the modern statistical, data driven approach to NLP/ASR. I will mention resources in the order in which we naive engi-neers working on ASR  X  X  X iscovered X  X  them. First was the Brown Corpus (Francis and Kucera, 1982) that existed since 1967. It was rather small by today X  X  standards, 1 million words, but it contained a selection of genres and was annotated by parts of speech. That got us interested in automatic tag-ging: we thought of it as an opportunity to improve the ASR language model. So Bahl and Mercer invented the HMM approach to tagging (Bahl, Mercer, 1976). It was quite a disappointment to us that even though the accuracy of our tagger was quite high (about 96%), we found no effective way to exploit it in a language model.
 at Lancaster attempted automatic tagging by rule (Garside, 1987, 1993). And this led to our discovery of the existence of the Lancaster X  X slo X  Bergen corpus (Johansson et al. , 1978) associated with the English grammar books by Quirk et al. (1985).
 of the statistical methods we developed for ASR. We hit on the possibility of machine translation (MT). And, of course, we thought that grammar would be important and we wanted to induce it from annotated data. That X  X  when we found the Lancaster treebank constructed in the years 1983 X 1986 under the leadership of Geoff Sampson and Geoff Leech (Garside et al. , 1987; Sampson, 1987). Unfortunately, as I recall, it was hard to obtain the rights to use this treebank, and so we commissioned the University of Lancaster to create a new treebank just for our own use.
 quantity would beat quality (within reason, of course). And we thought that the treebank should be based on solid intuition carried in the minds of  X  X  X very X  X  native speaker. So the resulting 3 million word treebank (Leech and Garside, 1991) was constructed by 10 Lancaster housewives guided by Leech who did finally write quite a thick annotation manual. At the end, the housewives became experts ... 5. The Founding of LDC In the late nineteen eighties the NSF Directorate of Computer and Infor-mation Science (CISE) was headed by a famous applied mathematician Jack Schwartz. Before he assumed the job he used to collaborate with the great John Cocke of IBM, the C in the CKY algorithm, and the originator of the RISC machine concept and of many other computer innovations. 2 In the fall of 1987 I went to visit Jack at NSF and suggested to him that NSF should underwrite the creation of a  X  X  X reasury X  X  of annotated English. I had in mind a much more sizeable treebank than the one their being constructed at Lan-caster. Jack was willing to explore the problem and instructed Charles Wayne to help.
 data. It was an enormous problem: organizations wanted to charge consid-erable money to a  X  X  X eep pockets X  X  company like IBM. We did find some  X  X  X ree X  X  data at the Reading House for the Blind, but in order to use it, we had to obtain individual releases from the owners of each separate item (book, article, etc.) contained in the collection. It was clear that to carry out nego-tiations for rights, the data guardianship task should reside in a non-profit institution best associated with a university. So at the NLP conference in January 1988 (Second Conference on Applied Natural Language Processing, 1998) I inquired of Aravind Joshi and Mitch Marcus if they would be inter-ested in having such an institution at the University of Pennsylvania. They said they would, I reported it to Charles Wayne, and he took it from there. conference, 1998), a steering committee was set up, rules about membership were drafted, and LDC came into being with its first task: the U Penn Treebank. 6. Rise of Data Driven Parsing By this time we were more eager than ever to see if construction of a sta-tistical parser were possible (on the basis of a treebank, of course) . We thought we needed cooperation with some group more experienced in NLP. So we applied for an NSF grant jointly with the University of Pennsylvania. 30 eventually resulted in the parsers developed by Collins (1996). 7. Machine Translation As mentioned earlier, we embarked on MT in 1986 when we sought a new area to which to apply our statistical, self organized techniques. Besides, we had 15 years of ASR work behind us and those who switched were also attracted by the change as well as the possibility of picking some  X  X  X ow hanging fruit. X  X  problem (see Figure 3), and to base our learning on parallel texts. Naturally, as the source language we wanted to use one not too different from English. So we were very fortunate when we discovered the Canadian Hansards text that transcribed in English and French the debates of the Ottawa parliament. was revealed to be almost common sense. In fact, it was probably Bob Mercer who found the following quotations in an article by Weaver (1995):  X  X  X hen I look at an article in Russian I say: This is really written in English but it has been coded in some strange symbols. I will now proceed to decode it. 3  X  X  ... the matter is probably absolutely basic  X  namely the statistical char-acter of the problem. X  X  Peter Brown, although many others were also importantly involved. Before we really got down to business, four of us took a fast course in French. Not that we believed it, but the organization that offered the course claimed that it will teach us French in 2 weeks! that participated in a 1991 DARPA project in which we had two competitors: Dragon Systems ( Lingstat ), and the combined forces of NMSU, CMU, and ISI ( Pangloss ). Our own system was called Candide  X  I don X  X  know why. not at all. And again, wise people said profoundly  X  X  X hat we need to do is to combine linguistics with statistics. X  X  As if we had not tried as hard as we could to include in our statistical frame the linguistics we could get hold of! Why else did we put in the effort to create good parsers? disambiguation (Brown et al. , 1991). And we performed preprocessing in which we attempted to rearrange the words of the French source sentence into a more English-like progression. 8. Conclusion The IBM group (actually, its successor) continues to exist and carries out outstanding research, but beginning with 1993 several of us  X  X  X ounders X  X  started leaving it. The original MT project was also stopped around 1996, although it has since been resurrected and is now going strong. study physical phenomena. They will give us advice, but will not directly engage themselves in building systems. Just as engineers learned to take advantage of the insights of physics, it is our task to figure out how to use the insights of linguistics.
 or categorized data. What we should ask is that linguists help us structure systems capable of extracting knowledge under minimal human supervision. modules that reflect language phenomena and enable machine learning to estimate the corresponding parameters (Baker, 1975).
 Notes 32 References
