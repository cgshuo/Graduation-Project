 I have shown that the presence of difficult query aspects that are achievements, cooperation, risks ) can be improved by taking advantage of the known presence of other, easier to verify query aspects. The approach proceeds by mining a large external corpus and results in substan tial improvements in re-ranking the subset of the top retrieved documents. H.3.3 [ Information Search and Retrieval ]: Retrieval models;  X  Retrieval Models Algorithms, Experimentation, Theory. Information retrieval, machine learning, external corpus. It has been noticed that a common reason for the search results to be of poor quality is missing one or more aspects of the user information need [1], where an aspect can be represented by a subset of query words. E.g., in the query antarctica exploration , the word antarctica is relatively rare and specific. Along with documents about Antarctica. On the other side, the word exploration, capturing the other aspect of the query, is not only more frequent, but also represents a higher level concept (theme, topic, etc.), often revealing itself only implicitly by such statements like  X ... scientists began to collect data... X  The ranking of the retrieved documents by currently state-of-the-art algorithms would be primarily determined by antarctica, mildly affected by the explicit occurrence of the word exploration , and not affected by the implicit presence of the exploration theme. Although techniques aimed at detecting and representing missing aspects have been suggested [2][3] they have not been yet methodologically studied or revealed convincing improvements. I suggest that it was because they were essentially limited to the bag-o f-words representations and the query expansion models. On the contrary, this research builds on the prior works studying the prediction of occurrence of given words (concepts) in a given text context (e.g. a sentence) such as [5][7]. Specifically, I proceeded by the exploring the following innovations: 1) Going beyond the bag of words by looking for the indicators of implicit asp ect presence among all the sequences of words (up to a certain length) from the document (e.g. polar station , oil drilling proposed , expedition ships , etc.) rather than relying on a finite number of expansion terms. 2) Considering the problem of aspect verification conditional on the presence of other, often easier to establish aspects . E.g., in a document about Antarctica, station is a good indication of the exploration theme, while not necessary so in unrestricted context. 3) Modeling subsumption of indicators, e.g. if the word station is a part of train station then its connection to the exploration theme is weaker. Here, I considered the simplest, but a common situation with the two aspects in a query, each can be specified by one or more keywords: 1) Ap is already known to be present in the document d and 2) the other aspect Am , explicit representation of which is missing in the document, thus simply referred below as the  X  X issing X  aspect. While Am is typically a difficult aspect to verify, as I have demonstrated here, the task of estimating the presence of Am conditional on the presence of Ap happens to be easier . As the possible indicators of the aspect implicit presence, I considered all the sequences of words (up to length of 3 ) in a document. For each indicator i, the algorithm estimated P(Am|i,Ap) , the probability of the occurrence of Am within the proximity (e.g. same sentence) of i , conditional on the occurrence of Ap. In order to do that, a regression (M5P model tree [6]) was trained independently for each topic, using the normalized frequency counts obt ained from Microsoft X  X  Bing search engine as independent va riables. For example, the high ratio #((station NEAR exploration) AND Antarctica)/#(station AND A ntarctica) would indicate the high probability of occurrence of exploration near the word station in the external corpus, conditional on the presence of Antarctica . The snippets returned by Bing for the query representing both aspects (e.g. antarctica NEAR exploration) served as training examples, thus no parameter tuning was necessary. The advantage of using M5P was learning automatically the reliability thresholds for the frequency counts. The subsumption step of the algorithm discarded all the sub-sequences (e.g. station ) within the word sequences (e.g. train station ) for which the reliable estimates of the conditional probabilities were obtained. This resulted in the average of 531 preserved indicators per document, with 90% of the strongest 100 indicators having 2 or more wo rds, some of those presented in Table 2 below. To rank the documents, the sum of all the conditional probability estimates over all the remaining indicators was treated as the total number of  X  X mplied X  occurrences of the missing aspect: applied. MAP 0.39 0.43 0.65** .53* Standard 
Deviation % change over B2 Table 1. The results of the evaluation. Statistically significant differences at the levels of 0.05 and .1 are marked with ** and * accordingly. Since the approaches studied here involved a large number of time-consuming external queries, I built a small but  X  X lean X  data set that was sensitive enough to evaluate various configurations and the overall verification accuracy of the techniques suggested here base d on the top ranked documents retrieved by bm25 ranking function (described as B1 below) using the HARD 2005 TREC topics, which are known to be difficult and often result in missing aspects [1]. I chose only consisting of missing and present aspects. 2) The present aspect was occurring in at least 90% of the top 20 documents. 3) The missing aspect was not explicitly occurring in more than half of the top 20 documents. This left me with 18 topics, some examples of them listed in Table 2. Only up to 20 top ranked irrelevant and relevant documents were selected, and only those that did not have the missing aspect mentioned explicitly. I also removed (approx. 10% of) the documents assessed by TREC as irrelevant but still having both aspects present in order to reduce the sensitivity of the evaluation to the details supplied only in the narratives of the topics and t hus not available to neither the baseline nor the suggested algorithms. The resulting data set was almost  X  X alanced X  with approximately 15 negative and 10 positive examples on average per each topic. I compared the performance against two strong baselines: B1 was obtained by applying bm25 ranking formula using the topic titles only, with stemming and pseudo-relevance f eedback using Lemur retrieval engine default settings. Since the approach here involves an external corpus, to make a fair comparison, I also involved B2 obtained and optimized the same way as in [4], which was essentially an application of a relevance model with an external corpus (here, using Bing X  X  snippets). As the results in Table 1 indicate, it was possible to significantly improve verifying the presence of the difficult implicit aspects by the techniques suggested he re. Also, no specific topic has been harmed as a result. While the actual impact on a larger set of topics remains to be seen, I have nevertheless been able to handle a very common scenario with the implicit presence of a difficult aspect (e.g. exploration ) and the explicit presence of an easier aspect (e.g. Antarctica ). Although the dataset involved in experiments here was very sma ll, it still represented the top ranked results from the state of the art techniques, and thus being able to improve them by re-ranking has great practical implications. The ablation studies (not reported here due to the space limitations) confirmed that each of the novelties 1-4 stated in the introduction was crucial. While sending queries to a search portal delayed the proce ssing substantially, in order to achieve the real time speeds, future implementations can make use of the processed large corpus data such as Google X  X  1T or a faster access to a search engine index. [1] Buckley, C. Why current IR engines fail. SIGIR 2004 . [2] Collins-Thompson, K., Callan, J. Query expansion using [3] Crabtree, D.W., Andreae, P. Gao, X. Exploiting [4] Diaz, F. and Metzler, D. Improving the estimation of [5] Edmonds, P. Choosing the word most typical in context [6] Monz, C. Model Tree Learning for Query Term Weighting [7] SzeWang F., Roussinov, D., Skillicorn, D.B. Detecting indicators that are specific to the present aspect.
 Topic Strongest Indicators of Presence Transportation Tunnel 
Disasters Black Bear 
Attacks Iran Iraq Cooperation
