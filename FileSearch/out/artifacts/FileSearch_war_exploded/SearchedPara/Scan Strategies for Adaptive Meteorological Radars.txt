 Traditionally, meteorological radars, such as the National Weather Service NEXRAD system, are tasked to always scan 360 degrees. In contrast, the Collaborative Adaptive Sensing of the Atmo-sphere (CASA) Engineering Research Center [5] is developing a new generation of small, low-power but agile radars that can perform sector scanning, targeting sensing when and where the user needs are greatest. Since all meteorological phenomena cannot be now all observed all of the time with the highest degree of fidelity, the radars must decide how best to perform scanning. While we fo-cus on the problem of how to perform sector scanning in such an adaptive meteorological sensing resource-constrained sensor networks.
 Given the ability of a network of radars to perform sector scanning, how should scanning be adapted at each decision epoch? Any scan strategy must consider, for each scan action, both the expected quality with which phenomena would be observed, and the expected number of decision epochs before which phenomena would be first observed (for new phenomena) or rescanned, since not all regions are scanned every epoch under sectored scanning. Another consideration is whether to opti-mize myopically only over current and possibly past environmental state, or whether to additionally optimize over expected future states. In this work we examine three methods for adapting the radar scan strategy. The methods differ in the information they use to select a scan configuration at a particular decision epoch. The sit-and-spin strategy of always scanning 360 degrees is indepen-dent of any external information. The limited lookahead strategies additionally use the expected environmental state K decision epochs in the future in its decision-making. Finally, the full looka-Markov decision process and using reinforcement learning to estimate the optimal scan strategy. All strategies, excluding sit-and-spin, work by optimizing the overall  X  X uality X  (a term we will define precisely shortly) of the sensed information about phenomena in the environment, while restricting or penalizing long inter-scan intervals.
 Our contributions are two-fold. We first introduce the meteorological radar control problem and show how to constrain the problem so that it is amenable to reinforcement learning methods. We such as reinforcement learning is necessary. With respect to the radar meteorological application, we show that the main benefits of considering expected future states are when there are multiple meteorological phenomena in the environment, and when the maximum radius of any phenomenon the average quality with which a phenomenon is scanned and the number of decision epochs before which a phenomenon is rescanned. Finally, we show that for some environments, a limited looka-head strategy is sufficient. In contrast to other work on radar control (see Section 5), we focus on tracking meteorological phenomena and the time frame over which to evaluate control decisions. presents results. Section 5 reviews related work on control and resource allocation in radar and sensor networks. Finally, Section 6 summarizes this work and outlines future work. Meteorological radar sensing characteristics are such that the smaller the sector that a radar scans (until a minimum sector size is reached), the higher the quality of the data collected, and thus, the more likely it is that phenomena located within the sector are correctly identified [2]. The multi-and possibly overlapping footprints. Each radar has a set of scan actions from which it chooses. In to determine which scan actions to use and when to use them. An effective scanning strategy must balance scanning small sectors (thus implicitly not scanning other sectors), to ensure that phenomena are correctly identified, with scanning a variety of sectors, to ensure that no phenomena are missed. We will evaluate the performance of different scan strategies based on inter-scan time, quality, and cost. Inter-scan time is the number of decision epochs before a phenomenon is either first observed or rescanned; we would like this value to be below some threshold. Quality measures how well a phenomenon is observed, with quality depending on the amount of time a radar spends sampling a voxel in space, the degree to which a meteorological phenomena is scanned in its (spatial) en-tirety, and the number of radars observing a phenomenon; higher quality scans are better. Cost is a meta-metric that combines inter-scan time and quality, and that additionally considers whether a phenomenon was never scanned. The radar control problem is that of dynamically choosing the scan strategy of the radars over time to maximize quality while minimizing inter-scan time. We define a radar configuration to be the start and end angles of the sector to be scanned by an (one configuration for each radar in the meteorological sensing network). We define a scan strategy different scan strategies. 3.1 Quality Function The quality function associated with a given scan action was proposed by radar meteorologists in [5] and has two components. There is a quality component U phenomenon p . There is also a quality component U independent of any phenomena in that sector. Let s and let S scanning a phenomenon p using scan action S r with the following equations, where U ( p,S r ) is the maximum quality obtained for scanning phenomenon p over all possible radars and are plotted in Figure 1. F c captures the effect on quality due to the percentage of the phenomenon covered; to usefully scan a phenomenon, at least 95% of the phenomenon must be scanned. F w F d captures the effects of the distance from the radar to the geometrical center of the phenomenon on quality; the further away the radar center is from the phenomenon being scanned, the more degraded subsector i of radar r scanned using configuration s r is, Intuitively, a sector scanning strategy is only preferable when the quality function is such that the 3.2 Scan Strategies We compare the performance of the following three scan strategies. The strategies differ in whether they optimize quality over only current or also future expected states. For example, suppose a storm cell is about to move into a high-quality multi-doppler region (i.e., the area where multiple radar footprints overlap). By considering future expected states, a lookahead strategy can anticipate this event and have all radars focused on the storm cell when it enters the multi-doppler region, rather (i) Sit-and-spin strategy. All radars always scan 360  X  . (ii) Limited  X  X ookahead X  strategy. We examine both a 1-step and a 2-step look-ahead scan strategy. Although we do not have an exact model of the dynamics of different phenomena, to perform the look-ahead we estimate the future attributes of each phenomenon using a separate Kalman filter. For and the measurement y is a vector comprising only the ( x,y ) location. The Kalman filter assumes particular, x Following work by [8], we initialize each Kalman filter as follows. The A matrix reflects that storm cells typically move to the north-east. The B matrix, which when multiplied with x assumes that the observed state y matrix assumes that there is little noise in the true state dynamics. Finally, the measurement error covariance matrix R is a function of the quality U t . We discuss how to compute the  X  storm cell y estimate of x We compute the k -step look-ahead quality for different sets of radar configurations S where N the current set of observed attributes for phenomenon i , p for phenomenon i , S then S  X  and phenomena, and to consider the possibility of new phenomena appearing, we restrict S those scan actions that ensure that every sector has been scanned at least once in the last T epochs. T that all sectors be scanned, for instance by a 360  X  scan, at most every 5 minutes. process (MDP) and use reinforcement learning to obtain a lookahead scan strategy as follows. While a POMDP (partially observable MDP) could be used to model the environmental uncertainty, due to the cost of solving a POMDP with a large state space [9], we choose to formulate the radar control problem as an MDP with quality (or uncertainty) variables as in an augmented MDP [6]. S is the observed state of the environment. The state is a function of the observed number of storms, the observed x,y velocity of each storm, and the observed dimensions of each storm cell given by x,y center of mass and radius. To model the uncertainty in the environment, we additionally define as part of the state quality variables u in Equations (1) and (2) in Section 3.1. u observed, and u A is the set of actions available to the radars. This is the set of radar configurations for a given 0, 90, 180, or 270  X  . Thus, with N radars there are 13 N possible actions at each decision epoch. The transition function T ( S  X  A  X  S )  X  [0 , 1] encodes the observed environment dynamics: specif-ically the appearance, disappearance, and movement of storm cells and their associated attributes. 360 degrees, then any new storm cells that appear in the unscanned areas will not be observed. Thus, the new storm cells that will be observed will depend on the scanning action of the radar. The cost function C ( S,A,S )  X  R encodes the goals of the radar sensing network. C is a function of the error between the true state and the observed state, whether all storms have been observed, and a penalty term for not rescanning a storm within T where N o observed value of attribute j of storm i , d number of storms, P storm i was last scanned, P epochs, and I ( t storm is observed determines the difference between the observed and true values of its attributes. We use linear Sarsa(  X  ) [15] as the reinforcement learning algorithm to solve the MDP for the radar control problem. To obtain the basis functions, we use tile coding [13, 14]. Rather than defining 4.1 Simulation Environment We consider radars with both 10 and 30km radii as in [5, 17]. Two overlapping radars are placed in a 90km  X  60km rectangle, one at (30km, 30km) and one at (60km, 30km). A new storm cell can appear anywhere within the rectangle and a maximum number of cells can be present on any decision epoch. When the ( x,y ) center of a storm cell is no longer within range of any radar, the cell is removed from the environment. Following [5], we use a 30-second decision epoch. We derive the maximum storm cell radius from [11], which uses 2 . 83 km as  X  X he radius from the cell real storm cell tracks obtained from meteorologists. Each track is a series of ( latitude,longitude ) coordinates. We first compute the differences in latitude and longitude, and in time, between suc-the longitude (or y ) velocity has mean 16.7 km/hr and std. dev. of 28.8 km/hr. To obtain a storm cell X  X  ( x,y ) velocity, we then sample the appropriate Gaussian distribution.
 To simulate the environment transitions we use a stochastic model of rainfall in which storm cell arrivals are modeled using a spatio-temporal Poisson process, see [11, 1]. To determine the number of new storm cells to add during a decision epoch, we sample a Poisson random variable with rate  X  X  X a X t with  X  = 0 . 075 storm cells/ km 2 and  X  = 0 . 006 storm cells/minute from [11]. From the radar setup we have  X a = 90  X  60 km 2 , and from the 30-second decision epoch we have  X t = 0 . 5 minutes. New storm cells are uniformly randomly distributed in the 90km  X  60km region and we uniformly randomly choose new storm cell attributes from their range of values. This simulates the true state of the environment over time. The following simplified radar model determines how well the radars observe the true environmental state under a given set of radar configurations. If a storm cell p is scanned using a set of radar configurations S are observed as a function of the U u between zero and one. Then the observed value of the attribute is the true value of the attribute plus some Gaussian noise distributed with mean zero and standard deviation (1  X  u ) V max / X  where V strategy we also use  X  R , in our Kalman filter.
 We parameterize the MDP cost function as follows. We assume that any unobserved storm cell has been observed with quality 0, hence u = 0 . Summing over (1  X  u ) V max / X  for all attributes with  X  = 0 gives the value P m = 15 . 5667 , and thus a penalty of 15.5667 is received for each unobserved storm cell. If a storm cell is not seen within T given. Using the value 200 ensures that if a storm cell has not been rescanned within the appropriate amount of time, this part of the cost function will dominate. We distinguish the true environmental state known only to the simulator from the observed environ-mental state used by the scan strategies for several reasons. Although radars provide measurements about meteorological phenomena, the true attributes of the phenomena are unknown. Poor over-lap in a dual-Doppler area, scanning a subsector too quickly or slowly, or being unable to obtain a sufficient number of elevation scans will degrade the quality of the measurements. Consequently, models of previously existing phenomena may contain estimation errors such as incorrect velocity, propagating error into the future predicted locations of the phenomena. Additionally, when a radar scans a subsector, it obtains more accurate estimates of the phenomena in that subsector than if it 4.2 Results In this section we present experimental results obtained using the simulation model of the previous section and the scan strategies described in Section 3. For the limited lookahead strategy we use a granularity of 1.0; for the ( x,y ) velocity, phenomenon confidence, and radar sector confidence tilings, we use a granularity of 0.1. When there are a maximum of four storms, we restrict Sarsa(  X  ) to scanning only 180 or 360 degree sectors to reduce the time needed for convergence. Finally, all strategies are always compared over the same true environmental state.
 Figure 2(a) shows an example convergence profile of Sarsa(  X  ) when there are at most four storms in the environment. Figure 2(b) shows the average difference in scan quality between the learned to perform as well as or better than Kalman filtering. Examining the learned strategy showed that when there was at most one storm with observation noise 1 / X  = 0 . 001 , Sarsa(  X  ) learned to simply relative difference increases for sit-and-spin, and decreases for the 2-step. Figure 2(c) shows the strategies for a 30 km radar radius. Sarsa(  X  ) has the lowest average cost.
 not scanning a storm within T 1, 2, or 3 decision epochs than do the other scan strategies, it scans almost all storm cells within 4 epochs. Note that for the sit-and-spin CDF, P [ X  X  1] is not 1; due to noise, for example, the measured location of a storm cell may be (expected) outside any radar footprint and consequently the storm cell will not be observed. Thus the 2-step has more inter-scan times greater than T inter-scan time and scan quality. We hypothesize that this trade-off occurs because increasing the size of the scan sectors ensures that inter-scan time is minimized, but decreases the scan quality. the same as the 2-step quality. We hypothesize that this is a consequence of the maximum storm cell radius, 4 km, relative to the 10 km radar radius. With a 30 km radius and at most eight storm cells, that quality is a value between 0 and 1). Now recall that Figure 2(b) shows that with a 30 km radius that there may be some maximum number of storms above which it is best to sit-and-spin. marginal returns for considering more than 1 or 2 future expected states. Instead, the primary value maximizing scan quality while minimizing inter-scan time. Implementing the learned reinforcement learning scan strategy in a real meteorological radar network requires addressing the differences be-tween the offline environment in which the learned strategy is trained, and the online environment in which the strategy is deployed. Given the slow convergence time for Sarsa(  X  ) (on the order of Figure 2: Comparing the scan strategies based on quality, cost, and inter-scan time. Recall that  X  is a scaling term used to determine measurement noise, see Section 4.1. days), training solely online is likely infeasible, although the time complexity could be mitigated by using hierarchical reinforcement learning methods and semi-Markov decision process. Some online training could be achieved by treating 360  X  scans as the true environment state. Then when unknown states are entered, learning could be performed, alternating between 360  X  scans to gauge the true state of the environment and exploratory scans by the reinforcement learning algorithm. Other reinforcement learning applications in large state spaces include robot soccer [12] and heli-copter control [10]. With respect to radar control, [4] examines the problem of using agile radars on airplanes to detect and track ground targets. They show that lookahead scan strategies for radar tracking of a ground target outperform myopic strategies. In comparison, we consider the problem of tracking meteorological phenomena using ground radars. [4] uses an information theoretic measure to define the reward metric and proposes both an approximate solution to solving the MDP Bellman equations as well as a Q-learning reinforcement learning-based solution. [16] examines where to target radar beams and which waveform to use for electronically steered phased array radars. They maintain a set of error covariance matrices and dynamical models for existing targets, as well as track existence probability density functions to model the probability that targets appear. They then choose the scan mode for each target that has both the longest revisit time for scanning a target and error covariance below a threshold. They do this for control 1-step and 2-steps ahead and show that considering the environment two decision epochs ahead outperforms a 1-step look-ahead for tracking of multiple targets. In this work we compared the performance of myopic and lookahead scan strategies in the context of the meteorological radar control problem. We showed that the main benefits of using a lookahead strategy are when there are multiple meteorological phenomena in the environment, and when the maximum radius of any phenomenon is sufficiently smaller than the radius of the radars. We also showed that there is a trade-off between the average quality with which a phenomenon is scanned and the number of decision epochs before which a phenomenon is rescanned. Overall, considering decision epoch, it may be useful to consider actions that cover multiple epochs, as in semi-Markov decision processes or to use controllers from robotics [3]. We would also like to incorporate more radar and meteorological information into the transition, measurement, and cost functions. Acknowledgments The authors thank Don Towsley for his input. This work was supported in part by the National Sci-ence Foundation under the Engineering Research Centers Program, award number EEC-0313747. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the National Science Foundation.
