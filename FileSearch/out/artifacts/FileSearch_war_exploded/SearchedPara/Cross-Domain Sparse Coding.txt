 Sparsecodinghasshownitspowerasaneffectivedatarep-resentation method. However, up to now, all the sparse cod-ing approaches are limited within the single domain learning problem. In this paper, we extend the sparse coding to cross domain learning problem, which tries to learn from a source domain to a target domain with significant different distribu-tion. We impose the Maximum Mean Discrepancy (MMD) criterion to reduce the cross-domain distribution difference of sparse codes, and also regularize the sparse codes by the class labels of the samples from both domains to increase the discriminative ability. The encouraging experiment results of the proposed cross-domain sparse coding algorithm on two challenging tasks  X  image classification of photograph and oil painting domains, and multiple user spam detection  X  show the advantage of the proposed method over other cross-domain data representation methods.
 I.2.6 [ ARTIFICIAL INTELLIGENCE ]: Learning Cross-Domain Learning; Sparse Coding; Maximum Mean Discrepancy
Traditional machine learning methods usually assume that there are sufficient training samples to train the classifier. However, in many real-world applications, the number of labeled samples are always limited, making the learned clas-sifier not robust enough. Recently, cross-domain learning has been proposed to solve this problem [2], by borrowing labeled samples from a so called  X  X ource domain X  for the learning problem of the  X  X arget domain X  in hand. The sam-ples from these two domains have different distributions but are related, and share the same class label and feature space. Two types of domain transfer learning methods have been
In this section, we will introduce the proposed CroDomSc method.
We denote the training dataset with N samples as D = { x i } N i =1  X  R D ,where N is the number of data samples, x i is the feature vector of the i -th sample, and D is the feature dimensionality. It is also organized as a matrix X = [ x 1 ,  X  X  X  , x N ]  X  R D  X  N . The training set is composed of the source domain set D S and target domain set D T , i.e., D = D S D T .Wealsodenote N D and N T as the number of samples in source and target domain set separatively. All the samples from the source domain set D S are labeled, while only a few samples from the target domain D T are labeled. For each labeled sample x i , we denote its class label as y i  X  C ,where C is the class label space. To construct the objective function, we consider the following three problems: Sparse Coding Problem Given a sample x i  X  X  and a Semi-Supervised Sparse Coding Regularization In the
By fixing the sparse codes V and removing irrelevant terms, the optimization problem (6) is reduced to The problem is a least square problem with quadratic con-straints, and it can be solved in the same way as [7].
The proposed Cross Domain Sparse coding algorithm, named as CroDomSc , is summarized in Algorithm 1. We have applied the original sparse coding methods to the sam-ples from both the source and target domains for initializa-tion.
 Algorithm 1 CroDom-Ss Algorithm
INPUT : Training sample set from both source and target sets D = D S D T ;
Initialize the codebooks U 0 and sparse codes V 0 for sam-ples in D by using single domain sparse coding. for t =1 ,  X  X  X  ,T do end for OUTPUT : U T and V T .

When a test sample from target domain comes, we simply solve problem (9) to obtain its sparse code.
In the experiments, we experimentally evaluate the pro-posed cross domain data representation method, CroDomSc.
In the first experiment, we considered the problem of cross domain image classification of the photographs and the oil paintings, which are treated as two different domains.
We collected an image database of both photographs and oil paintings. The database contains totally 2,000 images of 20 semantical classes. There are 100 images in each class, and 50 of them are photographs, and the remaining 50 ones are oil paintings. We extracted and concatenated the color, texture, shape and bag-of-words histogram features as visual feature vector from each image.

To conduct the experiment, we use photograph domain and oil painting domain as source domain and target domain in turns. For each target domain, we randomly split it into training subset (600 images) and test subset (400 images), while 200 images from the training subset are randomly se-lected as label samples and all the source domain samples are labeled. The random splits are repeated for 10 times. We first perform the CroDomSc to the training set and use
To conduct the experiment, we randomly select two users X  inboxes as source and target domains. The target domain will further be split into test set (100 emails) and training set (300 emails, 100 of which labeled, and 200 unlabeled). The source domain emails are all labeled. The word occurrence frequency histogram is extracted from each email as origi-nal feature vector. The CroDomSc algorithm was performed to learn the sparse code of both source and target domain samples, which were used to train the semi-supervised clas-sifier. The target domain test samples were also represented as sparse codes, which were classified using the learned clas-sifier. This selection will be repeated for 40 times to reduce the bias of each selection.
Figure 2 shows the boxplots of classification accuracies on the spam detection task. As we can observed from the figure, the proposed CroDomSc always outperforms its com-petitors. This is another solid evidence of the effectiveness of the sparse coding method for the cross-domain represen-tation problem. Moreover, SSTCA, which is also a semi-supervised cross-domain representation method, seems to outperform other methods in some cases. However, the dif-ferences of its performances and other ones are not signifi-cant.
 Figure 2: The boxplots of detection accuracies of 40 runs for spam detection task.
In this paper, we introduce the first sparse coding algo-rithm for cross-domain data representation problem. The sparse code distribution differences between source and tar-get domains are reduced by regularizing sparse codes with MMD criterion. Moreover, the class labels of both source and target domain samples are utilized to encourage the dis-criminative ability. The developed cross-domain sparse cod-ing algorithm is tested on two cross-domain learning tasks and the effectiveness was shown.
 This work was supported by the National Key Laboratory for Novel Software Technology, Nanjing University (Grant No. KFKT2012B17), and 2011 Qatar Annual Research Fo-rum Award (Grant No. ARF2011).
