 The rapid technological improvements in Internet and telecommunication have led to billion mobile phone short messages are sent each day in Mainland China [1]. Tencent QQ has attracted more than 430 million users, and billions of instant messages are sent each day [2]. 
Duplicates are abundant in short text databases. In our investigation, more than 40% mobile phone short messages have at least one identical duplicate, and an even larger proportion of them are near-duplicates. Det ecting and eliminating these duplicate short clustering, opinion mining, topic detection and tracking, community uncovering. Identical duplicate short texts are easy to de tect by standard hashing schemes. Identi-fication of near-duplicate short texts is much more difficult because of the following reasons: First of all, a single short text contains usually less than 200 characters, which makes it difficult to extract effective featur es. Second, there are usually a huge number network languages are prevailing in short text databases [2]. 
In this paper, an algorithm called SimFinder is presented to detect near-duplicates in large-scale short text databases. An ad hoc weighting scheme is employed in SimFinder texts with the same fingerprint will compare with each other. An optimization solution is also proposed to reduce comparisons further. A variety of techniques have been develope d to identify academic pl agiarism [3,4,5,6], proposed a prototype system called COPS (COpy Protection System) to safeguard intellectual property of digital documents [3]. Shivakumar et al. have developed SCAM (Stand Copy Analysis Mechanism) as a part of the Stanford Digital Library project [4]. Broder finds it sufficient to keep each document a  X  X ketch X  of  X  X hingles X  to compute the resemblance of two documents. Any document pair with at least one common shingle is examined whether it exceeds the threshold for resemblence. Broder X  X  shin-gling method works well on duplicate detection in AltaVista search engine [8]. 
Lyon et al. have investigated the theore tical background to automated plagiarism detection [5]. They observe that independently written texts have a comparatively low level of matching trigrams. The Ferret plagiarism system counts matching trigrams of a pair of documents [5,6]. Shivakumar presents two approaches to compute overlap between all web document pairs simultaneously. Both of them assume that only when where k is a predefined threshold [7]. 
Manku et al. show that Charikar X  X  simhash [13] is practically useful for identifying near-duplicates in large-scale web page repository [9]. Simhash is a fingerprint tech-nique enjoying the property that fingerprints of near-duplicates differ only in a small number of bit positions [9,13]. If the simhash fingerprints of two documents are similar, they are deemed to be near-duplicates. comparing texts with each other. A certain number of fingerprints are extracted from each text in SimFinder, and only short texts sharing same fingerprints are possible to be near-duplicates. 3.1 Term Weighting and Duplicate Degree Terms play different roles in texts. Generally speaking, nouns, verbs and adjectives are more discriminative than adverbs, connectives, pronouns and numerals. It is improper to assign a same weight to all terms [14]. Since few terms will occur more than one time in a single short text, the traditional tf-idf scheme is inappropriate for short texts. 
As for each set G of terms with the same part-of-speech, an empirical weight interval [a,b] is associated in SimFinder, where a and b are the minimal and maximal weight that may be assigned to terms in G respectively. Let weight interval of G be [a,b] , a simple linear interpolation is used to compute the weight of each term G t  X  as fol-lows: frequency of the most and least frequently used term in G respectively. The weighting terms are usually more important than shorter terms. Let |t| denote the length of term t , the long-term-preferred weighting scheme can be defined as follows: 
Duplicate degree is a measure of similarity between two texts. Texts with duplicate degree higher than a predefined threshold  X  are considered as near-duplicates. Let A and B be two texts, the standard duplicate degree called Jaccard similarity is defined as follows: Where S(A) and S(B) are the set of terms contained in text A and B respectively. All terms are considered as equal importance in Equation 3. Let w(t i ) be the weight of term t , the weighted variant of duplicate degree can be defined as follows: 3.2 Feature Extraction and Optimization features. differ usually only in connectives, pronouns, numerals, and punctuations. gerprint. If two short texts A and B have no fingerprints in common, they are impossible to be near-duplicates. As a result, numerous unnecessary comparisons can be avoided. As for text A with m terms, no more than N k + =  X  terms are necessary to be selected as features, where k is the minimal integer satisfying the following inequality: Where w(t i ) denotes the weight of term t i and  X  is the duplicate degree threshold. Remark 2: In real short text databases, duplicate transitivity holds in almost all cases. In other words, if ArB and BrC , A and C are near-duplicates in almost all cases. 
If ArB and BrC , A and C are called a potential duplicate pair. In traditional text da-tabases, duplicate relation does not always observe transitivity. While almost all short text databases satisfy Remark 2. With Remark 2, potential duplicate pairs can be safely regarded as near-duplicates, so the computation of duplicate degree is unnecessary. short message corpus composed of 12 million mobile phone short messages (735 megabytes), the other is a BBS title corpus with 5 million BBS titles (157 mega-bytes). 
Before we verify the effectiveness of SimFinder, a proper duplicate degree threshold selected randomly and are checked manually whether they are near-duplicates. The precision of Equation 3 and Equation 4 are shown in Figure 1 and Figure 2. Experi-ments indicate that Equation 4 is more effect ive than Equation 3. The duplicate degree 0.65 is selected as the threshold because the precision is acceptable in both the short message corpus and the BBS title corpus. A base-line algorithm is employed to ge nerate all possible near-duplicate pairs. One million short messages with no identical duplicates have been used to choose gram size and feature number. The recall of algorithm A is defined as the ratio of the number of duplicate text detected by algorithm A to the number of duplicate text detected by the shows the effect of gram size on efficiency. N=3 is selected in SimFinder because the recall is acceptable and the efficiency is promising. Let  X  =k+N , where k is defined in Ineqation 5, and N has been determined to be 3. Figure 5 and Figure 6 show the effect of feature number on recall and efficiency re-spectively. As can be seen that the feature number computed as Inequation 5 is feasible since the recall is almost 1. More features are unnecessary because the recall increases very little. 
Ten thousand potential duplicate pairs are selected randomly to verify the correct-computed using Equation 4. Only 23 of them are less than 0.65, So the optimization optimization procedure is included, the duplicate degree of 642,404,813 duplicate pairs must be computed using Equation 4. When optimization procedure is included, only 120,725,627 comparisons are needed. The optimization procedure increases the effi-ciency of SimFinder more than 4 times. 
The SimFinder has been implemented in C++. We use a dawning server S4800A with 4 CPUs and 8G bytes of memory to test the performance of SimFinder. Figure 7 and Figure 8 show the run time of SimFinder on short message corpus and BBS title corpus respectively. Figure 9 and Figure 10 show the storage consumption of Sim-Finder. As can be seen that both run time and storage consumption are almost linear correlated with the size of corpus. SimFinder is an effective and efficient algori thm to detect and eliminate duplicates in large-scale short text databases. Three techniques have been included in SimFinder: the ad hoc term weighting technique, the discriminative-term selection technique, the optimization technique. Experiments have shown that SimFinder is an encouraging solution for large-scale short text duplicate detection. Acknowlegments. This research is supported by The 973 National Basic Research Program of China under the Grant NO. 2004CB318109 and 2007CB311100. 
