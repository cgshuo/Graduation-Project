 In the past twenty years, the Web has evolved from a framework of information dissemination to a social interaction facilitator for its users. From the initial dominance of static pages or sites, with addition of dynamic content generation and pro-vision of client-side computation and event han-dling, Web applications have become a preva-lent framework for distributed GUI applications. Such technological advancement has fertilized vi-brant creation, sharing, and collaboration among the users (Ahn et al., 2007). As a result, the role of Computer Science is not as much of designing or implementing certain data communication tech-niques, but more of enabling a variety of creative uses of the Web.

In a more general context, Web is one of the most important carriers for  X  X ocial media X , e.g. In-ternet forums, blogs, wikis, podcasts, instant mes-saging, and social networking. Various engaging interactions among users in social media differ-entiate it from traditional Web sites. Such char-acteristics should be utilized in attempt to pro-vide intelligent services to social media users. One form of such interactions of particular inter-est here is user comments . In self-publication , or customer-generated media , a user can publish an article or post news to share with others. Other users can read and comment on the posting and these comments can, in turn, be read and com-mented on. Digg (www.digg.com), Yahoo!Buzz (buzz.yahoo.com) and various kinds of blogs are commercial examples of self-publication. There-fore, reader responses to earlier discussion provide a valuable source of information for effective rec-ommendation.

Currently, self-publishing media are becoming increasingly popular. For instance, at this point of writing, Technorati is indexing over 133 million blogs, and about 900,000 new blogs are created worldwide daily 1 . With such a large scale, infor-mation in the blogosphere follows a Long Tail Dis-tribution (Agarwal et al., 2010). That is, in aggre-gate, the not-so-well-known blogs can have more valuable information than the popular ones. This gives us an incentive to develop a recommender to provide a set of relevant articles, which are ex-pected to be of interest to the current reader. The user experience with the system can be immensely enhanced with the recommended articles. In this work, we focus on recommendation in Internet fo-rums and blogs with discussion threads.

Here, a fundamental challenge is to account for topic divergence, i.e. the change of gist during the process of discussion. In a discussion thread, the original posting is typically followed by other readers X  opinions, in the form of comments. Inten-tion and concerns of active users may change as the discussion goes on. Therefore, recommenda-tion, if it were only based on the original posting, can not benefit the potentially evolving interests of the users. Apparently, there is a need to consider topic evolution in adaptive content-based recom-mendation and this requires novel techniques in order to capture topic evolution precisely and to prevent drastic topic shifting which returns com-pletely irrelevant articles to users.

In this work, we present a framework to recom-mend relevant information in Internet forums and blogs using user comments, one of the most rep-resentative recordings of user behaviors in these forms of social media.

It has the following contributions.  X  The relevant information is recommended  X  We model the relationship among comments In a broader context, a related problem is content-based information recommendation (or filtering). Most information recommender systems select ar-ticles based on the contents of the original post-ings. For instance, Chiang and Chen (Chiang and Chen, 2004) study a few classifiers for agent-based news recommendations. The relevant news selec-tions of these work are determined by the textual similarity between the recommended news and the original news posting. A number of later proposals incorporate additional metadata, such as user be-haviors and timestamps. For example, Claypool et al. (Claypool et al., 1999) combine the news con-tent with numerical user ratings. Del Corso, Gull  X   X , and Romani (Del Corso et al., 2005) use times-tamps to favor more recent news. Cantador, Bel-login, and Castells (Cantador et al., 2008) utilize domain ontology. Lee and Park (Lee and Park, 2007) consider matching between news article at-tributes and user preferences. Anh et al. (Ahn et al., 2007) and Lai, Liang, and Ku (Lai et al., 2003) construct explicit user profiles, respectively. Lavrenko et al. (Lavrenko et al., 2000) propose the e-Analyst system which combines news stories with trends in financial time series. Some go even further by ignoring the news contents and only us-ing browsing behaviors of the readers with similar interests (Das et al., 2007).

Another related problem is topic detection and tracking (TDT), i.e. automated categorization of news stories by their themes. TDT consists of breaking the stream of news into individual news stories, monitoring the stories for events that have not been seen before, and categorizing them (Lavrenko and Croft, 2001). A topic is mod-eled with a language profile deduced by the news. Most existing TDT schemes calculate the similar-ity between a piece of news and a topic profile to determine its topic relevance (Lavrenko and Croft, 2001) (Yang et al., 1999). Qiu (Qiu et al., 2009) apply TDT techniques to group news for collabo-rative news recommendation. Some work on TDT takes one step further in that they update the topic profiles as part of the learning process during its operation (Allan et al., 2002) (Leek et al., 2002).
Most recent researches on information recom-mendation in social media focus on the blogo-sphere. Various types of user interactions in the blogosphere have been observed. A prominent feature of the blogosphere is the collective wis-dom (Agarwal et al., 2010). That is, the knowledge in the blogosphere is enriched by such engaging interactions among bloggers and readers as post-ing, commenting and tagging. Prior to this work, the linking structure and user tagging mechanisms in the blogosphere are the most widely adopted ones to model such collective wisdom. For ex-ample, Esmaili et al. (Esmaili et al., 2006) fo-cus on the linking structure among blogs. Hayes, Avesani, and Bojars (Hayes et al., 2007) explore measures based on blog authorship and reader tag-ging to improve recommendation. Li and Chen further integrate trust, social relation and semantic analysis (Li and Chen, 2009). These approaches attempt to capture accurate similarities between postings without using reader comments. Due to the interactions between bloggers and readers, blog recommendation should not limit its input to only blog postings themselves but also incorporate feedbacks from the readers.
 The rest of this article is organized as follows. We first describe the design of our recommenda-tion framework in Section 3. We then evaluate the performance of such a recommender using two different social media corpora (Section 4). This paper is concluded with speculation on how the current prototype can be further improved in Sec-tion 5. In this section, we present a mechanism for rec-ommendation in Internet forums and blogs. The framework is sketched in Figure 1. Essentially, it builds a topic profile for each original posting along with the comments from readers, and uses this profile to retrieve relevant articles. In par-ticular, we first extract structural, semantic, and authority information carried by the comments. Then, with such collective wisdom, we use a graph to model the relationship among comments and that relative to the original posting in order to eval-uate the impact of each comment. The graph is weighted with postings X  contents and the authors X  authority. This information along with the original posting and its comments are fed into a synthe-sizer. The synthesizer balances views from both authors and readers to construct a topic profile to retrieve relevant articles. 3.1 Incorporating Comments In a discussion thread, comments made at differ-ent levels reflect the variation of focus of read-ers. Therefore, recommended articles should re-flect their concerns to complement the author X  X  opinion. The degree of contribution from each comment, however, is different. In the extreme case, some of them are even advertisements which are completely irrelevant to the discussion topics. In this work, we use a graph model to differenti-ate the importance of each comment. That is, we model the authority, semantic, structural relations of comments to determine their combined impact. 3.1.1 Authority Scoring Comments Intuitively, each comment may have a different de-gree of authority determined by the status of its author (Hu et al., 2007). Assume we have  X  users in a forum, denoted by  X  = {  X  1 ,  X  2 , . . . ,  X   X  } . We calculate the authority  X   X  for user  X   X  . To do that, we employ a variant of the PageRank algo-rithm (Brin and Page, 1998). We consider the cases that a user replies to a previous posting and that a user quotes a previous posting separately. For user  X   X  , we use  X   X  (  X ,  X  ) to denote the number of times that  X   X  has replied to user  X   X  . Similarly, we use  X   X  (  X ,  X  ) to denote the number of times that  X   X  has quoted user  X   X  . We combine them linearly: Further, we normalize the above quantity to record how frequently a user refers to another:
Inline with the PageRank algorithm, we define the authority of user  X   X  as 3.1.2 Differentiating comments with Next, we construct a similar model in terms of the comments themselves. In this model, we treat the original posting and the comments each as a text node. This model considers both the content simi-larity between text nodes and the logic relationship among them.

On the one hand, the semantic similarity be-tween two nodes can be measured with any com-monly adopted metric, such as cosine similarity and Jaccard coefficient (Baeza-Yates and Ribeiro-Neto, 1999). On the other hand, the structural re-lation between a pair of nodes takes two forms as we have discussed earlier. First, a comment can be made in response to the original posting or at most one earlier comment. In graph theo-retic terms, the hierarchy can be represented as a tree  X   X  = (  X ,  X   X  ) , where  X  is the set of all text nodes and  X   X  is the edge set. In particular, the original posting is the root and all the comments are ordinary nodes. There is an arc (directed edge)  X   X   X   X   X  from node  X  to node  X  , denoted (  X ,  X  ) , if the corresponding comment  X  is made in response to comment (or original posting)  X  . Second, a comment can quote from one or more earlier com-ments. From this perspective, the hierarchy can be modeled using a directed acyclic graph (DAG), Figure 2: Multi-relation graph of comments based on the structural and semantic information denoted  X   X  = (  X ,  X   X  ) . There is an arc  X   X   X   X   X  from node  X  to node  X  , denoted (  X ,  X  ) , if the corre-sponding comment  X  quotes comment (or original posting)  X  . As shown in Figure 2, for either graph  X   X  or  X   X  , we can use a  X   X   X  X  X  X   X   X  adjacency ma-trix, denoted  X   X  and  X   X  , respectively, to record them. Similarly, we can also use a  X   X   X  X  X  X   X   X  ma-trix defined on [0 , 1] to record the content similar-ity between nodes and denote it by  X   X  . Thus, we combine these three aspects linearly:
The importance of a text node can be quantized by the times it has been referred to. Considering the semantic similarity between nodes, we use an-other variant of the PageRank algorithm to calcu-late the weight of comment  X  : where  X  is a damping factor, and  X   X , X  is the nor-malized weight of comment  X  referring to  X  de-fined as where  X   X , X  is an entry in the graph adjacency ma-trix M and  X  is a constant to avoid division by zero.
In some social networking media, a user may have a subset of other users as  X  X riends X . This can be captured by a  X   X   X  X  X  X   X   X  matrix of { 0 , 1 } , whose entries are denoted by  X   X , X  . Thus, with this infor-mation and assuming poster  X  has made a comment k for user  X   X  X  posting, the final weight of this com-ment is defined as 3.2 Topic Profile Construction Once the weight of comments on one posting is quantified by our models, this information along with the entire discussion thread is fed into a syn-thesizer to construct a topic profile. As such, the perspectives of both authors and readers are bal-anced for recommendation.

The profile is a weight vector of terms to model the language used in the discussion thread. Con-sider a posting  X  0 and its comment sequence {  X  1 ,  X  2 ,  X  X  X  X  ,  X   X  } . For each term  X  , a compound weight  X  (  X  ) = (1  X   X  )  X   X  1 (  X  ) +  X   X   X  2 (  X  ) is calculated. It is a linear combination of the contribution by the posting itself,  X  1 (  X  ) , and that by the comments,  X  2 (  X  ) . We assume that each term is associated with an  X  X nverted document fre-quency X , denoted by  X  (  X  ) = log  X  the corpus size and  X  (  X  ) is the number of docu-ments in corpus containing term  X  . We use a func-tion  X  (  X ,  X  ) to denote the number of occurrences of term  X  in document  X  , i.e.  X  X erm frequency X . Thus, when the original posting and comments are each considered as a document, this term frequency can be calculated for any term in any document. We thus define the weight of term  X  in document  X  , be the posting itself or a comment, using the standard TF/IDF definition (Baeza-Yates and Ribeiro-Neto, 1999):  X  (  X ,  X  ) =
The weight contributed by the posting itself,  X  0 , is thus: The weight contribution from the comments {  X  1 ,  X  2 ,  X  X  X  X  ,  X   X  } incorporates not only the lan-guage features of these documents but also their importance in the discussion thread. That is, the contribution of comment score is incorporated into weight calculation of the words in a comment.  X  2 (  X  ) =
Such a treatment of compounded weight  X  (  X  ) is essentially to recognize that readers X  impact on selecting relevant articles and the difference of their influence. For each profile, we select the top- X  highest weighted words to represent the topic.
With the topic profile thus constructed, the re-triever returns an ordered list of articles with de-creasing relevance to the topic. Note that our approach to differentiate the importance of each comment can be easily incorporated into any generic retrieval model. In this work, our retriever is adopted from (Lavrenko et al., 2000). 3.3 Interpretation of Recommendation Since interpreting recommended items enhances users X  trusting beliefs (Wang and Benbasat, 2007), we design a creative approach to generate hints to indicate the relationship (generalization, spe-cialization and duplication) between the recom-mended articles and the original posting based on our previous work (Candan et al., 2009).

Article  X  being more general than  X  can be in-terpreted as  X  being less constrained than  X  by the keywords they contain. Let us consider two ar-ticles,  X  and  X  , where  X  contains keywords,  X  1 and  X  2 , and  X  only contains  X  1 .  X  If  X  is said to be more general than  X  , then  X  If, on the other hand,  X  is said to be more
Note that, in the two-keyword space  X   X  1 ,  X  2  X  ,  X  can be denoted by a vector  X   X   X  ,  X   X   X  and  X  can be denoted by  X   X   X  , 0  X  . The origin  X  =  X  0 , 0  X  cor-responds to the case where an article does contain neither  X  1 nor  X  2 . That is,  X  corresponds to an article which can be interpreted as  X   X  1  X  X   X  2  X   X  (  X  1  X   X  2 ) . Therefore, if  X  is said to be more general than  X  ,  X   X  =  X  (  X ,  X  ) should be greater than  X   X  =  X  (  X ,  X  ) . This allows us to measure the degrees of generalization and specialization of two articles. Given two articles,  X  and  X  , of the same topic , they will have a common keyword base, while both articles will also have their own content, different from their common base. Let us denote the common part of  X  by  X   X  and com-mon part of  X  by  X   X  . Note that  X   X   X  and  X   X   X  are usually unequal because the same words in the common part have different term weights in article  X  and  X  respectively. Given these and the gener-alization concept introduced above for two similar articles  X  and  X  , we can define the degree of gen-eralization (  X   X  X  X  ) and specialization (  X   X  X  X  ) of  X  with respect to  X  as
To alleviate the effect of document length, we revise the definition as
The relative specialization and generalization values can be used to reveal the relationships be-tween recommended articles and the original post-ing. Given original posting  X  and recommended article  X  , if  X   X  X  X  &gt;  X   X  , for a given generalization threshold  X   X  , then B is marked as a generalization. When this is not the case, if  X   X  X  X  &gt;  X   X  , for a given specialization threshold,  X   X  , then  X  is marked as a specialization. If neither of these cases is true, then  X  is duplicate of  X  .

Such an interpretation provides a control on de-livering recommended articles. In particular, we can filter the duplicate articles to avoid recom-mending the same information. To evaluate the effectiveness of our proposed rec-ommendation mechanism, we carry out a series of experiments on two synthetic data sets, collected from Internet forums and blogs, respectively. The first data set is called Forum. This data set is constructed by randomly selecting 20 news arti-cles with corresponding reader comments from the Digg Web site and 16,718 news articles from the Reuters news Web site. This simulates the sce-nario of recommending relevant news from tradi-tional media to social media users for their further reading. The second one is the Blog data set con-taining 15 blog articles with user comments and 15,110 articles obtained from the Myhome Web site 2 . Details of these two data sets are shown in Table 1. For evaluation purposes, we adopt the tra-ditional pooling strategy (Zobel, 1998) and apply to the TREC data set to mark the relevant articles for each topic.
The recommendation engine may return a set of essentially the same articles re-posted at different sites. Therefore, we introduce a metric of novelty to measure the topic diversity of returned sugges-tions. In our experiments, we define precision and novelty metrics as where  X  is the subset of the top- X  articles returned by the recommender,  X  is the set of manually tagged relevant articles, and  X  is the set of man-ually tagged relevant articles excluding duplicate ones to the original posting. We select the top 10 articles for evaluation assuming most readers only browse up to 10 recommended articles (Karypis, 2001). Meanwhile, we also utilize mean aver-age precision (MAP) and mean average novelty (MAN) to evaluate the entire set of returned ar-ticle.

We test our proposal in four aspects. First, we compare our work to two baseline works. We then present results for some preliminary tests to find out the optimal values for two critical parameters. Next, we study the effect of user authority and its integration to comment weighting. Fourth, we evaluate the performance gain obtained from inter-preting recommendation. In addition, we provide a significance test to show that the observed differ-ences in effectiveness for different approaches are not incidental. In particular, we use the  X  -test here, which is commonly used for significance tests in information retrieval experiments (Hull, 1993). 4.1 Overall Performance As baseline proposals, we also implement two well-known content-based recommendation meth-ods (Bogers and Bosch, 2007). The first method, Okapi, is commonly applied as a representa-tive of the classic probabilistic model for rele-vant information retrieval (Robertson and Walker, 1994). The second one, LM, is based on statisti-cal language models for relevant information re-trieval (Ponte and Croft, 1998). It builds a proba-bilistic language model for each article, and ranks them on query likelihood, i.e. the probability of the model generating the query. Following the strat-egy of Bogers and Bosch, relevant articles are se-lected based on the title and the first 10 sentences of the original postings. This is because articles are organized in the so-called inverted pyramid style, meaning that the most important informa-tion is usually placed at the beginning. Trimming the rest of an article would usually remove rela-tively less crucial information, which speeds up the recommendation process.

A paired  X  -test shows that using  X  @10 and  X  @10 as performance measures, our approach performs significantly better than the baseline methods for both Forum and Blog data sets as shown in Table 2. In addition, we conduct  X  -tests using MAP and MAN as performance measures, respectively, and the  X  -values of these tests are all less than 0.05, meaning that the results of experi-ments are statistically significant. We believe that such gains are introduced by the additional infor-mation from the collective wisdom, i.e. user au-thority and comments. Note that the retrieval pre-cision for Blog of two baseline methods is not as good as that for Forum. Our explanation is that blog articles may not be organized in the inverted pyramid style as strictly as news forum articles. 4.2 Parameters of Topic Profile There are two important parameters to be consid-ered to construct topic profiles for recommenda-tion. 1) the number of the most weighted words to represent the topic, and 2) combination coeffi-cient  X  to determine the contribution of original posting and comments in selecting relevant arti-cles.We conduct a series of experiments and find out that the optimal performance is obtained when the number of words is between 50 and 70, and  X  is between 0.65 and 0.75. When  X  is set to 0, the recommended articles only reflect the author X  X  opinion. When  X  = 1 , the suggested articles rep-resent the concerns of readers exclusively. In the following experiments, we set topic word number to 60 and combination coefficient  X  to 0.7. 4.3 Effect of Authority and Comments In this part, we explore the contribution of user authority and comments in social media recom-mender. In particular, we study the following sce-narios with increasing system capabilities. Note that, lacking friend information (Section 3.1.2) in the Forum data set,  X   X , X  is set to zero.  X  RUN 1 (Posting): the topic profile is con- X  RUN 2 (Posting+Authority): the topic profile  X  RUN 3 (Posting+Comment): the topic profile  X  RUN 4 (All): the topic profile is constructed
Here, we set  X  1 =  X  2 =  X  3 = 1 . Our  X  -test shows that using  X  @10 and  X  @10 as performance measures, RUN4 performs best in both Forum and Blog data sets as shown in Table 3. There is a step-wise performance improvement while integrating user authority, comments and both. With the as-sistance of user authority and comments, the rec-ommendation precision is improved up to 9.8% and 21.6% for Forum and Blog, respectively. The opinion of readers is an effective complementarity to the authors X  view in suggesting relevant infor-mation for further reading.

Moreover, we investigate the effect of the se-mantic and structural relations among comments, i.e. semantic similarity, reply, and quotation. For this purpose, we carry out a series of experiments based on different combinations of these relations. Figure 3: Effect of content, quotation and reply relation  X  Content Relation (CR): only the content rela- X  Quotation Relation (QR): only the quotation  X  Reply Relation (RR): only the reply relation  X  Content+Quotation Relation (CQR): both the  X  Content+Reply Relation(CRR): both the con- X  Quotation+Reply Relation (QRR): both the  X  All: all three matrices are used.

The MAP yielded by these combinations for both data sets is plotted in Figure 3. For the case of Forum, we observe that incorporating content in-formation adversely affects recommendation pre-cision. This concurs with what we saw in our pre-vious work (Wang et al., 2010). On the other hand, when we test the Blog data set, the trend is the op-posite, i.e. content similarity does contribute to re-trieval performance positively. This is attributed by the text characteristics of these two forms of social media. Specifically, comments in news fo-rums usually carry much richer structural informa-tion than blogs where comments are usually  X  X lat X  among themselves. 4.4 Recommendation Interpretation To evaluate the precision of interpreting the re-lationship between recommended articles and the original posting, the evaluation metric of success rate  X  is defined as where  X  is the number of recommended articles,  X   X  is the error weight of recommended article  X  . Here, the error weight is set to one if the result interpretation is mis-labelled.

From our studies, we observe that the success rate at top-10 is around 89.3% and 87.5% for the Forum and Blog data sets, respectively. Note that these rates include the errors introduced by the ir-relevant articles returned by the retrieval module. To estimate optimal thresholds of generalization and specialization, we calculate the success rate at different threshold values and find that neither too small nor too large a value is appropriate for inter-pretation. In our experiments, we set generaliza-tion threshold  X   X  to 3.2 and specialization thresh-old  X   X  to 1.8 for the Forum data set, and  X   X  to 3.5 and  X   X  to 2.0 for Blog. Ideally, threshold values would need to be set through a machine learning process, which identifies proper values based on a given training sample. The Web has become a platform for social net-working, in addition to information dissemination at its earlier stage. Many of its applications are also being extended in this fashion. Traditional recommendation is essentially a push service to provide information according to the profile of in-dividual or groups of users. Its niche at the Web 2.0 era lies in its ability to enable online discus-sion by serving up relevant references to the par-ticipants. In this work, we present a framework for information recommendation in such social media as Internet forums and blogs. This model incor-porates information of user status and comment semantics and structures within the entire discus-sion thread. This framework models the logic con-nections among readers and the innovativeness of comments. By combining such information with traditional statistical language models, it is capa-ble of suggesting relevant articles that meet the dy-namic nature of a discussion in social media. One important discovery from this work is that, when integrating comment contents, the structural infor-mation among comments, and reader relationship, it is crucial to distinguish the characteristics of var-ious forms of social media. The reason is that the role that the semantic content of a comment plays can differ from one form to another.

This study can be extended in a few interest-ing ways. For example, we can also evaluate its effectiveness and costs during the operation of a discussion forum, where the discussion thread is continually updated by new comments and votes. Indeed, its power is yet to be further improved and investigated.
 Li X  X  research is supported by National Natural Sci-ence Foundation of China (Grant No.60803106), the Scientific Research Foundation for the Re-turned Overseas Chinese Scholars, State Educa-tion Ministry, and the Fok Ying-Tong Education Foundation for Young Teachers in the Higher Ed-ucation Institutions of China. Research of Chen is supported by Natural Science and Engineering Council (NSERC) of Canada.

