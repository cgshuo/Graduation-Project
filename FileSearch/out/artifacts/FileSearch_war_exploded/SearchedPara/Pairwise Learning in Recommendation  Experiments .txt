 Many online systems present a list of recommendations and infer user interests implicitly from clicks or other contex-tual actions. For modeling user feedback in such settings, a common approach is to consider items acted upon to be rel-evant to the user, and irrelevant otherwise. However, click-ing some but not others conveys an implicit ordering of the presented items. Pairwise learning, which leverages such implicit ordering between a pair of items, has been success-ful in areas such as search ranking [12, 14]. In this work, we study whether pairwise learning can improve commu-nity recommendation. We first present two novel pairwise models adapted from logistic regression. Both offline and online experiments in a large real-world setting show that incorporating pairwise learning improves the recommenda-tion performance. However, the improvement is only slight. We find that users X  preferences regarding the kinds of com-munities they like can differ greatly, which adversely affect the effectiveness of features derived from pairwise compar-isons. We therefore propose a probabilistic latent semantic indexing model for pairwise learning (Pairwise PLSI), which assumes a set of users X  latent preferences between pairs of items. Our experiments show favorable results for the Pair-wise PLSI model and point to the potential of using pairwise learning for community recommendation.
 H.3.3 [ Information Search and Retrieval ]: Information filtering; H.3.5 [ Online Information Services ]: Web-based services pairwise learning, community recommendation
An increasing number of recommendation systems on the web depend on implicit binary feedback  X  the presence or absence of a user action on an item. Examples of binary user actions include liking an item, following a person, join-ing a community or clicking through a news story. In such systems, user feedback differs from traditional rating-based systems in two important ways X  X eedback is only partial (neg-ative ratings are implicit), and always binary. The presence of only positive feedback creates a challenge in learning user preferences.

One intuitive approach is to consider items with positive feedback as relevant, and consider all the other items as irrel-evant. This is a common approach in collaborative filtering, and is an effective way of understanding user feedback [4, 7]. However, collaborative filtering algorithms work best when given ratings across the good-bad spectrum, and even typi-cal classification algorithms rely on a comparable number of positive and negative examples. To counter for the positive bias in feedback, another approach in literature has been to consider the problem as a special case of one-class classifi-cation and develop algorithms to generate artificial negative data [16, 15].

The above approaches, however, lose the relative nature of the information conveyed by the items that are shown to a user, but are not acted upon. Assuming a user sees all the recommendations and acts only on some of them, her inac-tion on certain items does not directly convey an absolute rejection of those items. Instead, we argue that it conveys an implicit negative feedback for those items, relative to the ones she acted upon. Thus, we can reasonably assume that clicked items are more relevant for the user than unclicked ones, though we cannot be sure about the absolute quality of unclicked items. This is the basis of pairwise learning, a popular approach for relevance feedback in search [3].
Past experiments with pairwise learning in collaborative recommendation systems have shown promising results [20, 17]. In this paper, we explore how a pairwise approach for preference learning can be used in a content-based recom-mender. In particular, we study the problem of recommend-ing communities to users, where a community is a social unit consisting of people with certain common characteristics or interests, for example, a LinkedIn group for RecSys 2013, a LinkedIn group for Cornell alumni, or a Facebook page for RecSys. Our findings are three-fold. First, we present gen-eral pairwise adaptations for content-based recommendation based on logistic regression, and show that pairwise mod-els are comparable and in general slightly better than the non-pairwise model. Second, we show that a direct pairwise adaptation might not yield significant improvement for com-munity recommendation, due to users X  vast different commu-nity preferences which make pairwise comparison less mean-ingful. Third, we present a probabilistic latent semantic in-dexing model for pairwise learning, which models latent user preferences and significantly outperforms the direct pairwise adaptation models and the non-pairwise model.
 Application domain. We choose community recommen-dation on LinkedIn.com as a domain for evaluating our rec-ommendation models. LinkedIn is the world X  X  largest pro-fessional network in which members create profiles and con-nect with other individuals. In addition, members are free to create and join communities (or groups 1 ) of their liking (subject to admin approval, in certain cases). Members may add themselves to a group when they see it on another mem-ber X  X  profile, through search or when they get recommenda-tions. At present, there are more than 2 million groups on LinkedIn. The recommendation problem is to select a set of top-k groups to join for each user.

Figure 1 shows a typical recommendation interface. A user is presented with a list of k recommendations. A user conveys positive feedback by either clicking the link corre-sponding to a group, and/or choosing to join the group. However, the interface does not allow negative feedback, which provides a motivation for using pairwise learning.
We first discuss pairwise learning, and its relevance for recommendation systems. In the second part of this section, we present previous work on community recommendation.
Understanding implicit feedback has been an active prob-lem for search engines. Joachims [9] was the first to show how information retrieval can be improved by considering user feedback in pairs of items. He assumed that users are more likely to see items ranked higher in the list (position bias [6]). Thus, between a clicked item and an unclicked item ranked higher than that item, we can infer safely that the clicked item is more relevant than unclicked one. These clicked and unclicked items in search logs are clubbed to-gether to form pairs, which convey a relative ordering be-tween their constituent items. Encoding user actions into
We use the term community recommendation to disam-biguate against the more common use of the term group recommendation to me an recommendation for groups. pairwise preferences converts the problem into a classifica-tion problem on pairs, instead of classifying relevance for individual items. This approach was shown to improve re-trieval results, and is now a popular method of relevance feedback in search engines [12, 14].

In principle, one could construct triplets, or even arbitrary lists [3] to encode relative preference. However, in a recent paper, Radinsky and Ailon [18] demonstrate that triplets do not give any more information than pairs in terms of the sta-tistical significance of preference. Further, in a user study, Joachims et al. [10] provided empirical support for the pair-wise approach by showing that people are more consistent at making comparisons between items than evaluating on an absolute scale of relevance or quality. The use of pairs is also consistent with an axiom in decision theory, which states that the relative attractiveness of two choices does not depend upon other choices available (Independence of Irrelevant alternatives [19]).

Apart from using click logs, pairs can also be constructed in other ways to convey relative preference of users. For example, Balakrishnan and Chopra [1] have proposed an adaptive scheme in which users are explicitly asked for their relative preference between a pair of items. Thus, users give pairwise feedback to the underlying algorithm, which up-dates user parameters as it receives more responses. Instead of pairs of items, one may also ask users to order a set of items [11]. Though it may provide an accurate measure of a user X  X  preference, explicitly asking users for their preference may not be feasible for large numbers of users or items, or desirable as a design strategy in certain cases.

To the extent that recommendations are shown as an or-dered list, the problem of recommendation quality is similar to that of relevance in search engines. Just as relevance in search depends on the information need, quality in recom-mendation depends on the user preference and context. For matrix factorization and kNN models, recommendation per-formance on movies has been shown to improve by incorpo-rating pairwise preferences from recommendation feedback logs [20]. A pairwise strategy may also be applied to explicit ratings, where pairs are generated by comparing Likert-scale ratings of a user [13, 17]. In the present work, we focus on problem domains where such rich ratings are not present, us-ing content-based recommendation models. As in [9], we use system logs of clicked recommendations to construct pairs.
We now present a brief overview of previous work on com-munity recommendation. In one of the first papers on com-munity recommendation, Spertus et al. [21] used similarity measures to recommend communities in Orkut which are similar to a particular community. Chen et al. [4] extended the work on Orkut communities and compared two different algorithms, Association Rule Mining and Latent Dirichlet Allocation for the purposes of community recommendation. In [5], Chen et al. describe a latent model that conditions a user joining based on the hidden topics that a community represents. In another domain (Flickr), different memory-based and model-based approaches have been compared in terms of top-k recommendation, and tags were found to be helpful [22].

Owing to the rich profile data (education, career, skills, in-terests, publications etc.) available for each user on LinkedIn, we adopt a content-based approach to recommendation. This is not unlike many other online social networks, where users self-create an elaborate personal profile. For example, Face-book hosts a profile for each user which spans a user X  X  inter-ests. LinkedIn groups, especially, is an example of a recom-mendation domain where we have rich data about a user as well as the group. We build on previous work by adapting a similarity-based algorithm (logistic) and a latent model (PLSI) with pairwise feedback and comparing their perfor-mance to non-pairwise models.
For clarity, let us first formally define the problem. Given auser u , the recommendation task is to suggest communities that may be of interest, from a set of candidate communities Y . Suppose there are | U | = m users and | Y | = n communi-ties. Each observed preference is in the form of a tuple ( u, y ), where u is a user, y is a community, and u  X  X  1 , 2 , 3 ...m y  X  X  1 , 2 , 3 ...n } . We assume that we are given a set of known ( u, y ) and the task is to predict a set R ( u )foreach user which denotes recommendations for a user u .
For our problem, we specify another variable s which de-notes the impression list, or the communities that are shown together to a user. For example, in Figure 1, the three com-munities presented will belong to the same impression list. Thus each observation is given as a ( u, y, s ).
 Current system. There are three main components: fea-ture generation, model learning, and computation of the results from the learned model. Although continual fea-ture generation and free-text standardization over millions of members is a complex problem in itself, here we provide a brief overview. Features for members are largely profile-driven, such as skills, industry, pa st positions, e ducation etc. Similarly, a group is represented by features such as group summary and category. In addition, a group X  X  features are also constructed in aggregate from the features of its con-stituent members. Elements of these two feature sets are matched to each other, to determine similarity between a user and a group. In the limiting case, the number of match-ings can be quadratic in the number of features. Thus, in-dividual features are matched only when semantically rel-evant. For example, it may be useful to match the group description with  X  X nterests X  feature for a user, but not with the  X  X onnection counts X  feature. For every user and group, a dot product of matched user-group features ( u.y )givesus a similarity score. In addition, we introduce social features that reflect user-group interactions, for instance, whether and how many friends of a user have joined a group. The final similarity vector conveys the degree of similarity be-tween a user and a group. All models described utilize the similarity feature vector, thus constructed.

We now describe the current model in production on LinkedIn (as of May 2012), starting from some basic definitions. Given a similarity vector for each pair of user and item, a simple recommendation model can be described as: for some &gt; 0, where Sim ( f u ,f g ) is the similarity vector for user u and group y feature vectors. If the similarity function is just a dot product of the vectors, we get: where w i represents the relative importance of different simi-larity features. Using the sigmoid function for similarity and setting =0 . 5, we can represent the problem in the form of standard logistic regression.

Given this model, we precompute the similarity between a users and all items. For each user, the most similar items can be chosen for recommendation. This is the baseline model implementation for our experiments.
 Pairwise approach. We now turn to the preliminaries for using pairwise approach for recommendation. We first discuss how pairs are created from group-join data.
The first step is to access the group-join log as well as the recommendation impressions log. To connect a group-join with a recommendation impression, we choose the latest impression for each user-item pair and select all group-joins which occured within 10 minutes of the impression (a rec-ommendation is not shown after a user joins a group). This is a conservative assumption, considering that the join may still happen on account of the impression or otherwise. But for the purposes of this study, a hard stance of 10 minutes is taken. We now have a a set of ranked impression lists. Each element of the ranked list contains an item and an indicator of whether it led to a group-join or not. From these lists, we create item pairs by the following rule (see [9]): where I y 2 and I y 1 represent impressions in the same list for y 2and y 1. Once we have the pairs, we define a variable t for each user and a pair of items ( y 1 ,y 2 ), such that the learning problem translates to a classification problem on t . given a user u and two items y 1 and y 2 .

Note that our above strategy for creating pairs will lead to pairs where the first group in the pair is always higher in preference ( t = 1) than the second group. To ensure equal number of positive and negative examples for classification, we randomly invert all pairs with probability 0 . 5.
Any classification algorithm can be used to learn prefer-ences on pairs, thus constructed. However, an important re-quirement is to have a fast way of ranking individual items, once we have a learnt a model for classifying pairs. For a naive implementation, ranking k items will require con-structing O ( k 2 ) pairs, which will be too computation inten-sive. For the best performance, the ranking function should be independent of the pairs. In the next two sections, we discuss how we can derive fast ranking functions for logistic regression and PLSI-based pairwise models.
We now describe two pairwise models derived from logistic regression. We assume that we are given a list of M known pairwise preferences t u ( y i ,y j ). Let us define an item ranking function h  X  ( y ), which has the following property (as in [9]): Then our task is to learn such a function h  X  from the avail-able pairwise preferences. We make a simplifying assump-tion that pairwise preferences are independent of each other, drawing on the Independence of Irrelevant Alternatives as-sumption from decision theory literature [19]. Thus, our task can be set-up as a likelihood maximization problem: If we redefine t in terms of h , then we can write the equivalent maximization problem. maximize  X  M k =1 P [ h  X  ( y j )  X  h  X  ( y i )] t P [ h  X  maximize  X  M k =1 P [ h  X  ( y j )  X  h  X  ( y i )] t (1  X  P [ h Basedonhowwemodel h  X  ( y ), the above formulation gives rise to two novel pairwise models.
In the special case that h  X  ( y ) is a linear function, we have h ( y )=  X  T y . Then the problem reduces to: max  X  M k =1 P [  X  T ( y j  X  y i )  X  0] t (1  X  P [  X  T ( y Taking y ji = y j  X  y i , this formulation is the same as standard logistic regression with features y ji . Hence if we assume that the ranking function is linear, we can simply learn a logistic model on the difference of features of the items. To rank the items, we use the linearity property again. We can see that h  X  ( y j )  X  h  X  ( y i )  X  y j  X  y i . Thus, it is sufficient to calculate  X   X  T y i for each item to rank the items.
The feature difference model lends itself well to a stan-dard learning framework, but makes a strong assumption about the ranking function. We now propose a model for any general ranking function. We define: as the difference in ranking scores for two items y i and y Then, we can write P ( t | y i ,y j )as(wheretisasbefore): Since h  X  ( y )  X  [0 , 1], we add the additional constants to en-sure that the P ( t | y i ,y j )  X  [0 , 1]. This formulation is based on the intuition that difference in ranking scores for two items is proportional to the probability of one being more preferred than the other.

We can now frame this as a maximum likelihood estima-tion problem. l (  X  )= max
Using gradient descent,
We can use any ranking function h  X  in the above equa-tion. For our experiments, we choose the logistic function because it is used as the base for LinkedIn recommendation platform. Setting h  X  ( y )= 1 1+exp(  X   X  T y ) ,wegetthegradient in Equation 3 (Figure 2).

The likelihood can be optimized using any of the gradient methods. We use L-BFGS 2 in our implementation. For generating top recommendations, we have to order items by h  X  ( y ). Since logistic is an increasing function, this reduces to ranking items based on their  X   X  T y scores, as in the Feature Difference model.
Given the success of pairwise learning in domains such as information retrieval, it is natural to expect similar improve-ment in recommendation. However, as that will be shown later in Section 6, the two pairwise models described above only slightly outperform a baseline non-pairwise model.
One of the major reasons for the limited improvement is the heterogeneity in communities and users X  vast different preferences for the communities they want to join, which make features derived from pairwise comparison less effec-tive. For example, a user might look to expand her net-work. Thus even though a relevant interest-based group (e.g, a machine learning group) is recommended, the user might choose an alumni group instead, which as a result of pairwise comparison would penalize the feature represent-ing user interest and reward the feature representing user X  X  education history. When presented with a similar list of recommendations, however, another user might choose an interest group over an alumni group, thus producing the op-posite impact on the two features. In the extreme case that an equal number of users make the opposite choices, the two features representing interest and education would not serve as discriminative features as we would have expected.
We now present a pairwise model that also accounts for variation in users X  preferences towards different features, by treating a user as a mixture of some latent preferences. Our model is based on probabilistic latent semantic indexing [8]. The intuition is that users may have different reasons for joining a group, such as networking, learning skills or for social support 3 . Each user may also value these reasons dif-ferently. Assuming the possible reasons people join groups are consistent across users, we can think of each user X  X  de-cision to join a group as a combination of these reasons, or core preferences .
 Figure 3 shows the plate notation for our proposed model. We assume that each user can be described by a set of Z core latent preferences. We also assume that given a core prefer-ence z and two items y i and y j , the preference value t for the two items is independent of the user. Thus, when presented with a pair of communities ( y 1 , y 2 ), a user X  X  decision is com-puted from the mixture of core preferences, weighted by the relative importance of each core preference to the user. http://www.chokkan.org/software/liblbfgs/
We verified this intuition by considering different types of groups on LinkedIn (networking, professional, alumni, phi-lanthropy, corporate and conference) as proxies for reasons to join. Using a random sample of 1M users, we found that most users join groups of more than one type; mean number of group types per user is 3 . 1 and median is 3. In accordance with the above assumptions: where t is as before, and z is a latent variable representing core preference. Then, for all training pairs, using maximum likelihood estimation,
We discuss modeling choices first, and then describe learn-ing and inference for the model.
The parameter Z controls how much personalized the model is  X  a Z value of | U | effectively creates a different core pref-erence for each user. There is a tradeoff between accurately modeling a user X  X  preference and model size. A paper de-scribing Google news recommendation [7] followed a compa-rable approach by assigning a different probability for each user. In the present case, however, that would result in a lot of parameters to learn since the number of parameters in the model is linear in the number of latent preferences. Hence, we consider | Z | to be a small positive number (  X  for our experiments). We have two model choices to make, P ( t | y i ,y j ,z )and P ( z | u ). For the first, we may use any of the user-agnostic models (latent preferences do not change across users). In the following analysis, we use Logistic Loss as our base model.

P ( z | u ) represents the relative propensity of users to asso-ciate with different latent preferences. We use a softmax-based multinomial function to represent this probability.
We use Expectation-Maximization to fit the parameters to the model, assuming z as the hidden random variable. Thus, we maximize the likelihood:
Let Q z be an arbitrary distribution over z ,foreach k th training example &lt;u,y i ,y j &gt; . Then, the E step yields: And the M-step becomes:  X  := argmax  X   X  := argmax  X  Substituting the Logistic Loss and the multinomial models, we get the equivalent equations shown in Figure 2. Un-like [8], for the pairwise case, we do not get a closed form expression in the M-step. Hence, we use gradient descent to compute the maximization in each M-step, as shown in Figure 2.
Once we have fitted the parameters, we can compute the output class of a pair as follows:
To generate recommendations, we would need a way to rank the communities for a user. It turns out that we get a simple metric for the logistic loss base model, that can be used to rank the recommendations. This becomes possible due to a special property of the logistic and multinomial functions. We present it next.

Theorem 1. Let P ( t | u, y i ,y j ) be the probability that y is preferred over y i , given by where P ( t | y i ,y j ) is a logistic function, and P ( z nomial distribution. Then A y k = z h  X  z ( y k ) P ( z valid ranking function.

Proof. Let us assume there exist two items y i ,y j for which P ( t | u, y i ,y j ) is computed. We further assume that y function values A 1 and A 2 ,of A y function.

We will proceed to show that A 2 &gt;A 1  X  P ( t | u, y i 0 . 5 by showing A 2  X  A 1 =2 P ( t | u, y i ,y j )  X  1. Consider Using Equation 8, Hence proved. We now turn to the evaluation of our proposed models. We first compare the time complexity and scalability of the algorithms, followed by offline evaluation, and finally an on-line evaluation on linkedin.com.
We analyze the time complexi ty for two major operations  X  model learning (offline), and recommendation computa-tion (online). In a typical scenario, a learned model is used to recompute recommendations frequently for all the users, to utilize new user feedback. But because model learning is not done so frequently, a model with low online complexity and reasonable offline complexity is acceptable.

If L is the size of the recommendation list shown to a user, and J is the total number of group joins, then the number of pairs P generated is O ( L  X  J ). For both pairwise models, one step of the gradient descent takes O ( F  X  P ), where F is the number of features. In contrast, Pairwise PLSI model is slower to learn, since learning is based on EM iterations. Each E step takes O ( Z  X  P ) time, and each M-step consists of another minimization using gradient descent, which is O ( Z  X  P 2 ).

For non-latent pairwise models, it takes constant time ( O ( F )) to compute ranking score for each user and item. For Pairwise PLSI model, the corresponding time complex-ity is O ( Z  X  F ), where F is the number of features. Thus, ranking for each item is fast in all three algorithms, provided Z is small (2-8).

The parametric models also lend themselves to parallelized rank computation. Given the same model file, different nodes can compute recommendation lists for different users independently. Thus, we can easily scale recommendation computation for millions of users.
We collected log data for group recommendation over the summer of 2012. The log entries were converted to pairs as described in Section 3. Table 1 shows some statistics for the data. The number of group-pairs are 13 per user on average. For prediction, the test data was selected from logs beginning from a later date than the training data. We chose a relatively small train dataset to speed up model fitting as the learning gains from a bigger dataset were not substantial.
The baseline is a logistic regression model that does not use pairs for learning, as represented in Equation 1. We compare the two base pairwise models, Feature Difference and Logistic Loss, and three versions of the Pairwise PLSI model, with Z  X  X  2 , 4 , 8 } .
 Learning pairwise preferences. We first evaluate how well the models learn user preference within a pair of groups, by framing it as a classification task. For each pair of groups ( y 1 ,y 2 ) in the dataset, we classify the pair as positive (1) if y is more preferred than y 1 , and zero (0) otherwise. For all models, 5-fold cross validation is used during training. We report accuracies of different models on the pair classifica-tion task and compare them in Table 2.

Among non-latent models, Feature Difference delivers the highest accuracy for pair classification, but both pairwise models beat the baseline. Latent models perform better than the other algorithms. Performance of Pairwise PLSI increases with the number of latent preferences, although the relative boost decreases with z . We next see how the accuracy varies for different users.
 Per user accuracy. One of the goals of recommendation is user satisfaction, and hence we desire a model that delivers  X  X ood X  recommendation to all users. For our purposes, we define  X  X ood X  to be the fraction of group-pairs for a user in the test set that are correctly classified. More precisely, Figure 4 shows frequency plots of the per user accuracy of the algorithm in the group-pair classification task, for Fea-ture Difference and Pairwise PLSI( Z = 2). We see that the number of users with non-zero correct classification increase with the Pairwise PLSI model. Also, the number of users with PUA &gt; 0 . 5 is higher for Pairwise PLSI. This suggests that the Pairwise PLSI gives an overall better recommenda-tion experience per user.
 Top-k recommendation. We now evaluate the algorithms on the list of groups returned as recommendation. We choose top-k metric for comparing the different models, with k  X  { 5 , 10 , 25 } . For any k , the top-k metric is defined as the number of groups among the highest ranked k recommenda-tions that are also joined by the user in the test data. k =5 and k = 10 represent the number of group recommendations typically shown on the homepage, and on the groups page of LinkedIn respectively.

Generating a test set for evaluation is non-trivial due to presentation bias [2]. Since the baseline algorithm also gen-erated recommendations for the users during the test period, there might be a bias in the groups that a user gets exposed to for joining. In one scenario, we could collect all group joins and label them as positive examples. In an alterna-tive overcompensatory scenario, we remove all group joins that happened because of a recommendation and consider the rest as the examples to test on. These are groups that are joined by  X  X rganic X  traversal of the website, and hence are a closer estimate of user X  X  preference. We use both types of test sets for evaluation.

Tables 3a and 3b show the top-k metric for the models, under the two versions of the test set. As expected, the num-ber of correctly retrieved groups increases with the increase in k for all models. We observe that Feature Difference again performs better than Logistic Loss among the base pairwise models, but the difference is only slight. The Pairwise PLSI model outperforms all the others, offering a more than 10% boost over the baseline top-5 metric for both test scenarios.
To test whether offline evaluation translates to on-site performance too, we compare the performances of pairwise models after deploying them on the LinkedIn website. We ran the logistic loss and feature difference models to a 5% subset of total LinkedIn users respectively, in addition to the current baseline model, for a period of 2 weeks. We evaluate the click-through-rate (CTR) of the recommendations. The pairwise models perform slightly better, as predicted by the offline analysis. In particular, Feature Difference reports a lift of 5% on the CTR metric (Table 4).

Thus, our results suggest that there is value in learning from pairwise feedback. Although the performance boost using only base pairwise algorithms is slight, Pairwise PLSI modelperformsbetteronbothtop-k and classification met-rics. However, the tradeoff is in the learning time of the model, which is considerably higher for Pairwise PLSI.
As users interact with online recommender systems more and more, understanding user feedback has become impor-tant for recommendation quality. We presented our results of applying pairwise learning to community recommenda-tion. Our experiment results show that pairwise models di-rectly adapted from a baseline recommendation model per-form better than the baseline non-pairwise model, although only slightly. We argue that the nature of community recom-mendation does not lend itself well to pairwise comparision due to vast different user preferences towards communities. To that end we proposed a probabilistic latent preference model (Pairwise PLSI) which assumes a set of inherent pref-erences within each user. Offline evaluation shows that the Pairwise PLSI model significantly outperforms other models. Acknowledgments The authors would like to thank Dan Cosley, for feedback on initial drafts of the paper, and LinkedIn for providing the data used in the experiments.
