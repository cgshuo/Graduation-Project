 1. Introduction
Twitter is a service which allows users to publish short text messages (tweets) which are shown to other users following the author of the message. In case the author is not protecting his tweets, they appear in the so-called public timeline and they are served as search results in response to user submitted queries. Thus, Twitter can be a source of valuable real-time information and, in fact, several major search engines were including tweets as search results at the moment of this writing.
Given that tweets are published by individual users, ranking them to find the most relevant information is a crucial mat-ter. Indeed, at the moment of this writing, Google seemed to be applying the PageRank method to rank Twitter users to that end ( Talbot, 2010 ). Nevertheless, the behavior of different graph centrality methods and their vulnerabilities when con-fronted with the Twitter user graph, in general, and Twitter spammers in particular, are still little-known.
Thus, this paper aims to shed some light on this particular issue besides providing some recommendations for future re-for other tasks. Hence, this author is not considering any a priori  X  X  X ood X  X  ranking and, instead, he suggests measuring the per-formance of the different methods on the basis of two desirable features: on one hand presumed relevant users should rank atop  X  although the actual ordering among them is irrelevant; and, on the other hand, spammers should achieve lower rankings.

The paper is organized as follows. First of all, a comprehensive literature review is provided. It deals with several rank prestige algorithms (some well-known and others lesser-known) which are applicable to social networks; their known vul-nerabilities; and some partially related work and proprietary tools outside the scope of this study. In addition to that, Twitter  X  spam is discussed with a focus on link spam (known as follow spam in Twitter). Then, the different strategies to fight spam in social websites are overviewed. Finally, the research questions are stated and the feasibility of  X  X  X esensitizing X  X  prestige ranking algorithms against follow spam is analyzed. After that, the experimental framework in which this study was conducted is described: the dataset crawled from Twitter; the elaboration of the subset of relevant and abu-sive users; and the straightforward nature of the evaluation. Afterwards, results obtained with each of the different ranking methods are discussed along with the implications of the study. Finally, an in-depth analysis of the collected dataset is provided in an appendix: it provides details on the nature of the social network, in addition to some demo-graphical analysis. 2. Literature review
A social network, despite the current association with online services, is any interconnected system whose connections are a product of social relations or interactions among persons or groups. That way, families, companies, groups of friends, or scientific production are social networks.

Social networks can be mathematically modeled as graphs and, thus, graph theory has become inextricably related to so-cial network analysis with a long history of research. Think, for instance, of bibliometric studies that can be traced back to
Broadman (1944), Fussler (1987), Gross and Gross (1987), and Lotka (1987) , although the work by Garfield (1972) is, with no doubt, the one with the highest impact on the daily life of nowadays scholars. However, it is not our aim to provide a survey on this topic; we recommend the reader interested in social network analysis from a Web mining perspective the corre-sponding chapters from the excellent books by Chakrabarti (2002) and Liu (2006) . Instead, for the purpose of this paper it should be enough to briefly sketch the concepts of centrality and prestige .

Both centrality and prestige are commonly employed as proxy measures for the more subtle ones of importance, author-ity, or relevance. Thus, central actors within a social network are those which are very well connected to other actors and/or relatively close to them; this way, there exist several measures of centrality such as degree, closeness, or betweenness centrality.

While centrality measures can be computed for both undirected and directed graphs, prestige requires distinguishing in-bound from outbound connections. Thus, prestige is only applicable to directed graphs which, in turn, are the most common when analyzing social networks.

As with centrality, there are several prestige measures such as indegree (the number of inbound connections, e.g. cites, in-links, or followers), proximity prestige (related to the influence domain of an actor, i.e. the number of nodes directly or indi-rectly linking to that actor), and rank prestige, where the prestige of a node depends on the respective prestige values of the Given their importance, and for the sake of clarity, a comparison between the two last prestige measures is provided.
Proximity prestige is computed as the mean length of all the shortest paths connecting a given node to the nodes within its influence domain. In other words, proximity prestige measures reach as the mean number of  X  X  X ops X  X  between a node and all of the nodes linked (directly or indirectly) to it. In contrast, rank prestige takes into account the prestige of nodes linking (directly or indirectly) to a given node  X  that X  X  why it requires iterative algorithms  X  and, in some sense, it describes how well connected is a node to other well connected nodes.

Rank prestige is, by far, the most commonly used prestige measure and there exist a number of well-known methods to compute one or another  X  X  X lavor X  X  of such a measure. In the following subsection we will briefly review the popular PageRank , and HITS algorithms, in addition to lesser-known (although better targeted at social media) techniques such as NodeRanking ,
TunkRank , and TwitterRank , besides their weaknesses in different abusive scenarios. 2.1. Rank prestige algorithms 2.1.1. PageRank
PageRank ( Page et al., 1998 ) is, in all probability, one of the best known rank prestige methods because it underlies the Google search engine ( Brin &amp; Page, 1998 ). The PageRank algorithm aims to determine a numerical value for each document in the Web, such a value would indicate the  X  X  X elevance X  X  or  X  X  X uthority X  X  of that given document. That value, also known as PageRank , spreads from document to document following the hyperlinks  X  previously it must be divided by the number of outgoing links. That way, heavily linked documents tend to have larger PageRank values, and those documents receiving few links from highly relevant documents (i.e. documents with large PageRank values) also tend to have large PageRank values.

After iterating a finite (in fact a relatively short) number of steps the algorithm converges; at that moment all the nodes within the graph have got a PageRank value by means of which they can be ranked. A notable property of the algorithm is that the global amount of PageRank within the graph does not change along the iterations but it just spreads from some nodes to other ones. Thus, if the total amount of PageRank in the Web was arbitrarily fixed at 1 we could see the PageRank value for a given document as a proxy for the probability of reaching that given document by following links at random (that X  X  why PageRank is often described as a random surfer model ). Such a model is described by Eq. (1) , where PR(p) is the PageRank value for webpage p , M(p) is the set of webpages linking to p and L(p) is the set of pages linked from p .
Of course, this description is an oversimplification because it makes several unreal assumptions, namely that the Web is a strongly connected graph, and that there are no sink nodes (i.e. nodes with in-links but no out-links). In order to solve this, a modified version including a damping or teleportation factor is shown in Eq. (2) : d is the damping probability (usually 0.15), and N is the total number of webpages in the graph.
 2.1.2. HITS Hyperlink-Induced Topic Search  X  HITS ( Kleinberg, 1998 ) is another algorithm to estimate the relevance of a document.
The method assumes the existence of two different kinds of documents in the Web: authorities and hubs . An authority is a heavily linked document because each inbound link is a  X  X  X ote X  X  cast by the user linking that document. Conversely, a hub is a document comprising links to several authorities; therefore, hubs are valuable resources in the Web X  X  ecosystem because they ease users the task of finding relevant information.

Because webpages can exhibit both characteristics every document in the Web has associated two different scores: namely, its authority score and its hub score. It must be noticed that HITS is not aimed to be computed across the whole
Web graph but, instead, within a query dependent subgraph composed of those documents already satisfying a given query (obtained by means of a standard information retrieval system), plus those documents linked from, or linking to documents in that result set.

Therefore, HITS starts with a relatively small Web subgraph and iteratively computes both scores for every page in the graph. As it can be seen in Eqs. (3) and (4) authority and hub scores mutually reinforce themselves; the authority score for a given page p is the sum of the hub scores of those pages q linking to p ( E is the set of edges in the graph) while the hub score for a page p is the sum of the authority weights for those pages q linked from p . It must be noticed that with each iteration both scores must be normalized so their squares sum to 1. HITS ,as PageRank , converges after a number of iterations.
Finally, although HITS was not devised to compute scores for complete graphs, but rather topic-oriented subgraphs, it can of course be applied to a whole graph and, in fact, that is the way in which we are going to apply it to the Twitter user graph, using the computed authority scores to rank the users. 2.1.3. Abusing HITS and PageRank
In spite of claims on the original PageRank paper about being  X  X  X irtually immune to manipulation by commercial interests X  X  , the fact is that both PageRank and HITS are prone to manipulation or, at least, they have weaknesses that can be exploited under certain circumstances.

Bharat and Henzinger (1998) describe three scenarios were hyperlink analysis methods (a) can be abused, or (b) fail be-cause of wrong assumptions. Such scenarios are: (1) mutually reinforcing relationships between hosts, (2) automatically generated links, and (3) non-relevant nodes.

The first case occurs when a document in a host is linked by many documents from a second host; because each link is counted as a single vote although they are, in all probability, published by the same author, a single individual  X  the one pub-lishing the links  X  is earning undue importance. This phenomenon is the underlying base for the so-called link farms which pla-gue the Web, and is also somewhat related to Sybil attacks
The second scenario does not describe an abusing situation per se , but an assumption made by hyperlink analysis meth-ods that eventually proved wrong: that links are published by human beings where many of them are in fact, automatically generated. 2 Although not totally equivalent, behaviors in social networks such as auto-following users, can for sure bias the results eventually obtained by algorithms such as HITS or PageRank .

The third and last scenario, namely non-relevant nodes, especially affects HITS . Bharat and Henzinger describe how doc-uments not relevant to the query topic can drift the results if they are well connected. In contrast to the previous two sce-narios, for which we can find comparable situations within a social network setting, this third one is a little more elusive. In truth, this situation can only be broadly compared with one of the most common spamming behaviors in Twitter, namely getting the more followers the better no matter the relation between the contents promoted by the spammer to the potential interests of the eventual followers. 2.1.4. NodeRanking
NodeRanking ( Pujol, Sang X esa, &amp; Delgado, 2002 ) can be considered another variation of the random surfer model with authority spreading from one node in the graph to those linked from it. The main differences between NodeRanking and Page-
Rank are two: (1) it is devised to work on weighted graphs and (2) the damping/teleportation parameter is not fixed for the whole graph but is computed for each node and depends on the outbound connections of the node (see Eq. (5) ). According to its authors, this feature makes NodeRanking  X  X  X ble to adapt dynamically to graphs with different topologies X  X  .
Thus, Eqs. (5) X (7) underly this algorithm. P jump (p) is the probability of damping each node p . As it can be seen, nodes with few outbound links have a greater probability of being damped; this could be interpreted as the random surfer getting bored because of the limited set of choices.

P choose (p) , is the probability of a page p to be chosen by the random surfer after visiting page q (which, of course, would have a link to p ). In the original work by Pujol et al. this equation employs the edge weight from q to p in the numerator, and the sum of the weights for all of the links departing from q in the denominator. In this work the edges in the social graph are weightless and, thus, we are showing a simplified version of the original P page q would continue to any of the p pages linked from q with equal probability.

Finally, Eq. (7) describes how authority is  X  X  X ransferred X  X  from a node q to a node p linked from q . As it can be seen, the authority of q is weighted according to the probability of visiting p after q and then it is accumulated on the current authority of p . Since this would cause authority values approaching infinity Pujol et al. introduced a correcting factor F both on the authority of page p and the total authority of the whole graph (this is very similar to the normalization of values required by the HITS algorithm).
 2.1.5. TunkRank
As we have already said, both PageRank and HITS (in all probability the most commonly applied methods) are prone to manipulation when applied to the Web graph, in general, and to the Twitter user graph (or any other social network graph), in particular. Thus, it could be wise to propose methods tailored to the particular circumstances of social networks. One of such methods is the one originally proposed by Tunkelang (2009) and later named TunkRank for obvious reasons.
TunkRank defines influence as a numerical estimate for the number of people who will eventually read the tweets by a account two constrains:
First, the influence of a user A following a user B is not transmitted in full to B ; instead, A distributes his influence evenly among all of his followees. The intuition behind this is that attention of users is scarce and must be spread; without addi-tional knowledge an even distribution is the most sensible assumption.

Second, a tweet by user B will not be read by followers of A unless A retweets it; therefore, since influence is an estimator of the reach of a user X  X  tweets the probability of retweeting ( p ) must be incorporated.

Tunkelang suggests computing users X  influence recursively and argues that, although infinite for graphs containing cycles, it would converge as powers of p approach zero. In fact, shortly after describing this method an implementation for TunkRank was publicly released. 4
Eq. (8) shows the way in which influence for a given user X can be computed. As it can be seen, the equation incorporates all of the aforementioned constrains. The even distribution of attention to followees is expressed by means of the denom-inator, where |Following(Y)| stands for the number of users is following user Y . The probability of retweeting, p , appears in the numerator; again, a simplifying assumption was made: such a probability is equal for all of the users in Twitter.
Up to now no rigorous analysis of TunkRank has been performed; however, it seems plausible that, given its remarkable similarity to PageRank , it would suffer from many of the weaknesses described above (e.g. Sybil attacks, auto-following, and link spamming in general). Hence, to the best of our knowledge, this is the first thorough scholar analysis on TunkRank 2.1.6. TwitterRank
TwitterRank ( Weng et al., 2010 ) is an extension to the PageRank method which, in addition to link structure, takes into account the topical similarity between users in order to compute the influence one users wield onto the others. In that sense,
TwitterRank is a topic-sensitive method which ranks users separately for different topics. Thus, in order to rank users globally (i.e. with topic independence) one should aggregate every TwitterRank value weighted according the difference topic impor-tance within the corpus.

It must be noted that, in addition to this, the transition probability among connected users heavily relies in both the top-ical similarity between users, and the number of tweets published not only by the followee, but by all the followees the fol-lower is connected to. Certainly, these features make of TwitterRank a highly flexible method which, in theory, could easily follow topic drifts. However, we feel that such a degree of flexibility makes the algorithm difficult to scale to the number of users and tweets that are published on a daily basis. 5
Because of this,and forthe sake ofbetter comparisonwith the restof rank prestige,we employeda slightlymodifiedversion of TwitterRank . The differences are the following ones: (1) instead of computing a different TwitterRank value for each user and topic to be later aggregated across topics, we aimed to compute just one TwitterRank value without relying on any topic. (2) We also changed the topical similarity measure to compare users. Instead of applying Latent Dirichlet Allocation (LDA) to find the topics, then obtain each user X  X  distribution, and finally compute Jensen-Shannon Divergence between users X  distributions, we decided to apply the much more usual cosine similarity. And lastly, (3) we simplified the way to compute the damping/telepor-tation parameter. In the original paper it was computed from the matrix of users and topics obtained by means of LDA; we, in contrast, use the ratio between the number of tweets published by a given user and the total number of tweets in the corpus.
Eqs. (9) and (10) provide a description of our implementation of TwitterRank . TR(u) is the TwitterRank value for user u ; c is the probability of teleportation, a constant value between 0 and 1 for the whole graph  X  we used the commonly applied va-lue of 0.15; P(u j , u i ) is the transition probability from user u is the total number of tweets published by all the users. Lastly, sim(u we have already said, was implemented as cosine similarity.

Hence, TwitterRank is indeed an extension of PageRank which takes into account the topical similarity between users to weight the transitions among connected users, in addition to the number of tweets the different followees publish to estab-lish the influence a user has on its followers. 2.2. Other methods and tools to compute  X  X  X nfluence X  X  Apart from the previously described algorithms there have been many other approaches to inferring influence in so-called
Web 2.0 environments. Most of such approaches rely not only in the user graph, but they also require additional information such as user actions (e.g. joining a group, uploading a picture, tagging a resource), or the resources and tags collected and labeled by the users in the network.

For the interested reader we recommend the works by Goyal, Bonchi, and Lakshmanan (2010) and Noll et al. (2009) . Noll et al. describe the SPEAR algorithm (SPamming-resistant Expertise Analysis and Ranking) which processes data from a col-laborative tagging system (e.g. del.icio.us or bibsonomy) to find the most valuable resources and users by means of a mutu-ally reinforcement method. Goyal et al. describe different models to determine influence among users by exploiting both the social graph and the actions performed by the users within the service.

With regards to micro-blogging services like Twitter, there are a number of interesting proposals to find authoritative users exploiting idiosyncratic features of the service such as retweets or mentions.

In a seminal work, Cha et al. (2010) compared a simple graph-derived measure of influence (indegree) with two others better adapted for Twitter: retweets and mentions. According to those authors, users with high indegree (i.e. large numbers of followers) do not necessarily produce large numbers of retweets or mentions; in other words, indegree does not warrant message spreading. In addition to that, Cha et al. found that users with large numbers of followees or with a high tweeting rate were usually robots and spammers.

Bakshy et al. (2011) followed a different approach to estimate how influential users in Twitter are: they tracked the dif-fusion of URLs across communities of users, and studied the relation between the length of each diffusion cascade and a number of features of the user initiating it. The features were the number of followers and followees, the number of tweets, the account X  X  date of creation, and the past influence of the user which was based on the length of the cascades started by would reach. Although they found that past influence and large follower base are necessary to start large cascades they are insufficient and, according to them, predictions of cascade lengths were relatively unreliable.
 Romero et al. (2010) proposed the Influence X  X assivity (I X  X ) algorithm which is closely related to PageRank , HITS ,or Tunk-
Rank . The I X  X  algorithm weights the edges of the social graph according to user interactions, concretely, retweets. The under-lying intuition is very appealing: users X  influence depends on the passivity of their followers and, conversely, users X  passivity depends on the influence of their followees. For each pair of users, acceptance and rejection rates are computed for the fol-lower; the former is the ratio of received messages s/he retweets while the later is the amount of influence s/he rejects. This way, the passivity of a user depends both on his rejection rate and the influence of his followees, while his influence depends on the acceptance rate and the passivity of his followers. As in HITS , both scores are computed iteratively.
To test their algorithm, Romero et al. compared the correlation between influence scores (as computed with the I X  X  algo-rithm) with clickthrough data on URLs promoted in Twitter (i.e. they used clicks as a proxy measure for attention). According to them, the I X  X  algorithm outperforms PageRank , H-index, follower count, and number of retweets.

However, Gayo-Avello et al. (2011) argued later that Romero et al. missed the confounding effect of the number of followers in both the influence and the clickthrough data. When correcting the data for audience size, Gayo-Avello et al. did not found any significant correlation between influence computed by means of the I-P algorithm and clicks on URLs. However, they did found a significant correlation between clicks and PageRank and TunkRank scores. In addition to that,
TunkRank outperformed PageRank and a new algorithm devised by Gayo-Avello et al. outperformed both of them. That new method does not employ graph data but just relies on the mentions received by the users and their follower counts to compute a dynamic measure of influence which positively (and significantly) correlates with clicktrough data in promoted URLs.

Finally, Kwak et al. (2010b) describe a method to discover influential users in Twitter by analyzing the way in which infor-mation is diffused across the network. That is, they do not only consider if a user is following another one, but which new pieces of information s/he discovers via that followee, and how that user propagates (or not) that new information.
Finally, and for the sake of completeness, it must be noted that there also exist some proprietary tools which claim to determine different kinds of influence in Twitter. Among them we can mention Tweet Grader ( http://tweet.grader.com ), Klout ( http://klout.com ), PeerIndex ( http://www.peerindex.com ), or Twitalyzer ( http://twitalyzer.com ). Each of them provides one or more metrics which, purportedly, portray the influence or authority a user has on other Twitter users. All of them claim to take into account signals such as the number of followers, the follower X  X ollowee ratio, the number of retweets and mentions received by the user, or the connections with other users (and their respective scores). Needless to say, details about how each of these tools computes its metrics are undisclosed and, therefore, they cannot be neither replicated nor thoroughly analyzed.

None of the aforementioned methods was considered for this study. The techniques devised in Goyal et al., 2010 or Noll et al., 2009 could (and should) be adapted to microblogging services such as Twitter but such a goal is out of the scope of this paper. In Bakshy et al (2011) and Kwak et al. (2010b) , the social graph is not the most important piece of data, the way in which information flows through it is, instead, key. With regards to Gayo-Avello et al. (2011) and Romero et al. (2010) the behavior of the users (either retweets or mentions) is as important as the social graph or, as is the case of Gayo-Avello et al. (2011) , it simply replaces it. Finally, Cha et al. (2010) just made a point against the use of simplistic graph measures (inde-gree) as proxies for influence but did not make any attempt to correlate retweets and mentions with other external measures of influence.
 Thus, for the purpose of this study, we decided to focus on those methods just relying in the social graph, namely HITS ,
PageRank , NodeRanking , TunkRank , and TwitterRank , in addition to a new method proposed by the author of this paper and that is introduced in the following section. 2.3. Twitter spam  X  X  X pam is bad. The amazing degree of unanimity that greets such a simple declaration is, paradoxically, the biggest imped-iment to progress in anti-spam standards. X  X  (N. Borenstein, co-creator of MIME)
The reader has dealt, in all probability, with a fair share of unsolicited e-mails on a great variety of topics, found in search results weird webpages that no human could have possibly written, and perhaps read amusing (and totally off-topic) com-ments to blog posts. All of those experiences are qualified under the broad term  X  X  X pam X  X .

Twitter is no exception, and spammers have been targeting this service for a number of years. Of course, Twitter X  X  terms of use forbid spamming and there are a number of behaviors the company considers as such:  X  X  Posting harmful links to phish-ing or malware sites, repeatedly posting duplicate tweets, and aggressively following and un-following accounts to attract atten-tion X  X  ( Chowdhury, 2010 ). Twitter provides its users with a number of tools to pointing out spam accounts which are later checked for misuse and eventually suspended.

Needless to say, spammers persist and, as in other online services, the adversarial nature of their behavior makes spam-ming a popular research topic. Indeed, several papers on this regard have been recently published, such as Benevenuto et al. (2010), Irani et al. (2010), Lee, Caverlee, and Webb (2010), Stringhini, Kruegel, and Vigna (2010),or Yardi et al. (2010) just to cite the most relevant.

For instance, Benevenuto et al. (2010) considered spammers those users tweeting URLs unrelated to the topic of the tweet. Interestingly, they also state the following:  X  X  X e do not consider content received through the social links as spam since users are free to follow the users they want. X  X  Therefore, only tweets addressed to a user not following the spammer would be considered by those authors.

Lee et al. (2010) described a number of  X  X  X amilies X  X : from the purportedly self-describing  X  X  X ornographic spammers X  X  and  X  X  X hishers X  X  to  X  X  X romoters X  X  (users tweeting a mixture of  X  X  X egitimate X  X  tweets and tweets about online marketing) and  X  X  X riend infiltrators X  X  (users who massively follow other users to reach a certain amount of followers and only then spread spam).
This is not, however, the only classification for Twitter spammers. Stringhini et al. (2010) distinguished four categories of spammers in social networks (including Twitter):  X  X  X isplayers X  X  (users not posting spam but displaying spam on their profile),  X  X  X raggers X  X  (users posting spam), and  X  X  X osters X  X  and  X  X  X hisperers X  X  (the former are users addressing spam to other users in plain sight while the later use direct  X  and private  X  messages).

To the aforementioned categories Irani et al. (2010) added  X  X  X rend-stuffers X  X : spammers posting tweets including hashtags corresponding to the current trending topics. Such a behavior allows spammers to reach huge audiences because trending topics appear prominently in Twitter X  X  interface and by clicking on them users can read recent tweets on that particular topic.

Needless to say, there have been a number of attempts to characterize and eventually detect spammers in Twitter. For instance, Leavitt et al. (2009) suggested the follower to followee ratio as a measure to spot  X  X  X tereotypical spammers X  X .
According to them, if a user X  X  ratio approaches zero (i.e. relatively few followers versus relatively many followees) would imply that user is a spammer. Unfortunately, spammers are far from stereotypical and such a method simply does not work: according to both Benevenuto et al. (2010) and Yardi et al. (2010) spammers have rather high numbers of followers.
Hence, machine learning is the most popular approach: it requires a labeled set of legitimate users and spammers to then train a classifier on a number of features obtained from the users in the sample. Among the aforementioned researchers Ben-machine learning methods and achieving different precision values: 70% Benevenuto et al. (2010) , 82% Lee et al. (2010) or 97.5% Stringhini et al. (2010) .

It is worth noting that Yardi et al. (2010) showed that a rather simple algorithm based on the presence of URLs, spam keywords and certain patterns in the user names, was able to achieve 91% precision; this is remarkable because such an algo-rithm makes unnecessary preparing a sample of spammers to train the classifier.

We will close this section with an operative definition for Twitter spammers consistent with all of previous works albeit necessarily broad:
A Twitter spammer is a purported user  X  actually a bot or an instrumented account  X  with an underlying profit-making goal which requires persuading other users to visit one or more websites outside Twitter.
 To achieve that goal spammers X  tweets tend to contain URLs (usually in a higher proportion than the rest of the users).
Depending on the profit-making method, the message can range from transparent to overtly fraudulent. In other words, if the promoted website is not totally illegal the tweet text can be related to the contents of the website (e.g. weight-loss and diet websites), while if the website is malicious the tweet text would be unrelated to the contents of the website (e.g. phishing websites).

To maximize the probability of users visiting the promoted websites, spammers require both frequent repetition of their messages and huge audiences.

To achieve the former they tend to rely on minor modifications to the message; this can be achieved by changing the URL using URL shorteners and/or addressing each tweet to a different user.

To achieve the later there are two main approaches: (1) spammers can aggressively follow hundreds or thousands of users assuming some of them will follow-back thus becoming followers. (2) Spammers can include in their tweets hashtags corresponding to current trending topics or habitual Twitter memes. Given that users tend to search Twitter by using such hashtags as queries, spammers X  tweets would appear as search results having, thus, an opportunity for the promoted website to get clicked.

Those spammers engaged in the first approach to get huge audiences risk showing a telltale sign: an oddly low follower to followee ratio. Because of this, it X  X  not uncommon that spammers do not only aggressively follow other users but they also unfollow them shortly afterwards.

Previous description satisfies all of the assumptions made in the aforementioned works about spammers and, still, it shows that there are many different kinds of Twitter spammers. They differ on the way they make profit (legally or illegally), the nature of the product or service they promote, the way in which they reach their audiences, or their method to deliver their promotional messages. 3. Research motivation 3.1. Spam countermeasures
From the literature review regarding Twitter spam it can be concluded that false negatives (uncatched spammers) and false positives (legitimate users labeled as spammers) are unavoidable and, even worse, as it was stated in Benevenuto et al. (2010), Chowdhury (2010), or Yardi et al. (2010) the  X  X  X ar on spam X  X  is a never ending fight because every deployed anti-spam measure will be eventually overcome by spammers.

However, all of those works approach Twitter spam as a detection task while there are other approaches to fight it with-out requiring a detection phase. Here, we will refer to the excellent survey by Heymann, Koutrika, and Garcia-Molina (2007) . According to them, there are three possible countermeasures to spammers: detection, demotion and prevention.
As it has been shown, detection methods have two main problems: false positives and negatives, and knowing for sure that spammers will evolve to pass the detection filters.

Preventionmethodsaimtomakespampostingmoredifficult.AccordingtoHeymannetal.thiswouldrequirelimitingauto-matedinteraction.CAPTCHAsareoneofsuchmeasures andtheymentionitasawaytoavoidautomatedaccountcreation;nev-ertheless, it would be rather annoying requiring CAPTCHAs for every interaction in Twitter. In addition to that, although prevention methods can be an interesting approach to limit the occurrence of spam in Twitter in the future, they would require major changes to Twitter APIs and user interface and, thus, they seem to be of no immediate use in the short term.
Finally, demotion methods  X  X  X ttempt to lower the ranking of spam in ordered lists X  X  in the words of Heymann et al. That is, the system does not prevent nor detect and remove spam or spammers; instead, spam (or spammers) should have their prom-inence reduced. In this sense, they specifically discussed Web search engines which suffer the so-called  X  X  X pamdexing X  X . That kind of spam is defined by Gy X ngyi and Garcia-Molina (2005) as  X  X  X ny deliberate human action that is meant to trigger an unjus-tifiably favorable relevance or importance for some web page, considering the page X  X  true value. X  X 
A number of similarities can be drawn between Web search and Twitter search scenarios. The volume of published infor-mation is huge and not curated; anyway, worthwhile information could be available provided it could be adequately ranked; hence, there exist an incentive for cheating the eventual ranking algorithm and, therefore, spamdexing is a plausible threat.
Under such circumstances demotion-based methods are much more convenient than detection or prevention based ones for a number of reasons: Prevention methods consist of putting barriers to publishing which, at a minimum, are bothersome for legitimate users.
Detection methods are enforced only once spammers have plagued the community and moreover they eventually turn into an  X  X  X rm race X  X  which makes spammers better and better fitted and, hence, difficult to detect in the future.
Demotion based methods are akin to  X  X  X ecurity by design X  X  approaches to software building. That is, spammers are taken for granted and the ranking algorithms are envisioned to minimize both the impact of spamming actions and collateral effects in legitimate users.

Needless to say, up to now, ranking algorithms have not been devised to be  X  X  X pam proof by design X  X ; consequently, and given that Twitter search is still a rather unexplored field, relevant users in Twitter while at the same time demoting spammers. 3.2. The importance of reciprocal linking in Twitter spam
An operative definition of Twitter spammers was provided above. There, a number of features of spammers were de-scribed but there is one that deserves closer attention because (1) it is instrumental to the way in which most spammers operate in Twitter and (2) it is somewhat related to the problem of link farming in the Web.

As it was said, spammers require huge audiences to monetize their messages. Some spammers target so-called trending topics in order to  X  X  X nject X  X  their tweets in the search results of users looking for information about such topics. However, the most popular method and, by far, the most widely reported in the literature ( Benevenuto et al., 2010; Chu et al., 2010; Chu et al., 2012; Ghosh et al., 2011; Ghosh et al., 2012; Grier et al., 2010; Mowbray, 2011; Williams, 2008; Yang et al., 2012 )is that of following users expecting to be followed back.

This is also consistent with the findings of this author: Table 4 reveals that spammers use of hashtags is significantly high-er than that of other users; however, spam tweets with hashtags are far from being the majority of their tweets and, thus, most of the spammers are counting on his followers as their main audience.

This behavior has been denoted by Twitter as  X  X  X ollow spam X  X  ( Williams, 2008 ) and it exploits the fact that many users tend to follow back any other user who starts following them ( Benevenuto et al., 2010; Mowbray, 2011 ).

Indeed, it has been reported that sophisticated spammers do not only target those users more prone to follow back ( Ghosh et al., 2011; Ghosh et al., 2012 ) but they also unfollow those that do not reciprocate the following ( Benevenuto et al., 2010; Chu et al., 2010; Mowbray, 2011 ).
Hence, although reciprocation could be thought of as a sign of mutual interests or even actual friendship, it has been actu-ally found that spammers and other fraudulent accounts exhibit higher reciprocation than average users ( Ghosh et al., 2011; Yang et al., 2012 ).

In fact, spammers are getting their followers from a relatively small subset of Twitter users (about 100,000 accounts) who have huge follower bases and routinely follow back all of them ( Ghosh et al., 2012 ). In this regard, follow spam is related to link spam in the Web -a subclass of spamdexing, see ( Gy X ngyi &amp; Garcia-Molina, 2005 ) -and could be tackled with in similar ways: indeed, Ghosh et al. (2011) described CollusionRank , an algorithm similar to TrustRank ( Gy X ngyi, Garcia-Molina, &amp; Pedersen, 2004 ), to assign spamminess scores to Twitter users starting from a seed of known spammers.

So, in short, among the different features that can help to characterize spammers in Twitter, reciprocal linking, or follow spam, seems to be instrumental and, as it has been said, algorithms based on the fact that spammers rely on such reciprocal links have successfully spotted unknown spammers ( Ghosh et al., 2011 ).

Needless to say, such linking behavior can also be seen in other users and, hence, its mere presence would not immedi-ately point out a user as a spammer. Moreover, as it has been argued before, although spam detection is unavoidable in the
Web, Twitter is relatively new and there is still room for taking a demotion based approach against spam which, as discussed above, is far more convenient than a separated detection phase. 3.3. Research questions
Social networks are increasingly gaining importance in the day-to-day living of Internet users, and the contents they pro-vide can be exploited to provide up-to-date information (the so-called real-time web). Needless to say, because of the ease of publishing any content, anytime by anyone, it is ever more important to have a way to separate trustworthy/relevant/ authoritative sources of information from the untrustworthy/irrelevant/un-authoritative.

Given the prior success of applying rank prestige algorithms to bring order to the Web, it seems appealing to do the same with the user graphs from social networks.

However, as it has been shown above, ranking algorithms can be abused (for instance through spamdexing and link farm-ing) and, in fact, spammers following similar approaches (the so-called follow spam) are already operating in Twitter.
Besides, although there is a large body of work regarding spam detection in the Web, spam demotion can be a more con-venient approach given that spammers have not been abusing Twitter for too long.

In this sense, there is still a  X  X  X indow of opportunity X  X  to study to what degree ranking algorithms proposed up to date are spam proof (or at least spam tolerant), and the feasibility of trying to make them more robust to spammers.
Also, and as it has been aforementioned, reciprocal linking (follow spam in Twitter, link spam in the Web) is instrumental for spammers and, hence, that behavior (typical in spammers but also in other users) has been put at the core of the research described in this study.

Therefore, the main research questions addressed in this study can be stated as follows: (1) How vulnerable to follow spam are common graph methods when applied to user graphs from online social networks? (2) Is it possible to  X  X  X esensitize X  X  such algorithms in a way that avoids to detect and filter out spammers after computing
It must be said that in addition to the graph centrality methods studied in the Literature Review this report includes an analysis of a variation of the popular PageRank method which, purportedly, should be less sensitive to link abusing in social networks.

Such a variation, which will be thoroughly described in the following subsection, relies on a deweighting factor computed from the reciprocal links between users. In contrast to previous solutions, this variation incorporates information about re-ciprocal links during the ranking computation to avoid a prior spam detection phase while, hypothetically, demoting spam-mers anyway. 3.4. A rationale for  X  X  X esensitizing X  X  prestige ranking methods against link spamming
As we have previously exposed, one of the simplest prestige measures in a network is indegree which translated to Twit-ter terms is the total number of people following a user. A priori it seems a reasonable approach: as Leavitt et al. pointed out,  X  X  X he more followers a user possess, the more impact he appears to make in the Twitter environment, because he seems more popular. X  X 
Users such as Oprah Winfrey (3.1 M followers), CNN Breaking News (2.9 M followers), or TIME (2 M followers) expected to have such huge number of followers; after all, they are opinion-makers and mass media. One could even find rea-sons to explain the number of followers for Ashton Kutcher (4.5 M), Britney Spears (4.4 M), or Lady Gaga (2.8 M): they are celeb-can spammers have far more followers than average users ( Yardi et al., 2010 ); see also Section 4.2 for more details on this.
An explanation for such a phenomenon has been provided above: As with any other social environment, Twitter has seen the emergence of its own etiquette and, for many users, following back a new follower is considered  X  X  X ood manners X  X . Of course, such a behavior is not a problem per se and, in fact, it makes perfect sense: if somebody starts following you, it means (in theory) s/he is interested in what you are tweeting about; probably both of you have some common interests and, thus, it would be a good idea to follow-back that user to see what s/he is publishing.

Needless to say, many users are just following back their new followers as a matter of custom and many of them are using different tools and scripts to auto-follow back their followers. togetfollowers:spammersjustneededtomassivelyfollowotherusers.ItmustbesaidthatTwitterconsiderthisaviolationoftheir terms of use but spammers (and many users in general) are using this and other related methods to increase their follower count.
Hence, it seems that number of followers is not to be trusted when trying to infer a user X  X  relevance. Indeed, we have already said that Leavitt et al. (2009) suggested that the ratio between the number of a user X  X  followers and the number of his followees is a better metric.

According to these authors, if this ratio approaches infinity the user is a successful broadcaster,  X  X  X oving content to other users in the environment. X  X  For instance, Oprah has a follower X  X ollowee ratio of 1.67 10 TIME 2.19 10 4 , Ashton Kutcher 1.47 10 4 , Lady Gaga 18.08, and Britney Spears 10.43.

To the contrary, if the ratio tends to zero Leavitt et al. qualify that user as a  X  X  X tereotypical spammer X  X  ; nevertheless ( Ben-evenuto et al., 2010; Yardi et al., 2010 ) have found that spammers do not fulfill such a stereotype. In fact, the follower-fol-lowee ratio for spammers tends to be close to 1 and, actually, many of them manage to have a positive ratio indeed. With regards to common users it varies widely but, as an example, the ratio for this author was a meager 1.30 at the moment of this writing.

Fig. 1 illustrates these three common scenarios. The first one is the typical case for a celebrity/mass-media: s/he has got and relatively few outside. Lastly, the third scenario shows a user who has managed to get followers by mass following other users and who, in fact, has managed to have a few more followers than followees. ratio is 1.75 for the heavy-followed user, 0.67 for the user with a close group of friends, and 1.14 for the presumptive spammer.
Nevertheless,let X  X putasidespammersforamomentsowecanpayalittlemoreattentiontothefollower X  X olloweeratio.Isit just an ad hoc heuristic? Or, on the contrary, does it provide any sensible (and useful) reading? In our opinion it can be inter-preted as the user X  X   X  X  X alue X  X  regarding the introduction of new originalinformation from the outside world into the Twitter glo-bal ecosystem. Those users which publish valuable tweets get followers who do not mind if those users are  X  X  X mpolite X  X  (i.e. they donot follow back);that waythey have huge numberof followersbut small numbersof followees and, thus,their ratios tendto belarge.Ontheotherhand,userswhotendtodiscussrelativelypersonalmatterswiththeirclosegroupofacquaintancesdonot get large audiences and, in turn, their ratios tend to be small (even close to zero if they follow lots of people).
But there is the spam problem. How should we tackle with it? As it was pointed above, the answer may lie on reciprocal connections, those where two users are following each other. As we have said, many users consider this a sign of politeness but, many, especially those with huge numbers of followers, simply cannot follow-back everybody (not if they want to actu-ally read what their followees are writing). Spammers, however, are no reading tweets and, thus, they have no constrain in the number of people to follow; especially if they aim to get a new follower in reciprocity.

In other words, reciprocal links should be under suspicion because many times they are used as  X  X  X ounterfeit currency X  X  to increase the followers count. In consequence, we propose the follower X  X ollowee ratio with discounted reciprocity  X  see Eq. (11)  X  which, in our opinion, captures many of the subtleties of linking in social networks.

Fig. 2 shows the same three scenarios from Fig. 1 but reciprocal connections are shown in a lighter shade. Those users with many of such connections, namely spammers and common users, tend to  X  X  X ose X  X  most of their followers, while heavy-fol-lowed users are virtually unaffected. The crux of the matter is that, although for users in small close communities this could go undetected, spammers would find such a thing undesirable.

On the other hand, putting under suspicion all reciprocal links seems a bit obnoxious; that X  X  why we do not suggest using this ratio  X  X  X s is X  X  but, instead, employing either the follower X  X ollowee ratio or the discounted version depending on the pos-sible outcome: if a user would  X  X  X enefit X  X  of using the original ratio then we use the discounted one, and vice versa. Because of that, the whole name for the proposed ratio is in fact followers to followee ratio with paradoxical discounted reciprocity (Eq. (12) ). For sure this can look a bit nonsensical at first but, as we are about to show, it makes perfect sense.
First, let X  X  take two users: one of them, legit , has 34,000 followers and 300 followees with 200 reciprocal connections; the other one, spammer , has 25,000 followers and 30,000 followees with 20,000 reciprocal links. The ratios for them would be 113.33 and 0.83, respectively. The ratios with discounted reciprocity would be 338 and 0.5, respectively. If the users could choose which ratio they prefer to describe themselves it seems clear that legit would prefer discounted reciprocity which is larger, while spammer would prefer the raw ratio.

However, such selfish decisions are contrary to the interpretation of the ratios. That is, legit would prefer assuming his reciprocal connections are not legitimate but follow spam. On the other hand, spammer would prefer to count all his reci-procal connections as truly legitimate while, in all probability, this is not the case (you cannot simply follow thirty thousand people). However, both users could get us to apply the opposite ratio. For instance, spammer could unfollow 20 thousand people to achieve a 2.5 ratio; however, such massive unfollowing would probably make him lost most of his followers.
And what about legit ? He could massively follow most of his followers but, independently of the ratio to apply, such an ac-tion would only reduce his final value. Thus it does not seem that neither legit nor spammer would change their connections just to force a different way to compute their respective ratios
Finally, the paradoxical discounted ratio is not aimed to be directly applied to users in the graph but, instead, as a weight within another algorithm such as PageRank . For the sake of illustration, we will discuss here how to modify the original Page-Rank equation (see Eq. (1) ) in addition to other minor considerations to take into account for implementation.
Eq. (13) corresponds to the incorporation of the paradoxical discounted ratio to PageRank . As it can be seen, for each page p linking to page p i its PageRank score  X  PR(p j )  X  is weighted according to the number of outgoing links from p modified version, its paradoxical discounted ratio. Please note that the value for the ratio is normalized according to the maximum reached by all the nodes in the graph (remember that the value is always positive but unbounded).
Bydoingthis,theratioisplayingtheroleofanexternality,thatis,ithasanimpactnotontheagentresponsibleofitsvaluebut on third persons. In other words, a user is not affected by his own ratio, his followees are (the prestige they received is de-weighted).Fromaneconomicpointofviewthisis anappealingfeaturebecauseindividualspammersdonot haveanyincentive to modify their personal behavior, although as a group  X  they tend to weave tight networks  X  all of them lose out.
The only final consideration when incorporating the paradoxical discounted ratio to a given algorithm is that the scores for each page must be normalized after each iteration (otherwise they would decrease towards zero) 4. Research design
The main goal of this study was to compare the performance of different rank prestige algorithms when applied to social networks. To attain that, a relative large dataset was needed, in addition to an objective criterion against which to compare the performance of the different methods. The dataset, described in the following subsection, was crawled by the author from Twitter. Within that dataset two different subsets were prepared: one of presumed relevant users and another of abu-sive users.

The second subset was needed because the research questions underpinning this study deal with the vulnerability of cen-trality methods to spammers and the feasibility of  X  X  X esensitizing X  X  them to their abusive behavior. As it was said a desirable feature of any ranking algorithm would be that of demoting abusive users and, the lower the scores for spammers the better the algorithm.

Nevertheless, although demoting spammers is a desirable feature for a ranking algorithm it is not its main goal; ranking relevant users atop is: the higher the ranks for those users the better the algorithm. That is the reason for the first subset of users which, along with the subset of abusive users, will be described below.

Thus, this section describes the dataset employed for the research, the way in which subsets of presumably relevant and abusive users were extracted, and the simple evaluation method applied to compare the different algorithms. 4.1. Dataset description
We relied on the Twitter search API to create the dataset used in this study. To that end, we employed a query composed
That query was submitted once every minute from January 26, 2009 to August 31, 2009. Needless to say, the crawling was not flawless and, in fact, there were 18 days with minor network blackouts and 3 days with no tweets at all (April 26, and August 22 and 24). All in all, we collected 27.9 million English tweets corresponding to 214 days.

As we have already implied, users in Twitter can involve themselves in relationships with other users. Thus, a user can follow another one so that the first user can receive the tweets published by the second. This way, users can have, in Twitter parlance, followers and friends . Please notice that friends are no more than the persons a given user is following; hence we are using the term followee instead ( Huberman, Romero, &amp; Wu, 2009 ).

Using that information on followers and followees, Twitter can be represented as a directed graph. In order to build such a graph we tried to obtain followers and followees for each of the 4.98 million users appearing in the dataset. To do that, we employed the so-called Social Graph Methods provided by the Twitter API. This second crawl was performed after the first dataset was collected and took several months.

For the final graph we did not take into consideration links from/to users not appearing in the sample and we also dropped isolated users. In addition to this, a substantial amount of user accounts were suspended second crawl and, hence, no information on these users X  followers and followees was available. Lastly, because of the unavoid-able network problems, coupled with the fact that we pushed the API a little too far, the information for a noticeable amount of users was not eventually crawled.

The finally collected Twitter graph consisted of 1.8 million users; that is, 36% of the users within the original sample. It is bigger than other datasets reported in the literature (e.g. Java et al. (2007)  X  about 90,000 users  X  or Choudhury, Sundaram,
John, Seligmann, and Kelliher (2010)  X  200,000 users) but smaller than others (e.g. Kwak et al. (2010a)  X  41.7 million users, the whole Twitter graph as of July 2009). Anyway, we think it is a fairly substantial sample given that, at the moment of collecting the dataset, the number of US Twitter users was estimated between 14 ( O X  X eill, 2009 ) and 18 millions ( Ostrow, 2009 ) and, thus, our sample is 10% that size and covers a little more than 4% of the whole Twitter graph. An in-depth analysis of this dataset is provided as an Appendix for the interested reader. 4.2. Data preparation: relevant users The goal of applying a ranking algorithm to a social network is to find the most relevant users that should appear atop.
Hence, if only we were able to find a ranked list of users to be used as a ground truth, it would be straightforward to compare the different algorithms. Needless to say, we could rely on lists similar to those of Forbes magazine but there are a number of problems with them:
Although there is some overlap between such lists and the Twitter user base, not every person in those lists is using Twit-ter and not every relevant Twitter account is a person.

Despite the claims made by their proponents about using a methodology they are highly debatable at least and they would be hard to justify in a scientific paper.

The very idea of ranking users may be considered preposterous even when focusing in a very specific field. For instance, what would be a  X  X  X ight X  X  ranking for actors and actresses? Or for entrepreneurs?
That does not mean, however, that there is no way to find a subset of users against which to test the performance of the different algorithms. It means that, firstly, we should focus on Twitter X  X  ecosystem and, secondly, we do not need to have that group internally ordered or ranked but, instead, we need to have that group ranked atop as a whole to say that a ranking algorithm is properly working.

From such a perspective there is a group of users that can help our purposes: celebrities. Such a group is composed of actors, news anchors, politicians, sport figures, etc. and, depending on the different interests of the audience, they can be considered relevant. Moreover, all of them share a problem: to warrant their followers that they are who they seem. Besides, the problem is not only theirs but also of Twitter: by not properly handling deceptive accounts of celebrities the company could very well get involved in libel lawsuits.

Hence, Twitter is proactively verifying accounts to check they actually belong to the celebrity they claim. Verified ac-counts display a characteristic  X  X  X adge X  X  in Twitter X  X  interface and can be also checked thanks to the @verified Twitter account.
Needless to say, the number of verified accounts is relatively small (29,799 users out of 500 million users as of June 26, 2012) but, given the nature of those users, it is clear that any sensible ranking algorithm should provide them the highest scores.
 Therefore, using Twitter X  X  API all the available verified accounts were obtained and checked against the collected dataset.
Of course, not all of them were present in the dataset: some of the verified accounts are not tweeting in English and many of them did not exist at the moment of the data collection (2009). Nevertheless, 4884 verified accounts were found in the data-set, a 0.3% of the total number of users; this is a relatively small number but it is highly significant given that only 30 thou-sand users from the 500 million user base in Twitter have got a verified account.
 it is pretty common to emphasize that the account is the official channel of communication in Twitter for that user. In addi-tion to that, other phrases reveal that companies, news media outlets, politicians, artists and sport figures comprise the majority of verified accounts.

With regards to their tweeting behavior, Table 4 provides details and comparison with both spammers and average users; nevertheless, a summary of the most interesting features is provided here. As it was expected, verified accounts have huge follower bases and they follow thousands of accounts, much more than the average user and somewhat between spammers and aggressive marketers. They tweet much more than average users and, again, they are in between spammers and aggres-sive marketers in this regard. They use URLs much more than average users but much less than spammers. They use hashtags much less than average users, marketers and spammers which could suggest that verified accounts (i.e. celebrities) prefer not embrace with mass movements. Instead, they retweet much more than average users (although less than marketers) and get much involved in conversations than any other group of users; this could imply that they are really trying to per-sonally interact with their followers. 4.3. Data preparation: abusive users
As we have described in the Research motivation section, in addition to obtain sensible rankings for relevant users, we are interested in the feasibility of rank prestige methods less vulnerable to linking malpractice because one or more of such methods will certainly be used to rank users to find the most relevant/trustworthy content pro-ducers. In fact, at the moment of this writing Google seemed to be applying its PageRank method to rank Twitter users ( Talbot, 2010 ) in order to offer the most relevant tweets as search results.

We have already said that a desirable feature of ranking algorithms is that of demoting spammers. Hence, to compare different algorithms and test their respective performance we need a group of users who are actually trying to abuse Twitter linking. As many other so-called social services, Twitter is no immune to the spam problem. In addition to promoting dubi-ous websites and products, Twitter spammers are also furiously engaged in getting followers; in fact, they have both more followees and followers than legitimate users. According to ( Yardi et al., 2010 ), they triple the number of both kinds of con-nections; these authors argue that  X  X  spammers invest a lot of time following other users (and hoping other users follow them back) X  X  . An explanation we found highly plausible.

Whether this is done on purpose, anticipating the application of prestige algorithms to the user graph or, conversely, it is just a happy coincidence when spammers were just trying to find users to click the links they publish is irrelevant. The mat-ter is that those spurious connections are to be treated by the eventual algorithm in the same way that legitimate links and, thus, spammers can obtain an undeserved authority within the user graph.

Thus, to collect the necessary data for the experiments, a method was needed to detect spammers. In Section 2 it was explained that machine learning methods are an option but they require a sample of both legitimate users and spammer for training and, on top of that, it was shown that the simple algorithm proposed by Yardi et al. provided a similar perfor-mance. Thus, such a method was chosen. Their algorithm is based on the presence of URLs and a selection of keywords in the tweets, in addition to the matching of certain pattern in the user names.
We implemented an analogous version of their technique although we did not look for any pattern in user names. Hence, we prepared a black list of patterns (both terms and phrases) commonly associated with spam in Twitter. taining a URL and with at least 10% of its content matching any of the patterns in the black list was considered a spam tweet; any account with at least 5 spam tweets was considered a spam account.

Arguably, such a method can miss some spammers but it should be noted that for this study we did not aim at high recall regarding spammers but at high precision. Indeed, our implementation of the method by Yardi et al. achieved similar per-formance: 87.32% precision versus the 91% reported by them.

That spam detection system detected 9369 spammers in our collection of tweets. By examining a representative sample we found that about 24% of those users were already suspended by Twitter, techniques, about 11% were  X  X  X opywriters X  X  (i.e. they replicate content from other users, RSS feeds or publish plagiarized web-sites), 8% promote methods to get followers and/or website traffic, and the rest of them were a mixture of self-proclaimed ex-perts in SEO, marketing, weight loss, etc.

In a similar way to that of verified accounts, spammers biographies were mined to find distinctive terms (see Table 2 for a more exhaustive list). As it was expected, terms such as business , money , internet marketing , social media and SEO were at the top of the list. It must be noticed that those terms are not only popular among spammers but among other Twitter users. As followers and attention X  X  . We will denote those users as aggressive marketers and, thus, we decided to expand the group of abusive users from pure spammers to also include those marketers
To find them we prepared a list of patterns commonly occurring in spammer biographies which were also frequently associated with marketers and other heavy-following users. labeled as spammers but, we thought, could exhibit some abusive behavior with regards to connecting to other users. Table 3 shows a list of the 60 most distinctive terms for these aggressive marketers; please notice the degree of coincidence with spammers.
Of course, a mere similarity in biographies is not evidence of aggressive marketers trying to abuse Twitter. Because of that, we analyzed several characteristics of tweeting behavior for both spammers and aggressive marketers, and compared them to those of average Twitter users and verified accounts. Table 4 contains all the details and, thus, we will just summa-rize the most interesting findings.
 First, spammers have both much more followers and followees than average users (although less than verified accounts).
This is consistent with the findings of Yardi et al. However, in our datasets spammers do not triple those numbers with re-gards to common users, but they multiply them by almost 40! Aggressive marketers are in between but much closer to spammers than to the average twitterer: they have about 15 times the number of connections than an average user.
With regards to the number of tweets published, aggressive marketers double the frequency of average users and spam-mers publish 7 times the number of tweets an average user does. This probably means that spammers, in contrast to mar-keters, are publishing tweets in an automatic fashion.

Regarding different features of the tweets themselves there are some important differences between spammers, market-ers, and average users. Firstly, virtually every tweet published by a spammer contains a URL (90%); marketers use URLs in one in three tweets, while average users tend to use URLs in about one in five tweets. Secondly, both marketers and spam-mers employ hashtags more than average users but the differences, although substantial, are not as pronounced as with other features. Surprisingly, the number of hashtags include by these different groups is mostly the same on average. Lastly, one feature that again highlights the robot nature of most spammers is the much lower level of retweeting, in particular, and conversations they get involved, in general. As it was expected, marketers are much more prone to retweet than average users (two times) and also get much more involved in conversations than them.

To sum up, we have described two similar, albeit not identical, groups of abusive users  X  namely spammers and market-ers  X  which exhibit several features very different from those of average users and verified accounts. Both have further more followers and followees than the average user, both publish more than average users, and both promote URLs more than average users. Besides, as we have stated above, the line between aggressive marketers and spammers is not always totally clear. In fact, one could assume that relatively few users will respond to the stereotypical spammer profile and, to the con-trary, many users would exhibit a more or less marked spamming behavior.

Anyway, and spite of being an oversimplification, for the purpose of evaluating the different graph centrality algorithms with regards to spammers demotion we are going to consider a single group spammers-marketers assuming that their link-ing behavior, as a whole, is trying to abuse, or at least cheat, the assumptions underlying relationships in Twitter: i.e. that users should follow one another when they are genuinely interested in what the other is publishing. Thus, in the following sections we are going to analyze in which way the global authority/reputation is divided among the different groups (verified accounts, spammers X  X arketers and the rest of users), and which algorithms are less prone to be abused while, at the same time, providing a better ranking of relevant users within the social network. 4.4. Evaluation method
As we have already said we are not assuming any prior  X  X  X orrect X  X  ranking for the users; we consider user rankings just a tool to find the most relevant source of information at a given time and, thus, a ranking algorithm will be judged by its ability to rank atop relevant users as a whole while avoiding abusive users achieving undeserved rankings.

Hence, the evaluation process is quite straightforward. All of the different methods were applied to the Twitter graph to obtain a user ranking. Then, we compared the positions reached by spammers and marketers on one side, and verified ac-counts on another side. The lower the rankings abusive users reach while the higher for verified accounts, the better the method is.

In the following section we provide the minimum, average, and median positions for the different user classes across dif-ferent deciles. Such numbers will help to understand the positioning of both verified accounts and abusive users in relation to the rest of users in the social network. In addition to that, we will graphically show the percentage of verified accounts atop the ranks, the percentage of abusive users found as one moves down the ranking, and the level of agreement between the different rankings. 5. Results 5.1. Prestige of abusive users and verified accounts when applying PageRank
As it has been aforementioned, 4884 verified accounts appear in the collected dataset. They amount for a mere 0.3% of the users in the graph but, still, they accumulate 12.7% of the total PageRank in the graph. Regarding their positioning in the glo-bal ranking (see Table 5 , and Figs. 3 and 4 ), 85% of the verified accounts appear among the top 10% of users.
With regards to the subset of abusive users, about 50% of the spammers detected in the collection of tweets did not ap-pear in the graph. 18 Those who are present account for 0.25% of the users but they agglutinate 1.4% of the total PageRank in the graph. Regarding the aggressive marketers, 98% of them appear in the graph accounting for 3.3% of the total PageRank . The acute difference from spammer to marketer presence in the graph gives an idea of the work devoted by Twitter to get rid of spammers.

Thus, the whole set of spammers and marketers which represent a mere 1.5% of the users manage to grab 4.7% of the available PageRank .

With regards to their positioning in the global ranking (see Figs. 5 and 6 ), 90% of spammers are, approximately, among the 60% of top ranked users and, in fact, half of the spammers appear well above the top 10% of Twitter users. On the other hand, 90% of the aggressive marketers are among the 80% of top ranked users and half of them appear above the top 20% of users. 5.2. Prestige of abusive users and verified accounts when applying HITS
When applying HITS to the Twitter user graph verified accounts grab 1.65% of the available authority rank while spam-mers grab 5.20% and aggressive marketers account for another 11%. Thus, a reduce subset of users (1.5% of them) which are moreover abusive own 16.20% of the global authority outscoring verified accounts (i.e. relevant users).

Both spammers and marketers are pretty good positioned (see Table 6 ). Half of the spammers appear at the top 10% of positions and 90% of them are among the 40% better situated users. Aggressive marketers X  situation is not as good but equally impressive: half of them appear at the top 20% positions, and 90% of them are among the 60% better positioned users.
With regards to verified accounts, almost half of them appear at the top 10% positions and 90% of them are among the top 40% better ranked users. This, however, is not very different of the rankings achieved by spammers and marketers. 5.3. Prestige of abusive users and verified accounts when applying NodeRanking
When ranking users according to NodeRanking , verified accounts reach 11.94% of the global available prestige while spammers and aggressive marketers account for 1.62% and 3.86%, respectively. The amounts reached by abusive users are about 15% larger than those achieved when using PageRank while the prestige grabbed by verified accounts is slightly lower.
With regards to their positioning (see Table 7 ), 90% of verified accounts appear near the top 15% users, and half of them are among the top 2% of users. With regards to abusive users, 90% of the spammers are among the 60% best situated users and half of them appear at the top 10% positions. 90% of the aggressive marketers are above 30% of the users and half of them are among the top 20% users. Such results are pretty similar to those obtained by applying standard PageRank . 5.4. Prestige of abusive users and verified accounts when applying TunkRank
When ranking Twitter users according to TunkRank , 19 verified accounts grab 21.47% of the available global prestige while spammers and aggressive marketers account for 0.74% and 1.94%, respectively. Hence, the amount grabbed by abusive users is roughly half the one obtained when applying PageRank while the amount reached by verified accounts is 69% larger. Attending to their positioning (see Table 8 ), 90% of verified accounts are at the top 15%, and half of them are at the top 1%. In contrast, 90% of the spammers are among the 70% of best positioned users, and half of them appear above the top 20%.
Regarding aggressive marketers, there are no great differences between them and common users, although half of them are above the 40% top positioned users. 5.5. Prestige of abusive users and verified accounts when applying TwitterRank
When ranking Twitter users according to TwitterRank , verified accounts reach 9.12% of the available global prestige. In contrast, spammers and aggressive marketers account for 0.0003% and 0.00025%, respectively. In other words, using Twitter-
Rank , both groups of abusive users reach a virtually negligible prestige (although, again, spammers manage to outperform marketers).

With regards to their positioning (see Table 9 ), 90% of verified accounts are roughly among the top 60% users, and half of them are among the top 20%. Surprisingly, 90% of the spammers are among the top 30% users and half of them appear among the 10% best positioned users. Aggressive marketers, on the other hand, seem to be slightly better positioned than average users.

The reason for these apparently contradictory results (namely, the impressive prestige reduction for spammers while still achieving top positions) is that TwitterRank distributes the prestige in a highly biased way: in fact, top 10 users account for in spite of that, spammers manage to be  X  X  X ne-eyed kings in the land of the blind X  X  even outperforming a large number of verified accounts. 5.6. Prestige of abusive users and verified accounts when applying PageRank with paradoxical discounting
When applying PageRank with paradoxical discounting to the Twitter user graph, verified accounts grab 10.87% of the global PageRank while spammers can only grab 0.22% and aggressive marketers account for 1.05%. Thus, with regards to standard PageRank , spammers loose 84.3%, and marketers 68.2%.

One of the consequences of applying paradoxical discounting to PageRank is that many users reach a PageRank which is virtually zero and, hence, all of those users tie for the last position (see Table 10 ). 40.2% of the spammers end up in that bin while the rest of them appear among the 30% top ranked users. With regards to aggressive marketers, 55% of them reach a negligible PageRank value but the remaining 45% is among the top 30% users in the graph. Verified accounts behave as ex-pected with 90% of them among the top 14% of users and half of them above the 2%. These somewhat mixed results are later discussed. 5.7. Prestige of abusive users and verified accounts when applying PageRank to a  X  X  X runed X  X  user graph
As it was described in a previous section, paradoxical discounting could be used to  X  X  X rune X  X  the graph which would, in turn, be ranked by means of standard PageRank . When applying this approach to the Twitter graph, verified accounts grab 10.98% of the available PageRank , spammers 1.84%, and aggressive marketers account for 4.27%. Regarding of their posi-tioning (see Table 11 ), 90% of verified accounts are close to the top 15% of users, and half of them are above the top 2%.
With regards to abusive users, 90% of the spammers are best positioned than half of the users, and half of them are among the top 10% users; aggressive marketers, 90% of them appear among the 70% best positioned users, and half of them are among the top 20% users. These results will be later discussed because of their implications regarding reciprocal linking in Twitter.
 5.8. Agreement between the different rankings
Up to now we have shown the ability of the different algorithms to  X  X  X enalize X  X  abusive users while still ranking atop rel-and the level of agreement between them. Table 12 shows the top 30 users according to the different ranking algorithms.
As it can be seen, PageRank , NodeRanking , TunkRank and  X  X  X runed X  X  PageRank exhibit a large level of agreement; all of them highly rank celebrities and personalities, news wires, and a few companies.  X  X  X iscounted X  X  PageRank , promotes several new users to the top rank, most of them musicians or related to alternative news wires. All of those algorithms spotted plenty of verified accounts among the top 30 users.

HITS and TwitterRank are another question. HITS top rank is plagued with self-proclaimed entrepreneurs, CEOs, marketers and gurus. TwitterRank , probably because of the importance of content similarity between different users, promotes to the top of the list mainly feeds and robots interwoven in tight networks. The presence of verified accounts in both top 30 user lists is virtually null.

Table 12 , however, just provides anecdotal evidence. In order to gain details on the behavior of the different ranking algo-rithms we compared them by means of the normalized version of Kendall distance with a zero penalty parameter ( McCown &amp; Nelson, 2007; Fagin, Kumar, &amp; Sivakumar, 2003 , respectively). Figs. 7 X 9 show the agreement between the different rank-ings and PageRank , TunkRank , and  X  X  X iscounted X  X  PageRank . In the following section we will discuss the implications of such results. 6. Discussion of results
As we have explained before, our approach to evaluate the available ranking algorithms in the context of social networks and aggressive marketers who try to reach better positions by exchanging links instead of providing better content.
Because of the common knowledge about PageRank and, additionally, the fact that it seemed to be applied by Google to rank Twitter users in their real-time web search engine, we decided to take that method as the baseline against which the rest of techniques should be compared.

The analysis of the results obtained by PageRank when applied to the Twitter user graph support our initial concern, that is, one user X  X  PageRank is not only a measure of his value within the Twitter ecosystem, but also a consequence of the  X  X  X ips and tricks X  X  one can employ when establishing relationships within the social network. This is the only plausible explanation for spammers being much better positioned than aggressive marketers when the value of the contents they provide is vir-tually negligible.

There are two methods which are extremely similar to PageRank in terms of ranking abusive and relevant users, and in terms of ranking aggrement: NodeRanking and  X  X  X runed X  X  PageRank . With respect to NodeRanking , the similarities are unsur-prising given that both NR and PR are highly related. Perhaps NodeRanking could reach its full potential with a weighted
Twitter graph; however, the way in which such a weighted graph could be inferred from Twitter data (e.g. taking into ac-count the number of mentions or retweets among users, or their content similarity) is out of the scope of this paper. In this regard, however, we must note that both methods slightly underperform PageRank : on one hand, they promote to top posi-tions a slightly lesser number of verified accounts than PageRank and, conversely, they promote a slightly larger number of abusive users than PageRank .

The similarity between the results obtained by PageRank and PageRank applied to the  X  X  X runed X  X  Twitter graph are some-what expected; however, they deserve a deeper analysis because they support some of the points of this author. Let us remember that the  X  X  X runed X  X  graph was obtained by removing those users (and their in-and out-links) with zero de-weight-ing which, in turn, was computed taking into account reciprocal links between users. One of the arguments of this author is that discounting reciprocal links is a pretty fine way to separate users contributing to the ecosystem, from those with little or no value at all. The results obtained with the total Twitter graph and the  X  X  X runed X  X  graph are virtually the same and, thus, we can take that as supportive of the fact that most reciprocal links are not legitimate but, instead, merely an aim to reach larger audiences.

In contrast, there are two methods which greatly differ not only from PageRank but also from the other techniques, namely HITS and TwitterRank . Each of them exhibits different problems when applied to the Twitter graph.
HITS underperforms PageRank with respect to both verified accounts and abusive users. As it can be seen in Table 12 the top list produced by HITS is plagued by mostly irrelevant users (at least compared with the top lists produced by the other methods) which can also be appreciated in Fig. 3 . Moreover, if we checked the number of followers and followees for those users we could see that the ratio for most of them is close to 1 and, in fact, most of them have got a large number of reciprocal links.

In fact, because of the very nature of HITS , this algorithm is virtually inoperative when confronted with a relatively small number of users weaving a tight network of reciprocal connections. Let X  X  remember that many spammers and marketers tend to massive follow other users in order to gain a follow-back link. Because of this, when computing hub scores those users X  values tend to grow very fast; then, those hub scores are used to compute authority scores for their followees (which are mostly spammers and following them back). It is clear that after several iterations those users with lots of reciprocal links earn an undeserved amount of authority. Hence, the HITS algorithm is not advisable at all to rank users within social net-works since it is clear that HITS is not robust to follow-spam.

The results achieved by TwitterRank were very disappointing. Conceptually, it is a very appealing method: it provides ways to incorporate both content similarity measures and transition probabilities into the ranking. Some way, however, these appealing ideas seem to fail: as it can be seen from the top list, most of the users are feeds and robots, many of them highly related (even with strikingly similar names). To be fair it must be said that modifying a topic-sensitive method to operate globally is, perhaps, pushing too hard the technique. However, given that even the simplified version implemented for this research (using cosine similarity instead of LSA) is (1) much more computationally expensive than the rest of meth-ods surveyed, and (2) it requires much more data (namely, the tweets) to obtain the rankings, it seems not at all recommend-able, especially when other available methods (e.g. TunkRank ) are faster and provide much better results (at least when applied globally to the complete user graph).

Lastly, there are one method clearly outperforming PageRank with respect to both ranking atop verified accounts and penalizing abusive users: TunkRank . It is certainly similar to PageRank but it makes a much better job spotting relevant users and also when confronted with  X  X  X heating X  X : aggressive marketers are almost indistinguishable from common users  X  which is, of course, desirable; and spammers just manage to grab a much smaller amount of the global available prestige and reach lower positions  X  although they still manage to be better positioned than average users. In addition to that, the ranking in-a larger number of verified accounts at top ranks. Thus, TunkRank is a highly recommendable ranking method to apply to social networks: it is simple, it prominently ranks relevant users, and severely penalizes spammers when compared to PageRank .

With regards to the variation to PageRank described by this author,  X  X  X iscounted X  X  PageRank , the results are not highly conclusive.

On one hand, performance against the proposed benchmarks is pretty good. With regards to demoting abusive users, it seems to outperform PageRank  X  and even TunkRank  X  because the amount of prestige grabbed by such users is smaller and their rankings lower than when applying standard PageRank . With regards to spotting verified accounts, as it is shown in Fig. 4 , it outperforms PageRank (although underperforms TunkRank ).

Nevertheless, it has two issues which deserve further research. On one hand, the induced ranking could be labeled as  X  X  X litist X  X  because most of the users  X  about 70%  X  tie for the last position. Certainly, this is unsurprising given that 16% of the users in the graph have got a zero de-weighting factor what we interpret as their contributions being  X  X  X orthless X  X  for the network as a whole. Moreover, such results are consistent with the well-known participation inequality ( Nielsen, 2006 ), and with a recent study revealing that 75% of the users just publish a tweet every 9 days, and 25% of the users do not tweet at all ( Heil &amp; Piskorski, 2009 ). Hence, this could be considered a minor issue.

On another hand,  X  X  X iscounted X  X  PageRank exhibits a fairly distinctive curve (see Fig. 9 ) when comparing its agreement with other rankings  X  obviating the underperforming HITS and TwitterRank . The agreement is much lower than, for instance, that found between PageRank and TunkRank , but the most striking behavior is the local maximum at the top positions, fol-lowed by a relatively large trough, to eventually stabilize. We found several lesser-known users at top ranks and, after study-ing them, we concluded that most of them have one or more  X  X  X amous X  X  followers who, in many cases, they manage to outrank. We have denoted this as the  X  X  X iant shoulders X  X  effect and it explains not only the trough at the head of the list but the smaller agreement for the rest of the ranking: many of the top users from PageRank or TunkRank are a little behind of ing is still to be explored. Nevertheless, tackling with this and the former issue is left for future research. 7. Implications, conclusions, and future work
This study makes four main contributions. First, when applying graph prestige algorithms to social networks, ranking is spammers  X  who contribute no valuable content  X  are consistently better positioned than marketers  X  who contribute some-what valuable information  X  no matter the method employed supports this assert.

Second, evaluating ranking should not be a point in itself; it should, instead, be evaluated within an objective context. To compare the performance of different algorithms two metrics are to be applied: First, relevant users should reach top ranks as a whole without regards to their internal ordering. Secondly, abusive users should not reach undeserved rankings.
Third, TunkRank is an obvious candidate to rank users in social networks. Although highly related to PageRank , TunkRank outperforms it with respect to both spotting relevant users in top positions, and penalizing abusive users. In addition to that, it is simple to implement and computationally cheap  X  at least as cheap as PageRank .

And fourth, reciprocal linking in social networks is, in many cases, a sign of follow spam instead of mutual interest among legitimate users. This is supported by two experimental findings:
First, by applying PageRank to a Twitter graph where users with zero de-weighting were removed we achieved virtually the same results than when applying the same algorithm to the whole graph. In other words, most of the reciprocal links do not provide any information at all.

Second, when incorporating to PageRank a way to de-weight influence on the basis of reciprocal links spammers are highly demoted while a higher number of relevant users are found at top positions. In other words, although most of the reciprocal links provide little information this is not applicable to all of them and, hence, they should not be simply removed but accounted for as shown in Section 3.4.

This study opens several lines of research. First, the rankings induced by the different methods should be analyzed in other contexts, for instance, as a way to rank content providers in order to find relevant information within a social network.
Second, TunkRank is not immune to manipulation and, thus, its vulnerabilities should be thoroughly studied (e.g. Sybil at-tacks could be a starting point). And third, a deeper analysis of the role of nepotistic links, in general, and the  X  X  X iscounted ratio X  X  described in this paper, in particular, is needed.
 Acknowledgements ing the Twitter dataset collection. He is also in debt with Miguel Fern X ndez for comments on an early draft of this paper. This work was partially financed by grant UNOV-09-RENOV-MB-2 from the University of Oviedo. Finally, the author would like to thank the anonymous reviewers for their constructive suggestions to improve this paper, especially regarding the use of ground truth data about relevant users.
 Appendix A. In-depth analysis of the Twitter dataset
The study described in this paper relied on a Twitter dataset collected by the author along 2009. The dataset is composed of two different parts: a collection of 27.9 million English tweets, and a user graph comprising 1.8 million users and 134 mil-lion connections. In this Appendix we provide an in-depth analysis of such dataset: we describe both the network charac-teristics and several demographical features of the users in the network.

Table A-1 shows some statistics describing the collected graph and compares it with the graph previously built by Java et al. (2007) , and with the whole Twitter crawl by Kwak et al. (2010a) . In addition to that, Figs. A-1 and A-2 show the in-and outdegree distribution in the graph used for this study and the correlation between both features. Some of the values ability, to the Twitter growth occurring between those studies, in addition to sampling artifacts. In fact, when comparing the graphs by this author and Java et al., the increase in the average degree, the size of both the largest WCC and SCC, and the clustering coefficient is consistent with a growth in the number of users together with a larger number of connections be-tween them.

During the graph collection profile information was obtained for each user, namely the user X  X  name, location, biography and website (see Table A-2 for an extract of such profiles). Such information was employed to determine the geographical location, gender, and age of the users. It must be noticed that locations are nothing but free text and, thus, it X  X  up to the user providing a sensible location (e.g.
London or NYC ) or something mostly irrelevant (e.g. at home or in the office ). We processed the available locations (62.31% of the users provide such a string) and tried to match them to geographic coordinates by means of a geocoding service. tually, 50.36% of the original profiles provided a location string suitable to be matched to actual coordinates.
Given the noisiness of locations, one could argue that some, even many, of the obtained coordinates could be wrong. Nev-ertheless, as can be seen in the map in Fig. A-3 most of the locations must be necessarily correct: users from English speaking countries are majority (the USA and the British Isles are specially prominent); Canada, Australia, New Zealand, Jamaica, Puer-to Rico, Netherlands, central Europe and Israel have also a major presence in the sample. Finally, there exist pockets of Eng-lish-tweeting users in virtually every country but concentrated, as expected, in major global cities (e.g. Paris, Tokyo, Madrid,
Seoul, Buenos Aires or S X o Paulo). On the other hand, the distribution within English speaking countries faithfully corre-sponds with their population density. So, in short, it seems safe to claim that half of Twitter users provide an accurate geo-graphical location.

The name and biography fields were in turn employed to infer some demographic features about the sampled users, namely gender and age. To determine the gender we parted from the  X  X  X requently Occurring First Names and Surnames From the 1990 Census X  X  22 ; those data files provide 88,799 surnames, 4275 female first names and 1219 male first names. We assumed that any user name starting with a first name and ending with a last name from the census was a valid personal name. Certainly, many people provide aliases, just their first name, or their names and/or surnames are not frequent enough to appear in the US Census data; however, we think that this approach is the best for the sake of higher precision.

With regards to those first names appearing in both male and female data files (e.g. Alexis , Charlie ,or Dominique ) we as-sign gender according to the frequency of appearance provided the difference was high enough. In this regards, Alexis and
Dominique were always considered female names while Charlie was considered a male name. Of course, this is an oversim-plification which, certainly, could be improved by taking into account the data in the biography field but we considered that, for the descriptive purposes of this section, it is good enough.

To support that claim some anecdotal evidence can be provided. First, there exists an almost perfect positive correlation between the last name distribution in the US 1990 Census and within the Twitter users (0.9701). The correlation regarding first name lists is smaller but still positive (0.6355 for female names and 0.6356 for male names). Arguably, this can be due to a major presence of young users among twitterers . As it can be seen in Table A-3 just one female name appear in both top-10 lists ( Jennifer ) while three are common for male names ( James , John and Michael ). Both situations seem consistent with the fact that given names have relatively fast turnovers (well under a decade), in particular, female names (cf. Levitt &amp; Dubner, 2005 ).

In addition to this, we computed the most distinctive terms in both male and female biographies by means of a likeli-hood-ratio test in a way analog to that of Java et al. (2007) . Among the top-10 words for females were mom , girl , wife and mother , while husband , guy , father , dad and man appeared at the top of the list for male users; Table A-4 provides a more exhaustive list.

Hence, it seems that our method to assign gender to Twitter users is reasonably accurate and, thus, it can help to provide a picture of the demographics of these users. About 650,000 users provide a personal name (both first and last name appearing the 1990 Census data files), accounting for 36.46% of the users in the graph, from which 58.61% were men and 41.39% women.

In addition to gender, we also tried to determine the age of the users (see Fig. A-4 ). To that end we relied on the biogra-or a numeral). This is also a crude approach, and prone to some mistakes (consider for instance the phrase  X  X  X roud mother of 6 biographies, the average is 21.67 years with standard deviation of 11.086 years. The distribution is clearly not normal, and users between 15 and 29 years account for 70% of the population. Such a bias toward young adults is, however, expected given the social nature of Twitter, and consistent with the previous discussion about first names.

As we did with male vs. female users, we also obtained distinctive terms from the users X  biographies within each age range. Such terms do provide some clues on the confidence one can place on the aforementioned method to determine the age of Twitter users. Table A-5 shows how the most distinctive terms almost perfectly fit the usual age stereotypes in the US and the UK. For instance, 10 X 14 year-old users are fans of Twilight , Jonas Brothers and Miley Cyrus while users from 15 to 24 years tend to mention school , college and university . Users from 25 to 59 years are commonly married, with kids being especially prominent from 30 onwards. Grandparenthood appears as early as 45 X 49 years, but is much more common from 55 onwards. Lastly, from 60 to 74 years old, retirement does appear.

Needless to say, there are mistakes: as it was expected, users from 0 to 9 years old are not in fact that age but parents with little children, instead. With regards to the age range of 85 years and more, it seems that most of the users are not indeed that age given the lack of terms appearing in the immediately prior ranges, besides the great heterogeneity of the distinctive terms for that age. If those age ranges are dropped, then the average age is 21.13 years with standard deviation of 9.08 years.
Finally, by combining age and gender it is possible to produce a population pyramid for Twitter (see Fig. A-5 ). Only 4295 users have both gender and age information and, thus, it X  X  not entirely representative of Twitter users as a whole. However, we can extract some knowledge from it: the current prominence of male users against female users is expected to gradually change towards parity, even, surpassing the number of male users; as it can be seen, female users in the 10 X 14 and 15 X 19 ranges (the so-called digital natives ) clearly surpass the number of male users.

To sum up, our dataset consists of two different collections: a series of tweets, and the network of users who published them. The tweets collection comprises 27.9 million English tweets posted between January 26, 2009 and August 31, 2009.
The user graph consists of 1.8 million users with 134 million connections. 50% of the users are geolocatable, and most of them reside, as expected, in English speaking countries. It was possible to determine gender for one third of the users; of these, 59% were men and 41% women. A relatively small number of users provide age information. Taken them as sample, the average age in Twitter is 21 years and users between 15 and 29 years account for 70% of the total. By examining both age and gender, it seems that the male predominance in Twitter has its days numbered because female surpass male users among the youngsters (10 X 19 years old).
 References
