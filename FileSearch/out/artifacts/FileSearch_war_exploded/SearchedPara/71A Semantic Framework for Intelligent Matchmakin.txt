 The recruitment of human subjects for clinical trials is a critically important step in the discovery and validation of new cures for disease. However, current recruitment methodologies are inherently inefficient. Considerable resources continue to be ex-pended in an effort to recruit adequate numbers of patient volunteers who meet the inclusion/exclusion criteria for clinical trials. An important requirement for reliable conclusions from clinical trials is to minimize the variation between participating sub-jects, as the statistical significance of any observed differences in the medication or treatment responses from subjects is contingent on the assumption that they are sim-ilar to each other in health profiles X  X ny observed differences should ideally be solely due to differences in responses to drugs/treatments that they receive.

In order to minimize variation between the participants in a clinical trial, they are often preselected based on a set of eligibility criteria often subclassified as inclusion and exclusion criteria. As implied, inclusion criteria should be true for all selected subjects included in a trial, whereas exclusion criteria should be false. These are com-monly expressed in the form of phrases and sentences, for example,  X  X egative serum pregnancy test for women of childbearing potential. X  A criterion is often expressed in several different ways, such as  X  X illingness to accept randomization X  and  X  X onsent to be randomized into treatment. X  They vary considerably in the level of abstraction, from general criteria like  X 18 X 70 years of age X  and  X  X nglish speaking X  to highly specific cri-teria like  X  X  Hamilton Depression Rating Scale 17 Item (HDRS-17) score of &gt; 17 X  or  X  X eets DSM-IV criteria for generalized social anxiety disorder (GSAD). X 
Criteria may sometimes be abbreviated, for example,  X  X ADRS &gt; = 16 X  is synonymous with  X  X he subject has a Montgomery- X  Asberg Depression Rating Scale total score greater than or equal to 16 at screening and baseline. X  Practically speaking, the selection of subjects for clinical trials depends on the intelligence and experience of human recruiters to manually interpret such criteria and their potential matches with subject profiles.
 Standardizing the representation of inclusion/exclusion criteria has several benefits. It can minimize the ambiguity in interpreting criteria so that interrecruiter variation in subject selection is reduced. Some of the steps in the clinical trial recruitment work-flow, especially recruitment, can be automated if a standardized set is available. It can help to enhance the accuracy of matches from potential subject databases. Redundancy in recruitment efforts can be reduced if a new study uses criteria that can be mapped to criteria from previous studies. It can also facilitate the meaningful pooling of re-sults for meta-analysis from multiple clinical trials that have explored the efficacy of either identical or similar treatments. Three kinds of approaches to standardization X  ontology-based, formalization, and rule-based X  X re summarized in Table I.

In light of the potential benefits, several solutions have been proposed for standard-izing the representation of selection criteria [Davis 2005; Niland et al. 2007; Richesson and Krischer 2007]. Standardizing core eligibility criteria can serve as the underpin-ning for various use cases and technical implementations of eligibility screening and subject recruitment applications. The need for sensitive and specific criteria is high-lighted as an important consideration for prevention of misclassification of subjects [Davis 2005].

There are several initiatives for establishing structured or semantic representation of eligibility criteria for clinical trials. These include the Agreement on Standardized Protocol Inclusion Requirements for Eligibility (ASPIRE), which aims to establish structured representation of coded eligibility criteria using controlled vocabularies [Niland et al. 2007], and Eligibility Rule Grammar and Ontology (ERGO) [Tu et al. 2010]. ERGO uses a template-based expression language to encode eligibility criteria and adapted the Clinical Observations Interoperability (COI) Task Force designed by the W3C Interest Group [W3C 2008; Kashyap et al. 2009]. Weng et al. [2010] provide an overview of recent initiatives for establishing structured or semantic representation of eligibility criteria for clinical trials.

In contrast to the human-intensive strategies proposed previously, this article at-tempts to undertake an automated and complementary data-driven approach towards the enumeration of a canonical set of exclusion/inclusion criteria. Since this is based on existent criteria, such a representation has the advantage of being easily under-stood by personnel involved in clinical trial recruitment. This can facilitate widespread adoption of a common means for specification of eligibility criteria in clinical trials, thus rendering the benefits of a standardized representation without the overhead of learning a new form of representation.

The rest of the article is organized as follows. Section 2 describes the semantic frame-work for intelligent matchmaking in the MindTrial system. In Sections 3 and 4, we present the methodology for extracting a representative set of eligibility criteria from a given collection. In Section 5, we report a case study for detailed clinical trials related to Generalized Anxiety Disorder (GAD) with performance evaluation. We illustrate how a standardized set of criteria can facilitate matches between subjects and clinical trials. Section 6 discusses some limitations of this approach, while Section 7 concludes. The recruitment of human subjects for clinical trials plays a critical role in advanc-ing healthcare, but current recruitment methodologies are inherently inefficient. This project aims to extend the MindTrial system [Lee et al. 2010; Krishnamoorthy 2011] for clinical trial volunteer recruitment by the incorporation of a semantic framework for intelligent matchmaking with inclusion/exclusion criteria (Figure 1).

There have been substantial research efforts placed on identifying canonical rep-resentation and intelligent matching in different ways in various domains, such as bioinformatics, database integration, image processing, and programming. An exam-ple of such efforts is the previous work on weighted subgraph matching in biological network [Bhattacharjee and Jamil 2012]. Le Cl  X  ement et al. [2009] proposed a new constraint-based modeling language to define graphic similarity measures for program-ming. Dietrich [2012] derived a canonical data model as the most common structure of database schemas and addressed the benefits of unified schema matching and mapping processes. Srestasathiern and Yilmaz [2011] proposed a new canonical representation for planar objects that can be used in projective transformation. However, unlike all these examples, our work is based on excerpts from free-text data, which may hinder capturing the structure or schema with the eligibility criteria data already derived from previous clinical trial studies. In other words, the graph-based approaches presented in previous studies may not be suitable for us to exemplify a concrete and effective canon-ical representation for real-world applications including intelligent matchmaking in clinical trials.

In order to facilitate matches between volunteers and clinical trials related to a set of related pathological conditions, for example, mental diseases, we need to determine a minimal set of eligibility criteria to serve as the basis of a standardized representation. The automated pipeline presented in this article can be readily adapted for any given set of conditions.

As detailed next, the system can be dynamically updated. Each criterion for a new study is first compared to the index of existing unique criteria. If it is found to be a new criterion, it is set aside. Once a sufficient number of new criteria have accumulated, for example, 1,000, these are subjected to a round of clustering based on the methodology. Each cluster will now correspond to a new criterion and be cumulatively added to the index of criteria. It is anticipated that as more clinical trials are data-mined, there will be fewer new criteria to be added. Judging from our approach for GAD (Generalized Anxiety Disorder) presented in this article, we expect that the unique set of criteria will be several orders of magnitude smaller than the comprehensive listing of eligibility criteria in clinical trials. Further, the criteria can be progressively assembled into semantic hierarchies so that they can be used for intelligent prompts during the query building process by recruiters and for profile generation by subjects. Ultimately, this can facilitate rapid searches and subsequent refinement of eligibility criteria.
The key components of the semantic framework (Figure 2) and accompanying ad-vantages include (i) Step 1 X  Eligibility Criteria Clustering  X  X  minimal set of eligibility criteria are discovered by natural language processing (NLP), semantic, and clustering techniques for maximal coverage of clinical trials; (ii) Step 2 X  Comprehensive Modeling of Inclusion and Exclusion Criteria X  The semantic model (ontology), database schema, and the mapping between them facilitate rapid and accurate assessment of potential matches between clinical trials and subjects; (iii) Step 3 X  Intelligent Matchmaking for Clinical Trial Recruitment X  potential volunteers can be identified by an intelligent matchmaking process that facilitates matching with appropriate trials. Based on the knowledge base (ontologies) derived from data-driven clustering (discussed in Section 3), the selection of patients or potential volunteers can be automated through search interfaces (discussed in Section 4) within the semantic framework. The ac-quired model has been incorporated into the MindTrial clinical trial recruiting system [Lee et al. 2010]. The proposed approach is based on the hypothesis that the actual number of eligibil-ity criteria can be relatively small upon screening and filtering redundant variables, especially in the context of a single disorder or group of disorders. Typically, similar criteria are repeatedly used for recruiting volunteers in various studies, with several syntactic variations. Thus, the approach described next starts with a given collection of eligibility criteria. The general approach is described first, followed by a specific case study on clinical trials dealing with Generalized Anxiety Disorder (GAD).
 A typical example of the eligibility criteria for a study is given next in Table II.
We exploit the inherent redundancy in eligibility criteria (i.e., the same criterion is often used in different studies) by adopting an incremental approach to clustering as follows.  X  X reprocessing of eligibility criteria data.  X  X ptimization of similarity measure based on a small sample of eligibility criteria.  X  X lustering of eligibility criteria (Figure 3).  X  Phase 1. Creation of seed clusters using a sample of eligibility criteria.  X  Phase 2. Assignment of remaining criteria to the seed clusters.  X  Phase 3. Clustering of residual criteria.
 Syntactic heterogeneity is handled as follows.  X  Treatment of Inconsistent Representation of Punctuation Marks . We convert criteria with the inconsistent presence of punctuation marks like commas, periods, and semi-colons to a consistent representation.  X  Splitting Compound Sentences into Criteria . A single sentence sometimes speci-fies multiple criteria. We designed domain-specific rules to exploit the presence of connectors like  X  X nd X  and  X  X ith X  to split sentences into discrete fragments, each corresponding to a single criterion.
 For example,  X  X ale or Female outpatients at least 18 years of age with primary (the condition that is most central to the patients current distress) symptoms of Acute Stress Disorder as defined by DSM-IV criteria A1 A2 and at least one additional category of Acute Stress Disorder symptoms X  is interpreted as the following three distinct criteria.  X  X  1 . Male or female outpatients at least 18 years of age.  X  X  2 . Primary (the condition that is most central to the patients current distress) symp-toms of Acute Stress Disorder as defined by DSM-IV criteria A1 A2.  X  X  3 . At least one additional category of Acute Stress Disorder symptoms. In order to determine the similarity between criteria, there are two important ques-tions to be addressed: (i) which elements of criteria should be compared and (ii) how they should be compared. Since these directly relate to the accuracy of clustering, we optimize the measurement of similarity based on a small sample of eligibility crite-ria. Table III shows the intercriteria similarity measurements that are used for the optimization. 3.3.1. Term Selection for Similarity Match. Given a pair of criteria, it is necessary to deter-mine which representation should be considered for estimating the similarity between them. There are two general options: lexical and synonym match, and ontological term match. The former considers all words or their synonyms appearing within the criteria while the latter considers only ontological terms. (1) Lexical and Synonym Match . Variants of lexical matching including synonym, stop 3.3.2. Ontological Term Match. For ontological term matching, we need to decide on which ontologies or controlled vocabularies should be used. In our study, terms from MeSH, SNOMED-CT, LOINC, and MindTrial Lookup were considered for similarity matching of eligibility criteria. Ontological terms within each criterion were identified using SNOMED-CT, MESH, and MindTrial Lookup for clinical trials.  X  Normalizing Variation and Inconsistency in Representing Criteria . Varying expres-sions of eligibility criteria like  X  X reater than or equal to, X   X  X ore than or equal to, X   X  X lder than or equal to, X  or symbols like  X  &gt; =  X  are converted to a uniform notation.
Both the following criteria specify  X  X  score of &gt; = 20 on a 14-item HAM-A scale, X  but are expressed in different ways.  X  X  1 =  X  X he subject has a 14-item Hamilton Anxiety Rating Scale (HAM-A) equal to  X  X  2 =  X 14-item HAM-A &gt; = 20 at Screening and Baseline. X  Further, inequality may be represented inconsistently in different vocabularies. For example, MeSH defines a term  X  &gt; =  X  which can map to  X  X reater than or equal to X  but not to  X  X qual or above. X  To deal with the inconsistency between ontologies, we need to convert the terms to a uniform representation. For criteria C 1 and C 2 ,the domain terms { subject, 14-item HAM-A, &gt; = } and { 14-item HAM-A, &gt; = , Baseline and Screening } will be selected. This conversion simplifies the matching and is useful in solving the problem of inconsistency.  X  MultiWord Expansion by N-gram Detection . We use MeSH and SNOMED-CT to identify previously known multiword concepts like birth control or child bearing .
The eligibility criteria might also contain frequently used concepts not present in existing controlled vocabulary. To determine this, the number of unique terms and their frequency in inclusion and exclusion criteria (frequency is the number of times of occurrence divided by the total number of terms) is estimated using a seed exten-sion approach for n-gram detection. Frequent terms are incrementally extended by considering the frequency of progressively longer sequences (ranging 2 X 5 in length based on sampling experiments). For example,  X  X eriatric depression score X  is recog-nized as a frequent occurrence after recognizing that each of the constituent words is present at a high frequency and then aggregated to  X  X eriatric-depression-score. X  It is important to note the distinction between generic n-gram detection and maximal n-grams that are relevant to clinical eligibility criteria. For example, while both  X  X eri-atric depression score X  and  X  X epression score X  might be detected at high frequencies,  X  X epression score X  cannot be considered equivalent to  X  X eriatric depression score. X 
In other words, when one n-gram is a superset of another (this might be recursively true) within the same criterion, the longest one (most specific) should be captured as the relevant concept.  X  Treatment of Inconsistent Representations for Terminologies . There is often inconsis-tency in abbreviations for disorder names, laboratory test names, and scale names. The criteria do not follow a standard way of expressing these domain-specific terms.
For example, PTSD is lexically represented in four different ways.  X  X  primary diagnosis of noncombatant-related Post traumatic Stress Disorde r  X  X iagnosis of Post-Traumatic Stress Disorder (PTSD).  X  Posttraumatic Stress Disorder (criteria of SCID).  X  PTSD Diagnosis. 3.3.3. Similarity Measurements. For this research, two measurements were used: (i) Symmetric Pairwise Similarity Score and (ii) Jaccard Coefficient Measures Similarity . (i) Symmetric Pairwise Similarity Score . Given a pair of criteria, it is necessary to (ii) Jaccard Coefficient Similarity . We also used the Jaccard coefficient similarity be-The evaluation of these two measurements is further discussed in Section 5.3.2. Clustering is an important component of this model, where similar criteria are grouped together. We propose a novel three-phase model of eligibility criteria clustering that is performed incrementally by first constructing seed clusters for a large sample dataset (called the semantic clustering). This is followed by merging other criteria to the seed clusters by a model-based clustering approach. Finally, the remanining unknown crite-ria are clustered separately by the semantic clustering. All the clusters taken together constitute the canonical nonredundant set. There are multiple reasons for following an incremental approach rather than clustering all criteria at once. The number of pair-wise similarity values that need to be stored is proportional to the square of the number of criteria. Though there is wide lexical variation in the representation of eligibility criteria, the underlying semantically distinct criteria are relatively small in number. For example, half a million values need to be stored when dealing with a thousand cri-teria. To counter this, an incremental hybrid a priori/model-based clustering approach is employed that is scalable without compromising accuracy. Incremental clustering also makes it possible to accommodate new lexical variants of existing criteria as well as new criteria with minimal computation. 3.4.1. Three-Phase Clustering Model for Eligibility Criteria Clustering. The three-phase clus-tering model is composed of the following phases.  X  Phase 1: Semantic Clustering using MCL . In Phase 1, we use Markov clustering (MCL) [Vlasblom and Wodak 2009; van Dongen 2000] for clustering eligibility crite-ria. MCL is employed to cluster a subset of the criteria into semantically equivalent groups. Ideally, each cluster will end up with examples of different ways of expressing the same eligibility criterion. MCL is a highly scalable and widely used algorithm [Brohee and van Helden 2006] that is based on network flow paradigms and un-like approaches like k -means, does not require an explicit number of clusters to be predefined. It has shown to be superior in accuracy and performance to many other clustering approaches in multiple domains [Vlasblom and Wodak 2009]. A sample of criteria is first clustered using MCL to establish seed clusters. Each seed cluster is mined to define a term profile that characterizes it. This term profile can then be used to assign a large proportion of criteria to the existing seeds in linear time.
Since there are several semantic duplicates expected, it is logical to reduce dimen-sionality by first creating a relatively small number of cluster models to guide the clustering. The MCL algorithm includes a parameter called the inflation factor that determines the granularity of clustering; the higher the value of the inflation factor, the larger the number of clusters and the smaller the size. Since MCL is primarily based on simulation flow of graphs, the presence of a large number of weakly similar criteria (noise) tends to produce coarse and unnatural cluster formation. Choosing an appropriate threshold for minimum similarity circumvents this problem.
 takes in the symmetric pairwise similarity score matrix obtained from the previous step as input and outputs the criteria clusters. The seed clusters are obtained from a large sample of criteria. The F-Measure (harmonic mean of precision and recall) is used to determine the best value for this parameter based on a representative sample of criteria (discussed in Section 3.4.2). Once the seed clusters are generated, each cluster is labeled with a representative ontological term profile. This consists of high frequency terms that are relatively unique to each cluster. In order to identify the representative terms of clusters, term frequency and inverse document frequency (TF-IDF) are used together with three ontology sources: MeSH, SNOMED-CT, and
MindTrial Lookup.  X  Phase 2: Model-Based Clustering for New Eligibility Criteria. In order to cluster the remaining criteria, we followed a model-based clustering approach based on the representative (TF-IDF) terms obtained for the seed cluster set. We restrict the signature to the most representative terms rather than all tokens because the information content drops exponentially, including all tokens confounds classification by increasing noise. Further rationale for this approach is discussed in Section 6.2, and a comparison with the use of all ontological terms presented in Section 5.4.
The ontological terms of the target criterion, EC i = { DT i1 ,DT i2 ,..., DT in } , are taken and compared with the representative terms of each seed cluster, CT j = { Ct j1 ,
Ct j2 ,..., Ct jn } . Based on the similarity measurements discussed in Section 3.3.3, if the highest similarity score (among all the cluster candidates) is higher than a certain threshold, then the new target criterion is merged into the seed cluster.
When a criterion matches with an identical score to multiple clusters, the one with the maximum number of members is selected. This corresponds to the principle of a prior being influenced by real-world distribution of classes. If the clusters have the fewest number of classes, the tie is broken by favoring the cluster with more specific representative terms, as indicated by TF-IDF. In the unlikely event that there is still a tie, random allocation to a cluster is employed. The representative terms of the clusters are updated with any new terms of the target criteria whose weight is higher than the threshold. If new criteria do not match with any existing cluster, they will serve as seeds for new clusters. Admittedly, there may be cluster drift over a long period of time. The need to recluster periodically has been explicitly stated in Section 6.4. Figure 5 shows an example of the merging process in model-based clustering.  X  Phase 3: Clustering Remaining Criteria. The residual criteria that cannot be assigned to any existing cluster from Phase 1 or Phase 2 are clustered with the semantic clus-tering approach (as in Phase 1) to form additional clusters. The clusters augmented in
Phase 2 represent criteria that are common to both inclusion and exclusion criteria (e.g., they are criteria used in both affirmative and negated forms). The clusters generated in Phase 3 are more specific to exclusion criteria.

This three-phase model is an example of model-based clustering. If a criterion does not match any preexisting cluster, it is used to start a new cluster. Since the same clustering parameters and rules are employed, we expect preexisting and new clusters to be consistent. 3.4.2. Representative Terms Selection. A set of representative terms for each cluster is selected using TF-IDF. The representative terms are used for incremental clustering of new criteria. TF and IDF were estimated for ontological terms as follows. The term frequency (TF) in the given cluster is simply the number of times a given term appears in that cluster. Lexically distinct but semantically similar terms are counted together as ontological terms of the ontologies (discussed in Section 3.3.2) to give a measure of the importance of the term t within a particular cluster c . The inverse document frequency (IDF) is a measure of whether the term t is common or rare across all clusters, C . The IDF is obtained by dividing the total number of clusters by the number of clusters containing the term and then taking the logarithm of that quotient. The TF  X  IDF is calculated as follows.
 where | C | is cardinality of C, or the total number of clusters in the corpus, and |{ c  X  C : t  X  c }| is the number of clusters where the term t appears. If the term is not in the corpus, then this is calculated as 1 + |{ c  X  C : t  X  c }| to avoid division-by-zero.
A high weight in TF  X  IDF is reached by a high term frequency (in a given cluster) combined with a low document frequency of the term in the whole collection of clusters; the weights hence tend to filter out common terms. Since the ratio inside the IDF X  X  log function is always greater than 1, the value of IDF is greater than 0. As a term appears in more clusters, the ratio inside the log approaches 1, making IDF and therefore TF-IDF approach 0. If a  X 1 X  is added to the denominator, a term that appears in all clusters will have negative IDF, and a term that occurs in all but one cluster will have an IDF equal to zero. Finally, we select all top ranked terms with a TF-IDF score higher than an empirically determined threshold. The threshold selection is discussed in Section 5.4. To establish proof of concept for the proposed model for canonical eligibility criteria, we implemented a search engine in the MindTrial system that supports customized searches for potential recruiters. This application illustrates the motivation for clus-tered canonical eligibility criteria for clinical trials. Figure 6 shows an overview. Query processing is initiated by text input of inclusion or exclusion criteria from users. The input is compared with inclusion/exclusion clusters to map it to the appropriate se-mantic criterion type within the MindTrial Eligibility Ontology (Section 4.2) followed by a patient database query using the SQL generated by the semantic rules defined in the ontology. Potentially matching patients are retrieved based on both exact and near matches. We now discuss the ontology, rules, semantic query samples generated by the rules, and the output from the query.
 In order to design the MindTrial Eligibility Ontology (MEO), we used the set of eligibil-ity criteria for clinical trials on GAD from the NIH Clinical Trials website. 2 Relevant criteria can be selected as a subset of this for any particular study.

The MEO ontology hierarchy is basically a terminological schema formed by map-ping the top-ranked representative terms of the clusters (generated from the clustering in Section 3) to the terminology hierarchy of SNOMED-CT and MeSH. As the repre-sentative terms of clusters are mostly ontological terms, they were easily mapped to the ontologies. Some of the top ranked representative terms were the lookup terms developed by us and plugged into the hierarchy. The MEO has three main hierarchies: inclusion cluster, exclusion cluster, and database mapping. The inclusion cluster and exclusion cluster, in turn, have clusters as subconcepts. Figure 7 depicts the schema represented for eligilibity cluster Age/Human (Gender) and Informed Consent .Inthe top figure, the Human/Age Group was specified to represent both age and gender, as it is one of the dominant clusters from the eligiblity criteria clustering.

The MindTrial Database was developed on an MS SQL server for query processing in the clinical trial eligiblity search engine. The database is an important component of the model, which is ideally used to map the criteria set of a study to subject medical information, thereby identifying subjects for the study. Figure 8 shows the MindTrial database schema.

In this article, we have developed a framework to facilitate automatic mapping between ontology and database. A database SQL query can be automatically generated if there is a mapping between concepts in the ontology and fields in the database. The schema includes mapping between the concepts for the clusters in the MEO ontology and the corresponding database table, and also the columns to be identified by the properties associated with cluster concepts.

The database query generation executes the following steps based on the ontology-to-database (Onto-to-DB) mapping schema: first, for a given free-text query, identify the target criteria cluster based on the matching between query terms and representative terms of clusters. Second, for the target cluster identified from the first step, determine the corresponding database table and columns associated with the target cluster. Prop-erties of the ontology concepts of the target cluster facilitate this. Finally, a parsing process is used to construct the DB SQL queries with concepts and values based on the criteria using a set of rules written in Semantic Web Rule Language (SWRL). For example, as shown in Figure 9,  X  women with age &gt; = 18 and &lt; = 65 years  X  (free text) would be mapped to the Human/Age Group and the corresponding SQL query would be generated: select user id from mt user profile where age &gt; = 18 and gender =  X  X emale X  .
By accumulating cases where a good mapping cannot be found for the concept(s) from a cluster, the mapping scheme in the ontology is continuously refined. In ad-dition, we have developed two relaxation methods for approximate matching. First, relaxed queries are formed by relaxing the concepts to subsequent higher levels or to the siblings of the target criteria concept within the ontology (Figure 10). For example, DSM-IV may be relaxed to Assessment Question &amp; Standard (parent) or to MINI (sib-ling). Second, a relaxed query (e.g.,  X  X ind ten more subjects X ) is formed by relaxing the range of values for a query. For example, if the criterion is  X 18 &lt; = BMI &lt; = 25 X , relaxing the query to  X  X MI &gt; = 16 X  or  X  X MI &lt; = 27 X  years can yield more potential subjects. The MindTrial system provides intelligent matchmaking features for discovering po-tential participants in clinical trials (Figure 11). It provides both a free-text interface that expects eligibility criteria to be typed for subject search queries. It also provides a detailed fine-grained checklist view where fields identical to those in a screening ques-tionnaire can be selected as inclusion (desired) or exclusion (NOT desired) criteria. Us-ing the intelligent matchmaking (ontology to database mapping) approach (described in Section 4.2), the subjects who are matched to the study eligibility criteria will be retrieved. In addition to exact matches for the query, near matches are also displayed, ranked by semantic and information theoretic considerations. The search results can be shown using multiple views, such as tablet, map, and chart views. Figure 11 shows the search interface with results in multiple views. The tablet view provides detailed information, and the map view shows the search results mapped on the Google map interface as markers with each marker subgrouped according to age group. The MindTrial Intelligent Matchmaking component (backend) is implemented in Perl and MySQL DB. The clustering methods are all converted to Web services and deployed to the Amazon Cloud site (MindTrial Cloud Services). The MindTrial client interfaces (frontend) are implemented using C# as Web services with Microsoft SQL on the .NET Platform. The results of MindTrial subject search engine can be presented as table, Google Maps, or chart views. The graphical browser has been designed and imple-mented using Google Maps and Microsoft chat controls. An HTTP connection to the prototype Web Services is established to access the MindTrial system. This can be used both for clustering new clinical trial studies from the NIH Clinical Trials website as well as to search for potentially eligible subjects. This allows the user to elaborate eligi-bility criteria based on the clusters. In addition, a user could start with an open-ended query to get partial matches by relaxation of eligibility criteria.
 The MindTrial Eligibility ontology (MEO) has been implemented in the Web Ontology Language (OWL) using the Prot  X  eg  X  e editor [Noy et al. 2003]. The MindTrial Eligibility ontology (MEO) defines the concepts and their properties of the clinical trial domain. The MEO interface is used for the addition of new eligibility criteria to MEO. The It uses the Resource Description Framework Schema (RDFS) as the backend and the Prot  X  eg  X  e OWL plugin to provide support for both RDF and OWL ontologies. The APIs are used to create classes and instantiate them, linking them into assertions and attaching instances of publications to them. It also allows for recursive listing of subclasses. SWRL is used to specify questionnaire constraints described in the protocol ontologies and SPARQL for query interfaces based on the ontologies. Jena is used an implementation platform querying and inferencing on the MEO. The ontology handler communicates with external ontologies (e.g., MeSH, SNOMED-CT) via the UMLS. It connects to the UMLS API to invoke the lookup service for determining the semantic distance between two concepts and for retrieving synonym sets of concepts. Pointers to relevant clinical studies are stored and the MindTrial DB server invoked on demand. We present a case study that illustrates the preceding approach on clinical trials involv-ing subjects with Generalized Anxiety Disorder (GAD). A total of 709 clinical trial study descriptions matching the query term  X  X eneralized Anxiety Disorder X  were downloaded from the NIH Clinical Trials website in October, 2010. Since eight of them did not have any eligibility criteria, only 701 studies including inclusion or exclusion criteria are used for this study. These contained a total of 2,760 inclusion criteria and 4,871 exclu-sion criteria that were used for analysis. In the MEO ontology, 283 inclusion concepts and 338 exclusion and 15 and 18 properties are modeled for inclusion and exclusion eligiblity criteria and their clusters. Table IV presents the variants of the canonical criterion of being able to provide informed consent in the MEO.

A sample of inclusion criteria was used to optimize parameters for pairwise similarity and Markov clustering (MCL). All inclusion criteria were then used to create seed clusters with Markov clustering. Following this, clusters were automatically labeled with term profiles. Exclusion criteria were then evaluated for membership in each cluster. Criteria that could not be assigned to any cluster were subjected to Markov clustering to create additional seed clusters. Figure 12 shows the clustering process for eligibility criteria for GAD. 5.1.1. External Cluster Validation. We evaluated clustering based on the gold standard of manual verification and computing, the F-measure. For the F-measure, we need to calculate the precision and recall of the clustering results. If a criterion a falls into the correct cluster C (i.e., a  X  C ) then it is regarded as a true positive ( TP c ). If a criterion a criterion is missed out in a cluster (i.e., split clusters), it is considered as a false negative ( FN c ). We calculated precision ( P c ) and recall ( R c ) and F-measure ( F c )fora cluster c as follows.
 where  X  = 1 (a default value).

The F-measure is the harmonic mean of precision and recall, where precision depicts the accuracy of the cluster and recall depicts the completeness of the cluster. The overall F-measure is calculated as follows.
 where n is the number of clusters, C i is the number of criteria set in Cluster i , | C | is the total number of criteria in the entire set, and F i is the F-measure of Cluster i . 5.1.2. Internal Cluster Validation. We also performed cluster validation by using the Sil-houette index based on statistical properties of the clustering [Collins et al. 2002]. where A ( i ) denotes the average distance between i and all data items in the same clus-ter, and B ( i ) denotes the average distance between i and all data items in the closest neighboring cluster. The silhouette value for an individual data item i reflects the confi-dence of the data item in the cluster assignment. The Silhouette Width ranges between (  X  1, 1) and should be maximized. The average distance is computed by considering only the ontological terms of each criterion. 5.2.1. Results of Eligibility Criteria Clustering. The total number of inclusion criteria was 2,760 and after splitting into atomic criteria, 2,852. The total number of exclusion criteria was initially 4,871 and after splitting, 5,000. Following the eligibility criteria clustering, 126 inclusion clusters and 175 exclusion clusters represented semantically distinct criteria. The average and maximum number of criteria per cluster and the number of singleton clusters (single member cluster) for inclusion criteria are 22.63, 563, and 61, respectively. The same numbers for exclusion criteria (Phase 2) are 25.56, 1299, and 3, and for Phase 3, 10.02, 316, and 76, respectively. The summary of these results is shown in Table V.

Tables VI X  X III show the cluster information for the inclusion criteria from Phase 1, the exclusion criteria merged from Phase 2, and the exclusion criteria from Phase 3 (representative criterion, the number of member criteria).
 5.2.2. Representative Terms in Eligibility Criteria. We use the TF-IDF method to select the representative terms for each eligibility cluster. In order to determine the optimal threshold for selecting the representative terms for each cluster, we empirically de-termined the threshold of 80% for the selection of the representative terms for each cluster after several experiments with a subset of clusters (top 15 inclusion and top 18 exclusion clusters).
 We first obtained terms for each criterion by using the N-gram approach described in Section 3.3.2. We then tried to map it to the ontology terms (SNOMED-CT, MESH, and MindTrial Lookup). Stop words were retained. Table IX summarizes the unique set of ontological terms for inclusion and exclusion criteria that were detected. The unfiltered list of N-grams matches an existing ontology term. For example, the middle column counts  X  X eneralized anxiety disorder X  as one term, while the last column, counts it as two terms X  X  X nxiety disorder X  and  X  X eneralized anxiety disorder X . The MindTrial Lookup for 74 important terms (e.g., Hamilton Anxiety Rating Scale, comorbid anxiety disorder) and abbreviations are not defined in MeSH or SNOMED-CT.

The manual step for the initial terms in the MindTrial Lookup is required. However, once the MEO ontology is designed, the domain terms can be obtained from the ontology. In the MEO ontology, we have specified 283 concepts and 15 properties retrieved from the inclusion clusters and 338 concepts and 18 properties retrieved from the exclusion clusters. A total of 621 representative concepts mapped to the MindTrial Lookup, SNOMED-CT, and MeSH are now annotated in the MEO ontology. This section presents the validation of the model at each phase and its corresponding results. 5.3.1. Optimal Inter-Criteria Similarity Metric. Figure 13 shows the accuracy comparison of eight different models to identify the best pairwise scoring strategy. This is identified as the model that gives the maximum pairwise score. In order to validate the models, we used a control data subset P consisting of 60 semantically similar pairwise criteria with lexical similarity scores ranging from 0.1 to 1.0. All eight models were applied, and the best model was identified as the one which gave the best symmetric Pairwise scores in terms of mean, min, max, variance, and standard deviation. The max and min of these models are 1.0 and 0.14. The means ranged between 0.52 and 0.66 with an average standard deviation of 0.26. On analysis of this approach, we found that stop words removal + stemming + MeSH model proved to be the best (Figure 13).

Comparative histograms of the distribution of symmetric pairwise similarity scores based only on lexical matches versus combining all approaches (augmented) are shown in Figure 14. As seen in the figure, the augmented measure shows higher similarity scores for related criteria (0.5 &lt; = symmetric pairwise score &lt; = 0.9). 5.3.2. Optimal Similarity Measurement and Inflation Factor Computation.

Threshold for Symmetric Pairwise Score. We determine the best threshold for the semantic scoring strategy for the model-based clustering (Phase 2). A dataset was created for identifying the optimal cut-off point for the clustering membership. The purpose of the dataset was to optimize the scoring strategy and determine the cut-off to define semantic equivalence between a pair of criteria. Different combinations of similarity metrics were used to determine which gave the highest similarity score for the pairs of criteria in these subsets of data.

Specifically, about 10% of semantically similar inclusion criteria (dataset M) were chosen to have unique semantics and to represent the overall population of the inclusion criteria. In this case, a second dataset M with 60 clusters, each cluster containing one to four criteria and the symmetric pairwise scores ranging from 0.1 to 1 was used. The criteria in the dataset were mixed together and the symmetric pairwise similarity between all pairs of criteria measured to determine the best threshold to recover the true pairs without forming spurious pairs. This was done by comparing values of the F-measure [Steinbach et al. 2000] while varying the symmetric pairwise similarity score cut-off (threshold) to define membership in a cluster (Figure 15). The threshold 0.4 is rated with the highest F-measure 0.78.

Optimal Similarity Measurement. Sampling the results of the clustering showed the following potential causes of error. Multiple criteria are often mixed together and represented on one line, for example,  X  X ubjects with evidence of a current (within the past six months) clinically significant or unstable hematological, autoimmune, renal, endocrine, pulmonary, gastrointestinal, cardiovascular, hepatic, pancreatic, psychiatric, neurologic, immunological or retinal disorder; subjects with an active infection within the past two months. X  When comparing a short criterion with a long criterion, a low score may be reported even if the short criterion is a proper subset of the longer criterion. To work around this, an averaged symmetric pairwise score was also computed. The symmetric pairwise similarity measurement is better than the Jaccard index, because the criterion is written fairly different lengths for the same meaning, representing one in longer sentence and the other in short sentence. To treat the mix of short and long sentences problem, we used symmetric scoring (i.e., calculating pair wise scores from A to B and from B to A and finally taking the mean of both the scores). Also, unlike natural language processing (NLP) symmetric pairwise scoring ignores the order in which the terms are represented. The results show that treating each criterion as a set of tokens/terms is fine; this improved cluster accuracy.
Inflation Factor Selection. The MCL algorithm includes a parameter called the inflation factor that determines the granularity of clustering; the higher the value of the inflation factor, the larger the number of clusters. A dataset C was created for optimizing the parameter of the MCL clustering algorithm. The dataset consisted of 60 clusters with one (i.e., singleton) to four semantically equivalent criteria in each. This dataset that covers about 5% of the total clusters of the inclusion criteria was randomly chosen to exhibit lexical heterogeneity in terms of the overall inclusion criteria. The F-measure was computed and compared for inflation factor values of 2, 3, 4, 5, and 6. The value of the inflation factor that gave the highest F-measure was selected for clustering of the criteria. To minimize the possibility that the data subset C might be trivial to cluster because of high intracluster similarity, it was designed to exhibit a wide range of intracluster lexical similarity. This validation was done by comparing the F-measure while varying the inflation factors for the MCL clustering (Figure 16). An inflation factor value of three resulted the highest F-measure 0.781. The accuracy of the clustering was estimated by using both external (F-measure-based on ground truth) and internal (Silhouette Index-based on statistical properties) cluster validation metrics. Table X shows the results of the evaluation.
  X  Phase 1. We were able to represent 2,852 inclusion criteria by 126 clusters using the semantic clustering approach. Of these, 56 clusters were singletons. This indicates that the extent of redundancy is equivalent to at least one order of magnitude. The silhouette width on average for all 2,852 data items is 0.27. The overall F-measure for the obtained clusters is 0.93 with precision 0.915 and recall 0.908. Figure 17 shows the histogram for inclusion clustering. Interestingly, only 11 clusters (8%) out of the total 126 clusters had an F-measure lower than 0.8.  X  Phase 2. Validation for Model-Based Clustering . We estimated and compared the coverage and accuracy of mapping exclusion criteria to existing inclusion clusters for
TF-IDF and ontological term (OT) approaches as follows. (a) The proportion of 5,000 exclusion criteria that were mapped to some cluster (b) Accuracy of clusters based on the merging rule  X  X f maximum pairwise score The results summarized in Table XI show that TF-IDF performs better than the OT-based method for merging criteria to existing clusters.
  X  Phase 3. Validation of Semantic Clustering for Residual Exclusion Criteria . The remaining 1,909 underwent the three-phase clustering approach resulting in 175 clusters, corresponding to an F-measure of 0.956 (precision 0.929, Recall 0.910), and a silhouette width of 0.472. Figure 18 shows the distribution of F-measure for exclusion criteria clustering. There were about 27 clusters (15%) with lower than 0.8
F-measure out of the total of 175 clusters. We conducted validation for our clustering model by comparing Markov clustering (MCL) with hierarchical clustering (HC). For the HC, we used Ward X  X  method of the R project for statistical computing 3 that is based on minimum variance distance for mini-mizing the total variance of each cluster by merging the pair of criterion incrementally that leads to minimum increase. The squared Euclidean distance is used to compute the distance. At the initial step, all clusters are singletons (i.e., clusters containing a single criterion). Through a recursive process, the criteria were continuously merged until the cluster number became K = 126 for inclusion criteria (K = 175 for exclusion criteria). It tends to produce more compact clusters compared to MCL clustering in which we used an inflation factor of 3. Using the HC algorithm, we had a lot of split clusters and about 29 mixed clusters, of which we had five clusters with &gt; = 50% mixed criteria. Interestingly, more than 90% of exclusion criteria merged (spuriously) with one of the seed (inclusion) clusters when the HC algorithm was run based on default parameter values. Table XII shows the split clusters (generated by HC) for the top 15 inclusion clusters (generated by MCL).

The silhouette-width-based internal validation results are as follows. We have ob-tained very low silhouette widths with the HC algorithm compared to the MCL. It is mainly due to the large number of split clusters. Table XIII shows the silhouette width for both MCL and HC approaches for the proposed three-phase clustering model.
The advantage of MCL over HC is its higher robustness and tolerance to noise for diverse eligibility criteria. The silhouette width on average of the clusters by HC is  X  0.74, which is much lower than the average silhouette width of the clusters (0.26) from MCL. HC displays severe convergence problems (lots of split and merged clusters) with both inclusion and exclusion criteria that we tested, whereas MCL continues to identify meaningful clusters with both criteria. Furthermore, HC needs a termination condition or else it forms large clusters that are incorrect. Thus, for eligibility criteria clustering, we find that MCL outperforms HC in terms of its ability to generate meaningful partitions. Based on these observations, we conclude that MCL is more suitable for eligibility criteria clustering. There are several reasons for pursuing a bottom-up data-driven approach to building a minimal set of eligibility criteria. It helps to focus on the actual terminology used in the specification of eligibility criteria rather than requiring conformance to an externally developed standard that is imposed. It can help identify terms or phrases not found in standard terminologies, for example, the score on the Hamilton Depression Scale is a commonly used criterion in trials on mental health. It can offer insight into building intuitive interfaces for searching databases to facilitate recruitment for clinical trial recruitment. It can be used to map real-world preferred term usage to an underlying ontological structure, thus combining the advantages of user friendliness and rigor-ous semantics. This could cut down time and effort in both clinical trial design and execution.

To determine the optimal approach for our research, we compared several ap-proaches (e.g., lexical term matching using advanced techniques, such as stop word removal, stemming methods) to identify multiword concepts within a subset of data. The ontology-based n-gram approach was found to be superior to all other lexical-based approaches. To select representative terms for each cluster, we considered the following approaches: risk ratio, odds ratio, TF/IDF, and all ontological terms. The first approach is based on risk ratio (i.e., the frequency of a term in a cluster divided by the frequency of a term in the entire set, excluding the cluster of interest). This approach is expected to find frequent terms, but not necessarily unique to each cluster; this may result in distinct clusters looking similar. On the analysis, we found that it picked up frequently used terms (like diagnosis , meet ) that do not depict the semantics of underlying clusters.
The second method is using odds ratio given by (P 1 /(1-P 1 ))/(P 2 /(1-P 2 )), where P 1 is the probability of a term in a cluster and P 2 is the probability of a term in the entire set. On analysis, we found that it picked unimportant terms which might occur only once or twice in the cluster but not in the other clusters.

The third method is using TF/IDF considering only known ontological terms and additional terms in our lookup tables. This method was found to be the best at picking up the most representative terms of each cluster and shows the highest clustering quality compared to the other two approaches.

The fourth method is simply using all ontological terms present within the cluster as being representative of the cluster. This did not fare as well as TF/IDF. Ideally, a scoring metric should yield a value of exactly 1 (or 100%) between any two semantically equivalent criteria. The resulting standard deviation should be zero. Figure 13 shows a trend, but only a trend, towards this idealized extreme on using a combination of approaches to minimize the effect of lexical heterogeneity. The figure shows a decrease in standard deviation as the scoring system is refined towards higher values. In reality, the wide variation in expressing the same concept limits the maximum score that can be achieved. For example,  X  X hysically fit X  and  X  X ood general health X  do not share any word between them yet refer to the same inclusion criterion.
Refinement of the symmetric pairwise scoring system should generally be expected to increase the mean value and cause a shift of the distribution towards higher values. This is clearly seen in the effect of stemming. However, stop word removal might either increase or decrease the range of score values, depending on how much these words contributed to the pairwise score. It showed no difference for the control data subset P consisting of 60 pairs of semantically equivalent criteria. It was surprising to find that MeSH synonyms did not make a detectable difference. Part of the reason might be because of the way the criteria were preprocessed by inline replacement with MeSH terms. In some instances, an abbreviation was replaced by a multiword expansion which could potentially have a spurious effect on the score.
 The method for the analysis of inclusion criteria presented here should be useful for ex-clusion criteria as well as conditions other than GAD, because the set-based approach presented here makes no assumptions about the content or format of the data. We have observed that exclusion criteria are elaborated more specifically than inclusion criteria at a different levels of abstraction. Thus, it seems appropriate to use inclusion criteria as seed clusters for subsequent model-based clustering of exclusion criteria. Also, an inclusion criterion in practice is often stated as the negated version of exclu-sion criteria. For example,  X  X egative serum pregnancy test for women of childbearing potential. X  Within our framework, the inclusion and exclusion criteria are semantically represented (the exclusion criteria cluster are as the negation of their corresponding inclusion criteria cluster through a negation relationship) in the MEO ontology so that subjects can be selected as inclusion ( desired ) or exclusion (NOT desired ) criteria through the proposed intelligent matchmaking approach.
 No attempt was made to separate criteria based on applicable phase of clinical trial. A comprehensive approach is offered here as proof of concept, but it might have greater utility if subsequently resolved into different subtypes of clinical trials.
It is also important to consider issues such as required updates of the model due to evolving criteria in the clinical trial domain. Since new tokens are added to existing clusters, the meaning of clusters may change over time. It might be necessary to rebuild the model (Phase 1 clustering) periodically. We will explore these issues in our future work. Beside the silhouette measure, we also experimented with the use of the Dunn index [ Dunn 1973] as an internal validation measure. The Dunn index measures the ratio between the smallest intercluster distance and the largest intracluster distance. As this method is more conservative, the minimal score was low (i.e., 0.02). This was because our clusters were not completely pure. And this validation measure takes the outliers of each cluster into consideration. The criterion which has the largest average distance is taken and its corresponding average is taken as the largest intracluster distance. This article presents a general data-driven approach that can be used to compile a minimal set of eligibility criteria for clinical trials. The proposed model allows the flexibility of using free text while capturing the semantics of the criteria for computer readability. This approach complements the top-down specification of eligibility criteria based on formal ontologies. This approach can aid in better characterization of both human volunteers and clinical study requirements, thus leading to accurate and effi-cient matching of subjects with clinical studies. The results obtained by the application of our approach can be used to generate an atomic set of eligibility criteria which can be used to create successively refined or complex eligibility criteria that can readily be incorporated into intelligent search engines in databases of clinical trials and subjects.
