 Although open domain question answering systems provide essential information to seek general knowledge, it has not been widely used yet. In this paper, we remark that most existing question answering systems have concentrated on improving the ability of dealing with limited and typical target concepts. answers are previously prepared and named entity recognizers are widely used for capturing the answer candidates which have semantic hyponym relations with the typical categories. In the case of these systems, if a question has a target concept not to be prepared in the systems or the target concept cannot be captured by named entity recognizers, they must operate a module for handling the exception to generate an-swer candidates. For example, if a system does not have the target concept  X  X ook X  as an expected target category, it is highly difficult to extract answer candidates that are semantically hyponyms of  X  X ook X .  X  X hat book did Rachel Carson write in 1962? X  always  X  X s-a X  relations between answer candidates and target concept. Thus we ex-tracted Lexico-Semantic Patterns (LSP) [1][2] of  X  X s-a X  relations from the World Wide untypical nominal concepts. And we exploited bootstrapping algorithm of Ravi-chandran [3] and Riloff [4] in the proposed system. concepts. Table 1 shows a categorization method for typical nominal answer types which is used in many question answering systems. tions with an unexpected category of concepts, the system must add a new category to the set of expected concepts. The proposed method makes use of nominal concepts that are directly specified in a question as the question X  X  answer type. Table 2 shows the proposed method of answer type categorization. By using the method, answer types of all questions can be automatically classified without exception. What actress has received the most Oscar nominations? ACTRESS What beach was "I Dream of Jeannie" filmed on? BEACH What book did Rachel Carson write in 1962? BOOK terns, assigning them confidence scores, and using them to find answer candidates. 3.1 Extracting  X  X s-a X  Relation Patterns and Assigning Confidence Scores and a named entity tags. We also use the snippets returned by the Google web search What actress has received the most Oscar nominations? PERSON What beach was "I Dream of Jeannie" filmed on? LOCATION What book did Rachel Carson write in 1962? Cannot recognize engine 1 in the stages for extracting  X  X s-a X  relation patterns, assigning confidence scores to those patterns, and constructing an answer candidate set with the patterns. ously have  X  X s-a X  relationship. We manually picked out 110 &lt;answer(X), target-answering in TRECs from 1999 to 2002. In the next step, patterns with these &lt;X, Y&gt; pairs are extracted from snippets of the web search engine. Fig. 1. (a) shows an ex-ample of the process to extract a pattern for the word pair of &lt; X  X alcium X ,  X  X ineral X &gt;. shows an example of assigning a confidence score to each pattern. where Riloff (1996) X  X  RlogF measure scheme is used in the formula (1) and sam-ple_cnt means the count of total sample pairs which produce the same pattern. of the pattern generated by processes of Fig. 1. (a) and Fig. 1. (b). terns with the confidence scores of 0.0. Finally, we used 26 patterns in our method. 3.2 Extracting Answer Candidates Using the Patterns Now we can extract hyponyms of given target concepts by using the patterns con-structed in the previous section. In this process, we also use web search engine. The sumes that we already know what an X term of the  X  X  is-a Y X  relation is, but we just candidates. 3.3 The Hybrid Methods In general, the coverage of the propose method using patterns is wider than methods using a named entity recognizer (NE). However, each method has the weak points in one method can find the correct answer.  X  X hat gas is 78 percent of the earth's atmosphere? X  (Only the Pattern method)  X  X hat president served 2 nonconsecutive terms? X  (Only the NE method) while it cannot be covered by the named entity recognizer, and  X  X resident X  as the tar-get concept of the second example can be easily captured as a  X  X ERSON X  by the named entity recognizer. If two methods can be efficiently combined, their strong points can compensate for their weak points. Therefore, we constructed the hybrid methods as follows: tracts answers from the previously detected answer candidates. Otherwise, only the then we assign the confidence score of the pattern to the answer candidate. by a linear combination as the following formula: pattern and NE methods respectively. In the experiments, we focused on only questions with the pattern of  X  X hat Noun-Phrase Verb-Phrase X . These questions can be regarded as the equivalent form of  X  X hat Verb-Phrase Noun-Phrase X . However, we merely consider the questions whose research area of this paper. In such a pattern, the head noun of a noun phrase is obvi-ously resolved as the target concept.  X  X hat NP VP X  pattern. In addition, we removed 8 questions of which the judgement set has no correct answer. Finally, we experimented with 142 questions. To apply the through the process of Fig. 3. racy measures for TREC evaluations. According to the TREC 2003 judgement set, we determined whether the extracted candidate answer is a correct answer. 4.1 Experimental Results We conducted experiments for NE, Pattern, and two hybrid methods. Table 3 shows correct answers when the system submits only one answer per each question. our proposed pattern method works properly to capture the hyponyms of the target pattern methods are also useful. In this paper, we proposed the flexible method which can easily find answers with any nominal target concept. As shown in our experiments, the  X  X s-a X  relation patterns with ical answer type which can be hardly captured by the named entity recognizer. needed for practical applications. This research was performed for the Intelligent Robotics Development Program, one Industry and Energy of Korea.

