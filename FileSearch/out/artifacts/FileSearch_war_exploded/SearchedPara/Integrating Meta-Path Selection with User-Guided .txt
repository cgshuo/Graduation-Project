
Real-world, multiple-typed objects are often interconnected, forming heterogeneous information networks. A major challenge for link-based clustering in such networks is its potential to gener-ate many different results, carrying rather diverse semantic mean-ings. In order to generate desired clustering, we propose to use meta-path , a path that connects object types via a sequence of re-lations, to control clustering with distinct semantics. Nevertheless, it is easier for a user to provide a few examples ( X  X eeds X ) than a weighted combination of sophisticated meta-paths to specify her clustering preference. Thus, we propose to integrate meta-path s-election with user-guided clustering to cluster objects in network-s, where a user first provides a small set of object seeds for each cluster as guidance. Then the system learns the weights for each meta-path that are consistent with the clustering result implied by the guidance, and generates clusters under the learned weights of meta-paths. A probabilistic approach is proposed to solve the prob-lem, and an effective and efficient iterative algorithm, PathSelClus , is proposed to learn the model, where the clustering quality and the meta-path weights are mutually enhancing each other. Our exper-iments with several clustering tasks in two real networks demon-strate the power of the algorithm in comparison with the baselines.
H.2.8 [ Database Management ]: Database Applications X  Data mining
Heterogeneous information networks, meta-path selection, user guided clustering
The work was supported in part by the U.S. Army Research Lab-oratory under Cooperative Agreement No. W911NF-09-2-0053 (NS-CTA), NSF IIS-1017362, MIAS, a DHS-IDS Center for Mul-timodal Information Access and Synthesis at UIUC, and U.S. Air Force Office of Scientific Research MURI award FA9550-08-1-0265. The views and conclusions contained in this paper are those of the authors and should not be interpreted as representing any funding agencies.
 Figure 1: A toy heterogeneous information network containing organizations, authors and venues.
With the advent of massive social and information networks, link-based clustering of objects in networks becomes increasing-ly important since it may help discover hidden knowledge in large networks. Link-based clustering groups objects based on their links instead of attribute values. This is especially useful when attributes of objects cannot be fully obtained. Most existing link-based clus-tering algorithms are on homogeneous networks where links car-ry the same semantic meaning and only differ in their strengths ( i.e. , weights). However, most real-world networks are heteroge-neous, where objects are of multiple types and are linked via dif-ferent types of relations or sequences of relations, forming a set of meta-paths [21]. These meta-paths imply diverse semantics, and thus clustering on different meta-paths will generate rather differ-ent results, as shown below.
 Example 1.1. (Meta-path-based clustering) A toy heterogeneous information network is shown in Figure 1, which contains three types of objects: organization (O), author (A) and venue (V), and two types of links: solid line represents the affiliation relation be-tween author and organization, whereas the dashed one the publica-tion relation between author and venue. Authors are then connected (indirectly) via different meta-paths. For example, A  X  O  X  A is a meta-path denoting a relation between authors via organizations ( i.e. , colleagues), whereas A  X  V  X  A denotes a relation between authors via venues ( i.e. , publishing in the same venues). A question then raises: which type of connections should we use to cluster the authors?
Obviously, there is no unique answer to this question: Differ-ent meta-paths lead to different author connection graphs, which may lead to different clustering results. In Figure 2(a), authors are connected via organizations and form two clusters: { 1 , 2 , 3 , 4 } and Figure 2: Author connection graphs under different meta-paths. { 5 , 6 , 7 , 8 } ; in Figure 2(b), authors are connected via venues and Figure 2(c), a connection graph combining both meta-paths gener-ate 4 clusters: { 1 , 3 } , { 2 , 4 } , { 5 , 7 } and { 6 , 8 } .
This toy example shows that all the three clusterings look reason-able but they carry diverse semantics. It should be a user X  X  respon-sibility to choose her desired meta-path(s). However, it is often dif-ficult to ask her to explicitly specify one or a weighted combination of meta-paths. Instead, it is easier for her to give some guidance in other forms, such as giving one or a couple of examples for each cluster. For example, it may not be hard to give a few known con-ferences in each cluster ( i.e. , field) if one wants to cluster them into K research areas (for a user-desired K ), or ask a user to name a few restaurants if one wants to cluster them into different categories in a business review website ( e.g. , Yelp).

On the other hand, since we are dealing with heterogeneous networks, the previous work on user-guided clustering or semi-supervised learning approaches on (homogeneous) graphs [11, 30, 31] cannot apply. We need to explore meta-paths that represent heterogeneous connections across objects, leading to rich seman-tic meanings, hence diverse clustering results. With user guidance, a system will be able to learn the most appropriate meta-paths or their weighted combinations. The learned meta-paths will in turn provide an insightful view to help understand the underneath mech-anism for the formation of a specific type of clustering. For exam-ple, which meta-path is more important to determine a restaurant X  X  category? X  X he meta-path connecting them via customers, or the one connecting them via text in reviews, or the kNN relation deter-mined by their locations?
In this paper, we integrate the meta-path selection with the user-guided clustering for better clustering a user-specified type of ob-jects, i.e. , the target objects , in a heterogeneous information net-work, where the user guidance is given as a small set of seeds in each cluster. For example, to cluster authors into 2 clusters in Ex-ample 1.1, a user may seed { 1 } and { 5 } for two clusters, which implies a selection of meta-path A  X  O  X  A ; or seed { 1 } , { 2 } , { 5 } , and { 6 } for four clusters, which implies a combination of both meta-paths A  X  O  X  A and A  X  V  X  A with about equal weight-s. Our goal is to (1) determine the weight of each meta-path for a particular clustering task, which should be consistent with the clus-tering results implied by the limited user guidance, and (2) output the clustering result according to the user guidance and under the learned weights for each meta-path.

We propose a probabilistic model that models the hidden clus-ters for target objects, the user guidance, and the quality weights for different meta-paths in a unified framework. An effective and efficient iterative algorithm PathSelClus is developed to learn the model, where the clustering quality and the meta-paths quality mu-tually enhance each other. The experiments with different tasks on two real networks show our algorithm outperforms the baselines. Our contributions are summarized as follows:
Figure 3: Examples of heterogeneous information networks. 1. We propose to integrate meta-path selection with user-guided 2. A probabilistic model is proposed to put hidden clusters, user 3. Experiments on real heterogeneous information networks have
In this section, we introduce preliminary concepts in heteroge-neous information networks and define the problem of integrating meta-path selection with user-guided object clustering.
A heterogeneous information network [22] is an information net-work with multiple types of objects and/or multiple types of links. Here we introduce two heterogeneous information networks that are used in the experiment section in this paper, which are the D-BLP network and the Yelp network.
 Example 2.1. (The DBLP bibliographic network 1 ) DBLP is a typical heterogeneous information network (see schema in Figure 3(a)), which contains 4 types of objects, namely paper (P), author (A), term (T), and venue (V) including conferences and journals. Links exist between authors and papers by the relation of  X  X rite X  and  X  X ritten by X , between papers and terms by  X  X ention X  and  X  X entioned by X , and between venues and papers by  X  X ublish X  and  X  X ublished by X .  X  X itation X  relation between papers can be added further using other data source, such as Google scholar. Example 2.2. (The Yelp network 2 ) Yelp is a website where users can write reviews for businesses. The Yelp network (see schema in Figure 3(b)) used in this paper contains 4 types of objects, namely business (B), user (U), term (T), and review (R). Links exist be-tween users and reviews by the relation of  X  X rite X  and  X  X ritten by X , between reviews and terms by  X  X ention X  and  X  mentioned by X , be-tween businesses and reviews by  X  X ommented by X  and  X  X omment X , and between users by "friendship" (not included in our dataset).
Following the work [21], we use the concept of meta-path to describe the possible relations that can be derived from a heteroge-neous network between two types of objects in a meta level. Meta-path is defined by a sequence of relations in the network schema, http://www.informatik.uni-trier.de/  X  ley/db/ http://www.yelp.com/ and can be described by a sequence of object types when there is no ambiguity. For example, A  X  P  X  A is a meta-path denoting the co-authorship between authors, and A  X  P  X  V is a meta-path denoting the publication relation between the author and the venue type. Note that, a single relation defined in the network schema can be viewed as a special case of meta-path, e.g. , the citation relation P  X  P .
Link-based clustering is to cluster objects based on their connec-tions to other objects in the network. In a heterogeneous informa-tion network, we need to specify more information for a meaningful clustering.

First, we need to specify the type of objects we want to cluster, which is called the target type . Second, we need to specify which type of connection, i.e. , meta-path, to use for the clustering task, where we call the object type that the target type is connecting to via the meta-path as the feature type . For example, when cluster-ing authors based on the venues they have published papers in, the target type is the author type, the meta-path to use is A  X  P  X  V , and the feature type is the venue type.

In a heterogeneous information network, target objects could link to many types of feature objects by multiple meta-paths. For example, authors could connect to other authors by meta-path A  X  P  X  A , or connect to terms by meta-path A  X  P  X  T . The meta-path selection problem is then to determine which meta-paths or their weighted combination to use for a specific clustering task.
User guidance is critical for clustering objects in the network. In this study, we consider the guidance in the form of object seeds in each cluster given by users. For example, to cluster authors based on their (hidden) research areas, one can first provide several repre-sentative authors in each area. On one hand, these seeds are used as guidance for clustering all the target objects in the network. On the other hand, they provide information for selecting the most relevant meta-paths for the specific clustering task. Note that in practice, a user may not be able to provide seeds for every cluster, but only for some clusters they are most familiar with, which should be handled by the algorithm too.
In all, given a heterogeneous information network G , a user needs to specify the following as inputs for a clustering task: 1. The target type for clustering, type T . 2. The number of clusters, K , and the object seeds for each cluster, 3. A set of M meta-paths starting from type T , denoted as
For each meta-path P m , we calculate the adjacency matrix W which we call relation matrix , between the target type T and the feature type F m , by multiplying adjacency matrices for each rela-tion along the meta-path. For example, the relation matrix W for meta-path A  X  P  X  V , denoting the number of papers published by an author in a venue, is calculated by W = W AP  X  W P V , where W AP and W P V are the adjacency matrices for relation A  X  P and P  X  V respectively.

The output of the algorithm includes two parts: (1) to determine the weight  X  m  X  0 of each meta-path P m for a particular clus-tering task, which should be consistent with the clustering result implied by the limited user guidance, and (2) to output the clus-tering result according to the user guidance and under the learned weights for each meta-path, that is, to associate each target objec-t t i in T with a K -dimensional soft clustering probability vector,  X  i = (  X  i 1 ,..., X  iK ) , where  X  ik is the probability of t to cluster k , i.e. ,  X  ik  X  0 and P K k =1  X  ik = 1 .
In this section, we propose a probabilistic approach to model the problem into a unified framework.

A good clustering result is determined by several factors: first, the clustering result should be consistent with the link structure; second, the clustering result should be consistent with the user guidance; third, the importance of each meta-path is implied by the user-guided clustering, which should be modeled and learned to further enhance the clustering quality. In the following, we first introduce the modeling for the three aspects respectively, and then propose a unified model that takes consideration of all of them.
To model the consistency between a clustering result and a re-lation matrix, we propose a clustering-based generative model for relationship generation.

For a meta-path P m , let its corresponding relation matrix be-tween the target type T and the feature type F m be W m . For each target object t i , we model its relationships as generated from a mixture of multinomial distributions, where the probability of t  X  T connecting to f j,m  X  F m is conditionally independent on t given the hidden cluster label of the relationship is known. Let  X  ij,m = P ( j | i,m ) be the generative probability of the relationship starting from t i and ending at f j,m , where P j  X  ij,m = 1 , then where  X  ik = P ( k | i ) denotes the probability of t i belonging to cluster k and  X  kj,m = P ( j | k,m ) denotes the probability of f j,m appearing in cluster k . In other words, let  X  i,m (  X  i 1 ,m ,..., X  i | F m | ,m ) be the generative probability vector for tar-get object t i , then each  X  i,m can be factorized as a weighted sum-mation of ranking distributions of feature objects in each cluster. The factorization idea is similar to that of PLSA [10], PHITS [7], and RankClus [22], but is built on meta-path-encoded relationships rather than immediate links. This extension will capture more and richer link-based features for clustering target objects in heteroge-neous networks.

By assuming each target object t i is independent with each oth-er and each relationship generated by t i is independent with each other, the probability of observing all the relationships between all the target objects and feature objects is the production of the prob-ability of all the relationships following meta-path P m : where  X  m =  X  B m is the probability matrix with cells as  X   X  is the parameter matrix for  X  ik  X  X , B m is the parameter matrix for  X  kj,m  X  X . and w ij,m is the weight of the relationship between t f j,m . Note that, each meta-path P m corresponds to a different gen-erative probability matrix  X  m to model the relationship generation. The factorization of these probability matrices share the same soft clustering probabilities  X  , but different ranking distributions B in different meta-paths.
Further, we take the user guidance in the form of object seeds for some clusters as the prior knowledge for the clustering result  X  , by modeling the prior as a Dirichlet distribution rather than treating them as hard labeled ones.

For each target object t i , its clustering probability vector  X  assumed to be a multinomial distribution, which is generated from some Dirichlet distribution. If t i is labeled as a seed in cluster k  X  is then modeled as being sampled from a Dirichlet distribution with parameter vector  X  e k  X  + 1 , where e k  X  is a K -dimensional basis vector, with the k  X  th element as 1 and 0 elsewhere. If t not a seed,  X  i is then assumed as being sampled from a uniform distribution, which can also be viewed as a Dirichlet distribution with parameter vector of 1 . The density of  X  i given such priors is: where 1 { t i  X  X  k } is an indicator function, which is 1 if t holds, otherwise 0.

The hyper-parameter  X  is a nonnegative value, which control-s the strength of users X  confidence over the object seeds in each cluster. From Eq. (3), we can find that:  X  when  X  = 0 , the prior for  X  i of a labeled target object becomes  X  when  X   X   X  , the prior for  X  i of a labeled target object con-In general, a larger  X  indicates a higher probability of that  X  around the point mass e k  X  , and thus a higher confidence for the user guidance.
Different meta-paths may lead to different clustering results, therefore it is desirable to learn the quality for each meta-path for the specific clustering task. We propose to learn the quality weight for each meta-path by evaluating the consistency between its rela-tion matrix and the user-guided clustering result.

In deciding the clustering result for target objects, a meta-path may be of low quality for the following reasons: 1. The relation matrix derived by the meta-path does not contain 2. The relation matrix derived by the meta-path itself has a good The general idea of measuring the quality of each meta-path is to see whether the relation matrix W m is consistent with the detected hidden clusters  X  and thus the generative probability matrix  X  which is a function of  X  , i.e. ,  X  m =  X  B m .

In order to quantify the weight for such quality, we model the weight  X  m for meta-path P m as the relative weight for each rela-tionship between target objects and feature objects following P In other words, we treat our observations of the relation matrix as  X  m W m rather than original W m . A larger  X  m indicates a higher quality and a higher confidence of the observed relationships, and thus each relationship should count more.

Then, we assume the multinomial distribution  X  i,m has a prior of Dirichlet distribution with parameter vector  X  i . In this paper, we consider a discrete uniform prior, which is a special case of Dirich-let distribution with parameters as an all-one vector, i.e. ,  X  The value of  X  m is determined by the consistency between the ob-served relation matrix W m and the generative probability matrix  X  m . The goal is to find the  X   X  m that maximizes the posterior prob-ability of  X  i,m for all the target objects t i , given the observation of relationships w i,m with relative weight  X  m : The posterior of  X  i,m =  X  i B m is another Dirichlet distribution with the updated parameter vector as  X  m w i,m + 1 , according to the multinomial-Dirichlet conjugate:  X  which has the following density function: where n i,m = P j w ij,m , the total number of path instances from t following meta-path P m .

By modeling  X  m in such a way, the meaning of  X  m is quite clear:  X   X  m w ij,m + 1 is the parameter of j th dimension for the new  X  The larger  X  m , the more likely it will generate a  X  i,m  X  The smaller  X  m , the more likely it will generate a  X  i
Note that, we do not consider negative  X  m  X  X  in this model, which means relationships with a negative impact in the clustering process are not considered, and the extreme case of  X  m = 0 means the relationships in a meta-path are totally irrelevant for the clustering process.
By putting all the three factors together, we have the joint proba-bility of observing the relation matrices with relative weights  X  and the parameter matrices  X  m  X  X  and  X  : where  X  m is the Dirichlet prior parameter matrix for  X  m all-one matrix in our case. We want to find the maximum a posteri-ori probability (MAP) estimate for  X  m  X  X  and  X  , which maximizes the logarithm of posterior probability of {  X  m } M m =1 , given the ob-servations of relation matrices with relative weights {  X  and  X  , plus a regularization term over  X  i for each target object de-noting the logarithm of prior density of  X  i : By substituting the posterior probability formula in Eq. (6) and the factorization form for all  X  i,m , we get the final objective function:
In this section, we introduce the learning algorithm, PathSelClus , for the model (Eq. (9)) proposed in Section 3. It is a two-step iter-ative algorithm, where the clustering result  X  and the weights for each meta-path  X  mutually enhance each other. In the first step, we fix the weight vector  X  , and learn the best clustering results  X  under this weight. In the second step, we fix the clustering matrix  X  and learn the best weight vector  X  .
When  X  is fixed, the terms only involving  X  can be discarded in the objective function Eq. (9), which is then reduced to: The new objective function can be viewed as a weighted summation of the log-likelihood for each relation matrix under each meta-path, where the weight  X  m indicates the quality of each meta-path, plus a regularization term over  X  representing the user guidance.  X  and the augmented parameter B m  X  X  can be learned using the standard EM algorithm, as follows.
 E-step: In each relation matrix, we use z ij,m to denote the cluster label for each relationship between a target object t i and a feature object f j,m . According to the generative process described in Sec-tion 3.1, P ( z ij,m = k ) =  X  ik , and f j,m is picked with probability  X  kj,m . The conditional probability of the hidden cluster label given M-step: We have the updating formulas for  X  t and B t m as: From Eq. (12), we can see that the clustering membership vector  X  for t i is determined by the cluster labels of all its relationships to feature objects, in all the relation matrices. Besides, if t as a seed object in some cluster k  X  ,  X  i is also determined by the label. The strength of impacts from these factors is determined by the weight of each meta-path  X  m , and the strength of the cluster labels  X  , where  X  m  X  X  are learned automatically by our algorithm, and  X  is given by users. Once given a clustering result  X  and the augmented parameter B m  X  X , we can calculate the generative probability matrix  X  each meta-path P m by:  X  m =  X  B m . By discarding the irrelevant terms, the objective function of Eq. (9) can be reduced to:
It is easy to check that J 2 is a concave function, which means there is a unique  X  that maximizes J 2 . We use gradient descent approach to solve the problem, which is an iterative algorithm with the updating formula as:  X  t m =  X  t  X  1 m +  X  t m  X  X  2  X  X  the partial derivative of  X  m can be derived as: where  X  ( x ) is the digamma function, the first derivative of log  X ( x ) . The step size  X  t m is usually set as a small enough num-ber, to guarantee the increase of J 2 . In this paper, we follow the trick used in non-negative matrix factorization (NMF) [12], and set  X  can get updating formula for  X  m as: which guarantees to be a non-negative value. Also, by looking at the denominator of the formula, we can see that a larger log-likelihood of observing relationships w ij,m under model probabil-ity  X  ij,m , which means a smaller denominator as log-likelihood is negative, generally leads to a larger  X  m . This is also consistent with the human intuition. The PathSelClus algorithm is then summarized in Algorithm 1. Overall, it is an iterative algorithm that optimizes  X  and  X  alter-natively. The optimization of  X  contains an inner loop of EM-algorithm, and the optimization of  X  contains another inner loop of gradient descent algorithm. We discuss some details of the algo-rithm implementation in the following.
 The Weight Setting of Relation Matrices. Given a heteroge-neous information network G , we calculate the relation matrix W for each given meta-path P m by multiplying adjacency matrices a-long the meta-path. It can be shown that, scaling W m by a factor of 1 /c m leads to a scaling of the learned relative weight  X  factor of c m . Therefore, the performance of the clustering result will not be affected by the scaling of the relation matrix, which is a good property of our algorithm.
 Initialization Issues. For the initial value of  X  , we set it as an all-one vector, which assumes all the meta-paths are equally important. For the initial value of  X  in the clustering step given  X  , if t labeled, we assign a random clustering vector to  X  i ; while if t labeled as a seed for a cluster k  X  , we assign  X  i = e  X  Time Complexity Analysis. The PathSelClus algorithm is very efficient, as it is proportional to the number of relationships that are used in the clustering process, which is about linear to the number of target objects for short meta-paths in sparse network-s. Formally, for the inner EM algorithm that optimizes  X  , the time complexity is O ( t 1 ( K P m | E m | + K | T | + K P O ( t 1 ( K P m | E m | )) , where | E m | is the number of non-empty re-lationships in relation matrix W m , | T | and | F m | are the number-s of target objects and feature objects in meta-path P m , which are typically smaller than | E m | , and t 1 is the number of itera-tions. For the inner gradient descent algorithm, the time com-plexity is O ( t 2 ( P m | E m | )) , where t 2 is the number of itera-tions. The total time complexity for the whole algorithm is then outer iterations, which usually is a small number.
In this section, we will compare PathSelClus with several base-lines, and show the effectiveness and efficiency of our algorithm.
In this paper, we use two real information networks for perfor-mance test, the DBLP network and the Yelp network. For each network, we design multiple clustering tasks provided with differ-ent user guidance, which are introduced in the following. 1. The DBLP Network. For the DBLP network introduced in Example 2.1, we design three clustering tasks in the following.  X  DBLP-T1: Cluster conferences in the  X  X our-area dataset X  [23],  X  DBLP-T2: Cluster top-2000 authors (by their number of pub- X  DBLP-T3: Cluster 165 authors who have been ever advised 2. The Yelp Network. For the Yelp network introduced in Ex-ample 2.2, we are provided by Yelp a sub-network 3 , which include 6900 businesses, 152327 reviews, and 65888 users. Hierarchical http://www.yelp.com/academic_dataset categories are provided for each business as well, such as  X  X estau-rants X ,  X  X hopping X  and so on. For Yelp network, we design three clustering tasks in the following.  X  Yelp-T1: We select 4 relatively big categories ( X  X ealth and  X  Yelp-T2: We select 6 relatively big sub-categories under  X  Yelp-T3: We select 6 relatively big sub-categories under
First, we study the effectiveness of our algorithm under different tasks, and compare it with several baselines.
Three baselines are used in this paper. Since none of them has considered the meta-path selection problem, we will use al-l the meta-paths as features and prepare them to fit the input of each of these algorithms. The first one is user-guided information theoretic-based k-means clustering (ITC), which is an adaption of seeded k-means algorithm proposed in [4], by replacing Euclidean distance to KL-divergence as used in information theoretic-based clustering algorithms [8, 2]. ITC is a hard clustering algorithm. For the input, we concatenate all the relation matrices side-by-side into one single relation matrix, and thus we get a very high dimensional feature vector for each target object.

The second baseline is the label propagation (LP) algorithm pro-posed in [31], which utilizes link structure to propagate labels to the rest of the network. For the input, we add all the relation matrices together to get one single relation matrix. As LP is designed for ho-mogeneous networks, we confine our meta-paths to ones that start and end both in the target type. LP is a soft clustering algorithm.
The third baseline is the cluster ensemble algorithm proposed in [18], which can combine soft clustering results into a consen-sus, which we call ensemble_soft. Different from the previous two baselines that directly combine meta-paths at the input level, cluster ensemble combines the clustering results for different meta-paths at the output level. Besides, we also use majority voting as another baseline (ensemble_voting), which first maps each clustering result for each target object into a hard cluster label and then pick the clus-ter label that is the majority over different meta-paths. As we can use either ITC or LP as the clustering algorithm for each ensemble method, we then get four ensemble baselines in total: ITC_soft, ITC_voting, LP_soft, and LP_voting.
Two evaluation methods are used to test the clustering re-sult compared with the ground truth, where the soft clustering is mapped into hard cluster labels.

The first measure is accuracy , which is used when seeds are available for every cluster and is calculated as the percentage of target objects going to the correct cluster. Note that, in order to measure whether the seeds are indeed attracting objects to the right cluster, we do not map the outcome cluster labels to the given class labels. The second measure is normalized mutual information (N-MI) , which does not require the mapping relation between ground truth labels and the cluster labels obtained by the clustering algo-rithm. The normalized mutual information of two partitions X and Y is calculated as: NMI ( X,Y ) = I ( X ; Y )  X  are vectors containing cluster labels for all the target objects. Both measures are in the range of 0 to 1, and a higher value indicates a better clustering result in terms of the ground truth.
We first test the clustering accuracy when cluster seeds are given for every cluster. In this case, all the three baselines can be used and compared. Performances under different numbers of seeds in each cluster are tested. Each result is the average of 10 runs.
The accuracy for all the 6 tasks for two networks are summa-rized in Table 1 and Table 2 respectively. From the results we can see that, PathSelClus performs the best in most of the tasks. Even for the task such as DBLP-T3 where other methods give the best clustering result, PathSelClus still gives clustering results among the top. This means, PathSelClus can give consistently good result-s across different tasks in different networks. Also, by looking at the clustering accuracy trend along with the number of seeds used in each cluster, we can see that, more seeds generally leads to better clustering results.
We then test the clustering accuracy when cluster seeds are only available for some of the clusters. We perform this study on DBLP-T3 using PathSelClus , which includes 4 clusters, and the results are shown in Fig. 4. We can see that even if user guidance is only given to some clusters, those seeds can still be used to improve the clustering accuracy. In general, the fewer number of clusters with seeds, the worse the clustering accuracy, which is consistent with the human intuition. Note that, label propagation-based methods like LP cannot deal with partial cluster labels. However, in reality it is quite common that users are only familiar with some of the clusters and are only able to give good seeds in those clusters. That is another advantage of PathSelClus .
 Figure 4: Clustering accuracy under partial guidance: DBLP-T3 with #seeds = 1.
Now, we study the scalability of our algorithm using synthetic datasets, due to that we can manipulate the size of network flexibly. In Fig. 5(a), we keep the size of target objects and the total number of relationships they issued as fixed, and vary the size of feature objects. We can see that the average running time for one iteration of the inner EM algorithm is about linear to the size of the feature objects; and the average running time for one iteration of the inner gradient descent algorithm is almost constant, as it is only linear to the number of relationships in the network. In Fig. 5(b), we keep the size of feature objects as fixed, and vary the number of target objects. We keep the average relationships for each target object as constant. From the result we can see that the average running time for one iteration of both the inner EM algorithm and the gradient descent algorithm is linear to the size of target objects, since the number of relationships is also increasing linearly with the size of target objects. From the efficiency test, we can see that PathSelClus is very scalable and can be applied to large-scale networks.
In this section, we study the impact of the only parameter in the algorithm,  X  , to the performance of our algorithm. We select DBLP-T1 and Yelp-T2 as the test tasks. From the results in Fig. 6, we can see that the clustering results is in general not sensitive to the value of  X  , as long as it is a positive value. In practice, we set it as 100 for our experiments. Notice that in Fig. 6, we do not show (a) Varying Feature Object Size the accuracy value when  X  = 0 , as when there is no guidance from users, the accuracy cannot be correctly defined.
One of the major contributions of PathSelClus is that it can se-lect the right meta-paths for a user-guided clustering task. We now show the learned weights of meta-paths for some of the tasks. In DBLP-T1 task, the total weight  X  m for meta-path V  X  P  X  A  X  P  X  V is 1576 , and the average weight per relationship (a con-crete path instance following the meta-path) is 0 . 0017 . The total weight for meta-path V  X  P  X  T  X  P  X  V is 17001 , while the av-erage weight per relationship is 0 . 0003 . This means that generally the relationships between two conferences that are connected by an author are more trustable than the ones that are connected by a ter-m, which is consistent with human intuition since many terms can be used in different research areas and authors are typically more focused on confined research topics. However, as there are much more relationships following V  X  P  X  T  X  P  X  V than following V  X  P  X  A  X  P  X  V , the former overall provide more information for clustering.

In the Yelp network, similar to DBLP-T1 task, in terms of the av-erage weight for each relationship, meta-path B  X  R  X  U  X  R  X  B is with higher weight than B  X  R  X  T  X  U  X  B ; while in terms of total weight, meta-path B  X  R  X  T  X  U  X  B is with higher weight. An interesting phenomenon is that, for Yelp-T2 task, which tries to cluster restaurants into different categories, the average weight for relationships following B  X  R  X  U  X  R  X  B is 0.1716, much lower than the value (0.5864) for Yelp-T3 task, which tries to clus-ter shopping businesses into finer categories. This simply says that most users actually will try all different kinds of food, therefore they will not be served as a good connection between restaurants as they are in other categories.
In this section, we briefly discuss some interesting issues. 1. The Strength of Meta-Path Selection. Different meta-paths in heterogeneous networks could be viewed as different sources of information for defining link-based similarity between object-s. There are several ways to handle different meta-paths: (1) to combine them at relation matrix level, such as in baselines ITC and LP; (2) to combine the clustering results at the output level, such as in ensemble baselines; (3) to learn and improve the qual-ity weights for each meta-path iteratively, such as in PathSelClus . Only the third approach is able to select different meta-paths ac-cording to different clustering tasks, while the other two can only output an  X  X verage X  clustering result using all the information. It turns out that, in most cases, the third approach is more flexible to combine information from different sources, and its advantage has been shown in the experiment section. 2. Meta-Paths vs. Path Instances. In this paper, we only consider the different semantics encoded by different meta-paths. In prac-tice, different concrete paths (path instances) between two objects may also differ from each other, e.g., two objects may be linked via a  X  X ridge X  or via a  X  X ub X , indicating different meanings. The difference between the two concepts, i.e. , meta-path and path in-stance, is similar to the difference between a source of features and a concrete feature in a vector space. Due to limited scope, this paper only discusses the selection of meta-paths. It is possible to select path instance at the object level, and the concrete method is left for future research.
Recently, there are many clustering algorithms proposed for net-works, such as spectral clustering-based methods [19, 15], link-based probabilistic models [7, 1], modularity function-based al-gorithms [17, 16], and density-based algorithms [26, 25] on ho-mogenous networks; and ranking-based algorithms [22, 23], non-negative matrix factorization [12, 24], spectral clustering-based methods [13], and probabilistic approaches [14] on heterogeneous networks. However, while all these clustering methods use the in-formation given in the networks, none considers that different users may have different purposes for clustering, nor do they ask user-s to help select different information for link-based clustering. In this paper, we show that different types of relationships encoded by meta-paths have different semantic meanings in determining the similarity between target objects, and the selection of these meta-paths should be done with user guidance in order to derive user-desired clustering results.

There are several lines of research on how to add user guidance to derive good clustering results, consistent with users X  demand in vector space or networked data.

Clustering with constraints. In [4, 5, 11], clustering algorithms that consider constraints either in the form of seeds in each cluster or pairwise constraints as must-link or cannot-link are proposed. A probabilistic model with an HMRF (hidden Markov random field) as a hidden layer that models the must-link and cannot-link be-tween objects is proposed to solve the problem [5]. This approach can also be extended to graph data with the use of kernels instead of vector-based features [11]. However, these methods assume there is one trustable information source to either define the feature of each object or define the network structure between objects. The goal is to output the clustering result that is consistent with both the simi-larity defined by the data as well as the user guidance. In this paper, we dig further and study which type of information source encoded with meta-paths is more trustable in a heterogeneous network.
Semi-supervised learning on graphs. In [30, 31], algorithms that propagate labels for a small portion of objects into the rest of the network are proposed, which are based on harmonic functions de-fined between objects using the network structure. Again, this kind of methods totally trust the given network and determine the best labels of the rest of the nodes according to the cost function defined on the network.

Semi-supervised metric learning. In [6, 3], algorithms that learn the best distance metric functions according to the constrains for the clustering task are proposed. This line of problem is closer to the meta-path selection problem, but still differs significantly. First, they study features of objects in vector space instead of network; second, the metric functions should be given in an explicit format, which is very difficult to determine in a network scenario. In this paper, we are not finding an explicit metric function that determines the similarity between any two target objects, instead, we model and learn the quality weight for each meta-path in the clustering process, which can be viewed as an implicit way to determine the similarity between two target objects.

User-guided clustering in relational data. CrossClus [28] deals with another type of guidance from users: the attribute set of the target object type. The algorithm extracts a set of highly relevan-t attributes in multiple relations connected via linkages defined in the database schema, and then use the whole attribute set as the feature set to apply traditional vector space-based clustering algo-rithm. CrossClus works for relational data with complete attributes, but not for purely link-based clustering.

Cluster ensemble [20, 18] is a method that combines clustering results of different methods or different datasets to a single con-sensus. Most of these cluster ensemble methods try to find a mean partition given different partitions of target objects. However, in reality these clusterings may conflict with each other, represent-ing different purposes of clustering tasks, and a consensus does not necessarily lead to a clustering desired by users. In this study, we do not combine clustering results at the output level, but use inter-mediate clustering results as feedback to adjust the weight of each meta-path, and thus the clustering results and the quality weight for each meta-path can mutually enhance each other.

Our work also differs from traditional feature selection [9] and recently emerged semi-supervised feature selection [29, 27], which focus on vector space features, and do not have an immediate ex-tension of solutions to our problem. For our meta-path selection problem, each meta-path provides a source of features instead of a concrete feature, and we have shown that simple combinations of features from different sources may lead to no good solution.
Link-based clustering for objects in heterogeneous information networks is an important task with many applications. Different from traditional clustering tasks where similarity functions between objects are given and with no ambiguity, objects in heterogeneous networks can be connected via different relationships, encoded by different meta-paths. In this paper, we integrate the meta-path s-election problem with the user-guided clustering problem in het-erogeneous networks. An algorithm PathSelClus that can utilize very limited guidance from users in the form of seeds in some of the clusters and automatically learn the best weights for each meta-path in the clustering process, is proposed. The experiments on d-ifferent tasks on real datasets have demonstrated that our algorithm can output the most stable and accurate clustering results compared with the baselines. Also, the learned weights for each meta-path are very insightful to explain the hidden similarity between target objects under a particular clustering task.
