 We consider the fundamental problem of making inference about an unknown function f that pre-dicts an output Y using a p dimensional vector of inputs x when Y = f ( x ) + ,  X  N (0 ,  X  2 ) . To do this, we consider modelling or at least approximating f ( x ) = E ( Y | x ) , the mean of Y given x , by a sum of m regression trees: f ( x )  X  g binary regression tree.
 The sum-of-trees model is fundamentally an additive model with multivariate components. It is vastly more flexible than a single tree model which does not easily incorporate additive effects. Be-cause multivariate components can easily account for high order interaction effects, a sum-of-trees model is also much more flexible than typical additive models that use low dimensional smoothers as components.
 Our approach is fully model based and Bayesian. We specify a prior, and then obtain a sequence of draws from the posterior using Markov chain Monte Carlo (MCMC). The prior plays two essential roles. First, with m chosen large, it restrains the fit of each individual g made up of many small contributions in the spirit of boosting (Freund &amp; Schapire (1997), Friedman (2001)). Each g is shown to have good out of sample predictive performance.
 Inferential uncertainty is naturally quantified in the usual Bayesian way: variation in the MCMC draws of f = P g action. Our point estimate of f is the average of the draws. Thus, our procedure captures ensemble learning (in which many trees are combined) both in the fundamental sum-of-trees specification and in the model-averaging used to obtain the estimate. The model consists of two parts: a sum-of-trees model, which we have named BART (Bayesian Additive Regression Trees), and a regularization prior. 2.1 A Sum-of-Trees Model To elaborate the form of a sum-of-trees model, we begin by establishing notation for a single tree of terminal nodes, and let M = {  X  as follows: If x is associated with terminal node b of T by the sequence of decision rules from top to bottom, it is then assigned the  X  denote the function corresponding to ( T, M ) which assigns a  X  Using this notation, and letting g be expressed as Unlike the single tree model, when m &gt; 1 the terminal node parameter  X  is merely part of the conditional mean of Y given x . Such terminal node parameters will represent interaction effects when their assignment depends on more than one component of x (i.e., more than one variable). Because (1) may be based on trees of varying sizes, the sum-of-trees model can incorporate both direct effects and interaction effects of varying orders. In the special case where every terminal node assignment depends on just a single component of x , the sum-of-trees model reduces to a simple additive function.
 With a large number of trees, a sum-of-trees model gains increased representation flexibility, which, when coupled with our regularization prior, gives excellent out of sample predictive performance. are hundreds of parameters of which only  X  is identified. This is not a problem for our Bayesian analysis. Indeed, this lack of identification is the reason our MCMC mixes well. Even when m is much larger than needed to capture f (effectively, we have an  X  X vercomplete basis X ) the procedure still works well. 2.2 A Regularization Prior The complexity of the prior specification is vastly simplified by letting the T b assumptions we need only choose priors for a single tree T , a single  X  , and  X  . Motivated by our desire to make each g ( x ; T trees and small  X  For the tree prior, we use the same specification as in Chipman, George &amp; McCulloch (1998). In In all examples we use the same prior corresponding to the choice  X  = . 95 and  X  = 2 . With this choice, trees with 1, 2, 3, 4, and  X  5 terminal nodes receive prior probability of 0.05, 0.55, 0.28, 0.09, and 0.03, respectively. Note that even with this prior, trees with many terminal nodes can be grown if the data demands it. At any non-terminal node, the prior on the associated decision rule puts equal probability on each available variable and then equal probability on each available rule given the variable.
 For the prior on a  X  , we start by simply shifting and rescaling Y so that we believe the prior proba-bility that E ( Y | x )  X  (  X  . 5 , . 5) is very high. We let  X   X  N (0 ,  X  2 is the sum of m independent  X   X  X . The standard deviation of the sum is  X  m  X  that .5 is within k standard deviations of zero: k  X  m X  practice we typically rescale the response y so that its observed values range from -5. to .5. Note that this prior increases the shrinkage of  X  For the prior on  X  we start from the usual inverted-chi-squared prior:  X  2  X   X   X / X  2 hyperparameters  X  and  X  , we begin by obtaining a  X  X ough overestimate X   X   X  of  X  . We then pick a degrees of freedom value  X  between 3 and 10. Finally, we pick a value of q such as 0.75, 0.90 or aggressive, respectively. For automatic use, we recommend the default setting (  X , q ) = (3 , 0 . 90) which tends to avoid extremes. Simple data-driven choices of  X   X  we have used in practice are the estimate from a linear regression or the sample standard deviation of Y . Note that this prior choice can be influential. Strong prior beliefs that  X  is very small could lead to over-fitting. Given the observed data y , our Bayesian setup induces a posterior distribution backfitting MCMC algorithm can be used to sample from this posterior.
 At a general level, our algorithm is a Gibbs sampler. For notational convenience, let T set of all trees in the sum except T successive draws of ( T followed by a draw of  X  from the full conditional: pling for additive and generalized additive models with  X  fixed, and showed how it was a stochastic as backfitting MCMC. In contrast with the stagewise nature of most boosting algorithms (Freund &amp; Schapire (1997), Friedman (2001), Meek, Thiesson &amp; Heckerman (2002)), the backfitting MCMC algorithm repeatedly resamples the parameters of each learner in the ensemble.
 The idea is that given ( T (1) leaving us with a single tree model with known error variance. This draw may be made following the approach of Chipman et al. (1998) or the refinement of Wu, Tjelmeland &amp; West (2007). These methods draw ( T The first draw is done by the Metropolis-Hastings algorithm after integrating out M is a set of normal draws. The draw of  X  is easily accomplished by subtracting all the fit from both sides of (1) so the the are considered to be observed. The draw is then a standard inverted-chi-squared.
 The Metropolis-Hastings draw of T The algorithm of Chipman et al. (1998) proposes a new tree based on the current tree using one of four moves. The moves and their associated proposal probabilities are: growing a terminal node (0.25), pruning a pair of terminal nodes (0.25), changing a non-terminal rule (0.40), and swapping a rule between parent and child (0.10). Although the grow and prune moves change the implicit dimensionality of the proposed tree in terms of the number of terminal nodes, by integrating out M from the posterior, we avoid the complexities associated with reversible jumps between continuous spaces of varying dimensions (Green 1995).
 We initialize the chain with m single node trees, and then iterations are repeated until satisfactory convergence is obtained. At each iteration, each tree may increase or decrease the number of termi-nal nodes by one, or change one or two decision rules. Each  X  will change (or cease to exist or be born), and  X  will change. It is not uncommon for a tree to grow large and then subsequently collapse back down to a single node as the algorithm iterates. The sum-of-trees model, with its abundance of unidentified parameters, allows for  X  X it X  to be freely reallocated from one tree to another. Be-cause each move makes only small incremental changes to the fit, we can imagine the algorithm as analogous to sculpting a complex figure by adding and subtracting small dabs of clay. MCMC algorithm tends to quickly gravitate toward a single large tree and then gets stuck in a local neighborhood of that tree. In sharp contrast, we have found that restarts of the backfitting MCMC algorithm give remarkably similar results even in difficult problems. Consequently, we run one long chain rather than multiple starts.
 In some ways backfitting MCMC is a stochastic alternative to boosting algorithms for fitting linear each iteration, we get a new draw corresponding to the draw of T distribution on the  X  X rue X  f . Rather than pick the  X  X est X  f  X  from these draws, the set of multiple draws can be used to further enhance inference. We estimate f by the posterior mean of f which the actual underlying f by the variation across the draws. For example, we can use the 5% and 95% quantiles of f  X  ( x ) to obtain 90% posterior intervals for f ( x ) . In this section we illustrate the potential of our Bayesian ensemble procedure BART in a large exper-iment using 42 datasets. The data are a subset of 52 sets considered by Kim, Loh, Shih &amp; Chaudhuri (2007). Ten datasets were excluded either because Random Forests was unable to use over 32 cat-correspond to regression problems with between 3 and 28 numeric predictors and 0 to 6 categorical predictors. Categorical predictors were converted into 0/1 indicator variables corresponding to each level. Sample sizes vary from 96 to 6806 observations.
 As competitors we considered linear regression with L1 regularization (the Lasso) (Efron, Hastie, Johnstone &amp; Tibshirani 2004) and four black-box models: Friedman X  X  (2001) gradient boosting, random forests (Breiman 2001), and neural networks with one layer of hidden units. Implementation details are given in Chipman, George &amp; McCulloch (2006). Tree models were not considered, since they tend to sacrifice predictive performance for interpretability.
 We considered two versions of our Bayesian ensemble procedure BART. In BART-cv , the prior specifications of the quantile q were made relative to the least squares linear regression estimate  X   X  , and the number of burn-in steps and MCMC iterations used were determined by inspection of a single long run. Typically 200 burn-in steps and 1000 iterations were used.
 With the exception of BART-default (which has no tuning parameters), all free parameters in learners potential levels are given in Table 1. The levels used were chosen with a sufficientlly wide range that the optimal value was not at an extreme of the candidate values in most problems. Neural case, the number of hidden units was chosen in terms of the implied number of weights, rather than the number of units. This design choice was made because of the widely varying number of predictors across problems, which directly impacts the number of weights. A number of hidden units cases, the number of hidden units was further constrained to fall between 3 and 30. For example, with 20 predictors we used 3, 8 and 21 as candidate values for the number of hidden units. The models were compared with 20 replications of the following experiment. For each replication, we randomly chose 5/6 of the data as a training set and the remaining 1/6 was used for testing. As mentioned above, 5-fold cv was used within each training set. In each of the 42 datasets, the response was minimally preprocessed, applying a log or square root transformation if this made the histogram of observed responses more bell-shaped. In about half the cases, a log transform was used to reduce a right tail. In one case (Fishery) a square root transform was most appropriate. Finally, in order to enable performance comparisons across all datasets, after possible nonlinear transformation, the resultant response was scaled to have sample mean 0 and standard deviation 1 prior to any train/test splitting.
 A total of 42  X  20 = 840 experiments were carried out. Results across these experiments are summarized in Table 2, which gives mean RMSE values and Figure 2, which summarizes relative performance using boxplots. In Figure 2, the relative performances are calculated as follows: In Table 2: Average test set RMSE values for each learner, combined across 20 train/test replicates of 42 datasets. The only statistically significant difference is Lasso versus the other methods. Figure 2: Test set RMSE performance relative to best (ratio of 1 means minimum RMSE test error). Results are across 20 replicates in each of 42 datasets. Boxes indicate middle 50% of runs. Each learner has the following percentage of ratios larger than 2.0, which are not plotted above: Neural net: 5%, BART-cv : 6%, BART-default and Boosting: 7%, Random forests 10% and Lasso 21%. each of the 840 experiments, the learner with smallest RMSE was identified. The relative ratio for each learner is the raw RMSE divided by the smallest RMSE. Thus a relative RMSE of 1 means that the learner had the best performance in a particular experiment. The central box gives the middle 50% of the data, with the median indicated by a vertical line. The  X  X hiskers X  of the plot extend to 1.5 times the box width, or the range of values, whichever comes first. Extremes outside the whiskers are given by individual points. As noted in the caption, relative RMSE ratios larger than 2.0 are not plotted.
 BART has the best performance, although all methods except the Lasso are not significantly differ-ent. The strong performance of our  X  X efault X  ensemble is especially noteworthy, since it requires no computational savings, since under cross-validation, the number of times a learner must be trained is equal to the number of settings times the number of folds. This can easily be 50 (e.g. 5 folds by 10 settings), and in this experiment it was 90! BART-default is in some sense the  X  X lear winner X  in this experiment. Although average predic-tive performance was indistinguishable from the other models, it does not require cross-validation. Moreover, the use of cross-validation makes it impossible to interpret the MCMC output as valid un-inference, a benefit not available to any of the other learners considered.
 To further stress the benefit of uncertainty intervals, we report some more detailed results in the analysis of one of the 42 datasets, the Boston Housing data. We applied BART to all 506 observa-linear regression estimate  X   X  to anchor q . At each of the 506 predictor values x , we used 5% and 95% quantiles of the MCMC draws to obtain 90% posterior intervals for f ( x ) . An appealing feature illustrate this, we calculated Cook X  X  distance diagnostic D least squares regression of y on x . Larger D Figure 3: Plots from a single run of the Bayesian Ensemble model on the full Boston dataset. (a) Comparison of uncertainty bound widths with Cook X  X  distance measure. (b) Partial dependence plot for the effect of crime on the response (log median property value), with 90% uncertainty bounds. linear regression at x . To see how the width of the 90% posterior intervals corresponded to D plotted them together in Figure 3(a). Although the linear model may not be strictly appropriate, the plot is suggestive: all points with large D (Friedman 2001), which shows the effect of one (or more) predictor on the response, margining posterior distribution for the partial dependence function is straightforward. Computational details are provided in Chipman et al. (2006). For the Boston Housing data, Figure 3(b) shows the partial dependence plot for crime , with 90% posterior intervals. The vast majority of data values occur for crime &lt; 5 , causing the intervals to widen as crime increases and the data become more sparse. Our approach is a fully Bayesian approach to learning with ensembles of tree models. Because of the nature of the underlying tree model, we are able to specify simple, effective priors and fully exploit the benefits of Bayesian methodology. Our prior provides the regularization needed to obtain good predictive performance. In particular, our default prior, which is minimially dependent on the data, performs well compared to other methods which rely on cross-validation to pick model parameters. We obtain inference in the natural Bayesian way from the variation in the posterior draws. While predictive performance in always our first goal, many researchers want to interpret the results. In this case, gauging the inferential uncertainty is essential. No other competitive methods do this in a convenient way.
 Chipman et al. (2006) and Abreveya &amp; McCulloch (2006) provide further evidence of the predictive performance of our approach. In addition Abreveya &amp; McCulloch (2006) illustrate the ability of our method to uncover interesting interaction effects in a real example. Chipman et al. (2006) and have good frequentist coverage. Chipman et al. (2006) also illustrates the method X  X  ability to obtain inference in the very difficult  X  X ig p, small n X  problem, where there are few observations and many potential predictors.
 A common concern with Bayesian approaches is sensitivity to prior parameters. Chipman et al. to capture f , but making m  X  X oo large X  does not appreciably degrade accuracy (although it does make it slower to run). Chipman et al. (2006) provide guidelines for choosing m .
 In practice, the stability of the MCMC makes the method easy to use. Typcially, it burns-in rapidly. Code is publicly available in the R-package BayesTree.
 Acknowledgments The authors would like to thank three anonymous referees, whose comments improved an earlier draft, and Wei-Yin Loh who generously provided the datasets used in the experiment. This research was supported by the Natural Sciences and Engineering Research Council of Canada, the Canada Research Chairs program, the Acadia Centre for Mathematical Modelling and Computation, the University of Chicago Graduate School of Business, NSF grant DMS 0605102 and by NIH/NIAID award AI056983.
 Breiman, L. (2001),  X  X andom forests X , Machine Learning 45 , 5 X 32.
 Chipman, H. A., George, E. I. &amp; McCulloch, R. E. (1998),  X  X ayesian CART model search (C/R: Chipman, H. A., George, E. I. &amp; McCulloch, R. E. (2006), BART: Bayesian additive regression Friedman, J. H. (2001),  X  X reedy function approximation: A gradient boosting machine X , The Annals Green, P. J. (1995),  X  X eversible jump MCMC computation and Bayesian model determination X , Hastie, T. &amp; Tibshirani, R. (2000),  X  X ayesian backfitting (with comments and a rejoinder by the Hill, J. L. &amp; McCulloch, R. E. (2006), Bayesian nonparametric modeling for causal inference, Tech-Meek, C., Thiesson, B. &amp; Heckerman, D. (2002), Staged mixture modelling and boosting, Technical
