 Microblogging has become one of the most popular social networking platforms in recent years. When users search a query in a microblogging service such as Twitter, an archive of tweets would be returned as part of a retrospective piece on the impact of social media on a specific topic. For instance, a journalist may invest a sports scandal that has been brewing for the past several weeks. She just got news of a breaking development, and turns to searching tweets to find more details. However, due to the retweeting and sharing nature of Twitter, the traditional search engine would lead to a lot of duplicates or near-duplicates tweets that contain the same or highly-similar information -a user cannot easily get an overall idea of the retrieved these tweets. Thus, it would be helpful if the search system produced a  X  X ummary X  timeline about the topic, which is the studied task in this paper.
 named Tweet Timeline Generation (TTG) task [ 11 ]. The TTG task can be sum-marized as  X  At time T, I have an information need expressed by query Q, and I would like a summary that captures relevant information  X . Developing effective TTG system is inherently challenging. Aside from the challenges derived from the tweet retrieval with issues from topic detection and tracking (TDT) and tra-ditional multi-document summarization, systems should further address three additional challenges. First of all, as the length of microblog entry is limited to 140 characters and the content of tweet can be very noisy, it is hard to detect redundant tweets (or cluster similar tweets) using traditional bag-of-words rep-resentation of tweets. Generally, users are more interested with tweets which are highly relevant with the query, and a good summarized timeline should be concise and contain as few redundant tweets as possible. Secondly, topics evolve quickly in social media, people usually talk about a subtopic of a given topic in a specific time period. Hence, to measure the similarity of tweets, systems should also take the temporal information into consideration. Thirdly, different topics can attract different amount of attention, which leads to different amount of relevant tweets. As in the search scenario of TTG, users are assumed ready to consume the entire summarized tweet list (unlike a ranked list). Therefore, it is quite necessary for the system to keep the coverage of raw related tweet collection in the summarized timeline.
 in TTG and propose a graph-based dynamic greedy clustering approach to char-acterize the coverage , relevance and novelty properties of the tweet timeline. The major contributions of this work are: (1) We propose to learn tweet embedding representation to characterize the similarity between tweets which considers both the semantic relatedness and time proximity. We further utilize the similarity to construct tweet semantic graph. (2) We propose a dynamic greedy cluster-ing approach based on tweet semantic graph, where we estimate the coverage according to the vertex connectivity in the graph and we integrate a noise tweet elimination component based on logistic regression classifier to measure the rel-evance and novelty using many effective lexical and semantic features. (3) We construct extensive experiments on public Text Retrieval Conference (TREC) Twitter corpora, which demonstrate the effectiveness of the proposed approach. related work on subtopic retrieval, TDT, and timeline generation. The graph-based dynamic greedy clustering approach is presented in Sect. 3 . The exper-imental results as well as the comparisons with the-state-of-arts are shown in Sect. 4 . Finally, we conclude the paper and outline our future work in Sect. 5 . Subtopic Retrieval. Zhai et al. [ 19 ]presented subtopic retrieval problem ,which is concerned with finding documents that cover many different subtopics of a given topic. Subtopic retrieval is quite different from traditional retrieval prob-lem, where the search engines just simply return the search results in general. However, the retrieved documents always contain much redundant or noisy infor-mation in reality. Agrawal et al. [ 2 ] proposed a systematic approach to diversify the searched results, which tries to maximize the likelihood of selecting a rel-evant document in the top-k positions based on the categorical information of the queries and documents. Marco and Navigli [ 5 ] employed a method relying on n-grams to cluster and diversify web search results. They constructed a co-occurrence graph based on Dice coefficient calculated over the corpus in which the senses are discovered by word sense induction algorithm. In this way, the method can better capture the similarity between the web snippets. To build a more realistic and efficient solution, which allows to label for subtopics or aspects of a given query, Wang and Zhai [ 17 ] adopted the star clustering algorithm pro-posedin[ 4 ].
 Unlike subtopic retrieval problem, research in the area of TTG aims to obtain a sequence of documents that could describe how a topic evolves over time. In other word, the temporal information must be incorporated into the TTG system. Topic Detection and Tracking. TDT task mainly conveys the recognition and evolution of the topics contained in text streams. Many previous works [ 7 , 9 ] detect topic through discovering topic bursts from a document stream. Among them, detecting the frequency peaks of topic-related phrases over time in a histogram is a common solution. Another main technique attempted to monitor the formation of a cluster from a structure perspective. Lappas et al. [ 7 ] presented a approach to model the burstiness of a term, using discrepancy theory concepts. They could identify the time intervals of maximum burstiness for a given term, which is an effective mechanism to address topic detection in the context of text stream. Lin et al. [ 9 ] proposed burst period detection based on the phenomenon that at some time point, the topic-related terms should appear more frequently than usual and should be continuously frequent around the time point. Agarwal et al. [ 1 ] discovered events as dense clusters in highly dynamic graphs. Following the same idea, Lee et al. [ 8 ] applied a clustering algorithm named DBSCAN to recognize the evolution pattern of a topic.
 Though these methods have been successfully adopted in TDT task, they are not applicable to the TTG problem. The timeline generation problem represents a natural extension of traditional retrieval [ 11 ], which means the generation process is based on the documents returned by the search engines. Therefore, major techniques used in TDT such as burst period detection and dense-based clustering cannot be well applied in generating timeline since many subtopics or aspects in the timeline just contain exactly one document.
 Timeline Generation. There are also several works studying the timeline generation recently. A greedy algorithm based on approximation of Minimum-Weight Dominating Set Problem (MWDS) is exploited in [ 9 , 16 , 21 ]. Among these works, Wang et al. [ 16 ] proposed an approach that combines image and text analysis to generate a timeline containing textual, pictorial and structural infor-mation. They first constructed a multi-view graph, in which each node contains textual and pictorial information, and then selected the representative nodes by finding a minimum dominant set on the graph. Based on the same idea, Lin et al. [ 9 ] adopted the method to tweet timeline generation. Xu et al. [ 18 ]proposeda novel detection approach, framing the problem of redundant tweet removal as a sequential binary decision task. Lv et al. [ 12 ] applied hierarchical clustering algorithm based on Euclidean distance and adaptive relevance estimation to gen-erate tweet timeline, which achieved the best performance of TTG task in TREC 2014 Microblog Track.
 didn X  X  well handle the unique characteristics of microblog, especially the cover-age , relevance and novelty of the timeline. In this paper, we propose a graph-based dynamic greedy clustering approach, we first construct tweet semantic graph using tweet embedding representation, which considers both the seman-tic relatedness and time proximity in a more comprehensive way. Based on the graph, we estimate the coverage of timeline according to the vertex connectivity in the graph, and measure the relevance and novelty through noise tweet elimi-nation component which utilizes many effective lexical and semantic features. In this section, we first introduce the problem formulation, and then present our approach. The proposed approach first constructs tweet semantic graph based on tweet embedding representation, and then apply graph-based dynamic greedy clustering algorithm to generate the summarized tweet timeline, where we inte-grate a detection component to eliminate noisy tweets. 3.1 Problem Formulation We give a formal definition of TTG as follows: query term, we obtain a tweet collection C = { T 1 ,T 2 , query by traditional retrieval model, where T i is a tweet and N is the number of retrieved tweets.
 redundant, chronologically ordered tweets, i.e. R ( Q ) = where T ( Q ) i is a relevant tweet from C for query Q ,and K is the number of tweets in the timeline. 3.2 Tweet Semantic Graph Construction Definition 1. (TWEET SEMANTIC GRAPH): A tweet semantic graph G = ( V, E ) ,where V is a set of tweet vertices and E is a set of undirected edges, which represents the semantic relatedness between tweets. It is infeasible and meaningless to consider all the tweets for query-specific timeline generation. We apply state-of-the-art retrieval model to derive the top 300 ranked tweets as candidate. Given a candidate tweet collection with their timestamps, we construct a tweet semantic graph by viewing the tweets as the vertices V and calculating the weights of undirected edges on the basis of both content similarity and time proximity. Let T i and T j be two vertices in V .We make a undirected edge between T i and T j if and only if the similarity between them is greater than a similarity threshold  X  .
 Tweet Embedding Representation. Due to the length limit and informal expression of tweets, traditional retrieval models relying on  X  X ag-of-words X  repre-sentations are faced with challenges in describing the similarity of short tweets. For example, when talking about  X  X appy birthday X  in twitter, users may use many informal words, such as  X  X day X  and  X  X irthdayyy X . Besides, users may use different words to express same meaning, such as  X  X ord shortage X  and  X  X rought X , while these words are semantically related from the context of the twitter stream. Inspired by distributed representation methods [ 13 ], we propose to learn tweet embedding representation which can project tweets into low-dimensional semantic space. Give a tweet T = { w 1 ,w 2 ,  X  X  X  ,w | T | to maximize the log-likelihood, defined as where w i  X  c : w i + c is the subsequence ( w i  X  c ,...,w 2  X  c is the window size. We model each word w i an M -dimensional embedding vector v w i . With this form of embedding representation, we further employ a multiclass classifier softmax to formulate the probability Pr ( w follows where W is the word vocabulary, v w i is the output vector representation of target word w i and  X  v is the averaged vector representation of the context. We simply average all the word vectors to obtain the tweet vector. Based on the tweet vector, we can utilize classic similarity measure (i.e. cosine similarity) to estimate the similarity of tweets. Considering that tweets posted in a same time interval (e.g. the latest two hours) are more likely to talk about the same aspect of the topic, thus we combine the tweet vector with fading time factor to characterize both the semantic relatedness and time proximity in a more comprehensive way, which is defined as follows where v i and v j are the tweet embedding representations of T tively.  X  is the exponential parameter that controls the temporal influence.  X  and  X  j are the corresponding timestamps, measured in fractions of hours. 3.3 Graph-Based Dynamic Greedy Clustering Approach As discussed in Sect. 1 , In order to obtain the summarized tweet timeline from retrieved tweets, the system must dynamically detect and eliminate the redun-dant or noisy tweets for distinct topics. We propose a dynamic greedy clustering approach based on tweet semantic graph, which considers both the semantic relatedness and time proximity between tweets. Considering that the returned tweets from the retrieval model can still contain much noise, we further incorpo-rate a noise elimination component based on both lexical and semantic similarity during the clustering process.
 Graph-Based Dynamic Greedy Clustering Algorithm. The proposed algorithm iteratively identify representative vertices given a query, where rel-evance , coverage and novelty have been considered. We present the overall pro-cedure in Algorithm 1 .
 semantic graph G =( V, E ). At the beginning of each iteration, we first (Line 3 7) compute the coverage score for each remaining (unmarked) vertex by using a score function ComputeCoverageScore ( v i ) that calculates the connectivity Algorithm 1. Graph-based Dynamic Greedy Clustering.
 based on unmarked vertices connected with v i in the graph. Besides coverage , users would be more interested in tweets which are highly relevant with the query, and a good summarized timeline should be concise and contain as few redundant tweets as possible. In order to capture the relevance and novelty for timeline generation, we check the top ranked tweet (Line 10 boolean function IsN oiseT weet (  X  ) based on a rich set of relevance and novelty features, which will be discussed next. We perform the update procedure for marking as follows. If a tweet is measured as noise by IsN oiseT weet ( corresponding vertex is marked as noise vertex . Otherwise, the corresponding vertex is marked as the centroid vertex which will be incorporated into the timeline R ( Q ) . The rest neighboring vertices of the centroid vertex are marked as visited and no more considered for selection.
 Noise Tweet Elimination. In Algorithm 1 , a key component is the noise elim-ination function IsN oiseT weet (  X  ), which aims to filter noise tweets and improve the timeline quality. To implement IsN oiseT weet (  X  ), we utilize a logistic regres-sion classifier based on a rich set of lexical and semantic features to eliminate noise tweet, which have been used to achieve the state-of-art in adaptive filter-ing problem of news and tweets [ 3 , 20 ]. These two types of features are given as follows.  X  Relevance Features measure the relevance between tweet T and query Q .
We have four relevance features in total. Based on traditional  X  X ag-of-words X  model, three lexical similarity score features are calculated by cosine similarity,
Dice coefficient, and Jaccard coefficient, respectively. In addition, one semantic similarity score feature is obtained by cosine similarity measure using tweet embedding representation.  X  Novelty Features estimate the novelty of an unprocessed tweet compared with previous generated centroid tweets of clusters. We calculate the similarity between the unprocessed tweet and each centroid tweet of each generated cluster, and choose the closest centroid tweet as comparison to estimate the novelty of the unprocessed tweet. Like Relevance Features , we obtain three lexical and one semantic score features based on  X  X ag-of-words X  model and tweet embedding representation, respectively.
 To train the logistic regression classifier, we use the judgments on TREC2011-2012 topics as labeled data, which are released and labeled by the official TREC organizer.
 In summary, coverage is measured by using the function ComputeCoverage Score (  X  ) that calculates the connectivity based on unmarked vertices in the graph, , while relevance and novelty have been considered in function IsNoise T weet (  X  ) by leveraging the relevance and novelty features. Our clustering algo-rithm can be efficiently implemented based on the well-known Breadth-First-Search (BFS) graph traverse algorithm.
 In this section, we conduct extensive experiments to evaluate the effectiveness of the proposed method. In what follows, we first describe the experimental setting and then present the results. 4.1 Experimental Setting Dataset. Two large data collections (i.e. Tweets2011 and Tweets2013 collec-tions) are used in our experiments. TREC organizers release a streaming API to participants [ 10 ]. Using the official API 1 , we crawled a set of local copies of the canonical corpora. Tweets11 collection has a sample of about 16 million tweets, ranging from January 24, 2011 to February 8, 2011 while Tweets13 collection contains about 259 million tweets, ranging from February 1, 2013 to March 31, 2013 (inclusive). Tweets11 is used for evaluating the effectiveness of the pro-posed Twitter TTG systems over 10 training topics in TREC 2011 and 2012. And, Tweets13 is used in evaluating the proposed TTG systems over 55 official topics in the TREC 2014 Microblog track [ 11 ]. The topics of TREC 2011-2012 are used for tuning the parameters and then we use the best parameter setting to evaluate our methods with topics for TREC 2014. Table 1 summarizes basic statistics of the two corpora.
 Evaluation Metrics. Our evaluation metrics contain the following two types of metrics.
 Tweet Retrieval: As our TTG system X  X  input is a candidate tweet collection generated by retrieval models, the performance of our system might be affected by the retrieval performance. In TREC Microblog track, tweets are judged on the basis of the defined information using a three-point scale [ 14 ]: irrelevant (labeled as 0), minimally-relevant (labeled as 1), and highly-relevant (labeled as 2). We use two official main metrics for the retrieval task in TREC, including Mean Average Precision (MAP) and Precision at N (P@N). Specifically, MAP for top 1000 ranked documents and P@30 with respect to allrel (i.e. tweet set labeled as 1 or 2). Clustering Performance as Timeline Quality: TTG results will be evaluated by two different versions of the F 1 metric, i.e., an unweighted version and a weighted version, which are used in TREC 2014 Microblog Track [ 11 ]. F bined by cluster precision and cluster recall. We first introduce the unweighted version as follows.  X  Cluster precision (unweighted). Of tweets returned by the system, how many distinct semantic clusters are represented.  X  Cluster recall (unweighted). Of the semantic clusters discovered by the assessor, how many are represented in the system X  X  output.
 For unweighted version, the system does not get  X  X redit X  for retrieving mul-tiple tweets from the same semantic cluster. Different from unweighted F weighted F 1 (denoted as F w 1 ) attempts to account for the fact that some semantic clusters are intuitively more important than others. Each cluster will be weighted by relevance grade: minimally-relevant tweets get a weight of one and highly-relevant tweets get a weight of two. These weights are then factored into the precision and recall computations. The F w 1 score is the main evaluation metric for TTG task in TREC 2014. 4.2 Methods to Compare We consider the following methods as comparisons in our experiments.  X  TTGPKUICST2 : Hierarchical clustering algorithm based on adaptive rel-evance estimation and Euclidean distance, proposed in [ 12 ], which achieved the best performance in TREC 2014 Microblog Track.  X  EM50 : kNN clustering approach applied in [ 15 ], using a modified Jaccard coefficient (i.e. EM) and used top K retrieved results as candidates for clus-tering, which won the second place in TREC 2014 Microblog Track.  X  hltcoeTTG1 : The novel detection approach proposed by Xu et al. [ 18 ].
Unlike clustering methods, they framed the problem of tweet timeline gener-ation as a sequential binary decision task. Therefore, they proposed a binary classifier to determine whether a coming tweet is novel and then compose the novel tweets as the summarized tweet timeline, which won the third place in
TREC 2014 Microblog Track.  X  MWDSA : we implement the Greedy MWDS Approximation Algorithm (denoted as MWDSA ) that was exploited in generating storyline problem [ 9 , 16 , 21 ]. They identified the minimum-weight dominating set approximation as the most representative summary.  X  GDGC-BOW : The proposed graph-based dynamic greedy clustering app-roach, which only utilizes  X  X ag-of-words X  model in both tweet graph construc-tion and noise tweet elimination.  X  GDGC : The proposed graph-based dynamic greedy clustering approach in Sect. 3.3 .
 obtain the top-ranked 300 tweets from the ranked list achieved by the retrieval models as the candidates for TTG process. We set the time factor  X  as 0 . 01, usually around 0 . 005  X  0 . 02. In tweet graph construction based on  X  X ag-of-words X  representation, we set the similarity threshold  X  as 0 . 65, usually around 0 . 6  X  0 . 7. 4.3 Results and Analysis Recall that our TTG system X  X  input is a candidate tweet collection generated by a retrieval model. In our study, we utilize two retrieval models for the candi-date generation, namely RTRM and RankSVM . RTRM utilizes a two-stage pseudo-relevance feedback query expansion to estimate the query language model and expand documents with shortened URLs in microblog. In addition, RTRM can evaluate the temporal aspects of documents with the temporal-reranking components. RankSVM is a state-of-the-art pairwise learning to rank method, proposed in [ 6 ]. We follow the work of [ 12 ] and generate totally 250 features. candidate tweet retrieval performance. We can have the following obervations. outperform significantly in terms of F 1 and F w 1 for both RTRM and RankSVM retrieval candidate tweet collections. Since MWDSA considers the coverage by choosing the dominating vertexs in the graph, while it does not capture the rel-evance and novelty of tweet timeline. Besides, from the comparisons between two retrieval candidates, (e.g. MWDSA RT RM and MWDSA RankSV M can also observe that TTG performance will benefit from better retrieval per-formance, which is very reasonable since TTG utilizes retrieval tweets as input candidates. importance of tweet embedding representation in constructing tweet semantic graph and estimating the relevance and novelty in noise tweet elimination com-ponent. 2014 Microblog Track, which demonstrates the effectiveness of the proposed approach in depicting the characteristics of tweet timeline. Besides, com-pared with hltcoeTTG1 , the proposed approach using weaker retrieval results (i.e. GDGC RT RM ) can also perform better in TTG. Specially, our method GDGC RT RM improves the F w 1 score over EM50 and hltcoeTTG1 by 16.7 % and 20.3 %, respectively; while the corresponding increments in terms of F 36.2 % and 25.7 %. On the other hand, when utilizing a more effective retrieval model (i.e. RankSVM ), the graph-based dynamic greedy clustering approach will achieve more improvements in terms of F w 1 and F 1 . In addition, compared with TTGPKUICST2 , GDGC RankSV M achieves 3.91 % and 3.05 % further increases in terms of F w 1 and F 1 , respectively. 4.4 Parameter Tuning Several parameters in the proposed method may affect the system performance. In this section, we analyze the parameter setting in the graph-based dynamic greedy clustering approach. All these experiments are run on TREC 2011-2012 topics. Figure 1 (a) shows the effect of tweet embedding vector in terms of metrics F and F 1 . We can see that the two curves follow similar patterns, F-score increases rapidly with the increase of the embedding vector size when it is less than 300. When the vector size becomes larger, the performance changes slightly, which means that the vectors can already provide enough information to depict the tweets semantically from the contexts.
 We study the effect of similarity threshold parameter  X  in tweet semantic graph construction using tweet embedding representations, which is shown in Fig. 1 (b). we can observe that the value of  X  yields a significant effect on the evaluation metrics of TTG (i.e. F w 1 and F 1 ). tation is greater than that using  X  X ag-of-words X  model described in Sect. 4.2 , which demonstrates the characteristics of tweet embedding representations. That is, words used in similar contexts are considered semantically similar and tend to have similar vectors, which could lead to a general high similarity score for tweets. When it comes to the  X  X ag-of-words X  representation, different words are simply regarded as irrelevant. In this study, we propose a graph-based dynamic greedy clustering approach. We utilize learned tweet embedding representation to construct tweet semantic graph, which considers both the semantic relatedness and time proximity in a more comprehensive way. Based on the graph, we estimate the coverage by highly scoring vertices with larger graph connectivity. For top ranked candidate tweet at each iteration, we measure the relevance and novelty through a logistic regression classifier which adopts many effective lexical and semantic features. Extensive experiments using public TREC Twitter collection, demonstrate the effectiveness of the proposed method.
 as input candidates. In fact, the number of strong candidate tweets for distinct topics can be different due to the diverse popularity in Twitter. In the future, we will consider how to dynamically obtain candidate tweets from retrieval results.
