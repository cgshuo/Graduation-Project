 Numerous real-life applications, such as wireless sensor networks and location-based services, generate large amount of uncertain tim e series, where the exact value at each timestamp is unavailable or unknown. In this paper, we formalize the notion of correlation for uncertain time series data and consider a family of probabilistic, threshold-based correlation queries over such data. Th e proposed formulation extends the notion of correlation developed for standard, certain time series. We show that uncertain correlation is a random variable approaching normal distribution. We also formalize the notion of uncertain time series normalization which is at the core of our correlation query processing approach, while it proves to be an important pre-processing technique in particular for pattern discovery tasks . The results of our numerous experiments indicate that, unlike in the standard time series, there is a trade-off between false alarms and hit ratios, which can be controlled by the probability threshold provided by users. Our results also offer users a guideline for choosing proper threshold values. G.3 [ Probability and Statistics ]: Correlation and regression analysis, distribution functions, time series analysis. Algorithms, Performance, Experimentation , Theory. Uncertain time series, correlation, probabilistic queries. A time series is a sequence of real numbers usually recorded at regular time intervals. In uncertain time series, however, we have at each timestamp, some  X  X tatistical information X  about its uncertainty level. This information could be represented as a random variable within a given interval or as a multiset of values. While interesting analysis techniques have been developed for standard certain time series [17] , the research attention on uncertain time series data has been more recent. Such data is generated in many application domains, including wireless sensor networks [6], location-based services [7], and medical data analysis [12]. Uncertainty in time series could be due to several reasons such as limitations and error associated with collecting data techniques and equipment [6], privacy concerns [7 , 12], using forecasting techniques and multiple readings. As a matter of fact, uncertain time series data has become ubiquitous, but has been the topic of some recent papers investigating similarity search queries over such data. In this paper, we propose a probabilistic approach to process correlation queries over uncertain time series, in which each timestamp is represented as a random variable. Finding highly correlated time series in standard, certain time series has been well studied, for which effective techniques have been developed and applied in many application domains [3, 5]. Fo r the uncertain case, however, search for correlation between uncertain time series has not been studied yet. The measures for correlation in the standard case are inadequate for finding the correlation between uncertain time series, since the notion of correlation is not captured properly. In addition, queries that search for correlated uncertain time series are probabilistic, i.e., we do not know the exact result, instead, a probability is assigned to the result. Another complication in our context is lack of a unique model for representing uncertain time series. Examples of approaches for modeling uncertain time series include using, at each timestamp, a bag of values, an interval, a random variable, or a pair of values for the mean and standard deviation of the values at each timestamp. In this paper, we define the notion of correlation between two uncertain time series, and introduce a family of types of correlation queries . Given an uncertain time series, the goal is to search for uncertain time series with a high enough probability that their correlation with the given uncertain time series is within a given threshold. Our proposed formulation of uncertain correlation is a random variable modeled using normal distribution. Using this, we develop a method for candidate selection which only requires the mean and variance at each timestamp. We also show that our formulation of correlation for uncertain time series reduces to the standard case. Since normalization is at the core of our correlation query processing approach, we also formalize, for the first time, the notion of uncertain time series normalization . Normalization is an important pre-processing step in standard time series, especially in data mining tasks. Additionally, since current probabilistic similarity queries are all threshold-based [12, 19] , users are left with no hint as to how they may identify proper threshold values required for such queries. The situation is improved when the data is normalized. In our experiments, w e comp are our probabilistic approach with a deterministic one where uncertain time series are treated as standard . The results of our experiments indicate that , unlike in the deterministic one, our solution approach provides a flexible tradeoff between recall and false alarm s. This flexibility feature is valuable noting that we are dealing with uncertain data. The rest of this paper is organized as follows . Section 2 provides a background and reviews related work. In Section 3, we define the problem and propose our solutions for different types of uncertain correlation queries. Section 4 defines the notion of normalization for uncertain time series. The experiments and results are presented in Section 5 . Finally, Section 6 includes concluding remarks and possible future work. Uncertain time series can be defined as a sequence of  X  X tatistical information X , where each element in the sequence represents the uncertainty level of some real number the true value of which is unknown . In terms of representation, existing work can be classified into Multiset -B ased ( MB ) and Interval -B ased ( IB ) models, as follows. 1) IB Model : Each element is a continuous random variable, the possible value of which is within a given interval [12, 16, 19]. To be more precise, each element can be written as where is the true data value and is the error which is a continuous random v ariable. 2) MB Model : Each element is a multiset of values for the attribute measured or observed; the actual value may or may not be among them, i.e., [1] . Note that the random variables or the observed values at different timestamps in a time series may or may not be independent [1]. To the best of our knowledge, the dependent case has not been reported. A X falg et al. [1], for the first time, formalized -nor m and DTW distance for MB uncertain time series and defined two probabilistic similarity queries, probabilistic bounded and ranked range query. To speed up query processing, they also proposed an approximation technique . In [22 ], it was proposed to use the average of the observations as an approximation. Lian et al . [12 ] propose d probabilistic bounded range query for IB uncertain time series, which they called as cloaked range query. Yeh et al. [19 ] studied the same problem and proposed PROUD , a probabilistic approach to similarity queries for streaming data. In PROUD , they consider a single variance for different timestamps of the same time series. Sarangi et al. [16] proposed DUST as a similarity measure for IB uncertain time series data. They remark that a single time series has different error distributions in different timestamps , unlike assumed in PROUD . To use DUST , one needs to know not only the distributions of errors at each timestamp, but also the distr ibution of the actual time series data. [8] compares existing similarity search techniques for uncertain tim e series . Nearest neighbor query has also been investigated in [14].
 Some similarity search methods have been proposed over uncertain vector objects [2, 4 , 6, 11]. As discussed in [1], these methods are not suitable for uncertain time . There are also some related works on uncertain trajectories, which may be considered as multidimensional uncertain time series [7, 9 , 20], but they are not applicable in our context of uncertain time series, since the elements in different timestamp s they considered are correlated, and the moving objects are independent . Another important topic related in our context is dimensionality reduction techniques [14, 18, 21 ]. For lack of space we do not discuss details, however, we need to mention that so far, processing of limited types of queries for uncertain time series data ha ve been investigated. Finding highly correlated time series is gaining attention in different application domains and for uncertain time series. We next formalize the notion of probabilistic correlation queries over uncertain time series. In this paper, our focus is on IB uncertain time series where at each timestamp, there is a continuous random variable. I n addition, random variables at different timestamps are assumed to be independent of each other. We propose a novel approach to process correlation queries over uncertain time series. In our approach, the only required information is the mean and variance at each timestamp . In the next section, we will present our approach for correlation. We begin this section by defining the notion of correlation for uncertain time series. Let and be uncertain time series, where and are independent random variables. We extend the Pearson sample correlation coefficient to define correlation between two uncertain time series as follows: where  X   X   X   X   X   X   X  We consider Pearson correlation between two uncertain time series data as a sum of a sequence of independent random variables. According to the central limit theorem [ 15], as n increases, approaches the normal distribution: That is, regardless of the distribution of the original random variables X and Y , we can model correlation between two time series using normal distribution. Although our correlation definition for uncertain time series is similar to that for the standard case, uncertain correlation is a random variable whereas standard correlation is a real value in . Since finding the exact correlation between two uncertain time series is infeasible, we will consider some threshold value . A Threshold-based Correlation Query ( TCQ ) consists of an uncertain time series query Q and a correlation threshold c . Depending on the application, correlation queries could be of following forms: In TCQ-1 , the user is interested in those uncertain time series which are positively correlated with Q , and their correlation is no less than the given threshold c . In TCQ-2 , the user is looking for uncertain time series which are negatively correlated with Q . In the last form , the user is interested in uncertain time series that are highly correlated with Q (positively or negatively). The user may also need to find uncertain time series which are not highly correlated with Q , e.g. , in medical domain looking for some abnormalities in a test result. This yields the following additional forms of threshold -based correlation queries : Having a random variable as correlation between two uncertain time series motivated our definition of probabilistic threshold-based correlation queries. Instead of using their exact correlation, we use the cumulative distribution information of their correlation. A Probabilistic Threshold-based Correlation Query ( PTCQ ) consists of an uncertain time series query Q , a correlation threshold c , and a probability threshold p . Such queries search for uncertain time series that satisfy one of the above six threshold-based correlation queries ( TCQ X  X  ), with a probability no less than , i.e ., P ( TCQ -i ) -i ). For example, for the first probabilistic threshold -based correlation query , PTCQ -1 , the query would read as: given an uncertain time series Q , a correlation threshold , and a probability threshold , find every uncertain time series X in the database which satisfy : That is, time series X and Q are positively correlated with probability at least p and their correlation is no less than c . Next we discuss our solution to these queries. As pointed out in the previous section, uncertain correlation section, we determine expected value and variance of uncertain correlation between two uncertain time series X and Y . Since the random variables of different timestamps are assumed to be independent, t he expected value of uncertain correlation Using delta method [13], we estimate the variance as follows: ( )  X   X   X   X   X  Note that  X  , ,  X  , and are random variables. To simplify the computation, we will treat them as (uncertain) real numbers. Here,  X  and  X  indicate the average of means of the uncertain values at each timestamp, and and indicate their standard deviations. For a given uncertain time series X, we have: Knowing that has approximately normal distribution, we can simply answer all the PT CQ queries. For example, for PTCQ-1, we need to determine . For this, we need to find the complementary cumulative distribution function where erf () is Gaussian error function, and at the end, we need to compare the result with the given probability threshold . If PT CQ  X  s, except for the 3rd and 6 th, have similar solutions. For those two queries, since uncertain correlation is approximately a normal random variable, its absolute value has folded normal distribution , using this those queries can also be solved easily . In the following section, we formalize the notion of correlation between uncertain and standard time series. In this section, we study the notion of correlation between a standard and an uncertain time series, and show how to find solutions for the proposed PTCQ queries. We consider a standard time series as an uncertain time series uncertain time series where at each timestamp, we have a constant random variable. So we can simply substitute one of the uncertain time series in equation (1) with a standard time series. Again, w e consider Pearson correlation between uncertain and standard time series data as a sum of a sequence of independent random variables. According to central limit theorem [ 15] as n increases, candidate selection approach in the previous section.
 In addition, if both X and Y are standard time series, expected value and variance of their correlation would be their exact Pearson sample correlation coefficient and zero, respectively. This shows that their correlation would be a certain value. For a normal random variable with zero variance, the cumulative distribution function is the Heaviside step function. In fact, our approach can support both standard and uncertain time series. Note that the correlation between two time series is the dot product of their normal forms. In the next section, we formalize the notion of normalization for uncertain time series data. In the standard case, to make similarity measures invariant to scaling and shifting, normalization is applied as a preprocessing step. Normalization also helps better capture the similarity even in the context of probabilistic queries using Euclidean distance as the similarity measure [1 , 12, 19] . Note that Pearson correlation coefficient is invariant to scaling and shifting because it is the dot product of normal forms. So a side contribution of our work on uncertain correlation is uncertain time series normalization . Suppose we are given an uncertain time series data variable , and are independent. Similar to the standard case, we define the normal form of as an uncertain time series  X   X   X  , where  X  and are as defined in equation (1 ). Note that normalization of an (uncertain) time series yields an (uncertain) time series . In a normalized uncertain time series, the expected value and mean at each timestamp are as defined in equations (4) and (5) , respectively. The following lemmas show properties of normalized uncertain time series , the proofs of which are not provided due to lack of space. For any standard time series , its normal form  X  would have the average  X  and the standard deviation  X  . The following lemma characterizes this property for uncertain case. Lemma 1 . Given any uncertain time series X , ( (  X  ) are constant random variables with ( (  X  ( (  X  )) . So both normalized standard time series and uncertain time series would have the same average and standard deviation. Shasha et al. [17] showed that Euclidean distance between normalized time series is related to their Pearson sample correlation coefficient. Following their approach, we show that correlation between uncertain time series is closely related to the Euclidean distance between their normal forms. Lemma 2. Given two uncertain time series and , we have 
It is easy to see that this lemma holds even if one of the time series is standard. The following lemma shows the connection of our work with those which use Euclidian distance as the similarity measure [ 19, 12 ]. Lemma 3. Given two uncertain time series and , we have An important corollary of this lemma is that since correlation threshold c is in , Euclidean distance threshold, here is an interval from which he/she has to choose a distance threshold . On the other hand, when data is not normalized , the user has no clue of a suitable distance threshold in general without additional information about the dataset at hand. To evaluate our probabilistic correlation queries, we conducted extensive experiments and compared our approach for PTCQ-1 with a deterministic one where uncertain time series are treated as if they are certain time series. For a given uncertain time series, q , and a correlation threshold, c, an uncertain time series, x , would be an answer if . We call this type of query correlation query ( CQ ). Both approaches were implemented in MATLAB . To measure the ir performance, we compared them in terms of false alarm and hit ratio. Hit ratio is calculated as the ratio of the number of actual results in the candidate solutions to the number of all actual results. False alarm ratio is computed as the fraction of the number of false alarms over the number of all actual results. The ground truth is based on CQ result with the same correlation threshold on the dataset without uncertainty. We computed the average over 5 different random runs. We evaluated our approach using the set -ups used by Sarangi et al. [16] and Yeh et al. [19]. Due to the lack of space, we chose randomly one of the UCR datasets [10 ], Gun Point, and evaluated the impact of probability threshold, and standard deviation ratio on false alarm and hit ratio.
 In our experiments, we need to have not only uncertain time series data but also its real time series data as the ground truth, so we have to generate uncertain time series. To generate uncertain time series, we used an approach similar to [ 16 , 19]. To choose a standard deviation for an uncertain time series, first we compute the standard deviation of the given standard time series which is , then the standard deviation of the whole uncertain time series would be , where r is the standard deviation ratio ( SDR ) varied from 0.01 to 4 . Moreover, we illustrate the results under different probability thresholds varied from 0.01 to 0.8 . We perturb original data with different error functions. For the first 10% of the timestamp s, we use d a standard deviation of , for the next 80 %, a standard deviation of , and for the last part , . This pattern for standard deviation selection is very similar to the one used by Sarangi et al. [16 ]. Figure 1 shows the impact of probability threshold and standard deviation on the hit and false alarm ratio. For low probability thresholds (less than 0.05), hit ratio of PTCQ-1 is very close to one, in contrast to CQ , the hit ratio of which decreases significantly as standard deviation ratio increases. So when probability threshold is very small, we can say that PTCQ-1 is more resilient to error than CQ . The lower are the probability and standard deviation ratio, the higher is the hit ratio of PTCQ-1 . Note that probability threshold does not have any impact on CQ quality, according to its definition. A very interesting result is that for a given SDR , when the probability threshold is less than 0.5, PTCQ-1 would have higher hit ratio and lower false alarm than CQ . Conversely, when threshold is higher than 0.5, PTCQ -1 would have lower hit ratio and higher false alarm than CQ . These observations show how important is the role of probability threshold. For example, consider standard deviation ratio equal to 4, in CQ , hit ratio is around 0.2 which is very low, but in PTCQ-1 , if we choose a low probability threshold (say 0.01) the hit ratio would be close to 1. That is, with the same uncertainty level, CQ and PTCQ-1 can have very different recalls. Figure 1 also shows the impact of probability threshold and standard deviation ratio on false alarm of both CQ and PTCQ-1 . In general, CQ and PTCQ-1 hardly incurs any false alarms, but PTCQ-1  X  X  false alarm depends on the probability threshold. The higher is the probability threshold; the lower is the false alarm ratio. The left side of Figure 1 illustrates clearly that for PTCQ-1 , there is always a tradeoff between false alarm and hit ratio , and this trade -off is controlled by probability thre shold . On the other hand, the right side of Figure 1 shows that CQ does not offer this trade -off. These experimental results provide the user a guideline to choose the parameters in the query predicate. In this paper, we devised the first approach for correlation query processing for uncertain time series. We defined the notion of correlation between two IB uncertain time series data and introduced major types of probabilistic threshold-based correlation queries. To process such queries, first, we proved that uncertain correlation is approximately a normal random variable , and we successfully proposed a probabilistic approach as our query processing . In addition, we showed that our probabilistic approach can reduce to the standard case. We also formalized the notion of uncertain time series normalization constituting the core of our correlation query processing approach. The results of our extensive experiments indicated that our approach, unlike the deterministic one, provides a trade-off between false alarm and hit ratio of the results which can be controlled by the probability threshold given by users. Based on our observations, we also offer ed users a guideline about choosing proper thresholds. As our future work, we will extend our work to MB uncertain time series. This work was supported in part by Natural Sciences and Engineering Research Council (NSERC) of Canada and by Concordia University. [1] A X falg, J., Kriegel, H. P., Kr X ger, P., and Renz, M. [2] Bernecker, T., Kriegel, H.P., Renz, M., and Zuefle, A. [3] Bidgoli, B. M. and Lajevardi, B. Correlation mining between [4] Bohm, C., Pryakhin, A., and Schubert, M. Probabilistic [5] Chakraborti, A. An outlook on correlations in stock prices. [6] Cheng, R., Kalashnikov, D. V., and Prabhakar, S. Evaluating [7] Cheng, R., Kalashnikov, D. V., and Prabhakar, S. Querying [8] Dallachiesa, M., Nushi, B., Mirylenka, K., and Palpanas, T. [9] Emrich, T., Kriegel, H.P., Mamoulis, N., Renz, M., and [10] Keogh, E., Zhu, Q., Hu, B., Hao. Y., Xi, X., Wei, L. and [11] Kriegel, H.P., Kunath, P., and Renz, M. Probabilistic nearest-[12] Lian, X., Chen, L., and Yu, J. W. Pattern matching over [13] Oehlert, G. W. A note on the delta method. American [14] Qian, A., Ding, X., and Lu, Y. Probabilistic similarity search [15] Ross, S. M. Introductory statistics. Academic Press , 2009. [16] Sarangi S. R. and Murthy K. DUST: A generalized notion of [17] Shasha, D. and Zhu, Y. High performance discovery in time [18] Xu, J., Yue, D., Gu, Y., Li, C., and Yu, G. Pk-Period: A [19] Yeh, M. Y., Wu, K. L., Yu, P. S., and Chen, M. S. PROUD: [20] Zhang, L., Li, J., and Wang, Z. Uneven two-step sampling [21] Zhao, Y., Aggarwal, C.C., and Yu, P.S. On wavelet [22] Zuo, Y., Liu, G., Yue, X., Wang, W., and Wu, H. Similarity 
