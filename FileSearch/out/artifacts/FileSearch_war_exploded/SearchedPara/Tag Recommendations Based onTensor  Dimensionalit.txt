 Social tagging is the process by which many users add meta-data in the form of keywords, to annotate and categorize in-formation items (songs, pictures, web links, products etc.). Collaborative tagging systems recommend tags to users based on what tags other users have used for the same items, aim-ing to develop a common consensus about which tags best describe an item. However, they fail to provide appropriate tag recommendations, because: (i) users may have different interests for an information item and (ii) information items may have multiple facets. In contrast to the current tag rec-ommendation algorithms, our approach develops a unified framework to model the three types of entities that exist in a social tagging system: users, items and tags. These data is represented by a 3-order tensor, on which latent semantic analysis and dimensionality reduction is performed using the Higher Order Singular Value Decomposition (HOSVD) tech-nique. We perform experimental comparison of the proposed method against two state-of-the-art tag recommendations algorithms with two real data sets (Last.fm and BibSon-omy). Our results show significant improvements in terms of effectiveness measured through recall/precision.
Social tagging is the process by which many users add metadata in the form of keywords to annotate and catego-rize information items (songs, pictures, web links, products etc.). Many systems, such as Last.fm, Flickr, BibSonomy and Amazon use social tagging to categorize their informa-tion items and help users to share them. Moreover, based on social tagging, these systems are able to form tag categories and communities of users.

Many social tagging systems recommend tags to users based on what tags other users have used for the same items. Tag recommendations can expose different facets of an in-formation item and relieve users of the tedious task of man-ually entering useful tags. Thus, tag recommendation can reduce the problem of data sparsity in social tagging sys-tems, which results by the unwillingness of users to provide an adequate number of tags. Moreover, tag recommenda-tion confronts the vocabulary divergence problem and the ambiguity in the meaning of tags. The basic concern for a tagging system is to become relatively  X  X table X  with time and use. By  X  X table X , we mean to indicate that users have developed some consensus about which tags best describe an information item. Thus, by offering stability, tag recommen-dation helps users to find, share and integrate information items more easily.

Social tagging systems often fail to provide the appro-priate tag recommendations, which affects the retrieval of items. The reasons are the following: (i) users may have dif-ferent interests for an information item and (ii) information items have multiple facets. As a simple example, consider a social tagging system for images. Assume two users, one is a computer fan and the other likes fruits. The former se-lects an image of a Macintosh computer and the latter an image of a green apple. If they do not receive any tag recom-mendation, then they may both tag the images as  X  X pple X . Thus, after a while, when they provide the tag  X  X pple X  to retrieve relevant images, they will receive both images (Mac and fruit). If the former user is recommended the tag  X  X pple computer X  and the latter  X  X pple fruit X , the ambiguity could be resolved.

For the above reasons, recent research has focused on de-veloping tag recommendation algorithms [8, 18], which try to exploit tags given by users on specific items (henceforth, these data is called usage data ). However, existing tag rec-ommendation algorithms do not consider the 3 dimensions of the problem (i.e., users, items, tags) altogether. In con-trast, they split the 3-dimensional usage data into three 2-dimensional (pairwise) relations: { user, item } , { user, tag and { tag, item } . Thus, they miss a part of the semantics that is carried by the 3-dimensions. A more severe disad-vantage is presented from regular recommender systems, like Collaborative Filtering (CF), [2, 6, 7, 11], which are applied only to 2-dimensional data (e.g., users and items).
In this paper, we perform 3-dimensional analysis on the usage data, attempting to discover the latent factors that govern the associations among these multi-type objects. Con-sequently, tags can be recommended according to the cap-tured associations. This approach faces two challenges: (i) The relations among users, items and tags are com-plicated. There exist intra-relations among objects of the same type, as well as inter-relations among objects of differ-ent types. For personalized tag recommendations, what we are concerned about are the 3-order relations among them. That is, given a user and an item, the purpose is to predict whether and how much the user is likely to tag this item with a specific tag. Therefore, a unified framework is needed to model the multi-type objects and the multi-type relations among them. (ii) The three-way data is highly sparse. As we know, most CF algorithms are susceptible to data sparsity. For usage data, the sparseness problem becomes more serious because each user only tags a small number of items. La-tent Semantic Indexing (LSI) [3] has been proved useful to address the data sparseness problem in 2-dimensional data recommender systems, however, it is still an open problem for the 3-dimensional data case.

To address the first challenge, we need an approach deal-ing with 3-dimensional usage data. In this paper, we develop a unified framework to model the three types of dimensions: user, items and tags. The 3-dimensional data is represented by a 3-order tensor. To address the second challenge, we perform 3-mode analysis, using the Higher Order Singular Value Decomposition (HOSVD) technique [13].

The contributions of our approach are summarized as fol-lows:
The rest of this paper is organized as follows. Section 2 summarizes the related work, whereas Section 3 contains the description about Singular Value Decomposition (SVD) and HOSVD. The proposed approach is described in Sec-tion 4. Experimental results are given in Section 5. Finally, Section 6 concludes this paper.
In this section we briefly present some of the research lit-erature related to social tagging, CF recommendation algo-rithms and tag recommendation algorithms.

Social tagging is the process by which many users add metadata in the form of keywords to share content. So far, the literature has studied the strengths and the weaknesses of social tagging systems. In particular, Golder and Hu-berman [4] analyzed the structure of collaborative tagging systems as well as their dynamic aspects. Moreover, Halpin et al. [5] produced a generative model of collaborative tag-ging in order to understand the dynamics behind it. They claimed that there are three main entities in any tagging system: users, items and tags.

In contrast to the above ternary relation, many recom-mender systems use Collaborative Filtering (CF) to recom-mend items based on preferences of similar users, by exploit-ing a two-way relation of users and items [2]. Because of the ternary relational nature of social tagging, CF cannot be applied directly, unless the ternary relation is reduced to a lower dimensional space. Jaschke et al. [10], considered two alternative 2-dimensional projections to model the relation-ship among users, items and tags, in order to apply CF in social tagging. These projections preserve the user informa-tion and lead to log-based like recommender systems based on occurrence or non-occurrence of items, or tags, respec-tively, with the users.

Other tag recommendation algorithms are based on con-ceptual stuctures similar to the hyperlink structures used in Search Engines. For example, Collaborative Tag Sugges-tions algorithm [18], also known as Penalty-Reward algo-rithm (PR) uses an authority score for each user. The au-thority score measures how well each user has tagged in the past. This authority score can be computed via an iterative algorithm similar to HITs [12]. Moreover, the PR algorithm  X  X ewards X  the high correlation among tags, whereas it  X  X e-nalizes X  the overlap of concepts among the recommended tags to allow high coverage of multiple facets for an item. Another state-of-the-art tag recommendation algorithm is FolkRank [8]. FolkRank exploits the conceptual structures created by people inside the social tagging systems. Their method is inspired by the seminal PageRank [14] algorihtm, which reflects the idea that a web page is important if there are many pages linking to it, and if those pages are im-portant themselves. FolkRank employs the same underly-ing principle for Web Search and Ranking in social tagging. The key idea of FolkRank algorithm is that an item which is tagged with important tags by important users become important itself. The same holds, for tags and users, thus we have a tripartite graph of vertices which mutually re-inforces each other by spreading their weights. FolkRank is like the Personalized PageRank, which is a modification of global PageRank and was first proposed for personalized Web search in [14].

As described, all the aforementioned algorithms split the 3-dimensional space into pair relations { user, item } , { tag } and { tag, item } , that are only 2-dimensional. Thus, they miss a part of the total interaction between the three dimensions. In contrast, our approach develops a unified framework to concurrently model the three dimensions. Thus, usage data is represented by a 3-order tensor, on which la-tent semantic analysis is performed using the Higher Order Singular Value Decomposition (HOSVD) technique.

The higher-order singular value decomposition technique was proposed in [13]. It is a generalization of singular value decomposition and has been successfully applied for com-puter vision problems. In particular, Wang and Ahuja [16] present a novel multi-linear algebra based approach to re-duced dimensionality representation of multidimensional data, such as image ensembles, video sequences and volume data. Moreover, in the area of Personalized Web Search, Sun et al. proposed CubeSVD [15] to improve Web Search. They claimed that as the competition of Web Search increases, there is a high demand for personalized Web search. There-fore based on their CubeSVD analysis, which also uses HOSVD technique, web Search activities can be carried out more ef-ficiently. Their experiments were applied in MSN search engine data. Finally, Xu et al. [17] used HOSVD to provide item recommendations. Thus, they compared their work with a standard Collaborative Filtering algorithm, without focusing in tag recommendations. In the next section, we provide more information on HOSVD.
Since our Tensor Reduction approach is based on HOSVD [13], we first briefly review this technique. Henceforth, tensors are denoted by calligraphic upper-case letters ( A , B , ... ), matrices by uppercase letters ( A , B , ... ), vectors by bold b , ... ).

HOSVD generalizes SVD [1] to multi-dimensional matri-ces, which are called tensors . The SVD of a matrix F I 1 can be written as a product of three matrices, as shown in Equation 1 and Figure 1: where U is the matrix with the left singular vectors of F , V
T is the transpose of the matrix V with the right singu-lar vectors of F and S is the diagonal matrix of (ordered) singular values of F .

By preserving only the largest c&lt; min { I 1 ,I 2 } singular values of S , SVD results to matrix  X  F , which is an approx-imation of F . In Information Retrieval, this technique is used by Latent Semantic Indexing (LSI) [3], to deal with the latent semantic associations of terms in texts and to re-veal the major trends in F . The tuning of c is empirically determined by the information percentage that is preserved compared to the original matrix [13].

A N -order tensor A is denoted as A X  R I 1  X  ...  X  I N ,with elements real numbers of the form a i 1 ,...,i N . In the following, for the purposes of our approach, we only use 3-order tensors (the three dimensions are: users, items and tags).
To apply HOSVD on a 3-order tensor A ,three matrix un-folding operations are defined as follows [13]: where A 1 ,A 2 ,A 3 are called the 1-mode, 2-mode, 3-mode matrix unfoldings of A , respectively. The unfoldings of A the three modes, is illustrated in Figure 2.
 Figure 2: Visualization of the three unfoldings of a 3-order tensor.

Example: Assume a tensor A X  R 3  X  2  X  3 with a 111 = a a a 312 = a 123 = a 322 = 0. Figure 3 illustrates tensor A . Figure 3: Visualization of a tensor A X  R 3  X  2  X  3 . A 1  X  R I 1  X  I 2 I 3 , i.e., the 1-mode matrix unfolding of given in Figure 4.
 Next, we define the n -mode product of an N -order tensor as A X  n U . The result of the n -mode product is an ( I 1  X  I  X  ...  X  I n  X  1  X  J n  X  I n +1  X  ...  X  I N )-tensor, the entries of which are defined as follows: Figure 4: Visualization of 1-mode matrix unfolding of tensor A , which results to matrix A 1 . (
A X  n U ) i Since we focus on 3-order tensors, n  X  X  1 , 2 , 3 } , thus we use the 1-mode, 2-mode and 3-mode products.

In terms of n -mode products, SVD (Equation 1) on a reg-ular two-dimensional matrix (i.e., 2-order tensor), can be rewritten as follows [13]: U is an ( I 1  X  I 2 )-matrix with the following properties: (i) pseudodiagonality ( S =diag(  X  1 , X  2 ,..., X  min { I 1 (ii) ordering (  X  1  X   X  2  X  ...  X   X  min { I 1 ,I 2 }  X  0).
By extending this form of SVD, the HOSVD of 3-order tensor A can be written as follows [13]: where U (1) , U (2) , U (3) contain the orthonormal vectors (called the 1-mode, 2-mode and 3-mode singular vectors, respec-tively) spanning the column space of the A 1 ,A 2 ,A 3 matrix unfoldings. S is the core tensor and has the property of all orthogonality. This process is illustrated in Figure 5.
In this section we present our proposed approach. First, we provide the outline of the approach through a motivat-ing example, to grasp the essential characteristics of the ap-proach. Then, we analyze the steps of the proposed algo-rithm.
When using a social tagging system, a user u tags an item i with a tag t , in order to be able to retrieve information items easily. Thus, the tagging system accumulates a collection of usage data, which can be represented by a set of triplets { u, i, t } .

Our Tensor Reduction approach applies HOSVD on the 3-order tensor constructed from these usage data. In accor-dance with the HOSVD technique introduced in Section 3, the Tensor Reduction algorithm uses as input the usage data of
A and outputs the reconstructed tensor  X  A .  X  A measures the associations among the users, items and tags. The ele-ments of  X  A can be represented by a quadruplet { u, i, t, p where p measures the likeliness that user u will tag item i with tag t . Therefore, tags can be recommended to u ac-cording to their weights associated with { u, i } pair.
In this subsection, in order to illustrate how our approach works, we apply the Tensor Reduction algorithm to a run-ning example. As illustrated in Figure 6, 3 users tagged 3 different items. In Figure 6, the part of an arrow line (se-quence of arrows with the same annotation) between a user and an item represents that the user tagged the correspond-ing item and the part between an item and a tag indicates that the user tagged this item with the corresponding tag. Thus, the annotated numbers on the arrow lines gives the correspondence between the three types of objects. For ex-ample, user U 1 tagged item I 1 with tag  X  X BM Computer X , denoted as T 1 . The remaining tags are  X  X pple Computer X , denoted as T 2 ,  X  X pple Fruit X , denoted as T 3 .

From Figure 6, we can see that users U 1 and U 2 have common interests on computers, while user U 3 is interested in apple fruits. A 3-order tensor A X  R 3  X  3  X  3 ,canbecon-structed from the usage data. We use the co-occurrence frequency (denoted as weight) of each triplet user, item and tag as the elements of tensor A , which are given in Table 1.
After performing the Tensor Reduction analysis (details of how to do this are given in the following section), we can get the reconstructed tensor of  X  A , which is presented in Table 2, whereas Figure 7 depicts the contents of  X  A graph-ically (the weights are omitted). As shown in Table 2 and Table 1: Tensor Constructed from the usage Data of the running example.
 Figure 7, the output of the Tensor Reduction algorithm for the running example is interesting, because a new associa-tion among these objects is revealed. The new association is between U 1 , I 2 and T 2 . This association is represented with the last (bold faced) row in Table 2 and with the dashed arrow line in Figure 7).

If we have to recommend to U 1 a tag for I 2 , then there is no direct indication for this task in the original tensor However, we see that in Table 2 the element of  X  A associated with { U 1 , I 2 , T 2 } is 0.44, whereas for U 1 there is no other element associating other tags with I 2 . Thus, we recommend to user U 1 the tag T 2 for item I 2 .
 Table 2: Tensor Constructed from the usage Data of the running example.
 Figure 7: Illustration of the Tensor Reduction Al-gorithm output for the running example
The resulting recommendation is reasonable, because U 1 is interested in computers rather than fruits. That is, the Tensor Reduction approach is able to capture the latent as-sociations among the multi-type data objects: user, item and tags. The associations can then be used to improve the tag recommendation procedure, as will be verified by our experimental results.
In this section we provide details on how HOSVD is ap-plied on tensors and how tag recommendation is performed based on the detected latent associations.

Our Tensor Reduction approach initially constructs a ten-sor, based on usage data triplets { u, i, t } of users, items and tags. The motivation is to use all three objects that interact inside a social tagging system. Consequently, we proceed to the unfolding of A , where we build three new matrices. Then, we apply SVD in each new matrix. Finally, we build the core tensor S and the resulting tensor  X  A . The 6 steps of the proposed approach are summarized as follows: Steps 1  X  5 build a model and can be performed off-line. The recommendation in Step 5 is performed on-line, i.e., each time we have to recommend a tag to a user, based on the built model. In the following, we provide more details on each step.
From the usage data triplets (user, item, tag), we con-struct an initial 3-order tensor A X  R I u  X  I i  X  I t ,where I I , I t are the numbers of users, items and tags, respectively. Each tensor element measures the number of times that a user u tagged item i with tag t .
As described in Section 3, a tensor A can be unfolded (matricized), i.e., we build matrix representations of tensor A in which all the column (row) vectors are stacked one after the other. The initial tensor A is matricized in all three modes. Thus, after the unfolding of tensor A for all three modes, we create 3 new matrices A 1 , A 2 , A 3 , as follows:
We apply SVD on the three matrix unfoldings A 1 , A 2 , A We result, in total, to 9 new matrices.

For Tensor Dimensionality Reduction, there are three di-mensional parameters to be determined. The numbers c 1 , c and c 3 of left singular vectors of matrices U (1) , U (2) spectively, that are preserved. They will determine the final dimensionality of the core tensor S. Since each of the three diagonal singular matrices S 1 , S 2 and S 3 are calculated by applying SVD on matrices A 1 , A 2 and A 3 , respectively, we use different c 1 , c 2 and c 3 numbers of principal components for each matrix U (1) , U (2) , U (3) .Thenumbers c 1 , c c of singular vectors are chosen by preserving a percentage of information of the original S 1 , S 2 , S 3 matrices after ap-propriate tuning (the default percentage is set to 50% of the original matrix).
The core tensor S governs the interactions among users, items and tags. Since we have selected the dimensions of U (1) , U (2) and U (3) matrices, we proceed to the construction of S , as follows: where A is the initial tensor, U c 1 (1) T is the tranpose of the c -dimensionally reduced U (1) matrix, U c 2 (2) T is the tran-pose of the c 2 -dimensionally reduced U (2) matrix, U c 3 the tranpose of the c 3 -dimensionally reduced U (3) matrix. Finally, tensor  X  A is build as the product of the core tensor S and the mode products of the three matrices U (1) , U (2) and U (3) as follows: S is the reduced core tensor, U c 1 (1) is the c 1 -dimensionally reduced U (1) matrix, U c 2 (2) is the c 2 -dimensionally reduced U trix.
Tensor  X  A measures the associations among the users, items and tags and acts as a model that is used during the recom-mendation.

Each element of  X  A represents a quadruplet { u, i, t, p } p is the likeliness that user u will tag item i with tag t . Therefore, for a user u andanitem i , tags can be recom-mended according to their weights associated with { u , i pair. If we want to recommend to uN tags for item i ,then we select the N corresponding tags with the highest weights.
In this section, we present experimental results for the performance of our approach, compared to two state-of-the-art tag-recommendation algorithms. Henceforth, our pro-posed approach is denoted as Tensor Reduction. We use Folkrank [8] and the Collaborative Tag Suggestions [18] al-gorithm (known as Penalty-Reward algorithm), denoted as FolkRank and PR, respectively as comparisons to our ap-proach.
To evaluate the examined algorithms, we have chosen real data sets from two different social tagging systems: BibSon-omy and Last.fm, which have been used as benchmarks in past works [8].

BibSonomy : We used a snapshot of all users, items (both publication references and bookmarks) and tags pub-licly available on April 30, 2007. From this snapshot, we excluded the posts from the DBLP computer science bibli-ography since they are automatically inserted and all owned by one user and all tagged with the same tag (dblp). The number of users, items and tags are 1,037, 28,648 and 86,563, respectively.

Last.fm : The data for Last.fm was gathered during Oc-tober 2007, partly through the web services API (collecting user nicknames), partly crawling the Last.fm site. Here the items correspond to artist names, which are already normal-ized by the system. There are 12,773 triplets in the form user-artist-tag. These triplets correspond to 4,442 users, 1,620 artists and 2,939 tags.

Following the approach of [8] to get more dense data, we adapt the notion of a p -core to tri-partite hypergraphs. The p -core of level k has the property, that each user, tag and item has/occurs in at least k posts. For both data sets we used k = 5. Thus, for the Bibsonomy data set there are 105 users, 246 items and 591 tags, whereas for the Last.fm data set there are 112 users, 234 items and 567 tags.
We performed 4-fold cross validation, thus each time we divide the data set into a training set and a test set with sizes 75% and 25% of the original set, respectively. All algorithms had the task to predict the tags of the users X  postings in the test set.

Based on the approach of [9, 7], a more realistic evalua-tion of recommendation should consider the division of tags of each test user into two sets: (i) the past tags of the test user and, (ii) the future tags of the test user. Therefore, for a test user we generate the recommendations based only on the tags in his past set. This simulates the real-world appli-cations, where users gradually tag items and receive recom-mendations before they provide all their tags. As most ex-isting works ignore this division, their reported performance corresponds to the best case, because they indirectly exploit apriori known information (the tags in the future set). For example, assume a user in the test set, which has posted 10 tags for a particular item. According to the approach in previous works, all the 10 tags are used to calculate his similarity with training users. In contrast, if we consider 7 tags to belong in the past set, then we compute similarities based only on the past 7 tags and we have to predict the remaining 3 tags (those in the future set). With the divi-sion into past and future sets, the accuracy is expected to decrease compared to the best case when the two sets are identical. However, the reported performance is more in-dicative for real-world applications. The default sizes of the past and future sets are 50% and 50%, respectively, of the number of tags posted by each test user.

As performance measures we use the classic metrics of precision and recall. For a test user that receives a list of N recommended tags (top-N list), precision and recall are defined as follows:
For each of the algorithms of our evaluation we will now describe briefly the specific settings used to run them:
Tensor Reduction algorithm: The numbers c 1 , c 2 and
FolkRank algorithm: We set the damping factor d =0 . 7
PR algorithm: Initially, we set the uniform authority In this section, we proceed with the comparison of Tensor Reduction with FolkRank and PR, in terms of precision and recall. This reveals the robustness of each algorithm in at-taining high recall with minimal losses in terms of precision. We examine the top-N ranked list, which is recommended to a test user, starting from the top item. In this situa-tion, the recall and precision vary as we proceed with the examination of the top-N list.

For the BibSonomy data set ( N is between [1..5]), in Fig-ure 8, we plot a precision versus recall curve for all three algorithms. As shown, the precision of each algorithm falls as N increases. In contrast, as N increases, recall for all five algorithms increases too. Tensor Reduction algorithm attains 68% precision, when we recommend a top-1 list of tags. In contrast, FolkRank gets a precision of 42%. More-over, Tensor Reduction is more effective than FolkRank get-ting a maximum recall of 44%, while the latter X  X  is 36%. This experiment shows that Tensor Reduction is more ro-bust in finding relevant tags for the test user. The reason is that Tensor Reduction exploits all information that concerns the three objects (users, items, tags) and through HOSVD, it addressed sparsity and finds latent associations. 10 20 30 40 50 60 70 Figure 8: Comparison of Tensor Reduction, Folkrank and PR algorithms for the BibSonomy dataset.

For the Last.fm data set ( N is between [1..5]), in Figure 9, we plot also a precision versus recall curve for all three algo-rithms. Tensor Reduction algorithm again attains the best performance. Despite the different nature of the two data sets (the one is for bibliographic data and the other for musi-cal data), we observe similar behavior of algorithms for both data sets. It is important that Tensor Reduction provides more accurate recommendations in both cases.
Collaborative tagging systems recommend tags to users based on what tags other users have used for the same items, aiming to develop a common consensus about which tags best describe an item.

In this paper, we developed a unified framework to model the three types of entities that exist in a social tagging sys-tem: users, items and tags. These data is represented by a 3-order tensor.

We applied dimensionality reduction in a 3-order tensor, to reveal the latent semantic associations between users, items and tags. The latent semantic analysis and dimension-ality reduction is performed using the Higher Order Singular Value Decomposition (HOSVD) technique. 10 20 30 40 50 60 70 Figure 9: Comparison of Tensor Reduction, Folkrank and PR algorithms for the Last.fm dataset.
We also performed experimental comparison of the pro-posed method against two state-of-the-art tag recommen-dations algorithms, with two real data sets (Last.fm and BibSonomy). Our results show substantial improvements in terms of effectiveness measured through recall/precision.
As future work, we intend to examine the following topics: [1] M. Berry, S. Dumais, and G. O X  X rien. Using linear [2] J. Breese, D. Heckerman, and C. Kadie. Empirical [3] G. Furnas, S. Deerwester, and S. e. a. Dumais. [4] S. Golder and B. Huberman. The structure of [5] H. Halpin, V. Robu, and H. Shepherd. The dynamics [6] J. Herlocker, J. Konstan, and J. Riedl. An empirical [7] J. Herlocker, J. Konstan, L. Terveen, and J. Riedl. [8] A. Hotho, R. Jaschke, C. Schmitz, and G. Stumme. [9] Z. Huang, H. Chen, and D. Zeng. Applying associative [10] R. Jaschke, L. Marinho, A. Hotho, [11] G. Karypis. Evaluation of item-based top-n [12] J. Kleinberg. Authoritative sources in a hyperlinked [13] L. d. Lathauwer, B. d. Moor, and J. Vandewalle. A [14] L. Page, S. Brin, R. Motwani, and W. T. The [15] J. Sun, D. Shen, H. Zeng, Q. Yang, Y. Lu, and [16] H. Wang and N. Ahuja. A tensor approximation [17] Y. Xu, L. Zhang, and W. Liu. Cubic analysis of social [18] Z. Xu, Y. Fu, J. Mao, and D. Su. Towards the
