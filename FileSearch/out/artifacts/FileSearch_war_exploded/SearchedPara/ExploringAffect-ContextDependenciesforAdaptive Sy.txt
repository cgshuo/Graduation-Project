 forbesk@pitt.e du litman@cs.pitt. edu Detecting and adapting to user affect is being ex-plored by man y researchers to impro ve dialogue sys-tem quality . Detection has recei ved much atten-tion (e.g., (Litman and Forbes-Rile y, 2004; Lee and Narayanan, 2005)), but less work has been done on adaptation, due to the dif culty of developing re-sponses and applying them at the right time. Most work on adaptation tak es a conte xt-independent ap-proach: use the same type of response after all in-stances of an affecti ve state. For example, Liu and Picard (2005)' s health assessment system responds with empathy to all instances of user stress.
Research suggests, howe ver, that it may be more effecti ve to tak e a conte xt-dependent approach: de-velop multiple responses for each affecti ve state, whose use depends on the state' s conte xt. E.g., in the tutoring domain, Pon-Barry et al. (2006) sho w that human tutors use multiple responses to uncertain student answers, depending on the answer' s correct-ness and prior conte xt. In the information-seeking domain, it is commonly belie ved that while an apol-ogy is a good def ault response to user frustration (as in (Klein et al., 2002)), one conte xt requires a dif fer -ent response: after several frustrated user turns, the call should be forw arded to a human operator .
A conte xt-dependent approach to affect adapta-tion must address 2 issues: in what conte xts to adapt, and what responses to use there. This paper ad-dresses the rst issue and tar gets student uncertainty in our computer tutoring dialogues. Although our di-alogues have a Question-Answer format, our system contains 275 tutor questions. Treating each question as a conte xt is too labor -intensi ve for adaptation de-velopment and creates a data sparsity issue. Instead we treat automatically monitorable question proper -ties as conte xts. Here we examine 3 conte xts: the di-alogue act interpretation, and the discourse structure depth and transition, of the prior tutor question. We use certain student answers (correct and incorrect). Our results sho w that some conte xts are signicantly as-sociated with uncertain answers. Our next step will be to use these signicant dependencies to develop system responses to uncertain answers in these con-texts. These responses will be based both on our hypotheses about why uncertainty is associated with these conte xts, and on analyses of human tutor re-sponses to uncertain answers in these conte xts. ITSPOKE is a speec h-enabled version of a text-based tutoring system (VanLehn et al., 2002). The student rst types an essay answering one of 5 qual-itati ve physics problems. ITSPOKE parses the es-say , extracts dialogue topics concerning misconcep-tions, then engages the student in dialogue. In this study we used 2 ITSPOKE corpora containing 4590 student turns over 185 dialogues from 37 students. Figure 1 sho ws an annotated dialogue excerpt. 2.1 Uncertainty and Corr ectness Annotations ITSPOKE, lik e most computer tutors, responds only to student correctness. ITSPOKE labels each an-swer as corr ect or incorr ect 1 . If correct, ITSPOKE mo ves on to the next question. If incorrect, then for questions on simple topics, ITSPOKE gives the cor -rect answer and mo ves on, while for questions on comple x topics (ITSPOKE initiates a sub-dialogue with remediation questions (ITSPOKE
Recent computer tutoring research has sho wn in-terest in responding to student affect 2 over cor -rectness. Uncertainty is of particular interest: re-searchers hypothesize that uncertainty and incorrect-ness each create an opportunity to learn (VanLehn et al., 2003). The y cannot be equated, howe ver. First, an uncertain answer may be correct or incor -rect (Pon-Barry et al., 2006). Second, uncertainty in-dicates that the student per ceives a possible miscon-ception in their kno wledge. Thus, system responses to uncertain answers can address both the correct-ness and the percei ved misconception.

In our ITSPOKE corpora, each student answer has been manually annotated as uncertain or non-uncertain 3 : uncertain is used to label answers ex-pressing uncertainty or confusion about the material; non-uncertain is used to label all other answers. 2.2 Context Annotations Here we examine 3 automatically monitorable tutor question properties as our conte xts for uncertainty: Tutor Question Acts: In prior work one annotator labeled 4 Tutor Question Acts in one ITSPOKE cor -pus (Litman and Forbes-Rile y, 2006) 4 : Short (SA Q), Long (LA Q), and Deep Answer Question (D AQ) dis-tinguish the question in terms of content and the type of answer it requires. Repeat (RPT) labels variants of  X Can you repeat that? X  after rejections. From these annotations we built a hash table associating each ITSPOKE question with a Question Act label; with this table we automatically labeled ITSPOKE questions in our second ITSPOKE corpus.
 Discourse Structur e Depth/T ransition: In prior work we sho wed that the discourse structure Depth and Transition for each ITSPOKE turn can be au-tomatically annotated (Rotaru and Litman, 2006). E.g., as sho wn in Figure 1, ITSPOKE 1 and ITSPOKE els 3 and abo ve (3+) due to data sparsity . 6 Transi-tion labels represent the turn' s position relati ve to the prior ITSPOKE turn: Ne wT opLe vel labels the rst question after an essay . Advance labels questions at the same depth as the prior question (ITSPOKE Push labels the rst question in a sub-dialogue (after an incorrect answer) (ITSPOKE sub-dialogue, ITSPOKE asks the original question again, labeled PopUp (ITSPOKE the next question, labeled PopUpAdv . SameGoal la-bels both ITSPOKE RPTS (after rejections) and re-peated questions after timeouts. We use the denc y of uncertain (unc) or non-uncertain (nonunc) student answers that are correct (C) or incorrect (I). First, we compute an overall conte xt variable and the student answer variable. For example, the Question Act variable (QA CT) has 4 values: SA Q, LA Q, DAQ, RPT . The answer vari-able (SANSWER) also has 4 values: uncC, uncI, nonuncC, nonuncI . Table 1 (last column) sho ws the  X  2 value between these variables is 203.38, which greatly exceeds the critical value of 16.92 (p  X  0.05, df=9), indicating a highly signicant dependenc y. Signicance increases as the Table 1: Tutor Question Act Dependencies (p  X  .05: critical
Ho we ver, this does not tell us which variable val-ues are signicantly dependent. To do this, we create a binary variable from each value of the conte xt and answer variables. E.g., the binary variable for LA Q has 2 values:  X LA Q X  and  X An ything Else X , and the binary variable for uncC has 2 values:  X uncC X  and  X An ything Else X . We then compute the tween the binary variables. Table 1 sho ws this value is 133.98, which greatly exceeds the critical value of 3.84 (p  X  0.05, df=1). The table also sho ws the ob-serv ed (72) and expected (22) counts. Comparison determines the sign of the dependenc y: uncC occurs signicantly more than expected (+) after LA Q. The  X = X  sign indicates a non-signicant dependenc y.
Table 1 sho ws uncertain answers ( uncC and uncI ) occur signicantly more than expected after LA Qs. In contrast, non-uncertain answers occur signi-cantly less (-), or aren' t signicantly dependent (=). Also, uncI occurs signicantly more than expected after DAQs. We hypothesize that LA Qs and DAQs are associated with more uncertainty because the y are harder questions requiring denitions or deep reasoning. Not surprisingly , uncertain (and incor -rect) answers occur signicantly less than expected after SA Qs (easier ll-in-the-blank questions). Un-certainty sho ws very weak dependencies on RPTs.
Table 2 sho ws that Depth1 is associated with more correctness and less uncertainty overall. Both types of correct answer occur signicantly more than ex-pected, but this dependenc y is stronger for nonuncC . Both incorrect answers occur signicantly less than expected, but this dependenc y is stronger for uncI . Table 2: Depth Dependencies (p  X  .05: critical  X  =12.59 (df=6); critical
At Depths 2 and 3+, correct answers occur sig-nicantly less than expected or sho w no signi-cance. Incorrect answers occur signicantly more than expected, and the dependencies are stronger for uncI . We hypothesize that deeper depths are asso-ciated with increased uncertainty and incorrectness because the y correspond to deeper kno wledge gaps; uncertainty here may also relate to a percei ved lack of cohesion between sub-topic and lar ger solution.
Table 3 sho ws Pushes have the same dependen-cies as deeper depths (increased uncertainty and in-correctness); howe ver, here the uncI dependenc y is only slightly stronger than nonuncI , which suggests that increased uncertainty at deeper depths is more reliably associated with remediation questions after the Push. Although uncertainty sho ws only weak dependencies on PopUps, after PopUpAdvs the uncI dependenc y is strong, with uncI occurring more than expected. We hypothesize that this dependenc y re-lates to students losing track of the original ques-tion/lar ger topic. Uncertainty sho ws only weak de-pendencies on Adv ances. After Ne wT opLe vels, in-correct answers occur less than expected, but the de-pendenc y is stronger for nonuncI . After SameGoals, incorrect answers occur more than expected, but the dependenc y is stronger for nonuncI . Compared with the RPT results, the SameGoal results suggest stu-dents feel increased uncertainty after timeouts. Table 3: Transition Dependencies (p  X  .05: critical  X  =25.00 (df=15); critical We analyzed dependencies between uncertain stu-dent answers and 3 automatically monitorable con-texts. We plan to examine more conte xts, such as a Topic Repetition variable that tracks similar ques-tions about a topic (e.g. gra vity) across dialogues.
Our next step will be to use the signicant de-pendencies to develop system responses to uncer -tain answers in these conte xts. These responses will be based both on our hypotheses about why uncer -tainty is signicantly associated with these conte xts, as well as on analyses of human tutor responses in these conte xts, using our human tutoring corpus, which was collected with our rst ITSPOKE corpus using the same experimental procedure.

We also plan to investigate conte xt dependencies for other affecti ve states, such as student frustration. NSF (#0631930, #0354420 and #0328431) and ONR (N00014-04-1-0108) support this research.
