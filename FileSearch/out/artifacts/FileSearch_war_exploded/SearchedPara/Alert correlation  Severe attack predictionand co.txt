 LINA/KOD UMR CNRS 6241, Ecole Polytechnique de l X  X niversite de Nantes, Nantes, France 1. Introduction
Computer security is always facing new challenges as information systems are more and more net-worked and technologies are changing and increasingly complex. Two kinds of solutions are currently deployed in order to ensure the integrity, con fi dentiality or availability of computer and network re-sources/services: preventive solutions (such as fi re-walls and access control systems) aiming at pre-venting malicious users from performing unauthorized actions and detective solutions such as intrusion detection systems (IDSs) whose objective is detecting any malicious action targeting the information system resources and services [2]. IDSs act as burglar alarms and they are either misuse-based [29] or anomaly-based [26] or a combination of both the approaches in order to exploit their mutual comple-mentarities [33].

Computer security practitioners often deploy mu ltiple security products and solutions in order to increase the detection rates by exploiting their mutual complementarities. For instance, misuse-based IDSs are often combined with anomaly-based ones in order to detect both old and novel attacks and anomalies. It is important to note that all exiting anomaly-based approaches have a major drawback consisting in very high false alarm rates. These systems build pro fi les and models of legitimate activities and detect attacks by computing the deviations of the analyzed activities from normal activity pro fi les. In the literature, most anomaly-based IDSs are novelty or outlier approaches [26,30] adapted for the intrusion detection problem. Moreover, all modern IDSs (even the de facto network IDS Snort 1 ) are well-known to trigger large amounts of alerts most of which are redundant and false ones. This problem is due to several reasons such as bad parameter settings and inappropriate IDS tuning, etc. [32]. As a consequence, huge amounts of alerts are daily reported making the task of the security administrators time-consuming and inef fi cient. In order to cope with such quantities of alerts, alert correlation approaches are used [12, 14].

Alert correlation is the task of analyzing the alerts triggered by one or multiple IDSs in order to provide a synthetic and high-level view of the interesting malicious events targeting the information system. Alert correlation approaches aim either at reducing the number of triggered alerts by eliminating redundant and irrelevant ones [14] or detecting multi-step attacks [25] where the different alerts may correspond to the execution of an attack plan consisting in several steps. More recently, the authors in [5] proposed a method for prioritizing the triggered alerts according to the knowl edge and preferen ces of the security administrators.

In this paper, we propose a complete approach which fi rst reduces and preprocesses the alerts reported by several IDSs then ef fi ciently predicts severe attacks. The main objectives of our approach are iii) Flexible control of severe attack prediction/false alarm rate tradeoffs: We propose a fl exible In our approach, the severe attack prediction model is viewed as a classi fi cation problem based on a Bayesian multi-net and we rely on Pearl X  X  virtual evidence method [27] for handling the IDSs X  reliability. In order to control the severe attack prediction/false alarm rate tradeoffs, we propose an approach allowing to reject the alert sequences where the alert correlation model X  X  con fi dence is not suf fi cient to make a good prediction. As we will see in our experimental studies, our approach allows to signi fi cantly reduce the false alarm rates while ensuring very interesting severe attack prediction rates. Note that the other prediction and classi fi cation models such decision trees [28] cannot handle uncertain inputs (inputs provided by unreliable sources such as IDSs) and cannot offer means for asse ssing and controlling the model X  X  con fi dence when making predictions. As we will see in the following sections, our approach requires minimum expert intervention. In fact, given a set of severe attacks to predict and historical alert logs, one can easily build and deploy an ef fi cient model for predicting severe attacks. Moreover, our approach is easily deployed in real-time since one has just to preprocess the alert logs in real-time to extract the predictor vectors and perform real-time severe attack prediction. We can add (resp. discard) a new (resp. an existing) severe attack with minimum alterations on the existing prediction model as it is based on a multi-net.

Our approach is integrated and centered on Bayesian networks and intended to effectively address most of the challenging issues in alert correlation. As Bayesian networks are good prediction models, they are very suitable for the severe attack prediction problem and provide simple and ef fi cient means for dealing with the two major issues in alert correlation: dealing with false alarms and controlling prediction/false alarm rate tradeoffs. More precisely, Bayesian networks offer an elegant way for dealing with false alarms (using the virtual evidence method [27]) and controlling the prediction/false alarm tradeoffs with the reject option [10]. These methods are speci fi c to Bayesian networks and perfectly meet the requirements of the severe attack prediction problem. Our experimental studies, carried out on real data collected on a university campus, clearly show the effectiveness of our approach in predicting severe attacks with low false alarm rates.

The rest of this paper is organized as follows: Section 2 provides the basic backgrounds and related works on alert correlation. In Section 3, we present our method for redundant and irrelevant alert elimination. Section 4 brie fl y presents Bayesian mu lti-nets and our predictio n model taking into account the IDSs X  reliability. Section 5 presents our approach for handling IDSs X  reliability. In Section 6, we present our model for controlling the prediction/false alarm rate tradeoffs. Section 7 provides our experimental studies and fi nally, Section 8 concludes this paper. 2. Alert correlation: Approaches and challenges
In this section, we brie fl y review existing approaches in the alert correlation fi eld then present the two main challenges related to this problem and for which we propose a solution. 2.1. Alert correlation
Alert correlation [12,14] consists in analyzing the alerts triggered by one or multiple IDSs and other security tools in order to provide a synthetic and high-level view of the interesting malicious events targeting the information system. The input data for alert correlation tools is gathered from various sources such as IDSs, fi re-walls, web server logs, etc. Correlating alerts reported by multiple analyzers and sources has several advantages such as exploiting the complementarities of multiple analyzers. The main objectives of alert correlation are:
In the literature, alert co rrelation approaches are often grouped int o similarity-based approaches [14], prede fi ned attack scenarios [25], pre and post-conditions of individual attacks [12] and statistical ap-proaches [21,35].

In most similarity-based approaches, the objective consists in reducing the large volumes of alerts generated by the analyzers by aggregating similar ones on the basis of their features (victiom/attacker IP addresses, etc.). Examples of such approaches can be found in [13,14,35].

Approaches based on pre/post-conditions aim at detecting whether an attack plan (also called attack scenario ) is in progress. An attack plan designates a complex multi-step attack consisting in several malicious actions. It often consists in a set of actions executed in a prede fi ned sequence. Hence, in order to detect attack plans, there is a need to fi rst detect the individual actions and correlate them in order to fi nd which attack plan is ongoing. Pre/ post-condition approaches encode attack plans by specifying for each action its pre-cond itions (the actions/conditions that must executed/ful fi lled before executing the current one) and post-conditions (corresponding generally to the consequences of an action). In [1], the authors propose a grammar-based approach to encode attack plans. In [25], the authors propose a logic-based approach for attack scenario detection while it is a graph representation-based approach that is used in [23]. It is important to note that most works on multi-step attack detection heavily rely on expert X  X  knowledge. For instance, the model proposed in [12] requires identifying for each elementary attack, the preceding attacks and its consequences.

Several works propose statistical and data mining techniques for the alert correlation problem. The advantage of these techniques is their ability to exploit large data volumes and the fact that they do not require lot of expert knowledge. For instance, in [13] the authors apply clustering and data mining approaches to discover attack clusters which are then aggregated. The authors in [4] use naive causal Bayesian networks in order to detect whether an intruder is attempting to reach a given objective.
In this paper, we are interested in severe attack detection which can be viewed as a variant of multi-step attack recognition. 2.2. Alert correlation data
Alert correlation engines basically use as input data the alerts triggered by the detection and prevention tools monitoring the information system. In addition, they exploit other data such as the message notifying events, the log records of some applications such Web servers, database management systems, etc.

An alert is a message generated by un IDS when an attack or an abnormal activity is detected. It often contains an identi fi cation/name of the detected activity, its category, a severity level, the IP address of the attacker, the IP address of the victim, etc. Most of the modern IDSs can report alerts in IDMEF 3 format which is the XML intrusion detection message exchange format enabling inter-operability among IDSs and other security tools. In the following, we provide an example of an IDMEF alert generated by Snort IDS:
It is important to note that alerts can be generated by different categories of detection tools (such as network-based IDSs, host-based IDSs, application-based IDSs, etc.) and prevention tools (such fi re-walls, access control systems, etc.).

According to the IDSs X  con fi gurations, the alerts generated by IDSs are sent directly to the security administrators, stored in a log fi le, etc. Generally, alerts are generated in IDMEF format and sent to a server which collects these alerts for alert correlation purposes. For instance, Prelude-manager 4 is a collection of open source tools allowing to collect (via secure network connections) and store the alerts and events triggered by various IDSs and other security tools such that alert correlation engines can use them. Note that in our experimental studies, our data is collected on a university campus monitored by the Snort IDS and the triggered alerts are collected by the Prelude-manager tool. 2.3. IDSs X  Reliability: A crucial issue
The most important problem users of IDSs and security practitioners face is the one of false alerts which correspond to legitimate activities that have been mistakenly reported as malicious actions by the IDSs. Indeed, nowadays IDSs are well-known to trigger high false alarm rates. For instance, the well-known Snort IDS indicates for each attack, whether false alerts could be triggered. In an experimental evaluation of Snort IDS [32], the authors concluded that 96% of the triggered alerts are false positives. Hence, taking into account the reliability of IDSs is an interesting issue for aler t correlation tasks such as the prediction of severe attacks which is the focus of this work. For instance, if it is known that 90% of alerts reporting a malicious event triggered by a given IDS are false, then this information should be taken into account if such alerts should be exploited as inputs by the alert correlation tool. Note that there is to the best of our knowledge no work addressing the handling of IDSs X  reliability for severe attack prediction. As we will see in Section 5.1, Bayesian networks offer a natural and ef fi cient way to handle the reliability of IDSs as a problem of probabilistic reasoning in presence of uncertain data. 2.4. Controlling prediction/false alarm rate tradeoffs
Most of detection tools are equipped with means allowing their users to con fi gure them according to theirs needs, required analysis overload, etc. For instance, some Snort detection modules offer thresholds to be set by the security administrators in order to limit the volume of alerts. If one wants to ensure a high security level then he must deal with large volumes of alerts since any suspected event will be detected and an alert will be triggered. If, on the contrary, one wants to ensure an acceptable rate of false alarms, then this can be done only at a lower level of security. Note that the security level may change from day to day depending on the security recommendations and bulletins. Hence, it is essential for our system to provide a way for controlling the prediction/false a larm rate tradeoffs. In our approach, we propose to rely on the con fi dence of the prediction model to control the number of false alarms. 3. Alert preprocessing and redundancy/irrelevance elimination
In this section, we present the method we use for eliminating redundant and irrelevant alerts and preprocess raw IDMEF alerts in order to be analyzed by our severe attack prediction model. This method is inspired by the works of [3,4]. 3.1. From IDMEF to preprocessed alert windows
In this paper, severe attack prediction is viewed as a classi fi cation problem which a special kind of prediction. Hence, the analyzed data must be preprocessed and summarized into formatted input data composed of features with high information gain in order to ensure high prediction rates. Then in order to analyze a sequence of alerts Alert 1 , Alert 2 , ... , Alert k reported by one or multiple IDSs to determine if this alert sequence plausibly will lead or be followed by a severe attack Attack i , we need to preprocess the raw IDMEF alerts into attribute variables. In IDMEF standard, three dangerousness levels are de fi ned: low , medium and high . In our case, we analyze sequences of low and medium severity level alerts in order to predict high severity level attacks. Note that only the alerts with low/medium severity levels (often due to inoffensive attacks such as scans ) are concerned with the reduction and preprocessing. The alerts with high severity levels are those we want to predict. The alert preprocessing provides two reduction levels:
Regarding the criteria used for grouping the raw alerts, the alerts reported by IDSs can be grouped into several levels of granularity according to the alerts semantics, attack strategies and characteristics of the attacks to predict, etc. For instance, raw alerts can be summarized into alert windows by grouping alerts per IDSs, victims, attackers, etc. In our experimental studies, Snort IDS alerts are grouped according to their sid (alert signature identi fi er) and victim X  X  IP address and attacker X  X  IP address. Namely, an alert window  X  summarizes the alerts targeting the same victim and launched by the same attacker. Our choice is motivated by the nature of the severe attacks we want to predict which are not distributed and target only single Web applications.
It is important to note that the preprocessing of raw alerts data into presence/absence data ignores the sequential or temporal relationships between the alerts. Very often, the attackers execute on purpose some of their actions each time in a different sequence to escape detection. Our main objective in this paper is to show on real data that even if we ignore these sequential/temporal dependencies between alerts, we can still achieve good prediction/false alarm rate. Note also that our model exploits some correlations between attributes since it is based on non naive structures (in our experimental studies, we used MWST [11] to build our multi-net w here each network has a tree str ucture involving most of the strong correlations between alert features). These correlation relationships are automatically extracted from the training data. 4. Bayesian network-based model for predicting severe attacks
This section brie fl y presents Bayesian networks and their use as severe attack prediction models taking into account the IDSs X  reliability. 4.1. Bayesian network classi fi ers
Bayesian networks are powerful graphical models for modeling and reasoning with uncertain and complex information [20]. They are speci fi ed by: ii) A probabilistic component allowing to quantify the uncertainty relative to relationships between Bayesian networks are used for different types of inference such as the maximum a posteriori (MAP), most plausible explanation (MPE), etc. As for applications, they are used as expert systems for diagnosis, simulation, classi fi cation, etc.

Supervised classi fi cation consists in predicting the value of a target variable given the values of observed variables. Namely, given observed variables A 1 , ... , A n describing the objects to classify, it is required to predict the right value of the class variable C among a prede fi ned set of class instances. Bayesian network-based classi fi cation is a particular kind of probabilistic inference ensured by computing the greatest a posteriori probability of the class variable given the instance to classify. Namely, having an maximum a posteriori classi fi cation rule can be written as follows: evidence a 1 a 2 ..a n . This probability is computed using Bayes rule as follows: The denominator of Eq. (2) can be ignored because it does not depend on the different classes. Equation 2 means that posterior pr obabilities are proportional to the likeli hood of the evidence and class prior probabilities while the evidence probability is just a normalizing constant. Note that most works use naive or semi-naive Bayesian network classi fi ers such as TAN (Tree Augmented Naive Bayes) and BAN (Bayesian Network Augmented Naive Bayes) [9] which make strong assumptions in order to simplify the classi fi er X  X  structure learning from the data. The other Bayesian network classi fi ers require more general structure learning and parameter estimation (building the CPT tables).

Bayesian network-based approaches are widely used in many areas of computer security. More particularly, Bayesian classi fi ers are used in intrusion detection in several works such as [31,34,37]. In alert correlation, a Bayesian approach is used in [35] for alert fusion. Bayesian classi fi ers are also used in [3,4,15] where the authors use naive, TAN and other Bayesian network models for detecting attack plans and severe alerts. Note that all the works on detecting multi-step and severe attacks use naive or semi-naive prediction models. Note also that to the best of our knowledge, there is no work addressing the IDSs X  reliability handling. In the following, we propose a Bayesi an network-based approach for severe attack prediction. 4.2. Severe attack prediction as a classi fi cation problem
Severe attack prediction consists in analyzing sequences of alerts or audit events in order to predict future severe attacks. In this paper, severe attack prediction is modeled as a classi fi cation problem where the variables are de fi ned as follows: 1. Predictors ( attribute variables ) : The set of predictors (observed variables) is composed of the 2. Class variable: The class variable C represents the severe attacks variable whose domain involves Note that in order to automatically build the Bayesian network classi fi ers, the training data is labeled. Namely, for each alert vector (a presence/absence data representing an alert sequence) in the training data set, we associate a label denoting either the severe attack following this alert sequence or a special label NoSevereAttack in case where the alert sequence will not be followed by a severe attack. In our experimental studies, the labeling task is done automatically: we have only to list the severe attacks we want to predict. Then the preprocessing tool we developed for this purpose (see Section 7.1), checks for each preprocessed alert sequence whether a severe attack is detected. In the positive case, the current alert sequence terminates exactly at the detected severe attack and the alert window is shifted backwards to ensure that all the actions that led to this severe attack are present within the current alert sequence.
The main advantages of this approach for predicting severe attacks are: 1. Minimum expert intervention : the expert has just to identify the severe attacks he wants to predict 2. Easy deployment: one has just to preprocess the alerts logs in real-time to extract the predictors 3. Easy update: the prediction model can be easily updated and tuned by automatically relearning 4.3. Bayesian multi-net classi fi ers
In standard Bayesian classi fi ers, there is a unique network which encodes the in fl uence relationships relative to all the training data. However, the independence relationships are not the same over the different classes. More particularly, in our severe attack prediction application, each severe attack is correlated (in the statistical/causal sense) only with a small and speci fi c set of other alerts most of time because several attacks are undertaken by worms and scripts executing the same malicious events. For instance, the attack WEB-IIS CodeRed v 2 root.exe access whose Snort signature identi fi er ( sid ) is 1256 is correlated in our data set with alerts having sid = 2(( http inspect ) DOUBLE DECODING ATTACK ), 18(( http inspect ) WEBROOT DIRECTORY TRAVERSAL )and 1002 ( WEB-IIS cmd. exe access ) because this worm uses a directory traversal attack (causing alert with sid 18 and 2) in order to access the cmd.exe executable on MS Windows systems. As we will see in our experimental studies, local correlation modeling leads to better likelihood estimation for the classi fi cation task. Note that when most structure learning algorithms identify correlations using statistical tests, consequently the obtained network encodes mainly the correlations relative to the majority class. In a multi-net classi fi er, each class instance c i is associated with a network N c training instances belonging exclusively to the class c i . The a priori frequencies relative to the different classes can be encoded by a root node C representing the class variable [8] or just by a local probability distribution as in [9]. The generic procedure for learning a multi-net from empirical data is provided in Algorithm 1.
 Algorithm 1 shows that learning a Bayesian multi-net is performed by partitioning the training data set D into several partitions where each partition S i contains only the training instances sharing the same class c i . Note that learning a network on each S i can be done using a different algorithm and feature space since not all the feature are relevant for all classes. The multi-net based classi fi cation X  X  procedure is provided by Algorithm 2.

In [18,19], Bayesian multi-nets are considered as variants of unrestricted Bayesian classi fi ers. Authors more expressive and less complex than BANs. Moreover, multi-nets allow to update the model with minimum modi fi cations. For instance, in order to add a new class, one has just to learn an additional network for the added class. One can also update existent models by repeating the learning of local networks of the updated classes. In [8], author proposed approaches for selecting the branching variable A i that will be linked with the class variable C . Finally, multi-net classi fi ers offer the opportunity to choose a speci fi c learning algorithm and select the most appropriate features for each class. 5. Handling IDSs X  reliability
This section deals with the hand ling of IDSs reliability using Pear l X  X  virtual evidence method. 5.1. Reasoning with uncertain data: Pearl X  X  virtual evidence method
Pearl X  X  virtual evidence method [27] offers a natural way for handling and reasoning with uncertain evidence in the framework of probabilistic networ ks. In this method, the uncertainty indicates the con fi dence on the evidence: to what extent the evidence is believed to be true. In our context, if an IDS triggers an alert and we know (from past experience for example) that this event is a false alarm in 95% of the cases then we are in presence of uncertain evidence. The main idea of Pearl X  X  virtual evidence method is to recast the uncertainty relative to the uncertain evidence E on some virtual sure event  X  : the uncertainty regarding E is speci fi ed as the likelihood of  X  in the context of E .
 Example
Let us illustrate Pearl X  X  virtual evidence method on the simpli fi ed lung cancer problem presented by the network of Fig. 2.

According to the network of Fig. 2, if a patient has lung cancer (assume that the result of an infallible test is positive), then the probability that this patient is smoker is p (S = True/C = True) = 0.66. Assume now that the used medical tests revealing whether a patient has lung cancer or not are reliable at 95%. According to Pearl X  X  virtual evidence method, this uncertainty will be recasted on a virtual event (say T for Test ) as illustrated in network of Fig. 3.

Now, given a positive test saying that the considered individual has lung cancer, than the probability that this person smokes is p (S = True/T = True) = 0.65. In the following we provide our method for handling IDSs X  reliability for predicting severe attacks. 5.2. Handling IDSs X  reliability using Pearl X  X  virtual evidence method
In order to apply Pearl X  X  virtual evidence method for ef fi ciently handling IDSs X  reliability, we must fi rst assess the IDSs X  reliab ility by means of empir ical evaluations (an expert can examine for each alert type triggered by an IDS, the proportion of true/false alerts). An expert can also subjectively (by experience) fi x the reliability of the IDSs composing his intrusion detection infrastructure. Now, after assessing the reliability of the IDSs in triggering the alerts A 1 , ... , A n , the handling of the uncertainty regarding an alert sequence, proceeds as follows: 1. For each alert variable A i , add a child variable R i as a virtual evidence recasting the uncertainty 2. Each conditional probability distribution p ( R i /A i ) encodes the reliability that the observed values The example of Fig. 4 gives a tree-augmented naive Bayes network augmented with fi ve nodes R 1 , R 2 , R 3 , R 4 , R 5 for handling the uncertainty relative to variables A 1 , A 2 , A 3 , A 4 , A 5 respectively. associated with the actual malicious/norma l activities and they cannot be directly observed.
When analyzing an alert sequence r 1 r 2 ..r n (an instance of observation variables R 1 , ... , R n ), we compute argmax c complicated to assess the false/true positive rates than assessing the false/true negative rates which requires analyzing the whole activities (for example, all the network traf fi c) in order to evaluate the proportion of attacks that were not detected by the IDSs. In the following, we provide an ef fi cient mechanism for controlling the severe attack prediction/false alarm rate tradeoffs. 6. Controlling severe attack prediction/false alarm rate tradeoffs
This section presents our approach based on classi fi cation with reject option for controlling the severe attack prediction/false alarm rate tradeoffs. 6.1. Classi fi cation with reject option
Classi fi cation with reject option [10] is an ef fi cient solution allowing to identify and reject the data objects that will be probably misclassi fi ed. Indeed, in many application areas such medical diagnosis, military target identi fi cation, etc. it is better to reject (not classify) an object than misclassifying it. The reject option is crucial in our application especi ally for limiting the fals e alarm rates because the reliability of input s directly impacts the predictive and discrimination power of our prediction models (the greater the uncertainty in the input data, more dif fi cult will be the prediction of the nature of the analyzed alert sequence). Moreover, this approach allows the user to control the tradeoffs between the severe attach prediction and the underlying false alarm rates.

A classi fi cation model can be seen as a means of discriminating the frontiers de fi ned by the objects sharing the same class (as shown on illustration (a) of Fig. 5 where the classi fi er is represented by the line with reject option: 1. Ambiguity reject: As shown in illustration (b) of Fig. 5, in ambiguity reject the object to classify 2. Distance reject: This situation occurs when the instance to classify does not belong to any of the
The distance reject is often used for anomaly and outlier detection. For instance, we used a Bayesian network reject in [6] in order to detect novel attacks in network traf fi c. However, this reject is not relevant for controlling the severe attack prediction/false alarm rate tradeoffs since alert sequences are either followed by severe attacks or not (there is no other alternative to be captured by the distance rejection). The reader can refer to [22] for discussions on classi fi ers X  con fi dence evaluation and reject option rules interpretation. In the following, we present our approach for controlling the attack prediction/false alarm rate tradeoffs based on the ambiguity reject option. 6.2. Controlling severe attack prediction/false alarm rate tradeoffs
Bayesian network-based classi fi ers are naturally suitable for implementing the classi fi cation with reject option as classi fi cation is ensured by computing a posteriori probabilities of class instances given the data the instance to classify belongs to class instance c i . In our application, we are interested in controlling the attack prediction/false alarm rate tradeoffs according to the contexts and needs of each fi nal user. For example, a user may want an alert correlation tool with high con fi dence (with minimum false alerts). This objective requires rejecting the alert sequences where the tool is not very con fi dent. Let us de fi ne the con fi dence concept in our application as the unsigned value of the difference of the probability that the attack. This measure is adapted from the works of Leray et al. [22] on classi fi ers con fi dence evaluation. It is done by measuring the gap between the probab ility that the alert sequence will not be followed by a severe attack (namely p ( c i =0 /a 1 ..a n ) ) and the greatest probability that the event will be followed by a severe attack. Namely, where c i = 0 denotes the class instance representing alert sequences that are not followed by severe attacks while class instance c i = 0 denote class instances associated with the severe attacks to predict. will/will not be followed by a severe attack. Hence, a user wanting to reject all alert sequences where the probability of not being an attack is not twice the probab ility that they are severe attacks is done by setting the reject threshold L to the value 1/3. Note that the a posteriori probabilities of the classes given the alert sequence to analyze must be normalized in order to be used for implementing the reject option. Then, the Bayesian decision rule of Eq. 1 will be reformulated as follows: The value  X  denotes the reject decision, namely the instance to be classi fi ed is rejected because the condition  X  ( a 1 ..a n ) &gt;L is not satis fi ed. In the following, we provide our experimental studies on real IDMEF alert corpus. 7. Experimental studies
Our experimental studies are carried on real and recent alert log fi les produced by Snort IDS monitoring a university campus network. These alert logs represent three months activity collected during summer 2007 within the framework of PLACID project 6 dealing with probabilistic and logic approaches for alarm correlation in intrusion detection. The input to our system consists in alerts generated by Snort IDS gathered in IDMEF format. In the following we brie fl y present our alert preprocessing tool needed both in the training phase (for preparing the labeled training data) and analysis phase for predicting severe attacks. 7.1. Data preparation: IDMEF alert preprocessing
In order to preprocess IDMEF alerts into CSV data that can be used for training our models, we developed an alert preprocessing tool taking as inputs IDMEF alert log fi les and preprocessing options and outputs alert sequences in CSV format.

Among the preprocessing options provided by the user in the preprocessing option fi le, we fi nd:  X  Window duration ( in secs ) : the duration of the alert windows can be de fi ned by the user according  X  Predictors set: This set provides the alert identi fi ers ( sid ) that will be used as predictor variables.  X  Severe attacks set: This set lists the set of severe attack identi fi ers ( sid ) the user wants to predict.
Note that our preprocessing tool is used in off-line mode to provide the labeled data for training the prediction models. More precisely, our preprocessing tool proceeds for each alert log fi le as follows 1. It selects from each IDMEF alert only the needed information for our form atting task ( Source and 2. The alerts are sorted according to their source/destination IP addresses. 3. The sorted alert sequences are formatted into presence/absence CSV data as explained in Section 3. The labeling task is done automatically following the attack identi fi ers listed in the severe attacks set. In prediction mode, the tool preprocesses in real-time sequences of raw IDMEF alerts generated by IDSs and submits the preprocessed alerts for analysis. Note that in order to determine the relevant alerts for our task, we fi rst preprocessed the raw IDMEF alerts into CSV data (where each possible alert is associated with an alert variable in the presence/absence data sequences). Then using the information gain measure selection, we selected only relevant alert variables for our prediction task. Note also that the labeling is done automatically as explained in Section 4.2. However, if the detected severe attacks are false alarms, then the labeling will be done incorrectly. This issue can be dealt with by excluding the alerts revealing mistakenly severe attacks.
 7.2. Training and testing data sets
Our data sets are obtained from real IDMEF alerts reported during three months by the Snort IDS. We fi rst preprocessed the fi rst month of collected alerts in order to build the training data set and preprocessed the second month to build the testing set. Table 1 provides details on the severe attacks we used in our experimentations.

Among the severe attacks detected by Snort, we selected 9 Web-based severe attacks to predict on the basis of the alerts that often precede/prepare these severe attacks. All these attacks are associated with a high severity level and are targeting either Web servers or related web-based applications. Such attacks may result in arbitrary code execution and full control of the targeted system. Interested readers can refer to Snort signature database for additional information and references on these attacks.
The fi rst month (used to build the training data set) contains 333566 IDMEF alerts while the second month (used to build the testing set) is composed of 288425 alerts. In the training set, there are 23454 alerts with high severity level, 86679 with medium severity level and 223433 with low severity level alerts (similar proportions of low, medium and high level alerts are found in the testing set). Let us now focus on the redundant/irre levant elimination task perform ed by the preprocessing tool. Recall that the redundant alerts are eliminated by representing all the occurrences of an alert Alert i within the same time window by a unique variable telling whether this alert has been reported or not.
In order to eliminate the irrelevant alerts for our prediction task, we fi rst extracted all the existing alerts involving the same attackers and victims as the severe attacks then using the information gain [36] selection feature procedure, we selected a subset of relevant features. Then among more than two hundreds of low/medium candidate alerts composing our training and testing sets, we selected only 27 Snort alerts whose sid are 2, 3, 4, 7, 15, 16, 18, 839, 853, 882, 895, 1013, 1112, 1141, 1142, 1147, 1214, 1288, 1301, 1478, 1767, 1852, 2142, 2280, 2286, 2565 and 2566. The remaining input alerts are not relevant for predicting the selected 9 Web-based attacks. Note that the feature selection task does not require any expert knowledge while it allows to train a model on a large data set by reducing the feature space. Hence, each sequence of raw IDMEF alerts will be preprocessed into an alert window of 27 variables. Hence, using a 2 hours alert window, the 333566 IDMEF (resp. 223433) alerts composing the training (resp. testing) set are preprocessed into 48409 (resp. 49301) alert window vectors where each vector is composed of 27 variables. Note that the feature extraction/labeling process is similar to the works of [3,7].

In the following, we report our experimental results where Experimentation 1 compares the severe attack prediction model using a Bayesian multi-net with a C4.5 decision tree [28], a naive Bayes classi fi er [9] and a Bayesian network built with the MWST [11] algorithm. In Experimentation 2 we provide our results on handling the IDS X  reliability while Experimentation 3 provides our experimental results on controlling the prediction/false alarm rate tradeoffs. In all these experimentations, the models are built (resp. evaluated) on the same training data set of Table 1 (resp. testing data set). 7.3. Experimentation 1: Severe attack prediction using Bayesian multi-nets
In order to evaluate the effectiveness of our multi-net classi fi er, we compare it with a C4.5 decision tree, a naive Bayes classi fi er and a network classi fi er built using MWST algorithm [11] which is a structure learning algorithm using the mutual information measure that rapidly builds simple and ef fi cient tree structures [17]. As for the multi-net, we also used the MWST algorithm to build the networks representing each class of alert sequences. Note that the C4.5 is among the most ef fi cient classi fi ers in the literature and it is capable to handle both categorical and numerical features. As for the naive Bayes classi fi er, it is the simplest form of Bayesian network classi fi ers based on the strong assumption that the attribute features are independent in the context of the class node. In spite of this simplifying assumption, the performances of this model are very competitive on problems where there is enough training data. We trained the four classi fi ers on the same training set and evaluated them on the same testing set of Table 1. The results of this experimentation are given in Table 2.

Table 2 compares the results of the C4.5 decision tree, naive Bayes classi fi er, MWST classi fi er and our multi-net classi fi er with respect to their prediction rate and the false alarm rate. The results of Table 2 show that the multi-net outperforms both the decision tree, naive Bayes and MWST classi fi ers regarding the overall prediction and the false alert rates. In particular, the multi-net classi fi er predicted 76,92% of the severe attacks at a false alarm rate of 1,58% (29 false alarms/day) while the naive Bayes (resp. MWST) classi fi er triggered 3.21% (58 false alarms/day) (resp. 3,10% (56 false alarms/day)). This performance is due to the better modeling of each class leading to better estimation of the likelihoods of the alert sequences to analyze. It is important to note that the three classi fi ers failed to predict some severe attacks mainly because of the imbalance of class frequencies in the training set. This is for instance the reason why the severe attack with Sid = 1256 ( WEB-IIS CodeRed v 2 root.exe access ) which is represented in the training set only by 2 instances was not predicted. The C4.5 decision tree achieved the second best false alarm rate (1.66%) but its prediction rate is the worst (only 72,26%). Finally, note that the naive and MWST classi fi ers achieved comparable prediction rates but suffer from high false alarm rates which is a crucial issue when using IDSs.
 7.4. Experimentation 2: Handling IDSs X  reliability in Bayesian multi-nets
In this experimentation, we are interested in the effect of taking into account the IDSs X  reliability of the prediction/false alarm rate tradeoffs. We implemented the virtual evidence method as follows:  X  For each alert A i used as a predictor, we fi rst checked in Snort X  X  database whether the rule associated  X  When an alert sequence is submitted for analysis, the prediction is performed on the Bayesian
In order to evaluate the effectiveness of handling IDSs X  reliability in Bayesian multi-nets, we compare it with a standard Bayesian network-based classi fi er built using MWST as in Experimentation 1 .Table3 gives the results of handling the reliability of Snort IDS producing t he alert sequences we analyze.
The results of Table 3 show that the VE-Multinet classi fi er (the multi-net model implementing the virtual evidence method for handling the reliability of Snort IDS) achieves comparable prediction rates with respect to the standard multi-net classi fi er Multinet but signi fi cantly reduces the false alarm rate down to 0,74% (the false alarm rate was decreased from 29 down to only 13 false alarms/day). Note that this result is achieved by handling the true/false positive reliability relative to only three alerts (those having sid = 882, sid = 1288 and sid = 1852) constituting the majority of fa lse alerts triggered by Snort in our data sets (see [32] for an analysis of these false alarms triggered by Snort). Such results are very promising but require a rigorous reliability assessment and handling false negatives which are very time consuming tasks. Indeed, in order to ef fi ciently use our approach, one has to rigorously assess both the true/false positive and negative rates which is a very time consuming tasks. More speci fi cally, in order to assess the true/false positive rates, one has to check for each alert A i the proportion of A i instances which actually correspond to real attacks. In order to assess the true/false negative rates, all the network traf fi c should be analyzed in order to evaluate the proportion of attacks that were not detected by the IDSs. Clearly, assessing the true/false positive and negative rates are very complicated and time consuming tasks. Moreover, there is a need to reevaluate them more frequently in order to take into account new menaces and attacks, etc. 7.5. Experimentation 3: Controlling prediction/false alarm rate tradeoffs
In Experimentation 1 and Experimentation 2 , we showed that the Bayesian multi-net prediction model offers the best prediction/false alarm rate and naturally allows to handle the IDSs X  reliability improving the model X  X  performances. However, in real situations it is important to have means of con fi guring the prediction model so as not to exceed a given false alarm rate. In Experimentation 3 , we provide our results on using the ambiguity reject for controlling the attack prediction/false alarm rate tradeoffs. Note that we de fi ned different con fi dence levels L and we used the same Bayesian multi-net classi fi er as in Experimentation 1 .

Table 4 provides detailed results on the effect of using the reject option in order to control the attack prediction/false alarm rate tradeoffs. As expected, the false alarm rate decreases proportionally to the value of the con fi dence level L . However, the prediction rates of some severe attacks also decrease. Figure 7 gives the variation of the prediction rate ( FPRate ) and the rejection rate ( RRate ) at different con fi dence levels L . The rejection rate gives the proportion of alert sequences that were rejected by our severe attack predictor.

The results of Fig. 7 show that the TPRate decreases slightly as we augment the value of the con fi dence level L while the rejection rate RRate increases signi fi cantly. Indeed, Fig. 7 shows that it is possible to achieve a very high severe attack prediction rate while rejecting only a small amount of the analyzed alert sequences (see TPRate and RRate when L = 0.33). However, when L issetto0.9(toforce the model to take decisions only when it is very con fi dent) the proportion of alert sequences which are rejected attains 31,92%. As for the evolution of the false alarm rate ( FPRate ) at the different reject rates, Fig. 8 gives the FPRate of the same experimentation of Fig. 7.

Figure 8 shows that the false alarm rate can be controlled by setting the appropriate value for the reject rate. The results of this fi gure can guide the user to fi xthethreshold ( for the reject option ) according to the acceptable false alarm rate he wants not to exceed. Clearly, our approach offers an ef fi cient, fl exible and con fi gurable model for predicting severe attacks. Moreover, our approach requires minimum expert knowledge and the computational complexity of handling IDSs X  reliability and implementing the reject option is nearly the same as the standard classi fi cation based on Bayesian networks.
Because of the class imbalance in our testing data set and the difference in misclassi fi cation costs, the evaluation of our prediction model based only on the prediction rate ( TPRate ) is not suf fi cient. Indeed, our testing data set is dominated by alerts sequences which mostly are not followed by severe attacks while the misclassi fi cation cost of a false alarm and the cost of a missed attack (false negative) are clearly not equivalent. Therefore, additional experimentations are carried out in order to draw the ROC curve 7 of our prediction model. A ROC curve [16] allows to visualize the fl uctuations existing between the True Positive Rate (in our case, the true prediction rate TPRate ) and the corresponding false positive rate (denoted in this paper FPRate ) which are the two most important measurements of IDSs performance. More precisely, a ROC curve is a two-dimensional graph where the TPRate is plotted on the Y-axis while the FPRate is plotted on the X-axis. Each couple TPRate and its corresponding FPRate is represented by a point in the ROC curve. Note that in order to draw the ROC curves evaluating our severe attack prediction model, we used the method proposed in [16] and sorted testing data instances after computing for each testing alert sequence a score measuring how much the instance in hand is not likely a severe attack. This score is the a posteriori probability of not being a severe attack. Figure 9 gives the ROC curves of our prediction model evaluated on the testing data of Table 1.
The graph of Fig. 9 shows the variation of our model prediction rate with respect to different reject rates. This ROC curve shows that our reject option improves the prediction model and allows an expert to know which rejection rate will correspond to each prediction rate he may want to guarantee. Clearly, Fig. 9 shows that our prediction model exploiting the reject option is more effective than the same model without using the prediction/false alarm tradeoffs mechanism. The experimental results provided in this section clearly show the effectiveness of our prediction model for predicting severe attacks and controlling the prediction/false alarm rate tradeoffs. 8. Conclusions
This paper addressed crucial issues in the fi eld of alert correlation consisting in ef fi cient Bayesian network modeling/reasoning for handling IDSs X  reliability and controlling the prediction/false alarm rate tradeoffs. More speci fi cally, we proposed a method allowing to cope with the huge amount of alerts daily triggered by IDSs. In additio n to redundant/irrelevant alert elimination, this method also allows to cope with the class imbalance problem by encoding the local correlations leading to better likelihood estimation and pred iction performance. Then we proposed to take into account th e reliability of IDSs X  as it is a relevant information on the inputs used by the alert correlation engines. Finally, in order to better control the prediction/false alarm rate tradeoffs, we proposed an approach based on classi fi cation with reject option allowing to reject alert sequences where the prediction model has not enough con fi dence to make good predictions. Handling IDSs X  reliability and implementing the re ject option are naturally and easily implemented using Bayesian network-based classi fi ers. Our experimental results are very promising especially when one appropriately assesses the reliability of the IDSs and the con fi dence levels.

As future directions, it is very interesting to t ake into account and exploi t the IDSs X  reliability not only during the prediction phase, but also when building the prediction models from empirical data. Indeed, while reasoning with unreliable information (data provided by unreliable sources) has received much interest, all the approaches for learning probabilistic graphical models (and other prediction models) implicitly assume that training data is cleaned and ignore the reliability of sources even if such information is available. Our objective is to pr opose heuristics for learni ng probabilistic graphical models talking into account the available informatio n on the IDSs X  reliability. We also plan to carry out supplementary experimental studies in order to detect some recent attack scenarios such as the Con fi cker worm propagation which infected thousands of computers since November 2008.
 Acknowledgments
This work is supported by the (ANR) SETIN 2006 PL ACID project (Probabilistic graphical models and Logics for Alarm Correlation in Intrusion Detection http://placid.insa-rouen.fr/).
 References
