 Learning curves are a convenient way of characterising the performance that can be achieved with machine learning algorithms: they give the generalisation error as a function of the number of training examples n , averaged over all datasets of size n under appropriate assumptions about the data-generating process. Such a characterization is particularly useful in the case of non-parametric approaches such as Gaussian processes (GPs) [1], where in contrast to the parametric case [2] there is no generic classification of possible learning curves.
 Here we study GP regression, where a real-valued output function f ( x ) is to be learned. Qualita-tively, GP learning curves are relatively well understood for the scenario where the inputs x come from a continuous space, typically R n [3, 4, 5, 6, 7, 8, 9, 10, 11]. However, except in the limit of large n , or for very specific situations like one-dimensional inputs [3], the learning curves cannot be calculated exactly. Here we show that this is possible for discrete input spaces where similarity between input points can be represented as a graph whose edges connect similar points, inspired by work at last year X  X  NIPS that developed simple approximations for this scenario [12].
 There are many potential application domains where learning of such functions of discrete inputs x could be relevant, for example if x is a research paper whose impact f ( x ) we would like to predict; the similarity graph could then be constructed on the basis of shared authorship. Or we could be trying to learn functions on generic symbol strings x , for example ones characterizing protein amino acid sequences, and the similarity graph would have edges between homologous molecules. Our aim is to find out how well GP regression can perform in such discrete domains; alternative inference approaches including online algorithms [13, 14, 15, 16] would also be interesting to study but are outside the scope of the present paper. We focus on large sparse random graphs, where each node is connected only to a finite number of other nodes even though the overall number of nodes in the graph is large. In section 2 we give a brief overview of GP regression and summarize the approximation for the learning curves used in previous work [4, 8, 12]. Section 3 then explains our method: following a similar approach in [17] for random matrix spectra, we write down the belief propagation equations for a given graph in the form normally used in the cavity method [18] of statistical mechanics, and then translate them to graphs drawn from a random graph ensemble. Because for sparse random graphs typical loop lengths grow with the graph size, the belief propagation equations and hence our learning curve predictions should become exact for large graphs.
 Section 4 compares the predictions with simulation results for Poisson (Erdos-Renyi) graphs, where each edge is independently present with some small probability, and random regular graphs, where each node has the same degree (number of neighbours). The new predictions are indeed very ac-curate, and substantially more so than previous approximations. In section 4.1 we discuss in more detail the relationship between our work and these approximations to rationalize where the strongest deviations occur. Finally, section 5 summarises our results and discusses open questions and direc-tions for future work. Gaussian processes have become a well known machine learning technique used in a wide range of areas, see e.g. [19, 20, 21]. One reason for their success is the intuitive way that a priori information about the function to be learned is transparently encoded by the covariance and mean functions of the GP.
 A GP is a Gaussian prior over functions f with a fixed covariance function (kernel) C and mean function (assumed to be 0 ) 1 . In the simplest case the likelihood is also Gaussian, i.e. we assume clean function values f i  X  with i.i.d. Gaussian noise of variance  X  2 . Then the posterior distribution over functions is, from Bayes X  theorem P ( f | D )  X  P ( f ) P ( D | f ) : We consider GPs in discrete spaces, where each input is a node of a graph and can therefore be given a discrete label i as anticipated above; f i is the associated function value. If the graph has V nodes, the covariance function is then just a V  X  V matrix.
 A number of possible forms for covariance functions on graphs have been proposed. We will focus on the relatively flexible random walk covariance function [22], Here A is the adjacency matrix of the graph, with A ij = 1 if nodes i and j are connected by an edge, and 0 otherwise; D = diag { d 1 ,...,d V } is a diagonal matrix containing the degrees of the nodes in the graph ( d i = P j A ij ). One can easily see the relationship to a random walk: the unnormalised covariance function is a (symmetrised) p -step  X  X azy X  random walk, with probability a  X  1 of moving to a neighbouring node at each step. The prior thus assumes that function values up to a distance p along the graph are correlated with each other, to an extent determined by the hyperparameter a  X  1 . The constant  X  will be chosen throughout to normalise C so that 1 V P i C ii = 1 , which corresponds to setting the average prior variance of the function values to unity.
 Our main concern in this paper are GP learning curves in discrete input spaces. The learning curve describes how the average generalisation error (mean square error) decreases with the number of examples N . Qualitatively, it gives the rate at which one would expect a GP to learn a function in the average case . The generalisation error on an ensemble of graphs is given by where f is the uncorrupted (clean) teacher or target function, and  X  f is the posterior mean function of the GP which gives the function values we predict on the basis of the data D . It is worth noting that the generalisation error for a graph ensemble contains an additional average over this ensem-ble. As is standard in the study of learning curves we have assumed a matched scenario where the posterior P ( f | D ) for our predictions is also the posterior over the underlying target functions. The generalisation error is then the Bayes error, and is given by the average posterior variance. Sollich [4] and later Opper [7] with a more general replica approach showed that for continuous input spaces a reasonable approximation to the learning curve could be expressed as the solution of the following self-consistent equation: Here the  X   X  are appropriately defined eigenvalues of the covariance function. The motivation for our study is work presented at NIPS2009 [12], which demonstrated that this approximation can also be used in discrete domains, but is not always accurate. Studying random walk and diffusion kernels [22] on random regular graphs, the authors showed that although the eigenvalue-based ap-proximation is reasonable for both the large and the small N limits, it fails to accurately predict the learning curve in the important transition region between these two extremes, drastically so for low noise variances  X  2 .
 In the next section we will show that this shortcoming can be overcome by the cavity method (belief propagation) which explicitly takes advantage of the sparse structure of the underlying graph. This will give an accurate approximation for the learning curves in a broad range of ensembles of sparse random graphs. The cavity method was developed in statistical physics [18] but is closely related to belief propa-gation; for a good overview of these and other mean field methods, see e.g. [23]. We begin with equation (3). Because we only need the posterior variance in the matched case considered here, we can shift f so that  X  f = 0 ; f i is then the deviation of the function value at node i from the posterior mean. In this notation, the Bayes error is where P ( f | D ) now contains in the exponent only the terms from (1) that are quadratic in f . To set up the cavity method, we begin by defining a generating or partition function Z , for a fixed graph, as An auxiliary parameter  X  has been added here to allow us to represent the Bayes error as =  X  lim  X   X  0 (2 /V )  X   X  X   X  log Z  X  D, graphs . The dependence on the dataset D appears in Z only through number of examples seen at node i , then P  X  f 2 i partition function in equation (6) is not yet suitable for an application of the cavity method since the inverse covariance function cannot be written explicitly and generates interaction terms f i f j between nodes that can be far away from each other along the graph. To eliminate the inverse of the covariance function we therefore perform a Fourier transform on the first term in the exponent, the f i , and one finds Substituting the explicit form of the covariance function (2) into equation (7) we have where we have written the power in equation (2) as a binomial sum and defined c q = p ! / [ q !( p  X  q )!] a  X  q (1  X  a  X  1 ) p  X  q / X  .
 For p &gt; 1 , equation (8) still has interactions with more than the immediate neighbours. To solve for q  X  1 and h 0 = h . These definitions are enforced via Dirac delta-functions, each i and q  X  1 Substituting this into equation (8) gives the key advantage that now the adjacency matrix appears only linearly in the exponent, so that we have interactions only across edges of the graph. Rescaling interactions finally yields We now have the partition function of a (complex-valued) Gaussian graphical model. By differenti-ating log Z with respect to  X  , keeping track of  X  -dependent prefactors not written above, one finds that the Bayes error is, and so we need the marginal distributions of the h 0 i . This is where the cavity method enters: for a large random graph the structure is locally treelike, so that if node i were eliminated the correspond-ing subgraphs (locally trees) rooted at the neighbours j  X  X  ( i ) of i would become independent [17]. graphs, giving the cavity update equations One sees that these equations are solved self-consistently by complex-valued Gaussian distributions with mean zero and covariance matrices V ( i ) j . By performing the Gaussian integrals in the cavity update equations (11) explicitly, these equations then take the rather simple form where we have defined the (2 p + 1)  X  (2 p + 1) matrices
O Finally we need to translate these equations to an ensemble of large sparse graphs. Each ensemble is characterised by the distribution p ( d ) of the degrees d i , with every graph that has the desired degree distribution being assigned the same probability. Instead of individual cavity covariance graph. Picking at random an edge ( i,j ) of a graph, the probability that node j will have degree d j is then p ( d j ) d j / factor is the average degree  X  d .) Using again the locally treelike structure, the incoming (to node j ) cavity covariances V ( j ) k will be i.i.d. samples from W ( V ) . Thus a fixed point of the cavity update equations corresponds to a fixed point of an update equation for W ( V ) : to V k . The average is over the distribution over the number of examples n  X  n j at node j in the dataset D . Assuming for simplicity that examples are drawn with uniform input probability across all nodes, this distribution is simply n  X  Poisson (  X  ) in the limit of large N and V at fixed  X  = N/V . In general equation (13)  X  which can also be formally derived using the replica approach [24]  X  cannot be solved analytically, but we can solve it numerically using a standard population dynamics method [25]. Once we have W ( V ) , the Bayes error can be found from the graph ensemble version of equation (10), which is obtained by inserting the explicit expression for  X  ( h 0 i ) 2  X  in terms of the cavity marginals of the neighbouring nodes, and replacing the average over nodes with an average over p ( d ) : The number of examples at the node is again to be averaged over n  X  Poisson (  X  ) . The subscript  X 00 X  indicates the top left element of the matrix, which determines the variance of h 0 . singular when n = 0 and  X   X  0 . We split off the n -dependence of the matrix inverse by writing appearing above can then be expressed using the Woodbury formula as To extract the (0,0)-element (top left) as required we multiply by e T 0  X  X  X  e 0 . After some simplifica-tion the  X   X  0 limit can then be taken, with the result This has a simple interpretation: the cavity marginals of the neighbours provide an effective Gaus-sian prior for each node, whose inverse variance is d ( M  X  1 ) 00 .
 The self-consistency equation (13) for W ( V ) and the expression (16) for the resulting Bayes error are our main results. They allow us to predict learning curves as a function of the number of exam-ples per node,  X  , for arbitrary degree distributions p ( d ) of our random graph ensemble providing the graphs are sparse, and for arbitrary noise level  X  2 and covariance function hyperparameters p and a .
 We note briefly that in graphs with isolated nodes ( d = 0 ), one has to be slightly careful as already in the definition of the covariance function (2) one should replace D  X  D +  X  I to avoid division by zero, taking  X   X  0 at the end. For d = 0 one then finds in the expression (16) that ( M  X  1 ) 00 = 1 c so that (  X  + d )( M  X  1 ) 00 =  X  ( M  X  1 ) 00 = 1 /c 0 . This is to be expected since isolated nodes each have a separate Gaussian prior with variance c 0 . We will begin by comparing the performance of our new cavity prediction (equation (16)) against the eigenvalue approximation (equation (4)) from [4, 7], for random regular graphs with degree 3 (so that p ( d ) =  X  d, 3 ). In this way we can exploit the work of [12], where the quality of the approximation (4) for this case was studied in some detail.
 Figure 1: (Left) A comparison of the cavity prediction (solid line with triangles) against the eigen-value approximation (dashed line) for the learning curves for random regular graphs of degree 3 , and against simulation results for graphs with V = 500 nodes (solid line with circles). Random walk kernel with p = 1 , a = 2 ; noise level as shown. (Right) As before with p = 10 , a = 2 . (Bottom) Similarly for Poisson (Erdos-Renyi) graphs with c = 3 .
 As can be seen in figure 1 (left) &amp; (right) the cavity approach is accurate along the entire learning simulation results. Importantly, the cavity approach predicts even the midsection of the learning curve for intermediate values of  X  , where the eigenvalue prediction clearly fails. The deviations between cavity theory and the eigenvalue predictions are largest in this central part because at this point fluctuations in the number examples seen at each node have the greatest effect. Indeed, for much smaller  X  , the dataset does not contain any examples from many of the nodes, i.e. n = 0 is dominant and fluctuations towards larger n have low probability. For large  X  , the dataset typically contains many examples for each node and Poisson fluctuations around the average value n =  X  are small. The fluctuation effects for intermediate  X  are suppressed when the noise level  X  2 is large, because then the generalisation error in the range of intermediate  X  is still fairly close to its initial value (  X  = 0 ). But for the smaller noise levels fluctuations in the number of examples for each node can have a large effect, and correspondingly the eigenvalue prediction becomes very poor for intermediate  X  . We discuss this further in section 4.1.
 Comparing figure 1 (left) and (right), it can also be seen that unlike the eigenvalue-based approxi-mation, the cavity prediction for the learning curve does not deteriorate as p is varied towards lower values. Similar conclusions apply with regard to changes of a (results not shown). Next we consider Poisson (Erdos-Renyi) graphs, where each edge is present independently with probability c/V [26]. This leads to a Poisson distribution of degrees, p ( d ) = e  X  c c d /d ! . Figure 1 (bottom) shows the performance of our cavity prediction for this graph ensemble with c = 3 for a GP with p = 10 , a = 2 , in comparison to simulation results for V = 500 . The cavity prediction clearly outperforms the eigenvalue-based approximation and again remains accurate even in the central part of the learning curve. Taken together, the results for random regular and Poisson graphs clearly confirm our expectation that the cavity prediction for the learning curve that we have derived should be exact for large graphs. It is worth noting that our new cavity prediction will work for arbitrary degree distributions and is limited only by the assumption of graph sparsity. 4.1 Why the eigenvalue approximation fails The derivation of the eigenvalue approximation (4) by Opper in [8] gives some insight into when and how this approximation breaks down. Opper takes equation (6) and uses the replica trick to write  X  log Z  X  D = lim n  X  0 1 n log  X  Z n  X  D . The average of Z n is calculated for integer n and then appropriately continued to n  X  0 . The required n th power of equation (6) is in our case The dataset average, over n i  X  Poisson (  X  ) , then gives  X  Z n  X  D = If one now wants to proceed without explicitly exploiting the sparse graph structure, one has to approximate the exponential term in the exponent. Opper does this using a variational approximation for the distribution of the f a , of Gaussian form, and this eventually leads to the approximation (4) for the learning curve. This approach is evidently justified for large  X  2 , where a Taylor expansion of the exponential term in (18) can be truncated after the quadratic term. For small noise levels, on the other hand, the Gaussian variational approach clearly does not capture all the details of the fluctuations in the numbers of examples n i . By comparison, in this paper, using the cavity method we are able to retain the average over D explicitly, without the need to approximate the distribution of the n i . The result of this is that the section of the learning curve where fluctuations in numbers of examples play a large role is captured accurately, while the Gaussian variational (eigenvalue) approach can give wildly inaccurate results there. In this paper we have studied the learning curves of GP regression on large random graphs. In a significant advance on the work of [12], we showed that the approximations for learning curves proposed by Sollich [4] and Opper [7] for continuous input spaces can be greatly improved upon in the graph case, by using the cavity method. We argued that the resulting predictions should in fact become exact in the limit of large random graphs.
 Section 3 derived the learning curve approximation using the cavity method for arbitrary degree distributions . We defined a generating function Z (equation (6)) from which the generalisation error can be obtained by differentiation. We then rewrote this using Fourier transforms (equation (7)) and introduced additional variables (equation (9)) to get Z into the required form for a cavity approach: the partition function of a complex-valued Gaussian graphical model. By standard arguments we then derived the cavity update equations for a fixed graph (equation (12)). Finally we generalised from these to graph ensembles (equation (13)), taking the limit of large graph size. The resulting prediction for the generalisation error (equation (16)) has an intuitively appealing interpretation, where each node in the graph learns subject to an effective (and data-dependent) Gaussian prior provided by its neighbours.
 In section 4 we compared our new prediction to the eigenvalue approximation results in [12]. We showed that our new method is far more accurate in the challenging midsection of the learning curves than the eigenvalue version, both for random regular and Poisson graph ensembles (figure 1). Subsection 4.1 discusses why the older approximation, derived from a replica perspective in [7], is inaccurate compared to the cavity method. To retain tractable averages in continuous input spaces, resulting in the inaccurate predictions seen in figure 1. On graphs one is able to perform this average explicitly when calculating cavity updates and the resulting Bayes error, giving a far more accurate prediction of the learning curves.
 Although the learning curves predicted using the cavity method cover a broad range of graph en-ensembles (for instance graphs with community structure) that cannot be generated by imposing only the degree distribution. Indeed, an important assumption in the current work is that small loops are rare whilst in community graphs, where nodes exhibit preferential attachment, there can be many small loops. We are in the process of analysing GP learning on such graphs using the approach of Rogers et al. [27], where community graphs are modelled as having a sparse superstructure joining clusters of densely connected nodes.
 Following previous studies [12], we have in this paper set the scale of the covariance function by normalising the average prior covariance over all nodes. For the Poisson graph case our learning curve simulations then show, however, that there can be large variations in the local prior variances C ii , while from the Bayesian modelling point of view it would seem more plausible to use covariance functions where all C ii = 1 . This could be achieved by pre-and post-multiplying the random walk covariance matrix by an appropriate diagonal matrix. We hope to study this modified covariance function in future, and to extend the cavity prediction for the learning curves to this case. It would also be interesting to expand our approach to model mismatch, where we assume the data-generating process is a GP with hyperparameters that differ from those of the GP being used for inference. This was studied for continuous input spaces in [10]; equally interesting would be a study of mismatch with a fixed target function as analysed by Opper et al. [8]. It should further be useful to study the case of mismatched graphs , rather than hyperparameters. This is relevant because frequently in real world learning one will have only partial knowledge of the graph structure, for instance in metabolic networks when not all of the pathways have been discovered, or social networks where friendships are continuously being made and broken.
 GPs on graphs, to see if the work of Chai [28] can be extended to this scenario. One would hope that, as seen with the learning curves for single output GPs in this paper, input domains defined by graphs might allow simplifications in the analysis and provide more accurate bounds or even exact predictions.
 Finally, it would be worth extending the study of graph mismatch to the case of evolving graphs and functions. Here spatio-temporal GP regression could be employed to predict functions changing over time, perhaps including a model based approach as in [29] to account for the evolving graph structure.

