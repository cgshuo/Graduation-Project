 Microblogging systems such as Twitter and Sina Weibo 1 have become important communication and social networking too ls. Recently, mining individual users X  topical interests from their messages (tweets) attracts much attention. It has been demonstrated to be useful in many applications such as user clustering [9], friend recommendation [17], influential user detection [23], and user behavior prediction [2]. Various statistical topic modeling approaches have been applied to modeling users X  interests on microblog [2], [17], [23], [25], [28]. However, it remains a non-trivial task with the following challenges. 1) Data sparseness and topic diversity. Microblog messages are short (re-stricted to 140 characters) and may not provide sufficient information. Therefore, taking each individual message as a short document and directly applying topic modeling approaches may not work well [9], [28]. That is, the data sparseness problem occurs. To tackle the problem, previous studies proposed to aggregate messages posted by each user into a  X  X ong X  document and employ topic modeling approaches on aggregated documents [9], [17], [23]. However, such an aggregation strategy ignores the fact that topics discussed in different messages are usually different. Aggregating these topic-diverse messages into a single document and characterizing it with a unified topic distribution may be inaccurate. That is, the topic diversity problem occurs. We need to effectively deal with both problems. 2) Joint modeling of users and messages. In some applications (e.g., per-sonalized message recommendation), not only users X  topical interests but also messages X  topic distributions need to be identified (e.g., to judge how much a user likes a message at semantic level). Therefore, modeling users and messages simultaneously is always preferred. 3) Scalability and efficiency. With the rapid growth of microblogging systems, more and more data is created every day . User modeling techniques which can efficiently handle large-scale datasets are sorely needed.

To address these challenges, we propose a novel user modeling approach, re-ferred to as User Message Model (UMM). UMM is a hierarchical topic model in which users and their messages are modeled by a hierarchy of topics. Each user corresponds to a topic distribution, representing his/her topical interests. Each message posted by the user also corresponds to a topic distribution, with the user X  X  topic distribution as the prior. Topics are represented as distributions over words. We further propose a distributed version of UMM which can efficiently handle large-scale datasets containing millions of users.

The advantages of UMM are as follows. 1) UMM can effectively deal with both the data sparseness problem and the topic diversity problem which previous methods suffer from. 2) UMM can jointly model users and messages in a unified framework. 3) UMM is easy to be implemented through distributed computing, and can efficiently handle large-scale datasets. To our knowledge, UMM is the first user modeling approach that can address all the challenges discussed above. Experimental results on both Sina Weibo and Twitter datasets show that UMM can effectively model users X  interests on microblog. It can achieve better results than previous methods in topic discovery and message recommendation. Experimental results on a large-scale Twitter dataset, containing about 2 million users and 50 million messages, demonstrate the efficiency and scalability of the distributed version of UMM. Mining users X  topical interests from th eir messages (tweets) is a key problem in microblog analysis. A straightforward approach is to directly apply the Latent Dirichlet Allocation (LDA) [3] model on individual messages and simply repre-sent each user by aggregating the topic distributions of his/her messages [22]. However, as messages on microblog are short, the data sparseness problem occurs. To tackle this problem, previous studies proposed to aggregate messages by user and then employ the LDA model on aggregated messages (user-level LDA) [7], [9]. Hong and Davison empirically demonstrat ed that user-level LDA can achieve bet-ter performance in user and message cla ssification [9]. The effectiveness of user-level LDA in influential user detection and friend recommendation was further demonstrated in [17] and [23]. Ahmed et al. later proposed a time-varying user-level LDA model to capture the dynamics o f users X  topical interests [2]. Recently, Xu et al. employed a slightly modified Author-Topic Model (ATM) [20] to discover user interests on Twitter [25,26]. In fact, ATM is equivalent to user-level LDA when applied to microblog data [28]. Since different messages posted by the same user may discuss different topics, user-level LDA is plagued by the topic diversity problem. The proposed UMM can address both the data sparseness problem and the topic diversity problem.

Besides automatically discovered topi cs, users X  interests can be represented in other forms, e.g., user specified tags [22], [24], ontology-based categories [15], and automatically extracted entities [1]. However, these methods rely on either external knowledge or data labeling, which is beyond the scope of this paper. There are also other studies on microblog topic modeling [5], [6], [11], [18,19], [27], but they do not focus on identifying users X  interests. 3.1 Model Suppose that we are given a set of microblog data consisting of U users, and each user u has M u messages. Each message m (posted by user u ) is represented as w mn comes from a vocabulary
User Message Model (UMM) is a hierarchi cal topic model tha t characterizes users and messages in a unified framework, based on the following assumptions. 1) There exist K topics and each topic  X  k is a multinomial distribution over the vocabulary. 2) The first layer of the hierarchy consists of the users. Each user u is associated with a multinomial distribution  X  u over the topics, representing his/her interests. 3) The second layer consists of the messages. Each message m is also associated with a multinomial distribution  X  u m over the topics. The message X  X  topic distribution  X  u m is controlled by the user X  X  topic distribution  X  u .4)The third layer consists of the words. Each word in message m is generated according to  X  u m . Fig. 1 shows the graphical represent ation and the generative process. Note that  X  u m is sampled from an asymmetric Dirichlet distribution with parameter  X   X  u . Here,  X  u is a K -dimensional vector, denoting the topic distribution of user u ;  X  u is a scalar, controlling how a message X  X  topic distribution might vary from the user X  X ;  X  u  X  u means multiplying each dimension of  X  u by  X  u .
UMM differs from Hierarchical Dirichlet Process (HDP) [21]. 1) UMM fully exploits the user-message-word hierarchy to perform better user modeling on microblog, particularly to address the data sparseness and topic diversity prob-lems, while HDP is not specially designed for microblog data. 2) UMM keeps a fixed number of topics, while the topic number in HDP is flexible. 3.2 Inference We employ Gibbs sampling [8] to perf orm inference. Consider message m posted by user u .Forthe n -th word, the conditional posterior probability of its topic assignment z u mn can be calculated as: topic assignments except z u mn ; N u z | m the number of times a word in message m has been assigned to topic z ; N z | u the number of times a word generated by user u (no matter which message it comes from) has been assigned to topic z , and N  X | u = z N z | u ; N w | z the number of times word w has been assigned to assignment of z u mn . Fig. 2 gives the pseudo code for a single Gibbs iteration.
After obtaining the topic assignments and the counts,  X  u ,  X  u m ,and  X  z can be estimated as: the w -th dimension of  X  z .
 3.3 Advantages We compare UMM with Message Model (MM), User Model (UM), and Author-Topic Model (ATM) [20], and demonstrate its advantages. MM is a message-level LDA model, where each individual message is treated as a document [22]. As messages on microblog are short, MM suffers from the data sparseness problem. UM is a user-level LDA model, where messages posted by the same user are ag-gregated into a single document [9], [17], [23]. As different messages may discuss different topics, UM suffers from the topic diversity problem. ATM is equivalent to UM when applied to microblog data, where each message belongs to a single user [28]. It also suffers from the topic diversity problem.

As opposed to the existing methods, UMM naturally models users and mes-sages in a unified framework, and effectivel y deals with both the data sparseness and the topic diversity problems. Consider the Gibbs sampling procedure listed in Equation (1). The first term expresses the probability of picking a specific topic in a message, and the second the probability of picking a specific word from the selected topic. To pick a topic, o ne can rely on information either from the current message or from the current user. In the former case, a topic is picked with probability proportional to the number of times the other words in the cur-rent message have been assigned to the topic, i.e., N u z | m case, a topic is picked with probability proportional to the number of times the other words generated by the current user have been assigned to the topic, i.e., way, UMM leverages the  X  X pecific but insufficient X  message-level information and the  X  X ich but diverse X  user-level inform ation, and can effectively address both problems. Table 1 further compares the time and space complexities of MM, UM, and UMM, where N is the number of words in the whole collection and T the number of Gibbs iterations. We can see that UMM is comparable with MM and UM in terms of both time and space complexities. 3.4 ScalingUponHadoop To enhance the efficiency and scalability, we borrow the idea of AD-LDA [16] and design a distributed version of UMM, called Approximate Distributed UMM (AD-UMM). We implement AD-UMM on Hadoop 2 , an open-source software framework that supports data-intensive distributed applications.
AD-UMM distributes the U users over P machines, with U p = U P users and their messages on each machine. Specifically, let w = { w u mn } denote the set of words in the whole collection, and z = { z u mn } the set of corresponding topic distribute them over the P machines, ensuring that messages posted by the same user are shuffled to the same ma chine. User-specific counts N z | u and message-specific counts N u z | m are likewise partitioned and distributed. Topic-specific counts N w | z and N  X | z are broadcasted to all the machines. Each machine p maintains its own copy, denoted by N ( p ) w | z and N ( p )  X | z .
In each iteration, AD-UMM first conducts local Gibbs sampling on each ma-chine independently, and then performs a global update across all the machines. During the local Gibbs sampling step on machine p , for each message m shuffled to the machine, the topic assignment of word w u mn is sampled according to:
N ( p ) w | z are updated. To merge back to a single set of word-topic counts N w | z , a global update is performed across all the machines: The whole procedure is shown in Fig. 3.

Table 1 compares the time and space complexities of UMM and AD-UMM, where we have assumed that users and me ssages are almost evenly distributed. As the total number of words in the collection (i.e., N ) is usually much larger than the vocabulary size (i.e., W ), it is clear that AD-UMM outperforms UMM in terms of both time and space complexities.
 We have conducted three experiments. The first two tested the performance of UMM in topic discovery and message recommendation, and the third one tested the efficiency and scalability of AD-UMM. 4.1 Datasets The first two experiments were conducted on two datasets: Weibo and Twitter. The Weibo dataset consists of 2,446 randomly sampled users and all the messages posted and re-posted by them in three months (Aug. 2012  X  Oct. 2012). The messages are in Chinese. The Twitter dataset consists of 2,596 randomly sampled users and all the messages posted and re-posted by them in three months (Jul. 2009  X  Sep. 2009). The messages are in English. For re-posted messages, only the original contents were retained. URLs, hash tags (# #, #Twitter), and mentions (@ , @User) were further removed. For the Weibo dataset, the messages were segmented with the Stanford Chinese Word Segmenter 3 .Forboth datasets, stop words and words whose frequencies in the whole dataset are less than 5 were removed. Messages which co ntain less than 5 words and users who have less than 10 messages were further removed.

We split each dataset into two parts according to the time stamps: messages in the first two months were used for topic discovery (denoted as  X  X eibo-I X  and  X  X witter-I X ) and messages in the third month were used for message recommen-dation (denoted as  X  X eibo-II X  and  X  X witter-II X ). Since in the recommendation task messages were further filtered by a five-minute-window (as described in Section 4.3), Weibo-II and Twitter-II have much fewer users and messages.
The third experiment was conducted on a large-scale Twitter dataset (denoted as  X  X witter-III X ), consisting of about 2 million randomly sampled users and the messages posted and re-posted by them in three months (Jul. 2009  X  Sep. 2009). Twitter-III was preprocessed in a similar way, and finally we got about 50 million messages. Table 2 gives some statistics of the datasets. 4.2 Topic Discovery The first experiment tested the perfor mance of UMM in topic discovery, and made comparison with UM and MM. In the methods, K was set to 100,  X  (the Dirichlet prior on the topic-word distribution) was set to 0.01, and  X  (the Dirichlet prior on the user-topic/message-topic distribution) was set to 10 /K . In UMM,  X  u was set to 10 for all users.

Table 3 shows the top-weighted topica l interests of two randomly selected users on Weibo-I, generated by UMM, UM, and MM. The user biographies are also shown for evaluation. From the results, we can see that 1) The readability of the UMM topics is better than or equal to that of the UM and MM topics. 4 Almost all the UMM topics are readable, while some of the UM and MM topics are hard to understand. For example, in the first UM topic for the first user, the word  X  (life) X  is mixed with  X  (economy) X  and  X  (commerce) X .
 And in the first MM topic for the second user, the words  X  (movie) X  and  X  (director) X  are mixed with  X  (music) X  and  X  (voice) X . 2) UMM characterizes users X  interests better than UM and MM. The top interests of the users discovered by UMM are quite repres entative. However, for the first user, the top interests discovered by MM are  X  (real estate) X ,  X  (society) X ,  X  (information security) X , and  X  (electronic products) X , where the last two seem less representative. A nd for the second user, the top interests discovered by UM are pretty vague and not so representative.

Table 4 further shows the top-weighted topics of two randomly selected mes-sages generated by UMM on Weibo-I. The color of each word indicates the topic from which it is supposed to be generated. From the results, we can see that UMM can also effectively capture the topics discussed in microblog messages, and the topic assignments of the words are also reasonable. We have conducted the same experiments on Twitter-I and observed similar phenomena. 4.3 Message Recommendation The second experiment tested the per formance of UMM in message recommen-dation. We formalize the recommendation task as a Learning to Rank prob-lem [14]. In training, a ranking model is constructed with the data consisting of users, messages, and labels (whether the users have re-posted, i.e., have shown interests in the messages). In ranking, given a user, a list of candidate messages are sorted by using the ranking model.

The data in Weibo-II and Twitter-II were transformed for the ranking task, consisting of user-message pairs and th eir labels. The label is positive if the message has been re-posted by the user, and is negative if the message might have been seen by the user but has not been re-posted by him. 5 We randomly split each dataset into 5 parts by user and conducted 5-fold cross-validation.
Table 5 lists the features used in the ranking model. The seven basic features are suggested in [4] and [10]. To calculate the two term matching features, mes-sages, user X  X  historical posts, and their profile descriptions are represented as term frequency vectors. The topic matching features are calculated by UMM, UM, and MM models trained on Weibo-I and Twitter-I. Given user u and mes-sage m , the topic matching score is calculated as the dot product of their topic representations: s ( u, m )=  X  u , X  m . We retain top 5 topics in  X  u and  X  m ,and truncate other topics. As UM/MM cannot directly output topic representations for messages/users, we calculate them using the learned topic assignments.
When training topic models, we set K =10 , 20 , 40 , 60 , 80 , 100 , 200 , 400 , 600, 800 , 1000. The other parameters were set in the same way as in Section 4.2. We employed Ranking SVM [13] to trai n the ranking model. Parameter c was set in [0 , 2] with interval of 0.1, and the other parameters were set to default values. We tested the settings of using the basic features only (denoted as  X  X asic X ), the basic features plus the term matching features (denoted as  X  X asic+Term X ), and the basic features, the term matching features, and one of the topic matching features (denoted as  X  X asic+Term+UMM X  for example). For evaluation, we employed a standard information retrieval metric of NDCG [12].
 Table 6 reports the recommendation a ccuracies on Weibo-II and Twitter-II. The results indicate that 1) Topic matching features are useful in message recommendation. They can significantly (t-test, p-value &lt; 0 . 05) improve the accuracies achieved by using only the basic and term matching features. 2) UMM performs the best among the three topic models. The improvements of UMM over MM and UM are statistically significant on Weibo-II (t-test, p-value &lt; 0 . 05). 3) Content features (term matching and topic matching features) are more useful on Weibo-II than on Twitter-II, because more contents can be written in Chinese than in English with limited number of characters. 4.4 Scalability of AD-UMM We first compared the efficiency of AD-UMM and UMM on Twitter-I. We built a 10-machine mini Hadoop cluster, each of which has a 2-core 2.5GHZ CPU and 2GB memory. In the cluster, 9 machines were used for distributed comput-ing and 1 for scheduling and monitoring. AD-UMM was implemented on the Hadoop cluster, while UMM was implemented on a single machine. In UMM, with the limited 2GB memory, we set K in { 50 , 60 , 70 } . In AD-UMM, we set K in { 50 , 100 , 200 , 500 } . The other parameters were s et in the same way as in Sec-tion 4.2. Fig. 4 reports the average execution time per iteration (sec.) of UMM and AD-UMM on Twitter-I. The results indicate that AD-UMM is much more efficient than UMM, particularly when the number of topics gets large.
We further tested the scalability of AD-UMM on Twitter-III. Fig. 5 (left) shows the average execution time per iteration (min.) of AD-UMM when K (number of topics) equals 500, with P (number of machines) varying from 4 to 9. Fig. 5 (right) shows the execution time when P equals 9, with K varying in { 500 , 1000 , 2000 , 5000 } . Here,  X  X ocal Gibbs Sampling X  and  X  X lobal Update X  refer to the time costed in the local Gibbs sampling and global update steps respectively, and  X  X otal X  means the total time. The results indicate that 1) The execution time decreases linearly as the number of machines increases. 2) The execution time increases linearly as the nu mber of topics increases. As a result, it is practical for AD-UMM to handle huge number of users, messages, and topics with an appropriate number of machines. We have proposed a new approach to mining users X  interests on microblog, called User Message Model (UMM). UMM works b etter than the existing methods, because it can 1) deal with the data sparseness and topic diversity problems, 2) jointly model users and messages in a unified framework, and 3) efficiently handle large-scale datasets. Experimental results show that 1) UMM indeed performs better in topic discovery and message recommendation, and 2) distributed UMM can efficiently handle large-scale datasets. As future work, we plan to apply UMM to various real-world applications and test its performances.
 Acknowledgment. This work was done when the first author visited the Noah X  X  Ark Lab of Huawei Technologies.

