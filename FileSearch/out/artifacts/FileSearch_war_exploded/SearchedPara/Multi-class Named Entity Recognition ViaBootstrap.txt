 Supervised learning for Named Entity R ecognition (NER) ha s been studied thor-oughly and has become the dominant technique [1, 2, 3, 4]. However, this ap-proach requires hand-tagged training data, which is nontrivial to generate. Even more effort is needed to apply systems of this kind to a new domain of interest, since one needs to annotate a new training corpus by hand. Therefore, super-vised learning for NER is used mainly in well-known domains like news and biomedical texts.

Unsupervised learning [5, 6, 7, 8, 9], by contrast, requires no manually an-notated data at all. Therefore, this approach increases inter-domain portability. The common framework of this approach is known as  X  X ootstrapping X  [6, 8, 9], that is, from a list of some seed named entities, the system will discover many extraction patterns, a subset of which is selected to be the  X  X ood X  set, which is then used to discover more seed entities, and so forth.

Unsupervised frameworks for NER use ext raction patterns to e xtract entities, and many types of patterns have been proposed. Yangarber [6] used string-level representation of extraction patterns, that is, used only the surrounding text in a context window. Nevertheless, string-level patterns usually have limitations due to lack of syntactic information. Incorporating the parts of speech tends to help; the predicate X  X rgument model [5] is of this type. A further improvement on the predicate X  X rgument model [5] is the dependency sub-tree model proposed by Sudo et al. [10]. Since it is designed for Relation Extraction, it aims to extract relationships between entities recogn ized by a Named Entity (NE) recognizer. Thus, one needs an NE recognizer for this type of pattern. For example, with the sentence,  X  X  smiling Palestinian suicide bomber triggered a massive explosion in downtown Jerusalem, X  1 firstly, the NE recognizer understands that  X  X  smiling Palestinian suicide bomber X  is a &lt; PERSON &gt; and  X  X owntown Jerusalem X  is a &lt; LOCATION &gt; . The sentence is then generalized with the NE tag in place of the actual text:  X  &lt; PERSON &gt; triggered a massive explosion in &lt; LOCATION &gt; . X  The dependency tree-based pattern obta ined from this generalized sentence cap-tures the relation between those two entities. In this paper, we show that sub-tree patterns can be effectively integrated int o the framework of bootstrapping NER, rather than using an NE tagger for the work. Since each sentence can produce a large number of sub-trees, we also propose an efficient method to compute them.
Since bootstrapping uses the entities l earned from each iteration as seeds for the next ones, any false seed will misl ead the next iteration of learning and might lead to even more false seeds, which degrades the performance of the entire learning process. Therefore, we introduce the technique of simultaneous bootstrapping of multiple classes, which can dramatically improve the quality of the seeds obtained at each iteration an d hence increase th e quality of the final learning results.
 The main contributions of this paper are: (i) we apply sub-tree models to the NER task with an efficient computational method with beneficial results; (ii) we show the advantage of simultaneous bootstrapping of multiple classes to im-prove the quality of learning. In the following sections we focus on these points. Section 2 describes the bootstrapping framework with dependency tree-based patterns and introduces a method to efficiently compute the large number of generated patterns. Section 3 describes the advantages of bootstrapping from multiple classes. Experimental result s are presented in Section 4. Section 5 con-tains an overview of some related works. Finally, Section 6 gives concluding remarks and describes future paths for our research. 2.1 Pattern Acquisition From the list of seed entities in each cate gory, our system first retrieves all sen-tences that contain any of them. Occurre nces of these seeds are then replaced by a generalized concept &lt; C &gt; denoting their category (see Table 1). In our ex-periment, we use four categories: APPROACH ( X  &lt; APPR &gt;  X ) such as  X  X axi-mum Entropy Models X , TASK ( X  &lt; TASK &gt;  X ) such as  X  X amed Entity Recogni-tion X , TOOL ( X  &lt; TOOL &gt;  X ) such as  X  X VMLight X , and DATASET ( X  &lt; COL &gt;  X ) such as  X  X all Street Journal X . We use the Stanford Parser [16] to parse these generalized sentences to obtain dependency trees. Then we apply a rightmost expansion-based algorithm for sub-tree discovery [14] to generate all sub-trees of them. Each of these sub-trees is an extraction pattern, and these patterns form the set of potential patterns  X  . Fig. 1(a) shows the dependency tree obtained from the generalized sentence shown i n Table 1 and Fig. 1(b), (c) show some examples of patterns generated from this tree.
 2.2 Pattern Matching A tree-based pattern is said to match a target sentence if, (i) the pattern exclud-ing the generalized node is a sub-tree of the dependency tree obtained from that sentence, and (ii) the node on the target tree corresponding to the generalized node is a noun and is called the target node. The noun group ([Adj*Noun+]) con-taining this target node is considered to be the extraction target. Fig. 2 shows a matching between one tree-based pa ttern learned from the source sentence  X  Kernel functions allow SVMs to combine the input features at relatively low computational cost  X  (as shown in Section 2.1 above) against the target sentence  X  We employ Maximum Entropy models to combine diverse lexical, syntactic and semantic features derived from the text . X  We can see from the Fig. 2 that the pattern (on the left) is a sub-tree of the dependency tree of the target sentence (on the right), and  X  models  X  is the target node. Thus, the noun group containing  X  models  X  X  X he phrase  X  Maximum Entropy models  X  X  X s extracted as the entity.
After discovering a list of extraction patterns  X  for each category, our system starts to match all of them against all sentences in the entire corpus. If a pattern matches a sentence, the extraction tar get will be extracted as an entity (as  X  Max-imum Entropy models  X  in Fig. 2), which is then checked and labeled as follows.  X  Positive : An entity of category A is labeled as  X  X ositive X  when it has been  X  Negative : An entity of category A is labeled as  X  X egative X  when it has been  X  Unknown : An entity of category A is labeled as  X  X nknown X  when it has not
The limitation of dependency sub-trees models [10] is the very large number of patterns that need to be computed [12]. In our work, therefore, we take only patterns of maximum length five nodes, and their root node has to be either a noun or a verb. In each iteration, we observed the discovery of on average 1000 new potential patterns for each category. We needed to match all of these 1000 patterns against 2760 sentences in the entire corpus in each iteration to see whether they could extract any entities, which could then be used to check the accuracy of the potential patterns (please refer to Section 2.3). Exhaustively matching them against thousands of sentences is very time consuming, however there are actually only a small number of sentences that match each pattern, and the unmatched ones can be rejected with only a small amount of computation. IR-style Inverted File. We construct an IR-style inverted file for all sentences in the corpus. For each pattern to be matched, we only perform matching on sentences that contain all keywords of the pattern.
 Pattern Hierarchical Structure. Since patterns are actually trees, they have a hierarchical structure. This means that if a pattern does not match a target sentence, neither does its child. Therefore, each pattern only needs to be com-pared with those sentences which its parent matches. 2.3 Pattern Ranking To score the patterns in  X  , we use the scoring strategy proposed in [6]. The accuracy and confidence of the pattern p are defined as follows: where pos ( p ) is the number of unique positive entities that p extracts, neg ( p ) is the number of unique negative entities p extracts and ukn ( p )isthenumber of unique unknown entities p extracts. All patterns with an accuracy above a predefined threshold  X  will be selected and ranked by a measure given by: The top n patterns are then added to the lis t of accepted patterns for each category. Unknown entities extracted by all accepted patterns for a category will be considered candida te entities to be added to the list of seed entities for that category. Our next step is to select good entities from these as new seeds. 2.4 Entity Ranking We use the entity scoring strategy proposed in [6]. A score of an entity e is then defined as: The top m unknown entities with the highest scores extracted by accepted pat-terns for each category are then added to t he list of seed entities for that category, and the process from 2.1 to 2.4 is iterated until no new entities are found. The quality of seeds obtained in each iteration greatly affects the performance of the entire learning process. For example, if the learning process for finding extraction patterns for APPROACH (e.g., SVMs, Maximum Entropy Models) mistakes entities denoting TASK (e.g., word sense disambiguation) as new seeds in iteration k , it might then wrongly accept patte rns that actually extract TASK rather than APPROACH, and hence, it might mistake more TASK entities as seeds. As a result, the final set of learne d patterns for APPROACH will extract entities denoting both APPROACH and TASK, which is undesirable.

By bootstrapping from multiple classes simultaneously, we have the informa-tion about seeds from more than one cla ss. We can develop methods to exploit information about the seeds of these comp eting categories in order to guide the learning process to avoid mistakenly generating the wrong seeds. Our experi-ments show that a simple list of words created automatically X  X he Exception Lists X  X rom 10 starting seeds can improve the quality of seeds obtained in each iteration and dramatically improve the final learning results. 3.1 Exception List Construction Our bootstrapping system starts with 10 seeds for each category. The so-called Exception List is constructed also from only these 10 starting seeds, as described in Table 2 below.
 3.2 Exception List Usage Generally, the new entities discovered in iteration k will be used as seeds for iteration k + 1. In the stage of Pattern Acquisition for iteration k +1, for each category, we retrieve sentences contai ning any of its seeds to learn patterns. However, the seed for one category may actually be a seed for another due to a learning error. To prevent this from hap pening, for each retrieved sentence, we check whether the word appearing ri ght after the seed instance appears in the Exception Lists of any other classes. If it does appear, this instance is not likely to be a good seed. For instance, suppose the learning process mistakes  X  text categorization  X  as a seed for the class APPROACH. It should then know that  X  ...feature selection seems to be essential for some text categorization tasks  X  is not a good sentence from which to learn patterns for this class if  X  tasks  X  appears in the Exception List of TASK, meaning that  X  tasks  X  is more likely to come after entities of TASK. It should be noted that the simple Exception Lists constructed as described above are no t used to conclude that a new entity is a good seed. Instead, they are used to tell whether that entity is less likely to be a good seed for a particular class. In the example above, we do not conclude that  X  text categorization  X  is a good seed for TASK; instead, we say that it is less likely to be one for APPROACH.

Our experiments have shown that this simple method of exploiting informa-tion from competing categories dramati cally improves the performance of the NER system. We believe that the system of bootstrapping from multiple classes has great potential, and that more powerful methods, such as statistical tools, can give even better results. 4.1 Data Preparation We conducted experiments in the domain of Computer Science papers, extract-ing Computer Science-specific entities. This choice was made because the aim of an unsupervised approach is to eliminate time-consuming manual effort so that the approach can be applied to domains where no tagged data is available, and Computer Science text is such a domain. Moreover, entity recognition in Computer Science texts can provide useful information for researchers. For in-stance, if we can extract entities denoting approaches and tasks, we can then tell which approaches have been applied to which tasks. This obviously facilitates the process of literature review.

As our first attempt, we aimed to extract entities of four classes: APPROACH, such as  X  X aximum Entropy Models X , TASK, such as  X  X amed Entity Recogni-tion X , TOOL, such as  X  X VMLight X , and DATASET, such as  X  X all Street Jour-nal X . For each of the four classes, we manually constructed a list of common entities and submitted them to the Yahoo! search engine through the supported search API [17]. We took the top 20 returned pdf documents for each class. We then extracted sentences containi ng any instances of seeds and manually tagged these instances for evaluation. This process resulted in a collection of 2760 sentences with the following statistics.  X  Approach : 1000 sentences with 1456 instances.  X  Task : 1000 sentences with 1352 instances.  X  Tool : 380 sentences with 436 instances.  X  Dataset : 380 sentences with 480 instances.
 We used the Stanford Parser [16] to parse sentences to obtain dependency trees. We selected m = n =5and  X  =0.8 in our experiments. 4.2 Experimental Results We evaluated our system by comparing i t to the one described in [6] since it was the closest work to ours. In [6], the author used a bootstrapping framework with string-based patterns that were g enerated from a context window of width w around the gener alized concept.
 Fig. 3 shows the learning curves for all four categories. For the APPROACH, TOOL and DATASET categories, we can s ee that tree-based patterns outper-form string-based patterns. Our analysis shows that string-based patterns can only work with sentences with minimal variation such as  X  ...X for text classi-fication  X  X nd X  ...Y for text categorization  X . Otherwise, they fail to capture the salient contexts from the sentence. For instance, from the source sentence  X  We employ &lt; APPR &gt; to combine diverse lexical, syntactic and semantic features de-rived from the text , X  some generated string-based patterns are showed in Table 3 below. None of them matche s the target sentence  X  Neuro-fuzzy models combine various features of neural networks with fuzzy models  X  since it fails to capture the important context  X  &lt; APPR &gt; ...combine ...features  X , in which the key words are noncontiguous. Tree-based patterns, on the contrary, can deal with this very well. Fig. 4 illustrates the effectiveness of tree-based patterns. They can capture the crucial context shared between the s ource and target sentences, which can be very different to the surface texts.

It should be noted that the practical precision of our system is underestimated in the evaluation conducted here. With sentences such as  X  Figure 5 compares the runtime of our algorithm only with bisecting k-means and HFTC  X , the tree-based patterns extract  X  our algorithm  X  as an entity of APPROACH. Since we aim to extract the name of the approach, we judge this as a wrong extraction. However,  X  our algorithm  X  is actually a co-reference of a name which is mentioned somewhere. Thus, we understate the precision of our system (with both string-based and tree-based patterns). Table 4 shows examples of such sentences. The system even recognizes approaches tha t do not have a name, for instance,  X  We applied our approach to translation from German to English in the Europarl cor-pus  X , even though  X  our approach  X  (which is not always named) is a combination of many modules or techniques. We are not tackling this problem now: since we want to study the effectiveness of tree-based patterns and a bootstrapping framework for NER, we have not applied co-reference resolution to our work, though we believe it would improve precision.

Fig. 3 also shows the effectiveness of t he Exception List. Either with string-based or tree-based patterns, systems with an Exception List outperform sys-tems without one most of the time, which means the simple Exception List can help prevent the system from generating the wrong entities as new seeds during learning. This indicates the potential of simultaneously bootstrapping from mul-tiple classes. We believe that employing more complicated methods can further improve the quality of learning. Riloff [11] employed a weakly supervised method to the problem of NER. The author only requires the training corpus to be labeled as relevant and irrelevant rather than fully tagged. From a set of handcrafted rule templates, their system learns extraction patterns and selects those that occur most frequently in the relevant corpus. The set of patterns learned is then filtered manually. This ap-proach greatly reduces human intervention, but human labor is still required to judge the training data as relevant or not and to compose rule templates.
To the best of our knowledge, the first work using bootstrapping for Infor-mation Extraction is DIPRE [8]. From a handful of examples of (book title, author) relations, their system searches the web for their instances, and extracts patterns that are then used to extract n ew instances of (book title, author). Their system only uses simple token-based patterns and simple methods to se-lect good patterns X  X ust the length of the pattern and the number of times it occurs. Snowball [9] improved DIPRE by only extracting relationships between entities recognized by a named entity tagger. However, their techniques were proposed mainly for Relation Extraction.

The prior work that is closest to ours is the one proposed in [6], which describes the unsupervised learning of disease names and locations via bootstrapping. Since their system uses only string-based patterns, it has limitations because of the variation of text. They also took advantage of competing categories to select more distinctive patterns, but they did not address the problem of how picking bad entities as seeds can mislead the entire learning process.

Sudo et al. [10] proposed dependency tree-based patterns for Relation Extrac-tion, and they have been used very succe ssfully in an On-Demand Information Extraction system [13]. Its powerful representation ability for Relation Extrac-tion has also been confirmed by Stevenson et al. [12]. However, since it is designed for Relation Extraction, it requires a n amed entity tagger to specify the bound-ary of entities for which the relationship is to be extracted. Therefore, we modify it for NER.

Etzioni et al. [15] proposed an unsupervised method to extract named entities from the web. This interesting scheme us es web statistics to improve the accuracy of extraction. However, since their system is targeted more at extracting entities than learning patterns, it is not related to our work. Nevertheless, the idea is inspiring, and we can incorporate it into the present framework in the future. Dependency tree-based extraction patterns have powerful representation abilities [10, 12, 13]. They were originally used to id entify relationships between entities extracted by a Named Entity recognizer . In this paper, we have adapted them to the task of NER X  X ather than using a Named Entity Recognizer for this task X  X ia a bootstrapping framework, and shown that this is also very effective. We also proposed an efficient method f or handling the large number of tree-based patterns. Finally, we introduced a novel scheme using bootstrapping from multiple classes to improve the quality of the seeds obtained in each iteration, improving the final learning results.

Our system can be improved in many aspects. We have implemented a very simple technique for taking advantage of multi-class bootstrapping X  X nly a list of words that co-occur with entities of i nterest more than twice. We believe that by employing statistical methods such as co-occurrence statistics, we can fur-ther improve the results. Moreover, since we take the noun group containing the extraction target given by patterns as an entity, some seeds obtained during learning are not  X  X lean X , for example,  X  X raditional speech recognition X  instead of  X  X peech recognition X . The system w ill miss sentences in which  X  X peech recog-nition X  occurs on its own, which are eve n more frequent. We have to implement techniques to remove these  X  X oisy X  words to improve the learning quality.
In this paper, we only work with the four fixed classes in which we are inter-ested. We believe that the selection of classes for learning will affect the final learning results, and we will investigate this problem in the future. We also be-lieve the integration of co-reference reso lution can help the system extract more precise entities, rather tha n only their co-references.

