 This paper addresses the problem of Named Entity Recog-nition in Query (NERQ), which involves detection of the named entity in a given query and classification of the named entity into predefined classes. NERQ is potentially useful in many applications in web search. The paper proposes tak-ing a probabilistic approach to the task using query log data and Latent Dirichlet Allocation. We consider contexts of a named entity (i.e., the remainders of queries after the named entity is removed) as words of a document, and classes of the named entity as topics. The topic model is constructed by a novel and general learning method referred to as WS-LDA (Weakly Supervised Latent Dirichlet Allocation), which em-ploys weakly supervised learning (rather than unsupervised learning) using partially labeled seed entities. Experimental results show that the proposed method based on WS-LDA can accurately perform NERQ, and outperform the baseline methods.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Query formulation Algorithms, Experimentation Named Entity Recognition, Topic Model
In this paper we address a novel problem in web search, namely Named Entity Recognition in Query (NERQ). In the task given a query we are to detect the named entity within the query and identify the most likely classes of the named entity. Classes of named entities can be, for instance,  X  X ook X ,  X  X ovie X ,  X  X ame X , and  X  X usic X . Given query  X  X arry potter walkthrough X , we detect  X  X arry potter X  as a named entity and assign  X  X ame X  to it as the most likely class,  X  X ovie X  and  X  X ook X  as less likely classes, and  X  X usic X  as unlikely class. This is because the context  X  X alkthrough X  strongly indicates that  X  X arry potter X  here is more likely to mean the Harry Potter game. (If the query is only  X  X arry potter X , then  X  X ook X  and  X  X ovie X  will be more plausible.)
NERQ is essentially useful for many applications in web search. According to our analysis, about 71% of search queries contain named entities. Identifying named entities in queries would help us to understand search intents better, and therefore provide better search. For example, in rele-vance search, we can improve ranking by treating named entity and context separately; in query suggestion, we can generate more relevant suggest ions, e.g.  X  X arry potter walk-through X   X   X  X arry potter cheats X  (context in the same class) or  X  X alo 3 walkthrough X  (entity in the same class). As far as we know, there was no previous work on NERQ. Traditionally Named Entity Recognition (NER) is mainly performed on natural language texts [6, 3, 8]. Usually a su-pervised learning approach is exploited and a set of features (e.g., whether  X  X r. X  occurs before the word, or whether the first letter of words is capitalized) is utilized. However, di-rect application of exiting NER technologies to NERQ would not perform well. This is because queries are usually very short (i.e., 2-3 words on aver age) and are not necessarily in standard form (e.g., all letters are in lower case), and thus the features are not sufficient for performing accurate NERQ.
 In this paper, we propose a new probabilistic approach to NERQ using query log data. Without loss of generality, a query having one named entity 1 is represented as a triple ( e, t, c ), where e denotes named entity, t context of e ,and c class of e .Notethat t can be empty (i.e. no context), e.g.  X  X arry potter X . Then the goal of NERQ here becomes to find the triple ( e, t, c ) for a given query q , which has the largest joint probability Pr( e, t, c ). The joint probability is factorized and then estimated by using query log and LDA.
In the LDA model, contexts of a named entity are repre-sented as words of a document, classes of the named entity are represented as topics of the model. The alignment be-tween model topics and predefined classes needs to be guar-anteed. To address this problem, we propose a weakly su-pervised learning method, referred to as WS-LDA (Weakly Supervised Latent Dirichlet Allocation), which can leverage the weak supervision from humans.
Our approach is in part inspired by the work [19]. They proposed a method for acquiring named entities from query log using templates. There are some differences between their work and ours. Our focus is NERQ while theirs is offline query log mining (there is no online prediction in their case). We employ a probabilistic model, while they take a deterministic approach in the sense that they assume that each named entity can only belong to one class.
Our contribution in this paper lies in the following points. (1) We have formalized the problem of NERQ. (2) We have proposed a novel method for conducting NERQ. (3) We have developed a new topic modeling method with weakly super-vised learning, i.e. WS-LDA.

The rest of the paper is organized as follows. Section 2 introduces related work. Section 3 defines the problem of NERQ and proposes a probabilistic approach to the task. Section 4 describes WS-LDA in details. Experimental re-sults are presented in Section 5. Conclusions are made in the last section.
Needless to say, query processing is critically important for web search. Previous work mainly focused on query seg-mentation, query parsing, query classification, and query log mining. As far as we know, however, there was no work on Named Entity Recognition in Query (NERQ) as defined in this paper.

Query segmentation separates a query into a number of units [20, 2, 25]. However, it does not identify named entities from units and also does not assign class labels to units. Syn-tactic parsing focuses on identifying linguistic structure of query [9, 12, 13]. Query classification falls into two groups: (1) classification according to search intent, such as informa-tional, navigational or transactional [7, 21, 16]; (2) classifi-cation according to semantics of query, such as  X  X hopping X  or  X  X iving X  [24, 1]. In query classification, the whole query is classified and there is no further analysis on the internal structure of query.

Query log mining is also related to our work, particularly that by Pa  X  sca [19, 18, 23]. Pa  X  sca proposes a method for acquiring named entities in a class from query log. A query is supposed to consist of an instance (named entity) and a template (context). A bootstrapping method is employed to mine instances of a class by utilizing the templates of the class, starting with a small number of seed instances. Their approach is deterministic and it can only work well in the cases in which a named entity belongs to a single class.
Named Entity Recognition is usually performed on text documents. Early work on NER was based on rules [11]. Recently machine learning techniques have been applied to NER, including supervised machine learning [6, 3], semi-supervised learning [8] and unsupervised learning [10]. Fea-tures are utilized in these approaches. However, directly ap-plying previous NER approaches to NERQ would not work well, because queries are usually short and not well formed.
Related work also includes topic modeling. Many topic models have been proposed including PLSI [15], LDA [5], and their extensions [14, 4]. Topic models have been utilized in topic discovery, document classification, citation analysis, and social network analysis. Our work exploits topic model-ing in a new application, and is particularly unique in that it trains LDA with a weekly supervised learning method. There are several methods proposed for performing super-vised learning of topic models [26, 17, 22]. In WS-LDA, we include weak supervision information as soft constraints in the objective function.
Named Entity Recognition in Query (NERQ) is a task defined as follows. Given a query, we try to detect the named entities within query and categorize the named entities into classes. The classes are from a predefined taxonomy.
We have conducted a manual analysis on 1,000 unique queries randomly selected from the search log of a commer-cial web search engine. It indicates that named entities ap-pear very frequently in queries and about 70% of the queries contain named entities. Furthermore, if a named entity oc-curs in a query, usually only that single named entity occurs and less than 1% of the queries contain two or more named entities. (In this paper, we focus on single-named-entity queries and take the processing of multiple named-entity queriesasfuturework).

Queries tend to be short (i.e., 2-3 words on average) and not well formed. It makes NERQ a challenging task. In this paper, we propose a probabilistic approach to the problem using query log data.
A single-named-entity query q can be represented as triples ( e, t, c ), where e denotes named entity, t denotes the context of e in q ,and c denotes the class of e .Notethat t is fur-ther expressed as  X  #  X  ,where  X  and  X  denote the left and right contexts respectively and # denotes a placeholder for named entity. Either  X  or  X  can be empty (e.g.  X # walk-through X ,  X  X yrics to # X ), or both can be empty (i.e.  X # X ). For example, for query  X  X arry potter walkthrough X  belong-ing to Game, the associated triple is ( X  X arry potter X ,  X # walkthrough X , Game).

The goal of NERQ is to detect the named entity e in query q , and assign the most likely class label c to e . Therefore, it can be accomplished by finding the triple ( e, t, c )  X  all possible triples, satisfying:
In Eqn. (1), conditional probability Pr( q | e, t, c )represents how likely query q is generated from triple ( e, t, c ). Note that given a triple, it will uniquely determine a query. There-fore, for fixed query q and triple ( e, t, c ), Pr( q | only be one or zero. That is, there are only two possibil-ities: either ( e, t, c ) generates q or ( e, t, c ) does not gener-ate q . For instance, query  X  X arry potter walkthrough X  can be generated by ( X  X arry potter X ,  X # walkthrough X ,  X  ), but not ( X  X alo 3 X ,  X # walkthrough X ,  X  ). We define G ( q )asthe set containing all possible triples that can generate query q (i.e., Pr( q | e, t, c ) equals one). Thus, the triple having largest probability ( e, t, c )  X  must be in G ( q ).

Therefore, to conduct NERQ we only need to calculate the joint probability Pr( e, t, c ) for each triple in G ( q ), which can be further factorized as below:
In Eqn. (2), we assume that Pr( t i | c )=Pr( t i | c, e i context only depends on class but not specific named entity. This assumption largely reduces the parameter space and thus makes the learning tractable. It is also a reasonable assumption in practice because classes usually share com-mon contexts, e.g.,  X  X usic X  takes  X # lyrics X  and  X # mp3 X  as contexts. There are contexts specific to named entities. However, due to data sparseness, one can hardly accurately estimate the probabilities of them.

The problem then becomes how to estimate Pr( e ), Pr( c | and Pr( t | c ). The number of such probabilities is extremely large, because there are an extremely large number of named entities and contexts. These include variants of named en-tities like  X  X arry potter 6 X  and  X  X arry potter and the half-blood prince X , and variants of contexts like  X # lyrics X ,  X  X yrics to # X , and even typos  X # lyrix X .
Suppose there is a training data set available, which con-tains triples from labeled queries T = { ( e i ,t i ,c i ) where ( e i ,t i ,c i ) denotes the  X  X rue X  triple for query q is the data size. Therefore, the learning problem can be formalized as:
If each named entity only belongs to one class, we can build the training data T easily (e.g., using the method in [19]). However, in reality named entities are usually am-biguous, e.g.,  X  X arry potter X  can belong to classes  X  X ook X ,  X  X ovie X , and  X  X ame X . It would be difficult as well as time-consuming to manually assign class labels to named entities in queries. Therefore, we collect training data T = { ( e and view class label c i as hidden variable. We also know the possible classes of each named entity in training. The learning problem with respect to the new training data T = { ( e i ,t i ) } becomes: max
In Eqn. (4), Pr( e i ) represents the popularity of named entity e i ,Pr( c | e i ) represents the likelihood of class c given named entity e i ,andPr( t i | c ) represents the likelihood of context t i given class c . The prior probability Pr( e i be estimated in different ways, independent of Pr( c | e i Pr( t i | c ). Suppose it is estimated as  X  Pr( e i ), then Eqn. (4) becomes: In this way, the learning problem becomes that of learning the probabilities in Eqn. (5), which form a topic model. In the topic model, a named entity corresponds to a document, contexts of a named entity correspond to words of the doc-ument, classes of a named entity correspond to topics of the model. Without loss of generality, we choose LDA as topic model in this paper. The topic model also has some special-ties. The topics (or classes) in the topic model are prede-fined and the possible topics of each document are given in training.
In this section, we explain how to use the topic model and query log to build a NERQ system. The processing consists of two stages, offline training and online prediction.
The offline training process is a combination of learning algorithm and data mining technique. There are two steps: (1) We first select some named entities as seeds, and assign possible classes to each of them. There might be multiple classes for each named entity. Note that the effort in this labeling is limited, since we only need to label a small num-ber of named entities (not queries). Then we scan the query log with the seed named entities and collect all the queries containing them. In this way, we can generate the training data ( e i ,t i ) and learn a topic model with regard to the seed named entities. There is a significant difference between conventional topic modeling and the learning here. First, the hidden topics (or classes) are predefined. Furthermore, the possible topics (classes) of a document (named entity) are given in weak supervision. We propose a method that can conduct weakly supervised learning of topic model, re-ferred to as WS-LDA (Weakly Supervised Latent Dirichlet Allocation). We will introduce the details in the next sec-tion. After this step, we obtain the estimated probabilities Pr( c | e ) for each seed named entity as well as Pr( t | class. (2) We scan the query log again with the previously learned contexts, collect all the queries containing the contexts, and extract the remainder of these queries as new named entities. (To ensure a high quality extraction, we heuristically make a threshold cut-off in this process). Next, WS-LDA is em-ployed to estimate Pr( c | e ) for the newly extracted named en-tities, with the probabilities Pr( t | c ) fixed. The probabilities Pr( e ) for newly extracted named entities are also estimated in this process. Specifically, we use the total frequency of queries containing e in the query log to approximate Pr( e ). The more frequently named entity e occurs, the larger prob-ability Pr( e ) will be.

In this way, we can estimate all the probabilities we need, the named entities and the classes, and store the estimated probabilities for efficient online prediction. The detailed al-gorithm for the offline training process is shown in Alg. 1.
In online prediction, we try to find the most likely triples in G ( q )foraquery q . We can generate G ( q )bysegment-ing the query into named entity and context in all possi-ble ways, and labeling segmented named entities with all possible classes. For each triple ( e, t, c )in G ( q ), the joint probability Pr( e, t, c ) is then calculated. The triples with highest probabilities are output results for NERQ. The de-tailed algorithm is shown in Alg. 2. The time complexity of the algorithm is O ( kn 2 ), where k denotes number of classes and n denotes number of words in a query. Since both k and n are very small, the prediction can be conducted very efficiently. We skip those queries which do not have named entity and context stored in the index.
The learning of topic model in our method for NERQ is a new problem, since the topics in the model are predefined, Algorithm 1 Offline Training Algorithm and the possible topics of document are given. We propose a new method for learning topic model, WS-LDA (Weakly Su-pervised Latent Dirichlet Allocation). WS-LDA is a general method and can be used in other applications.

For readability, we use conventional notations for docu-ment processing to describe the topic model. Specifically, contexts become  X  X ords X , contexts of a named entity form a  X  X ocument X , and classes of named entity correspond to  X  X op-ics X . Suppose that we have named entity  X  X arry potter X  with classes  X  X ovie X ,  X  X ook X , and  X  X ame X , and find three queries containing  X  X arry potter X  in the query log,  X  X arry potter movie X ,  X  X arry potter walkthrough X , and  X  X arry potter re-view X . Then the document with respect to  X  X arry potter X  will contain three words, i.e.  X # movie X ,  X # walkthrough X , and  X # review X , and the topics of the document will be  X  X ovie X ,  X  X ook X , and  X  X ame X . The relationship between query data and document data is summarized in Table 1.
Accordingly, we can rewrite the topic model in Eqn. (5) in the following form for better understanding: where e denotes a unique named entity in training data. Please note that  X  Pr( e i ) is dropped for clarity, and it can be easily integrated into the model. The first product in Eqn. (6) is on all the unique named entities in the training data (document level product), and the second one is on all the contexts of the same named entity (word level product). Algorithm 2 Online Prediction Algorithm
We first give the definition of the model in WS-LDA, which is the same as the conventional LDA. Suppose there is a corpus of M documents D = { w 1 , ..., w M } sharing K topics, and each document is a sequence of N words denoted by w = { w 1 , ..., w N } . It is assumed that the documents in the corpus D are generated by the following generative process: 1. Draw topic distribution  X   X  Dirichlet(  X  ) 2. For each word
Given parameters  X  = {  X  ,  X  } , we obtain the probability distribution of a document:
Finally, taking the product of probabilities of documents, we obtain the probability of corpus: p ( D|  X ) =
In NERQ, employing an unsupervised learning method to learn the topic model would not work. This is because the topics (classes) are explicitly predefined in NERQ. In con-trast, the topics in a conventional topic model are implicit and are automatically learned. There is no guarantee that the hidden topics learned by unsupervised learning method will be aligned with the predefined topics (classes). There-fore, we need to introduce supervision in the training process of the topic model.

The supervision is from the manual class labels on each seed named entity. The labels are not exclusive because ambiguity exists in named entities. For example,  X  X arry potter X  may have three classes, i.e.  X  X ovie X ,  X  X ook X , and  X  X ame X . We only ask human judges to make a judgment on whether a named entity can belong to a class or not. (It would be extremely hard for human judges to decide a probability of a named entity X  X  belonging to a class.) This type of labels is viewed as weak supervision for training. That means, in the terminology of topic modeling, we only assume that a document has high probabilities on labeled topics , but very low probabilities on unlabeled topics .
Given document w , the assigned class labels are repre-sented as y = { y 1 , ..., y K } ,where y i takes 1 or 0 when the i -th topic is or is not assigned to the document, and K de-notes the number of topics. The weak supervision informa-tion will be used as soft constraints in the objective function. WS-LDA tries to maximize the likelihood of data with re-spect to the model, and at the same time satisfy the soft constraints. The constraints are defined as follows. topic is or is not assigned to the n -th word. That is to say,  X  z represents the empirical probability of the i -th topic in document w . As we can see, maximizing the soft constraints actually can meet the following two goals at the same time: (1) the i -th latent topic is aligned to the i -th predefined class; and (2) the document w is mainly distributed over labeled classes.

Specifically, the objective function with respect to a doc-ument is defined as follows.
 where likelihood function p ( w |  X ) and soft constraint func-tion C ( y ,  X ) are represented as in Eqn. (7) and (8) respec-tively, and  X  is coefficient. If  X  equals 0, WS-LDA learning will degenerate to LDA learning.

Finally, substituting Eqn. (7) and (8) into Eqn. (9) and taking the sum over all documents, we obtain the following total objective function: O ( D|Y ,  X ) =
WS-LDA is equivalent to maximizing the objective func-tion in Eqn. (10). However, there might be no analytic solution for the problem as in conventional LDA learning. Therefore, we employ a variational method similar to that in [5] to approximate the posterior distribution of the latent variables. The approximate distribution is characterized by the following variational distribution: where  X  = {  X  , X  1: N } are variational parameters. Specifi-cally,  X  is Dirichlet parameter and  X  1: N are multi-nominal parameters.

Therefore, the objective function for a single document can be derived as follows.

O ( w | y ,  X ) = L ( X ;  X )+ D ( q (  X  , z |  X ) || p (  X  , z | w where
Minimizing the KL divergence between the variational posterior probability and the true posterior probability, de-mate distribution of p (  X  , z | w ,  X ). From Eqn. (11) we can see, this is equivalent to maximizing the lower bound L ( X ;  X ) on the objective function O ( w | y ,  X ) with respect to  X  which has the form O ( w | y ,  X )  X  L ( X ;  X ) Let  X  iv be p ( w v n =1 | z i =1)forword v . Each of the above terms can be expressed in the following equations (12)  X  (17): Notice that is used for the derivation of the term (17).

A variational expectation-maximization (EM) algorithm is then employed to estimate the model parameters  X . E-step : M-step :
Dirichlet parameter  X  canbeupdatedintheM-stepby using an efficient Newton-Raphson method in which the in-verted Hessian can be computed in linear time.
WS-LDA is also used in prediction. Specifically, we cal-culate the probability Pr( c | e ) for unseen named entities in NERQ. This corresponds to estimating the probability of topic given a new document w with the already estimated model  X . The estimation is then equivalent to approximat-ing the posterior topic distribution  X  of the new document w using the variational inference procedure. Notice this is the same as variational inference in conventional LDA (cf., [5]). We conducted experiments to verify the effectiveness of NERQ using WS-LDA. In this section, we first introduce the data sets used in experiments. Then we demonstrate the effectiveness of our approach in NERQ. Finally, we com-pare our method of NEQR using WS-LDA with two base-line methods, the deterministic approach proposed in [19], referred to as Determ, and conventional LDA (unsupervised learning), referred to as LDA. Note that although LDA is viewed as a baseline, there was no previous work on using LDA in NERQ. In the experiments  X  was set to 1 by default.
We made use of a real data set consisting of over 6billion queries, in which the number of unique queries is 930 million . The queries were randomly sampled from the query log of a commercial web search engine.

Four semantic classes were considered in our experiments, including  X  X ovie X ,  X  X ame X ,  X  X ook X , and  X  X usic X . Based on these classes, 180 named entities were selected from the web sites of Amazon, GameSpot, and Lyrics. Four human anno-tators labeled the classes of the named entities. If there was a disagreement among the annotators, we took a majority voting. Multiple classes can be assigned to one named en-tity. The annotated data was further divided into a training set containing 120 named entities and a test set containing 60 named entities.

The data set has the following characteristics. First, the overlap ratios between classes vary according to class pairs, e.g. the  X  X ovie X  and  X  X ame X  classes as well as the  X  X ovie X  and  X  X ook X  classes have higher overlap ratios (  X  20%). It seems natural because a movie is often adapted from a book with the same title, or a game is often inspired by a movie and named after the movie. Second, the selected classes differ from one another in terms of frequency in query log, e.g. named entities in  X  X ovie X  and  X  X ame X  classes occur more frequently than in  X  X ook X  and  X  X usic X  classes. Starting from the 120 seed named entities, we trained a WS-LDA model for conducting NERQ. Specifically, we ex-tracted all the possible contexts of seed named entities, and created a WS-LDA model as described in Sections 3 and 4. Finally we obtained 432,304 contexts and indexed about 1.5 million named entities.
We conducted NERQ on queries from a separate query log, which consists of about 12 million unique queries, and obtained about 0.14 million recognition results. We ran-domly sampled 400 queries from the recognition results for evaluation. Table 2 gives some examples from the data set and Table 3 shows the number of queries in the data set grouped by the predicted classes of named entities.
Each recognition result was then manually labeled as  X  X or-rect X  or  X  X ncorrect X . A result is viewed as correct if and only if both the detection and classification of the named entity are correct . The performance of NERQ is evaluated in terms of top N accuracy.  X  X op N accuracy X  here is defined in the following way: an algorithm output will be considered  X  X or-rect X  if at least one of top N results is labeled as  X  X orrect X .
Fig. 1 shows the accuracy of our NERQ method in terms of top N accuracy.  X  X verall X  stands for the average perfor-mance of NERQ over all classes. From Fig. 1 we can see that the overall top 1 accuracy is 81 . 75% which is reason-ably good. When we consider the top 3 results, we can even pics of fight club braveheart quote watch gladiator online american beauty company 12 angry men characters mario kart guide pc mass effect crysis mods mother teresa images condemned screenshots 4 minutes lyric king kong the black swan summary blackwater novel new moon rehab the song nineteen minutes synopsis umbrella chords all summer long video girlfriend lyrics Table 3: Statistics on Sampled Recognition Results make the overall accuracy reach 97.5%. Fig. 1 also shows the performances of NERQ in different classes. From the re-sults we can see that our method of NERQ using WS-LDA is effective in each class.
 We further made error analysis on our NERQ results. There were mainly three types of errors. (1) Errors were mainly caused by inaccurate estimation of Pr( e ). It seems that the current wa y of estimating Pr( e ) has certain bias, which prefers the segmentation with a shorter named entity. We may reduce such kind of errors by employing a better estimation method. (2) Some contexts were not learned in our approach since they are uncommon. For example, in the query  X  X yrics for forever by chris brown X ,  X  X orever by chris brown X  was recognized as a  X  X usic X  named entity and  X  X yrics for # X  the context. Ideally,  X  X orever X  should be recog-nized as named entity of  X  X usic X , and  X  X yrics for # by chris brown X  as context. However, since the context  X  X yrics for # bychrisbrown X  X squitespecific,itwasnotcoveredbyour learning method. Some of such errors may be eliminated by using more seed named entities. (3) Some queries contained the named entity out of predefined classes. For example, in query  X  X merican beauty company X ,  X  X merican beauty X  was incorrectly recognized as a movie name. Since  X  X merican beauty X  was indexed as a movie name and  X # company X  was as a common context, our NERQ system may occasion-ally make such kind of errors. We may reduce them when we utilize more classes.
We performed experiments to make comparison between the WS-LDA approach and two baseline methods: Determ and LDA. Note that the main difference of these approaches lies in different assumptions and ways for modeling the re-lationship between named entity, context, and class.
Determ learns the contexts of a certain class by simply ag-gregating all the contexts of named entities belonging to that class. It can perform very well when a named entity only be-longs to a single class. In contrast, LDA and WS-LDA take a probabilistic approach and handle the ambiguity of named entities. However, LDA is based on unsupervised learning, and thus cannot ensure the alignment between latent classes and predefined classes.
We first compared the learning of contexts of each class between WS-LDA and two baselines. Table 4 shows the top ranked contexts of each class according to Pr( t | c ) generated Figure 1: NERQ Top N Accuracy on Test Data(%) by WS-LDA approach and baselines. From the results we can see that the quality of the top ranked contexts generated by Determ is not high. Take the  X  X ovie X  class as example, its top ranked contexts are mixed with the contexts of the  X  X ame X  class, e.g.  X # games X  or  X  X ree online # games X . The reason is that there are many named entities belonging to both  X  X ovie X  and  X  X ame X  classes. However, Determ ignores the ambiguity and forcibly merges all the contexts of such named entities together. The results indicate that by taking a probabilistic approach, we can improve the quality of the learned contexts. Among the two topic model approaches, WS-LDA achieves better results than LDA, because it can leverage human supervision. Note here manual class align-ment is performed to make it a fair comparison with LDA.
We further looked at the accuracy in ranking named en-tities by WS-LDA and Determ. In Determ, all the con-texts of a class are called the signature of the class. Candi-date named entities can then be ranked in each class based on the Jensen-Shannon similarity score [19] between all the contexts of the named entity and the signature of the class. For comparison, top 250 named entities ranked in each class generated by Determ and WS-LDA were evaluated. Each named entity was manually labeled as  X  X orrect X  or  X  X ncor-rect X  regarding to class. In total, 2,000 named entities for the four predefined classes were annotated. We used  X  X re-cision at rank N X  [19] as the measure and obtained the re-sults in Table 5. The results show that WS-LDA can sig-nificantly outperform Determ (p-value &lt; 0.01). The results demonstrate that WS-LDA can learn the contexts of classes better than Determ.
We next evaluated the accuracies of estimated probabili-ties Pr( c | e )inLDAandWS-LDAonthetestdata(i.e.,60 named entities). The overall class likelihood with respect to named entity e is calculated as K i =1 y i Pr( c i | e ), where y i takes 1 or 0 when the i -th class is or is not assigned to e . The overall class likelihood measures how consistent the machine predictions are with human labels. Fig. 2(a) shows the results by LDA and WS-LDA over different runs in testing. The results indicate that WS-LDA significantly outperforms LDA. The average likelihood obtained by LDA is about 34.89, while the average likelihood obtained by WS-LDA is about 53.39. Here to avoid inaccurate manual class alignment in LDA, we enumerate K ! possible alignments for LDA in each run and take the highest score as its result. It can be considered as the upper-bound of LDA. As shown in Fig. 2(a), the performance of LDA is quite unstable. It might be also related to the  X  X ocal maximum X  problem of LDA [5]. In contrast, WS-LDA model does not seem to suffer from the problem and can constantly produce high Figure 2: Comparisons between WS-LDA and LDA on (a) Overall Class Likelihood on Testing Set, (b) Convergence Speed on Training Set Table 6: Average Class Likelihood on Testing Set v.s. Coefficient  X  accuracy in prediction.
 We also found that the convergence speed of training for WS-LDA is much faster than that for LDA. Fig. 2(b) shows numbers of iterations needed for convergence for the two methods. The average convergence speed of WS-LDA is 3 times faster than that of LDA. It might be due to the reg-ulation from the soft constraint which makes the parameter space much smaller.
We also tested how the coefficient  X  (weight on soft con-straints) affects the performance of WS-LDA. We set  X  with different values from 0.01 to 100 and ran 10 trials under each setting. Table 6 shows the average class likelihood values on the testing set under different values of  X  . The results indi-cate that increasing  X  will help WS-LDA to predict class la-bels more accurately. It demon strates the necessity of using the supervision in learning and the capability of WS-LDA in utilizing the information. While  X  is small, the average class likelihood is unsurprisingly close to that of LDA. Moreover, when  X  continues to increase, the convergence speed will de-crease and the performance will drop. This is because the supervision is over emphasized.
Named Entity Recognition in Query (NERQ) is poten-tially useful in many applications in web search. We have, for the first time, investigated the problem in this paper, and proposed employing a probabilistic approach to perform the task using query log and a topic model. We have proposed a new weakly supervised learning method for creating the topic model called WS-LDA, in which the topics of a doc-ument are assigned. Experimental results indicate that the proposed approach can accurately perform NERQ, and out-performs other baseline methods.

There are several issues which we plan to address in the future. In this paper, we have verified the effectiveness of our method in experiments in which there are only a small number of classes. We plan to add more classes and conduct the experiments. The proposed method focuses on single-named-entity queries. We want to design a more general model to handle more complicated queries.
