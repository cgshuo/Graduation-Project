 measure the difference between two strings. Secondly, even though many string measured functions have been proposed, it is costly to calculate these measured functions. 
Based on the above discussion, for efficient string approximate search, a natural way [3-10]. Even though gram-based method can process approximate string matching efficiently in many cases, it has many weaknesses. First, it cannot effectively deal with the data update. Second, it has to introduce many collection operations when we use the inverted table to do the query, which increases the complexity of the query. 
There are still a lot of non-inverted list indexing structures supporting approximate each string into a number, and insert it into a B+ tree structure, which can support the data update well, but this structure emphasis on the ordering of the string too much and obvious, getting many alternative leaf nodes. 
In summary, existing methods have drawbacks. We attempt to address these Inspired by hashing index and B+ tree, if similar strings are mapped into the same entry in the index, during the search, they can be accessed by once probing. Thus, the design cluster as an item. Such that similar strings can be accessed in batch in the index. 
We choose a tree structure as the skeleton of our index, since such structure supports represent the nodes in the index, for each node, we extract some grams from the strings when some new strings are added to the set, they are added to the nodes with similar method to cluster the strings together and extract the feature grams from the center of each cluster. Our index is able to support threshold-based search, top-k search. 
The contributions of this paper include: 1 We present a new type of string indexing structure that supports a variety of types of similarity string search efficiently. 2 An effectiveness and efficient index building algorithm with complexity is proposed. 3 Extensive experimental results on real datasets show that our indexing scheme achieves comparable performance against other solution on search operations. principles of the Fgram-Tree. Section 4 presents details of the index building process and algorithm complexity. Section 5 presents a comprehensive evaluation of the proposed techniques and Section 6 concludes the paper. In this section we present some preliminary knowledge regarding string processing as well as the basic problem definition. 
In the literature of approximate string matching, edit distance is commonly used to measure the similarity of two strings. We use edit distance to measure string similarity in our query process operations. Definition 1. (Edit Distance) Figure 1 shows a simple database table including 5 distinct strings and its general index from single character  X  X  X  to  X  X  X . 
Next, we give the formal definitions of string approximate search with respect to edit distance. Definition 2. (Threshold-based Search) Given a query string q, a string set D and threshold  X  , find all strings in D with edit distance no larger than  X  .  X  and  X   X  , whose edit distances to q are no larger than 1 . Definition 3. (Top-k Search) than any other strings in D. which are more similar to q than any other strings in D . 
When we do the approximate search, the algorithm of counting edit distance between programming method. As a result, when we deal with large amount of strings, we use distance. We split a string into grams. Definition 4. (Ngram Split) Ngram split of a string is a set, that is composed by all the substrings with length N. For example, the 2-gram split for  X  X oey X  is {Jo, oe, ey}.  X 1 X  X  X  X | grams. As a result, the subtraction between two numbers is the least common n-grams. This section introduces the index structure and discusses query process methods including two kinds of approximate search queries. 3.1 Index Structure with each node representing a set of similar strings. Fgram-Tree pays more attention to the treatment of similar strings and supports threshold-based search, top-k search. We propose the formal definition of Fgram-Tree. Definition 5. (Fgram-Tree) A Fgram-Tree is a tree structure where each leaf node is represented as a triple (bs, cbs, ids) and each intermediate node is a tuple (bs, cbs), where bs is a set of ngram splits of strings contained by all lower node s and occurrences of each gram, cbs is the center of bs to represent bs (More details about cbs will be described in Section 4), and Ids is the set of the strings attached to the node. We use an example to illustrate our index. General index structure is shown in Figure 1. Figure 1, and we will discuss the problem by the collection way in the rest of the paper. 3.2 Query Process search based on our index. 
Before the introduction of query process supported by Fgram-Tree, we give two impossible to contain similar strings with the query. contain a string similar with the query. Obviously, if the number of common n-grams bs many grams with q , either.
 Threshold-Based Search Firstly, we discuss threshold-based search. We use these two conditions to prune nodes code of threshold-based search in Algorithm 1. 
Algorithm 1 traverses the nodes meeting Condition 1 and Condition 2 in the index CommonGramCbs() correspond to Condition 1 and Condition 2 respectively. Top-K Search Next, we discuss top-k search method. To take advantage of the feature of our index that follows: 
In Algorithm 2, we locate the nodes which contain the most similar string with q with elements in max-heap is more than k , we pop the strings with the largest distance. strings in the same node should be similar while those in different nodes should be not design a center-based algorithm for the construction of such index in this section. At first, we introduce the framework of our clustering method in Section 4.1. Since center initialization, node selection and center update are basic operations for the clustering, we discuss them in Section 4.2, Section 4.3 and Section 4.4, respectively. At the end of this section, we analyze the time complexity of the index construction. 4.1 Overall Method construction in Algorithm 3. 
The input of Algorithm 3 is a tree node N which contains all the strings waiting to be Line 2, the center is initialized with InitNode(). Line 3-9 is the iterative process. The NodeChoice(). Line 6-7 updates cbs of every child node using the method SetCenter(). Next, we will discuss the details about InitNode(), NodeChoice() and SetCenter() in Section 4.2, Section 4.3 and Section 4.4, respectively. 4.2 Center Initialization rather than randomly generate centers. 
Center-based clustering method is to select a center on behalf of the characteristics of each cluster. Clearly, two strings are similar if they have many common grams. Then we can extract some grams from every strings in the cluster to form a gram collection as the center, which share grams with each string. Moreover, we should extract the grams that similar strings share, because these grams could make similar strings located in the same cluster. 
Based on above discussion, we pick some shared grams from bs as our center. And according to the idea of vote, the frequency of these shared grams should be higher than that of other grams. Thus, we choose some grams of high frequency to initialize our high frequencies grams from the trie in InitNode(). Assume there are k centers and initialize for  X  X  X   X  ( i =1,2... k ). 
In the first step, we construct a trie and select k grams in the leaf node belonging to respectively (line 6-7). 
Algorithm 4. InitNode (tree node N ) 1: center  X  X  X   X  of N  X  X  every child ( i =1,2... k ) 2:  X  X  X  X  X  X  X  X   X   X   X  ( i =1,2... k ) 3: Heap H  X   X  4: TrieNode root  X  MakeTrie() 5: traverse the trie, H  X  k grams whose frequency is highest 6: for each  X  X  X  X  X  X  X  X   X  do 7:  X  X  X  X  X  X  X  X   X   X  H[i] 8: for each substring s of H[i] with length n do 9: if (a gram begins with s in trie) then 10:  X  X  X  X  X  X  X  X   X   X  gram 11: for each gram of  X  X  X  X  X  X  X  X   X  do 12:  X  X  X   X   X  the standard grams of gram grams in cbs and add these grams to initgram . (line 8-10) And we add them to the node center cbs . (line 11-12) 
The main computation cost of Algorithm 4 is the construction of the trie with  X   X  X   X  , 7-12) is mainly trie traversal with time complexity  X   X  X   X  . 4.3 Node Choice belonging to in the iteration. 
The goal is that strings in the same node should be similar but not similar to strings in other nodes. It means that strings in the same node should share more grams while less string s into one node, the intersection size may become large. As a result, when we after it is inserted.  X  follows. 
For the classification, we have two possible ways. The first is that gs is assigned to  X |  X | X  X   X   X  X | X  X   X  | . Thus if  X  X |  X   X  X | X  X   X  | , we choose  X  X  X   X  and otherwise we choose discussion, we define  X  X |  X  | as single covered degree sc-degree . 
Based on the above discussion, we compute sc-degree for every center and select the between any two cbs represented by bitmap in a two-dimensional array to support the operation filtering of common grams with other centers, therefore it runs in  X  X  X  X  X  time largest sc-degree . Obviously, the complexity of NodeChoice() is  X  X  X   X   X  . node choice method, gs must have a intersection with cbs which greatly enhanced filter function of the index. 4.4 Center Update construction. 
In each iteration if a gram is chosen as the center, it must be contained in the ngram splits of two strings. Therefore, we should choose the grams from those with frequencies no less than two. If we apply such update method, the number of grams in the center will be very large which may cause a new problem that many grams would lead to excessive iterations. 
Grams in each center must be constituted by each ngram split of the string waiting the number of elements in each overlapping set has taken to the minimum, then it is obvious that the center size will be minimal. conclusion in Theorem 1 that a large number of grams would not increase the iteration times. Definition 6. (Control Effect) where Common(A,B) is sc-degree between set A and B and cover is the subset of gs, then cover determines which center s bel ongs to and every gram in cover has control effect to gs. than to compare the whole ngram split collection. Every center should be composed by Then, we define min cover set as well as the min center. Definition 7. (Min Cover Set) Mcs is a min cover set , if its arbitrary subsets are not cover sets. Definition 8. (Min Center) where S presents all of strings in one node. Definition 8 shows the composition of the minimal center. Then we use above iteration times. Theorem 1. When Mcenter converges, any center L center with larger size satisfying  X  X  X  X  X  X  X  X   X  X  X  X  X  X  X  must also converge .
  X  X  X  X  X  X   X  X  X  X  X  X  X   X   X  X  X ,  X   X  X  X ... |  X  |  X  and the center  X  X  X  X  X  X   X  X  X  X  X  X  X   X   X  X  X  X   X   X  X  X ,  X   X   X  X  X   X   X  X  X ... | X  X   X  X  X  X  | X  X   X  , therefore Lcenter converges. 
Theorem 1 shows that due to the control effect, when Mcenter converges, Lcenter must also converge. In another word, their iteration times are the same. And because the increasing of center size. 
We use SetCenter() to update the center in Algorithm 3. And because our method is judging convergence. 4.5 Complexity Analysis In this section, we analyze the time complexity of index construction. 
Algorithm 3 visits each node recursively. In every recursion, it contains two phases, phase, because updating center and judging convergence run in constant time, the main Algorithm 3 is  X  X  X  X  X  X  X  X  X  . respect to threshold-based and top-k search on edit distance with a real dataset. 
Our data are from DBLP(http://dblp.uni-trier.de/xml/). We extracted the author element from the article list as the data set. The maximum length of strings is 56 and average length is 22. 
We chose Bed-Tree[2] for comparison. [2] proposed an edit distance tree structure able to work in both of memory and external memory. And in our experiment, order. We will measure the performance of queries for Bed-Tree and Fgram-Tree both in memory and external memory. 
We classified all the characters into two categories: 26 English letters and the other to take full advantage of the page size, each leaf node stored up to 200 strings and each 
We compile all the programs in Windows7 using jdk 6.0 with java. The experiments are run on a Intel(R) Core(TM)2 Duo CPU E7500 2.93GHz with 2 GB main memory and 7200 RPM disk drive. 5.1 Experimental Results of Index Construction and then shows the time of building index. 
In our algorithms, we selected grams whose frequency is no less than 2 as the center of each node. Figure 2(a) shows the variation of iteration times with the size of center. center size, we repeated 10 times to cluster these strings, and took the average value of 10 times as the iteration times. As can be seen from Figure 2(a), when the size of center is greater than 15, the iteration times is essentially the same, which validates Theorem 1. The center is slower to converge when the median is less than 10 because few bit size cannot guarantee the control effect. 
Figure 2(b) shows the variation of construction time with string size. We select the number of strings ranging from 0.01 million to 2 million. According to our analysis, the complexity of Algorithm 3 is  X  X  X  X  X  X  X  X  X  that is consistent with the growth trend of the curve in Figure 2(b). 5.2 Experimental Results for Query Processing querying time. 
We had test queries in two settings, one is the index is located in disk while the other retrieved from disk. In the second setting, the experiment represents the other extreme in which all data required to answer a query is already in memory. 
Figure 3 and Figure 4 present the experimental results of threshold-based search and distance computation. 
From the experimental results, Fgram-Tree consistently outperforms Bed-Tree both for raw disk performance and for a fully memory. The most important reason is that similar strings lie in different nodes in Bed-Tree and thus it has to generate more nodes for edit distance computation than Fgram-Tree. Therefore, the Bed-Tree is costly. 5.3 Scalability threshold-based search and top-k search for raw disk or fully memory. Because we used filter conditions CommonGramBs() and CommonGramCbs() simultaneously in our query process algorithms, we could filter more nodes unsatisfied with the query even though large amount of data. As a result, we got a better result. In this paper we propose a general tree-based index structure to support a broad class of string approximate queries with respect to edit distance. We map similar strings in the processing. To make the index support the query effectively, we design a center-based clustering approach, which can locate similar strings into the same node with the time complexity  X  X  X  X  X  X  X  X  X  . The experimental results show our indexing scheme achieves comparable performance against other solutions on threshold-based and top-k queries.
