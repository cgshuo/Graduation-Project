 In many applications, entities are often queried by their names. For example, e-commerce players such as Amazon.com helps people search books by inputting book names; movies can be found on imdb.com by inputting movie names, and researchers incomplete or duplicated results for such queries. From different aspects, there are two major problems. On the one hand, a name may have different spellings and one entity Wang X  can be both written as  X  X ei Wang X  and  X  X . Wei X . Another example of this confusion is movie names. Such as the movie called  X  X ong lou ment X  can also be represented as  X  X  Dream in Red Mansions X . On the other hand, one name can represent multiple entities. For example, when querying an author named  X  X ei Wang X  in dblp, the database system will output seven different authors all named  X  X ei latter is called tautonomy . operation in data cleaning and query processing with quality assurance. Given a set of objects with name and other properties, the goal of this operation is to split the set into clusters, such that each cluster corresponds to one real-world entity. 
Some techniques for entity identification have been proposed. However, each of these techniques focuses on one of the two problems. The techniques for the first problem are often called  X  X uplicate detection X  X 1]. These techniques usually find duplicate records by approaches are used to compare the similarity. These techniques are based on the cannot be distinguished. As far as we know, the only technique for the second problem is objects by assuming that the objects have identical names. If this method is used to solve entity identification problem, in which the assumption is unsatisfied, the results might be inaccurate. In summary, when these two aspects of problems both exist, current techniques can not distinguish objects effectively. 
For entity identification in general cases, new techniques with the ability of dealing with both these problems are in demand. For effective entity identification, this paper proposes EIF, an entity identification framework. With effective clustering techniques, approximate string matching algorithms and a flexible mechanism of knowledge integration, EIF can deal with both the two aspects of the problems. Given a set of objects, EIF split them into clusters, such that each cluster corresponds to one algorithm for identifying authors from the database with dirty data. For the simplicity representing each object as a tuple of attributes. 
The contributions of this paper can be summarized as following:  X 
EIF, a general entity identification framework by using name and other attributes of objects, is presented in this paper. Both approximate string matching and clustering techniques can be effectively embedded into EIF, domain knowledge integration mechanism as well. This framework can deal with both name diversity and tautonomy problems. As we know, it is the first strategy with the consideration of both problems.  X  the information of author name and co-authors to solve author identification problem. It shows that by adding proper domain information, EIF is suitable to process problems in practice.  X 
The effectiveness of this framework is verified by extensive experiments. The experimental results show that the author identification algorithm based on EIF outperforms the existing author identification approaches both in precision and recall. The rest of this paper is organized as follows. The entity identification framework concludes the whole paper. cluster correspond to one entity, vice versa. 2.1 The Introduction to the Framework null. Firstly, EIF classifies the objects by their names. If the names of two objects are computed from name and other attributes of u and v . Edge ( u, v ) is added if the value induced subgraph of each class is generated and is partitioned into clusters by domain the objects belonging to each cluster in the final partition refer to the same entity. The flow of EIF is shown in Algorithm 1. Algorithm 1. The EIF attributes. i &lt; j  X  t . Objects in the same cluster refer to the same entity. 1. Initialization: G N = (V, E) , V = N , E =  X  . 6. Return R . 
Both sim and  X  can be obtained by domain knowledge. For example, if at least two names occur simultaneously in two publications as authors, by the domain knowledge, we know that these authors with the identical name in these two publications are very likely to refer to the same author. Therefore, the similarity function can be defined as the size of intersection of co-author sets, and  X  can be set to 2. 2.2 Induced Subgraph Partition Method Step 4 is to partition the objects in induced subgraph. Effective clustering approaches and the initial node set of v as S(v) . ( u, v) is contracted and u, v are merged to one node u X  , where the original node set of neighbours of u and v , N(u X ) = N(u)  X  N(v) . 
The iteration terminates when no more nodes can be merged. The result is the of objects referring to this entity.The algorithm of this method is shown in algorithm 2. 
Since the time complexity of step 1-3 of EIF depends on domain knowledge, we complexity of step 4 is O(| V X  || E X  |) and the time complexity of step 5 is O(| V X  X  ). 2.3 Example In this subsection, we demonstrate the flow of EIF with Example 1. Example 1. There are six publications each with a list of authors, and each publication has an author named  X  X ei Wang X  or  X  X ang Wei X . By domain knowledge, it is known that these two names might refer to an identical name. For simplicity, the task of entity identification in this example is to distinguish the authors named  X  X ei Wang X  or consists of the following steps. Wang X  are considered). Step 2 (Fig. 1(b)): classify the objects by comparing their names. Since we only distinguish the objects with similar names  X  X ei Wang X  or  X  X ang Wei X , all nodes in G belongs to the same class N 1 . Step 3 (Fig. 1(c)): Suppose the similarity function is defined as the size of intersection Therefore, for any two objects u and v , if the intersection of their co-author sets is in size of at least 2, an edge ( u, v ) is inserted into G N .  X  Condition 2) is not satisfied either. 
Therefore, A X  X  and D are not to be merged. Step 4 of EIF is iterated until no more edge can be contracted. Finally, the partition of N 1 is obtained, which is {{ A, C, E }, { B, D, F }}. N , denoted as R 1 . Return R 1 in Step 6 (The algorithm ends). Both problems of name diversity and tautonomy exist in author identification of publications. Different authors may share identical or similar names; an author name may also have different spellings in different publications, such as abbreviation, apply EIF to design author identification algorithm. Example 1 has shown the major based on domain knowledge of publications will be discussed in detail. 3.1 Classification of Objects on Names by names in step 2 of Algorithm 1. Objects with similar names should be classified in the same class. Our task is to define the similarity judgement rules between names. 
Since author names are in type of string with special formats, rule-based strategies can be used in this step. The matching rules of name in [3] are used as the rules in this paper. These rules enumerate diversities of name spellings. of classification is to make the nodes in the same class match each other, which can be proved to be an NP-Hard problem. Due to limitations on space, we eliminate the proof. 
In order to efficiently solve this problem, we propose a heuristic rule-based strategy. The heuristic rules are as follows: 1) If names a and b are matching, then Class(a) = Class(b), 2) If Class(a) = Class(b), and Class(b) = Class(c), then Class(a) = Class(c), following steps: considered as a class 2) Merge two classes if their intersection is not empty 3) Repeat step2) until no more classes can be merged. 4) All classes are output. However, such classification can not distinguish objects effectively because of solve the problem of tautonomy . 3.2 Partition of Object s Based on Clustering identification with similar names algorithm. should be added into G N is determined by domain knowledge and the values of attributes of u, v . The domain knowledge for author identification is as follows. similar names refer to the same entity 2) the larger the intersection set of co-authors is, the more possible the objects with the similar names refer to the same entity 
These rules can be described as similar functions. Before the functions are defined, means that after classification, aut1 and aut2 are in the same class. Denote the set of similarity function and co-authors similarity function are defined as follows: 1) domain similarity of objects aut1 and aut2: f((aut1),(aut2)) = |C(p1)  X  C(p2)|; 2) co-authors similarity of objects aut1 and aut2: g((aut1),(aut2)) = |A(p1)  X  A(p2)| Combining above two similarities, the similarity function sim is defined as: 
Parameters a, b can be determined by domain knowledge or machine learning approaches. According to the similarity function sim and the threshold  X  , edges are added into G in the following rule:  X  u, v  X  V, if sim(u, v)  X   X  and terminates until no more edge can be added. research survey on early work of this problem. Nowadays, there are two kinds of entity identification approaches. records[4, 5]; the other is based on relations between records [8-10]. These definitions of similarity between entities can be applied in our system and orthogonal with our work. 
There are four kinds of entity identification approaches. Approaches based on rules [11, 12] define the conditions of any two records referring to the same entity by rules. [15] identify entities by using probability models. Approaches based on machine then process each block effectively, so as to reduce as much searching space as possible, e.g., [7] propose an iterative blocking method based on disk. 
The techniques proposed usually only focus on some particular part of entity identification problem. Instead, the EIF framework is based on the whole general problem and integrates related techniques by steps. In Step 1, EIF uses approaches of records by using the information of similarity between records obtained in step 1; in based on rules. experiments. The experimental results and analysis are shown in this section. 5.1 Experimental Settings 1) Experimental environment : We ran experiments on a PC with Pentium Processor 3.20 GHz CPU, 512 RAM. The operation system is Microsoft Window XP. We implemented the algorithms using VC++ 6.0 and SGI X  X  stl library. We have implemented the author identification algorithm based on EIF, called AI-EIF. We evaluate our framework on both real dataset and synthetic data set and show the effectiveness and efficiency of our algorithm. 2) Data sets : dataset used in [2] for comparisons. The second is the DBLP[17] to test the effectiveness and efficiency of our algorithm on real data. In order to test the impact generator for generating publication with authors. The parameters include the number ratio of the number of names to the number of authors(#name/#aut). For each author network among them. For each publication, its authors are a group of randomly selected co-authors in this network. 3) Measures : results of EIF with manually identification results. Manually identification is to manually divide the objects into groups accord ing to author X  X  home pages, affiliations and research areas shown on the papers or web pages. According to the definitions in cluster in both C and C*. Let FP (false positive) be the number of pairs of objects in the same cluster in C* but not in C, and FN (false negative) be the number of pairs of are defined as follows: precision = TP / (TP + FP), recall = TP / (TP + FN). 4) Parameters setting : algorithm, we set  X  = 2 and  X  = 0.05. The default setting of our data generator is that: #name/#aut = 0.9, #pub = 1000, #aut/per pub = 4. 5.2 Experimental Results on Real Data We test both efficiency and effectiven ess of the algorithm on DBLP. We extract of AI-EIF on DBLP is 1.64 hours. all 2074K author names in DBLP and identify them manually. Each of the 8 names corresponds to multiple authors. The basic information of them is shown in Table 2, including the number of authors (#aut) and number of references (#ref). Table 2 also shows the precisions and recalls of each name by AI-EIF. From the result, the precisions are always 100%. It means that AI-EIF always divide objects referring to different authors into differ ent clusters. The average of recall is entity are in the same cluster. connection between them is tight, otherwise it is loose. Take the author named Michael Siegel in Weizmann Institute of Science(WIS) as an example, in all his there are 3 other publications he cooperated with some people in Institut f X r Informatik and Praktische Mathematik(IIPM). Since the co-operator set in WIS never cooperate with the co-operator set in IIPM, the connection between these two co-Michael Siegel in WIS are partitioned into 2 clusters. 5.3 Comparison Experiments As far as we know, DISTINCT[2] is the best author identification algorithm. Therefore, we compare AI-EIF with DISTINCT. Since DISTINCT only tests its AI-EIF on real names in DBLP that correspond to multiple authors. 8 such names are shown in Table 3, together with the number of authors and number of references. 
The experimental comparisons of precisions and recalls are also shown in Table 3 respectively. From Table 3, it can be seen that AI-EIF outperforms DISTINCT both in precision and average recall. 5.4 Changing Parameters are shown in Fig.2 to Fig.7. experimental results of publications of Wei Wang in UNC(entity 0) and Wei Wang in Fudan(entity 1) are shown. The experiment results are shown in Fig. 2. From Fig. 2, it the stronger the similarity matching condition of objects is. Therefore, more and more our experiments), the precisions are no longer 100%. In another word, the larger  X  is, the stronger the matching condition is and the higher the precision is, vice versa. 
The conclusion drawn from the experiments of changing  X  is that the smaller  X  is, the lower the recall is and the higher the precision is; vice versa. From Fig. 3, it can be seen that the run time is approximately linear to the number of approximately linear to the number of objects, which is linear to the number of publications. number on effectiveness by changing #name/#aut from 0.05 to 0.95. From Fig.4, it can be seen that the bigger the ratio of the number of names to the number of authors is, the higher the precision is. That is because, the bigger the ratio is, the smaller the recalls are insensitive to the ratio of number of names to the number of authors. That is because, FN is insensitive to the probability of different authors having same name. 
We test the impact of the number of authors per publication on effectiveness by more number of co-authors in each publicatio n are, the more co-authors are connected by this publication, the higher the connections between co-authors are. Since the connections between co-operators of this auth or are higher, the recall gets larger. This result is coincident with the analysis of the experimental results of the changing of  X  . The reason for the incremental speed getting sl ower with #aut/per pub is that marginal impact of the number of authors per publication on the recall decreases. 
In Fig. 7 we test the efficiency by changing #aut/per pub from 2 to 14. From Fig.7, increasing of run time with #aut/per pub is because the more co-authors in each publication, the more information is to be processed. The increment speed of run time becomes slower is because even though the number of co-authors gets larger, the scale. It means that the number of objects to process will not increase in the same scale. In this paper, we study the entity identification problem, and propose a general framework of entity identification, EIF. Both clustering techniques and domain knowledge are includes how to apply EIF into some more complicated applications. Acknowledgments. Thanks for the help on experiments by Dr. Xiaoxin Yin in Microsoft Research. 
