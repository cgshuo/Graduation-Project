 It is often crucial for manufacturers to decide what product-s to produce so that they can increase their market share in an increasingly fierce market. To decide which products to produce, manufacturers need to analyze the consumers X  requirements and how consumers make their purchase de-cisions so that the new products will be competitive in the market. In this paper, we first present a general distance-based product adoption model to capture consumers X  pur-chase behavior. Using this model, various distance metrics can be used to describe different real life purchase behav-ior. We then provide a learning algorithm to decide which set of distance metrics one should use when we are given some historical purchase data. Based on the product adop-tion model, we formalize the k most marketable products (or k -MMP ) selection problem and formally prove that the problem is NP-hard . To tackle this problem, we propose an efficient greedy-based approximation algorithm with a prov-able solution guarantee. Using submodularity analysis, we prove that our approximation algorithm can achieve at least 63% of the optimal solution. We apply our algorithm on both synthetic datasets and real-world datasets (TripAdvi-sor.com), and show that our algorithm can easily achieve five or more orders of speedup over the exhaustive search and achieve about 96% of the optimal solution on average. Our experiments also show the significant impact of differ-ent distance metrics on the results, and how proper distance metrics can improve the accuracy of product selection. F2.2 [ Analysis of Algorithms and Problem Complex-ity ]: Nonnumerical Algorithms and Problems Product selection; consumer behavior; model learning; sub-modular set function; approximation algorithm
Product competition in the current digital age is becoming increasingly fierce. Consumers can easily access the infor-mation about a given product via the Internet. Moreover, consumers can share their opinions on products in the form of ratings or reviews via various web services, e.g., Amazon. Therefore, instead of relying on the sales pitch by salesmen or traditional TV advertisements, consumers can now re-view many competing products before they make their final purchase decision. Manufacturers, on the other hand, can use the web information, such as ratings and reviews, to gain a better understanding of consumers X  requirements on various products. This leads to a new challenge on how to discover consumers X  preferences, and how these preferences may help manufacturer to select appropriate new products so to compete with other manufacturers in the market.
To introduce new products into a market, a manufacturer usually has a set of candidate products to consider. How-ever, due to budget constraints, the manufacturer can only produce a small subset of these candidate products. The objective of a manufacturer is to select a subset of products which can maximize its profit or market share. In this study, we consider the following scenario: In a market consisting of a set of existing products from various manufacturers and a set of consumers, a manufacturer wants to select  X  k most marketable products  X  from a set of candidate products so as to maximize the market share of all products from this man-ufacturer (this includes the possibility that some existing products in the market are from the same manufacturer).
One of the major challenges of the  X  k most marketable products  X  problem is how to model various consumers X  adop-tion behavior, i.e., how consumers make their purchase de-cisions. Different adoption behavior may lead to different product selection results. However, there is a lack of formal work of how to model these behaviors using available data. Furthermore, finding the optimal solution to the  X  k most marketable products  X  problem can be shown to be NP-hard in general.

In this paper, we first model the consumers X  adoption be-havior with a generalized distance-based model where differ-ent distance metrics can be used to describe many different consumers behaviors. We then propose a method to learn which set of distance metrics one should use when we are given some historical purchase data. We also present a com-putationally efficient approximation algorithm to solve the k most marketable products problem. To the best of our knowledge, this is the first paper that provides the formal consumers X  adoption model and the analysis of product se-lection. The contributions of this paper are:
The outline of the paper is as follows. In Section 2, we propose a general product adoption model which can accom-modate different distance metrics to describe the consumers X  adoption behavior, and we formulate the k -MMP problem. In Section 3, we present a learning method to select the ap-propriate set of distance metrics according to the historical market share of existing products. In Section 4, we pro-pose an exact algorithm for the case of k = 1 and prove that finding the exact solution for k &gt; 1 is NP-hard . To tackle the computational challenge, we present an approxi-mation algorithm in Section 5. We show that this algorithm is computationally efficient and also provides a high quality solution guarantee. In Section 6, we perform experiments on both the synthetic data and the real-world data. Related work is shown in Section 7, and Section 8 concludes.
In this section, we first present a model of a market by considering both products and consumers. Then we present a distance-based product adoption model to describe vari-ous consumers X  product adoption behaviors. Based on these models, we formulate the k -MMP problem.
Let us consider a market which consists of a set of l con-sumers C = { c 1 ,c 2 ,...,c l } and a set of m existing product-s P E = { p 1 ,p 2 ,...,p m } . Let M represent a manufacturer in the market, and P M denote the set of existing products produced by M , where P M  X  X  E and |P M | = m M . The re-maining products in P E are from other manufacturers who are the competitors of M . These competing products are denoted by P C , where P C  X  X  E and |P C | = m C . According to these definitions, we have m = m M + m C , P E = P M  X  X  and P M  X  X  C =  X  .

Suppose the manufacturer M wants to produce some new products to maximize its utility, i.e., the market share. M has a set of n candidate new products to choose from, which we denote by P N = { p m +1 ,p m +2 ,...,p m + n } . Note that all the products in P N are new to the market, in other words, P
N  X  X  E =  X  . Due to the budget, technological and manu-facturing constraints, the manufacturer M can only produce k  X  n of these candidate products in P N .

Each product in P E  X  X  N is associated with d attributes denoted by A = { a 1 ,a 2 ,...,a d } . Each attribute a i resented by a non-negative real number, and higher value implies higher quality. One can use a i to represent various attributes of a given product, e.g., durability, ratings, inverse of price. Hence, the quality of a product can be described by a d -dimensional vector. Specially, the quality of produc-t p j is described by the vector q j = ( q j [1] ,q j where q j [ t ]  X  [0 ,  X  ),  X  t  X  X  1 , 2 ,..,d } indicates p attribute a t . Similarly, each consumer in C is also associated with A to describe his requirements on different attributes. c  X  X  minimum requirement on attribute a t , i.e., c i requires that the product X  X  quality on attribute a t is at least r he will not adopt (or purchase) that product.

Example 1. To illustrate the notations, we present an example in Figure 1. Consider a market of smart phones where we have two existing products P E = { p 1 ,p 2 } and three consumers C = { c 1 ,c 2 ,c 3 } . Manufacturer M is considering two candidate products P N = { p 3 ,p 4 } . Let say each prod-uct is described by two attributes: a 1 is the inverse of price (units per thousand dollars, UPM for short) and a 2 is dura-bility (years), and they are represented in the horizontal and the vertical axis respectively. The quality vectors of products and the requirement vectors of consumers are shown in the vector of p 1 is (2 , 6) , so we can purchase two units of p with one thousand dollars (or the price of p 1 is $ 500), and the durability of p 1 is six years. Similarly, the requirement vector of c 1 is (1 , 5) , so consumer c 1 wants a product which is at most $ 1000 and can last for at least five years. 1 2 3 4 5 6 7 0
We assume that a consumer may adopt a product if the product satisfies his requirement. We say that a product satisfies a consumer X  X  requirements if and only if the product meets the requirements of that consumer on all attributes. Formally, we define the product satisfiability condition.
Definition 1. (Product satisfiability) Consider a con-sumer c i and a product p j . We say the product p j denote this relationship as p j % c i , and p j is said to be a satisfactory product of c i , while c i is a potential consumer of p j in other words.

For example, consider the products and consumers depict-ed in Figure 1. One can observe that the quality vector of p 1 is (2 , 6) and the requirement vector of c 1 is (1 , 5). Since 2 &gt; 1 and 6 &gt; 5, so p 1 satisfies c 1 , or p 1 % c 1 have p 3 % c 2 and p 3 % c 3 .

We assume that if a consumer has some satisfactory prod-ucts, then he will adopt one unit of product from any of these feasible products. When a consumer c i has only one satisfactory product, say p j , then c i will adopt p j for sure. However, it becomes complicated when there are multiple satisfactory products. All previous works [7, 12, 13, 16] as-sume that the consumer will randomly adopt one of the sat-isfactory products, but this is not realistic in many situation-s. In the following, we present the distance-based adoption model to describe some realistic and representative product adoption behavior when consumers make their purchase de-cisions. Our model is very general to model various product adoption behaviors in the real world scenarios.

In a real world market, products with higher quality usu-ally attract more consumers. Therefore, we use a distance measure between a product X  X  quality and a consumer X  X  re-quirement to decide which product the consumer may adop-t. Note that consumers will only consider their satisfactory products. Furthermore, larger distance implies better qual-ity. Let d i,j be the distance between the consumer c i  X  X  re-quirement vector ( r i ) and the product p j  X  X  quality vector ( q j ). We assume that c i will adopt the product p j has the largest distance among all his satisfactory products. If there are multiple satisfactory products which have the same largest distance measure with c i , then c i will random-ly select one of these products. Mathematically, we define the distance-based adoption model as follows.

Definition 2. (Distance-based adoption model) Giv-en a consumer c i and a set P of products available in the market, let F P ( c i |P ) be the set of products which have the largest distance between their quality vectors and c i  X  X  require-ment vector among all c i  X  X  satisfactory products. The prob-ability that c i adopts a product p j  X  X  is
Note that we can use many distance metrics , e.g., l 1 ,l norms. For instance, if l 1 norm (or the Manhattan distance ) is used, then consumers will choose the satisfactory products which have the largest sum of all components X  values in the quality vectors. To describe different adoption behaviors of different consumers in a real world market, we also take into account the weighted distance metrics. Let w t be the weight of attribute a t , w t  X  0 ,  X  a t  X  X  , then under the l 1 distance d i,j can be expressed as:
It is important to point out that the algorithms we present in this paper are general to all distance metrics. Readers can use other distance metrics when appropriate. In here, we present four representative distance metrics which we use as examples for illustrations and experiments.  X  Discrete metric (DM). We define d i,j = 1 for consumer-s c i and c i  X  X  satisfactory product p j in the discrete met-ric. This distance metric simplifies the adoption model that consumers will randomly select one from all his satisfactory products. Using this distance metric, our work subsumes the adoption models of previous works [7, 12, 13, 16].  X  Norm metric (NM). In this distance metric, we set the weight w t = 1 . 0,  X  a t  X  X  based on the l 1 norm metric as defined in Equation (2). Note that in general, one can use other norm as distance metric and our algorithms still apply.  X  Price metric (PM). In a real world market, one common situation is that if a consumer X  X  requirements are satisfied, then he will select the cheapest product, i.e., the one with the highest quality on the attribute of  X  X rice X . In this case, we can set the weight of all attributes to zero except the  X  X rice X  based on the l 1 norm metric as defined in Equation (2).  X  Richman metric (RM). Unlike the price metric , some consumers may be rich and they are insensitive to the price but only want the best product. In this case, we can set the weight of  X  X rice X  attribute to zero while setting the weight of other attributes to one.

Example 2. To illustrate, let us consider the products and consumers depicted in Figure 1. Suppose that manu-facturer M decides to produce p 3 , then the set of available products in the market is P = P E  X  X  p 3 } = { p 1 ,p us consider the probability c 2 will adopt p 3 , i.e., Pr(2 , 3 |P ) , when c 2 uses the above four distance metrics. From Fig-ure 1, one can observe that c 2 is satisfied by p 1 , p 2 If c 2 uses the discrete metric , then d 2 , 1 = d 2 , 2 Pr(2 , 3 |P ) = 1 / 3 . If c 2 uses the norm metric , then we have d probability Pr(2 , 2 |P ) = Pr (2 , 3 |P ) = 1 / 2 . If c metric , then we only need to consider the attribute inverse of c 2 will adopt p 3 . If c 2 uses the richman metric , we have d 2 , 1 = 3 , d 2 , 2 = 1 , d 2 , 3 = 0 . Thus c 2 will adopt p Pr(2 , 1 |P ) = 1 and Pr(2 , 3 |P ) = 0 .
To find the k most marketable products, we first need to define the expected market share of a set of products under the distance-based adoption model. Given the market con-dition, i.e., the consumers C and the existing products P let P be the set of products we consider, then the expected market share of P is defined as where l = |C| , PC ( p j ) denotes the set of potential consumers of product p j , and Pr( i,j |P E  X  P ) is defined in Equation (1).
Example 3. Let us illustrate the expected market share of p 3 , or MS ( { p 3 } ) , by considering the scenario depicted in Figure 1. There are two existing products ( P E = { p and three consumers ( C = { c 1 ,c 2 ,c 3 } ) in the market. By adding product p 3 into the market, p 3 satisfies consumers c and c 3 . Assume that c 2 uses the norm metric , then accord-ing to Example 2, we have Pr(2 , 3 |P ) = 1 / 2 . Now consider consumer c 3 . Since we have not added p 4 into the market, p 3 is c 3  X  X  only satisfactory product, so c 3 will adopt p sure. Therefore, in this scenario, c 2 and c 3 will adopt p probability 1 / 2 and 1 , respectively. So the expected sales of p 3 is 1.5 units, It follows that the expected market share of p 3 is 1 . 5 / 3 = 50% since there are three consumers in total.
Based on the definition of market share in Equation (3), we formulate the k -M ost M arketable P roducts ( k -MMP ) problem as follows.

Definition 3. ( k -MMP ) Given a set of consumers C , a set of existing products P E = P C  X  P M in the market, and P N , a set of candidate products by the manufacturer M , select a set P  X  P N where | P | = k so to maximize MS ( P  X  X  M ) for manufacturer M .

To solve the k -MMP problem, we need to tackle the fol-lowing two issues: (1) Find the proper distance metrics for the market. (2) Design an efficient algorithm to find the solution to the k -MMP problem. Since there are various potential distance metrics and manufacturers usually do not know which distance metrics the consumers may adopt, we present a learning approach to discover the proper set of distance metrics for a given market from historical purchase data. This is presented in Section 3. After deciding on the proper distance metrics, we present the algorithmic design in solving the k -MMP problem. In Section 4, we present an efficient and exact algorithm for the 1-MMP problem and prove that the k -MMP problem is NP-hard when k  X  2. In Section 5, we present an efficient approximation algo-rithm. By exploiting the monotonicity and submodularity properties of the market share function MS (  X  ), we prove that our approximation algorithm can provide high performance guarantee on the quality of the solutions.
As discussed in Section 2, there are various distance met-rics one can use and the product selection results can vary significantly depending on the distance metrics according to the results shown in Section 6. Hence, it is important to  X  learn  X  about the proper distance metrics (in other words, consumers X  product adoption behavior) from the available data. In this work, we propose a learning method based on the market share of a set of products in the market so to discover the appropriate distance metrics.

Note that in real life, some manufacturers may not release full information about their market share. Therefore, we assume that we only know the market share of a subset of existing products. Formally, let P 0 E be the n 0 products that we know the market share data, where P 0 E  X  X  E . Let ms be the market share of p j  X  X  0 E .

Assume that we have a model set consisting of distance-based product adoption models using m 0 different potential distance metrics, which are numbered from 1 to m 0 e ji be the expected market share of product p j under the product adoption model using the i -th potential distance metric. Let  X  i be the probability that consumers use the i -th distance metric, and  X  = (  X  1 , X  2 ,..., X  m 0 ) can forecast the market share for each product p j  X  X  0 E where f j ( X ) is the forecast market share of product p j
We can find the best fit for  X  by minimizing the squared difference between the forecast market share f j and the real-world market share ms j . Let  X  j be the difference between f and ms j , or mathematically,  X  j ( X ) = | f j ( X )  X  ms j | . We can formalize the model selection problem as follows. where  X   X  0 means that  X  i  X  0 ,  X  i  X  X  1 ,...,m 0 } . Thus, the problem is reduced to a linear regression problem with con-strained least squares approach, which can be solved using the technique in [3]. Once we solve this linear regression problem, we can forecast the market share f j ( X ) based on the probability vector  X .

Example 4. Consider a model set consisting of adoption models using the norm metric (NM), the price metric (PM) and the richman metric (RM). Assume we obtain the real-world market share of three products p 1 , p 2 , and p 3 and we want to forecast the market share of p 4 . The real-world mar-ket share and the expected market share under three different models of these products are shown in Table 4.

Let  X  1 ,  X  2 , and  X  3 be the probability of consumers using the norm metric , the price metric , and the richman metric , respectively. Then we can formalize the problem as follows.
Minimize subject to  X   X  0 ,  X  1 +  X  2 +  X  3 = 1 . We obtain  X  = (0 . 3074 , 0 . 6926 , 0) T by solving the above opti-mization problem. Thus, we can forecast that the real-world market share of p 4 as (10% , 40% , 5%)  X   X  = 30 . 78% .
In Section 6, we will show that we can estimate the proba-bility vector  X  with high accuracy if we know the model set and the market share of a small number of products, based on which, we can find products with higher market share.
Let us first present the exact algorithm for solving a spe-cial case of the k -MMP problem when k = 1. This will serve as the foundation of our approximation algorithm in Section 5. Then we prove the NP-hardness of the k -MMP problem when k  X  2.
One way to find the exact solution of the 1-MMP prob-lem is via exhaustive search: Calculate the expected market share for all candidate products in P N and select the prod-uct with the largest market share. To calculate the expected market share of a product, we need to check the requiremen-t vectors of all l consumers and the quality vectors of their satisfactory products with time complexity O ( mld ), where m is the number of existing products and d is the dimension of the attribute vector A . Assume that we consider a model set S consisting of m 0 potential product adoption model-s. Since there are n candidate products, the computational complexity of the exhaustive search is O ( m 0 mnld ).
In the following, we present an enhanced algorithm for the 1-MMP problem based on precomputation. This en-hanced algorithm has a lower computational complexity, or O ( m 0 ( m + n ) ld ). The pseudo code of this algorithm is shown in Algorithm 1.
 Algorithm 1: Exact top-1 algorithm Input : P E , P M , P N , C ,S,  X 
Output : 1-MMP for all model t in S do end max increase  X  0; for all p j  X  X  N do end return res
Lemma 1. The computational complexity of Algorithm 1 is O ( m 0 ( m + n ) ld ) , where m 0 = | S | , m = |P E l = |C| , d = |A| .

Proof. Firstly, it takes O ( d ) time to calculate the dis-tance for each pair of consumer and product under each adoption model, while there are l consumers, m existing products, and m 0 product adoption models, so it takes O ( m in total. Then, for each product p j  X  X  N , we calculate the increase of sales caused by adding p j , which takes O ( m time. Since there are n candidate new products, the com-plexity of these steps is O ( m 0 nld ). Therefore, the total com-putational complexity of Algorithm 1 is O ( m 0 ( m + n ) ld ).
Similarly, exhaustive search is a direct approach to find the exact solution of the k -MMP problem. By enumerating all possible subsets of size k from P N , and calculating the expected market share of each subset, one can find the set of product with size k which achieves the largest market share. However, the exhaustive approach is not scalable since there exist exponentially many possible subsets. In the following theorem, we formally show that finding the exact solution of the k -MMP problem is NP-hard.

Theorem 1. Finding the exact solution for the k -MMP selection problem is NP-hard when k  X  2 and the number of attributes is d  X  3 .

Proof. Please refer to the appendix.
In this section, we extend the top-1 algorithm for the k -MMP problem using a greedy-based approximation algo-rithm. The algorithm is not only computationally efficient, but also provide at least (1  X  1 /e )-approximation by exploit-ing that the market share function is monotone and submod-ular. In the following, let us first present our approximation algorithm. Then we formally prove its performance guar-antee, and finally prove that the market share function we consider is indeed monotone and submodular.
Our approximation algorithm is based on the exact top-1 algorithm to solve the top-k problem. The main idea is as follows. We select k products in k steps. In each step, we se-lect the product which is the solution of the exact top-1 algo-rithm. Furthermore, instead of building the farthest product tables at each step, we only build them in the first step, and then update the tables in the remaining steps. The pseudo code of this algorithm is depicted in Algorithm 2.
 Algorithm 2: Approximation top-k algorithm Input : P E , P M , P N , C ,S,  X  ,k Output : k -MMP while | P res | &lt; k do end return P res
Theorem 2. (Computational complexity) The com-putational complexity of Algorithm 2 is O ( m 0 ( m + kn ) ld ) , where m 0 = | S | , m = |P E | , n = |P N | , l = |C| , d = |A| .
Proof. Based on Lemma 1, it takes O ( m 0 mld ) time to build these farthest product tables and O ( m 0 nld ) time to find the exact solution of 1-MMP . The complexity of up-dating tables is only O ( ld ). Since we only build the tables once and find the 1-MMP k times in Algorithm 2, the com-putational complexity of Algorithm 2 is ( m 0 ( m + kn ) ld ).
To prove the performance guarantee of our approximation algorithm, let us first introduce the notion of  X  submodular set function  X  [11].

Definition 4. (Submodular set function) Given a fi-nite ground set U , a function f that maps subsets of U to real numbers is called submodular if
Next, we show one interesting property of submodular set functions [5], based on which we design our approximation algorithm with theoretical performance guarantee.

Theorem 3. For a non-negative monotone submodular function f : 2 U  X  R , let S  X  U be the set of size k obtained by selecting elements from U one at a time, each time choosing the element that provides the largest marginal increase in the function value. Let S  X   X  U be the set that maximizes the value of f over all k -element sets. Then we have f ( S )  X  approximation, or guarantees a lower bound on the quality of solution as compared to the optimal solution.
 Applying to the k -MMP problem, the ground set is P M  X  P
N , the market share function MS (  X  ) defined in Section 2 maps subsets of P M  X  X  N to real numbers, i.e., the expected market share of products. According to Theorem 3, if we can prove that MS (  X  ) is a non-negative monotone submod-ular set function, then our approximation Algorithm 2 can provide a (1  X  1 /e )-approximation. We leaves the proof of these properties in the next subsection, and once we prove them, we have the following theorem.

Theorem 4. (Performance guarantee) The approx-imation algorithm stated in Algorithm 2 provides at least (1  X  1 /e ) -approximate solutions compared with the optimal ones, where e is the base of the natural logarithm.
Proof. According to Theorem 5, which will be proved in the following sub-section, the market share function MS (  X  ) in Equation (3) is non-negative, monotone submodular. So, according to Theorem 3, Algorithm 2 provides (1  X  1 /e )-approximate solutions.
Let us consider the market share function MS (  X  ) defined in Section 2. According to the definition of MS (  X  ), it is obviously non-negative, so we seek to prove the monotonicity and submodularity properties. For the ease of presentation, we define the following notations. For any set S  X  X  M  X  X  of products, let P S = P E  X  S and S j = S  X  X  p j } , let pr P p j  X  S Pr( i,j |P S ) denote the probability of the consumer c adopting products in S when a set P S of products is available in the market. Furthermore, when a set P of products is available in the market, we define F C ( p j |P ) as the set of consumers that p j is their farthest product, and recall that F P ( c i |P ) is the set of farthest products from c i .
One key fact we use in our proof is that by adding a new product, say p u , only those consumers in F C ( p u change their product adoption decisions. Therefore, to cal-culate the change of market share caused by adding p u , we only need to consider the consumers in F C ( p u |P u ). Mathe-matically, we have the following proposition.

Proposition 1. Let P S be the set of products in the mar-ket, by adding a new product p u into the market, p u  X  X  N the increase of the market share of products in S u is
Based on Proposition 1, we now proceed to prove the monotonicity and submodularity of the market share func-tion MS (  X  ). First, we prove two lemmas (Lemma 2 and 3). Based on these two lemmas, we prove the monotonicity and submodularity properties in Theorem 5.

Lemma 2. Let S  X  P M  X  X  N be a set of products, and p u be another product in P N , p u  X  X  N \ S . For a consumer c  X  X  , if c i  X  F C ( p u |P S u ) , then we have Proof. Please refer to the appendix.
 Lemma 3. Let S and T be two sets of products, S  X  T  X  P
M  X  X  N , and p u be another product in P N , p u  X  X  N \ T . For a consumer c i  X  X  , if c i  X  F C ( p u |P T u ) , then we have Proof. Please refer to the appendix.

Theorem 5. Suppose consumers adopt products follow-ing the distance-based adoption model, then the market share function MS (  X  ) defined in Equation (3) is monotone submod-ular for the k -MMP problem.

Proof. We prove the monotonicity property first. To prove the monotonicity property, we need to show holds, which can be proved by combining the results of Proposition 1 and Lemma 2.

To prove the submodularity property, according to Defi-nition 4, we need to show holds  X  S  X  T  X  X  N  X  X  M and p u  X  X  N .

In the case of p u  X  S , Inequality (12) holds since both sides are equal to 0. In the case of p u  X  T \ S , the right side of the inequality equals 0, while according to the monotonicity, which has been proved, the left side is non-negative. Hence Inequality (12) also holds. In the case of p u  X  X  N \ T , In-equality (12) can be easily proved by combining the results of Proposition 1 and Lemma 3. Thus, Inequality (12) holds  X  S  X  T  X  X  N  X  X  M and p u  X  X  N .
We perform experiments on both synthetic datasets and real-world web datasets. We implement our approximation algorithm and the exhaustive search algorithm in C ++ and perform experiments on a PC with a 16-core 2.4GHz CPU, 30 GB of main memory under the 64-bit Debian 6.0. First, we use synthetic datasets to evaluate the computational effi-ciency and accuracy of our approximation algorithm. Then we apply our algorithm on the real-world web datasets to show the impact of different distance metrics, and how to learn distance metrics from some historical sales data and to perform product selection.
We generate the synthetic datasets using the generator provide by [1]. In a real-world market, products usually do not have high quality on all attributes. Instead, they have high quality on some subset of attributes only. For example, a smart phone with a large screen will have high quality on display but low quality on portability. Furthermore, if a product has high quality on most attributes, then the price of this product will be high in general, which indicates low quality on the price attribute. We generate the datasets of products with negative correlation on attributes: Products which have high quality in one attribute tends to have low quality on at least one other attribute. On the other hand, we generate the consumers X  requirement of each attribute independently using a uniform distribution.

We compare the running time and the market share be-tween our approximation algorithm (or greedy ) and the ex-haustive search algorithm (or exh ). We examine the impact of various factors, including the size of datasets ( n , m , l , d ), the number of new products we need to select ( k ), and mod-els using different distance metrics (four distance metrics as introduced in Section 2). The default settings of these pa-rameters are: m = 100, n = 20, l = 10 , 000, d = 10, k = 2. The computational efficiency and accuracy our experiments are similar under all distance models, so we only show the results for the norm distance metric .

Note that both the running time of our approximation al-gorithm and the exhaustive algorithm increases linearly with m , l , and d , due to the page limit, we only show the results of varying k and n while keeping other parameters as default values. Table 2 shows the speedup of our approximation al-gorithm over the exhaustive algorithm. Figure 2 shows the running time of these two algorithms, where the horizon-tal axis depicts the variation on parameters n (number of candidate products we need to consider) and k (number of products we need to select), while the vertical axis depicts the log scale of the running time, in seconds.

From the table and the figure, one can observe that our approximation algorithm is significantly faster than the ex-haustive algorithm: O ( n k ) times faster when selecting k products from n candidate products. The speedup is around 285,000 even for a small dataset (i.e., select k = 5 product-s from n = 20 candidates). In this case, the running time of exhaustive algorithm is around 40 hours. In the case of selecting five products from n = 80 candidates, our conser-vative estimate on the running time of the exhaustive al-gorithm is about 10 years. In contrast, the running time of our approximation algorithm for all cases remain in less than one second. We also test our approximation algorithm on a larger dataset where m = 1 , 000, n = 100, l = 1 , 000 , 000. We select k = 8 new products from the 100 candidates. Our approximation algorithm still only takes about 7 minutes.
Figure 3 depicts the expected market share of the two algorithms. One can observe that our approximation algo-rithm provides high accuracy: about 0.96 approximation on average as compared with the optimal solution obtained us-ing the exhaustive algorithm. This shows that our algorithm generates results which is much better than the theoretical lower bound guarantee. In fact, the results of the two al-gorithms are exactly the same for over 80% of all experi-ments we performed and our approximation algorithm still provides a 0.82 approximation even under the worst case scenario among all experiments.
In this subsection, we perform experiments on a real-world web dataset, and we aim to show the influence of using dif-ferent distance metrics.

We extract the TripAdvisor dataset from [15]. Hotels and reviewers of these hotels are considered as products and con-sumers respectively in this dataset. The reviewers rated ho-tels on seven attributes: value, room, location, cleanliness, front desk, service, and business service. We use the aver-age rating of an attribute as the quality of that attribute for each hotel. We also add the inverse of the average price of the hotel as the eighth attribute, which is normalized in the range of (1, 5). For each consumer, we extract requirement vector as follows. Let  X  r be the average rating of a hotel X  X  attribute and r i be the rating from the consumer c i . If r is lower than  X  r , it means that c i has a higher requirement than average, and if r i is higher than  X  r , c i may have a lower requirement than the average. Thus, we set the requirement of c i as  X  r +(  X  r  X  r i ). For example, if  X  r = 3 . 5 and r the requirement of c i will be 3 . 5+(3 . 5  X  4) = 3. Table 3 shows the overall statistics of the dataset.
We select the first 605 hotels as the candidate products and set the remaining 1000 hotels as the existing products. We apply our approximation algorithm to solve the 2-MMP problem using the four distance metrics introduced in Sec-tion 2: discrete metric (DM) , norm metric (NM) , price met-ric (PM) , and richman metric (RM) . The results are shown in the first four rows of the second column in Table 4. One can observe that the results vary greatly when we use d-ifferent distance metrics. This implies the importance of inferring and understanding consumers X  adoption behavior.
In the following, we evaluate the accuracy of our learning method using the same dataset in the last subsection. Since we do not have the information about products X  real-world market share and consumers X  adoption models, we manually set the probability  X   X  that consumers use the above four distance metrics. Then we randomly set the distance metric for each consumer according to  X   X  and estimate the  X  X eal-world market share X  by enumerating each consumer X  X  choice. We estimate the probability as  X  using the learning method in Section 3 and compare the normalized root-mean-square error (NRMSE) between  X  and  X   X  to evaluate the accuracy of our learning method. Note that NRMSE ranges in (0 , 1) and lower value implies higher accuracy.

We present the experimental results in the case that  X   X  = P
E of five products are known. Firstly, we calculate the expected market share of these products under all the four potential models. The results are shown in Table 5 along with the  X  X eal-world market share X .

Then, by solving the following optimization problem, we can estimate  X  = (0 . 1084 , 0 . 1979 , 0 . 5953 , 0 . 0984) observe that  X  is very close to  X   X  ( NRMSE  X  0 . 0099), which indicates a high accuracy of the estimation.

Minimize subject to  X   X  0 ,  X  1 +  X  2 +  X  3 +  X  4 = 1 .

Based on the derived probability  X , one can forecast the market share of products and make a better product selec-tion decision. The result of the 2-MMP problem in this scenario is shown in the last row of Table 4. For the selected products under each adoption model in Table 4, we estimate the  X  X eal-world market share X  and list the result in the last column. One can observe that, the product selection result based on learning the proper weighting of distance metrics achieves a better market share than other distance metrics.
We also select different sets P 0 E of products that we know the market share and examine the NRMSE . The results are shown in Figure 4, where the vertical axis is the NRMSE of the estimation, the horizontal axis of (a) is n the size of P 0 E , and the horizontal axis of (b) is the average variance  X  2 of the expected market share of products in P under different models when n 0 = 5 and n 0 = 20.

One can observe that our estimation maintains a high ac-curacy in general. The average accuracy is about 0.035 even in the case that we only know the market share of five prod-ucts. Furthermore, the accuracy increases exponentially fast when the size of P 0 E increases. On the other hand, product sets with larger  X  2 have higher accuracy, which is realistic since if the market share varies slightly under different mod-els, it may be difficult to estimate.
 Due to the page limit, we only present the above example. We like to note that our results and conclusions are consis-tent when we vary  X   X , model set, or any other parameters. Product selection: Let us provide some related work on product selection. In [6], authors formulated a number of mi-croeconomic applications as optimization problems via data mining perspective. Inspired by [6], Li et al. [7] extended
Figure 4: Accuracy of distance metric learning the concept of dominance, which is used as skyline operators [1] to analyze various forms of relationships between prod-ucts and consumers. A manufacturer can position popular products effectively while remaining profitable by analyz-ing the dominance relationships. The works in [16, 14, 13, 12] considered the situation that there exist multiple man-ufacturers. The authors of [16] derived the Nash Equilibri-um when each manufacturer modifies its product in a round robin manner to maximize the market share. Wan et al. [14] aimed to find the most competitive products which are not dominated by any competitors without taking into accoun-t the consumers. They extended their work in [13, 12] by considering the consumers X  preferences. However, the above papers all aimed to maximize the number of potential con-sumers , which is not equivalent to the market share derived in this paper. In fact, potential consumers may not lead to higher market share because different consumers have differ-ent probability to adopt new products. Authors in [8] aimed to find the products with the maximum expected number of total adopters, which is similar with the market share in our paper. But their algorithm could not provide any theoret-ical performance guarantee. Furthermore, none of the pre-vious works consider the complicated product adoption be-havior of consumers. Instead, they assumed that consumers will make randomly product adoption decisions, which cor-responds to a special case of our product adoption model using the discrete norm .
 Maximization of submodular functions: Submodular functions have properties which are very similar to the con-vex and concave functions. The authors of [2, 11] showed that a natural greedy hill-climbing strategy can achieve a provable performance guarantee for a problem of maximiz-ing a non-negative monotone submodular function: at least 63% of optimal. Due to the generality of this performance guarantee, this results has found applications in a number of areas, e.g., discrete optimization [10], materialized view [4], and influence maximization [5].
In this work, we present the problem of finding the k most marketable products ( k -MMP ) under a distance-based adoption model. Our adoption model is general in that we can use different distance metrics to describe various con-sumers X  adoption behaviors. Given some historical data sets on market share, we propose a learning method to selec-t the appropriate distance metrics to describe consumers X  production adoption behavior. We prove that the k -MMP problem is NP-hard when k  X  2 and the number of products X  attributes, d , is three or more. We propose a polynomial time approximation algorithm to solve the k -MMP prob-lem. Using the submodularity analysis, we formally prove that our approximation algorithm can guarantee a (1  X  1 /e )-approximation as compared to the optimal solution. We compared our approximation algorithm with the exhaus-tive search algorithm on the synthetic datasets. The results showed that our approximation algorithm can achieve O ( n times speedup when selecting k products from n candidates. Furthermore, the solution quality of our algorithm is about 96% on average, which is much higher than the theoretical lower bound. We also perform experiments on the real-world web datasets to show the crucial impact of different distance metrics and how we can improve the accuracy of product s-election using our distance metric selection method. The work of John C.S. Lui is supported in part by the GRF Grant 415112. [1] S. Borzsony, D. Kossmann, and K. Stocker. The [2] G. Cornuejols, M. L. Fisher, and G. L. Nemhauser. [3] P. E. Gill, W. Murray, and M. H. Wright. Practical [4] V. Harinarayan, A. Rajaraman, and J. D. Ullman. [5] D. Kempe, J. Kleinberg, and  X  E. Tardos. Maximizing [6] J. Kleinberg, C. Papadimitriou, and P. Raghavan. A [7] C. Li, B. C. Ooi, A. K. Tung, and S. Wang. Dada: a [8] C.-Y. Lin, J.-L. Koh, and A. L. Chen. Determining [9] X. Lin, Y. Yuan, Q. Zhang, and Y. Zhang. Selecting [10] G. L. Nemhauser and L. A. Wolsey. Integer and [11] G. L. Nemhauser, L. A. Wolsey, and M. L. Fisher. An [12] Y. Peng, R. C.-W. Wong, and Q. Wan. Finding top-k [13] Q. Wan, R. Wong, and Y. Peng. Finding top-k [14] Q. Wan, R. C.-W. Wong, I. F. Ilyas, M. T.  X  Ozsu, and [15] H. Wang. [16] Z. Zhang, L. V. S. Lakshmanan, and A. K. H. Tung.  X  Proof of Theorem 1:
Proof. The NP-hardness proof can be achieved by trans-forming an NP-hard problem, called the top-k Representa-tive Skyline Product (top-k RSP) [9], to a special case of the k -MMP problem.

Let us state the top-k RSP [9]. Given a set U of points and a positive integer k , compute a set S of k skyline points such that the number of points dominated by these k points is maximized. A point p = ( p [1] ,p [2] ,...,p [ d ]) dominates i  X  d and there exists at least one dimension k such that p [ k ] &gt; q [ k ], and we denote this as p q . Consequently, the skyline point is defined as follows. Given a set U of points, the skyline points of U are the set of S  X  U points which are not dominated by any points in U .

Given an instance of top-k RSP problem, we construct an instance of k -MMP problem, which can be carried out as follows. Set P E =  X  , i.e., m = 0. Let P N be the set of skyline points in U , and C be the rest, i.e., C = U \P N that in general, the concept of dominance is different from product satisfiability as stated in Definition 1. Formally, we have p j c i  X  p j % c i , but p j % c i ; p j c i . However, if p % c i but p j c i , then the quality vector of p j is exactly the same with the requirement vector of c i , i.e., p j and c have the same location in the d -dimensional space. But in our construction, the product points are skyline points while the consumer points are not, so there does not exist such kind of c i and p j pairing in our construct. Therefore, we can treat dominance and product satisfiability to be the same in this instance.

Let P be the set of k products we select from P N . In this case, since there is no existing product, so if a consumer has any satisfactory product in P , the consumer will adopt one unit of products in P , otherwise, 0. As a result, the expected number of adopters is equal to the number of consumers who have satisfactory products in P . In another word, MS ( P ) is equal to the total number of points dominated by the skyline points in P divide by the total number of non-skyline points. Since the total number of non-skyline points is fixed, the result of the corresponding top-k RSP problem is also the result of this instance of the k -MMP problem.

Therefore, any instance of the top-k RSP problem can be transformed to an instance of the k -MMP problem. Since the top-k RSP problem has been proved to be an NP-hard problem, the k -MMP problem is also NP-hard .  X  Proof of Lemma 2:
Proof. To simplify the proof, we define the following notations. Let  X  = | F P ( c i |P S u ) | and s = | F P ( c where  X   X  s  X  1. Let d = d i,j where p j  X  F C ( c i |P S F C ( p u |P S u ), we have d i,u  X  d . If d i,u &gt;d , then c p u with probability 1, i.e., pr i ( S u ) = 1. While pr 1, so Inequality (9) holds. If d i,u = d , then F P ( c | F P ( c i |P S )  X  S | = s  X  1. When  X  = 1, F P ( c i |P set, which means p u is c i  X  X  only choice, the situation is the same with the case of d i,u = d . So we only need to consider the case when  X &gt; 1. Bring the notations into Inequality (9), we have which can be proved by observing that  X   X  s and  X &gt; 1.  X  Proof of Lemma 3:
Proof. Because S u  X  T u , p u has more competitors when a set T u of products is available in the market. As a re-sult, F C ( p u | T u )  X  F C ( p u | S u ). Since c i  X  F C ( p c  X  F C ( p u | S u ). Follow the same notations in the proof of Lemma 2, let us consider the case of  X  = 1 first. In this case, pr i ( S u ) = 1, pr i ( S ) = 0, so the left side of Inequality (10) equals to 1. While the right side of the inequality is obvi-ously no larger than 1, so the Inequality (10) holds. Now let us consider the case when  X &gt; 1. According to the proof of Lemma 2, we have Let d T and d S denote the distance between c i and the prod-ucts in F P ( c i |P T ) and F P ( c i |P S ), respectively, where d d Inequality 10 equals to 1, so the inequality holds. Thus, the remaining thing is to prove the inequality holds when d i,u = d T = d S . In this case, F P ( c i |P S u ) = F P ( c F P ( c i |P T u ) = F P ( c i |P T )  X  X  p u } , and F P ( c  X  +  X  = | F P ( c i |P T u ) | , s +  X  = | F P ( c i |P T According to Equation (14) and (15), we can derive Inequal-ity (10) as follows.
 Hence, we only need to show that Inequality (16) holds, which can be proved by observing that  X  &gt; 1,  X   X  0 and  X   X  s .
