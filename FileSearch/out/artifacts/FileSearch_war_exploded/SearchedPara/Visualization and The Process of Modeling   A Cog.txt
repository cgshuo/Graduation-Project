 Models are artifacts used to better understand our world. In the context of mining data to create knowledge, the modeler is often faced with discovering and understanding relationships in data that have no apparent analog in the laws of physical science. Much of these data are increasingly abstract; not directly related to the physical, perceivable world. The use of sketches and diagrams as aids in problem solving and as a means of communication is as old as recorded history. Can visualization help us not only to discover the patterns and relationships in these data, but also to use newly discovered knowledge to build computational models? The purpose of this paper is to provide a description of the process of modeling and, based upon theories of cognition, show how visualization can assist in developing and assessing computational models for very large, high dimensional data sets. H.1.2 [ Information Systems ]: User/Machine Systems X  X uman information processing; H.5.3 [ Information Systems ]: Group and Organization Interfaces--Computer-s upported cooperative work; I.6.5 [ Computing Methodologies ]: Model Development--Modeling methodologies; I.6.1 [ Computing Methodologies ]: Simulation Theory--model classification. Design, human factors, languages, performance. Cognition, representation, visualization, expert modeler. Albert Einstein once wrote, "My particular ability does not lie in mathematical calculation, but rather in visualizing effects, possibilities, and consequences." [30]. As the domain of human endeavor moves increasingly beyond the three-dimensional space-time continuum of our visual experience into abstract problems with many variables and large quantities of data, the need for  X  X isualizing effects, possibilities, and consequences X  has never been greater. The modeler X  X  task is to explore the data, understand the relationships relevant to the problem at hand, and capture those relationships in a computational model that will match a specific need. Visualization is not new. Throughout recorded history, drawings and other visually oriented representations have been an integral part of man X  X  investigation of the world, and of the historical record as well. From Da Vinci to Einstein to the present, visualization has contributed significantly to invention and discovery. What is new is the computational and visual display capabilities of desktop computers. Data analysts have been quick to embrace computer-based visualization, and effective principles of graphical data representation have been elucidated by Tukey, Cleveland, Mosteller, and Tufte, among many others [3, 4, 5, 13, 41, 42, 43]. The modeling community, including decision support and knowledge-based systems practitioners, has perhaps had less success in exploiting visualization to facilitate the development of and to improve the quality of models. The demands of building models in increasingly abstract, data-rich domains increase the potential benefits of successful model visualization. Just as word-processing software has made almost everyone who wishes to be so a publisher, spreadsheet software has made millions of people potential modelers [34, 35]. A surprisingly large number of these people have, in fact, constructed computational models. While it is easy to create various kinds of presentation graphics from these spreadsheet models, there is very limited support for the actual process of conceiving, building, validating, and communicating the models themselves. We believe that significant advances in modeling tools are possible using visualization. What unique capabilities of our visual and cognitive systems can be leveraged to better help modelers exercise their craft, or to place modeling within reach of more people? In attempting to answer this question, we will of necessity consider theories of 
Permission to make digital or hard copies of part or all of this work or personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to permission and/or a fee.

KDD 2000, Boston, MA USA  X  ACM 2000 1 -58113 -233 -6/00/0 8 ...$5.00 model building, vision, and cognition, and will examine the role of visualization in the modeling process. We will suggest areas of opportunity for advancing the state-of-the-art in visual modeling tools. A model is an abstraction of reality. Modeling, the act of building a model, can be described as the process of developing an analogical system of relations, and the resulting model is comprised of entities and the relationships between them [51]. Modeling is  X  X  fundamental way in which human beings understand the world X  [31]. Modeling is closely related to and may be thought of as a subset of problem solving. There are many kinds of models. The literature contains a variety of dimensions along which models may be classified. These include function, structure, dimensionality, degree of certainty, temporal reference, degree of generality, degree of closure, and degree of quantification [46]. In seeking to improve the quality of computational models, and make their construction more universally achievable, we are most interested in the modeling process. Morris [24], while warning against trying to move modeling too far out of the  X  X ntuitive X  realm of an art, describes the process as consisting of the  X  X ontext of discovery X  and the  X  X ontext of justification. X  He observed that models are developed in a discovery context and then presented in a justification context that may have little, if any, resemblance to the original discovery process. This poses an impediment to those trying to learn modeling as a skill, since they are most often exposed to the justification context. The visualizations supporting each context may be quite different. Several theories of modeling and problem solving divide the process into stages [51, 46]. In general, the stages include problem identification or recognition, problem definition and structuring , alternative generation , alternative selection , and implementation . These are not carried out in sequential order but rather expert modelers move back and forth between stages as needed. Complex problems are often decomposed into simpler problems, so the modeling process is applied recursively and the modeler can be in different stages at different levels of the problem. A number of researchers have examined how the modeling process varies with the experience-level of the modeler. The significantly better performance of experts can be at least partially explained by their superior organization of and access to knowledge. Another characteristic is their continual self-monitoring of progress. Experts often suspend an activity at one stage and return to an  X  X arlier X  stage [51]. Less experienced problem solvers tend to move rapidly to the alternative generation and selection stage without sufficient problem identification and structuring [36]. We refer to the thought processes that monitor progress in building a model as meta-cognition . A slightly different explanation of expert performance sees modeling as consisting of search and recognition. An expert is able to replace search with recognition, a faster and usually more reliable process [21]. Newell and Simon [26] defined problem solving as the co-operative processes of understanding and searching. The understanding process generates the person's internal representation of the problem (mental model) and the search process generates a solution. If level of experience is seen as a continuum from beginner to expert, the beginner will approach a problem quite differently from the expert. However, after modest training, compared to the time required to become an expert, the novice will begin to take approaches similar to those of the expert. The novice, however, will search in less productive solution spaces and will make more mistakes [43]. Willemain [50, 51], who studied the behavior of expert modelers, suggests five modeling  X  X opics X  or objects of attention which may be used to categorize the time spent creating a model. They are (1) problem context , (2) model structure , (3) model realization , (4) model assessment , and (5) model implementation . During the context phase, which normally begins first, modelers tend to mentally step through the other stages. Willemain found that the most time was spent on structure (average of 57%) followed distantly by assessment and context (15% and 13%, respectively). Transitions between topics were frequent, with the largest number occurring between structure and assessment. (This frequent transition is an important distinguishing behavior of expert modelers.) Because these expert modelers were performing their tasks in a laboratory setting, realization, assessment, and implementation probably received less attention than they would in a real-world problem where validation and successful transition of the model to the customer (users) become critical issues. Modelers today need both modeling skill and tools skill. A good tool should be essentially transparent to the user. Otherwise valuable working memory and cognitive resources will be spent on the tool instead of on the modeling task itself. If you have to think about a pencil to write with one, the quality of your writing will suffer. To achieve this transparency, the tool must be flexible enough to be tailored to the individual user X  X  personal style and preferences as well as to the particular modeling task [48]. As with all software, visualization tools should be easy to learn and use. Otherwise modelers may not be willing to invest the time to learn the tool or the effort to use it, even if the tool can help create better models [39]. The conclusion we draw from the literature is that modeling is a flexible, recursive process which is dependent on the individual practitioner, the practitioner's skill level, and the modeling task. Finding the right representation for a given problem or sub-problem and a particular user is sometimes referred to as cognitive fit [18, 38, 44]. Highly successful modelers are adept at monitoring their progress and at revisiting any aspect of the process as needed. This means that tools designed to assist modelers in their tasks must be equally flexible. They should support recursive problem decomposition. If intended to assist novice modelers, the tools might even encourage revisiting the context and structure topics at any level of model development. When the human brain is compared to that of other species, several differences stand out. One is the expanded prefrontal lobes where deliberate thought and planning take pl ace. Wit hout this capacity, modeling would not be possible. A second is our greatly expanded areas for language, which make it possible to communicate abstract ideas through speaking and writing. A third is an expanded region for the processing of complex visual information. Finally, expanded temporo-parietal areas carry this complex visual information to the language and conceptual regions of the brain. (See [30].) Sensory perception is closely related to two of these distinguishing features of the brain. Our auditory sense is closely associated with language, for which speaking and hearing are the primary expression. For example, the hearing-impaired often experience difficulty in language development. The other associated sense, vision, is by far the predominant mode by which humans perceive the world in which we live [29, 45]. A quick look at language can help us better appreciate our visual capabilities. Language is inherently one-dimensional, sequential. This is necessarily so because s ound waves arrive at the ear of the listener over time. The cognitive processing which interprets this audio sensory information is such that even if multiple sources of sound (i.e., multiple people speaking) are picked up by the mechanisms of the ear, we are generally unable to comprehend multiple threads of conversation simultaneously. Nor does written language free us of this single-dimensionality. The symbols of a written language, usually associated with sounds or sequences of sound, form strings of symbols which have meaning and which can easily be converted back into meaningful audio sequences (read aloud). What was sequenced with respect to time in spoken language becomes sequenced with respect to a spatial dimension when the language is written. Vision, by contrast, is not one-dimensional. The retina of the eye, which is an extension of the brain, is a two-dimensional surface with topographical mapping to visual portions of the brain [45, 20, 30]. A variety of mechanisms including ocular convergence, vertical disparity, occlusion, and motion parallax provide information about the distance to an object in the visual field, the third spatial dimension. The result is that we usually interpret the stimulus reaching our eyes in a three-dimensional manner. Because the brain appears to handle the depth information differently from the other two spatial dimensions, Marr [22] dubbed our internal representation of the 3-dimensional world as a  X 2 1/2-D sketch. X  In addition, neurological structures provide our visual perception. This permits, for example, detection of motion. When text, i.e., symbols representing natural language, are placed on a page, which is inherently 2-dimensional and can be traversed by the eyes in either direction, it is rare for a person to be able to comprehend the meaning in other than a sequential fashion; line-by-line in the case of English. These sequential representations are sometimes referred to as sentential [21]. Waisel [46] defined sentential as information that can be represented digitally using only ASCII. Diagrammatic representations may be distinguished from sentential representations by observing that information in a diagrammatic representation is indexed spatially, by location in two or three dimensions, and is processed by the visual portions of the brain [21]. Natural language, whether heard by the ears, seen by the eyes, or felt by the fingers, is primarily processed by the language areas of the brain. To illustrate this difference, consider the 2-dimensional array of text blocks that we commonly refer to as a table (see Table 1). While the content of each cell is clearly sentential, the arrangement of the cells is spatial, and cells can be, and usually are, indexed in a non-sequential manner. Visual processing is largely parallel in nature. Each eye contains around 130 million photor eceptors that converge to a bout 1 million fibers (communication pathways) in each optic nerve. At the center of the retinal field of vision, the fovea, receptors may map directly to optic nerve axons, providing a high degree of resolution. The number of receptors mapping to a single optic nerve fiber increases with distance from the fovea, resulting in a marked decrease in visual acuity in peripheral vision. The optic nerves cross and divide at the optic chiasma with nerves from the left side of each retina going to the left side of the brain and vice versa. The integrity of each of these two million channels is maintained from the eye through much of the visual regions of the cortex, providing many layers of neural processing of visual information [45]. As a result, a number of visual features including motion, color, intensity, size, intersection, closure, orientation, lighting direction, and distance from the observer may be extracted  X  X reattentively, X  without conscious effort and within 100-200 milliseconds. Such features seem to  X  X op out X  of the visual scene [12]. Card et al. [2] refer to this as "automatic" processing. Parallelism also exists in higher levels of the brain where, for example, processing of spatial information appears to occur separately from processing of texture or motion [20]. Our ability to process and think about information relating to the three dimensional world is not limited to what we see, any more than our ability to understand linguistic expression is limited to what we hear. For example, if someone asks you,  X  X hich is darker, a Christmas tree or a frozen pea? X  there is g ood chance you will create a mental image of each and compare them (from [30]). Many of the same portions of the brain which are active when looking at a physical scene are also active when a detailed mental image is created and examined [20]. There are some important differences, however. Experiments suggest that it is difficult to construct and maintain detailed images in memory [7, 20]. As the complexity of the image increases, our ability to examine or manipulate the image to solve problems becomes increasingly inferior to our ability to use an external visualization to solve the same problem [32]. Furthermore, a mental image is apparently stored in a particular context, probably incident to the indexing mechanisms used to retrieve it, and it is difficult to  X  X ee X  things in the mental image which are not normally a part of that context [7, 30]. This is less true of visualizations, which are perceived more like the real world and are more amenable to a change of context. In this paper, we will use the words image and imagery to refer to mental images and the word visual and visualization to refer to external representations. Non-sentential representations will be referred to as spatial, diagrammatic, or graphical. A number of researchers report that creative insight and problem-solving performance can be improved with appropriate visualizations [46, 33, 30, 14]. At least two explanations for this improvement are offered in the literature. The more common is that visualization extends working memory by using the massively parallel architecture of the visual system to make an external representation function as an effective part of working memory [21]. Using concepts of expressiveness and effectiveness , Stenning and Gurr [37] alternatively suggest that the strength of diagrammatic representations may, in fact, lie in their limited expressiveness. By reducing the degrees of freedom of expression, interpretation becomes easier, thus making diagrams more effective. In other words, sentential representations allow ambiguities that cannot exist in spatial visualizations. To illustrate, the statement,  X  X he lemon is next to the banana. X  tells us nothing about which is on the left, which on the right. Now try to imagine a lemon next to a banana. Ambiguity is not possible; it must be on the right or the left (from [30]). Representation , used repeatedly in the preceding paragraphs, it is a critical concept. Gardner [8] defines representation as the level of explanation, including symbols, rules, and images, between neuroscience and behavior. Marr [22] wrote,  X  X  representation is a formal system for making explicit certain entities or types of information, together with a specification of how the system does this. X  It follows that any particular representation will make explicit certain information at the expense of other information that is pushed into the background and made more difficult to recover. Jones [18] observes that representations suitable for a computer algorithm are often impenetrable to humans and vice versa, and that experts in modeling and optimization may prefer different representations from experts in the problem domain. Representation will be central to any attempt to enhance the creation and use of models. Reference has already been made to sentential versus diagrammatic and mental versus external representations. Until recently, most external representations, whether created by painting on a cave wall, depositing pigment on paper, or exciting phosphors on a computer screen, have been on flat (2-dimensional) surfaces. Advances in computational power and display technology are making possible representations that can be perceived as both dynamic and 3-dimensional. Virtual reality allows the perceiver to interact with these representations. Interest in visual modeling is heightened by the expectation that technological advances will continue to open up new opportunities to leverage human visual perception. Recent interest in diagrammatic reasoning has led to a more rigorous understanding of what makes a representation useful and how reasoning with diagrammatic representations is similar to and different from reasoning with sentential representations [11]. Ideally, every relevant relationship between entities in a represented world should hold between corresponding entities in a model. Such a model is said to be homomorphic [10] and represents a minimal requirement for a model to be considered tractable and well behaved. A more stringent requirement, leading to even stronger models, is that the homomorphic mapping from represented world to model have an inverse mapping from the model back to the represented world which is also homomorphic. Such a model is said to be isomorphic [10]. As a simple example, image a number line with negative numbers to the left and positive numbers to the right. Such a number line constitutes an isomorphic representation of the abstract concept of real numbers. The relationships  X  X o the left of X  and  X  X o the right of X  in the model (the number line) map exactly to the relationships  X  X s less than X  and  X  X s greater than, X  respectively, in the system of real numbers. The inverse mapping is equally robust. A generally accepted axiom of modeling states that models s hould  X  X epresent as little as possible explicitly X  [17] while still supporting solution of the problem at hand. Unn ecessary representation in a model simply makes it more difficult to focus on the important aspects of the problem. This is consistent with the view of Alabastro et al. [1] that visual models  X  X ignificantly increase the speed and quality of model development X  by focusing attention on what is absent and important (and should therefore be added) and what is present and unimportant (and should therefore be eliminated). (See also [23].) All of this is to say that an ideal model will have one and only one entity for each relevant entity in the system modeled, and that for each relevant relationship between entities, there will be one and only one relationship in the model. The relationships in both worlds should behave similarly. To better understand the hypothesis that a visualization is effective because it extends working memory, a model of cognition is useful. Several models have been suggested in the literature (Baddley and Hitch, 1974 [9]; EPIC [19]; ACTOR [25]). One of the best-known is the Model Human Processor (MHP) proposed by Card, Moran, and Newell in 1983 [25]. As shown in Figure 1, this model views the sensory image buffers as part of working memory, and working memory as part of long-term memory. The cognitive processor takes input from long-term memory and from working memory, including the sensory buffers, and returns results to working memory. If the visual image buffer contains information relevant to the cognitive task at hand, working memory is effectively increased. The perceptual processors, shown together for simplicity, work in parallel with the main cognitive processor. In the case of vision, this gives rise to the preattentive effect noted previously and, assuming relevant visual content, brings increased cognitive processing power to bear on the task. The MHP characterizes each memory by the type of storage, the capacity, and the decay rate, and each processor by a cycle time. Long-term memory is of essentially unlimited capacity and has a very low decay rate. Working memory is of limited capacity and duration as are the sensory buffers. As an interesting aside, the auditory buffer can be refreshed using sub-vocalization in a phonological loop, as when we repeat a phone number to ourselves until we have dialed it [9]. One of the strategies used to increase reading speed (processing rate of sentential information) is to avoid sub-vocalization because it significantly increases cycle time. Access to information stored in memory is an important requirement for effective cognitive processing, and the organization of this information appears to be a key driver in how readily it may be accessed. In 1956, George Miller presented the idea that if working memory capacity is measured in chunks , it may be thought of as fairly constant --the famous  X  X emory capacity is seven plus or minus two. X  For example, asked to repeat back the sequence  X  X  C A C B S W S J, X  most people will miss some letters since nine items exceeds working memory capacity. However, if a person familiar with the acronyms is presented with or recognizes the sequence as  X  X CA CBS WSJ, X  there will be no difficulty repeating them--the effective load on working memory has been reduced from nine to three [25]. In other words, as we organize material in memory, increasingly large amounts of information can be accessed as a single c hunk as far as load on working memory is concerned. Hence expert modelers increase cognitive capacity through superior organization, i.e. chunking, of knowledge. Johnson-Laird [15] describes three kinds of internal representation: mental models, propositional representations, and images. A mental model is defined as, simply, a model that exists in the mind. A propositional representation is comprised of a set of natural language formulations, i.e., a sentential representation. Images reside in the visual portion of the brain, and can be created either from information flowing  X  X p X  from the eyes or from information flowing  X  X own X  from memory and/or cognitive areas of the brain, including from mental models [30, 8]. The rendering of a mental model, whether sentential or diagrammatic, for cognitive processing can be referred to as a view [15]. Visualization is the external realization of these views in terms of text or diagrams (see Figure 2). As already noted in Section 3.1, mental images are more fluid than visualization and less supportive of complex problem solving. It follows that as problems become more complex, it becomes increasingly difficult to construct and hold in working memory the view(s) necessary to reach a desired goal (i.e., solve a problem, make a decision). A common solution is to anchor at least some aspects of our mental model(s) as visualization(s). We believe such visualization increases understanding. By comparing the view extracted from the mental model with the view created by seeing the visualization, the modeler is able to determine if anything of importance is missing or if the extraneous has been included. This may result in modification of the mental model, the view, and/or the visualization. Willemain X  X  expert modelers demonstrated this process in data captured by the think-aloud protocols [46]. This iterative process of comparison and modification is continued until the modeler is satisfied that the mental model, view(s), and visualizations(s) are consistent and sufficient. Besides extending working memory, anchoring a view as a visualization can be an effective aid in communicating a model to others. Underscoring the communicative aspects of such external representations, Norman [27] notes that almost all tasks require not just the aid of pencil and paper, books, computers, etc., but also of other people. When a group of people is tasked with building a model or solving a problem, each will begin with a different perspective X  X  different mental model. As these mental models are made explicit in external representations, common elements are identified and discussion is focused on understanding and resolving differences [23]. Ideally, the result of this interaction is a group cognitive structure that is better, in some sense, than the starting model of any one individual. Having examined how visualization is believed to contribute to cognitive process and the characteristics of the modeling process itself, we propose a model of how visualization can support modeling. Figure 3 represents an environment for the development and use of computational models. It is assumed that to solve a given problem, the modeler must discover and understand relationships in a large amount of abstract data. By abstract we mean that the significant relationships in the have no physical analog, and therefore, there is no readily apparent real-world representation on which an intuitive visualization could be based. It is the role of the modeler to build a robust model incorporating discovered relationships to some end, i.e., predicting, explaining, etc., and ensure that the model is correct, understandable, and usable. There are three primary uses of visualization represented in Figure 3, and all are potentially interactive as shown by the dashed motor control arrows in the diagram. Exploratory data visualization tools assist the modeler in discovering and understanding relationships within the data. This exploration leads to the creation or enhancement of a mental model which captures the implications of the data relative to the modeling objective. If the visualization and modeling tools are well integrated, this exploration can lead directly to the capture of relationships in the computational model. Otherwise the modeler must construct the computational model manually by interacting with the model visualization software. In either case, the visualization of the computational model allows the user to compare her mental model, or a view of that mental model, with the computational model, and to interact with the model, the model output, and the data until a satisfactory model is obtained. Through the iterative process depicted in Figures 2 and 3, the modeler focuses on the missing but important or present but unimportant, as evidenced by the data, and is assisted in building and refining effective models. Visualizations extracted from the data and the model facilitate cooperative work were diagrams (p = .0005) and visualizations were used sooner for some problems (identified as harder problems) than for others (p = .0011). These data are consistent with the hypotheses that the expressiveness of sentential representations works well in the ambiguous early stages of model development, and that the more difficult the problem, the more need modelers have of visualization. Table 2 suggests the types of visual representations expected to be Modeling Dimension Range Comments exploratory data analysis. Search for modeling approach supported by model visualization. Understanding supported by model visualization and output. Early understanding likely to be expressed sententially .
 output and comparison with data analysis 
Modeling topic [50] Context, structure, realization, 
Visualization found to be significantly related to individual expert modeler and to modeling topic but not to specific problem [46]. See also Table 2 
Objective [6] Exploration, analysis, 
Exploration can be of data and of modeling options. Analysis of data and of model performance (model output). Presentation of relationships (data and model) and of model output 
Modeling skill Continuum from novice to 
Visualization of data, model, and model output, combined with meta-cognitive aids for managing complex problem decomposition, can combine with tutorial systems to help less experienced modelers 
Tool skill Continuum from novice to 
Visualization tools, like other software, should be easily learned and become  X  X nvisible X , i.e. utilization should not require continued cognitive attention. Advanced functionality should be available when needed without being burdensome otherwise (discover, understand, justify) (understand, communicate) most useful to modelers during each of Willemain X  X  [51] modeling topics. These suggestions are based on the results of analysis of expert modelers X  activities and the general cognitive theory reviewed above [51, 46]. Both Tables 1 and 2 suggest areas of additional research to establish a clearer understanding of the ways modelers prefer to use visualizations, of when and how visualization can make the biggest contribution to model correctness, and of how the set of potentially effective modelers may be expanded. In particular, preattentive processing offers promise because of the unique way in which the capabilities of the human visual system are brought to bear on a problem without the modeler sensing any additional effort. How to effectively use preattention is not necessarily clear, however. In general, preattentive attributes do not combine because of the neurological structure at their root. More work like that of Healey et al. [12] will be required to begin to understand the best use of preattention. Another promising area is that of meta-cognitive support. Whether novices fail to continually assess their own progress because they do not have sufficient cognitive resources or for some other reason, visualization can help. Visualization offers an effective way to help the modeler maintain a hierarchical set of sub-models, to maintain the various sub-models at different stages of development, and to move from one level to another without loss of cognitive effectiveness. Parker et al. [28] refer to this as being able to change focus without loosing context . The sketches of Willemain X  X  expert modelers demonstrate quite clearly the use of diagrams to visualize problem decomposition [46]. Modeling is a cognitive process, limited by the working memory of the practitioner. External representation is the primary method of extending working memory. While information technology has expanded our ability to gather and analyze data into increasingly abstract domains, and the quantity of data available is exploding, we struggle to understand what the data mean and to develop robust models which make the newly acquired understanding useful and comprehensible by others. Visualization can be an important part of exploring the data, building the model, and collaborating, but to successfully exploit it we need to understand the modeling process and visualization itself. We have Topic Representational Expectations Comments 
Model realization Model made more concrete as parameters are 
Model assessment Validation of model correctness (assumptions 
Model implementation Implement model; manage its transition into active summarized foundational work in these areas and have proposed a general model of how visualization supports model building. Research in the use of visualization by expert modelers provides evidence relating the type of visualization to the modeling task, but many questions remain unanswered. We suggest additional interactions between visualization and the modeler and modeling process, and hope that the proposed framework will help identify fruitful areas for future research. This research was supported by National Science Foundation grant number 9730465. 
