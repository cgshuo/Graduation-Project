 1. Introduction
Machine Learning employs a variety of supervised/unsupervised learning algorithms to enable the machine to search large amounts of information/data and identify patterns that can be (e.g. association rule mining and clustering) tasks. Rule-based methods are among the most popular machine learning methods because they are quite versatile and also more understandable compared to their rivals due to the representation methods they commonly adopt. These methods use a fi nite set of condition-action rules to represent a small portion of the overall solution space; conditions identify part of the problem domain and actions represent a decision on the sub-problem identi fi ed by the condi-tion ( Lanzi, 2008 ).

Being among the most widely explored rule-based tools, classi fi er systems are popular for their ability to work in multiple environment types and their broad application to tasks of various levels of complexity. In its basic form, a classi fi er system comprises a set (population) of rules (classi fi ers) where each rule represents a potential solution to the target problem. 1 These classi gradually evolve through the use of a reinforcement scheme
Recognizing the shortcomings of LCS, in 1994 Wilson intro-duced the Zeroth-level Classi fi er System (ZCS) ( Wilson, 1994 ). ZCS, too, employs a population of gradually evolving cooperative classi fi ers. Successful classi fi cation of an instance is associated with a scalar reward apportioned to the system classi fi ers accord-ing to a reinforcement scheme. Thus, at each discrete time-step, the system follows a cycle of performance, reinforcement and discovery component activation. It is shown that ZCS can solve problems of low complexity more ef fi ciently than LCS provided that its parameters are  X  tuned  X  properly ( Fani, 2008 ). Nonetheless,
ZCS is shown unable to deal with more complex problems ( Lanzi, 2008 ).

It was not until the introduction of eXtended Classi fi er System in 1995 that the ability of a classi fi er to provide accurate responses was allowed to play a role in reinforcing the classi fi er, hence encouraging initially-na X ve classi fi ers to evolve toward accurate decision makers ( Wilson, 1995 ). Being capable of solving complex problems with little need for parameter adjustments, XCS is believed to be the most successful learning classi fi er system to date ( Lanzi, 2008 )due, in part, to its capability to perform fairly accurately on dynamic, non-linear and noisy environments ( Tsai and Chen, 2010 ). XCS has been the source of inspiration for several other models including UCS ( Bernado  X  -Mansilla and Garrell-Guiu, et al., 2000 ; Butz et al., 2000 ; O ' Hara and Bull, 2005 ; Tomlinson and Bull, 2002 ). Details of the original models of XCS could be found at ( Goldberg, 1989 ; Holland et al., 1998 ) and its recent modi fi cations at ( Wilson, 1995 ; Butz and Wilson, 2000 ; Wilson, 2002 ).

In traditional XCS, the rewards and the stopping criteria are normally provided by a third party and not the environment itself ( Colombetti and Dorigo, 1999 ). The reinforcement mechanism determines the reward of each action according to some prede-fi ned criteria or by system ' s own priorities ( Butz and Wilson, 2000 ). Also, the fi tness of a classi fi er is re fi ned based on the accuracy of the classi fi er  X  s payoff prediction rather than the prediction itself. Unlike LCS and ZCS, rule reproduction takes place in the action sets rather than the entire population. Moreover, XCS lacks a messaging mechanism and is therefore unable to perform ef fi ciently in non-Markov environments ( Butz and Wilson, 2000 ). 2. Problems with the equal-treatment policy in the XCS
The traditional XCS fails to discriminate between classi fi produce correct answers to queries and those that prescribe wrong actions in supervised learning. That is because the experience of a classi fi er, de fi ned as the number of times it attends an action set, regardless of prescribing a correct-or an incorrect action, directly contributes to the updating of its prediction and fi tness values.
Furthermore, in order to produce new classi fi ers and eliminate inef fi cient ones, XCS uses the reproduction mechanism of GA that would produce fresh classi fi ers to replace some of the less-ef fi cient ones. In other words, GA is used as a search mechanism intended to discover more promising rules by recombining the existing ones, where the discovered rules would replace those that do not contribute effectively to the system ' s expertise. In most proportional to the inverse of its fi tness value which often is not justly updated.

One could conclude that the similar treatment of both correct-and incorrect-responding classi fi ers would not only indicate their unjusti fi ably equal chances of survival, but also their somewhat equal chances of making it to the future action sets and possibly producing weak responses to the queries. The authors ' experience with a number of problems of medium to high complexity shows if a member of the action set predicts the correct action, in addition to its experience, its pos-exp is raised by 1 unit; otherwise it remains unchanged. The change in the fi tness of a classi then made proportionate to the ratio pos-exp/exp for all the classi fi ers that attend the action set using the following relation: f  X  f
Where f cl is the classi fi er ' s fi tness,  X  is the learning coef the classi fi er ' s accuracy, num cl is the classi fi er the classi fi er ' s experience and j is summed over action-set ( Butz and Wilson 2000 ).

This would also help preserve more successful classi fi ers by reducing their chance of being eliminated in a conventional, inverse-fi tness-proportionate elimination draw. It would therefore lead to higher rates of convergence and more ef fi classi fi er sets. 3. Case studies
To demonstrate the applicability and ef fi ciency of SRXCS, it was applied to a number of standard data mining problems plus a new benchmark problem in the area of mobile robot path planning. The results are presented here and compared with those from litera-ture (wherever available). This section also highlights the advan-tages of the proposed algorithm. The standard data mining problems examined here include the popular Monk ' s problems (I, II, and III), Iris fl ower classi fi cation, Haberman classi fi cation and the tic-tac-toe game.

Monk ' s problems involve the classi fi cation of a fairly large set of arti fi cially generated data with six attributes into two classes.
Monk ' s I is the easiest of the three which has been successfully tackled by most classi fi cation algorithms. Monk ' s II, however is much more complicated. Some surveys (including ( Thrun et al., 1991 )) suggest that only a small fraction of the traditional machine learning algorithms have been able to thoroughly identify the patterns in the data set, with the rest of the algorithms achieving ef fi ciencies of 57.2% to 93.1%. Monk ' s III is even more complicated because it contains about 5% noise.

The Haberman ' s survival data set contains actual data from a study conducted between 1958 and 1970 at the University of
Chicago ' s Billings Hospital on the survival of patients who had undergone breast cancer surgery.

The Iris data set is one of the most popular benchmark data sets for recognition purposes ( Fisher, 1950 ; Duda and Hart, 1973 ).The problem involves classi fi cation of sample fl owers into three classes, of which only one is linearly separable from the other two.
The Tic-Tac-Toe data set contains the complete set of possible board con fi gurations at the end of tic-tac-toe games, where assumed to have played fi rst. The target concept is for x to win the game.

The results obtained by SRXCS are presented in Table 4 along with those from XCS ( Olgierd Unold and Krzysztof Tuszyn  X  2008 ; Garcia et al., 2009 ), XCSL ( Olgierd Unold and Krzysztof
Tuszyn  X  ski 2008 ), ACS ( Olgierd Unold and Krzysztof Tuszyn 2008 ), C4.5 ( Olgierd Unold and Krzysztof Tuszyn  X  ski, 2008 ; Garcia et al., 2009 ) and ZCS-DM ( Garcia et al., 2009 ).
 training cycles. The parameters and settings of the algorithm are presented in Table 6 .InthisTable, P wc represents the probability of a bit to be set to a wild card in the condition part,  X  represents the fraction of the population ' s average fi tness below which the aclassi fi er contributes to its deletion probability,  X  mna number of distinct actions in the action-set,  X  del is the deletion-probability increase factor for more experienced classi fi subsumption threshold, ASSF (Action Set Subsumption Flag) is a
Boolean parameter that determines whether or not an action-set is to be tested for subsuming classi fi ers and GASF (GA Subsumption
Flag) is a Boolean parameter that de termines whether or not parents are to be tested for subsuming children.
 A typical performance history of SRXCS is demonstrated in
Fig. 1 along with that of XCS. It could be seen that SRXCS converges to its fi nal state much faster than traditional XCS. Moreover, comparison of the fi nal classi fi er sets from the two algorithms revealed that in all 20 experiments, SRXCS resulted in fewer, more general classi fi ers than XCS. This could be partially attributed to the accelerated decline of unsuccessful classi fi ers in SRXCS, aug-mented by Subsumption which encourages the survival of more general and accurate classi fi ers.
 epochs; however, as shown in Figs. 1  X  3 , the SRXCS was more successful in improving the success rate by including the pos-exp/ exp ratio.

A fourth case study presented here involves a mobile robot navigation task. Motivated by the rapidly growing demand for robust control strategies for autonomous systems to work in partially observable environments, the design of Autonomous
Mobile Robots (AMRs) has provided a new test bed for learning agents that were once thought of as intelligent  X  data miners.
Nonetheless, there is no globally adopted benchmark problem in the genre to help assess the performances of various control strategies. For the same reason, a mobile robot control problem is presented here and used to demonstrate the performance of the proposed algorithm.

An AMR is tasked to move in a square fi eld from a starting point to a goal point without colliding with an obstacle of known shape which moves randomly within the fi eld. At each time-step the obstacle would either stay put or move with variable velocity toward the robot, away from it or perpendicular to the line connecting it to the robot (two directions). The sensory data of the robot would include the obstacle ' s current position and its last move. The robot could make the same moves plus the default move toward the goal point, if a collision is deemed improbable.
A schematic of the environment and the obstacle ' s and robot possible moves is presented in Fig. 4 .

The problem was solved by both SRXCS and XCS. Classi fi ers of constant length with eight possible actions and a maximum population size of 2000 were used in both cases. Fig. 5 shows a typical path taken by the robot according to the rules produced by
SRXCS. At the end of the training phase, the two classi fi (from SRXCS and XCS) were tested on 15 randomly generated obstacle position/motion scenarios. The experiment was carried out twice (using two sets of 15 random scenarios.) The results underway in such areas as  X  learning-based conceptual design of mechanical systems  X  and  X  localization of rescue robots in disaster-hit areas  X  , all using the proposed approach. 5. Summary and conclusions
An improved variant of XCS, called Success Rate XCS (SRXCS) was presented. The new classi fi er system features an experience-evaluation mechanism that would allow the classi fi ers '  X  rates  X  to contribute to their rise or decline in terms of performance parameters. A high success rate would promote the classi fi chance to survive and to reproduce whereas a low success rate would render the classi fi er vulnerable to deletion. Using multiple data mining and control case studies, SRXCS was shown to outperform XCS fairly noticeably. The proposed improvement would reduce the computational cost of the training process and would result in fewer, more general classi fi ers in the fi without using the traditional rule reduction techniques. Acknowledgments
Most of the data sets studied in section  X  Case Studies  X  from the UCI Machine Learning Repository ( http://archive.ics.uci. edu/m l). The authors would like to thank the management of the site for sharing those and other valuable data sets.
 References
