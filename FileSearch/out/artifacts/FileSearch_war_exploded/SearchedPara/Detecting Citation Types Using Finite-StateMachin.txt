 Emerging trend detection (ETD) is a new and challenging problem in text min-ing. ETD is commonly defined as  X  X etecting topic areas which are growing in interest and utility over time X  [1]. Recently, several ETD models have been pro-posed [2, 3] in which the ETD process can be viewed in three phases: topic representation, identification, and verification. Each topic  X  the ETD central notion  X  is usually represented by a set of temporal features in the phase of topic representation . These features are then extracted from document databases using text-processing methods in the topic identification phase. After that, the topic verification phase plays the role of monitoring these features over time and classifying the topic by using interest and utility functions [1].

One very significant task for ETD is to find emerging research trends from a collection of scientific articles. This can help researchers quickly understand the occurrence and the tendency of a scientific topic, and thus they can, for example, find the most recent, related topics in the research domain. However, existing ETD models are still poor in representing research topics and inappropriate for determining and ranking interest and utility. Motivated by the need of a more appropriate model for emerging trend detection from scientific corpora, our ultimate target is to build an ETD model which has a richer representation scheme for topics, and to use citation information as one of the characteristics of the ETD model.

Citations appear very frequently in sci entific articles and most of digital li-braries now organize their papers in the structure of citation indexes [4]. By examining the citations inside an article, we can reveal relationships between articles, draw attention to important co rrections of published work and identify significant improvements or criticisms of earlier work [5, 6]. However, this is still very difficult for researchers because the large and increasing number of arti-cles prevents them from reading everyth ing in the published literature. There is a clear need for new tools to identify the types of citation relationships that indicate the reasons for citation in a human-understandable way [7]. The purpose of identifying the reasons for citations (citation type detection -CTD) varies according to the main objective of each research. The method of Nanba and Okumura [8] uses an heuristic sentence selection and pre-defined cue phrases to classify citations into t hree categories for supporting a system of automatic review articles. To extend the usage of linguistic patterns, Teufel [9] uses formulaic expressions, agent patterns and semantic verb classes instead of cue phrases to determine the corresponding class for a sentence. Although both these works show the usefulness of linguistic patterns in citation type de-tection, the manual construction of linguistic patterns is obviously a rather time-consuming task. It also involves some conflicts that are difficult to be resolved. For example, the method of Pham and Hoffmann [10] has to elimi-nate such conflicts and send to human experts for providing rules that resolved them.

The available methods do not appear to be integrated into an ETD process because of two main limitations: the first is their definitions of citation types are not appropriate for evaluating the interest and utility of topics; the second reason is the manual construction of linguistic patterns must depend on the corpus. This makes the detection process become inflexible when applying to other corpora. The work presented in this paper is an intrinsic part of the construction of an emerging trend detection model for s cientific corpora, for that we propose an automatic method for detecting citat ion types. The significant differences of our method compared to other works are: (1) the defined six categories of the reasons for citations which support the detection of emerging trends by tracing the development of a topic and clarify the relationship between articles; (2) our method using finite-state machines can d etect citation types without any need for user-interactions or explicit knowledge about linguistic patterns as were required in [8,9,10].

In the following section, we first define the six citation types and then propose a method for detecting citation types using two kinds of finite-state machines: HMMs and MEMMs. Section 3 describes the experimental comparative eval-uations. In Section 4, we briefly introduce our proposed ETD model and the integration of citation types into the interest and utility functions. Conclusions and future works are given in the last section.
 2.1 Definition of Citation Types Given a paragraph containing citations (we call this paragraph the citing area), we want to detect why the cited paper is mentioned in the purpose of the authors written in this paragraph. It is well known that there are many reasons for citations (citation types). To classify citing areas using citation relationships, we also have to consider the citation t ypes. For example, in [11], Weinstock proposed 15 categories for the common reasons of citations, to build a system for the automatic generation of review articles, Nanba and Okumura [8] classified the reasons for citations into three categories while Pham and Hoffmann [10] used four types of citations for buildin g a citation map between articles.
In order to support researchers in tracing the development of a topic over time as well as clarify the relationship between articles, we classified citation types into the following six main categories (or classes), which are important for emerging trend detection: Type 1: The paper is based on the cited work; it means that the citation shows Type 2: The paper is a part of the cited work Type 3: The cited work supports this work Type 4: The paper points out problems or gaps in the cited work (correspond-Type 5: The cited work is compared with the current work Type 6: Other citations
Note that these classes are overlapping, meaning that a citation area may belong to two or more classes. We will choose the most suitable class label for a citation area and also measure the likelihood of each citing area on a class. Details of technique are discussed in the following sections. 2.2 Citation Type Detection Using Finite-State Machines In this section, we describe the method f or detecting citatio n types. The detec-tion process can be described as follows: Given a citing area consisting of several sentences, we apply finite-state machines to compute the likelihood of each sen-tence on each class. After that, we evaluate the importance of each sentence and combine these values to identify the corre sponding class for this citing area. We present here two methods to evaluate the above likelihood using hidden Markov models and maximum-entropy Markov models, after that we will introduce the sentence-weighting strategy to identif y class label for a given citing area. Sentence Evaluation Using Hidden Markov Models. A hidden Markov model (HMM) is a finite-state automaton with stochastic state transitions and observations whereby a sequence of observations is emitted along the transitions of states over time [12]. A HMM  X  =( A, B,  X  )isdefinedonasetofstates S, a set of possible observations O and three probability distributions: a state transition probability to s j  X  S from s i  X  S : a ij = P ( s j | s i ); an observation distribution for each state s i  X  S :  X  i = P ( q 1 = s i ).

In most text-processing tasks using HMMs, people often use word-based mod-els, i.e, each word (or n-gram) is one observation. The main drawback of these methods is the machine cannot accept unk nown observation symbols or accepts them with a very low probability of emission functions. For example, if we con-sider each English word as an observation, the model trained by the sentence  X  The man walks so fast  X  may produce 0 or a small value depending on the train-ing algorithm when computing the likelihood of the sentence  X  The man goes so fast  X  even though the meaning of the second sentence can be implied from the semantics of the trained sentence. This problem occurs not only with finite-state machines, but also with all word-based methods.

One solution to this problem is enlarging the training set so as to cover all possible cases of synonymy and hyponymy. However, it is difficult to build a large training set and it also increases the complexity of training phase. For example, the method using cue phrases [8] has to construct a very long list of cue phrases; the rule-based method [10] has to add many rules to the rule set in order to achieve high accuracy.

To overcome the drawback of the aforementioned solution, we still use word-based models, but after the training phase, we re-adjust the emission functions of the HMMs so as to deal with the synonym and hyponym of words by: where o  X  o means the word o is a hyponym or synonym of the word o .
For detecting citation types, we used six HMMs, each HMM consisting of n states: S = { s 1 ,s 2 , ..., s n } and accepting the set of English words including  X  \ cite X  as the set of observations O . In the following explanation, we denoted q t and o t as the state of the model and the observation at time t, respectively. In the training phase, we have a number of training sentences for each class. These sentences are used as the input of the training algorithm for estimating model parameters. The standard method to train HMMs is the EM algorithm, alsoknowninHMMcontextastheBaum -Welch algorithm [12]. However, we use the Viterbi training (VT) algorithm instead of EM to avoid expensive com-putation in practice. The VT algorithm just takes the single most likely path and maximize the probability of emitting the observation sequence along its cor-responding path. The details of the Viterbi Training Algorithm is described in [12].

Given an unknown sentence O and six trained HMMs corresponding to six classes, we compute how well the sentence O matches these HMMs by calculating the probability of generating sentence O along its best path on each HMM: where Q ( O ) is the state sequence found by Viterbi algorithms.
 Sentence Evaluation Using Maximum-Entropy Markov Models. The structure of maximum-entropy Markov models (MEMMs) is similar to that of hidden Markov models, but instead of transition and observation probabilities, we have only one single function P ( s | s ,o ) which provides the probability of the current state s given the previous state s X  and the current observation o. This complex function is often separated in to S transition functions P s ( s | o ). In contrast to HMMs, in which the current observation only depends on the current state, in MEMMs, the current observation may also depend on the previous state. It means the observations is associated with state transition rather than with states [13].

In MEMMs, each transition function P s ( s, o ) is often represented in expo-nential form: where f a is a feature,  X  a is a parameter to be learned and Z ( o, s ) is the nor-malizing factor that makes the distribution sum to one across all next state s.

To find the corresponding state sequence to an observation sequence, we can still use an efficient dynamic programming algorithm by modifying some equa-tions of the Viterbi algorithm for HMMs [13]. To train a MEMM, we first split the training data into (state-observation) pairs relevant to the transitions from each state s , then apply the Generalized Iterative Scaling method (GIS) [14] to estimate the transition function for state s ( f s ).

To measure how well a sentence matches a MEMM, we first organize all word concepts in a concept hierarchy, in which each node in the hierarchy consists of a word and its synonyms and a sub-con cept is represented by a descendant of its parent concepts. The synonymy and hyponymy relationships between words are represented by feature functions of MEMMs: where c represented for a node in the concept hierarchy, w is a word and w  X  c means the concept c accepts the word w as its synonym or hyponym.
 Similar to HMMs we can find the best path for a given sentence O and use P  X  ( O |  X  ) to measure how well the sentence O matches the MEMM  X  Weighting Sentences and Classification of Citing Areas. Consider a kind of finite-state machine, HMM or MEMM. We have a total of six machines {  X  i } 6 i =1 corresponding to six classes. Given an unknown sentence O , we find the best state sequence Q O i corresponding to O in each machine  X  i and compute the likelihood P  X  ( O |  X  i )= P O, Q O i |  X  i to measure how closely the sentence O matches the machine  X  i .

A citing area might consist of many sentences; each sentence can match all six machines with different levels. We need to combine these likelihoods in order to determine which class is suitable for the entire citing area. To this end, we want to determine the importance of each sentence in evaluating the citing area.
Given a sentence O, and a finite-state machine  X  i , we compute P  X  ( O |  X  i )and define: as the probability of selecting the model  X  i given the sentence O. The entropy of this probability distribution is:
As the entropy H ( O ) becomes larger, the chance of selecting the model cor-responding to sentence O becomes more uncerta in, and the the role O plays in determining class label for the citing area becomes less important. Thus, we can weight each sentence O in the citing area by
If the citing area C consists of m sentences: O 1 ,O 2 ,...O m . The corresponding citation type for this citing area is:
To use citation types more flexibly, instead of assigning a class label for a given citing area, we can compute how closely a given citing area matches a category i by measuring the likelihood:
Making a model that analyzes the entire citing area requires many com-plicated computations and a very large training set. Like other methods, our method segments the citing area into sentences and classifies it by evaluating the sentences. However, instead of select ing only one sentence for evaluating the whole citing area, we evaluate the like lihood of each sentence on each class, and use the weight of each sentence to combine these likelihoods in a reasonable way.
From theoretical viewpoint, before doing experiments, it is worth noting that our method can be extended to deal with more citation types. It takes into account the problem of word synonymy and hyponymy, allows overlapping be-tween classes and works without any user-interactions or pre-defined linguistic patterns.Thatcanbeviewedasasignifi cant difference between our citation type detection method and previous works. We designed two experiments for two purposes: first, we want to evaluate if the model using FSMs is more appropriate than other methods using linguistic patterns in the task of detecting citation types; secondly we want to compare two methods using HMMs and MEMMs and discuss the advantages and drawbacks of each model in practice.

The concept hierarchy is built from WordNet [15] in which each node  X  a con-cept  X  consists of a word and its synonym s, a sub concept (hyponym) is placed in the hierarchy as a descendant of its par ent concepts. These experiments used HMMs and MEMMs with 25 states (This is the average of number of words in each sentence). Increasing the number of states may improve the classifica-tion results, but requires longer computational time in the training and testing phases. 3.1 Experiment 1 This experiment is used to evaluate if ou r method achieves higher accuracy com-pared to Nanba and Okumura X  X  method when running in the same conditions. The data set provided by Nanba and Okumura in [8] consists of 282 citing area for training and 100 citing area for testing. We use the same definition of cita-tion types as they defined: B, C and O and select training sentences according to their sentence selection strategy. Table 1 shows the accuracy of Nanba and Okumura X  X  method comparing to our methods.

Running under the same conditions, our method using HMMs and MEMMs based on concept-representation achiev e higher accuracy than Nanba X  X  method. Although the set of cue phrases is well designed for this dataset, Nanba X  X  method still has the problem of synonymy and hyponymy, that why our method using concept-representation ca n result in higher accuracy. 3.2 Experiment 2 This experiment is used to compare the performance of two methods using HMMs and MEMMs. To this end, we collect 9000 papers from two main sources: ACM Digital Library and Science Direct, and randomly select 811 citing areas for this experiment. For a limited number of sentences for training, we randomly selected sentences from these 811 citi ng area and run the experiment 10 times before taking an average of accuracy. T able 2 shows the detection accuracies of the methods using HMMs and MEMMs.

The method using MEMMs produced slightly better result than HMMs as shown in Table 2. In addition, the method using MEMMs requires lower com-putation time for the training phase: it takes 7918 seconds for training MEMMs with 800 sentence compared to 20168 seconds taken by the VT algorithm. The main reason is not only the different characteristics of HMM training and MEMM training algorithms, but also because we must re-distribute the emission func-tions of HMMs to deal with the synonymy and hyponymy relationships between words while we can model these relat ions by feature functions of MEMMs. Because the details of our ETD model is out of the scope of this paper, we will briefly describe the structure of the ETD model and the key idea of building the interest and utility functions to detect emerging trends, including the integration of citation types into ETD process.

In our ETD model, each topic t i in T is a node in the topic hierarchy, which is associated with a time series: where  X  is the length of the trial period.
 t where:  X  t k i (1): determine how often the topic t i is mentioned in the year k th  X  t k i (2): the weight of citations type 1, 3, and 5 in the year k th to t i  X  t k i (3): the number of citations in the year k th to t i  X  t k i (4): the influence of t i on other topics in the year k th  X  t k i (5): the weight of author of t i in the year k th  X  t k i (6): the weight of journal /proceedings talking about t i in the year k th
The topic verification module will monitor these features along the time-series to evaluate the growth in interest and utility of the topic. In our ETD model, the growths of all six time-series t k i ( j ) k (1  X  j  X  6) are independently evaluated and integrated into interest and/or utility functions. In concrete terms, the growth in interest of each topic is evaluated using four time-series t k i (1) k , t i (3) k , t is evaluated using t k i (2) k , t k i (4) k , t k i (5) k ,and t k i (6) k . The citation information is used in both the interest and utility functions. Only citation types 1, 3, and 5 are integrated into the utility function while the number of citations, regardless of citatio n type, is used to evaluate the interest of each topic. We then consider each pair ( time, value ) as a data point, then use regression analysis to predict the dependence of values on the time. The simplest way is to apply linear regression on all data points and use the slope co-efficient of the regression equation to evaluate the global tendency of the time-series.
Citation types can help us understand the research context, select papers for background reading, and identify problems or gaps in related works. In addition, as the topics of recent papers are not always novel and attractive, using citation information is an appropriate way to find the most recent and important topics in a research domain. The integration of these usages of citations into the emerging trend detection process is our ongoing work. We have proposed a method to detect the reasons for citations. By defining six classes of citation types, we developed a method using finite-state machines to evaluate how closely a citing area matches a class. Our method is robust to the problem of synonymy and hyponymy, achieved better accuracy that previous works. In addition, our method using finite-state machines requires neither user-interactions nor explicit knowledge about cue phrases, so it has more flexibility to be extended. We believe this method can be improved and applied to other text-processing tasks, such as named-entity classification, document ranking, text segmentation, emerg ing trend detection, etc.
