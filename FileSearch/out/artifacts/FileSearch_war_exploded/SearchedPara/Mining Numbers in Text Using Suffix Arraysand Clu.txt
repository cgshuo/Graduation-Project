 Texts often contain a lot of numbers. How ever, they are stored simply as strings of digits in texts, and it is not obvious how to treat them as not strings but numeric values. For example, systems that treat numbers simply as strings of digits have to treat all numbers  X 1 X ,  X 2 X ,  X 213 X , and  X 215 X  as different, or all of them in the same way (e.g., by replacing them with  X 0 X ). In this paper, we propose treating numbers more flexibly, such as similar numbers like  X 1 X  and  X 2 X  should be treated as the same,  X 213 X  and  X 215 X  should also be treated the same, but  X 1 X  and  X 213 X  should be treated as different. Range of numbers is a representation of number collections that is appropriate for this purpose. In the above case, the collection of  X 1 X  and  X 2 X  can be expressed by the range  X 1..2 X  and the collection of  X 213 X  and  X 215 X  can be expressed by  X 213..215 X . Not only it can represent a lot of numbers compactly , but also it covers the numbers similar to the given collections not f ound in the given collection.

We propose a system that provides the following two basic indispensable func-tions for treating a range of numbers as normal strings:  X  the function to derive appropriate number ranges from a collection of  X  the function to search texts by using number range queries.
 The former is to find the range of numbers inherent in a collection of numbers and the latter is to use the extracted number ranges for further processing.
For the former problem of finding number ranges, the system dynamically clusters the numbers in the search results based on the Dirichlet process mixture (DPM) [1] clustering algorithm, which can automatically estimate the appropri-ate number of clusters. Our DPM model for number clustering is a mixture of Gaussians [2], which is a very popular example of DPM models. Inference for cluster assignment for DPM models has been extensively studied for many pre-vious papers, including MCMC [3], variat ional Bayes [4], and A* or beam search [5]. However, our task is somewhat different from the ones discussed in these papers, because our task is to derive appropriate number ranges ,whichrequire constraints to be put on the derived clus ter assignments that each cluster must consist of contiguous regions, and it is unobvious how to incorporate them into existing inference algorithms. To the best of our knowledge, no previous studies have discussed how to derive such number ranges on DPM models.

For the latter problem of the number range search, we propose using suffix arrays for the basic index structures. We call the resulting index structure number suffix arrays . The following operations are possible on number suffix arrays. TF calculation: obtaining the counts for the queries that contain the range of Adjacent string calculation: obtaining the strings (or tries) next to the range Search engine providers are one of many groups that have extensively studied indexing for searching by range of numeric values. Fontoura et al. [6] proposed an indexing method with inverted-indexes to efficiently restrict a search to the range of values of some of the numeric fields related to the given documents. In particular, Google search ( X  X earch by numbers X ) in English provides a search option  X .. X  to indicate the number ranges. The inverted-index based methods for number range retrieval are for returning the positions of the numbers in the given range. On the other hand, our number suffix arrays not only return the positions, but also return the suffix array for the strings adjacent to the query, which can be used as a trie of the strings adjacent to the query and can be used for many text mining applications. These applications include extracting frequent adjacent string patterns for further text mining operations like synonym extraction (as shown in the later sections). In other words, number suffix arrays can be regarded as the extended version of the normal indexes for number ranges that are more appropriate for text mining tasks. The main component of our number mining system is number suffix arrays , which are based on suffix arrays [7] and can enable searches by numbers. Suffix arrays are data structures that represent all the suffixes of a given string. They are sorted arrays of (positions of) all suffixes of a string. By use of the suffix array constructed from the corpus S , all the positions of any substring s of S any s by using binary search on the suffix array. Suffix arrays require 2 | S | bytes 1 of additional space to store indices and even more space for construction. We assume that both the corpus and the suffix array are stored in memory. We denote by S [ i.. ]thesuffixof S starting from index i .
 Our algorithm for searching for a range of numbers is defined as follows. means concatenation of adjacent strings, and lb k and ub k are integers. Strings surrounded by [ and ] in a query represent the range of numbers from the number on the left of .. to the number on the right of .. .Forthequery q = KDD-[2000..2005] , s 1 = KDD-, lb 1 = 2000, ub 1 = 2005, and s 2 = X  X  (null string), where n = 2. Setting the current index array ca = sa ( sa is a suffix array of the whole input document), our algorithm iterates the following steps for k =1 , 2 , ..., n . 1. Search for string s k on the array ca , and obtain the resulting range of indices 2. Search for all digits that follow s k . This is done by searching for the index of 3. Sort the array sa 3 according to the alphabetic order of S [ sa 3 [ j ] .. ]. Let ca = In general, the range [ i 1 ...i 2 ] in step-2 in the above algorithm will not be so large because it is only covers the su ffixes that are at least preceded by s 1 and start with digits. However, if s 1 is null ( i.e., the query starts by the range of numbers such as [100..200] years old ), the range [ i 1 ...i 2 ] will be considerably large (it will be the number of all numbers in the text), which means scanning the range will be prohibitively time-consuming. Our basic idea to solve this problem is to make an additional array, which we call a number array , that retains numeric ordering . The number array na for corpus S is the array of indices that all point to the start point of all consecutive digits in S . It is sorted by the numeric order of the numbers represented by the digits that start from each position pointed to by the indices, and we can find (range s of) numbers by performing binary search on this array with numeric-order comparison. Search results for number suffix arrays also may contain numbers. Number suf-fix arrays can describe co llections of different numbers by number ranges, i.e., by the smallest and largest values, such as  X  X 20..50] X  for the collection of 20, 23, 30, 35, 42, and 50. The problem here is that these values do not always appropriately represent th e collection. For instance, expressing the collection the collection are con centrated in two ranges ( i.e. , [1..4] and [1000..1002]). This problem can be avoided by dividing the collection into clusters.

Clustering algorithms that need to set the number of clusters ( e.g. ,K-means) are not appropriate for our situation because the appropriate number of clusters is different for each collection of numbers. Of the clustering algorithms that do not need data on the number of clusters, we selected the DPM [1] clustering algorithm because it provides the principles to probabilistically compare clus-tering results even if the number of clusters differs among distinct clustering results.

Given the collection of numbers x 1 ,  X  X  X  ,x n 4 , assume there exists the hidden parameter  X  i for each number x i . The Dirichlet process [8] is a distribution over distributions and generates a discrete (with probability one) distribution over a given set (which is all the real numbers in our case). Let G be a distribution drawn from the Dirichlet process. Each value  X  i is drawn from G ,whereeachob-servation x i is generated from a distribution with parameter  X  i : G  X  DP (  X , G 0 ),  X   X  G ,and x bution G 0 and concentration parameter  X  .

The Dirichlet process can give the probability of clusters of  X  i when G is integrated out. Here,  X  i and  X  j (, and thus x i and x j ) are in the same cluster if  X  =  X  j .Let C j be a cluster of indices c j 1 ,c j 2 ,  X  X  X  ,c j | C  X  X  X  =  X  the number of clusters, | C j | is the number of observations in the j th cluster and  X  ( n ) =  X  (  X  +1)(  X  +2)  X  X  X  (  X  + n  X  1).  X   X 
We use a DPM of Gaussians (or, equivalently, the infinite Gaussian mixture [2]) model. In our model, both G 0 and f are assumed to be Gaussians, with (mean,deviation) being (  X  1 , X  1 ) for the former and (  X  i , X  2 ) for the latter: G 0 = N (  X  1 , X  1 ) , and f i = N (  X  i , X  2 ) . 5
The joint distribution of x =( x 1 ,x 2 ,  X  X  X  ,x n )and  X  is thus We integrate out  X  because we need only cluster assignments, not parameter values themselves. This results in the the objective function to maximize (which indicates the goodness of clustering), which is denoted by f ( C ). where
The algorithm searches for the best cluster assignment that maximizes the objective function (1). Note that the objective function (1) is defined as the product of g for each cluster, which means that the function is  X  X ontext-free X  in the sense that we can independently calculate score g ( C j ) and then multiply it to calculate f because the value of g ( C i ) is not affected by changes in other clusters C i s.t. i = j . Note that our purpose in clustering is to appropriately divide a given number collection into continuous regions . Therefore, we do not need to consider the case where a cluster is not a region ( i.e., elements in the cluster are separated by elements in another cluster, such as a case where C 1 = { 1 , 5 } and C
In this situation, the best cluster assignment can be found by a naive dynamic programming approach. We call this approach the baseline algorithm or CKY algorithm because it is a bottom-up style algorithm performed in the same way as the Cocke-Younger-Kasami (CKY)-parsing algorithm for context free grammar, which is popular in the natural language processing community.

In our approach, we accelerate the sear ch further by using a greedy search strategy. Starting from no partition ( i.e., all elements are in the same region (cluster)), the algorithm divides each region into two sub-regions to best increase the objective function (1) and then recursiv ely divides the sub-regions. If it is not possible to divide a region into two sub-regions without decreasing the objective function value, division stops.

More precisely, number clustering is done by calling the following function partition ( A ), where A is the collection of all numbers input to the algorithm. After that, we obtain C as the clustering result.
 P artition ( N ) : Find the best partition left ( N )and right ( N )thatmaximizes
Here,  X  is multiplied with g ( left ( N )) g ( right ( N )) because partitioning in-creases the number of clusters | C | that appear as  X  | C | in objective function (1). Our flexible number handling is useful i n many text-mining tasks, especially when we want to use the numbers as some kind of contexts . A typical example is measuring the semantic similarities of words. When measuring word similarities, we typically calculate the distributions of words related to word w (e.g., distri-bution of words around w , distribution of words that have dependency relations with w , etc.) as the contexts of w , and measure the similarities of the meanings of the words w 1 and w 2 by calculating the similarities of their contexts. A direct application of measuring similarities of words is synonym extraction . Especially, we developed an algorithm to dynamically extract synonyms of given queries using suffix arrays [9]. To find words similar to a given query q ,the algorithm extracts context strings ( i.e. , strings that precede or follow q )by using suffix arrays 6 , which in turn are used to find strings surrounded by these extracted contexts.

We enhanced the algorithm by adding the ability to appropriately treat num-bers in context strings in number suffix arrays. For example, we can use the context strings  X  X 10..20] persons X  to cover all numbers between 10 and 20 pre-ceding the word  X  X ersons X , while in naive suffix arrays, only raw strings such as  X 11 persons X  and  X 17 persons X  can be used as contexts. Our number suffix arrays can thus improve coverage of contexts an d extracted collections of synonyms.
We evaluate the performance of syno nym extraction with number suffix ar-rays to investigate whether number suffix arrays enhance text mining. We used aviation-safety-information texts from Japan Airlines that had been de-identified for data security and anonymity. The re ports were in Japanese, except for some technical terms in English. The size o f the concatenated documents was 6.1 Mbytes. Our text-mining system was run on a machine with an Intel Core Solo U1300 (1.06 GHz) processor and 2 GByte memory. All algorithms were imple-mented in Java. The size of the number array for each (normal or reversed) suffix array was 60,766.

To evaluate the performance of the system, we used a thesaurus for this corpus that was manually developed and independent of this research. The thesaurus consists of ( t, S ( t )) pairs, where t is a term and S ( t )isasetofsynonymsof t .We provided t as a query to the system, which in turn returned a list of synonym candidates c 1 ,c 2 , ..., c n ranked on the basis of their similarities to the query. S ( t ) was used as a correct answer to evaluate the synonym list produced by the system. The number of queries was 404 and the average number of synonyms was 1 . 92.

We compared the average precision [10] of our algorithm with the baseline (us-ing naive suffix arrays) and the no-clustering version (using number suffix arrays without number clustering). The results are shown in Table 1. We observed that the performance was improved by using number suffix arrays by about 0.6 percent, which was improved further by a bout an additional 0.4 percent by per-forming number clustering. However, the average execution time for each query became 3.5 X 4.5 times larger than that of the baseline. For practical use, we will have to reduce the execution time by reducing the number of range-starting queries ( i.e. , the queries that start with a range of numbers). 4.1 Results: Speed and Accuracy of the Algorithm We stored all the queries to the number suffix arrays and all the collections of numbers for number clustering that appeared in the above experiments. We randomly selected 200 queries that included the range of numbers for each suf-fix array (normal and reversed), resulting in 400 queries in total. Of each 200 queries, 100 started with a range of numbers (indicated as  X  X umStart X ), and the remaining 100 started with non-digit characters (indicated as  X  X otNumStart X ). We also randomly selected 1000 collections of numbers, and used them to mea-sure the accuracy and execution time of our number clustering algorithms. 7
The result of the query-time experiment is shown in Table 2 (left). We ob-served that the search time for queries starting with a range of numbers was drastically reduced by using the number arrays. Considering the large ratio of the search time of NumStart and NotNumStart, using the number arrays is an efficient way to conduct a number search.

The results of a comparison of two clustering algorithms are shown in Table 2 (right). The greedy algorithm was much faster than the baseline CKY algorithm. The important point here is that the difference of total log-likelihood values between the greedy (approximate) algorithm and the baseline was quite small, which suggests that using the greedy algorithm for number clustering achieves much faster processing with almost no sacrifice of quality of the clustering results. We described number suffix arrays, which enable us to search for numbers in text. The system is based on suffix arrays and DPM clustering. We also showed applications of number suffix arrays to text mining, including synonym extrac-tion, where the performance could be improved by using number suffix arrays. Future work includes developing more so phisticated preprocessing for numbers such as normalization of number expressions.
 This research was partially supported by Fujitsu Laboratories Ltd.

