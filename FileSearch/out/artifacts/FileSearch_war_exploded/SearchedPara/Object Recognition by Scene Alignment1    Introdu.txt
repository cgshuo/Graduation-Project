 relationship between scenes and objects and allow informat ion transfer across the two. contained in the labels? and conclude in Section 6. information and is similar to applying the SIFT descriptor [ 9] to the image region. well and we account for outliers in Section 4. We evaluate the ability of the retrieval set to predict the presence of objects in the input image. For this, we found a retrieval set of 200 images and formed a normalized histogram (the histogram entries sum to one) of the object cate-gories that were labeled. We compute performance for object categories with at least 200 training examples and that appear in at least 15 test images. We compute the area under the ROC curve for each object category. As a com-parison, we evaluate the performance of an SVM applied to gist features by using the maximal score over a set of bounding boxes extracted from the im-age. The area under ROC performance of the retrieval set versus the SVM is shown in Figure 3 as a scatter plot, with each point corresponding to a tested ob-ject category. As a guide, a diagonal line is displayed; those points that re-side above the diagonal indicate better SVM performance (and vice versa). No-tice that the retrieval set predicts well the objects present in the input image and outperforms the detectors based on local appearance information (the SVM) for most object classes. object labels belonging to the retrieval set.
 image, and their appearance g . For a set of N images, each having M object categories, we assume a joint model that factorizes a s follows: We assume that the joint model factorizes as a product of thre e terms: (i) p ( o likelihood of which object categories will appear in the ima ge, (ii) p ( x category o duplicated based on the counts depicted in the top-left corn er of the plate. boxes x tion). Each component of x are multinomial parameters and  X  bounding box parameters. Finally, we assume g feature  X  g The parameters  X  training SVMs for each object class on the set of all labeled examples of object class l and a set of distractors. We then fit logistic functions to the positive and negative examples of each class. We learn the parameters  X  online using the object labels corresponding to the retrieval set. These are learned by sim-ply counting the object class occurrences and fitting Gaussians to the bounding boxes corre-sponding to the object labels.
 For the input image, we wish to infer the latent variables h pling of all possible bounding box locations x parameters  X  compute the postierior distribution p ( h proportional to the product of the three learned distributi ons, for m = { 0 , 1 } . to fit the parameters from the retrieval set and train the obje ct detectors separately. utions over  X  Furthermore, we assume a Bernoulli prior distribution over h hand-tuned the remaining parameters in the model. For h distributions o will best assist us in detecting objects in the input image. We augment the model of Section 3 by assigning each image to a l atent cluster s Intuitively, the model finds clusters using the object label s o ( d ) ( e ) ( f ) ( g ) spatial location  X  corresponds to a single customer that is seated at a table.
 To learn  X  distribution over s used a symmetric Dirichlet hyperparameter with  X  For final object detection, we use the learned parameters  X  ,  X  , and  X  to infer h infer the best cluster s  X  outside of the training set.
 represented by bounding boxes (e.g. buildings and sky).
 matching, which causes a poor context model to be learned. Grant N00014-06-1-0734.

