 Data mining is increasingly being applied in environments h aving very high rate of data generation like network intrusion det ection [7], where routers generate about 300,000  X  500,000 connect ions every minute. In such rare class data domains, the cost of mis sing a rare-class instance is much higher than that of other classe s. How-ever, the high cost for manual labeling of instances, the hig h rate at which data is collected as well as real-time response cons traints do not always allow one to determine the actual classes for th e col-lected unlabeled datasets. In our previous work [9], this pr oblem of missed false negatives was explained in context of two dif ferent domains  X   X  X etwork intrusion detection X  and  X  X usiness oppo rtunity classification X . In such cases, an estimate for the number of such missed high-cost, rare instances will aid in the evaluation of the performance of the modeling technique (e.g. classification ) used. A capture-recapture method was used for estimating false ne ga-tives, using two or more learning methods (i.e. classifiers) . This paper focuses on the dependence between the class labels ass igned by such learners. We define the conditional independence for clas-sifiers given a class label and show its relation to the condit ional independence of the features sets (used by the classifiers) g iven a class label. The later is a computationally expensive probl em and hence, a heuristic algorithm is proposed for obtaining cond itionally independent (or less dependent) feature sets for the classi fiers. Ini-tial results of this algorithm on synthetic datasets are pro mising and further research is being pursued.
 H.2.8 [ Database management ]: Database Applications X  data min-ing ; G.3 [ Probability and statistics ]: Contingency table analysis; H.1.1 [ Models and principles ]: Systems and infomation theory X  information theory ISS-0308264, ARDA Grant F30602-03-C-0243, and a grant from IBM. S.-Y. Hwang X  X  work was supported by a Fulbright scholar -ship.
 Copyright 2005 ACM 1-59593-135-X/05/0008 ... $ 5.00.
 Algorithms, Measurement.
 false negative, capture-recapture method, conditional in dependence of classifiers given class label, conditional independence of features given class label, conditional mutual information.
In many data mining or machine learning domains, the distri-bution of the data instances (or just instances) over classe s is ex-tremely skewed in addition to a high rate of data generation. For example, data mining is being applied to the problem of netwo rk intrusion detection (Lazarevic et al. [7]), where routers g enerate about 300,000  X  500,000 connections every minute. Classific ation (and/or anomaly detection) techniques are used to determin e if a given network connection belongs to class  X  X ntrusion X  or cl ass  X  X or-mal X . A normal security analyst may not be able to examine mor e than about 10 reported events per minute. The manual labelin g of the remaining connections is constrained by both the cost as well as time requirements. Hence, in this domain, only instances pre-dicted as  X  X ntrusions X  (rarer class  X  also lesser number of i nstances are predicted as intrusions) are usually analysed to check w hether they are actually intrusions or not. However, there is no or v ery lit-tle analysis to determine whether there are any intrusions t hat may have been missed by the intrusion detection system. A method of false negative estimation was illustrated for such analysi s in our previous work (Mane et al. [9]). The method also allows to obt ain an estimate of the distribution of classes in an unlabeled da taset through much less effort of manual labeling.

The method of false negative estimation makes use of model-ing the data in a contingency table, which is obtained by cros s-tabulating the number of true positives detected by several classi-fiers. However, since the number of true positives detected b y each classifier is small, the modeling technique used for the cont ingency table may not be able to capture the dependencies between cel l fre-quencies. This motivated us to study and to show that indepen dence (or to be more practical, low dependence) between the classi fiers used in this method will aid in reducing the error in the estim ate. A fundamental question that remains open is  X  X ow to train clas sifiers that are independent ? X  In this paper, we address this questi on. First, we show the relationship between the conditional ind epen-dence of models and the feature sets used by the models. This l ays the theoretical groundwork for our filter-based  X  X eature su bset se-lection algorithm X  to obtain less dependent models. Note th at our approach can be extended to use techniques like anomaly dete ction and semi-supervised learning.
The remainder of this paper is organized as follows  X  the section 2 explains false negative estimation problem using capture-recapture method and then defines the problem addressed in this paper. Section 3 provides theoretical background. Section 4 shows a practical approach. Section 5 ex-plains some experimental results. Section 6 draws conclusions and identifies future re-search directions.
The main idea behind the method of es-timation of false negatives (Goldberg and Wittes [5], Hook and Regal [6]) is to first estimate the number of actual positives (APs) in the unlabeled dataset. Using this estimate for actual positives, an estimate for false negatives is obtained. The capture-recapture met hod (Dar-roch [3]) is used for such estimation of the number of actual p osi-tives in the unlabeled dataset using two or more different cl assifica-tions 1 of the dataset. The rare class is treated as positive class an d the remaining class(es) is(are) treated as negative class( es). This keeps the number of predicted positive classes low and hence they can be manually segregated into true positives and false pos itives.
The Figure 1 illus-APs detected trates the overall method-ology for estimating ac-tual positives in an un-labeled dataset using two classifiers. Given two different classifiers and an unlabeled dataset, the number of true positives detected by each of the two classifiers is determined and thes e are then cross-tabulated in a contingency table, as shown in the table 1. The sum of all the cells in this Actual class contingency table equals the num-ber of actual positives in the dataset.
 Only one cell in the contingency table will be unknown ( n 00 ), which corresponds to the number of ac-tual positives not detected by both classifiers. If independence holds between the cell frequencies of the contingency table, then ML-esti-mation techniques can be used to estimate the unknown value ( b n 00 = n 01  X  n 10 dence does not hold between the cell frequencies, log-linea r models can be used to estimate the unknown cell ( b n 00 ). Thus, an estimate for total number of actual positives in the dataset is obtain ed. An implicit assumption made here is that the classifiers used in the capture-recapture method do a good job of keeping the number of false positives low (i.e. they have sufficiently good accura cy). This helps to keep the number of instances to be manually classifie d by experts low.

Once an estimate for the missing cell, and hence the total num -ber of actual positives, is made (i.e c AP for the dataset has been ob-tained), the same dataset is then classified using a classifie r whose performance (accuracy) is to be evaluated. As shown in table 2, the instances predicted True by the classifier are analyzed manually to separate true positives from false positives. The estimate for c AP is used to obtain an estimate for false negatives ( c FN negatives ( d TN ) detected by a classifier. Using these estimates, the performance (accuracy) of the classifier is evaluated.
Before we proceed further, we present an example to illustra te the effect of independence of cell frequencies on the error i n the estimate obtained for b n 00 . We consider the same setting (two-class problem using two classifiers), as used previously in table 1 . Table 3: Lesser is the dependence among cells in contingency table, better is the estimate b n 00 .

The table 3 illustrates the need for independence of classifi ers using a synthetic two-class example for estimating actual p ositives using two classifiers. Let us assume that each classifier has a con-stant accuracy = 60 % for the positive rare class and the unlab eled dataset has 10 actual positive instances (for ease of explai nation, we have used small numbers). Then, the rows in table 3 represe nt all the possible scenarios for actual positives detected by the clas-sifiers (with accuracy condition met). The probabilities in the fifth and sixth column are conditioned on the actual positive clas s. For example, for the first row, Pr( n 11 ) = ( n 11 / Total number of actual positives) = 6 / 10 = 0 . 6 . The fourth column ( n 00 ) represents the actual number of missed actual positives while the secon d last column ( b n 00 ) represents ML-estimate for the fourth column (ob-tained using the first three columns). From the table, it is no ted that with accuracy remaining the same, as the classifiers become m ore (positively or negatively) dependent on each other, with re spect to the number of true positives identified by each classifier, th e error in the predicted estimate for the number of actual positives missed by both classifiers increases. This can be noted from the last col-umn of the table 3. This example thus demonstrates the need fo r independence of classifiers.

To best of the authors X  knowledge, little research has been c ar-ried out related to independence of classifiers. Kuncheva et al. [8] have demonstrated that, opposite to the common notion, nega tive dependence may be an asset for classifier fusion. They have il lus-trated this using a table similar to table 3 for a synthetic da taset. However, their work does not address the issue of how to obtai n independent or dependent classifiers. Blum and Mitchell [1] speak about the conditional independence of features of classifie rs given a label. There is some similarity between this paper and thei r work as regards of this definition. However, this paper is less res trictive about the probability distribution D of instances over the features than their work, as will be illustrated later on.
An important assumption in the method using ML-estimates is that two or more feature sets are available for a dataset such that the classifiers trained using those feature sets are indepen dent. In case of the estimates using log-linear model, lesser is the d epen-dency between the variables (class labels), better will be t he esti-mate for actual positives obtained using log-linear model. This is because lesser are dependencies between variables in the co ntin-gency table, lesser will be the number of parameters that mus t be estimated for the log-linear model. Another important obse rvation for a rare class problem is that the data (i.e number of true po sitives detected by each classifier) available for the contingency t able (Ta-ble 1) is small. Thus, lesser are the dependencies between va riables in the contingency table, better is the estimate obtained us ing the available small frequencies in cells of the contingency tab le.
This motivates us to define the main problem addressed in this paper  X   X  X iven a labeled dataset with a set of features, what is an opt imal way to train independent (or less dependent) classifiers tha t will be used in the capture-recapture based method for estimating a ctual positives in other unlabeled datasets? X 
This work will continue using a two class C = { True , False } problem of estimating the actual positives using two classi fiers. Other notations used in this paper are  X  a bold upper case symb ol represents a set of features, bold lower case symbol represe nts val-ues of the set of features for an instance, normal upper case s ymbol represents a single feature while normal lower case symbol r epre-sents the value that a single feature can take. Also, a symbol having calligraphic style font is used to represent a set of values, either for a single feature or for a set of features.
The table 1 motivates us to begin by formally defining what is conditional independence of classifiers given a class label .
D E FINIT ION 1. Consider a 2-class, { True , False } , classifica-tion problem. Let p be an instance whose actual class is T rue C 1 be the class assigned by the 1 st classifier to the instance C 2 be the class assigned by the 2 nd classifier to the same instance p . Then the two classifiers are  X  X onditionally independent gi ven class C a = True  X  (i.e. conditionally independent for given class label) if and only if the following condition holds for each a ctual positive  X  Pr(C 1 = True , C 2 = True | C a = True ) =
Pr(C 1 = True | C a = True )  X  Pr(C 2 = True | C a = True )
Figure 2 illustrates the definition 1. It should be noted that we are interested that equation 1 hold only for all actual posit ives and Figure 2: Venn diagram of predicted class labels for two clas s classification. not all instances in the dataset. In the method of estimation of ac-tual positives in an unlabeled dataset, definition 1 should h old for the true positives detected by the two classifiers in order fo r inde-pendence to hold among the cells in table 1. Since the class la bel (dependent variable) assigned by a classifier is a function o f fea-tures (independent variables), this motivates us to study t he influ-ence of conditional independence relationship between fea ture sets of classifiers on the conditional independence of classifier s given a class label.
For a two-class C = { True , False } dataset, let F = { F feature set. Choose disjoint subsets F 1 , F 2  X  F and build classi-fiers Pr(C 1 | F 1 ) , Pr(C 2 | F 2 ) , where C 1 and C 2 assigned to an instance by the two respective classifiers. Ma themat-ically, it can be stated that the first classifier will predict an instance having feature vector F 1 = f 1 as belonging to a specific class if the probability of that instance belonging to that class is m aximum. Hence, the condition under which the first classifier will pre dict an instance with F 1 = f 1 as belonging to True class is, where , C a is the actual class of the instance .
 Thus, for instances having F 1 = f 1 for which eq. 2 holds,
For an instance with a value of F 1 for which the eq.2 does not than the True , to the instance. Similar equations also hold for the second classifier trained using feature set F 2 .

We are interested in actual positives detected correctly (i .e. true positives detected) by each classifier and the independence between number of actual positives detected (i.e. true positives) b y each classifier. Since, as illustrated above, the fact whether a stance is predicted as True by a classifier depends on the values that an instance has for the features (i.e. F 1 or F 2 ), we define con-ditional independence between features of classifiers give n class label.
 D E FINIT ION 2. For two classifiers trained with feature sets and F 2 respectively, the two classifiers are said to have  X  X ondi-tionally independent feature sets given class label C a = True  X  F 1 = f 1 , F 2 = f 2 of actual positives This definition of conditional independence of feature sets given a class label is similar to the conditional independence giv en the label defined by Blum and Mitchell [1]. In their work, the prob a-bility distribution D of instances over the features F = F defined, where F 1 and F 2 are two subsets of features (which give different  X  X iews X  or classifications of the instance.) Our w ork dif-fers from their work since we relax the conditional independ ence of features given a class label to hold only for the rare class (i .e. class label of interest). Also, in our work, D can have non-zero proba-bility for an instance with F 1 = f 1 and F 2 = f 2 , where classifiers using F 1 and F 2 give different class label from each other and/or from the combined classifier.

In definition 2, we are interested whether equation 3 holds on ly for all those values F 1 = f 1 , F 2 = f 2 of actual instances that have non-zero probability over the probability distribution D . A classi-fier (like a decision tree) built using feature set F 1 may, at some decision node (leaf node), use only a subset of features F to classify an instance as True . Thus, a more strict condition for eq.3 in definition 2 is  X   X  F  X  dition holds, = Pr( F  X  1 = f  X  1 | C a = True )  X  Pr( F  X  2 = f  X  2 | C
The Apriori (anti-monotonic) property does not hold for thi s stricter definition eq.4. Hence, to reduce the computationa l costs, we consider only eq.3 in definition 2. The theorem 1 explains t he relationship between conditional independence of feature s given class label and conditional independence of classifiers giv en class label. This theorem will hold in case of the stricter equatio n (eq.4) for definition 2.
 T HE ORE M 1. For two classifiers built using feature sets F 2 respectively, the two feature sets are independent given cl ass label if and only if the two classifiers are independent given class label i.e. eq.3  X  X  X  eq.1 holds. N
Proof: Let D be the probability distribution of instances with features F 1 , F 2 over class labels C = { True , False } figure 3. For the two feature subsets F 1 , F 2  X  F , let x , x 4 , x 5 } be the set of all possible values of F 1 for actual posi-of
F 2 for actual positives. Note, there may be values of F 1 x , . . . } and F 2 = { y 5 , y 6 , . . . } which may not be included in the table shown in figure 3 since those values have zero probabili ty in D for actual positives. The proof will not be affected by such v alues. Figure 3: Probability distribution D of ( F 1 , F 2 ) over C .
 equal to the probability of True class over D , i.e.
 where, C a is the actual class label for an instance with
Similarly, the probability that True is assigned by a classifier to an instance with F 2 = f 2 will be
The probability that True class is assigned by a combined clas-sifier to an instance with F 1 = f 1 and F 2 = f 2 will be We have, from eq.7,  X  Pr(C 1 = True , C 2 = True , F 1 = f 1 , F 2 = f 2 ) = Pr( F 1 = f 1 , F 2 = f 2 | C a = True )  X  Pr(C a = True )
Consider an actual positive p with feature values F 1 = f F 2 = f 2 , where f 1  X  X  and f 2  X  X  . Since f 1 and f 2 are features of the same instance, there is only one probability value for an actual positive p in the figure 3 which corresponds to
Pr(C 1 = True , C 2 = True , F 1 = f 1 , F 2 = f 2 ) which for p is, Pr(C 1 = True , C 2 = True , C a = True ) This is the highlighted cell in figure 3 for f 1 = x 1 and Notice that this probability is the probability from perspe ctive of AP p . Thus, we have, for AP p , Thus, using eq.8 and eq.9 Similarly, we can prove that,
Pr(C 1 = True | C a = True ) = Pr( F 1 = f 1 | C a = True )
Pr(C 2 = True | C a = True ) = Pr( F 2 = f 2 | C a = True ) Sufficient condition: Assume that eq.3 holds for all actual positives. Hence, usin g eq.10, eq.11 and eq.12, we have, = Pr( F 1 = f 1 , F 2 = f 2 | C a = True ) = Pr( F 1 = f 1 | C a = True )  X  Pr( F 2 = f 2 | C a = True ) = Pr(C 1 = True | C a = True )  X  Pr(C 2 = True | C a = True ) Thus, the sufficient condition is proved.
 Necessary condition: Assume that eq.1 holds for all actual positives. Hence, usin g eq.10, eq.11 and eq.12, we have,
Pr( F 1 = f 1 , F 2 = f 2 | C a = True ) = Pr(C 1 = True , C 2 = True | C a = True ) = Pr(C 1 = True | C a = True )  X  Pr(C 2 = True | C a = True ) = Pr( F 1 = f 1 | C a = True )  X  Pr( F 2 = f 2 | C a = True ) Thus, the necessary condition is proved.  X  Figure 4: Cross-tabulation of probability distribution of actual positives detected as True using F tual information (Cover and Thomas [2]) between two random vari-ables since it gives a measure of independence between two ra ndom variables. Important properties of mutual information of r andom variables U and V are: (i) I(U,V)  X  0 with equality iff U and V are independent, and (ii) I(U,V) =I(V,U) , i.e. mutual information is a symmetric mea-sure.
 The joint probability distribution of F 1 and F 2 given class label True for the actual positive instances will be as shown in the figur e 4. The shaded cells in figure 4 represent the probabilities of true positives detected by the two classifiers (i.e. these are the proba-bilities conditioned on C a = True ). Using figure 4 and the same notations for X and Y as used previously in the proof of theorem 1, we define  X 
D E FINIT ION 3. The  X  X onditional mutual information given class label C a = True  X  between two discrete feature sets F 1 and defined as,
I( F 1 ; F 2 | C a = True ) = log
The previous sections 3.3 and 4.1 discussed about the condit ion for solving the problem. The main issue that now needs to be ad -dressed is  X  given a labeled dataset with a set of features Algorithm 1 Feature subset selection algorithm Input: Output: Pseudo-code: 1. Choose instances belonging to True class. 2. Obtain  X  X airwise-conditional mutual information X  matr ix for 3. Apply block diagonalization algorithm on the pairwise-4. Discard the subsets having size less than user specified 5. Evaluate conditional mutual information between the re-6. Choose two best subsets F 1 , F 2 having least conditional mu-possible to search for two feature subsets F 1 , F 2  X  F such that the classifiers, obtained by training using each feature subset , are least dependent and they have a minimum threshold accuracy ? Such a required dependence relationship between subsets of a feat ure set F does not have Apriori property. This problem is analogous to global optimization problem with constraints, since we are trying to find a pair of classifiers with best accuracies (global opti mum) subject to a non-convex constraint that the two feature sets are con-ditionally independent given class label.
We used a heuristic approach to solve this computation inten sive search problem. The algorithm 1 is based on the equation 4 (i. e. the more strict form of definition 2)  X  which requires that for two fea-ture subsets F 1 and F 2 to be conditionally independent given class label, the equation 3 must hold for each of the individual fea tures also, i.e.  X  F 1  X  F 1 and F 2  X  F 2 , I(F 1 , F 2 | C a = True ) = 0
The algorithm proceeds as follows. Using the values of the fe a-tures of actual positives, the conditional mutual informat ion for each pair of features is computed and cross-tabulated to obt ain a pairwise-conditional mutual information matrix. A block d iag-onalization technique, reverse CutHill-McKee algorithm (George and Liu [4]), is then used to cluster the features with minimu m inter-subset pairwise-conditional mutual information. T he condi-tional mutual information between each pair of the clustere d fea-ture subsets is determined. Feature subsets having conditi onal mu-tual information less than a user-specified threshold are se lected. Assuming that each feature provides equal amount of informa tion about the class for an instance (i.e. each feature has equal p redic-tive power), the algorithm 1 also uses a user-specified limit on min-imum number of features required in each subset. This guaran tees a minimum accuracy for each classifier.
To evaluate the performance of algorithm 1, we used noise-ad ded synthetic datasets generated using  X  X ata generator X  (http ://www. datgen.com). One of the reasons for this was that it was diffic ult to obtain large labeled datasets for training. Sufficiently large datasets (each with 100,000 instances) were generated, each with mod er-ate number (20-24) of attributes, and a skewed class distrib ution  X  approximately 2% True class instances with remaining 98% be-longing to False class. Each dataset was divided into a training set (80%) and a test set (20%), keeping the class distributio n same in the training and test data as in the original data. The algo rithm 1 was applied to the feature set of actual positives in the tra ining dataset with k = 5 and  X  = 10 . A decision tree (WEKA [10]) was trained on the training data using each of the feature sub sets. For the test dataset, the true positives detected by each suc h classi-fier were determined, then cross-tabulated into a contingen cy table (similar to table 1), and finally an estimate for missed actua l posi-tives ( b n 00 ) was obtained.

The table 4 shows the summarized results for algorithm 1 for different synthetic datasets. The values within parenthes es repre-sent the standard deviations. The columns  X  X verage classifi er ac-curacy for True class X  represent the classifier accuracies for class instances only, i.e. it represents what fraction of ac tual posi-tives were correctly identified as True by a classifier. For datasets  X 4 X  and  X 5 X , the conditional mutual information between cla ssifiers is nearly same but dataset  X 5 X  has more accurate classifiers t han dataset  X 4 X . The accuracy of estimate is better for dataset  X  4 X  ( 115 | /115) than that for dataset  X 5 X  ( | 16-13 | /13). Thus, dependence among classifiers plays a more important role in improving th e ac-curacy of the estimate when the accuracies of the classifiers are low. The results for estimate of actual positives using a ran dom split of feature set for same synthetic datasets are also sho wn. As seen from the table 4, the algorithm 1 provides a better split ting method for the feature set. The first dataset in the table 4 ill ustrates that with the accuracy of the classifiers remaining approxim ately constant, if the conditional mutual information between th e feature subsets increases, then the error (e.g. the absolute differ ence be-tween b n 00 and the number of actual positives actually missed) in the estimate b n 00 increases. The second dataset illustrates that even though accuracies of the classifiers increase, the increase in condi-tional mutual information more than negates that effect res ulting in more error in the estimate. The third dataset illustrates th at even though the accuracies of the classifiers decrease, since the condi-tional mutual information also decreases for random split, it gives a better (closer) estimate. The last two datasets illustrat e that the al-gorithm 1 does a good job at keeping the estimate for missed ac tual positives closer to the actual number of missed actual posit ives.
Similar experiments done using Naive Bayes classifier show t hat decision trees performed better, which asserts that the str icter con-dition of definition 2 is more useful for decision trees.
The main aim of this paper was to study the relationship of the conditional independence of classifiers given a class label to the conditional independence of the feature sets (used to train classi-fiers) given a class label. The problem of obtaining such cond i-tionally independent subsets of features for a given datase t is com-putationally expensive. A heuristic approach for obtainin g feature subsets was proposed and the results of application of this a lgo-rithm to synthetic datasets were shown. Application of this algo-rithm to compare the performance of two network intrusion de tec-tion systems using a real world dataset will be demonstrated in our future work. An important observation made from the experim ents was that, in addition to independent classifiers, more accur ate are Thus, the future research directions involve developing ef ficient al-gorithms for obtaining the right balance between the condit ional accuracies of classifiers and the conditional dependence be tween classifiers given class. [1] A. Blum and T. Mitchell. Combining labeled and unlabeled [2] T. M. Cover and J. A. Thomas. Elements of Information [3] J. N. Darroch. The multiple-recapture census: I. estima tion [4] A. George and W. Liu. Computer Solution of Large Sparse [5] J. Goldberg and J. Wittes. The estimation of false negati ves [6] E. Hook and R. Regal. Capture-recapture methods in [7] A . Lazarevic et . al . A survey of intrusion detection [8] L . Kuncheva et . al . Is independence good for combining [9] S . Mane et . al . Estimation of false negatives in [10] I. H. Witten and E. Frank. Data Mining: Practical machine
