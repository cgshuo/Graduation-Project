 With the popularity of the social network, users are taking delight in sharing. For example, users can send tweets and comments on Twitter [1], and upload videos and post relevant reviews on the video sharing platform YouTube [2]. However, spammers are also planning to bene t from the prosperity by means of advertising, posting nonsenses and spreading fake information. Series of security risks may be caused due to spammers. For instance, users' privacy information can be lched by phishing links and the recommended lists are polluted by spam. Hence, spammer detection has become a signi cant work in social service. researchers and the industry. Existing detection methods are categorized into unsupervised methods, supervised methods, semi-supervised methods, etc. Un-supervised spammer detection methods [3{6] do not need the labeled samples, which can save the cost of labeling. But the absence of labels may lead to the low accuracy. In contrast, supervised methods [1,2,7,8] and semi-supervised [9{12] methods perform better than unsupervised methods with the supervision of the labels. However, the methods relying on both positive and negative labels fail when there are only one class labels available. In addition, it is time-consuming to label numerous spammers in real situations. In order to resolve this prob-lem, we propose a novel spammer detection method which incorporates Princi-pal Component Analysis(PCA) [13] and Positive and Unlabeled Learning (PU Learning) [14], named PCA-PUD. First, we use PCA to extract key features, then utilize Naive Bayes (NB) to build the reliable negative (RN) classi er to pick out negative samples. Next, the positive and unlabeled detecting (PUD) classi er is trained on positive and predicted negative samples. The main con-tributions of this paper are as follows:  X  Propose a novel method PCA-PUD to detect spammers in social network;  X  Evaluate and compare the performance of the proposed PCA-PUD method  X  Discuss the e ect of the proportion of positive samples on PCA-PUD, which troduce some related work about social spammer detection and PU Learning. The problem statement and the illustration of proposed PCA-PUD method are shown in Section 3. In Section 4, we conduct experiments on two real world datasets. Finally, Section 5 concludeds this paper and point out the potential future work. In this section, we review some related work from current research about social spammer detection and background knowledge about PU Learning. 2.1 Social Spammer Detection Methods Generally speaking, the detection methods can be classi ed into unsupervised methods, supervised methods and semi-supervised methods according to the amount of needed labeled data.
 Unsupervised Detection Methods. These methods mainly utilize the so-cial network topology to identify the abnormal nodes. Gao et al. [3] exploited similarities of text content and URLs to cluster users in Facebook. The method of combining social relation graphs and user link diagrams was proposed in [4]. Zhao et al. [5] utilized the dynamic query extension method which construct-s tweet graphs, then used anomaly detection method to identify spam tweets. Zhang et al. [6] adopted 12 types of topological features in ego network to detect spammers.
 Supervised Detection Methods. Supervised methods usually extract rele-vant characteristics of users. Benevenuto et al. [1] extracted the user behavior characteristics and tweet content characteristics, then established a SVM model to detect spammers. In [15], main features were extracted from uses' registered and content information. The features can be drawn from social networking maps as well. Wei et al. [7] explored characteristics of spammers and network stability on Twitter. A group modeling framework was proposed in [8], which adaptively characterizes social interactions of spammers.
 Semi-supervised Detection Methods. Semi-supervised methods leverage labeled samples and massive unlabeled samples. A hybrid method that aimed to detect multiple spammers from user characteristics and user relationships was proposed in [9]. In [10], the trust propagation which utilized PageRank to propagate labels was used to recognize spammers. Li et al. [11] used the Laplace method to extract features, then used the semi-supervised method to train the classi er. Tan et al. [12] proposed a two-layer sampling algorithm by three criteria to quantify the value of unlabeled samples.
 methods, but they need abundant labeled data. The semi-supervised methods improve the accuracy of detection by using both labeled and unlabeled data. Either supervised or semi-supervised methods rely on both positive and negative samples. Our work is di erent from above methods, only a few positive labeled data and plenty of unlabeled data are required. 2.2 Outline of PU Learning The approach merely adopting positive and unlabeled data is called Positive and Unlabeled Learning or PU Learning. A theoretical research of Probably Approx-imately Correct learning from positive and unlabeled data was rst presented in [16]. At the beginning, PU Learning mainly aimed to solve the task of text classi cation [14], then researchers extended this method to other areas. Such as the web page classi cation [17], the disease gene identi cation [18], the spam detection [19], the Multi-graph learning [20], etc.
 of labeled spammers is much smaller than those of normal users. Furthermore, the cost of marking normal users is cheaper marking than spammers. These characteristics show that PU Learning meets the demand of real situations. Negative Samples (RN) from the Unlabeled Samples (U) according to the Pos-itive Samples (P). Step 2: Construct the binary classi er by Positive Samples and Reliable Negative Samples. In this section, we will rst state the problem of social spammer detection for-mally. Next, we illustrate the main steps of the PCA-PUD method. 3.1 Problem Statement Let X  X  R n t be the t features of n users in a social network, and Y  X  X  0 ; 1 } n are corresponding labels of users, where y i = 0 indicates the i th account is a spammer and equals to 1 otherwise. We use U , P , RN to represent the Unlabeled Samples, Positive Samples and Reliable Negative Samples, respectively. More ; l; r represent the amount of users in the corresponding samples and = n  X  l ; since only a few positive samples and plenty of unlabeled samples are used, we assume that l  X  u . In order to balance P with RN , we set r  X  l . The PCA-PUDs means that PCA-PUD regards spammers as positive data, thus we assume c = 0, c 2 = 1; oppositely, the PCA-PUDn regards normal users as positive data, where c 1 = 1, c 2 = 0.
 features for all n instances and some positive labels, learning a model PCA-PUD with well performance to classify an unknown account. 3.2 PCA-PUD Framework The framework of our proposed method consists of three steps, as described in Fig.1. At the rst step, key features are extracted from raw data. In the second step, the reliable negative classi er is trained using positive and unlabeled users. Then the negative samples are obtained from unlabeled samples. In the last step, the PUD classi er is learnt from positive and predicted negative users. Finally, we can use the PCA-PUD classi er to predict the labels of unlabeled users. 3.3 Feature Selection Users are accompanied with high-dimensional features in social networks. For example, millions of tweets are posted every day in Twitter, it causes the high-dimensional features. In addition, the unrelated, noisy and redundant features may over t the training algorithm and lower the performance.
 key features. This algorithm selects features according to the maximum variance which can increase the density of the key features. Moreover, it discards minimum variance, because the eigenvector of the smallest eigenvalue is associated with noise information usually. The algorithm is showed in Table 1: 3.4 Reliable Negative Classi cation Picking out the reliable negative samples is a critical in PU Learning. Theo-retically, maximizing the con dence of the negative samples and ensuring the positive samples are correctly classi ed, we can get a superior classi er [14]. Therefore, it is vital to nd as many reliable negative samples as possible in the unlabeled dataset. In the following, we will describe the algorithm in detail. because it is a mature and popular classi ed algorithm, while other algorithms are alternative. Naive Bayes learns the joint probability distribution P r ( X; Y ) from the training dataset. Speci cally, it needs to learn the priori probability distribution in Equation(1) and conditional probability distribution in Equa-tion(2).

P r ( X = x | Y = c k ) = P r where c 0 and c 1 denote the labels of positive samples and unlabeled samples, respectively. The joint probability distribution P r ( X; Y ) is learnt by Equations (1) and (2).
 probability distribution in Equation(3) by the learnt model. The label of x is the one having the highest posterior probability.
 sample P and unlabeled samples U is as follows: rst of all, we assign each spammer label c 1 to constitute P and some unlabeled users label c 0 to form U . Second, RN classi er is learnt from P and U by Naive Bayes, where l is the amount of P and r is the amount of RN . We set = 0 : 5, because training and predicting both need plenty of samples. Note that, is an important parameter will be discussed in experiment. Third, we exploit the classi er to identify other unlabeled users, (1  X  ) U . Finally, those users in (1  X  ) U that are identi ed as normal users whose labels are c 2 form RN until r = l . These negative samples will be utilized in the next step. In addition, normal users can be regard as positive samples as well, and we will discuss the two situations in experiments. 3.5 PUD Classi cation In our method, the last step is constructing the PUD classi er to detect s-pammers. We construct the PUD classi er with positive and predicted negative samples by Naive Bayes algorithm as well.
 where c 1 indicates the positive label and c 2 denotes the negative label. The procedures of PUD classi er are as follows: rst, the PUD classi er is trained by the predicted negative samples RN from the RN classi er and given positives samples P . Then the PUD classi er is utilized to detect spammers: the user is a spammer if the predicted label is positive, otherwise the user is legitimate. Just like RN classi er, normal users also can be regard as positive samples. The process of the PCA-PUD method is shown in Table 2.
 In this section, we conduct experiments to evaluate the e ectiveness of the pro-posed PCA-PUD method. We rst introduce the datasets and metrics. Then we compare the performance of PCA-PUD with other detection methods. Finally the sensitivity of parameter will be discussed. 4.1 Datasets and Metrics Two real datasets provided by Benevenuto [1,2] are used for evaluation. The one is from the most popular on-line social network in the world, Twitter [1]. This dataset contains 1650 labeled users, 355 of them are spammers. Each user has 62 features which are derived from tweet content and user social behavior. The other is from YouTube [2], one of the largest video sharing and spreading sites, and the dataset includes 188 spammers and 641 legitimate users. Each user has 60 features which are derived from video attributes, individual characteristics of user behavior, and node attributes.
 F-measure to analyze the performance. The metrics are de ned as where P and N represent positive samples and negative samples. The true posi-tive ( T P ) sample means predicted and actual labels are positive. If the predicted label is positive, and actual label is negative, the sample is a false positive ( F P ) sample. Likewise, false negative ( F N ) means that the predicted label is negative, but actual label is positive. 4.2 Performance of PCA-PUD In this subsection, we rst compare the performance of RN classi er. Then the PCA-PUD is compared with maturely surprised methods and a semi-supervised method. The experiment is conducted by 5-fold cross validation 10 times, and we utilize the average value to represent the results. It be note worthy that spammers are regard as positive samples in PCA-PUDs, and normal users are regard as positive samples in PCA-PUDn as well.
 Credibility of RN Classi ers. We evaluate the credibility of the RN classi ers by precision. It can be seen from Table 3, RNs achieves better precision than RNn. Compared to RNn, in Twitter, the precision of RNs get a 7.8% rise; RNs improves precision by 5.4% in YouTube. The explanation of the results is that RNs method identi es normal users from unlabeled users. And the proportion of normal users is large that makes it easier to identify the normal user; therefore, the precisions of RNs are quite good. By contrast, RNn identi es spammers from unlabeled users, and the small proportion of the spammers in the datasets makes it dicult to distinguish spammers, the precisions of RNs are not as good as those of RNs.
 Compare PCA-PUD with other detection methods. To show that our proposed method has competitive performance, we compare PCA-PUD with tra-ditional supervised methods, including Decision tree (DT), Naive Bayes (NB), Logistic Regression (LR), and a state-of-the-art semi-supervised method which samples by uncertainty and representativeness(SUR UNC) [12]. Comparison re-sults are shown in Table 3, and we bold the best values in each row. measure to supervised methods and similar F-measure to the semi-supervised method despite that only utilize positive labeled and unlabeled samples. In con-trast with SUR UNC, our methods have better stability on both two datasets. PCA-PUD only needs positive data which reduce the time-consuming of labeling, consequently, it meets the requirements of real situation. 4.3 Parametric Sensitivity Analysis In this subsection, we discuss the sensitivity of the parameter which determines the proportion of positive samples chosen. The experimental results on Twitter and YouTube dataset are shown in Fig.2 and Fig.3, respectively.
 er with the di erent values of on the Twitter dataset. Note that the number of positive samples is increased with the increasing of . It can be observed that the precision of RNs is gradually increased while the recall of RNs is gradual-ly reduced. In order to balance the performance of the RNs classi er, we take = 0 : 5 in experiment, and then the performance of PUDs reaches the optimal state. Fig.2 (b) shows the performance of RNn classi er and PUDn classi er. The precision of RNn moves inversely to the recall. We also take = 0 : 5 in experiment to make the precision and recall balance. Futherfore, the PUDn can achieve ideal performance when = 0 : 5. equals to 0.3, the classi ers can keep precision and recall equilibrium. It is proven that our approaches which only need a few positive samples and plenty of unlabeled data can perform competitively.
 method is not always outstanding in precision and recall simultaneously, but it can keep the F-measure stable well. The e ect of the parameter was analyzed, which proves that our method can achieve the ideal results merely use a few positive samples. Thus PCA-PUD can be applied in many real situations. In this paper, we proposed a novel method PCA-PUD based on PU Learning, it aims to construct a detection classi er by a few positive samples and plenty of unlabeled data. Speci cally, we utilize PCA to extract key features from the original dataset. Then the reliable negative classi er is build to pick out nega-tives from unlabeled data. Next, we use given positive and predicted negative samples to train the PUD classi er. Furthermore, PCA-PUDs and PCA-PUDn regard spammers and normal users as positive samples, respectively. Experi-mental results on the two real-world datasets show that our approaches have competitive performance with stable F-measure, and it meets the requirements of real situations, thus it can be applied extensively.
 detection method. A few possible directions remain to be studied. First, we will combine PCA-PUD with various state-of-the-art surprised methods to improve the precision of spammer detection. Next, the PCA-PUD method will be used to detect fake comments in social networks.
 Acknowledgments. The work is supported by the Basic and Advanced Re-search Projects in Chongqing under Grant No. cstc2015jcyjA40049 and the Na-tional Key Basic Research Program of China (973) under Grant No. 2013CB328903.
