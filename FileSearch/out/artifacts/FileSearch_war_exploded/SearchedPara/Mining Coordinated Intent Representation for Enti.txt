 We study the problem of learning query intent representation for an entity search task such as product retrieval, where a user would use a keyword query to retrieve entities based on their structured attribute value descriptions. Existing intent representation has been mostly based on the query space. These methods overlook the crit-ical information from the entity space and the connection in be-tween. Consequently, when such representation methods are used in intent mining from user engagement logs in entity search, they cannot fully discover the comprehensive knowledge of user pref-erence, which is essential for improving the effectiveness of entity search and recommendation, as well as many applications such as business intelligence.
 To address this problem, we propose a novel Coordinated Intent Representation, where each user intent is represented collectively in both the query space and the entity space. Specifically, a coordi-nated intent representation consists of a language model to capture typical query terms used for search and a series of probabilistic distributions on entity attributes and attribute values to characterize the preferred features of entities for the corresponding intent. We propose a novel generative model to discover coordinated intent representations from the entity search logs. Evaluation in the do-main of product search shows that the proposed model is effective for discovering meaningful coordinated shopping intents, and the discovered intent representation can be directly used for improving the accuracy of product search and recommendation.
 H.2.8 [ DATABASE MANAGEMENT ]: Database applications X  Data mining ; H.3.3 [ INFORMATION STORAGE AND RETRI-EVAL ]: Information Search and Retrieval Algorithms, Performance, Experimentation c  X  2015 ACM. ISBN 978-1-4503-3794-6/15/10 ...$15.00.
 Intent representation; intent mining; product search; product rec-ommendation; coordinated representation; joint mixture model
In many application domains, there is a need to rank entities in a database in response to a preference keyword query, which we refer to as entity search. Often times, the databases of entities are nat-urally available as in the case of product search or medical record search, where detailed descriptions of entities are manually added to a database with clearly defined attributes. A database of entities can also be constructed automatically or semi-automatically by us-ing information extraction techniques to extract entities and their attribute values from unstructured text data; for example, genes, along with their regulation relations and associated species, can be automatically extracted from biology literature. In the most general setting, databases of entities may be formed by merging manually created databases with automatically extracted structured data.
Such databases are very different from the traditional transac-tional databases in that the application needs are dramatically dif-ferent. Particularly, in entity datases, there is a need for supporting keyword queries to help users find relevant items by providing a ranked list of entities in descending order of likelihood of match-ing the user X  X  query. A good example of such application system is product search engine for e-commerce, which is an integral and indispensable part of e-commerce websites such as walmart.com amazon.com 2 and ebay.com 3 . These product search engines answer a gigantic volume of queries every day and are essential for people who shop online. Naturally, their accuracy affects the productivity and quality of our lives.

While general Web search has been studied extensively, research on entity search (as we defined) has just started with only a few studies [7, 8], which have mainly focused on developing effective probabilistic retrieval models. As in all search engines and rec-ommender systems, understanding users X  search intent is of criti-cal importance and largely determines the accuracy of the applica-tion. For example, in product search, users X  search intents directly relate to their purchasing activities. Rather than having an infor-mation need as in the case of Web search, a user X  X  product search intent primarily reveals his/her shopping preferences. Clearly, un-derstanding such preferences is very useful for optimizing the prod-uct search and recommendation accuracy. In this paper, we study how to model and discover users X  search intents in an entity search http://www.walmart.com http://www.amazon.com http://www.ebay.com system and explore applications of the discovered intent models in improving entity search and recommendation.

Intent understanding has been widely studied in the context of document retrieval and Web search. Existing work use predefined taxonomies, automatically determined topics or concepts mined from knowledge base to represent user intents[14]. A major lim-itation of these methods is that the intent representations are only based on the query space with little or no connection with the en-tity space. Due to such disconnection, when used in intent mining from user engagement logs in entity search, these methods cannot fully utilize the data and discover the comprehensive user prefer-ences. It is also difficult to leverage such inferred intents to directly improve retrieval accuracy due to the gap between the query space representation and the entity space representation. Although simi-lar issue also exists in traditional document search, the problem is amplified in the entity search scenario, where the concepts in query space do not naturally map into the target entity space, creating a severe vocabulary gap.
 To address this problem, we propose a novel Coordinated Intent Representation, where the intent is represented in both the query space and the entity space. Specifically, a coordinated intent rep-resentation consists of a language model to characterize the user preferred query terms and a series of probabilistic distributions on entity attributes and attribute values to characterize the preferred entity features for the intent. Each intent is thus  X  X ollaboratively X  captured in the vocabularies of both the query space and the entity space.

Such a dual-space intent representation is well suited for entity search because we can leverage the structures of entities to obtain another layer of understanding of user intents, which will allow us to drill down to what users actually look for in the target entity space directly, rather than  X  X uperficially X  understanding the seman-tic meanings of queries as the current intent representation does. By coordinating the understanding of user intents in both query and entity space, we can achieve a holistic view of intents, which will enable/improve many important analytical tasks.

Further, we stress that compared with existing work on query space intent representation, the proposed coordinated intent repre-sentation provides more complete information, which are neces-sary for disambiguating search intents and are therefore useful for improving the accuracy of entity search. As an illustrating exam-ple, Figure 1 shows three users having different purchasing intents in buying laptops. Two users issue the same query  X  X ightweight laptop X , but they are looking for different types of products: the first user is looking for an inexpensive lightweight laptop used for web browsing ( Processor=Atom &amp; Price &lt; $250 ); the second user is looking for a portable but high performance laptop with more capabilities ( Processor=Core i3 ), and price is not the primary con-cern ( Price &gt; $500 ). Yet another user is having a similar preference as the first user (searching for  X  X etbook X ), but he/she ended up buy-ing a different laptop. In this example we can see using either query space representation or entity space representation alone would not be sufficient to differentiate the subtle differences among intents.
In the proposed coordinated representation, we capture both query space and entity space with several probabilistic distributions. Specif-ically, we use an attribute distribution to capture the importance of attributes (e.g. Processor ), a feature distribution for each attribute to capture user preferences on that attribute (e.g. Processor=Atom ), and a word distribution to capture users X  choice of search terms (e.g.  X  X etbook X ).

Once we can infer the coordinated intent representation for a query, we can leverage it to improve accuracy of entity search and recommendation. Take product search for example. It is often that users use different keywords to search for similar or same products because their perception and knowledge about the product varies. For instance, the queries  X  X amera stick X ,  X  X amera pole X ,  X  X elfie holder X ,  X  X elfie kit X  are used to search for the same type of prod-ucts. Separately optimizing each query based on text matching is clearly not the ideal solution, especially for a conversion-centric product search engine. On the other hand, different users may also use the same query to search for distinct products. For instance, users with the query  X  X amera kit X  may be either looking for tripods, cleaning tools or even camera lens for phones. With a good intent model, we can interpret a query based on the users X  potential shop-ping preferences and rank products based on how likely they can satisfy such preferences. In this way, search queries can be op-timized in semantic groups, rather than each individually. As a result, semantic level matching can be achieved. A successful in-tent model will not only improve search accuracy, but also largely benefit the search experience as a whole. For instance, when the user query is too specific (e.g. directly copied from product titles elsewhere), matching zero or few products, we can provide recom-mendations based on the inferred intents and/or matching products of the query. On the other hand, when a user query is too broad or ambiguous, we can diversify the results according to the potential user intent, so that representative products of different intents are showed first.

The benefit of understanding and modeling entity search intent goes beyond optimizing search and recommendation. For exam-ple, accurate understanding of user X  X  shopping intent provides a platform for multiple business intelligence purposes. Also, a suc-cessful intent model would be able to predict the demands of prod-uct features, so that we can optimize for inventory and even for manufacture.

To automatically discover coordinated intent representations, we propose a novel joint mixture model to learn such intent represen-tations from entity search logs. The proposed model assumes the following generative process for modeling a user X  X  query and the at-tribute values of the entities liked by the user simultaneously. First, the user chooses an intent from a mixture of search intent. The user then composes a query according to the word distribution of the chosen intent model. Upon receiving the search results, the user decides which product to engage with by generating the entities by sampling the features on each of its attributes. Particularly, the user first selects an attribute based on the attribute preference distribu-tion, and then samples a value based on the feature value distribu-tion of the attribute. In order to estimate the joint mixture model, we use an expectation-maximization (EM) algorithm to maximize the data likelihood of a search log.

To demonstrate the utility of the proposed coordinated represen-tation, we apply it to product search and empirically evaluate the fitted models on several large domains in online shopping. Ex-amination of representative queries, terms and product features of popular intents in three large online shopping categories show that the proposed method can accurately detect the distinct intents and predict their popularities. Further, we apply the intent model in product search and product recommendation. We show the model can be easily incorporated into the language modeling framework. With the combination of the intent model and the language model, we can achieve significant improvement in search accuracy. When used in recommendation, the intent model enables semantic match-ing between products even though they may not share the exact same features. Experiment results confirm the effectiveness of our model in both the applications. Although not studied in this paper, the intent model can also be applied to many other related applica-tions such as query suggestion and search result diversification.
Intent modeling in search systems has been studied in recent years mostly in the context of document retrieval and Web search. Much work has been done on categorizing search intent into the general stereotypes of navigational, informational and transactional intent [1, 16, 22, 15, 17]. Nguyen et al. propose to capture user intent based on three components including context, interests and preferences [20]. Guo and Agichitein propose to explore mouse movements for enhancing query intent detection [10]. But due to the lack of structure in documents, it is usually difficult to appro-priately represent intent, hence difficult to gain insights in intent understanding. Personalization studies user specific intent model-ing. Work in this area typically explore the search and browse his-tory of a user in order to obtain a better understanding of the user X  X  preferences [21, 23, 4]. The problem of intent representation and intent discovery in entity search is very different from the existing work on document retrieval. As we have seen in the examples in Section 1, understanding search intent on the text level is not suffi-cient and leveraging the structure information of entities is critical for successful intent modeling.
 Our work also falls into the general category of query log mining. Query log mining has provided opportunities to improve search and many other applications. The data driven methods based on query log mining have been shown to be effective in these applications. Cui et al. mine search logs for query expansion [6]. Zhang and Nasraoui mine search logs for query recommendation [26]. Hassan et al. mine from user behaviors to detect success of search [11]. Our work in terms of query log mining is unique and important in several ways. In particular, we study entity search log, which is very different from ordinary document search log as the data consists of both unstructured and structured data. There has been only few studies on product search log, and no previous work has explored the dual space of queries and entities in entity search log to represent and discover user intent.

Click modeling is a special branch of query log mining and anal-ysis. The goal of click modeling is to extract reliable evidence for relevancy. Early work study how to reduce the position bias from click logs [9, 2, 5]. Hu et al. propose an intent hypothesis to cap-ture the search intent and query formulation bias to complement the existing click models that only consider position and relevance bias [13]. Wang et al. propose a content-aware model of relevance in dealing with click data, where the dependencies among documents are taken into account [24]. In general, click modeling can be the building block for almost all query log analysis. Because the main focus of this work is the modeling of user intent, the discussion of click modeling techniques falls out of the scope of the paper. However, it is clear that these techniques can be incorporated into the proposed intent modeling method and potentially improve the performance. We plan to explore them in our future work.

Our work is also related to applications such as product search and product recommendation, as the discovered intent models can be directly applied to improve these applications. Work has been done to adapt document retrieval models on structured data [3]. It has also been studied in the form of keyword search in databases where the emphasis is on the efficiency and problem of matching keywords across different tables [19]. In this paper, we focus on studying the benefits of intent modeling in product search, which is novel and has not been explored in either area. Duan et al. study the problem of vocabulary gap between user queries and structured product information in product search [7, 8]. Probabilistic retrieval models are proposed to leverage search logs and product reviews, in order to align product features with word descriptors. Although these methods can transform specific query intent into data level representations, they cannot discover and model the popular user intent in product search, which is the research problem we study in this paper.
Understanding a user X  X  search intent is necessary in order to op-timize search accuracy. However, it is not immediately clear what is exactly an intent. In some existing work, an intent is charac-terized by categories (e.g., one intent can be  X  X ravel X  and another can be  X  X hopping X , or even more broader categories such as  X  X av-igational X  vs.  X  X nformational X  queries) [1, 15, 18]. Such a coarse representation is clearly insufficient for optimizing the search ac-curacy for a specific query. In general, the existing work has either not been able to explicitly capture an intent or only represented an intent using the information from the query space. While such kind of representation is natural and meaningful to a certain extent, it has the limitation of being disconnected from the information items, which in our case, are entities in the collection. Such a dis-connection creates a gap between the intent representation and the representation of entities, thus making it difficult to directly use the inferred intents to optimize retrieval accuracy.

We observe that in general, a search intent can be viewed from two different perspectives. One perspective is how a user describes an intent, i.e., what kind of query terms the user would likely use to search in order to fulfill the intent. This naturally correlates to a query-space representation. The other perspective is what entities or entity features the user is looking for with such an intent. This leads to an entity-space representation. We argue that a more ap-propriate and useful representation of search intent should capture an intent in both the query space and the entity space, i.e., obtaining a dual-space intent representation. Based on this idea, we propose a Coordinated Intent Representation for entity search.

Compared with the existing intent representation methods, the coordinated intent representation has three major advantages. First, it bridges the vocabulary gap between a user X  X  query and the entity data. Therefore, the inferred intents of a query can be directly used to optimize entity search results. This is significant for entity search tasks because in entity search, the keywords that users search for do not naturally translate into what entities they are looking for. For example, a user searching for  X  X erformance laptop X  is actu-ally looking for some specific types of CPUs and/or graphics cards. Second, because such an intent representation is more meaningful and interpretable, it enables interesting analytical applications to provide business intelligence for product manufacturers and answer questions such as what features of products are important to users.
In the following we describe the coordinated intent representa-tion in more detail. We use three distributions to characterize entity search intent. Formally, let I be a set of intent models, let k be the size of I and I i be the i th intent in I . We have where  X  i is a multinomial distribution over search terms W , cap-turing the importance of each term in describing the intent. For ex-ample, given a shopping intent for portable TV set , words such as  X  X otable X  and  X  X ompact X  will likely have high probabilities, while words such as  X  X ignal X  and  X  X ifi X  may have relatively low prob-abilities.  X  i = {  X  i,a | a  X  A } is a set of Bernoulli distributions over each attribute a from the entire attribute set A in the entity data.  X  i,a captures how likely the corresponding attribute a (e.g. Color ) is concerned in the intent I i (vs. in the generic intent). A small  X  i,a value corresponds to a high probability that users want to impose a preference on the attribute, rather than complying with the popular preference. For example, in the portable TV set intent, the Size attribute will have a very high probability, possibly close to 1, meaning that users have specific requirements on TV size; whereas other attributes like Refresh Rate and Warranty will have low probabilities, meaning that users do not care much about these properties as long as their values comply with the popular choices. The third parameter  X  i is a set of multinomial distributions, also defined on the entity attributes. Each  X  i,a  X   X  i is a multinomial distribution over possible values of attribute a , capturing the pref-erence on that given attribute. In the same portable TV set intent example, on the Size attribute, it will have high probabilities on the small sizes such as Size=10" and Size=18" , and low probabili-ties on large sizes. In the following, we introduce how such intent models can be automatically discovered from user engagements in entity search logs.
The coordinated intent representation simultaneously captures a user intent in the dual space, i.e. the query space and entity space. Each intent model encodes comprehensive information to distin-guish it from other intents. However, it is no easy task to auto-matically discover a set of distinct intents, as user intents are not directly observable. In entity search, users are not able to explic-itly reveal their search intents. Rather, their intents are embodied in the search activities, which are ambiguous in several ways. On one hand, users with different intents may have overlap behaviors on the choices of search queries and entities they engage with (see example in Figure 1). On the other hand, users with the same intent may as well use semantically the same but verbally quite differ-ent queries and examine similar but different entities. To overcome these ambiguities in observation, and to automatically discover the set of popular and distinguishable entity search intent, we propose and explore a generative process, which  X  X roduces X  the observa-tions of user activities in entity search based on a set of intent mod-els. This is referred to as the joint mixture model. We then propose an EM (Expectation-Maximization) algorithm to infer the underly-ing intents based on the observed user behaviors by maximizing the likelihood of the data. Below we present the joint mixture model and the EM algorithm.

Notations. For the convenience of discussion, we introduce a set of notations and will use them throughout the rest of the paper. We use E to denote a set of entities. Each entity is represented by a feature vector in a predefined attribute space A . For an entity e  X  E , its value on attribute a  X  A is denoted as v e,a . We use S to denote a set of sessions acquired from entity search logs, where each session s  X  S consists of a query q s and a set of engaged entities E s . Each query q consists of a set of keywords, i.e. q = { w | w  X  W } , where W is the word vocabulary.

Note that our definition of  X  X ession X  is different from the typical definition of session, as each session contains only one query. The notion here is merely to encapsulate all user behaviors in response to the search results of one query. Conceptualizing user behaviors in this way ensures the assumption that a user X  X  search intent re-mains invariant during one session.
Given an entity search log, We assume a generative process that explains the observations of user behaviors. At the beginning of any session s , the user chooses an intent I i by sampling from a mixture of intent. Upon choosing an intent, the user will follow the encoded behaviors in its intent model {  X  i ,  X  i ,  X  how he/she interacts with the search system. In particular, this will determine the query q s and the set of entities the user will engage with, i.e. E s .

More specifically, the user first selects a query q s by repeatedly sampling a word from the word distribution  X  i . Note that although a specific intent model has been selected, the user still has the free-dom of choice to either select a topic specific word or a more gen-eral word from the generic word distribution  X  G . Then each entity e  X  E s is generated in the following way. On each attribute, the user first decides whether he/she has strong preference on the fea-tures of the attribute, as compared to the general popular preference on that attribute. For this the user chooses between the selected in-tent model I i and the generic intent model I G by sampling a binary variable from the Bernoulli distribution  X  i,a . If the intent specific preference is selected, the value v e,a will be generated by the in-tent model X  X  value distribution  X  i,a . Otherwise, it will be sampled from the generic value distribution  X  G,a . To further understand this, consider in product search a user is searching for large TV set. Given this intent, the user may have strong preference on certain attributes, such as TV size and Price range . The user may also have preference on some less obvious attributes, such as TV technology as some technology (e.g. LED vs. Plasma) might be more suit-able for larger TV sets. These could be very different preferences from the general preferences on TVs and are unique to this intent. Therefore, the Bernoulli distribution  X  on these attributes will re-flect such preferences by having a higher probability on choosing the intent specific feature distribution. On the other hand, on certain attributes, such as Warranty , the users searching for large TV sets do not have a distinguishable preference than users who are search-ing for TV sets in general. In all cases, users are likely to prefer longer warranty on the product. In this case, this intent model will have a lower probability on selecting the intent specific value dis-tribution, therefore a higher probability selecting the general value distribution on the Warranty attribute.

The joint mixture model has many advantages. First, compared with alternative generative processes where users may select in-tent models to generate queries and entities separately, the proposed joint mixture model generates both queries and all attribute values for the engaged entities using the same intent model. This is con-sistent with our intuition that user X  X  general intent (e.g. shopping) remains unchanged throughout a single search query. Therefore, it is more likely to produce meaningful intents. Second, because the joint mixture model accounts for both the query and the entities in a user engaged session, the intent models discovered in this way will be coherent and less likely to be affected by users X  behavioral am-biguity in choosing queries and engaging with entities. Finally, the joint mixture model utilizes the structure of entities in modeling in-tent. The feature value generation process is modeled separately on different attributes. Compared to an alternative model which gen-erates the values using an all-in-one distribution similar to generat-ing words, the proposed solution is more consistent with the entity search behaviors. More importantly, it ensures that the estimation of one feature probability will not affect other features on different attributes, i.e. values on different attributes do not need to  X  X ight X  for the same probability mass. The intent models is therefore more meaningful and interpretable.
To infer the underlying intents from a set of observed sessions S in search log, we follow the generative process of the joint mixture model and maximize the likelihood of the data:
L = X
To estimate the intent models, we employ an EM algorithm. The algorithm maximizes the likelihood by iteratively applying an ex-pectation step (E-step) and a maximization step (M-step).
In the E-step, the algorithms computes the expectation of the likelihood by inferring the identity variables: p ( z G = 1 | s,e,a,I i ) =  X  i,a p ( v e,a where  X  p ( z i = 1 | s ) = p ( I i | s ) Y
Here  X  G is a generic word preference distribution and  X  G,a a generic value preference distributions on attribute a . Both can be estimated using the entire collection data. z i , z G and  X  indicator variables. If z i = 1 , the i th intent, i.e. I If z G = 1 , the generic intent model will be used to generate the feature value; if z G = 0 , the selected intent model I i instead. The same semantic is applied to  X  G for generating words.
In the M-Step, the algorithm reestimate the model parameters based on the values of the latent variables inferred in the previous iteration: p ( v |  X  i,a ) = p ( w |  X  i ) = where  X  ( v 1 ,v 2 ) is an indicator function assigning value 1 if v v , and 0 otherwise.
 In the previous discussions, we fix the number of intents to k . In fact, we can determine the number of intent models dynamically by using a relatively large k and eventually combine similar intent models. This can be done by applying a similarity measure on intent models. In this work, we use the KL-Divergence of the word distributions as the similarity function. With this method, we can combine overlapping intents and obtain the final intent set.
Interpretability is one of the advantages of the coordinated intent representation. We will demonstrate this in more details in Sec-tion 6.1 where we empirically evaluate the quality of discovered intents. As such it is also clear that the intents discovered from real user activities will largely benefit business related analytical tasks. But beyond these, one primary goal of intent discovery is to reapply it to entity search to optimize the overall search experience. As discussed earlier, this includes a number of applications, such as entity search, entity recommendation, query suggestion, result diversification, etc. In this work, we will demonstrate the utility of intent discovery in optimizing the accuracy of entity search and entity recommendation. We will further explore its utility in other applications in our future work.
Previous work have shown that a good understanding of search intent will improve the accuracy of search. Existing methods uti-lizing search intent are to augment the search queries using cate-gories and concepts, etc [14]. However, these methods are limited by the incomplete intent representations that emphasizes only the query space. Based on the coordinated intent representation, in this work we propose an intent-based language model for entity search, where each intent is evaluated based on how likely it generates the search query, and entities are ranked according to how likely they are generated from the most suitable intents for the query. The model bridges queries and entities with the intents, and therefore enables semantic matching between terms and entity features.
More specifically, we integrate the discovered intent models with the KL-Divergence language model. In this model, the scoring function is essentially given by the negative KL-Divergence of the query language model and the document language model (entity model in our case):
Without assumption of any feedback data, the query language model is estimated using the query itself. In the regular keyword-based language model, the document language model is typically estimated by the content of the document, and smoothed by the collection language model. In the case of entity search, we can use entity information (i.e. words describing each feature) for estimat-ing the entity language model.

In the intent-based language model, rather than generating query terms directly from the distinct entity space, we first sample an intent from the entity, and then use the intent X  X  word distribution to generate the query. Formally, in the intent-based language model, we reuse the scoring function and redefine p ( w | e ) as follows: where where
The intent-based language model avoids the vocabulary problem between queries and entities. Therefore, it can match between what user searches for (the query) and what user is indeed intended for (the target entity). It also constructs an  X  X ntent map X  of the query, so that results are optimized for the intents, rather than for separate queries. For example, the results of  X  X elfie kit X  and  X  X amera stick X  will be similar as they are from the same intent.

Despite the advantage of semantic matching, sometimes key-word matching still provides the most reliable evidence of rele-vance. Because the intent-based language model deemphasized keyword matching, we can complement the effect by combining the regular keyword based language model with it. Given the two sep-arately estimated language models (typical LM and intent model augmented LM), there are two possible ways to combine them. We can either combine them into one probabilistic model, or perform separate rankings and combine the final scores for each item. Inter-estingly, we find the latter method tend to outperform the former. Therefore in practice we linearly interpolate the two language mod-els and set the interpolation parameter using cross validation.
Recommending entities based on a given entity is an important application to enrich the overall entity search experience. For in-stance, product recommendation in online shopping is an important way for users to explore product inventory. To make good recom-mendations, we need to be able to measure the similarity of two products.

Typically, the similarity can be measured by comparing product features. Products having more overlapping features are deemed to be more relevant. Such a method does not account for the similari-ties between attributes. For instance, 65 inch TVs are more recom-mendable if the user is considering a 60 inch TV, as compared to a 40 inch TV. Further, the method does not distinguish the impor-tance of different attributes. A match on TV size is clearly more important than matching on length of warranty. To overcome these issues, a typical solution is to cluster related features. For instance, in a session based clustering method, if two brands are constantly examined together in the same sessions, then products with these brands are more likely to be similar, therefore the brands are clus-tered and treated as a match.

In this work, we apply the proposed intent model to product rec-ommendation. From Section 6.1 we see that the intent modeling method serves as a principled way to simultaneously cluster query terms and product features. It also naturally provides a similarity measurement for products. Intuitively, if two products can be de-rived from the same intent model (with high probabilities), they are likely good recommendations for each other. Based on these considerations, we derive the similarity function within the proba-bilistic framework. Specifically, the similarity of two products e and e 2 are measured by their joint probability: where k is the total number of intents we discovered, p ( e | I computed using Equation 13 and p ( I i ) is computed using Equation 15. Here we assume the generation of two products is independent from each other given a specific intent I i .

Because p ( I i ) captures the popularity of the intent I ties matching on more popular intents are more  X  X imilar X , i.e. more recommendable for each other. The similarity metric can therefore produce more meaningful entity recommendations. We will eval-uate the proposed metric with existing methods in more detail in Section 6.3, in the context of product recommendation.
In this section, we apply coordinated intent discovery to the do-main of product search, and empirically evaluate its utility, both qualitatively and quantitatively. In particular, we first examine the quality of the discovered intents in three major online shopping domains, and also demonstrate the interpretability of the coordi-nated intent representation. We then apply the discovered intents to product search and recommendation, to evaluate their effect in improving search experience.
By fitting the joint mixture model to a product search log, we can automatically discover a set of popular shopping intent in the form of coordinated representation. In this section, we empirically examine the discovered intent models using search engagement logs from Walmart.com 4 , an established e-commercial website with large search volume. For demonstration we use three large cate-gories in online shopping,  X  X omputer Laptops X ,  X  X Vs X  and  X  X am-eras X . We obtain a month X  X  search logs and extract engagements http://www.walmart.com for the three categories separately by matching the engaged product entities to the corresponding category X  X  database. In total, we have more than 9K sessions for the  X  X omputer Laptops X  category with user engagements (each session containing one query), more than 25K sessions for the  X  X Vs X  category and more than 10K sessions for the  X  X ameras X  category. On average there are 3.8 engagements per session. The detailed statistics of the corpora are summarized in Table 1.

Obtaining useful information using intent models. The intent models we discover are probabilistic models that contain compre-hensive information about search intent. While these raw proba-bility distributions are informative, they can also be used to obtain more interpretable knowledge. In the following, we demonstrate this by computing intent popularity and representative queries, both of which can help us better understand user intent.

Intent popularity. Intent popularity is an important piece of in-formation that can help us draw insights from the discovered intent models. Knowing how likely users have certain intent has clear impact on e-commerce business. Formally, given the i th intent I , its popularity is captured by p ( I i ) , which can be computed by marginalizing over the joint mixture model parameter p ( I
Since we don X  X  have any prior knowledge on each session, it is reasonable to assume p ( s ) is uniformly distributed. p ( I the popularity of an intent.

Representative queries. Both the word distribution and the feature distribution in the intent models are very informative, but they can also be used to obtain more directly interpretable informa-tion, e.g. representative queries.

There are many ways to select meaningful queries given the in-tent models. In our case, we prefer queries that are both repre-sentative and discriminative. In order to be representative, a query should have high probability being generated from the intent model. Meanwhile, we also want the selected queries to be exclusively generated from the given intent. That is, the query should have low probability being generated by all other intent models. Fol-lowing this idea, we use the conditional probability p ( I queries: where p ( I i ) is the intent popularity computed by Equation 15, and p ( q | I i ) is the probability of generating query q from the intent model of I i , which is computed as:
Given intent I i , p ( I i | q ) provides a balance between representa-tiveness and discriminativeness. Queries with high p ( I be meaningful and uniquely characterizing the intent. In this order, we select queries to cover a desired probability mass in the term distribution for each intent.

With this additional information, we summarize the discovered most popular intent models in the categories  X  X aptop X ,  X  X V X  and Table 2: Top discovered intent models in  X  X aptop X  category  X  X amera X  in Table 2, Table 3 and Table 4, respectively. For each intent model I i , we first show the probability p ( I i ) as an indication of intent popularity. We then show the representative queries, the top 5 words in  X  i , the top 5 attributes ranked by 1  X   X  to 3 top feature values on each attribute a according to  X  with probabilities smaller than 0.01 are ignored).

Judging from the representative queries in Table 2, we can see that the top intent models in  X  X aptop X  category can be interpreted as  X  X aptop bundles X  and  X  X etbook laptop X , with  X  X aptop bundles X  being the most dominating intent. Looking into the words and fea-tures, we can see the three intent models are clearly different from each other. The first one is mostly concerned with the  X  X undle X  fea-ture; the second has emphases on a particular type of processor and the size of the laptop; the third intent model prefers high end CPUs and specific brands and colors. From the discovered intent models in the  X  X V X  category, we can see that the user difference is mostly captured by the screen sizes. Different intent models have distinct preferences on the  X  X rice X  and the  X  X creen Size X . For  X  X amera X  category, the top 3 intent models are clearly different in the  X  X ype X  attribute, each preferring  X  X oint Shoot X ,  X  X ltra-zoom X  or  X  X SLR X . Each intent also has a unique price range.

Overall, we can see that the proposed intent modeling method can successfully capture the user behavioral difference and gener-ate meaningful intent models as well as interpretable representa-tions. The queries selected based on the proposed query selection procedure can effectively capture the preferences.
To evaluate the performance of product search, we created an evaluation set by randomly selecting queries and asking experi-enced industrial annotators to label the returned products from the search engine into 5 relevance degrees. In total we obtain 96 queries for the  X  X aptop X  category, 146 for  X  X V X  and 98 for the  X  X amera X 
Queries vizio 47, vizio 47 class, vizio 42 class, Words tv, vizio, 3d, led, smart Features Resolution 1080p
Queries 32 inch tv, 32 tv, pink tv, 32 inch, 32 in tv, Words tv, 32, vizio, inch, lcd Features Brand Sceptre, Vizio, RCA
Queries 19 inch tv, tv with dvd, 19 inch flat screen tv, Words tv, dvd, vizio,with, combo Features Brand Vizio, RCA, Emerson Table 4: Top discovered intent models in  X  X amera X  category category. We evaluate the search systems based on NDCG@3 and NDCG@10.
 We show the experiment results on product search accuracy in Table 5. For comparison we implement three baseline systems. The first baseline is a regular KL divergence language model approach, Base.LM, where the product language models are estimated based on the keywords from the product feature descriptions. The sec-ond baseline method is language model with relevance feedback (FB.LM). This method is implemented according to Zhai and Laf-ferty [25]. We include this feedback method as a baseline method because the proposed intent modeling method uses product search logs for estimation, so they are indirectly using relevance feedback information. The third baseline is an unstructured intent model (UInt.LM) wherein we eliminate the use of product structure in es-timating search intents. In practice this is achieved by fixing the  X  to a constant value in the joint mixture model in Section 4 (same as  X  ). In effect this produces co-clusters of terms-product features. We compare the performance of these three baseline methods with our proposed intent modeling method (Int.LM) and the interpolated model with baseline language model (Base+Int.LM). We perform statistical significant test to compare our methods with Base.LM, FB.LM and Uint.LM. Values showing significant improvement (p-value&lt;0.05) over Base.LM are marked by  X  . Values showing sig-nificant improvement over all three baseline methods are marked by  X  .
 From Table 5 we see that all other methods outperform Base.LM. This is expected because these methods use search log data, there-fore leveraging the relevance feedback information directly or indi-rectly. We also observe that Int.LM almost always outperforms the regular feedback method FB.LM. This shows that the intent model-ing method is a better way of utilizing user feedback. Through in-tent modeling, we can generalize the knowledge from feedback in-formation, whereas the existing method FB.LM only use the feed-back information for each individual query (i.e. queries with no feedback will not be affected). Compared with UInt.LM, Int.LM has consistent advantages in all three categories. This is because by modeling product feature structures, we can achieve more ac-curate and representative intent models. Finally, we find that the search accuracy could be further boosted by combining Int.LM with the Base.LM model. While Intent model captures the gener-alized feedback knowledge, the keyword language model produces more direct evidences for matching against query terms and such Table 6: Intent similarity vs. topic similarity for product rec-ommendation evidences should not be neglected. By combining the effects from the two types of language models, the best performance is achieved by Base+Int.LM in all three categories.
To evaluate product recommendation, we create an evaluation set by extracting products that co-occur frequently in user engagement in search log. To avoid bias, for estimating intent models we use a different time duration from the search log used in evaluation. The two sets of logs are half a year apart. We set a high threshold so that only confident candidates are selected. On average, each queried product has 2.8 recommendations. We select top 5 products for each method and measure the precision, recall and F1 score.
In Table 6, we show results for the evaluation of product recom-mendation. For comparison we implement two baseline methods, one based on feature matching (Feat.Sim) and the other based on clustering of product features (Clu.Sim). A generative clustering algorithm similar to PLSA [12] is used for this purpose. The pro-posed method based on intent model is denoted by  X  X nt.Sim X . From Table 6, we can see that in general clustering product features has a positive effect in recommendation, though the precision decreased in  X  X aptop X  category. With the intent based similarity, there is a consistent improvement on precision and recall compared to both baseline methods. This is because our intent model can more pre-cisely capture the important user preferences. Products matching on these dimensions are likely better recommendations for each other.

To further understand the effect of the intent model in prod-uct recommendation, we further compare it with the co-occurrence counting method (Co.Cnt). Note that co-occurrence counting is the same method we use for generating the ground truth data, except here we use a different set of session logs (half a year before) and a relatively low threshold to ensure coverage.

As compared to the intent model based similarity method, we can see the co-occurrence counting method performs inconsistently across different categories. One explanation is that some categories update inventories faster than others. For categories that constantly have new products coming out, the co-occurrence counting method would not work well as it cannot recommend unseen products. It lacks the ability to generalize from observations. We further com-bined the two methods, i.e. co-occurrence counting and the pro-posed similarity measurement method based on intent modeling. This is denoted as Feat+Int.Sim+Co.Cnt. We see that the results Table 7: Intent similarity vs. co-occurrence counting for prod-uct recommendation are consistently better in all three categories compared to either of the method used alone. While co-occurrence counting captures the more direct and confident recommendation signals, the intent model provides more coverage by successfully generalizing from the search session data.
In this paper, we study the problem of mining coordinated intent representation from entity search logs. To comprehensively char-acterize users X  search intent, we propose a novel coordinated rep-resentation, where each intent is collectively represented by users X  preference in query terms, entity attributes and targeting features (i.e. values on the attributes). We propose a novel joint mixture model and employ an EM algorithm to automatically discover the representative intents from an entity search log. Our intent repre-sentation and modeling methods can successfully mine the unique knowledge from entity search logs, where queries and entities typ-ically have very different structures.

We propose and study how to utilize the coordinated intent repre-sentations to improve entity search and recommendation. We apply coordinated intent discovery to the domain of product search and evaluate the quality of discovered intents and their utility in opti-mizing search applications. Evaluation results show that the pro-posed method is effective for discovering distinct, coherent and in-terpretable shopping intents. The discovered intents are meaningful and representative. Quantitative evaluation on product search and product recommendation also demonstrate the benefits of leverag-ing the proposed intent modeling method in both applications.
This work opens many interesting future directions. First, the in-tent model we proposed in entity search will enable/improve many practical applications. Because the represented intents are highly interpretable, they can be easily used in market analysis and user analysis. Further use of the model can help improve business in-telligence applications such as inventory planning and pricing opti-mization. Second, the results are also encouraging to new ideas in search intent modeling in general, where good intent representation is key for improvement. In the future, we plan to enhance the intent discovery by utilizing all types of user engagements and investigate into its value in more critical applications in business intelligence. [1] A. Broder. A taxonomy of web search. In ACM Sigir forum , [2] O. Chapelle and Y. Zhang. A dynamic bayesian network [3] S. Chaudhuri, G. Das, V. Hristidis, and G. Weikum.
 [4] K. Collins-Thompson, P. N. Bennett, R. W. White, S. de la [5] N. Craswell, O. Zoeter, M. Taylor, and B. Ramsey. An [6] H. Cui, J.-R. Wen, J.-Y. Nie, and W.-Y. Ma. Query expansion [7] H. Duan, C. Zhai, J. Cheng, and A. Gattani. A probabilistic [8] H. Duan, C. Zhai, J. Cheng, and A. Gattani. Supporting [9] G. E. Dupret and B. Piwowarski. A user browsing model to [10] Q. Guo and E. Agichtein. Ready to buy or just browsing?: [11] A. Hassan, R. Jones, and K. L. Klinkner. Beyond dcg: User [12] T. Hofmann. Probabilistic latent semantic analysis. In [13] B. Hu, Y. Zhang, W. Chen, G. Wang, and Q. Yang.
 [14] J. Hu, G. Wang, F. Lochovsky, J.-t. Sun, and Z. Chen. [15] B. J. Jansen, D. L. Booth, and A. Spink. Determining the user [16] B. J. Jansen, D. L. Booth, and A. Spink. Determining the [17] U. Lee, Z. Liu, and J. Cho. Automatic identification of user [18] X. Li, Y.-Y. Wang, and A. Acero. Learning query intent from [19] F. Liu, C. Yu, W. Meng, and A. Chowdhury. Effective [20] H. Nguyen, E. Santos, Q. Zhao, and H. Wang. Capturing user [21] F. Qiu and J. Cho. Automatic identification of user interest [22] D. E. Rose and D. Levinson. Understanding user goals in [23] A. Sieg, B. Mobasher, and R. Burke. Web search [24] H. Wang, C. Zhai, A. Dong, and Y. Chang. Content-aware [25] C. Zhai and J. Lafferty. Model-based feedback in the [26] Z. Zhang and O. Nasraoui. Mining search engine query logs
