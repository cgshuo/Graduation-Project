 Microblogging platforms, such as Twitter, already play an important role in cultural, social and political events around the world. Discovering high-level topics from social streams is therefore important for many downstream applications. However, traditional text mining methods that rely on the bag-of-words model are insufficient to uncover the rich se-mantics and temporal aspects of topics in Twitter. In par-ticular, topics in Twitter are inherently dynamic and often focus on specific entities, such as people or organizations. In this paper, we therefore propose a method for mining multi-faceted topics from Twitter streams. The Multi-Faceted Topic Model (MfTM) is proposed to jointly model latent semantics among terms and entities and captures the tem-poral characteristics of each topic. We develop an efficient online inference method for MfTM, which enables our model to be applied to large-scale and streaming data. Our exper-imental evaluation shows the effectiveness and efficiency of our model compared with state-of-the-art baselines. We fur-ther demonstrate the effectiveness of our framework in the context of tweet clustering.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Clustering ; I.2.7 [ Artificial Intelli-gence ]: Natural Language Processing X  Text analysis Twitter; Topic Model; Unsupervised Learning; Clustering
In recent years, social media and in particular microblogs have seen a steep rise in popularity, with users from a wide range of backgrounds contributing content in the form of short text-based messages. Twitter, a popular microblog-ging platform, is at the epicenter of the social media explo-sion, with millions of users being able to create and publish short posts, referred to as tweets , in real time. Discovering high-level topics from social streams is therefore important for many downstream applications, such as classification, clustering and user modeling [10, 13, 15].

However, there is still a lack of accurate and efficient mod-els for automatic topic discovery in microblogs. In contrast to traditional domains such as news documents or scien-tific literature, topic discovery in microblogs faces many new challenges. We summarize the main challenges as follows.
Entity-centric. Microblog posts often discuss specific en-tities, such as famous people, organizations, or geographic locations [2]. Traditional models for textual data based on the vector-space model or topic modeling take a simplistic bag-of-words view of a  X  X opic X  [1, 5, 13]. These methods fail to distinguish the rich semantics of microblog topics and exploit the various entity types.

Highly dynamic: Microblog topics are constantly evolving, implying the need to model their temporal characteristics. However, the temporal dimension has not been sufficiently explored in current topic models for Twitter data. Moreover, the real-time and streaming nature of social content calls for scalable and updatable models.

Figure 1 illustrates the mentioned characteristics of a topic in Twitter.
 Figure 1: Multiple facets of a topic discussed in Twitter
To tackle these issues in a unified way, we propose a novel topic discovery method. At the core, we propose the Multi-Faceted Topic Model (MfTM), which extracts rich latent topics from microblog content and the associated temporal patterns. In essence, each latent topic has multiple orthog-onal  X  X acets X . For example, the latent topic  X  X rab revolu-tions X  may consist of five facets: general terms (e.g.  X  X ibya X ,  X  X ar X ,  X  X rotest X ), person names (e.g.  X  X uammar Gaddafi X ), organizations (e.g.  X  X nited Nations X ), location names (e.g.  X  X ibya X ,  X  X gypt X ) and a temporal distribution, indicating the trending behavior of the topic. As we show in this paper, the MfTM is more suitable to social streams than standard topic models, such as LDA.
Parameter inference is a known bottleneck of topic mod-els, in particular in face of the scale of microblog data. We therefore build upon the recent advances in variational in-ference methods and develop an  X  X nline X  X nference algorithm for MfTM. In contrast to Gibbs sampling or batch varia-tional inference, our algorithm processes data sequentially. As we show in our evaluation, our inference method easily scales to large datasets and has the advantage of continuous updatability.

The performance of our topic discovery method is thor-oughly evaluated and compared against multiple baseline methods. On the task of tweet clustering, we demonstrate the benefits of our model for downstream applications.
The rest of the paper is structured as follows: Section 2 reviews related work. In Section 3, we present our topic discovery method. Section 4 presents our experimental eval-uation. We conclude our findings in Section 5.
Our topic modeling approach is related to previous works on probabilistic topic models. Blei et al. [1] proposed Latent Dirichlet Allocation (LDA) to analyze electronic archives. Topic models were since applied in various domains, includ-ing search query logs [6, 7] and app marketplaces [8]. In the microblogging environment, Hong et al. [5] study ap-proaches to apply LDA on microblog data. Topic models are used in [18] to compare topics in Twitter and in news articles. In [16], a topic modeling approach is used to dis-cover geographic user interests.

To enrich the bag-of-words representation of a topic, some models were proposed to consider additional semantics. The topic-aspect model by Paul and Girju [12] is proposed to model  X  X ulti-faceted X  topics. In their definition, a  X  X ulti-faceted X  topic is a topic that is expressed differently across different aspects, such as scientific disciplines. Our focus and definition of multi-faceted topics is therefore fundamen-tally different. The entity-topic model by Newman et al. [11] considers two facets of a topic: general terms and en-tities. In contrast, our model considers general terms and each entity type in a separate facet, as well as a temporal facet. In [17], the timestamps of a topic are assumed to fol-low a beta distribution. In contrast, we model timestamps as a multinomial distribution, thus enabling our model to capture arbitrary temporal patterns.

Our work also builds upon recent advances in topic model inference, in particular stochastic variational inference (SVI) [4]. SVI enables topic models to be trained on massive and streaming data, since it operates in a sequential rather than batch fashion (such as Gibbs sampling). We adopt this tech-nique to develop an online learning method for MfTM.
Our approach shows a new direction in the use of topic models in social media. This is to the best of our knowledge the first work that proposes to organize the interplay be-tween general terms, entities and time in a principled man-ner. As shown in our experiments, our method can consis-tently outperform standard LDA.
In this section, we present our method for topic discovery from Twitter streams. We first discuss pre-processing steps. Then we present the novel Multi-Faceted Topic Model and its online inference algorithm.
Due to the informal nature of microblog posts, a num-ber of cleansing steps are performed. First, posts are con-verted to lower-case, punctuation and numbers are removed and characters repeated consecutively more than twice are stripped, in order to correct basic misspellings (e.g. the string  X  X oooood X  will be converted to  X  X ood X ). Second, URL links are stored separately for further use and removed from the post. Third, stopwords are removed and all terms are stemmed using a standard Porter stemmer.
URL links contained in posts provide an opportunity to obtain additional semantics from the referred web docu-ments. Specifically, we utilize the referred web documents to extract named entities. We choose this approach over other methods, such as matching Wikipedia entries [10], since our approach does not require a matching algorithm, thus reduc-ing computational cost. We first follow the URLs mentioned in tweets and crawl the web documents. Second, we perform named entity recognition (NER) using the Stanford NER li-brary 1 . In general, our framework is able to accommodate an arbitrary number of named entity types. In this paper, we focus our attention on  X  X erson X ,  X  X rganization X  and  X  X oca-tion X  named entities. Apart from web documents, we note that named entities can also be extracted directly from mi-croblog posts. However, the short and informal nature of microblog content results in a poor accuracy of conventional NER tools [14]. In principle, tweet-based named entity ex-traction can be seamlessly integrated into our topic discovery method with the availability of appropriate NER tools.
Traditional topic models, such as Latent Dirichlet Alloca-tion (LDA) [1], can be used to learn a set of latent topics. Each topic in LDA is a multinomial distribution over words. In contrast, we aim to model latent topics with finer granu-larity, such as preference towards specific entities (e.g., spe-cific locations) and the topic X  X  temporal characteristics. We therefore propose the Multi-Faceted Topic Model (MfTM) to discover rich latent topics from Twitter data.
In MfTM, we assume the existence of X types of elements in the microblog corpus. In this paper, we focus on five particular element types. First, we distinguish three named entity types, comprising person ( e p ), organization ( e location ( e l ) entities. Similarly to LDA, MfTM also models general terms, which are treated as term elements ( e t ). Ad-ditionally, we capture the trending behavior of topics over time. Tweet timestamps are discretized into fixed-length in-tervals and treated as time elements ( e  X  ). In general, the length of the time interval depends on the desired tempo-ral granularity. In our work, timestamps are discretized into day-intervals, since a day is a commonly used unit for group-ing news-related content.

In MfTM, elements of each type follow a multinomial dis-tribution given a latent topic. In other words, each element type forms an orthogonal facet of a latent topic. Figure 2 illustrates the structure of the model.

The generative process of MfTM proceeds as follows: http://nlp.stanford.edu/ner/ 1. For each topic k  X  X  1 ,...,K } : 2. For each document d  X  X  1 ,...,D } :
Given the hyperparameters  X  and  X  , the joint distribution of topics  X  , document-topic mixture  X  , topic assignments z and elements e is given by: p (  X , X , z , e |  X ,  X  )= p (  X  |  X  ) p (  X  |  X  ) where e x are all elements of type x in the corpus and z x the topic assignments of all elements of type x .
Since exact inference for this model is intractable, an ap-proximate posterior inference method is needed to estimate the latent parameters. Although Gibbs sampling is a widely adopted inference method for topic models, an online learn-ing method for LDA, namely stochastic variational inference (SVI), has been developed recently [4]. In stochastic opti-mization, we find the maximum of the variational objective by following noisy estimates of its natural gradient. SVI en-ables parameter inference on massive and streaming data, since it operates in a sequential, rather than batch fashion. This inference method fits well in the scenario of analyz-ing microblog posts, which essentially arrive in a streaming fashion. We use SVI as a basis to develop an online learning method for MfTM.
We now proceed to present our online inference algorithm for MfTM. Due to space constraints, we only present the major components of the algorithm. Interested readers may refer to [4] for full details of stochastic variational inference. We begin by listing the complete conditionals of the model.
Local hidden variables. The complete conditional of the topic assignment z d,x,n of entity e d,x,n is a multinomial, The complete conditional of document d  X  X  topic distribution is a posterior Dirichlet, where z d are the topic assignments of all elements in d . Algorithm 1 Stochastic Variational Inference for MfTM 1: Initialize  X  (0) randomly. 2: Initialize  X  (0) =  X  . 3: repeat 4: Sample a document d from the data set. 5: Initialize intermediate local topic proportion  X   X  d 6: repeat 7: for x  X  X  1 ,...,X } ,n  X  X  1 ,...,N d,x } do 8: for k  X  X  1 ,...,K } do 10: end for 11: end for 13: until  X  d converges 14: for x  X  X  1 ,...,X } do 15: Set intermediate topics: 16: Set global topics  X  ( i +1) k,x =(1  X   X  ( i ) )  X  ( i 17: end for 18: until forever
Global hidden variables. The complete conditional for facet x of topic k is also a posterior Dirichlet,
The parameters of the variational distribution are chosen as follows:
Each update of the local variables  X  k d,x,n is defined as
After each update of  X  d ,  X  d is updated as
After fitting the local variables, we set the intermediate topics as
Finally, after processing the i th document, we set the global topics as where  X  ( i ) =( i +  X  )  X   X  . The parameter  X   X  (0 . 5 , 1] is the forgetting rate , which controls the weight of fresh content. The delay  X   X  0 is used to demote early iterations. The full inference algorithm is presented in Algorithm 1.

After applying MfTM to a training corpus, we may obtain the topic vector  X  d of a new document d as follows In this section, we first describe our evaluation dataset. Second, we evaluate the proposed topic model using internal metrics, such as perplexity and topic distinctiveness. We also evaluate scalability of our inference algorithm. Third, we study the effectiveness of our framework on the task of tweet clustering.
To construct our evaluation dataset, we crawled publicly accessible data from Twitter using Twitter X  X  REST API 2 . Our dataset consists of two parts: tweets by popular users and tweets by general users .

Popular users. We selected an initial set of 50 seed users from Listorius 3 , a web-based service that categorizes popu-lar Twitter users into various topical categories. The users are randomly selected from 5 different categories (technol-ogy, business, politics, celebrities and activism). Starting with these seed users, we crawled Twitter users X  posts in a breadth-first search manner by traversing the followee graph. For each user, we stored up to 1,000 recent posts and selected top 20 followees of the user to add to the crawl queue. The followee selection criteria is based on the number of times the user has re-tweeted or mentioned the followee. This dataset part contains 328,428 tweets by 1,874 users in total.
General users. Twitter X  X  Streaming API 4 provides a sam-ple of the full public Twitter stream. We monitored the stream for one day in April 2013 and selected 700 users who posted English-language tweets and had at least 3,000 posts in total. For each of these users, we crawled up to 3,000 tweets. This dataset part contains 1,798,471 tweets in total and spans a time period from January 2009 to April 2013.
Table 1 shows the statistics of our dataset. A high-level analysis has shown that nearly 40% of tweets in our dataset mention an entity, showing that our multi-faceted model is applicable to a large proportion of tweets.
After collecting Twitter posts from each user, we pre-process the data as described in Section 3.1. It has been shown in [5] that grouping all posts of a user as a single doc-ument produces more accurate topic models compared with treating each post as a separate document. In our work, all user X  X  posts published during the same day are grouped as a document. The resulting user-day documents thus have timestamps discretized into day-intervals.

We set the hyperparameters for MfTM in accordance with common practice in topic modeling,  X  =  X  =1 /K . To select https://dev.twitter.com/ http://www.listorious.com https://dev.twitter.com/docs/streaming-apis Figure 3: Example latent topics produced by MfTM. The topics titles are the authors X  interpretation. suitable values for the parameters  X  and  X  in stochastic vari-ational inference, we performed a series of experiments with K = 50. We vary each parameter while keeping the others fixed and observe the per-word perplexity of the model (cf. Equation 10). Finally, we set  X  =0 . 7andand  X  =4.
In addition to training MfTM by means of stochastic vari-ational inference, we also implement a Gibbs sampler for MfTM for comparison. Due to space constraints, we omit the details of the Gibbs sampling procedure. We apply the Gibbs sampler on a reduced dataset of 320,000 posts due to a longer training time required by the sampling procedure.
Figure 3 shows an example of the latent topics produced by MfTM from our dataset. To draw each topic X  X  time dis-tribution, we plot the multinomial values of the temporal facet in chronological order.
Perplexity is a standard metric to evaluate a topic model X  X  capability of predicting unseen data. After training the model on the training dataset, we compute the perplexity of heldout data to evaluate the models. Formally, where M is the model learned from the training dataset,  X  X  X  w d is the word vector for document d and N d is the number of words in d . A lower perplexity score indicates better generalization performance of the model. As baselines for comparison, we choose LDA [1] and Twitter-LDA [18]. (c) Perplexity compari-son of SVI and GS Figure 5: Scalability evaluation of online inference
Figure 4(a) presents the perplexity comparison of MfTM and LDA built using online inference, across different values of K . In Figure 4(b), we show the perplexity of MfTM, LDA and Twitter-LDA learned using Gibbs sampling (GS). From both figures, we can see that MfTM outperforms the baseline models. When GS is used to build the models (cf. Figure 4(b)), we can observe that the perplexity of LDA and Twitter-LDA increases with the number of topics, while that of MfTM decreases. These results indicate that MfTM potentially supports finer topics than the baseline models.
To illustrate the differences when using GS and our infer-ence algorithm to train MfTM, we show the change in per-plexity during the online learning of MfTM in Figure 4(c). The dotted line indicates the final perplexity after 1,000 it-erations of GS on the dataset. We observe that online infer-ence is able to reach the perplexity of the GS-learned model already after processing 200,000 posts.
To evaluate the distinctiveness of the discovered topics, we calculate the average Kullback-Leibler (KL) divergence between each pair of topics. KL-divergence is a standard metric to evaluate the distance between two distributions. The higher the average KL-divergence, the more distinct the discovered topics are.

From the results presented in Figure 4(d), we see that the topics discovered by MfTM enjoy a much higher KL-divergence, indicating that the topics are more distinct than those discovered by LDA and Twitter-LDA. Furthermore, as the number of topics increases from 50 to 300, the average KL-divergence of topics discovered by LDA is decreasing while that of MfTM is increasing. This result again verifies our assumption that MfTM potentially supports more and finer topics than LDA.
To illustrate the runtime requirements of the online infer-ence algorithm for MfTM, we conduct a scalab ility evalua-tion. We run the experiments using a standard PC with a dual-core CPU, 4GB RAM and a 600GB hard-drive. First, we measure the time to train MfTM using different values of K and a fixed dataset size of 2 million tweets. The re-sults in Figure 5(a) indicate a near-linear increase of training time as K increases. Second, we measure time to process a specified number of documents. Figure 5(b) illustrates that the inference algorithm is suitable for processing streaming data, since it essentially requires constant time to process each document. The timing results clearly show that SVI inference enjoys good scalability in face of voluminous data.
In this section, we evaluate the effectiveness of our model in the context of tweet clustering. Clustering tweets is a challenging task due to their short length [9, 15]. The per-formance of traditional text mining techniques is negatively affected in this situation, since the bag-of-words represen-tation results in sparse instances. In contrast, our frame-work utilizes named entities and timestamps as additional semantic dimensions. We first describe two datasets used to conduct our clustering experiments.

Manually Labeled Dataset (ML). We invite three human reviewers and ask them to select 10 queries of their choice. For each query, we crawl the top 50 tweets returned by Twit-ter Search. Each reviewer is then asked to read the returned tweets and assign topic labels. Each topic label is a short free-form phrase that describes the main story of the tweet. We note that we choose to use free-form labels over a pre-defined taxonomy, mainly because of the diversity and evolv-ing nature of topics in Twitter. The reviewers are asked to use a consistent set of topic labels when reviewing the list of tweets for a query. In total, we obtained 1,524 labeled tweets for 32 queries, with an average of 47 . 6 tweets per query. The tweets X  topic labels serve as the ground truth when evaluat-ing clustering quality. Based on the topic labels, there are 9 . 4  X  X deal X  clusters for each query on average.
Hashtag Labeled Dataset (HL). To obtain a larger dataset for comparison of clustering performance, we utilize hash-tags in tweets as topic labels. We make use of the fact that Twitter users include hashtags in their tweets to indicate the tweet X  X  topic. We first extract 100 most popular hashtags from our dataset. We then divide them into 10 batches, each batch containing 10 hashtags. For each hashtag, we select tweets containing the respective hashtag from our Twitter dataset. Before performing clustering, all hashtags are re-moved from the tweets. Our clustering goal in then to place tweets containing the same hashtag into the same cluster. In total, the hashtag-labeled dataset contains 7,901 tweets, each batch containing 790 tweets on average.

We use Normalized Mutual Information (NMI) as the met-ric for evaluating clustering quality of our labeled datasets. Figure 6: Tweet clustering evaluation on the manually-labeled (ML) and hashtag-labeled (HL) datasets We perform clustering for each query in the ML dataset and each batch in the HL dataset and report the average NMI.
As baseline representations, we choose LDA, Twitter-LDA [18] and the vector-space model (VSM) with TF-IDF term weighting. LDA, Twitter-LDA and MfTM are built in sev-eral versions with a different number of topics (50, 100, 200). To perform tweet clustering, we use the following three al-gorithms:
Results. Figures 6(a) and 6(b) present the overall cluster-ing results. In the figures,  X  X M X  and X  X S X  X efers to K-means and DBSCAN, respectively, and  X  X -LDA X  denotes Twitter-LDA. Due to the large number of obtained results for each topic model, we only present the best result for each model.
Starting with the baseline VSM representation, we observe a relatively high clustering quality when using both K-means and DBSCAN. Importantly, VSM outperforms Twitter-LDA using K-means. Using DBSCAN, VSM outperforms LDA. In fact, this behavior is in agreement with the findings in [15]. Since LDA is based on (potentially sparse) bag-of-words representation of tweets, it fails to produce a signifi-cant improvement over VSM.

The tweet representation obtained using MfTM achieves the best overall results using all three clustering algorithms. This shows that the multi-faceted topics from MfTM have better potential to place semantically related tweets into the same clusters. We also note that the performance of the Direct clustering method is better than using the K-means algorithm, while requiring significantly shorter running time. In fact, after training our topic model, Direct only requires constant time to assign a tweet to a cluster.

These experiments demonstrate that the proposed multi-faceted topic model can be effectively applied for clustering short documents, such as tweets. In this paper, we study the problem of topic discovery in Twitter. To capture the dynamic and entity-oriented top-ics in microblogs, we propose a novel Multi-Faceted Topic Model. The model extracts semantically-rich latent topics, including general terms mentioned in the topic, named en-tities and a temporal distribution. As evidenced by our experimental evaluation, our method demonstrates a high potential to discover more accurate topics for applications such as clustering. Relevant issues for future work include considering the social interactions between users for topic discovery and refining the representation of temporal fea-tures of topics.
This work is partially supported by RGC GRF under grant number HKUST 617610.
