 Given the many difficulties related to the encoding of  X  X emantic X  ontologies today, an appealing and challenging approach is to build such ontologies au-tomatically from wealthy r esources like texts. This led to the emergence of the field of ontology learning from text [6]. In this paper, we present OLEA (Ontology LEArning), a new framework for ontology learning from text 1 . The general ar-chitecture of OLEA is illustrated in Figure 1. The proposal is a hybrid approach that aims to deal with key issues in the area: On Low Recall of the Pattern-Based Approach. The pattern-based ap-proach [5], though yealdin g  X  X  X cceptable X  precision, s uffers from very low recall since detecting relations depends on the appearance of a set of rigid lexico-syntactic patterns (e.g., NP such as { NP,NP.. } ). Our framework deals with this drawback, and proposes a technique able to capture and match more  X  X lexible X  patterns in text.
 On Low Precision of the Distributionnal Approach. This approach con-sisting mainly of clustering terms basing on their similarities, lacks generally from low precision. This is due to two main reasons: (1) The commonly used hi-erarchical methods are not quiet adaptive [2,4,1] since they provide binary trees of crisp clusters. (2) Methods lack of reliability since they rely, in most cases, on a single semantic relation (e.g., synonymy). That is, we present a learning procedure involving more semantic relations, and thus supplying us with more reliable decisions while building the concepts hierarchy.
 On Ontology Evolution. It is known that an ontology should be subject of continuous refinements in order to adapt i t to new users X  requirements. However, existing approaches either ignore this issue, or require regular human interven-tions, which is a tedious task [3,7]. That is, we propose a preliminary approach that places the learned taxonomy at the core of a search engine, in order to adapt the taxonomy to users X  vision over text, without any manual effort. The overall technique for estimating relations more  X  X lexibly X  is described as follows. Each pair of terms occurring in a corpus is represented by a set of lexico-syntactic features. Pairs that could be matched in WordNet will be augmented by confidence rates for each of their semantic relation. This will construct the learning base that will serve to predict th e semantic relation rates between pairs uncovered by WordNet.
 Calculating Relations between Concepts. For pairs of terms that could be matched in WordNet (concepts), we calculate a confidence rate for each of their semantic relations basing on the semantic structure of the taxonomy. What we are seeking at the end, is statem ents assessing, for instance, that  X  X bject X  and  X  X ar X  are 0.1-synonyms, 0.8-hypernyms, and 0-meronyms . The calculation of such rates depends on the target relation. While hypernymy confidence re-lies on the edges count along the shortest path separating two concepts, con-fidences for antonymy and meronymy are boolean, depending simply on the presence/absence of such relations. Syn onymy relations are calculated by means of our semantic distance measure proposed in [10].
 Mining Relations between Terms. The obtained rates from the previous step are used as a  X  X eference X  for predict ing semantic relations between the un-covered pairs in WordNet 2 . The assumption is that terms pairs appearing in similar contexts tend to have similar semantic relations. Relations X  confidence rates for an uncovered pair P are calculated by means of the confidence rates of its K Nearest Neighbors (KNN). Each context is characterized by a set of lexico-syntactic features (e.g., head word, partial path, path length). In order to compare two contexts, d istances between the different features can be ei-ther a simple integer/string comparison, or based on the Waterman alignment algorithm [11] (for path features).

Consider a relation r forapair P . Finding the best K confidence rates de-pends on how much we can  X  X ptimize X  the distance between a pair of contexts. These distances can be optimized when reaching a maximal correlation with distances between pairs of semantic relat ions (response variables). That is, we applied a multiple linear regression model to find the coefficients (weights) that optimize the correlation between them. Then, we apply the optimal coefficients on the previous equation in order to find more accurately the KNN. A relation X  X  confidence is finally calculated by means of the weighted average of the K-nearest relations confidences.
 Evaluation and Results. Our experiments was carried out on a benchmark composed of 1000 documents picked from the Reuters corpus 3 along with the WordNet taxonomy. The goal is to check how far can semantic relations between terms approach the  X  X old standard X  semantic relations between concepts. For this, we divided the set of concept pairs into 80% for the training set, and 20% for the test set. Obtained results illustrated in Figures 2,3 show that K has no significant effect on performance, depending more on the obtained R 2 . Without using the linear model we obtained a best correlation ratio of 0.32 for synonymy. However, when incorporating the regression model with KNN, we could dramatically in crease correlation, a ttaining an interesting rate of 0.82 for synonymy. In this section, we present a two-phases procedure that takes as an input the semantic relations rates, and provides as an output a hierarchy of concepts. It includes concepts learning, and concepts hiearchy learning.
 Concepts Learning. The goal here is to group terms into a set of sense-bearing units which will be regarded as concepts. Hence, we define a soft hierarchical-based clustering algorithm able to deal with polysemous words (see Algorithm 1) 4 . Rather than clustering terms by relying solely on semantic similarity which is error-prone, our algorithm offers more reliable decisions by taking into account a larger set of relations. The point is that two related clusters will be merged only if they are found  X  X urely X  synonyms, therefore do not have any other relation with a confidence rate greater than a specified threshold.
 Algorithm 1. Concept Learning Process Concepts Hierarchy Learning. Following concepts learning, we present Al-gorithm 2 which aims to learn taxonomic is-a relations. As hypernyms occur rarely between pairs of terms, lot of con cepts will remain unlinked. To overcome this shortcoming, we defined a measure that aims at finding the most appropriate place for an unlinked concept in a given hierarchy.

At the end of this phase, we obtain a fuzzy taxonomy in the sense that related terms within a concept are assigned a synonymy confidence between each others, and that concepts are related to each others by an  X  X s-a X  relation being assigned a hypernymy confidence as well.
 Algorithm 2. Taxonomic-Relation s Learning Process Evaluation and Results. Actually, ontology learning community lacks com-mon frameworks for evaluation and comparison. Concerning our work, we per-formed a preliminary evaluation against a  X  X eference X  taxonomy. Typically, after specifying the actual context of newspapers , we asked a human subject to group and organize in one or many trees a set of 50 terms. Finally, we compare the human-made tree with our lea rned tree in terms of precision and recall by consid-ering the number of correct vs incorrect learned relatio ns. Concerning concepts learning, since precision and recall depends on  X  1 and  X  2 , we altered  X  1 in the range of [0.88, 0.97], while fixing  X  2 to 0.05. As we can see in Figure 4, while precision tends to drop dramatically when reducing  X  1 , recall tends to be some-how stable. Concerning taxonomic-relations learning, we consider the number of correct vs incorrect links between validated co ncepts by the user. We fixed the parameter  X  1 at 0,95, since it gave the optimal trade-off between precision and recall. Then, we applied Algorithm 2 by altering  X  1 in the interval [0.1, 0.2] and fixing  X  2 at 0.05. Results illustrated in Figure 5 show interesting performance, especially from a recall point of view. Involving human subjects in the learning process, although extremely benefic, can be a very tedious and time-consuming task [3,7]. What we propose here is to add supervision to the learning process without any manual effort: Since our taxonomy seeks essentially to integrate a IR environment, we placed our learned taxonomy at the core of our IR system [9]. Keywords queries will be expanded to other related terms by means of the synonymy and hypernymy relations. Then, users interactions with the system are taken into account to update the taxonomy by means of a relevance feedback mechanism [8]. For instance, given a query term q expanded with another term t . As a respond, a document d was presented to the user by its outline o .if o contains both q and t ,and d was clicked by the user, the relation between q and t will be strengthen by a parameter  X  that we define. Such feedbacks will enable the system to take more subjective decisions about accepting or rejecting a sp ecific expansion term i n future queries. Evaluation and Results. To evaluate the effect of relevance feedback on tax-onomy learning, we took as a starting point the results given by the learned taxonomy obtained using the optimal parameters. Next, 100 keywords queries (related to the selected hierarchy for ev aluation) are sent consecutively to the system. At the end of session of each query, clicked and unclicked documents are considered for the feedback. Taxonomy is updated at the end of each set of 20 queries in order to be reevaluated against the hand-built taxonomy. Figure 6 shows the precision and recall values for both concepts and relations learning along the 100 queries. We can notice the slight but sure improvement in the final results (especially in precision). Yet, we argue that the improvement can be seen more clearly with larger set of queries.
 To wrap up, we presented in this paper OLea, a framework for learning ontology from a text corpus. It has the advantage of addressing the main drawbacks of the pattern-based and distributional approaches. However, a comparison with other methods is still needed to assess the added-value of our proposal. This is not an easy task though. We argue that a better evaluation is task-oriented. That is, we are intending to perform other evaluations in environments like Information Retrieval and Document Clustering.

