 Weight optimization is an important step in build-ing machine translation (MT) systems. Discrimi-native optimization methods such as MERT (Och, 2003), MIRA (Crammer et al., 2006), PRO (Hop-kins and May, 2011), and Downhill-Simplex (Nelder and Mead, 1965) have been influential in improving MT systems in recent years. These methods are ef-fective because they tune the system to maximize an automatic evaluation metric such as BLEU, which serve as surrogate objective for translation quality. However, we know that a single metric such as BLEU is not enough. Ideally , we want to tune to-wards an automatic metric that has perfect corre-lation with human judgments of translation quality. While many alternatives have been proposed, such a perfect evaluation metric remains elusive.

As a result, many MT evaluation campaigns now report multiple evaluation metrics (Callison-Burch et al., 2011; Paul, 2010). Different evaluation met-rics focus on different aspects of translation quality. For example, while BLEU (Papineni et al., 2002) focuses on word-based n-gram precision, METEOR (Lavie and Agarwal, 2007) allows for stem/synonym matching and incorporates recall. TER (Snover et al., 2006) allows arbitrary chunk movements, while permutation metrics like RIBES (Isozaki et al., 2010; Birch et al., 2010) measure deviation in word order. Syntax (Owczarzak et al., 2007) and se-mantics (Pado et al., 2009) also help. Arguably, all these metrics correspond to our intuitions on what is a good translation.

The current approach of optimizing MT towards a single metric runs the risk of sacrificing other met-rics. Can we really claim that a system is good if it has high BLEU, but very low METEOR? Simi-larly, is a high-METEOR low-BLEU system desir-able? Our goal is to propose a multi-objective op-timization method that avoids  X  X verfitting to a sin-gle metric X . We want to build a MT system that does well with respect to many aspects of transla-tion quality.

In general, we cannot expect to improve multi-ple metrics jointly if there are some inherent trade-offs. We therefore need to define the notion of Pareto Optimality (Pareto, 1906), which characterizes this tradeoff in a rigorous way and distinguishes the set of equally good solutions. We will describe Pareto Optimality in detail later, but roughly speaking, a hypothesis is pareto-optimal if there exist no other hypothesis better in all metrics. The contribution of this paper is two-fold:  X  We introduce PMO ( P areto-based M ulti- X  We show that PMO outperforms the alterna-In the following, we first explain the theory of Pareto Optimality (Section 2), and then use it to build up our proposed PMO approach (Section 3). Experiments on NIST Chinese-English and PubMed English-Japanese translation using BLEU, TER, and RIBES are presented in Section 4. We conclude by discussing related work (Section 5) and opportuni-ties/limitations (Section 6). 2.1 Definitions and Concepts The idea of Pareto optimality comes originally from economics (Pareto, 1906), where the goal is to char-acterize situations when a change in allocation of goods does not make anybody worse off. Here, we will explain it in terms of MT: Let h  X  L be a hypothesis from an N-best list L . We have a total of K different metrics M k ( h ) for evaluating the quality of h . Without loss of gen-erality, we assume metric scores are bounded be-tween 0 and 1, with 1 being perfect. Each hypoth-esis h can be mapped to a K -dimensional vector ple, suppose K = 2 , M 1 ( h ) computes the BLEU score, and M 2 ( h ) gives the METEOR score of h . Figure 1 illustrates the set of vectors { M ( h ) } in a 10-best list.
 For two hypotheses h 1 ,h 2 , we write M ( h 1 ) &gt; M ( h 2 ) if h 1 is better than h 2 in all metrics, and M ( h 1 )  X  M ( h 2 ) if h 1 is better than or equal to h 2 in all metrics. When M ( h 1 )  X  M ( h 2 ) and M k ( h 1 ) &gt; M k ( h 2 ) for at least one metric k , we say that h 1 dominates h 2 and write M ( h 1 ) . M ( h 2 ) . Definition 1. Pareto Optimal: A hypothesis h  X   X  L is pareto-optimal iff there does not exist another hypothesis h  X  L such that M ( h ) . M ( h  X  ) .
In Figure 1, the hypotheses indicated by circle (o) are pareto-optimal, while those with plus (+) are not. To visualize this, take for instance the pareto-optimal point (0.4,0.7). There is no other point with either (metric1 &gt; 0 . 4 and metric2  X  0 . 7 ), or (met-ric1  X  0 . 4 and metric2 &gt; 0 . 7 ). On the other hand, the non-pareto point (0.6,0.4) is  X  X ominated X  by an-other point (0.7,0.6), because for metric1: 0 . 7 &gt; 0 . 6 and for metric2: 0 . 6 &gt; 0 . 4 .

There is another definition of optimality, which disregards ties and may be easier to visualize: Definition 2. Weakly Pareto Optimal: A hypothesis h  X   X  L is weakly pareto-optimal iff there is no other hypothesis h  X  L such that M ( h ) &gt; M ( h  X  ) .
Weakly pareto-optimal points are a superset of pareto-optimal points. A hypothesis is weakly pareto-optimal if there is no other hypothesis that improves all the metrics; a hypothesis is pareto-optimal if there is no other hypothesis that improves at least one metric without detriment to other met-rics. In Figure 1, point (0.1,0.8) is weakly pareto-optimal but not pareto-optimal, because of the com-peting point (0.3,0.8). Here we focus on pareto-optimality, but note our algorithms can be easily modified for weakly pareto-optimality. Finally, we can introduce the key concept used in our proposed PMO approach: Definition 3. Pareto Frontier: Given an N-best list L , the set of all pareto-optimal hypotheses h  X  L is called the Pareto Frontier.

The Pareto Frontier has two desirable properties from the multi-objective optimization perspective: 1. Hypotheses on the Frontier are equivalently 2. For each hypothesis not on the Frontier, there
This provides a principled approach to optimiza-tion: i.e. optimizing towards points on the Frontier and away from those that are not, and giving no pref-erence to different pareto-optimal hypotheses. 2.2 Reduction to Linear Combination Multi-objective problems can be formulated as: Here, the MT system X  X  Decode function, parame-terized by weight vector w , takes in a foreign sen-tence f and returns a translated hypothesis h . The argmax operates in vector space and our goal is to find w leading to hypotheses on the Pareto Frontier.
In the study of Pareto Optimality, one central question is: To what extent can multi-objective prob-lems be solved by single-objective methods? Equa-tion 1 can be reduced to a single-objective problem by scalarizing the vector [ M 1 ( h ); ... ; M k ( h )] with a linear combination: Here, p k are positive real numbers indicating the rel-ative importance of each metric (without loss of gen-erality, assume P k p k = 1 ). Are the solutions to Eq. 2 also solutions to Eq. 1 (i.e. pareto-optimal) and vice-versa? The theory says: Theorem 1. Sufficient Condition: If w  X  is solution to Eq. 2, then it is weakly pareto-optimal. Further, if w  X  is unique, then it is pareto-optimal. Theorem 2. No Necessary Condition: There may exist solutions to Eq. 1 that cannot be achieved by Eq. 2, irregardless of any setting of { p k } .
Theorem 1 is a positive result asserting that lin-ear combination can give pareto-optimal solutions. However, Theorem 2 states the limits: in partic-ular, Eq. 2 attains only pareto-optimal points that are on the convex hull. This is illustrated in Fig-ure 1: imagine sweeping all values of p 1 = [0 , 1] and p 2 = 1  X  p 1 and recording the set of hypotheses that maximizes P k p k M k ( h ) . For 0 . 6 &lt; p 1  X  1 we and for 0 &lt; p 1 &lt; 0 . 6 we get (0 . 4 , 0 . 8) . At no setting of p 1 do we attain h = (0 . 4 , 0 . 7) which is also pareto-optimal but not on the convex hull. 1 This may have ramifications for issues like metric tunability and local optima. To summarize, linear-combination is reasonable but has limitations. Our proposed approach will instead directly solve Eq. 1.
Pareto Optimality and multi-objective optimiza-tion is a deep field with active inquiry in engineer-ing, operations research, economics, etc. For the in-terested reader, we recommend the survey by Mar-ler and Arora (2004) and books by (Sawaragi et al., 1985; Miettinen, 1998). 3.1 Computing the Pareto Frontier Our PMO approach will need to compute the Pareto Frontier for potentially large sets of points, so we first describe how this can be done efficiently. Given a set of N vectors { M ( h ) } from an N-best list L , our goal is extract the subset that are pareto-optimal.
Here we present an algorithm based on iterative filtering , in our opinion the simplest algorithm to understand and implement. The strategy is to loop through the list L , keeping track of any dominant points. Given a dominant point, it is easy to filter out many points that are dominated by it. After suc-cessive rounds, any remaining points that are not fil-Algorithm 1 FindParetoFrontier tered are necessarily pareto-optimal. Algorithm 1 shows the pseudocode. In line 3, we take a point h  X  and check if it is dominating or dominated in the for-loop (lines 4-8). At least one pareto-optimal point will be found by line 8. The second loop (lines 9-11) further filters the list for points that are dominated by h  X  but iterated before h  X  in the first for-loop.
The outer while-loop stops exactly after P iter-ations, where P is the actual number of pareto-optimal points in L . Each inner loop costs O ( KN ) so the total complexity is O ( PKN ) . Since P  X  N with the actual value depending on the probability distribution of { M ( h ) } , the worst-case run-time is O ( KN 2 ) . For a survey of various Pareto algorithms, refer to (Godfrey et al., 2007). The algorithm we de-scribed here is borrowed from the database literature in what is known as skyline operators. 2 3.2 PMO-PRO Algorithm We are now ready to present an algorithm for multi-objective optimization. As we will see, it can be seen as a generalization of the pairwise ranking optimiza-tion (PRO) of (Hopkins and May, 2011), so we call it PMO-PRO. PMO-PRO approach works by itera-tively decoding-and-optimizing on the devset, sim-ilar to many MT optimization methods. The main difference is that rather than trying to maximize a single metric, we maximize the number of pareto points, in order to expand the Pareto Frontier
We will explain PMO-PRO in terms of the pseudo-code shown in Algorithm 2. For each sen-tence pair ( f,e ) in the devset, we first generate an N-best list L  X  { h } using the current weight vector w (line 5). In line 6, we evaluate each hypothesis h with respect to the K metrics, giving a set of K -dimensional vectors { M ( h ) } .

Lines 7-8 is the critical part: it gives a  X  X a-bel X  to each hypothesis, based on whether it is in the Pareto Frontier. In particular, first we call FindParetoFrontier (Algorithm 1), which re-turns a set of pareto hypotheses; pareto-optimal hy-potheses will get label 1 while non-optimal hypothe-ses will get label 0. This information is added to the training set T (line 8), which is then optimized by any conventional subroutine in line 10. We will follow PRO in using a pairwise classifier in line 10, which finds w  X  that separates hypotheses with labels 1 vs. 0. In essence, this is the trick we employ to directly optimize on the Pareto Frontier. If we had used BLEU scores rather than the { 0 , 1 } labels in line 8, the entire PMO-PRO algorithm would revert to single-objective PRO.

By definition, there is no single  X  X est X  result for multi-objective optimization, so we collect all weights and return the Pareto-optimal set. In line 13 we evaluate each weight w on K metrics across the entire corpus and call FindParetoFrontier in line 14. 3 This choice highlights an interesting change of philosophy: While setting { p k } in linear-combination forces the designer to make an a priori preference among metrics prior to optimization, the PMO strategy is to optimize first agnostically and a posteriori let the designer choose among a set of weights. Arguably it is easier to choose among so-lutions based on their evaluation scores rather than devising exact values for { p k } . 3.3 Discussion Variants: In practice we find that a slight modifi-cation of line 8 in Algorithm 2 leads to more sta-Algorithm 2 Proposed PMO-PRO algorithm ble results for PMO-PRO: for non-pareto hypothe-ses h /  X  { f } , we set label l = P k M k ( h ) /K in-stead of l = 0 , so the method not only learns to dis-criminate pareto vs. non-pareto but also also learns to discriminate among competing non-pareto points. Also, like other MT works, in line 5 the N-best list is concatenated to N-best lists from previous iterations, so { h } is a set with i  X  N elements.

General PMO Approach: The strategy we out-lined in Section 3.2 can be easily applied to other MT optimization techniques. For example, by re-placing the optimization subroutine (line 10, Algo-rithm 2) with a Powell search (Och, 2003), one can get PMO-MERT 4 . Alternatively, by using the large-margin optimizer in (Chiang et al., 2009) and mov-ing it into the for-each loop (lines 4-9), one can get an online algorithm such PMO-MIRA. Virtually all MT optimization algorithms have a place where metric scores feedback into the optimization proce-dure; the idea of PMO is to replace these raw scores with labels derived from Pareto optimality. 4.1 Evaluation Methodology We experiment with two datasets: (1) The PubMed task is English-to-Japanese translation of scientific abstracts. As metrics we use BLEU and RIBES (which demonstrated good human correlation in this language pair (Goto et al., 2011)). (2) The NIST task is Chinese-to-English translation with OpenMT08 training data and MT06 as devset. As metrics we use BLEU and NTER.  X  BLEU = BP  X  ( X  prec n ) 1 / 4 . BP is brevity  X  RIBES = (  X  + 1) / 2  X  prec 1 / 4 1 , with Kendall X  X   X  NTER= max(1  X  TER , 0) , which normalizes
We compare two multi-objective approaches: 1. Linear-Combination of metrics (Eq. 2), 2. Proposed Pareto approach (PMO-PRO).

Evaluation of multi-objective problems can be tricky because there is no single figure-of-merit. We thus adopted the following methodology: We run both methods 5 times (i.e. using the 5 differ-ent ( p 1 ,p 2 ) setting each time) and I = 20 iterations each. For each method, this generates 5x20=100 re-sults, and we plot the Pareto Frontier of these points in a 2-dimensional metric space (e.g. see Figure 2). A method is deemed better if its final Pareto Fron-tier curve is strictly dominating the other. We report devset results here; testset trends are similar but not included due to space constraints. 7 4.2 Results Figures 2 and 3 show the results for PubMed and NIST, respectively. A method is better if its Pareto Frontier lies more towards the upper-right hand cor-ner of the graph. Our observations are: 1. PMO-PRO generally outperforms Linear-2. For both methods, trading-off between met-3. Interestingly, a multi-objective approach can
The third observation relates to the issue of metric tunability (Liu et al., 2011). We found that RIBES can be difficult to tune directly. It is an extremely non-smooth objective with many local optima X  X light changes in word ordering causes large changes in RIBES. So the best way to improve RIBES is to not to optimize it directly, but jointly with a more tunable metric BLEU. The learning curve in Fig-ure 4 show that single-objective optimization of RIBES quickly falls into local optimum (at iteration 3) whereas PMO can zigzag and sacrifice RIBES in intermediate iterations (e.g. iteration 2, 15) leading to a stronger result ultimately. The reason is the diversity of solutions provided by the Pareto Fron-tier. This finding suggests that multi-objective ap-proaches may be preferred, especially when dealing with new metrics that may be difficult to tune. 4.3 Additional Analysis and Discussions What is the training time? The Pareto approach does not add much overhead to PMO-PRO. While FindParetoFrontier scales quadratically by size of N-best list, Figure 5 shows that the runtime is triv-ial (0.3 seconds for 1000-best). Table 2 shows the time usage breakdown in different iterations for PubMed. We see it is mostly dominated by decod-ing time (constant per iteration at 40 minutes on single 3.33GHz processor). At later iterations, Opt takes more time due to larger file I/O in SVMRank. Note Decode and Pareto can be  X  X mbarrasingly par-allelized. X  How many Pareto points? The number of pareto hypotheses gives a rough indication of the diversity of hypotheses that can be exploited by PMO. Fig-ure 6 shows that this number increases gradually per iteration. This perhaps gives PMO-PRO more direc-tions for optimizing around potential local optimal. Nevertheless, we note that tens of Pareto points is far few compared to the large size of N-best lists used at later iterations of PMO-PRO. This may explain why the differences between methods in Figure 3 are not more substantial. Theoretically, the num-ber will eventually level off as it gets increasingly harder to generate new Pareto points in a crowded space (Bentley et al., 1978).
 Practical recommendation: We present the Pareto approach as a way to agnostically optimize multiple metrics jointly. However, in practice, one may have intuitions about metric tradeoffs even if one cannot specify { p k } . For example, we might believe that approximately 1-point BLEU degra-dation is acceptable only if RIBES improves by at least 3-points. In this case, we recommend the following trick: Set up a multi-objective prob-lem where one metric is BLEU and the other is 3 / 4 BLEU+ 1 / 4 RIBES. This encourages PMO to ex-plore the joint metric space but avoid solutions that sacrifice too much BLEU, and should also outper-form Linear Combination that searches only on the ( 3 / 4 , 1 / 4 ) direction. Multi-objective optimization for MT is a relatively new area. Linear-combination of BLEU/TER is the most common technique (Zaidan, 2009), some-times achieving good results in evaluation cam-paigns (Dyer et al., 2009). As far as we known, the only work that directly proposes a multi-objective technique is (He and Way, 2009), which modifies MERT to optimize a single metric subject to the constraint that it does not degrade others. These approaches all require some setting of constraint strength or combination weights { p k } . Recent work in MT evaluation has examined combining metrics using machine learning for better correlation with human judgments (Liu and Gildea, 2007; Albrecht and Hwa, 2007; Gimnez and M ` arquez, 2008) and may give insights for setting { p k } . We view our Pareto-based approach as orthogonal to these efforts.
The tunability of metrics is a problem that is gain-ing recognition (Liu et al., 2011). If a good evalu-ation metric could not be used for tuning, it would be a pity. The Tunable Metrics task at WMT2011 concluded that BLEU is still the easiest to tune (Callison-Burch et al., 2011). (Mauser et al., 2008; Cer et al., 2010) report similar observations, in ad-dition citing WER being difficult and BLEU-TER being amenable. One unsolved question is whether metric tunability is a problem inherent to the metric only, or depends also on the underlying optimization algorithm. Our positive results with PMO suggest that the choice of optimization algorithm can help. Multi-objective ideas are being explored in other NLP areas. (Spitkovsky et al., 2011) describe a tech-nique that alternates between hard and soft EM ob-jectives in order to achieve better local optimum in grammar induction. (Hall et al., 2011) investigates joint optimization of a supervised parsing objective and some extrinsic objectives based on downstream applications. (Agarwal et al., 2011) considers us-ing multiple signals (of varying quality) from online users to train recommendation models. (Eisner and Daum  X  e III, 2011) trades off speed and accuracy of a parser with reinforcement learning. None of the techniques in NLP use Pareto concepts, however. We introduce a new approach (PMO) for training MT systems on multiple metrics. Leveraging the diverse perspectives of different evaluation metrics has the potential to improve overall quality. Based on Pareto Optimality, PMO is easy to implement and achieves better solutions compared to linear-combination baselines, for any setting of combi-nation weights. Further we observe that multi-objective approaches can be helpful for optimiz-ing difficult-to-tune metrics; this is beneficial for quickly introducing new metrics developed in MT evaluation into MT optimization, especially when good { p k } are not yet known. We conclude by draw-ing attention to some limitations and opportunities raised by this work:
Limitations: (1) The performance of PMO is limited by the size of the Pareto set. Small N-best lists lead to sparsely-sampled Pareto Frontiers, and a much better approach would be to enlarge the hy-pothesis space using lattices (Macherey et al., 2008). How to compute Pareto points directly from lattices is an interesting open research question. (2) The binary distinction between pareto vs. non-pareto points ignores the fact that 2nd-place non-pareto points may also lead to good practical solutions. A better approach may be to adopt a graded definition of Pareto optimality as done in some multi-objective works (Deb et al., 2002). (3) A robust evaluation methodology that enables significance testing for multi-objective problems is sorely needed. This will make it possible to compare multi-objective meth-ods on more than 2 metrics. We also need to follow up with human evaluation.

Opportunities: (1) There is still much we do not understand about metric tunability; we can learn much by looking at joint metric-spaces and exam-ining how new metrics correlate with established ones. (2) Pareto is just one approach among many in multi-objective optimization. A wealth of meth-ods are available (Marler and Arora, 2004) and more experimentation in this space will definitely lead to new insights. (3) Finally, it would be interesting to explore other creative uses of multiple-objectives in MT beyond multiple metrics. For example: Can we learn to translate faster while sacrificing little on ac-curacy? Can we learn to jointly optimize cascaded systems, such as as speech translation or pivot trans-lation? Life is full of multiple competing objectives. We thank the reviewers for insightful feedback.
