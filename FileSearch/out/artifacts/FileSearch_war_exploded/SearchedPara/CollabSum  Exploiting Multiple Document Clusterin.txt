 Almost all existing methods conduct the summarization tasks for single documents separately without interactions for each document under the assumption that the documents are considered independent of each other. This paper proposes a novel framework called CollabSum for collaborative single document summarizations by making use of mutual influences of multiple documents within a cluster context. In this study, CollabSum is implemented by first employing the clustering algorithm to obtain graph-ranking based algorithm for collaborative document summarizations within each cluster. Both the with-document and cross-document relationships between sentences are incorporated in the algorithm. Experiments on the DUC2001 and DUC2002 datasets demonstrate the encouraging performance of the proposed approach. Different clustering algorithms have been investigated and we find that the summarization performance relies positively on the quality of document cluster. H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing  X  abstracting methods ; I.2.7 [ Artificial Intelligence ]: Natural Language Processing  X  text analysis General Terms : Algorithms, Experimentation, Performance Keywords: CollabSum, Single document summarization, Collaborative summarization, Graph-ranking algorithm Document summarization is the process of automatically creating a compressed version of a given document that delivers the main topic of the document. Automated document summarization has drawn much attention for a long time because it becomes more and more important in many text applications. For example, current search engines usually provide a short summary for each resultant document so as to facilitate users to browse the results and improve users X  search experience. News portals usually provide concise headline news describing hot news topic each day and they also produce weekly news review to save users X  time and improve service quality. Document summary can be either query-relevant or generic. Query-relevant summary should be closely related to the given query. Generic summar y should reflect the main topic of the document without any additional clues and prior knowledge. In this paper, we focus on generic single document summarization. Very often, all single documents in a document set are required to be summarized. While almost all previous methods for single document summarization produce a summary for a specified document based only on the information contained in the document. One common assumption of existing methods is that the documents are independent of each other. Hence the summarization task is conducted separately without interactions for each document. However, some documents within an appropriate cluster context actually have mutual influence and contain useful clues which can help to extract summary from each other. For example, two documents about the same topic would provide additional knowledge for each other to better evaluate and extract salient information from each other. The idea is borrowed from human X  X  perception that a user would better understand a topic expressed in a document if the user reads another document about the same topic. This study proposes a novel framework called CollabSum for collaborative document summarizations by making use of additional information from multiple documents within appropriate cluster context. The cluster context can be obtained by applying the clustering algorithm on the document set and we have investigated how the cluster context influences the summarization performance by employing different clustering algorithms. The proposed CollabSum employs the graph-ranking based algorithm for collaborative document summarization of each document in a specified cluster and both the cross-document relationships and the within-document relationships between sentences are incorporated in the algorithm, where the within-document relationships reflect the local information existing in the specified document and the cross-document relationships reflect the global information existing in the cluster context. We perform experiments on the DUC2001 and DUC2002 datasets and the results demonstrate the good effectiveness of CollabSum. The use of the cross-document relationships between sentences can much improve the performance of single document summarization. We find that the summarization performance is positively correlated with the quality of cluster context and existing clustering algorithms can yield appropriate cluster context for collaborative document summarizations. The rest of this paper is organized as follows: Section 2 briefly introduces the related work. The proposed CollabSum is described in detail in Section 3. We set up the experiments in Section 4 and give the results in Section 5. Section 6 discusses the results and lastly we conclude this paper in Section 7. Single document summarization has been widely explored in the natural language processing and information retrieval communities. A series of workshops and conferences on automatic text summarization (e.g. DUC 1 and NTCIR 2 ), special topic sessions in ACL, COLING, and SIGIR have advanced the technology and produced a couple of experimental online systems. Generally speaking, single document summarization methods can be categorized into two categories: extraction-based methods and abstraction-based methods [11, 12, 14]. Extraction is just to select existing sentences while abstraction needs sentence compression and reformulation. In this paper, we focus on extraction-based methods. Extraction-based methods usually assign each sentence a saliency score and then rank the sentences in the document. The score is usually computed based on a combination of statistical and linguistic features, including term frequency [18], sentence position [9], cue words [6], stigma words [6], topic signature [17], lexical chains [25], etc. Machine learning methods are also employed to extract sentences, including classification-based methods [1, 15], clustering-based methods [22], HMM-based methods [5], CRF-based method [24], etc. Other methods include maximal marginal relevance (MMR) [4], latent semantic analysis (LSA) [8], and relevance measure [8]. In [27], the mutual reinforcement principle is employed to iteratively extract key phrases and sentences from a document. Moreover, a method based on text segmentation is proposed by McDonald and Chen [19] and the text segments instead of the sentences are ranked. Most recently, the graph-ranking based methods, including TextRank [20, 21] and LexPageRank [7], have been proposed for document summarization. Similar to PageRank [3] or HITS [13], these methods first build a graph based on the similarity relationships between the sentences in a document and then the importance of a sentence is determined by taking into account the global information on the graph recursively, rather than relying only on the local sentence-specific information. The basic idea underlying the graph-based ranking algorithm is that of  X  X oting X  or  X  X ecommendation X . When a sentence links to another one, it is basically casting a vote for that other sentence. The higher the number of votes that are cast for a sentence, the higher the importance of the sentence is. Moreover, the importance of the sentence casting the vote determines how important the vote itself is. The computation of sentence importance is usually based on a recursive form, which can be transformed into the problem of solving the principal eigenvector of the transition matrix. However, all the above methods summarize each single document independently. Particularly, only the sentences within the same document cast votes for each other in the graph-ranking based methods. We believe that the sentences in other topic-related documents can also cast votes for the sentences in the specified document, so both the cross-document relationships and the within-document relationships between sentences are incorporated in the proposed CollabSum in this study. Given a document set in which each document needs to be summarized respectively, CollabSum first employs the clustering algorithm (e.g. the agglomerative algorithm, the divisive algorithm, the k-means algorithm, etc.) [10, 26] to group the documents into a few clusters. The documents within each cluster are expected to be topic-related and each cluster can be considered as a context for any document in the cluster. Given a document cluster, CollabSum incorporates both the within-document relationships (local information) and the cross-document relationships (global information) between sentences into the graph-ranking based algorithm to summarize each single document within the cluster. Figure 1 gives the framework of the proposed approach. 1. Document Clustering : Group the documents in the 2. Document Summarization : For each cluster, perform For the first step of the above framework, different clustering algorithms will yield different clusters and the documents in a high-quality cluster are usually deemed to be highly topic-related (i.e. appropriate cluster context), while the documents in a low-quality cluster are usually not topic-related (i.e. inappropriate reliability of the contextual information for evaluating the importance of the sentences in the cluster. A number of clustering algorithms will be investigated in the experiments. For the second step of the above framework, step 1) aims to build a global affinity graph reflecting the relationships among all sentences in the document set of the given cluster. Step 2) aims to compute the informativeness score of each sentence based on the global affinity graph. The informativeness of a sentence indicates how much information about the main topic the sentence contains. Step 3) aims to remove redundant information in the summary and keep the sentences in the summary as novel as possible. Step 1) and 2) perform on all documents in the cluster in order to get highly informative sentences from a global perspective, while step 3) performs only on each single document in order to remove redundancy from a local perspective. A summary is expected to include the sentences which are both highly informative and highly novel. Note that the summarization tasks are conducted in a batch mode for each cluster. The steps of 1), 2) and 3) will be described in next sections respectively. the affinity weight sim ( s i , s j ) between a sentence pair of s calculated using the Cosine measure [2]. The weight associated with term t is calculated with the tf t .isf t formula, where tf frequency of term t in the sentence and isf t is the inverse sentence of sentences in a background corpus and n t is the number of sentences containing term t .
 If sentences are considered as nodes, the sentence collection can be modeled as an undirected graph by generating a link between two sentences if their affinity weight exceeds 0, i.e. an undirected link between s i and s j ( i R j ) with the affinity weight sim ( s constructed if sim ( s i ,s j )&gt;0; otherwise no link is constructed. Thus, we construct an undirected graph G reflecting the relationships between sentences by their content similarity. The links (edges) between sentences in the graph can be categorized into two classes: within-document link and cross-document link. Given a link between a sentence pair of s i and s j , if s i and s document, the link is a within-document link; and if s i from different documents, the link is a cross-document link. Actually, the within-document link reflects the local information in a document, while the cross-document link reflects the global information in a cluster context, which is exploited by CollabSum to make use of mutual influences between different documents in the cluster. The graph G contains both kinds of links between sentences and is called as Global Affinity Graph . We use an adjacency (affinity) matrix M to describe G with each entry corresponding to the weight of a link in the graph. M = ( M defined as follows: Then M is normalized to M row equal to 1: Similar to the above process, another two affinity graphs G G inter are also built: the within-document affinity graph G include only the within-document links between sentences (the cross-document affinity graph G inter is to include only the cross-document links between sentences (the entries of the within-document links are set to 0). The corresponding adjacency (affinity) matrices of G intra and G inter are denoted by M M inter respectively. M intra and M inter can be extracted from M and we have M=M intra + M inter . Similar to Equation (2), M are respectively normalized to intra sum of each row equal to 1. Based on the global affinity graph G , the informativeness score IFScore all ( s i ) for sentence s i can be deduced from those of all other sentences linked with it and it can be formulated in a recursive form as follows[7, 20, 21, 28]: And the matrix form is: scores. e damping factor usually set to 0.85. For implementation, the initial informativeness scores of all sentences are set to 1 and the iteration algorithm in Equation (3) is adopted to compute the new informativeness scores of the sentences. Usually the convergence of the iteration algorithm is achieved when the difference between the informativeness scores computed at two successive iterations for any sentences falls below a given threshold (0.0001 in this study). Similarly, the informativeness score of sentence s i can be deduced based on either the within-document affinity graph G cross-document affinity graph G inter as follows: The final informativeness score IFScore ( s i ) of sentence s either IFScore all ( s i ), IFScore intra ( s i ) or IFScore combination of IFScore intra ( s i ) and IFScore inter ( s where ] 1 , 0 [  X  l is a weighting parameter, specifying the relative contributions to the final informativeness scores from the cross-document relationships and the within-document relationships between sentences. If : =0, IFScore ( s IFScore inter ( s i ); if : =1, IFScore ( s i ) is equal to IFScore : =0.5, the cross-document relationships and the within-document relationships are assumed to be equally important. We will investigate all the above methods for informativeness score computation. Note that all previous graph-ranking based methods do not consider the cross-document links and have IFScore ( s i )= IFScore intra ( s i ). For each single document d k to be summarized we can extract a sub-graph corresponding edges between them from the global affinity graph G . We assume the document d k has m ( m &lt; n ) sentences and the sentences X  affinity matrix original matrix M by extracting the corresponding entries. Then M is normalized into each row equal to 1. Similar to [28], the greedy algorithm is used to penalize the sentences highly overlapping with other informative sentences based on score for each sentence within the document is obtained and the sentences with highest overall rank scores are both highly informative and highly novel, which are chosen into the summary for d k according to the summary length limit. The basic idea of the algorithm is to decrease the overall rank score of less informative sentences by the part conveyed from the most informative one. The overall rank score ORScore ( s sentence s i is initialized to its informativeness score. Once the highest ranked sentence s i is chosen into the summary, any remaining sentence s j linked with s i are penalized as follows: The details of the algorithm are omitted due to page limit. The algorithm is applied once for each single document to be summarized in the document cluster. We use the DUC2001 and DUC2002 datasets for evaluation in the experiments. Both task 1 of DUC2001 and task 1 of DUC 2002 aim to evaluate generic single document summaries with a length of approximately 100 words or less. Table 1 gives a short summary of the two datasets. The sentences in each article have been separated and the sentence information is stored into files. The articles have been grouped into clusters manually and the documents within each cluster are topic-related or relevant. The manually labeled clusters are considered as the ground truth clusters or gold clusters. In order to investigate different clustering algorithms, the documents in the clusters are mixed together to form the whole document set for single document summarizations. As a preprocessing step, the stop words in each sentence are removed and the remaining words are stemmed using the Porter X  X  stemmer [23]. In the experiments, several popular clustering algorithms and random clustering algorithms are explored to produce cluster contexts. Note that we know the numbers of the clusters for the two datasets beforehand and simply use them as input for the following clustering algorithms 3 .
 Gold Clustering : It is a pseudo clustering algorithm by manually grouping the documents. For any of the two datasets, we use the ground truth clusters as the upperbound of the automatic clustering algorithms. Agglomerative (AverageLink) Clustering : It is a bottom-up hierarchical clustering algorithm and starts with the points as individual clusters and, at each step, merge the most similar or closest pair of clusters, until the number of the clusters reduces to the desired number. The similarity between two clusters is computed using the AverageLink method, which computes the average of the Cosine similarity values between any pair of documents belonging to the two clusters respectively as follows: where d i , d j are two documents in cluster c 1 and cluster c respectively, and m is the number of documents in cluster c is the number of document in cluster c 2 .
 Agglomerative (CompleteLink) Clustering : It differs from the above agglomerative (AverageLink) clustering algorithm only in that the similarity between two clusters is computed using the CompleteLink method, which computes the minimum of the Cosine similarity values between any pair of documents belonging to the two clusters respectively as follows: Divisive Clustering : It is a top-down hierarchical clustering algorithm and starts with one, all-inclusive cluster and, at each step, splits the largest cluster (i.e. the cluster with most documents) into two small clusters using the KMeans algorithm until the number of clusters increases to the desired number. KMeans Clustering : It is a partition based clustering algorithm. The algorithm randomly selects k documents as the initial centroids of the k clusters and then iteratively assigns all documents to the closest cluster, and recomputes the centroid of each cluster, until the centroids do not change. The similarity between a document and a cluster centroid is computed using the standard Cosine measure. Random1 Clustering : It produces k clusters by randomly assigning each document into one of the k clusters. Random2 Clustering : It randomly produces k clusters in a different randomization process. Random3 Clustering : It randomly produces k clusters in another different randomization process. Given a cluster of documents, we can design the following three summarization methods based on how to use the cross-document relationships between sentences in the cluster for computing the informativeness scores of sentences: UniformLink : The method computes the informativeness score of a sentence based on the global affinity graph with both the cross-document relationships and the within-document relationships between sentences, i.e. IFScore ( s i )= IFScore InterLink : The method computes the informativeness score of a sentence based only on the cross-document relationships between sentences, i.e. IFScore ( s i )= IFScore inter ( s i ); UnionLink : The method computes the informativeness scores IFScore inter ( s i ) and IFScore intra ( s i ) of sentence s cross-document relationships and the within-document relationships between sentences respectively, and then combines them as in Equation (7) to get the final informativeness score. Typically, we let : =0.5 to make the two kind of relationships equally important. i.e., IFScore ( s i ) = 0.5  X  IFScore In addition, we design the following baseline summarization method using only the within-document relationships between sentences in a document, which is widely explored in previous work [7, 20, 21]. IntraLink : The method computes the informativeness score of a sentence based only on the within-document relationships between sentences, i.e. IFScore ( s i )= IFScore intra ( s i ); The cross-document methods of  X  X nterLink X ,  X  X nionLink X  and  X  X niformLink X  rely on the clustering algorithm adopted for document clustering, and a summarization system implementing CollabSum is represented by a combination of one of the clustering algorithms and one of the above cross-document summarization methods. The system based on the  X  X ntraLink X  method is the baseline summarization system, which is independent of any clustering algorithm. Note that the process of redundancy removing is the same for all the above methods. We adopt the widely used F-Measure to evaluate the performance of the clustering algorithm (i.e. the quality of the clusters) by comparing the produced clusters with the gold clusters (classes) as follows [10]: For cluster j and class i , we have Recall ( i,j ) =n Precision ( i,j ) =n ij /n j , where n ij is the number of members of class i in cluster j , n j is the number of members of cluster j and n number of members of class i . The F-Measure of cluster j and class i is then given by maximum value it attains at any cluster and an overall value for the F-measure is computed by taking the weighted average of all values for the F measure as where the max is taken over all clusters and n is the number of all documents in the set. The larger the F-Measure is, the better the cluster quality is. We use the ROUGE [16] toolkit (i.e. ROUGEeval-1.4.2 in this study) for evaluation, which is widely adopted by DUC for automatic summarization evaluation. It measures summary quality by counting overlapping units such as the n-gram, word sequences and word pairs between the candidate summary and the reference summary. ROUGE-N is an n-gram recall measure computed as follows: where n stands for the length of the n-gram, and Count match ( n-gram ) is the maximum number of n-grams co-occurring in a candidate summary and a set of reference summaries. Count ( n-gram ) is the number of n-grams in the reference summaries. ROUGE toolkit reports separate scores for 1, 2, 3 and 4-gram, and also for longest common subsequence co-occurrences. Among these different scores, the unigram-based ROUGE score (ROUGE-1) has been shown to agree with human judgment most [16]. We show three of the ROUGE metrics in the experimental results: ROUGE-1 (unigram-based), ROUGE-2 (bigram-based), and ROUGE-W (based on weighted longest common subsequence, weight=1.2). In order to truncate summaries longer than length limit, we use the  X -l X  option 4 in ROUGE toolkit. First of all, we show the document clustering results in Table 2. The gold clustering result is the upperbound of all automatic clustering results. Seen from the table, the four popular clustering algorithms (i.e. CompleteLink, AverageLink, KMeans and Divisive) all perform much better than the three random clustering algorithms (i.e. Random1, Random2 and Random3). Different clustering results lead to different document relationships and a high-quality cluster produced by popular algorithms is deemed to summarizations. Now we compare the summarization results on the two datasets in Tables 3 and 4 respectively. In the tables,  X  X ntraLink X  is the implementations of CollabSum. For example,  X  X nterLink (Gold) X  is implemented by using the gold clustering for document clustering and the  X  X nterLink X  method for summarization. The systems in the tables are listed in a decreasing order of the ROUGE-1 value. Seen from the tables, most proposed systems using the popular clustering algorithm or gold clustering algorithm outperform the baseline  X  X ntraLink X . The systems of  X  X niformLink (Gold) X  and  X  X nionLink (Gold) X , which make use of both the within-document relationships and the cross-document relationships betweens sentences in the ideal (gold) clusters, almost perform best on both datasets, except for  X  X niformLink(Gold) X  on the DUC2001 dataset. It is encouraging that the  X  X niformLink X  and  X  X nionLink X  methods using the popular clustering algorithms always outperform the baseline  X  X ntraLink X , which demonstrates that the mutual influences through the cross-document relationships between sentences within a high-quality cluster do benefit single document summarizations. The importance of the cross-document relationships are further validated by that even the methods considering only the cross-document relationships between sentences ( X  X nterLink X ), based on high-quality clusters, can perform better than or at least comparable to the baseline  X  X ntraLink X . We can also observe that all the proposed systems using the random clustering algorithms (i.e. the random1, random2 and random3 algorithms) perform not well, even much worse than the baseline  X  X ntraLink X  system in most cases. This is because that the random clustering algorithms usually produce low-quality clusters, in which the documents are not truly topic-related, and so in any cross-document relationships between sentences are not reliable for evaluating sentences. (* indicates that the improvement over  X  X ntraLink X  is statistically significant.) In order to better understand the results, the performances of the proposed systems are visually compared in Figures 2-3. We only show ROUGE-1 results due to page limit. The clustering algorithms in x -axis are arranged in an ascending order of their F-measure values. We can clearly see that high-quality clusters lead to high summarization performances. The proposed systems using the popular clustering algorithms perform much better than the systems using the random clustering algorithms. Figure 2: ROUGE-1 vs. clustering algorithm on DUC2001 Figure 3: ROUGE-1 vs. clustering algorithm on DUC2002 In order to investigate how the relative contributions from the cross-document relationships and the within-document relationships between sentences influence the summarization performance, Figures 4-7 show the ROUGE-1 values of the systems based on the  X  X nionLink X  method with respect to different values of the combing weight X . Figures 4 and 5 show the performances of the systems using the popular clustering algorithms and Figures 6 and 7 shows the performances of the systems using the random clustering algorithms. With the increase of X , the cross-document relationships between sentences contribute less to the final summarization performance, and the within-document relationships between sentences contribute more to the final summarization performance. Seen from Figures 4 and 5, when using the popular clustering algorithms for document clustering, the ROUGE values of the systems first increase and then decrease with the increase of X , and the best performances are achieved by assigning appropriate relative contributions of the cross-document and within-document relationships between sentences. Seen from Figures 6 and 7, when using the random clustering algorithms for document clustering, the ROUGE values of the systems almost always increase with X , i.e., the reduction of the contribution of the cross-document relationships can improve the summarization performance, because the random clustering algorithms usually produce low-quality clusters, in which the documents are not topic-related, so the cross-document relationships between sentences in the clusters could not be considered as reliable evidences for evaluating the importance of the sentences. Figure 4: ROUGE-1 vs. on high-quality clusters of DUC2001 Figure 5: ROUGE-1 vs. on high-quality clusters of DUC2002 
Figure 6: ROUGE-1 vs. on low-quality clusters of DUC2001 
Figure 7: ROUGE-1 vs. on low-quality clusters of DUC2002 The reason underlying the above observations that the cross-document relationships in the framework of CollabSum can improve single document summarizations is that the adopted graph-ranking based algorithm evaluates the importance of a sentence based on the  X  X ecommendation X  and  X  X oting X  from its neighboring sentences. We believe that the votes of neighbors in an appropriate cluster context are at least as important as the votes of neighbors in the same document, so we use both the neighbors from the same document and the neighbors from other documents to iteratively compute the informativeness score of a sentence. In the real world, information usually redundantly exists, for example, there are many different documents on the Internet to discuss the same topic from various perspectives, and users can obtains thousands of documents for a specified topic through search engines. An important piece of information about a topic in a sentence would be expressed in different ways in the sentences of other documents, and the sentences might have different representations. The appropriate cluster context would guarantee that the mutual influences through the cross-document relationships between sentences are reliable. The proposed approach thus makes use of this phenomenon to incorporate the guaranteed cross-document relationships between sentences for collaborative single document summarizations. In this paper, we propose a novel framework-CollabSum for collaborative single document summarizations, which first groups the documents into clusters and then incorporates the cross-document relationships between sentences in a cluster into the graph-ranking based summarization algorithm. Experimental results on the DUC2001 and DUC2002 datasets demonstrate the good effectiveness of CollabSum. The cross-document relationships between sentences in an appropriate cluster context can improve single document summarizations. The clustering algorithm is important for obtaining the appropriate cluster context and the low-quality clustering results will deteriorate the summarization performance. It is encouraging that most existing popular clustering algorithms can meet the demands of the proposed approach. The proposed CollabSum has more implementations than the graph-ranking based implementations in this study. In future work, we will explore more summarization methods in the proposed framework to validate the robustness of the framework. Furthermore, we will adapt the proposed approach to collaboratively summarize single web pages. Web pages have rich link information and we can make use of the link structure between web pages to find the appropriate cluster context and mine the implicit mutual influences between web page units for single page summarizations. [1] Amini, M. R., Gallinari, P.: The Use of Unlabeled Data to [2] Baeza-Yates, R., and Ribeiro-Neto, B. Modern Information [3] Brin, S. and Page, L. The anatomy of a large-scale [4] Carbonell, J., Goldstein, J.: The Use of MMR, [5] Conroy, J. M., O X  X eary, D. P.: Text Summarization via [6] Edmundson, H. P.: New Methods in Automatic Abstracting. [7] ErKan, G  X unes, Radev, D. R.: LexPageRank: Prestige in [8] Gong, Y. H., Liu, X.: Generic Text Summarization Using [9] Hovy, E., Lin, C. Y.: Automated Text Summarization in [10] Jain, A. K, Murty, M. N., and Flynn, P. J. Data clustering: a [11] Jing, H.: Sentence Reduction for Automatic Text [12] Jing, H., McKeown, K. R.: Cut and Paste Based Text [13] Kleinberg, J. M. Authoritative sources in a hyperlinked [14] Knight, K., Marcu, D.: Summarization beyond Sentence [15] Kupiec, J., Pedersen, J., Chen, F.: A.Trainable Document [16] Lin, C. Y., Hovy, E.: Automatic Evaluation of Summaries [17] Lin, C. Y., Hovy, E.: The Automated Acquisition of Topic [18] Luhn, H. P.: The Automatic Creation of literature Abstracts. [19] McDonald, D., Chen, H.: Using Sentence-Selection [20] Mihalcea, R., Tarau, P.: TextRank: Bringing Order into Texts. [21] Mihalcea, R. and Tarau, P.: A language independent [22] Nomoto, T., Matsumoto, Y.: A New Approach to [23] Porter, M. F. An algorithm for suffix stripping. Program, [24] Shen, D., Sun, J.-T., Li, H., Yang, Q., and Chen, Z. [25] Silber, H. G., McCoy, K.: Efficient Text Summarization [26] SteinBack, M., Karypis, G., and Kumar, V. A comparison of [27] Zha, H. Y.: Generic Summarization and Keyphrase [28] Zhang, B., Li, H., Liu, Y., Ji, L., Xi, W., Fan, W., Chen, Z., 
