 1. Introduction ation [9] are also addressed.
 ables. Furthermore, once the transformation matrix is disclosed, all participants will be compromised. however, malicious collusion exists, and thus our method also addresses malicious collusion. 2. Method described in Section 2.3 .
 2.1. Privacy measurement data X . Let X i be the i th column of X and Y i be the i th column of Y , the perturbed form of X in [3] , we use the variance Var  X  X i Y i  X  to evaluate the privacy level of column X greater the variance, the more difficult it is for the miner to guess X the candidate perturbation. The normalized forms of X and Y are represented as X level of X i changes from Var  X  X i Y i  X  to Var  X  X 0 i Y where E is the identity matrix.
 The privacy level of X i corresponds to the i th diagonal element in the covariance matrix. different levels of privacy. 2.2. Customized privacy transformation matrix the requirements for the m m transformation matrix, H , in the following equation set, where H of H and E , respectively, ority list.
 transformation matrix H determines the relative order of privacy level of the ith attribute in D. Proof. The privacy level of the i th attribute is quantified by plify Eq. (3) . So we have Thus, h i ; i represents the order of the privacy level of the i th attribute. h transformation matrix.

Algorithm 1. Implementation of Customized Privacy 10: S :  X  S [ h ij ; 11: end 12: sort the elements of S in ascending order; 13: for i :  X  1 to m do 14: begin 15: find s k 2 S which is also from the i th row of G ; 16: if i 6  X  k then 17: begin 18: swap the i th and the k th rows of G ; 19: end 20: end 21: for i :  X  1 to m do 22: begin 23: find s k 2 S which is also from the i th column of G ; 24: if i 6  X  k then 25: begin 26: swap the i th and the k th columns of G ; 27: end 28: end 29: output matrix G ; 30: end the diagonal elements of G .
 2.3. Transmission protocols for clustering integration process performed by the miner.
 In a two-party situation, for example, suppose party A has data matrix X party B has data matrix X B and transformation matrix H B turbed rows is H one coordinate system. We first define the  X  X  RD  X  matrix used in our protocols. N  X  l ; d 2  X  .

Example. A3 3 X  X  RD  X  matrix when l  X  0 and d  X  0 : 5: ranged in a circle. Thus, the left neighbor of party i is party i 1 when 1 &lt; i
RD
RD 2 H and sends the product as the  X  X  X erturbation matrix X  to the miner.
Algorithm 2. Data Perturbation for the i th Party 1: Input: own data set X 2: Output: N/A 3: Suppose the left neighbor is party j 4: begin 5: generate orthogonal H using Algorithm 1 ; 6: perturb X by Y :  X  X H ; 7: generate  X  X  RD  X  matrices RD 1 and RD 2 ; 8: T i :  X  X  RD 1 H  X  T ; 9: send T i to the right neighbor; 10: receive matrix T j from the left neighbor; 12: send Y and T j ; i to the miner; 13: end for 1 6 i &lt; n and T i ; 1 , when i  X  n . For example, in a two-party system, the miner receives H
Algorithm 3. Data Integration Process 1: Input: the perturbed data sets of 2: Output: the integrated data set 3: begin 4: DS :  X ; ; 5: TCS :  X  k ; k 2 X  1 ; n ; 6: for i :  X  1 to n do 7: begin 8: if i 6  X  TCS then 9: begin 10: 11: DS :  X  DS [ Z ; 12: end 13: end 14: output data set DS ; 15: end we will analyze the data accuracy and privacy level. 3. Accuracy analysis ginal data is x A x B , where x A is a row in the data matrix X multiplied by a sequence of the perturbation matrices T i ; i  X  1 a dot product from the original data and the corresponding dot product from the received data. of the received data vectors are entries of two dot products.
 P N  X  l p ; d 2 p  X  ; Q N  X  l q ; d 2 q  X  . We have the expectation of their product: and the variance of their product:
Theorem 3. Assume the recursive sequence a n  X  P k i  X  1 p nonzero real roots x i  X  i  X  1 ; 2 ; ... ; k  X  , then a n ing accuracy.
 average of the squared values of the involving record vector entries. respectively. Applying Eqs. (7) and (8) , we get the recursions of a
Let a  X  X  m 1  X  d 2 ; b  X  1  X  X  m 2  X  d 2 , then
From the above equations, we have
The corresponding characteristic equation for a t a t 1 is whose roots are set: where
Since a t is smaller than b t , we focus on discussing b t party is chosen, the maximal number of  X  X  RD  X  matrices in the product is about n = 2. Referring to Eq. (17) , we can compare the dot product of the original row vectors x perturbed forms typical values of r are about ten. 4. Privacy analysis uated by y i ; j x i ; j . The higher the variance Var  X  Y and everyone complies with the transmission protocols.
 any other participant in the form of  X  X i R 1 R 2  X  by any polynomial-time algorithm. In  X  X that the malicious parties do not know the data records of other parties. prove the protection for the individual privacy. 4.1. Problems in the common way example, in a two-party ( A ; B ) situation, when the miner receives X X cause privacy leakage. Suppose party A colludes with the miner: he shares his H tem is chosen as the  X  X  X CS X , the miner gets H T party 1 H formation matrices, which is a disaster. 4.2. Problems of direct randomization can be obtained according to Eqs. (7) and (8) .
 T A ; B  X  H T A RanDiag A RanDiag B H B , he will get the values in RanDiag this sense, SVD can increase the probability of revealing B  X  X  data to 1 4.3. Privacy level of our method method.
 H the orthogonal transformation would allow the miner to identify the original X of each entry in the perturbed version 4.3.1. Level of privacy protection
While the privacy level by Var  X  X i Y i  X  measures the overall perturbation of column X gets protected in our method. Referring to Eq. (19) , the perturbation of the original value x
P vidual privacy in the j th column is determined independently of the elements themselves. miner gets R , it is possible for him to approximate the data of any participant by multiplying R 4.3.2. Restriction on privacy protection technique in [2] , a well-known technique for perturbing the data using random noise. vidual values and the overall perturbation. It is defined as follows: h  X  X j Y  X  h  X  X  X  X  h  X  Y j X  X  h  X  Y  X  .
 Referring to Eq. (19) , the noise R for the j th attribute is er than h  X  Y  X  in our method, i.e. h  X  X j Y  X  h  X  X  X  X  h  X  Y j X  X  h  X  Y  X  P 0. 5. Enhanced method matrix method to alleviate this problem.
 generates a single  X  X  RD  X  matrix instead of two different matrices in Algorithm 2 . Then, it sends H turbation matrix X  to the miner.

Algorithm 4. Improved Data Perturbation for i th Participant Party 1: Input: own data set X 2: Output: N/A 3: let party j be the left neighbor 4: begin 5: generate orthogonal H using Algorithm 1 ; 6: perturb X by Y :  X  X H ; 7: generate  X  X  RD  X  matrix RD ; 8: T i :  X  X  RD 1 H  X  T ; 9: send T i to the right neighbor; 10: receive matrix T j from the left neighbor; 11: T j ; i :  X  T j RD H ; 12: send Y and T j ; i to the miner; 13: end
In this way, the transformation of a data matrix to the target coordinate system will be We are able to remove most of the  X  X  RD  X  matrices in the transformation path. to the  X  X  X CS X  is D C RD C 2 RD D 1 RD D 2 RD A 1 H A . In our enhanced method, C  X  X  path changes to D fewer  X  X  RD  X  matrices in the multiplication.
 part of this section.
 d number j  X  E  X  X k E 1 kk E k X  1 [15, Chapter 5] .
 We denote by k A k 2 the spectral norm of matrix A , and k A k bation on the inversion of a general matrix, which can be found in [15] . Theorem 5. Let A 2 C m m be a non-singular matrix, if we perturb it by adding matrix P, i.e. A k A 1 k 2 k P k 2 &lt; 1 . Then, the deviation of A 1 P from the original A Then we give an upper bound for the spectral norm.

Theorem 6. Suppose matrix A 2 C m m , g  X  max 1 6 i 6 m P j k a ii j 6 affect the errors between the  X  X  RD  X  inversion and E 1  X  E .

Proposition 7. Suppose an m m X  X  X D  X  matrix R is generated by normal distribution  X  0 ; d deviation matrix  X  R 1 E  X  share the same variance n 2 . Then n if k P k 2 &lt; 1. By the definition of the spectral norm of a matrix and Theorem 6 , we have
The k th row in P T P is  X  P m i  X  1 p ik p i 1 ; ... ; P independently. Thus, the product of different elements has expectation equal to 0, i.e. Exp  X  p we have Combining Eqs. (21) X (23) , we have
Under our assumption that the entries in the deviation matrix share the common variance n ffiffiffiffiffiffiffiffiffi p ffiffiffi p , and we get n 6 d 1 ffiffiffi m p d . h ticipating parties perturb their data using  X  X  RD  X  matrices generated by d &lt; 1 = with Eqs. (18) and (19) can be improved by a factor of O  X  n  X  . Recall that we choose d so that d d &lt; 1 = 6. Experiments algorithms. Finally, we compare our enhanced  X  X  RD  X  method with the  X  X  X andom Projection X  technique. 6.1. Experimental setup d effect on the accuracy, since this denotes the lowest accuracy level under the maximum d . with the smallest sum of distances. 6.2. Comparison between  X  X  X D  X  methods mation maintains the distances between the data vectors.

Fig. 3 . We also compare the two versions of our  X  X  RD  X  method under the same d  X  d maximum variance, but also becomes invariant to the increased number of participants. 6.3. Influence of clustering parameters and clustering algorithms eters k  X  6 ; n  X  10 ; r  X  3.
 influence our privacy protecting methods.
 slightly influences the effects of  X  X  RD  X  methods. 6.4. Comparison with  X  X  X andom Projection  X  ring to Propositions 4 and 7 , we should have the maximum d as 1 there are 20 participants, and we set k  X  10 to make the error rate curves clearly distinguishable. expectations. For example, if an m m matrix _ H is generated using a Gaussian distribution  X  0 ; d of _
H T _ H are in v 2  X  m  X  distribution. Since _ H is divided by meet different privacy requirements.
 rithms minimally impact the effectiveness of our methods.
 7. Conclusions clude more work on different types of attributes and extending this idea into other mining algorithms. Acknowledgements their careful and constructive comments.

References
