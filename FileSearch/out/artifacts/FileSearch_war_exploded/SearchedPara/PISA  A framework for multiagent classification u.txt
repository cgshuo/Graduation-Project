 1. Introduction can be made explicit. The process of Multiagent Argumentation can be conceptualised as a discussion, about some issue that requires a solution, between a group of software agents with different points of view; where each agent attempts to persuade ied in an agent dialogue protocol. Computer automation and modelling of the argumentation process have found applications in Arguing from Experience [57,56] , is well suited to the classification task.

Much work on argumentation has been related to the deductive paradigm, where axioms are used to license the move from a recent comprehensive account of this style of argumentation. Such argumentation does, however, rely on the existence of a number of examples.

For such concepts argumentation based on a series of rules is inappropriate: while we may form a theory based on the exam-a bird ). Arguing from experience is such a pattern: 1. In my experience, most things with features F are of kind K . 2. This thing of unknown kind has features F . 3. Thus, I have reason to think that this thing is of kind K .

Like any argument based on a presumptive argumentation scheme, such an argument is defeasible: in particular we need to [7] in terms of an adversarial three ply exchange. 1. Proponent cites a case supporting his side. 2. Opponent points to features distinguishing the current cases, or supplies counter examples supporting her side. 3. Proponent cites a stronger case or distinguishes the current case.

The dialogue moves used for our proposed argumentation from experience schema are closely related to this style of argu-ment. A more formal account of reasoning with legal cases was given in [12]. There the reasoning was characterised in terms what we will call, using the data mining terms, its support and confidence. examples must be considered.
 and natural way to approach classification of such concepts.

The proposed model allows a number of agents to draw directly from past examples to find reasons for coming to a decision background dataset of past examples which is mined as required. Each agent's database can be considered to encapsulate that agent's experience . The exchange of arguments between agents represents a dialogue which continues until an agent poses an as producing a reasoned consensus obtained through argumentation (dialogue), as opposed to some other mechanism such as cation by argumentation concept has been built into an argumentation framework called PISA (Pooling Information from Several offers a number of practical advantages: 1. It enjoys general applicability as it does not require the generation of specialised knowledge or case bases. need for reference to a domain expert. operates directly with the raw case data. 4. It avoids the need for any knowledge re-engineering, again because it works directly with the case data. 5. It provides an easy-to-understand explanation, in the form of dialogues, concerning a particular classification. 6. It is particularly good at handling noisy data.
 of reasons, cannot be readily combined into a single  X  data warehouse
The application of multi-agent classification based on argumentation requires the resolution of two high level issues: 1. The nature of the framework that will allow the envisioned argumentation from experience process whereby a collection of agents can reach an agreement about the classification of cases in some domain. to classification.
 These issues are all addressed by the PISA framework which forms the focus of the remainder of this paper.  X  tified from the reported investigation and some suggested future directions. 2. Classi fi cation Association Rule Mining Central to the operation of PISA is the concept of Classification Association Rule Mining (CARM), which is a special form of patterns in a binary valued tabular data set D ={ d 1 , d threshold  X  . The confidence value for an AR is calculated in terms of of records in which P occurs with respect to the total number of records in D expressed as a percentage:
The confidence of a rule is the given by: (A discussion on the use of support and confidence thresholds in CARM can be found in [21], further discussion on CARM per-formance metrics can be found in [53].) and then to generate the desired ARs. Given an attribute set A there are 2
Clearly the number of combinations to be considered needs to be limited in some way. This is typically done by introducing a support threshold,  X  , to identify frequent itemsets , an itemset P is deemed to be frequent if supp ( P ) butes in an itemset), calculate the support for each K itemset and then prune those whose support is less than documented (see for example [9]).
 class attribute taken from a set of classes C , thus a record d ( I  X  Rule Mining (CARM) and the generated rules Classification Association Rules (CARs).

There are many CARM techniques that have been proposed in the literature (see for example [52]), that used to support the likelihood of common leading subsets increases as | D | increases. The P-tree is therefore well suited to large data sets. this branch. 2 The T-tree is constructed in an Apriori manner. The time complexity of this generation approximates to O (| P maximum size ( K max ) of a frequent itemsets will be equivalent to in D . In which case to identify the set of frequent itemsets the maximum size of an itemset in S will be K the nature of T-trees and P-trees can be found in [22]. 3. The PISA framework generated from local datasets of past examples which are mined as required. For this reason PISA agents require both  X  follows: where: (i) AM (Argumentation Mechanism) is some argumentation from experience mechanism, (ii) G is a set participant agents (players), (iii) D is the collected experience of the participants divided into | G | mutually exclusive subsets ( D ={ E a class attribute), (iv)  X  is the case to be considered ( confidence threshold, and (vii) CPA is the  X  Chair Person Agent The AM comprises: where: (i) R a set CAR generation algorithms (see Section 7 for further detail), (ii) summarised as follows:
The first is an aggressive (attacking) strategy where participant agents aim to win the game by favouring rules that support  X  discussed in more detail in Section 4 below.

The set G comprises the set of participant agents, in its simplest form PISA requires | G |=| C |. Each participant agent g following form: where: (i) E i is the agents local data set (  X  E i , E j agent ( strat i  X  Strat ) and (iii) c i is the class advocated by the agent ( c
Participant agents produce reasons for and against classifications by mining CARs from their local dataset E selected from R. The antecedent of every CAR represents a set of reasons for believing the consequent; which will include a class attribute. In other words given a CAR, P  X  Q where c classified as c, as long as the additional attributes in Q also exist in the case .

The exchange of arguments between agents represents a dialogue which continues until one agent poses an argument for a to one move per round. The dialogue terminates when no participant makes a contribution for two rounds,
Cycles are avoided by preventing participant agents from  X  twice, a rule that is played remains  X  in force  X  until it is directly or indirectly defeated). 4. Strategy
Proposing Moves . There are two kinds of proposing moves: 1. Propose Rule : Allows a new CAR (argument), with a confidence higher than
Attacking Moves . Moves intended to show that a CAR (argument) proposed by some other agent should not be considered decisive with respect to the current case. Three sub-types of attacking moves are available: (i) Distinguish, (ii) Unwanted
Consequence, and (iii) Counter Rule, as follows:
Refining Moves . Moves that enable a CAR (argument), proposed by the current agent, to be refined to meet a
At first glance it would appear that moves 5 and 3 contradict one another, however it easily possible to both increase and { b , c , d , z }, { b , d , y }} (where I ={ a , b , c , d }and C ={ x , y , z }) and a rule r mise to give r 1
R = b  X  y the confidence value will be 2/3=67%; if we now add c to give r 2=50%. Thus the same mechanism has been used to both increase and decrease the confidence value.
Each of the above six moves has a set of legal next moves, these are itemised in Table 2 . Note that move 5 (Increase Confi-dence) is only  X  played  X  if a Distinguish move has been played, and move 6 (Withdraw Unwanted Consequents) only if an
Unwanted Consequent move has been played. Section 8 provides an example dialogue using the above moves, and illustrates how they can be utilised to reach an agreement about the classification of a given case. where a participant agent continuously attempts to undermine an opponents arguments (and thus indirectly advocate their own class). The Increase Confidence and Withdraw Unwanted Consequent moves are associated with the defensive (refining) strategy mentation tree which is described in the following section. 5. The CPA and the argumentation tree in [41]. The CPA has the following specific responsibilities:  X 
Starting a dialogue.  X 
Terminating a dialogue when a termination condition is satisfied.  X  Announcing the resulting classification for the given case (once the dialogue has terminated). dialogue.
 which is maintained by the Chairperson. This is defined as: where: (i) V is a set vertices such that | V |  X   X  where  X  a set of vertex labels, (iv) L E is a set of edge labels and vertex labels, L v , is defined as: following interpretation: Green : New CAR.
 Blue : New CAR that undermines an existing CAR.
 Red : Existing CAR that is under direct attack.
 Purple : Existing CAR that is under indirect attack.
 with lower confidence; while moves 3 and4 are direct attacks. The set of edge labels, L where  X  indicates a direct attack, and  X  an indirect attack.
 that change the colouring of the argumentation tree. For example it would not make sense for an agent to attack red nodes as these are nodes representing CARs that are already defeated; however, it does make sense for participants to attack purple of moves (this prevents  X  deadlocks  X  and cycling). 6. The PISA dialogue protocol possible classes in the domain from which this case was drawn; then the PISA dialogue protocol operates as follows: 1. Before the start of the dialogue the chairperson arbitrarily selects one participant ( g 2. At the first round g 1 proposes a new CAR, CAR 1 , such that conf ( CAR all the participants fail to propose an opening argument, the dialogue terminates with failure. 3. In the second round the other remaining participants attempt to attack CAR promoted by g 1 . Otherwise, the argumentation tree data structure is updated with the submitted attacks. m rounds from the dialogue and updates the argumentation tree. This is to exclude non-participating agents (agents who are one agent remains in the game then the dialogue is terminated, and the case is classified according to the class promoted by this agent. Otherwise, any participant who can play a legal move, according to the protocol highlighted in Table 2 , can do so, and the argumentation tree data structure is updated with the submitted attacks. sive experiments were undertaken and it was found that the most appropriate setting for dialogue would continue for 50 rounds. The experiments conducted by the authors, using many different data sets, indicated that a dialogue never required more than 40 rounds to complete (even with very large data sets featuring many classes), the maximum number of round in most cases was nearer 25.

Once a dialogue has terminated the status of the argumentation tree will indicate the realised only when no other participant has played an undefeated move with higher or similar confidence. 2. If there are no green nodes, and all the blue nodes were played by the same participant, that participant wins. implements a tie resolution mechanism. We have identified various possible tie resolution mechanisms [58]. For example we can repeat the argument process but with only the tied parties, adopt a voting strategy or simply adopt a random resolution.
The latter is akin to using a default rule and has, for simplicity, been used in the remainder of this paper. 6.1. Groups of agents advocating the same class selection is made.
 the leader to select the move to be played (if any) at each round. The selection is made from moves suggested by the group's members. The inter-group dialogue model is as follows. At the start of a new round the group leader instructs other members of the group to suggest moves. The following dialogue then occurs: 1. All the group members who are able to suggest moves (according to their strategies and experience). 2. If all the group members fail in suggesting any move, the leader passes the round and submits no moves. 3. Otherwise the leader compares the members' moves and identify a best move (i.e. the move with the best confidence) and submits this move.

The authors have conducted work to support more sophisticated group argumentation, that takes into consideration the individual strategies of the group members, but because of space limitations this is not reported here. 7. The classi fi cation rule mining algorithms
Having introduced, in the foregoing, the legal moves in PISA dialogues, the realisation of these moves using CARM techniques algorithms are as follows:
Algorithm A. Find a rule given a particular case to be classified and some local confidence threshold respect to the Propose Rule and Counter Rule moves (Moves 1 and 2). In the first case u = to increase the confidence to above some local threshold  X  Algorithm C. Generalise a given rule by removing attributes from the consequent. The algorithm is used in relation to the
Withdraw Unwanted Consequent move (Move 6). A similar algorithm (Algorithm C
Consequent move (Move 4).The first seeks to increase the confidence value above value to below  X  (preferably below  X  ).

Note that local confidence thresholds (  X  ) are used because, although all acceptable rules must have a confidence value of above the global threshold  X  , during the dialogue there will be a agents will seek to address. Agents will wish to present rules with confidence values above own position, or below  X  if they are seeking to attack some other agent's advocated position. the T-tree is only populated as required (so as to avoid unwanted overheads). In other words the CARM is dynamic. we assume a 50% density and a normal distribution, each single item will occur in 50% of the records ( P each 2 itemset existing will be 0.25 ( P 2 =0.25), P 3 =0.125, P  X  =0.01 (a fairly standard value) the likelihood is that there will be no supported itemsets of size 7 or more, in other words exists, therefore a maximum of K indexing operations will be required. The maximum complexity to determine whether a partic-ular K itemset, I i , exists in the T-tree is thus O(K) 4 search, thus the complexity can more accurately be expressed as O ( K ) X  p ( I nations of I (assuming all these combinations exist) will thus require 2 many of these combinations will not exist because they are not supported. To give some upper bound on the complexity of the on the remainder of this section.
 desired class attribute c , (iii) a desired local confidence threshold (recall that level one in the T-tree contains one itemsets, level two two itemsets, and so on). For each I whether a more exhaustive search might generate a higher confidence rule). If no appropriate CARs can be generated from I
T-tree as required). The process continues until either: (i) an appropriate CAR is found, or (ii) I that all candidate itemsets I k are present in the T-tree, but all generated rules have a confidence value of less than be O (2 Inst +1) (plus one fro the initial indexing operation to the are less likely to find an appropriate CAR if the value of or no more candidate attribute sets can be generated (in which case null is returned). Fig. 2 presents the pseudo code for
Algorithm B . A variation of this algorithm, Algorithm B ?
This alternative algorithm proceeds in a similar manner, but instead of returning rules whose confidence is below than  X  ), it returns rules with a confidence higher or equal to  X  ?) is difficult to define. However, to conduct an exhaustive search will require 2 that the maximum complexity is O (2 | Inst \ Ant | ).

Algorithm C is used in order to withdraw some unwanted consequences ( Cons ) from an input rule ( Ant algorithm first tries to produce a rule: Ant  X  c . If such a rule satisfies the local confidence value to Algorithm B , to produce CARs of the form Ant  X  c  X  Cons input case. A similar algorithm can be used (Algorithm C  X 
Unwanted Consequents and reduce the confidence threshold. In this case the generated CARs must have a confidence value such that conf ( rule )  X   X  . The worst case complexity will be O (|{ Ant of the T-tree with respect to potential attributes to include in the new consequent). 8. Explanatory example PISA has been fully implemented in Java, and uses the algorithms described in Section 7 above to mine CARs as appropriate.
Ljubljana [39]. The dataset was obtained from the UCL data repository [15]. The original dataset consisted of 12,960 records 4320, 2, 328, 4266 and 4044 records respectively). Note that the recommended and highlyRecommended classifications are rare. For the purpose of the example described here the two records associated within the recommended class were removed from attributes other than the class attribute: 1. ParentsOccupation = {usual | pretentious | ofGreatPretension}. 2. ChildsNursery = {proper | lessProper | improper | critical | veryCritical}. 3. FormOfTheCFamily = {complete | completed | incomplete | foster}. 4. NumberOfChildren = {1 | 2 | 3 | moreThan3}. 5. HousingConditions = {convenient | lessConvenient | critical}. 6. FinancialStandingOfTheFamily = {convenient | inconvenient}. 7. SocialConditions = {nonProblematic | slightlyProblematic | problematic}. 8. HealthConditions = {recommended | priority | notRecommended}. the four classes. Note that ct HR is disadvantaged because it only has 82 (328/4=82) records from which to generate CARs thresholds within the data mining community (see for example [20] ).

The dialogue commences when the chairperson invites the HR player agent to propose the opening argument, HR proposes the following CAR ( R 1 ): whose con fi dence exceeded  X  . This rule is attacked by the other three agents in the second round ( R follows (the reader might fi nd it helpful to refer to the completed argument tree shown in Fig. 4 as the debate develops):
Note that SP does not propose a rule of advocating its own class but instead attacks the rule proposed by HR. Since the case argument as it has the best unattacked rule.

In round three all four players make moves:  X 
HR: propose a new rule to attack the current best rule, a rule which will turn out to be the winning rule ( R  X 
NR: distinguishes PR's argument by demonstrating that ParentsOccupation = usual and HealthConditions = recommended only gives priority with 18.64% confidence ( R 6 ).  X 
PR: proposes a Counter Rule against NR's rule from round two ( R  X 
SP: distinguishes PR's rule from round two by demonstrating that by adding ParentsOccupation = usual , using its data, the modified rule has 19.9% confidence ( R 8 ).
 small.

In round four SP has no more moves it can make. The other two agents can, however, make moves:  X  class = priority to only 20% ( R 9 ).  X 
PR: proposes a Counter Rule against HR's rule of round three ( R nonProblematic reduces the confidence to just 20% ( R 11 ). In the sixth PR proposes another rule ( R
This, however, can be distinguished by HR since adding SocialConditions = nonProblematic reduces the confidence to 20% ( R
This reinstates the argument HR made in round 3. No more arguments are now possible, and so the final classification is highlyRecommended (i.e. the correct classification). 9. Experimental evaluation assigned to individual PISA participants.

The experiments were designed to evaluate the following: 1. The hypothesis that the proposed classification using argumentation process produces at least comparative results to that to resemble in that both approaches combine the results of the application of more than one classifier to produce a final classification. 2. The effectiveness of PISA when agents work (collaborate) in groups. 3. The performance of PISA, with respect to alternative classification mechanisms, in the presence of very 9.1. Methodology
The results presented throughout this section were obtained using standard Tenfold Cross Validation (TCV). For each TCV the data set was first partitioned into 10 equal sized sets, then each set was used in turn as the test set while the dialogues were executed to classify cases in the test sets. For each reported evaluation datasets).
 techniques used. We chose to apply Boosting and Bagging, combined with decision trees (C4.5 and RDT), because previous work demonstrated that such combination is very effective ( [10,46] ).
 9.2. Evaluation of PISA and other classi fi cation paradigms
This sub-section describes experiments conducted to compare the operation of PISA, using the datasets listed in Table 4 , frequently used to evaluate the operation of binary classifiers.

The results are presented in Tables 6 to 9 . Tables 6 to 8 compare the operation of PISA, according to ER, BER and execution time, with respect to the ensemble methods, decision trees and TFPC. Table 9 compares the operation of PISA with the SMO implementation of an SVM.
 parable to those produced by the ensemble methods. PISA produces the best overall performance in that the lowest ER results
From Table 6 the ensemble methods tended to perform worse than PISA in domains that contain large numbers of classes (the domains to which arguing from experience is most applicable), although the ensemble methods tended outperform PISA in two-class domains. The results also show that PISA performs well with imbalanced class domains (e.g. Car Evaluation, Nursery and Page Blocks).

Table 7 shows the BER for each of the given datasets. From the table it can be seen that PISA produced good results overall, error-rate for the three imbalanced datasets.

Table 8 gives the execution times (in milliseconds) for each of the methods. As expected, because of the communication over-faster than Bagging and ADABoost with some datasets. Fig. 6 shows that, on average, the time complexity associate with the operation of PISA is comparable to that of the other methods considered.
Table 9 provides a comparison between the above results for PISA and SMO. The SMO implementation was run in the default general than the SMO Implementation, additionally PISA performed faster than SMO with respect to most of the datasets considered. 9.3. The role of groups in increasing the accuracy of PISA each agent among a number of agents supporting the same classification (i.e. groups of agents) the quality of the resulting classifications will increase, with some trade-off in execution time. For the evaluation the above reported experiments were databases the greater the number of arguments found, enabling a more thorough exploration of the problem. Note, however, mentation process. However, halving the data between two agents (supporting the same classification) always produced better results than using one agent. These results apply also to the BER as can be seen from Fig. 8 .
Another issue is the communication overhead resulting from the PISA decision making process within each group. For each
The group's leader has to choose one of these moves to present in the ongoing dialogue. The experiments reported in sub-section 2 provided information about execution time when groups are not used. Fig. 9 shows the increase in execution times (in milliseconds) when using groups of 2, 4 and 5 agents compared to the execution time recorded when using PISA with one agent per class. The increase in execution time is not unacceptable. 9.4. Experimenting with noisy data and effective, agent based approach, to the problem of classifying noisy data.
 To assess the robustness of PISA with respect to noise a sequence of experiments was conducted using the datasets from an N % noise level in a dataset of I records, (( N /100) * were: 2%, 5%, 10%, 20% and 40%. The operation of PISA in the presence of noise was also compared with noise-free data (as reported above).

The results obtained demonstrated, as expected, that the overall level of accuracy decreased as the noise percentage was in-and 12 where the percentage of noise is given on the X-axis and percentage error rate on the Y-axis (TCV was again applied). to most of the dataset. Note that the datasets where PISA was outperformed when high levels of noise were introduced are those with only a small number of records per class, so that each PISA player had only a limited number of cases from which of datasets. 10. Related work
Moreover, the system in [37] assumes that each example in the dataset of any agent has a unique identifier shared by all the than single-agent approaches (e.g. [47] ).
 computing a global classifier from large and inherently distributed databases [3]. Meta-learning aims to compute a number of dictive accuracy (see for example [50] ).

One particular example of a meta-learning technique is ensemble learning (a survey of which can be found in [23], an exper-imental comparison of three main techniques can be found in [24]). Ensemble techniques have been shown to achieve good per-formance, especially in fields where the development of a powerful single learning system requires considerable effort [55]. environment. For example, in [43] the authors propose several ensemble schemas for cooperative case-based learners. PISA, as already noted, can be considered to be a multiagent ensemble system. Generally, multiagent ensemble learning can be divided into two categories: the group decision.
PISA supports both techniques; the overall argumentation process presents a competitive ensemble approach, whereas the inter-group decision making procedure is more like the cooperative ensemble approach. Olmeda and Fernandez [40] have shown that an effective ensemble learning system may benefit from the combination of both techniques. These findings were also supported by the results of the experiments described in Section 9 .

A foundational account of argumentation on which much contemporary work in based was given by Dung [25] . There arguments that a small set of analysed cases.

Concerning the application of argumentation techniques to classification [44] articulates an argumentation framework for arguments from past examples and to provide a means to define the preference relation between the generated arguments. PISA on the other hand implements more straightforward CARM techniques to produce arguments and applies a preference relation based upon the support/confidence measures. [44] also presents a framework for multiparty argumentation to enable a commit-tee of agents to jointly deliberate about given cases. However, unlike PISA, the communication between the arguing agents is counter argument (and changes its prediction) or not. Also, when an agent has the token it can answer to such attacks, by has passed and no agent has generated any counter argument. Moreover, if at the end of the argumentation the agents have not mediator agent (the chairperson) to facilitate the argumentation process between a number of agents. Thus, PISA agents can focus on generating the best arguments rather than on the communication amongst themselves. Additionally, instead of voting, PISA applies a tie-resolution mechanism when agreement cannot be reached in a given number of rounds.
Amgoud and Serrurier propose a formal argumentation framework for classification, in which arguments can be constructed for examples, whereas PISA has no such assumption. Additionally, the strength of each argument is identified such that the argu-ments derived from the set of training examples are stronger than the arguments built from the set of hypothesis, whereas
PISA applies support and confidence measures to evaluate the strength of the generated arguments. Other work has tried to number of agents. 11. Conclusion
The PISA arguing from experience framework has been described. The framework allows a collection of participating agents to
Arguments are dynamically generated (mined) from each participant agent's data set, which is viewed as a repository of that agent's experience. The arguments are mined and expressed in the form of Classification Association Rules (CARs), which are tree , as it progresses. The tree indicates the final  X  winner
With respect to argumentation PISA provides the following advantages: (i) it obviates the need to build a static knowledge do not supports this).

In the context of classification the framework provides for a
References
