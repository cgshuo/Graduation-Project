 Recently, Korean national agencies launched an ambitious project of building a digital library of historical archives that have been kept by various institutions. Leveraging the Internet infrastructure of Korea, the project aims to provide instant access to the archives for the researchers and the public, who had been endowed with limited chance due to maintenance reasons.
 iment that explores the possibility. During this phase, the chronicles of King X  X  secretaries have been digitalized, which is shown in figure 1. A number of unique and challenging technical issues have been identified as a result.
 of handwritten Chinese characters. Basically, they are similar to traditional Chi-nese characters, but there are a lot of obsolete characters that are hardly used in contemporary texts. The archives also contains significant number of unique vari-ants, which are depicted in figure 2. The unique layout of documents, in which the characters are written in vertical order, also provide additional challenges. methods had to be developed for almost everything, including the character code set and the keyboard layout. As a consequence, the initial system had to rely on humans for analyzing and annotating the scanned document images. Initially, operators who were trained with new input methods typed in the content of the document. These annotations were later verified by experts who could in-terpret and understand the content of archives. This approach was inevitably time-consuming and showed only limited performance. During four years, docu-ments with about one billion characters were digitized, which accounts for about 1.25 % of entire archives. This suggests that it will take centuries to complete the digitization project in current pace. In order to improve the overall throughput, we developed a dedicated recognition system for handwritten Chinese characters in historical archives. Our system does not intend to completely replace the op-erators. The recognition of handwritten Chinese characters has been one of the most challenging pattern recognition problem, and current recognition perfor-mance are far from perfect yet [1][2][3][4][5]. Rather, our system aims to augment human operators and experts by freeing them from repetitive input task. Our system provides the most likely recognition candidates by analyzing the entire layout of document, the shape of each character, and the linguistic contextual likelihood in a single probabilistic framework. The results can be regarded as sensible initial hypotheses. As a consequence, the human operators only need to verify the recognition results in most cases instead of typing in every character. Combined with intuitive verification interface, our system achieved considerable increase in overall throughput. 2.1 Overview The problem of recognizing a document can be regarded as identifying its layout L and the content S , given the image X . In our system, the relationships between these elements are modeled as a single probabilistic model. The system yields the recognition result by choosing the one with maximum posterior probability p ( L, S | X ) among hypotheses.
 transform the posterior into product of likelihoods of the image given the layout and the content by using Bayes X  rule. Assuming the likelihoods of the layout and the content S to be conditionally independent of each other, equation 1 can be represented as follows: -the layout model p ( L ), the language model p ( S ), and the character model p ( X | S, L ). The layout model evaluates the likelihood of the segmentation of document image. The character model represents the likelihood of the image being generated by given character. The language model evaluates the linguistic likelihood of recognition result.
 2.2 Layout Analysis The objective of the layout analysis is to segment the entire document image into individual character images. The layout model evaluates the likelihood of each segmentation hypothesis by inspecting simple geometric characteristics of character image candidates.
 have relatively simple layout. However, it is almost impossible to get correct segmentation using simple geometric features only. As a consequence, we employ over-segmentation approach: all possible character boundaries are first identified using a dedicated algorithm, and then a lattice that indicates possible character image hypotheses are created.
 each line, which is identified through projection profile analysis. In order to deal with complex character boundaries, we used a Tseng X  X  nonlinear segmentation algorithm [6]. As figure 3 shows, the algorithm can effectively identify complex boundaries between overlapped and touched characters.
 tice as figure 4 shows. Each node in lattice represents a possible character bound-ary, and each arc a candidate for a character image which is enclosed between a pair of boundaries. Because it is computationally infeasible to investigate all possible boundary pairs, we only add character image candidates that have sig-nificant layout likelihoods. The layout likelihood p ( L ) utilizes three geometric features of character image: the height h ( x ), the squareness sq ( x ) and the in-ternal gaps gap ( x ). The squareness measures the similarity of bounding box to the square. The internal gap indicates blank lines contained in character image. These features are assumed to be independent of each other. The probability distribution of each feature was estimated using Parzen windows [7].
 identified using Viterbi algorithm as figure 4. These segmentation candidates are used for evaluating the posterior in later stages. 2.3 Character Model The character model evaluates the geometric likelihood of each individual char-acter image, which is provided by a layout hypothesis L . The geometric vari-ations for individual character shapes are assumed to be independent of each other. Therefore, the geometric likelihood of entire sentence/document can be factorized into that of individual characters as shown in equation 4. direction feature, which has been preferred for handwritten Chinese character recognition. The contour direction features are extracted from respective images as follows. First, the image is normalized into 64 by 64 pixels by a nonlinear normalization algorithm and smoothed using Gaussian filter in order to minimize the effect of geometric variations, aliasing and noises[8]. Then, it is divided into 8 by 8 independent blocks. Within each block, the distribution of contour direction is estimated using the gradients of the image. The directions of contours are quantized into four groups as shown in figure 6. Consequently, the dimension of the feature vector is 256.
 ate Gaussian with mean vector  X  i for each character and common covariance  X  . For the sake of computational efficiency, n best character candidates of each image are identified using the geometric likelihoods before evaluating the full posterior p ( S, L | X ). The candidates can be identified by measuring the Maha-lanobis distance from the mean vector of each character  X  i . acter, it is classified as an out-of-vocabulary character. These out-of-vocabulary characters are manually processed in the last stage. 2.4 Language Model The language model assesses the linguistic contextual likelihoods of recogni-tion results. It helps to resolve ambiguities in individual character level by in-corporating contextual information provided by adjacent character recognition result.
 ing Katz X  X  back-off method[9]. The back-off model hierarchically cascades the maximum likelihood estimates of high order conditional probability models with lower order ones in order to provide more robust estimate, as shown below. 2.5 Verification After evaluating the posterior, the system creates groups of character images with same recognition results and create the indices into their original positions in the respective images. This character groups are presented to operator, sorted by their posterior likelihoods as shown in figure 8. The operator then visually identifies the recognition errors by looking at the character in the original image. After removing all errors, the recognition result is assigned to all images in the group with confirmation of the operator. As a consequence, the operators only have to type in the identities of misrecognized character images and out-of-vocabulary character image.
 We evaluated the effectiveness of the proposed methods using the manually digi-tized chronicles of King X  X  secretaries. For building character model, 100 example images for each character were used. The character models were built for most frequently used 2,568 characters that constitute 99% of frequency of usage in training data. The remaining characters were considered as out-of-vocabulary characters. For testing the recognition performance, we used other 1,000 doc-ument images. As shown in table 1, the proposed system achieved 95.1% of recognition rates. Compared to the recognition rates of baseline system that is based on Euclidian distance template matching, the proposed system reduces error rates by about 8%.
 We proposed a recognition-based digitization system for building digital library of Korean historical archives. By integrating layout analysis and recognition into single probabilistic framework, the proposed system could automate significant amount of annotation process. Experiments showed that the character recogni-tion rates of the propsed system is 95.1%, which means only 5% of characters demand time-consuming manual annotation process. As a result, the overall throughput of the system and the reliability of final results was significantly improved.
