 Department of Electrical, Computer, and Software Engineering, University of Ontario Institute of Technology (UOIT), Oshawa, ON, Canada Pattern Analysis and Machine Intelligence Lab, Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada 1. Introduction
High dimensionality is known to be an intrinsic property of text classi fi cation problems, which not only increases the complexity of the problem but also degrades the performance of the system. In text alization capacity of a classi fi er [5].

Dimensionality reduction can be either supervised or unsupervised depending on whether it is be-reduction [18], supervised techniques are more successful and well-appreciated by researchers in text which correspond to two families of feature selection approaches: wrapper and fi lter.
One well-known fi lter-based approach for excluding a large number of non-discriminant and irrelevant (BIF). In this approach, each feature is scored by a ranking measure such as information gain. All features are sorted from high to low based on their scores. Then, a small number of the best features correlation and dependency between terms and the risk of term redundancy, feature ranking methods are highly scalable and less expensive as compared to other feature selection techniques.
A number of ranking measures have been perviously proposed. In [20,24,33], the measures have been comprehensively compared with each other. According to their fi ndings, information gain and  X  2 function to fi nd the best feature ranking measure for a given data set. The problem is more complex the characteristics of the training data, such as sparsity and class imbalance [19].
One alternative approach is to combine existing individual ranked lists produced by different feature lists of features are combined and produce a new feature ranking. The proposed method is independent of classi fi er model and offers a performance very close to that of the best individual ranking.
The proposed method is evaluated by two different subjective and objective frameworks. First, it is by two objective measures including ranking similarity and Kendall-Tau disagreement metric. Accord-
The paper consists of eight sections. Following the introduction, feature ranking methods for text dependency of feature ranking methods which is the main motivation for this research is discussed in Section 4. The combining feature ranking method is described in Section 5. Section 6 introduces two objective metrics to evaluate the combining schemes. Section 7 includes experimental results and discussion. Conclusions are presented in Section 8. 2. Feature ranking measures for feature selection scores as measured by relevancy, discriminating capacity, and information content. Compared to the ranking methods work better with particular classi fi ers [8].

All feature ranking methods are based on the following three steps: such as joint and conditional probabilities. Let T different conditions as follows:
Most feature ranking measures can be grouped into two families: (i) I nformation theory measures, for example, information gain, mutual information, entropy,  X  2 , Bi-Normal Separation (BNS), and corre-measures, including document frequency and its variants, odds ratio, and F-measure based ranking. 2.1. Document Frequency (DF) and its categories varies. The second assumption in estimating DF is that all the terms are uniformly categories, which means DF can be potentially employed in stopword reduction. Since DF ignores the in text clustering. Each term is assigned a measure, representing the number of documents containing index [3]. We also introduce category-document frequency measure, which is an extension of local DF.
Inverse Document Frequency (IDF) is an information retrieval ranking measure and widely used in word removal is performed by removing all the terms with DF n/ 2 . This rule fails in the case of domain-speci fi c stopword reduction and data sets with high class distribution imbalance [7]. IDF is calculated by different formulations such as where n ( t 2.2. Category-Document Frequency (CDF)
IDF is an unsupervised feature ranking measure, where the frequency of the term across the collection class information of the documents can be involved in the DF measure by the joint probability of a term and a category P ( t is proposed as follows: where 0 &lt; X  2.3. Odds Ratio
Odds Ratio (OR), as a feature ranking measure, has been adopted from relevance ranking in informa-tion retrieval [23]. OR is estimated as follows: low-DF fi lter to reject rare and obscure words. 2.4. Ranking measure based on F-measure
F-measure is widely used as feature ranking measure [7]. Let h be a single classi fi cation rule as follows: which implies an association between term j and class k , t in the vocabulary, Precision ( P and where P and (6) are read as P is de fi ned as follows: 2.5. Information Gain (IG)
Information Gain (IG) is one of the improved variants of mutual information. IG not only measures against the class c where P ( c document contains the term t all these probabilities can be estimated using document frequencies T Eq. (8) for all classes.
 2.6. Normalized Information Gain (NIG)
Using the entropy of term t Several formulations have been previously reported for normalizing information gain measure [21,28]. In the proposed NIG, the aim is to normalize the average information shared between a feature and classes by the information provided by the feature itself.

It means that by the proposed NIG, we bound IG measure to the weight of the term ( i.g. its document frequency). NIG ( t the average NIG, because NIG ( t uncorrelated with others. 2.7. The  X  2 statistic lack of independence between a term and a category. An estimation of  X  2 is as follows:
It should be noted that  X  2 values are normalized across a category, and can be compared as long as by applying a conservative Low Document Frequency (Low-DF) term elimination, usually  X  2 offers the best results of the different ranking methods. 3. Feature ranking performance
In order to compare feature ranking methods, they should be evaluated by a unique performance classi fi er performance is estimated by the macro-average F-measure [7].
 Using feature ranking, all terms are sorted from high to low according to a ranking measure  X  .Let T = { t function is  X  such that  X  : T  X  V where V = { v 1 ,v 2 ,...,v that  X  ( v 1 )  X  ( v 2 ) ...  X  ( v elements, respectively. The set of feature scores  X = {  X  ( v 1 ) , X  ( v 2 ) ,..., X  ( v is selected such that V q = { v where J is the macro-averaged F-measure of classi fi er h by employing features in the feature vector V employed. In this case, the average feature ranking performance with different threshold values are obtained.
 where Q is the set of threshold values and | Q | is its cardinal number. 4. Problem-dependency of feature ranking methods
Figure 1 illustrates the performance of eight feature ranking measures on three benchmark data sets not necessarily correlated. Some of them, such as Information Gain (IG) and Normalized IG (NIG) might feature ranking methods and data set characteristics.

Let T be the set of all distinct terms (single words) occurring in the training data D . According to the vector space model [26], each term is considered as a feature. Let  X  1 ,  X  2 ,...,and  X  ranking measures same as those described in Section 2. In a feature ranking measure  X  sorted from high to low according to the ranking measure  X  V challenging problem is to fi nd  X  V  X  V where V = { V 1 ,V 2 ,...,V
One approach, which is called meta-ranking technique, is estimating the performance of ranking mea-technique.

An alternative approach is combin ing ranked feature lists instead of running a competition over can-didate ranking measures. In this approach, each measure ranks the features and then a system for com-bining ranked feature vectors is implemented. In this paper, a combining system based on different combining and voting methods [2] is proposed to deal with data-dependency of feature ranking mea-sures. 5. Combining feature rankings
Decision combining and fusion have received lots of attentions in the fi eld of machine learning and fusion have been also employed in dimensionality reduction [32]. In [4], a voting scheme based on Borda Count is used for feature extraction.
 strategies and then combining the selected feature subset, the neglected features which have informa-based algorithms are combined using a set of voting schemes such as majority vote and decision tem-combined to generate a single feature subset.

In [34], a hybrid feature s election approach is proposed for a m achinery condition monitoring. The scored again by a weighted voting scheme. Next, by applying a wrapper including a Radial Basis Func-the proposed system is employed in a problem with 256 features which is considered low dimensional problem compared to text classi fi cation with thousands of features.
 In combining feature rankings, L given feature ranking vectors { V 1 ,V 2 ,...,V combined feature ranking vector F bining process. The major issue in this approach is to determine the combining scheme.
In multiple classi fi er systems, the most popular combining scheme is majority vote [11]. Along with majority vote, other operators such as minimum, maximum, average, and median have been also em-ployed [12].
 According to [11], decision fusion and combining strategies can be categorized into two classes: (i) of each individual expert. We call the fi rst strategy Soft-fusion and the second one Hard-fusion . 5.1. Combining based on hard-fusion
Feature ranking methods have two outputs including soft output which is called scores or quality mea-sures and their values are usually normalized between zero and one, and hard output which is the rank respectively. Since L m , majority voting does not work properly. Table 1 depicts an example of the ranking of ten terms with eight feature ranking measures. To combine different ranks of a particular feature, the elements of corresponding row are combined together. Due to the large number of candi-dates, we can not come up with a decision to choose the combined rank of each feature using majority combine the rankings.
 voting methods, including two Borda techniques are employed.

Let 0  X  feature j when using feature ranking method  X  voting is as follow: where F can be either or operator. 5.2. Combining based on soft-fusion
Alternatively, feature ranking score  X  where F might be any function such as MAX, MIN, ,and . In this paper, two soft-fusion operators are implemented including Mean, and Product. 6. Evaluation method
Although by combining ranked list of features instead of individual lists, the problem of selecting proper feature ranking measure has been resolved, it raises a new question: which combining method? In order to answer this question, we propose to employ evaluation measures which have been used in aggregation of document rankings in information retrieval [27]. Two metrics for comparing combining methods are employed in this paper: similarity metric and disagreement among rankings. 6.1. Similarity metric
In voting systems, the fi nal decision should have minimum overall distance with the opinion of all ings, should have minimum distance (maximum similarity) from (to) all contributing ranked lists. From Section 4, V = { V 1 ,V 2 ,...,V Overall similarity of combined ranked list  X  V to V is estimated as follows: one with maximum similarity with the individual rankings V is preferred. 6.2. Kendall-Tau disagreement measure
The Kendall-Tau measure is a metric to measure disagreement level of two ranked list. It counts the number of pairwise disagreement between two rankings [6].
 where i, j  X  X  1 , 2 ,...,m } , i&lt;j ,and V good combining method should have minimum overall disagreement with the original individual ranked lists V .
 The Kendall-Tau disagreement metric is also applied to the hard outputs of ranking measures. Because dimensional space could be expensive. In practical cases, we only compare small number of top ranked features for pairwise disagreement measure. 7. Experimental results
Three document data sets have been used in this paper (see Table 2). The data sets are well-known benchmark collections including Industry Sectors, 20 Newsgroups, and Reuters. All data sets are pre-processed by the Porter stemmer, and stopword reduction using a general stoplist. In few cases, empty or very small documents and classes containing less than three documents have been removed from the database.
Eight feature ranking measures including: F-measure, IG, NIG, Max(  X  2 ), Mean(  X  2 ), Max(OR), CDF, and IDF are examined in this paper. Two soft-fusion and two hard-fusion combining methods described in Section 5 are employed to combine the eight feature rankings. The result is four new combined rankings. A fi fth combining method, which aggregates four combined, ranked lists using Borda-sum technique, is also implemented. This combining scheme is called run-off voting method. is estimated using macro-average F-measure with fi ve-fold cross validation method.
The experiment is repeated for ten various ranking threshold. The performance of feature ranking methods is very different when small number of features is used. Also, in the case of higher thresh-similar. Because of these two reasons, and to distinguish any difference between ranking measure when where 1 q m .

In order to test the robustness of the combining feature ranking methods, the following experiments is set up. A robust combining system must perform similarly using diverse sets of voters. It means, under tougher conditions, in group four, random ranki ng is added to the eight original ranking mea-sures. Random ranking can play the role of irrational and unwise voter, which randomly votes for the candidates. In group fi ve, three random rankings are employed.
Figures 3 X 5 illustrate the performance of all combined feature rankings in fi ve scenarios along with some cases better than) the best single ranking method, which is IG ranking. The interesting point is their performance is almost independent of scenario which is using different groups of single ranking methods. The similar results are also obtained by using Rocchio classi fi er.

Performance of hard-fusion combining methods are dependent to the scenario, which means by ap-voters, the performance drops and approaches the poorest single ranking. Exactly similar pattern can also be found for other two data sets.

By averaging the performance of each feature ranking in Figs 3 X 5, the results are summarized in Ta-ble 4. For Industry Sectors data set, among the single feature ranking measures, IG outperforms other measures and IDF offers poorest performance. In the case of combined rankings, with different groups ity voters, hard-fusion methods (Borda-sum, Borda-Product, and run-off), offers better results, while similar patterns.

It should be noted that high quality voters are identi fi ed by domain experts. In our case, from the combining approaches. In other words, the proposed approach is a democratic voting system and voters (ranking measures) are not discriminated based on their quality.

The advantage of combining feature ranking is that it can select a set of features with a performance ious thresholds, which can be an expensive process. Among the fi ve combining techniques examined in this paper, soft-fusion methods including Mean and Product offered better results and guaranteed a dimensionality in machine learning problems in general and in text classi fi ers in particular.
Robustness of proposed combining feature rankings can be examined by using objective evaluation metrics. Table 5 depicts the result of similarity measure and pairwise Kendall-Tau disagreement mea-product shows better performance. Using similarity measure, we cannot draw any certain conclusion. though the Kendall-Tau metric indicates soft-product as the best combining method, the more important point is that it shows the robustness of the proposed method to combine feature rankings. 8. Conclusion
Feature ranking-based feature selection is a well-known dimensionality reduction method in text clas-the feature dependencies. More importantly it is highly data dependent which means it behaves dif-ferently from one data set to the other. Because of data dependency of feature ranking methods, it is presented for dealing with data dependency of feature ranking methods.

The proposed method was based on decision combining techniques. The candidate feature rankings are combined using a set of fusing operators categorized into soft and hard methods. According to the experimental results, soft-fusion combining methods such as Mean and Product can guarantee selecting proposed technique provides a framework to select features (via combining various candidate feature rankings) independent of not only the data set but also the classi fi er model.
 References
