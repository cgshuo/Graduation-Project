 process. Not only do we have to specify where the plant has to m ove to but also when it reaches that position. In some control schemes, the temporal compon ent is implicit; for example, with a the time horizon is set explicitly as a parameter of the probl em [8, 13].
 how should one choose these temporal parameters? This quest ion is non trivial and important even stationary task cost function and computes the control whic h minimizes the joint cost of movement not require sequential achievement of multiple goals. Alth ough this limitation could be overcome restricted to linear costs if we wish to remain time optimal. A second more important flaw is that which we highlight during our comparative simulation studi es.
 A wide variety of successful approaches to address stochast ic optimal control problems have been stochastic optimal control methods which have been success fully used in the domain of robotic ma-nipulators and in particular, the iLQG [9] algorithm used by [10], and the Approximate Inference the structure of the temporally non-stationary cost functi on used, which binds incurrence of goal We implement this general approach in the context of the appr oximate inference formulation of AICO, leading to an Expectation Maximisation (EM) algorithm where the E-Step reduces to the standard inference control problem. It is worth noting that due to the similarities between AICO, iLQG and other algorithms, e.g., DDP [6], the same principle and approach should be applicable more generally. The proposed approach provides an extensio n to the time scaling approach [12, 3] tionally, it also extends previous applications of Expecta tion Maximisation algorithms for system identification of dynamical systems, e.g. [4, 5], which did n ot consider the temporal aspects. Let us consider a process with state x  X  R D x and controls u  X  R D u which is of the form with non-linear state dependent dynamics F , control matrix B and Brownian motion  X  , and define a cost of the form find the policy  X  : x ( t )  X  u ( t ) given by leading to the discreet problem with dynamics Note that here we used the Euler Forward Method as the discret ization scheme, which will prove advantageous if a linear cost on the movement duration is cho sen, leading to closed form solution be used and indeed, be preferable. 2.1 Approximate Inference Control an auxiliary (binary) dynamic random task variable r Shaded nodes are observed. control consists of computing the posterior conditioned on the observation r a posteriori (MAP) controls. For cases, where the process and cost are lin ear and quadratic in u respectively, the controls can be marginalised in closed fo rm and one is left with the problem of computing the posterior with W := Q + BH  X  1 B  X  .
 (details are given in supplementary material). The algorit hm has been shown to have competitive performance when compared to iLQG [16]. Classically,  X  t are independent of time and incurred throughout the movemen t. In order to allow the time point at mapping from canonical to real time.
 the associated mapping with  X  as an additional control. We also reformulate the cost in ter ms of the time  X  as 1 L ( x ( ) , u ( ) ,  X  ( )) = with T an additional cost term over the controls  X  and the  X   X  for  X   X  cost term T over the new controls  X  which we have introduced. Note that in the special case where T is linear, we have R  X   X  N formulation of [11] used in an imitation learning setting.
 We now discretize the augmented system in canonical time wit h a fixed number of steps K . Making  X  the canonical time with an explicit dependence on  X  for some given  X  k an auxiliary binary dynamic random variable, we obtain the i nference problem illustrated by the LQG with linear duration cost. However, observing that for g iven  X  standard case of Section 2.1 suggest restricting ourselves to finding the MAP estimate for  X  the associated posterior P ( x T to reflect the temporal aspect of the optimization. 3.1 E-Step trajectories, given the current parameter values, i.e. the  X  i  X  X . However, as will be shown below we actually only require the e xpectations x during the M-Step. As these are in general not tractable, we c ompute a Gaussian approximation to 3.2 M-Step In the M-Step, we solve with posterior q i ( x hJ ( x k ) i and h log P ( x k +1 | x k ,  X  k ) i =  X  with e F ( x approximations choosing the mean of q i ( x independent of  X  , with  X  a  X 
In the general case, we can now use gradient ascent to improve the  X   X  X . However, in the specific case where T is a linear function of  X  , we note that 0 =  X  Q extremum under the constraint  X  3.3 Practical Remarks The performance of the algorithm can be greatly enhanced by u sing the result of the previous E-to restrict the  X   X   X  X  can be kept in a prescribed range by adjusting the number of discretization steps K after an M-Step.
 may be desirable to consider a cost directly over the duratio n T . Noting that T = P  X  The proposed algorithm was evaluated in simulation. As a bas ic plant, we used a kinematic simula- X  , (effectively the ratio between reaching cost and duration cost) on (a) duration and (b) reaching a fixed duration approach, i.e. AICO. small diagonal covariance.
 For all experiments, we used a quadratic control cost and the state dependent cost term: for some given  X  k x to the vector of end point positions and velocities in task sp ace coordinates. The time cost was linear, that is, T (  X  ) =  X  X  . 4.1 Variable Distance Reaching Task In order to evaluate the behaviour of AICO-T we applied it to a reaching task with varying start-the movement duration ( = P  X   X  (we used  X  and standard reaching cost for varying movement distances. In Fig. 2(c), we compare the reaching costs of AICO-T with those obtained with a fixed duration appr oach, in this case AICO. Note that are reduced for short movements, these movements necessari ly have up to 4  X  longer durations than those obtained with AICO-T. For example for a movement dista nce of 0.2 application of AICO-T results in a optimised movement duration of 0.07 (cf. Fig. 2( a)), making the fixed time approach impractical when temporal costs are considered. Choosing a short duration on the other hand (AICO by AICO-T in absence of this, there would have been no practic al way of choosing them apart simple scaling of duration with movement distance, in clutt ered environments and plants with more complex forward kinematics, an efficient decision on the mov ement duration cannot be based only on task space distance. 4.2 Via Point Reaching Tasks We also evaluated the proposed algorithm in a more complex vi a point task. The task requires the end-effector to reach to a target, having passed at some poin t through a given second target, the Figure 3: Comparision of AICO-T (solid) to the common modell ing approach, using AICO, (dashed) with fixed times on a via point task. (a) End point task space trajectories for two dif-dom start points. The proportion of the movement duration sp end before the via point is shown in light gray (mean in the AICO-T case). these movement distances and on the other, makes the implici t assumption that the two movements are in some sense independent.
 adjusting movement durations between sub goals in a princip led manner, and show that it improves upon the standard modelling approach. Specifically, we appl y AICO-T to the two via point problems eling approach and apply AICO to compute the controller. We a gain choose the movement duration for the standard case post hoc to coincide with the mean movem ent duration obtained with AICO-T two point target cost terms. Specifically, (18) takes the for m with K the number of discrete steps and diagonal matrices  X  most intuitive choice for the uninformed case as we have done here. Note that although for AICO-T Interestingly, although the end point trajectory for the near via point produced by AICO-T may look sub-optimal than that produced by the standard AICO alg orithm, closer examination of the incurred cost compared to un-optimised movement durations . The movement durations and reaching costs (control + error c ost) for 10 random start points. The mean proportion of the movement duration spend before the vi a point is shown in light gray. In order to highlight the shortcomings of sequential time op timal control, next we compare plan-ning a complete movement over sequential goals to planning a sequence of individual movements. Specifically, using AICO-T, we compare planning the whole vi a point movement ( joint planner ) to planning a movement from the start to the via point followed b y a second movement from the end the cost functions were given by appropriately splitting (1 9), i.e., V with  X  end target which is the main problem for the sequential plann er. The contribution of this paper is a novel method for jointly o ptimizing a movement trajectory and a goal horizon by hand is common practice but typically lacks justification.
 The method was derived in the form of an Expectation-Maximiz ation algorithm where the E-step ad-an LQG approximation, we can employ the Laplace method to obt ain Gaussian posteriors or adjust the M-Step for the non-Gaussian posterior. We demonstrated the algorithm on a standard reaching horizon methods and sequenced first exit time methods cannot find equally efficient motions as the proposed method. [1] David Barber and Tom Furmston. Solving deterministic po licy (PO)MDPs using expectation-[2] Marc Peter Deisenroth, Carl Edward Rasmussen, and Jan Pe ters. Gaussian process dynamic [3] Yu-Yi Fu, Chia-Ju Wu, Kuo-Lan Su, and Chia-Nan Ko. A time-scaling method for near-time-[4] Z Ghahramani and G Hinton. Parameter estimation for line ar dynamical systems. Technical [5] Z Ghahramani and S Roweis. Learning nonlinear dynamical systems using an em algorithm. [6] D Jacobson and D Mayne. Differential Dynamic Programming . Elsevier, 1970. [8] Donald E. Kirk. Optimal Control Theory -An Introduction . Prentice-Hall, 1970. [9] Weiwei Li and Emanuel Todorov. An iterative optimal cont rol and estimation design for non-[10] Djordje Mitrovic, Sho Nagashima, Stefan Klanke, Takam itsu Matsubara, and Sethu Vijayaku-[11] Peter Pastor, Heiko Hoffmann, Tamim Asfour, and Stefan Schaal. Learning and generalization [12] Gideon Sahar and John M. Hollerbach. Planning of minimu m-time trajectories for robot arms. [13] Robert F. Stengel. Optimal Control and Estimation . Dover Publications, 1986. [14] Emanuel Todorov. Compositionality of optimal control laws. In Advances in Neural Informa-[15] Emanuel Todorov and Michael Jordan. Optimal feedback c ontrol as a theory of motor coordi-
