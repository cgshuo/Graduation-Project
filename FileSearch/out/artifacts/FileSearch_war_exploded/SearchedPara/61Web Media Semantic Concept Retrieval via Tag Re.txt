 CHAO CHEN, QIUSHA ZHU, LIN LIN, and MEI-LING SHYU , University of Miami Recently, online social websites, such as Flickr and Picasa, have drawn lots of atten-tion not only from end users but also from commercial investors. There is a large demand to effectively search and retrieve desired Web media according to users X  inter-ests. Content-based retrieval methods commonly rely on those low-level or mid-level visual features to retrieve high-level multimedia semantic concepts, but they typically suffer from the so-called semantic gap issue, which is known as  X  X he lack of coincidence between the information that one can extract from the visual data and the interpreta-tion that the same data have for a user in a given situation X  [Smeulders et al. 2000]. On the other hand, Web media, such as images on the websites, are usually attached with user-defined tags describing the content of the images, location, users X  feeling, etc. Hence, tags can be utilized to facilitate image search and retrieval since they suffer less from the semantic gap issue and, at the same time, can be treated as high-level semantic concepts. Thus, it motivates us to use these tags as features to train tag-based models in addition to the traditional content-based retrieval models.

However, the user-defined tags are often incomplete and imprecise since they are subject to users X  perspectives, and thus some of them may not reflect the whole content or even are irrelevant to the actual content presented in the images. For example, a couple uploading an image recording their ten-year anniversary of marriage at Key West could add the tags  X  X ey west X ,  X  X nniversary X ,  X  X cean X  together with the other tags on the image. However, some users may be only interested in the tag  X  X cean X  and do not care about the others. In other words, there may exist many tags that do not reflect the actual content of an image. Cantador et al. [2011] categorized social tags into four categories based on users X  intentions, namely, content-based (describing the actual content), context-based (providing information such as when and where a photo was taken), subjective (expressing opinions), and organizational (defining personal usages and tasks). From the perspective of content-based image retrieval, only those tags that describe the image content are the focus of this article and those tags that fall into the other three categories are considered as trivial tags, which could result in poor learning models and thus compromise the retrieval performance. On the other hand, removing these trivial tags by human efforts is practically unaffordable and infeasible, considering that a huge amount of images are uploaded on the Web every day.
In response to the aforementioned issues, effective and efficient methods for auto-matic tag removal and tag filtering to convert the tags into useful features have been urgently sought recently. Based on the visual similarity derived from the low-level fea-tures in the images, tags can be ranked and selected [Zhu et al. 2010]. However, such tag ranking and selection methods suffer from the semantic gaps between the low-level features and semantic concepts, as indicated earlier, because low-level features cannot justify whether or not the presence of certain tags in an image is reasonable. Since tags are closely related to the high-level concepts, it motivates us to develop an approach to rank and select the tag features based on their relevance to the semantic concepts and filter out those weak-correlated tags. For example, if a semantic concept retrieval task aims to retrieve the images containing the concept  X  X ree X  (the concept  X  X ree X  now be-comes the target concept, i.e., the concept to be retrieved), it is more desirable that the tag features relevant to the target concept, such as  X  X eaves X  and  X  X reen X , are retained; while those irrelevant tags, such as  X  X oad X  and  X  X ark X , are discarded.

In this article, a novel multiple correspondence analysis (MCA)-based tag removal method is proposed. MCA is a technique that measures the correlations among multiple variables [Greenacre and Blasius 2006]. It can be considered as an extension of the standard correspondence analysis (CA) to more than two nominal/categorical variables. MCA [Salkind 2007] has been proved able to capture the correlations among nominal variables effectively. Tags inherently have nominal representations (a tag is present in an image or not). Therefore, the correlation between each tag and the target concept is suitable to be measured by MCA.
 Once the tag features are available, it comes to the problem of utilizing them. Kennedy and Naaman [2008] tackled the problem of automatically generating the image representation for the landmarks by first using tags and location metadata to detect tags and locations that represent landmarks, and then applying visual analysis to the images associated with the detected tags and locations. The computational cost is greatly reduced since visual analysis is only applied to a subset of images that are filtered by the tags. However, targeting at improving the retrieval results, current research studies fuse visual features with tags features since they may contain comple-mentary information to each other. There are broadly two categories of fusion, and we briefly list them as follows. The first category concatenates both content-based features and tag features before training the models, which is often known as early fusion .For example, Crandall et al. [2009] adopted early fusion to combine the visual features and tag features. Their experiments on 35 million images collected from Flickr demon-strated that the classifiers trained by the combined features are significantly better in a statistical manner. The methods belonging to this category are simple and effective in some cases, though they increase the dimensionality of the features. The drawbacks of those methods fall into two aspects. First, early fusion increases the computational cost and requires a larger space to import all the features. Second, the excessively large dimensionality could lead to the so-called  X  X urse of dimensionality X  issue.
To focus more on efficiency, the other category of fusion methods build models for different modalities and combine them together using their class labels or ranking scores (or called soft labels). In contrast to the fusion methods in the first category, the methods of the second category are called late fusion as a fusion process is applied after training the models. In the case of searching and retrieving images from Internet sources, where millions of images are available, early fusion is practically infeasible, but late fusion works well. Therefore, in this article, a late fusion method is proposed to fuse the models trained by the content-based features and the tag features. In traditional fusion methods, ranking scores may be directly combined together, such as taking the minimum/maximum values from all models, which might result in the ranking scores from one model dominates the others, compromising the idea of applying fusion to integrate useful information from all models. In addition, some commonly-seen fusion methods, such as taking the average/median values from all models, fail to consider the reliability of the ranking scores generated by different models. However, such information may contribute to the improvement of the retrieval performance of the semantic concepts. Some recent fusion methods [Wu et al. 2004] built linear/nonlinear models by learning the weights from the training set to combine the ranking scores from a number of models. Lustgarten et al. [2008] pointed out that the numeric ranking scores could be inaccurate, while a range of ranking scores could eliminate inaccuracy to some extent. Based on our empirical study and observations, we believe that utilizing a set of ranges/intervals of the ranking scores, instead of using individual ranking scores, can better guide the fusion process. Thus, we discretize the ranking scores into several intervals/ranges to identify those strong-correlated intervals for our proposed fusion strategy.

In our proposed method, the ranking scores from different models are balanced by introducing an adjusted parameter. Furthermore, the reliability of the models (i.e., how accurately a model can retrieve a concept) is also taken into consideration. Finally, the ranking scores within the same model are partitioned into several intervals, where each interval may have different correlation values toward the target concept class. Those correlation values serve as the weights in the fusion models, which may vary for the ranking scores within the same model if they are located in different intervals. In this way, our proposed fusion method is able to capture more useful information than the other fusion methods and is expected to provide better fusion results by considering both the global characteristics (such as the reliability of a model) and the local characteristics (such as the correlation between an interval and a concept) of an individual model.

The rest of the article is organized as follows. Section 2 briefly reviews previous work on noisy tag removal and model fusion. Section 3 describes our proposed framework in details, including the proposed methods to remove noisy tags and to fuse different ranking models. Experimental results and discussions are presented in Section 4. Finally, Section 5 concludes this article. The peer work related to noisy tag removal is discussed in Section 2.1, and the related model fusion methods are presented in Section 2.2. Semantic concept retrieval frameworks which use noisy tags to boost the performance of content-based retrieval for social Web images have been widely developed in recently years [Lienhart et al. 2009; Ma et al. 2010; Tang et al. 2009].

One direction is to use visual content to remove noisy tags. Li et al. [2009] proposed a neighbor voting algorithm which accumulated votes from visual neighbors for learning tag relevance. Under the condition that the probability of correct tags is larger than the probability of incorrect tags and content-based visual retrieval is better than random sampling, they showed that the retrieval performance with the refined tags obtains 24 . 3% gain in terms of mean average precision compared with that using the original tags with noise. Lee et al. [2010] discussed a tag removal technique that differentiated noisy tags from correct ones through the combined use of visual similarity and tag cooccurrence statistics. Experiments on the user-contributed images retrieved from Flickr showed that their proposed tag refinement technique reduced the number of noisy tags by 36%, at the cost of removing 10% of the correct tags. All of these content-based noisy tag removal approaches are based on the assumption that those images with the same tags hold strong visual similarity. However, Yu and Tian [2008] indicated that such an assumption might not hold for some cases. Moreover, those proposed frameworks have difficulty scaling to a very large image corpus since their iterative optimization process requires loading the whole visual similarity matrix into memory, whose size quadratically increases with the number of images. Thus, it may be difficult to apply their framework to the semantic concept retrieval on a large image corpus.
The other direction is to use text mining techniques or feature selection methods to identify representative and discriminative tags from the whole tag set. De Meo et al. [2009] proposed a probabilistic technique for determining the similarity and the generalization degrees of two tags. It allows the users to visualize tags of their interests according to desired semantic granularities and helps them find those tags best expressing their information needs. Specia and Motta [2007] also focused on the relationships amongst tags and clustered the tags based on their cooccurrence after basic clean up. Among various methods, TF-IDF (term frequency-inverse document frequency) is the most widely used one. Considering in most cases, a tag is assigned to any image at most once, so the TF value of the tag for an image is either 0 or 1. Thus, TF-IDF now becomes IDF. Wang et al. [2010] argued that IDF is not reasonable for use in text categorization and introduced inverse category frequency (ICF) as a supervised term weighting scheme. Evaluations of four weighting schemes, including TF-IDF, ICF, and two other methods, showed that ICF outperformed the other three in terms of F1 measure on average. The assumption of ICF is that the terms appearing in fewer categories have a larger discriminative ability. Therefore, for each tag t k ,an ICF score is calculated according to Equation (1).
 where | C | is the total number of concepts and cf k is the number of concepts that tag t k occurs. For example, if t k occurs in ten concepts, then cf k equals ten.

Traditional feature selection methods can also be used to reduce tag feature di-mensionality, such as principal component analysis (PCA). As the roles of the users become more and more important, another dimension, users, is added into the origi-nal two-dimension problem which only involves images or items and tags. Symeonidis et al. [2008] proposed a unified framework to represent the three types of entities in a social tagging system, which are users, items/images, and tags as a third-order tensor. The latent semantic analysis and dimensionality reduction were performed us-ing the higher-order singular value decomposition (HOSVD) technique to reveal the semantic association between users, items, and tags. If only two dimensions are con-sidered, HOSVD is essentially simplified to singular value decomposition (SVD). Li et al. [2011] presented a more general algorithm based on HOSVD for indexing and re-trieval of higher-order tensor data obtained from a multi-camera system. Experiments showed that their approach could be used to handle a query structure consisting of an arbitrary number of objects, cameras, and modalities. A pairwise interaction tag factorization (PITF) model is presented [Rendle and Schmidt-Thieme 2010] to model pairwise interaction between users, items, and tags. PITF has a linear runtime for both learning and prediction, thus making it more feasible for midsized and large datasets.
Since the focus of this article is to improve the performance of image retrieval by utilizing tags associated with the images, it is a 2D problem which does not need to take users into account. Our proposed MCA-based tag removal algorithm is there-fore designed to filter out tags according to their correlation with the target concept. Compared to the methods based on projection (e.g., principal component analysis) and compression (e.g., information theory) [Saeys et al. 2007], the advantages of MCA-tag removal lie in two aspects. First, the semantics of the concept can be captured in a more intuitive way. The retained tags can be easily interpreted according to their meanings. Second, tags are usually represented by a value 0 or 1 to indicate their presence in the images, and such a representation is rather sparse. MCA-tag removal preserves this sparse structure of the image-tag (or item-tag) relationship, which is very efficient when training models based on tag features. To integrate the content-based and tag-based information, most of the existing ap-proaches that adopt late fusion used various ways of combining the results from sev-eral models trained by visual and tag features. The straightforward fusion method is to apply the product, minimum, maximum, average, or median rule, which can be considered as the special case of a generic fusion model. Suppose there are M models that produce the posterior probability P m ( w | x n ) as ranking score, where w is the target concept and x n stands for the n th instance. The generic model is shown in Equation (2). The average rule is where  X  n ( x n ) = 1 / M . For the maximum rule,  X  n ( x n )isshownin
Fusion rules like minimum and median can also be written in a similar manner. The majority voting rule is only applicable when the class labels of the concept are available. The product rule, though a little bit complicated, is still able to be represented by such a generic model, in which  X  n ( x n ) is shown in Equation (4). Some other fusion models, like those of Wu et al. [2004], are also a special case of Equation (4), but their  X  n ( x n ) cannot be decided until the training process is finished.
A theoretical analysis of the aforementioned fusion models can be found in Kuncheva [2002], which estimated the theoretical error in terms of classification accuracy. There are also complicated model fusion methods based on fuzzy rules, the belief function, and Dempster-Shafer theory. Moreover, some work (e.g., [Wu et al. 2004]) used the outputs of the models as new features to train a super model to perform fusion. In our proposed fusion method, we also consider the outputs of the models as new features and derive their weights from the training data instances. However, intervals are partitioned on ranking scores considering that each partition will have a different correlation towards a target concept, which reflects the data characteristics of the instances located within each interval. In this manner, a new data-dependent fusion method is designed to utilize more detailed information provided by the training models. In addition to the previously mentioned fusion methods, multiple kernel learning (MKL) [Gehler and Nowozin 2009] was proposed and utilized in image classification [Yang et al. 2009]. Different from the aforementioned late fusion methods that fuse the scores/labels generated by learning models, MKL performs fusion on the kernel level, which is more like a learning method than a fusion method. Figure 1 shows the overview of our proposed framework. The Web media, such as images from online image corpus, are accompanied with a number of tags. In the tag-based model, the tags are considered as features, but only a subset of tags after noisy tag removal is used. In the content-based models, the visual features of an image are extracted. Since the visual feature extraction is beyond the scope of this work, we adopted those commonly extracted features, such as color histogram and wavelet texture. The low-level visual features are used by subspace-based modeling methods to train the content-based retrieval models and those filtered tag-based features are used by LibSVM (Section 3.3) to generate the tag-based retrieval model, as shown in Figure 1. Later, a model fusion step fuses the ranking scores from the content-based models and the tag-based model and then learns a way to combine those ranking scores. For each testing image, its visual features and the tags are the inputs to the trained content-based and tag-based models, and the generated fusion scores from the fusion process are used to rank the testing images according to the query concept. The main novelty and contributions of this article are summarized as follows.  X  X  novel MCA-based noisy tag removal method is proposed that adaptively filters out tags that have weak correlations with a target concept (Section 3.2). To our best knowledge, this is the first attempt to use MCA in tag removal.  X  X  novel model fusion method is developed, which includes the adjustment of the ranking scores at different scales, the reliability of the ranking models, and the cor-relation of each interval within the ranking scores to a target concept (Section 3.4). To our best knowledge, such a fusion strategy that considers the factors of adjustment, reliability, and correlation altogether is also a new attempt in model fusion.  X  X  novel framework is proposed that integrates the content and tag information and the corresponding content-based and tag-based models for semantic concept retrieval. MCA is adopted to measure the correlations between tags and concept classes. The concept class stands for the class label (either 0/negative or 1/positive) of a concept, and an image with class label 0 means that the concept does not exist in the image, while class label 1 means that the image has the concept in it. The tag features can be either 1 or 0, which are called feature-value pairs in our study. The tag features of the images are represented in a two-dimensional image-tag matrix TG in which each element TG ng in TG is defined in Equation (5).

The aim of the proposed tag removal method is to filter out noisy tags, meaning the tags having weak correlations with the concept classes. Ideally, the remaining tags could predict the class label of the target concepts better. Tag features are nominal values, so MCA can be directly applied to produce the correlation of each feature-value pair of a tag feature with a concept class. Details of the MCA technique and the way to generate such correlations can be found in Lin et al. [2011]. The objective of applying MCA is to represent the maximum possible variance of a feature regarding to the concept class in a map of a few dimensions. Usually, the first two dimensions could capture over 95% of the total variance. In some cases, one dimension is enough, while in other cases, more than two dimensions are preferred. So instead of using the fixed first two dimensions, as in Lin et al. [2011], the number of dimensions is automatically decided that can well capture the variance in this article.

The graphical representation of MCA, called the symmetric map , can be used to visualize the feature-value pairs of a feature and the classes as points in a map with the dimensions depending on the number of principal components. Thus, the correlation between a feature-value pair and a concept class can be measured by the cosine value of the angle between the two vectors representing the feature-value pair and the concept class. Figure 2 shows a two-dimensional symmetric map in which there are a tag feature F with two feature-value pairs F 1 i and F 2 i , a tag feature F j with two feature-value pairs F j and F between feature-value pair F 1 i and the concept class C 1 ,and a 2 i 1 is the angle between the feature-value pair F 2 i and the concept class C 1 . If a feature-value pair is correlated with a class, then the other feature-value pair is negatively correlated with this class to cosine value indicates a strong correlation between a feature-value pair and a class. As shown in Figure 2, the angle between F 1 i and C 1 is smaller than the angle between F 2 j and C 1 . Thus, the tag feature F i has a larger correlation with the classes than F j .
The NUS-WIDE-LITE dataset provides 1,000 tags for both training and testing sets. In the 81 concepts, the names of the 76 concepts exist in the 1,000 tags, which means these 76 tags are regarded as class labels for these concepts. Thus, for each of these 76 concepts, the rest of the 999 tags are used as the tag-based features. On the other hand, for the five concepts (namely computer, fire, swimmers, tattoo, and whales) whose names are not in the 1,000 tags, all the 1,000 tags can be used to train the model. More detailed description of NUS-WIDE-LITE can be seen in Section 4.1. Since MCA performs SVD on a very low-dimensional matrix (4  X  4 in this case) to each feature at a time, the complexity of performing MCA on 1,000 features is still much lower compared to PCA-based methods which involve solving SVD on a large matrix (27,807  X  1,000 in this case). This advantage will be more obvious as the number of features increases.
During the training step, those tags with relatively small correlations with the classes (meaning the absolute values of the cosine values are smaller than a pre-defined threshold value) are discarded, and the remaining tag features of the training images are used to train the tag-based model. While in the testing step, the retained tag features of the testing images are fed into the tag-based model to generate the ranking scores. The selection of the threshold for our MCA-based tag removal (MCA-TR) algorithm is dynamically determined by searching the one that yields the best retrieval performance on the training set in terms of average precision. In the proposed framework, a subspace-based modeling method is used to train the content-based models using visual features (color histogram and wavelet texture in our experiments) of the training images. The subspace-based modeling method transforms the training and testing data from the original space to the principal com-ponent subspaces, where the dimensionality of the data instances is reduced and the time to train the model is also shortened.
 We use the subspace-based modeling method used by Lin et al. [2011] in this study. The difference of the subspace-based modeling method used in this article with the one proposed in Lin et al. [2011] is that the final ranking score P ( w |  X  ) is generated via Equation (6).
 where SP (  X  ) is interpreted as the score of an instance  X  derived from the relevant subspace model which is built from the instances containing the target concept, and SN (  X  ) is the score of an instance  X  calculated from the irrelevance subspace model that is built from the instances without the target concept. The detailed process to get scores SP (  X  )and SN (  X  ) can be seen in Lin et al. [2011].

The difference between the tag features and the visual features is that the tags are binary variables rather than real-valued variables. Therefore, an analysis on their mean and standard deviation is meaningless. For the tag-based model, LibSVM [Chang and Lin 2011] with Radial Basis Function (RBF) kernel is adopted to train a tag-based model from the input tags, since the RBF kernel is commonly used in multimedia domain and usually gives better performance than the other kernels. The confidence of the output from LibSVM is the probabilistic estimation that an instance is relevant to the query (target) concept, which is used as the ranking score for our tag-based learning model. The purpose of model fusion is to achieve a performance gain from all individual models. In the proposed fusion strategy, the form of the generic model is adopted, since most fusion methods can be generalized into this form. Besides, the output values of a probabilistic fusion model are bounded between 0 and 1. Here, a few intuitive parameters closely related to the final retrieval performance are defined.  X   X  . An adjusted parameter to balance the ranking scores from different models. The reason why we introduce this parameter is that the ranking scores from diverse models could have a wide range of values, even if they use the same modeling method.  X   X  . The reliability of a model to the final retrieval performance. This parameter re-veals the retrieval performance of the learning models from the view of the training instances. Intuitively, the model with good performance on the training set should be assigned a relatively large weight value.  X   X  . The correlation of an interval of scores from a ranking model to the target concept.
Within the same model, the scores are distributed within a certain range. In the case of utilizing probabilistic estimation as the ranking score, the range of scores is between 0 and 1. In the case that the range is partitioned into several intervals, where each interval is disjoint with each other, the different correlation values between each interval and the target concept imply the way that the scores from different models should be combined at an interval level. For example, a large correlation value between an interval of a model and the target concept indicates the instances falling into the intervals of that model should have a large weight.
 Based on these intuitive parameters, our proposed fusion model is shown in Equation (7), given a testing image x . Again, assuming there are M models that pro-w is the target concept, and x n stands for the n th instance. The adjusted parameter  X  m is used to balance the ranking scores from different models at different scales (e.g., the ranking scores of one model might be between 0 to 0 . 001, but the ranking scores of another model could vary from 0 . 9 to 1). Besides, since  X  m and  X  m are both important parameters, a harmonic balance is made between  X  m and  X  m in Equation (7).
The values of these parameters are driven by the images in the training set.  X  m is introduced to prevent large ranking scores from dominating the small ones in our framework and is defined as the mean value of the ranking scores of x from all M models. The value of  X  m is set to be the average precision of the m th model evaluated on the images in the training set. The method to decide  X  m is as follows. First, the ranking scores of the training instances generated from the m th model are treated as a numeric feature, and the ground truth of the training instances are treated as class labels. Then, the ranking scores are discretized into nominal values (one interval is represented by one nominal value) using a supervised discretization method named information entropy maximization (IEM) [Fayyad and Irani 1993].

Next, MCA is applied to capture the correlation between each nominal value (repre-senting an interval of the ranking scores) and the target concept. In other words, MCA is used to measure the correlation between each interval generated on the ranking scores and the concept class. As shown in Figure 2, the cosine value of the angle be-tween an interval of the ranking scores and the concept class is used to measure their correlation whose value is between  X  1 and 1. For a testing image x , the correlation between its ranking score from the prediction model and the target concept can be calculated by looking up which interval the ranking score falls into. If its correlation value is denoted as MW I ( x ) ( w ), where I ( x ) is the score interval a testing instance x falls into,  X  m is calculated by Equation (8), which ensures the range of the correlation value from 0 to 1 so that it is qualified to have probability meaning. The final score of x is the ranking score from M models combined in the way given by Equation (7). To evaluate the effectiveness of our proposed framework and related components, ex-tensive experiments have been conducted on two real-world datasets originated from the social website Flickr. The framework is evaluated against some prevailing compar-ative algorithms as well as the results reported by the other research groups. The datasets used here include a light version (NUS-WIDE-LITE) and a full version (NUS-WIDE-270K) of the NUS-WIDE dataset [Chua et al. 2009]. In the NUS-WIDE-LITE dataset, there are in total 55,615 images with associated tags crawled from the Flickr website. The images from the NUS-WIDE-LITE dataset have already been divided by the dataset provider into training and testing sets in advance, where 27,807 images are used as the training set and the testing set is composed of the rest 27,808 images. The dataset provides some low-level features that have already been extracted from the original images, including color histogram, wavelet texture, etc. The low-level features used here in this article are 64-dimensional color histogram in LAB color space and 128-dimensional wavelet texture, which are the basic features that are commonly extracted to analyze the content of images. NUS-WIDE-LITE also provides the ground truth of 81 concepts as well as 1,000 frequent tags.

The detailed information of the NUS-WIDE-LITE dataset is shown in Figure 3, consisting of the names of the 81 concepts (horizontal axis) and their corresponding P/N ratios (the ratios of the number of positive instances to the number of negative instances) of both training and testing sets (vertical axis). For example, the P/N ratio of the concept  X  X ree X  in the training and testing sets are both lower than 0 . 025. It can be seen from this figure that most of the concepts are very imbalanced in that the number of positive images (images containing a target concept) divided by the number of negative images (images without a target concept ) is smaller than 0 . 05. This is very challenging in the area of multimedia semantic information retrieval.

The NUS-WIDE-270K dataset contains 269 , 648 images with tags, and it is the origi-nal dataset from which the NUS-WIDE-LITE dataset is constructed. Like NUS-WIDE-LITE, the provider splits the whole dataset into a training set (161 , 789 images) and a testing set (107 , 859 images), extracts low-level features including color histogram, wavelet texture, etc. from the images, and provides the 1,000 tags and the ground truth labels of 81 concepts for all images. The low-level features used in our experiment on this NUS-WIDE-270K dataset are the same as those used on the NUS-WIDE-LITE dataset. The P/N ratios of all 81 concepts in NUS-WIDE-270K are shown in Figure 4.
It is worth mentioning that the characteristic of NUS-WIDE-270K is rather different from NUS-WIDE-LITE in terms of the P/N ratio. The NUS-WIDE-270K dataset is far more imbalanced than NUS-WIDE-LITE. For example, the P/N ratios of the concept  X  X each X  in the training set and the testing set of the NUS-WIDE-LITE dataset are both close to 0 . 1. However, these two ratios are far below 0 . 1 in the NUS-WIDE-270K dataset. As can be seen from Figure 4, the P/N ratio of many concepts in the NUS-WIDE-270K dataset are close to 0. Besides, the size of the NUS-WIDE-270K dataset is about five times larger than the NUS-WIDE-LITE dataset. Therefore, the evaluation on the NUS-WIDE-270K dataset is expected to be more challenging and interesting. To systematically evaluate the proposed framework with regard to the three proposed contributions, we design our experiments sequentially by applying evaluation on (1) the proposed tag-removal method, (2) the proposed model fusion method, and (3) the over-all framework. First, the performance of our proposed tag-removal method against peer methods is evaluated on the training/testing split (denoted as one-split) offered by the provider on both the NUS-WIDE-LITE and the NUS-WIDE-270K datasets.
 The precision-recall curve is also given for all tag remove methods to show the better performance of our proposed MCA-based tag removal methods than the other compar-ative approaches in more detail. For the NUS-WIDE-LITE dataset, we further conduct experiments by comparing our proposed tag-removal method with best comparison methods using three-fold cross-validation on the NUS-WIDE-LITE dataset. In addi-tion, the experiments of five times three-fold cross-validation are conducted to show the significance of our proposed method.

To show the effectiveness of the proposed fusion method, our fusion method is eval-uated against several well-known fusion approaches on the NUS-WIDE-LITE and the NUS-WIDE-270K datasets. Also, significance tests on the proposed fusion method against its best peer methods are conducted on the NUS-WIDE-LITE dataset. Finally, the performance of the proposed framework is compared with the constructed frame-works using a combination of noisy tag removal and model fusion as well as those results reported by the other research groups by using diverse frameworks.
The major criterion for, evaluating the performance is mean average precision (MAP), which is the mean of the average precision (AP) of all concepts, shown in Equation (9).  X  I + is the number of relevant images with respect to the query (target) concept.  X  N is the number of retrieved images.  X  r o is defined in Equation (10). The evaluation of the tag removal method is performed among several methods, in-cluding a state-of-art method proposed by Zhu et al. [2010] (LR ES CC TC), a baseline method that adopts inverse category frequency (ICF) introduced in Section 2 and a sin-gular value decomposition (SVD) method. We tuned the parameters of LR ES CC TC to fairly compare it with our MCA-based tag removal (MCA-TR) algorithm. For the baseline method ICF, based on our empirical study, its best performance (which) could be achieved by keeping those tags with ICF scores larger than 0 . 7 (i.e., those tags occur-ring in fewer than 50 concepts). This 0 . 7 is calculated using Equation (1) with | C |= 81 and cf k = 50. In the comparative SVD method, we keep all nonzero eigenvalues based on an empirical study on the training sets and then the transformed training and test-ing data are used to evaluate the retrieval performance. For MCA-TR, we search the optimal threshold for MCA correlation on each training set from 0 to 0 . 1 with a step size of 0 . 02 on the NUS-WIDE-LITE dataset and from 0 to 0 . 25 with a step size of 0 . 05 on the NUS-WIDE-270K dataset.
 The mean average precision values of all the four methods on the NUS-WIDE-LITE and the NUS-WIDE-270K datasets are shown in Tables I and II, respectively. It shows that our proposed MCA-TR algorithm overall outperforms the other two methods from 0 . 63% to 8 . 7% on the NUS-WIDE-LITE dataset, and from 0 . 57% to 7 . 85% on the NUS-WIDE-270K dataset. We have also conducted significance tests to show how significantly our proposed MCA-TR outperforms the best peer method (see Table VII for details). Please note that although the result from LR ES CC TCisclosetoours, a lot of effort was spent on tuning its parameters to get the best result. However, our tag removal algorithm does not need to tune any parameters, since the MCA threshold corresponding to the best MAP on the training set is automatically selected, and it can dynamically remove trivial and irrelevant tags according to the target concept. Besides, although the SVD-based method is slightly worse than our proposed method, it takes much longer time to train the learning model on the transformed training and testing data given by the SVD-based method, since the transformed data have lost the sparsity characteristics in the original image-tag matrix (like TG ).

The precision-recall curves of all the four methods are shown in Figure 5(a) (for the NUS-WIDE-LITE dataset) and Figure 5(c) (for the NUS-WIDE-270K dataset). Figures 5(b) and 5(d) show the precision-recall curves of the concept  X  X rass X  on the NUS-WIDE-LITE dataset and the concept  X  X ater X  on the NUS-WIDE-270K dataset as examples, which show that the performance of the MCA-TR method is better than the other comparative approaches.

We also observed in our experiment that the threshold for our MCA-TR algorithm is 0 for a number of concepts, which indicates that it is unnecessary to remove tags from the original tag set for these concepts. For the NUS-WIDE-LITE dataset, there are 23 concepts whose MCA correlation thresholds are greater than 0. Therefore, we further show the results of the 23 concepts whose tags actually have been filtered by MCA-TR. Figure 6 shows the ratios of the retained tags to the total tags after MCA-TR is applied. As can been seen from Figure 6, the concepts such as  X  X astle X ,  X  X oral X , and  X  X oon X  only retain less than 15% of the tags, which means more than 85% of the tags are removed for these concepts. That is very promising in terms of reducing computational cost and saving storage space. Table III further summarizes the average MAP improvement and the average number of tags retained before and after using MCA-TR. The results clearly show that our proposed MCA-TR can averagely increase the MAP values at about 2 . 6% for those selected 23 concepts, while the size of retained tag set can have about 75% reduction.

For the NUS-WIDE-270K dataset, there are 46 total concepts whose tags are actu-ally filtered by MCA-TR. Therefore, we further show the results of these 46 concepts before and after MCA-TR is used. The retain ratios of these 46 selected tags before and after MCA-TR is applied are shown in Figure 7. Table IV further summarizes the average MAP improvement and the average number of tags retained before and after using MCA-TR. Although the MAP of these 46 concepts only have a little improvement after MCA-TR, the dimensionality of the tags has reduced by more than 2 / 3. Consid-ering the size of the NUS-WIDE-270K dataset, such a reduction in the dimensionality of the tags will significantly decrease the computational cost related to model training as well as the demand for the storage space.

To further reveal the effectiveness of the proposed MCA-TR method against other comparative approaches, three-fold cross-validation is conducted on the NUS-WIDE-LITE dataset. The experimental results are shown in Table V. As can be seen from the results, MCA-TR can still outperform the other approaches in terms of MAP. For those concepts that have been refined by MCA-TR, the average retained tags before and after applying MCA-TR are shown in Table VI, which indicates that the proposed MCA-TR method achieves about 1.5% MAP gain, and at the same time removes around 75% tags. Furthermore, in order to demonstrate how significant our proposed MCA-TR method is, five times threefold cross-validation experiments are conducted. The results after the student t-test is applied to the MCA-TR and SVD (singular value decomposition) methods are shown in Table VII. As can be seen from this table, MCA-TR can provide significantly better results than SVD, since the one-tail p-value is close to 0 and the confidence level is almost 1.
 The proposed model fusion method is evaluated against several methods, including four fusion methods using minimum (min), maximum (max), median, and average rules. Here, majority voting is not included since it requires hard decision on class labels. The super kernel fusion (SKF) method [Wu et al. 2004] introduced in Section 2 is also compared with our proposed fusion method that considers adjustment, reliability, and correlation of the intervals to the target concept (called ARC). Each fusion method is applied separately on the ranking scores of the testing images rendered by our two content-based models (one built from color histogram and the other built from wavelet texture using subspace classifiers), as well as the tag-based model (the SVM model built on the tags kept by MCA-based tag removal method). The ranking scores of the training images are also provided to SKF and ARC, since both of them require the use of the ranking scores of the training images to decide the weight parameters. The comparative experiment results evaluated on the NUS-WIDE-LITE dataset are shown in Figure 8(a). It can be observed from this figure that the proposed model fusion method outperforms the comparative approaches by more than 2% X 20%. Median fusion gives the worst performance, and our proposed method can outperform it by 20%. SKF produces the second best result but is still 2% lower than ARC. The min fusion method shows fairly good result and is better than the average and max fusion methods. Figure 8(c) shows the comparison result of all fusion method on the NUS-WIDE-270K dataset. The results are in accordance with the results from NUS-WIDE-LITE, except max fusion renders the worst result instead of median fusion. ARC can still outperform SKF by 1% and max fusion by 13% on average of 81 concepts. We further plot the MAP values at different scales in order to show the effectiveness of our proposed model fusion method against other peer methods. The results evaluated on NUS-WIDE-LITE dataset and NUS-WIDE-270K dataset are shown in Figures 8(b) and 8(d), respectively. It can be observed from Figures 8(b) and 8(d) that ARC is able to render the best retrieval performance at all retrieval depth, such as first 5, 10, 20, etc.
For the NUS-WIDE-LITE dataset, the MAP values of ARC are more than 90% for the first 5, 10, and 20 retrieved results over 81 concepts and can still reach almost 74% for the first 100 retrieved results. For the NUS-WIDE-270K dataset, the MAP values of ARC are more than 80% for the first 5, 10, and 20 retrieved results and can reach almost 72% for the first 100 retrieved results. These results are very promising due to the fact that the users are most interested in the top retrieved results. Furthermore, although the NUS-WIDE-270K dataset is more imbalanced and much larger than the NUS-WIDE-LITE dataset, which means the concept retrieval on the NUS-WIDE-270K is more challenging, the MAP values on the NUS-WIDE-LITE and NUS-WIDE-270K datasets at the first 150 retrieved results become very close, and the first 200 retrieved results are almost the same. These results demonstrate the ability of our proposed fusion method to handle large datasets.

We also conduct five times threefold cross-validation to evaluate the performance of the proposed ARC method against the best peer method, namely, SKF (super kernel fusion). Again, student t-test is employed to calculate the one-tail p-value and confi-dence level, which are shown in Table VIII. As shown in this table, the p value is less than 0 . 001 and the confidence level is almost 1, which indicates that the proposed ARC method is able to outperform SKF significantly. There are also many research studies dealing with semantic information retrieval on the NUS-WIDE-LITE and NUS-WIDE-270K datasets, and several results were re-ported in previous work by using the K-nearest neighbor (KNN) model [Witten and Frank 2005], LibSVM model [Witten and Frank 2005], linear neighborhood propa-gation (LNP) [Wang and Zhang 2008], entropic graph semi-supervised classification (EGSSC) [Subramanya and Bilmes 2009], sparse graph-based semi-supervised learn-ing (SGSSL) [Tang et al. 2009], and large-scale multi-label propagation (LSMP) [Chen et al. 2010]. In addition to these research studies, we construct retrieval frameworks using SVD combined with minimum fusion (SVD + MIN) and SVD combined with SKF fusion (SVD + SKF) on the NUS-WIDE-LITE dataset, and using SVD + MIN on the NUS-WIDE-270K dataset.

The results of our proposed framework using MCA-based tag removal algorithm and model fusion method (MCA-TR + ARC) of the content-based and tag-based mod-els, together with all of the aforementioned frameworks, are displayed in Figures 9(a) and 9(b). The results of LNP, EGSSC, SGSSL, and LSMP are collected from their original papers. The results of our constructed frameworks are generated by our ex-periments.

For the NUS-WIDE-LITE dataset, the parameters for the other algorithms are as follows. In the KNN model, the number of nearest neighbors k was set to 500. In the LibSVM model, the RBF kernel with  X  = 0 . 6 was used in the experiments. In the LNP model, the parameter representing the fraction of label information that each image receives from its neighbors was set to be 0 . 95. In the EGSSC model, the parameters for weighting the Kullback-Leibler divergence term and Shannon entropy term were set to 0 . 1 and 1, respectively, and the parameter ensures the convergence of the two similar probability measures was 2. In the LSMP model, the parameters in the modified version of Kullback-Leibler divergence were set to be 10 and 5. In the constructed SVD + MIN and SVD + SKF frameworks, SVD keeps all nonnegative eigenvectors.

For the NUS-WIDE-270K dataset, the parameters for the other algorithms are as follows. In the KNN model, the number of nearest neighbors k was set to 1,000. In the LibSVM model, the RBF kernel with  X  = 0 . 8 was used in the experiments. In the LNP model, the parameter representing the fraction of label information that each image receives from its neighbors was set to be 0 . 98. In the EGSSC model, the parameters for weighting the Kullback-Leibler divergence term and Shannon entropy term were set to 0 . 5 and 1, respectively, and the parameter ensures the convergence of the two similar probability measures was 2. In the LSMP model, the parameters in the modified version of Kullback-Leibler divergence were set to be 15 and 8. The set up of these parameters have been shown to be the best ones tuned [Chen et al. 2010]. In the constructed SVD + MIN framework, SVD also keeps all nonnegative eigenvectors.
It can be seen in Figures 9(a) and 9(b) that the MAP values of our proposed frame-work are at least 2% and at most 24% higher than those of the other frameworks on the NUS-WIDE-LITE dataset, and at least 3% and at most 22% higher than those of the other frameworks on the NUS-WIDE-270K dataset. The reasons why our pro-posed framework performs better than those results reported in previous work are as follows. The other frameworks either built their models on the low-level visual features or the relationship between tags. In other words, there were only content-based models in their frameworks or the tags were considered as class labels, not discriminant features. On the other side, tags are used in our framework directly as the features. Therefore, the other frameworks suffer from the semantic gap problem. However, there are no semantic gaps between tags and those high-level concepts. In addition, the tag features after noisy tag removal are considered more precise than the visual features. Moreover, the content-based models and the tag-based model are fused to get final ranking scores which are expected to be better than the scores from the content-based models or the tag-based model alone. Therefore, the overall frame-work gives a promising improvement with respect to the semantic concept retrieval on images. Since the proposed MCA-TR method and the proposed ARC method out-perform SVD method and MIN or SKF fusion methods, it is expected to see MCA-TR + ARC renders better performance than the results from the other constructed frameworks.

Table IX and Table X further demonstrate the contribution of each component to the final performance of the framework on the NUS-WIDE-LITE and the NUS-WIDE-270K datasets. As can be seen from Table IX and Table X, the tag-based model (MCA-TR only) renders better performance than the content-based models (using Color Histogram and Wavelet Texture) and contributes the most to the final performance. The MAP of  X  X CA-TR only X  is derived using the tag-based model built from the filtered tag after MCA-TR is applied and no fusion is further applied.  X  X RC only X  stands for the case where the content-based models and tag-based model (trained on the original tags without applying MCA-TR) are fused together. It can be seen that  X  X CA-TR only X  contributes more than  X  X RC only X  to the final retrieval performance of the framework MCA-TR + ARC on the NUS-WIDE-LITE dataset. However,  X  X RC only X  contributes more on the NUS-WIDE-270K dataset. In addition, MCA-TR + ARC that considers both content-based and tag-based models holds the best performance. However, it is noticeable that MCA-TR + ARC performs only slightly better than MCA-TR. This is due to the situation that the performance of the content-based models (using Color Histogram and Wavelet Texture) is much worse than the tag-based model (MCA-TR only). Therefore, the tag-based model benefits little from the content-based models.

Finally, the computational costs of our proposed framework are mainly from the operation of singular value decomposition within the MCA (used in the tag removal method and model fusion method). Therefore, in the training phase, the computational cost is O ( N 2 K + NK 2 + K 3 ) in order to derive singular values as well as the left and right singular vectors (such as the U and V in the MCA algorithm), where N is the number of images and K is the dimensionality of the features that are extracted from the images. In the testing phase, the time computational costs are mainly from the searching of the corresponding MCA weights. For example, a tag can have a MCA weight towards a class representing the concept  X  X lowers X , which is calculated by the cosine value of the angle between that tag (a nominal value) and the concept Flower (a nominal value) measured by MCA. The worst case of the time complexity is O ( N ). Depending on the way of implementing such a searching process (e.g., use a HashTable), the time complexity could be O (1 + N / m ), where m is the number of used keys. In this article, a novel Web media semantic concept retrieval framework that includes both tag removal and model fusion for content-based and tag-based models is proposed. The proposed MCA-based tag removal algorithm is able to remove trivial or irrelevant tags dynamically for a query (target) concept. Our proposed tag removal algorithm converts the tags into useful features which are proved to be helpful in retrieving the target concepts. Our framework utilizes both content-based and tag-based models, fol-lowed by a proposed model fusion strategy to fuse the results from these two models. In our fusion strategy, the correlation of the intervals within the ranking scores as well as the reliability of each individual model are considered and harmonically com-bined to fuse different learning models. Experimental results show that our proposed tag removal algorithm can render better ranked results than the other tag removal approaches in terms of mean average precision. Our model fusion strategy is also su-perior to the other prevailing fusion methods in terms of overall MAP. Compared with the other research work using the NUS-WIDE-LITE and NUS-WIDE-270K datasets, the whole framework reports a significant improvement with respect to the retrieval performance.

