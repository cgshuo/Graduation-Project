 1. Introduction
The World Wide Web and the technologies and protocols that make the Web work (TCP/IP, http, HTML/XML, etc.) have become an essential part of the modern infrastructure of virtually any business. Users at all organizational levels in a variety of positions are using the Web to respond to their information needs. According to Jupiter Media Metrix, an Internet measurement service (see http://www.searchenginewatch.com/reports/mediametrix.html ), 80% of an estimated 114 million
Internet users make some type of search request, with the most popular search engines receiving tens of millions of searches each day ( http://www.searchenginewatch.com/reports/perday.html ).
Anecdotal evidence (including our opening quote by Google  X  s CEO Eric Schmidt) as well as esti-mates placing monthly search hours in the millions (see, for example, Media Metrix above) support the perception that many knowledge workers spend a considerable amount of time on a daily basis searching for information from sources on the Internet. It is, therefore, very important to under-stand the factors that affect knowledge workers  X  performance in and perceptions about search tasks in the Web environment. In this study, we will investigate the effects of two possible mechanisms for improving a Web user  X  s search performance: an assisted search tool and training in Boolean logic.
All Web search engines provide a  X  X  X imple search X  X  interface that presents the user with an empty textbox for entering a search. This command language interface requires active user involvement, as the user must remember the correct format and syntax for a query (Shneiderman, 1998;
Shneiderman, Byrd, &amp; Croft, 1998). Also offered by many search engines is an  X  X  X dvanced search X  X  interface. While they vary in configuration, most provide forms with drop-down menus containing
Boolean operators for joining search terms, as well as menu options for specifying various pre-sentation options, such as the number of results to display per page. These menu-based forms require less active user involvement, because choices are made from pre-defined lists (Shneiderman, 1998; Shneiderman et al., 1998). Although these interfaces are in many respects simpler to use than the  X  X  X imple interfaces, X  X  users often avoid advanced search options, believing they are intended for experienced users because of the way they are labeled (Pollock &amp; Hockley, 1997). In the experiment reported in this paper, the subjects were presented with one of two search interfaces. The first duplicated the simple search interface and the second provided the subjects with the drop-down menu options for selecting Boolean operators found in most  X  X  X dvanced search X  X  features. It did not, however, include any options affecting the presentation of search results, as they are not under investigation here. We therefore refer to this interface as an  X  X  X ssisted search X  X  tool.
Another important factor that potentially affects user performance is training in the tools used for searching. Optimal performance in the search tasks with the search engine used in this study required understanding of basic Boolean logic. Earlier research suggests that non-expert users are not capable of writing correct Boolean queries (Turtle, 1994). It is conceivable that general training in Boolean logic could have a beneficial impact on user performance, and it is the second treatment in this study. Before the experimental task, the subjects either did or did not receive training in fundamental Boolean logic concepts, depending on the experimental treatment.
Consequently, there were four treatments: simple search with no training, simple search with training, assisted search with no training, and assisted search with training.
This paper will first discuss earlier research related to this study. It will then present a theo-retical framework and the research hypotheses, and describe the methods and the research variables. Next, the results of the experimental study will be presented, followed by a discussion of those results and their implications for practice and future research. 2. Related work
Despite its practical importance, the usability of Web search interfaces and its impact on search effectiveness has received relatively little attention in academic literature. Prior to the widespread use of the Web, the information retrieval (IR) community focused on the needs of the typical user, a dedicated searcher. The overview of the Second Text REtrieval Conference, by Donna Harman of the National Institute of Standards and Technology, states that:  X  X  X t should be assumed that the users need the ability to do both high precision and high recall searches, and are willing to look at many documents and repeatedly modify queries in order to get high recall. Obviously they would like a system that makes this as easy as possible, but this ease should be reflected in TREC as added intelligence in the system rather than as special interfaces. X  X  (Harman, 1994).
Despite the fact that this profile no longer describes the typical searcher, research efforts often neglect the needs of today  X  s far less experienced user. A comprehensive review of relevant journals in the fields of management information systems and IR revealed few papers that have specifically addressed user interface issues in Web information search. Information systems research in par-ticular has paid little attention to Web search as a research area even though usability of query languages in database environments has received a great deal of attention over the past 10 X 15 years (see, for example, Chan, Wei, &amp; Siau, 1998). The exceptions are studies by Te  X  eni and Feldman (2001) and Lucas, Schiano, and Crosett (2001). The former paper presents the results of an ex-perimental study that investigates the effects of adaptive Web site design on user performance and satisfaction in an environment where search takes place with browsing. Their results suggest that adaptive sites can improve user search performance but may have a harmful impact on user sat-isfaction. Lucas et al. (2001) identify the importance of Web search as an essential productivity technology, present a review of present and future search technologies, contrasting them with traditional IR mechanisms, and evaluate the economic issues related to providing Web search.
Most IR research has focused on the performance and characteristics of search engines (Gordon &amp; Pathak, 1999; Leighton &amp; Srivastava, 1999), search-related data structures and re-trieval algorithms (Sparck Jones &amp; Willett, 1997), or typical search behaviors (Jansen &amp; Spink, 2000; Spink, Wolfram, Jansen, &amp; Saracevic, 2001). In a review of  X  X  X eb searching studies X  X  in IR,
Jansen and Pooch (2001) did not identify any significant findings related to search interfaces; the main focus was on studies that analyze search engine transaction logs. They summarize the findings of three major studies (H  X  olscher, 1998; Jansen, 2000; Silverstein, Henzinger, Marais, &amp;
Moricz, 1999) by stating that a great majority of Web search engine users fit this model: their queries have either two or three terms, the query syntax is very simple, Boolean operators are seldom used and if they are, then they are often used incorrectly, and the result sets are not fully utilized, with users typically viewing only the first page of search results. Later studies that have evaluated search behaviors of typical Web searchers (Lucas &amp; Topi, 2002; Spink, Jansen, Wol-fram, &amp; Saracevic, 2002) provide additional support for these findings.

Another recent review (Kobayashi &amp; Takeda, 2000) focuses primarily on search engine char-acteristics (i.e. indexing, clustering, and ranking algorithms) and future trends, including adaptive
Web sites, search engines for retail shopping, and searches for multimedia documents. In their subsection on search user interfaces, Kobayashi and Takeda concentrate on emerging search technologies, such as the use of visualization to support Web searches and acoustical interfaces for visually impaired users. The studies included in this review suggest that search interface research to date has been fragmented; while it has suggested a variety of avenues for future research, it has not yet provided a set of clearly identifiable core results.

Prior research has, however, identified two major dimensions of searching that are closely linked to user interfaces and potentially affect search effectiveness. First, there is the distinction between querying/IR and browsing/hypertext navigation, which is discussed in Allen (2001),
Golovchinsky (1997), Hertzum and Frokjaer (1996) and Plaisant, Shneiderman, Doan, and Bruns (1999). All of these works present the possibility that a combination of browsing and querying might be the most effective strategy, although the results are highly inconclusive and suggest that the best selection of tools depends on both the task and the characteristics of the searcher.
Wildemuth, Friedman, and Downs (1998) did not find any significant differences between the hypertext and Boolean environments in their study, with subjects preferring the Boolean envi-ronment.

A second dimension that has been relatively widely discussed is the difference between Boolean search systems and natural language search systems. Boolean search environments simply ask the users to express their queries with keywords along with Boolean and proximity operators. By contrast, natural language search systems  X  X  X ccept as input a description of an information need in some natural language and produce as output a list of documents ranked by the likelihood that they will be judged to match the information need. X  X  (Turtle, 1994, p. 1). IR research has, since the 1980s, concluded that Boolean searches are inferior to natural language queries (Borgman, 1986;
Turtle, 1994). These findings have not been validated in the Web environment, and some recent results suggest that Boolean queries can be at least as successful as natural language searches (Hersh, Turpin, Price, &amp; Kraemer, 2001). Nonetheless, there have been some attempts to apply natural language processing (NLP) techniques to Web queries. For commercial search engines, these have typically been limited to automatic truncation of query terms (so that a search on  X  X  X eservation X  X  will also find documents containing  X  X  X eserve, X  X   X  X  X eservers, X  X  and  X  X  X eserving X  X ), au-tomatic identification of proper nouns, and phrase identification. While search engines may allow users to enter queries as questions, they do not interpret those questions but either treat them as a collection of keywords or return a list of matching questions for the searcher to choose from (the AskJeeves search engine approach).
 Some recent research efforts have been directed at applying more advanced NLP technology to
Web searches. The MULDER automatic question-answering system (Kwok, Etzioni, &amp; Weld, 2001) uses a natural language parser in translating the user  X  s question into a series of queries, which are then sent in parallel to a search engine. Relevant pieces of information are extracted from the retrieved pages, scored, ranked, and presented to the searcher. In comparing MULDER, which used Google for providing the searching component, to Google alone and to AskJeeves,
MULDER was found to outperform the other two in terms of required user effort, estimated by the number of words the user must read from the start of the result page until the first correct answer is reached.
Another approach that makes use of NLP is the IntelliZap System (Finkelstein et al., 2002), which captures the context surrounding user-highlighted text using semantic keyword extraction and clustering. New queries are then automatically generated and submitted to both general and domain-specific search engines. Results are ranked on the basis of their semantic proximity to the original context. IntelliZap  X  s performance is comparable to that of test subjects using major search engines but requires much less user involvement.

These findings highlight the need for queries that accurately capture the searcher  X  s information need while conforming to the syntax required by the search engines to which they are being submitted. While the correct usage of Boolean operators is known to be confusing (Cooper, 1988), few studies have examined the effectiveness of training on Boolean logic on the user  X  s ability to construct valid search statements. Johnson and Szabo (1998) studied the effects of training in both
Boolean logic and keyword selection on the ability of high school students to construct complex search statements, and found that training had a positive impact. This improvement in query construction did not lead to an improvement in the students  X  success in finding topic-related documents after submitting their queries to the Excite search engine. A recent study on query term and operator usage found, however, that differences in the number of terms used in searches conducted by experts and non-experts, the percentage of matching terms between the two groups  X  queries, and the erroneous use of non-supported operators by non-expert searchers explained most of the variation in the relevancy of search results (Lucas &amp; Topi, 2002).

The research presented here continues the work of these earlier studies by focusing on the user interface and training in Boolean operators as factors that affect users  X  performance in Web query tasks and user satisfaction with the query environment. 3. Theoretical framework
As in Te  X  eni and Feldman (2001) and in most studies on query performance in structured query tasks (Chan, Tan, &amp; Wei, 1999), our main focus of interest is on two categories of dependent variables: performance (correctness/accuracy and time) and attitudes (confidence and satisfac-tion). In this section, we will build the theoretical model that has guided this research and the hypotheses derived from it. 3.1. Assisted search and training for improved performance
There are several potential sources of errors that could have significant effects on user per-formance and satisfaction with both simple and advanced search tools. These errors fall into three categories: (1) misinterpretation or misreading of the stated information request, (2) errors in query formation, and (3) misinterpretation or misreading of search results. Errors in the first category will override errors in the other two, as a misinterpretation of the search request is likely to result in an incorrect answer, regardless of how the query is formed or the results interpreted. It is therefore very important that information requests be as unambiguous as possible in studies on either of the latter two types of errors.

Errors in the third category will occur when searchers interpret a search request correctly, execute a properly formed query containing relevant search terms, but misunderstand the search results. These types of errors will also have an adverse effect on the quality of the search results and are likely to be detrimental to perceived satisfaction with a search tool.

In this study, we are primarily interested in the second category, in which errors are related either to the search terms or the search operators. Lucas and Topi (2002) suggest that users often select an incorrect search term or multiple incorrect search terms when constructing their query, so that the search results bear little relevance to the stated information request. More importantly from the perspective of this study, errors involving query operators were also shown to affect search results, and are caused either by the absence of operators required for optimal query performance or by their incorrect usage. While users making either type of error may eventually arrive at the correct answer to a search request, it is likely to take them longer to find that answer and for it to appear later in the list of search results than it would have given an optimal search. In addition, searchers are apt to become frustrated and unsatisfied with the search tool as a result of these errors because the problems with formulating the query will be attributed to the search tool itself. These implications along with findings from earlier studies highlight the need for supporting users in the query formation process, and provided the motivation for this research.
Two mechanisms for improving the search performance and perceptions regarding the search experience of an inexperienced user are readily identifiable: first, it is possible to provide training that guides the user in the fundamental principles of the use of the search tool and second, the user can be provided with an assisted search interface that guides her with the use of that tool. The research model of Fig. 1 was adapted from the model of query-specific factors affecting the rele-vancy of search results (Lucas &amp; Topi, 2002). Our focus here is on how training and assisted search tools affect the usage of Boolean operators, which, in turn, affects the overall success of the search.
A wide range of models have been developed to describe the process of interactive information searching (e.g., Belkin, 1984; Kuhlthau, 1993, 1999; Saracevic, 1996), but they all deal with a significantly broader search process than the one focused on in this research. While these other models typically represent the many stages of search, this study explores the process of forming a query based on a known information request. Our subjects were searching for a single factual answer to a specific question. The model that has guided this research is therefore limited to this very specific aspect of searching. Its contribution is in presenting the main variables of the study in a graphical format. In future work, it will provide the framework for the development of a more elaborate model of user behavior.

In this study, we will investigate (1) the effectiveness of training and interface in assisting in-experienced users to achieve high-quality information search results in a short amount of time and (2) the effects of these mechanisms on the users  X  satisfaction with the search process. Both of these mechanisms are related to the correct usage of search operators; we do not expect them to affect search term selection. The choice of query terms is often based on experience with the search subject (H  X  olscher &amp; Strube, 2000; Hsieh-Yee, 1993). Standard experimental procedures should ensure that errors of this type are evenly distributed throughout the study participant population, thereby mitigating their impact on our results. 3.2. Hypotheses
Prior research on IR suggests that the correct use of logical operators is a cognitively complex task, particularly for searchers with relatively little experience (H  X  olscher &amp; Strube, 2000; Mischo &amp; Lee, 1987). At the same time, research suggests that training in Boolean logic can improve the subjects  X  understanding of the correct usage of the operators and thus improve performance (Siegfried, Bates, &amp; Wilde, 1993). Searchers who have undergone logic training are expected to make fewer operator-related errors than their untrained counterparts. The expectation is that, all else being equal in regard to term usage, syntactically correct queries stand a greater chance of finding the information being sought. In addition, if a searcher has been trained in the usage of
Boolean operators, it is more likely that he or she will actually use them, thereby improving the probability of retrieving the most relevant documents earlier in the search list. This should in-crease the correctness of their responses to the information request. Finally, trained subjects  X  performance times, defined here for each information request as the elapsed time from when the information request is first viewed until an answer to that request is entered, are likely to be faster because there are fewer documents to sift through before finding the correct one. This is also likely to improve their satisfaction with the search tool, i.e., to move their general perceptions regarding the suitability of the search tool to the search task in a positive direction. This leads to our first three hypotheses: Hypothesis 1. Logic training will lead to improved correctness of search results.
 Hypothesis 2. Logic training will lead to decreased information request response time. Hypothesis 3. Logic training will lead to increased satisfaction with the search tool.
The assisted search tool used in this experiment has been designed to assist users in forming correct Boolean-type queries. By guiding the query formation process, the tool reduces the cog-nitive load on the study subject (Cooper, 1990), thereby helping the user achieve better results.
Conceptually, the interface does not require the same degree of knowledge about Boolean queries as the simple search mechanism because a structure for the query is presented to the user. Studies have shown that users have difficulty forming Boolean queries (Mischo &amp; Lee, 1987). By pro-viding an interface that assists them in proper query formation, some of that burden is lessened.
This is predicted to lead to better performance, higher satisfaction, and a shorter time required to perform the IR task. Our next three hypotheses follow:
Hypothesis 4. The use of the assisted search tool leads to improved correctness of search results compared to the use of the simple search tool.

Hypothesis 5. The use of the assisted search tool leads to decreased information request response time compared to the use of the simple search tool.

Hypothesis 6. The use of the assisted search tool leads to improved satisfaction with the search environment compared to the use of the simple search tool.

The beneficial effect of the assisted search tool is likely to be more significant for those subjects who did not receive training than for those who did because some of the effects of the training and the assisted search are overlapping: both of these mechanisms make the user more sensitive to the need for using Boolean operators to improve the search results. In addition, both mechanisms help by making the users aware of the available set of operators, which a user without training might not know. Therefore, in both of these respects the beneficial impact of the assisted search tool will be diminished for those who gained the same benefits through training. For the same reasons, the decrease in time will be greater for the users with no training. Our final hypotheses are:
Hypothesis 7. The use of the assisted search tool will lead to a greater increase in the correctness of search results compared to the use of the simple search tool for those users who did not receive logic training.

Hypothesis 8. The use of the assisted search tool will lead to a greater decrease in the time re-quired for the information search compared to the use of the simple search tool for those users who did not receive logic training. 4. Methodology 4.1. Design
A controlled laboratory experiment was conducted to test the hypotheses presented above using a 2 2factorial design with two between-subjects factors: Training and Search Interface Type. The levels of the Training factor are called Training and No Training, and the levels of the Search Interface Type are referred to as Simple and Assisted.

Fig. 2shows the segmentation of study participants by search interface and training. Each cell, labeled I through IV, is comprised of 3 2(34 in cell III) test subjects. Subjects in cells I and II used the simple search interface consisting of a text box with a submit button. In this environment, the user clicked on the button after entering a query to that box. This opened another window containing the retrieved document set. Subjects in cells III and IV used the assisted search in-terface shown in Fig. 3. Subjects in cells II and IV received training in basic Boolean logic, while those in cells I and III did not. 4.2. Subjects
Subjects for this study were recruited from students enrolled in an introductory information systems course at a small university located in the northeastern US. Table 1 contains background information and Internet-related experience for the 130 participants. Statistical analyses revealed no significant differences between the experimental conditions for gender, academic standing,
Internet experience, or mother tongue. There was, however, a statistically significant difference between the two search tools for age, but we believe that this difference has no effect on search results, because the absolute difference between the groups was small (18.45 years for the assisted tool and 18.7 years for the simple tool). 4.3. Procedure and task
The subjects performed the task as an in-class search exercise in an introductory information technology course. Participation was voluntary and no extra credit was awarded based on par-ticipation in the experiment. As an incentive, $50 prizes were offered to the two best performing subjects based first on correctness and secondly on time.

For treatments II and IV, the experiment began, after customary introductions and proce-dure descriptions, with training on basic Boolean logic. Training was implemented as an in-teractive Web exercise. The experiment continued with a Microsoft PowerPoint slideshow that introduced the experimental procedure to the subjects. After the slideshow, the subjects logged on to the experiment system for collection of some demographic and attitudinal back-ground data. This was followed by the actual experiment data task with either simple or assisted search. After completing the task, the subjects finished the session with additional question-naires.

Experimentaltaskandthesearchspace . The experimental task asked subjects to look for an-swers to nine information requests with varying levels of complexity using either the simple or the assisted interface. The nine requests appeared in random order for every subject in the study, and each subject was asked to respond to each of those nine requests. The searches were conducted in a research environment and against a set of HTML documents that were selected specifically for this research program. The document database is a snapshot of a university Intranet Web site from which all links had been removed. Once a search was initiated, the subjects were not able to continue that search by browsing but rather were forced to continue using only queries. The search space consisted of 21,890 documents.

As mentioned above, the complexity of the queries required to directly access the document with the relevant information varied. A total of nine queries were categorized into three groups of three queries each, based on their structural characteristics. The appendix to this paper shows the nine information requests categorized by query complexity. Queries required for the first category were the simplest, consisting of the use of the conjunctive AND operator between two single search terms. The second category required AND operators for joining three terms in the first case, two terms and a phrase in the second case, and two phrases in the third case. This cate-gorization was based on data from our pilot study, which found these three cases to be of equivalent difficulty for searchers. Queries associated with information requests in the third cat-egory were the most complex in that they required at least four terms or phrases and the use of the negation operator, NOT. In two of these cases, more compact queries could be formed by ap-plying the NOT operator to a group of terms joined with disjunctive ORs. Again, our pilot study found these last three queries to be of equivalent difficulty. 4.4. Independent variables
Querycategory . Although we do not present any explicit hypotheses regarding the effects of the query complexity category, it was included as an independent variable in the analyses whenever possible. Prior research and an analysis of pilot data suggested that it would have a strong effect on the results and thus, weaken the analysis if it were left out. Complexity was treated as a cat-egorical variable with three possible values, which are labeled simple, moderate, and complex. It is important to note that these are references to relative complexity rather than specific statements about the absolute complexity of these queries.

Logictraining . The first independent variable is the logic training, which either was or was not given to the subjects, depending on the treatment. Subjects in Cells II and IV (see Fig. 2) received
Web-based training in basic Boolean constructs to help them form properly constructed queries (training material available by request). The training covered the usage of the Boolean operators
AND, OR, and NOT; in addition, it included material on the use of quotation marks to indicate phrases and parentheses for enforcing precedence. As described below in the results section, a manipulation check verified that this manipulation worked as expected.

Searchenvironmentcharacteristics . The second independent variable was the search interface: subjects were assigned to use either the Simple or the Assisted interface. The Simple search in-terface consisted of a textbox into which the subject could enter a Boolean query, which was then submitted directly to the search engine. The Assisted interface provided several mechanisms de-signed to help the user formulate correct Boolean queries, namely: the selection of operators from drop-down lists, the selection of parentheses with buttons, and the automatic treatment of mul-tiword entries as phrases (see Fig. 3), all of which are typical mechanisms in  X  X  X dvanced X  X  Web search interfaces.
 4.5. Covariates Seven pre-validated instruments were used as covariates in the analyses: Pre-task Enjoyment,
Computer Anxiety, and Computer Playfulness scales, which were adapted from (Venkatesh, 2000), Task Importance, adapted from (Topi, 1995), Self-Efficacy, which was measured with an instrument based on Marakas, Yi, and Johnson (1998), Search Experience, which refers to a scale of six items developed for this study that measures the subject  X  s experience with various search tools (Cronbach  X  s alpha  X  0 : 78), and Product Familiarity, which measures how familiar the user is with a set of six computing productivity tools (Cronbach  X  s alpha  X  0 : 82). Additional covari-ates were Age and a binary variable describing whether or not a subject  X  s mother tongue was
English. 4.6. Dependent variables
Correctness . The simplest performance variable is Correctness, i.e. the searcher  X  s ability to provide correct answers to the information requests, which is used in this study as a measure of the quality of search results. All of the information requests were designed to have only one correct answer, enabling results to be evaluated as correct or incorrect based on the match be-tween the subject  X  s answer and the correct one. Answers containing an error that clearly was typographical were evaluated as correct. In the binary logistic regression performed at the query level, as described in the next section, Correctness was the categorical dependent variable, with each query categorized as either correct or incorrect. In Table 3, average Correctness of each cell of the research design is expressed as an aggregated value at the subject level.

Time . The system included automatic mechanisms for measuring the time the subjects used for formulating the queries and viewing the results. Each user action was time stamped, so that very detailed information about user behavior was available. In this analysis, the performance variable
Time is the elapsed time from when the subject first saw the information request until an answer to that request was entered. The system imposed a 5-min time limit on each of the nine information requests to be completed by each user, and gave a warning 30 s before that time was up.
Satisfaction . An ease-of-use measure adapted from Venkatesh (2000) was used to measure users  X  satisfaction with the search environment. This scale demonstrated acceptable psychometric characteristics in a reliability analysis (Cronbach  X  s alpha  X  0 : 93).

Confidence . The user  X  s confidence in his or her answers was measured with a one-item scale after each question. The item is the same as that used in the latest TREC studies (available from http://www.nlpir.nist.gov/projects/t9i/qforms.html ).

It is important to point out that we intentionally chose to not use precision and recall, the traditional dependent variables of search engine studies, due to our focus on user performance instead of search engine performance. Our objective was not to compare search engines but rather the effects of manipulations that have an impact on the way users form queries. Therefore, we believe that the correctness of a user  X  s answers to specific information requests is the best measure of the success of that user  X  s search experience. In addition, the time used for finding answers to the information requests is a relevant measure because shorter response times indicate better pro-ductivity in search tasks.

Table 2summarizes the independent and dependent variables used in this study. 5. Results 5.1. Manipulation check
As a manipulation check, a 2 2ANCOVA analysis was performed with Search Tool (As-sisted vs. Simple) and Logic Training (Training vs. No Training) as factors and Self-Efficacy, Search Experience, Enjoyment, Product Familiarity, Task Importance, Computer Anxiety, and
Computer Playfulness as covariates. The dependent variable was Pretest, a five-item instrument that measured the subjects  X  mastery of basic Boolean constructs. In this analysis, only Logic we can conclude that the training had the required effect to be a valid manipulation. 5.2. Test of hypotheses
Because of the categorical nature of the binary Correctness variable, the hypotheses related to it were tested by performing a binary logistic regression at the query level. Correctness was the categorical dependent variable and Query Category (Simple, Moderate, and Complex), Search
Tool (Assisted vs. Simple) and Logic Training (Training vs. No Training) were the primary in-dependent variables. The covariates were Self-Efficacy, Search Experience, Enjoyment, Product Familiarity, Task Importance, Computer Anxiety, Computer Playfulness, Age, and Mother
Tongue. A stepwise analysis was performed, which followed these steps: (1) Covariates, (2) Query category, (3) Search Tool, (4) Logic Training, (5) Two-way interactions: Query Category Search Tool and Query Category Logic Training, (6) two-way interaction: Search Tool Logic Training, and (7) three-way interaction: Query Category Search Tool Logic Training.
The hypotheses related to Time were tested using a 2 2ANCOVA analysis at the individual information request level with Time (in min) as the dependent variable and the same independent variables and covariates as above. Finally, the hypotheses related to Satisfaction were tested using a2 2ANCOVA analysis at the subject level using Ease-of-Use (surrogate of Satisfaction) as the dependent variable, Search Tool and Logic Training as independent variables, and again the same covariates as above.

Even though the Query Category was included in the analyses as one of the independent variables, the sample sizes and the means and standard deviations for the dependent variables Score (aggregated Correctness), Time, Satisfaction, and Confidence are presented in Table 3 as aggregated over all queries. This makes it easier to evaluate the nature of the effects observed in the study.

The first three hypotheses were related to training. Hypothesis 1 posited that Logic Training would lead to an increase in the quality of the search results. The results of the binary logistic regression show that adding Logic Training to the model does not add significantly to the pre-dictive capability ( v 2 change  X  1 : 68, 1 df, p  X  0 : 1949) and thus, Hypothesis 1 is not supported.
Hypothesis 2claimed that Logic Training would decrease the time required to respond to the information request. An ANCOVA for Time indicates that there is no main effect for Logic
Training, and therefore, Hypothesis 2is not supported. The final hypothesis in this set, Hy-pothesis 3, suggested that Logic Training would lead to increased satisfaction with the search environment. An ANCOVA for Satisfaction shows that there is a significant main effect for Logic
Training ( F  X  1 ; 117  X  X  4 : 12, p  X  0 : 044) and an inspection of the means tells that the scores were higher for Training than for No Training. Therefore, Hypothesis 3 is supported.

The second set of hypotheses was related to the search tool. Hypothesis 4 proposed that the use of the assisted search tool would lead to an improvement in the correctness of the search results.
The binary logistic regression analysis indicates that adding the Search Tool variable to the re-the regression results reveals that the use of the assisted interface is associated with improved performance. Hypothesis 4 is therefore supported. Hypothesis 5 argued that the assisted search tool would reduce the time required for the search tasks. An ANCOVA for Time demonstrates inspection of the means, however, tells that the subjects using the assisted search tool required more time than those using the simple search tool and thus, the hypothesis is contradicted. It is worth noting, however, that the differences are relatively small and their practical consequences are uncertain. Hypothesis 6 suggested that the use of an assisted search tool would lead to an increase in satisfaction with the search environment. An ANCOVA for Satisfaction shows that there is a significant main effect for Search Tool ( F  X  1 ; 117  X  X  4 : 680, p  X  0 : 033), and, because an evaluation of the means reveals that the users of the assisted search tool gave higher ratings than the users of the simple search tool, Hypothesis 6 was supported.

Hypotheses 7 and 8 discuss the interaction between Logic Training and Search Tool. Hy-pothesis 7 posited that the hypothesized positive effect of the assisted search tool on the quality of search results over the simple tool would be greater for those who do not receive training than for those who do. Training would therefore have a greater positive impact on the quality of search results with the simple search tool than it would with the assisted one. Adding the Search Tool
Logic Training interaction to the binary logistic regression improves the predictive capability of the model ( v 2 change  X  11 : 07, 1 df, p &lt; 0 : 001). To interpret this interaction, aggregated cell means were inspected (see Table 3). This revealed that training did not affect performance for users of the assisted search tool, but did for users of the simple one. Moreover, performance using the simple search tool with training matched the superior performance achieved by users of the assisted tool. Hypothesis 7 is therefore supported.

Finally, Hypothesis 8 suggested that the hypothesized time difference between the simple and the assisted search tools would be greater for those subjects who did not receive training. There was, however, no significant interaction between Logic Training and Search Tool in the
ANCOVA for Time and thus, Hypothesis 8 is not supported. 5.3. Other analyses
In addition to the hypothesis analysis, we analyzed the effect of the main factors and their interaction on confidence with a regression analysis and found both a significant main effect for Search Tool ( F  X  1 ; 964  X  X  21 : 201, p &lt; 0 : 001) and an interaction effect for Search Tool by Logic
Training ( F  X  1 ; 964  X  X  4 : 698, p  X  0 : 030). The users of the assisted search tool were significantly more confident with their answers than the users of the simple search tool, and the interaction tells that this effect was stronger for the trained subjects than for the non-trained subjects. It should also be mentioned that the Query Category variable was a very strong predictor of
Confidence ( F (1,1149)  X  22.380, p &lt; 0 : 001). Increasing query complexity had a negative effect on correctness, increased the time required to perform the queries (Simple different from Moderate and Complex), and decreased the subjects  X  confidence (all categories different from each other). It was possible to determine the effect of the query category on these dependent variables because Correctness, Time, and Confidence were measured at the query level.

Moreover, it should be pointed out that the standard deviation of correctness is clearly greater in the Training/Simple Interface treatment than in the other treatments. This suggests that there is high variability between the subjects  X  ability to effectively utilize the type of relatively simple training given in this study; further research is therefore warranted. 5.4. Summary of the results
In this study, we found that there was a statistically significant overall positive main effect for the assisted interface on performance, as measured by the level of correctness of the users  X  re-sponses to information requests. In addition, there was a significant and interesting interaction between the search tool and training. Users of the assisted search tool performed significantly better than users of the simple search tool if they had not received training in basic Boolean logic.
If training had been given, users of the simple search tool actually outperformed users of the assisted search tool, although not at a significant level. To summarize, having simple Boolean training or using the assisted interface improved the subjects  X  performance over that of those who did not have training and used the simple interface. The combination of training and the assisted interface did not, however, cause any further improvement in performance.

Subjects using the assisted search tool used significantly more time than those using the simple one, but the former were more satisfied with the search tool and more confident about the cor-rectness of their results. The subjects that received Boolean training were also more satisfied with the search environment than those users who did not receive training. Finally, the complexity of the queries had a strong, negative impact on the correctness of the answers, the time it took to perform the queries, and the subjects  X  confidence in their answers. 6. Discussion
Our research model (Fig. 1) theorized that both training and the search tool would affect user performance and attitudes toward the search process. Results of the hypothesis analysis show that the search interface had a stronger overall impact on performance and attitudes towards the search environment than training did. The most important observed effect, however, was the interaction between the interface and the training. With no training, there was a significant positive difference in the correctness of the search results for those using the assisted search tool over those using the simple one. When training was introduced, the difference between the search tools disappeared. Training therefore served as a performance equalizer, compensating for the lack of direction and assistance in the simple search environment. In other words, the introduction of either the assisted interface or training had approximately the same positive effect, but no additional benefit was garnered from their joint usage.

Training in the use of Boolean operators was not found to have a significant main effect on the quality of search results or on response time, though it did increase user satisfaction. The ma-nipulation check, however, strongly supports the effectiveness of the training on improving the subjects  X  ability to formulate valid Boolean queries, thus supporting the results obtained by
Johnson and Szabo (1998). One of the reasons that training was effective only for those using the simple interface could be because of the similarity between that interface and the training envi-ronment. In using the assisted interface, a query must be broken down into a number of text boxes separated by logical operators. It appears that both logic training and the assisted interface provided the users with a sufficient introduction to the use of Boolean operators.

In this research, the relatively short training session was not sufficient to improve over the results achieved with the assisted search interface. Studies have shown that Web-based instruction can be as effective as direct instruction (Goldberg, 1997; McCollum, 1997). The fact that there was no opportunity for further exploration of the subject matter along with the short duration of the training could have adversely affected training usefulness. On the other hand, earlier research suggesting that terms are potentially more important than operators in achieving high-quality query results (Lucas &amp; Topi, 2002) opens the possibility that more extensive training would not be beneficial. Further research is needed to explore whether or not this is the case by considering training that provides, for example, additional resources to the user and permits the entry of queries to an actual search interface.

As noted at the start of this discussion, the assisted search tool itself did have a significant direct positive effect on both correctness and satisfaction over the simple tool, although it must be emphasized that the interaction described above is much stronger than this main effect. The as-sisted interface helped the subjects use a richer set of search operators and guided them toward correct structures. Without further analysis, we can only speculate about the results related to satisfaction with the search environment, but it is likely that the strengthened task structure provided by the assisted interface led the subjects to perceive the environment in more favorable terms. This is supported by the finding that users of the assisted interface felt significantly more confident about their performance than did those using the simple interface.

The unexpected finding of this study was the negative impact of the assisted interface on re-sponse time. Participants were given no training in the use of the assisted tool beyond brief in-structions appearing at the top of the form. Since most searchers do not use the advanced search features found at search engine sites, it is quite likely that additional time was needed to orient the participant to its use. The simple interface, on the other hand, had a look and feel that would be familiar to any search engine user. Further study on the impact of training on the use of the assisted search tool itself will provide greater clarity on this finding.

The results of this study suggest that future research should refine our research model (Fig. 1) in at least two different ways. First, the model should explicitly acknowledge the possibility for a moderating effect between Search Interface and Training; in this study, this interaction was the strongest result. Second, mediating factors that have been integrated into Operator Usage need to be defined and explored. This will enable a better understanding of the intermediate steps between training and interface manipulations and search performance. We still know very little about actual search behaviors and their effect on search performance.

Overall, the results of this research show that simple training on Boolean queries and/or a user interface that supports correct formulation of Web queries can have a direct and significant impact on both the correctness of the search results and searchers  X  perceptions regarding the search environment. Hence, it would be advantageous for search engine sites to find ways to attract users to either their help pages or their advanced search tools. This finding is particularly significant given the widespread use of Web search tools and the importance of having correct information for supporting organizational decision making. Additionally, our results suggest that organizations would benefit from systematic training in both the search tools employees are using and the fundamental principles underlying their effective use. 6.1. Limitations
In order to focus solely on the subjects  X  ability to find information by submitting queries and avoid the potentially confounding effects of browsing, we removed all the links from the search domain, as previously noted. This created an artificial Web environment that prohibited users from the common information-gathering approach of combining searching with browsing (Catledge &amp; Pitkow, 1995). Undoubtedly, this lead to increased user frustration with both of the interfaces used in this study. In addition, queries that may have been adequate for a hypermedia environment because they returned pages linking to the correct results would not have been adequate here. Improvements in correctness noted in this experiment may therefore have less significance when applied to an unaltered Web environment.

A second limitation arose from our inability to completely monitor all of the participants  X  be-haviors. Some amount of copying of responses to information requests from adjacent participants may have occurred. To reduce this likelihood, requests appeared in random order, and participants were watched at all times during the study. There was also the possibility of participants misunderstanding or ignoring instructions to use only the provided search interface for find-ing information. Again, careful viewing of participants should have served to minimize these behaviors.

Another limitation of this study concerns the nature of the information requests. Each had only one correct response, which is not always the case with an information need, and so represents a subset of the types of searches that may be performed. Again, this could affect the importance of the correctness of the query in the Web environment: if there are several answers existing in several documents, then a less optimal query may be sufficient for finding one of them.
Lastly, our study participants were college students enrolled in a required introductory com-puter course. Their age distribution therefore covered a much smaller range than that of general
Web users. It is also likely that their level of experience with computers, their exposure to search engines, and their comfort with searching were higher than that of the general public. In this case, however, the lack of external validity because of the subject population is not likely to be a problem. College students are relatively good surrogates for knowledge workers who use search tools actively in their everyday tasks. Motivation is always an issue in experimental research using student subjects; using a monetary reward alleviated this potential problem. 7. Conclusions and future work
This study highlights the importance of training and interface design, and the effects of the interaction between the two, on improving both the outcome of searches and user attitudes to-ward the search process. Both our training and assisted search interface focused on assisting users in forming correct Boolean queries. Future research will investigate the effects of training on the use of a specific assisted search tool on performance and attitudes. Ways in which to influence the user  X  s choice of search terms were not investigated here, yet terms have been shown to have a significant effect on search performance (Lucas &amp; Topi, 2002). This topic will also be investigated in future studies.

Our assisted interface provided limited user interaction capabilities, and did not allow the user to affect the presentation of search results. The visualization of both the query formation process and the results of a search can enhance a user  X  s understanding and aid in the query formation process (Rao et al., 1995). A variety of search and presentation tools can be integrated into our testing system architecture, permitting analysis of their impact on both the user and the search process.
The results of this study are encouraging and provide a justification for further work that in-vestigates more closely and from additional perspectives the effects of Web search interfaces on search performance and attitudes toward search. Both of these factors have a potentially sig-nificant impact on the quality of organizational decision making.
 Acknowledgements
We gratefully acknowledge the contributions of Arihant Jain in the development of the ex-perimental environment and Weixin Yuan in data analysis. We are also thankful to the reviewers and the Associate Editor for their insightful comments and suggestions. For reprints, please contact the first author. Appendix A. Information requests by complexity category
Category 1:  X  Who is the chair of the philosophy department?  X  In what month and year did the Smith family double its gift to the Smith Center?  X  What former chair who established Bentley  X  s English program died in Weymouth?
Category 2:  X  From what institution did Professor Davis of the management department receive his BSEE?  X  What faculty member of the management department whose first name is John attended Syr-acuse University?  X  Which course discusses both starting salaries and a training program?
Category 3:  X  What faculty member of the management department whose first name is Joseph but whose last name is not Byrnes taught and worked in the Middle East?  X  What faculty member has an MA from Indiana University, is not in the philosophy or manage-ment department, and is interested in politics?  X  What faculty member in the accountancy department has a degree from a college in Boston and is not named Charles, Priscilla, or Jane? References
