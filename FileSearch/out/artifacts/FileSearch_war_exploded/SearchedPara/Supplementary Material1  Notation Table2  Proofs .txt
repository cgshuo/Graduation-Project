 Wenzhuo Yang a0096049@nus.edu.sg Huan Xu mpexuh@nus.edu.sg To prove the corollaries in Section 2, we give the following lemma. Proof. Since any two di erent groups g p and g q in G i are non-overlapping, we have Hence the lemma holds.
 By using Theorem 3 and Lemma 1, we have 5. Proof of Corollary 4: The dual problem of the optimization problem 6. Proof of Corollary 5: From Theorem 2 and Lemma 1 , we have 3.1. Proof of Theorem 4: From the de nition of ^ U , we have ( ; ; ) = max hyperplane that separates ( 0 ; 0 ; 0 ) with S .
 S , then by solving ( 12 ), we can nd in polynomial time c 0 ; ( i ) 0 such that which is the hyperplane separates ( 0 ; 0 ; 0 ) with S . 3.2. Extension of Corollary 8: Theorem 1. Let g 1 ; ; g t be t groups such that bound of  X  j for j 2 g i , e.g.  X   X  j  X  2 c j g f  X  linear regularized regression problem is where  X  X  X  q is the dual norm of  X  X  X  q .
 Proof. From Theorem 3 and Theorem 4, we have which establishes the theorem. Recall that the uncertainty set considered in this paper is W i = I for i = 1 ; ; t and the bound c g of  X  ( i ) g for each group g equals be rewritten as D = f D j Similarly, the uncertainty set f  X  j  X   X  g  X  2 c g is equivalent to where D g = f D j notation is a little complicated so we rst consider three simple cases:  X  g such that [ X ij The following holds Step 1: Using the notation above, we rst give the following corollary: Corollary 1. Given y 2R n , X 2R n m , the following equation holds for any 2R m , Here, where ij depends on the \decomposition" set S .
 Proof. The right hand side of Equation ( 15 ) is equal to From Theorem 2, we know that the left hand side is equal to Furthermore, applying Proposition 1 yields which proves the corollary.
 Observe that the estimated distribution above belongs to the set of distributions and hence belongs to ^ P ( n ) = Step 3: Combining the last two steps, and using the fact that regression.
 almost surely.
 By Corollary 1 and ^ n 2 ^ P ( n ), we have Notice that, side converges to where the last inequality follows from the de nition of C . Notice that almost surely when c n # 0 and nc m +1 n "1 . Hence the theorem follows. Theorem 2. Let f c n g converge to zero suciently slowly. Then almost surely.
 We now prove this heorem. We establish the following lemma rst. distribution satis es then 2 ^ P ( n ) .
 that the l 1 radius of V t is less than c n p m , we have Therefore, for any S f 1 ; ; n g , the following holds Hence 2 P n ( X ; S ; y ; c n ) which implies 2 ^ P ( n ).
 and Equation ( 17 ), hence inf V ) j =n , which goes to zero as n increases for any xed c n . Therefore, if c n # 0 suciently slow. Combining this with Inequality ( 18 ) proves the theorem. mization , volume 2. Springer, 1988.

