 This paper proposes a system ca lled  X  X erankEverything X , which enables users to rerank search results in any search service, such as a Web search engine, an e-commerce site, a hotel reservation site, and so on. This system he lps users explore diverse search results. In conventional search services, interactions between users and systems are quite limited and complicated. By using RerankEverything, users can interactively explore search results in accordance with their interests by reranking search results from various viewpoints. Experimental results show that our system potentially help users search more proactively. When using our system, users were more likely to click search results that were initially low ranked. Users also browsed through more diverse search results by reranking search results after giving various types of feedback with our system. H.5.2 [ Information Interfaces and Presentation ]: User Interfaces  X  Graphical user interfaces , Interaction styles. Keywords : Search user interfaces, information retrieval, reranking interaction. People access the World Wide Web for various purposes, such as acquiring knowledge, purchasing some thing, making travel plans, reserving hotels, or just watchi ng interesting videos. To find the desired information, people use ma ny kinds of search services such as Web search engines, e-commerce sites, hotel reservation sites, video sharing sites, and so on. When using a search service, users usually issue a query to it. The service then selects contents from its index, ranks them in accordance with its own criteria, and finally displays them as search results. These search services have become important information resources for many people. However, it is not always easy for users to obtain satisfactory information from search results because of the following problems: z It is difficult for users to come up with appropriate queries and takes an interested in pape rs authored by Wei-Ying Ma. The user selects  X  X Y Ma X  and presses the promote button to promote search results containing  X  X Y Ma X . If the user wants to browse papers in descending order of the citation counts, the user selects  X  X ited by 181 X  (in this case, the user can select just  X 181 X  to sort results) in the search results, and the system then displays four buttons with which to rerank th em. After the user clicks the descending button, the system sorts the search results in accordance with the number of citations, as shown on the right-hand image in Figure 2. In this way, users can interac tively rerank search results in accordance with their interests. Google Scholar does not provide search functions to sort results in accordance with the citation counts, although it does display these counts in the search results. Our system thus enables users to sort using this attribute even when the service does not provide such a sorting function. To encourage users to explore search results from various viewpoints, our system displays TermCloud , which are generated from terms that frequently appear in search results. Users can give term-based feedback and rerank search results by simply clicking a term in a TermCloud . Figure 3 shows an example of a TermCloud of Web search results for the query  X  X ork green pepper recipes. X  In that case, the system displays some terms that are related to cooking like  X  X arli c X ,  X  X nion X ,  X  X hinese X ,  X  X asy X  and so on. Because a TermCloud might bring interesting and various terms in search results to the attention of users, we expect users will be more likely to fi nd valuable and diverse search results. appropriate button.

Figure 1. Reranking search results using direct interaction. To evaluate how our reranking in teraction supports users seeking information, we conducted a user study. We think our reranking interaction become important when the user X  X  information needs are not well defined and the user needs to browse search results from diverse viewpoints. Therefore, we prepared such search tasks and compared the effectiveness of performing the tasks between our system and conve ntional search services. We recruited eight students from our university as participants: four graduate students, and four undergraduate students. All were male. The subjects did our experiment individually. In the study, we first asked the subjects to watch a th ree-minute-long instruction video ( http://rerank.jp/everything/demo.mp4 ) that explained how to rerank search results. After they watched the video, we asked the subjects to visit a Web search engine and spend five minutes learning how to use our system. Then we asked the subjects to perform the following tasks: z You are seeking recipes for tomorrow X  X  dinner. Use the Web z After that, use the Web search e ngine without using our system During the task, when the subjects found a search result that contained information about an inte resting recipe, they were asked to double-click it, which changed its background color. In the experiment, if necessary, the subj ects were allowed to perform all kinds of interactions that the Web search engine provided, such as following links from search results , modifying their queries, using advanced search options, clicki ng suggested queries, and so on, regardless of whether they were using our system or not. The wrapper for the Web search engine was prepared in our system in advance so the subjects did not need to create any wrappers. To prevent the order effect, we divided eight subjects into four groups and changed the order of queries ( X  X ork and green pepper X  and  X  X eef and onion X ) and interfaces for searching for the information ( X  X sing our system X  and  X  X ithout using our system X .) From the study, we can see that the numbers of selected search results highly depended on the subjects. For example, one user chose many results (67 results) using our system and another user chose much fewer results (4 results) using our system. Average numbers of search results that subjects selected when using our system were not significantly diffe rent from those without using our system t 14 =0.37, p&gt;.05). However, we can see that 6 out of 8 subjects can find more results when they used our system. These results show that our system could support users in finding more interesting results than conventional search engines alone. In the conventional search engines, the ways for users to state their interests are limited to query m odification or advanced search options. On the other hand, in add ition to these functions, users can state their interests by selecting or clicking terms in the search results and TermCloud by using our system. Thus, users could easily collect search results that contain interesting terms like ingredients and adjectives by performing reranking operations. When the subjects used only the Web search engine, the average number of query modifications during the task was 0.625 (five query modifications within the whole subjects.) Four modifications active Web researchers and reported using Firefox as their default Web browser. In the study, we first asked the subjects to watch the instruction video described above. After they watched the video, we asked them to install our prototype system on their Firefox browser for the user study. The system already contained several wrappers for major search services such as Google, Yahoo!, Bing, Amazon, and so on. The subjects were allo wed to use our system for seven days. In the study, we did not impose any specific search tasks on the subjects. We asked the subjects to freely use our system since we wanted to investigate how our system would affect users X  daily search behavior. During the test period, we co llected 408 reranking operations from the subjects. The distribution of the types of reranking operation and the areas where users performed reranking operations are shown in Table 1. From the results, we can observe that about 70% of the reranki ng operations were promotion operations. One subject performed promotion operations eight times on one search results page. On the other hand, demotion operations were rarely used. As mu ch literature has explained [1], it was difficult for users to give negative feedback. The total queries issued to search engi nes were 452, and 17.7% queries were reranked. We think this per centage is not small since most queries that were not reranked we re navigational query and users did not need to rerank search results. Half of the term-based feedback was done in the TermCloud area. This indicates the TermCloud was effective in suggesting terms for reranking search results. When the subjects used Web search engines, 62% (94/151) of term -feedbacks were performed in TermCloud. On the other hand, when the subjects used other search services, such as publication search service and e-commerce sites, only 32% (51/150) of term-feedbacks were performed in TermCloud. Web sear ch results consisted of more unstructured text such as titles a nd snippets, so the subjects might have had difficulty in finding in teresting terms from the search results. Therefore, for Web searching, the subjects selected terms in TermCloud rather than in search results. Moreover, such unstructured text contains va rious terms, so TermClouds generated from Web search results could display unexpected and interesting terms to the subjects. Numerical feedback was used for various services such as e-commerce sites, publication sites, video sharing sites, and so on. For example, the number of view s and the uploaded dates were used on video sharing sites to sort video search results. The citation count and the publication year were often used on publication search services. For Web searching, some subjects tried to sort search results using numerical feedback. For example, one subject issued the query  X  X Pod X  and sorted search results by selecting  X 64GB X  in a search result. Thus the search results containing  X 160GB X  were reranked higher. In this way, our dynamic attribute extraction method allowed the subjects to utilize Web search results as ad hoc structured resources. Overall, however, the subjects rarely used numerical feedback in Web searching (only 22 times). We think this was because sorting Web search results was an unfamiliar task for the subjects and it was not easy for them to find appropriate numerical attributes from unstructured Web search results. Moreover, our extraction method is simple, so it often fails to ex tract correct attributes from Web search engines. To address thes e problems, we plan to develop some kinds of TermCloud-like suggestion systems that will 
