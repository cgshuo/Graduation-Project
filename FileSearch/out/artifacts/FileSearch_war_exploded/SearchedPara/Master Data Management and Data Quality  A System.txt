
Master Data Management (MDM) has been used to enable an organization or enterprise to associates all of its critical data to a single reference [1] . This reference provides a standar d-ized cent er of definitions that can be leveraged across different business units in an organiz a-tion [2] . By having this MDM reference, it is expected that the data redundancies and inco n-sistencies can be furthe r reduced [3] [4] [5] .

To the best of our knowledge, there has yet to be presented a systematic literature revie w report on the association between MDM and Data Quality in the research domain . Therefore, this paper intends to fill in the gap in the current research domain. The structure of this paper starts with the background of MDM and Data Quality definition. We then present the review methodology and subsequently discuss the review results based on the research questions. Finally we conclude the paper and recommend the future works. 2.1 Master Data Management
The genesis of MDM was started in 200 6 as a pr ocess of creating and maintaining the va l-ues and master data and the relationship between them [6] . Two years later, [3] defined as an approach that combines between architecture, technology and busine ss processes to slowly eliminating the amount of duplicated information and providing information to the consumers throughout an enterprise with authoritative master data. Furthermore in [7] , they described it is an application -independent process that explains, owns and manages core business of data entities. This process ensures the consistency and accuracy of this data through a single set of guidelines and creates a common view of key comp any data, which may or may not be held in a common data source.

Despite various MDM terms defined by earlier researchers, there are similarities that exist between them. It can be summarized that MDM is not just about the technology. It is also a managemen t of shared core data to reduce redund ancy and ensure better data quality through standardized definition and use of data values with a combination of process, governance and technology. It aims to serve data as a  X  X ingle reference of truth X  to the consume rs by consol i-dating and integrating the master data from multiple data sources into a central system. 2.2 Data Quality
Data Quality is defined as the measurement of agreement between data views that is repr e-sented by information system and data in the real world [8] . A study by [9] stated that in ave r-age, organisations have been disbursing huge amount of direct cost in data cleansing activities in order to improve the quality of information for their business. Moreover, the hidden cost of data quality issues such as lost opportunities, low productivity, waste, and myriads of other consequences, is believed to be much higher than these direct costs. 
The management of scattered datasets over multiple data sources is one of the data quality issues in an organisation. It has led to duplication, inaccuracy and inconsistency of info r-mation [10], [11] . Through a combination of processes , data governance, and technical i m-plementation of technology, MDM tends to resolve data quality issues that have been encou n-tered from the management of multiple data sources in an organisation. MDM is evaluated under the Information Systems (IS), Information Technology (IT) and Data Management field of stud ies [12]  X  [14] . Thus, this research adapted a systematic review methodology that is designed particularly for the IS research [15] . This study simplified the review protocol suggested by [15] to the following four (4) stages enumerated as follows: (1) research questions; (2) search strategy design; (3) study selection; and (4) analysis of findings. 3.1 Research Questi ons
As described earlier, this paper aims to summarize the existing literatures of MDM and to review the association of MDM and Data Quality . To achieve this aim, four (4) research que s-tions were formulated as shown in Table 1: 3.2 Search Strategy Design
There are four strategies that we have designed and they are, source of databases, search keywords and search criteria.

Source of Databases : There are n ine electronic repositories which are : 1) ACM Digital L i-brary; 2) Emerald; 3) Gartner; 4) IEEE; 5) Science Direct; 6) Scopus; 7) Springer Link; 8) Web of Science; and 9) Google Scholar. Title, abstract and index terms were used to conduct searches for jour nals, proceedings, books, book chapters and industry research.

Search Keywords : There are three steps involved in constructing the search keywords [16] which are: 1) Identification of alternative spellin gs and synonyms for major te rms; 2) Identif i-cation of keywords in rele vant papers or books ; and 3) Usage of the Boolean OR to incorp o-rate alternative spellings and synonyms. The initial search strings are ( X  X aster data X ), ( X  X a n-agement X ), ( X  X aster Data Management X ), and ( X  X DM X ). Then, the search strings were join t-ed usin g  X  X ND X  and  X  X R X  Boolean. The search strings were used in each electronic reposit o-on the advanced search facility.

Search Criteria : There are three search crite ria which are: 1) t he langua ge used in the paper is English, and 2) t he paper is categorized under journals, proceedings, books, book chapters and industry research.
 Study Selection
Initially, seven hundred and sixty seven literatures were identified by using the search keywords from eight electronic repositories. We then, extended our searching through a ma n-ual search from Google Scholar database . This is to ensure that all literatures that are not i n-dexing in any electroni c repositories will be handled as well . From this Google Scholar dat a-base search ing , ten additional literatures were found. 
During the searching process, metadata of the initial literatures results were gathered and indexed in Microsoft Excel sheet . The m etadata are: 1) Electronic Repository; 2) Title of the literature; 3) Abstract; 4) Year; 5) Publication Type; and 6) DOI/ISBN/ISSN Number. Based on the metadata, deduplication process was then performed to eliminate any duplicated copies of the literatures [17] . After performing the deduplication process, there were forty two dupl i-cate values we re found and removed. Then, t he new list of literatures became seven hundred and thirty five .

Next , a quality assessment activity was conducted through practical screening against the new the new list of literatures . The p ractical screening is the activity of screening the title and abstract of the literatures based on quality assessment criteria to check the relevance of the literatures [15] . The quality assessment criteria are listed in Table 2. Two phases of filtration were involved in this process. The first filtration listed three hundred and forty seven releva nt literatures that are based on quality assessment criteria in answering RQ 1 -3 . Then, second filtration was performed in answering RQ 4. Out of three hundred and forty seven literatures, there were forty nine literatures was selected (s ee Table 2 for the quality assessment criteria ) . The analyses of findings are presented in the Section 4 .

Fig. 1 . illustrates the s election process of this review which consists of searching process, de -duplication process and quality assessment process.
 The analysi s of findings is reported based on the formulated research questions. 4.1 RQ1 -When was the first literature of MDM being introduced and by how much 
Data f rom the review shows that the term  X  X aster Data Management X  had been in the lite r-ature abstrac t since year 1994 from Scopus journal database [18] . This term was mentioned in to describe one of the functional areas of an integrated system for computer -aided maint e-nance of diesel -powered vehicles . 
In 20 th century, this term was firstly described by Gartner in the SAP M DM analysis sol u-tion to manage and maintain the distributed master data within organisation [19] . S ince then, the MDM topic received increasing interest from 2006 in parallel with Big Data Era , whereas starting from 2010 the interest seems to be slightly decreased. 4.2 RQ2 -Who is leading the MDM research among the selected source of databases?
Fig. 2 . illustrates related literatures distribution by the sources. The chart only displays eight databases excluded Web of Science (WOS) database because most of the literatures were duplicated with Scopus database. 
The chart testifies that a total of 183 (52.7%) literatures come from the Gartner database and followed by Scopus database of 116 (33.4%). Others electronic database repositories recorded less than 50 literatures in each database: (Science Direct: 15 (4.3%); ACM: 13 (3.8%); Google Scholar: 10 (2.9%); IEEE: 5 (1.4%); Springer Link: 3 (0.9%); and Emerald: 2 (0.6%). This shows that industry rese arch by Gartner has led the MDM research as compared to academic research in eight others electronic repositories. 4.3 RQ3  X  How do the MDM literatures vary in different publication types? the distribution of MDM literatures among publication types which are industry research, journals,conference proceedings, book chapters, and books.

It is note d that a total of 54.18% of the literatures have been published as industry research whereas type of conference proceedings publication of 23.05% and only 19.02% are journals. The rest are books and book chapters of 2.59% and 1.15% respectively. This significantly shows that this topic needs an improvement of evidence in academic research in catching up the gaps from the industry research. 4.4 How does MDM associate with Data Quality ?
Analysis of the filtered literatures showed that the data quality aspects in the MDM r e-search are focusing on the management of multiple data sources and how MDM resolve the issues. In addition, earlier researchers also described that data quality is a critical success fa c-tor of MDM implementation [20]  X  [22] . The following paragraphs discuss the data quality issues on multiple data sources management, and followed by how MDM resolves those data quality issues. Finally, why data quality is a critical success factor of MDM implementation is discussed.
 Data Q uality issues on multiple data sources management . One of the issues on managing multiple data sources is the data are spread over a silo management practice [10] . Every bus i-ness unit tends to manage their own data without having alignment to other business unit . Moreover, it is likely one data source may contains similar datasets as in the other data sources and this datasets is being managed in silo by the respective owner (e.g business units, and departments). Over time, the management of these scattered datas ets over those multiple data sources has led to the data quality issues such as duplication, inaccuracy and inconsiste n-cy of information [10], [11] . 
With inconsistent, inaccurate and isolat ed data across multiple data sources, there is a high demand to have an integrated data management in an organization . There is a lot of enterprise data integration, data warehouse and data mart technologies have been used to meet the d e-mand [23] . Nevertheless, when there is a conflict between two similar data from different data They mainly used to resolve batch mode of data. Thus the MDM is a better real -time solution to address the weaknesses of the enterprise data integration, data warehouse and data mart technologies for the real time validation [25] .
 MDM resolve data quality issue on multiple data sources manag ement : MDM would resolve data quality issues on duplication, inaccurate, inconsistency data across multiple data sources management [26] . With MDM practice , the common critical data that give value s across business unit and departments will be consolidated into a central system datasets. T h e-se datasets will be considered as a highly accurate dataset [27], [28] . According to [3], [29] , MDM is not just about a technology, it is an approach to ensure data quality through a comb i-nation of processes, data governance, and technical implementation of technology. These three (3) elements play a critical role in resolving data quality issues of multiple data sources management (inaccuracy and inconsistent).
 First, there are two main processes which are : 1) Entity Resolution (ER) Process; and 2) Entity Identity Information Management (EIIM) [30] . Entity Resolution (ER) Process or also known as record linking or de -duplication is the essential process that have been recognized as a main data cleansing to remove the duplicate records and to promote data quality in dat a-base system s [31], [32] . On one hand, ER determines the accurate data when there are mult i-ple entities tha t have been identified from several sources which referring to the same set of EIIM is to sustain the identity integrity over time. EIIM is a basic requirement in MDM as it is specific operational configurations. These operationa l configurations are all executed together to maintain the entity identity integrity of master data over time. [30] With regards to data qua lity, EIIM is not limited to MDM but it can be applied to other types of systems suc h re f-erence data management systems, referent tracking systems and social media [34] . Overall, the MDM implementation wou ld promote data quality of an organization by incrementally reducing the amount of duplicated data and providing authoritative master data to the data consumers throughout an enterpris e [29], [35] .

Second, MDM builds quality into data management processes through documented roles and responsibilities under data governance [36]  X  [39] . T hree important aspects of data gover n-ance for MDM are: (1) managing key data entities an d critical data elements; (2) ensuring the obs ervance of information policies; and (3) documenting and ensuring accountability for maintaining high -quality master data [40] . To accomplish these tasks, an effective team of people which have a clean -cut mission statem ent and well -defined roles and responsibilities are very vital to be established. This team should be an association between business people and Information Technology (IT) staff [41] . 
Third, technologies are designed to be a system that integrates the multiple data source s i n-to a single unified view . Typically, MDM system consist of four (4) main modules which are: (1) data integration modul e ; (2) master data repository; (3) metadata repository; and (4) data quality module [11] . Fi g. 4 . illustrates the interrelation among the modules.

The data quality module pre -processes the input data from sources to MDM system through data clean ing and data standardization techniques . This module is also performing Entity Resolution (ER) Process and Entity Identity I nformation Management (EIIM) . The d ata integr ation module then combines pre -processed data from data quality module to provide a unified view of them by using schema mappings. After that, t he master data repository stores integrated master data processed by data integration module. The metadata repository mana g-es information about schema mappings between data sources and the master data repository [42], [43] . In recent years , the development of MDM systems has been fostered by large software vendors [15], [37] . To name a f ew, Oracle Master Data Management, IBM I nfoSphere Master Data Managemen t , SAP NetWeaver MDM and Informatica MDM [30], [35], [43] . While most of the MDM vendors tend to develop a comprehensive solution for MDM, yet there is still a lack of strength in other aspects of data quality be yond matching initial stages of an MDM effort , but some of the M DM system does not have that capabilities. For this reason, a growing number of integration and partnerships are arising between MDM vendors and data quality tools vendors [49]  X  [55] . High -quality master data is a critical success factor of MDM . MDM shares the data across several different systems or organizational units, serve as reference for transactional data, and rarely changed [35], [56] . Storing a high -quality of master data in the master data repository is one of the critical success factors of the MDM implementation [20]  X  [22], [57] . To achieve that, data quality assurance must be in place throughout the master data lifecycle [58] . Master data lifecycle phases typically consist of three (3) main stages which are: 1) Assessment; 2) Integration, and 3) Assurance [22] .
The assessment is an initial process where core data entities from multiple data sources are data selection are always identified from the business requirements [59], [60] . With the assi s-tance of tools and technologies, the assessment process identifies and analyses candidate ma s-before any data integration can begin [61] .

The integration stage is a process of linking up the identi fied core data together prior to data are gone through the cleansing, standardization, matching, and linkage process. After completing the integration processes, the integrated data are ready to be stored in master data repository and published to data con sumers. On top of using MDM solution during this stage, it also may require assistance from other data quality tools to perform these processes [50]  X  [52] .

The final stage of master data lifecycle is an assurance stage. MDM is not going to be a case of  X  X uild once and they will come. X  Changes in the master data requirements due to new business requirements or data user complaints may trigger a refinement of master data object design. Auditing and monitoring compliance with defined data quality expectatio ns coupled with effective issue response and tracking, along with strong data stewardship within a co n-sensus -based governance model, will ensure ongoing compliance with application quality objectives. According to [62] , the key ch allenges in managing master data is poor data quality. Hence, it is inevitable to instill data quality assurance in MDM implementation with the focus of master data [63] . Without a focus on managing the quali ty of master data, the organization runs a risk of repeating from an enterprise information management program to just another unsynchronized data silo [64] . This paper presents a systematic literature review results that has been conducted on the Master Data Management ( MDM ) state -of -the -art research progress. We have assessed nine (9) databases which are: 1) ACM D igital Library; 2) Emerald; 3) Gartner; 4) IEEE; 5) Science Direct; 6) Scopus; 7) Springer Link; 8) Web of Science; and 9) Google Scholar to come out with this report . T he report shows that the topic has received dominant growing interest from industry res earch compared to academic research communit ies . With regard to a data quality perspective , we could say that the data quality has codependence relationship with Master Data Management. On one hand, MDM could improve data quality management in an organization through a set of processes, predefined data governance, and technologies . On the other hand, the key success o f MDM implementation is depends on the data quality of the master data in central repository . For future works, it is highly recommended to further investigate on the association of MDM with other information systems research topics such as big data, data modeling, or business intelligence . The study is financially supported by a Contract Research Grant (Vot e No. 4C124) under Universiti Teknologi Malaysia.

