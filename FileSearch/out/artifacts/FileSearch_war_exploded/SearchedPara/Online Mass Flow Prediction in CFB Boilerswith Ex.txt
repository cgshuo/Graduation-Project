 Fuel feeding and inhomogeneity of fuel typically cause fluc-tuations in the circulating fluidized bed (CFB) process. If control systems fail to compensate the fluctuations, the whole plant will suffer from dynamics that is reinforced by the closed-loop controls. This phenomenon causes reducing effi-ciency and the lifetime of process components. In this paper we address the problem of online mass flow prediction, which is a part of control. Particularly, we consider the prob-lem of learning an accurate predictor with explicit detec-tion of abrupt concept drift and noise handling mechanisms. We emphasize the importance of having domain knowledge concerning the considered case and constructing the ground truth for facilitating the quantitative evaluation of different approaches. We demonstrate the performance of change de-tection methods and show their effect on the accuracy of the online mass flow prediction with real datasets collected from the experimental laboratory-scale CFB boiler. Continuous growth and increase of variance in electricity consumption can lead to frequent load changes. This calls for novel control concepts in order to minimize emissions and to sustain high efficiency during load changes. From combustion point of view the main challenges for the existing boilers are caused by a wide fuel selection, increas-ing share of low quality and bio fuels, and co-combustion. In steady operation, combustion is affected by the distur-bances in the feed rate of the fuel and by the incomplete mixing of the fuel in the bed. It may cause changes in the burning rate, oxygen level and increase CO 2 emissions. This is especially relevant for the new biomass fuels, which have increasingly been used to replace coal. The bio-fuels are rather inhomogeneous and very reactive in comparison with coal.
 Traditionally, mathematical models of CFB boiler opera-tion, have been developed [13; 10; 14], incorporating op-erational parameters in the models. More recently, data mining approaches were considered for developing better un-derstanding of the underlying processes in CFB boilers, or learning a model to optimize its efficiency [9].
 In our work we focus on a data driven approach for online mass flow estimation. It is required for efficient control of the boiler. Online estimation of fuel consumption in me-we overview the problem of a mass flow prediction in CFB boiler. In Section 3 we present our solution for online mass flow prediction. In Section 4 the experimental evaluation is presented and the results are discussed. We conclude and point out open problems in Section 5. To better understand and control the operation of CFB boiler it is important to know how much fuel mass is in the container. Direct measurement is hardly possible in prac-tice from the technological perspective. Therefore, fuel mass is calculated from estimates of a mass flow in the system. That is equivalent to predicting the amount of fuel in the fuel feeding system at each point in time, which we adress in this paper. We start by briefly explaining how the input signal is generated, discuss the properties of the data and available solutions. The automatically available mass signal is a noisy estimate of fuel mass at each operation time point. The mass of the fuel inside the container is measured by a scale, sampled with a sample rate of 1 Hz.
 The boiler is fed with fuel from the fuel container (bunker) as depicted in Figure 1. The fuel inside the container is mixed using a mixing screw. There is a feeding screw at the outlet of the container, which transfers the fuel from the container to the boiler. During the burning stage the mass of fuel inside the container decreases (reflected by a decreasing amount of fuel in the data signal). As new fuel is added to the container (the burning process continues), the fuel feeding stage starts that is reflected by a rapid mass increase.
 There are three main sources of changes in the signal: 1. Fuel feeding is manual and non standardized process, Let us define the original signal as x =( x 1 ,x 2 ,...,x t ,...,x n ). Having x as input we want to obtain the actual mass flow signal y that can be achieved by learning a functional map-ping, so that y = F ( x ).
 This problem has a connection to the problem of concept drift [7] that refers to unforeseen changes over time in the phenomenon of interest. Our phenomenon of interest here is the true signal, or actually the concept we aim to learn is the functional mapping F of noisy sensor measurements to the true actual signal.
 Once a change in the system stage happens (reasons are described in Section 2) the functional mapping F might be-come outdated. The learners capable of handling concept drift can be classier into proactive (explicitly detecting the change and dropping out the old training sample) or reac-tive (using forgetting heuristics at each time step to have the best adapted learner) [8]. The boiler data exhibits abrupt changes, thus we employ a proactive approach.
 The intuition behind the model is the following: at each point in time t we fit a model F ( x ), using all or a subset of the historical data x . If a change is detected, the old portion of the historical data is dropped out. A simplified estimation procedure is presented in Figure 3, the steps are explained in more detail in the following subsections. We start with selecting the functional mapping F corresponding to the step 3 and then consider methods for detecting sudden changes corresponding to the step 4.
 We assume that the mass flow signal has a nonzero second derivative. The nature of the measured phenomena in a single stage can be modeled using the following equation: y where y t denotes the output of the scales at time t , a is ac-celeration of the mass change, v 0 stands for the speed of the mass change at time t 0 , m 0 is the initial mass at time t 0 ; A and B ,  X  feed and  X  mix ,  X  feed and  X  mix are amplitude, fre-quency and phase of the fluctuations caused by the feeding and mixing screws, respectively; e ( t ) denotes the random peaked high amplitude noise caused by the jamming of the fuelparticleattime t . Note that here we assume t 0 was the time of switch from the feeding stage to burning or other way around.
 Since we are not interested in estimating the signal gener-ated by the oscillations of the screw and the noise signal, test is to compare the prediction performances obtained on different subsets of the data.
 When a new point arrives, it is tested for being an outlier (peak due to a fuel particle jamming) with respect to the preceding points. If it is classified as outlier, it is replaced by an extrapolation from these points. If outliers follow one another in a row, the state change is alarmed (pointing to the first outlier in the row) and the detected  X  X alse outliers X  that actually belong to the after-change period are restored from the backup buffer. The process continues then from the beginning of the newly detected phase.
 Parametric approach. Deterioration in the performance of the current model can be detected by keeping track of two statistical properties of the performance [4]. The first is the error rate that signifies the probability of miss classifying the actual value y t of the signal. The second is the standard deviation of the error rate. In [4] it is assumed that the classification task can be modeled by a binomial distribu-tion. Since the mass flow is continuous, we have to assume that given a large enough sample or window, the binomial distribution is close to a normal distribution with the same mean and standard deviation. This is used in an online test to see whether the signal has changed.
 Since this task is in continuous space, we use the Mean-Squared-Error (MSE) as metric for change detection instead of the error rate. For each time step the window is moved and for point x t all local reference MSEs are calculated with a leave-one-out cross validation (LOOCV).
 We assume that the model prediction performance is stable if the local found reference MSE ( E t ) satisfies where E min is the minimal found reference MSE, S min the minimal found reference standard deviation, and  X  a param-eter that reflects the level of confidence. If there is a large enough deviation in the signal the algorithm will report a warning. This level is determined by the condition: where  X  is the upper confidence bound signifying a change. Since it might occur that there is a local change in the signal (an outlier) it is not possible to go the change state imme-diately. If E t + S t &gt;E min +  X S min the algorithm reports a change and it will switch to the initial state of the other process. When this happens E min and S min are reset to the minimal found values in the new regime.
 This procedure puts a strict lower bound on the window size. Since we have to assume that the normal distribution is representative for the distribution of reference MSEs, the window size should be at least 30 consecutive points. In principle, a small window size is preferable when trying to detect rapid changes. But a smaller window size will result in a higher variation in the local models. In our experiments we used  X  =2,  X  = 3 (lower and upper bounds for the confidence interval), and the window size of 30 points. For each 30 accumulated points, the LOOCV is used. For each N  X  1 local model the MSE and it X  X  standard deviation are calculated. The transition conditions are checked and when an outlier is detected it is ignored by the global fit. If, after this, the algorithm detects a change, the boundaries for the transition criteria are reset and the global fit is relearnt for the future points.
 ADWIN method was originally designed for univariate se-quential data. The method works as follows: given a se-quence of signals it checks whether there are statistically significant differences between the means of each possible split of the sequence. If a statistically significant difference is found, the oldest portion of the data backwards from the detected point is dropped and the splitting procedure is re-peated until there are no significant differences in any possi-ble split of the sequence. More formally, suppose m 1 and m 2 are the means of the two subsequences as a result of a split. Then the criterion for a change detection is | m 1  X  m 2 | &gt; cut , where here n is total size of the sequence, while n 1 and n 2 are sizes of the subsequences respectively. Note that n = n 1 + n 2 .  X   X  (0 , 1) is a hyperparameter of the model. In our experiments we used  X  =0 . 3, n = 200.
 Heuristic approach. We design an online signal prediction approach, which takes into account the properties of mass flow signal (noise, trends, specific outliers, switch between operational stages).
 An intuitive solution for detecting the feeding stages, which are characterized by a steep increase in the signal value, would be to take the first order differences of the signal d the system is in feeding stage, if d (1) t &lt; 0 the system is in burning stage.
 Unfortunately, due to noise, the stages are undistinguishable directly (see Figure 5a). We can try replacing the original signal with the moving average, before taking the first order differences, this already gives apparent feed regions, but that still is noisy (see Figure 5b). Figure 5: Change detection using L th order signal differ-ences d ( L ) and moving averages (MA). The upper (black) line represents the original signal and the lower (blue) is the differentiated signal. Dashed line (green) is the threshold for a change. Circles indicate the ground truth change. We propose using L th order differences d ( L ) t = x t  X  x t  X  L , applied to a moving averaged signal for the detection of stage changes. The more noisy the signal is, the larger lag is needed. In this case study we use L = 10 (see Figure 5c) prediction is an unsupervised learning task. The need for prediction arises from the fact that there is no method to measure the ground truth . However, to verify the validity of the model we still need a benchmark. To obtain an approx-imation to the ground truth we use the following. Construction of the ground truth. We know that the outliers are oriented upwards. We identify the outliers by by comparing the difference between a point of the signal and the moving average against a threshold Tr out .Thenwe take a moving average of the signal with removed upward oriented outliers to obtain an approximation to the ground truth , which we associate with y , so predictions can be com-pared against the ground truth by computing mean absolute errors, MAE = 1 n n t =1 | e t | ,where e t = y t  X  X  ( x t ). Next we identify the change points from burning to feeding stage and vice versa ( C feed and C burn ). We employ AD-WIN, which showed to be robust to false positives in semi-online settings. ADWIN identifies C feed approximately. To get the exact change points we search for a maximum and minimum of the moving average in the neighborhood of the points identified by ADWIN. We validate the estimated ground truth by visual inspection of a domain expert and introduce changes where necessary.
 Experimental setup. We use dataset A for training and parametrization of the model. Datasets B and C are used as test sets, applying the model trained on A with identical parameterization. Note that the level of noise and outliers in the datasets are different. B and C represent two fuel tanks, operating in parallel, therefore there are nearly twice as much noise sources as in A.
 We conduct a set of experiments allowing a delay D in pre-dictions. E.g. having D = 10 (maximum possible delay suggested by the domain experts) we would predict (filter) the signal x t , but will have the historical data available up to time x t +9 inclusive. This gives smoother moving average (nearest neighbors from both sides are available) and it also allows verification of outlier and change detection. We do the following verification: the stage (feeding or burn-ing) is defined to be consistent if it lasts for not less than D time steps. Say at time t the system is at burning stage and at time t + 1 we detect a feeding stage. Having a delay D = 10 we are able to see the next four examples before casting the signal prediction for time t +1. Thus we check if the feeding stage sustains at time t +2 ,...,t +10. If positive, we fix the change point, if negative, we cancel the detected change and treat this as an outlier.
 Once a change is detected, old portion of the data is dropped out of the training sample. We do not use the 2 nd order polynomial model until we pass 10 samples after the change. For the first 2 samples we use simple moving average rule: x +1 = x t + s ,where s is a linear intercept term obtained using an average feeding stage pattern of the training dataset A. For burning stage s c =  X  2 is used, for feeding stage s f = 81. If more than 2 but less than 11 historical data points are available after the change, we fit the 1 st order polynomial model.
 We test for prediction accuracy and for change detection accuracy. We report the performance of the change detection in online Figure 8: Sensitivity of the heuristic method as a function of allowed change detection deviation for two different stages. ing stage or an upwards oriented outlier) and outer shape denoting the corresponding detection method (parametric, nonparametric or heuristic). Points having the same inner and outer shape are connected with lines such that they form a  X  X race X  of points corresponding to different lags ( t +1, t , t  X  1, etc.).
 Both the heuristic and the nonparametric methods are accu-rate in identifying outliers (sensitivity over 90%) and change points in burning stages (about 80%), heuristic approach seeming to be slightly ahead. However, the heuristic method has rather low TP rate with respect to change detection in feeding stages 2 , while the sensitivity of the nonparametric method here is more than 80% and the number of FPs is very small. The specificity of both methods is close to 100%. The parametric method is worse in detecting the changes generating the highest amount of FPs (e.g. roughly 300 FPs to 6 or 9 detected changes). The method is too sensitive and reports a change point roughly every 10 seconds. This does result in good accuracies for the prediction (since it is closely following the original signal), despite having a lot of local variation and relatively low TN rate (see Figure 7). We present MAE X  X  for the whole datasets and for feeding and burning stages separately in Table 3.
 MA stands for simple prediction by moving averages (over 3, 5 and 10 points for t  X  2, t  X  4and t  X  9 correspondingly), the number indicates how many instances are averaged.  X  X in50 X  uses the 2 nd order prediction model presented in Section 3.2, but instead of change detection a simple moving window of the 50 last instances is used for the model training at each time step.  X  X ll X  uses the 2 nd order prediction model with no change detection at all, it retrains the model at every time step. Finally we include a benchmark of the 2 nd order model assuming known change points ( X  X nown X ). We assume with this method that the change detection is 100% accurate. MAE in  X  X verall performance X  is rather close to MAE in  X  X urning stages X  and very different from  X  X eeding stages X . This is because of uneven distribution of the stages in the data.  X  X urning stages X  comprise less than 2% of the data.
 Heuristic and nonparametric outperform the competitive methods in terms of overall accuracy, nonparametric being slightly ahead. However, for the feeding stage, simple mov-
Note that low TP rate in this setting means that change points were not detected in time (within 10 sec interval). Figure 8 shows how the sensitivity of the heuristic method improves with increase of allowed detection deviation. and more intuitive than the nonparametric method. There is no trivial correlation between the accuracy of the change detection method and MAE of the eventual predic-tion. This has to do with the construction of the ground truth (e.g. local variance and the accuracy of sensitive meth-ods) and the types of errors that dominate the change de-tection method. This indicates that having more training window cuts than a  X  X erfect X  number, corresponding to the number of actual change points, might be beneficial. Having a stream of data there is no scarcity of training points and local fit might be accurate enough. We developed an effective approach for the online mass flow prediction during the boiler operation. In our approach we try to learn a regressor from the raw sensor measurements and therefore we employed abrupt change detection and noise canceling mechanisms. This appeared to be a challeng-ing task due to the signal properties and peculiarities of the data. We evaluated the performance of our approach and compared the accuracies of three change detection meth-ods of different nature: statistical parametric, nonparamet-ric and heuristic. We used real datasets from experimental CFB boiler, including two distinct fuel types and two dis-tinct operating stages (single vs. multiple fuel). One of the methodological challenges in this task is coming up with an approximation for constructing the ground truth for the signal, which we handle by a combination of mov-ing average and responding for change and outlier points in the offline settings. We used this approximation to evaluate the performance of the online predictors. Anyhow, our ex-perience shows that both quantitative and qualitative (i.e. visual inspective) evaluation of the performance are impor-tant. The process of developing a data mining solution for the problem at consideration appeared to be truly iterative and interactive.
 We achieved sufficiently accurate detection of changes in transition from the burning to the feeding stage, where the incline in signal is rather sharp. However, the reverse de-tection still has room for improvement. It should be noted, that the change point at this stage is hard to distinguish even visually.
 Overall, the domain experts found the achieved performance on the provided datasets acceptable and the next step of the research would be to employ the presented approach in operational settings when online mass flow estimation is used in the control system of the boiler.
 However, it remains interesting to explore the effects of the feeding screw on the mass signal in the context of gradual drift detection and handling. Furthermore, it would be in-teresting to come up with different models for different fuel types and different operational contexts. This research is partly supported by The Netherlands Orga-nization for Scientific Research (NWO) HaCDAIS project, Finnish Funding Agency for Technology and Innovations (TEKES) DYNERGIA project, and LOIS visitor grant. The authors are thankful to the domain experts, Timo Leino and Mikko Jegoroff for their endless support and valuable discus-sions.
