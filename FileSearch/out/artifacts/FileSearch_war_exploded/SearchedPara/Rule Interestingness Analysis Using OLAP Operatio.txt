 The problem of interestingness of discovered rules has been investigated by many researchers. The issue is that data mining algorithms often generate too ma ny rules, which make it very hard for the user to find the interesting ones. Over the years many techniques have been proposed. Ho wever, few have made it to real-life applications. Since August 2004, we have been working on a major application for Motorola. The objective is to find causes of cellular phone call failures from a large amount of usage log data. Class association rules have been shown to be suitable for this type of diagnostic data mining application. We were also able to put several existing inte restingness methods to the test, which revealed some major shortcomings. One of the main problems is that most existing methods treat rules individually. However, we discovered that users seldom regard a single rule to be interesting by itself. A rule is only interesting in the context of some other rules. Furthermore, in many cases, each individual rule may not be interesting, but a group of them together can represent an important piece of knowledge. This led us to discover a deficiency of the curre nt rule mining paradigm. Using non-zero minimum support and non-zero minimum confidence eliminates a large amount of c ontext information, which makes rule analysis difficult. This pa per proposes a novel approach to deal with all of these issues, which casts rule analysis as OLAP operations and general impression mining. This approach enables the user to explore the knowledge space to find useful knowledge easily and systematically. It also provides a natural framework for visualization. As an evidence of its effectiveness, our system, called Opportunity Map , based on these ideas has been deployed, and it is in daily use in Motorola for finding actionable knowledge from its engineering and other types of data sets. H.2.8 [Information Systems]: Data Management  X  Data Mining. 1.3.m [Computer Graphics]: Mi scellaneous  X  Visualization General Terms: Human Factors, Ma nagement, Design. Keywords: Diagnostic data mining, Interestingness analysis, general impressions, class a ssociation rules, OLAP. It is well known that many exis ting data mining techniques often produce a large number of rules, which make it very difficult for manual inspection of the rules to identify the interesting ones. This is called the interestingness problem. Over the years, many techniques have been proposed to d eal with this problem in order to help the user find useful knowledge. However, despite these efforts, interestingne ss remains a difficult problem. Few existing techniques have made it to real life applications. The difficulty is often attributed to the fact that interestingness is highly subjective. It depends on the us er X  X  current needs and his/her existing domain knowledge. While this is true, in this paper we also argue that another reason for the limited success is that we perhaps have looked in the wrong direction. Furthermore, the research is also somewhat mis guided by the current rule mining paradigm, which tends to fragment the knowledge space, creates a large number of holes in the space and makes it difficult for the user to find interesting knowledge. Since August 2004, we have been working on a major application for Motorola. The data set contains cellular phone call records. The raw data has more than 600 attributes and millions of records. After some pre-processing by our dom ain experts, we are left with just over 200 attributes. The data set is like any classification data set. Some of the attributes are continuous and some are discrete. One attribute indicates the final disposition of the call such as failed during setup , dropped while in progress , and ended successfully . This attribute is the class attribute in classification with discrete values. We note that this data set is only the data set that we began with. Our deployed system has been successfully used to analyze eleven (11) different data sets so far for entirely different applications in Motorola. Thus, we speak with some level of generality rather than based on only a single application. Two types of mining are usually pe rformed with this kind of data: 1. Predictive data mining : The objective is to build predictive or 2. Diagnostic data mining : The objective here is usually to Our above application falls into the second type. The objective is not prediction, but to better unders tand the data and to find causes of call failures or to identify situ ations in which calls are more likely to fail. That is, the user wants interesting and actionable knowledge. Interestingness evaluation of rules is thus the key. Clearly, the discovered knowledge has to be understandable. As the data set is a typical cla ssification data set, rules that characterize product problems are of the following form where X is a set of conditions and y is a class, e.g., for our above example y  X  { failed-during-setup , dropped-while-in-progress , ended-successfully }. In this paper, we focus on helping the user identify interesting knowledge based on such rules. These rules basically give the conditional probabilities of Pr( y | X ), which are exactly what a diagnostic data mi ning application is looking for. Moreover, such rules are easily understood. It is easy to see that such rules are classification rules , which can be produced by classification algorithms such as decision trees and rule induction, a nd class association ru le mining. However, traditional classification techniques such as decision trees and rule induction are not suitable for the task due to three main reasons: 1. A typical classification algor ithm only finds a very small 2. Due to the completeness probl em, the context information of 2. Since the rules are for classification purposes, they usually Class association rule mining [17] is found to be more suitable as minimum support and minimum c onfidence thresholds. Class association rules are a special type of association rules [1] with only a class on the right-hand-side of each rule. Using the Motorola application, we were able to put several interestingness techniques to the te st. We found that most existing interestingness techniques are useful to some extent, but they are  X  X ood to have X  techniques rather th an essential techniques. Thus, they cannot form the core of a ru le interestingness analysis system to help the user systematically identify interesting knowledge. To our great surprise, we also discove red that the current rule mining paradigm itself poses a major obs tacle for this interestingness analysis task. Below we first summarize the main shortcomings of the current interestingness techniques:  X  Lack of contexts: Most existing methods treat rules  X  Do not find generalized knowle dge from rules (meta-mining):  X  Lack of knowledge exploration tools: Due to the subjective Context is the key to dealing with all the above problems. However, the existing rule mini ng paradigm eliminates a large amount of contextual inform ation. Let us see why:  X  In the mining of class association rules, user-specified For example, an attribute B has three possible values, a , b , d . Due to the minsup we only find the rule B = a  X  c , where c is a class. The other two possible rules, B = b  X  c and B = d  X  c , which form the context for B = a  X  c , are not found because they do not satisfy the minsup. We call them holes (or gaps ) in the knowledge space. Then rule B = a  X  c does not have a context. We also cannot find any generalized knowledge about the attribute due to incomplete information or the holes. Hence, we say that the current mining paradigm fragment s the knowledge space and creates discontinuity in the space, which make the understanding and exploration of knowledge by human users very difficult. In this paper, we propose a novel a pproach to deal with all these problems. We show that a major pa rt of rule exploration can be casted as an OLAP problem (On-line Analytical Processing) [7] based on rule cubes whereby well established techniques in OLAP, e.g., slicing, dicing, dr illing down and rolling up, can be used to explore rules to systemically discover useful knowledge. Methods are also proposed to help the user find general impressions , which are also critical as they are what the users are very interested in. To the best of our knowledge, this is the first time that OLAP operations have b een used for rule interestingness analysis. The OLAP framework also provides a natural way for visualization with contexts. Together with the mining of general expressions, the proposed technique represents an effective and systematic approach. The mining support is provided by a class association rule miner. The full system, called Opportunity Map , based on this approach has been deployed and is in daily use in Motorola. Originally, the intended task was to identify causes of cellular phone call failures, but th e system has been found to be generic and has been used to mine many other data sets for the diagnostic type of applications and for data understanding. This work is related to three areas of research, rule mining, rule interestingness analysis and rule visualization. As we have discussed the shortcomings of the current rule mining paradigm in the introduction, we will not repeat it here. Below we only focus on rule interestingness analysis and visualization . There are several existing interestingness methods that can help the user find interesting knowledge. Unexpectedness : In this method, the user is asked to give some existing knowledge and the system then finds the unexpected rules [11][19][23][26][33]. This did not work well because our users were not sure what to expect. They wanted the system to find interesting knowledge for them. [4] studies neighborhood unexpectedness of rules. The neighborhood of a rule, which is similar to the concept of context, is a set of syntactically similar rules, i.e., involving similar items. Th is is not applicable to us. We need a different definition and also different rule mining. The idea of general impressions is first proposed in [16]. However, they need to be given by the user for finding unexpected rules. In this work, we mine general impre ssions from discovered rules. Rule ranking : Ranking rules according to some interestingness measures [2][9][28]. Our experiences show that almost all top ranked rules represent some artifacts of the data rather than any useful patterns. Moreover, givi ng only individual rules without contexts to compare with is not appropriate as we discussed earlier. This method does not find generalized knowledge. Querying and filtering : In [6][21], some data mining query languages are proposed to select th e right data to mine different types of rules. [14][30][31] also report several rule query languages to enable the user to specify what rules that he/she needs and the system then retrieve s the relevant rules. We tried this approach, but our users did not know what to ask. In [29], a set of rule post-processing operators is defined to allow the user to filter unwanted rules, select rules of interest, group rules, etc. This is a good approach. However, it stops short of providing contexts to rules and mining generalized knowledge. We also considered several other methods [8][24][27]. All of these and above methods had some use but were not sufficient. The first version of our syst em [35] was based on class association rules, rule ranking and grouping, and sophisticated visualization. However, the t echniques were not effective enough because they did not provide a systematic approach to enable the user to explore the knowledge space, and could not produce the kind of knowledge that the user needed. Thus, it was not a final product that could be deployed. The approach still requires extensive human effort to interpret the results, so was not considered satisfactory. Regarding data mining results visua lization, our work is related to rule visualization [13]. [10] proposes interactive mosaic plots to visualize the contingency tables of association rules. In [5], classification rules are visualized using rule polygons. [34] visualizes the temporal behavior of rules. In [12], a post-processing environment is proposed to browse and visualize association rules so that the user can divide a large rule set into smaller ones. In [22], important rules in terms of support and confidence values are highlighted with a grid view. In [20], ordering of categorical data is st udied to improve visualization. The above approaches mainly help to visualize individual rules. They do not actively help the user find useful knowledge. They visualize rules without sufficient contextual information. Thus, they differ from our approach in terms of both the goal and the visualization. Our visualization is based on rule cubes and OLAP with a set of well established and systematic operations. Before building the current system we spent more than a year building the first system [35]. As discussed in the related work, it was not deployable although the system was useful to some extent. After several demonstrations, it became clear to us that a new approach was needed as our domain experts were not willing to use it. However, our extensiv e interactions with the domain experts during the process were very valuable. We found that 1. Presenting rules individually and ranking them is not very 2. Users are interested in generalized knowledge because that is 3. Users are mostly interested in short rules, seldom more than 4. Users want to explore rules to discover knowledge based on OLAP based on rule cubes provides a generic and convenient environment for addressing all of these issues. By design, OLAP is an exploration tool. We will also see that interesting rules and their contexts can be visualized in the OLAP framework. General impressions can also be mined in the framework. Thus, interactive rule exploration and interesti ng knowledge finding are naturally integrated. This turned out to be a powerful approach, which is used in Opportunity Map. Class association rule mining provides the backbone mining support for the whole system. The conceptual framework of the proposed approach is shown in Fig. 1. The class association ru le miner produces both rule cubes for OLAP and also long rules (ru les with many conditions). We will discuss them shortly. GI miner mines general impressions (GI) from rules in rule cubes. The visualization and the user interaction are powered by th e usual OLAP operations, which also show the GI mining results and long rules. OLAP is a database technology. The idea is to organize the data using a multi-dimensional data cube . Each attribute and its values in the data represent a dimension. There is also a measurement attribute. Its values are the cell values in the cube. The well-known example is the sales data across different regions in different time periods [7]. The measurement attribute is the sales volume of each region in a particular quarter. Each dimension may also have a concept hierarchy, which allows the user to see the sales volume at different levels of hierarchy. The main OLAP operations are roll-up, drill-down, slice, and dice. Below, we introduce these operations in the cont ext of rules. We will see that these operations for data analysis are also very powerful for rule analysis. The OLAP framework thus presents a systematic methodology for the exploration of knowledge. Rules are not data. The problem is how to transform rules into cubes so that OLAP operations can be applied. We discuss it now. Let the set of attributes in the data D be A = { A 1 , A the class attribute be C . Let the domain or the set of possible values of an attribute A i be dom ( A i ). We want to convert class associa tion rules into cubes. Recall that class association rules (CAR) [17] are a special kind of association rules [1] with only a class on the right-hand-side of each rule. They are of the form: X  X  y , where X is a set of conditions, and y  X  dom ( C ) is a class. A condition is an attribute value pair of the form: A i =a ij ( a ij  X  dom ( A uses a distinctive attribute. CA R mining requires every attribute in the data to be discrete. This is not a problem as there are many existing discretization algorithms that can be used to discretize a continuous attribute into intervals. Given any set of attributes, { A i 1 , ..., A ip }  X  A , we use S to denote the set of all possible rules using the set of attributes: 
S = {( A i 1 = v 1 , ..., A ip = v p  X  C = c k ) | v The supports and confidences of the rules are omitted here. It is easy to see that all the ru les using the attributes can be represented as a cube with p +1 dimensions (1 being the class attribute). We call this a rule cube . The measurement attribute, which we do not have explicitly, is the support/frequency count of data records that satisfy each rule. Thus, each cell of the rule cube is represented with Its cell value is the number of data points that contains ( A ..., A ip = v p , C = c k ), which is simply the support count of the rule: A i 1 = v 1 , ..., A ip = v p  X  C = c k The confidence of the rule can be computed with where the function sup gives the support count of a cube cell. Let us see an example. We have a data set with three attributes. One of them is the class attribute C , which has two values, yes and no . The other two attributes are A 1 and A 2 . A 1 has four possible values data set has 1158 data points. The ru le cube is shown in Fig. 2, which represents 24 rules (3  X  4  X  2). Fig. 2. A rule cube example representing 24 rules. As an example, the rule, A 1 = a , A 2 = e  X  C = yes , has the support of 100/1158, and the confidence of 100/(100+50). The rule, A a , A 2 = f  X  C = yes , has the support of 0 and the confidence of 0. We see that the support and the confidence of each rule can be easily computed if we have the rule cube. In visualizing rules, we will have both values computed and visualized. Let us now see how various OL AP operations are performed on the rule cube. Roll-up : The roll-up operation performs aggregation on the rule cube, either by climbing up a concept hierarchy for a dimension or by dimension reduction. In application, it is easy to build a concept hierarchy for an attribute based on the domain knowledge or requirement. For example, we may group the values a and b Likewise, we can group ab and cd to create a concept abcd . This gives a 3-level hierarchy. In an actual application, suitable names can be given to the concepts. He re, we only use an example of Fig. 1 . The conceptual framework of Opportunity Map dimension reduction to show the working of roll-up. For instance, if we remove attribute A 1 , we obtain the sub-cube in Fig. 3. Fig. 3. Roll-up: after removing the dimension A 1 This roll-up operation gives us 6 one-conditional rules: A 2 = e  X  C = yes A 2 = e  X  C = no A 2 = f  X  C = yes A 2 = f  X  C = no A 2 = g  X  C = yes A 2 = g  X  C = no Computing their supports and conf idence is straightforward. Drill-down : Drill-down is the reverse of roll-up. It goes from less detailed data to more detailed data. Drill-down can be stepping down a concept hierarchy for a dimension or introducing additional dimensions. For example, if our current cube only has two dimensions, A 2 and C , then adding the A constitutes a drill-down operation, which give more detailed information. For example, we can drill down from Fig. 3 to Fig. 2. Slice : The slice operation performs a database selection on one dimension of the given cube, resulting in a sub-cube. For example, if we select using the criterion A 1 = a , we obtain the sub-cube in Fig. 4. Fig. 4. A slice operation This operation gives us the following 2-conditional rules: A 1 = a , A 2 = e  X  C = yes A 1 = a , A 2 = e  X  C = no A 1 = a , A 2 = f  X  C = yes A 1 = a , A 2 = f  X  C = no A 1 = a , A 2 = g  X  C = yes A 1 = a , A 2 = g  X  C = no Dice : The dice operation defines a sub-cube by performing a selection on two or more dimensi ons. For example, if we do the selection, ( A 1 = a or A 1 = b ) and ( A 2 = e or A sub-cube in Fig. 5. Fig. 5. A dice operation This operation results in the following rules: A 1 = a , A 2 = e  X  C = yes A 1 = a , A 2 = e  X  C = no A 1 = a , A 2 = f  X  C = yes A 1 = a , A 2 = f  X  C = no A 1 = b , A 2 = e  X  C = yes A 1 = b , A 2 = e  X  C = no A 1 = b , A 2 = f  X  C = yes A 1 = b , A 2 = f  X  C = no There are other OLAP operations. However, the operations above have been shown sufficient for finding interesting knowledge. Our practical experience shows that OLAP operations are useful for interestingness analysis due to the following reasons: 1. They allow the user to see rules in context because all relevant 2. The cube representation of rules gives us a natural way to 3. They allow general impressions about rules to be easily mined 4. The well defined operations of OLAP enable the user to The downside is that we cannot build a huge rule cube to cover all attributes in the data as the c ube size grows exponentially with the number of attributes. Fortunately, we do not need such a huge rule cube in practice because our application experiences show that users are seldom interested in l ong rules. In this work, we only build all 3-dimensional rule c ubes (the class attribute is a dimension in every rule cube). This can be done using a class association rule miner, which al so generates longer rules at the same time. Cube generation and ru le mining are thus integrated. To support the cube operations us ing a class association rule (CAR) miner, we need to find all possible rules. This means that we have to set both minsup and minconf to 0. However, this causes combinatorial explosion. We need a compromise.  X  We set minsup and minconf to 0 in mining rules with 1 and 2  X  We set non-zero minsup and minconf for rules with more All these can be done quite easily in a CAR miner such as CBA [17] by setting some parameters . We have re-implemented CBA to accommodate the required flexibility. For more details on class association rule mining, please refer to [17][15]. Slice for A 1 = a : e f g We also note that rule cubes do not need to be materialized. The tree structure (we use a hash tree) for generating and storing CAR rules can be used directly as virtual cubes by OLAP operations. Our current implementation takes this approach. However, it is possible to materialize the cubes and store them on disk if there is not enough main memory for generating long rules. As we discussed in Section 4, domain experts usually look for general knowledge which is broa dly applicable and exception rules in some contexts. As we mentioned earlier, they often say  X  "Attribute A is an important attribute": We call such attributes  X  "When the values of attribute A i increase (or decrease), the  X   X  X hen the attribute A i takes value a ij , the phone call is more These pieces of knowledge are ca lled general impressions (GI). The question is how to let a data mining system find such knowledge in the first place. This is the topic of this section. General impressions are mine d from the following construct: where X is a set of conditions, which can be empty (i.e., | X |  X  0), A is an attribute, and C is the class attribute. Each condition in X is an attribute value pair expressed as A k = a data constraint as it defines a subset of the data D satisfies the constraint. Attribute A i is called the active attribute as we will consider all its values. Let the set of attributes used in X be X A . We have | X | = | X A | (each attribute in X is distinct) and X { A } =  X  . Thus, X , A i  X  C represents a set of rules: {( X , A i = a ij  X  c k ) | a ij  X  dom ( A i ), c k  X  dom ( C )}. These rules can be easily obtained by an OLAP operation. In the examples in Section 4, if X =  X  , these rules can be obtained by a roll-up operation in Fig. 2. If X contains A 1 obtained by a slice operation in Fig. 4. As we discussed above, a rule is only interesting in a meaningful context. The context of a rule is simply its sibling rules, which can be defined in various ways. Our applications show that the following definition is a very useful one. Definition (context of a rule) : The context of the rule ( X , A  X  c k ) consists of the following rule s, which cover all the values of the active attribute A i : where { a i1 , ..., a ir } is the domain of A i called sibling rules of one another. In this context, we can compare all rules and detect values of A that represent exceptions, i.e., highly correlated (positively or negatively) to the class c k . We compute exceptions based on confidences, but can be done in other ways. Definition (degree of exception in confidence): The degree of exception , denoted by DE ( X, A i =a ij , c k ), of the rule ( X , A  X  c k ) is measured by how the obs erved confidence is different from the expected confidence: where Conf O ( X , A i =a ij , c k ) is the observed confidence of the rule, and Conf E ( X , c k ) is the class c k 's prior probability in D We now compute the discriminative power of an attribute. Definition (discriminative power of an attribute) : The discriminative power of attribute A i given X is the ability of this attribute to distinguish data of all classes in D DC : where r is the number values of attribute A i , m is the number of classes, sup ( X , A i = a ij , c k ) is the support count of the rule: X, A = a ij  X  c k , and w c importance of class c k . This weight parameter is useful because it enables the user to focus on the class that he/she is interested in. We note that there are other ways to define discriminative power of an attribute, e.g ., information gain [25]. Ranking can be performed based on the results. Recall a trend represents a pi ece of knowledge that when the values of an attribute increase/decrease, a particular class is more/less likely to occur. The trend analysis is only applicable to continuous attributes and ordinal attributes. Definition (unit trend of A i on class c k ): A unit trend of attribute A i with respect to class c k and fixed conditions X , denoted by 
UT ( X , A i = [ a ix , ..., a iy ], t l , c k ), is a trend t confidences of a set of consecutive values [ a ix , ..., a attribute A i with respect to class c k in D DC . t type ) is decided by a statistical test, and takes one of the types from the set { increasing-trend , decreasing-trend , stable-trend }. 
The value range from a ix to a iy is such that any larger range will not have the trend t l . That is, the trend is maximal . over the values of the attribute. For example, it can have an increasing trend from value1 to value5 , and a decreasing trend from value6 to value10 . An example trend is: Here, " loan approved " is the class c k that we are interested in. The attribute " salary " is the trend attribute A increasing trend t l as its values go from small a ix to large a A unit trend is derived from a set of rules based on their confidences. For example, the above simple trend may be derived from the following rules: Rule 1: salary = 20K  X  loan_approved, Confidence: 20% Rule 2: salary = 30K  X  loan_approved, Confidence: 35% Rule 3: salary = 40K  X  loan_approved, Confidence: 40% By using the trend relationship, all the three rules (or even more) can be summarized into a single piece of knowledge. This unit trend has the value range from 20K to 40K. Our domain experts really like this notion because that is what they are interested in and is exactly the format that they are familiar with. The type of a trend is calculated using a statistical test called reverse arrangement test [3]. For example, to test whether it is an increasing trend, we first calcula te how many times that a later value is strictly greater than an earlier value. Each time that happens, we call it a reversal . If there are a lot of reversals (more than are likely from pure chance with no trend), we have significant evidence of an increasing trend. If there are too few reversals we have significant evidence of decreasing trend. Formally, it works as follows: For r values, the maximum possibl e number of reversals is r ( r -With value r and R , we can lookup the statistic tables [3] to For each unit trend, we also compute two statistical properties. Support : It is the sum of the data points this trend covers (can be the raw count). It can also be e xpressed as a percentage of the total number of data points in D DC . Confidence : It is used to indicate how likely the trend is correct. 
A value of 1.0 indicates a perfect trend of that type without exception. Otherwise, it is calcu lated based on how many data values and their covered data poi nts satisfy the trend behavior. where Abnormal_data is the data count which does not follow the trend. Definition (trend value of an attribute on class c value of attribute A i given X , denoted as TV ( X , A respect to class c k for trend type t l in data D DC where UT j is an unit trend of attribute A i and there are k such unit trends. Finally, we can use the trend values ( TV ) to rank attributes according to different types of trends ( increasing-trend , decreasing-trend or stable-trend ). The user can see them in the visualization and determine which tr ends are interesting. We also note that there are other ways for computing the trend value of an attribute. The above method works quite well for our applications. We first give a brief description of our system. The main focus is on the visualization sub-system. We then discuss the evaluation. The Opportunity Map system consis ts of five main components: a discretizer, a CAR rule generator, a GI miner, and a visualizer. Given a data set, continuous attri butes are first discretized using the discretizer (a manual discretization option is also available). The discretized data is fed into the CAR rule generator. The resulting rules form 3-dimentional virtual rule cubes. The user uses the visualizer to explore the rule space based on OLAP operations. GI miner is called wh en requested based on the sub-cube shown on screen. Below, we give more details on rule cube visualization. Due to the use of rule cubes and OLAP operations, the visualization is simple. In our system, every visualization screen is a 2-dimensional matrix. Each gr id in the matrix visualization visualizes one or more cells in the rule cube. 1. For a 2-dimensional cube, each grid represents a cube cell. 2. For a 3-dimensional cube, each grid represents the cube cells Note that rules with more than two conditions are not visualized in our current system as they are seldom used in our applications (our engineers said that it is very hard to do anything about long rules). However, if the user want s to see longer rules related to a cube cell, the relevant rules w ill be listed in a separate window. Since the proposed system helps the user find subjectively interesting/useful knowledge, it is difficult to have an objective measure of its effectiveness. As an evidence of its effectiveness, our system has been deployed and is in regular use in Motorola. The original intended application was to find causes of cellular phone call failures from the call log data. Due to its success, the system has been used to analyze more than 11 large data sets for entirely different applications by Motorola engineers. Many pieces of actionable knowledge have also been put to practice use. Here, we give a case study using th e call log data to show how the user interacts with the system to find useful knowledge. The goal is to discover possible causes of ca ll failures. This is a large and high dimensional data set. It has seventy six million data records, and about 600 attributes. Sampling was used to reduce the data size. After some initial analysis by domain experts, the number of attributes was reduced. This version of the data contains 211 attributes, in which one attribute is the class attribute with three values. The majority class covers a very large proportion of the data. Due to confidentiality, we could not disclose the exact percentage. All the attribute names and values are also replaced by generic names and values. The visualization uses a matrix layout, and has two main modes, overall visualization mode , and detailed visualization mode . In the overall visualization mode (Fig. 6), the X axis is associated with all attributes in the data. The Y axis is associated with all the classes. For each attribute (a column), each grid shows all one conditional rules of the correspondi ng class value. Each rule is visualized as a thumbnail bar. The height of the bar is the rule confidence value. Thus, this sc reen simply shows all the 2-dimensional rule cubes. Each rule cube is formed by the class attribute and one other attribute. Each column shows one cube. The system supports automatic s caling among classes to address the class imbalance issue. Sca ling increases relative proportions. In Fig. 6, it has already been a pplied. Otherwise, we will not see anything for the minority classes (the first two classes on the Y axis), which are the classes that our users are interested in. Blue color is used by default. So me attributes may have so many possible values (e.g., Att002, Att003, etc.) that the grid size may be inadequate to draw them all. Li ght blue is used to indicate this. To see all values, the user can eith er increase the grid size, or use a detailed visualization (see be low). Various support counts and proportions are written on the screen or in the Information Panel on the right when the user m oves the mouse over the screen. This overall visualization mode is able to summarize and show a number of important properties of the data immediately: 1. The data distribution of each attribute is illustrated by the 2. One-conditional class association rules are visualized for all 3. Trends are detectable from the shape in each grid. Strong unit After seeing the overall visualization, the user may be interested in trends and want to see which attributes are strongly correlated with the classes. For example, if he is interested in seeing increasing trends with respect to the first class (first row, class Value4733), using a sorting command from the menu, he gets the visualization in Fig. 7. Attributes are sorted so that those with strongest increasing trends on cl ass Value4733 appear first on the X axis. With this screen, the user can easily confirm his previous knowledge, or find new knowledge. For example, it clearly shows that as the values of attribute Att951 increase from small to large, the chance of occurrence of fa ilure class Value4733 increases. This may be a vital piece of knowledge that could be used in product design. Visualization of so rted trend attributes for other trend types and classes is vi ewable using similar commands. Another sorting shows the discrimi native attributes (Fig. 8). Note that the pink color is used to indicate that the scaling produced some very small values that can hardly be seen on screen (for that grid). The top ranked attributes all have strong discriminating powers on the classes. For example, the values of the first attribute (Att021) clearly discrimina te data into different classes. Attribute Att020 also has strong discriminating power except for the middle 4 values. Our users confirmed that this kind of knowledge is very useful. Also crucia l is the fact that the user can view all the details side-by-side. This provides context for visual comparison and discovery, which is vital in practice. Visualizing all the 2-dimensional rule cubes in the overall visualization is very useful to get the users started and to pick the right attributes for further study using the detailed visualization . A detailed visualization shows e ither a larger version of a 2-dimensional rule cube (Fig. 9), or a 3-dimensional rule cube (Fig. 10). The X axis shows the values of a given attribute. The Y axis shows another attribute (usually the class attribute). 1. Fig. 9 shows a detailed visuali zation of one attribute (Att001, 2. Exceptions of this attribute. The dotted dark blue horizontal For each piece of knowledge discovered here, the user is able to see all the related classes (in the vertical direction) and all the related values (in the horizontal di rection) from the visualization. They act as the context. Now, s uppose the user is interested in seeing what will happen if another condition is added. This is an OLAP slice operation. It is visua lized by adding a data constraint to the visualization so that the subset of data can be visualized and studied. Fig. 10 shows the result of using attribute "Att012 = Value0497" as the data constrai nt (Value0497 is a phone model). Thus, all the information shown in this visualization has 2 attributes involved (plus the cla ss attribute), i.e., two conditional rules. For example, the rule in the grid of row 2 and column 2 is: Comparing with Fig. 9, we can see that the slice operation affects the last column greatly. It changed the class Value4734 from below expected confidence in Fig. 9 to far above expected confidence in Fig. 10. Visualizing 3-dimensional rule cubes (or sub-cubes) using detailed visualization can be employed for comparative study, as shown in Fig. 11. It "stacks" tw o or more detailed visualizations by drawing the bars for each corresponding grid side by side into one grid, creating a clear contrast view in each grid. Since the Y axis is the class attribute and the data constraints represent two different phones, this visualiza tion shows that the second phone (Value0498) has a lower failure rate than the first one, by having consistently tall bars in the row of Value4735 (the class for "success calls"). Other rows a nd bars show how the products perform on different values of A tt012 as well as the comparisons between them. This visualization is produced by a slice operation. Due to space limitation, we are unable to show many other types of analysis that can be performed on the system. In summary, the overall visualiza tion provides a summary of all the 2-dimensional rule cubes. Vari ous sorting of attributes give the user different general impressi ons. This allows the user to pin down interesting attributes easily. Detailed visualizations provide further information and enables detailed analysis. What is crucial is that all pieces of information and rules are shown in context within their corresponding rule cube s or slices, which enables the user to quickly detect interesting knowledge. Our users confirm that the system to allow them to easily analyze their data. This paper proposed a novel approach to rule analysis to help users find useful knowledge. The approach has four key ideas. The first idea is that the traditi onal mining paradigm hinders rule analysis. The second idea is that rules need to be analyzed in context. The third idea is that rule analysis can be performed using OLAP operations. The fourth idea is the mining of general impressions. Rule cubes and OLAP provide a general framework for exploration of rules in context to enable the user find useful knowledge. A data mining system, called Opportunity Map, based on the ideas and class association rules have been built. The system has been deployed and is in daily use in Motorola. [1] Agrawal, R. and Srikant, R.  X  X ast algorithms for mining [2] Bayardo, R. and Agrawal, R.  X  X ining the most interesting [3] Bendat J., Persol A. Random da ta: analysis and measurement [4] Dong G., Li J. Interestingness of discovered association rules [5] Han J, Cercone N. "RuleViz : A model for visualizing [6] Han J., Fu, Y., Wang W., Koperski, K. and Zaiane, O. [7] Han, J and Kamber, M. Da ta mining: concepts and [8] Hussain, F, Liu, H, Suzuki, E ., Lu, H. Exception rule mining [9] Hilderman, R., Hamilton, H.  X  X valuation of interestingness [10] Hofmann H, Siebes A., Wilhelm, A. "Visualizing association [11] Jaroszewicz, S., and Simovi ci, D.  X  X nterestingness of [12] Jorge A., Pocas J., Azevedo P. "Post-processing environment [13] Keim D. "Information visualiza tion and visual data mining". [14] Klemetinen, M., Mannila, H., Ronkainen, P., Toivonen, H., [15] Liu, B. Web Data Mining: e xploring hyperlinks, contents, [16] Liu B., Hsu W. and Chen S.,  X  X sing general impressions to [17] Liu B., Hsu W., and Ma Y.  X  X  ntegrating classification and [18] Liu B., Hsu W., Ma Y.  X  X ining association rules with [19] Liu, B., Hsu, W., Mun, L., &amp; Lee, H.  X  X inding interesting [20] Ma S., Hellerstein J. "Ordering categorical data to improve [21] Meo, R. Psaila, G., and Ceri , S.  X  X  new SQL-like operator [22] Ong K-H, Ong K-L, Ng W-K, Lim E-P. "CrystalClear: [23] Padmanabhan, B. and Tuzhilin ,  X  X . knowledge refinement [24] Piatesky-Shapiro, G., and Math eus, C.  X  X he interestingness [25] Quinlan J.R. C4.5: Programs for Machine Learning. 1993. [26] Silberschatz, A, Tuzhilin, A. Wh at makes patterns interesting [27] Suzuki, E.  X  X utonomous discovery of reliable exception [28] Tan, P-N. &amp; Kumar, V.  X  X  nterestingness measures for [29] Tuzhilin, A. and Adomavicius, G.  X  X andling very large [30] Tuzhilin, A., and Liu, B.  X  X uerying multiple sets of [31] Virmani A., Imielinski, T.  X  X -SQL: A query language for [32] Vapnik, V. The nature of statistical learning theory. 1995. [33] Wang K., Jiang Y., Lakshmanan L. V.S.  X  X ining [34] Zhao K. Liu, B., Tirpak, T. and Schaller, A. "V-Miner: using [35] Zhao K., Liu B., Tirpak T. and Xiao W.  X  X  visual data 
Fig. 11. Detailed visualization of one 3-dimensional rule 
