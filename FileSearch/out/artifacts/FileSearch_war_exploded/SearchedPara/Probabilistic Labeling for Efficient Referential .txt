 In situated human-robot dialogue, humans and robots have mismatched capabilities of perceiving the shared environment. Thus referential commu-nication between them becomes extremely chal-lenging. To address this problem, our previous work has conducted a simulation-based study to collect a set of human-human conversation data that explain how partners with mismatched per-ceptions strive to succeed in referential commu-nication (Liu et al., 2012; Liu et al., 2013). Our data have shown that, when conversation partners have mismatched perceptions, they tend to make extra collaborative effort in referential commu-nication. For example, the speaker often refers to the intended object iteratively: first issuing an initial installment , and then refashioning till the hearer identifies the referent correctly. The hearer, on the other hand, often provides useful feedback based on which further refashioning can be made. This data has demonstrated the importance of in-corporating collaborative discourse for referential grounding.

Based on this data, as a first step we developed a graph-matching approach for referential ground-ing (Liu et al., 2012; Liu et al., 2013). This ap-proach uses Attributed Relational Graph to cap-ture collaborative discourse and employs a state-space search algorithm to find proper ground-ing results. Although it has made meaning-ful progress in addressing collaborative referen-tial grounding under mismatched perceptions, the state-space search based approach has two ma-jor limitations. First, it is neither flexible to ob-tain multiple grounding hypotheses, nor flexible to incorporate different hypotheses incrementally for follow-up grounding. Second, the search al-gorithm tends to have a high time complexity for optimal solutions. Thus, the previous approach is not ideal for collaborative and incremental di-alogue systems that interact with human users in real time.

To address these limitations, this paper de-scribes a new approach to referential grounding based on probabilistic labeling. This approach aims to integrate different types of evidence from the collaborative referential discourse into a uni-fied probabilistic scheme. It is formulated un-der the Bayesian reasoning framework to easily support generation and incorporation of multi-ple grounding hypotheses for follow-up processes. Our empirical results have shown that the prob-abilistic labeling approach significantly outper-forms the state-space search approach in both grounding accuracy and efficiency. This new ap-proach provides a good basis for processing col-laborative discourse and enabling collaborative di-alogue system in situated referential communica-tion. Previous works on situated referential grounding have mainly focused on computational models that connect linguistic referring expressions to the per-ceived environment (Gorniak and Roy, 2004; Gor-niak and Roy, 2007; Siebert and Schlangen, 2008; Matuszek et al., 2012; Jayant and Thomas, 2013). These works have provided valuable insights on how to manually and/or automatically build key components (e.g., semantic parsing, grounding functions between visual features and words, map-ping procedures) for a situated referential ground-ing system. However, most of these works only dealt with the interpretation of single referring ex-pressions, rather than interrelated expressions in collaborative dialogue.

Some earlier work (Edmonds, 1994; Heeman and Hirst, 1995) proposed a symbolic reasoning (i.e. planning) based approach to incorporate col-laborative dialogue. However, in situated settings pure symbolic approaches will not be sufficient and new approaches that are robust to uncertain-ties need to be pursued. DeVault and Stone (2009) proposed a hybrid approach which combined sym-bolic reasoning and machine learning for inter-preting referential grounding dialogue. But their  X  X nvironment X  was a simplistic block world and the issue of mismatched perceptions was not ad-dressed. Previously, we have collected a set of human-human dialogues on an object-naming task (Liu et al., 2012). To simulate mismatched perceptions between a human and an artificial agent, two par-ticipants were shown different versions of an im-age: the director was shown the original image containing some randomly placed objects (e.g., fruits), and the matcher was shown an impov-erished version of the image generated by com-puter vision. They were instructed to communi-cate with each other to figure out the identities of some  X  X amed X  objects (only known to the direc-tor), such that the matcher could also know which object has what name.
 Here is an example excerpt from this dataset:
As we can see from this example, both the direc-tor and the matcher make extra efforts to overcome the mismatched perceptions through collaborative dialogue. Our ultimate goal is to develop com-putational approaches that can ground interrelated referring expressions to the physical world, and enable collaborative actions of the dialogue agent (similar to the active role that the matcher played in the human-human dialogue). For the time be-ing, we use this data to evaluate our computa-tional approach for referential grounding, namely, replacing the matcher by our automatic system to ground the director X  X  referring expressions. 4.1 System Overview Our system first processes the data using auto-matic semantic parsing and coreference resolu-tion. For semantic parsing, we use a rule-based CCG parser (Bozsahin et al., 2005) to parse each utterance into a formal semantic representation. For example, the utterance  X  X  pear is to the right of the apple X  is parsed as which consists of a list of discourse entities (e.g., a 1 and a 2 ) and a list of first-order-logic predicates that specify the unary attributes of these entities and the binary relations between them.

We then perform pairwise coreference resolu-tion on the discourse entities to find out the dis-course relations between entities from different ut-terances. Formally, let a i be a discourse entity ex-tracted from the current utterance, and a j a dis-course entity from a previous utterance. We train a 2003) to predict whether a i and a j should refer to the same object (i.e. positive ) or to different ob-jects (i.e. negative ).

Based on the semantic parsing and pairwise coreference resolution results, our system fur-ther builds a graph representation to capture the collaborative discourse and formulate referential grounding as a probabilistic labeling problem, as described next. 4.2 Graph Representation We use an Attributed Relational Graph (Tsai and Fu, 1979) to represent the referential grounding discourse (which we call the  X  dialogue graph  X ). It is constructed based on the semantic parsing and coreference resolution results. The dialogue graph contains a set A of N nodes: in which each node a i represents a discourse en-tity from the parsing results. And for each pair of nodes a i and a j there can be an edge a i a j that represents the physical or discourse relation (i.e. coreference) between the two nodes.

Furthermore, each node a i can be assigned a set of  X  X ttributes X : which are used to specify information about the unary properties of the corresponding discourse entity. Similarly, each edge a i a j can also be as-signed a set of attributes x ij to specify informa-tion about the binary relations between two dis-course entities. The node attributes are from the semantic parsing results, i.e., the unary proper-ties associated to a discourse entity. The edge at-tributes can be either from parsing results, such as a spatial relation between two entities (e.g., RightOf ( a 1 ,a 2 ) ); Or from pairwise coreference resolution results, i.e., two entities are coreferen-tial ( coref = + ) or not ( coref =  X  ).

Besides the dialogue graph that represents the linguistic discourse, we build another graph to rep-resent the perceived environment. This graph is called the  X  vision graph  X  (since this graph is built based on computer vision X  X  outputs). It has a set  X  of M nodes: in which each node  X   X  represents a physical ob-ject in the scene. Similar to the dialogue graph, the vision graph also has edges (e.g.,  X   X   X   X  ), node attributes (e.g.,  X  x  X  ) and edge attributes (e.g.,  X  x Note that the attributes in the vision graph mostly have numeric values extracted by computer vision algorithms, whereas the attributes in the dialogue graph have symbolic values extracted from the lin-guistic discourse. A set of  X  X ymbol grounding functions X  are used to bridge between the hetero-geneous attributes (described later).

Given these two graph representations, referen-tial grounding then can be formulated as a  X  node labeling  X  process, that is to assign a label  X  i to each node a i . The value of  X  i can be any of the M node labels from the set  X  . 4.3 Probabilistic Labeling Algorithm The probabilistic labeling algorithm (Christmas et al., 1995) is formulated in the Bayesian frame-work. It provides a unified evidence-combining scheme to integrate unary attributes, binary rela-tions and prior knowledge for updating the label-ing probabilities (i.e. P (  X  i =  X   X  ) ). The algo-rithm finds proper labelings in an iterative manner: it first initiates the labeling probabilities by consid-ering only the unary attributes of each node, and then updates the labeling probability of each node based on the labeling of its neighbors and the rela-tions with them.
 Initialization: Compute the initial labeling probabilities: P in which  X  P (  X  i =  X   X  ) is the prior probability of labeling a i with  X   X  . The prior probability can be used to encode any prior knowledge about possi-ble labelings. Especially in incremental process-ing of the dialogue, the prior can encode previ-ous grounding hypotheses, and other information from the collaborative dialogue such as confirma-tion, rejection, or replacement.

P ( a i |  X  i =  X   X  ) is called the  X  X ompatibility co-efficient X  between a i and  X   X  , which is computed based on the attributes of a i and  X   X  : and we further define a dialogue graph node, e.g., for the color attribute: grounding function X , i.e., the probability of ob-serving  X  x ( k )  X  given the word x ( k ) compatibilities between the symbolic attribute val-ues from the dialogue graph and the numeric at-tribute values from the vision graph. These sym-bol grounding functions can be either manually defined or automatically learned. In our current work, we use a set of manually defined ground-ing functions motivated by previous work (Gor-niak and Roy, 2004).
 Iteration:
Once the initial probabilities are calculated, the labeling procedure iterates till all the labeling probabilities have converged or the number of it-erations has reached a specified limit. At each it-eration and for each possible labeling, it computes a  X  X upport function X  as: and updates the probability of each possible label-ing as: how the labeling  X  i =  X   X  at the n -th itera-tion is supported by the labeling of a i  X  X  neigh-tions that exist between a i and them. Similar to the node compatibility coefficient, the edge com-patibility coefficient between a i a j and  X   X   X   X  , Table 1: Comparison of the reference grounding performances of a random guess baseline, Prob-abilistic Labeling (P.L.) and State-Space Search (S.S.S.), and P.L. using manually annotated coref-erence. namely the P ( a i a j |  X  i =  X   X  , X  j =  X   X  ) for com-puting Q ( n ) (  X  i =  X   X  ) , is also based on the at-tributes of the two edges and their corresponding symbol grounding functions. So we also man-ually defined a set of grounding functions for edge attributes such as the spatial relation (e.g., RightOf , Above ). If an edge is used to encode the discourse relation between two entities (i.e., the pairwise coreference results), the compatibility coefficient can be defined as (suppose edge a i a j encodes a positive coreference relation between entities a i and a j ): which can be calculated based on the results from the coreference classifier (Section 4.1). Our dataset has 62 dialogues, each of which con-tains an average of 25 valid utterances from the director. We first applied the semantic parser and coreference classifier as described in Section 4.1 to process each dialogue, and then built a graph representation based on the automatic processing results at the end of the dialogue. On average, a di-alogue graph consists of 33 discourse entities from the director X  X  utterances that need to be grounded.
We then applied both the probabilistic label-ing algorithm and the state-space search algorithm to ground each of the director X  X  discourse entities onto an object perceived from the image. The av-eraged grounding accuracies of the two algorithms are shown in the middle part of Table 1. The first column of Table 1 shows the grounding accura-cies of the algorithm X  X  top-1 grounding hypothesis (i.e.,  X  i = argmax second and third column then show the  X  X ccura-tively.

As shown in Table 1, probabilistic labeling (i.e. P.L.) significantly outperforms state-space search (S.S.S.), especially with regard to produc-ing meaningful multiple grounding hypotheses. The state-space search algorithm actually only re-sults in multiple hypotheses for the overall match-ing, and it fails to produce multiple hypotheses for many individual discourse entities. Multiple grounding hypotheses can be very useful to gen-erate responses such as clarification questions or nonverbal feedback (e.g. pointing, gazing). For example, if there are two competing hypotheses, the dialogue manager can utilize them to gener-ate a response like  X  X  see two objects there, are you talking about this one (pointing to) or that one (pointing to the other)? X . Such proactive feedback is often an effective way in referential communi-cation (Clark and Wilkes-Gibbs, 1986; Liu et al., 2013).

The probabilistic labeling algorithm not only produces better grounding results, it also runs much faster (with a running-time complexity of O MN 2 , 5 comparing to O N 4 of the state-eraged running time of the state-space search al-gorithm on a Intel Core i7 1.60GHz CPU with 16G RAM computer (the running time of the prob-abilistic labeling algorithm is not shown in Fig-ure 1 since it always takes less than 1 second to run). As we can see, when the size of the dialogue graph becomes greater than 15, state-space search takes more than 1 minute to run. The efficiency of the probabilistic labeling algorithm thus makes it more appealing for real-time interaction applica-tions.

Although probabilistic labeling significantly outperforms the state-space search, the grounding performance is still rather poor (less than 50% ) Figure 1: Average running time of the state-space search algorithm with respect to the number of nodes to be grounded in a dialogue graph. even for the top-3 hypotheses. With no surprise, the coreference resolution performance plays an important role in the final grounding performance (see the grounding performance of using manually annotated coreference in the bottom part of Ta-ble 1). Due to the simplicity of our current coref-erence classifier and the flexibility of the human-human dialogue in the data, the pairwise coref-erence resolution only achieves 0 . 74 in precision and 0 . 43 in recall. The low recall of coreference resolution makes it difficult to link interrelated re-ferring expressions and resolve them jointly. So it is important to develop more sophisticated coref-erence resolution and dialogue management com-ponents to reliably track the discourse relations and other dynamics in the dialogue to facilitate ref-erential grounding. In this paper, we have presented a probabilistic la-beling based approach for referential grounding in situated dialogue. This approach provides a uni-fied scheme for incorporating different sources of information. Its probabilistic scheme allows each information source to present multiple hypotheses to better handle uncertainties. Based on the in-tegrated information, the labeling procedure then efficiently generates probabilistic grounding hy-potheses, which can serve as important guidance for the dialogue manager X  X  decision making. In future work, we will utilize probabilistic labeling to incorporate information from verbal and non-verbal communication incrementally as the dia-logue unfolds, and to enable collaborative dia-logue agents in the physical world.
 This work was supported by N00014-11-1-0410 from the Office of Naval Research and IIS-1208390 from the National Science Foundation.
