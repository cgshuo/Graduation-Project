 This paper proposes a data mining approach to modeling relationships among categories in image collection. In our approach, with image feature grouping, a visual dictionary iscreatedforcolor,texture,andshapefeatureattributesre-spectively. Labeling each training image with the keywords in the visual dictionary, a classification tree is built. Based on the statistical properties of the feature space we define a structure, called  X  -Semantics Graph , to discover the hid-den semantic relationships among the semantic categories embodied in the image collection. With the  X  -Semantics Graph , eachsemantic category is modeledasauniquefuzzy set to explicitly address the semantic uncertainty and se-mantic overlap among the categories in the feature space. The model is utilized in the semantics-intensive image re-trieval application. An algorithm using the classification accuracy measures is developed to combine the built classi-fication tree with the fuzzy set modeling method to deliver semantically relevant image retrieval for a given query im-age. The experimental evaluations have demonstrated that the proposed approach models the semantic relationships effectively and the image retrieval prototype system utiliz-ingthederivedmodel ispromising bothineffectivenessand efficiency.
 H.2.8[ Database Management ]: DatabaseApplications X  data mining, image databases Algorithms, Measurement, Design Relationships,semanticcategory,fuzzymodel,imagecollec-tion
Large collections of images havebecome popular inmany applications, from photo collections to Web pages or even video databases. To classify or retrieve them is a challenge which is the focus of many research projects (for instance IBM X  X  QBIC [6]). Almost all of these systems generate low-level image features such as color, texture, shape, and mo-tion, for image index and retrieval. This is partly because low-level features can be computed automatically and effi-ciently. Thesemanticsoftheimages,whichusersaremostly interested in, however, is seldom captured by the low-level features. On the other hand, there is no effective method yet to automatically generate good semantic features of an image. One common compromise is to obtain some seman-tic information through manual annotation. Since visual data contain rich information and themanual annotation is subjective and ambiguous, it is difficult to capture the se-mantic content of an image using words precisely and com-pletely,nottomentionthetediousandlabor-intensivework involved.

It is desirable to organize an image collection in a mean-ingful manner using image classification. Image classifica-tion is the task of classifying images into (semantic) cat-egories based on the available training data. A common approach to image classification involves addressing the fol-lowingfour issues: (i)imagefeatures X  X owtorepresentthe image; (ii) organization of the feature data  X  how to orga-nize the data; (iii) classifier  X  how to classify an image; and (iv) semantics modeling  X  how to address the relationships between the semantic classes.

Inthispaper,weproposeadataminingapproachtomod-elingrelationshipsamongcategoriesinimagecollection. We assumethatasetoftrainingimageswithknownclasslabels isavailable. Multiplefeatures(color,texture,andshape)are extracted for each image in the collection and are grouped to create visual dictionaries. Using the visual dictionaries for the training images, a classification tree is constructed. Once the classification tree is obtained, any new image can be classified easily. On the other hand, to model the se-mantic relationships between the image categories, a repre-sentation, called  X  -Semantics Graph, is generated based on the defined semantics correlations for each semantic cate-gory pairs. Based on the  X  -Semantics Graph each semantic category is modeled as a unique fuzzy set to explicitly ad-dressthesemanticuncertaintyandthesemanticoverlapbe-tween the semantic categories in the feature space. For the image retrieval application, a retrieval algorithm is devel-opedbasedontheclassificationtreeandthefuzzysemantics model for the semantics-relevant image retrieval.
Veryfewstudieshaveconsidereddataclassificationonthe basis ofimage featuresin thecontextofimage indexingand retrieval. In the general context of information retrieval, the majority of the related work has been concerned with handling textual information [2]. Not much work has been done on how to represent imagery (i.e., image features) and how to organize the features. In the following, we review some of thepreviouswork onautomatic classification based image retrieval.
 YuandWolf presenteda one-dimensional Hidden Markov Model (HMM) for indoor/outdoor scene classification [15]. An image is first divided into horizontal (or vertical) seg-mentsandeachsegmentisfurtherdividedintoblocks. Color histograms of blocks are used to train HMM X  X  for a preset standard set of clusters, such as a cluster of sky, tree, river, a cluster of sky,tree, grass, etc. Maximum likelihood classi-fiersarethenusedtoclassify animageasindoororoutdoor. In general, it is difficult to enumerate a set to cover a gen-eralcasesuchasindoor/outdoor. The configural recognition scheme proposed by Lipson et al [10] is also a knowledge-basedsceneclassification method. Amodeltemplate,which encodesthecommonglobalsceneconfigurationstructureus-ing qualitative measurements, is hand-crafted for each cat-egory. An image is then classified to the category whose modeltemplatebestmatchestheimagebydeformabletem-plate matching (which requires intensive computation, de-spite that theimages are subsampled to low resolutions)  X  the nearest neighbor classification.

Oneearlyworkforresourceselection indistributedvisual information systems was reported by Chang et al [3]. The method proposed was based on a metadata base at a query distribution server. The metadata base records a summary of thevisual contentoftheimages in each category through image templates and statistical features. The selection of the databases is driven by searching the metadata base us-ing a nearest-neighbor ranking algorithm that uses query similarity toatemplateandthefeaturesofthedatabaseas-sociated with the template. Another approach [8] proposes a new scheme for automatic hierarchical image classifica-tion. Using banded color correlograms, the approach mod-els the features using singular value decomposition (SVD) [4] and constructs a classification tree. The technique used extracts a certain form of knowledge to classify images. Us-ing a noise-tolerant SVD description, the image is classified inthetrainingdatausingthenearestneighborwiththefirst neighbor dropped. Based on the performance of this clas-sification, the categories are partitioned into subcategories, and the interclass dissociation is minimized through using normalized cuts. In this scheme, the content representation is weak (only using color and some kind of spatial informa-tion) and the semantic overlap among semantic categories in the feature space is not addressed.
To capture as much content as possible to describe and distinguish images, we extract multiple semantics-related features as image signatures. Specifically, our framework incorporates color, texture, and shape features to form a feature vector for each image in the collection. Since image features f  X  R n , it is necessary to perform regularization on the feature set such that the visual data can be indexed efficiently. In our approach, we create a visual dictionary for each feature attribute to achieve this objective.
Thecolorfeatureisrepresentedasacolorhistogrambased on the CIELab space [1] due to its desired property of the perceptualcolordifferenceproportionaltothenumericaldif-ferenceintheCIELabspace. TheCIELabspaceisquantized into96bins(6for L ,4for a ,and4for b )toreducethecom-putational intensity. Thus, a 96-dimensional feature vector C is obtained for each image as a color feature representa-tion.

To extract texture information of an image, we apply a set of Gabor filters [12], which are shown to be effective for CBIR [11], to the image to measure the response. The Gabor filtersareonekindoftwo-dimensional wavelets. The discretization of a two-dimensional wavelet applied to an image is given by using Gabor function  X  ml ,where I denotes the processed image, x , y denotes the spatial sampling rectangle; p , q are image positions, and m , l specify the scale and orienta-tion of the wavelets, respectively.

Applying the Gabor filter bank to an image results, for every image pixel ( p,q ), in an M (the number of scales in the filter bank) by L array of responses to the filter bank. We only need to retain the magnitudes of the responses: F mlpq = | W mlpq | m =0 ,...,M  X  1 ,l =0 ,...L  X  1(2)
Hence, a texture feature is represented by a vector with each element of the vector corresponding to the energy in a specified scale and orientation sub-band w.r.t. a Gabor filter. In the implementation, a Gabor filter bank of 6 ori-entations and 4 scales is performed for each image in the collection,resultingina48-dimensionalfeaturevector T (24 meansand24standarddeviationsfor | W ml | )forthetexture representation.

The edge map is used with water filling algorithm [17] to describe the shape information for each image due to its effectiveness and efficiency for CBIR. A 18-dimensional shapefeaturevector, S ,isobtainedbygeneratingedgemaps for each image in the collection.

Fig. 1showsvisualizedillustrationsoftheextractedcolor, texture, and shape features for an example image. These featuresdescribethecontentofimagesandareusedtoindex the images.
Thecreationofthevisualdictionaryisafundamentalpre-processingstepnecessarytoindexfeatures. Itisnotpossible tobuildavalidclassification treewithoutthepreprocessing step in which similar features are grouped. The centers of thefeaturegroupsconstitutethevisualdictionary. Without the visual dictionary, we would have to consider all feature values of all images, resulting in a situation where very few feature values shared by images, which makes it impossible to discriminate categories.

For each feature attribute(color, texture, and shape) we create a visual dictionary, respectively, using Self Organiza-tion Map (SOM) [9] approach. SOM is ideal for our prob-lem, as it can project high-dimensional feature vectors to 2-dimensional planewith mappingsimilar features together while separating different features apart at the same time.
The procedure to create  X  X eywords X  in the dictionary is similar to the one developed in [16]. By the procedure, thenumberof X  X eywords X  X sadaptivelydeterminedandthe similarity-based featuregroupingisachieved. Applyingthis procedure to each feature attribute, a visual dictionary is created for each one.
Althoughwecantakeadvantageofthesemantics-oriented classification information from the training set, there are stillsomeissuesnotaddressedyet. Oneisthesemanticover-lap between the classes. For example, one category named  X  X iver X  has some affinities with the category named  X  X ake X . For some users, the images in the category  X  X ake X  are also interestingalthoughtheyposeaqueryimageof X  X iver X . An-other issue is the semantic uncertainty, which means that animage inonecategory may also contain semantic objects inquired by the user although the category is not for the semantics in which the user is interested. For instance, an image containing peoples in an  X  X each X  category is also rel-evanttousersinquiringtheretrievalof X  X eople X  X mages. To addresstheseissues,weneedtoconstructamodeltoexplic-itly describe the semantic relationships among images and the semantics representation for each category.
To describe the uncertainty and overlap of semantic cat-egories quantitatively, we propose a metric to measure the scale, called semantics correlation , which reflects the rela-tionships between two semantic categories in the feature space. Thesemanticscorrelationisbasedonstatisticalmea-sures on the shape of the category distributions.
Perplexity . The perplexity of feature distributions of a category reflects the uncertainty of the category; it can be represented based on the entropy measurement [13]. Sup-posethereare k elements s 1 ,s 2 ,...,s k inasetwithprobabil-ity distribution P = { p ( s 1 ) ,p ( s 2 ) ,...,p ( s k ) of the set is defined as By Shannon X  X  theorem [13], this is the lower bound on the average number of bits per element (bpe) required to en-code a state of the set. For a particular semantics repre-sented in the images, it is difficult to precisely determine the probability of an image feature p ( s i ). Consequently we use the statistics in the training semantic category to esti-mate theprobabilities. Since each image is represented as a 3-component vector [ C,T,S ], the entropy of each category, r , is defined as where P ( C i ,T i ,S i ) is the joint occurrence probability of an image feature in the category and N i is the number of im-ages in the category. Assuming that color, texture and shape properties are independent in image representation, i.e., P ( C j ,T j ,S j )= P ( C j ) P ( T j ) P ( C j )where P ( C and P ( S j ) are theoccurrence probabilities of thesingle fea-ture attribute in the category, respectively, it follows that H ( r i )=  X  1 As an analogy to the concept of perplexity [14] for a text corpus, wedefinethe perplexity of a semantic category r i the image collection as which is an approximate measure of thehomogeneity of the feature distributions in the category r i . The more perplex in the category, the bigger  X  ;andviceversa.

Distortion . The distortion is a statistical measure to estimate the compactness degree of the category. For each category, r i , it is defined as where f j is the feature point j in this category and c i the centroid of the category. The distortion describes the distributionshapeofcategories, i.e.,thelooserthecategory, the bigger D defined.

Based on these statistical measures on the categories, we propose a metric to describe the relationship between any two different categories r i and r j , i = j , in the category set Re . The metric, called semantics correlation , is a mapping corr : Re  X  Re  X  X  X  R . For any category pair { r i ,r j } ,i = j , it is defined as where L max is the maximal L i,j between any two differ-This definition of semantics correlation has following prop-erties: Forconvenience,thesupplementofthesemanticscorrelation for each semantic category pair is defined as and is called semantics discrepancy between the two differ-entsemanticcategories,resultinginanquantitativemeasure of therelationship betweenanytwo differentsemantic cate-gories based on their distributions in the feature space.
Withsemanticscorrelationsdefinedabove,agraphiscon-structedinthecategoryspace. Wecallthegraph  X  -Semantics Graph. It is defined as follows:
Definition 4.1. Given a semantic category set D = { r 1 , r ,...,r m } , the semantics correlation function corr i,j fined on the set D , and a constant  X   X  R , a weighted undi-rected graph is cal led  X  -Semantics Graph if it is constructed abiding to the following rules:
The  X  -Semantics Graph uniquely describes the relation-ships between semantic categories for an arbitrary  X  .With a tuned  X  , we can model a semantic category based on its connected neighbors and corresponding edge weights in the  X  -Semantics Graph.
To address the semantic uncertainty and the semantic overlap problems, we propose a fuzzy model for each cat-egory based on the constructed  X  -Semantics Graph. In this model , each semantics category is defined as a fuzzy set while one particular image may belong to several semantic categories.

A fuzzy set F on the feature space R n is defined by a mapping  X  F : R n  X  [0 , 1] named the membership function . For any feature vector f  X  R n ,thevalueof  X  F ( f ) is called the degree of membership of f to the fuzzy set F (or, in short, the degree of membership to F ). For a fuzzy set F , there is a smooth transition for the degree of membership to F besides the hard cases f  X  F (  X  F ( f ) = 1) and f/ (  X  F ( f )=0).

The most commonly used prototype membership func-tions are cone, trapezoidal, B-splines, exponential, Cauchy, and paired sigmoid functions [7]. Since we could not think of any intrinsic reason why a particular one should be pre-ferred to any other, we tested the cone, trapezoidal, expo-nential,andCauchyfunctionsinoursystem. Ingeneral,the performance oftheexponentialandtheCauchyfunctionsis betterthanthatoftheconeandtrapezoidalfunctions. Con-sidering the computational complexity, we use the Cauchy function because it requires much less computation. The Cauchy function is defined as where d and  X   X  R , d&gt; 0,  X &gt; 0, v is the center loca-tion (point) of the fuzzy set, d represents the width of the function, and determines the shape (or smoothness) of the function. Collectively, d and  X  portray the grade of fuzzi-ness of the corresponding fuzzy set. For fixed d , the grade of fuzziness increases as  X  decreases. If  X  is fixed,thegrade of fuzziness increases with the increase of d .

Foreachcategory,theparameters v and d aredetermined basedontheconstructed  X  -SemanticsGraph. Forthecenter point of each semantic category r i , it can be conveniently estimated by the mean vector, c i , of the feature vectors in the category. For the width d i , it is determined as follows: where { c 1 ,c 2 ,...,c w } is the set of the centroids of all con-nected nodes to the node r i in the  X  -Semantics Graph and width of the membership function for each category is a semantics correlation weighted combination of the distance to its connected nodes in the  X  -Semantics Graph. Conse-quently,each category r i in the training set is modeled as a unique fuzzy set Denoting the distance between a feature f and c i as dist , the above equation can be equally presented as The experiments show that the performance changes in-significantlywhen  X  isintheinterval[0 . 7 , 1 . 5], butdegrades rapidly outside the interval. Thus, we set  X  =1inEq.11 to simplify the computation.
With the three visual dictionaries ready, an order for the  X  X eywords X  in the visual dictionaries is determined and an index to each  X  X eyword X  is assigned. Given an image, for each feature attribute, replace it by the index of the  X  X ey-word X  X owhichitisassignedinthecorrespondingvisualdic-tionary. Hence each image in the training set is represented byatuple Img [ Color,Texture,Shape ] while each attribute has discrete value type in a limited domain.

Tobuildaclassification tree,C4.5algorithm[5]isapplied on the training tuple sets transformed. We assume that each image in the training set belongs to only one semantic category. The splitting attribute selection for each branch is based oninformation gain ratio [5]. Associated with each leaf node of the classification tree is a ratio m/n ,where m is the number of images classified to this node and n is the number of incorrectly classified images. This ratio is a measure of the classification accuracy of the classification tree for each class in the training image set.

A retrievalalgorithm is developedbasedontheclassifica-tion and its accuracy with the fuzzy model for the category to which the query image is classified. In this algorithm, the category is predicted by the classification tree for the queryimage. Atthesame time, a reference featureis deter-mined by inverse analysis from the classification accuracy; the reference feature X  X  membership values of the semantic categories of the neighborhood to the predicted category in the  X  -Semantics Graph are determined. The intuition is il-lustrated in Fig. 2. In this figure, two categories modeled with the fuzzy set are shown. Every vector in the feature space is associated with the two categories by the obtained membership values. These membership values are used to guide the sampling percentage in the corresponding seman-ticcategories. Inaddition,sincethealgorithmisorthogonal withthedistancemetric DM ,differentdistancemetric DM can be used for different applications. In our evaluation ex-periment,weuseEuclidiandistanceas DM foritssimplicity and effectiveness.

With this algorithm the images are retrieved not only basedonthecategorythequeryimageisclassifiedto(which is called primary category ) but also based on the semantics correlations betweenthisprimarycategory andotherneigh-boring categories in the  X  -Semantics Graph constructed. The percentage of images sampled in each potential rele-vant categories is determined by the corresponding classi-fication accuracy and its fuzzy model. Intuitively, we give most share to the primary category ; the shares to the con-nectedcategoriesofthe primary category inthe  X  -Semantics Grapharebasedontheirsemanticscorrelationswiththe pri-mary category . Inotherwords, moreshares aregiventothe highly semantics-correlated categories while fewer shares to thelowly semantics-correlated categories. Consequently,we have solved the semantic uncertainty and semantic overlap problems explicitly.
We have implemented the approach in a prototype sys-tem on a platform of PentiumIV 2.0 GHZ CPU with 256M memory. Theimageretrievalevaluationswereperformedon a general-purpose color image collection containing 10,000 images from COREL collection of 96 semantic categories. Each semantic category has 85 X 120 images. Images in the samecategoryareoftennotallvisuallysimilar. Forthisim-age collection we randomly shuffle the images in each cat-egory and take 50% of them as the training set to train the image classifier. To evaluate the image retrieval perfor-mance, 1,500 images were randomly selected from all cate-gories oftheremaining 50%of theCORELcollection asthe query set. The relevancy of the retrieved images is subjec-tively examined by the users and the retrieval accuracy is the average values across all query sessions.

Before we evaluate the prototype system, an appropriate  X  mustbedecided. Fortheextremecase  X  =0,eachnodeis connected to all other nodes in the 0-Semantics Graph (all categories are treated as semantics-related to each other); for  X  = 1, each node is isolated (with no edges connected to other nodes), the 1-Semantics Graph degraded to a cat-egory set. In the experiment we have calculated pair-wise semanticscorrelation corr i,j forallthecategory pairsinthe training set; the third quartile, which is obtained as 0.649 for the training set, was used as the  X  in the prototype.
Fig. 3 shows an excerpted  X  -Semantics Graph example for the categories in the training set. The annotation of each category is labeled on its node. The length of each edge between two nodes in the figure is proportional to the semantics discrepancy between the two corresponding cat-egories. It is noticeable that the semantic uncertainty and the semantic overlap among categories described in Section 4.1 are measured explicitly. For example, for the  X  X ut-door scene X  category, category  X  X astle X  is more semantics-correlated than  X  X each X  category; category  X  X aterfall X  has strong semantics correlations with  X  X ishing X ,  X  X afting X , and  X  X each X  categories;  X  X easant life X  category is connected to  X  X utdoor scene X  and  X  X ashion model X  categories. These se-mantics correlations measured in the feature space among categories agree well to the subjective perceptions of the image contents.

Fig. 4 shows three test images with 0, 2 and 6 cate-gories connected in the constructed  X  -semantics graph re-spectively. The primary category assigned to Fig. 4(a) is category  X  X hina X , which is correct, without any edges con-nected. Fig. 4(b) is assigned primary category as  X  X eople X  andtwocategories, X  X uilding X  X nd X  X utdoorscene X ,arecon-nected to the primary category with the corresponding se-manticscorrelations0.652and0.723, respectively. Basedon the subjective observation,  X  X uilding X  is not relevant while the primary category  X  X eople X  X ndtheotherconnectedcate-gory X  X utdoorscene X  X re. The primary category ofFig.4(c) is  X  X inter season X  with connections to  X  X uilding X ,  X  X each X ,  X  X uropean town  X ,  X  X ountain X ,  X  X ea shore X , and  X  X acation resort X  categories in the  X  -semantics graph. Although the primary category  X  X inter season X  assigned to this image by the classification tree is not semantically relevant, there are 4 semantically relevant categories ( X  X uilding X ,  X  X uropean town X ,  X  X ea shore X , and  X  X acation resort X ) connected with the primary category ( X  X inter season X ) this image is classi-fiedto. Thus,theretrievalaccuracyissignificantlyimproved by incorporating these categories into the fuzzy model de-scribedinSection5. Figure 5: Average precision comparison with / with-out  X  -Semantics Graph.

To evaluate the effectiveness of the semantics correlation measurement and the fuzzy model for categories, we have comparedtheretrievalprecisionwithandwithout  X  -Semantics Graph. Fig. 5 shows the results. From the figure, it is ev-identthatthe  X  -Semantics Graph and the derived fuzzy model for categories improve the retrieval precision signifi-cantly. These results substantiate our motivations: by ex-plicitly addressingthesemanticuncertaintyandtheseman-tic overlap, the classification errors can be substantially re-duced for image retrieval.

Toevaluatetheinfluenceoftheerrorrateoftheclassifica-tion tree, we have recorded the statistics of the correspond-ingretrievalprecisionsforthetestingandtrainingsets. Two evaluation statistics are recorded. They are: The results are shown in Table 1.

Anotheradvantage of our method is its high online query efficiency. Inmoststate-of-the-artCBIRsystems,thesearch isperformedlinearly. Inotherwords,thecomputationcom-plexityis O ( n )foranimagecollectionwith n images. Inour method,theaveragecomputationcomplexityis O (log m )for image classification and O ( w ) for image similarity compu-tation, where m is the number of image categories and w is the average number of images in a category. Thus, the overall complexity is O (log m + w ). Hence, withimage clas-sificationthecomputationcomplexityofourmethodismuch moretractablethanthatofthelinearsearchmethods. This conclusionisalsovalidatedintheexperiment. Theobserved average query time for returning top 30 images is less than 0.5 second.
In this paper, we have proposed a data mining approach to modeling relationships among categories in image col-lections. A semantics correlation based structure, called  X  -Semantics Graph, is proposed to represent the semantic uncertainty and the semantic overlap explicitly. Founded on the  X  -Semantics Graph, each semantic category is mod-eled as a fuzzy set which captures the statistical distribu-tion in the feature space. With the generation of a mul-tiple feature (color, texture, and shape) supported visual dictionary, a classification tree is trained using a provided training set. The model derived is utilized in the image re-trieval application. A unique image retrieval algorithm is developed through integrating the classification results and the fuzzy model for each category. With the effective su-pervised learning applied to the image collection and the precisemodelingofimagesemanticcategories, theproposed methodology inauguratesanewgenerationofcontent-based image retrieval approaches, which aims at achieving more semantics-relevant performance.
