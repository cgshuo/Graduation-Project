 Textbooks have a direct bearing on the quality of education im-parted to the students. Therefore, it is of paramount importance that the educational content of textbooks should provide rich learn-ing experience to the students. Recent studies on understanding learning behavior suggest that the incorporation of digital visual material can greatly enhance learning. However, textbooks used in many developing regions are largely text-oriented and lack good visual material. We propose techniques for finding images from the web that are most relevant for augmenting a section of the textbook, while respecting the constraint that the same image is not repeated in different sections of the same chapter. We devise a rigorous for-mulation of the image assignment problem and present a polyno-mial time algorithm for solving the problem optimally. We also present two image mining algorithms that utilize orthogonal signals and hence obtain different sets of relevant images. Finally, we pro-vide an ensembling algorithm for combining the assignments. To empirically evaluate our techniques, we use a corpus of high school textbooks in use in India. Our user study utilizing the Amazon Me-chanical Turk platform indicates that the proposed techniques are able to obtain images that can help increase the understanding of the textbook material.
 H.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Algorithms, Experimentation, Human Factors Education, Textbooks, Data Mining, Image Mining, Text Augmen-tation
Education is the key for improving the economic well-being of people living in developing regions [1, 24]. While the problem of providing high-quality education is multi-faceted and complex [8, 50], textbooks have been shown to provide the most cost-effective means of improving the educational quality [11, 16, 26]. They are the primary conduits for delivering content knowledge to the stu-dents and the teachers base their lesson plans primarily on the ma-terial given in textbooks [18, 55]. Unfortunately, textbooks in many developing countries often suffer from the lack of clarity as well as the inadequacy of information provided [2, 44].

It has been shown that the linking of encyclopedic information to educational material can improve both the quality of the knowl-edge acquired and the time needed to obtain such knowledge [12]. In [4], a decision model has been proposed for diagnosing deficient sections of a textbook. In [5, 40, 41, 43], techniques have been pro-posed for finding articles from the web with which such sections should be augmented.

We extend prior work and propose techniques for augmenting textbooks with links to selective, highly relevant images. Our work has been instigated by the research in the learning literature show-ing that the use of visual materials enhances learning, not only by enabling retention of information but also by promoting compre-hension and transfer [35, 39, 48]. Some researchers even suggest that visual materials should be given as much attention as text and not viewed as merely supporting the text [36].

The learning literature informs us that any supplementary mate-rial is most effective when it is presented in close proximity to the main material [9]. We therefore find images that are relevant to a particular section of the textbook. In order to avoid undue cognitive burden, we select only a small number of images that collectively best aid the understanding, shunning repetition of an image in dif-ferent sections of the same chapter.

Our solution has three components: 1. Image Assignment . Given a set of candidate images and their 2. Image Mining . This component comprises of algorithms that 3. I mage Ensembling . Since the relevance scores provided by
In order to assess the usefulness of our proposal, we conducted a user study employing the Amazon Mechanical Turk platform [29]. The corpus used in this evaluation comprises of the high school textbooks published by the Indian National Council of Educational Research and Training (NCERT). We wanted to use a corpus from a developing country and settled on the NCERT books because of their ready availability online. However, our techniques are not country-dependent. We consider fourteen textbooks from grades IX to XII, covering eight subjects, seventy chapters, and over a thousand sections. The results of this study indicate that the pro-posed techniques are able to discover images that can help increase the understanding of the textbook material.

Scope of the paper. We present techniques for proposing im-ages with which a section of a textbook can be augmented, but do not discuss specific mechanisms for integrating the augmentations into the textbook. Our techniques could be integrated into author-ing tools for helping textbook authors decide what images to use when writing or revising a book. They can also be used for creating supplementary material that is distributed with the paper version of the books. Furthermore, there are ongoing efforts aimed at creat-ing platforms and inexpensive devices for distributing books in a digital form (see, for example, the use of interactive DVDs as an educational platform [17], inexpensive e-book readers [3, 7], and mobile learning devices [31]). Our work fits quite naturally with these efforts.

Complementary approaches and issues that merit serious inves-tigation, but are beyond the scope of this paper include: (a) refining and enhancing the results produced by our techniques using col-laboration and crowdsourcing [2, 53], (b) implications for royalty sharing and intellectual property rights [14, 20], and (c) integration with other interventions for improving the learning outcomes [19, 45].

Organization of the paper. The rest of the paper is structured as follows. We discuss related work in  X 2. The particular algorithms used in our solution are described in  X 3. The results of experimental evaluation are presented in  X 4. We conclude with a summary and directions for future work in  X 5.
There has been research on translating short textual sentences to pictures [42]. The work in [10] uses semantic representation of the text to synthesize three-dimensional scenes from English text. Such translations work well only with descriptive sentences that can be effectively mapped to corresponding object models. Our focus is on finding a few representative images relevant for a section of a textbook, not on synthesizing scenes from sentences, which leads to different techniques.

The goal of research in story picturing is to find a set of pictures to describe a fragment of a text. In [32], key phrases are extracted from the text to retrieve matching images, which are then ranked by weighting image region similarity and phrase overlaps. In [59], the picturable key phrases are extracted from a given text; the pictura-bility of a phrase is measured as the ratio of the frequencies under regular web vs. image search. Each picturable phrase is then as-sociated with an image using image search coupled with computer vision and finally graphics is used to spatially arrange the images to represent the story. In [15], the meaning of images and their sur-rounding texts are represented jointly as probability distributions over a set of latent topics, which are then used to find pictures to illustrate a story. While close in spirit, the setting and the solution techniques in these works and ours are quite different.

The rich literature on image retrieval in response to key word queries is relevant for the image mining component of our work. Indeed, one of our mining algorithms (C OMITY ) issues queries to the commercial search engines as a subroutine. We refer the reader to [13] for a comprehensive survey of recent advances in image retrieval. While there is ground breaking research on retrieving im-ages solely based on the content of the images, most image search engines work by indexing associated metadata and matching key-word queries with the stored metadata. The metadata may include a description of the image, the filename of the image, the anchor text pointing to the image, the queries that led to a click on the image, or the text adjacent to the image. The ImageCLEF competition, for example, uses an image repository consisting of Wikipedia images that have been tagged with the associated title and description of the image extracted from the Wikipedia page for the image [46].
Several web based applications (e.g. Flickr) provide facilities for any web user to tag pictures hosted on their websites with tex-tual descriptions that can serve as metadata for the image. Lui von Ahn developed an interactive ESP game in which the players la-beled images while playing the game [56]. There is rich body of image processing research on automatically linking text to image. The survey in [6] distinguishes the task of annotation from that of correspondence. The former attempts to predict the annotation of an entire image using all information present, whereas the latter attempts to associate particular words with particular image sub-structures. There is also work on extracting image regions con-taining text that can then be fed to an optical character recognition module [30, 38].

Related work also includes the proposal in [2] to create an educa-tion network to harness the collective efforts of educators, parents, and students to collaboratively enhance the quality of educational material. Some websites (e.g. Notemonk.con) allow students to download textbooks, ask questions on a topic, and annotate books for quick reference. Several institutions are making the videos of the course lectures available through Internet and there are web-sites (e.g. EducationPortal.com) that aggregate links to them. We view these crowdsourcing efforts as complementary approaches to improving the quality of textbooks.
We now describe the design of our system. We first present the image assignment component consisting of an optimization prob-lem, followed by two algorithms for mining relevant images from the web, and finally the image ensembling component.
Given a set of candidate images relevant to the various sections of a chapter and their relevance scores, the goal of the image as-signment component is to allocate to each section the most relevant images, while respecting the constraints that each section i s not augmented with too many images and that each image is used no more than once in a chapter. The rationale for these constraints is that an augmentation of a section with too many images will put undue cognitive burden on the reader while the repetition of an im-age across sections in the same chapter would be redundant for the reader.

First, a few notations. Let I = { 1 , 2 , . . . , n } denote the set of images and S = { 1 , 2 , . . . , m } denote the set of sections in a chapter. Let  X  ij denote the (non-negative) relevance score of image i  X  I for section j  X  S (  X  ij = 0 if the image i is not present in the candidate set of images for section j ). Let K j denote the maximum number of images that can be associated with section j . K be either a fixed integer for all sections or a function of the length of the section j .

This problem admits a natural greedy algorithm. Sort the  X  values in decreasing order and go through them. At each step, the greedy algorithm picks the highest  X  ij value such that an image can still be assigned to section j (that is, less than K j so far been assigned to j ) and then assigns image i to section j . This process ends when either all sections have been assigned the maximum number of images or there are no more images to be assigned.

At a first glance, the greedy algorithm might seem optimal in terms of the sum of relevance scores of all assigned images. But the following counterexample shows that the optimal value can be substantially larger. Consider a chapter consisting of two sections and suppose that we want two images each for a section ( K K 2 = 2 ). Represent by ( i,  X  ) that image i  X  X  relevance score is  X  . Let the top images and their relevance scores obtained by an image mining algorithm for various sections be as follows: s h ( i 1 , 1) , ( i 2 , 1  X   X  ) , ( i 3 , 1  X  3  X  ) i , s 2  X  X  ( i where  X  = 0 . 01 . Then the greedy assignment would be s 1 h i , i 2 i , s 2  X  h i 4 , i 5 i with a total score of 2 +  X  . On the other hand, an optimal assignment is s 1  X  X  i 1 , i 3 i , s 2  X  X  i total score of 3  X  4  X  .

Therefore, we instantiate the image assignment component as an optimization problem. We show that this optimization problem can be solved optimally in polynomial time and provide an efficient algorithm as part of the proof. The following is the statement of the optimization problem:
Here, x ij is an indicator variable that takes value 1 if image i is selected for section j and 0 otherwise. Eq. 2 captures this binary constraint. Eq. 3 ensures that the number of images assigned to a section is at most K j . Eq. 4 enforces that each image is assigned to at most one section in a chapter. The optimization objective (Eq. 1) is the total relevance score for the chapter, defined as the sum over all sections of relevance scores of the images assigned to the section. Thus the goal of the optimization is to compute the binary variables x ij such that the total relevance score for the chapter is maximized.
 Algorithm 1 A F FINITY Input: A textbook section j ; Number of desired image results k ; Number of desired closest articles from an authoritative external source t  X  ; Number of desired concept phrases c .
 Output: A list of top k image results from the authoritative source, along with value scores. 1: Obtain (up to) top c concept phrases from section j . 2: Obtain (up to) top t  X  closest articles from the authoritative ex-3: Extract the set of images present in these t  X  articles, as well as 4: For each image i , let n ij := Number of articles in which image 5: Assign the relevance score  X  ij := n w 1 ij d w 2 ij w 6: Return top k images along with their  X  ij values.
 solved optimally in polynomial time.

P ROOF . The proof follows by showing an efficient reduction W
EIGHTED B IPARTITE M ATCHING problem [49], which admits an efficient polynomial time solution. Given an instance of M EVANT I MAGE A SSIGNMENT , form a complete weighted bipartite graph G = ( V, E ) as follows. Associate a node u i with each im-age i  X  I and associate K j nodes, v j 1 , v j 2 , . . . , v section j . Create an edge between every image node and every sec-tion node copy. Weight of the edge ( u i , v jk ) is set to  X  k  X  X  1 , 2 , . . . , K j } , that is, each of the K j edges joining an image i to the section j has the same weight, equal to the corresponding relevance score.
 We observe that any feasible solution to M AX R ELEVANT I AGE A SSIGNMENT corresponds to selecting a matching in G . Given a satisfying assignment of x ij  X  X , we can obtain a matching in G by picking one of the K j edges corresponding to any x ij that is set to 1. Similarly, given any matching in G , there is a corresponding fea-sible solution. Further the objective of M AX R ELEVANT I SIGNMENT can be maximized by obtaining the maximum weight bipartite matching in G . As the M AXIMUM W EIGHTED B IPAR TITE M ATCHING problem can be solved optimally in O ( nm ( n + m )) time, it follows that M AX R ELEVANT I MAGE A SSIGNMENT also be solved optimally in O ( nm ( n + m )) time.
H ere we give particulars of the A FFINITY and C OMITY algo-rithms, the two algorithms used for obtaining the ranked list of top k images along with their relevance scores for a given section. Note that our system design admits various possible variants of these al-gorithms as well as additional image mining algorithms one could conceive.

The intuition behind this algorithm is the observation that the im-ages included in an authoritative article relevant to a topic are often illustrative of the key concepts underlying the topic. We therefore find authoritative articles whose contents have high textual simi-larity with a given section of the book. We then extract images contained in these articles and use their relevance scores to find top k images for the section.

Algorithm 1 (A FFINITY ) first obtains the key concept phrases present in a section as well as the closest authoritative articles from the web. Thus the key topics discussed in the section are available in the form of the concept phrases while the search space for im-ages is refined to the set of articles with high document similarity to the section. The relevance score for an image is computed by ana-lyzing the overlap between the concept phrases and the cumulative metadata associated with the various copies of the image present in the narrowed set of articles. The metadata for an image com-prises of text adjacent to the image including caption and alterna-tive text, filename of the image, anchor texts pointing to the image, and queries that led to clicks on the image. The scoring has desir-able properties such as: (a) an image occurring in multiple articles gets a higher score, (b) an image whose metadata contains multi-ple concept phrases gets a higher score, and (c) an image whose metadata contains words from many concepts gets a higher score.
In the rest of this subsection, we provide implementation details of steps 1 and 2. If a textbook includes a back-of-the-book in-dex [47], it can be used for obtaining concept phrases for a sec-tion. There is also rich literature on algorithmically extracting key phrases from a document that can inform the task of extracting key concepts from a section [33]. The current approaches primarily in-volve detection of the key phrases based on rules or statistical and learning methods. In the former, the structural properties of phrases form the basis for the rule generation. In the latter, the importance of a phrase is computed based on statistical properties (e.g., relative frequency, document frequency) of the phrase.

Our study of several textbooks from the developing regions re-vealed that they often do not include a back-of-the-book index, but the concept phrases typically consist of terminological noun phrases containing adjectives, nouns, and sometimes prepositions. It is uncommon for concepts to contain other parts of speech such as adverbs, conjunctions, or verbs. Following [34], we adopt the linguistic pattern A  X  N + , where A refers to an adjective and N a noun and use the algorithm from [5] to determine the top c con-cepts. Examples of concepts satisfying this pattern include  X  X umu-lative distribution function X ,  X  X iscal policy X , and  X  X lectromagnetic radiation X .

Early research on finding documents similar to a given document includes techniques based on relevance feedback [51], which were subsequently used to show similar results by some of the search engines [54]. Recent research includes the query by document work [58] that extracts key phrases and uses them as queries to search for similar documents (see also references therein). We in-dex the corpus of authoritative articles using Lucene [25] and use its in-built scoring to retrieve the closest articles to a given textbook section.

One might think that one could simply use the text string of a section to query a commercial image search engine and obtain the relevant images. However, the current search engines do not per-form well with long queries [28, 37]. Indeed, when we queried the search engines using even the first paragraph of a section, we got none or meaningless results. In one major stream of research on information retrieval with long queries, the focus is on selecting a subset of the query, while in another it is on weighting the terms of the query [57]. This body of research however is not designed to work for queries consisting of arbitrary textbook sections.
Algorithm 2 (C OMITY ) is based on using the key concepts present in a section to query the commercial image search engines. How-Algorithm 2 C O MITY Input: A textbook section j ; Number of desired image results k ; Number of desired image search results per query t ; Number of desired concept phrases c .
 Output: A list of top k image results from web, along with relevance scores. 1: Obtain (up to) top c concept phrases from section j . 2: Form queries consisting of two and three concepts phrases each 3: Obtain (up to) top t image search results for each of the queries 4: Aggregate over (potentially e ( ` c 2  X  + ` c 3  X  ) ) lists of images, to 5: Return top k images along with their  X  ij values. ever, each concept phrase in isolation may not be representat ive of the section as a typical book section can discuss multiple concepts. Hence we form ` c 2  X  + ` c 3  X  image search queries by combining two and three concept phrases each, in order to provide more context about the section. A relevant image for the section is likely to occur among the top results for many such queries. Thus, by aggregating the image result lists over all the combination queries, we end up boosting the relevance scores of very relevant images for the sec-tion. We further increase the coverage by obtaining and merging results across e different search engines. We treat each search en-gine as a blackbox [23, 28], that is, we have access to the ranking of results but do not have access to the internals of the search engine such as the score given to a document with respect to a query.
Aggregation across multiple lists is performed as follows. Each of (up to) t images in a result list is assigned a position-discounted score equal to 1 / ( p +  X  ) where p denotes the position and  X  is a smoothing parameter. For the same image occurring in multiple lists, the scores are added, weighted by a function f of the im-portance of the concept phrase present in the underlying query:  X  ij := P q f ( Importance scores of concept phrases used in q )  X  (1 / ( p ( i, q, R ( q )) +  X  )) . Here the summation is over e ( ` queries issued and p ( i, q, R ( q )) denotes the position of image i in the result list R ( q ) for query q if i is present in R ( q ) and  X  otherwise. This choice is based on our empirical observation that an image occurring among the top results for multiple queries was more relevant to the section than an image that occurred among the top results for only one query.
We next describe our ensembling algorithm for combining the different image assignments. Since the relevance scores computed by the image mining algorithms will be incomparable in general, we combine the results after the M AX R ELEVANT I MAGE A SSIGN MENT optimization has been performed independently for each al-gorithm. We use only the ordering returned by these algorithms and do rank aggregation without considering the magnitudes of the scores.

We employ Borda X  X  method to merge l ranked lists correspond-ing to l different image mining algorithms. Borda X  X  method tries to achieve a consensus ranking and satisfies certain desirable proper-ties such as reversal symmetry [52]. It assigns a score correspond-ing to the positions in which an image appears within each ranked list of preferences, and the images are sorted by their total score.
However, a consequence of performing rank aggregation for each section independently is that the same image may appear more than once in a chapter. Consider a chapter consisting of two sections Algorithm 3 E N SEMBLE Input: S et of sections S = { 1 , 2 , . . . , m } in a textbook chapter; Set of images I = { 1 , 2 , . . . , n } ; Number of desired images K for each section j  X  S ; Scores assigned by l different image mining algorithms for each image i  X  I ; Orderings produced after the optimization for these l algorithms.
 Output: A new assignment of images to sections. 1: Let I 0 := I and S 0 := S . For each of l image mining al-2: for section j = 1 to m do 3: Merge l ranked lists (corresponding to l algorithms) for sec-4: Remove the assigned images from consideration for sub-5: For each of l image mining algorithms, perform M AX R and suppose that we want two images for every section. Assume t hat the optimal assignments (ranked lists) corresponding to the two image mining algorithms are as follows. Alg 1 (OPT): s h i , i 2 i , s 2  X  h i 3 , i 4 i (that is, image i 1 has the highest relevance score and i 2 has the second highest score for section s 1 ilarly h i 3 , i 4 i in that order are the top two images for section s and Alg 2 (OPT): s 1  X  h i 3 , i 4 i , s 2  X  h i 1 , i 2 i . Then the rank ag-gregation would give: s 1  X  X  i 1 , i 3 i , s 2  X  X  i 1 , i
Algorithm 3 (E NSEMBLE ) avoids this problem by taking advan-tage of the logical linear organization of sections within a chapter. It considers sections in a chapter sequentially from the first section to the last, ensembling at a section level, and then removing images selected for this section from the pool of available images for the remaining sections. Before moving to a subsequent section, it re-runs the image assignment optimization for the remaining sections over the remaining images. Thus images discarded due to merging for a section are taken into account for consideration in subsequent sections as such images may be more relevant than any of the can-didate images for a section.

Consider a chapter consisting of three sections and suppose that we want two images for every section. Assume that the images and their relevance scores for different sections found by the two image mining algorithms are as follows. Alg 1 : s 1  X  h ( i 1 , 1) , ( i s 2  X  h ( i 7 , 0 . 7) , ( i 8 , 0 . 6) i , s 3  X  h ( i 2 , 0 . 5) , ( i and Alg 2 : s 1  X  h ( i 3 , 1) , ( i 4 , 0 . 9) i , s 2  X  h ( i s be: Alg 1 (OPT): s 1  X  X  i 1 , i 2 } , s 2  X  X  i 7 , i 8 } , s Alg 2 (OPT): s 1  X  { i 3 , i 4 } , s 2  X  { i 7 , i 8 } , s rank aggregation for the first section would give: s 1  X  { i thereby dropping i 2 from Alg 1 and i 4 from Alg 2 respectively. We note that i 2 is more relevant than current assignments for section s under Alg 1 and similarly, i 4 is more relevant than current as-signments for section s 3 under Alg 2 . The benefit of rerunning the optimization is that such dropped images can be assigned to later sections ( s 3 in our example). E NSEMBLE would result in the final assignment: s 1  X  { i 1 , i 3 } , s 2  X  { i 7 , i 8 } , s i s more desirable than an assignment that excludes assigned images from later sections but does not rerun optimization ( s 3
The difficulty of evaluating a system like ours has been earlier experienced in works with similar goals (e.g. story picturing [32, 59], scene synthesis from text [10], translating sentences into picto-rial representations [42]). We believe that defining standard bench-marks will greatly accelerate research into these topics and repre-sents an interesting research opportunity. Meanwhile, we resort to conducting a user study to understand the performance of our pro-posal. Ideally, we would have liked to have high school students from India participate in this study. In the absence of the availabil-ity of this subject population to us, we use the Amazon Mechanical Turk platform, which is becoming increasingly mainstream for car-rying out user studies [29]. We wanted to evaluate our techniques on textbooks from a develop-ing country. We chose a corpus of high school textbooks published by the National Council of Educational Research and Training, In-dia because of the online availability of these books. We considered fourteen books from grades IX to XII, covering eight subjects: Ac-counting, Business Studies, Economics, History, Physics, Political Science, (General) Science, and Sociology. They covered seventy chapters and over a thousand sections. Out of these, we randomly selected 100 sections for the user study. This sample size keeps the cost of carrying out the study within a reasonable budget, and yet it is big enough for having meaningful results. Figure 1 shows the subject-wise distribution of sections.
 For mining images, A FFINITY limits itself to finding similar Wikipedia articles and extracts images only from them. This con-straint allows us to contain the crawling and image extraction ef-fort. Similarly, when querying the search engines, C OMITY the site restriction feature to obtain only Wikipedia images, which allows the behavior of the two image mining algorithms to be com-pared. It also reduces the determination of whether the two images are the same to comparing their Wikipedia URLs. We note that the Wikipedia articles are known to differ from the general web pages in characteristics such as the encyclopedic orientation and the style of writing [22], and restricting to Wikipedia reduces the available pool of relevant images to choose from. In spite of these handicaps, our techniques emerge as quite effective in the user study. Figure 3: Distribution of judgments for top 20 judges who par-t icipated in the most number of HITs Figure 4: Variance from the mean for the three types of judg-m ents for the Science books In the image mining component, we set the number of images per section parameter k to 5 and the number of desired concept phrases parameter c to 20 . For C OMITY , we set the number of desired im-age search results per query t to 10 . We use two different search engines ( e = 2 ): Google and Bing. We use  X  = 10 as the smooth-ing parameter and give equal importance to all the concepts. For A
FFINITY , we obtain t  X  = 10 closest articles for every book sec-tion and set w 1 = 1 , w 2 = 1 , and w 3 = 1 / 3 . During the image assignment, we set the maximum number of images that can be associated with any section to 5 (that is, K j = 5 for all sections). Each section along with the candidate images produced by A ITY , C OMITY , and E NSEMBLE (five per algorithm) was provided to Mechanical Turk as a HIT (Human Intelligence Task). Images within a HIT were intermixed and randomly ordered. Fig. 2 il-lustrates a sample HIT. Each judge was asked to read the section (provided as a link in the HIT) and rate every image separately as helpful or unhelpful in understanding the material. We also pro-vided the  X  X nable to decide X  option. Images were also provided with the associated captions that the judge could use in making the decision.

We also specified the minimum time a judge was required to spend on a given HIT. This time was arrived at by considering the length of the section and the statistics on average reading speed [21, 27]. We rejected any HIT (and resubmitted it) where the time spent was less than the minimum. We found that different judges took varying amount of time on a particular section which is what we expected (and hoped).

Each HIT was judged by 7 judges. There were 58 judges who took part in the study. Fig. 3 shows the distribution of judgments in terms of helpful, unhelpful, and undecided for the top 20 judges. This figure shows that the distribution of judgments varied across the judges, which indicates the absence of impostor judges who repeatedly judged a HIT using multiple identities. The same figure also indicates that judges were not providing random judgments; otherwise the distribution would have been more uniform.
We also computed the three-dimensional normalized mean vec-tor using all the available judgments for a given chapter. This vec-tor captures the probability of each of the three types of judgments for the images shown for that chapter. Fig. 4 shows the averaged variance from the mean for chapters in the Science books (similar trends held for other subjects). Here the average was performed across all the judges. The deviation is not large, indicating the ab-sence of outlier judges.
 We propose helpfulness index as the measure for understanding the effectiveness of an image augmentation system. Given the to-tal number of images an image augmentation system can propose, the helpfulness index is defined to be the total number of images deemed helpful for understanding the corresponding section di-vided by the total number of images.

For an image to be considered helpful for understanding a sec-tion, we require that the majority of judges find it helpful. Although we have odd number of judges for every image, judges are allowed to vote  X  X nable to decide X . Thus, there may be a split vote on an im-age. We can therefore compute the majority in two different ways: Sec 2: Magnetic field due to a current carrying conductor Sec 3: Force on a current carrying conductor in a magnetic field Sec 6: Electric generator Sec 6: Electric generator current X  in the grade X Science book plays crucial role of initiating recombinational repair of potentially lethal double strand breaks in DNA.

Fig. 6(b) shows the cases that illustrate opportunity for further work. The first example is from a section in the twelfth chapter titled  X  X ound X  in the grade IX Science book. This section describes the structure of the human ear and how it enables conversion of pressure variations in air with audible frequencies into electric sig-nals that travel to the brain via the auditory nerve. The last two images that depict the passage of sound through the middle and in-ner ears are obviously useful. The image illustrating the sinusoidal waves of various frequencies is also helpful. While the first two images are also relevant for the chapter as a whole, they are not particularly suited for this section. The reason these images were ranked high was that they have overlapping words; an important component of human ear is the thin membrane called the ear drum, which can be confused with a playing drum or membrane on it.
The image mining algorithms retrieve images that can potentially repeat across multiple sections of the same chapter. In fact, as can be seen in Fig. 7, this duplication is quite high for both A and C OMITY . The duplication in this figure has been computed at the subject level by averaging the overlaps computed at the chap-ter level for all the chapters in that subject. The image assignment algorithm reorders the images and uses more of the available or-dered set of images so that the images selected within a chapter are distinct.

We illustrate this point further with an example from the chap-ter on  X  X agnetic effects of electric current X  in the grade X Science book. Fig. 8a shows the top five images for three sections in this chapter proposed by A FFINITY before image assignment. Clearly, while all the sets of images shown are relevant to the chapter and can serve as illustrations for the corresponding sections, there is re-dundancy amongst them. Fig. 8b shows the top five images for the same sections, after applying the image assignment optimization. Figure 10: Comparison between A F FINITY , C OMITY , and E N -Besides removing redundancy, the optimization also enabled selec-tion of images more relevant to the sections. For instance, Section 2 on  X  X agnetic field due to current carrying conductor X  now includes images for the right hand rule, which is a guide to finding the di-rection of magnetic field around a current-carrying wire. Section 6 on  X  X lectric generator X  now includes wiring schematic for each of (single, two, three) phase to rotary converter, which is a motor generator that leverages magnetic field to generate power. Figure 11: Illustration of the benefit of E N SEMBLE for the sec-tion on  X  X ispersion of white light by a glass prism X  in grade X Science textbook
E NSEMBLE is best suited when the ensembled algorithms use largely non-overlapping signals. In order to understand the overlap between A FFINITY and C OMITY , we compute two statistics: one using the overlap in the retrieved images and the other using the overlap in the articles from which these images are retrieved.
Fig. 9 provides the two statistics, subject-wise. The image over-lap is computed by measuring the ratio of intersection to union in the top five images retrieved by the two algorithms. We compute overlap at the chapter level, and average it across all chapters for a subject. To compute article overlap, we pool the articles from which the top images for a particular chapter were retrieved for each algorithm. Then, we compute the ratio of intersection to union of these articles for every chapter. We can see that the overlap is small. These numbers are substantially lower when analyzed at the section level.
Fig. 10 compares E NSEMBLE with A FFINITY and C OMITY . We can see that E NSEMBLE consistently produces a larger fraction of the helpful images than either of the other two, thereby confirming the value of ensembling.

We use Fig. 11 to provide an illustration, using the results for a section from the chapter on  X  X uman eye and colourful world X  in the grade X science book. This chapter describes the optical phe-nomena in nature, including rainbow formation and the splitting of white light and blue color of the sky. The section we discuss intro-duces the concept of dispersion and assumes that the students are already familiar with refraction. The ensembled results are clearly superior than the results of the other two algorithms.
We studied the feasibility of enriching textbooks with links to relevant images and presented a solution for this problem. The so-lution comprises of three components: a component for optimizing the assignment of images to different sections within a chapter on a per algorithm basis, another for mining images from the web us-ing multiple algorithms, and finally a component for ensembling the results of the per algorithm assignments. We devised a rigorous formulation of the image assignment problem and gave a polyno-mial time algorithm for solving the problem optimally. We also presented two particular image mining algorithms that utilize or-thogonal signals and hence obtain different sets of relevant images. Finally, we provided an ensembling algorithm for combining the assignments.

We conducted a user study employing a corpus of fourteen high school textbooks, published by the central body for education in India. We used the Amazon Mechanical Turk platform for this pur-pose. Seven judges each, coming from a population of 56 judges, judged the results produced by our implementation for a random sample of 100 textbook sections. The results demonstrate the promise of the proposed system: the judges conservatively considered 87% of the images assigned to various sections to be helpful for under-standing the corresponding section and the performance was main-tained across the subjects.

The directions for future work include investigating what new issues arise if the ideas from this paper were to be extended for enriching textbook material with other media types. Another im-portant research direction is developing benchmarks for measuring the performance of these systems. Finally, it is worthwhile to ex-amine synergies between algorithmic approaches such as the one presented in this paper and the collaborative approaches such as the one proposed in [2].
