 Location-Based Services (LBS) have been widely accept-ed by mobile users recently. Existing LBS-based system-s require users to type in complete keywords. However for mobile users it is rather difficult to type in complete keywords on mobile devices. To alleviate this problem, in this paper we study the location-aware instant search prob-lem, which returns users location-aware answers as users type in queries letter by letter. The main challenge is to achieve high interactive speed. To address this challenge, in this paper we propose a novel index structure, prefix-region tree (called PR-Tree), to efficiently support location-aware instant search. PR-Tree is a tree-based index struc-ture which seamlessly integrates the textual description and spatial information to index the spatial data. Using the PR-Tree, we develop efficient algorithms to support single prefix queries and multi-keyword queries. Experiments show that our method achieves high performance and significantly out-performs state-of-the-art methods.
 H.2.8 [ Database Applications ]: Spatial databases Algorithms, Design, Experimentation, Performance Type-ahead search, Keywords search, Spatial databases
Location-Based Services (LBS) have become more and more popular and attracted significant attention from both academic and industrial communities recently. Many LBS based systems, such as AT&amp;T Location Information Ser-vices 1 , have been deployed to provide users with location-aware experiences, and they are widely accepted by millions of mobile users, thanks to the modern mobile devices. http://www.wireless.att.com/lbs/
Most of the existing studies adopt a spatial keyword search basedmethodtohelpusersretrievelocation-awareanswer-s [7, 5]. Given a set of objects with spatial information and textual description (e.g., points-of-interest (POIs)) and a user query with location and keywords, spatial keyword search finds top-k relevant objects by considering the dis-tance and textual relevance between the query and objects. For example, if a user wants to find a gas station nearby, she can issue a keyword query  X  gas station  X  to a LBS system, which returns the relevant gas stations by considering the user X  X  location and keywords.

Traditional spatial keyword search method requires users to type in complete keywords for finding location-aware an-swers. However for mobile users, typing a complete keyword is tedious and also susceptible to errors. To alleviate this problem, instance search (also known as type-ahead search or search-as-you-type) [1, 17, 16, 3, 15, 14, 18] is proposed to provide users with new search experiences, which return-s relevant answers as users type in queries letter by letter. Recently many systems, e.g., Google, have been deployed to support instant search.

It is very natural to extend instant search to support s-patial keyword search. To this end, in this paper we study the location-aware instant search problem. In our method, as a user types in queries letter by letter, the system re-turns the location-aware answers on-the-fly, and provides the user with instant replies. Figure 1 provides an exam-ple of location-aware instant search over 13 POIs. At ev-ery keystroke a user types in our system, the system takes her current input string as a query and returns the relevant location-aware answers instantly. For instance, as shown in Figure 1(b), when the user types in a partial query X  park s  X , the nearest objects containing complete keyword  X  park  X  X nd the prefix  X  s  X , i.e., o 9 and o 8 , are returned. Obviously this new search method can help users to find desired answers in a more friendly way than the traditional methods. Figure 1: An example for location-aware instant search on query  X  park s  X  X ndlocatedat X   X   X .
It is rather challenging to support location-aware instant search due to the requirement of a high interactive speed. Existing studies [13, 21] devise hybrid index structures to address this challenge. However, [13] has very limited filter-ing power for short or frequent query prefixes. [21] cannot support multi-keyword queries and it also consumes a large amount of memory. Moreover, both of them cannot perfor-m well for large data sets since they fail to fully utilize the textual and spatial pruning simultaneously.

To address these limitations, in this paper, we propose a novel index structure, prefix-region tree (called PR-Tree), to efficiently support location-aware instant search. PR-Tree is a tree-based index structure. Different from traditional indices, PR-Tree considers both textual partitioning and s-patial partitioning simultaneously to build the index. Thus it can achieve great improvement of efficiency for location-aware instant search.

Our contributions are summarized as follows.
The rest of this paper is organized as follows. We formu-late the problem of location-aware instant search and discuss related work in Section 2. We introduce our proposed index structure PR-Tree in Section 3. We develop efficient search algorithms in Section 4. In Section 5, we discuss how to support sophisticated ranking functions in PR-Tree. Exper-iments are provided in Section 6. Finally, we conclude the paper in Section 7.
In this section, we first formalize the problem of location-aware instant search in Section 2.1, and review related work in Section 2.2. Data Model. Our work considers a set of objects, O = { o 1 ,o 2 ,...,o |O| } in a spatial database. Each object o  X  X  consists of spatial information o.l and textual information o.W , denoted by o =( l, W ). Specifically, the spatial in-formation o.l represents a location in the two-dimensional geographic space, and the textual information o.W is a set of distinct words, denoted by o.W = { w 1 ,w 2 ,... w | o.W | For example, Figure 1 shows 13 objects, each of which has a location and a set of words, e.g., o 2 =( l 2 , { palace , street Query Model. Our paper focuses on supporting location-aware instant query q that consists of a location q.l ,asetof complete keywords q.W = { w 1 ,w 2 ,...,w | q.W | } that a user has typed, a prefix q.p that the user is typing in and an integer k , denoted by q =( l, W,p, k ). Given a set of objects O , the answer of q , denoted by R ,isthe k nearest objects sorted by their distances to query location q.l ,whereeach object o satisfies (1) object o contains all complete keywords in the query, i.e., o.W  X  q.W ,and (2) o has at least one word with q.p as its prefix, i.e., o.W, p w ,where p w denotes that p is a prefix of w .
We assume that  X  w i ,w j  X  q.W that w i ( w j )isnotaprefix of w j ( w i ). Let dist ( q,o ) represent the distance between query location q.l and object location o.l .Inthispaper,we use Euclidean distance as the distance measurement. Problem Formulation. Based on these notations, we for-mulate the location-aware instant search problem. Definition 1 (Location-Aware Instant Search).
 Consider a set of objects O = { o 1 ,o 2 ,...,o |O| } and a location-aware instant query q =( l, W, p,k ) . It returns the top-k ob-jects R X  X  such that each object o  X  X  satisfies o.W  X  q.W and  X  w  X  o.W, p w , sorted by their distances to the query location.

To make it consistent with existing work [13, 21], we only use the distance to rank the answers. We will discuss how to support other complex ranking functions in Section 5. Location-Aware Instant Search: Existing studies de-vised different index structures [13, 21] to support location-aware instant search.
 Ji et al. [13] proposed an R-tree based method called Filtering-Effective Hybrid Indexing (FEH). The method first builds an R-tree on top of locations of all objects. Then, in each R-tree node, it adds textual filters with possible prefix-es contained by the objects in this node. Given a query, it traverses the R-tree from the root to the leaves using the best-first-search strategy [10]. Whenever a tree node is reached, it first employs the filter to decide whether to insert its child nodes or objects into a priority queue. The search stops when the first k answers have been found. However, the FEH algorithm is very expensive for short and frequent prefixes, since the number of the potential candidate objects is extremely large, and the filters have poor pruning power.
Materialized Trie (MT) is a trie based method [21]. First, it builds a trie structure on top of words of all objects. Each leaf node has an inverted list to record those object-s which contain the corresponding word. To incorporate spatial pruning power into the trie structure, spatial infor-mation is added in each trie node. For a trie node with a prefix p , it divides the whole query space into R regions and maintains an upper-bound score for each region to indicate that a query with prefix p will reach the maximal score in this region. However it is rather expensive to materialize the information for all trie nodes. Thus it proposes to s-elect M nodes for materialization. The main problem for MT is that it will consume a large amount of memory. To achieve high performance, it needs to divide the space into a large number of smaller regions, thus incurs significant of s-pace utilization. Another limitation of MT is that it cannot supportmulti-keywordqueries,whichiscommoninmany applications.
 Spatial Keyword Search: Spatial keyword search has been widely studied in the database community [24, 4, 9, 7, 5, 23, 22, 20, 19, 6, 11]. Given a set of points-of-interest (POIs) and a query with keywords and location, the spatial keyword search aims to find the relevant POIs by consider-ing both spatial proximity and textual relevance. [24, 9, 4] (a) Spatial partition for the solved the range query problem by the use of R-tree. Fe-lipe et al. [7] integrated signature files into R-tree. Cong et al. [5] proposed the IR-tree by combining the inverted files and R-tree. Yao et al. [23] studied how to support approxi-mate string matching. Wu et al. [22] studied spatial keyword search for moving objects and Lu et al. [20] tracked reverse spatial and textual k nearest neighbor search.

Traditional spatial keyword search method requires users to type in complete keywords to find location-aware answers. In this paper, we study a more user-friendly search method, location-aware instant search. The method returns relevant POIs on-the-fly when users type in keywords letter by letter, which helps users find information with less typing efforts.
In this section, we introduce a novel index structure, called prefix-region tree, to support efficient location-aware instan-t search. We first introduce our basic idea in Section 3.1 and give an overview of the prefix-region tree in Section 3.2. Then, we respectively discuss the tree construction and up-date in Section 3.3 and Section 3.4. Finally we discuss some issues on PR-Tree in Section 3.5.
We can extend existing textual index structures (e.g., trie) or spatial index structures (e.g., R-Tree) to support location-aware instant search. Using a trie index based on the textual information of objects, we can adopt a text-only strategy to obtain the top-k answers as follows. Given a query q ,wefirst retrieve the objects which satisfy the textual constraints, i.e., such o  X  X  that o.W  X  q.W and  X  w  X  o.W, q.p w ,and then sort them in ascending order by their distances to q.l to get the top-k answers. Obviously, this method is inefficient since it never considers the spatial pruning, and may involve a huge number of objects which are not the top-k answers.
On the other hand, using an R-tree index based on the spatial information of objects, we can employ a spatial-only strategy. Specifically, we can adopt the best-first traversal method [10] to iteratively find the nearest objects. Then, we examine whether the objects satisfy the textual constraints mentioned above. However, this method fails to consider the textual pruning since the traversal over the R-tree ignores the words of the underlying objects.

To address these problems, we aim to build a more effec-tive index structure which integrates both the textual and spatial information seamlessly. To achieve this goal, we have the following observations. (1) Given a specific prefix p ,theobjectswith p may scatter in different areas. Based on the spatial distribution, we can partition the objects into several regions to facilitate effec-tive spatial pruning. Figure 2(a) shows objects containing prefix  X  s  X  (represented by circles), which can be partitioned into three regions. Using these regions, we can estimate objects X  distance bounds to the query location, and utilize spatial pruning to efficiently obtain top-k answers. (2) Given a specific region r ,theobjectsin r may contain different prefixes but it is hard to distinguish them by spa-tial information only. Thus, we can partition the objects based on the prefixes, in order to facilitate effective textu-al pruning. Figure 2(b) provides some objects in a region. We can partition the objects based on different prefixes they contain, e.g.,  X  s  X  X nd X  p  X , and efficiently prune the objects dissatisfying the textual constraints.

If we partition the objects by simultaneously using the textual and spatial information, we can fully utilize the spa-tial textual pruning at query time. However it is non-trivial to devise an index structure that seamlessly combines tex-tual and spatial partitions. To address this challenge, we propose the prefix-region tree in the following sections.
For ease of presentation, we first introduce an important concept, called prefix region . Intuitively, a prefix region con-sists of a prefix for textual partition and a region for spatial partition. Formally, the prefix region is defined as follows.
Definition 2 (Prefix Region). Let p denote a prefix and r denote an MBR (Minimum Bounding Rectangle). A pre-fix region is defined as a combination of prefix p and region r , denoted by f = p, r .

Given a prefix region f ,weuse O f to represent the ob-jects satisfying f ,thatis,eachobject o  X  X  f has prefix f.p and its location o.l is within region f.r . Take Figure 3 as an example. Consider a prefix region f =  X  s  X  ,r and a set of objects O = { o 1 ,o 2 ,o 3 ,o 4 ,o 7 ,o 8 ,o 9 ,o 10 ,o O f = { o 1 ,o 2 ,o 4 ,o 8 ,o 9 ,o 13 } since all objects in fix  X  s  X  and their locations are within r , as illustrated by the dashed-line rectangle labelled with prefix  X  s  X  X nFigure3. In addition, we define that a prefix region f 1 is subsumed by another prefix-region f 2 , if and only if 1) f 2 .p is a prefix of f 1 .p , denoted by f 2 .p f 1 .p ,and2) f 2 .r encloses f denoted by f 1 .r  X  f 2 .r .

Then, we define the prefix-region tree (or PR-Tree for short) as follows. PR-Tree organizes all objects in O in a hierarchical manner, where each node is a prefix region In the PR-Tree, each non-leaf node subsumes all its child nodes. Each leaf node, say f l = p l ,r l is associated with an object list, denoted by ObjectList , which contains the objects with prefix p l located within region r l .Inparticular, the root is f root =  X  ,r all ,where r all represents the MBR of all objects in O . Obviously, in a PR-Tree, the region sizes of nodes in lower levels are smaller than those in higher levels. For ease of presentation, we use  X  X refix region X  and PR-Tree node interchangeably. In order to avoid large tree depths, we introduce a param-eter M to allow at most M objects contained in every leaf. Figure 4 provides an example of a PR-Tree. The string on the top-left of the node box denotes the prefix f.p ,andthe inner frame denotes the region f.r .
We construct a PR-Tree in a top-down manner. We first initialize the root node f root =  X  ,r all with object set Then, we split O into subsets to generate child nodes. Simi-larly, we recursively split the generated nodes until the num-ber of objects in each leaf node is not greater than M .Ob-viously, the essential task is how to split a node f .Tothis end, we consider both textual and spatial partitioning.
Textual partitioning groups the objects O f of node f based on the textual information. Specifically, consider a set of words W f with prefix f.p contained by the objects in
O f . Based on W f , we can construct a radix trie 3 where each path from the root to a node corresponds to a prefix. Using the radix trie, we can define Next ( f.p ) as the child nodes of f.p in the trie. For example, given a set of key-words W f = { pavement, palace, park, parliament, po-lice, post } ,wehave Next ( X  p  X ) = { pa , po } and Next ( X  pa  X )= { pavement, palace, par } . Based on prefixes in Next ( f.p ), we can partition objects O f into subsets for generating child nodes in the PR-Tree. Figure 5(a) provides an example of textual partitioning. The root node  X   X   X  is partitioned in-to two child nodes respectively with prefixes  X  s  X  X nd X  p  X  X n Next (  X  ). Then, node with prefix  X  p  X  is further partitioned into two child nodes respectively having  X  pa  X  X nd X  po  X .
Spatial partitioning groups objects O f of node f based on the spatial information. Specifically, we partition region f.r into subregions, each of which contains subsets of O f .In this paper, we consider one of the most fundamental strate-gies, i.e., to partition one region into four non-overlapped subregions by splitting at a central point horizontally and vertically. We omit discussing other partitioning methods in this paper due to the space limitation.

More formally, we partition region f.r into four regions, r ll (lower left), r ul (upper left), r lr (lower right) and r (upper right), and respectively represent the object sets in the regions as O ll f , O ul f , O lr f and O ur f . A straightforward method is to simply partition r into four regions of the same size, which is used in a quad-tree [8]. However, this method may result in skew distribution of objects, that is, some regions may contain more objects than the others. To make the partitioning as even as possible, i.e., each subset contains nearly the same number of objects, we select the centroid as
A radix trie is a space-optimized trie structure where each node with only one child is merged with its child.
Figure 5: Textual partition and spatial partition. the center for spatial splitting. As shown in Figure 5(b), the objects are partitioned into four sub-regions. Note that the partition strategies may produce less than four sub-regions, sincesomeregionscontainnoobject.

Based on the textual and spatial partitioning, we present the algorithm for constructing a PR-Tree, as shown in Algo-rithm 1. The algorithm first initializes a root node f root  X  ,r all , and puts the root with its corresponding objects O into a stack. Then, the algorithm iteratively employs the following textual and spatial partitioning operations on each node f , which is illustrated in Figure 6. 1) The algorithm employs textual partitioning to obtain sev-eral intermediate nodes, i.e. p 1 ,r p 1 , p 2 ,r p 2 ,..., p where p i  X  Next ( f.p ). 2) For each intermediate node p i ,r p i , the algorithm em-ploys spatial partitioning to further generate four nodes, p are then assigned to be the children for the node p, r O .
This above node-splitting procedure stops when every leaf node contains no more than M objects.
 Algorithm 1 : ConstructPRTree ( O , M ) Input : O :Anobjectset; M :aparameter
Output : T : A constructed PR-Tree
In this section, we discuss the update operations, i.e., in-sertion and deletion of the PR-Tree.
We discuss an algorithm to insert an object o =( l, W ) into a PR-Tree. The basic idea is to traverse the PR-Tree and select an appropriate node for insertion. Specifically, for every word w i in o.W , the algorithm traverses the PR-Tree from the root. For a visited node f , the algorithm identifies the nearest child node f c that f c .p w i with respect to o.l . After selecting the child node f c , the algorithm updates f as follows. If o.l is not contained within region f c .r ,theal-gorithm enlarges region f c .r to a region containing o.l .We can recursively apply the above procedure until reaching a leaf node f l .If f l contains less than M objects, we simply insert o into f l  X  X  object list. Otherwise, we employ the tex-tual and spatial partitioning in Section 3.3 to further split f ,andinsert o into a new leaf node.

The time complexity scales to the height of the PR-Tree tree. Formally, it takes O (log N ) to finish an insertion op-eration, where N is the number of objects.
We propose a bottom-up algorithm for deleting an object from a PR-Tree. When deleting an object o , the algorithm first finds all the leaf nodes which containing o ,andremoves it from the object list in the leaf nodes. Then, it updates the intermediate nodes of the PR-Tree in a bottom-up way. The basic idea is to examine whether the MBR sofintermediate nodes are affected by the object deletion. Specifically, if o.l is located at the border of the MBR of a given intermediate node, the MBR needs to be re-calculated based on the MBR s of its child nodes. The algorithm terminates when reaching the root of the PR-Tree.

Note that, according to our tree construction, a node must have at least two child nodes. Therefore, if a node f is empty after deletion, we examine the number of its child nodes for the parent node of f .If f is an only child, we merge the node f to its parent node.

Then we analyse the time complexity. Since a deletion operation needs to examine | o.W | paths from leaves to root, the time complexity is bounded to O ( | o.W | log N ).
In this section, we discuss three issues on PR-Tree. The first is on the balancing issue, the second is on the space complexity and the third is on the storage alternatives.
PR-Tree is not a balanced tree, since the textual partition-ing cannot guarantee that each child node contains the same number of objects 4 . However, it does not affect the search-ing efficiency on the PR-Tree due to the following reasons. 1) The height of our PR-Tree is not very large since the fanout of each intermediate node is large. Let  X  denote the alphabet generating all words. The fanout of each interme-diatenodeisatmost |  X  | X  4, which is usually large. We constructed PR-Trees on two real datasets in our experi-ments, and the heights were respectively 6.35 and 5.29. 2) There are no rather long branches due to our spatial partitioning strategies. Since we choose centroid as the cen-
It is similar to a radix-tree since we employ Next () function. ter for spatial partitioning, the descendant nodes would con-tain roughly the same number of objects, leading to the maximum length of branches scaling to log N . For exam-ple, in our experiments, the maximum branch lengths of the PR-Trees on the two datasets were respectively 12 and 14.
Therefore, although the PR-Tree is not balanced, the time of traversing different branches would differ insignificantly. In this section, we analyse the space complexity of the PR-Tree. Recall that the partitioning process of a node terminates when it contains at most M objects. Therefore, we can prove that the upper bound of the total number of leaf nodes in a PR-tree is within [ | o i .W | M , | o shown in Lemma 1.

Lemma 1. The bound for the total number of leaf nodes
Proof. We first prove that any object will appear in at most | o.W | leaf nodes of the PR-tree. According to the building process, the regions for the nodes with the same prefix will never be overlapped. Each word of the objects in
O will finally be included in one leaf node, and hence an object o is contained in at most | o.W | leaf nodes. Thus the upper bound is | o i .W | .

On the other hand, each leaf node contains M objects, thus the lower bound is | o i .W | M .

Based on Lemma 1, the indexing size is scalable to the volume of the data set, i.e., | o.W | .
In this paper, we only consider maintaining the PR-Tree in memory. Nevertheless, PR-Tree is feasible to be disk-based. Since each non-leaf node only needs to store a few number of attributes, i.e., prefix, MBR and child list, and each leaf node needs to store the ObjectList , the information on one node is possible to be stored in one page of disk. However, in this paper, we mainly focus on devising the PR-Tree in memory and demonstrate its supreme efficiency, while taking the disk-based alternative as future work.
In this section, we first propose an algorithm for single-prefix queries in Section 4.1, and then extend the algorithm to support multi-keyword queries in Section 4.2.
We first consider a single prefix query q with empty complete-keyword set, i.e., q.W =  X  . Given the query, we employ the effective best-first traversal algorithm (BFT) [10], to effi-ciently retrieve the top-k answers using the PR-Tree. The BFT algorithm uses a priority queue for maintaining the nodes and objects in the PR-Tree that need to be visited. For each node f in the queue, we compute the minimum distance between query location q.l and the corresponding MBR f.r , denoted by MIND ( q.l,f.r ). For each object o in the queue, we compute its distance to q.l , i.e., dist ( q,o ). Then, we sort the elements in the queue in ascending order by their minimum distances.

Due to the space limitation, we omit the details for BFT and only show an example of Algorithm 2 in this section. Example 1. Consider the objects in Figure 1 and the PR-Tree in Figure 4. For a query q = { (40 . 5 ,  X  74 . 0) ,  X  p  X , 2 } , we compute top-2 answers as follows. Step 1 : Enqueue root node with  X  ,0 .
 Queue:  X  ,0 Step 2 : Dequeue the top element  X  ,0 ,expanditschildn-odes containing prefix  X  p  X , calculate their minimal distances to q.l and enqueue them.
 Queue: p ,0 p ,1.19 Step 3 : Dequeue the p ,0 , expand all objects containing prefix  X  p  X , and enqueue them.
 Queue: o 10 ,0.38 o 12 ,0.54 p ,1.19 Step 4 : Dequeue o 10 ,0.38 . Since it is an object, we direct-ly put it into the result list. So does o 12 ,0.54 . Now, top-2 answers have been retrieved. Algorithm terminates. Algorithm 2 : kNNQuery ( p , l , k , T ) Input : p :Prefix; l :Location; k :Number; T :PR-Tree
Output : R : The top-k result list
In this section, we extend our algorithm to support queries with multiple keywords, i.e., q.W =  X  . We first introduce an intersection-based method and then propose a cost-based method to improve the performance.
To support multi-keyword queries by PR-Tree, a straight-forward method is to simply extend the algorithm for single-prefix queries. Specifically, consider a query q =( l, W,p, k ) where q.W =  X  . Each time when a dequeued element is a leaf node, we can only enqueue the objects which contain all keywords in q.W . To efficiently examine whether an object contains all keywords in q.W , we pre-compute and maintain a global inverted list that maps each word to the objects containing such word, denoted by I ( w ). Thus, we can effi-ciently obtain the promising objects containing the q.W by computing the intersection of I ( w i ).
 Figure 8: Two circumstances for occurrence list.
 Figure 7 provides an example to illustrate the method. Consider a query with W = { park } and prefix  X  s  X . We first obtain the object list using inverted list I ( park ), i.e., { o 4 ,o 8 ,o 9 } . Then, we examine each object contained in a leaf node, say  X  st  X , and only enqueue the objects contained in I ( park ), i.e., o 4 .
 Next, we analyse the time complexity of the above method. Since the size of ObjectList in a leaf is strictly less than or equal to M , and the size of the I ( w ) is maximally equal to the size of the data N , thus the time complexity for inter-section on one node is O ( M log N  X | W | ).

However, in the worst case, we have to examine all the leaf nodes, which leads to low performance. Thus, according to Lemma 1, the overall time complexity is O ( NM log N  X | W Obviously, this method visits many unnecessary leaf nodes which do not contain all keywords in q.W . For example, giv-en query  X  palace s  X , for the prefix  X  s  X , there may b e many leaf nodes that need to be visited. However, the number of leaf nodes containing word  X  palace  X  X srathersmall(See Figure 8(a)). We can see that the expanding child nodes labelled with  X 2 X ,  X 3 X  is useless for producing the answers.
To avoid unnecessary traversal, we must include addition-al textual information for early termination. Inspired by our observation in Figure 8(a), for any keyword w on node n , we can explicitly use a child list to indicate that only the children of n in the list will contain the keyword w .Wecall such a list an occurrence list , denoted by OL ( n, w ). Thus, when traversing to such a node n ,weonlyneedtoexpand  X 
OL ( n, w i ) ,w i  X  q.W into the priority queue to prune the unpromising descendants.

Obviously, if we store occurrence lists for all possible key-words on every tree node, the pruning power will be fully utilized. However, it will result in high memory cost, since the space requirement for storage will be N  X | Vocabulary in a worst case. In fact, sometimes occurrence list may have no effect on the performance. It happens when a keyword is frequent in the spatial database, and thus many leaf nodes may contain such word. Figure 8(b) shows this case. The keyword  X  X ark X  appears in the sub-tree of every child of the root node, and thus it is useless to store occurrence list for  X  park  X  on the root node.

Therefore, we need to judiciously select keywords and n-odes for storing occurrence lists. To this end, we first con-sider the cost of storing OL ( n, w ) as its length. Definition 3 (Cost).

Each OL ( n, w ) will benefit query processing by ignoring those child nodes of n which do not contain keyword w . Therefore, the benefit can be described in two parts: (1) the overhead saved on priority queue operations, e.g. en-queue or dequeue, and (2) the overhead saved on leaf nodes intersection. Let CL ( n ) denote the original children list for node n .Let PQO ( n ) denote the overhead on priority queue operations for all nodes rooted at n and LNO ( n )denotethe overhead on intersection for all leaf nodes in sub-tree of n , we define the benefit of OL ( n, w )as: Definition 4 (Benefit).
 where p ( w ) is the probability for word w being queried.
Conventionally, PQO ( n ) is equal to the number of tree nodes under n ,and PQO ( n )isestimatedbythenumberof objects under n .

Finally, for a given amount of memory budget B ,wewant to maximize the overall benefit for different selected key-words and nodes. The formal problem is stated as follows.
Definition 5. (Memory-Constrained Keywords N-odes Selection Optimization) Given the budget B ,the keyword set K and the node set N , we want to find a collec-tion of keyword-node pairs, that achieve maximum benefits within the budget B . We now prove this problem is NP-Complete.
 Theorem 1. Memory-Constrained Keywords and Nodes Selection Optimization is NP-Complete.

Proof. The problem can be reduced from the 0-1 K-napsack Problem. Since the budget B is equivalent to the knapsack X  X  volume, Cost ( OL ( n, w )) is the size of the items and Benefit ( OL ( n, w )) can be looked as item X  X  value. Thus, proof is done.

We propose a greedy heuristic algorithm to solve this scending order, then choose the current best ( n, w )solong as the budget is not exhausted. Previous study [12] showed that the approximate ratio for greedy algorithm is 2. Note that, the Cost ( OL ( n, w ) is far smaller than the budget thus the results would not be bad. Example 2 shows a sce-nario for multi-keyword search on a materialized PR-Tree.
Example 2. Consider a multi-keyword query  X  palace s  X  at location (40.5,-74.0).
 Step 1 : We start to push the  X  ,0 into the queue: Queue:  X  ,0 Step 2 :  X  ,0 is dequeued, and we check child nodes s,1.84 , s,1.22 and s,1.38 .Sinceonlythenode s,1.84 has been materialized with keyword  X  palace  X , we discard the other t-wo unpromising nodes and only enqueue node s,1.84 . Queue: s,1.84 Step 3 : The objects list for node s,1.84 is { 2,4,13 } ,andwe intersect it with the global inverted list for keywords  X  palace  X  { 2 } . Finally only object o 2 has been enqueued; Queue: o 2 ,2.76 Thus, we get the answers for query  X  palace s  X  X nthema-terialized PR-Tree.
Existing studies on keyword search in spatial database [5] can support more sophisticated ranking functions, which consider not only the spatial proximity but also textual rel-evancy between queries and objects. Here we discuss how to use our PR-Tree to support such ranking functions.
Given a query q andanobject o , a general ranking func-tion D st to compute their similarity can be defined as where maxD s is the maximum distance on space, maxD t is the maximum distance on text, and rel ( q,o ) is the tf*idf based textual relevance between q and o . where tf ( w,o ) is the term frequency of term w in object o and idf ( w, O ) is the inverse document frequency of term w in the object set O .

Next we discuss how to use the PR-Tree to support the new ranking function. We add a list of keyword,weight pairs on each node of the PR-Tree, which indicates that for all objects in the sub-tree of this node, the maximum tf*idf for keyword is weight . Formally speaking, on a tree node f and for a specific keyword w ,the weight is calculated by: where SubTreeObj ( f ) denotes all the objects in the sub-tree of node f .

At query time, we can compute the textual relevancy by w  X  q.W weight ( w,f ), then aggregate the spatial distance to obtain the ranking score D st ( q,f ). This overall value can be used as the maximum boundary value for a given query q at node f on the PR-Tree, facilitating effective pruning.
Similarly, our PR-Tree is also capable of supporting the ranking function in [21].
In this section, we report the experimental results. We im-plemented two baseline algorithms, FEH [13] and MT [21], as mentioned in Section 2.2. For FEH, we used R*-tree [2] as reported in the paper. We compared our PR-Tree based method (denoted by PRT) with the two baseline methods. We used two real datasets in our experiments. 1) OpenStreet : We extracted 2 million POIs for day-life in USA, such as government buildings, parking lots, schools, etc., from the OpenStreet open-source spatial database 5 . 2) Business : We obtained 5 million POIs for business in USA, such as cafe, company, restaurant, etc., from a popular directory website, Factual 6 .

Table 6.1 provides some statistics of the two data sets, such as number of objects, data size, etc.
 All baseline indices and our PR-Tree were memory-resident. The parameters of the baseline algorithms were set as the default values in the original papers. All the algorithms were implemented in C++, and all the experiments were http://planet.openstreetmap.org http://www.factual.com
Avg. # of words per object 3.23 5.45 conducted on an 2.66MHz Intel Xeon processor and 24GB RAM, running on Ubuntu 11.04. We evaluated the query performance for single prefix queries. Since the MT algorithm could not support word segmenta-tion on text, we conducted the following two experiments. We first compared our method PRT with FEH under the word-segmentation setting, and then compared PRT with MT by taking the whole text of each object as a single string.
We randomly chose 1000 words from the vocabulary, and generated three prefixes from one selected word. For exam-ple, consider a selected word  X  park  X . We generated three prefixes, i.e.,  X  p  X ,  X  pa  X  X nd X  par  X  for query evaluation. Com-pared with long prefixes, the short prefixes were much better for evaluating the query performance, since users always s-tart from scratch when typing to search. Figure 9: PRT vs. FEH for single-prefix queries with different k (prefix lengths are within [1 , 3] ).
Figure 9 shows the experimental results on the two dataset-s with different k . We can see that our algorithm outper-formed the FEH algorithm in both datasets. On the Open-Street dataset, our PRT algorithm is about 15 times faster than FEH. On the Business dataset, PRT was about 5 times faster than FEH. The improvement of the performance was mainly attributed to our novel index structure, since PR-Tree can utilize both textual and spatial pruning simultane-ously. Using the PR-Tree, we can efficiently find the promis-ing objects which not only contain the query prefix, but also are near our query location. In contrast, FEH only utilizes a pure spatial index and does not consider textual pruning. Figure 10: PRT vs. FEH for single-prefix queries with different prefix lengths ( k =20 ).

We also conducted an experiment to evaluate the perfor-mance on different prefix lengths between PRT and FEH. Given 1,000 selected words mentioned above, we generated all possible prefixes for each word. Figure 10 provides the results for k = 20. Though there were lots of candidates for shorter prefixes, they could still be distinguished by d-ifferent nodes on PR-Tree that represent different regions. Thus, PRT achieved better performance than FEH.
To compare PRT and MT, we took the text of each POI as a single string without word-segmentation. Similar to pre-vious experiments, we generated 1000 prefixes whose length were within [1 , 3]. Figure 11 provides the experimental re-sults on both datasets for different k values.

We can see that the PRT algorithm was much more ef-ficient than the MT algorithm. The poor performance of MT was due to its trie-based index structure, which failed to utilize effective spatial pruning. Figure 11: PRT vs. MT for single-prefix queries with different k (prefix lengths are within [1 , 3] ).
We then examined the space complexity of different in-dices. Table 2 provides the memory usage on two data sets. As shown, PRT consumed less memory, compared with FEH and MT. To achieve better performance, FEH maintained twofiltersoneachR-Treenodeforahugeamountofpre-fixes, and MT materialized a lot of tree nodes with a small granularity of regions. Compared with these algorithms, our method only maintained a PR-Tree, which scaled to the size of original data as proved in Section 3.5.2.
 Table 2: Index size for three algorithms (MB).

We examined the query performance of our cost based algorithm (Section 4.2) by varying memory budget B ,to investigate the impact of materialization size on the perfor-mance. On each data set, we randomly selected 1000 objects and randomly chose 3 keywords from o.W in each selected objectsasaquery. Then,wetookthefirsttwokeywords as complete words, and generated a random length of pre-fix from the last keyword. For example, given an object with text  X  Washington State Driving School  X , one possi-ble keyword query generated from it was  X  Driving Wash-ington Sc  X .

Figure 12 provides the experimental results for multi-keyword queries on the OpenStreet dataset. We can see that differ-ent materialization sizes had great impact on query perfor-mance. Specifically, we can see that the average query time Figure 12: Performance with different budgets.
Figure 14: On two spa-tial partition strategies varies dramatically when B is 0% to 60% of the original data size. When B is larger, the difference is not significan-t. Based on this observation, we could judiciously select a proper memory budget in practice, in order to balance the space and time. In the remainder of our experiments, we set the budget percentage as 70%.
We evaluated performance for multi-keywords queries for our intersection-based method (denoted by PRT-I), cost-based method (denoted by PRT-C) and the baseline FEH algorithm. All the settings were the same as those in Sec-tion 6.3.1 Figure 16: PRT vs. FEH for multi-keyword queries with different k (2 complete keyword and 1 prefix).
Figure 16 provides the experimental results on the two datasets for different k values. We can see that our PRT-C algorithm was approximately 100 times faster than the FEH algorithm for both data set. This significant improvement results from the fact that PR-Tree has guaranteed that the visited leaf nodes satisfy the constraints on query prefix q.p , thus it would not bring any unnecessary work of traversal. On the other hand, FEH might traverse many unpromising leaf nodes which could not produce any top-k answer. More-over, the PRT-I algorithm achieved poor performance. This is because that PRT-I did not utilize the occurrence list and a lot of unnecessary nodes might be visited at query time.
In addition, we compare the algorithms by varying dif-ferent numbers of complete keywords. Figure 17 provides the experimental results. As PRT-C was always better than PRT-I, in the figure we only show the results of PRT-C and FEH. We can see that the time of PRT increases sub-linearly with the increase of complete keyword numbers. This shows that our cost-based method of materialization achieves good performance on multi-keywords queries.
We evaluated the query performance on two spatial parti-tioning settings, i.e., planar center or centroid as the quad-split point, which mentioned in Section 3.3. We first built two different PR-Trees, then applied single prefix and multi-keyword queries to make comparisons. All the query settings were the same as those in Sections 6.2 and 6.3. Figure 17: PRT vs. FEH for multi-keyword queries with different keyword numbers.

Figure 14 shows the results, where  X  X LNC X  denotes the  X  X lanar center X  and  X  X TND X  denotes the  X  X entroid X . We can see that, by using centroid as the splitting point, we could achieve about 40% speed improvement for single pre-fix query compared to planar center. This is because using the centroid will result in a more even partitioning of objects on space. However, for multi-keyword queries, the improve-ment is not significant. The reason is that utilization of occurrence list results in early terminations, and thus long branches have little effect on the query time. We examined the scalability of our best algorithm on the Business dataset, since it contains POIs in the whole re-gion of USA. We used the same experimental settings as we applied in Sections 6.2 and 6.3.
We first evaluated the time scalability for single-prefix and multi-keyword queries with different sizes of the original da-ta. Figures 13 shows the experimental results. We can see that the query time for both queries increased sub-linearly when the data size increased from 1 to 5 millions. From the results we can see that our PRT algorithm could support location-aware instant search on large datasets.
We evaluated the space scalability of PRT. Figure 18(a) provides the experimental results for single-prefix queries. We can see that with the increase of data sizes, both the size of the PR-Tree and the inverted lists in the leaf nodes in-creased sub-linearly, which was consistent with the analysis on space complexity mentioned in Section 3.5.2. To further improve the storage utility, we can store the inverted list in disk, and only maintain the PR-Tree in memory.

Figure 18(b) provides the experimental results for multi-keyword queries, where the global keyword inverted index and keyword occurrence materialization were included. We can see that the size of the global keyword inverted index consumed little memory, and the total materialization size was adjusted linearly to the size of the data. Thus the in-dexing memory of our PR-tree also scaled to the data size.
In this section, we evaluated the performance of PR-Tree operations, i.e., construction, insertion, deletion, on the two datasets. We first conducted 1000 insertion and deletion operations for testing. Figure 3 shows that the PR-Tree can be efficiently maintained.
 We also conducted the throughput experiments on PRT. We generated a series of operations, i.e., 10% insertions, 10% deletions and 80% random queries. Figure 19 shows the high throughput of our PRT algorithm. Figure 19: Evaluation on throughput (10% inser-tions, 10% deletions, 80% top-k queries).
We evaluated the efficiency of the tf*idf based ranking function mentioned in Section 5. We generated 1000 queries, each of which only contained complete words(the length var-ied from 1 to 3).
 Figure 15 provides the experimental results on the Open-Street dataset with different k values. Wecanseethat with the increase of parameter  X  , the average query time decreased. This is because for large parameter  X  , the impact of spatial filtering became insignificant. The experimental results showed that although we focus on prefix search, the PR-Tree can still support the tf*idf ranking function.
In this paper, we have studied the problem of location-aware instant search. We proposed a novel indexing struc-ture PR-Tree to support location-aware instant search. We used prefix-regions to partition the spatial data by consid-ering the spatial information and textual description simul-taneously. We discussed how to construct and update the PR-Tree. Using the PR-Tree, we devised effective algorithm-s to support single prefix queries and multi-keyword queries. We proposed a best-first traversal based algorithm to answer single prefix queries. We developed an intersection-based al-gorithm and a cost-based algorithm to answer multi-keyword queries. We have implemented our techniques and experi-mental results show that our method achieved high perfor-mance and outperformed state-of-the-art approaches. This work was partly supported by the National Natural Science Foundati on of China under Grant No . 61003004, the National Grand Fundamental Research 973 Program of Chi-na under Grant No. 2011CB302206, a project of Tsinghua University under Grant No . 20111081073, and the  X  X Ex-T Research Center X  funded by MDA, Singapore, under the Grant No. WBS:R-252-300-001-490.
