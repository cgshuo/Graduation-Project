 The booming of e-commerce in recent years has led to the generation of large amounts of product search log data. Prod-uct search log is a unique new data with much valuable infor-mation and knowledge about user preferences over product attributes that is often hard to obtain from other sources. While regular search logs (e.g., Web search logs) contain click-throughs for unstructured text documents (e.g., web pages), product search logs contain clickth-roughs for struc-tured entities defined by a set of attributes and their val-ues. For instance, a laptop can be defined by its size, color, cpu, ram, etc. Such structures in product entities offer us opportunities to mine and discover detailed useful knowl-edge about user preferences at the attribute level, but they also raise significant challenges for mining due to the lack of attribute-level observations.

In this paper, we propose a novel probabilistic mixture model for attribute-level analysis of product search logs. The model is based on a generative process where queries are generated by a mixture of unigram language models de-fined by each attribute-value pair of a clicked entity. The model can be efficiently estimated using the Expectation-Maximization (EM) algorithm. The estimated parameters, including the attribute-value language models and attribute-value preference models, can be directly used to improve product search accuracy, or aggregated to reveal knowledge for understanding user intent and supporting business intel-ligence. Evaluation of the proposed model on a commercial product search log shows that the model is effective for min-ing and analyzing product search logs to discover various kinds of useful knowledge.
 H.2.8 [ DATABASE MANAGEMENT ]: Database appli-cations X  Data mining ; H.3.3 [ INFORMATION STOR-AGE AND RETRIEVAL ]: Information Search and Re-trieval Algorithms, Performance, Experimentation Product search, search log mining, probabilistic mixture model
Product search log is an important data source for mining business related knowledge and understanding user behav-ior. Product search log is similar to regular search logs (e.g., Web search logs) but different in that products are struc-tured entities rather than unstructured web documents in Web search logs. Particularly, each product can be defined by its specifications, which is essentially a set of attribute and value pairs. For instance, Table 1 shows a set of entities and a subset of their specifications. Such structured data together with user click-through activities and their queries form a unique invaluable resource, from which much useful knowledge can be discovered, particularly knowledge about user preferences over product features, user search intents, and relative strengths and weaknesses of competing prod-ucts. For example, many interesting questions can be poten-tially answered by mining product search logs: What are the most important aspects to users when shopping for a prod-uct? What are the differences in features favored by users between expensive and inexpensive products? Which brands of a product attract most attention for what features? Do people care about  X  X egapixels X  more than  X  X rand X  when shopping for  X  X oint shoot camera X ? Automatic acquisition of such knowledge not only enables improvement of a prod-uct search engine, but also opens up many opportunities of other applications such as market research, business intelli-gence, and targeted advertising.

While mining product search log has the potential of dis-covering a lot of useful knowledge, it also raises challenge in mining techniques. Indeed, the building block for most of the questions we raised for knowledge discovery is the association between query words and entity specifications, which cannot be directly obtained from the search log. Fig-ure 1 illustrates the difficulty. This concept graph describes a query q which consists of four keywords ( w 1 ,w 2 ,w 3 and a clicked entity e which has a list of three specifications ( s 1 ,s 2 ,s 3 ). In product search log, the relation between a query q and an entity e is considered observable. For click analysis, this relation is an abstraction of clicking behaviors. However, since each query has multiple keywords and each entity is associated with multiple specifications, the relation Brand Hard Drive Graphics Blu-ray HP 750G Radeon HD 7690M XT No Dell 782G NVIDIA N13P-GS Yes Acer 500G Intel HD No Asus 128G UMA No Acer 500G Radeon HD 7640G Yes Asus 750G Intel HD Graphics 3000 No
Sony 640G Intel HD Graphics 4000 No between query words and entity specifications cannot be di-rectly observed. How to successfully model this relation is the key for mining product search log.

Although some techniques for mining regular search logs can still be applied to mining product search log, to the best of our knowledge, systematic mining of product search logs has not been studied. In this paper, we propose and study a novel principled method, i.e. a probabilistic mix-ture model for systematically mining and analyzing prod-uct search log data. Specifically, we propose a novel proba-bilistic mixture model for attribute-level analysis of product search logs in consideration of the click-throughs and the associated queries. The model is based on a generative pro-cess where queries are generated by a mixture of unigram language models defined by each attribute-value pair of a clicked entity. Such a generative model essentially simulates how a user formulates a query in the following way. First, a query would be generated word by word. Second, each query word is generated in two steps. In the first step, the user would decide which attribute values of the product that the user prefers; in the second, the user would choose words to express the preferences of an attribute value (i.e., attribute specification). Such a generative model naturally includes two component models that represent detailed knowledge about user preferences: 1) There is an attribute specifica-tion selection mode p ( s | e,c ) where e is a product entity, s is an attribute specification, and c  X  { 0 , 1 } indicates whether the user skipped or clicked on the product. This model represents detailed knowledge about users X  preferences on feature/attribute values. For example, p ( s | e,c = 1) tells us what feature values were preferred when a user liked prod-uct e . 2) There is a specification preference language model p ( w | s,c ), where w is a (query) word. This model tells us what query words tend to be used by users who liked or dis-liked an entity attribute value s . For example, p ( w | s,c = 1) tells us what words are most commonly used in queries if a user favored a particular attribute specification s of product e .
 The model can be efficiently estimated using the Expectation-Maximization (EM) algorithm. The estimated parameters, including the attribute-value language models and attribute-value preference models, can reveal various kinds of useful knowledge, such as knowledge about user preferences over different product features, user search intents, and relative strengths and weaknesses of comparable products. Such knowledge has many applications including, e.g., improving search accuracy, user profiling, market research, and busi-ness intelligence.

We evaluated the proposed model on a commercial prod-uct search log. The experiment results show that the model is effective for mining and analyzing product search logs to discover various kinds of useful knowledge about users, products, and more more importantly, user preferences over product features. We present qualitative results to show that the model can be useful for many applications such as comparing product specifications, ranking of product fea-tures, brand preference analysis, detailed user preferences, and business intelligence and market research in general. We also present quantitative evaluation results to show that the proposed model can annotate product entities to improve search accuracy.
As pointed out by Silvestri, search log is a (potentially) infinite source of information for extracting useful knowl-edge [18]. Indeed, the overwhelmingly large amount of user search log data generated by Web search engines has at-tracted much attention in research. Many work have been done towards the mining and exploitation of knowledge for various purposes.

Silverstein analyzed a large scale Web search log and stud-ied various aspects of search engines, leading to many in-sightful conclusions on term query analysis and user behav-ior analysis [17]. They found web users differ significantly from the user assumed in the standard information retrieval literature, as they type in short queries and mostly look at the first 10 results only, and seldom modify the query. Mei and Church used Web search log to study the difficulty of search and personalization from an information theory per-spective [13]. They used conditional entropy of URLs as an indicator of search difficulty, and compared the general search difficulty to the search difficulty when personalized with user X  X  IP address. Kang et al. studied Web search log as a multidimensional data source including time, location and topic concepts and proposed a topic-concept cube for mining topic related knowledge [9].

A particularly important direction in search log mining is to improve search quality. Xue et al. modeled the click-through data as a bipartite graph and proposed an iterative algorithm to solve the data sparsity problem for improving Web search results [22]. Zhang and Nasraoui combined the use of sequential based approach and a content based simi-larity in mining Web search log for query recommendation [24]. Wang and Zhai used context-sensitive term patterns to mine term associations from Web search log for query refor-mulation [21]. Hu et al. mine subtopics of queries from Web search log by clustering clicked URLs [7]. Tan et al. mine the contextual information from long term search history of users to improve language modeling for retrieval [19].
However, these work are all focused on classic Web search logs where the click-throughs are made on unstructured web documents. Due to the unstructured nature of web docu-ments, it is difficult to obtain fine level insights from web search logs. In this work we study a different type of search log, i.e. product search log, and focus on exploiting the structure of product entities to mine deep knowledge about user and business preferences. The techniques we propose are novel and different from existing approaches for Web search log mining.

Transaction log mining is an important branch in data mining. A lot of studies have been carried out in this theme, including frequent pattern mining [4], association rule min-ing [2, 23], sequential pattern mining [3], etc. These studies provide a lot of useful insight for user preference and for busi-ness optimization. However, compared with product search log, transaction log does not involve user queries, making it impossible to perform query related analysis. Indeed, we see in Section 1 that many interesting analysis related to user preference and business decision making are closely related to queries. Mining this new log data will allow us to dis-cover a lot of new knowledge that cannot be easily obtained elsewhere.

Recently, some studies of e-commerce related applications have also made use the product search logs. Li et al. pro-posed a semi-supervised method trained with search queries and matched products for tagging query keywords with prod-uct meta-data [12]. Sarkas et al. studied a similar problem with a supervised and an unsupervised model [16]. Pound et al. studied yet another problem, i.e. facet discovery, by mining a search log that contain structured product in-formation [15]. These work are task oriented and utilize task specific heuristics for mining. In comparison, our work propose a principled and systematic approach for mining product search logs, which can be used for practical appli-cations. Furthermore, in this work we study the real, large scale search log from a commercial product search engine, which is significantly different from the simulated product search logs used in the previous studies.

Review mining is also an important research area for busi-ness intelligence. Major directions in the area include opin-ion and sentiment analysis [14] and review summarization [6, 1, 10, 11]. Pang and Lee reviewed the major directions and techniques for opinion and sentiment analysis [14]. Hu and Liu proposed to mine product features users discuss in reviews and organize reviews by features [6]. Archak et al. further analyzed the implicit score for each product fea-ture, and the effect in revenue of a product [1]. Kim and Zhai studied the problem of generating comparative sum-maries by optimizing the selection of sentences from Pros and Cons in the review set [10]. Li et al. integrated lin-guistic rules and statistical methods for review mining and summarization [11]. None of these work explicitly modeled the structural information of product entities in their min-ing frameworks. Want et al. recently studied the problem of learning aspect preferences from product reviews with a latent regression model [20]. They assumed an overall rat-ing is available for each product. Due to the task specific settings, such methods in product review analysis are gener-ally not applicable to analyzing product search logs. On the other hand, although we are primarily focused on analyzing product search logs, our proposed model is general and can be easily adapted to analyzing product review data.
The essential information in a product search log can be represented as a table with three columns:
Formally, we denote a query by q , a product entity by e , and a clicking record as r  X  { 0 , 1 } ( X  r  X  for relevance) with r = 1 indicating  X  X licked X  and r = 0,  X  X kipped X . As an example, consider a log entry with query q as  X  X mall light laptop X , product entity e as  X  X ell xps 13 X  and r = 1. This entry records that  X  X ell fps 13 X  was clicked by a user who issued the query  X  X mall light laptop X . A product search log also contains other useful information such as time, IP address from which a query has come, etc. However, in this paper, we have not explored such information even though the proposed model can be extended in a straightforward way to incorporate such extra information to support more sophisticated analysis.

Our basic idea for using a probabilistic model to mine such data is to model such a three column table with a probabilistic generative model p ( q,e,r ) which models the probability that we will see a triplet ( q,e,r ) in the search log. This joint probability can be factored as follows:
Let L = { ( q i ,e i ,r i ) } be a product search log, where i = 1 ,...,N , and N is the total number of records in the search log. We can then estimate the generative model by maxi-mizing the likelihood of the observed prodcut log. Let  X  be all our parameters. Formally, this is to solve the following optimization problem:
With such a basic generative model, we obtain the follow-ing maximum likelihood estimates (we only show the case of r = 1, which is generally more useful and interesting than the case of r = 0): p ( q = q i | e = e i ,r = 1) =
These basic probabilities can already be useful:
However, such basic models cannot reveal a detailed un-derstanding of product features. For example, we cannot know what features of a product are favored by users when a user liked a product. To systematically analyze and mine the product search log to obtain such a more detailed level of understanding, we propose to further refine the key compo-nent model p ( q | e,r = 1) with a more detailed probabilistic mixture model. Since we will be only considering the case of r = 1, i.e., the clicked entities, we will drop r = 1 in the condition part of the model. That is, our task is to refine p ( q | e ) which should be interpreted as the probability that we will see q as a query when entity e is clicked on.
In the proposed mixture model, each entity would be rep-resented by a set of feature-value pairs .That is, we will not treat a product entity as a black box, but rather decompose it into a detailed representation consisting all the feature value specifications (e.g., price=$100, screen size = 14 X , etc, for a laptop). We will also decompose our query representa-tion into a sequence of words in order to enrich the data for parameter estimation and to obtain detailed understanding of user tasks and preferences. Using such a detailed repre-sentation, we can model the generation of q given e as fol-lows: An associated query to the entity would be assumed to be generated by sampling each word from the mixture model in two steps. In the first, we would select an attribute value based on an attribute specification selection model, p ( s | e ) which tells us how interesting a particular attribute speci-fication s is to the user. In the second, we would generate a word w according to an attribute value language model p ( w | s,e ) conditioned on the selected attribute specification s .

We study the model estimation methods by fitting it to the product search log. We then show how the model can be applied to perform various mining task. Below we first present the proposed probabilistic mixture model.
Formally, we are given a set of entities E . Each entity e in E is described by a list of specifications (specs) S e where each specification (spec) s = ( a s ,v s ) is an attribute-value pair represented by its attribute name a s and its corre-sponding value v s , and S is the set of all possible attribute-value pairs. For example, a laptop entity  X  X sus zenbook X  can be described by a set of attribute value pairs such as { [ a 1 = X  X rand X , v 1 = X  X sus X  X , [ a 2 = X  X creen X , v 2 =13 X  X , [ a v = X $800 X  X , ... } . Our goal is to refine the query-generation model of p ( q | e ) with decomposed representation of an en-tity e with attribute values. To develop such a model in a principled way, we need to better understand the process of query formulation of a user. Imagine a user likes an en-tity e , and we would examine the question how such a user would have formulated a query (in order to retrieve entity e ). Intuitively, the user would have to specify two compo-nents in the query: 1) the entity type (e.g.,  X  X aptop X ), and 2) preferences on attribute values for the target entity (e.g.,  X  X mall X ,  X  X heap X ). We can thus assume our query has two parts correspondingly, i.e., q = ( q t ,q p ), where q t is a term denoting the desired entity type and q p is a keyword query expressing preferences on attribute values. A user X  X  choice of q t is logically independent of the preferences q p . Thus we have p ( q | e ) = p ( q t ,q p | e ) = p ( q t | e ) p ( q now is to model separately how a user expresses the desired category of entity and how a user expresses preferences on attribute values.

While in general, the selection of entity category may also be uncertain, in virtually all real applications of product search, the categories of all the products in a database are usually known. Indeed, a user is often asked to select a cate-gory of products in addition to entering preference keywords. That is, p ( q t | e ) is no longer uncertain in most applications and we have p ( q t = c | e ) = 1 if c is the category of e , and p ( q t = c | e ) = 0 for all other categories. In terms of model estimation, we can slice the query log according to the cat-egories and estimate for each category separately. In the following, we therefore only focus on discussing how we fur-ther decompose p ( q p | e ) and estimate the model. We want to stress, though, our proposed model can easily accommodate alternative ways of refining p ( q t | e ) (e.g., to accommodate inexact category matching based on ontology), which would be an interesting future work.

How to refine p ( q p | e ) has to do with the question how a user expresses preferences if the user likes entity e . Intu-itively, if a user likes entity e , the user must have liked some of the attribute values of entity e . Thus, it is reasonabe to assume that the user would formulate a preference query by first selecting an interesting attribute of e and then choos-ing appropriate words to describe his/her preference on the value of the chosen attribute. That is, the probability that a user, who likes entity e , would use word w in the query is given by where s denotes a specification ( abbv. spec). Each spec s consists of an attribute a s and a corresponding value v Different specs may have the same attribute but different value, e.g.  X  X ize=small X  and  X  X ize=large X . p ( w | s ) is the uni-gram language model probability that a user would use word w in the query if the user likes specification s , satisfying the constraint P w  X  V p ( w | s ) = 1. Naturally, p ( s | e ) captures the probability that the user cares about attribute a s spec-ified in s (as opposed to another attribute), and satisfies P s  X  S p ( s | e ) = 1. For example, if e is a cheap small laptop, then we could assume that both p ( X  size  X  | e ) and p ( X  price  X  | e ) are reasonably high, likely higher than other attributes such as  X  X am size X . Also, we would expect the language model for the specification  X  X ize=small X  would give higher proba-bilities to words such as  X  X mall X ,  X  X ortable X , or  X  X ight X  than other words such as  X  X ast X  or  X  X owerful X .

Thus the probability of generating a multiword preference query q p based on entity e would be where c ( w,q ) is the count of word w in q .

Note that for convenience, here we have dropped the sub-script p in q p and simply use q to denote preference query q since there is no concern of ambiguity. In the rest of the discussion, we also use s to denote a spec and the language model for the spec interchangeably.

It is now clear that in order to fit such a model to our search log data, we essentially need to estimate the following two component models: 1. attribute selection model ( p ( s | e ) ) : this is the prob-2. specification preference language model ( p ( w | s ) ) :
We now discuss how we fit the model with the search log data and estimate these parameters.
To analyze and mine product search log, we need to fit the proposed probabilistic model with the search log data. Let Q = { q 1 ,...,q N } be the set of all the queries in the search log L . Each query q in Q is associated with a set of entities E which are the clicked entities of q . That is, E q = { e A thresholding may be applied to E q to restrict the set to only the entities that have been clicked on multiple times for query q .

We now discuss how we can estimate the defined mixture generative model based on the Maximum Likelihood estima-tor.
Equation 7 gives the conditional probability of query q given an entity e . Consider the following conditional log-likelihood log p ( q | e ):
We can thus use the Maximum Likelihood estimator to estimate both the attribute selection model p ( s | e ) and the specification preference language model p ( w | s ) by maximiz-ing the following log-likelihood function defined on the entire search log:
In order to ensure the learned language model p ( w | s ) to be discriminative, we introduce a background language model p ( w |  X  B ) to account for the generation of common words in the whole search log. The background model can be esti-mated based on relative frequency counts in the whole search log, i.e., Thus the generation of a query word could be from the back-ground model p ( w |  X  B ) or from the specification language model p ( w | s ), and the choice is controlled by a parameter  X  that indicates the likelihood of choosing the background model to generate a query word. The effect of  X  is to con-trol the influence of the background model on accounting for common words in the query. The larger  X  is, the more com-mon words would be explained by the background, thus the learned p ( w | s ) would be more discriminative. We heuristi-cally set  X  to 0.9 in our experiments.

With this extension, our log-likelihood on the whole search log becomes: F = X
It is easy to notice that we are essentially dealing with a finite mixture model involving multinomial word distribu-tions. Indeed, the model is quite similar to the Probabilistic Latent Semantic Analysis (PLSA) model proposed for topic modeling [5], though with two differences. One is the use of a background model, but the other more important dif-ference is that the choice of  X  X opics X  available is restricted to those corresponding to the actual features that a product is associated with. To understand the proposed model from the perspective of PLSA, we can view each specification as a  X  X opic X  and take the queries as a sample of words drawn from a mixture topic model. The model parameters are pre-cisely the two component models that we are interested in mining: p ( s | e ) and p ( w | s ), and we can use the Expectation-Maximization (EM) algorithm to compute an ML estimate of them by iteratively executing the E-step and M-step to improve a set of randomly initialized parameter values just as it works for PLSA.

Specifically, in the E-step, we compute the contribution of each specification for each word in a query.
In the M-step, we re-estimate the model parameters: p ( s | e ) = p ( w | s ) = where V is the vocabulary set.

It is important to note that p ( s | e ) is non-zero only when s  X  S e . That is, when selecting attribute specifications to generate words, we can only select from those valid speci-fications for the particular entity e , and for different enti-ties, this  X  X easible X  set of attribute values would generally be different (since different products differ in their specifica-tions). Such a constraint can be theoretically modeled and explained by imposing an infinitely strong prior on p ( s | e ) to force non-applicable attribute values to have a zero proba-bility of selection. In the algorithm, this can be achieved by initializing p ( s | w,e ) as:
In this section, we discuss how we may use the proposed model to mine a product search log in many different ways to discover useful knowledge about user preferences and their associations with product attribute values.

First, the estimated model parameters are directly useful to reveal useful knowledge. For example, p ( w | s ) can pro-vide a word distribution characterizing what kind of words users typically use if they like attribute specification s ; by looking at the high probability words, we can obtain insights about the potential market of the particular product feature specified by s . Also, p ( s | e ) can immediately be useful for understanding what attribute specifications (i.e., what fea-tures) of a product are most attractive to consumers. The hidden variable distribution computed in the middle of the EM algorithm can also be very useful: p ( s | w,e ) can be in-terpreted as the inferred intent behind a user query word w since this probability tells us which feature of product e has  X  X riggered X  the use of query word w in the query.

Second, these parameters can be further post-processed in many interesting ways to support further mining and anal-ysis, including, e.g., comparative analysis of specifications, product feature ranking, and product annotation. Below, we first briefly describe the search log data set that we ex-perimented with, and then present a number of applications of the model for mining the search log.
We focus on three major categories of products for testing our mining algorithm, i.e. electronics, furniture and outdoor sports. The electronics dataset consists of subcategories of laptops , cameras , camcorders , TVs and ebook readers . There are in total 1066 entities in the electronics category. The furniture dataset consists of subcategories of cribs , dressers , changing tables , storage organizers , etc. There are in total 1503 entities in the furniture category. The outdoor sports dataset consists of subcategories of adult bikes , kids bikes , , storage organizers . There are in total 2406 entities in the outdoor sports category.

To study the mining of search log, we collect a month X  X  search log from the search engine of Walmart.com 1 .
One very interesting family of mining questions that can be answered by using our model are about relative com-parisons of product specifications. For example, comparing different brands on the same category of products is particu-larly interesting for business intelligence applications. Com-parison of the various features of the same product in terms of their importance to various consumers provides useful in-sights for market research. All such comparisons can be easily done with the native use of the model parameters p ( w | s ).

For example, we can compare the top words (with highest probabilities) in the specification language models p ( w | s ) to analyze the similarity/difference between values on the same attribute. We show some sample results from such a comparative analysis in Table 2, where we show the compar-ison between different brands in several categories. In the camcorders category, we compare two brands: Midland and Samsung . We can see that Midland is focused on wearable devices and outdoor use, while Samsung products have an emphasis on night conditions. For camera category, the top words of Vistaquest shows its speciality is waterproof cam-eras; Kodak , on the other hand, is well known for its sharing feature. In the storage organizer category, the brand Disney is focused on toy organizers while Munchkin is for baby prod-ucts like diapers and towels. In adult bikes , we can see the brand Workman specializing in tricycle and folding bicycles, while Mongoose specializes in mountain bikes and perhaps has good suspension system, as evidenced by the popular keywords. Such comparative analysis can be very useful for business intelligence. Note that although we did not explore in this work, it is straightforward to apply our model to gen-erate such comparisons over different time periods to reveal interesting trends. Recall that our model provides probabil-ities for all these words, so even subtle changes of relative ranking positions of these words over time across different brands or product makers can be revealed in a visible way. It is worth noting that these results are not only interest-ing, but also revealing the good knowledge as we can most likely find evidences to back them up by surfing the Web. For example, we could find from online reviews for  X  X on-goose bikes X  such as  X  I think my next bike will be a nice All Mountain ride  X  and  X  The suspension is preload adjustable and hence extremely effortless to set-up  X  2 .

As another example, in Table 3, we show the comparison between different price ranges for TVs and adult bikes . We can see that for low end TVs ($150-$200), the emphasis of sales is small size TVs with combo dvd players; for midrange TVs, the focus is the hd streaming capability; for high end TVs, the focus is large size and 3d capability. For adult bikes, low end bikes emphasize on the basic needs for bikes including the position, the comfortness and the turnings. For midrange bikes the emphasis is on the more special needs like body material and weight. High end bikes focus on even special needs like battery and folding. These results are intuitively quite meaningful. It is worth noting that although we can simply pull together the queries relevant to a specification to form a word distribution, such distribution http://www.walmart.com http://reviews.mtbr.com/bike-review-mongoose-xr200 is usually noisy and unreliable because it cannot distinguish which specification each query is targeting. In contrast, our model solves the problem by inferring the latent connection between query terms and product specifications.

Such knowledge is very useful for market research as well business intelligence since it is also possible to further de-compose the comparison by conditioning on a specific brand. Once again, time information can be easily leveraged to plot trends.

These example comparisons demonstrate clearly that we can immediately obtain useful knowledge by fitting our model to the product search log and then simply pulling out the rel-evant conditional probabilities for a comparison. It is also obvious that one can easily imagine many possibilities of such comparisons. Indeed, it is straightforward to develop a system to help an analyst make such comparisons in a flex-ible way by specifying candidate specifications in a flexible way with an  X  X nalysis query X , and such a system can effec-tively serve as a general tool for business intelligence and market research since it would enable an analyst to analyze the data flexibly from many different perspectives as driven by a specific application need.
Next, we present another type of application where the goal is to engage users and help users clarify their informa-tion need in a product search engine. Product search engines usually provide a list of facets, i.e. values of particular at-tributes of products, on a sidebar beside the search results to help users refine the search results. For instance, a list of brands are showed on the top of the facet bar when we issue the query to Walmart.com . When a brand is selected by the user, the search engine will filter the results based on the selected brand. Traditionally, the facet list is achieved by hiring human experts to manually select and order a sub-set of attributes for each category of products. The task is very laborious and the manually generated facets are not necessarily in accordance with the users X  preferences.
In this section, we show that our proposed model can be easily used to perform automatic facet selection and order-ing. The method is data driven; the facets generated using our model can therefore reflect the preferences of real users. We further show that in addition to generating facets in a static manner (i.e. independent of queries), we can also adapt our model to perform query specific facet generation where the selection and ordering of facets are dynamically determined based on the query. The facets generated in this way are usually closer to the user X  X  information need and therefore more effective in refining search results.
We first study how to use our model to generate static (i.e. query independent) facets. Let us use p ( a ) to denote the probability that a user will be interested in attribute a when searching for entities in the relevant category. Clearly, p ( a ) is a reflection of the general preference of all users. With this probability, we can achieve a meaningful ordering of attributes. Using our model, p ( a ) can be computed by summing over the probabilities p ( s ) of all the specifications on attribute a :
With the assumption of uniform p ( e ), we can easily com-pute p ( a ) using the model parameters we estimated from product search log. In Table 4 we show the top facets gen-erated in this way. The facets are ranked in descending order of probabilities p ( a ). We can see that for almost all categories (except Skateboards),  X  X rand X  is the most con-cerned facet. This result suggests that for most categories of products (e.g., cameras, laptops), users might have al-ready had a preference of brand before they type in a query to search, whereas when choosing Skateboards, people tend to be more open for brands.  X  X rice X  is the second most concerned attribute in the categories of Cameras and Adult Bikes. But for Laptops, users tend to be more concerned with the  X  X ype X , the  X  X rocessor X  and  X  X creen size X  than the  X  X olor X ,  X  X rice X  and  X  X ard drive size X . For TVs, the second most important facet is  X  X creen size X  above all others, which is a surprising but reasonable discovery. When users shop for Kids Bikes, an important consideration is whether the bike will be ridable by the kids. Our discovery is consistent with this consideration as the  X  X heel size X  is ranked second in the facet list of the category. The Skateboards category is very interesting as users are less concerned about the  X  X rand X , but more interested in the  X  X ype X  and  X  X ge X  attributes.
Such knowledge discovered in facet ranking are not only useful for refining search results, but also important to un-derstanding users X  needs in marketing analysis. By under-standing what features are most important to users, manu-facturers can make more effective business decisions.
The static facets are useful for helping users refine their in-formation need, understanding general user preferences and supporting business decisions. But the fact that it remains static for all queries makes it less effective in engaging user interactions, especially in a search engine scenario where the query has indicated specific search intents. To improve the facet generation, we further study query specific facet gen-eration by adapting the parameters learned in the proposed product search log mining model.

We consider the posterior probability of preferring an at-tribute given a query. Formally, let p ( a | q ) be the probability that users are interested in attribute a when issuing query q . p ( a | q ) can be computed as: p ( a | q ) = X
Using p ( a | q ) as a scoring function, we can dynamically generate the facet list for each query. Table 5 shows sample results of query specific facets for four different categories. For query touch screen camera , the attribute  X  X pecial fea-ture X  is ranked top because  X  X ouch screen X  is a special feature for cameras. The attributes  X  X rice range X  and  X  X rand X  are ranked next because various manufacturers make cameras with the feature and those cameras fall into different price ranges. In comparison, for the query point shoot camera , users are mostly interested in the  X  X egapixels X  and  X  X pti-cal zoom X  features. For Laptops category, the two queries mini laptop and white laptop have very different emphasis in preference. The proposed query specific facet generation method captures these emphases successfully as  X  X creen size X  is ranked top for mini laptop and  X  X olor X  is for white laptop . Similarly, in TVs category, the method successfully captures the focuses on  X  X echnology X  and  X  X efresh rate X  for the query led tv and 120 hz tv , respectively; in Kids Bikes we discovered the facets of  X  X rand X  and  X  X haracter X  are important for the query disney bike and  X  X ender X  is the most relevant attribute for boy bike . For all these queries, the newly generated facet lists are different from the lists generated in the query in-dependent manner. Compared with the static facets, it is clear that the query specific facets are more clarifying for the information need.
Another very important application in mining product search log is automatic tagging of product entities. As we discussed earlier, we can compute a query set Q e that are highly associated with entity e by thresholding the count of clicks in the search log. This query set can naturally serve as an extended profile of the entity and we can use them to improve search quality. It can also be used for browsing or information visualization. We refer to this extended pro-file as the result of tagging product entities. However, this Figure 2: Evaluation of tagging product entities in retrieval simple tagging method depends heavily on click-throughs. If an entity is never clicked (and indeed the distribution of clicks are highly skewed), it will not be tagged by any query word. This will especially affect the product entities that are newly put online, suffering from a problem commonly known as the  X  X old start X .

The product search log mining model we proposed in this paper provides a good solution to this problem. Since the model computes specification level language model, we can derive the language model for an entity by  X  X ssembling X  the language models from its specifications. Specifically, we can compute the word distribution for each entity using the at-tribute selection model and the specification preference lan-guage model with Equation 6. However, the ML estimation may not be directly usable as it cannot estimate the at-tribute selection probabilities for entities that have never been clicked. Therefore, a back-off model for these entities is necessary.

To obtain the back-off model attribute selection model, we compute the marginal distribution p ( s ):
For entities that do not have click information, i.e. where p ( s | e ) has not been estimated, we back off to p ( s ) and use Equation 6 to compute p ( w | e ).

We then filter the word list by thresholding p ( w | e ) with a parameter  X  and obtain an extended set of query terms as the result of tagging product entities.

To evaluate the proposed tagging method, we use the tagged entity profiles to improve the performance of re-trieval. We created a test set with queries for all categories in Electronics. Annotation of the search results of these queries is conducted by a group of human experts. For each query, the retrieved product entities will be labeled with a numeric relevance rating, with values ranging from 1 to 5. We use language model as the retrieval model for incorporat-ing the tags of product entities. The baseline method uses only the tags generated by the click-based tagging method. Our method combines the tag sets generated by click-based method and the proposed method.

In Figure 2, we show the performance of our method com-pared to the baseline method at different level of thresh-olds  X  . We use Normalized Discounted Cumulative Gain (NDCG) as the measurement for retrieval performance [8]. NDCG is a widely adopted performance metric for search engine systems using multi-level relevance annotation. Two metrics, i.e. NDCG@3 and NDCG@10 are visualized in the figure. The performance of our method is shown by the solid lines and the performance of the baseline method is shown by the dashed lines. At  X  lg(  X  ) = 0 we have  X  = 1, and our method is the same as the baseline method. By relaxing  X  we see the performance of our method is consistently better than the baseline method. After relaxing  X  to  X  lg (  X  ) &gt; 4, i.e.  X  &lt; 1 e  X  4 we can see our method is stable on both metrics. This quantitive evaluation of retrieval performance based on product tagging verifies the effectiveness of the the probabilistic mixture model in discovering and representing the attribute level knowledge from product search logs.
In this paper we study the novel problem of mining and analyzing product search log. Our contributions are as fol-lows:
Our model is primarily proposed for mining from the click information in search log. One interesting direction for fu-ture work would be to explore whether we can also make use of the skiped entities in search log to enhance our model and to mine additional knowledge for business intelligence.
As an emerging topic, product search log mining is a very promising subject of study which can have immediate im-pact on a large spectrum of applications and analysis. Our model provides a very effective tool to analyze the product search log on the product attribute level. In the future we plan to continue the exploration of product search log with the use of the proposed model. [1] N. Archak, A. Ghose, and P. G. Ipeirotis. Show me [2] J. Han and Y. Fu. Discovery of multiple-level [3] J. Han, J. Pei, B. Mortazavi-Asl, Q. Chen, U. Dayal, [4] J. Han, J. Pei, and Y. Yin. Mining frequent patterns [5] T. Hofmann. Probabilistic latent semantic indexing. In [6] M. Hu and B. Liu. Mining and summarizing customer [7] Y. Hu, Y. Qian, H. Li, D. Jiang, J. Pei, and Q. Zheng. [8] K. J  X  arvelin and J. Kek  X  al  X  ainen. Cumulated gain-based [9] D. Kang, D. Jiang, J. Pei, Z. Liao, X. Sun, and H.-J. [10] H. D. Kim and C. Zhai. Generating comparative [11] F. Li, C. Han, M. Huang, X. Zhu, Y.-J. Xia, S. Zhang, [12] X. Li, Y.-Y. Wang, and A. Acero. Extracting [13] Q. Mei and K. Church. Entropy of search logs: how [14] B. Pang and L. Lee. Opinion mining and sentiment [15] J. Pound, S. Paparizos, and P. Tsaparas. Facet [16] N. Sarkas, S. Paparizos, and P. Tsaparas. Structured [17] C. Silverstein, H. Marais, M. Henzinger, and [18] F. Silvestri. Mining query logs: Turning search usage [19] B. Tan, X. Shen, and C. Zhai. Mining long-term search [20] H. Wang, Y. Lu, and C. Zhai. Latent aspect rating [21] X. Wang and C. Zhai. Mining term association [22] G.-R. Xue, H.-J. Zeng, Z. Chen, Y. Yu, W.-Y. Ma, [23] M. J. Zaki and C.-J. Hsiao. Charm: An efficient [24] Z. Zhang and O. Nasraoui. Mining search engine
