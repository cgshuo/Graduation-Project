 In this paper, we introduce a trial-and-error model to study information diffusion in a social network. Specifically, in every discrete period, all individuals in the network concur-rently try a new technology or product with certain respec-tive probabilities. If it turns out that an individual observes a better utility, he will then adopt the trial; otherwise, the individual continues to choose his prior selection.
We first demonstrate that the trial and error behavior of individuals characterizes certain global community struc-tures of a social network, from which we are able to de-tect macro-communities through the observation of micro-behavior of individuals. We run simulations on classic bench-mark testing graphs, and quite surprisingly, the results show that the trial and error dynamics even outperforms the Lou-vain method (a popular modularity maximization approach) if individuals have dense connections within communities. This gives a solid justification of the model.

We then study the influence maximization problem in the trial-and-error dynamics. We give a heuristic algorithm based on community detection and provide experiments on both testing and large scale collaboration networks. Simu-lation results show that our algorithm significantly outper-forms several well-studied heuristics including degree cen-trality and distance centrality in almost all of the scenar-ios. Our results reveal the relation between the budget that an advertiser invests and marketing strategies, and indicate that the mixing parameter, a benchmark evaluating network community structures, plays a critical role for information diffusion.
 F.m [ Theory of Computation ]: Miscellaneous Economics Trial and error, social networks
It is well-documented that information spreads via indi-viduals X  interactions in social networks. The dynamic pro-cesses governing the diffusion of information and  X  X ord-of-mouth X  X ffects have been studied extensively in various disci-plines, e.g., Epidemiology, Sociology, Economics, and Com-puter Science. A central question studied in all of these dis-ciplines is that how the dynamics of information diffusion unfolds within a social network.

Motivated from the fact that individuals in a social net-work are self-interested entities, applying game theoretical analysis to study the diffusion of information has received considerable attention in recent years [17, 10, 28, 29, 31, 22]. A common assumption in all of these game theoretical mod-els is that an individual makes a rational choice to adopt a new strategy (e.g., a product) if it increases his payoff, which takes place when enough of his neighbors have adopted it. In other words, the spread of information is driven by strategic incentives.

While game theoretical analysis captures individuals X  self-motivated behavior, in many real social networks, people may have little knowledge about the structure of the un-derlying network, either globally or locally. Therefore, the interactions between individuals and adoptions of new prod-ucts are rather blinded. Another important aspect ignored by the aforementioned models is that some individuals, en-dowed by their own personal characteristics, may have ad-ventures to try new products. For instance, an iPhone user may try for curiosity a Samsung X  X  product and even adopt it if obtaining better experience. How does information diffuse in a social network given such (to some extent) bounded ra-tional behavior of individuals? In this paper we will address this question by proposing a trial and error model to study the diffusion of information.

Trial and error is a heuristic method of problem solving and knowledge acquisition. It is often employed in incom-plete information settings where limited guidance could be drawn from theory. In a trial and error process, people learn from both their successes and failures of occasional trials of new strategies and adapt their future decisions according to accumulated knowledge from experience. A large vol-ume of literature has been accumulated on trial and error, spanning across different disciplines from various aspects, including, e.g., evolution of cognition [1], product develop-ment [4], business innovation [26], game theory [30], and computational complexity [2], to name a few.

In the trial and error model introduced in the present pa-per, for every discrete period, individuals in a social network concurrently try a new product with certain respective prob-abilities. If an individual observes a better outcome, he will then adopt the trial; otherwise (i.e., upon an error), the in-dividual continues to use his prior selection. The trial and error process is nondeterministic and concurrent, and cre-ates a cascade of adaptive adoptions in a social network. Our model still assumes that individuals behave rationally, and beyond that, characterizes the aforementioned user be-havior in a social network with incomplete information.
In a real social network, people in the same community tend to adopt the same product. We first demonstrate that the trial and error dynamics exhibits the same phenomenon, that is, we are able to detect macro-communities through the observation of micro-behavior of individuals. Detect-ing communities is of great importance in disciplines where interactions are represented as graphs and has a variety of algorithmic challenges (see a survey by Fortunato [11]). Our results show that the natural trial and error behavior of indi-viduals characterizes certain global community structures of a social network; this gives a solid justification of the model.
Specifically, we simulate the trial and error dynamics on the community detection testing graphs of Lancichinetti et al. [20], who described a procedure that generates random graphs with power law distributions on the degree of a node and the size of a community. The graphs generated by [20] are a refinement of the classic Girvan and Newman X  X  testing graphs [12] and has been taken as benchmarks for commu-nity detection algorithms. We compare the trial and er-ror dynamics with the Louvain method [3], one of the most widely used modularity maximization approaches for com-munity detection. Our simulation results show that the trial and error dynamics detects communities with high preci-sion and even outperforms the Louvain method if individuals have dense connections within communities.
 We next study the influence maximization problem [18]: Suppose that a new product is entering a market, which was dominated by another product. A critical question is how to spend the limited budget on initially seeding a few individuals (e.g., giving free samples of the product) in order to trigger a cascade of influence by which a large fraction of individuals eventually adopt the new product.

We consider the influence maximization problem in the trial and error model; here the problem becomes much more complicated due to the nondeterministic and concurrent dy-namics of the trial and error process. We give a heuristic algorithm based on community detection and provide ex-periments on both testing and large scale collaboration net-works. Simulation results show that our algorithm signifi-cantly outperforms several well-studied heuristics including degree centrality and distance centrality in almost all of the scenarios. Our results imply that given the limited budget, seeding a large number of low-influence vertices is indeed better than seeding a small number of high-influence ver-tices. Our findings echo some real life advertising strategies in terms of the amount of advertising investments, and in-dicate that the mixing parameter, a benchmark evaluating network community structures, plays a critical role for in-formation diffusion.
The dynamics of information diffusion has been studied extensively in different disciplines with different focuses. It is referred to [16, 9] for a comprehensive introduction of a number of classic models analyzing the spread of information and related issues.

Influence maximization was first proposed by Domingos and Richardson [8, 25] as an algorithmic problem. Later on, Kempe, Kleinberg, and Tardos [18] formulated the problem as a discrete optimization problem described above. They considered two natural diffusion models, linear threshold and independent cascade, and showed that the simple high-degree greedy algorithm gives a constant approximation to the optimal. Since the seminal work of [18], the influence maximization problem has received numerous attention for different influence processes, see, e.g., [21, 5, 7, 6, 19] and the references within.

As discussed earlier, game theoretical analysis has been applied to model the process of information diffusion. One of the most natural individual behaviors is that of the best response dynamics, which has been studied extensively for the emergence of technologies [29] and is similar but signifi-cantly different from our trial and error dynamics; we give a comprehensive comparison of the two models in the subse-quent section. For the best response dynamics, Kandori et al. [17] showed that with a small noise it always converges to a monopoly state in which all individuals choose the same product. Ellison [10] and Montanari and Saberi [22] then studied the speed of convergence to such a dominant equi-librium.
In a social network G =( V,E ), V is the set of vertices (i.e., individuals) and E is the set of undirected edges that represent relations between individuals in the network. We assume that the network is connected. There is a weight function w : E  X  R + associated with each pair. That is, for any ( i, j )  X  E , w ( i, j ) gives the tie strength between j . In the present paper, we define which is the number of common friends of i and j plus one.
Assume that there is a set of products A ,andeachvertex can choose one of the products. For each i  X  V ,let f i  X  A denote the product that i chooses; then ( f i ) i  X  V defines a configuration of the network. For any given configuration,
The concept of tie strength was first introduced by Gra-novetter in his landmark paper [13]; a basic hypothesis in [13] is that the stronger the tie between two individuals, the larger the proportion of individuals in the rest to whom they both are tied. In other words, there is a monotonically increasing relationship between weight and the number of common friends. Our definition of weights is one of the sim-plest functions that satisfy this hypothesis (note that the addition of one is to count the direct relationship between individuals). In fact, our weight function is characterized by the matrix A 2 + A ,where A is the adjacency matrix of the (unweighted) social network. the normalized utility of agent i is defined as follows: The numerator in the above formula is the total weight of the neighbors of i that choose the same product as him, and the denominator is the total weight of all edges incident to i , which is a fixed number. The utility of an individual thus completely depends on his and his friends X  selections. In the present paper, we will consider a simple setting with only two products, i.e., A = { a, b } .
We will consider a trial and error model to study the dy-namics of product adoption caused by self-interested behav-ior of individuals. Initially, every vertex is associated with a product. In each of the following rounds, all vertices will try another product concurrently according to the following probability function: 2 That is, assume that a vertex i chooses product a with utility u at the beginning of the round; then with probably p ( u i the vertex will try another product b , and with probability 1  X  p ( u i ) he will continue to use a . If the vertex finds an improved utility at the trial b (with respect to the trials of all of his neighbors), then he will adopt the new product b at the end of the round. Otherwise (which corresponds to an  X  X rror X ), he will continue to use the prior choice a The following figure shows the process of trial and error of a vertex within one round.
We say a configuration is a zero configuration if all vertices have utility 0; otherwise we call it a nonzero configuration . It can be seen that zero configurations only occur in bipar-tite graphs where the two sides adopt different products. If the trial and error dynamics starts from a zero configura-tion, then at every round all vertices try another product with probability 1 and realize that it does not give a better utility (with respect to the trails of other vertices). Thus, all vertices will continue to choose their prior selections, i.e., the zero configuration will stay forever. We first establish
The intuition behind the probability function is that a ver-tex is more likely to try a new product if his current utility is small. In particular, if u i = 1 (i.e., all neighbors of the same product as him), then p = 0, which means that the vertex has no incentive to try a new product. If u i =0, then p = 1, which means that the vertex is surely to try a new product. the following characterization, which essentially eliminates zero configurations in the trial and error dynamics.
Lemma 2.1. A nonzero configuration will never move to a zero configuration in the trial and error dynamics.
In the context of game theory, our model can be consid-ered as a game played on an underlying graph G =( V,E ), where each pair of vertices i and j with ( i, j )  X  E plays a co-ordination game. A profile (in our language, a configuration) is called a (pure) Nash equilibrium if no individual can im-prove his utility by unilaterally adopting another product. That is, from individuals X  strategic point of view, the dy-namics of adoptions reaches a stable state. It is well-known that coordination games with players in an underlying graph are a potential game. Thus, a pure Nash equilibrium always exists, and can be achieved by the best response dynam-ics [24], i.e., individuals sequentially adopt products that yield the highest utilities.

The trial and error dynamics by its nature is quite simi-lar to the best response dynamics. However, the trial and error dynamics allows concurrent moves for all individu-als, whereas the best response dynamics considers sequential moves. If concurrent moves are allowed, the best response dynamics may not converge any more for many networks. For instance, for the complete graph with n vertices, ini-tially, n/ 2 vertices choose product a and n/ 2verticeschoose product b ; then at every round all vertices change to adopt another product and the dynamics never converges.
The best response dynamics identifies the set of Nash equi-libria as the set of stable configurations. But are all of these configurations really  X  X table X  in a social network? Consider the example in Figure 1 in which there are a small clique G 1 with m vertices and a big clique G 2 with n vertices, and each vertex in G 1 connect to a vertex in G 2 . Consider the special case when m = 2, i.e., G 1 contains only two vertices i and j , and the configuration where i and j use product a while all vertices in G 2 use product b .Itiseasytoverify that it is a Nash equilibrium, but such a Nash equilibrium rarely happens in a social network: the utility of both i j is 0 . 5, and they are able to improve their utility to 1 if both adopting product b . In other words, the small commu-nity can be easily influenced by the large community even if their connections are sparse.
In this subsection, we will consider whether and when the trial and error dynamics stabilizes, and if yes, it stabilizes to which configuration. First, it is natural to see that a configuration that is not a Nash equilibrium should not be considered as stable: In such a configuration there always exists a vertex whose utility is less than 0 . 5 and can be better if adopting the other product.

Second, not all Nash equilibria should be considered as stable. In the example of Figure 1, when the clique G 1 both of them will try and then adopt product b .Thatis, the Nash equilibrium configuration may jump to another configuration with a constant probability even in a single round; thus, the prob ability that such a configuration re-mains unchanged decreases exponentially as the dynamic process continues. However, if G 1 contains more vertices, then all vertices of G 1 have more utilities when adopting product a because of internal edges and their trial prob-ability becomes much smaller. Further, the only way to jump out of the Nash equilibrium configuration is to have at least half of the vertices of G 1 simultaneously try product b ; this happens, however, with an extremely small probabil-ity. That is, while eventually the trial and error dynamics will change to another configuration as the process contin-ues, this Nash equilibrium configuration will stay for a very long period.

Third, for some Nash equilibrium configuration, while there is a non-negligible probability to jump out, it is also very likely to return to the configuration. There are 2 small com-munities G 1 and G 2 which are connected by a vertex k (see Figure 2). The initial adoptions are labelled next to each vertex. It can be seen that both i and j will try the other product with a constant pr obability in eac h round, but due to the dominance of their neighbors in the community, they will continue to choose the prior selection (i.e., a and b spectively). Now let us consider the following dynamics: both i and k try product b (this happens with a constant probability), then i will continue to choose a but k will adopt b . That is, the configuration is changed to a new one where the only difference is on vertex k . For the new configura-tion, consider another dynamics: both j and k try product a (this happens again with a constant probability), then j will continue to choose b but k will adopt a .Thatis,the configuration is changed back to the original one. It can be seen that the swaps between the two configurations will continue forever.

In summary, in a social network some configurations may stay for a long period or occur frequently. In both cases the configurations to some extent slow down or even block the diffusion of information, and thus, the network has reached a rather stable state. Given this observation, we next define the notion of k -stable Nash equilibrium, a refinement of the definition of Nash equilibrium, to characterize a stable state of a trial and error dynamic process.

Definition 2.1. For any given number k , we say that a trial and error process reaches a k -stable state if a Nash equilibrium configuration appears more than 0 . 5  X  k times in k consecutive rounds. Such a Nash equilibrium is called a k -stable Nash equilibrium .

Note that the coefficient 0 . 5 in the definition can be re-placed by any constant. This parameter together with k characterize the extent of the stability of a Nash equilib-rium. For instance, if k = 1 then the definition degenerates to the normal Nash equilibrium; and if k =  X  then the only stable configurations are those that will stay forever (e.g., monopoly).

The theorem below shows that any trial and error process must reach a k -stable state for any finite k . However, differ-ent realizations of the process may reach different k -stable Nash equilibria. This is by the randomness of trial and er-ror, and also reflects the nature of dynamics of information diffusion.

Theorem 2.1. For any finite number k&gt; 0 ,thetrial and error dynamics starting from a nonzero configuration reaches a k -stable state with probability 1.

In the following sections, we simulate the trial and er-ror dynamics on various benchmark graphs and real social networks with vertex sizes ranging from 1000 to 25000. A general guidance for picking the best value of k is that it should give us the most reasonable stable state of an under-lying network. In all of our simulations, the trial and error process stabilizes to the first stable state within dozens of rounds, and then it stays at that configuration with very occasional local disturbances, for as long as 10 6 rounds. We will therefore use k =10 6 and consider the first k -stable state in all of our simulations. For convenience, in the rest of the paper, we will use stable state to denote a k -stable state.
In the above section, we argued that the trial and error dynamics can lead to a more stable Nash equilibrium. In this section, we will provide a further justification to the trial and error model. Specifically, in practice, people in the same community usually turn out to adopt the same product. Does the trial and error dynamics exhibit the same phenomenon?
To answer this question, we simulate the trial and error dynamics to detect communities of a social network. We run two types of experiments on the benchmark graphs of Lanci-chinetti et al. [20] with 1000 and 5000 vertices, respectively. Similar to the setup of [20], we choose parameters  X  =2and  X  =1,where  X  and  X  are the exponents of the power law distributions of the degree of a vertex and the size of a com-munity, respectively. We choose the average degree of all vertices to be 15 and 20 for the 1000-vertex and 5000-vertex graphs, respectively, and the maximum degree to be 100. Further, every graph has an associated mixing parameter  X  which denotes that each vertex shares a fraction of 1  X   X  of its edges with other vertices of its own community and a fraction of  X  with the rest vertices of the graph. The gener-ated graphs have well defined built-in community structures; more details of the benchmark graphs are referred to [20].
For every randomly generated graph, we run the following experiment: Initially every vertex chooses one of the prod-ucts a and b with equal probability; we then simulate the trial and error process from the initial state until it reaches a stable state. The simulation is repeated 100 times on the graph. For every pair of vertices ( i, j ) that are connected by an edge, we denote by p ( i, j ) the probability that i and up with using the same product among all 100 simulations.
From the derived data, it can be seen clearly that when the mixing parameter  X  =0 . 2, all pairs of vertices are di-vided into two groups: one with small probabilities (roughly between 0 . 3and0 . 7) and one with probability 1. When  X  =0 . 5, the communities become fuzzy and there is no clear separation on the probabilities (there are positive densities for all probabilities larger than 0 . 3).

We next describe our community detection algorithm by the trial and error dynamics.
 Algorithm 1 Community Detection by Trial and Error 1: Let V be the set of vertices of the graph and k =1. 2: Let threshold =0 . 95. 3: while V =  X  do 4: Pick i  X  V and let S k = { i } . 5: for j  X  V do 6: if p ( i, j ) &gt; threshold then 7: S k  X  S k  X  X  j } . 8: end if 9: end for 10: Let V = V \ V k and k = k +1. 11: end while 12: Return ( S 1 ,S 2 ,... ).

In the algorithm, we first set a threshold value (which is 0 . 95 in the description below), and cluster vertices in the same community if their probabilities are beyond the thresh-old value. 3 We compare the performance of our algorithm with the Louvain method [3], which is a popular modularity maxi-mization approach. Modularity maximization is one of the most widely used methods for community detection. The Louvain method iteratively optimizes local communities un-til global modularity can no longer be improved given per-turbations to the current community state. To compare the built-in community structures of the generated graphs with our trial and error algorithm and the Louvain method, we use the normalized mutual information, which is a measure of similarity of partitions from information theory. The fol-lowing figures show the comparison results (each point cor-responds to an average over 10 graph realizations).
Notice that our algorithm detects communities with high precision (even outperforms the Louvain method) when the mixing parameter is less than 0.4. When the community structures become fuzzy as the mixing parameter approaches 0.5, the performance of our algorithm gradually drops. Note that the runtime complexity of our algorithm is rather high, as the probability p ( i, j ) for every pair is computed in terms of 100 simulations. However, here we do not attempt to propose a new community detection algorithm. Instead, the simulations indicate that the trial and error dynamics
Different social networks may have different optimal threshold values depending on their structures. For instance, we also run our community detection algorithm on the Gir-van and Newman benchmark graph [12], and obtain similar simulation results when setting the threshold to be 0 . 99. exhibits certain community structures of a social network. This gives a solid justification to the trial and error model.
In this section, we study the word-of-mouth effect in our trial and error model: Given a social network G =( V,E ), initially all vertices use product a . A new product b now is about to enter the market. Given a sharp budget B on marketing,whichverticesshouldbeseededinordertocreate a large fraction of adoptions? For each node i  X  V ,let c ( i )= j :( i,j )  X  E w ( i, j ) be the cost to seed i using product b at the beginning 5 .Let f ( S ) denote the expected amount of adoptions if S is the set of seeded vertices. Then the influence maximization problem is to find a set S  X  V to maximize f ( S )giventhat i  X  S c ( i )  X  B .
Our algorithm, at a high-level viewpoint, divides the net-work into communities and then considers each community separately. While we can use the community detection al-gorithms described in the previous section, how should we deal with each community? To answer this question, let us
Note that the best response dynamics does not have such community detection property; for instance, for the com-plete graph discussed earlier with n/ 2 using product a and n/ 2 using product b , the best response dynamics does not even converge.
The cost to seed a vertex i here is defined as the total weight of all edges incident to i . This definition is motivated from the observation that large degree vertices usually slow down the diffusion process [22]. Thus, seeding these vertices needs a larger cost. first consider the special case where the underlying network is a complete graph; such a complete graph closely approx-imates the structure of a community. In a complete graph with n vertices, the weight of every edge is n  X  1 and thus c ( i )=( n  X  1) 2 for all vertex i .Sinceallverticeshavethe same cost and the same influence, the only (optimal) strat-egy is to seed B ( n  X  1) 2 vertices arbitrarily. Note that the only Nash equilibria in a complete graph are the two mo-nopolies where all vertices adopt the same product, either a or b . Thus, the expected number of adoptions is equal to n  X  dominate ( k, n ), where dominate ( k, n ) denotes the proba-bility that product b dominates the entire market if k vertices are initially seeded.

The value of dominate ( k,n ) can be approximately com-puted via a straightforward dynamic programming proce-dure: Define Pr [ i ][ t ] to be the probability that there are vertices using product b at the end of round t . Initially let Pr [ k ][0] = 1 and Pr [ k ][0] = 0 for all other k = k .Ingen-eral the value of Pr [ i ][ t ]foreach i can be computed precisely given Pr [0][ t  X  1] , Pr [1][ t  X  1] ,..., Pr [ n ][ t  X  cedure until we have Pr [0][ t ]+ Pr [ n ][ t ] &gt; 1  X  for some and small enough , i.e., all vertices adopt the same product. Then Pr [ n ][ t ] gives an approximation of dominate ( k,n Figure 4a shows the results for several values of k and n We can see clearly that the probability that product b dom-inates increases rapidly when the fraction of targeted seeds goes from 50% to 60%, and the probability grows to 1 when the fraction is around 65%. In other words, seeding 65% vertices is sufficient to influence the entire graph and extra investment is redundant.
Note that a real social network in general exhibits strong community structures and vertices in the same community tend to use the same product. Given the connection be-tween the trial and error dynamics and community structure established in the previous section, our community-based al-gorithm first partitions the network into disjoint communi-ties, and then picks several communities and seed certain amount of vertices from the picked communities. While a network may not have perfect community structures in the sense that vertices may not be linked in the same community and there may have crossing-community edges, we expect (and are supported by the simulation results) that our anal-ysis for complete graphs above gives close approximations to partitioned communities. A remaining question is which communities should be considered first in the algorithm.
Note that if we seed k vertices in a complete graph with in total n vertices, we spend k ( n  X  1) 2 amount of budget with an expected return of n  X  dominate ( k,n ); thus, the efficiency of the investment, i.e., the expected number of vertices adopt-ing product b per unit budget spent, is given by Therefore, in order to spend the budget efficiently, we should always first consider those communities with larger invest values. Figure 4b shows the values of invest ( k,n )forseveral choices of k and n , from which we can conclude that: (1) for every n , invest ( k,n ) achieves maximal at around k 0 . 6  X  n , and (2) the smaller a community is, the larger value invest ( k,n )is.

Therefore, in the algorithm we always pick communities according to the increasing order of their sizes. The algo-rithm is described as follows.
 Algorithm 2 CommunityUp 1: Let ( C 1 ,...,C k ) be a partition of graph G based on some 2: Let fraction be the percentage of seeded vertices in a 3: Order communities by their sizes, e.g., | C 1 | X | C 2 | X  4: for =1 ,...,k do 5: For the community C , randomly pick fraction  X | C | 6: end for
Notice that we use a parameter fraction instead of the nearly optimal value 60% in the description of the algorithm. In real social networks, a vertex may also be influenced by those from other communities, and the optimal value of the parameter fraction depends on the structure of the under-lying network. In particular, if a network has poor commu-nity structures, one may need to seed a larger fraction of vertices in order to derive the same domination probability. In the simulations, we choose a slightly larger parameter fraction = 65%.
We run a number of experiments to evaluate the per-formance of our community-based algorithm. We compare our algorithm with several other heuristic algorithms based on vertices X  structural measures of influence. Following the benchmarks considered in [18], we use degree and distance centrality heuristics as our comparison algorithms. Degree has long been considered as a standard estimate of a vertex X  X  influence in a network. Distance centrality, which is defined as the total distance from one vertex to all other vertices, is another commonly used influence measure in sociology. It is based on the assumption that a vertex that has shorter distances to all other vertices has more chance to influence them.

Clearly seeding vertices with larger influences stands a better chance to influence more vertices. However, in our model a more influential vertex may have a larger cost. Thus, the fixed budget constraint yields a trade-off between the number of vertices one can seed and their influences. In our experiments, we consider two extremes of this trade-off: one always seeds vertices with larger influences and the other always tries to pick as many vertices as possible. Specifically, we run the following algorithms in the simulations.
We choose the following two types of social networks as our testing data:
The testing data of the simulation network is available at http://snap.stanford.edu/data/ca-CondMat.html
To compare simulation results on different graphs, we as-sume for convenience that the budget B is of a proportion  X  of the total cost of all vertices, i.e., B =  X   X   X  i  X  V cost We run all of the aforementioned algorithms on the testing networks with  X  =1% , 3% , 5% , 10% , 20%, up to 70%, re-spectively. For each specific setting, we simulate the trial and error dynamics 100 times and take the average result.
Figure 5 shows the performances of different algorithms in the benchmark graphs of Lancichinetti et al. [20]. Our community-based algorithm CommunityUp outperforms all other algorithms by a big margin. This shows that taking community structures into account can reduce the amount of inefficient investment and greatly improve the marketing result. A more detailed analysis shows that in the trial and error process with the CommunityUp algorithm, almost all communities picked by the algorithm are dominated by the new product in the stable state. For all other algorithms, however, there are a number of communities to which the algorithm invests a fairly amount of budget, but eventually all vertices inside still use the original product in the stable state.

Figure 6 shows the results of the CondMat collaboration network. The structure in this real social network is more complicated then the benchmark graphs. As a result, the improvement margins between CommunityUp and other algo-rithms are not as large as those in the benchmark graphs.
From the simulations we can derive the following obser-vations and conclusions.
Quantity vs. quality. Among all other algorithms, we notice that DegreeUp and DistanceDown perform significantly better than the other two algorithms DegreeDown and Dis-tanceUp in almost all data sets. For a vertex with a small degree or a large distance centrality, the edges incident to the vertex usually have smaller weights. This indicates that for the limited budget, seeding a large number of low-influence vertices is strategically better than seeding a small number of high-influence vertices. A similar conclusion has been de-rived in Watts and Dodds [27].

Low budget vs. high budget. The amount of budget also plays different roles in different algorithms. The algo-rithms that prioritize low-influence vertices perform much better than the ones that prioritize high-influence vertices when the budget is small. As the budget increases, the lat-ter start to catch up and even outperform the former in some cases. Such phenomena echo some real world scenar-ios: Many companies tend to market products with small investments through local advertising and promotions to at-tract as many customers as possible (e.g., giving free sam-ples), whereas for companies with enormous budget, their strategy is to sign celebrities who have large influences as their spokespersons.

Mixing parameter. When the mixing parameter of a network is small, each community in the graph is more or less independent to each other. Thus, the number of com-munities adopting the new product should be roughly pro-portional to the budget invested, which is confirmed by the approximately straight lines in Figure 5a.

Meanwhile, networks with large mixing parameters have bad community structures. Each vertex would receive more influences from vertices of other communities. As a result, the performances of some heuristic algorithms on such a graph (Figure 5b) become very similar to that of a purely random strategy on a complete graph: the fraction of ver-tices adopting the new product increases rapidly when the budget goes from 40% to 60%, and then slowly goes to 1 as the budget keeps growing to around 70%. Yet our Commu-nityUp algorithm can still take advantages from such fuzzy community structures and outperform the other algorithms.
Testing vs. real networks. When comparing the bench-mark graphs of [20] with the real network CondMat, one can see a noticeable similarity between Figure 5a and Figure 6. In fact, the average mixing parameter of the CondMat net-work is 0.289, which indicates that the CondMat network has a pretty good community structure. On a side note, it also shows that mixing parameter, a benchmark evaluating whether a network has good community structures, is essen-tial for the performances of different influence maximization algorithms.
The diffusion of information in a social network is affected not only by its network structure but also by individuals X  preferences and experiences. We introduced a trial and er-ror model to study the dynamics of information diffusion due to strategic incentives of individuals. We showed that the trial and error dynamics reveals certain global community structures of a social network and from which we are able to detect macro-communities through the observation of micro-behavior of individuals. We also studied the influence maxi-mization problem and proposed a heuristic algorithm based on community detection. Simulations showed that the algo-rithm significantly outperforms several well-studied heuris-tics including degree and distance centralities.

We believe that investigating trial and error as the bridge linking individuals X  behavior in the micro-level and social phenomena in the macro-level would bring us a deeper un-derstanding of how information diffuses in a social network. Our work leaves a number of intriguing questions and direc-tions for future studies. [1] C. Beer. Trial and error in the evolution of cognition. [2] X. Bei, N. Chen, and S. Zhang. On the complexity of [3] V.D. Blondel, J.L. Guillaume, R. Lambiotte, and [4] S. Callander. Searching and learning by trial and error. [5] N. Chen. On the approximability of influence in social [6] W. Chen, C. Wang, and Y. Wang. Scalable influence [7] W. Chen, Y. Wang, and S. Yang. Efficient influence [8] P. Domingos and M. Richardson. Mining the network [9] D. Easley and J. Kleinberg. Networks, Crowds, and [10] G. Ellison. Learning, local interaction, and [11] S. Fortunato. Community detection in graphs. Physics [12] M. Girvan and M. Newman. Community structure in [13] M. Granovetter. The strength of weak ties. The [14] S. Hangal, D. MacLean, M. S. Lam, and J. Heer. All [15] J. C. Harsanyi and R. Selten. A General Theory of [16] M.O. Jackson. Social and economic networks . [17] M. Kandori, H. Mailath, and F. Rob. Learning, [18] D. Kempe, J. Kleinberg, and E. Tardos. Maximizing [19] M. Lahiri and M. Cebrian. The genetic algorithm as a [20] A. Lancichinetti, S. Fortunato, and F. Radicchi. [21] J. Leskovec, A. Krause, C. Guestrin, C. Faloutsos, [22] A. Montanari and A. Saberi. The spread of [23] M. Newman. The structure of scientific collaboration [24] N. Nisan, T. Roughgarden, E. Tardos, and [25] M. Richardson and P. Domingos. Mining [26] M. Sosna, R.N. Trevinyo-Rodriguez, and S.R.
 [27] D.J. Watts and P.S. Dodds. Influentials, networks, and [28] H. P. Young. The evolution of conventions.
 [29] H. P. Young. Individual Strategy and Social Structure: [30] H. P. Young. Learning by trial and error. Games and [31] H.P. Young. The diffusion of innovations in social
