 In the past decade, computer vision research in object recognition has firmly established the efficacy of representing images as collections of local descriptors of edge orientation. These descriptors are usually based on histograms of dominant orientation, for example, the edge orientation histograms of [1], the SIFT descriptor of [2], or the HOG features of [3]. SIFT, in particular, could be considered today X  X  default (low-level) representation for object recognition, adopted by hundreds of computer vision papers. The SIFT descriptor is heavily inspired by known computations of the early visual cortex [2], but has no formal detailed connection to computational neuroscience. Interestingly, a parallel, and equally important but seemingly unrelated, development has taken place in this area in the recent past. After many decades of modeling simple cells as linear filters plus  X  X ome X  nonlin-earity [4], neuroscientists have developed a much firmer understanding of their non-linear behavior. One property that has always appeared essential to the robustness of biological vision is the ability of individual cells to adapt their dynamic range to the strength of the visual stimulus. This adap-tation appears as early as in the retina [5], is prevalent throughout the visual cortex [6], and seems responsible for the remarkable ability of the visual system to adapt to lighting variations. Within the last decade, it has been explained by the implementation of gain control in individual neurons, hundreds of papers have been written on divisive normalization, and its consequences for visual processing. Today, there appears to be little dispute about its role as a component of the standard neurophysiological model of early vision [9]. In this work, we establish a formal connection between these two developments. This connection is inspired by recent work on the link between the computations of the standard model and the basic operations of statistical decision theory [10]. We start by formulating the central motivating question for descriptors such as SIFT or HOG, how to represent locally dominant image orientation , as a decision-theoretic problem. An orientation  X  is defined as dominant, at a location l of the visual orientations . An optimal statistical test is then derived to determine if x  X  ( l ) is distinct from the responses of remaining orientations. The core of this test is the posterior probability of orientation of the visual stimulus at l , given x  X  ( l ) . The dominance of orientation  X  , within a neighborhood R , is then defined as the expected strength of responses x  X  ( l ) , in R , which are distinct . This is shown to be a sum of the response amplitudes | x  X  ( l ) | across R , with each location weighted by the posterior probability that it contains stimulus of orientation  X  .
 The resulting representation of orientation is similar to that of SIFT, which assigns each point to a dominant orientation and integrates responses over R . The main difference is that a location could of locations to orientations, according to their posterior orientation probability. Exploiting known properties of natural image statistics, and the framework of [10], we then show that this measure of orientation dominance can be computed with the sequence of operations of the standard neurophys-iological model : simple cells composed of a linear filter, divisive normalization, and a saturating non-linearity, and complex cells that implement spatial pooling. The proposed measure of orien-tation dominance can then be seen as a biologically plausible version of that used by SIFT, and is denoted by bioSIFT. BioSIFT units are shown to exhibit the trademark properties of V1 neurons: their responses are closely fit by the Naka-Rushton equation [11], and they exhibit an inhibitory be-havior, known as cross-orientation suppression, which is ubiquitous in V1 [12]. We note, however, that our goal is not to provide an alternative to SIFT. On the contrary, the formal connection between findings from computer vision and neuroscience provides additional justification to both the success of SIFT in computer vision, and the importance of divisive normalization in the visual cortex, as well as its connection to the determination of orientation dominance.
 The main practical benefit of bioSIFT is to improve the performance of biologically plausible recog-nition networks, whose performance it brings close to the level of the state of the art in computer vision. In the process of doing this, it points to the importance of divisive normalization in vision. While such normalization tends to be justified as a means to increase robustness to variations of illumination, a hypothesis that we do not dispute, it appears to make a tremendous difference even when such variations do not hold. We illustrate these points through object recognition experiments with HMAX networks [13]. It is shown that the simple replacement of Gabor filter responses with the normalized orientation descriptors of bioSIFT produces very significant gains in recognition ac-curacy. These gains hold for standard datasets, such as Caltech101, where lighting variations are not a substantial nuisance. This points to the alternative hypothesis that the fundamental role of contrast normalization is to determine orientation dominance. The hypothesis is substantiated by the fact that the bioSIFT enhanced HMAX network substantially outperforms the previous best results in the lit-erature of biologically-inspired recognition networks [14, 15]. While these networks implement a number of operations similar to those of bioSIFT, including the use of contrast normalized units, they do not have a precise functional justification (such as the determination of orientation domi-nace), lack a well defined optimality criterion, and do not have a rigorous statistical interpretation. The importance of these properties is further illustrated by experiments in a dataset composed ex-clusively of natural scenes [16], which (unlike Caltech) fully matches the assumptions under which bioSIFT is optimal (natural image statistics). In this dataset, the HMAX network with the bioSIFT features has performance identical to that of very recent state-of-the-art computer vision methods. We start by describing the implementation of the bioSIFT network in detail. We lay out the com-putations, establish their conformity with the standard neurophysiological model, and analyze the statistical meaning of the computed features. 2.1 Motivation Various authors have argued that perceptual systems compute optimal decisions tuned to the statis-tics of natural stimuli [17, 18, 19]. The ubiquity of orientation processing in visual cortex suggests that the estimation of local orientation is important for tasks such as object recognition. This is reinforced by the success, in computer vision, of algorithms based on SIFT or SIFT-like descriptors. While the classical view was that the brain simply performs a linear decomposition into orientation channels, through Gabor filtering, SIFT representations emphasize the estimation of dominant ori-entation. The latter is a very non-linear operation, involving the comparison of response strength across orientation channels, and requires inter-channel normalization. In SIFT, this is performed implicitly, by combining the computation of gradients with some post-processing heuristics. More formal estimates of dominant orientation can be obtained by formulating the problem in decision-theoretic terms, and deriving optimal decision rules for its solution. For this, we assume that the visual system infers dominant orientation from a set of visual features x  X  R M , which measure stimulus amplitude at each orientation. In this work, we assume these features to be the set of re-sponses X i = I  X G i of the stimulus I , to a bank of Gabor filters G i . Here, G i is the filter of i th orientation, and  X  convolution. In principle, determining whether there is a dominant orientation requires the joint inspection of all feature channels X i . Statistically, this implies modeling the joint feature distribution and is intractable for low-level vision.
 A more tractable question is whether the i th channel responses, X i , are distinct from those of the question can be posed as a classification problem with two hypotheses of label Y  X  X  0 , 1 } , where This problem has class-conditional densities and the posterior probability of the  X  X istinct X  hypothesis given an observation from channel i is where we have assumed that P Y (0) = P Y (1) = 1 / 2 . Given the response x i ( l ) of X i at location l  X  X  , the minimum probability of error (MPE) decision rule is to declare it distinct when While this test determines if the responses of X i are distinct from those of X j 6 = i , it does not deter-mine if X i is dominant: X i could be distinct because it is the only feature that does not respond to the stimulus in R . The second question is to determine if the responses of X i are both distinct and large. This requires a new random variable which measures the strength (absolute value) of the distinct responses. The expected strength of distinct responses in R is then The empirical estimate of (5) from the sample x i ( l ) ,l  X  X  , is Figure 1: bioSIFT computations for given orientation  X  : (a) an image, (b) response of Gabor filter of ori-This measure of the dominance of the i th orientation is a sum of the response amplitudes | x i ( l ) | across R , with each location weighted by the posterior probability that it contains stimulus of that orientation and integrates responses over R . The main difference is that a location could contribute to more than one orientation, since the expected strength relies on a soft assignment of locations to orientations, according to their posterior orientation probability.
 Figure 1 illustrates the computations of (6) for the image shown in a). The response of a Gabor filter that these probabilities are much smaller than the Gabor responses in the body of the starfish, where the image is textured but there is no significant structure of orientation  X  . On the other hand, they are largest for the locations where the orientation is dominant. Figure 1 d) shows the final dominance measure. The combined multiplication by the Gabor responses and averaging over R magnifies the responses where the orientation is dominant, suppressing the details due to texture or noise. This can be seen by comparing b) and d). Overall, (6) is large when the i th orientation responses are 1) distinct from those of other channels and 2) large. It is small when they are either indistinct or small. One interesting property is that it penalizes large responses of X i that are not informative of the presence of stimuli with orientation i . Hence, increasing the stimulus contrast does not increase \ S ( X i ) R when responses x i ( l ) cannot be confidently assigned to the i th orientation. This can be seen in Figure 1 f) and h), where the Gabor response and dominance measure are shown for a low-contrast replica of the image of a). While the Gabor responses at low (f) and high (b) contrasts are substantially different, the dominance measure (d and h) stays almost constant. It follows that (6) implements contrast normalization, a topic to which we will return in later sections. It is worth noting that such normalization is accomplished without modeling joint distributions of response across orientations. On the contrary, all quantities in (6) are scalar. In this section we study the biological plausibility of the orientation dominance measure of (6). 3.1 Natural image statistics Extensive research on the statistics of natural images has shown that the responses of bandpass features follow the generalized gaussian distribution (GGD) where  X ( z ) = R  X  0 e  X  t t z  X  1 ,dt,t &gt; 0 is the Gamma function,  X  is a scale and  X  a shape param-eter. The biological plausibility of statistical inference for GGD stimuli was extensively studied in Figure 2: One channel of the bioSIFT network. The large dashed box implements the computations of the [10]. This work shows that various fundamental computations in statistics can indeed be computed biologically when a maximum a posteriori (MAP) estimate is adopted for  X   X  , using a conjugate (Gamma) prior. This MAP estimate is where  X  and  X  are the prior hyperparameters, and x ( j ) a sample of training points. As is usual in Bayesian inference, the hyperparameter values are important when the sample is too small to enable reliable inference. This is not the case for the current work, where the estimates remain constant over a substantial range of their values. Hence, we simply set  X  = 10  X  3 and  X  = 1 in all experiments. For natural images, the value of  X  is quite stable. We use  X  = 0 . 5 , (determined by fitting the GGD to a large set of images) in our experiments. 3.2 Biological computations To derive a biologically plausible form of (6) we start by assuming that P  X  ( i ) = 1 M . This is mostly for simplicity, the discussion could be generalized to account for any prior distribution of orienta-tions. Under this assumption, using (1) and where  X  k is the classical softmax activation function q the log-likelihood (up to constants that cancel in (11)) and, from (7) with the MAP estimate of  X   X  from (8) and the responses in R as training sample, Figure 3: (a) COS in real neurons(from [12]), and (b) in bioSIFT features (c) Contrast response in bioSIFT The computations of (11)-(13) are those performed by simple cells in the standard neurophysiolog-ical model of V1. A bank of linear filters is applied at each location l of the field of view. This produces the Gabor responses x i ( l ) . Each response x i ( l ) is divisively normalized by the sum of responses in the neighborhood R , for each orientation channel k , using (13). Notice that this im-plies that the conditional distribution of responses of a channel is learned locally, from the sample of responses in R . Altogether, (12) implements the computations of a divisively normalized simple cell. Finally, the softmax  X  k is a multi-way sigmoidal non-linearity which replicates the well known saturating behavior of simple cells. The computation of the orientation dominance measure by (10) then corresponds to a complex cell, which pools the simple cell responses in R , modulated by the magnitude of the underlying Gabor responses. This produces each channel X  X  contribution to the bioSIFT descriptor. A graphical description of the network is presented in Figure 2. 3.3 Naka-Rushton fit In addition to replicating the standard model of V1, the biological plausibility of the bioSIFT features can be substantiated by checking if they reproduce well-established properties of neuronal responses. One characteristic property of neural responses of monkey and cat V1 is the tightness with which they can be fit by the Naka-Rushton equation [11]. The equation describes the average response to a sinusoidal grating of contrast c as where R max is the maximum mean response, c 50 is the semi-saturation contrast i.e. the contrast at which the response is half the saturation value. The parameter q , which determines the steepness of the curve, is remarkably stable for V1 neurons, where it takes values around 2 [20]. The fit between the contrast response of a bioSIFT unit and the Naka-Rushton function was determined, using the procedure of [11], and is shown in Figure 3 c). As in biology, the Naka-Rushton model fits the bioSIFT data quite well. Over multiple trials, the q parameter for the best fitting curve is stable and stays in the interval (1 . 7 , 2 . 1) . 3.4 Inhibitory effects It is well known that V1 neurons have a characteristic inhibitory behavior, known as cross-orientation suppression (COS) [12, 7, 21]. This suppression is observed by measuring the response of a neuron, tuned to an orientation  X  , to a sinusoidal grating of orthogonal orientation (  X   X  90  X  ). When presented by itself, the grating barely evokes a response from the neuron. However, if super-imposed with a grating of another orientation, it significantly reduces the response of the neuron to the latter. To test if the bioSIFT features exhibit COS, we repeated the set of experiments reported in [12]. These consist of measuring a simple cell response to a set of sinusoidal plaids obtained by summing 1) a test grating oriented along the cell X  X  preferred orientation, and 2) a mask grating of orthogonal orientation. The test and the mask have the same frequency as the cell X  X  Gabor filter. The cell response is recorded as a function of the contrast of the gratings. Figure 3 a) shows the results reported in [12], for a real neuron. The stimuli are shown on the left and the neuron X  X  response on the right. Note the suppression of the latter when the mask contrast increases. The response of the bioSIFT simple cell, shown in Figure 3 b), is identical to that of the neuron.
 From a functional point of view, the great advantage of COS is the resulting increase in selectivity of the orientation channels. This is illustrated in Figure 3 (e). The figure shows the results of an experiment that measured the response of 12 Gabor filters of orientation in [0 o , 180 o ] to a horizontal grating. While both the first and twelfth Gabor filters have relatively large responses to this stimulus, the twelfth channel of bioSIFT is strongly suppressed. When combined with the contrast invariance to lighting variations. An example of this is shown in Figure 3 (f) which shows the value of the dominance measure for the most dominant orientation at each image location (in  X  X plit screen X  with the original image). Note how the bioSIFT features capture information about dominant orientation and object shape, suppressing uninformative or noisy pixels. 3.5 Independence and sparseness Barlow [18] argued that the goal of sensory systems is to reduce redundancy, so as to produce statistically independent responses. A known property of the responses of bandpass features to natural images is a consistent pattern of higher order dependence, characterized by bow-tie shaped conditional distributions between feature pairs. This pattern is depicted in Figure 3 g), which shows the histogram of responses of a Gabor feature, conditioned on the response of the co-located feature of an adjacent orientation channel. Simoncelli [22] showed that divisively normalizing linear filter responses reduces these higher-order dependencies, making the features independent. As can be seen from (10), (12), and (13), the bioSIFT network divisively normalizes each Gabor response by the sum, across the spatial neighborhood R , of responses from each of the Gabor orientations (11). It is thus not surprising that, as shown in Figure 3 h), the conditional histograms of bioSIFT features independent (knowledge of the value of one feature does not modify the distribution of responses of the other).This is a consistent observation across bioSIFT feature pairs.
 Another important, and extensively researched, property of V1 responses is their sparseness. Chan-nel sparseness is closely related to independence across channels. Sparse representations have sev-eral important advantages, such as increased generalization ability and energy efficiency of neural decision-making circuits. Given the discussion above, it is not surprising that the contrast normal-ization inherent to the bioSIFT representation also makes it more sparse. This is shown in Figure 3 d), which compares the sparseness of the responses of both a Gabor filter and a bioSIFT unit to a natural image. It is worth noting that these properties have not been exploited in the SIFT literature itself. For example, independence could lead to more efficient implementations of SIFT-based rec-ognizers than the standard visual words approach, which requires an expensive quantization of SIFT features with respect to a large codebook. We leave this as a topic for future research. In this section, we report on experiments designed to evaluate the benefits, for recognition, of the connections between SIFT and the standard neurophysiological model. 4.1 Biologically inspired object recognition Biologically motivated networks for object recognition have been recently the subject of substantial research [13, 23, 14, 15]. To evaluate the impact of adding bioSIFT features to these networks, we considered the HMAX network of [13], which mimics the structure of the visual cortex as a cascade of alternating simple and complex cell layers. The first layer encodes the input image as a set of complex cell responses, and the second layer measures the distance between these responses and a set of learned prototypes. The vector of these distances is then classified with a linear SVM. For this evaluation, each unit of the first layer was replaced by a bioSIFT unit, implemented as in Figure 2. The experimental setup is similar to that of [23]: multi-class classification on Caltech101 (with the size of the images reduced so that their height is 140) using 30 images/object for training and at-most 50 for testing. The baseline accuracy of [13] was 42% . The work of [23] introduced several enhancements that were shown to considerably improve this baseline. Two of these enhance-ments, sparsification and inhibition, were along the lines of the contributions discussed in this work. Others, such as limiting receptive fields to restrict invariance, and discriminant selection of proto-types could also be combined with bioSIFT. The base performance of the network with bioSIFT ( 54 . 5% ) is superior to that of all comparable extensions of [23] ( 49% ). This can be attributed to the fact that those extensions are mostly heuristic, while those now proposed have a more sound decision-theoretical basis. In fact, the simple addition of bioSIFT features to the HMAX network outperforms all extensions of [23] up to the prototype selection stage ( 54% ). When bioSIFT is com-plemented with limited C2 invariance and prototype selection the performance improves to 69% , which is better than all results from [23]. In fact, the HMAX network with bioSIFT outperforms the state-of-the-art 1 performance ( 65 . 5% ) for biologically inspired networks [15]. This improvement is interesting, given that these networks also implement most of the operations of the bioSIFT unit (filtering, normalization, pooling, saturation, etc.). The main difference is that this is done without a clear functional justification, optimality criteria, or statistical interpretation. In result, the sequence of operations is not the same, there is no guarantee that normalization provides optimal estimates of orientation dominance, or even that it corresponds to optimal statistical learning, as in (8). 4.2 Natural scene classification When compared to the state-of-the-art from the computer vision literature, the HMAX+bioSIFT network, does not fare as well. Most notably, it has worse performance than the method of Yang et al. [26], which holds the current best results for this dataset (single descriptor methods). This is explained by two main reasons. The first is that the networks are not equivalent. Yang et. al rely on a sparse coding representation in layer 2, which is likely to be more effective than the simple Gaussian units of HMAX. This problem could be eliminated by combining bioSIFT with the same sparse representation, something that we have not attempted. A second reason is that bioSIFT is not exactly optimal for Caltech, because this dataset contains various classes with many non-natural images. To avoid this problem, we have also evaluated the bioSIFT features on the scene classification task of [16]. Using the same HMAX setup, a simple linear classifier and 3000 layer 2 units, the network achieves a classification performance of 80 . 1% (see Figure 4). This is a substantial improvement, since these results are nearly identical to those of Yang et al. [26], and better than many of those of other methods from the computer vision literature. Overall, these results suggest that orientation dominance is an important property for visual recognition. In particular, the improved performance of the bioSIFT units cannot be explained by the importance of contrast normalization, since this is not a major nuisance for the datasets considered, it is also implemented by the other networks, bioSIFT is not optimized to normalize contrast, and it is unlikely that constrast variations would be more of an issue on Caltech than on the natural scene dataset.
