 Laurent Charlin lcharlin@cs.toronto.edu Richard Zemel zemel@cs.toronto.edu Craig Boutilier cebly@cs.toronto.edu The burgeoning interest in recommender systems has led to a plethora of techniques for predicting user preferences or ratings for unseen items (e.g., prod-ucts in e-commerce applications). Collaborative filter-ing (CF) methods ( Goldberg et al. , 1992 ) have proven especially popular and have attained impressive per-formance ( Koren , 2009 ). In practice, however, rec-ommendations must not only account for user prefer-ences in isolation; one usually has to tradeoff prefer-ences for recommended items with various constraints or objectives . For example, an online retailer may want to limit the number of recommendations (to different users) for any particular item so stock is not depleted (which would create unsatisfied customers). The same retailer may wish to facilitate serendipitous purchases by ensuring items recommended to any single user are diverse ( McNee et al. , 2006 ).
 In this paper we focus on match-constrained recom-mendation , where the quality of a set of recommenda-tions or matching is measured relative to constraints or objectives that account for the entire set of users to whom an item is recommended, the entire set of items recommended to a single user, or both. These are traded off against the predicted degree of preference of individual recommendations. Match-constrained rec-ommendation has wide application. For example, con-sider the problem of assigning papers to reviewers: given preferences (self-assessed expertise) of reviewers for certain papers, we want to find the best assignment of papers to reviewers. Recent work has used learning techniques such as CF to predict missing preferences X  allowing reviewers to specify preferences for only a small selection of papers X  X nd finding high quality matches subject to specific  X  X ollective X  constraints on the matching (e.g., number of papers per reviewer, number of reviewers per paper) ( Conry et al. , 2009 ; Charlin et al. , 2011 ).
 Eliciting preferences (e.g., in the form of item ratings) imposes significant time and cognitive costs on users. In domains such as paper matching, product recom-mendation, or online dating, users will have limited pa-tience for specifying preferences. While learning tech-niques can be used to limit the amount of required in-formation in match-constrained recommendation, the intelligent selection of preference queries is just as im-portant in reducing user burden. It is this problem we address in this paper. We frame the problem as one of active learning : our aim is to determine those preference queries with the greatest potential to im-prove the quality of the matching. This is a depar-ture from most work in active learning, and, specifi-cally, approaches tailored to recommender systems (as we discuss below) where queries are selected to im-prove the overall quality of ratings prediction. We de-velop techniques that focus on queries whose responses will directly impact X  X ossibly indirectly by changing predictions X  X he matching objective itself.
 In this paper we propose several new active learning methods for match-constrained recommendation. In contrast to previous active approaches, our methods are sensitive to the matching objective. We also pro-pose a new probabilistic matching technique that ac-counts for uncertainty in predicted preferences when constructing a matching. Finally, we test our methods on several real-life datasets for online dating, confer-ence reviewing, and assigning jokes to users. Our re-sults show that active learning methods that are sen-sitive to the matching task significantly outperform a standard active learning method. Furthermore, we show that our probabilistic methods can be success-fully leveraged by active learning. We define our problem formally below, but informally, assume a set of users must be matched to items sub-ject to certain constraints or objectives on the overall matching. Items are construed broadly to refer to any-thing to which users might be matched: products in e-commerce recommender systems, papers in reviewer matching problems, even other users in roommate as-signment, stable marriage or online dating. User pref-erences over items are represented by suitability scores which reflect the quality of matching a given item to a user  X  X n isolation. X  Again, suitabilities should be interpreted broadly as user preference, expertise, or some other application-specific metric.
 Matching problems have been studied in economics for decades, where the focus has been on incen-tives and stability , especially in two-sided match-ing domains where both users and items (e.g., other users) express preferences over the other. Classic ex-amples include stable marriages and college admis-sions ( Gale &amp; Shapley , 1962 ), medical resident to hos-pital matching ( Roth , 1984 ) and (one-sided) housing markets ( Hylland &amp; Zeckhauser , 1979 ). This work typically assumes all preferences have been specified. Considerable work in information retrieval and ma-chine learning has dealt with predicting suitabilities given only a partial set of scores or other relevant data. CF is, of course, a prime example ( Goldberg et al. , 1992 ). Recent work on reviewer-paper matching X  a domain we consider here X  X ncludes work using co-authorship graphs ( Rodriguez &amp; Bollen , 2008 ), lan-guage and topic models ( Mimno &amp; McCallum , 2007 ), and CF ( Conry et al. , 2009 ; Charlin et al. , 2011 ). The latter work in particular shows that high-quality matchings can be constructed while eliciting only a small set of suitabilities, and that tuning the learning objective to account for the matching objective can improve match quality with limited data.
 Active learning is a rich field (e.g., see ( Settles , 2009 ) for a recent survey). Closest to our work are active learning methods developed for CF ( Boutilier et al. , 2003 ; Jin &amp; Si , 2004 ; Harpale &amp; Yang , 2008 ). These methods consider objectives that deal with recommen-dation sets (somewhat akin to our matching objec-tive). Rigaux ( 2004 ) considers an iterative elicitation method for paper matching using neighborhood CF, but requires an initial partitioning of reviewers, and elicits scores (with the aim only of improving score pre-diction quality) for the same papers from all reviewers in a partition. In our work, we need not partition users, and we focus on matching quality rather than prediction accuracy. Our approach is thus conceptu-ally similar to CF methods trained for specific rec-ommendation tasks (e.g., ( Weimer et al. , 2007 )). Fi-nally, Bayesian optimization has been used for active learning recently ( Brochu et al. , 2009 ); however, these methods assume a continuous query space and some similarity metric over item space, hence are not read-ily adaptable to our match-constrained problems. In this section, we describe a general framework for exploiting learning in match-constrained recommen-dation, adopting the model and principles used in recent work on paper matching ( Conry et al. , 2009 ; Charlin et al. , 2011 ). We then introduce a new model for probabilistic matching within this framework that we exploit when considering active learning in Sec. 4 . 3.1. Matching Framework Our aim is to determine high quality matchings of items to users while requiring users to specify pref-erences or suitabilities over only a small fraction of all items. Our overall framework is illustrated in Fig. 1 , and comprises three steps, which may be iterated in the active learning setting (Sec. 4 ). We first elicit suit-ability scores from users for certain items (A); we then learn some model (e.g., CF) to predict unobserved suitabilities (B); finally, some form of optimization is used to determine a matching meeting certain objec-tives and constraints, using both observed and pre-dicted suitabilities (C). We first formalize the model, then discuss components (B) and (C) in more detail. Model Formulation We formalize our problem as follows. Let r  X  R refer to users (e.g., reviewers, con-sumers, etc.), p  X  P to items (e.g., papers, products, other users), with |R| = N and |P| = M . Every user-item pair has a suitability score s rp , the set of which of the suitabilities are observed, namely, those elicited from users. We denote this by S o , and denote the ob-served scores for a particular user r and item p by S o r and S o p , respectively. S u , S u r , S u p are the analogous collections of unobserved scores.
 Estimating Unobserved Scores Estimating un-observed scores given a (small) set of observed scores X  together with any side-information, e.g., word vectors in submitted papers X  X s a straightforward supervised learning task to which a variety of approaches can be applied. Conry et al. ( 2009 ), for instance, use CF to predict unknown scores in a paper matching domain. While our framework is quite general, our experiments, including those in Sec. 5 on paper matching and several other domains, suggest that Bayesian probabilistic ma-trix factorization (BPMF) ( Salakhutdinov &amp; Mnih , 2008a ) is a very competitive CF method for match-constrained recommendation. So we describe it here as one method, of many, that can be used.
 Standard PMF ( Salakhutdinov &amp; Mnih , 2008b ) fac-torizes the observed score matrix, S o , into two low-k  X  min( M, N ). Unobserved scores are predicted us-ing their product: s u ij is predicted to be u i v  X  j . While PMF can be given a probabilistic interpretation by as-suming Gaussian noise with fixed standard deviation  X  , BPMF provides a Bayesian extension of PMF by as-suming priors on U and V . Apart from outperforming PMF on standard CF tasks, BPMF also provides a dis-tribution over unobserved suitabilities, Pr( S u | S o ,  X  ), instead of a simple point prediction.
 Matching Optimization Matching uses both ob-served and predicted suitability scores to assign items to users. We focus primarily on domains where constrained many-to-many matching is required, i.e., where an item is matched to multiple users and multi-ple users are matched to a single item. Paper matching is a prime example, where each paper needs a specific number of reviewers, and each reviewer must be as-signed a number of papers within some range. While many objectives and constraints can be accom-modated in our framework, we illustrate it using a sim-ple paper matching problem. Treating self-reported in-terest or expertise as observed suitabilities, standard learning methods like BPMF are used to predict un-observed scores. We then formulate the matching op-timization (treating predicted scores as if observed) as an integer program (IP) ( Taylor , 2008 ): Here the binary variable y rp  X  Y encodes the matching of item p to user r ; a matching is a complete instanti-ation of these variables. R min ( R max ) is the minimum (resp. maximum) number of users per item, while P min ( P max ) represent the minimum (resp. maximum) user capacities. Of course, many other criteria can be in-corporated into the matching optimization. While IPs of this form can quickly become intractable, the to-tal unimodularity of the constraint matrix (Eqs. 2  X  4 ) allows one to use the linear programming (LP) relax-ation while retaining optimality. 3.2. Probabilistic Matching While the LP optimization is straightforward, and pro-vides optimal solutions when all scores are observed, it has potential drawbacks when used with predicted scores, and specifically, when used in conjunction with active learning. First, the LP does not consider poten-tially useful information contained in the uncertainty of the (predicted) suitabilities. Second, it does not express the range of possible matches that might opti-mize total suitability (given the constraints). While optimal matching given true scores can be viewed as a deterministic process, score prediction is inherently stochastic; and we can exploit this if our prediction model outputs a distribution over unob-served scores S u rather than a point estimate. Given inputs consisting of observed scores S o and possibly additional side-information X , we can express our un-certainty over the optimal matching as: where Pr( S u | S o , X,  X  ) is our score prediction model (assuming model parameters  X  ), and Y (  X  ) (see Eq. 1 ) is the optimal matching given a fixed set of scores. With this in hand, we overcome the limitations of pure LP-based optimization by developing a sampling method for determining  X  X oft X  or probabilistic match-ings that reflect the range of optimal matchings given uncertainty in predicted suitabilities. While Eq. 5 ex-presses the induced distribution over optimal match-ings, the integral is intractable as it requires solving a large number of matching problems (e.g., LPs). In-stead we take a sampling approach: we independently sample each score from the posterior Pr( S u | S o , X,  X  ) to build a complete score matrix, then solve the match-ing optimization (LP) using this sampled matrix. Re-peating this process T times provides an estimated distribution over optimal matchings. We can then average the resulting match matrices, obtaining Y =
P T t =1 Y ( t ) . Each entry Y rp is the (estimated) proba-bility that user-item pair rp is matched; and the prob-ability of this match depends, as desired, on the dis-tribution Pr( s rp | S o , X,  X  ).
 Fig. 2 illustrates Y , comparing it to the LP solution, on a randomly-generated  X  X oy X  problem with 3 review-ers and 6 papers (1 reviewer per paper, 2 papers per reviewer). Assuming a fixed predicted score matrix S , two versions of Y are shown, one when all estimated variances are low, the other when they are higher. 1 Note that the Y matrices respect the matching con-straints by design (for visualization purposes we round matching probabilities). With low variances, Y agrees with the LP, but with higher variances, we observe the inherent uncertainty in the optimal matching; e.g., col-umn one shows all three match probabilities to be rea-sonably high. In addition, the last column shows that even though the second and third users have scores that differ by 2, the high variance in their scores gives both users a reasonable probability of being matched. Since it is impractical to elicit or otherwise observe the preferences of all users for all items, supervised learn-ing, as discussed above, can be used to effectively es-timate unobserved suitabilities for match-constrained recommendation ( Conry et al. , 2009 ; Charlin et al. , 2011 ). However, little work has considered strategies for actively querying the  X  X ost informative X  prefer-ences from users, thus further reducing the elicitation burden on users. Random selection of user-item pairs for assessment will generally be sub-optimal, since query selection is uninformed by the learned model, the objective function, or any previous data. By con-trast, an active approach , in which queries are tailored to both the current preference model and the current best matching, will typically give rise to better match-ings with fewer queries. 2 In this section we describe several distinct strategies for query selection: we review a standard active learn-ing technique and introduce several novel methods that are sensitive to the matching objective. Our methods can be broadly categorized based on two properties: whether they evaluate in score space S or matching space Y ; and whether they select queries with the maximal value M, or maximal entropy E. Score Entropy ( S E): Uncertainty sampling is a com-mon approach in active learning, which greedily se-lects queries involving (unobserved) user-item pairs for which the model is most uncertain ( Settles , 2009 ). In our context, this corresponds to selecting the user-item pair with maximum score entropy w.r.t. the score dis-tribution produced by the learned model. The ratio-nale is clear: uncertainty in score predictions may lead to poor estimates of match quality. Of course, this approach fails to explicitly account for the matching objective (the term Y ( S u , S o ) in Eq. 5 ), instead focus-ing (myopically) on entropy reduction in the predictive model (the term Pr( S u | S o , X,  X  )).
 Score Max ( S M): An alternative, simple strategy is to select queries involving user-item pairs with highest predicted score w.r.t. MAP score estimates given our predictions of unobserved scores:  X  S u  X  arg max S u Pr( S u | S o , X,  X  ). This may be especially ad-vantageous for matching problems where scores for matched user-item pairs contribute an amount equal to their value in the matching objective (see Eq. 1 ). An obvious shortcoming of both S E and S M is their insensitivity to the matching objective. Queries that reduce prediction entropy may have no influence on the resulting matching (e.g., if s u rp has high entropy, user r  X  may remain matched to p with high probability regardless of the response to query rp ). One remedy is to use expected value of information (EVOI) to mea-sure the improvement in matching quality given the re-sponse to a query (taking expectation over predicted responses). This approach has been used effectively in (non-constrained) CF ( Boutilier et al. , 2003 ); but EVOI is notoriously hard to evaluate. In our context, we would (in principle) have to consider each possible query rp , estimate the impact of each possible response s rp on the learned model (the term Pr( S u | S o , X,  X  ) in Eq. 5 ), and re-solve the estimated matching (the term Y ( S u , S o ) in Eq. 5 ). Instead, we consider several more tractable strategies.
 Y -Max ( Y M): A simple way to select queries in a match-sensitive fashion is to consider the solution re-turned by the LP w.r.t. the observed scores, S o , and the MAP solution of the unobserved scores,  X  S u . We query the unknown pair rp that contributes the most to the value of the objective: arg max ( rp )  X  S u y rp  X  s user r and item p, and s rp the corresponding MAP score value. In other words, we query the unobserved pair among those actually matched with the highest predicted score. We refer to this strategy as Y-Max ( Y M) . It reflects the intuition that we should either confirm or refute scores for matched pairs, i.e., those pairs that, under the current model, that directly de-termine the value of the matching objective. However, Y M is insensitive to score uncertainty.
 Y -Max ( Y M)): This method exploits our probabilistic matching model to select queries. As with Y M, Y M queries the unobserved pair rp that contributes the most to the objective value: arg max ( rp )  X  S u Y rp  X  s The difference is that we use the probabilistic match, exploiting prediction uncertainty in query selection. Y -Entropy ( Y E): This method exploits the probabilis-tic match Y as well, but unlike Y M, Y E queries un-known pairs whose entropy in the match distribution is greatest. Specifically, we view each Y rp as a Bernoulli random variable with (estimated) success probabil-ity Y rp . We then query that pair with maximum (1  X  Y rp ) log Pr(1  X  Y rp ) .
 One important point to note is that the match-sensitive strategies, Y M, Y M, Y E, all attempt to query unobserved pairs that occur (possibly stochas-tically) in the optimal match. When the LP does not match on any unobserved pairs, a fall-back strategy is needed. All three strategies resort to random query-ing as a fall-back, selecting a random unobserved item score for any specific user as its query. For Y M and Y E, we refer to any query that corresponds to a user-item pair with less than a 1% chance of being matched as a  X  X andom X  query. We test the active learning approaches described above on three data sets, each with very different characteris-tics. We begin with a brief description of the data sets and matching tasks, then describe our experimental setup, before proceeding to a discussion of our results. Data sets We first describe our three data sets and define the corresponding matching tasks.
 Jokes data set: The Jester data set ( Goldberg et al. , 2001 ) is a standard CF data set in which over 60,000 users have each rated a subset of 100 jokes on a scale of -10 to 10. It has a dense subset in which all users rate ten common jokes. Our experiments use a data set consisting of these ten jokes and 300 randomly se-lected users. We convert this to a matching problem by requiring the assignment of a single joke to each user (e.g., to be told at a convention or conference), and re-quiring that each joke be matched to between 25 and 35 users (to ensure jocular diversity at the convention). Fig. 3 (a) provides a histogram of the suitabilities for the Jester sub-data set.
 Conference data set: This data is derived from the NIPS 2010 conference. It contains suitability scores for 1251 paper submissions provided for 48 area chairs (henceforth, reviewers). Scores range from 0 ( X  X aper lies outside my expertise X ) to 3 ( X  X ery qualified to re-view X ). Suitabilities for a subset of papers were elicited in two rounds. In the first round scores were elicited for about 80 papers per reviewer, with queries selected using the Y M procedure described above (where the initial scores were estimated using a simple language model ( Balog et al. , 2006 ) using reviewers X  published papers). In the second round, unobserved scores were estimated using both the language model and a re-stricted Boltzmann machine (RBM) trained on the first-round scores and paper word-frequency vectors. Each reviewer was queried about 143 papers on aver-age (excluding one outlier), and each paper received an average of 3.3 suitability assessments (std. dev. 1.3). The mean suitability score was 1.14 (std. dev. 1.1); a histogram of scores is shown in Fig. 3 (b). Each paper was then assigned to one reviewer, and each reviewer received 20 X 30 papers.
 Dating data set: The third data set comes from an online dating website (see http://www.occamslab.com/petricek/data/ ). It contains over 17 million ratings from roughly 135,000 users of 168,000 items (other users). We use a denser subset of 32,000 ratings from 250 users (each with at least 59 ratings) over 250 items (other users); see Fig. 3 (c). Since items are users with preferences over their matches, dating is generally treated as a two-sided problem. While two-sided matching can fit within our general framework, the focus of our current work is on one-sided matching. As such, we only consider user preferences for  X  X tems X  and not vice versa. Each user is assigned 25 X 35 items (and vice versa since  X  X tems X  are users).
 5.1. Experimental Procedures Our experiments simulate the typical interaction of a recommendation or matching engine with its users. All experiments start with a few observed preferences for each user and go through several rounds of querying. At each round, a querying strategy selects queries to ask one or more users. Note that in practice we restrict the strategies to only query (unobserved) scores avail-able in our data sets. Once all users have responded, the system re-trains the learning model with newly and previously observed preferences, then proceeds to select the next batch of queries. This is a somewhat simplified model that assumes semi-synchronous user communication. We also assume for simplicity that the same fixed number of queries per user is asked in each round. The initial goal is simply to assess the rel-ative performance of each method; we do relax some of these assumptions in Sec. 5.2 .
 There are a variety of reasonable interaction modes for eliciting user preferences. For example, in paper-reviewer matching, posing a single query per round is undesirable, since a reviewer, after assessing a single paper, must wait for other reviewer responses X  X nd the system to re-train X  X efore being asked a subse-quent query. Reviewers generally prefer to assess their expertise off-line w.r.t. a collection of papers. Conse-quently batch interaction is most appropriate where, at each round, users are asked to assess K items. While batch frameworks for active learning have re-ceived recent attention (e.g., ( Guo &amp; Schuurmans , 2007 )), here we are interested in comparing different query strategies, hence use a very simple greedy batch approach where we elicit the  X  X op X  K preferences from a user, where the  X  X op X  queries are ranked by the spe-cific active strategy under consideration. Appropriate choice of K is application dependent: smaller values of K may lead to better recommendations with fewer queries, but require more frequent user interaction and user delay. We test different values of K below. We use BPMF to generate our predictions and its uncertainty model for unobserved scores. A pro-cedure for setting some of the hyper-parameters of BPMF is outlined in ( Salakhutdinov &amp; Mnih , 2008a ). We use a validation set for the other methods giv-ing (using notation from the original paper) Jokes: D = 1 ,  X  = 0 . 1 ,  X  0 u = 0 . 1 ,  X  0 v = 10; Conference: D = 15 ,  X  = 2 ,  X  0 u =  X  0 v = 0 . 1; and Dating: D = 2 ,  X  = 2 ,  X  0 u =  X  0 v = 0 . 1. Each observed score is Y -based methods, which require sampling, we use 50 samples in all experiments.
 We compare query selection methods w.r.t. their matching performance X  X .e., the matching objective value of Eq. 1  X  X sing the match matrix given by the LP using estimated scores and known scores S o , eval-uated on the full set of available scores. We use a random querying strategy, which selects unobserved items uniformly at random for each user, as a base-line . All figures show the number of queries per user on the x -axis. The y-axis indicates the difference in the matching objective value between a specific querying strategy and the baseline. Positive differences indi-cate better performance relative to the baseline. The magnitude of this difference can be best understood relative to the number of users in the data set. For example, a difference of 300 in objective value for the 300 users in the Jokes data set means that users are better by one  X  X core unit X  on average. Note that as we increase the number of queries, even random queries will eventually find good matches X  X n the limit, where all scores are observed, matching performance of all methods will be identical (hence the bell-shape curves and asymptotic convergence in our results).
 We don X  X  focus on running time in our experiments since query determination can often be done off-line (depending on batch sizes). Having said that, even the most intense querying techniques are fast and can support online interaction: (a) in all 3 data sets, solv-ing the LP takes a fraction of a second; (b) BPMF can be trained in a matter of a few minutes at most, but can be run asynchronously with query selection (which will use the most  X  X p-to-date X  learned model avail-able); and (c) sampling scores is very fast as the pos-terior distribution is Gaussian. Furthermore, given the above, our methods should scale to larger datasets al-though the training time of BPMF may preclude fully online interaction. 5.2. Results We first investigate the performance of the different querying strategies on our three data sets using default batch sizes X  X hese K values were deemed to be natu-ral given the domains (different K values are discussed below). Fig. 4 (a) shows results for Jokes using batches of 10 queries per user per round ( K = 10). Figs. 4 (b) and (c) show Conference and Dating results, respec-tively, both with a batch size of 20. All users start with 20 observed scores: 15 are used for training and 5 for validation. We also experimented with a more realistic setting where some users have few observed scores (e.g., new users) X  X esults are qualitatively very similar.
 The relative performance of each of the active meth-ods exhibits a fairly consistent pattern across all three domains, which permit us to draw some reasonably strong conclusions. 3 First, we see that all methods ex-cept for S E outperform the baseline in all domains. Recall that S E is essentially uncertainty sampling, a classic (match-insensitive) active learning model often used as a general baseline method for active learning. It outperforms the random baseline only occasionally, most significantly after the first round of elicitation in Dating. Second, all of our proposed match-sensitive techniques outperform S E consistently on all data sets. Third, the match-sensitive approaches that leverage uncertainty over scores, namely, Y M and Y E, typically outperform Y M, especially after the initial rounds of elicitation. This difference in performance behavior is most pronounced in the Conference domain.
 We gain further insight into these results by examin-ing the inner workings of these strategies. The overlay in Figs. 4 (a X  X ) show the number of random (or fall-back) queries used (on average) by each of Y M, Y M and Y E. On all data sets Y M resorts to the fall-back strategy significantly earlier than the others, explain-ing Y M X  X  fall-off in performance and indicating that the diversity of potential matches identified by our probabilistic matching technique plays a vital role in match-sensitive active learning.
 Finally, when considering the performance of these methods on score prediction, we found no correla-tion between score prediction and matching perfor-mance. This further highlights the benefit of match-constrained active learning methods.
 Sequential Querying We employed a semi-synchronous querying procedure above, where all users are queried in parallel at each round. We now consider a different mode of interaction where, at each round, users are queried sequentially in round robin fashion. This allows the responses of earlier users within a round to influence the queries asked to later users X  potentially reducing the total number of queries at the expense of increased synchronization (and delay) among users. Fig. 5 (a) shows that our methods are robust to this modification in the querying procedure. Batch Sizes The choice of the number of queries K per batch affects both the frequency with which the user interacts with the system as well as the over-all match performance. For example, high values of K reduce the number of user  X  X nteractions X  needed for a specific level of performance, at the expense of query efficiency (improvement in matching objective per query). The  X  X ptimal X  value for K depends on the actual recommendation application. Figs. 5 (b) and (c) shows results with different values of K on Conference, using 10 and 40 queries per round, respectively. The relative performance of the active methods remains almost identical. As expected, absolute performance w.r.t. query efficiency is better with smaller values of K . The matching-sensitive strategies clearly outper-form the score-based techniques. Results are similar across all data sets.
 Matching constraints Our results are also robust to different matching constraints, specifically, bounds on the numbers of items per user and vice versa (i.e., R min , R max , P min , P max ). Using the Conference data set, we increase to two (from one) the number of re-viewers assigned to each paper. Fig. 5 (d) shows that the behavior of the methods changes little, with both Y -methods still outperforming all other methods. The other domains (not shown) exhibit similar results. We investigated the problem of active learning for match-constrained recommendation systems. We explored several different approaches to generating queries that are guided by the matching objective, and introduced a novel method for probabilistic matching that accounts for uncertainty in predicted scores. Ex-periments demonstrate the effectiveness of our meth-ods in determining high-quality matches with signif-icantly less elicitation of user preferences than that required by uncertainty sampling, a standard active learning method. Our results highlight the importance of choosing queries in a manner that is sensitive to the matching objective and uncertainty over predicted scores.
 There are many promising avenues of future research in match-constrained recommendation. We are cur-rently exploring different matching objectives (e.g., two-sided matching with stability constraints) and methods for eliciting side-information from users in a way that is guided by the recommendation objec-tive. Finally, higher-level, abstract queries (such as preferences over item categories or features) may sig-nificantly boost  X  X ain per query X  performance.
