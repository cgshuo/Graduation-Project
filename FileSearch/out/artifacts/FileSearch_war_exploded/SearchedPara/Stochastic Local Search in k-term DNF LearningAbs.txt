 Allee, Geb  X  aude 079, D-79110 Freiburg i. Br., Germany Stefan Kramer KRAMER @ IN . TUM . DE This paper deals with one of the most fundamental abstrac-tions of rule learning, namely k-term DNF learning. The task in k-term DNF learning is to induce a formula in dis-junctive normal form of at most k disjuncts (terms) given positive and negative examples. This problem is at the core of DNF minimization, i.e. the problem of finding a DNF formula for a given dataset with as few terms as possible. The goal of finding small formulae is, in one or the other form, present in most practical rule learning algorithms, and related to the principle of William of Ockham. K-term DNF learning is known to be NP-complete.
 K-term DNF learning is essentially a combinatorial search problem. Because of the combinatorial complexity, ex-haustive search algorithms for finding solutions require huge computational resources for hard problem settings. In this paper we investigate other approaches with the goal to find solutions more efficiently. Clearly, there are some trade-offs involved: stochastic local search (SLS) algo-rithms are incomplete, i.e. they are not guaranteed to find a solution. Other approaches such as separate-and-conquer only find good approximations with a slightly larger num-ber of terms than the optimal solution.
 In previous work (R  X  uckert et al., 2002) we laid the founda-tion for this investigation: first of all, we presented a com-plete exhaustive search algorithm, that can be used as a ref-erence for other algorithms. We then used this algorithm to investigate the distribution of the search costs for ran-domly generated problem instances. We applied the phase transition framework to identify hard randomly generated problem instances, that can be used as a benchmark for the evaluation of the algorithms. Finally, we used a polyno-mial reduction of the k-term DNF learning problem to the satisfiability problem (SAT) to show that WalkSAT is able to solve a large fraction of the hard problems in the bench-mark set. WalkSAT can be seen as a reference for native SLS algorithms, i.e. SLS algorithms that search directly in the solution space of the k-term DNF learning problem. In this paper we continue our investigation: first of all we design a native SLS algorithm, that is able to efficiently solve hard k-term DNF learning problems without the need for encoding a k-term DNF learning problem as a SAT problem. We give a detailed analysis of the algorithm X  X  per-formance compared to WalkSAT. In the same context, we evaluate the separate-and-conquer approach used in many rule-learning systems. More specifically, we investigate the average size of the learned rules for hard problems from the phase transition region in relation to the shortest possible formula. Finally, to show the practical relevance of the term DNF learning problem, we apply our SLS algorithm to a challenging chess-endgame problem. A k-term DNF formula is a disjunction of k terms, where each term is a conjunction of literals. E.g. ( a ( a and ( a The k-term DNF learning problem can now be formalized as follows (Kearns &amp; Vazirani, 1994): Given  X  a set of Boolean variables Var ,  X  a set Pos of truth value assignments p i : Var  X   X  a set Neg of truth value assignments n i : Var  X   X  a natural number k , Find a k -term DNF formula that is consistent with Pos and Neg , i.e. that evaluates to 1 ( true ) for all variable assignments in Pos and to 0 ( false ) for all variable assignments in Neg .
 This problem is in the presented form a decision problem. Given the parameters, we would like to know, whether or not there exists a solution. The corresponding optimiza-tion problem is DNF minimization: given the positive and negative examples, we would like to find the smallest k , so that there is a formula consistent with the examples. Ev-ery algorithm for solving the k-term DNF learning problem can easily be extended to solving the DNF minimization problem (usually by adding branch and bound techniques). Thus, in the following we focus only on k-term DNF learn-ing, even though the optimization version is much more common in practical applications.
 K-term DNF learning is essentially a combinatorial search problem. Indeed, k -term DNF learning is NP-hard. There are two basic ways of solving a k -term DNF learning prob-lem. One possibility is to search the space of all possi-ble k -term DNF formulae directly. The other possibility is to search the usually smaller space of k -partitions of Pos . A k -partition is a partition of Pos into k disjunct subsets. Given any k -partition, one can obtain a k DNF formula that covers all positive examples by comput-ing the k least general generalizations of the k partitions. The least general generalization of a set is the conjunction E.g., for the examples e e = { a 1 = 1 ,a 2 = 0 ,a 3 = 0 } the lgg ( e 1 ,e 2 ) = a 1 because the variable assignments to a amples can be combined to the literals a formula obtained in this manner covers all positive exam-ples. If it does not cover any negative example, it is a so-lution. Furthermore, if there is no k partition whose gener-alization is a solution, then the k -term DNF problem does not have a solution at all. This leads to an elegant combi-natorial search algorithm for solving k-term DNF learning problems, as outlined in (R  X  uckert, 2002).
 Due to the NP-hardness of the k -term DNF learning prob-lem, exhaustive algorithms are impractical. Therefore, we are often willing to sacrifice completeness (i.e. the cer-tainty of finding a solution, if there exists one) for better runtime behavior. In this context, stochastic local search (SLS) algorithms have been shown to find solutions to many hard NP-complete problems in a fraction of the time required by the best complete algorithms at the cost of in-completeness. Since the introduction of GSAT (Selman et al., 1992), there has been a lot of research on SLS al-gorithms, and a couple of different variants have been pro-posed and evaluated (Hoos, 1998; Selman &amp; Kautz, 1993; Selman et al., 1996; McAllester et al., 1997). In this paper, we will study such stochastic local search algorithms for k -term DNF learning.
 In order to evaluate SLS algorithms, we need a suitable test set of hard problem instances. If the test set contains only easy problem instances, all algorithms perform quite well. Unfortunately, large values of | Pos | , | Neg | , n = | Var | and k do not necessarily indicate that a problem at hand is hard to solve. For example, even though the test sets used in (Kamath et al., 1992) have up to one thousand ex-amples, they can be solved by a randomized version of the exhaustive search algorithm in partition space in less than a second (R  X  uckert, 2002). On the other hand, some prob-lem instances with only sixty examples can take weeks to solve. We therefore need some way to estimate the hard-ness of our benchmark data sets.
 One way to assess problem hardness is the phase transi-tion framework. Consider, for instance, k-term DNF learn-ing problem instances where n , | Pos | , and k are fixed and | Neg | is varied. One would expect to have  X  on average  X  low search costs for very low or very high | Neg | . With only a few negative examples, almost any formula covering Pos should be a solution, hence the search should terminate soon. For very large | Neg | , we can rarely generate formu-lae covering even a small subset of Pos without also cov-ering one of the many negative examples. Consequently, we can prune the search early and search costs should be low, too. Only in the region between obviously soluble and obviously insoluble problem instances, the average search costs should be high. Similar considerations can be made about n , | Pos | , and k . This transition between obviously soluble and obviously insoluble problem settings resembles the phase transition in physical systems. It is, however, not obvious, which parameter influences the average hardness of the generated problem instances in which way. A first step towards the characterization of the phase transition in k-term DNF Learning has been made in (R  X  uckert et al., 2002): Figure 1 shows P and average search costs for randomly generated problem instances with k = 3 , | Pos | = 15 , 1  X  | Neg |  X  128 , and 1  X  n  X  128 . As can be seen, the problem in-stances whose average probability of being soluble is ap-proximately 0.5 require the largest average search costs. This interrelation can be expressed using an equation which is derived according to methods from statistical mechanics. In the following we will make use of these results to eval-uate Stochastic Local Search algorithms on hard problems taken from the phase transition region. SLS algorithms differ from other approaches in that they perform a local, randomized-walk search. In its basic incar-nation, an SLS algorithm starts with a randomly generated solution candidate. It then iterates in a two-step loop: in the first step it examines a fixed set of  X  X eighboring X  can-didates according to some predefined neighborhood rela-tion. Each neighbor is evaluated according to some global scoring function. In the second step the SLS algorithm selects the neighbor with the highest score as next candi-date. Such a greedy hill climbing approach is obviously susceptible of getting caught in local optima. Most SLS algorithms therefore select with a fixed probability p (the so-called noise probability ) a random neighbor instead of the neighbor with the highest score. In this way they can escape local optima through random steps. Algorithm 1 sketches the main concept.
 Technically, SLS algorithms are Las Vegas algorithms , i.e. nondeterministic algorithms that output a correct solution, if they terminate. Because of the non-determinism, the run-time of a Las Vegas algorithm is a random variable. Since in practice one is not willing to wait forever, SLS algo-rithms are usually implemented to stop after a certain max-imum runtime (the so called cutoff time ) and output  X  X o solution found X . This yields a Monte Carlo algorithm , i.e. Algorithm 1 A framework for typical Stochastic Local Search Algorithms. procedure SLSearch( p ) end procedure a non-deterministic algorithm which might with a certain probability output a wrong result. Sometimes the aver-age runtime of an SLS algorithm on a specific set of prob-lems can be improved by selecting a comparably low cutoff time and using frequent restarts (Gomes et al., 1998; Hoos, 1998).
 When designing an SLS algorithm for k-term DNF Learn-ing, one has to decide about a suitable candidate space first. Using the space of k-partitions, just as with the exhaustive search algorithm outlined in section 2 seems to be an ob-vious choice. Unfortunately, calculating the neighboring formulae for a given candidate in k-partition space is a rel-atively time consuming task, because it requires the com-putation of two lgg s per neighbor. From our experiments (R  X  uckert, 2002) it seems to be more time-efficient to use k-term DNF formulae as candidates and to add or remove literals to generate the neighboring candidates. A reason-able choice for the global scoring function is the number of positive and negative examples that are misclassified by the current formula: score x violated by S } X  X  x  X  Neg | x satisfied by S }| . Obvi-ously, a candidate is a solution, if its score is zero. We are therefore aiming for minimal, not maximal score.
 Another important design issue for SLS algorithms is the choice of the neighborhood relation and the decision rule. The decision rule specifies which of the neighbors is cho-sen as the next candidate. A straightforward decision rule for k-term DNF learning SLS algorithms could evaluate all formulae that differ from the current candidate by one lit-eral and choose the neighboring formula with the lowest score. As it turns out, this approach is not very effective (R  X  uckert, 2002). In the following we present a more target-driven decision process to boost the search.
 The main idea is to concentrate on those changes that will correct the misclassification of at least one misclassified ex-ample. Assume p is an uncovered positive example. Thus, Algorithm 2 An SLS algorithm for k-term DNF learning. procedure SLSearch( k , maxSteps , p end procedure the current candidate formula c is obviously too specific: we have to remove at least one literal in order to satisfy p . Of course it does not make sense to modify a random term in c , because one might then affect a large number of currently correctly classified examples. A more sensible strategy would generalize the term t in c that differs in the smallest number of literals from p . One can then evaluate the formulae that differ in one literal in t as neighbors and choose that neighbor with the lowest score.
 Similar considerations can be made for adding literals: as-sume n is a covered negative example. Then the current formula is obviously too general. Let t be the term that covers n . We have to add a literal to t in order to make uncovered. Again we can evaluate generate a set of neigh-bors by adding one literal to t and then choose that neigh-bor whose score is lowest. This consideration leads to a decision rule and a neighborhood relation for the final al-gorithm, that use as much information as possible to guide the search: the decision rule first selects a random misclas-sified example e . If e is an uncovered positive example, the algorithm performs a generalization step as explained above; if e is a covered negative example, it performs a specialization step. Of course, this algorithm can get stuck in a local optimum quite quickly. It makes sense to re-place each decision step with a random choice from time to time to escape those local optima. There are two decisions to be made during a generalization step and one decision for the specialization step. Thus, we have three different places to perform a random instead of an informed deci-sion with certain probabilities. Algorithm 2 sketches the idea. Note that k is a fixed input parameter. However, the algorithm can easily be extended to solving the DNF minimization problem with varying values of k (usually by adding branch-and-bound techniques). For noisy and in-consistent data sets, the algorithm returns the formula that misclassifies as few instances as possible. This allows for an easy extension to noisy data. In this section we will empirically evaluate the performance of the SLS algorithm. For the purpose of this paper we are only concerned with compression instead of prediction: we aim at finding a compact representation of the information given in the training set, not necessarily a representation that performs well on unseen data. The characteristics of SLS with regard to prediction are the topic of a companion paper (R  X  uckert &amp; De Raedt, 2003).
 The experiments are realized in three steps. First, we com-pare our SLS algorithm to other SLS algorithms applied to k -term DNF learning. As  X  to the best of our knowledge  X  there exists no other published SLS algorithm that di-rectly works on the k -term DNF learning problem, we use a polynomial reduction of the k -term DNF problem to the well-known SAT problem. This in turn enables us to em-ploy the widest possible range of SLS algorithms for solv-ing the reduced k term DNF learning problem, including GSAT, WalkSat, etc. Secondly, we compare our SLS algo-rithm with three established rule learning systems. While separate-and-conquer does not guarantee to find the short-est possible formulae, it is a popular choice for settings in which runtime or predictive accuracy are more important than pure compression. Using the SLS algorithm we can quantify the overhead relative to the optimal formula size when using separate-and-conquer on hard problems taken from the phase transition region. Thirdly, to show the rel-evance of the k -term DNF learning problem, we apply our SLS algorithm to a challenging chess-endgame problem. This problem is directly relevant for practical applications, because the key challenge in endgame databases is com-pression. Compression in our framework corresponds to finding the minimum k -term DNF formula. 4.1. SLS on SAT-encoded k-term DNF Learning Kamath et al. present a reduction scheme to encode k-term DNF learning problems as satisfiability problems (SAT) (Kamath et al., 1992). Using this reduction one can encode k-term DNF learning problems as satisfiability problems and then use some of the many published SLS algorithms for SAT. In (R  X  uckert et al., 2002) we showed that Walk-SAT is able to solve a large fraction of hard SAT-encoded k-term DNF learning problems. This result can be used as a reference for the native SLS algorithm 2.
 We start with a survey of various established SLS algo-rithms for the satisfiability problem. For our experiments, we used the same three data sets as in (R  X  uckert et al., 2002). Each data set contains one hundred soluble problem in-stances taken from the hard region of the phase transition. The first test set was generated with | Pos | = | Neg | = 10 and n = 10 , the second with | Pos | = | Neg | = 20 and n and the third one with | Pos | = | Neg | = 30 and n =180. In our initial experiments we ran ten tries per problem instance and counted the number of successful tries (i.e. tries that found a solution) for each algorithm. We used the default cutoff values: for WalkSAT and Novelty each try was cut off after 100000 flips, for the GSAT based algorithms, we chose a cutoff value of 20 times the number of variables in the corresponding SAT problem and for native SLS we used a cutoff value of 50000 steps. Note that the noise level for native SLS in table 1 denotes the values for p p for each algorithm. As can be seen, only WalkSAT and the native SLS algorithm are able to find a significant part of the solutions. Similarly distinct results can be obtained for other noise settings and cutoff values.
 Comparing the performance of SLS algorithms is difficult: the performance of a given algorithm depends on the used data sets, the values for the noise probabilities, and the cutoff value. Furthermore, pure runtime is a bad indica-tor of an algorithm X  X  performance, because an algorithm with comparably low runtime might output  X  X o solution found X  for many more problem instances than an algorithm with comparably bad runtime. We therefore followed the methodology outlined in (Hoos, 1998) to take this trade-off into account. First of all, we investigate the runtime be-havior of WalkSAT and algorithm 2 for the problems in the third test set. We set the noise level to 0.25 for both algo-rithms. In figure 2 we plot P( X  X lgorithm needs less than steps to find a solution X ) against x for a typical problem instance in the third data set. The upper curve shows the distribution for the native SLS algorithm, the lower curve the distribution for WalkSAT. Both curves strongly resem-ble an exponential distribution. According to a  X  2 test the distribution of the native algorithm is indeed an exponen-tial distribution with an error probability of 0.15. As ex-plained in (Hoos, 1998) this also indicates that unlike for some other SLS algorithms a low cutoff value with frequent restarts will not boost the algorithm X  X  performance. The graph also shows that our native algorithm is able to find a larger fraction of solutions than WalkSAT when both algorithms use the same cutoff value. Unfortunately, the number of candidate-neighbor steps is not an adequate in-dicator for runtime, because WalkSAT X  X  steps are simpler than the ones of algorithm 2 and can be executed faster. We therefore identified the distribution of P( X  X lgorithm needs less than x milliseconds to find a solution X ) and compared the curves for both algorithms. Just as in figure 2 the re-sulting curves also resemble an exponential distribution. If the first curve dominates the second curve for every x value, then the expected runtime of the first algorithm is better than the runtime of the second algorithm for all cut-off values. If one does not consider the first hundred mil-liseconds (because algorithm performance is arbitrary in the setup phase), then algorithm 2 dominates WalkSAT in seventy eight of the one hundred problem instances in the test set. We also calculated the size of the area between the two curves as a measure of the average expected speedup that is gained when using the dominating algorithm instead of the dominated algorithm. We found that the native al-gorithm dominates in eighty eight cases, but the speedup (as measured by the area between the two curves) is of-ten rather small; in seventy seven cases the absolute value of the speedup is smaller than one hundred milliseconds. These results suggest that the native SLS algorithm com-pares favorably with the best available SLS algorithm for SAT-encoded k-term DNF learning problems. Another ad-vantage of the native SLS algorithm is that the encoding step can be left out. A SAT-encoded k-term DNF problem contains k  X  ( n  X  ( | Pos | + 1) + | Neg | ) + | Pos | clauses. For example, a SAT-encoded version of the first king-rook-king endgame problem in section 4.3 contains 96045 clauses and takes 54.7 MB of disk space, when saved in the .cnf format used by WalkSAT. Generating and processing this data can take considerable amounts of time. 4.2. Rule Learning on Hard k-term DNF Learning As outlined in section 2, the general k-term DNF learning problem is NP-complete. That means that complete ex-haustive search algorithms are not able to find solutions in a reasonable time frame for most problem instances. As demonstrated above, SLS algorithms can alleviate this dilemma at the cost of losing completeness. If low run-time is very important (such as for very large data sets) one is sometimes willing to also forego finding the shortest possible formula that is consistent with the examples. In such a setting one would accept finding a slightly longer-than-optimal formula in order to gain acceptable runtime. This is indeed the case for the classical rule learning set-ting, where high predictive accuracy and efficient runtime behavior is generally considered more important than high compression. Consequently, most rule learning algorithms utilize a separate-and-conquer approach (F  X  urnkranz, 1999) to find adequately short, but not necessarily optimally short formulae. In the following we investigate the degree of compression that can be achieved using this separate-and-conquer algorithm on hard k-term DNF learning problems taken from the phase transition region. This can be seen as a hard benchmark for both, the SLS algorithm and the rule learning algorithms. It also sheds some light on the in-herent compromise between compression on one side and accuracy and runtime on the other side.
 We examine the separate-and-conquer approach as im-plemented in popular rule learning algorithms: RIPPER extends the standard separate-and-conquer approach with incremental reduced error pruning and an iterated post-processing optimization step. PART avoids over-pruning by obtaining rules from partial decision trees. Addition-ally, we included C5.0, an improved version of the classic C4.5 rule learning algorithm. We generated ten sets of hard problem instances, all taken from the phase transition re-gion of the problem setting space. The first three test sets are the same ones as in section 4.1: we used the complete algorithm outlined in section 2 to remove those problems that are not soluble for the stated k . For the remaining seven test sets the complete algorithm requires huge com-putational resources; we therefore use the SLS algorithm outlined in section 3 to remove all supposedly insoluble problem instances until each test set contains one hundred problems that are soluble for the given k . 1 We apply each rule learning algorithm to each data set. Since we are not interested in high predictive accuracy but in high compression, we disable pruning for the RIP-PER algorithm. C5.0 and PART do not offer any option to disable pruning. Theoretically, they should be able to find even shorter formulae, because the formulae generated by these two algorithms do not classify all examples cor-rectly. We run C5.0 and PART with pruning, but addition-ally state the percentage of correctly classified examples in the results table. The average number of terms in the in-duced formulae and standard deviation are stated in table 2. PART and C5.0 generate formulae that are between 30% and 100% larger than necessary. RIPPER found consider-ably shorter formulae than C5.0 and PART. This might in-dicate that RIPPER X  X  iterated post-processing step  X  while being computationally not too demanding  X  can decrease the average size of the induced formula. The pure separate-and-conquer approach as employed by PART seems to be not very well suited for compression of hard random prob-lems. If, of course, the training set is sampled according to a more favorable distribution (e.g. the uniform distribu-tion), separate-and-conquer can work remarkably well. 4.3. King-Rook-King Chess Endgame In the previous sections we gave empirical evidence that SLS algorithms can be successfully applied to hard ran-dom k-term DNF learning problem instances. However, real world problems are not  X  X andom X . Instead, they of-ten feature an (unknown) inherent structure, which might hinder or prevent the successful application of SLS algo-rithms. In the following we examine, whether or not SLS algorithms can efficiently deal with structured real-world problems.
 The domain of chess endgames provides an ideal testbed for DNF minimization, because here we deal with noise-free datasets with discrete attributes only, and since we have complete domain knowledge we are more interested in compression than in predictivity. Finding a minimum theory for such endgame data was also a goal for previ-ous research in this area (Bain, 1994; Quinlan &amp; Cameron-Jones, 1995; Nalimov et al., 2000) and is of continuing interest (F  X  urnkranz, 2002). We decided to especially ex-amine the simplest chess endgame, King and Rook ver-sus King. In his PhD thesis Bain (Bain, 1994) studies the task of learning to predict the minimum number of moves required for a win by the Rook X  X  side. This problem is available from the UCI Machine Learning Repository (Blake &amp; Merz, 1998) and has been used as a benchmark, for instance in Quinlan X  X  evaluation of FOIL (Quinlan &amp; Cameron-Jones, 1995). Note that this data set is different from the easier data set for learning legality in the King and Rook versus King endgame.
 The problem is stated as a repetitive application of a learn-ing algorithm: from a database of all legal positions the al-gorithm learns all positions won in zero moves first. These positions are then removed from the database and the al-gorithm is subsequently used to learn positions won in one, two, three, etc. moves. This process is repeated until the learning algorithm separates positions won in sixteen moves from drawn positions. Originally, the problem is stated in a first-order representation. To make the problem setting suitable for our algorithm, we had to express the given chess situation as a truth value assignment. We de-cided to extract the most basic information from the given chess positions: the location of the chessmen, the distances between them and their position with regard to the two di-each of the two dimensions are in the range one to eight, we express positions and distances using 2  X  2  X  3  X  8 = 86 Boolean variables. The (symmetrical) distance to the two diagonals for the three chessmen requires 3  X  2  X  8 = 48 Boolean variables. Thus, we encode a chess situation in 96 + 48 = 142 variables.
 We ran the native SLS algorithm outlined in section 3 on the problem instances for the problems in the KRK endgame suite. Table 3 shows the results. As a comparison we also state Quinlan X  X  results with FOIL and Bain X  X  orig-inal results with GCWS (Bain, 1994). FOIL and GCWS are ILP systems and can therefore make use of background knowledge and built-in predicates. However, it turns out that, even though FOIL and GCWS use a much more ex-pressive representation language, they generate a larger set propositional algorithms we applied RIPPER, because it was able to find the smallest sets of rules in our preceding investigation. Additionally we evaluate PFOIL, a propo-sitional version of FOIL (Mooney, 1995), to get a com-parable result for a FOIL-based learning strategy. While PFOIL induces up to thirteen times more terms than nec-essary, RIPPER performs relatively well with up to three times as many terms as generated by the SLS algorithm. All in all, SLS clearly outperforms the other algorithms. We presented a novel stochastic local search algorithm for finding short formulae that are consistent with sets of posi-tive and negative examples. We evaluated this algorithm in comparison to SAT-based SLS algorithms and to traditional rule-learning approaches on hard problem instances taken from the phase transition region. We finally showed that the algorithm can be applied successfully to a real world problem. These results reveal some possible routes for fur-ther research. First of all, one can investigate SLS on other learning settings than k-term DNF learning. (Chisholm &amp; Tadepalli, 2002) present some encouraging results for SLS in general rule learning settings. Second, we are cur-rently evaluating the compression of separate-and-conquer-approaches on real-world problems, instead of artificially generated ones. Third, one could extend and improve the presented algorithm in various directions, such as adding noise handling or multi-valued and continuous attributes.
