 Tamil is a Dravidian language spoken predominantly by a significant population in the southern region of India. The language is written using the  X  X amil script X  and is written from left to right. In this article, we address various practical aspects related to recog-nizing online, handwritten, isolated Tamil words. As is evident from the recent litera-ture, there has been very little work exploring the problem of online word recognition in Indian languages. The earliest work on online Tamil character recognition was that of Sundaresan and Keerthi [1999]. They evaluated the performance of angle, Fourier, and wavelet features on a neural network classifier. Amongst these features, they show that wavelet features are quite effective, as they retain both intra-class similarity and inter-class differences. A combination of time-domain and frequency-domain features has been attempted with a hidden Markov model (HMM) classifier [Toselli et al. 2007]. A similar set of feature combinations was recently tested with an elastic matching ap-proach [Prasanth et al. 2007]. For writer-dependent, online, handwriting recognition of isolated Tamil characters, a comparative study of elastic matching schemes using dynamic time warping (DTW) has been presented [Joshi et al. 2004]. Three different features are considered, namely, preprocessed x -y coordinates, quantized slope values, and dominant point coordinates. However, the writer-dependent setup, in a way, limits the experimental validation. A subspace-based classification approach has been pro-posed [Deepu et al. 2004]. Principal component analysis (PCA) is applied separately to feature vectors extracted from the training samples of each class. The subspace formed by the first few eigenvectors is considered to represent the model for that class. During recognition, the test sample is projected onto each subspace, and the class cor-responding to the one that is closest is declared as the recognition result. A similar methodology of class-specific subspace classification has been adopted in Sundaram and Ramakrishnan [2008, 2009] using the two-dimensional PCA (2DPCA) technique. Different strategies for prototype selection for recognizing handwritten characters of Tamil script are investigated in Raghavendra et al. [2005]. In particular, for modeling the differences in the complexity of different character classes, a prototype set growing algorithm is proposed with DTW+nearest neighbor as the classifier. A method of proto-type learning is discussed in Niels and Vuurpijl [2005] to speed up the recognition with the DTW framework. Swethalakshmi et al. [2007] propose a set of offline-like features to capture information about both the positional and structural (shape) characteris-tics of the handwritten unit. The obtained features are then fed to a support vector machine (SVM) for classifying the pattern. In Aparna et al. [2004], unique strokes in the script are manually identified, and each stroke is represented as a string of shape features. The test stroke is compared with the database of such strings using the pro-posed flexible string matching algorithm. The sequence of stroke labels is recognized as a character using a finite-state automaton (FSA). Rule-based approaches, as de-scribed in Swethalakshmi et al. [2007] and Aparna et al. [2004], are too script specific and may not generalize well to different writing styles. Kiran et al. [2010] provide a comparative study of statistical DTW and HMM on Tamil symbols.

Despite the different classification methodologies being addressed for the problem of isolated online Tamil character recognition, confusion between symbols does arise that affect the performance of handwriting recognition. This is primarily due to the fact that the techniques rely on decisions made by a single classifier operating on fea-tures at a global level. Though it has been acknowledged in state-of-the-art literature that the confusions between online handwritten Tamil symbols arise primarily as a result of a high degree of structural similarity, no attempts have been made so far to specifically come up with strategies of resolving this. This is an important area to look at, considering the fact that the problem of writer-independent recognition is quite complex to be solved by a single classifier alone [Vuurpijl et al. 2003].
In contrast to isolated online Tamil symbol recognition, there are very few works in the literature [Bharath and Madhvanath 2007, 2012] dedicated to the recognition of online Tamil words. In Bharath and Madhvanath [2007], each symbol is modeled using a left-to-right HMM. Inter-symbol pen-up strokes were modeled explicitly us-ing two-state left-to-right HMMs to capture the relative positions between symbols in the word context. Independently-built symbol models and inter-symbol pen-up stroke models were concatenated to form the word models. The approach is segmentation free and is tested with lexicons of varying sizes. An extension to this work is reported in Bharath and Madhvanath [2012]. Here, a bag-of-symbols (BoS) representation of the handwritten word is proposed to address the issue of symbol order variations within and across characters.
 Both the lexicon-driven and lexicon-free approaches proposed in Bharath and Madhvanath [2012] for recognizing the dataset containing only 85 distinct Tamil words and 70 distinct Hindi words are limited to using a lexicon for improving accuracy. How-ever, for real-life applications, one may encounter out-of-vocabulary words. Hence, it is important to come up with an approach that can well generalize to such scenarios. The main contribution of this article lies in integrating a postprocessing module, with the aim of providing a complete solution to the recognition problem (Figure 1). The idea is to enhance the recognition of online Tamil words beyond that provided by the primary classifier. The postprocessing techniques proposed in this work, namely, incor-poration of language models and disambiguation of confused symbols have not been adequately explored in the literature for the recognition of online Indic scripts.
The use of bigram language models has been proposed in two independent and dis-tinct ways. The symbol-level bigram model has been applied in the traditional Viterbi lattice to obtain the output sequence of labels with the best joint posterior probability. On the other hand, the bigram model at the character level is employed without the use of Viterbi selection; whenever a symbol is recognized, the character bigram statis-tics is used to restrict the search space for the next symbol to a subset of the total number of recognition classes.

Researchers in recent literature attribute a part of their recognition errors to the presence of symbols that appear visually similar, which confuse the classifier. Classi-fiers usually work on features at the global level, and so at times fail to capture the subtle differences between these symbols. One way to address this issue is to incorpo-rate a framework that employs class-specific features and a bank of expert classifiers to improve the recognition of frequently-confused characters. However, to come up with such features, one needs to identify the parts of the trace that can well differentiate between two or more similar-looking characters. Accordingly, we propose a novel tech-nique for learning the fine nuances of the confused characters using a dynamic time-warping scheme. Each expert works on the discriminative part of the trace thus learnt to improve the recognition of the handwriting system. Thus, if the label assigned to an input pattern (after the language model) belongs to one of the frequently-confused symbols, it is reevaluated by the appropriate set of expert classifiers. In other words, the experts aim to correct wrong decisions, if any, from the language model block. The resulting postprocessing framework (comprising the integration of one of the two dis-tinct language models at a time with disambiguation of confused symbols by experts) improves recognition results at the word level. The original Tamil script comprises 12 pure vowels, 18 pure consonants, and a special character /ah/ . The pure consonants get modified by each of the 12 vowels to generate a total of 18  X  12 = 216 consonant-vowel (CV) combinations. These add up to a total of 247 Tamil characters. In this work, however, we have included five additional pure consonants (used to represent the consonants borrowed from Sanskrit) [Aparna and Ramakrishnan 2002] and another special symbol /sri/. These consonants contribute an additional 5  X  12 = 60 CV combinations. The complete 313 character set consists of 276 CV combinations, 12 vowels, 23 pure consonants, and two special characters [Nethravathi et al. 2010]. All of these characters are supported by Unicode.
Analysis of the complete character set indicates that the characters may appear in one of the forms listed as follows. Based on these observations, we come up with a strategy to choose the minimum number of entities/ symbols for recognizing the 313 characters, taking into account the fact that many of the symbols may be written with a single or multiple strokes. (1) Pure consonants modified by the inherent vowel /a/ are referred to as  X  X ase (2) The vowel modifier for /A/ , written as , appears to the right of the base conso-(3) In the CV combinations of vowels /i/ ,and /I/ , the vowel modifier overlaps (4) When the vowel /u/ or /U/ combines with any one of 18 of the 23 pure (5) In the CV combinations of vowels /e/ , /E/ ,and /ai/ , the corresponding (6) CV combinations of vowels /o/ , /O/ ,and /au/ comprise two distinct (7) The vowel /au/ comprises two distinct entities-/o/ and /La/ that have
With this analysis, it is found that the set of 155 distinct classes (henceforth referred to in this work as  X  X ymbols X ) is sufficient to form (and hence recognize) all the 313 characters considered. The 155 distinct symbols comprise as follows. (1) 11 pure vowels (excluding /au/ ). (2) 23 pure consonants. (3) 23 base consonants. (4) 23 CV combinations of /i/ . (5) 23 CV combinations of /I/ . (6) 23 CV combinations of /u/ . (7) 23 CV combinations of /U/ . (8) 6 Additional symbols ( ( VM of /A/ ), ( VM of /e/ ), ( VM of /E/ ), ( VM of It is to be noted that a Tamil character may consist of at most three symbols. We refer to characters comprising more than one symbol as  X  X ulti-symbol X  in this work. In this study, even though we deal with the recognition of handwritten word data collected by us, the primary as well as the expert classifiers have been trained using isolated character data from an external database. Based on the symbol set described in the earlier section, Hewlett Packard Labs (HP Labs) India in the International Workshop on Frontiers in Handwriting Recognition (IWFHR) 2006 released a corpus comprising isolated online Tamil symbols for research [Madhvanath and Lucas 2006]. We refer to this dataset as the  X  X WFHR Tamil symbol set X  in this work. We used the training set of this corpus for training our primary clas-sifier. This classifier is then applied to the test set of this corpus (comprising 26,926 samples) to construct the confusion matrix and to pick the sets of frequently confused symbols for disambiguation. Thereafter, we revert to the training samples of each con-fused set to learn the discriminative regions of their traces and to build their expert classifiers. Further details on the expert classifiers are systematically described in Sections 7.1, 7.2, 7.3, and 7.4.
 The present work is an outcome of an ongoing funded project from the Technology Development for Indian Languages (TDIL) program of the Ministry of Information Technology of the Government of India. The main agenda of the project is to create a writer-independent recognition framework suitable for form-filling applications such as encumbrance certification and census data collection. Since every such form in-volves proper name and address fields, the requirement is also to look for open vocabu-lary recognition. Isolated Tamil words have been collected using a custom application running on a tablet PC. We have ensured that all the writers who participated in the data collection activity are native Tamil speakers who currently write in that lan-guage at least irregularly. Accordingly, we came across different popular writing styles for Tamil symbols. Moreover, the participants were provided with a graphics interface with large rectangular boxes and were prompted to write Tamil words with minimal constraints, one in each box in the form. No restrictions were placed on the number of strokes, shape of the symbols, and direction of the constituent strokes. Figure 2 present a few sample words from our database. This database is available for research purposes from our lab server. 2
High school and college students from many educational institutions in the Indian state of Tamil Nadu contributed in building the word database of size 15,000, compris-ing 2,000 distinct words. This of words has been chosen to cover all the 155 symbols of the Tamil script. The collected word samples are stored using the UNIPEN v1.0 for-mat [Guyon et al. 1994]. The collected words consist of 80,098 labeled Tamil symbols. We use the labeled symbols as the ground truth for computing the recognition accura-cies. The 15,000-word database contains several instances of all the 2,000 word classes. Each word class has seven to eight instances in the test set. The word set excludes sym-bols written with delayed, overwritten, and extraneous strokes and cursively-written words. The bar distribution representing the frequency of each the 155 symbols in the word dataset is shown in Table I.

We reemphasize that (i) the training data for the primary and the expert classifiers and (ii) the information on confusion sets are all derived from the IWFHR Tamil sym-bol set which is distinct from the word dataset that we have collected. The latter (word) data is only used as test data. In this article, we extend the work presented in Sundaram and Ramakrishnan [2013] and present a full-fledged system to recognize online, handwritten, isolated Tamil words. We first segment an online Tamil word to its constituent symbols in a two-step process. The resulting segments are recognized by the primary classifier to generate valid symbol labels, which, in turn, are concatenated to generate the output word. Owing to the good generalization capability of the SVM classifier to unseen test data, we adopt it as the primary classifier in this work.

Let the input word W be segmented to p symbols, { S i } p a sequence of x -y coordinates with pen-up and pen-down events. A preprocessing step, applied prior to recognition, compensates for variations in time, scale, and velocity. It comprises three steps: (1) smoothing, (2) normalization, (3) resampling [Joshi et al. 2004; Deepu et al. 2004]. The final result of preprocessing is a new sequence of points { x , y i } n i = 1 regularly spaced in arc length. A feature vector x is constructed from this sequence and fed to the SVM classifier. We experimented with varying numbers of resampled points and observed that n 60 is quite sufficient in capturing the shape of the character, including points of high curvature. The vector x is referred to as the  X  X oncatenated x -y coordinates X  in this work.
The performance of the SVM classifier is largely dependent on the selection of the parameters. The training data of the IWFHR symbol set are employed to obtain the model parameters. We have employed the LIB-SVM software [Chang and Lin 2011] with the radial basis function (RBF) chosen as the kernel. The type of kernel and the corresponding parameters have been set optimally after performing fivefold cross-validation experiments.

The primary SVM classifier, fed with concatenated x -y coordinates of the prepro-cessed segmented symbols, is found to be quite effective for the task of segmentation [Sundaram and Ramakrishnan 2010; 2013]. However, the classifier is not sufficiently robust to effectively distinguish between similar-looking symbols. With the view of improving the performance of symbol recognition beyond that given by the primary classifier, we propose in the remainder of this article, two postprocessing approaches, namely, bigram language models and confused-character disambiguation.

Two distinct, independent bigram models have been proposed in this work. These have been described in Sections 6 and 8, respectively. The reevaluation techniques, aimed at correcting the decisions made by the language model are discussed in Section 7. The performance of the proposed postprocessing schemes on a set of 15,000 words is described in Section 9. Section 10 summarizes the article. The goal of a language model is to exploit the linguistic regularities and characteris-tics in the recognition framework. There are quite a few works in the current litera-ture on the use of language models for recognition of handwriting in non-Indic scripts [Li and Tan 2004a, 2004b; Marti and Bunke 2000; Perraud et al. 2003; Quiniou and Anquetil 2006; Quiniou et al. 2005; Vinciarelli et al. 2004; Zimmermann and Bunke 2004]. However, in the area of online recognition of Indic scripts, there is hardly any work incorporating the use of language models [Bharath and Madhvanath 2009].
An extensive Unicode text corpus comprising 1.5 million Tamil words is utilized for generating the frequency count of each of the 155 symbols. The text has been derived from the Project Madurai site 3 and the EMILLE Beta Version text corpus. pus essentially is a collection of sentences, wherein each word comprises a sequence of Tamil characters. The Unicode corpus was first transformed to a corpus of Tamil symbols by inverse mapping from the Unicode sequence of Tamil characters to the cor-responding symbol sequences. This is essential, since the symbol order and the order of the Unicodes are different for different sets of CV combinations, as shown in Table II. We consider the statistics of the symbols obtained from this corpus to be representa-tive of the script. Moreover, a multi-symbol character may be composed of as many as three symbols. From the corpus, we derive the following statistics.  X  N T : Total number of occurrences of all the symbols.  X  N s ( X  i ) : Total number of occurrences of symbol  X  i .  X  N ss ( X  i ,  X  j ) : Number of occurrences of the symbol pair ( X   X  N cs ( c i ,  X  j ) : Number of occurrences of symbol  X  j  X  N sc ( X  i , c j ) : Number of occurrences of the multi-symbol character c  X  N cc ( c i , c j ) : Number of occurrences of the multi-symbol character pair ( c Table III presents illustrations for each of these pairs.

A specific word W can be interpreted as a realization of a discrete stochastic pro-cess. Two different models are proposed to probabilistically describe the interdepen-dencies of symbols in W , namely, (1) n-gram language models and (2) n-class models. As such, an n-gram/n-class model is interpreted as a Markovian model of order n-1. In the present work, we consider n=2, namely, the bigram and biclass models. Given an online Tamil word W , recognized as {  X  i } p i = (assuming a full order Markov process) as However, it becomes very unrealistic and demanding to obtain statistics for higher-order Markovian processes. In our work, we have considered only the first-order Markovian dependency.

The simplest language model called the  X  X nigram model X  treats the symbols of a word to be independent of each other. However, the actual probability of occurrence of a symbol, as determined from the corpus, is accounted for. Using this model, we can write where
In the bigram model, the probability of occurrence of a symbol in a word depends only on the immediately-preceding symbol. This model incorporates a first-order Markovian dependency, and accordingly, we can rewrite the probability of the word as where
It is quite possible for a symbol or pair of symbols in the word to be recognized to have never occurred in the corpus [Marti and Bunke 2000]. In order to incorporate a nonzero probability to the bigram statistics for such symbols, we smooth the language model. The idea is to reduce the probabilities of bigrams occurring in the corpus and redistribute this mass of probabilities among bigrams never encountered. One simple smoothing technique is to pretend each bigram occurs once more than it actually does. This is accomplished by the following updation.
 Biclass models merge the symbols into groups [Perraud et al. 2003]. In this section, we use the words  X  X roup X  and  X  X lass X  interchangeably. In order to form meaningful classes, we club symbols that are linguistically similar and create the eight groups ( G as listed in Table IV. It can be observed that the groups occur with varying frequencies in the text corpus.

We consider the first-order Markovian dependency between the classes (groups), wherein a Tamil symbol is assigned to exactly one group. Dedicated SVM classifiers are designed to compute the probability estimate of the symbol placed in a specific group. Accordingly, one can write for a biclass model, G P ( X  i / G  X  i , x ) corresponds to the probability estimate (returned by the SVM classifier) vantage of biclass models is their compactness in representation. Because symbols are combined in groups, the number of biclass probabilities is lower than that of bigrams. Let X represent the sequence of feature vectors for an online handwritten word con-sisting of p symbol patterns { S i } p i = 1 . The aim of word recognition is to find the most plausible sequence of symbols  X  W for X . W represents the set of candidate symbol sequences for X . From Bayes rule, we can write Here, p ( X | W ) represents the probability estimate of the handwritten word for the given candidate sequence W . p ( W ) is the prior probability of W derived from the language model. The denominator p ( X ) is independent of W and hence is ignored. Thus, We use the decimal logarithmic representation for the various probabilities and write The optimal sequence of symbols for the handwritten word can be traced using the well-known Viterbi algorithm [Rabiner and Juang 1986]. Assuming context-free, inde-pendent shape recognition for each pattern S i by the classifier, we can write The unigram (Eqn. 3) and the bigram models (Eqn. 5) are used to provide the estimates for P ( W ) .

We now describe the structure of the word recognition system. The preprocessed x -y coordinates (feature vector x ) of every symbol of the segmented word are input to the SVM classifier, which outputs a list of M (chosen as four in this work) candidate sym-bols ordered by their probability estimates. A word graph is then created with these choices. In that graph, the ( i , j ) th node represents the probability estimate P ( x the j th recognized symbol for i th segment S i . In the case of bigram models, the edges between the nodes ( i , j ) to ( i + 1, l ) represents P ( X  given by the prior probability P ( X  i + 1 l ) in the corpus. Let G signed for the j th recognized symbol for the i th segment. Then, for the case of biclass tation of a pair of nodes of a word graph for the three different models. In this section, we address an issue that does, at times, lead to an erroneous sym-bol with the bigram model. Let the optimal symbol sequence of the word bigram model be defined as We consider the actual symbol sequence of the online Tamil word W as If the word  X  W differs from W in exactly one position, say j , then the bigram language model favors  X   X  j to  X  j whenever In such cases, total dependence only on the bigram language model unduly favors one of the two confused symbols, given the same context. We need to rectify the symbol to  X  j . One could consider resolving the confusion by extracting a set of discriminative features from regions of the trace in the symbols  X   X  j and  X  reevaluate the label of x S j .

We illustrate here one such situation where reevaluation is necessitated, since lan-guage models cannot, by themselves, deliver. In Tamil, a verb can be modified by forms of tense, number, gender, and person. Each verb results in a new word after each of these morphological changes. Considering verbs modified with gender, the ones asso-ciated with masculine gender end with the symbol /n/ , while those with feminine gender end with /L/ . Examples of such words include ( (he came), (she came)) and ( (he comes), (she comes)). Note that the words in each pair differ only by the symbols /n/ and /L/ at the last position. Inter-estingly, the symbols /n/ and /L/ get confused with each other by the SVM classifier. All the remaining symbols of the word being the same, from Eqn. (16), the bigram model favors the more likely symbol of the confusion set ( , )atthelast position. Thus, at times, the wrong symbol may be preferred to the correct one, leading to an error. Therefore, strategies are invoked to disambiguate ( , ) to output the right symbol.

We now propose a methodology for reducing the confusion between such symbols. In order to find the possible confusions, we run the SVM classifier across the 26,936 test samples of the IWFHR Tamil symbol set. A few of the similar-looking pairs with their frequencies of confusion and their recognition accuracies from the primary SVM classifier are listed in Table V.

Let C represent the confusion matrix of size 155  X  155. The term c to the number of samples of symbol  X  i wrongly-classified as  X  Accordingly, for a symbol pair ( X  i ,  X  j ) , we can write the number of confusions as For a given symbol  X  i , the set of symbols to which it gets frequently confused is given by We choose the threshold  X  so that only confusion sets having a frequency above 3% in the confusion matrix are considered for disambiguation. We denote the set of all symbols that possibly get confused as Visual inspection of the confused symbols indicates that they appear different in some critical parts of the trace, while retaining certain common structures. For example, the confused symbols /la/ and /va/ differ mainly in the middle portion of the online trace. The confusion pair /ka/ and /cu/ appear structurally different towards the end of the trace.

In this work, we address the disambiguation of confusion pairs by proposing a set of dedicated classifiers referred to as  X  X xperts X . Figure 4 presents the block diagram of an expert. We design independent expert networks for each confusion set. Each ex-pert consists of three blocks: (a) discriminative region extractor, (b) feature extractor, and (c) SVM classifier. Let ( s 1 , s 2 ) denote a confusion pair as obtained from the con-fusion matrix C . Then, for each confusion ( s 1 , s 2 ) , the corresponding expert extracts the specific discriminative region ( s 1 , s 2 ) from the input symbol pattern. This region corresponds to those parts of the trace that capture the finer structural nuances in s and s 2 . The feature extractor extracts features from ( s the SVM classifier for disambiguation. In this section, we propose a novel methodology to automatically locate the discrimina-tive parts of strokes in confused pairs. In the domain of offline handwriting recognition, extraction of the distinctive image regions in confused patterns have been addressed [Leung and Leung 2010; Rahman and Fairhurst 1997; Xu et al. 2010]. However, in the context of online recognition of Indic scripts, such attempts have not been made. In this article, we exploit the available temporal information of the trace for learning the finer parts that distinguish the confused symbols. Accordingly, let ( s sent a confusion symbol pair. We use the training patterns of s Tamil symbol set to learn the discriminative parts of the online trace ( s and N s 2 Tr correspond to the number of training data for s such pattern is preprocessed (using the steps presented in Section 5) and described by { ( x 1 , y 1 ) , ( x 2 , y 2 ) ,...., ( x n P , y n P [2004]) to learn the structural differences between the traces of confused pairs s s . Essentially, we elastically match each temporal sequence in the training set N against each of the sequences in N s 2 Tr . This in turn gives rise to N DTW cost matrices with corresponding optimal warping paths.
 fusion pair s 1 and s 2 . The ( k , l ) th element in the cost matrix describes the degree of dissimilarity d ( k , l ) between these points.
The optimal path W  X  in each cost matrix has some sections with low values of d ( k , l ) corresponding to similar regions in the confused pair of symbols and other section or sections with high values corresponding to the discriminative parts. We utilize this property to obtain the discriminative region ( s 1 , s 2 ) .

We generate a histogram to accumulate the pen positions of the trace contributing to native distance histogram X  (DTW-DDH)) has n bins. For a DTW match between a pair of training patterns from s 1 and s 2 , we first record the maximum dissimilarity cost obtained in the optimal path W  X  . Thereafter, we compare the remaining costs along W  X  to this value. The indices (in W  X  ) that have costs greater than a threshold T voted in the DTW-DDH. This procedure is repeated for each of the N matrices. The net result is an accumulation of votes for the sample indices. Subse-quent to the construction of the DTW-DDH, we analyze the peaks. The peaks in the histogram correspond to the repeated occurrence of higher costs in the different warp-ing paths W  X  and denote the possible regions for discriminating the symbols ( s We present the pseudocode for construction of the DTW-DDH in Algorithm 1. We set T d to 90% of the maximum dissimilarity cost along a given warping path This value is sufficient for identifying the region of finer nuances that discriminate the confusion pairs ( s 1 , s 2 ). The threshold is adaptive and varies with the maximum dissimilarity cost obtained in each of the N s 1 Tr  X  N s the DTW-DDH obtained from the training samples of the confusion set ( /la/ , /va/ ). The sample index corresponding to the bin having the largest number of votes in the DTW-DDH gives rise to the maximum peak. Around this peak, a window of samples is considered to describe the part of trace distinguishing the confusion pair s and s 2 . This, in turn, forms the discriminative region (DR) ( s
It is to be noted that owing to different styles of writing, different transients occur at the start and/or end of the online trace. This in turn creates peaks at the start and/or end of the DTW-DDH. Such peaks correspond to the votes of the first and last sample indices in the DTW-DDH and are not included for analysis. From the DTW-DDH of the symbols /la/ and /va/ , we observe that the main peak occurs in the middle region, thereby indicating that the discriminative region lies in the middle part of the trace.

For a given confusion pair ( s 1 , s 2 ) , we now address the issue of selecting the window size for extracting the discriminative region ( s 1 , s 2 DTW-DDH of a confusion pair ( s 1 , s 2 ) . The size of the window is automatically decided by the set of sample indices around the main peak that have votes above 30%. From the previous discussion, it is evident that each confusion pair ( s criminative region ( s 1 , s 2 ) that can be obtained from its DTW-DDH. The concatenated x -y coordinates in the region ( s 1 , s 2 ) are used as the features for disambiguating the confused pairs s 1 and s 2 .

Let the size of the window used for extracting the ( s 1 , s DDH be denoted by L . One can then represent the part of trace captured in ( s 1 , s 2 ) by { ( x b , y b ) , ( x b + 1 , y b + 1 ) ,...., ( x 2  X  L is constructed from this sequence and fed to the expert SVM classifier for disambiguation. Here, ( x b , y b ) is the first sample index of the DR for the given confusion pair. Several experts can exist for a given symbol  X  i . Hence, in order to disambiguate a pat-tern recognized as symbol  X  i , it is passed through a set (or a bank) of expert classifiers. In fact, the number of experts in the bank corresponds to the number of symbols in i (defined in Section 7.1) that can be possibly confused with  X  confusion pair extracts the features from its discriminative region and passes it to a trained SVM classifier. The recognition scores from each of the expert SVMs together with their labels are noted. Subsequently, based on the best recognition probability es-timate obtained, we make a decision to choose its corresponding symbol as the reeval-uated output for the pattern.
 For a confusion pair ( s 1 , s 2 ) , we use their corresponding training patterns from the IWFHR Tamil symbol set to learn the expert SVM. The features are derived from the discriminative parts of the online trace ( s 1 , s 2 ) (as described in the previous sec-tion). The RBF kernel is used in our experimentation. We have employed the LIB-SVM software [Chang and Lin 2011] for learning the SVM model parameters. The kernel and the corresponding parameters are optimally set after performing fivefold cross-validation experiments on the training patterns.
 As explained in Section 3, the CV combinations of the vowels /A/ , /e/ , /E/ , and /ai/ are made up of two distinct symbols, and those of /o/ , /O/ ,and /au/ are written with three distinct symbols. Thus, a multi-symbol Tamil character can comprise up to three distinct symbols. We consider the symbols in a Tamil word to be drawn from the finite vocabulary V ={  X  k } 155 k = has been segmented into its constituent symbols [Sundaram and Ramakrishnan 2010, 2013].

In this section, we propose ways in which context information aids in reducing the number of symbol classes to be tested for an input pattern. We describe the con-textual information in terms of the positional and bigram statistics derived at the character level. A bigram at the level of characters is equivalent to a higher-order lan-guage model, where the context deciding the occurrence probability of a symbol can involve up to five previous symbols, thus essentially constituting a six-gram model at the symbol level.

It is important to clarify the distinction between the use of the bigram model at the character level (proposed in this section) and that at the symbol level (described in Section 6). The bigram language model at the symbol level is applied post recognition to choose the maximum probability path (word) among the multiple, possible paths in the Viterbi trellis. On the other hand, the language model at the character level is applied prior to recognition to eliminate some of the symbols from being considered as probable for the segmented symbol pattern. The set of possible labels for a sym-bol depends on its contextual history (described in terms of the recognized labels of past symbols that form a Tamil character). Here, at every position of the word, it is assumed that the recognition up to the previous symbol (position) is correct. Accord-ingly, the current input symbol is recognized against only a subset of the 155 symbols. By considering the history in terms of the character, the probability of all the sym-bols that have zero bigram probability are removed from the search space for the test pattern under consideration. Owing to the fact that a Tamil character may comprise up to three symbols, the search space is adaptive based on the recognized history of each symbol. In contrast to word recognition using the symbol-level bigram models, the bigram model at the character level does not rely on the optimal Viterbi path for obtaining the output word. The proposed character-level bigram approach is quite analogous to the prefix tree concept in the field of computer science, hence the name prefix-tree-based language models .  X  Let us look at the first symbol position of a word. Now, language constraints specify  X  As we move to symbol positions beyond the first, the complete past context is always  X  For a pattern S p , occurring at the end of a word, we can further reduce the search A symbol under consideration will only belong to one of the previous contexts, and accordingly, the reduced search space described by the set L Thus, if j th contextual information is applicable for the i th symbol, then one can write We now illustrate the application of the prefix-tree language model for the recognition of a Tamil word /yOkam/ (refer to Table VI) in a step-by-step manner using the prefix tree.  X  The pattern at the start of the word is tested against the 87 symbols in L
SVM classifier, and the most probable symbol (VM of vowel /E/ ) is assigned to it.  X  To recognize the second pattern, we use its contextual information of the previous recognized symbol . The symbol is a vowel modifier of /E/ . In fact, it corre-sponds to the the initial part of a two-symbol CV combination of /E/ . In order to form a complete character (from context 2), we constrain the current pattern to be recognized to the set of 15 base consonants that can follow . Accordingly, the SVM returns the symbol /ya/ as the most probable for this pattern.  X  We constrain the third pattern to be recognized only against those symbols that can follow the two-symbol character (context 3). From the set of 16 symbols, the
SVM returns as the most probable symbol for this pattern. Though it is not a complete character, we make use of the prior knowledge that this symbol always follows a base consonant and associate it to the previous character to form another valid character /yO/ (consonant modified by the vowel ).  X  To recognize the fourth pattern, we rely on the contextual prior information of its preceding character (context 4). Thus, we constrain the pattern to be rec-ognized only against the 15 symbols that can follow this three-symbol character.
Accordingly, the SVM returns symbol /ka/ as the most probable label for this pattern. The recognized symbol is a character by itself.  X  The prior context for the last pattern is the single symbol . Accordingly, we con-strain this pattern to be recognized against the subset of 76 symbols and obtain /m/ as the most probable label.
 For comparison, Table VII illustrates the reduction in the search space for each symbol pattern by considering only the previous symbol label. It is interesting to observe that the number of symbols to be tested is higher than that obtained using the context of the previous character label (see Table VI). In this section, we evaluate the performance of the proposed postprocessing system comprising language modeling and confused-character disambiguation (reevaluation). For ease of understanding the experimental results, we hereinafter refer to the recog-nition framework described in Sundaram and Ramakrishnan [2013] (without the postprocessing module) as the baseline system . In order to set up the biclass language model (described in Section 6.2), an SVM classifier is separately trained, specific to the symbols in each of the groups G Table VIII presents the details of the designed classifiers with their recognition perfor-mance on the IWFHR Tamil symbol test set.

In the experiments outlined in this section, we compare the performance of the n-gram and class-based language models with and without the reevaluation module. In order to incorporate the influence of linguistic knowledge, we weighted the second term of Eqn. (12) by a factor  X  (ranging between 0 and 1) as presented here.  X  = 0 corresponds to the baseline system, while  X  = 1 provides an equal weighting to both the recognition and the language model. Figure 6 presents the symbol recognition rate for values of  X  from 0 to 1 in steps of 0.1 on a validation set of 250 words. The three curves (corresponding to unigram, biclass, and bigram language models) show their behavior: the optimal value of  X  is 0.3 for the unigram and the bigram models and 0.4 for the biclass model. On average, irrespective of  X  , the bigram model outperforms the unigram model by 2%. Furthermore, we can see the importance of this weight, since the symbol recognition rate is 94.3 % with the bigram model when  X  it is 95.5 % with the optimal value of  X  . One can also observe that the biclass model performs lower than that of the bigram model but better than the baseline system and unigram model. An improvement of up to 2% is achieved with respect to the baseline system.

The symbol recognition accuracies for each model are obtained across the word database (Table IX). We notice that the bigram model outperforms the others in terms of recognition performance. Table X shows a few sample words that have been cor-rected by imposing the bigram language model on the baseline SVM recognition sys-tem. The wrongly-recognized symbols are highlighted by square boxes in the third column. From Table IX, across the 80,098 symbols in the word database, we notice an improvement of 3.7% (from 88.4% to 92.1%) and 1.3% (from 88.4% to 89.7%) in sym-bol recognition performance over the baseline classifier for the bigram and unigram models. The incorporation of the bigram models gives a word recognition accuracy of 77.6%.

Table XI lists a few sample words that have not been corrected by the bigram lan-guage model (Column 3). As discussed in Section 7, the symbol errors occur due to the optimal path chosen by the Viterbi encoding scheme, which heavily depends on the bias in the bigram statistics between adjacent symbols. For such scenarios, reevalua-tion strategies are invoked on the output symbols returned by the optimal Viterbi path for possible corrections (Column 4). For all four words, the reevaluation of base conso-nants is employed for correcting the erroneous symbols. From Table IX, incorporation of the reevaluation strategies on the output from the bigram language model enhances the symbol recognition from 92.1% to 92.9%. In summary, a judicious combination of reevaluation strategies with a language model improves the symbol recognition perfor-mance beyond that provided by the language model alone. The combination of bigram model with reevaluation enhances the word recognition rate of the baseline classifier by 15.7% (from 65.1% to 80.8%).
 In this section, we evaluate the performance of the prefix-tree-based language models on the word database with and without the reevaluation module. The incorporation of the different contexts for reducing the search space for the test pattern shows an improvement of 1.7% (from 88.4% to 90.1%) in symbol recognition accuracy over the baseline recognition system (Table XII). Correspondingly, the word accuracy improves by 6.5%.

A drawback of incorporating the prefix-tree language model alone is the possible propagation of symbol errors as depicted in the third column of Table XIII. This is at-tributed to the fact that such models make use of the contextual information provided by the immediately preceding character for recognition. Unlike symbol-level language models (described in Section 6.3), we have not incorporated dynamic programming approaches like the Viterbi algorithm to obtain the optimal word. However, the error propagation can be minimized to a great extent by reevaluating the label of the current symbol by reevaluation strategies before proceeding to the next symbol (see fourth col-umn of Table XIII). The combination of language models with reevaluation improves the symbol recognition rate by 4.6% (from 88.4% to 93.0%) and word recognition by 16.5% over the baseline system.

It is interesting to note that the recognition performances of symbol-level and prefix-tree-based bigram models on the word database (92.9% and 93.0%) are comparable after the reevaluation strategies. With respect to the baseline classifier, the tree-based bigram model with reevaluation enhances the word recognition rate by 16.5% (from 65.1% to 81.6%), as compared to 15.7% obtained by the bigram Viterbi approach. One of the metrics for evaluating a language model is its perplexity [Marti and Bunke 2000]. For a test set W T composed of t words ( W 1 , W 2 probability of p ( W T ) as the product of the probabilities of all the words in the set. In particular, given a language model that assigns probability p ( W of t words, we can derive a compression algorithm that encodes the words W  X  log 2 p ( W T ) bits. Let N t represent the total number of symbols in the t words. The entropy H and perplexity P of a language model can be defined as For our work, we have t = 15,000, corresponding to the number of words in the database. Intuitively, perplexity is regarded as the average number of symbols from which the current symbol can be chosen. Table XIV presents the perplexity measures for the different language models.
 In this section, we discuss the computational complexities involved for the prefix-tree language model and the symbol-level bigram-based recognition using Viterbi path.  X  Symbol-level language model . Given a word comprising p segments, the symbol-level language-model-based recognition by the Viterbi algorithm has a maximal time complexity of O ( | V | 2 p ) [Huang et al. 2001]. Here, symbols in the vocabulary. For our case, | V | =155.  X  Prefix tree language model . The prefix tree language model analyzes the segmented symbol pattern based on its context in terms of the recognized labels of the past symbols. Let L i correspond to the set of symbols to be compared against for the i th symbol of the word. Then one needs to make | L i | (cardinality of the set) comparisons for recognizing that symbol. Accordingly, with the incorporation of contextual infor-mation to each segment in the word, we get the overall complexity of the system as
O ( p i = 1 | L i | ) .Bynotingthat L i is a subset of 155 symbols, we can write
This in turn implies that p i = 1 | L i | &lt; p | V | . Making use of the fact that p model is less computational than the symbol-level language model.
 Based on our current implementation in MATLAB, on average, it takes about three seconds to recognize each symbol in a Tamil word. Given that there is no prior work reported on explicitly segmenting and recognizing online Tamil words, it is difficult to compare our method to a benchmark. This being said, the results reported in Bharath and Madhvanath [2007, 2012] adopt an implicit-segmentation approach to recognize a set of 85 distinct words using hidden Markov models. Moreover, a different set of symbols (distinct from the one used in this work) has been used for generating the models. Bharath and Madhvanath [2007] report word recognition rates of 98% to 92.2% with different lexicon sizes (1K to 20K words). Their recent work [Bharath and Madhvanath 2012] suggest recognition rates of 91.8% by presenting a combination of HMM-based lexicon-driven and lexicon-free word recog-nizers. Both the lexicon-driven and lexicon-free approaches are limited to using a lexi-con for improving accuracy.

Our method, on the other hand, views explicit segmentation followed by postpro-cessing techniques as the recognition paradigm. It is to be noted that our segmenta-tion/recognition approach is not aided by a lexicon and hence can be applied in real-life applications, where one may encounter out of vocabulary words.

The writer-independent and lexicon-free segmentation-recognition approach devel-oped in this work for online handwritten Tamil word recognition is promising. The best performance of 93.0% (achieved at symbol level) is comparable to the highest reported accuracy in the IWFHR 2006 Tamil symbol Competition [Madhvanath and Lucas 2006]. However, the latter is on a database of isolated symbols (IWFHR Tamil symbol test set), whereas our accuracy is on a database of 15,000 words and thus a product of segmentation, recognition, and postprocessing strategies.
 This article presented a postprocessing scheme for enhancing the performance of a segmentation-driven recognition system for online handwritten Tamil words. In par-ticular, we proposed the (i) use of bigram language models and (ii) expert classifiers for reevaluating and disambiguating the confused symbols in a Tamil word. We showed that a judicious combination of bigrams with reevaluation is an effective postpro-cessing strategy. As an alternative, we propose a prefix-tree-based approach using character-level bigrams for reducing the search space of symbols during recognition.
Future avenues for research include exploration of a strategy for grouping Tamil symbols, prior to recognition, using possibly shape-based features and confusion pair analysis. In addition, since the isolated word data have been collected keeping in mind the usability of the recognition system for form-filling applications, it would be inter-esting to extend our recognition strategy for online handwritten paragraphs in the future.

The proposed technique is able to handle the limited skew present in the data without any specialized preprocessing technique. Nevertheless, it may be conducive to modify the segmentation strategy and test our approach on applications that present heavily skewed data. Currently, our approach does not effectively recognize the words comprising symbols written as a different temporal sequence rarely encountered in Tamil script. Cursive writing in Tamil is rare. Thus words in which two or more sym-bols are written by a single stroke get incorrectly segmented and hence wrongly rec-ognized. In the future, a stochastic framework such as hidden Markov models with an incorporation of online and offline features needs to be investigated to alleviate these shortcomings. In addition, the incorporation of lexicon may be considered in our segmentation/ recognition framework in finite vocabulary problems.

Nevertheless, to the best of our knowledge, this article is one of the pioneering works directed at addressing the issues in developing an explicit segmentation-based recog-nition system for online isolated Tamil words.

