 helps users to easily access those texts that are relevant to the queries, and hence sig-nificantly reduces the gap between users and the huge information space. Main diffi-culties of text ranking lie on identifying semantics of each term, which is often diverse and depends on different contexts of discussion. 
In this paper, we explore how contextual information may be encoded to improve existing ranking techniques so that more information relevant to natural language queries may be ranked higher for users to access. More specifically, we focus on context-based assessment of the term frequency (TF) of each term in a document 1 . Since TF is a fundamental component of many ranking techniques, the refined TF assessment may be used to improve the ranking techniques. 
Therefore, we develop a context-based TF assessment technique CTFA4TR ( C on-text-based TF A ssessment for T ext R anking) . To assess TF of a term t , CTFA4TR employs locality contexts of t , based on the observation that semantics of a term t in a document d often depends on locality context (neighboring) terms of t in d . We will show that, by encoding the locality contexts into TF assessment, many ranking tech-niques are more capable of ranking relevant information higher. In the next section, we discuss related studies. CTFA4TR is then presented in Section 3. To evaluate CTFA4TR, experiments are conducted on OHSUMED [6], which is a popular collection of medical queries and literature (Section 4). CTFA4TR is efficient online, and the experimental results show that it may significantly improve many ranking techniques under various environmental settings. To rank texts with respect to a query, systems often assign a score to each text. There-fore, many scoring methods were developed. They often estimated how the text (for a list of popular features, the reader is referred to [9]). Since each of the features has its relative strengths and weaknesses, many techniques were developed to inte-produce better ranking. Typical methods included support vector machines (Rank-ingSVM [8] and its variants such as [3]), boosting [8][17], neural networks [4], association rules [15], and genetic algorithms [18]. 
In contrast to the previous studies, we explore how the features (scoring methods) may be improved, so that those ranking techniques that employ the features may be improved as well. We employ term locality contexts to improve the features. Actu-ally, contributions of term contexts to the retrieval of information was noted in previ-ous studies. For example, considerations of adjacent terms (in fixed order [16] or words [1][5]), and distances between each pair of query terms [2][11][14] were shown to be helpful. 
In contrast to the previous approaches, we focus on encoding term contexts to re-fine TF assessment so that many text rankers may be improved, without needing to revise the algorithms and training processes of the rankers. Although some previous approaches employed term proximity (distances between pairs of query terms) to improve text rankers [2][11][14], they only focused on very few basic scoring meth-ods (e.g., BM25 [12]) by directly adding a proximity-based score to the scores from the methods. Their applicability to other scoring methods deserve more exploration, since scoring methods may produce scores in different scales, making it difficult to set a universal weight for the proximity-based score. The scale problem is more com-(features). Fig. 1 illustrates an overview of CTFA4TR, which is proposed to improve text rank-ers by context-based TF assessment, without requiring any change to the rankers. The basic idea is that, for a term t appearing in both a query q and a text d , its semantics in q is more possible to be similar to its semantics in d if a higher percentage of terms in direct the ranking techniques to promoting the score of d with respect to q . 
Given a document d and a query q , CTFA4TR assesses TF of each term t in d with respect to q . As illustrated in Fig. 2, each occurrence of t in d may have its term con-texts, including a neighbor context and a window context . As defined in Fig. 3, for each occurrence of t in d , CTFA4TR computes a weighted occurrence value (WeightedOcc) based on the contexts. If a term t in document d is not in query q , its WeightedOcc is simply 1 (as done by traditional TF assessment); otherwise CTFA4TR increments its WeightedOcc value by a linear combination of its neighbor context score and window weighted occurrence values for all occurrences of t in d (Equation A in Fig. 3). 3.1 Neighbor Context Score are those distinct query terms that consecutively appear around position k in d . For the (x Fig. 2). 
For a query term t occurring at position k in document d , CTFA4TR computes its neighbor context score by considering percentage of distinct query terms that serve as neighbor context terms (including t per se) around position k in d (ref., Equation C in Fig. 3). Obviously, the larger the percentage is, the larger the neighbor context score at position k should be. In that case, CTFA4TR increases the weighted occurrence value of t at position k , which in turn amplifies TF of t in order to direct various kinds of ranking techniques to promoting the score of d with respect to q . 3.2 Window Context Score For a query term t occurring at position k in document d , its window context terms are example in Fig. 2, one term (w 3 ) serves as the window context term for t at position t 1 if it is a query term that appears in the term window at position t 1 and not considered as a neighbor context term at position t 1 . Certainly, some occurrences of t might have no window context terms (e.g., positions t 2 and t 3 in Fig. 2). 
For a query term t occurring at position k in document d , CTFA4TR computes its window context score by considering percentage of distinct query terms that serve as window context terms around position k in d (ref. Equation D in Fig. 3). The size of larger term window. 
Therefore, both neighbor context scores and window context scores are computed by considering percentage of distinct query terms serving as contexts. CTFA4TR actually conducts query-dependent TF assessment  X  each term in a document may get different TF values with respect to different queries. Moreover, the relative weight of more preference to the window context, since it governs the completeness of seman-tics of query q appearing in the term window. 
It is interesting to note that, CTFA4TR mainly considers locality of query terms in the document being ranked. It is thus quite efficient to conduct TF assessment online 2 , without requiring any training processes and data. Moreover, the TF assessment may be directly input to various kinds of ranking techniques, without requiring any revi-sions to the algorithms and development processes of the ranking techniques. CTFA4TR is applied to several ranking techniques. To measure the contributions of CTFA4TR, experiments are designed and summarized in Table 1. Experimental re-sults show that it may significantly improve the ranking techniques on ranking texts. 4.1 Experimental Data Experimental data is from OHSUMED [6], which is a popular database of 348,566 medical references. OHSUMED contains 106 queries that are descriptions of medi-cal information requests. It also provides 16,140 query-reference pairs that indicate not relevant . The relevance information helps to evaluate contributions of CTFA4TR. 
When ranking the references with respect to queries, we consider titles and ab-stracts of the references (i.e., the .T an d .W fields in OHSUMED) and information requests of the queries (i.e., the .W field in OHSUMED). A few steps are conducted to preprocess the data, including removing stopwords, removing non-alphanumeric character of a term. Moreover, those references that do not have abstracts in OH-SUMED are not employed in training and testing if ranking is based on abstracts of the references. 
To conduct 4-fold cross validation, we evenly partition the 16,140 pairs into four only once (and the other three parts are for training). Average performance in the 4-fold experimentation is then reported. Moreover, to conduct more complete evalua-tion, we set up two kinds of partitions, which are named CrossVaidation1 and CrossValidation2 . Results on both partitions are reported separately. 4.2 Underlying Rankers Many basic ranking methods were implemented and tested in previous studies (e.g., [3][9][10]). For each document being ranked with respect to a query, each method ment with respect to the query. In the experiment, we test the same set of features in [3], which is defined in Table 2. When performing ranking, the features are applied to the abstracts of the references in OHSUMED. Among the 7 features in Table 2, there are 5 features that consider TF of each term in the document being ranked (i.e., fea-tures L1, L4, L5, L6, and L7), and hence CTFA4TR is applicable to the 5 features. We aim at exploring the extent to which CTFA4TR improves them individually. 
Moreover, as noted in Section 2, there were also techniques that aimed at achieving better ranking performance by integrating individual features. Among the integration techniques, we employed RankingSVM [8], which has been one of the most impor-tant techniques routinely tested in many previous studies (e.g., [3] [9] [15] [17] [18]). It models the ranking problem as a classification problem whose input is an instance pair and output may be one of two categories: correctly ranked and incorrectly ranked. We employ SVM light to implement RankingSVM 3 . 
To conduct more complete evaluation, two feature sets are constructed for Rank-ingSVM. The first feature set is derived by the 5 features that consider TF (recall L1, each reference in OHSUMED X  X itle, abstract, and both title and abstract. Therefore, there are 15 features (=5 X 3) in the feature set. On the other hand, the second feature and hence the second feature set contains 21 features (=7 X 3). 4.3 Evaluation Criteria Two evaluation criteria are employed to measure the contributions of CTFA4TR: mean average precision (MAP) and normalized discount cumulative gain at x (NDCG@x) [7], which were commonly employed in previous studies in text ranking. MAP is defined to be where k is number of relevant documents for the i th query, and Doc i ( j ) is the number of documents whose ranks are higher than or equal to that of the j th relevant document and MAP is simply the average of the AP values of the 106 queries. On the other hand, NDCG@x is defined to be N ( x ) value of 1.0. That is, N i ( x ) actually measures the relevance of top-x documents higher-ranked documents. NDCG@x is simply the average of the N i ( x ) values of the 106 queries. In the experiment, we report experimental results when x ranges from 1 to 10. 
Also note that MAP only considers binary relevance levels (i.e., relevent and non-relevant), while NDCG@x may consider more relevancy levels. Therefore, following many previous studies (e.g., [9]), when computing MAP, only those references that are judged to be "definitively relevant" to a query are relevant to the query (i.e., both "possibly relevant" and "not relevant" are treated as  X  X on-relevant X ). When computing NDCG@x, those references that are judaged to be  X  X efinitely relevant, X   X  X ossibly relevant, X  and  X  X ot relevant X  are given scores of 2 , 1, and 0, respectively. 4.4 Result and Discussion We separately discuss contributions of CTFA4TR to individual ranking methods (features) and integrative ranking techniques (i.e., RankingSVM). 4.4.1 Contributions to Individual Ranking methods Fig. 4 illustrates contributions of CTFA4TR to the 5 basic ranking methods that con-sider TF. L1 ranks documents by considering TF of each term. CTFA4TR success-fully improves L1 in all evaluation criteria (MAP and NDCG@1~NDCG@10) under both cross validations (i.e., CrossValidation1 and CrossValidation2). We also conduct a significance test to verify the significance of the improvement (two-tailed, paired t-test with 95% confidence level), and those improvements that are statistically signifi-cant are marked with  X   X   X . The results show that, in addition to the large improvements on NDCG@1, CTFA4TR contributes statistically significant improvements to L1 on NDCG@6, NDCG@7, and MAP. The improvements in the two cross validations are quite similar. 
L4 ranks documents by considering normalized TF (or the probability of a term occurring in the document being ranked). Again, CTFA4TR successfully improves L4 two cross validations are quite similar. It is interesting to note that, L4 performs worse than L1, indicating that the normalization conducted by L4 is not helpful. In this case, CTFA4TR contributes much more statistically significant improvements (NDCG4~10 and MAP). 
L5 ranks documents by considering both normalized TF (as L4 does) and IDF (in-verse document frequency). Again, CTFA4TR successfully improves L5 in all evaluation criteria under both cross validations, while the improvements in the two forms better than L4, indicating that the IDF component of L5 is helpful. On the other hand, performance of L5 is more stable than that of L1, especially in NDCG@7~10 in which CTFA4TR contributes more statistically significant improvements. 
L6 ranks documents by considering both normalized TF (as L4 and L5 do) and a component functioning like IDF (focusing on times of occurrences of terms in the training corpus). In this case, CTFA4TR improves L6 and provides several statisti-cally significant improvements to L6, although the performance differences in many criteria are not large, which may be attrib uted to the fact that the component performs better than L5, especially in NDCG@1~3, and CTFA4TR contributes statis-tically significant improvements to L6 in NDCG@2 and MAP. 
L7 ranks documents by BM25 scores. Again, CTFA4TR successfully improves L7 two cross validations are somewhat different. It is also interesting to note that, L7 has the most stable performance than other methods, however, it performs worse than L6 in NDCG@1~3. CTFA4TR contributes statistically significant improvements to L7 in many evaluation criteria, including NDCG@1~2. Therefore, the overall results justify the contribution and applicability of CTFA4TR to the basic ranking methods. It is also interesting to note that, for all the 5 basic ranking methods, CTFA4TR contributes statistically significant improvements to their MAP in both cross validations. 4.4.2 Contributions to Integrative Ranking Techniques Fig. 5 illustrates contributions of CTFA4TR to RankingSVM that integrates 15 fea-tures derived from the above 5 basic ranking methods that consider TF in ranking (recall Section 4.2). Again, CTFA4TR successfully improves RankingSVM in all evaluation criteria under both cross validations, while the improvements in the two cross validations are somewhat different. As expected, RankingSVM with 15 features achieves much better performance than all the original individual 5 features, indicat-ing that feature integration is helpful. In this case, CTFA4TR improves RankingSVM and contributes several statistically significant improvements as well. The results indicate that the refined TF values produced by CTFA4TR may be helpful even when multiple ranking methods are integrated in a collective manner. features derived from all the 7 basic ranking methods in Table 2 (recall Section 4.2). We aim at exploring whether CTFA4TR is still helpful when the underlying ranker integrates several features that do not consider TF in ranking (i.e., L2 and L3 in Table 2). Interestingly, the results show that CTFA4TR successfully improves RankingSVM in all evaluation criteria under both cross validations as well, and the improvements in RankingSVM with 21 features achieves much better performance than all the original individual 5 features, however, it performs worse than RankingSVM with 15 features in NDCG@1~3, indicating that adding more features is not necessarily helpful. In this case, CTFA4TR contributes more statistically significant improvements to Rank-ingSVM with 21 features, and makes this version of RankingSVM able to achieve similar performance as RankingSVM with 15 features. Text ranking is essential for the access of relevant information. In this paper, we ex-plore how various kinds of text rankers may be improved by considering term locality contexts in the documents being ranked. We propose a technique CTFA4TR that recognizes term locality co ntexts by considering completeness of query terms appear-ing in both neighbor contexts and window contexts of each term in the documents being ranked. To improve various kinds of text rankers by the term locality contexts, the technique identifies term frequency (TF) as the target into which the term locality contexts are encoded. Given that TF is one of the most common components consid-ered by text rankers, CTFA4TR is applicable to many text rankers. Moreover, CTFA4TR is efficient online without requiring any training. Empirical evaluation justifies the contributions of CTFA4TR, which successfully improves various kinds of ranking methods both individually and collectively (integrated with machine learning approaches) under different experimental se ttings. The contributions are of practical significance, since many text ranking techniques were developed, and if they consider TF in ranking, CTFA4TR may be used to enhance them without incurring any cost to them, since neither their algorithms nor training processes need to be changed. Acknowledgments. This research was supported by the National Science Council of the Republic of China under the grant NSC 96-2221-E-320-001-MY3. 
