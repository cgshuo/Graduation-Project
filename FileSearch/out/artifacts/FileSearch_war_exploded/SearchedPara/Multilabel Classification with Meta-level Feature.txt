 Effective learning in multi-label classification (MLC) requires an appropriate level of abstraction for representing the relationship between each instance and multiple categories. Current MLC methods have been focused on learning-to-map from instances to ranked lists of categories in a relatively high-dimensional space. The fine-grained features in such a space may not be sufficiently expressive for characterizing disc riminative patterns, and worse, make the model complexity unnecessa rily high. This paper proposes representations of instances and categories into a relatively small set of link-based meta-level feat ures, and leveraging successful learning-to-rank retrieval algorithms (e.g., SVM-MAP) over this reduced feature space. Controlled experiments on multiple benchmark datasets show strong em pirical evidence for the strength of the proposed approach, as it significantly outperformed several state-of-the-art methods, in cluding Rank-SVM, ML-kNN and IBLR-ML (Instance-based Logistic Regression for Multi-label Classification) in most cases. I.5.2 [ PATTERN RECOGNITION ] Design Methodology; Classifier design and evaluation ; H.1.0 [ INFORMATION SYSTEMS ]: General; Algorithms, Design, Experi mentation, Performance comparative evaluation Multi-label classification (MLC) refers to the problem of instance labeling where each instance may have more than one correct label. MLC has a broad range of applicati ons. For example, a news article be related to China and USA as the regional categories. An image (picture) could have flower as the object type, yellow and red as the colors, and outdoor as the background category. A computer trouble report could be simultaneously related to a hardware failure, a software problem, an urgency-le vel category, a regional code, and so on. well-studied two-way classifiers, such as binary Support Vector Machines (SVM), Na X ve Bayes pr obabilistic classifiers, etc. Approaches to MLC typically re duce the problem into two sub-problems: the first is learning to rank categories with respect to each input instance, and the second is learning to place a threshold on each ranked list for a yes/no decision per category. The first sub-problem is the most challenging part and therefore has been the central focus in MLC. A variety of approaches has been developed and can be roughly divided into tw o types: binary-classifier based methods versus global optimizati on methods, and the latter can be further divided into model-base d and instance-based methods. representative example is to use a standard SVM ( X  X inary-SVM X ) [17] to learn a scoring function for each category independently from the scoring functions for othe r categories. Other kinds of binary classifiers could also be used for such a purpose, such as logistic regression, Na X ve Bayes probabilistic classifiers, boosting algorithms, neural networks etc. In the testing phase, the ranked list of categories is obtained for each test instance by scoring each category independently and then sorting the scores. Binary-classifier based methods have b een commonly used due to their simplicity, but also have been criticized for the lack of global optimization in category scori ng. These methods are common baselines in benchmark evaluations of stronger methods in MLC. Rank-SVM, which is a represen tative example of model-based methods. Unlike conventional bina ry SVM which maximizes the margin for each category independently, Rank-SVM maximizes the sum of the margins for all cate gories simultaneously, conditioned on partial-order constraints . That is, ranking the relevant categories of each training instance higher than the irrelevant categories is an explicit optimization criterion in th is method. The scoring function is parameterized by the weights of input features for every category; thus, the number of parameters in Rank-SVM is the product of the number of categories and the size of the feature set. In other words, the model complexity (measur ed using the number of free parameters) is the same as that of m binary-SVMs where m is the number of target categories. Expe riments by the authors of Rank-SVM show that this method signi ficantly outperformed binary SVM in gene classification on a micr o-array dataset (namely  X  X he yeast dataset X ). which is named as Multi-label k-Nearest Neighbor (ML-kNN). Cheng and Hullermeier proposed another variant called Instance-Based Logistic Regression (IBLR) [3]. Multi-label versions of kNN have been studied in text categorization for a long time and commonly used as strong baselin es in benchmark evaluations [2][20][22]. ML-kNN and IBLR are relatively new variants which are similar in the sense that both use Euclidean distance to identify the k nearest neighbors for each test instance, but differ in how the local probabilities are estimated for categories. ML-kNN gives an equal weight to each label occurrence in the neighborhood of the input instance while IBLR varies the weight of each label according to how distant it is to the test instance. Further, ML-kNN assumes independence among category occurrences while IBLR explicitly models pairwise dependencies among categories using logistic regression. IBLR also makes combined use of instance-based features (such as the similarity score of each neighbor) and conventional features (such as words in the test document) in the logis tic regression. The evaluations by the authors of ML-kNN showed its superior performance over Rank-SVM, BoosTexter [14] and Adaboost.MH [15] , and the experiments by the authors of IBLR showed further performance improvement by IBLR over the results of ML-kNN on multiple datasets [3]. been focused on learning-to-rank in a relatively high-dimensional space. In Rank-SVM for text categorization the features are words in the training-set document vocabulary. In IBLR for text categorization the feature set is the union of word-level features and kNN-based features (used to model the interdependencies among categories). Both methods learn a linear function per category, so the total number of features is md where d is the feature-set size and m is the number of categories. In machine learning, it is generally understood that when the number of model parameters is unnecessarily large, the model tends to overfit training data and does not ge neralize well on test data. To what extent would this be an issue in current MLC methods? Further, can we find a better solution for MLC by transforming lower-level features to higher-level ones, and then learning to rank more effectively in the reduced space? Thorough investigation is needed to answer these questions, and such is the primary focus of this paper. Specifically, we address these questions by the following means: 1) We propose a generic framework that allows automated 2) We use SVM-MAP, a large-margin method for optimizing 3) We conduct controlled experi ments on multiple benchmark 4) We provide strong empirical evidence for the strengths of the introduces the meta-level features for MLC. Section 3 describes the method for category ranking optimization, i.e., SVM-MAP-MLC and the strategy for optimizing the threshold on each ranked list. Section 4 presents design of controlled experiments. Section 5 reports the main results. Sec tion 6 summarizes our findings and conclusion. Following a standard notation in machine learning, we define X as the input space (of all possible instances), Y as the output space of X x i  X  and Y y i  X  . The learning-to-rank problem is generally defined as to find the optimal mapping Y X f  X  : given T . Now we define a transformation from X x  X  to Z z  X  following properties: 1) The feature-set size of Z should be relative small. 2) The features in Z z  X  should be highly informative about 3) The transformation from X x  X  to Z z  X  should be 4) The transformed training data should allow a broad range of Based on these criteria we define vector z as the concatenation of the sub-vectors below, which are defined for each test instance x and category C c j  X  for m j , , 2 , 1 L = as: 
For rare categories, since the number of training instances in each category is small, there might not be k nearest neighbors. In such a case we duplicate the furthest neighbor so that the sub-vector reaches size k . Of course the listed features are not necessarily exhaustive for all possibly informative features but rather a set of concrete examples for illustrating the principle in our approach. The number of held-out validation dataset which is typically in the range from 10 to 100. The size of such a meta-level feature set is much smaller than those typically found in current MLC methods. supervised manner, taking the labe ls of training instances into account. Also, the meta-level features make a combined use of local information (through kNN-based features) and global information (through category centroids) in the training set. Vector Z z  X  synthetically represents a pattern for each instance about how it is related to multiple categories. Figure 1 illustrates the concept geometrically in a 2-D space. For simplicity we only plot the L2-norm links in this graph and omit the other types of links. Figure 1: The link-based representation of one particular instance (the dot in the center) in relation to multiple categories is shown. Each category is represented usi ng its positive examples (points in the same color) in the training set and its centroid (triangle). Each instance is represented using the  X  X verage links X  (i.e., the distance to each category centroid, shown by thick lines) and multiple  X  X ingle links X  (i.e., the distance to each of the k nearest neighbors, shown by the thin lines) per cat egory. These links together portray an informative picture about how the instance is related to multiple categories. Our goal now is to solve the mapping Y Z f MLC  X  the transformed training set where Z x z z i i  X  = ) ( is an transformed input vector whose elements are meta-level features, and Y y i  X  is a true ranked list of categories for the input 2 . Any learning-to-rank algorithm could be deployed in principle; among the successful ones, we choose SVM-MAP in the remainder of this paper. with respect ad-hoc queries where ad-hoc means that queries could be any combination of word s, not fixed in advance. The mapping Y Q f IR  X  : where Q the input space (of all possible queries), Y as the output space (of all possible ranked lists of documents), and optimal means to minimize the training-set loss as well as the model complexity. A variety of learning-to-rank algorithms have been developed recently in machine learning for ad-hoc retrieval, with different loss functions and model selection criteria. SVM-MAP [24] is designed to maximize the Mean Average Precision (MAP) of ra nked lists, which is a common metric for method comparison in IR evaluations. Methods focusing on other optimization criteria include a multivariate version of SVM [8] that maximizes ROC-Area for classification, MCRank and AdaRank [11] [19] that use boosting algorithms to maximize the Normalized Discount ed Cumulated Gain (NDCG) of ranked lists, and so on. a shared representation between queries and documents, i.e., a bag-of-words per query and per document. Such a shared representation facilitates a natural way to induce features for discriminating the relevance of query-document pairs. For example, SVM-MAP uses a conventi onal search engine (Indri) to produce the cosine similarity and language-model based scores for each query-document pair, discretizes those scores into bins, and treats the bins as the features in a dimension-reduced vector space where each query-document pair with relevance judgment is treated as a training instance. Optimizing the mapping from queries to ranked lists of docum ents therefore reduces to the learning of feature weights in the dimension-reduced vector space. learning-to-rank retrieval algorithm to MLC in general, we need to find discriminative features to represent instance-category pairs and the one-to-many mapping from each instance to categories. The meta-level features we introduced in the previous section are exactly designed for such a purpose, allowing a broad range of learning-to-rank algorithms in IR to be deployed for MLC. The category-specific links ( 2 3 + k per category) in vector z (Section 2) and the corresponding label (yes or no with respect to the category) There may be more than one true ranked list for an instance. 
That is, any list that places all the relevant categories above all the irrelevant categories is truly correct. on SVM-MAP in this paper because it explicitly optimizes MAP which is one of the primary metrics we use in our evaluation of MLC methods (Section 4.3). SVM-MAP and other learning-to-rank retrieval methods have not been used for MLC before, to our knowledge. We name our novel application of SVM-MAP as SVM-MAP-MLC, in contrast to its conventional use in ad-hoc information retrieval. In order to enable the system to make classification decisions in MLC, we need to apply a threshold to the ranked list of categories for each test instance. A variety of thresholding strategies have been studied in the literature [21],[5], among which we choose the linear regression approach proposed in [5]. Unlike binary-SVM where the natural choice of threshold is zero and probabilistic classifiers (such as logistic regression, Na X ve Bayes, IBLR, etc.) where the default choice of threshold is 0.5, SVM-MAP-MLC produces non-probabilistic scores to rank categories with partial-order preferences. Obviously, neith er 0 nor 0.5 is the appropriate optimal threshold on a ranked list of categories given an instance. The strategy proposed in Rank-SVM [5] is designed for optimizing the threshold conditioned on each ranked list. That is, the system uses a training set to learn a linear mapping from an arbitrary ranked list of categories to the optimal threshold as: where categories, and R T  X  is the space of all possible thresholds. The optimal mapping is defined as th e linear-least-squared-fit (LLSF) solution given a training set of ranked lists with the optimal the threshold that minimizes total e rror, i.e. the sum of type-I errors training set can be automatically generated by 1) learning a SVM-MAP-MLC model to score all categories conditioned on each input instance, and 2) finding the optimal threshold for each vector of scored categories given an instan ce. The LLSF function is applied in the testing phase, to the syst em-scored categories conditioned on each test instance. The resulting th reshold is then applied to the corresponding ranked list of categorie s: the categories above or at the threshold receive a yes decision, and the categories below the threshold receive a no decision. We modified the original method by rescaling scores of each instance to make it in the unit norm. We conducted controlled experi ments to evaluate SVM-MAP-MLC 3 in comparison with the following methods:  X  Binary-SVM is a standard version of SVM for one-versus-rest We used the publicly available SVM-MAP software at http://projects.yisongyue.com/svmmap/ as the core algorithm. We used the publicly available SVMlight software package at http://svmlight.joachims.org/ in our experiments.  X  Rank-SVM, the method proposed by [5], is representative  X  IBLR, the instance-based method recently proposed by [3], is  X  ML-kNN, the instance-based method proposed by [25] is instance . The ranked lists can be directly evaluated using rank-based metrics, and indirectly evaluate d based on binary classification decisions (yes or no on each category) after applying a threshold to each ranked list. each classification method. In Binary-SVM, for each category, we used the conventional threshold of zero to obtain a yes/no decision for that category. In ML-kNN, IBLR-ML and Rank-SVM we follow the same thresholding strategies as proposed by the authors. Specifically, for ML-kNN and IBLR we set the threshold to 0.5, and for Rank-SVM we use the linear l east squares fit solution as the threshold, as proposed in [5]. We used five datasets 6 in our experiments, namely emotion , scene , representative sample across different fields and they vary in training-set size and feature-space size. All the datasets except Citeseer have been used in previous evaluations of MLC methods, with conventional train-test splits. We follow such conventions in order to make our results comparable to the previously published ones. Table 1 summarizes the datasets statistics:  X  Emotions [16] is a multi-label audio dataset, in which each  X  Scene [1] is an image dataset. The images are indexed using We thank the authors of ML-kNN for sharing their implementation of Rank-SVM. The emotions, scene and yeast datasets were obtained from http://mlkd.csd.auth.gr/multilabel.html  X  Yeast dataset [5] is a biomedical dataset. Each instance is a  X  Citeseer is a set of research articles we collected from the  X  Reuters-21578 is a benchmark dataset in text categorization We select two standard metric s for evaluating ranked lists, and two standard metrics for evalua ting classification decisions.  X  Mean Average Precision (MAP) [18] is a popular metric in  X  Ranking Loss ( RankLoss ) is a popular metric for comparing http://citeseer.ist.psu.edu/directory.html  X  Micro-averaged 1 F is a conventional metric for evaluating  X  Macro-averaged 1 F is also a conventional metric for Both micro-averaged 1 F and macro-averaged 1 F are informative for method comparison. The former gives the performance on each instance an equal weight in computing the average; the latter gives the performance on each category an equal weight in computing the average. We choose the evaluation measur es so as to evaluate the performance of both the ranking algorithms as well as the thresholding strategies. MAP a nd RankLoss measure how well a system ranks the categories; Micro-F 1 and Macro-F effectiveness of the thres holding strategies for making classification decisions. All parameters are tuned to op timize MAP and the tuning is done through a five-fold cross validation on the training set for each corpus. The tuned parameters include the number of nearest neighbors in SVM-MAP-MLC, ML -kNN and IBLR-ML, and the regularization parameter in SVM-MAP-MLC, Binary-SVM, Rank-SVM. For the number of nearest neighbors we tried values from 10 to 100 with the increments of 10; for the regularization parameter we tried 20 di fferent values between 3 10 IBLR, on Citeseer and Reuters-21578 , the best choice for the number of nearest neighbors through cross validation was found to be 300 and 190 respectively. for any method. For term weighting in Citeseer and Reuters documents, we used a conven tional TF-IDF scheme (namely  X  X tc X ) [22]. On the Emotions dataset, each feature was rescaled to a unit variance representation since we observed that the original values of the features are not comparably scaled. The results of all the systems on the five datasets are summarized in Table 2. The methods with the best scores are highlighted in bold, and the relative ranks among the methods on each dataset in a specific metric are provided insi de parentheses. We report the value of 1-RankLoss instead of Ra nkLoss just to make the scores consistent to each other, i.e., higher values are better. The total rank of each system is provided at the bottom line of the table. Let us call each line in Table 1 a case , which corresponds to a particular dataset and a specific metric. SVM-MAP-MLC is the best in 18 out of the 20 cases while Binary-SVM is the best on the two remaining cases. That is, the proposed approach consistently outperformed other methods in most cases. margin methods but the former outperformed the latter on 12 out of the 20 cases. These results are consistent with the previously reported evaluation on the Yeast dataset [5], showing some success of Rank-SVM by reinforcing partial-order preferences among categories. Comparing Ra nk-SVM with SVM-MAP-MLC, on the other hand, the latter outperformed the former in 19 out of the 20 cases although both methods have partial-order preferences in their objective functions for optimization. The advanced 
Figure 2. SVM-MAP-MLC with different feature sets (Performance in MAP, 1-RankLoss, Micro-F1, Macro-F1) performance of SVM-MAP-MLC, evidentially, comes from the use of meta-level features instead of the conventional features as that in Rank-SVM. these methods have one property in common: they are either fully instance-based or partially inst ance-based leveraging kNN-based features. IBLR-ML outperformed ML-kNN in 13 out of the 20 cases in our experiments; this is more or less consistent with the previous report by [3] in terms of the relative performance of the two methods. Nevertheless, both IBLR-ML and ML-kNN underperformed SVM-MAP-MLC in all the 20 cases, showing the advantage of using of the meta-level features in the learning-to-rank framework with SVM-MAP. outperformed the latter in 13 out of the 20 cases. The relative performance of these two methods compared to each other is different from the previously reported evaluation in [25] where ML-kNN outperformed Rank-SVM on average. In order to clarify this issue, we compared the performance of Rank-SVM with different values of its regulariza tion parameter which controls the balance between the training-set loss and model complexity. We found Rank-SVM performed subop timally with the default parameter setting,, and performed better when this parameter was tuned through cross validation. Our results of Rank-SVM are based on the properly tuned parame ters, and this should explain why Rank-SVM performed stronger than ML-kNN in our experiments. Comparing Rank-SVM with IBLR-ML, each method outperformed the other in 10 out of the 20 cases. Thus the two methods have comparable performance; both are strong baselines for method comparison in MLC. We used the Wilcoxon signed-rank test to compare the performance of each method with that of SVM-MAP-MLC. Signed-rank is a non-parametric st atistical test for pairwise comparison of methods, and a better alternative to the paired t-test when the performance scores are not normally distributed. Due to the space limit of the paper, we only present the tests based on the MAP scores of the systems. Each test instance is treated as a random event, and the average precision scores of system-generated ranked lists over all test instances are used to compare each pair of systems. The null hypothesis is that the system being compared with SVM-MAP-MLC is equally good; the alternative is that SVM-MAP-MLC is better. The p-values are presented in Table 3 where the null hypothesis is rejected with strong evidence in most cases. That is, the performance difference is statistically significant in 17 out of the 20 tests if using 1% p-value as the threshold. systems because such tests have a normal-distribution assumption about the data which is inappropr iate for the performance scores we use for system comparison. The Friedman test has been recently advocated for comparing classifiers on multiple datasets [4] [6], which does not have the normal assumption. However, it treats each dataset as a random event, and requires a relatively large number of datasets for m eaningful testing. It is not recommended to use the Friedman test when the number of datasets is 10 or less 8 . In order to analyze the usefulness of different types of meta-level features (links), we conducted experiments with the following combinations: using the single links in 1 L -norm only, using the single links in 2 L -norm only, using the single links in cosine similarity, and using all th e links --including those in 
L -norm, cosine similarity and the two average links per category. Figure 2 compares the performance of SVM-MAP-MLC under these conditions. The di fferent types of links have complementary effects: the single links in 1 L -norm are more useful in the datasets ( Emotions , Scene and Yeast ) whose feature-This is according to personal communication with the author of [4]. ( Citeseer and Reuters-21578 ) whose feature-set sizes are large. On the other hand, cosine-simila rity based single links have a different performance pattern; single links in 2 L -norm have comparable performance across the datasets. Using all the features together performs th e best, showing that SVM-MAP-MLC is able to assign appropriate weights to different features, and improve the robustness of its predictions by making a combined use of different features types. In this paper we produced a new approach for learning to rank categories in multi-label classifica tion. By introducing meta-level features that effectively characterize the one-to-many relationship from instances to categories in MLC, and by formulating the category ranking problem as a sta ndard ad-hoc retrieval problem, our framework allows a broad ra nge of learning-to-rank retrieval algorithms to be deployed for MLC optimization with respect to various performance metrics. Using SVM-MAP-MLC as a specific instantiation of this framework, and with controlled experiments on multiple benchmark datasets, the strength of the proposed approach is strongly evident, as it significantly outperformed all the state-of-the -art methods (Rank-SVM, ML-kNN and IBLR-ML) being eval uated in our experiments. enhance the performance of MLC methods by improving the representation schemes for instances, categories and their relationships, and by creatively leveraging dimensionality reduction. A line of future research would be to explore our framework with other learning-to -rank algorithms, using different dimensionality reduction technique s (such as SVD or LDA), and for different optimization metr ics (such ach NDCG and other types of loss functions). This work is supported, in part, by the National Science Foundation (NSF) under grant IIS_0704689. Any opinions, findings, conclusions or recomme ndations expressed in this material are those of the authors and do not necessarily reflect the views of the sponsors. [1] M.R. Boutell, J.Luo, X.Shen and C.M. Brown. Learning multi-[2] Robert H. Creecy, Brij M. Masand, Stephen J. Smith, David L. [3] W.Cheng and E.H X llermeier. Combining Instance-Based [4] J. Demsar. Statistical comparisons for classifiers over multiple [5] A Elisseff and J. Weston. A ke rnel method for multi-labeled [6] S Garc  X  a and F. Herrera. An extension on  X  X tatistical [7] M. Hall, E. Frank, G. Holmes , B. Pfahringer, P. Reutemann [8] T. Joachims: A support vector method for multivariate [9] T. Joachims, Making large-Scale SVM Learning Practical. [10] D.D. Lewis, R.E. Schapire, J. P. Callan and R.Papka. Training [11] F. Li and Y. Yang. A loss func tion analysis for classification [12] P Li, C Burges, Q Wu, JC Platt, D Koller, Y Singer and S [13] S Har-Peled, D Roth and D Zimak. Constraint classification: a [14] R.E. Schapire and Y. Singe r . BoosTexter: A boosting-based [15] R.E. Schapire and Y. Singe r . Improved boosting algorithms [16] K. Trohidis ,G. Tsoumakas, G. Kalliris, I. Vlahavas. Multilabel [17] V. Vapnik, The nature of statistical learning theory, Springer [18] E.Voorhees Overview of TREC 2002, NIST Special [19] Jun Xu and Hang Li. AdaRank: a boosting algorithm for [20] Y. Yang: Expe rt Network: Effective and Efficient Learning [21] Y. Yang. A Study of thres holding strategies for text [22] Y. Yang. An evaluation of statistical approaches for text [23] Y. Yang and J.O. Pederson. A co mparative study of features [24] Yisong Yue, T. Finley, F. Radlinski and T. Joachims. A [25] ML Zhang and ZH Zhou. ML-kNN: A lazy learning approach 
