 1. Introduction model embedded in additive noise is a fundamental problem in signal processing and in time series analysis. In several applica-tions in signal processing ( Kay, 1988 ; Stoica, 1993 ; Quinn and
Hannan, 2001 ; Stoica and Moses, 2005 ) and time series analysis (Brillinger, 1987 ), the signals dealt with can be described by the following multiple sinusoidal model: y  X  t  X  X  t =1,2, y , N . The unknown parameters of the model are the frequencies ( o 1 , y , o M ) and the corresponding amplitudes ( A , o k s are distinct real numbers lying between (0, p ). The real valued additive white noise sequence { e ( t )} is assumed to be stationary with finite variance s 2 and it has the following form: e  X  t  X  X  { d ( t )} being a sequence of independent and identically distributed (i.i.d.) normal random variable with mean 0 and variance s .

Furthermore, f r i g P i  X  1 are such that the sequence { e ( t )} is stationary. The particular case of r i =0 for all i , corresponds to the i.i.d. noise case. M , the number of sinusoidal components is assumed to be known. Given a sample of size N ,{ y (1), y the problem is to estimate the unknown frequencies and the corresponding amplitudes.

The sinusoidal model (1), is used to describe and model many real life applications where periodic phenomena is present. The extraction of frequencies of the sinusoidal signals model from time series data is a classical problem of ongoing interest in the literature of statistical signal processing ( Mackisack et al., 1994 ; Kundu and Mitra, 1996 ; Kundu, 1997 ; Mitra and Kundu, 1997 ; Smyth and Hawkins, 2000 ; Nandi et al., 2002 ; Chan and So, 2004 ;
Trapero et al., 2007 ; Bonaventura et al., 2007 ; Coluccio et al., 2008 ) and indeed has created interests among scientists, from various diverse fields. There exists a vast amount of literature addressing the computational aspect of the frequencies of the sinusoidal model as well as focusing on theoretical behavior of the estimators. The most intuitive and natural approach is the least squares approach. A closely related approach is the approximate least squares estimators (ALSEs) approach, which is asymptoti-cally equivalent to the least squares estimators (LSEs). Asymptotic properties of the ALSE and LSE are studied in detail in Walker (1971) , Hannan (1971) , Kundu (1993, 1997) and Kundu and Mitra (1996). It is well known that, although the LSEs are the most desired estimators from theoretical point of point of view, obtaining the LSEs is numerically a very difficult problem ( Kahn et al., 1993 ). It is observed that the least squares surface has local minima spaced O ( N 1 ) apart, making the gradient based search methods of general non-linear optimization ineffective without excellent starting values. Several methods are available in the literature to obtain the LSEs efficiently, but unfortunately all the methods are quite sensitive to the initial value chosen. It is further observed in Rice and Rosenblatt (1988) , that unless the frequen-cies are resolved at the first step with order O ( N 1 ), the failure to converge to global minima may give a very poor estimate of the amplitudes. Thus, fitting these multiple sinusoidal models can involve daunting computational difficulties. The problem can be further complicated in case outliers are present in the dataset.

In this paper, we develop genetic algorithm based frequency estimation methods optimizing outlier-insensitive criterion func-tions. The aim here is to find an algorithm, under the assumption of stationary additive noise random variable, whose performance significantly does not depend on initial guess values (or intervals), and also have a high breakdown point with respect to outliers present in the data. Recently, Smyth and Hawkins (2000) proposed an algorithm based on elemental sets for robust frequency estimation, under the assumption of independently and identically distributed (i.i.d.) normal random variables. Contrary to the remarks made in Smyth and Hawkins (2000) that the genetic algorithms does not seem to be a suitable approach for this problem (under i.i.d. setup), especially with the presence of outlier, we observe that the proposed genetic algorithm based methods perform quite satisfactorily even in the dependent noise structure.

The rest of the paper is organized as follows. In Section 2, we give the least squares and the L1-norm formulation of the frequency estimation problem. In Section 3, we will give a brief review of the outlier-insensitive criterion functions. Section 4 presents the proposed genetic search based iterative algorithms for robust frequency estimation. The empirical studies, imple-menting the proposed algorithms, will be presented in Sections 5. Finally, the conclusions will be discussed in Section 6. 2. Least squares and L1-norm estimators
The least squares estimators of the parameters for the model (1) are the minimizers of the criterion function: c  X  o ; A ; B  X  X  where o  X  X  o 1 ; ... ; o M  X  T is the vector of frequencies and Here  X  T  X , denotes transpose of a vector or of a matrix. The sinusoidal model parameters estimated through minimization of (3) has the smallest least squares distance to the observed data. o , A and B obtained by minimizing (3) are called the non-linear least squares (NLS) estimators. When the noise e ( t ) is white Gaussian, the NLS estimators are same as the maximum like-lihood estimators.

For the sinusoidal model (1), the criterion function (3) can conveniently be concentrated with respect to the conditionally linear parameters A and B . Introducing the notations: Y  X  X  y  X  1  X  ; y  X  2  X  ; ... ; y  X  N  X  T ;  X  4  X  A  X  o  X  X   X  X  A 1 ; B 1 ; ... ; A M ; B M T ;  X  6  X  we can write c  X  o ; A ; B  X  as c  X  o ; A ; B  X  X  X  Y A  X  o  X  a  X  T  X  Y A  X  o  X  a  X  :  X  7  X  With distinct frequencies, if N Z 2 M the Vandermonde matrix the vectors o and a which minimize (3) are given by ^ o  X  argmax ^ a  X  X  A  X  o  X  T A  X  o  X  X  1 A  X  o  X  T Y j o  X  ^ o
It is well known that the least square estimators for this problem are optimal under various considerations on the noise sequence. It is observed that, under the i.i.d. assumption on the noise sequence, the estimators are strongly consistent ( Kundu and
Mitra, 1996 ), asymptotically normal with a covariance matrix that coincides with the Cram er-Rao bound under the normality assumption. It is further observed that the LSEs under the dependent error structure are also strongly consistent and asymptotic normal ( Kundu, 1993 ).

As an alternate to the above LSE formulation of the problem, we can use L1-norm formulation, which is often used in the literature of robust regression. The L1-norm estimates of the parameters of the multiple sinusoidal model (1) are obtained by minimizing f  X  o ; A ; B  X  X 
The non-linear optimization problem (10) is solved using standard non-linear optimization routines in order to get the L1-norm estimates. The L1-norm estimators, also called the least absolute deviation (LAD) estimators, correspond to the maximum likelihood estimators under the assumption that noise are i.i.d. with double exponential distribution. In recent literatures of signal processing, use of modified simplex algorithm is proposed for obtaining the L1-norm estimates. The estimates are then computed using the Barrodale X  X oberts modified simplex algo-rithm ( Barrodale and Roberts, 1973, 1974 ). For a more detailed review of L1-norm techniques, readers are referred to Bloomfield and Steiger (1983) . 3. Outlier-insensitive criterion functions
The conventional estimates that are found by the least squares criterion, i.e. minimizing the sum of squares of all the N residuals, are motivated by the ideas of statistical efficiency. However, the estimates are inappropriate if some of the observations are contaminated. The L1-norm estimates are potentially better options in situations where the dataset contains outliers. Deviat-ing from the use of usual sum of square errors or sum of absolute errors criterion functions, literature of robust regression provides us with alternate criterion functions that are relatively insensitive to the presence of outliers in the data. The primary aim of these outlier-insensitive criteria is to protect the estimate from such outlier contamination.

Among the most widely used specialized outlier-sensitive criterion functions, are the least trimmed (LT) sum and the least median (LM) criteria. We now formulate the criteria to be used in the robust frequency estimation methods proposed in this paper. 3.1. Least trimmed criterion
Let e (1) 2 o e (2) 2 o , y , o e ( N ) 2 be N ordered estimated squared residuals, for an estimated value of A , B , o . The unordered e ( i ) for the model (1) are given by e  X  t  X  2 A ; B ; o  X  y  X  t  X  in Rousseeuw (1984) , is found by finding the parameters that satisfy property is obtained when h = N /2, approximately. In this case a breakdown point of 50% is attained. Higher efficiency of the estimates is obtained with lower trimming proportions. We consider in the present paper, a 50% trimming.
 larly define a least trimmed (sum of) absolute (LTA) deviation estimator. The LTA deviation estimator is found by finding the parameters that satisfy
Min the unordered j e ( t ) j s for model (1) are given by j e  X  t  X j X  y  X  t  X  estimators in the present paper. 3.2. Least median criterion finding the model parameters that minimizes the h th-ordered squared residual, i.e. e ( h ) 2 , where h is usually taken as h =[ N / 2]+[( p +1)/2], p denotes the number of parameters in the model. This estimator was introduced in Rousseeuw (1984) (see also Rousseeuw, 1988 ; Rousseeuw and Leroy, 1987 ).
 absolute (LMA) estimator as the estimator that is obtained by finding the parameters that minimize the h th-ordered absolute residual, i.e. j e ( h ) j , with appropriate choice of h . 4. Proposed robust frequency estimation methods based frequency estimation techniques for the multiple sinusoidal model.
 rithm and different criterion functions. These estimators are: (i) genetic algorithm based least square estimator (GA-LS), (ii) genetic algorithm based least trimmed square estimator (GA-
LTS), (iii) genetic algorithm based least median square estimator (GA-LMS), (iv) genetic algorithm based L1-norm estimator (GA-
L1), (v) genetic algorithm based least trimmed absolute deviation estimator (GA-LTA), (vi) genetic algorithm based least median absolute deviation estimator (GA-LMA).
 genetic search formulation of the GA-LS estimator of the parameters of the model (1), we take the objective function (8) as the fitness function in the genetic search setup and aim to find the optimum member through repeated applications of the three genetic operators of selection, crossover and mutation, over the successive generations. The parameter space, O freq for the frequency vector, o  X  X  o 1 ; ... ; o M  X  T , for the sinusoidal model (1) is given by
O freq  X  X  0 ; 1  X  X  0 ; 1  X  X  0 ; 1  X  R M :  X  15  X 
We first obtain the binary chromosomal representation of the parameter space. We form, for any possible solution belonging to the original parameter space O freq , a binary string of length M p .
Where, p denotes the length of the binary bit representation of any component of the parameter vector o , i.e. for each of the unknown frequencies, we obtain a p-bit coded binary representa-tion. It is however well known that ordinary binary coding can result in search process being deceived, i.e. unable to efficiently locate the global minima, due to large hamming distances in the representational mapping between adjacent values ( Hollstien, 1971 ). A hamming distance, between two binary strings is defined as minimum number of bits that must be changed in order to convert one bit string into another. In order to avoid the above-mentioned problem, a Gray coding approach of the original binary strings is adopted. The literature of GA and its applications report that Gray coding exhibits accelerated convergence rate of the objective function, and provides better accuracy than the binary coded GA ( Caruana and Schaffer, 1988 ; Yokose et al., 2000 ).
Superior performance of a Gray coded GA is mainly attributed to the fact that Gray codes do not bias the searching direction, as in the case of ordinary binary coding, having a large hamming distance between adjacent values. A Gray code represents each number in the sequence of integers {0,1, y ,2 K 1} as a binary string of length K in an order such that adjacent integers have
Gray code representations that differ in only one bit position. Use of Gray code thus allows, going through the integer sequence requiring flipping just one bit at a time. This is called the adjacency property of Gray codes. Gray code takes a binary sequence and shuffles it to form some new sequence with the adjacency property. We use here a Gray coding derived from the initial binary coding.

To initialize the genetic search, we populate an initial population of a pre-determined size. Each member of this initial population is a randomly chosen parameter vector o 0 A O freq coded to get the chromosomal string representation of bit length
M p . The ranking based fitness of each of the members of this initial population is evaluated according to the criterion (8). For a detailed discussion on various selection procedures, see for example Goldberg (1989) . Using a stochastic sampling with replacement approach, we next populate fit parents pool, size of the pool depending on the generation gap. From the selected parent pool, we select pairs in order and apply a two-point crossover (with a pre-assigned crossover probability), exchanging genetic material of parents to obtain new chromosomes. Cross-over produces new individuals that have some parts of both the parent X  X  genetic material. An example of a multipoint crossover is illustrated in Fig. 1 .

Mutation is applied on the mated chromosome strings with a low pre-assigned mutation probability. Mutation is considered to be the genetic operator that ensures that the probability of searching any given string will never be zero and thus has the effect of tending to inhibit the possibility of convergence of the GA to a local optimum. Mutation changes the genetic representation of the chromosomes according to a probabilistic rule. In the binary string representation, mutation will cause a single bit to change its state, i.e. 0 ) 1or1 ) 0.

An elitist strategy is used to fill the generation gap. An elitist strategy ( De Jong, 1975 ; Thierens, 1997 ) is adopted while populating a new generation. Elitism encourages the inclusion of highly fit chromosome strings, from earlier generations, in the subsequent generations. The fractional difference between the number of chromosomes in the old population and the number of new chromosomes produced by selection and recombination is termed as the generation gap. Under the elitist approach, a fraction (based on the value of the pre-determined generation gap) of the most-fit individuals is deterministically allowed to propagate through successive generations.

Since GA is a stochastic optimization algorithm, the appli-cation of conventional termination criteria becomes problematic in GA based optimization procedure. We follow here the most commonly adopted practice, where the cycles of selection, crossover and mutation is carried on until a pre-determined number of generations have been completed or no better solution is found after a pre-determined number of successive genera-tions have evolved, whichever is earlier. We walk through the GA steps repeatedly, until the termination criterion is reached.

After completion of each generation, we preserve the informa-tion regarding the most fit, i.e. the parameter vector that is the best solution for the optimization of (3) ((8) for frequency estimation), in that generation. The GA based least square (GA-LS) solution of o , say ^ o among all the generations, at the point when termination criterion is reached. Once we obtain ^ o conditionally linear parameters, the amplitudes, a , may be obtained using (9).

The algorithmic steps for the proposed procedure are given below:
Step 1: Randomly initialize initial population generation (of a pre-determined size) of chromosomes of Gray coded binary strings of length M p , each of these chromosomes is the coded binary representation of a possible solution for the least square frequency estimation problem.

Step 2: Decode the Gray coded binary strings using a linear scaling.

Step 3: Evaluate the objective function (8) for each of the decoded strings and obtain their fitness values using a ranking based approach. Preserve the information about the string with highest fitness value.

Step 4: Using a stochastic sampling with replacement approach, populate fit parents pool, size of the pool depending on the generation gap.

Step 5: From the selected parents pool, we select pairs in order and apply a two-point crossover (with a pre-assigned crossover probability), exchanging genetic material of parents to obtain new chromosomes.

Step 6: Apply mutation on the mated chromosome strings with small pre-assigned mutation probability.
 Step 7: Use elitist strategy to fill the generation gap.
Step 8: Repeat the steps 2 X 7 till maximum number of generations is reached or no better solution is found after the pre-determined maximum number of generations is reached. Step 9: ^ o the generations.

Step 10: Calculate the estimates of the conditionally linear parameters a through (9).

For the GA-LTS estimator, we consider the 3 M dimensional model parameter vector as Z  X  X  A 1 ; B 1 ; o 1 ; ... ; A M consider the objective function as
Min duals, the unordered squared residuals, e ( t ) 2 s, are given by (11).
The parameter space, O for the present setup for the model (1) is given by
O  X  X 1 ; 1 X  X 1 ; 1 X  X  0 ; 1  X  X 1 ; 1 X  X 1 ; 1 X  X  0 ; 1  X  R 3 M :
Similar to the GA-LS method, we first obtain the binary chromosomal representation of the parameter space O . We form, for any possible solution belonging to the original parameter space
O , a binary string of length 3Mp. p denotes the length of the binary bit representation of any component of the parameter vector Z .
The algorithmic steps for obtaining the GA-LTS estimator is similar to the steps followed to obtain the GA-LS estimates with the difference that in Step 1 we initialize the initial population now with binary strings of length 3 Mp and in Step 9 we obtain the GA-LTS estimates of the entire parameter vector.

For the GA-LMS estimator, the objective function in the GA-LTS setup is replaced by
Min
The parameter space and the algorithmic steps remain same as that of GA-LTS estimator. For the L1-norm based estimators, namely the GA-L1 estimator, the GA-LTA estimator and the GA-
LMA estimator, the parmeter space remains (17). The objective function for the GA-L1 estimator is given by Min
The algorithmic steps remain the same as the steps for obtaining GA-LTS estimator. The objective function for the GA-LTA estimator is given by deviations, the unordered j e ( t ) j s for model (1) are given by (14). Finally, for the GA-LMA estimator, the objective function for the GA procedure is given by 5. Simulation studies and real life data analysis based frequency estimation techniques for frequency estimation of various simulated sinusoidal models. We will also perform extensive simulation studies to investigate the possible effect of outliers present in the data. In the simulation studies, we consider both dependent error as well as independent error structures. We report here the performance of the following estimators: (i) genetic algorithm based least square estimator (GA-LS), (ii) genetic algorithm based least trimmed square estimator (GA-
LTS), (iii) genetic algorithm based least median square estimator (GA-LMS), (iv) genetic algorithm based L1-norm estimator (GA-
L1), (v) genetic algorithm based least trimmed absolute deviation estimator (GA-LTA), (vi) genetic algorithm based least median absolute deviation estimator (GA-LMA). Real life data analysis using the proposed methods will also be presented. 5.1. Simulation results for independent error structure component and 2-component simulated sinusoidal models with independent error structure. For the purpose of comparing the performance of the proposed robust methods with the elemental set based robust frequency estimates of Smyth and Hawkins (2000) , we consider the same models as reported therein. We report the average estimates, the root mean square errors (RMSE) and the standard deviations (St. Dev.) over 100 simulation runs.
The random numbers are generated using MATLAB random number generator. 5.1.1. One sinusoid y  X  t  X  X  cos  X  o t  X  f  X  X  e  X  t  X  ; t  X  1 ; 2 ; ... ; N :  X  22  X  o =0.5 and that of f is 0.1. e ( t ) is taken as i.i.d. normal noise sequence, with mean zero and standard deviation s =0.2. The sample size is taken as 100. The Cram er-Rao bound, which is same as the asymptotic variance of the LSE ( Kundu and Mitra, 1996 ), for the frequency parameter is 9.6E 07. For each of the simulated datasets, we estimated the frequency using the methods de-scribed in Section 4. The particular choice of the genetic parameters for the genetic formulation setup for the simulation model is given in Table 1 .
 and for the GA-LTA it is taken as 50%. The root mean square errors (RMSE), the average estimates and the standard deviation over 100 simulations for the frequency is computed for all the proposed methods. We also report, for comparison, the corre-sponding result of the best performing robust frequency estimate of Smyth and Hawkins (2000) . We also investigate the perfor-mance of the proposed estimators when data contains 30% outliers. Outliers were generated to have standard deviations 100 times that of the good observations. The outliers were associated to a randomly selected subset of 30 observations. The results for the no outlier and the outlier scenarios are presented in Table 2 .

From the results for the non-outlier case, we observe that the proposed estimators perform quite well, even for the trimmed cases. Among the proposed estimators, GA-LS and GA-L1 performs the best. The performance of the GA-LS is almost fully efficient (98%) and better than the best performing estimators ELS-LS, LTS-LI1-MM and LMS-LI1-MM (efficiency 94%) reported in Smyth and
Hawkins (2000) . We further observe that the best performing method in the non-outlier case, the GA-LS method fails com-pletely in the presence of outliers. The performance of the GA-L1 method is still quite promising. However, much better results are obtained with genetic algorithm based trimmed and least median criterion functions. The best results are obtained for the GA-LMA method. The performance of the GA-LTS with 50% trimming and the GA-LTA (80%) method is also quite encouraging. For the outlier scenario, the performances of the proposed GA-LMA and GA-LTA (80%) are better than the best performing method LTS-L1-MM (with St. Dev. and RMSE 0.00127) of Smyth and Hawkins (2000) . 5.1.2. Two sinusoids
We consider the following two-component sinusoidal model where we take the true values of the frequencies of the simulation model as o 1 =0.3 and o 2 =0.7 and that of f 1 as 0.2 and f e ( t ) is taken as i.i.d. normal noise sequence, with mean zero and standard deviation s =0.2. The sample size is taken as 100. The
Cram er-Rao bounds for the frequency parameters are same and equal to 9.6E 07. For each of the simulated dataset, we estimated the frequencies using the methods described in Section 3. The choice of the genetic parameters for the two-component sinusoi-dal model is similar to the ones mentioned for the one-component model ( Table 1 ). However, to accommodate for higher-dimensional parameter space, we form a larger chromosome pool (350) for each population. The root mean square errors (RMSE), the average estimates and the standard deviations over 100 simulations for all the frequencies are computed for all the proposed methods. Once again we also report, for comparison, the corresponding results of the best performing robust frequency estimate of Smyth and Hawkins (2000) . Similar to the one-component model, we also investigate the performance of the proposed estimators when data contains 30% outliers. Once again outliers were generated to have standard deviations 100 times that of the good observations. The outliers were associated to a randomly selected subset of 30 observations. The results for the outlier as well as the non-outlier cases are presented in Table 3 .

From the results of the two-component model, we observe that for the no-outlier scenario, GA-LS and GA-L1 methods perform the best. These estimators give super efficient estimates in the sense that their MSEs are lower than the corresponding Cram er-Rao bounds. The performances of GA-LS (efficiency of 131% for the higher frequency and 124% for the lower frequency) and GA-L1 (efficiency 113% for the higher frequency and 102% for the lower frequency) are much better than Smyth and Hawkins (2000) elemental set based methods (the reported maximum efficiency of 109% is reported for the higher frequency and 104% for the lower frequency). The performances of the genetic algorithm based trimmed criterion function estimators are also reasonably good. The results for the two-component sinusoidal model with 30% outliers are qualitatively same as the results of the one sinusoid. The results once again indicate satisfactory performance of the proposed robust estimators. 5.2. Simulation results for dependent error structure
In this subsection, we present the simulation studies for sinusoidal models with dependent error structure. 5.2.1. One sinusoid
We consider the following one-component sinusoidal model
The error structure of e ( t ) is taken as  X  t  X  X  0 : 3 e  X  t 1  X  X  d  X  t  X  ;  X  25  X  where d ( t )s are i.i.d. normal noise sequence, with mean zero and standard deviation s . We consider two different values of s , 0.01 and 0.05. The sample size is taken as 100. For each of the simulated datasets, we estimated the frequency using the methods described in Section 4. The choices of the genetic parameters for the genetic formulation setup for the simulation model are as in Table 1 . The trimming proportions for GA-LTS and
GA-LTA are taken as 80%. The root mean square errors (RMSE), the average frequency estimates and the associated standard devia-tions over 100 simulations are computed for all the proposed methods. The theoretical asymptotic standard deviation of the least squares estimator for s =0.01 is 1.044E 5 and that for s =0.05 is 5.218E 5. We next investigate the performance of the proposed estimators when data contains 30% outliers, under the correlated error structure. Outliers were generated to have standard deviations 100 times that of the good observations and associated to a randomly selected subset of 30 observations. Two representative plots of 30% outlier dataset in the dependent error setup and the corresponding GA-L1 fit of the data are given in
Figs. 2 and 3 . The results for the non-outlier as well as the outlier scenarios are presented in Table 4 .

We observe that the proposed methods are able to resolve the unknown frequency with high level of accuracy for dependent error structure as well. For the non-outlier scenario, GA-LS performs the best closely followed by GA-L1. Even the perfor-mances of the least trimmed and least median based approaches provide fairly accurate estimates. From the simulations of the outlier study, we observe that the proposed robust frequency estimation methods perform quite well. While the performance of the GA-LS deteriorates significantly as compared to non-outlier case, the performance of GA-L1 and the least trimmed and least median approaches remain fairly stable even with 30% outlier contamination in the data. We had observed similar pattern for independent errors also. The GA-L1 estimator performs the best in this situation. A further investigation reveals that for s
GA-LS totally breaks down, the robust frequency estimators still continue to give reasonably good results. 5.2.2. Two sinusoids
We consider the following two-component sinusoidal model y  X  t  X  X  1 : 0cos  X  0 : 3 t  X  X  1 : 5sin  X  0 : 3 t  X  X  2 : 5cos  X  0 : 8 t  X 
The error structure of e ( t ) is taken as e ( t )=0.3 e ( t 1)+ d ( t ), where d ( t )s are i.i.d. normal random variables, with mean zero and standard deviation s . The sample size is taken as 75. We have considered two different values of s , 0.01 and 0.1. Performances of the proposed estimators with 30% outlier contamination are also investigated. As in the previous cases, outliers were generated to have standard deviations 100 times that of the good observations and are associated to a randomly selected subset. For each of the simulated datasets, we estimated the frequencies using the methods described in Section 4. The choice of the parameters for the genetic formulation setup for the two-component dependent error simulation model is similar to that of the two-component independent error model. The results for the lower of the two sinusoids are presented in Table 5 and the results for the higher of the two sinusoids are presented in Table 6 .A representative plot of 30% outlier dataset in the two-component dependent error setup is given in Fig. 4 and the data along with the fit corresponding to GA-L1 solution is given in Fig. 5 .
For the two-component model non-outlier cases, we observe that the GA-LS performs the best closely followed by GA-L1. The theoretical asymptotic standard deviation of the LSE of o =0.8 at s =0.01 is 9.738E 6 and that for s =0.1 is 9.738E 5 and the asymptotic standard deviation of the LSE of o =0.3 at s =0.01 is 1.228E 5 and that for s =0.1 is 1.228E 4. The GA-LS almost attains these above-mentioned asymptotic values for the respec-tive frequencies. The GA estimators based on least trimmed (GA-LTS and GA-LTA) approaches also provide reasonably accurate estimates. For the outlier contaminated data, the performance of the GA-LS deteriorates significantly, especially for the higher s value. The GA-L1 and the GA trimmed and median based approaches appear to be fairly robust with respect to outliers in the data. Among the robust methods GA-L1 performs the best. 5.3. Real life data analysis In this subsection, we present the real life data analysis results.
Two different datasets, the  X  X ircadian Rhythms X  data and the  X  X ariable Star X  data, are considered for analysis. 5.3.1. Fitting Circadian Rhythms data
We consider the  X  X ircadian Rhythm X  dataset. The data was collected at the Princeton University in the late 1960s under the direction of Dr. C.S. Pittendrich. In order to observe the periodicities in the behavior of Perognathus formosus (also called long-tail pocket mouse), a nocturnal mammal, the animal was given 8 days of 12hours light and 12hours darkness as an adjustment period, which was followed by about 73 days of constant darkness ( Andrews and Herzberg, 1985 ). The data are temperature recordings made at 2-min intervals over 3 months. It is known that problems occurred during the experiment asso-ciated with transient failures of the monitoring equipment and with imperfections in the data logging process. As a result of which the data contains a good proportion of outliers. The data have been downloaded from http://www.statsci.org/data/general/ pformosu.html .

For the analysis of the Circadian Rhythms dataset, we analyze 20-min averages of the temperatures. We fit a one-component sinusoid model of the form y  X  t  X  X  K  X  A cos  X  o t  X  X  B sin  X  o t  X  to the Circadian data using GA-LTA (50% trimming) approach. The parameter initialization for genetic search is made in the following ranges: Parameter Initialization range K [ Median ( y (1) y y ( n )) 50, Median ( y (1) y y ( n ))+50] A [ 100, 100]
B [ 100, 100] o [0, p ] The final fitted model, for the first 8 days data, arrived after 13
GA generations is given below: given in Fig. 6 .
 number of outliers, but the fitted curve successfully ignores them and follows nicely the periodic pattern. The less obvious outliers, closer to the fitted curve, also do not distort the data fit. We get similar results using other proposed outlier-insensitive robust frequency estimation techniques. Fig. 7 gives fit of the data using
GA-LMA estimator. The fitted model under this approach is method, which fails completely. Considering the same dataset, it is reported in Smyth and Hawkins (2000) that the fitted frequency for the first 8 days to be 0.87273, which is very close to our frequency estimates. 5.3.2. Fitting Variable Star data frequently used data. The determination of the periodicities of a variable star and the shape of its light curve is important in studies of stellar structure and evolution. The relationship between the period and magnitude is used to determine distances on a cosmic scale, for example. The data in this example gives observations on the magnitude of a variable star, made from the
Mount Stromlo Observatory near Canberra in Australia over a period of about 250 days ( Reimenn, 1994 ). Magnitudes were recorded separately for the blue and red bands. Observation times were irregularly spaced depending on the conditions of sky and the observation schedule. We consider here the analysis of blue band measurements. A number of observations were considered to be unreliable due to observation conditions. The data have been downloaded from http://www.statsci.org/data/oz/ceph2.html.
We fit a two-component sinusoid model of the form y  X  t  X  X  K  X  A 1 cos  X  o 1 t  X  X  B 1 sin  X  o 1 t  X  X  A 2 cos  X  o using GA-LTA (50% trimming) approach. The initial population is populated from the following ranges of the respective parameters: Parameter Initialization range K [ Median ( y (1) y y ( n )) 0.5,
A 1 , A 2 [ 0.5, 0.5]
B 1 , B 2 [ 0.5, 0.5]
The final fitted model is y  X  t  X  X  0 : 01992 0 : 0128cos  X  0 : 1247 t  X  X  0 : 2032sin  X  0 : 1247 t  X  The plot of the observed data and the fitted model is given in
Fig. 8 . We observe from the plot that the fit ignores the outliers and is able to trace the correct sinusoidal pattern.

Smyth and Hawkins (2000) considered the same dataset for testing the usefulness of their robust frequency estimation technique. For implementation of their method, which requires time points to be equidistant, the data was first interpolated linearly onto an equally spaced grid of time points of the same length, no such preprocessing of the data is required for implementation of our methods. The estimated frequencies reported in Smyth and Hawkins (2000) are 0.126 and 0.253, which once again are close to our frequency estimates.
The GA-LTA estimates of the frequencies 0.1247 and 0.2461 correspond to periods of 50 and 25 days. The star is therefore determined to be periodic with period of about 50 days. 6. Conclusion
In this paper, we propose genetic algorithm based robust frequency estimation techniques for multiple sinusoidal models with correlated error structures. The proposed methods use genetic search technique for optimizing various outlier-insensitive criterion functions. The methods do not require the data points to be equidistant or the noise sequence to be independent Gaussian structure, which is otherwise required in other robust frequency estimation techniques for this model (see for example Smyth and Hawkins, 2000 ). Furthermore, the GA based robust frequency estimation techniques search a population of possible optimal solutions in parallel and do not require derivative information or other auxiliary information, only the levels of fitness influence the direction of search. Another advantage of using the proposed methods is that since they are based on genetic algorithms they use probabilistic transition rules and have potentially high chance of converging to the optimal solution.

In the simulation studies and real life data analysis, it is observed that the proposed genetic algorithm based robust frequency estimators, optimizing outlier-insensitive criteria are able to resolve frequencies of the sinusoidal model with high degree of accuracy and provides reasonably high breakdown point robust estimates.
 Acknowledgement The work is supported by Department of Science &amp; Technology, Government of India, Grant no. SR/S4/MS:374/06.
 References
