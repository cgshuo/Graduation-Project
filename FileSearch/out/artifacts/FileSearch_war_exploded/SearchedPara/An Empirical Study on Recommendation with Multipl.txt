 User feedback like clicks and ratings on recommended items pro-vides important information for recommender systems to predict users X  interests in unseen items. Most systems rely on models trained using a single type of feedback, e.g., ratings for movie rec-ommendation and clicks for online news recommendation. How-ever, in addition to the primary feedback, many systems also allow users to provide other types of feedback, e.g., liking or sharing an article, or hiding all articles from a source. These additional feed-back potentially provides extra information for the recommenda-tion models. To optimize user experience and business objectives, it is important for a recommender system to use both the primary feedback and additional feedback. This paper presents an empir-ical study on various training methods for incorporating multiple user feedback types based on LinkedIn recommendation products. We study three important problems that we face at LinkedIn: (1) Whether to send an email based on clicks and complaints, (2) how to rank updates in LinkedIn feeds based on clicks and hides and (3) how jointly optimize for viral actions and clicks in LinkedIn feeds. Extensive offline experiments on historical data show the effectiveness of these methods in different situations. Online A/B testing results further demonstrate the impact of these methods on LinkedIn production systems.
 Recommender System; Personalized Recommendation; Multi-objective Optimization
Recommender systems have been applied to a wide range of ap-plications, such as recommending news articles, movies, books, and research papers. Recommender systems seek to predict the  X  X reference X  that a user would give to an item. A typical way for recommender systems to provide recommendations is to build a model based on users X  historical feedback (previously clicked, pur-chased or selected and/or numerical ratings given to those items); then use that model to predict items (or ratings for items) that the users may have an interest in the future.

As modern recommender systems become more complicated and touch more aspects of user experience, there has been a rapid in-crease in demand for a variety of user feedback to be incorporated into a recommendation model. A few examples are in the follow.
Incorporating multiple types of user feedback in a recommenda-tion model has become an important challenge for more and more recommender systems, though the related research is still relatively new in the field of recommendation. An intuitive solution to the problem is simply incorporating different feedback types into la-bels in training data, e.g., for click and hide feedback, we can label data instances such that click is 1, non-click is 0, hide is -1. How-e ver, this will change the original binary classification model to a multinomial model and a multi-class prediction problem. It is not favorable for the recommendation and ranking purpose, because it generates multiple ranking scores and multiple ranking recom-mendations for each item. Keeping the same type of models, like binary classification model, and handling an additional feedback inside the model itself is a more preferable and scalable solution for most recommender systems. Furthermore, in a lot of situations, some additional feedback may not be able to put into labels. For example, downstream utilities such as page views are not easily put into binary labels as clicks.

In this paper, we only focus on generalized linear model based recommendation algorithms, which predict the user X  X  interest and rank items based predicted interests. The performance of recom-mendation heavily depends on the accuracy of prediction. At LinkedIn, this type of algorithms is widely used in many products since con-tent information, such as user profile and job information, are avail-able for models. Collaborative filtering based approaches, such as matrix factorization, are mainly used in feature engineering to gen-erate latent features for the generalized linear models.
The first method we consider is model combination, i.e., train-ing one model for each feedback data then combining all models into a single model. This approach is feasible if the outputs of all models are the ranking scores or recommendation scores for dif-ferent feedback types. For example, two logistic regression models for click data and hide data can be combined. We can either com-bine the predicted responses of the models or combine the model coefficients if the two models are in the same feature space and for-mulations are also the same. Additional weight parameters control the tradeoff of the importance of different types of feedback.
The second method is a sequential training based on Bayesian inference. In the previously mentioned example of the click feed-back and hide feedback, we first train a model only using the click data and then use the model as the prior to train the final model using the hide feedback data. The final model fits the hide data but is also regularized by the click model. In general, we sequentially train the model for each feedback type where the prior is utilized to incorporate the previous model.

The third method is joint training, where we put multiple feed-back types into a single training problem. The joint training still has one primary feedback to optimize, but we incorporate other secondary feedback as constraints to regularize the optimization problem. This constrained optimization framework can be applied to various recommendation applications. It is capable of incorpo-rating some additional feedback types that are very different from the primary feedback type without changing the original recom-mendation model; i.e., there is no need to revise the online recom-mendation system to support multiple models and scorings. Mean-while, in many applications, a certain correlation exists in different types of user feedback. For example, clicks and hides are often negatively correlated; the likes and clicks are positively correlated.
In this paper, we present an empirical evaluation on the three methods based on LinkedIn recommendation products. We study three important problems that we face at LinkedIn: (1) Whether to send an email based on clicks and complaints, (2) how to rank feed updates in LinkedIn feeds based on clicks and hides and (3) how jointly optimize for the viral actions and clicks in LinkedIn feeds. Extensive offline experiments on historical data show the effective-ness of these methods in different situations. Online A/B testing results further demonstrate the impact to LinkedIn production sys-tems with real traffic. Meanwhile, model combine has been adopted by the current LinkedIn feed modeling in both desktop and mobile platforms to promote viral actions and improve the overall liquidity of the users X  social network.

The rest of this paper is organized as follows. In Section 2, we formally introduce the problem of recommendation with multiple types of feedback. Detailed description for the three methods that we evaluated is presented in Section 3. Section 4 briefly discusses the implementation of the training algorithm. Extensive empiri-cal evaluation results are reported in Section 5. Section 6 presents a brief summary of prior work relevant to the multi-feedback and multi-criteria recommendation problems, and transfer learning. Fi-nally, Section 7 concludes the paper.
Recommender systems build a model from users X  historical im-pressions and feedback, such as clicks, hides, likes, shares, com-ments, and purchases etc. In LinkedIn, the recommendation mod-els usually consider multiple user feedback. For instance, LinkedIn feeds models aim to maximize the click per impression (CTR), but also minimize the hide per impression since hide is a strong nega-tive feedback. Meanwhile, like, comment and share are more im-portant than click because they can significantly increase the viral-ity of the contents and the liquidity of the social network. Hence, those actions are important feedback to maximize in recommenda-tion as well. Therefore, our recommendation model has multiple objectives.

We denote our data as P = { ( x i , y (1) i , y (2) i , ..., y where x i is the feature vector of the i -th impression, which includes the user features and item features, y (1) i , ... , y ( m ) ent types of feedback received in this impression. All the feedback are represented as binary variables: 1 or 0. For instance, y indicates there is a click action and 0 indicates this impression does not receive any click. The recommendation model calculates the ranking score for each impression and selects (or ranks) the items based on the ranking scores. Let f ( x i ,  X  ) be the ranking score of a given feature vector x i , where f is the model function and  X  is the coefficient vector of the model. For instance, we use the logistic regression to predict the CTR of articles. In this model, the rank-ing score is the predicted CTR, f ( x i ,  X  ) = 1 / (1 + exp(  X  Selecting the articles with high predicted CTRs can maximize the received click feedback from the users in future.

The problem that we study in this paper is to build a recommen-dation model that maximizes (or minimizes) m types of feedback received from users respectively, where the m types of feedback are pre-defined. For instance, for job recommendation at LinkedIn, two typical types of user feedback are click and dismiss. Click is a positive feedback that indicates the user is interested in the recom-mended job. However, dismiss is a strong negative feedback that indicates the user is upset by seeing this job recommendation. The desired model should be able to maximize the number of received clicks and minimize the number of received dismisses simultane-ously. It is worth to mention that we still need a single model to make the recommendation decision for each job posting, which is recommend or not recommend.
When the number of feedback types m &gt; 1 , the studied problem is a multi-objective optimization or multi-task learning problem. We explored three potential methods for solving this problem based on LinkedIn products and data. The first simple method is called model combine . Basically, this method trains an individual model for each objective. Since there are m feedback types, it has m in-dividual models, f 1 , ..., f m . The final model is the combination of f , ..., f m . A simple combination is the weighted linear combina-tion, such that the final model f ( x i ,  X  ) = P m j =1 w where w j is the weight parameter to control the tradeoff between different objectives and  X  j is the model coefficient for the model j , where j = 1 , ..., m . This method can train the models in parallel and compose the final model in the end.

Besides training the individual models in parallel, we also ex-plored a sequential training method. Let L be the loss function for the training algorithm for each feedback. We sequential solve the model coefficients  X  1 , ...,  X  m by the following series of optimiza-tion problems, The final model is the last model with coefficient  X  m . The idea of this method is to utilize the previous model as the prior to regu-larize the next model, so that the training result from the previous model can be transmitted to the next model. The final recommen-dation model is the last model that should contain the information of all the m models. Thus, we call this method as prior combine . Some literatures also mention this method is a warm-start training, in which they consider the old model as the prior or starting point, and use the new training data to train the new model. It is worth to mention that the method has two assumptions. First, the prior model X  X  coefficient is a multivariate normal distribution and sec-ond the variance of each dimension is identical and determined by the inverse of w j . However, the assumption may not exist in many high dimension data. In practice, it is very common that some of the features are sparse and some of the features are dense in real world high dimensional data. Thus, the associate coefficients have very distinct variances.

The third method is the joint training, where all types of feed-back are utilized in a single joint optimization problem for the final model. The general form is, where L is the joint loss function. There are lots of different ap-proaches to compose the joint loss L . For instance, L is a linear combination of a logistic loss and a constraint loss (e.g., the hinge loss). In this instance, where w 1 , w 2 are the weight parameters, c is a given positive pa-rameter, and y (2) i is a strong negative feedback from users (e.g., hide and dismiss). The hinge loss, max(0 , y (2) i ( c + f ( forces the ranking score f ( x i ,  X  )  X   X  c if y (2) i = 1 . Thus, it is a constrained optimization. It aims to minimize the loss from the primary feedback y (1) i subject to the constraints f ( x i if y (2) i = 1 . The weight w 2 determines the hardness of the con-straints. If w 2 is an arbitrary large number, the constraints are hard constraints. Similarly, if y (2) i is a strong positive feedback from users (e.g., like or apply a job), an example of L is where the hinge loss, max(0 , y (2) i ( c  X  f ( x i ,  X  ))) , forces the rank-ing score f ( x i ,  X  )  X  c if y (2) i = 1 . It is common that a recommen-dation model has one primary type of feedback (e.g., click) with other secondary types of feedback (e.g, hide and dismiss). The sec-ondary types of feedback are either strong positive or strong neg-ative, so we utilize them as constraints to regularize the primary feedback optimization problem. This method is called constrained regression in this paper. In many applications, different types of user feedback may have some correlation. For instance, in the LinkedIn feeds, the click and like are positive correlated, while the click and hide are negative correlated. In these situations, the con-straints from the secondary types of feedback can help the learning algorithm better regularize the primary feedback learning. At the same time, the primary feedback also helps the learning algorithm find more reliable solutions subject to the constraints. This correla-tion of feedback is quite useful in some practical scenarios because the strong negative or positive feedback is often very rare in online systems. For instance, the total number of received clicks can be more 100 times larger than the total number of received hides in a same time period. Such rare feedback can hardly build a good rec-ommendation model. But if we add a large amount of correlated feedback data to train jointly, the model performance can be im-proved. In machine learning, this technique is defined as Transfer Learning [8, 32, 10, 2, 3, 4, 27], in which each feedback refers to a domain. In the experimental section, we will discuss several cases where this transfer learning works and several other cases where it does not work based on LinkedIn data. Table 1 shows several loss functions that are widely used in our recommendation models, where y i is the label of a feedback and x i is the corresponding fea-ture vector of the impression. The last loss is a pairwise loss, where x is the feature vector of another impression.

The three methods have various advantages and disadvantages in different data sets. prior combine takes the trained results from the previous model to regularize the next model X  X  fitting. It has an initiative explanation based on Bayesian inference. model com-bine trains different models separately, where each model only has one objective so its training can easier coverage to its own optimal solution. constrained regression is a joint training, which utilizes multiple types of feedback together and is potentially to obtain a better joint optimal solution. It is difficult to theoretically deter-mine which method is the best one in different particular cases. In this paper, we only focus on the empirical evaluation based on LinkedIn data.
The offline training data is collected from a random bucket of users, where the historical recommended items are randomly se-lected to the users in order to avoid the sample bias and serving b ias. In the algorithm implementation, we only focus on the convex loss function of L . In order to speed up the offline model training, we apply the coordinate gradient descent algorithm [37]. This al-gorithm minimizes the total loss function along one dimension at a time. On each dimension, it only goes one step along the opposite gradient direction. Recent studies have shown that the efficiency of this coordinate-wise optimization method is superior to many con-vex optimization algorithms in practice [37, 16]. Another advan-tage of this algorithm is that, it does not need to employ the back-tracking linear search [31] to calculate the appropriate step size. Instead, it fixed the step size to be the inverse of the Lipschitz con-stant [5] of  X  L . The Lipschitz constant of  X  L provides an upper bound of the step size on each dimension, which is not conservative in coordinate-wise algorithms. We found this trick can significantly improve the efficiency of the algorithms in our model training.
Let d be the dimensionality of the data space,  X  ( i ) denote the i -th element of the vector  X  , and l i be the Lipschitz constant of ( i ) , i = 1 , 2 , ..., d . Algorithm 1 presents the pseudocode of the Algorithm 1 C oordinate Gradient Descent with Lipschitz Constant 1:  X   X  0 4: for i = 1 , 2 , ..., d do 6 : end for 7: end while algorithm, where each dimension X  X  Lipschitz constant l i is precom-puted before entering the algorithm,  X  is the tolerance parameter for the stopping criteria, which is the same definition for libLinear and libSVM 1 . This algorithm is flexible since it only requires the first order information of the total loss function L and the Lipschitz con-stant of  X  L . In this paper, for the offline experiments, the training algorithm is implemented in a single machine. For the online A/B testing, we apply the large scale of distributed optimization algo-rithm ADMM to scale up the production model training [ ? ].
We present the empirical evaluation to answer the following im-portant questions for recommendation with multiple types of feed-back. First, what kind of feedback is feasible to be incorporated in a practical recommendation model? Second, how to select a suitable method for a particular application? Third, how do the different approaches perform for the real applications?
Email is one of the most useful channel to improve the user engagement in social network industry. LinkedIn email recom-mender system aims to rank LinkedIn email candidates, such as news article content,  X  X eople you may know X  and job postings, and then send top ranked emails to members. The primary feedback is click/non-click from members after they receive the emails. At the same time, the system records other types of feedback, such as complaints. The complaints include the actions of unsubscribing and labeling emails as spams. While the system optimizes CTR to boost member engagement, it is also desirable to minimize the complaints from the users. As described in Section 3, in this prob-lem the number of types of user feedback is m = 2 , click and h ttps://www.csie.ntu.edu.tw/ cjlin/liblinear/ complaint. The objective is to maximize the CTR and minimize the complaint rate for each sent email.

We investigate the three potential methods described by Sec-tion 3 in the email recommendation experiment. For prior com-bine , we implement two algorithms,  X  X rior Combine(Click)" and  X  X rior Combine(Complaint)", where the first one uses the click data to train the prior model and the second one uses the com-plaint data to train the prior model. For constrained regression , we also implement two algorithms,  X  X onstrained(Complaint)" and  X  X onstrained(Click Complaint)", where the first one only uses the complained emails as the constraints and the second one uses both clicked and complaints emails to establish the constraints. We tested the squared hinge loss and logistic loss for the click and complaint feedback, but there is no significant difference for the experimental results. For each algorithm, we vary the weight parameter w regularization weight  X  for model training. As a result, for each approach, we obtain 60 -70 models based on different parameter combinations.
The training and testing data is from the historical logs of a ran-dom bucket, i.e., the system randomly sent emails to a group of members and recorded their feedback. Thus, there is no serving bias for the training and testing data. We use around 2.5K features to build the recommendation model for this study. The features mainly consists of the member features, content features and inter-action features. The member feature includes the member X  X  profile data, such as the job title, education, company and industry cate-gory. The content features describe the content of the emails that we want to notify the member. The interaction feature represents the interests of a particular type of member to a particular category of emails. Table 2 summarizes the details of the data sets. We split the training data and testing data by the member Ids, so that there is no member who both appears in the training and testing data. Feedback #Members for Training # Members for Testing Click 350K 1.2M
Complaint 460K 1.3M
T he evaluation metric is AUC (Area Under ROC curve) [ ? ]. An intuitive explanation of the AUC is the probability of a positive in-stance being ranked higher than a negative instance. Since there are two types of feedback, we consider the click AUC and non-complaint AUC at the same time to evaluate the model perfor-mance. The non-complaint is the opposite of the complaint. If the user did not complaint an email, the non-complaint feedback is 1, otherwise it is 0. Minimizing the complaint rate is equiva-lent to maximizing the non-complaint rate. A clicked email should have a higher ranking score than a non-clicked email. A non-complained email also should have a ranking higher core than a complained email. Therefore, click AUC and non-complaint AUC are higher,then the model performance is better. If model A has a both higher click AUC and non-complaint AUC than another model B , then we are sure that model A is better than model B . In multi-objective optimization, we say model A dominates model B [33]. If model A has a higher click AUC but a lower non-complaint AUC than model B , then we do not know A is better or worse than B . In this paper, our goal is to evaluate the potential training methods, not particular models, because two models with different tradeoffs may not be comparable. Since we vary different weights of click a nd non-complaint feedback, the tradeoff between the click AUC and the non-compliant AUC is also varied. If an algorithm P gener-ates more models that dominate the models generated by algorithm Q , then we can say the algorithm P is better than Q in most cases.
Figure 1 shows the click AUC and non-complaint AUC of each training method on the test data sets. To protect the user privacy, we show the experiment results in terms of normalized AUC. The nor-malized click AUC is the click AUC divided by the click model X  X  AUC, where the click model is trained only by the click data. Like-wise, the normalized non-complaint AUC is the non-complaint AUC divided by the complaint model X  X  AUC, where the complaint model is trained only by the complaint data.

As shown by Figure 1, we observe that incorporating complaint feedback does not hurt our model X  X  CTR performance too much, but it significantly decreased the complaint rate more than 40% in some area. The constrained regression and model combine have the best tradeoff between the click AUC and non-complaint AUC. They can improve the non-complaint AUC from 0.4 to 0.7 by sacrificing the click AUC as little as 0.18. For other methods, to achieve the same non-compliant AUC, they have to sacrifice larger click AUC. It is worth to note that the constrained regression with only com-plaint constraints performs worse rapidly when the weight for com-plaints becomes large. This is because when the complaint weight is larger, the regression algorithm spends more much effort to fit the complaint data points. As a result, the entire data set becomes highly imbalance with more negative feedback. If we put both click and complaint data points into the constraints, constraints set are well balanced as shown by  X  X onstrained(Click Complaint)", then it performs better than  X  X onstrained(Complaint)". The performance of data combine approach is almost identical to constrained regres-sion . The two algorithms based on prior combine perform much worse than the other algorithms. This is because this prior com-bine method only utilizes the coefficient mean of the prior model into the L2 regularizer for the next model training. As we discussed in Section 3, the assumption that the prior model coefficient is a multivariate normal distribution and each dimension has an iden-tical variance may not hold. In the email data, some member and content features are very sparse or very dense so that the corre-sponding coefficients should have very different variances. Using an inappropriate prior can make the final model worse.

In practice the size of the secondary feedback varies a lot in dif-ferent applications and time periods, to illustrate the the situation that the secondary feedback data is scarce, we randomly sample only 100 complained emails for training in the experiments. Figure 2 shows another AUC comparison for all the methods. As shown in the figure, constrained regression shows a better tradeoff curve of click AUC and non-complaint AUC than other methods. In other words, for the same AUC on non-complaints, constrained regres-sion models show a higher AUC on the click feedback. For exam-ple, for the models with non-complaint AUC 0.85, the constrained regression models achieve around 0.99 on normalized click AUC, while the model combine models only achieve around 0.96. Since there are only 100 complained data points, the model for predicting complaint feedback has a high variance, which also hurts the per-formance of the combined model. A few outliers in the 100 data points can ruin the entire compliant model in model combine . On the other hand, constrained regression is a joint training that uses the click data and complaint data together. The large number of click data can regularize the joint model to be more robust to these outliers in complaint data. By this way, the correlation between the c lick feedback and complaint feedback help constrained regression achieve better performances than model combine .
 Figure 2: AUC Tradeoff on Email Data (100 Complaints in Train)
LinkedIn feeds are mainly ranked by relevance models, which aim to maximize the user engagement and other business metrics. The user engagement is represented by the number of user clicks on feed items, which also include like, share, comment and other social actions. We apply the logistic regression model to predict the click probability for each item, and then rank all feed items based on the predicted click probabilities in descending order. Beside like, comment, share and other positive feedback, the users can also provide negative feedback by hiding certain feed items if they do not want to see certain feed updates again. The hide action is a strong negative feedback for user experiences. Therefore, while the ranking system optimizes CTR of feeds, it is also important to eliminate the future user X  X  hide feedback to minimize the negative impact to user experience.
We investigate the three methods described by Section 3 in this experiment. Like the LinkedIn email experiment, for prior com-bine , we implement two algorithms,  X  X rior Combine(Click)" and  X  X rior Combine(Hide)", where the first one uses the click data to train the prior model and the second one uses the hide data to train the prior model. For constrained regression , we also imple-ment two algorithms,  X  X onstrained(Hide)" and  X  X onstrained(Click Hide)", where the first one only uses the hidden impressions as the constraints and the second one uses both clicked and hidden im-pressions to establish the constraints. The training data and testing data are summarized in Table 3. Both data sets are sampled from the historical impressions of a ran-dom bucket, where we randomly shuffle the ranking list of feeds to a small group of users and collect the feedback in order to avoid the sample bias. The number of features is around 4.5K, which in-clude the member profile features, item X  X  features, and member X  X  past behaviors etc. [ ? ] lists the details of the LinkedIn feeds rank-ing model in production systems. Since in feed ranking, different Feedback #Impression for Training #Impression for Testing Click 810K 64.6M
Hide 410K 1.3M feed positions have different biases to the CTR and hide rate, we s elect to use precision at top K as the evaluation metric instead of AUC, because AUC estimates the classification accuracy of items without considering the feed position. Based on the ranking order of feeds from each model, the CTR and hide rate on top K posi-tions are calculated for each model. If a model A has a higher CTR and a lower hide rate than model B by precision at top K , then the model A is better than model B , and A dominates B . For each potential method, we vary different weight parameters and also the regularization weights for model training. As a result, we gener-ate 60 -70 models for each method based on different parameter combinations.

Figure 3 shows the CTRs and non-hide rates for top 1, 3 and 5 positions by precision at top K , K = 1 , 3 , 5 respectively. The non-hide feedback is the opposite of the hide feedback. To pro-tect the user privacy, we only show the normalized CTR and non-hide rate in this paper. The normalized CTR is the CTR divided by the click model X  X  CTR, where the click model is trained only based on the click data. Likewise, the normalized non-hide rate is the non-hide rate divided by the hide model X  X  non-hide rate, where the hide model is trained only based on the hide data. The com-parison results are similar as in the experiment for the email rec-ommendations. prior combine performs much worse than other methods. constrained regression shows slight better tradeoffs than model combine on the high non-hide rate areas. It is also interesting to see that, some constrained regression models have higher non-hide rates than the hide model that is trained purely based on the hide feedback data. This observation reveals the effect of transfer learning, because the click action and non-hide action have a cer-tain correlation. The large mount of click feedback data helps the joint model to build a better prediction on hide actions.
To further study the performance of these methods, we conduct online A/B testing experiments in LinkedIn production systems. We launch 4 models of constrained regression , where each model is randomly allocated to serve a certain percentage of LinkedIn desk-top users. It is worth to note that the members in the training data has no intersection with the members in the online testing. This A/B testing lasts for one week. We set the weight parameter w the constraints according to  X  : , where N  X  click is the number of negative click data points and hide is the number of negative hide data points (or the hided items) in the training data. Meanwhile, w 1 = 1  X  w 2 is the weight for the logistic loss of the click data.  X  can be explained as the ratio of the constraint loss to the entire loss from negative data, therefore, it is more intuitive than directly setting up the w 2 .
The online testing experiment is deployed on two types of LinkedIn homepage. The first one is the old LinkedIn homepage, which has lower CTRs and hide rates, but the online traffic is large. The other one is the new homepage, which has a smaller online traffic but higher overall user engagements in terms of CTRs and hide rates. Tables 4 and 5 show the online results of the online experiment in the two types of LinkedIn homepage respectively. The control m odel is the one with  X  = 0 , i.e., the control model is trained only with the click data. The CTR and hide rate are calculated in
Table 5: Feed Relevance Online A/B Testing in New Homepage the page view level, which are the total number of clicks or hides d ivided by the total number of page views. As shown in the two tables, the CTRs have a small positive lift compared against the control model. It shows that the hide feedback provides additional signals about the member X  X  interest that benefit the click modeling. Meanwhile, the three experimental models decrease the hide rate from 1 to 12 percent. Although the effect of hide rate decreasing is not as large as offline experiments, it is clear enough to demon-strate that this method can successfully incorporate the hide feed-back without losing CTR in a real online system.
Like, share and comment are called viral action in LinkedIn feeds, because these actions can generate the new feed updates for the user X  X  neighbors, such as  X  X  shared an article Y",  X  X  liked an post of Z". Therefore, encouraging viral actions can improve the liquidity of the social network. In LinkedIn feeds, viral actions are more important than the other click actions, such as pure click, connect, follow and play. However, the volume of pure click feed-back is much larger than the volume of viral actions in LinkedIn feeds. We cannot only use the viral action feedback to train the ranking model because it would lose plenty of useful signals from the clicks. It is worth to mention that the viral action is a subset of the click action. There are other types of click actions that do not generate new feed updates in the social network.

The objective of the ranking model is to maximize the CTR and viral action rate simultaneously. Compared with the hide action, the viral action is more correlated with the click action since the viral action is a subset of the click action.

Table 6 summarizes the volume of the training data and testing data in the experiment. The features of the feed ranking model are same as in the previous experiment for hide actions. The details of the model can be found in [ ? ].
 Feedback #Impression for Training #Impression for Testing Click 1M 29.5M Viral Action 1M or 2M 29.5M
In this experiment, the c onstrained regression algorithm consid-ers the click data as the primary feedback and put viral actions as positive constraints. prior combine still has two algorithms that consider the click model and viral action model as the prior respec-tively. We vary the weight parameters to obtain various tradeoff between the CTR and viral action rate for each algorithm.
The performance metric is still the precision at top K for clicks and viral actions. Due to the space limitation, we only show the experimental results of K = 1 .
 Figure 4: Top 1 Position : CTR and Viral Action Rate (1M Viral A ctions in Train) Figure 5: Top 1 Position : CTR and Viral Action Rate (2M Viral A ctions in Train)
Figures 4 and 5 show the experimental results for all experimen-tal models, where the number of viral action training data is 1M and 2M respectively in the two figures. To protect the user pri-vacy, we only show the normalized CTR and normalized viral ac-tion rate. The normalized CTR is the CTR divided by the click model X  X  CTR, where the click model is trained only based on the click data. Likewise, the normalized viral action rate is the viral action rate divided by the viral model X  X  viral action rate, where the viral model is trained only based on the viral action data. It is clear to see that c onstrained regression achieved a better trade-off than other algorithms in both figures. For example, to achieve 1.0 normalized viral action rate, constrained regression models can maintain 98% of the original CTR, however, model combine needs to lose 4% CTR.

Recall that in the previous experiment on hide actions, constrained regression and model combine have similar performances. How-ever, in this experiment, constrained regression performs better than model combine . It is probably because the correlation between the click and viral action is larger than the correlation between the click and hide action. Therefore, constrained regression obtains a bigger gain from the joint training. Currently, LinkedIn feed pro-duction system adopts the model combine method to promote viral actions in both desktop and mobile platforms. The major reason is that, model combine only needs to train two individual models and vary the weights to obtain various tradeoffs, but constrained regression requires to retrain the joint model for each weight pa-rameter and tradeoff. In future, we will conduct the A/B testing experiments to evaluate constrained regression for the click/viral action tradeoff in production systems.

In summary, for the three potential methods, model combine and constrained regression have a clear better performance than prior combine . If the multiple types of feedback has a certain correla-tion and some type of feedback has very small data, constrained regression performs better than model combine .
Multi-Criteria Recommendation: Many product recommender systems has different ratings for one product, such as story rat-ing and the visual effect rating for one movie. Users also have different interests and preferences on those aspects. The goal of multi-criteria recommender systems is to maximize interests of all aspects interests at the same time. To achieve this goal, collabora-tive filtering based algorithms and content based algorithms have different approaches. Collaborative filtering based algorithms con-struct a rating vector of a user provide for an item. Each user X  X  neighbors are computed based on their rating vectors to items, in-stead of a single rating variable [24, 1]. The preferences on differ-ent rating aspects can be substitute as the weights into the distance function of two rating vectors. Content based algorithms are based on the feature based learning models to predict the user interests. When the user has multiple interests, it can naturally build multiple learning models for predicting those interests [33]. For each user, the algorithms selects the Pareto optimal items to recommend [30]. Those work are similar to the model combine and response com-bine methods in this paper. They do not explore the benefit of the dependent responses to the user modeling. Besides the accuracy of the user interests, many research studies also consider some item X  X  criteria, such as the item diversity [40, 25] and the novelty [23, 20, 15]. Other criteria including confidence, trust, risk, robustness, and privacy are also mentioned in the survey [35]. Those criteria are the constraints for the recommended items. Our work in this paper fo-cuses on the criteria from the user X  X  explicit feedback or response.
Transfer Learning: Another related field is transfer learning.Transfer learning approaches can be mainly categorized into three classes. A popular class of transfer learning methods is instance-based [6, 11, 28, 7, 19, 13, 36], which assumes that certain parts of the data in the source domain can be reused for the target domain by re-weighting. [21] proposed a heuristic method to remove  X  X is-leading" training instances from source domain so as to include  X  X ood" instances from labeled source-domain instances and unla-beled target-domain instances. [11] introduced a boosting algo-rithm, TrAdaBoost, which assumes that the source and target do-main data use exactly the same set of features and labels, but the distributions of the data in the two domains are different. TrAd-aBoost attempts to iteratively re-weight the source domain data and target domain data to reduce the effect of the  X  X ad" source data while encourage the  X  X ood" source data to contribute more for the target domains. [6] proposed a framework to simultaneously re-weight the source domain data and train models on the re-weighted data with a kernel logistic regression classifier.

Another category of approaches can be viewed as model-based approaches [34, 26, 14, 9], which assumes that the source tasks and the target tasks share some parameters or priors of their models. An efficient algorithm MT-IVM [26], which is based on Gaussian Process (GP), was proposed to handle multi-domain learning case. MT-IVM tries to learn parameters of GP over multiple tasks by assigning the same GP prior to the tasks. Similarly, Hierarchical Bayes (HB) is used with GP for multi-task learning [34]. [14] bor-rowed the idea of [34] and used SVMs for multi-domain learning. The parameters of SVMs for each domain is assumed to be sepa-rable into two terms: a common term across tasks and a task spe-cific term. [29] proposed a consensus regularization framework for transfer learning from multiple source domains to a target domain.
The third category of transfer learning approaches are feature based. [8, 32, 10, 2, 3, 4, 27], where a feature representation is learned for the target domain and used to transfer knowledge across domains. A structural correspondence learning (SCL) algo-rithm [8] is proposed to use unlabeled data from the target domain to extract features so as to reduce the difference between source and target domains. A simple kernel mapping function is intro-duced in [12], which maps the data from both domains to a high-dimensional feature space. [32] proposed to apply sparse coding, an unsupervised feature construction method, to learning higher level features across domain. On the other hand, heterogeneous transfer learning starts to attract attention very recently. We notice that [39] extends PLSA to a specific application, using social Web data to help image clustering; [38] proposes a manifold alignment based approach for heterogeneous domain adaptation; [18] formu-lates heterogeneous transfer learning as multi-task and multi-view learning and proposes a graph-based solution; [17] focus on sin-gle task learning with multiple outlooks, which is also related to heterogeneous transfer learning.
Learning multiple user feedback in a recommendation model has become an important challenge for recommender systems. Related research on multiple feedback is relatively new in the empirical study of recommender systems. This paper presents an empirical study on the methods for incorporating multiple types of user feed-back into a single recommendation model. We investigate three common training methods, prior combine , model combine and con-strained regression in this study. We conduct extensive experiments based on LinkedIn products and real historical data. In the ex-periments, we show how to use the methods to find the various tradeoff of the click/complaint in LinkedIn email recommendation, click/hide and click/viral action in LinkedIn feeds ranking. Based on our experimental results, prior combine does not perform well since its assumption for the prior model and prior distribution often does not hold in many real data. If each user feedback has enough training data, the performance of model combine and constrained regression are very close. But if some feedback data is rare, another feedback data is large, and the two types of feedback have a certain correlation, then constrained regression performs better than model combine . In this situation, constrained regression is actually doing a transfer learning. The correlated two types of feedback data help th e model to better regularize the fitting on each other.
In addition to the offline experiments with historical data, we also conduct the online A/B testing for evaluating the constrained regression method for click/hide problem in LinkedIn feeds rank-ing based on a large amount of real users. The online A/B testing results also confirm the effectiveness of this method. The launched models can reduce 12% of the hide rate without hurting the CTR comparing against the control model.

As for the future work, we consider more advanced joint training methods to incorporate multiple types of feedback into recommen-dation, such as the constrained matrix factorization in collaborative filtering based on recommendation. Also, we continue to explore more advanced methodologies from transfer learning into the mul-tiple feedback recommendation and utilize the relationship of dif-ferent types of feedback to provide more accurate personalized rec-ommendation. Meanwhile, we will continue to explore and solve other problems of the multiple types of feedback recommendation. For instance, in LinkedIn job recommendation, the user can apply a job or dismiss the job posting, where apply/not apply is the primary feedback and dismiss/not dismiss is a secondary feedback. [1] G. Adomavicius and Y. Kwon. New Recommendation [2] R. Ando and T. Zhang. A high-performance semi-supervised [3] A. Argyriou, T. Evgeniou, and M. Pontil. Multi-task feature [4] A. Argyriou, C. Micchelli, M. Pontil, and Y. Ying. A spectral [5] A. Beck and M. Teboulle. A fast iterative [6] S. Bickel, M. Br X ckner, and T. Scheffer. Discriminative [7] J. Blitzer, K. Crammer, A. Kulesza, F. Pereira, and [8] J. Blitzer, R. McDonald, and F. Pereira. Domain adaptation [9] E. Bonilla, K. Chai, and C. Williams. Multi-task gaussian [10] W. Dai, G. Xue, Q. Yang, and Y. Yu. Co-clustering based [11] W. Dai, Q. Yang, G. Xue, and Y. Yu. Boosting for transfer [12] H. Daume. Frustratingly easy domain adaptation. In Annual [13] H. Daume III and D. Marcu. Domain adaptation for [14] T. Evgeniou and M. Pontil. Regularized multi-task learning. [15] F. Fouss and M. Saerens. Evaluating performance of [16] J. Friedman, T. Hastie, and R. Tibshirani. Regularization [17] M. Harel and S. Mannor. Learning from multiple outlooks. [18] J. He and R. Lawrence. A graph-based framework for [19] J. Huang, A. Smola, A. Gretton, K. Borgwardt, and [20] N. Hurley and M. Zhang. Novelty and diversity in top-n [21] J. Jiang and C. Zhai. Instance weighting for domain [22] T. Joachims. Optimizing search engines using clickthrough [23] N. Kawamae. Serendipitous recommendations via [24] K. Lakiotaki, N. F. Matsatsinis, and A. Tsouki X s.
 [25] N. Lathia, S. Hailes, L. Capra, and X. Amatriain. Temporal [26] N. Lawrence and J. Platt. Learning to learn with the [27] S. Lee, V. Chatalbashev, D. Vickrey, and D. Koller. Learning [28] X. Liao, Y. Xue, and L. Carin. Logistic regression with an [29] P. Luo, F. Zhuang, H. Xiong, Y. Xiong, and Q. He. Transfer [30] K. Miettinen. Nonlinear Multiobjective Optimization . [31] J. Nocedal and S. Wright. Numerical Optimization . Springer [32] R. Raina, A. Battle, H. Lee, B. Packer, and A. Ng. [33] M. T. Ribeiro, A. Lacerda, A. Veloso, and N. Ziviani. [34] A. Schwaighofer, V. Tresp, and K. Yu. Learning Gaussian [35] G. Shani and A. Gunawardana. Evaluating recommendation [36] M. Sugiyama, S. Nakajima, H. Kashima, P. von Bunau, and [37] P. Tseng and S. Yun. A coordinate gradient descent method [38] C. Wang and S. Mahadevan. Heterogeneous domain [39] Q. Yang, Y. Chen, G.-R. Xue, W. Dai, and Y. Yu.
 [40] C.-N. Ziegler, S. M. McNee, J. A. Konstan, and G. Lausen. conference on World Wide Web , pages 22 X 32. ACM, 2005.
