 Semantic recognition and annotation of unqiue enities and their relations is a key in understanding the essence con-tained in large text corpora. It typically requires a com-bination of efficient automatic methods and manual verifi-cation. Usually, both parts are seen as consecutive steps. In this demo we present MIKE, a user interface enabling the integration of user feedback into an iterative extraction process. We show how an extraction system can directly learn from such integrated user supervision. In general, this setup allows for stepwise training of the extraction system to a particular domain, while using user feedback early in the iterative extraction process improves extraction quality and reduces the overall human effort needed.
 H.5.2 [ Information Interfaces and Presentation ]: User Interfaces X  Evaluation/methodology, Graphical User inter-faces, Natural language ; I.2.6 [ Artificial Intelligence ]: Learn-ing X  Knowledge Acquisition ; I.2.7 [ Artificial Intelligence ]: Natural Language Processing X  Language Parsing and Un-derstanding Information Extraction, Knowledge Acquisition, Learning, GUI, User Feedback, Web Service
With the growing amount of textual information digitally available, an efficient analysis of large amounts of natural language text to grasp the essential content relevant for a particular interest becomes increasingly important.
In several areas, e.g. the humanities, semantic informa-tion is traditionally attached to source documents by ex-pert users, e.g. by annotation, in order to allow automatic evaluation and management of the data and the contained semantic information. However human processing cannot ef-ficiently deal with the large amount of documents digitally available. There is a growing number of automatic informa-tion extraction systems [1, 3, 6], which can support humans in grasping the essential semantic information contained in natural language texts. Typical systems support named en-tity recognition (NER), e.g. identifying  X  X arack Obama X  and  X  X S President X  as references to the same unique entity, and relation extraction, e.g. extracting an instance of an abstract bornIn relation from the text  X  X arack Obama X  X  birthplace Hawaii X  . Such relational information is often represented in RDF triple form, e.g. ( Obama , bornIn , Hawaii ). Informa-tion extraction systems often follow an iterative approach, expanding an initial knowledge base step by step. User in-volvement is usually required to provide the initial basic do-main knowledge, e.g. by providing examples for entity and relation recognition. Although these extraction systems can reach relatively good precision values in general[6], high pre-cision usually comes at the price of lower recall, such that many relationship instances are not found or at least not found in all documents where they occur. Additionally, for many use-cases there is a need for quality guarantees. This is typically achieved by an additional manual filtering step after the extraction is complete.

In this paper, we aim to close the gap between manual annotation and automatic extraction by integrating large portions of initial domain knowledge generation and man-ual quality control into the extraction process. We present LUKe , an extraction system based on [6] that can integrate user feedback on-the-fly, and MIKE , a user-interface to con-trol the extraction system, present the extraction results to a human user and allowing for extension and correction of r ecognized knowledge. The seemless integration of user feed-back into the iterative extraction process allows the system to learn early on. Hence, quality achieved is optimized while human effort needed to ensure a given quality level is mini-mized.
There are several other approaches to visualize semantic information [1, 2, 4, 7, 8]. Traditional tools to model ontolo-gies, e.g. WebProt  X eg  X e [7], lack the capability to link infor-mation extracted from documents back to their sources[2]. On the other hand, there are general semantic frameworks like UIMA[4] and GATE[1] with especially the latter allow-ing user interaction by modeling the extraction process as a workflow where each step produces some sort of document representation, e.g. a token stream, and this representa-tion can potentially be modified before being fed into the next step of an extraction pipeline. Semantic Wikis have a stronger focus on user driven data generation, yet they typically lack information extraction capabalities to sup-port users in the annotation process. However, there has been work on integrating existing ontologies and reasoning capabilities as a background model into semantic wiki sys-tems[8]. The most similar vision of an iterative learning sions an integration of information extraction and knowl-edge management with Wiki technology[5]. While we share a similar architecture as envisioned in the project, our fron-tend aims at a user base that is not accommodated to Wikis. Still, since backend and frontend are independent, a Wiki-frontend could as well be attached to our extraction API.
A typical user workflow consists of two main iteratively re-peated steps: 1) Information Extraction 2) Evaluation and Modification of extracted information After each extraction phase, the user can give feedback, such that in the next ex-traction iteration the system can learn from user corrections and apply any new insights on the whole corpus.

However, initially a user first has to select source files by providing their URIs (e.g. web urls or WebDAV directories), which will be added to a list of project files to work on. Next, the user may configure the extraction run including the choice of domain knowledge used and which extraction steps (entity recognition, relation recognition) shall be performed. Once the extraction process is started MIKE displays status information on the extraction progress. When the extraction process has finished, results are retrieved from the extrac-tion system and provided as a listed overview, which may be grouped and sorted by files, entities or statements (Figure 1, area 1). In case of grouping by files, the extracted entites and the extracted statements within each file are indicated. In both the other cases, for each entity/statement the files where it is mentioned are listed.

A click on a list item opens the corresponding document within an editor component. There, its textual content is displayed enriched with highlighted entity and statement mentions (Figure 1, area 3). This way, a user directly sees the extracted information in context allowing her to judge correctness and completeness of the extraction results. Both entity and statement mentions can be filtered by a confi-dence threshold (area 2). A click on an entity or statement mention provides further information, such as its author (the user or system name that found or last edited the mention), the recognition confidence and its context (area 4). In case of an entity mention also the referenced entity is shown, while in case of a statement mention all relations recognized be-tween the included entities (at that mention) are listed. En-tity mentions may be corrected by changing the referenced entity and/or by adjusting their bounds. For a statement mention a user may support/refute a given relation and/or add a new one. Both types of mention can be added by selecting a text part and providing an entity reference or at least one relation, respectively. After giving feedback a user may restart the extraction on all or a subset of docu-ments and the system can re-evaluate all findings based on the given feedback.

Finally, the frontend allows for export of edited files in an annotated XML format or of all extracted information in a single dump.

In our setup we use a pattern based extraction system based on [6]. However, the system has been extended to learn from user feedback and integrate it into its own it-erative extraction process. This way the extraction system learns from corrections of entity disambiguations to do it correctly at other occurrences of the same entity represen-tation. For instance, if  X  X S President X  has been manually set to indicate the entity BarackObama then 1) in other cases where  X  X S President X  occurs the system will tend towards interpreting these as references to BarackObama and 2) all other entity references that are ambiguous, but might refer to Obama are more likely associated with the entity Barack-Obama . Additionally, if the system did not even consider BarackObama as the entity being adressed by  X  X S President X  , e.g. because its database was outdated, then it will consider this new possibility also in other texts. For the relations the system manages pattern X  X elation associations with con-fidence values, e.g. it might consider X  X  was born in Y X  X s an expression of the bornIn relation between two entities X and Y or  X  X   X  X  newest master piece Y X  as a (less reliable) pattern for a directed relation, but it might also indicate a actedIn wrote o r painted relation. If a user adapts the interpretation of an ambiguous pattern, the system can modify its confi-dence in the corresponding pattern X  X elation association and thus learn about the typcial interpretation within the cur-rent domain. Additionally, as relations are typed, choosing correct entities, e.g. by fixing disambiguation decisions or by setting the relation, allows the system to also adapt the entity X  X  type information. For instance, if the system only knows about Quentin Tarantino being a director, a manu-ally added instance of an actedIn instance can lead to him being also known as an actor. The architecture is divided into three main layers.
T he CORE layer consists of an adapted extraction system and an efficient ontology store, such as a database or a triple store. On top of these core components a REST Web service API provides access to extraction, feedback and knowledge management. That is, extraction jobs can be started via the interface, results can be obtained, feedback be provided and snapshots of all information extracted so far can be ex-ported in an ontological format. Information is exchanged either in HTML, XML or JSON format. Extraction results mainly consist of entity and statement occurrences. Each entity occurrence X  X  main components are 1) the position in the text, 2) the original text and 3) the entity reference can-didates along with confidence values. Similarly, statement occurrences mainly consist of 1) the position in the text, 2) the two entities involved and 3) the possible interpretations.
Finally, MIKE provides a web-based user-interface. It wraps the functionality provided by the REST API in an easily understandable graphical frontend.

The architecture is modular in nature, e.g. any extraction system supporting the REST-API interface could be used and similarly another visualisation frontend could access the interface. In our demo setup we use LUKe , a modified ver-sion of [6], and a PostgreSQL database as core components. While in the demo a single system hosts all components (po-tentially except the database), the extraction could also be run in a distributed way. Both the extraction system in our setup as well as the REST-API are written in Java with the latter being run on a Tomcat server. MIKE is implemented in PHP using cURL and openSSL for communication with the REST-API.
In our demonstration we will showcase the use of the user interface and the underlying learning extraction sys-tem by selecting a couple of documents, running the extrac-tion, editing some entity and relation occurrences and then re-running the extraction to show the learning effects. A video outlining this procedure is available at http://bit. ly/MdsU8F .
This work has been partially funded by the BMBF (Ger-man Federal Ministry of Education and Research) through [1] H. Cunningham, D. Maynard, K. Bontcheva, and [2] S. Elbassuoni, K. Hose, S. Metzger, and R. Schenkel. [3] O. Etzioni, M. Banko, S. Soderland, and D. S. Weld. [4] D. Ferrucci and A. Lally. Uima: an architectural [5] P. Smrz and M. Schmidt. Information extraction in [6] F. M. Suchanek, M. Sozio, and G. Weikum. SOFIE: A [7] T. Tudorache, N. F. Noy, S. M. Falconer, and M. A. [8] D. Vrandecic and M. Kr  X  otzsch. Reusing ontological http://www.wisnetgrid.org/
