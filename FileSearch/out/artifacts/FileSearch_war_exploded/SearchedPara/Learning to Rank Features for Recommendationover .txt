 Incorporating phrase-level sentiment analysis on users X  tex-tual reviews for recommendation has became a popular meth-od due to its explainable property for latent features and high prediction accuracy. However, the inherent limitations of the existing model make it difficult to (1) effectively dis-tinguish the features that are most interesting to users, (2) maintain the recommendation performance especially when the set of items is scaled up to multiple categories, and (3) model users X  implicit feedbacks on the product features. In this paper, motivated by these shortcomings, we first in-troduce a tensor matrix factorization algorithm to L earn to R ank user P references based on P hrase-level sentiment analysis across M ultiple categories (LRPPM for short), and then by combining this technique with Collaborative Filter-ing (CF) method, we propose a novel model called LRPPM-CF to boost the performance of recommendation. Thorough experiments on two real-world datasets demonstrate that our proposed model is able to improve the performance in the tasks of capturing users X  interested features and item recommendation by about 17%-24% and 7%-13%, respec-tively, as compared with several state-of-the-art methods. Recommender Systems; Sentiment Analysis; Collaborative Filtering; Tensor Factorization
Emerging popularity of e-commerce has highlighted the importance of recommendation systems, with many mod-els have been studied. Among these models, latent factor models [2, 5, 11, 20] have gained much attention from the research community and industry due to their good pre-diction accuracy on some benchmark datasets. However, recommendation based on these methods could hardly give Figure 1: An example of feature ranking with rat-ings predicted by rating-based optimization func-tions. intuitional explanations for the latent features which weak-ens the ability to persuade users and help users make better decisions in practical systems.

In recent years, there has been an upsurge of interest in exploiting the users X  textual review information to enhance the interpretability of latent factor models. A well-known example is the HFT model [6]. By linking the latent factors leveraged in modeling user rating behavior with the topics presented in the user comments, this model directly explain the latent factors by the user mentioned topics. However, as a topic may contain products X  different features and a user could express different opinions for various features in the same topic, simple topic-level analysis without more detailed natural language processing makes such approaches biased and limited.

Several attempts to construct a more explainable recom-mendation model have been made very recently in [17, 18]. In their models, phrase-level sentiment analysis are used to excavate products X  explicit features and users X  corresponding opinions.For instance, if a user purchased a phone, and made a 5 star rating with the text review  X  X creen is perfect, but earphone is bad!" The methods proposed in [17, 18] could capture the feature-sentiment pairs like (screen, perfect) and (earphone, bad), which would provide finer-grained analysis of the textual reviews as compared with HFT, and could help to make more accurate recommendations.

Despite that encouraging improvements have been brought by these models, they still suffer from three issues. First, selecting the most interesting features is an important com-ponent in their models for user profiling, however the ex-isting rating-based optimization target is not suitable for such an inherently ranking task. Second, they both con-sider a user X  X  extent of interest towards each feature as static over all products.This setting is not practical in real-world Figure 2: User X  X  different features for various prod-ucts are first extracted utilizing phrase-level senti-ment analysis, and then the items which perform well on the user X  X  cared features would be recom-mended. scenarios, especially when the products are from different categories. Finally, instead of modeling users X  implicit feed-back(mentioned a feature in the review or not)directly, these models convert the implicit feedbacks into rating scores, which would bias it in terms of preference estimation [14].
In this paper we describe and analyze a general method to learn and infer user preferences from ratings along with textual reviews. The main building block of our proposed method is an effective tensor-matrix factorization algorithm to L earn to R ank user P references based on P hrase-level sentiment analysis across M ultiple categories (LRPPM). By learning to rank, we wish to make our model more suitable for ranking tasks in selecting the most interesting features for each user. By tensor-matrix factorization, we wish to capture users X  different interests to various products directly from their implicit feedback, and to keep the recommenda-tion performance even when the set of products scales up to multiple categories. Furthermore, by bridging this method with traditional Collaborative Filtering (CF) approaches, we build a novel LRPPM-CF algorithm to boost the per-formance of personalized recommendation.

Compared with the existing models, the key advantages of our proposed method are: (1) It introduces ranking-based optimization objective to replace rating-based target for bet-ter understanding user preferences on feature-level. In Fig-ure 1 for instance, where our goal is to select the top-three favourite features for a user from the feature pool { A,B,C,D, E } . Suppose that the real scores the user would make on these features are { 5 , 4 , 2 , 3 , 1 } , and we have two strategies 1 } , respectively. From the perspective of rating-based op-timization, the former strategy is better because it gains higher prediction accuracy (lower root mean square error(RM-SE)), and thus the features A,B,C would be selected. How-ever, the latter strategy is actually more preferred because it selects A,B,D , which are the top favourite features ac-cording to the real ratings, although this strategy gains lower prediction accuracy according to RMSE. (2) It ex-tracts the different favoured features for each user more precisely, which can further make our model more accurate when making recommendations. In Figure 2 for example, our model would value more on the screen pixel when a user is selecting digital cameras, while the style might be consid-ered as a more important feature when he/she is looking for clothes. (3) It is able to model the user implicit feedbacks directly to capture the user preferences.

In the rest of the paper, we first review the related work in section 2, and give detailed explanation of our methods in section 3. Another rating-based tensor factorization method is explored in section 4 for model comparison. And then in section 5, we describe our experiments and analyze the effectiveness of our methods. The conclusions and outlook of this work are presented in section 6.
With the ever growing amount of user generated textual reviews, the problem of how to leverage such information-rich resources to construct more explainable recommenda-tion models has received increasing attention. Until recently, a lot of recommendation algorithms [1, 3, 10, 12, 18] based on sentiment analysis of textual reviews have been proposed. In general, these algorithms are conducted on three different levels: (1) review-level, (2) sentence-level, and (3) phrase-level.
 Review-or sentence-level methods. These methods take a review or a sentence as a whole, and analyze its sentiment directly. The method proposed in [1] presents three approaches to identify movie aspects which are used as features for collaborative filtering. [3] considers different sentimental orientations (SO) of similar words in different scenarios, and proposes a framework to determine the sen-timental orientations. [10] focuses on the situation of user textual review without explicit rating labels, and introduces a sentiment-aware nearest neighbor model to boost the per-formance of existing recommendation methods. Finally, [12] constructs an opinion matrix by extracting user interests from the reviews, and combines this matrix with traditional model-based collaborative filtering to provide rating predic-tions.

The models mentioned above have made great contribu-tions to the modeling of user review information in recom-mendation tasks. However, such review-or sentence-level approaches could not explicitly identify the product features in a review/sentence, and therefore fail to capture user pref-erences in a finer-grained manner towards specific features, which can be very important to generate personalized rec-ommendations and explanations.
 Phrase-level methods. A recent approach proposed in [18] utilizes phrase-level sentiment analysis to extract the explicit product features and finer-grained per feature sen-timent information from user reviews. Specifically, it con-structs a sentiment lexicon from a corpus of reviews, based on which to further generate an explicit user-feature atten-tion matrix and item-feature quality matrix, where the for-mer reflects user interests towards different features, and the latter shows the quality of each product on each feature. It then adopts matrix factorization techniques to complete these matrices by optimizing the root mean square error (RMSE). At last, this model makes recommendations by matching the most favourite features of a user with the in-trinsic properties of items.

Though this model could provide more detailed user pref-erences and more accurate predictions, the simple matrix factorization approach to optimize RMSE as a rating-based task makes it limited in that: (1) the estimation of user-feature attentions is inherently a ranking-based task to se-lect the favourite features, (2) it fails to distinguish users X  different interests of features on different products, and (3) it converts users X  implicit feedbacks on product features into explicit rating scores, which could be a step that introduces inaccuracy. In contrast, in this paper, we propose a ranking-based tensor-matrix factorization algorithm to resolve these problems, which makes more practical, explainable, and ac-curate recommendations.
In this section, we describe the major components of our model. Firstly,we give a brief introduction to the extraction of feature-sentiment pairs from user textual reviews. And then we analyze the Yelp 1 dataset to verify our assumption that users usually care about different features for different product categories. Next, we elaborate the main compo-nents of our LRPPM model. At last, by combing this tech-nique with collaborative filtering, we propose a novel frame-work for purchase prediction and recommendation. Specif-ically, we implement our framework on both product-level and category-level, respectively, so as to make it easy to compare and understand the performance of our framework.
In the first stage, we construct the set of feature-sentiment pairs from a corpus of textual reviews based on the state-of-art optimization approach described in [4, 18, 19] due to its high accuracy. Specifically, we first extract feature word set F from all the user textual reviews. Then for a given piece of review, we generate a set of feature-sentiment pairs ( F,S ) to represent this review, where S is assigned as 1 or -1 according to the sentiment polarity that the user expressed on this feature. For example, for the piece of review  X  X he taste is perfect, but the appearance is ugly! X , the extracted feature-sentiment pairs can be (taste, +1) and (appearance, -1). Since the feature-sentiment pair extraction is not the key contribution of this paper, we refer the readers to the related literature such as [4, 18, 19], and focus our atten-tion on the next stages of user preference prediction and recommendation.
We adopt the Yelp dataset for analysis because it cov-ers items from multiple categories, which matches with our research tasks. We focus our analysis on the categories of beauty,entertainment,food,health,clothing and bars due to their high co-occurrence frequencies in user transactions. To verify the hypothesis that users usually care about differ-ent features for various products, we select the most popular features in every category according to the frequencies they are mentioned in the textual reviews. In this dataset, we select top-10 most cared features for empirical analysis, as shown in Table 1. Based on simple observations we can find that: (1) On pairwise level, only three pairs of categories contain three common features, and the others have at most two common features or no intersection at all. (2) Among all these 47 mentioned features, only three appear in more than three categories.

These observations and case studies imply that the user interests may vary with the categories, which is an important motivation for us to model the user preferences and recom-mendation with the discrimination of different categories. In the next subsections, we introduce our LRPPM framework http://www.yelp.com/dataset_challenge Table 1: The top-10 most cared features in user re-views of different categories. category beauty entertainment food category health clothing bars so as to Learn to Rank user Preferences based on Phrase-level sentiment analysis across Multiple categories, and fur-ther integrate this framework with Collaborative Filtering on both product-and category-levels.
The most direct yet naive implementation to model user interests in different categories is to conduct user/item pro-filing on each category independently, for example, by an-alyzing the reviews from each category with EFM [18] in isolation. However, with the large and ever growing num-ber of categories, this method is practically infeasible. To alleviate the problem of both effectiveness and efficiency, we propose a unified framework based on tensor factorization in this section, and the major components of this framework would be introduced in detail in the following.

Factorizing User-Item-Feature Cube. To capture users X  different favored features for various items, we should model interactions among users, items and features simultaneously, this inspires us to introduce tensor matrix factorization meth-od, and for clear exposition, let U = { u 1 ,u 2 ,...u | U | textual reviews. Then we represent users X  reviewing behav-ior as a set of user-item-feature triplets as follows:
O := { ( u,i,f ) | u  X  U,i  X  I,f  X  F,User u mentioned
We consider the user-item-feature relationship as an in-teraction cube T ,where the element reflects the extent that a user is interested in a feature when he/she reviewed on an item. For more accurate modeling, we model the implicit feedback of users directly by labeling the triplets from O as observed elements in the corresponding position of cube T . Note that, instead of being converted to explicit rat-ings(e.g. X 1 X ), these observed elements would be employed to construct preference pairs in the next section.

A number of techniques exist for tensor factorization [15, 16, 13], and we adopt a method similar to [15] due to its efficiency and relatively lower learning complexity. In our method, the pairwise interactions among users, items and features are modeled directly, and the scoring function which reflects u 0 s interest for i 0 s feature f is shown as follows:  X  R + } are the latent matrices of users, items and features respectively, and K represents the number of factors in these matrices.

Ranking-based optimization target on implicit feed-back. As selecting the favourite features for each user is an inherently ranking-oriented task, we should care more about users X  relative preference on different features rather than the explicit rating predictions on them, and that a ranking-based approach can be more suitable than the rating-based criterion used in [18].
 In our model, we use the ranking-based criterion of Bayesian Personalized Ranking (BPR) [14] as our optimization goal. Intuitively, a user would generally review on his/her cared features, while the features not mentioned in his/her com-ments, in turn, are not attractive to him/her, so to con-duct BPR method, we build preference pairs between the observed elements in T which correspond to interested fea-tures with the non-observed ones, we define: which reveals user u 0 s interests for feature f A over f he reviewed item i . Then we use a similar method in [14] to estimate our model parameters by maximizing a log poste-rior (MAP): where  X  () is a logistic sigmoid function, F + ui is the set of features that were mentioned by user u for item i , F  X  ui the set of features that were not mentioned, namely, F + ui { f | ( u,i,f )  X  O } and F  X  ui = { f | ( u,i,f ) 6 X  O } ,  X  is the model parameter and  X   X  is the regularization constant.
After estimating the parameters,we could rank the fea-tures according to equation (2) and select the features with top-N scores to model the user preferences on a specific item.
In this section, we incorporate both rating and reviewing information together to build a hybrid model. Specifically, we first share the latent factors used for modeling user rat-ing behavior with the factors embedded in user reviewing behavior, and then propose a unified LRPPM-CF frame-work by combining our model LRPPM with model-based collaborative filtering method, which attempts to optimize the following objective: min of R U u  X  , R I i  X  is the i -th row of R I ,  X  is the model parame-ter, A ui is the rating that user u gives to item i ,  X  is the tuning parameter that balances the weight between the two types of behaviors, and  X   X  is the regularization constant.In this expression, we model the user ratings with latent tensor factors by the first term, and further model the user prefer-ences on features embedded in reviews through learning to rank by the second term. The parameters are regularized by a unified way in the last term.
There is no closed-form solution for equation (8), and we introduce a stochastic gradient descent algorithm to find the optimal solution for the parameters  X  = { R U ,R I ,R UF ,R For convenience, we define the training set as D S = { ( u,i,f f ) | ( u,i,f A )  X  O, ( u,i,f B ) 6 X  O } and the decaying param-eter l ui = 1 in Algorithm 1. In this algorithm, we first initialize the pa-rameters, and then update these parameters repeatedly until convergency or reaching the maximum number of iterations.
Given the optimal solutions of { R U ,R I ,R UF ,R IF } , we es-timate the user-item-feature cube as  X  T and user-item rating matrix  X  A . In order to make recommendations, we consider two aspects:(1)the direct rating that a user would score on an item and (2) the compatibility between a user X  X  interested features and an item X  X  high-quality features.

A user u 0 s estimated rating for item i could be readily derived as R rating ui =  X  A ui . To evaluate the consistency be-tween a user X  X  favorite features and an item X  X  intrinsic prop-erties. We first estimate items X  quality on different features. Suppose item i  X  X  quality on various features is defined as { s timents { m ij 1 ,m ij 2 ,...m ijn j } , where n j is the number of times feature j is mentioned in all the reviews of item i , m ijk  X  { X  1 , 1 } for k = 1 , 2 ,...n j . Then we evaluate s it as 0 otherwise.

We assume that a user X  X  decision about whether or not to make a purchase is based on several important product features to him or her, rather than considering all hundreds of possible features. For a given user-item pair ( u,i ) , we could select u 0 s favorite features according to equation (2), let the indices of the n f largest feature scores in the cube be INDF ui = { indf ui 1 ,indf ui 2 ,...indf uin f } . Then a user X  X  interests for an item could be derived as follows: where  X  is a rescaling parameter.Note that when implement-ing, we normalize every feature score to be a value in (0,1). Algorithm 1 LPRRM-CF Input: A,m,n,p,K, X , X   X  ,O Output: R U , R I , R UF , R IF initialize iter=0 repeat until Converge or iter &gt; max_iter return R U , R I , R UF , R IF
At last, we set the final ranking score (RS) of user u for item i as follows: In our datasets, as the rating range is [1,5] and thus the maximum value of  X  A ui is 5, we set  X  = 0 . 2 to map the first part of (7) that falls in the range of (0,1) into a comparable value with  X  A ui . 0 &lt;  X  &lt; 1 is a scale parameter that con-trols the trade off between feature-based score and direct user-item ratings. The recommendation list for user u can be constructed by ranking the items in descending order of
The LRPPM-CF model above is conducted on product-level, which is able to capture the various interested fea-tures of users for different products especially when the dataset is sufficiently dense. However, in many practical scenarios, user interactions with a single product is very sparse (usually only a single piece of review), and to make our model more robust and adaptable in such application scenarios, we further extend our LRPPM-CF approach to category-level modeling. We define the set of categories as C = { c 1 ,c 2 ,...c NC } , where NC is the number of categories and the set of user-category-feature triplets as follows: feature f when he ( she ) reviewed products in category c. }
Similar to product-level LRPPM-CF, the scoring function  X  T ucf is computed as follows when factorizing this cube:  X  R + } are the representation matrices of users, categories and features, respectively, and K is the dimension of the representations.

Suppose R I  X  R | I | X  K + is the representation of items. Let the products in category c be CI c = { i c 1 ,i c 2 ,...i products and their categories. The integrated optimization task thus is:  X   X  X where  X  is a tuning parameter,  X  = { R U ,R I ,R UF ,R IF  X 
 X  is the regularization constant. F + uc is the set of features that are mentioned by user u for category c  X  X  items, and F uc is the set of features that are not mentioned, namely, F uc = { f | ( u,c,f )  X  O  X  } and F  X  uc = { f | ( u,c,f ) 6 X  O adopt u 0 s favourite features for i 0 s category c as the final feature list for item i . The recommendation list could be generated according equation (7), where we replace  X  T uif  X  T
The product-level and category-level LRPPM-CF approac-hes are suitable for different scenarios regarding the charac-teristic of the tasks (e.g., data sparsity), and they play a complementary role to each other.
LRPPM-CF vs EFM The relationship between these two models lies in that they both attempt to model the pairwise interactions among users, items, and features. The difference is that when generating users X  favourite features, a rating-based 2D-matrix factorization technique is used in EFM model to capture the static produce-irrelevant feature preferences of users. However, in our LRPPM-CF model, we designed a ranking-based tensor-matrix factorization ap-proach to discriminate users X  different interests on feature over different products.

Product-vs Category-level LRPPM-CF Obviously, if every category contains only one product, Category-level LRPPM-CF would reduce to Product-level LRPPM-CF. When the categories contain more than one products, we can bring equation (9) into (10), and rewrite the Category-level LRPPM-CF optimization objective function as: min
Let H = X
H = X we set R CF = R IF , and according to (3)(4), we have: H = X )  X  1 then the Category-level LRPPM-CF optimization objective function can be rewriten as: min  X 
Comparing with Product-level LRPPM-CF optimization goal shown in equation (5), we see that Category-level LRPPM-CF uses all the features extracted from a category as the positive observations for its products.
In our LRPPM-CF framework described above, we model the user preferences towards different features with a ranking-based approach by modeling the implicit feedbacks directly, because we believe the estimation of user preferences on fea-tures is inherently a learning to rank task, which attempts to capture the preference of a feature over another one on products-or category-levels. To verify our assumption, we also study a rating-based tensor factorization model that treats the implicit feedbacks as explicit ratings.
We define the rating user u gave to item i is defined as a the features extracted from user u  X  X  textual review for item of extracted features.

Similar to LRPPM-CF, we consider user-item-feature re-lationship as an interaction cube T s . However, instead of modeling user X  X  implicit behavior, the element T s uik in T is assigned as a score that reflects the degree of user u  X  X  interest towards item i on feature f . In this method, we and 0 when f k /  X  F ui . To make fair comparison, the fitting function adopted here is the same as the method used in LRPPM-CF(equation (2)).

We adopt the least square minimization method to fit these ratings, suppose O s is defined as:
O s := { ( u,i,f ) | u  X  U,i  X  I,f  X  F,User u mentioned then the optimization objective function is: where  X  = { R U ,R I ,R UF ,R IF } are the model parameters.
We adapt stochastic gradient descent algorithm to learn the parameters. When making recommendation for user u , we first estimate the score u would give to the items, and then select the items with top-N highest scores to generate the recommendation list, where the score  X  a ui is computed by:
Although this method tends to capture various user in-terests in a more compact way, it does not perform better than the LRPPM-CF approach in our experiments, which will be introduced in the following sections. The underlying reason can be that: (1) It may introduce too much noise when directly assigning T s uik as a ui K may account for different weights when deriving the rating estimations  X  a ui ; (3) Converting the user implicit feedback into explicit ratings may be bias and limited, which could be a shortcoming of the EFM approach, while our LRPPM-CF approach can model such implicit feedbacks directly in a learning to rank framework.
In this section, we conduct extensive experiments to eval-uate our LRPPM-CF framework. We focus on the following research questions: (1) What is the performance of our LRPPM-CF model in number of total factors increase from 25 to 100.
 Table 2: Statistics of the Amazon and Yelp datasets Amazon 965 13005 38430 39.82
Yelp 859 8750 51965 60.54 capturing various features for different products/categories. (2) What is the performance of our LRPPM-CF model in the task of item recommendation.

We begin by introducing the experimental setup, and then report and analyze the experimental results to attempt to answer the research questions.
We choose the Amazon 2 [7, 8] and Yelp 3 datasets for ex-periments. The former dataset contains user transaction records and textual reviews from Amazon spanning May 1996 -July 2014. The latter dataset consists of user re-views on various businesses. For evaluating the properties of our models, in both of these datasets, we select the users who purchased items in at least 3 categories, and choose the items with 5 or more reviews. We randomly holdout 30% reviewed items from each user to construct the testing set, and the others are used for training. The statistics of our datasets are shown in Table 2. In this subsection, we investigate the performance of LRP-PM-CF in capturing different features for various products/c-ategories. We compare the predicted features with the tru-ely mentioned features for every user-item pair in the test dataset. Two methods are selected as our baselines, which are Rating-based Tensor Factorization (RTF) proposed in section 4 and Explicit Factor Model (EFM) [18], which is the state-of-the-art approach for user preference prediction and recommendation based on explicit features from reviews. When implementing RTF, we select 5 features according to their scores in the fitted cube. When implementing EFM, http://jmcauley.ucsd.edu/data/amazon/ http://www.yelp.com/dataset_challenge Table 3: Statistics of the datasets containing various number of categories Amazon_C1 749 2697 3568 1 Amazon_C2 949 5584 13004 2 Amazon_C3 965 7641 22412 3 Amazon_C4 965 8867 25242 4 Amazon_C5 965 13005 38430 5 Yelp_C1 856 1902 14274 1 Yelp_C2 858 2204 15514 2 Yelp_C3 858 2245 15607 3 Yelp_C4 859 2832 17252 4 Yelp_C5 859 8265 46059 5
Yelp_C6 859 8750 51965 6 in order to achieve the best performance, we tune the ra-tio between explicit and latent factors by fixing the total number of factors as 25, 50, 75, 100, respectively, and the weighting scalar is set as 0.85 as reported in [18]. For ev-ery user, we select 5 features for all the products according to their scores in the fitted user-feature attention matrix. When implementing LRPPM-CF, we set the dimension K as 25, 50, 75, 100, respectively, so as to ensure equal model complexity, and also select the top-5 features utilizing the method proposed in section 3.2 as the predicted results.
The hyper-parameters of these methods are selected by conducting grid search and 5-fold cross-validation. We com-pare these models on the metric of F 1 -score. In order to validate the performance under different number of cate-gories, we construct 5 datasets for Amazon and 6 datasets for Yelp, where the n -th dataset contains products from n categories, respectively. The statistics of the datasets are shown in Table 3.
The overall experimental results of comparing product-level LRPPM-CF with RTF and EFM on the task of pre-dicting the features for a given user-item pair are shown in Figure 3. We see from the results that: (1) When the datasets contain only one category, the EFM method performs better than RTF and LRPPM-CF across all the choices on the number of factors. The reason may be that people tend to care about a similar and limited set of features when purchasing products in the same category, thus the RTF and LRPPM-CF approach with 25 or more factors to capture the features could face severe overfitting problems. (2) When the datasets contain more than one categories, LRPPM-CF performs better than RTF and EFM(enhance the performance by about 17% and 24% on the Amazon dataset containing 5 categories and Yelp dataset containing 6 categories respectively), and the improvements are signifi-cantly at 0.01 level. This result is in expectation because the RTF method forcefully converts user X  X  implicit feedbacks to ratings, which could bias the results, and that for a given user, EFM does not consider his/her different interests on features for different products. Instead, our LRPPM-CF ap-proach models the implicit interaction between users, items, and features simultaneously and directly. (3) With the increasing on the number of categories, LRPPM-CF maintains a satisfactory prediction accuracy compared with EFM, whose performance decrease significantly with the increase on categories. In this section, we further investigate the performance of LRPPM-CF by applying this model on two levels of granu-larities, i.e., product-level and category-level. Similar to the previous experiment, we generate 5 features for each user on each category when implementing category-level LRPPM-CF. The parameters of category-level LRPPM-CF are also selected by conducting grid search in their corresponding ranges. The models are evaluated on Amazon datasets con-taining 5 categories(i.e., the dataset Amazon_C5) and Yelp datasets containing 6 categories (i.e., the dataset Yelp_C6), where the statistics of the datasets can be seen in the 5th and the last line of Table 3.
 Table 4: Performance comparison of Product-level and Category-level LRPPM-CF. The dimensionality is increase from 25 to 100. dataset dimension 25 50 75 100
From the results shown in Table 4, we notice that category-level LRPPM-CF performs better than product-level LRPPM-CF in all dimensions, also at a significant level of 0.01. The underlying reason can be that: (1) As the implicit feed-back in the user-item-feature cube on product-level is very sparse, this model fails to capture sufficiently many positive features to generate user preference pairs, which could lead to lower prediction accuracy. (2) Because all the products in a category are considered as a whole when conducting category-level LRPPM-CF, much more positive features are collected that help to alleviate the problem of data sparsity.
In this section, we investigate the LRPPM-CF model in the task of item recommendation. We analyze the model to find what and how the performance is affected by some specific parameters, and which parameters are of key impor-tance to the users in the task.

We use the Amazon containing 5 categories and Yelp con-taining 6 categories for our experiments (Datasets Ama-zon_C5 in the 5th and Yelp_C6 in the last line of Table 3). Our product-level LRPPM-CF model is compared with the following baseline methods: MostPopular: A static method that recommends different users with the same products according to their popularity. PMF: The Probabilistic Matrix Factorization method pro-posed in [9], which is a frequently used stat-of-the-art ap-proach for rating-based optimization and prediction. The number of latent factors is set as 50 for Yelp dataset and 20 for Amazon dataset based on cross-validation.
 EFM: The state-of-art algorithm [18] in terms of making recommendations based on phrase-level sentiment analysis on textual reviews. In order to achieve the best performance, we conduct grid search on the number of each user X  X  most cared features k in the range of [5,100], as well as the weigh-ing scalar  X  in the range of (0,1]. When determining the number of explicit and latent factors, we fix the total num-ber as 50 and tune the ratio between them to find an opti-mal ratio, and then we increase the total number from 10 to 100 by fixing this ratio. The parameters are finally set as k = 5 , X  = 0 . 8 , total number of factors = 20, ratio of explicit factors = 60% in the Amazon dataset, and k = 15 , X  = 0 . 85 , total number of factors = 50, ratio of explicit factors = 40% in the Yelp dataset.
 RTF: The compact Rating-based Tensor Factorization meth-od proposed in section 4. We still set the number of factors as 50 for Yelp dataset and 20 for Amazon dataset when im-plementing this method.

We conduct top-5 recommendation on both of the Ama-zon and Yelp datasets. The dimension K in our LRPPM-CF model is set as 50 for Yelp datasets and 20 for Amazon datasets to ensure equal model complexity. Grid search and five-fold cross-validation are used for parameter tuning and performance evaluation. We adopt F 1 -score and Normal-ized Discounted Cumulative Gain (NDCG) as the measures to evaluate the performance of different models.

The experimental results are shown in Table 5. From the results we can see that: (1) Among the baseline methods PMF performs better than MostPopular because PMF takes the global information into consideration and thus provides personalized recommendations. By utilizing user review in-formation and sentiment analysis, EFM and RTF performs better than other baseline methods, while little difference is observed between EFM and RTF. (2) Our product-level LRPPM-CF approach gains superior performance against all the baseline methods, and this is actually as expected because it captures user interests over features more pre-cisely on a per-product level, and thus makes more accurate item recommendations.
We first fix the number of most cared features n f = 5 and find that the optimal value for  X  is 0.3. We then fix  X  = 0 . 3 throughout the following experiments to focus on the effect of the key parameter n f .

Our goal is to investigate the performance of LRPPM-CF when n f increases from 5 to the maximum possible value (100 for Amazon, and 80 for Yelp), larger n f would lead to significant bias and the results on Yelp are shown in Figure 4. Based on performance of F 1 -score we see that our LRPPM-CF model outperforms all the baseline methods when n f ranges from 20 to 40. The best performance of LRPPM-CF with n f = 25 is 11% better than EFM, which performs best among the baseline methods. From the perspective of LRPPM-CF itself, the performance continues to rise as n f increases from 5 to 25. However, when n f falls in the range of [25,40], the performance tends to be stable, and when n exceeds 40, the performance begins to drop rapidly. From the performance of NDCG@5 we see that LRPPM-CF per-forms better than all the baseline methods when n f is in [15,40], and achieves its best performance when n f arrives at 25. Similar results are observed on Amazon dataset, which are shown in Figure 5.

These observations confirm our hypothesis in section 3.3.3 that when making decisions, users usually care about sev-eral key features, and taking too many features into con-sideration could introduce noise into the models, which is consistent with the observations in EFM [18].

Figure 5: Influence of n f on the Amazon dataset
In the following set of experiments, we set n f = 25 which achieves the best performance as reported above.We study how the performance ( F 1 -score) changes as  X  increases from 0.05 to 1.2(larger  X  would lead to significant bias), and the results on Yelp dataset is shown in Figure 6. We can see that: (1) LRPPM-CF outperforms the other models when  X  is in the range of [0.2, 0.5]. It confirms that our integrated model does enhance the recommendation quality as compared with the simple model of leveraging only the ratings, i.e., when  X  = 0 . (2) The performance of LRPPM-CF continues to rise until  X  reaches around 0.3, then after hovering approximately stable in the range of [0.3, 0.4], it begins to drop rapidly with the increase of  X  . This observation indicates that although the user reviewing behavior is important in boosting the performance of recommendation, user rating behavior still helps to make accurate predictions. Besides, similar results can be seen on the Amazon dataset, which are shown in Figure 6.
 Figure 6: Influence of  X  on Amazon and Yelp datasets
Although the results in section 5.2 show that category-level LRPPM-CF performs well in the task of capturing var-ious features, we still want to explore whether LRPPM-CF is adequately qualified in the task of item recommendation.
In this set of experiments, we compare the performance between Category-and Product-level LRPPM-CF on the Yelp dataset. The key parameters in both of these methods are n f and  X  . For fair comparison, we tune one of these parameters by fixing the other to observe the differences between the models. For implementing, we first fix  X  as 0.4, and observe the change in performance with different n f , and then investigate the performance with various  X  when n f = 25 . The dimensions of category-and product-level LRPPM-CF are set as 50. We still adopt F 1 -score@5 for performance evaluation.

The experimental results are shown in Figure 7. It shows that category-level LRPPM-CF performs better than product-level in most cases, which indicates that a higher level LRPPM-CF may be more practically effective in personalized recom-mendation. The underlying reason could be that ranking and summarizing the features for users on per-category level help to alleviate the problem of data sparsity. Figure 7: Performance comparison on F 1 -score be-tween Category-and Product-level LRPPM-CF in the task of item recommendation.
In this paper, we propose a learning to rank framework to model user preference on explicit features extracted from textual reviews, which is able to capture the implicit feed-backs in a direct way that promotes the accuracy. We thus propose a tensor-matrix factorization technique to learn user interests over features on both product-and category-levels. Furthermore, we integrate this technique with traditional collaborative filtering methods, and propose a unified hy-brid framework for both more accurate product/category-level feature ranking and better performance on personalized recommendations, which are verified thorough extensive ex-periments on both Amazon and Yelp datasets.

This is a first step towards our goal in explainable recom-mendation on high-level feature spaces and heterogeneous cross-domain recommendation, and there is much room for further improvements. In the future, we will focus on the fol-lowing research directions. Because our LRPPM approach is a framework rather than simply an algorithm, we are able to integrate more personalization models into this frame-work according to specific application scenarios, which may bring us more inspiring insights on the characters and per-formance of traditional methods from the angle of explain-able recommendation. We can also adapt other machine learning methods beyond tensor factorization to capture the user-item-feature interactions, such as probabilistic graphic models and topical modeling. [1] N. Jakob, S. H. Weber, M. C. M X ller, and [2] Y. Koren, R. Bell, and C. Volinsky. Matrix [3] C. W. Leung, S. C. Chan, and F.-l. Chung.
 [4] Y. Lu, M. Castellanos, U. Dayal, and C. Zhai. [5] B. M. Marlin. Modeling user rating profiles for [6] J. McAuley and J. Leskovec. Hidden factors and [7] J. McAuley, R. Pandey, and J. Leskovec. Inferring [8] J. McAuley, C. Targett, Q. Shi, and A. van den [9] A. Mnih and R. Salakhutdinov. Probabilistic matrix [10] N. Pappas and A. Popescu-Belis. Sentiment analysis [11] D. Y. Pavlov and D. M. Pennock. A maximum [12]  X . Pero and T. Horv X th. Opinion-driven matrix [13] S. Rendle, L. Balby Marinho, A. Nanopoulos, and [14] S. Rendle, C. Freudenthaler, Z. Gantner, and [15] S. Rendle and L. Schmidt-Thieme. Pairwise [16] P. Symeonidis, A. Nanopoulos, and Y. Manolopoulos. [17] Y. Wu and M. Ester. Flame: A probabilistic model [18] Y. Zhang, G. Lai, M. Zhang, Y. Zhang, Y. Liu, and [19] Y. Zhang, H. Zhang, M. Zhang, Y. Liu, and S. Ma. Do [20] Y. Zhang, M. Zhang, Y. Liu, S. Ma, and S. Feng.
