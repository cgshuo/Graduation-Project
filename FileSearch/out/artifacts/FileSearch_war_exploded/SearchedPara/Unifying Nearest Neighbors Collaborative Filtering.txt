 We study collaborative filtering for applications in which there exists for every user a set of items about which the user has given binary, positive-only feedback (one-class col-laborative filtering). Take for example an on-line store that knows all past purchases of every customer. An important class of algorithms for one-class collaborative filtering are the nearest neighbors algorithms, typically divided into user-based and item-based algorithms. We introduce a reformu-lation that unifies user-and item-based nearest neighbors algorithms and use this reformulation to propose a novel algorithm that incorporates the best of both worlds and outperforms state-of-the-art algorithms. Additionally, we propose a method for naturally explaining the recommen-dations made by our algorithm and show that this method is also applicable to existing user-based nearest neighbors methods.
 Categories and Subject Descriptors: H.3.3 [Informa-tion Storage and Retrieval]: Information filtering Keywords: One-class collaborative filtering, nearest neigh-bors, explaining recommendations, top-N recommendation, recommender systems.
Typically, the training data for collaborative filtering is represented by a matrix in which the rows represent the users and the columns represent the items. A value in this matrix can be unknown or can reflect the preference of the respective user for the respective item. Here, we consider the specific setting of binary, positive-only preference feedback. Hence, every value in the preference matrix is 1 or 0, with 1 representing a known preference and 0 representing the unknown. Pan et al. [10] call this setting one-class collab-orative filtering (OCCF). Applications that correspond to this version of the collaborative filtering problem are likes on social networking sites, tags for photo X  X , websites visited during a surfing session, articles bought by a customer etc.
In this setting, identifying the best recommendations can be formalized as ranking all user-item-pairs ( u,i ) according to the probability that u prefers i .

One class of algorithms for solving OCCF are the nearest neighbors algorithms. Sarwar et al. [13] proposed the well known user-based algorithm that uses cosine similarity and Deshpande et al. [2] proposed several widely used item-based algorithms.

Another class of algorithms for solving OCCF are matrix factorization algorithms. The state-of-the-art algorithms in this class are Weighted Rating Matrix Factorization [7, 10], Bayesian Personalized Ranking Matrix Factorization [12] and Collaborative Less is More Filtering [14].

This work builds upon the different item-based algorithms by Deshpande et al. [2] and the user-based algorithm by Sar-war et al. [13] that uses cosine similarity. We introduce a reformulation of these algorithms that unifies their existing formulations. From this reformulation, it becomes clear that the existing user-and item-based algorithms unnecessarily discard important parts of the available information. There-fore, we propose a novel algorithm that combines both user-and item-based information. Hence, this algorithm is nei-ther user-based nor item-based, but nearest-neighbors-based . Our experiments show that our algorithm not only outper-forms the individual nearest neighbors algorithms but also state-of-the-art matrix factorization algorithms.

Furthermore, it is well accepted that every recommenda-tion should come with a short explanation to why it is rec-ommended [7, 6]. Good explanations help users to put the recommendations in the right perspective [17]. Typically, item-based nearest neighbors algorithms are considered to be superior for this task [3, 7].

Thanks to our reformulation however, we are able to chal-lenge this belief and show that also other nearest neighbors algorithms have a natural explanation.

The main contributions of this work are:
Let U be a set of users and I a set of items. We are given a matrix with training data R  X  { 0 , 1 } |U| X |I| . R indicates that there is a known preference of user u  X  U for item i  X  I . R ui = 0 indicates that there is no such information.

Furthermore, c ( x ) gives the count of x, meaning
The goal of OCCF is to rank all user-item-pairs ( u,i ) for which R ui = 0 according to the likelihood of u preferring i . The most well known algorithms perform this task by computing for every user-item-pair ( u,i ) a score s ( u,i ), by which the user-item-pairs are then ranked.

A key element of nearest neighbors algorithms is their definition of the neighborhood of an object, or more specifi-cally, the similarity measure sim () used for computing it. A typical choice for sim () is the cosine similarity. The cosine similarity between two users u and v is given by Analogously, the cosine similarity between two items i and j is given by
We denote the k U ( k I ) nearest neighbors of a user u (an item i ) by KNN ( u ) ( KNN ( i )).
In this section we propose a novel formulation of nearest neighbors collaborative filtering that unifies the known for-mulations of the user-based algorithm by Sarwar et al. [13] and the different item-based algorithms by Deshpande et al. [2]. This formulation is given by The score s ( u,i ), that represents the likelihood that a user u prefers an item i , is computed as a weighted sum over all possible user-item pairs ( v,j ). The weight of every ( v,j )-pair with respect to the pair ( u,i ) is a multiplication of four functions: the local function L ( u,i ) , ( v,j ) , the neighbor-hood function N ( u,i ) , ( v,j ) , the global function G ( u,i ) , ( v,j ) and the rescaling function S ( u,i ) , ( v,j ) .
Before giving a general definition of L , N , G and S , we first discuss the reformulation of the user-based algorithm by Sarwar et al. [13] and the different item-based algorithms by Deshpande et al. [2].
Deshpande et al. [2] proposed the now widely used class of item-based nearest neighbors algorithms. We discuss the variation that uses cosine similarity without similarity nor-malization ( cosine, SNorm-) because of its clean formula-tion. The analysis for the other variations is analogous.
This algorithm first finds the neighborhood KNN ( j ) for every preferred item j ( R uj = 1) by using the cosine sim-ilarity cos ( j,i ). Next, every preferred item independently increases the score for its k I most similar items i  X  KNN ( j ) with the similarity value cos ( j,i ). Thus, the score of a can-didate recommendation i for user u is given by [2]:
We reformulate this algorithm by substituting cos ( j,i ) by its definition (Eq. 2) and regrouping the terms. This gives s ( u,i ) = X This particular formulation now nicely fits our Equation 3: a weighted sum over all possible user-item pairs ( v,j ) in which the weight of every ( v,j )-pair with respect to the pair ( u,i ) is determined by the functions L , N , G and S .

The local function L selects the pairs ( v,j ) based on their direct relation to the pair ( u,i ). For the item-based algo-rithm, it is given by It thus only selects those pairs ( v,j ) such that v and u share a preference for j and both i and j are preferred by v .
Next, the neighborhood function N further selects the pairs ( v,j ) based on their neighborhood relations to the pair ( u,i ). For the item-based algorithm, it is given by Thus, only those pairs ( v,j ) for which i is in the neighbor-hood of j are selected. Notice that the selection of the pair ( v,j ) by N is independent of v . As such, the item-based al-gorithm ignores half of the neighborhood information about the pair ( v,j ).

Then, the global function G weighs the selected pairs ( v,j ) based on global statistics of the items i and j . For the item-based algorithm, it is given by It thus gives lower weights to those pairs ( v,j ) for which j has a higher count. Intuitively, if j is more popular, the evidence related to the pair ( v,j ) is considered less informa-tive. Similarly, if i is more popular, all evidence with respect to s ( u,i ) is considered less informative. Notice that, in this case, also the weight of the pair ( v,j ), as determined by G , is independent of v . As such, the item-based algorithm ignores c ( v ) and c ( u ), the global information about v and u . Notice furthermore that G is also used in the definition of the cosine similarity measure (Eq. 2), used to determine KNN ( j ). As in this case no rescaling is applied, S is given by
For a given user u , the user-based nearest neighbors al-gorithm by Sarwar et al. [13] first finds the neighborhood KNN ( u ) using the cosine similarity. Next, each neighboring user v  X  KNN ( u ) increases the score of a candidate rec-ommendation i , if i is preferred by v . Thus, the score of a candidate recommendation i for user u is given by [13]: Multiplying the above equation with the constant |I| = P j  X  X  1 does not change the ordering of the pairs ( u,i ) and allows us to rewrite it as Hence we have reformulated also the user-based algorithm as a weighted sum over all possible user-item pairs ( v,j ) in which the weight of a ( v,j )-pair with respect to the pair ( u,i ) is determined by the functions L , N , G and S (Eq. 3).
The local function L , which selects the pairs ( v,j ) based on their direct relation to the pair ( u,i ), is for the user-based algorithm given by It thus selects those pairs ( v,j ) such that v prefers i . Un-like the item-based algorithm, it does not consider the in-formation R uj and R vj to discriminate between different ( v,j )-pairs. Hence, the selection of the pair ( v,j ) by L is independent of j . As such, the user-based algorithm ignores local information related to j when weighing the pair ( v,j ).
Next, the neighborhood function N further selects the pairs ( v,j ) based on their neighborhood relations to the pair ( u,i ). For the user-based algorithm, it is given by Thus, only those pairs ( v,j ) for which v is in the neighbor-hood of u are selected. Notice that the selection of the pair ( v,j ) by N is independent of j . As such, the user-based al-gorithm ignores half of the neighborhood information about the pair ( v,j ).

Furthermore, since this algorithm does not weight the pairs ( v,j ) with any global statistic of u,i,v or j , the global function for the user-based algorithm is given by
Finally, for the user-based algorithm, the rescaling func-tion S rescales the weight of the pairs ( v,j ) with the size of the neighborhood of u and is therefore given by Now we generalize the definitions of the four functions L , N , G and S such that our formulation covers the most well known user-and item-based algorithms. Table 1 gives an overview of how these functions are defined for both the existing algorithms and our novel algorithm, which we will propose in the next section.

First, the local function L selects the pairs ( v,j ) depend-ing on the direct relations R ui , R vj and R vi between ( v,j ) and ( u,i ). The user-based algorithm (Sec. 3.2) considers only R vi and ignores the other information. The item-based algorithm (Sec. 3.1) on the other hand, combines all three pieces of direct information in the multiplication R ui R vj R vi , and thus selects those pairs ( v,j ) such that v and u share a preference for j and both i and j are preferred by v . Essentially, any combination of these direct relation-ships between u , i , v and j is possible.

Secondly, the neighborhood function N weighs the pairs ( v,j ) depending on the neighborhoods KNN ( u ), KNN ( v ), KNN ( i ) and KNN ( j ). Existing algorithms for OCCF con-sider only one of the four neighborhoods, as shown in Sec-tions 3.2 and 3.1. Consequently, the weighing function N reduces to a selection function for these algorithms . How-ever, any function of these four neighborhoods can be used. For example, in our novel algorithm KUNN, which we will propose in Section 4, we use
Both the user-and the item-based algorithm discussed in the previous two sections used the cosine similarity mea-sure to compute KNN ( x ) of an object x . Our formulation however, covers a broader range of similarity measures. Let p ,p i ,p v ,p j  X  R . For users u,v  X  X  , we define the similarity measure to compute KNN ( u ) as Similarly, for items i,j  X  X  , we define the similarity measure to compute KNN ( i ) as Notice that, in our formulation, the similarity between users (Eq. 6) and the similarity between items (Eq. 7) share the parameters p v and p j . Thus, choosing the user similarity limits the possibilities for choosing the item similarity and vice versa.

Thirdly, the global function G uses the global statistics to the pair ( u,i ). It is given by with p g  X  { 0 , 1 } and p u ,p i ,p v ,p j the same parameters as in Equations 6 and 7. Typically, these parameters are neg-ative or zero. In that case, users u,v and items i,j with higher counts reduce the weight of the ( v,j )-pairs with re-spect to ( u,i ). Intuitively, a more popular item is considered less informative for determining a taste, since this item is more likely preferred by diverse users. Similarly, a user that prefers many items is considered less informative for deter-mining a taste, since this user X  X  preferences are more likely to cover diverse items.

Notice that G , sim ( u,v ) and sim ( i,j ) (Eq. 8, 7 and 6) share the factors c ( u ) p u , c ( i ) p i , c ( v ) p v and c ( j ) we introduce the notation which allows us to rewrite the global function (Eq. 8) as and the similarities (Eq. 6 and 7) as with c (  X  ) = 1. This definition of W covers both the user-based algorithm by Sarwar et al. [13] and the different item-based algorithms by Deshpande et al. [2]. A more general faced and marked with a ? .
 definition of W would cover a broader range of nearest neigh-bors algorithms. We choose this definition over a more gen-eral one to emphasize the strong similarity between the lat-ter two algorithms.

Finally, some algorithms rescale the weights of the pairs ( v,j ) with the density of KNN ( u ), KNN ( i ), KNN ( v ) or KNN ( j ). A neighborhood KNN ( x ) of x is denser if the total distance of x to its neighbors is smaller. In other words, if the sum of the similarities of x to its neighbors is higher. Depending on the choice for KNN ( u ), KNN ( i ), KNN ( v ) or KNN ( j ), the rescaling function is given by one of the four density functions with p g the same parameter as for the global function G (Eq. 9).
 For an algorithm that does not apply rescaling,
Looking at Table 1, we observe that the user-based al-gorithm by Sarwar et al. [13] ignores the information R uj R vj , c ( i ), c ( j ), KNN ( i ) and KNN ( j ) for weighing the pairs ( v,j ) with respect to ( u,i ). Similarly, all item-based algo-rithms by Deshpande et al. [2] ignore the information c ( u ), c ( v ), KNN ( u ) and KNN ( v ) for weighing the pairs ( v,j ) with respect to ( u,i ). Thus, the existing algorithms ignore an important part of the available information. What is more, the information ignored by item-based algorithms is disjoint with the information ignored by the user-based algorithm. However, the fact that both user-and item-based algorithms generate acceptable results [13, 2], indicates that most likely both types of information are useful. Therefore, a novel al-gorithm that combines both types of information, KUNN 1 , KUNN is a recursive acronym for KUNN Unified Nearest Neighbors potentially leads to improved results. The experiments dis-cussed in Section 5 confirm that this is indeed the case. It is not only possible to outperform the individual user-and item-based algorithms, but also to outperform state-of-the-art matrix factorization algorithms [12, 7, 10].

The definitions of L , N , G and S corresponding to KUNN are given on the last row of Table 1.
 For KUNN, the local function is given by and thus selects those pairs ( v,j ) such that v and u share a preference for j and both i and j are preferred by v . As such, KUNN does not discard any information about the direct relation between ( v,j ) and ( u,i ).
 Next, the neighborhood function for KUNN is given by It thus selects those pairs ( v,j ) such that v is in the neigh-borhood of u or j is in the neighborhood of i . If both condi-tions are fulfilled, the weight of the pair ( v,j ) with respect to s ( u,i ) is doubled. As such, KUNN uses neighborhood information of both v and j to weight ( v,j ) with respect to ( u,i ).
 Furthermore, for KUNN, W is given by Consequently, the user-similarity results in and the item-similarity: Intuitively, if u and v share a preference for an item r I is only weak evidence of their similarity if r I is popular and both u and v have many preferences. Similarly, if i and j are both preferred by r U , it is only weak evidence of their similarity if r U has many preferences and both i and j are popular items.
 In addition, the global function for KUNN is given by
G ( u,i ) , ( v,j ) = W ( u,i ) , ( v,j ) 1 = 1 Intuitively, if the counts of u , i , v and j are higher, it is more likely that the direct relation between ( v,j ) and ( u,i )( L ( u,i ) , ( v,j ) = 1), exists by chance. Therefore, this direct relation is less informative.

Finally, we see no convincing arguments for making KUNN more complex by introducing a rescaling factor. Therefore we define To enhance the intuitive understanding of KUNN, we rewrite Equation 3 as with and Thus, we can decompose s ( u,i ) in a user-based part s U and an item-based part s I ( u,i ). Notice that these two parts cannot be reduced to any existing user-or item-based algo-rithm.

The user-based part s U ( u,i ) is a weighted sum over the neighbors of u in which the weight of a neighbor v is pro-portional to: A similar intuition holds for the item-based part s I ( u,i ).
Finally, the denominator of Equation 10, reduces the strength of the evidence if u prefers many items and i is popular.
We experimentally evaluate the accuracy of KUNN on three datasets: the Movielens , the Yahoo!Music user and the Yahoo!Music random datasets [19, 5]. These datasets contain ratings of users for movies and songs respectively. The rat-ings are on a 1 to 5 scale with 5 expressing the highest pref-erence. We convert these datasets to binary, positive-only datasets. Following Pradel et al. [11], we convert the ratings 4 and 5 to preferences and the ratings 1 and 2 to dislikes. Furthermore, we ignore the ratings 3, effectively converting them to unknowns. As such, we obtain a buffer between preferences and dislikes. Since our setting presumes binary, positive-only data, both the unknowns and the dislikes are represented by zeros in the training data. For evaluating the recommendations however, we are allowed to distinguish be-tween unknowns and dislikes.

In our evaluation we compare KUNN with five other al-gorithms. As a baseline, we select pop , the non-personalized algorithm that ranks all items according to their popular-ity, i.e. the number of users in the training set that prefer the item. Next, we select the user-based nearest neighbors algorithm with cosine similarity by Sarwar et al. [13] and the widely used item-based nearest neighbors algorithm with cosine similarity and similarity normalization ( SNorm+ ) by Deshpande et al. [2]. We choose this item-based algorithm because it performed well in comparison to other item-based algorithms [2]. Furthermore, we also compare with UB+IB , a linear ensemble that computes a recommendation score as with s UB ( u,i ) the user-based score from the algorithm by Sarwar et al. and s IB ( u,i ) the item-based score from the al-gorithm by Deshpande et al. Finally, we compare with two state-of-the-art matrix factorization algorithms for OCCF: the BPRMF algorithm by Rendle et al. and the WRMF al-gorithm by Hu et al. [7]. For WRMF and BPRMF we used the MyMediaLite implementation [4]. For all other algo-rithms, we used our own implementation, which is available at https://bitbucket.org/KVs/unncf_submit .

To thoroughly evaluate the performance of KUNN, we use evaluation measures from multiple previous works [2, 12, 11, 13]. The experimental evaluation consists of two experimental setups. In the user selected setup (Sec. 5.1), the users selected which items they rated. In the random selected setup (Sec. 5.2), users were asked to rate randomly chosen items.
This experimental setup is applicable to the Movielens and the Yahoo!Music user datasets. In both datasets, users chose themselves which items they rated. Following Desh-pande et al. [2] and Rendle et al. [12], one preference of every user is randomly chosen to be the test preference for that user. If a user has only one preference, no test preference is chosen. The remaining preferences are represented as a 1 in the training matrix R . All other entries of R are zero. We define the hit set H u of a user u as the set containing all test preferences of that user. For this setup, this is a singleton, denoted as { h u } , or the empty set if no test preference is chosen. Furthermore, we define U t as the set of users with a test preference, i.e. U t = { u  X  U | |H u | &gt; 0 } . Table 2 summarizes some characteristics of the datasets.

For every user u  X  U t , every algorithm ranks the items { i  X  I | R ui = 0 } based on R . We denote the rank of the test preference h u in such a ranking as r ( h u ).
Then, every set of rankings is evaluated using three mea-sures. Following Deshpande et al. [2] we use hit rate at 10 and average reciprocal hit rate at 10. In general, 10 can be replaced by any natural number N  X  |I| . We follow Deshpande et al. [2] and choose N=10.
 Hit rate at 10 is given by with top 10( u ) the 10 highest ranked items for user u . Hence, HR @10 gives the percentage of test users for which the test preference is in the top 10 recommendations.
 Average reciprocal hit rate at 10 is given by Unlike hit rate, average reciprocal hit rate takes into account the rank of the test preference in the top 10 of a user.
Following Rendle et al. [12], we also use the AMAN version of area under the curve, which is for this experimental setup given by AMAN stands for All Missing As Negative, meaning that a missing preference is evaluated as a dislike. Like average reciprocal hit rate, the area under the curve takes into ac-count the rank of the test preference in the recommendation list for a user. However, AUC AMAN decreases slower than ARHR @10 when r ( h u ) increases.

We repeat all experiments five times, drawing a different random sample of test preferences every time.
The user selected experimental setup introduces two bi-ases in the evaluation. Firstly, popular items get more rat-ings. Secondly, the majority of the ratings is positive. These two biases can have strong influences on the results and are thoroughly discussed by Pradel et al. [11]. The random se-lected test setup avoids these biases.

Following Pradel et al. [11], the training dataset is con-structed in the user selected way: users chose to rate a number of items they selected themselves. The test data-set however, is the result of a voluntary survey in which random items were presented to the users and a rating was asked. In this way, both the popularity and the positivity bias are avoided.
 This experimental setup is applicable to the dataset Yahoo!Music random . The training data, R , of this dataset is identical to the full Yahoo!Music user dataset. Additionally, this dataset includes a test dataset in which the rated items were randomly selected. For a given user u , the hit set H contains all preferences of this user which are present in the test dataset. The set of dislikes M u contains all dislikes of this user which are present in the test dataset. We define U t = { u  X  U | |H u | &gt; 0 , |M u | &gt; 0 } , i.e. all users with both preferences and dislikes in the test dataset. Table 2 summarizes some characteristics of the dataset.

For every user u  X  U t , every algorithm ranks the items in H u  X  X  u based on the training data R . The rank of an item i in such a ranking is denoted r ( i ).

Then, following Pradel et al. [11], we evaluate every set of rankings with the AMAU version of area under the curve, which is given by with AMAU stands for All Missing As Unknown, meaning that a missing preference does not influence the evaluation. Hence, AUC AMAU ( u ) measures, for a user u , the fraction of dislikes that is, on average, ranked behind the preferences. A big advantage of this measure is that it only relies on known preferences and known dislikes. Unlike the other measures, it does not make the bold assumption that items not pre-ferred by u in the past are disliked by u .

Because of the natural split in a test and training dataset, repeating the experiment with different test preferences is not applicable.
Every personalization algorithm in the experimental eval-uation has at least one parameter. For every experiment we try to find the best set of parameters using grid search. An experiment is defined by (1) the outer training dataset R , (2) the outer hitset S (4) the evaluation measure, and (5) the algorithm. Apply-ing grid search, we first choose a finite number of parameter sets. Secondly, from the training data R , we create five in-ner data splits, defined by R k , S run the algorithm on all five inner training datasets R k evaluate them on the corresponding inner test datasets with the chosen evaluation measure. Finally, the parameter set with the best average score over the five inner data splits, is chosen to be the best parameter set for the outer training dataset R with respect to the chosen evaluation measure. Notice that, given an outer training dataset, the best pa-rameters with respect to one evaluation measure, can differ from the best parameters with respect to another evaluation measure.
Table 3 shows the evaluation of the considered algorithms on different datasets, with different measures. The exper-iments belonging to the user selected setup were repeated 5 times, drawing a different random sample of test prefer-ences every time. Therefore, we report both the mean and the standard deviation for these experiments. The experi-ments belonging to the random selected setup use a natural split between the test and training dataset. Therefore, ran-domizing the test set choice is not applicable and only one value is reported for every experiment. Scripts for auto-matically repeating all experiments are available at https: //bitbucket.org/KVs/unncf_submit . The exact paramter combinations explored by the grid search procedure (Sec. 5.3) and other details can be inspected in these scripts.
From Table 3 we can make several observations. First of all, KUNN outperforms every other algorithm five out of seven times, shares one best performance with WRMF, and is one time outperformed by WRMF.

Secondly, the user-based algorithm clearly outperforms the item-based algorithm on the Movielens dataset. On the Yahoo!Music user dataset on the other hand, the item-based algorithm clearly outperforms the user-based algorithm. For UB+IB, the grid search procedure (Sec. 5.3) is successful in choosing  X  such that the best of both algorithms in the ensemble gets the highest weight. However, UB+IB cannot outperform the best of both individual algorithms. KUNN, on the other hand, successfully combines the user-and item-based information and consistently outperforms both indi-vidual algorithms.

Thirdly, the rather disappointing performance of BPRMF stands out. A possible explanation lies in the choice of the parameters. Following Rendle et al. [12], we used grid search (Sec. 5.3) to choose the best out of 267 parameter combina-tions for BPRMF in every experiment. We can however not rule out that there exist parameter combinations outside our 267 possibilities, for which BPRMF performs better. Find-ing a good set of parameters is harder for BPRMF than for the other algorithms because BPRMF uses 7 parameters that can all take an infinite number of values. The param-eters k U and k I of KUNN, on the other hand, are integers within the bounds [0 , |U| ] and [0 , |I| ] respectively. There-fore, we can find a good set of parameters among only 25 possibilities.

Finally, all personalized algorithms perform much better than the non personalized baseline pop .
The consideration that explanations of item-based algo-rithms are superior comes from observing the formulas for computing the recommendation scores [3, 7]. For item-based algorithms on the one hand, this formula is given by Equa-tion 4 in which every term can be attributed to one of the known preferences of the target user. Therefore the known preferences related to the biggest terms can naturally serve as an explanation for the recommendation. For user-based algorithms on the other hand, the formula is given by Equa-tion 5 in which every term can be attributed to one of the collaborative users. This is much less useful because the most similar users give no intuitive explanation for the rec-ommendation as they are probably strangers to the target user and the same for every recommendation. Furthermore, this kind of explanation would also be an invasion on the privacy of these collaborative users.

However, this difference is only artificial. Thanks to our reformulation, we can write both the user-based algorithm by Sarwar et al. [13] (Eq. 5) and KUNN as a sum over the known preferences of the target user.

We start with the user-based algorithm (Eq. 5). This algorithm can be rewritten as s ( u,i ) = 1 | KNN ( u ) | X Notice that the last factor in the summation is simply 1, but allows us to rewrite the equation as s ( u,i ) = 1 | KNN ( u ) | X In the above equation, we have written the user based score s ( u,i ) as a weighted sum over the known preferences of u .
The known preferences l 1 with the biggest weights, serve as a natural explanation for recommending i to u . Hence, we have naturally explained the user-based recommendation of i for u .

Next, we consider KUNN, which can be rewritten as s ( u,i ) = 1 p by regrouping Equation 3. Thus, also KUNN computes s ( u,i ) as a weighted sum over the known preferences of u .
Again, the known preferences with the biggest weights serve as a natural explanation for recommending i to u . Hence, we have naturally explained recommendations made by KUNN.
The majority of the work on collaborative filtering pre-sumes rating data. This setting is significantly different from our setting with binary, positive-only data. Therefore, the algorithms for rating based collaborative filtering differ on important aspects such as how they measure similarity, how their performance is measured and how they handle missing ratings, user-and item-biases.
 Hence, specific algorithms have been proposed for OCCF. First, an analysis of user-based nearest neighbors algorithms for OCCF was given by Sarwar et al. [13]. We discussed their work in Section 3.2 and compared experimentally to it in Section 5.

Later, Deshpande et al. [2] introduced the item-based near-est neighbors approach for OCCF. We discussed their work in Section 3.1 and experimentally compared to it in Section 5. Afterwards, similar approaches were suggested [15, 1]. Recently, multiple authors proposed to minimize a global cost function for computing the item similarities [12, 9, 8].
Furthermore, Symeonidis et al. [16] recognized that com-bining user-and item-based approaches could be beneficial. Additionally, Wang et al. [18] proposed a unification of user-and item-based algorithms. However, their work presumes rating data.

Finally, there exist also matrix factorization algorithms for OCCF [7, 10, 12, 14]. In our experimental evaluation (Sec. 5), we compared with two state-of-the-art algorithms of this class: WRMF by Hu et al. [7] and BPRMF by Rendle et al. [12].
We proposed KUNN, a novel algorithm for one class col-laborative filtering, a setting that covers many applications.
KUNN originates from a reformulation that unifies user-and item-based nearest neighbors algorithms. Thanks to this reformulation, it becomes clear that user-and item-based nearest neighbors algorithms discard important parts of the available information.

KUNN improves upon these existing nearest neighbors al-gorithms by actually using more of the available informa-tion. Our experimental evaluation shows that KUNN not only outperforms existing nearest neighbors algorithms, but also state-of-the-art matrix factorization algorithms.
Finally, we challenged the well accepted belief that item-based algorithms are superior for explaining the recommen-dations they produce. Thanks to our reformulation, we were able to show that also recommendations by KUNN and the traditional user-based algorithm come with a natural expla-nation.
 We see research on novel definitions of the functions L , N , G and S as the most important direction for future work. [1] F. Aiolli. Efficient top-n recommendation for very [2] M. Deshpande and G. Karypis. Item-based top-n [3] C. Desrosiers and G. Karypis. A comprehensive survey [4] Z. Gantner, S. Rendle, C. Freudenthaler, and [5] Grouplens. ml-1m.zip. [6] J. Herlocker, J. Konstan, and J. Riedl. Explaining [7] Y. Hu, Y. Koren, and C. Volinsky. Collaborative [8] S. Kabbur, X. Ning, and G. Karypis. Fism: Factored [9] X. Ning and G. Karypis. Slim: Sparse linear methods [10] R. Pan, Y. Zhou, B. Cao, N. Liu, R. Lukose, [11] B. Pradel, N. Usunier, and P. Gallinari. Ranking with [12] S. Rendle, C. Freudenthaler, Z. Gantner, and [13] B. Sarwar, G. Karypis, J. Kostan, and J. Riedl. [14] Y. Shi, A. Karatzoglou, L. Baltrunas, M. Larson, [15] B. Sigurbjornsson and R. van Zwol. Flickr tag [16] P. Symeonidis, A. Nanopoulos, A. Papadopoulos, and [17] N. Tintarev. Explanations of recommendations. In [18] J. Wang, A. P. de Vries, and M. J. Reinders. Unifying [19] Yahoo!Research. Yahoo webscope r3.tgz.
