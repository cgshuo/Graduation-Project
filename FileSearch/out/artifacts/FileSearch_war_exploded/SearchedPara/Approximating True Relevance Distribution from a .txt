 Pseudo relevance feedback (PRF), which has been widely applied in IR, aims to derive a distribution from the top n pseudo relevant documents D . However, these documents are often a mixture of relevant and irrelevant documents. As a result, the derived distribution is actually a mixture model, which has long been limiting the performance of PRF. This is particularly the case when we deal with difficult queries where the truly relevant documents in D are very sparse. In this situation, it is often easier to identify a small number of seed irrelevant documents, which can form a seed irrelevant distribution. Then, a fundamental and challenging problem arises: solely based on the mixed distribution and a seed irrelevance distribution, how to automatically generate an optimal approximation of the true relevance distribution? In this paper, we propose a novel distribution separation model (DSM) to tackle this problem. Theoretical justifica-tions of the proposed algorithm are given. Evaluation results from our extensive simulated experiments on several large scale TREC data sets demonstrate the effectiveness of our method, which outperforms a well respected PRF Model, the Relevance Model (RM), as well as the use of RM on D with the seed negative documents directly removed. Category and Subject Descriptors: H.3.3 [Information Search and Retrieval]: Retrieval models General Terms: Theory, Algorithms Keywords: Pseudo-relevance feedback, True relevance dis-tribution, Irrelevant data, Distribution separation model
Pseudo relevance feedback (PRF) has been widely used to improve information retrieval (IR) effectiveness due to its simple and fully automatic manner. Essentially, PRF aims at deriving a distribution from a set of n top ranked pseudo relevant documents D . A well regarded technique is the Relevance Model (RM) [6]. In reality, however, D is often a mixture of both relevant and irrelevant documents, thus yielding a mixture distribution. This has long been a bottleneck for effective deployment of PRF, due to the fact that the mis-inclusion of the irrelevant (or called negative) documents can hurt the IR performance. This is particularly the case when we are dealing with  X  X ifficult X  queries where the truly relevant documents in D are very sparse.
Negative relevance feedback has recently drawn increas-ing attention [3, 11, 13, 14]. Intuitively, due to the often preponderance of negative documents in D , a small num-ber of sample negative documents can be easier to identify, especially for difficult queries, than the relevant documents. When the relevant documents are sparse, the cognitive over-head for a user to find the truly relevant ones would be high. For example, the user may have to click as many as possible document links, even though some of them may not look relevant enough. This means that some documents clicked or viewed by the user may not be relevant at all. Instead, the documents ignored by the user may be regarded as irrel-evant. Therefore, the scenario this paper is concerned about is that relevant documents are difficult to obtain, while we can somehow identify a small number (or a small portion, e.g., 10%) of top ranked irrelevant documents in the pseudo relevance feedback set D .

Accordingly, our model assumes that the seed irrelevant documents are available. Besides the aforesaid user interac-tion manner (i.e., by click-through record), the seed irrele-vant documents can be obtained through a number of other ways, e.g., user explicit negative relevance feedback, or some automatic methods such as clustering algorithms (like k -nn used in [7]), which assume that negative documents tend not to cluster together, as opposed to the relevant ones. Regard-less of these different methods, in this paper, we will focus on how to utilize the seed irrelevance distribution, derived from these available seed negative documents, to estimate the true relevance model.

To do this, we have two distributions to start with: a mixed distribution from the top ranked pseudo relevant doc-uments D , and a seed irrelevant distribution obtained from the seed irrelevant documents in D . It is worth mentioning that our model is based on distributions rather than docu-ments, and is thus more general. In many cases, for example, we may have discarded old relevant or irrelevant documents after a number of search iterations. Nevertheless, we may still be able to keep updating relevant or irrelevant distribu-tion incrementally, as well as keep tracking other items or features, such as query modifications, from which a proba-bility distribution can also be formed.

The research problem we deal with in this paper is: Given the mixed distribution and the seed irrelevance distribution, how to automatically derive an optimal approximation of the true relevance distribution? In other words, can we separate the true relevance distribution from the mixture one?
In this paper, we propose a novel distribution separation model (DSM) to tackle this problem. The model is based on two assumptions. Firstly, the distribution w.r.t. the pseudo relevant document set is a linear combination of two distributions w.r.t two partitions of the whole set. This is consistent with the fact that linear combination is a com-monly used technique in IR for mixture model generation. It makes the distribution separation possible. Secondly, the seed irrelevance distribution and the optimal relevance dis-tribution have a minimum correlation. Imagine that if the irrelevance distribution had strong positive correlation with the relevance distribution, then the irrelevance distribution would have resulted in a good retrieval performance.
Based on these two assumptions (linear combination and minimum correlation), a unified framework for distribution separation is proposed. Theoretical justifications of the pro-posed algorithm are given. Evaluation results from our ex-tensive simulated experiments on several large scale TREC data sets demonstrate the effectiveness of our method. Our approach outperforms the classical Rocchio X  X  model [9] for negative relevance feedback, the RM for pseudo relevance feedback, as well as the use of RM on D with the seed neg-ative documents directly removed.
In the IR context, (positive and/or negative) relevance feedback is a post-query process to enhance IR performance by creating a revised query [12]. A classical method to con-struct the refined query is Rocchio X  X  relevance feedback [9], which aims to boost the terms from relevant documents and reduce the weights of terms from irrelevant documents. Note that we can also use Rocchio X  X  model to perform negative feedback by ignoring its component w.r.t. relevant docu-ments. Another well regarded pseudo-feedback method is the Relevance Model [6], which assumes that both the orig-inal query and top ranked documents are samples from a relevance model R , and efficiently constructs a probability distribution P ( w | R ).

The process of relevance feedback can be explicit, implicit or pseudo, each of which has its own advantages and disad-vantages. Explicit relevance feedback has been shown useful to improve the IR performance [1]. However, users in gen-eral may be constrained and reluctant to provide explicit relevance feedback on a large number of top ranked doc-uments [2, 5, 4]. Implicit relevance feedback aims to infer the user X  X  preferences based on his/her interactions with the system, such as the user X  X  click-through record and viewing time, etc [15]. It avoids the need of user X  X  explicit judgments, but in the expense of the accuracy of the implicit relevance judgements inferred from user interactions. Indeed, it is still largely under exploration on what interactions should be taken into account and how good they are as relevance factors. Pseudo relevance feedback simply assumes a num-ber of top ranked documents as relevant. It is simple, fully automatic, and in general can improve the IR effectiveness, but may suffer from problems caused by the irrelevant doc-uments in the pseudo relevant document set.

This motivates our work, aiming at enhancing pseudo rel-evance feedback by automatically approximating the true Figure 1: An illustration of the linear combination assumption for pseudo relevant documents.  X + X  and  X   X   X  stand for the relevant and irrelevant feedback documents, respectively. relevance distribution from a mixture model (correspond-ing to pseudo relevant documents) and a seed irrelevance distribution (corresponding to a small number of irrelevant documents that can be obtained through explicit relevance feedback, user interactions, or automatic methods).
Our approach is distinct in the following aspects: (1) It can integrate explicit, implicit and pseudo relevance feedback, thus inheriting their advantages and overcoming their limitations. (2) It is robust and feasible in practice as it requires only a small number of seed irrelevant documents to achieve a stable and good performance; (3) It deals with separating probabilistic distributions di-rectly, thus is more general and applicable to many other cases where the seed irrelevance information is available in other forms (e.g., terms excluded from previous queries in a query modification history) that can be converted into a probability distribution.
Table 1 lists some major notations used in our paper. For simplicity the l (  X  ,  X  ) omits the specific linear coefficient. Fig-ure 1 illustrates how the distribution M w.r.t. the pseudo relevant document set, is a linear combination of two distri-butions I S and l ( R, I S ) w.r.t two partitions of the whole set, where l ( R, I S ) is also a linear combination of R and I Notation Description Corresponding Doc M mixed distr. all feedback docs. D I irrel. distr. all irrel. docs. D I in D R rel. distr. all rel. docs. D R in D I S seed irrel. distr. seed irrel. docs. D I S
I S unknown irrel. unknown irrel. docs.
P F ( i ) probability of the i th term in distr. F l ( F, G ) linear combination of distr. F and G
Our task can be then defined as follows: given the mixture distribution M and a seed irrelevance distribution I S , find a R  X  which approximates the R . This can be divided into three steps: 1) How to separate the distribution l ( R, I S ), which is less noisy but is still a mixture of the true relevance and the unknown irrelevance distributions, from the seed irrelevance distribution I S in M . 2) How to further find an optimal R  X  that approximates R as closely as possible; 3) How to generate a framework which can comprise pre-vious steps and have a unified theoretical explanation.
Now, given the mixture distribution M and the seed ir-relevance distribution I S , we need to compute the less noisy mixture distribution l ( R, I S ). Recall that M is a nested linear combination l ( l ( R, I S ) , I S ), which can be represented as: where  X  (0 &lt;  X   X  1) is the (real) linear coefficient w.r.t. l ( R, I S ).

Our aim is to compute an estimate of l ( R, I S ), denoted as  X  l ( R, I S ). According to Equation 1,  X  l ( R, I S ) can be computed by finding a  X   X  , an estimate of  X  : where 0 &lt;  X   X   X  1.

The key is to find an estimated linear coefficient  X   X  , as the choice of  X   X  determines  X  l ( R, I S ). Furthermore, if  X  bution. However, there are infinite choices of  X   X  , and accord-ingly there will be infinite solutions to  X  l ( R, I S ). Hence, we add a necessary and natural constraint  X  l ( R, I S ) &lt; 0, which means that all the values in  X  l ( R, I S ) should be not less than 0. This constraint theoretically sets a lower bound of  X   X  : where ./ denotes the entry-by-entry division of M by I S , and max(  X  ) denotes the max value of the resulted vector 1  X  M./I S . This lower bound  X  L itself also determines an estimate of l ( R, I S ), denoted as l L ( R, I S ).
The lower bound  X  L is essential to the determination of  X   X  . We will discuss it in-depth in the rest of the paper. To analyze it, we will first investigate how the reduction of affects its corresponding  X  l ( R, I S ), by presenting Lemma 1. For simplicity, we use some simplified notations listed in Table 2.

Lemma 1. Assume P M ( i ) &lt; P I S ( i ) . If  X   X  1 &lt; corresponding P  X  l
Proof. Suppose term i satisfies P M ( i ) &lt; P I S ( i ) cording to Equation 2, we can get: This equation implies that P  X  l the same sign. Hence, if  X   X  1 &lt;  X   X  2 , then P  X  l accordingly, and vice versa.

The lower bound of  X   X  ,  X  L , is the critical value and its cor-responding l L ( R, I S ) definitely has zero values. If this does not hold, meaning P l L ( i ) &gt; 0 for every term i , there exists a smaller  X   X  (  X   X &lt; X  L ), which can correspond to a distribution  X  l ( R, I S ) with no negative value. This conflicts the fact that  X  L is the lower bound.

Next, we will present another property of  X  L in Lemma 2, which guarantees if there exists zero value in l ( R, I S  X 
L =  X  . This is an important property, in the sense that, in pseudo relevance feedback, the zero values often exist in l ( R, I S ) if there is no smoothing step involved. In this case,  X  L =  X  , leading to l L ( R, I S ) that equals to l ( R, I is our desired distribution.

Before presenting Lemma 2, let us consider a simple ex-ample. Suppose l ( R, I S ) = [0.1, 0.3, 0.3, 0.1, 0, 0.2] [0.2, 0, 0.1, 0.3, 0.1, 0.3] T , and the real linear coefficient  X  = 0 . 4. According to Equation 1, M =[0.16, 0.12, 0.18, 0.22, 0.06, 0.26] T . Now, given M and I S only, according to Equation 3, we can derive  X  L = 0 . 4. This means that  X  L =  X  and l L ( R, I S ) = l ( R, I S ).
 Lemma 2. If there exists a zero value in l ( R, I S ) , then  X  =  X  , leading to l L ( R, I S ) = l ( R, I S ) .

Proof. Let the probability of term i in l ( R, I S ) be zero, Table 2, this means P l ( i ) = 0.

Recall that P l L ( i )  X  0. Thus we can only consider two mer condition will always be satisfied and can demonstrate  X  generate a contradiction with itself thus does not hold. 1) P l L ( i ) = 0: For the i th term, this means P l L ( i ) = P ( i ) = 0, a perfect linear fitting for P l ( i ) by P M ( i ) and P
S ( i ). If we find the  X  for the term i , then  X  will also be the right one for other elements, since all the elements in a same distribution should have the same linear coefficient. Thus,  X  L =  X  ; 2) P l L ( i ) &gt; 0: Recall that  X  L is a critical value and there exist zero values in its corresponding l L ( R, I S P
L ( i ) &gt; 0, we can let the j Now, we will consider two cases of P l ( j ), i.e., P l ( j ) = 0 and P ( j ) &gt; 0: a) If P l ( j ) = 0, then P l ( j ) = P l L also a perfect linear fitting and leads to  X  L =  X  . Therefore, P L ( i ) = P l ( i ) = 0. This is contrary to the precondition P
L ( i ) &gt; 0. b) If P l ( j ) &gt; 0, since P l ( j ) ( P P
L ( j ) ( P l L ( j ) = 0) correspond to  X  and  X  L respectively, according to Lemma 1, we have  X  &gt; X  L and thus 0 = P l ( i ) &gt; P l L ( i ). This contradicts the fact that P l L ( i )  X  0.
Now, we consider the case where a smoothing step is in-volved. In PRF background, after applying smoothing (usu-ally with the collection model), there will not be zero values,
In this subsection, the discussion is only based on the cases when P M ( i ) &lt; P I S ( i ). Other cases will be discussed later. but instead a lot of small values exist, in l ( R, I S ). In this context, Remark 1 guarantees the approximate equality be-tween  X  L and  X  .

Remark 1. If there is no zero value, but there exist a lot value, then l L ( R, I S ) will be approximately equal to l ( R, I
Since  X  L is the lower bound, then  X  L  X   X  . Also because there exist zero elements in l L ( R, I S ), then  X  L 6 =  X  , implying  X  L &lt;  X  . However, if  X  L is not close to  X  , according to Lemma 1, a lot of small values in P l L ( i ) are likely to be negative. This violates the fact that all P l L ( i ) are not less than zero. Thus  X  L should be quite close to  X  . According to Lemma 1, l L ( R, I S ) should then be approximately equal to l ( R, I S ). Therefore, the proper estimate of l ( R, I be l L ( R, I S ).
Using the above strategy, a less noisy but still mixed distri-bution l ( R, I S ) can be derived. In this section, we investigate how to compute a distribution R  X  that can approximate the true relevance distribution R . Our method is based on the following two observations on the difference between l ( R, I and R . 1) The linear coefficient of R w.r.t M ( M = l ( R, I )) is less than that of l ( R, I S ) w.r.t M ( M = l ( l ( R, I S ) , I means that the corresponding linear coefficient  X  should be reduced accordingly for R . 2) If the pseudo feedback documents do not share the same or a very similar distribution with each other, which is true in most cases, then the true relevance distribution R should be less smooth than the mixture distribution l ( R, I S ).
To further explain the first observation, let us consider a simple example. Assume the probability of each term w in a specific document set D F (e.g., D F could be D or D I S defined as where tf ( w, D F ) denotes the number of times of w occurring in D F , and tf ( D F ) = where N , N F and N G are the numbers of terms in D ( D = D puted by Equation 5 on document sets D , D F and D G , re-spectively. From this example, we can find that the numbers of terms, e.g., N F or N G , determine the linear coefficient of F or G , respectively. Therefore, if we generate distribution using Equation 5, since the number of terms in R is less than the number in l ( R, I S ), the linear coefficient of R should be less than that of l ( R, I S ). More generally, this observation can still hold by just imagining that the linear coefficient of R or l ( R, I S ) w.r.t. M can be equivalent to the weights of them w.r.t. M .

As for the second observation, it is also the number of terms and their distribution that play a key role. If each top-ranked document does not have the same distribution with each other, the more terms will usually mean a more smooth distribution. This is also an explanation why in many methods the distributions are smoothed by the collec-tion model.

Now, given the above two observations, the problem is how to refine the distributions M and I S by reducing terms properly, in order to further compute a relevance distribu-tion R  X  that can bridge the gap between l ( R, I S ) and R . To this end, we propose a strategy as follows: If any term i meets the following condition: then, term i will be deleted in both M and I S , where  X  L the pervious lower bound, and  X  &lt; 1 is a parameter in our model to control the refinement step. This refinement step can be explained in an intuitive way. Specifically, if term i satisfies Equation 7, it means that P M ( i ) is very small while P
S ( i ) is relatively large, and then we can safely consider this term as irrelevant.

After this refinement, we let the current l L ( R, I S ), which is computed by Equation 2 using current M , I S and  X  L , be the solution to the relevance distribution R  X  . Next, we will describe that  X  L has been reduced, and accordingly the cur-rent l L ( R, I S ) becomes less smooth than the previous one.
To demonstrate the reduction of  X  L , we will consider two cases. First, if current M and I S are not normalized, accord-ing to Equation 3 and 7, the current  X  L is not greater than previous  X  L multiplied by  X  . Second, if current M and I are normalized, we need to normalize the previous l L ( R, I only concerned with remaining terms, and compute its lin-ear coefficient w.r.t. M . This coefficient is also larger than current  X  L , which is the lower bound of all possible linear coefficients. In other words,  X  L has been reduced. For a better clarity, let us look at the example before Lemma 2. Here, we set  X  = 0 . 6 to control the refinement. According to Equation 7, the fourth and fifth terms in M and I S will be deleted. After this refinement, if M and I
S are not normalized, the current  X  L will be 0.2 which is less than the previous  X  L 0.4, and the current l L ( R, I is [0, 0.6, 0.5, 0.1] T which is equivalent to [0, 0.5, 0.4167, 0.0833] T after normalization. If M and I S are normalized, the current  X  L is 0.3333, and the corresponding l L ( R, I is still [0, 0.5, 0.4167, 0.0833] T ; the previous l L ( R, I remaining terms is [0.1111, 0.3333, 0.3333, 0.2222] T after normalization. By slightly changing Equation 2, we can get the linear coefficient of this previous l L ( R, I S ) w.r.t. M is 0.5, which is greater than the current  X  L , 0.3333.
With regard to the less smoothness of current l L ( R, I S firstly, it involves less number of terms than the previous one. Secondly, even for the remaining terms, the current l ( R, I S ) is still less smooth than the previous one (see the above example). Now, only considering these remaining terms in current normalized M and S , we propose Lemma 3 to demonstrate that along with reducing  X   X  (  X  L &lt;  X   X   X  1), the probability values in the corresponding  X  l ( R, I S ) will ap-proach to 0 or 1 (see Figure 2). In this sense, the current l ( R, I S ) should be less smooth than the previous one since the former corresponds to a smaller linear coefficient.
Lemma 3. The more we reduce  X   X  (  X  L &lt;  X   X   X  1 ), the more values in the corresponding  X  l ( R, I S ) approaches to 0 or 1. Proof. This proof is based on Lemma 1. When P M ( i ) &lt; P
S ( i ), if Similarly, when P M ( i ) &gt; P I S ( i ), from Equation 4, it turns out that if  X   X  1 &lt;  X   X  2 , then P  X  l Figure 2: The effect of reducing  X   X  (  X  L &lt;  X   X   X  1 ) on the corresponding  X  l ( R, I S ) computed by Equation 2. Now, we can keep reducing  X   X  (  X   X  1 or  X   X  2 ) (see Figure 2). When P M ( i ) &lt; P I S ( i ), it turns out that the more we re-duce  X   X  , the more P  X  l ( i ) approaches to 0. On the other hand, when P M ( i ) &gt; P I S ( i ), the more we reduce  X   X  , the more P approaches to 1;
Till now, we can conclude that l L ( R, I S ) is less smooth than before and corresponds to a smaller linear coefficient. This complies with the two observations mentioned earlier in this subsection. To sum up, it is expected that if  X  in Equation 7 is properly adjusted, the refined l L ( R, I S be R  X  that approximates R .
We have shown the important role of the lower bound  X  L and the corresponding l L ( R, I S ). Indeed, they have good properties as discussed in the previous sections. However, an underlying risk is that l L ( R, I S ) (a  X  l ( R, I S be singular (i.e., too unsmooth). A subsequent problem is: which criterion can we adopt to control this risk and choose the proper  X  l ( R, I S )?
From Figure 2, we observe that for any 2 term i , the more we reduce  X   X  , the more P  X  l ( i ) will be further away from P Intuitively, this can make the correlation between  X  l ( R, I and I S smaller. In this paper, we propose to use Pearson product-moment correlation coefficient [10]  X  (  X  1  X   X   X  1), which is a standard correlation measurement, as the crite-rion to control the linear coefficient  X   X  . At first, we will ana-lyze how this correlation coefficient changes while reducing  X   X  , by Proposition 1.

Proposition 1. If  X   X  (  X   X  &gt; 0) decreases, the correlation coefficient between  X  l ( R, I S ) and I S , i.e.,  X  (  X  l ( R, I decrease.

Proof. Let E ( M ) = E ( I S ) = E (  X  l ( R, I S )) = 1 m m is the number of terms concerned. Let a = )( P M ( i )  X  P I S ( i )), b = and c &gt; 0; and assume  X  (  X  l ( R, I S ) , I S ) = 0 if
From the definition of correlation coefficient, we obtain  X  (  X  l ( R, I S ) , I S ) = Here, we do not consider the case when P M ( i ) = P I S ( i )
To facilitate the proof, let  X  = 1 /  X   X  and  X  (  X  ) =  X  ( I ). By expanding P  X  l ( i ) based on Equation 2, it turns out that
The derivative of  X  (  X  ) w.r.t.  X  is
By Cauchy-Schwarz inequality, ( a 2  X  bc )  X  0. Hence it turns out  X  0 (  X  )  X  0. When ( a 2  X  bc ) &lt; 0,  X  (  X  ) is strictly monotonically decreasing with increasing  X  .

When ( a 2  X  bc ) = 0,  X  =  X  b a is a discontinuity point in  X  (  X  ), since c X  2 + 2 a X  + b = 0, which means  X  l ( R, I , 1 m , . . . , 1 m ] T , leading to  X  (  X  l ( R, I S ) , I assumption of this proof. If  X  6 =  X  b a , from Equation 8, we equivalently  X  &gt; 0 ); and  X  &lt;  X  b a is not in the domain of (  X  &gt;  X  b a ).

In conclusion,  X  (  X  ) decreases when  X  increases. Therefore,  X  (  X  l ( R, I S ) , I S ) is decreasing with decreasing  X   X  (  X  According to Proposition 1, among all  X   X   X  [  X  L , 1],  X  responds to min(  X  ), i.e., the minimum correlation coefficient between  X  l ( R, I S ) and I S . This minimum correlation coeffi-cient could be negative. However, we think that negative correlation does not often exist between true relevance dis-tribution R and irrelevance distribution I S , especially in the PRF context. In general, most terms in R are independent of those in I S , while some terms are expected to be posi-tively correlated, such as query terms and common terms. Only a small number of terms may be negatively correlated.
Therefore, it is natural to change the minimum correla-tion coefficient (i.e., min (  X  )) to minimum correlation (i.e., min (  X  2 )), in order to avoid negative coefficients and control the singularity of  X  l ( R, I S ). This idea can be formulated as the following optimization problem:
To solve this optimization problem, we need to first solve such a  X   X  that the corresponding  X  (  X  l ( R, I S ) , I S cording to the proof in Proposition 1, this  X   X  =  X  a b . Then, we need to check whether  X  L  X   X  a b  X  1 holds. If it holds, the optimal linear coefficient  X   X  for the optimization prob-lem in Equation 10 is  X  a b . Otherwise, we just compare the values of [  X  (  X  l ( R, I S ) , I S )] 2 w.r.t.  X   X  = 1 and to get the optimal  X   X  . The corresponding l  X  ( R, I S ), called the optimal R  X  , is the relevance distribution obtained by our model.

Now, we will present a unified framework of our distribu-tion separation model (DSM) in Algorithm 1. When  X  = 1 in DSM, according to Equation 7, there is no refinement step for M , I S and  X  L . By contrast, when  X  &lt; 1, DSM involves refinement. Note that the refinement cannot be performed alone, i.e., after refinement, the distribution separation (see steps 3 and 4 in Algorithm 1) will still need to be involved. Algorithm 1 Framework for Distribution Separation Input: Distribution: mixed M , seed Irrelevant I S Output: Approximately true relevance distribution: R  X  Parameter:  X  (0 &lt;  X   X  1)
Step 1: Compute the initial  X  L using Equation 3 based on input M and I S .

Step 2: Given  X  , according to Equation 7, refine M , I S and  X  L .

Step 3: Based on the refined M , I S , and  X  L , solve the optimization problem in Equation 10, and get the optimal  X  .
 Step 4: Using  X   X  , obtain the R  X  based on Equation 2.
Compared with min (  X  ), the objective function min (  X  2 in Equation 10 can make our model more general and also control the risk of reducing  X  L due to the facts that: 1) if an unreasonable  X  L (i.e., leading to a negative correla-tion) occurs, min (  X  2 ) can result in a  X   X   X  [  X  L , 1] that has a minimum but non-negative correlation; 2) if  X  L does not deduce a negative correlation, then,  X  L , corresponding to min (  X  ), will also be the solution of min (  X  2 ); in this case,  X  is equivalent to the one computed in Section 3.2 (  X  = 1) or in Section 3.3 (  X  &lt; 1), and so does its corresponding relevance distribution.

In summary, DSM can encompass the different strategies discussed earlier. In the next section, we will report the experimental results on this unified framework.
Experiments are conducted on four standard TREC col-lections, including WSJ (87-92, 173,252 docs), AP (88-89, 164,597 docs) in TREC Disk 1 &amp; 2, ROBUST 2004 (528,155 docs) in TREC Disk 4 &amp; 5, and WT10G (1,692,096 docs). These data sets respectively involve a variety of texts, e.g., newswire articles and Web/blog data.

Title queries are used for retrieval. Both WSJ and AP data sets are tested on queries 151-200, while the ROBUST 2004 and WT10G collections are tested on queries 601-700 and 501-550, respectively.

Lemur[8] 4.7 is used for indexing and retrieval. All collec-tions are stemmed using the Porter stemmer and stop words are removed in the indexing process.
Although the input distributions for DSM can be drawn from any method (e.g., by using Equation 5), in our exper-iments, we choose to use the output distributions of Rele-vance Model (RM) [6]. Note that two methods (RM1 and RM2) were developed in RM. The distribution by RM1 can be defined as follows: where P ( Q ) = can be computed by Equation 12: where tf ( w, d i ) is the occurrence frequency of a term w in a document d i .

DSM adopts RM1 for distribution generation due to two reasons. Firstly, RM is a well accepted model in PRF. Sec-ondly, compared with the RM2 3 , RM1 is more consistent with the linear combination assumption and has generated a competitive performance. In the implementation, we use the distribution obtained by RM1 in Lemur 4.7, and set the smooth parameter  X  1 as the default value 0.5. Further, for sake of efficiency and feasibility, we just keep the terms whose probabilities are greater than 0.0001 in the mixed dis-tribution, and use the same set of terms in the seed irrelevant distribution. Initially, the top n ( n = 50) pseudo feedback documents D are retrieved by the KL-divergence based language model (LM), with Dirichlet prior[16]  X  2 as the default value 700. Based on these documents, we then run experiments to com-pare our model with two well-known relevance feedback tech-niques: Rocchio X  X  relevance feedback model and the Rele-vance Model (RM1, see Equation 11).
 RM is selected as the baseline due to the facts that: first, RM is a successful PRF model and consistently outperform the standard LM model by 10%-15% [6]; second, it has been demonstrated in [14] and in our experiments as well that only based on given irrelevant documents, Rocchio X  X  model does not perform well (see the next subsection for details).
Next, a small portion (top 10%, 20%, and 30% separately) of negative documents in D are selected as the seed negative documents D I S . We then run RM1 on D and D I S , respec-tively, to generate the mixed distribution M and the seed irrelevant distribution I S .

Based on these two distributions, M and I S , we first run the distribution separation model (DSM) without the re-finement step (i.e., step 2 in Algorithm 1), to see whether it can outperform the baseline (RM on D ), and whether it can produce a comparable performance with RM on D  X  D I S . After that, DSM with refinement step is tested to evaluate the effect of the refinement step. In all these feedback mod-els, the number of expanded terms is fixed as 100, and 1000 retrieved documents are used for performance evaluation. As for the evaluation metric, we use the Mean Average Precision (MAP), which reflects the overall ranking accu-racy. In addition, we use the Wilcoxon significance test to examine the statistical significance of the improvements of the DSM model over the baseline.
Rocchio X  X  relevance feedback is a classical relevance feed-back method to update original query. It is initially based on the Vector Space Model, and here we rewrite it in the
Different from RM1, RM2 involves conditional sampling and is less consistent with the linear combination assump-tion. S (top 20% of I ) I S (top 30% of I ) 0.3798(+7.35%)  X  X  X  0.3872(+9.44%)  X  X  X  0.3787(+7.04%)  X  X  X  0.3776(+6.73%)  X  X  X  0.4042(+7.64%)  X  X  X  0.4109(+9.43%)  X  X  X  0.4004(+6.63%)  X  X  X  0.4050(+7.86%)  X  X  X  ROBUST 2004 0.3772(+15.63%)  X  X  X  0.3853(+18.12%)  X  X  X  0.3745(+14.81%)  X  X  X  0.3797(+16.40%)  X  X  X  0.2419(+20.71%)  X  X  X  0.2631(+31.29%)  X  X  X  0.2438(+21.66%)  X  X  X  0.2609(+30.19%)  X  X  X  form of probabilistic distributions: P new ( w ) =  X   X  P Q ( w ) ) where the subscripts Q new and Q stand for the original and refined queries; R and I indicate the relevant and irrele-vant distributions;  X  ,  X  and  X  are three parameters; and P ( w | d i ) can be computed by Equation 12, which are es-sentially equivalent to Vector Space Model based on term frequency.

As in our scenario only irrelevance information is avail-able, the second component in the right-hand side of Equa-tion 13 is removed. Using the irrelevant distribution w.r.t 20% top ranked irrelevant documents, the results of the Roc-chio X  X  model (with fixed  X  = 1) are shown in Figure 3, which indicate that Rocchio X  X  model does not perform well with irrelevance information only. This observation is consistent with the results shown in [14], where it was found that the use of negative information only in Rocchio X  X  model often hurts the retrieval performance. This is indeed a motivation for us to derive alternative methods to utilize these seed irrelevance information more effectively.
The aim of this set of experiments is to test the effective-ness of the distribution separation model (DSM) without refinement step, i.e., DSM (  X  = 1), and see if it can outper-form the baseline (RM).

Furthermore, this experimental configuration is also used to verify the theoretical justifications in Section 3.2. The real l ( R, I S ) can be generated by RM on D  X  D I S . How-ever, this is a document-level method since the exact D  X  D must be available. By contrast, DSM is a distribution-level method and its input are two distributions. In the experi-ments, when the refinement step is not involved, the negative Figure 3: The performance of Rocchio X  X  model un-der different modified parameter  X  using irrelevance data w.r.t each collection. correlation rarely exists. In this case, according to our anal-ysis following the Algorithm 1, the  X   X  computed by DSM equals to  X  L in most cases. This means that the output distribution would be l L ( R, I S ), which should be close to l ( R, I S ) according to Remark 1.

From the experimental results shown in Table 3, we can observe that DSM (  X  = 1) significantly outperform the base-line (i.e., RM on D ), even when only 10% irrelevant docu-ments in D are used seed. Also, an exciting trend is that the larger scale collections and the larger ratio (from 10% to 30%) of irrelevant documents are involved, the larger im-provements are obtained.

Moreover, when  X  = 1, DSM X  X  performance is very close to RM on D  X  D I S . On WT10G (10% and 20% of I ), it even slightly outperforms RM on D  X  D I S . This is con-sistent with the theoretical analysis we gave in Section 3.2, and demonstrates that DSM can derive a less noisy mixture distribution.
Now we will evaluate whether DSM with refinement (i.e.,  X  &lt; 1) can derive a distribution that approximates the true relevance distribution R . Since it involves the refinement (or reduction) of distribution M and I S , we initially keep the original query terms apart from the refinement and sep-aration process. After the separation process, we then add them back with the highest value to the derived distribution. We use this approach due to two reasons. First, if we do not reserve query terms, they would be deleted in the refinement process, which is indeed not good for retrieval performance. Second, both M and I S correspond to top-ranked documents retrieved by the original query. As a result, it will be likely that the probabilities of some query terms in all these dis-tributions are similar. In this case, these highly correlated terms would affect our process to find a distribution that has the minimum correlation with the given I S .

There is only one main parameter  X  to adjust in the DSM method. In Table 3, we list the optimal results by selecting  X   X  [0 . 4 , 1] with increment 0.1. The results show that DSM method not only significantly outperform RM, but also out-performs RM a lot on D  X  D I S in most cases, for instance, by 4.53%, 6.11%, 4.75% on WSJ, by 5.95%, 6.92%, 6.57% on Robust 2004, and by 1.19%, 7.23%, 3.54% on WT10G. Also note that, for Robust 2004, the relative improvements of DSM over RM on D  X  D I S are at the significance levels 0.05, 0.01 and 0.01 respectively.
As for the parameter selection, we observe that most ef-fective refinements (e.g., results on WSJ, Robust2004 and WT10G) are corresponding to the minimum value (0.4) of  X  . This could be because that if we only consider the re-maining terms after the refinement using the minimum  X  , the corresponding  X  l ( R, I S ) and I S w.r.t. minimum  X  has the minimum correlation coefficient, compared with other correlation coefficients between  X  l ( R, I S ) and I S w.r.t. other  X  .

We would also like to discuss the difference between the minimum correlation min (  X  2 ) and minimum correlation co-efficient min (  X  ), which has been addressed in Section 3.3. Experimental results reported earlier were obtained by the use of min (  X  2 ). For comparison, we also carried out experi-ments using min (  X  ). We observe that there is a very small difference (about 0.2% in MAP) between the performance of two objective functions, due to the fact that negative cor-relation seldom exists.

Here, we argue that the objective function min (  X  2 ) is more general. When negative correlation is rare, as in our experiments, the solution of min (  X  2 ) has the same effective-ness as the solution of min (  X  ). On the other hand, if neg-ative correlation occurs quite often and hurts the retrieval performance, min (  X  2 ) can serve as a constraint to alleviate the negative impact on retrieval performance.
In this paper, we have presented a unified framework for a distribution separation model (DSM), which can derive an optimal approximation of the true relevance distribu-tion from a mixture distribution (corresponding to pseudo relevance feedback documents), based on a small amount of available seed irrelevance data. The proposed model is neat due to the theoretical justification and guarantee of its solutions. Practically, our model consistently and signifi-cantly outperforms two widely accepted relevance feedback approaches on a variety of TREC collections.
The authors would like to thank anonymous reviewers for their constructive comments. This work is supported in part by the UK X  X  Engineering and Physical Sciences Research Council (EPSRC, grants EP/E002145/1 and EP/F014708/1), the National Natural Science Foundation of China (NSFC grant 60603027), and MSRA Internet Services Theme Project. [1] C. Buckley and G. Salton. Optimization of Relevance [2] S. Dumais, T. Joachims, K. Bharat, and A. Weigend. [3] M. D. Dunlop. The effect of accessing non-matching [4] M. R. Henzinger, R. Motwani, and C. Silverstein. [5] B. Jansen, A. Spink, and T. Saracevic. Real Life, Real [6] V. Lavrenko and W. B. Croft. Relevance-based [7] K.-S. Lee, W. B. Croft, and J. Allan. A cluster-based [8] P. Ogilvie and J. Callan. Experiments using the lemur [9] J. J. Rocchio. Relevance feedback in information [10] J. L. Rodgers and A. W. Nicewander. Thirteen ways [11] A. Singhal, M. Mitra, and C. Buckley. Learning [12] C. J. van Rijsbergen. Information Retrieval . [13] X. Wang, H. Fang, and C. Zhai. Improve retrieval [14] X. Wang, H. Fang, and C. Zhai. A study of methods [15] R. White, I. Ruthven, and J. Jose. A Study of Factors [16] C. Zhai and J. Lafferty. A study of smoothing
