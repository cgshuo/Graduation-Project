 Yue Wu yw289@cam.ac.uk Jos  X e Miguel Hern  X andez Lobato jmh233@cam.ac.uk Zoubin Ghahramani zoubin@eng.cam.ac.uk Univariate financial returns are heteroscedastic, that is, the volatility or standard deviation of financial re-turns is not constant, but changes with time (Cont, 2001). Several univariate models have been proposed to capture this property. The best known are the Autoregressive Conditional Heteroscedasticity model (ARCH) (Engle, 1982) and its extension, the Gen-eralized Autoregressive Conditional Heteroscedastic-ity model (GARCH) (Bollerslev, 1986). This topic has recently received attention in the machine learning community, with the development of copula processes (Wilson &amp; Ghahramani, 2010) and heteroskedastic Gaussian processes (L  X azaro-Gredilla &amp; Titsias, 2011). Multivariate financial returns exhibit similar pat-terns. Moreover, besides time-dependent volatilities, they also display time-dependent correlations (Patton, 2006). Covariances are the product of variances and correlations. Therefore these temporal dependencies are likewise present in covariance matrices. To capture these properties Engle &amp; Kroner (1995) proposed a multivariate extension of GARCH called BEKK, based on synthesized work of Baba, Engle, Kraft, and Kro-ner. An alternative to BEKK are stochastic volatility models, including recent non-parametric models based on generalized Wishart processes (Wilson &amp; Ghahra-mani, 2011; Fox &amp; Dunson, 2011). In practice BEKK performs similarly to the generalized Wishart pro-cesses for modeling financial data. However, BEKK is known to suffer from the following disadvantages: 1. The parameters of BEKK are usually fit by maxi-2. The parameter values in BEKK are constant. 3. Finally, maximum likelihood fit of the parameters To address the difficulties mentioned above, we present a novel dynamic model for describing time-dependent covariance matrices which extends BEKK as follows: Instead of computing point estimates, as in BEKK, we follow a fully Bayesian approach and compute poste-rior probabilities for the parameter values. This re-duces the detrimental effect of multiple maxima in the likelihood function and limits overfitting problems. In addition to this, the new dynamic model incor-porates a diffusion process for parameter values. At each point in time, every parameter is slightly modi-fied by a random perturbation. These perturbations allow the model to adapt its parameters to changes in market conditions. Finally, Bayesian inference is performed using a regularized auxiliary particle filter (Liu &amp; West, 1999). This technique is very efficient in terms of computational cost and allows our method to scale up to high dimensions.
 The performance of the new dynamic model for time-changing covariance matrices is evaluated in a series of experiments with real financial returns. The pro-posed model is compared with the standard BEKK model and a variant of BEKK that assumes multi-variate Student X  X  t innovations. Finally, we compare the proposed model against the generalized Wishart processes. Overall, the new dynamic model for time-varying covariance matrices obtains the best predictive performance.
 The rest of the document is organized as follows: Section 2 describes standard heteroscedastic models such as GARCH and BEKK. Section 3 introduces our novel Bayesian Multivariate Dynamic Covariance model (BMDC). Section 4 reviews current models for dynamic covariances in machine learning. Section 5 describes the particle filter algorithm for making infer-ence in BMDC. Experiments comparing BMDC with BEKK are included in Section 6 and additional experi-ments comparing BMDC with the generalized Wishart process are included in Section 7. Finally, Section 8 contains the conclusions of the study. GARCH is the standard time-series model for univari-ate heteroscedastic data. GARCH assumes Gaussian noise or innovations and produces a sequence of time-varying variances  X  2 t that follow an Autoregressive and Moving Average (ARMA) process with autoregression on p previous variance values and moving average on q previous squared time-series values: The generative model is flexible and can produce a variety of clustering behavior of high and low volatility periods for different settings of the model coefficients,  X  ,..., X  p and  X  1 ,..., X  q . Maximum likelihood is used to learn these coefficients with p and q usually set to 1 to reduce overfitting problems.
 BEKK (Engle &amp; Kroner, 1995) is a popular multivari-ate extension of GARCH, where the dynamic covari-ance matrix for the data follows an ARMA process: x t  X  X  (0 ,  X  t ) , (3) where A i and B j are d  X  d coefficient matrices for d dimensional data and C is a triangular matrix with d ( d + 1) / 2 non-zero entries. Therefore BEKK( p , q ) is a highly parameterized model with a total of ( p + q ) d 2 + d ( d + 1) / 2 parameters.
 Restricted versions of BEKK are used in practice to mitigate overfitting problems. The order parameters p and q are set to 1 and the matrices A 1 and B 1 are constrained to be diagonal. The expression for  X  t is now This diagonal BEKK model (Engle &amp; Kroner, 1995) has only 2 d + d ( d + 1) / 2 parameters. We will use this model as the baseline for comparison because it of-ten has better predictive performance than other ver-sions of BEKK and its computational cost is also lower. Subsequent references to BEKK will mean the diago-nal BEKK model shown in (5).
 Standard BEKK has Gaussian innovations. How-ever, there is strong evidence that financial returns are heavy-tailed. Harvey et al. (1992) and Fiorentini et al. (2003) incorporate heavy-tails in BEKK by modeling x t using a multivariate Student X  X  t distribution with  X  degrees of freedom, zero mean, and scale matrix S t : p ( x t ) = The degrees of freedom,  X  , should be larger than two for x t to have a well defined covariance. Finally, the expression for S t ensures the expected covariance of x t is  X  t . We will refer to the diagonal BEKK model with Student X  X  t innovations as BEKK-T. A major limitation of BEKK is that the parameter ma-trices A , B and C are assumed to be constant. This is unrealistic for financial data, where market funda-mentals are expected to change with time. A heuristic solution is to run BEKK over different windows of his-torical data. The problem is then how to choose the window size, with trade-offs between noisy but reactive estimates of the model parameters for small windows and more stable but constant parameter estimates for large windows.
 As a more principled approach to capture changes in market dynamics, we introduce a novel Bayesian Mul-tivariate Dynamic Covariance model (BMDC) with time-varying parameters. For this, we replace (5) by where C t , B t and A t are time-dependent matrices. Let  X  = { A , B , C } and  X  t = { A t , B t , C t } . Figure 1 shows the corresponding graphical models for BEKK and BMDC.
 In BMDC, the dynamic parameters in  X  t follow a dif-fusion process in which  X  t +1 is obtained by adding a small random perturbation to the parameters in  X  t . Since A t and B t are diagonal, let a t and b t denote d -dimensional vectors with the diagonal elements of these matrices and let c t be the vector with the upper triangular terms of C t . Then we specify the following diffusion process for a t , b t and c t : a t  X  X  ( a t  X  1 , X  2 I ) , (10) b t  X  X  ( b t  X  1 , X  2 I ) , (11) c t  X  X  ( c t  X  1 , X  2 I ) , (12) where the hyper-parameters  X  ,  X  and  X  control the amount of drift in the system. In practice, vague priors are chosen for the value of these hyper-parameter, with mean prior drift set to zero,  X  = 0.  X  was set to 0 . 005 so that A , B and C can move up to 0 . 005 is the number of observations. Other values of  X  were tried with little difference in predictive performance. The prior for the initial state a 0 , b 0 and c 0 is also vague, taking into account the constraint ( | A 0 A | B 0 B 0 | )  X  1 so that  X  t does not diverge, where | X | calculates the determinant of a matrix.
 An important property of BMDC is that its predic-tive distribution is heavy-tailed. This is desirable as financial time series have fat tails (Cont, 2001). The heavy-tails in the predictions of BMDC arise because where the distribution of  X  t |  X  t  X  1 , x t  X  1 is obtained by integrating (9) with respect to the posterior for  X  is an infinite mixture of multivariate Gaussians and it will generally be heavy-tailed. This implies that the predictive density in the BMDC model will also have heavy tails.
 In addition to BMDC, we propose a variant of this model with Student X  X  t innovations, which we denote BMDC-T. In this case, a vague log-normal prior is placed on the parameter  X  corresponding to the num-ber of degrees of freedom of the Student X  X  t innova-tions: The GARCH and BEKK models described in Section 2 constitute the most popular family of volatility mod-els. They are characterized by the latent covariance matrix  X  t being dependent on both its most recent past value  X  t  X  1 and the previous time-series obser-vation x t  X  1 . Another class of models is the family of Stochastic Volatility models (Harvey et al., 1994; Chib et al., 2009; Gouri  X eroux et al., 2009; Philipov &amp; Glick-man, 2006). In this case,  X  t is conditionally indepen-dent of x t  X  1 given its previous value  X  t  X  1 . That is, graphically, in a stochastic volatility model there will be no arrow from node x t to node  X  t +1 in the graphs shown in Figure 1. However,  X  t will still be condition-ally independent of  X  k for k &lt; t  X  1 and k &gt; t + 1 given  X  t +1 and  X  t  X  1 . This latter condition does not hold in recent generalizations of these models based on generalized Wishart processes (GWP) (Fox &amp; Dunson, 2011; Wilson &amp; Ghahramani, 2011). In this case, there are dependencies between all the latent covariance ma-trices and the model can produce complex non-linear patterns in the evolution of covariance matrices. How-ever, it is not clear that such flexibility is necessary for successfully modeling financial data. Our exper-iments show that BMDC outperforms GWP on this task, which confirms that this is not the case. Inference for the proposed Bayesian models is per-formed using particle filters (Doucet et al., 2001). Par-ticle filters seem a natural choice to do online inference for these non-linear and non-Gaussian sequential mod-els. BMDC has Gaussian likelihoods, but is non-linear in the model parameters A t , B t and C t . Further-more, particle filters can easily accommodate models with Student X  X  t innovations, such as BMDC-T.
 We analyzed several particle filtering methods, includ-ing Resample-Move (Gilks &amp; Berzuini, 2001), Regu-larized Sequential Importance Sampling (Musso et al., 2001), Regularized Sequential Importance Resampling (Gordon et al., 1993), and Regularized Auxiliary Par-ticle Filter (RAPF) (Liu &amp; West, 1999) to perform inference in the proposed models. RAPF, a hybrid version of regularized (Musso et al., 2001) and auxil-iary particle filters (Pitt &amp; Shephard, 1999), exhibited the best performance in terms of predictiveness. This agrees with results given by Casarin &amp; Marin (2009). An implementation of the RAPF for BMDC is shown in Algorithm 1. A detailed description of the algorithm is given in the following paragraph.
 Liu &amp; West (1999) introduced the RAPF, which com-bines the Regularized Particle Filter with the Auxil-iary Particle Filter. The Regularized Particle Filter al-lows joint inference of the diffusion hyper-parameters,  X  ,  X  ,  X  , and the hidden states, A t , B t and C t . This method explores the posterior distribution of the model parameters by taking kernelized steps sequen-tially, thereby avoiding particle death. The shrinkage kernel, (17) and (19), avoids over-dispersion problems in standard Regularized Particle Filters and improves prediction accuracy. The shrinkage kernel retains the previous mean, while the posterior variance does not diverge: The Auxiliary Particle Filter part of the algorithm can be viewed as interchanging the importance sam-pling and resampling steps in traditional particle fil-ters such as Sequential Importance Resampling. The resampling, (18), is performed on  X  i t , which are pre-dicted estimates of  X  t given particles from the previ-ous time step. Importance samples are then generated from the resampled point estimates. Particle diver-sity is maintained if the predicted estimates from the previous step are close to the true state. Auxiliary par-ticle filtering is less sensitive to outliers and works well when the predicted estimates are good representations of the unknown states.
 There are two algorithm parameters in Algorithm 1. The number of particles N and the shrinkage param-eter a . We followed Liu &amp; West (1999) and fixed a = 0 . 95. This leads to a little shrinkage and avoids parameter variance exploding. If shrinkage is large ( a = 0) then the particle filter would propose from a less heavy-tailed proposal distribution, with the pa-rameters set to be their empirical means from the pre-vious step. When the empirical means are inaccurate, then the proposed particles will not be representative of the hidden state. The number of particles, N , can affect the accuracy of the predictions, and is investi-gated in Section 6. The computational complexity of the algorithm is O ( Nd 3 ) at each time step, where d is the dimension of the data, since importance sampling at each step requires N likelihood computations, each one with cost O ( d 3 ). We evaluated the performance of BMDC, BEKK and their Student X  X  t variants in several experiments with multivariate financial time series. The high computa-tional cost of BEKK limited the maximum number of different financial assets in each of the analyzed series to five. We considered daily foreign exchange (FX) and daily equity returns, as well as intraday FX returns. The daily FX time series contain a total of 780 returns from January 2008 to January 2011. The daily equity time series contain 3000 returns from Jan 2000 to Dec 2011. The intraday FX time series consist of 5000 five-minute returns, which covered approximately the first six trading months of 2008. The price data were pre-processed to eliminate spurious prices. In particu-lar, we eliminated prices corresponding to times when markets were closed or not liquid. All the time series were standardized to have zero mean and unit stan-dard deviation.
 To illustrate the usefulness of considering time-varying parameter values, we compared the predictive per-formance of BMDC and BMDC-T with BEKK and BEKK-T. In addition, we compared the execution times of i) the RAPF method used by the Bayesian models and ii) the maximum likelihood estimation method used by the BEKK models. Finally, we stud-ied the sensitivity of RAPF to the number of particles used.
 The performance of each method is measured in terms of the predictive log-likelihood on the first return out of the training set. During the experiments, each method receives an initial time-series of length 50. The dif-ferent methods are trained on that data and then a one-step forward prediction is made. The predictive log-likelihood is evaluated on the next observation out of the training set. Then the training set is augmented with the new observation and the training and predic-tion steps are repeated again. The process is repeated sequentially until no further data is received. 6.1. Results for BMDC vs. BEKK Table 1 shows the average predictive log-likelihood for BEKK, BEKK-T, BMDC and BMDC-T on twenty-one daily FX time series sorted by the dimensionality of the data. The method with the best predictive per-formance on each time series is highlighted in bold. Corresponding results are shown in tables 2 and 4 for fifteen intraday FX and thirty daily equity time series respectively. Overall, the best performing method is BMDC-T followed by BEKK-T and BMDC. The worst performing method is BEKK.
 We perform a statistical test to determine whether dif-ferences among BEKK, BEKK-T, BMDC and BMDC-T are significant. These methods are compared to each other using the multiple comparison approach de-scribed by Dem X sar (2006). In this comparison frame-work, all the methods are ranked according to their performance on different tasks. Statistical tests are then applied to determine whether the differences among the average ranks of the methods are signifi-cant. In our case, each of the 66 = 21+15+30 datasets analyzed represents a different task. A Friedman rank sum test rejects the hypothesis that all methods have equivalent performance at  X  = 0 . 05. Pairwise com-parisons between all the methods with a Nemenyi test at a 95% confidence level are summarized in Figure 3. The methods whose average ranks across datasets differ more than a critical distance (segment labeled CD in the figure) show significant differences in perfor-mance at this confidence level. The Nemenyi test con-firms that BMDC-T is superior to all the other meth-ods. Additionally, the dynamic methods are superior to their static counterparts with BMDC outperform-ing BEKK and BMDC-T beating BEKK-T. Finally, BMDC is not statistically different from BEKK-T. The plot in Figure 3 shows that the heavy-tailed mod-els BMDC-T and BEKK-T perform better than the non-heavy-tailed BEKK. Although BMDC assumes a Gaussian likelihood its posterior predictive distribu-tion is heavy-tailed, as discussed in Section 3. Fig-ure 2 confirms this by showing the logarithm of the posterior predictive density produced by BMDC on a particular instance of the analyzed time series. To pro-duce this plot, we evaluated p ( x t |  X  t ,  X  t  X  1 , x t  X  1 grid of values for one dimension of x t , averaging over the available particles which approximate the poste-rior distribution of  X  t and  X  t  X  1 . This is compared to the plot obtained by evaluating p ( x t |  X  t ,  X  t  X  1 , x the posterior mean estimate of  X  t and  X  t  X  1 , which is approximated by the empirical mean computed across all the particles.
 To understand the superior performance of BMDC rel-ative to BEKK, we plot the average predictive log-likelihood of each method against the number of ob-servations in Figure 4. The plot shows typical average predictive log-likelihood for a 3 D Daily FX time se-ries. BMDC-T is clearly the most predictive method for any number of observations. BEKK and BEKK-T underperform BMDC and BMDC-T early on, when relatively few observations are available to fit the mod-els. These two methods are susceptible to overfit-ting at early stages (especially BEKK-T in this case). With more data, BEKK-T is less susceptible to over-fitting and outperforms BEKK. However, BEKK and BEKK-T still perform worse than BMDC and BMDC-T when the amount of training data increases. This confirms that BMDC and BMDC-T are better mod-els for dynamic covariances in financial data, not only because BEKK and BEKK-T suffer from initial over-fitting problems. As a note of financial interest, the average predictive log-likelihood dips after 150 obser-vations. This corresponds to the highly turbulent pe-riod near the end of 2008 with large swings in financial asset prices resulting in lower predictive log-likelihood. A major advantage of BMDC and BMDC-T with the RAPF method for Bayesian inference is scalability. Table 3 shows prediction sensitivity of the regularized particle filter to different number of particles and to-tal execution times in minutes in parentheses for the BMDC-T model on the daily FX dataset with 780 ob-servations, ordered by data dimension. BEKK-T pre-dictions and execution times are also provided for com-parison, except for datasets of ten or higher dimensions where BEKK-T failed to finish in a reasonable amount of time. BEKK-T was implemented using numerical optimization routines provided by Kevin Sheppard 1 . Clearly particle filtering is much faster than the nu-merical optimization of the log-likelihood function used by BEKK. In fact, particle filtering can be used for intraday trading and hedging since each sequential update is on the order of 68  X  60 / 780  X  5 seconds for five dimensional time series with N = 9000 particles. The computational cost of the particle filter is O ( Nd 3 at each step, as described in Section 5. The computa-tional cost for BEKK is O ( Ltd 5 ) at each step, where L denotes the average number of numerical iterations needed per cycle and t is the length of the training data currently seen. The power d 5 in this cost orig-inates because, at each iteration of the optimization process, BEKK has to compute the gradient of O ( d 2 ) parameters, where each gradient computation requires O ( d 3 t ) operations. This cost makes BEKK infeasible for large datasets. In contrast, the cost of the RAPF at each step does not depend on t and only scales as O ( d 3 ). This allows the RAPF to analyze long high-dimensional time series.
 Table 3 also shows the sensitivity of the predictions of BMDC-T to the number of particles N . Increasing N improves performance, but has relatively small effect for low dimensional datasets. For higher dimensions, that is, d  X  10, improvements are more substantial, but do not scale linearly with N . Since run times are linear in N , but improvements in predictive perfor-mance are not, we can choose N such that inference and prediction are done in a desired amount of time for high dimensional datasets. We performed another series of experiments comparing BMDC, BEKK with full parameter matrices (BEKK-Full) and the diagonal version of BEKK with the gen-eralized Wishart process (GWP) proposed by Wilson &amp; Ghahramani (2011). For these experiments, we used the two financial datasets analyzed previously by these authors. The first one corresponds to the daily re-turns of three currencies with respect to the US dollar: the Canadian dollar, the Euro and the British pound. This three-dimensional time series contains 400 obser-vations from 15/7/2008 to 15/2/2010. This datasets Dataset BEKK BEKK-T BMDC BMDC-T A  X  1 . 24  X  1 . 16  X  1 . 19  X  1 . 18 AA  X  1 . 25  X  1 . 23  X  1 . 24  X  1 . 23 AAPL  X  1 . 36  X  1 . 24  X  1 . 23  X  1 . 23 ABC  X  1 . 31  X  1 . 23  X  1 . 26  X  1 . 25 ABT  X  1 . 30  X  1 . 26  X  1 . 28  X  1 . 27 AFL  X  1 . 08  X  0 . 98  X  1 . 01  X  1 . 01 AGN  X  1 . 31  X  1 . 26  X  1 . 28  X  1 . 27 AIG  X  0 . 75  X  0 . 65  X  0 . 68  X  0 . 68 AIV  X  3 . 00  X  0 . 91  X  0 . 92  X  0 . 92 AKAM  X  1 . 27  X  1 . 15  X  1 . 20  X  1 . 20 ACE,ADSK  X  2 . 58  X  2 . 38  X  2 . 44  X  2 . 40 ADBE,AEE  X  2 . 51  X  2 . 31  X  2 . 37  X  2 . 36 ADI,AEP  X  2 . 38  X  2 . 29  X  2 . 31  X  2 . 31 ADM,AES  X  2 . 55  X  2 . 21  X  2 . 28  X  2 . 25 ADP,AET  X  2 . 65  X  2 . 37  X  2 . 44  X  2 . 38 AKS,AMGN  X  2 . 56  X  2 . 44  X  2 . 51  X  2 . 48 ALL,AMT  X  2 . 11  X  1 . 98  X  2 . 01  X  2 . 01 ALTR,AMZN  X  2 . 47  X  2 . 26  X  2 . 36  X  2 . 32 AMAT,AN  X  2 . 37  X  2 . 31  X  2 . 34  X  2 . 32 AMD,ANF  X  2 . 61  X  2 . 45  X  2 . 53  X  2 . 51 ADSK,AFL,AKS  X  5 . 54  X  3 . 98  X  3 . 53  X  3 . 43 AEE,AGN,ALL  X  4 . 50  X  3 . 85  X  3 . 42  X  3 . 34 AEP,AIG,ALTR  X  3 . 57  X  3 . 26  X  2 . 97  X  2 . 94 AES,AIV,AMAT  X  4 . 56  X  3 . 25  X  3 . 06  X  3 . 03 AET,AKAM,AMD  X  3 . 93  X  3 . 82  X  3 . 72  X  3 . 57 AMGN,AON,APOL  X  4 . 06  X  3 . 60  X  3 . 71  X  3 . 43 AMT,APA,ARG  X  6 . 07  X  3 . 49  X  3 . 35  X  3 . 29 AMZN,APC,ATI  X  4 . 51  X  3 . 91  X  3 . 66  X  3 . 60 AN,APD,AVB  X  3 . 42  X  3 . 41  X  3 . 25  X  3 . 22 ANF,APH,AVP  X  6 . 04  X  3 . 70  X  3 . 68  X  3 . 54 is refered to as FX. The second dataset was generated from the daily returns on five equity indexes: NAS-DAQ, FTSE, TSE, NIKKEI, and the Dow Jones Com-posite over the period from 15/2/1990 to 15/2/2010. A sequence of time-varying empirical covariance matri-ces  X   X  t was obtained from the returns of these indexes and then used to produce a return series by sampling from N ( 0 ,  X   X  t ) at each time step for a total of 400 steps. This dataset is refered to as EQUITY. In this case, the time series were not standardized to have zero mean and unit standard deviation to be consis-tent with (Wilson &amp; Ghahramani, 2011).
 We followed the same experimental protocol as in the previous section. During the experiments, each method receives an initial time-series of length 200. We then make predictions one step forward for 200 iterations. In these experiments, the predictions for BMDC were generated in the same way as in (Wil-son &amp; Ghahramani, 2011), that is, instead of aver-mean estimate of  X  t and  X  t  X  1 , which is approximated by the empirical mean computed across all the parti-cles. The predictions for GWP were done similarly, by evaluating a Gaussian likelihood on the posterior mean of  X  t , as approximated by averaging over the samples produced by a Markov chain Monte Carlo method. In this section we do not evaluate the performance of BMDC-T. The reason for this is that GWP assumes a Gaussian likelihood for the data and the Student X  X  t likelihood used by BMDC-T would give an advantage to this method with respect to GWP. 7.1. Results for BMDC vs. GWP Table 5 shows the cumulative predictive log-likelihood obtained by each method on the FX and EQUITY datasets. The method with the best predictive perfor-mance is highlighted in bold. In both datasets, BMDC is the best performer. BEKK-Full underperforms diag-onal BEKK, which was used as a benchmark through-out this paper. This is likely due to worse overfitting problems in BEKK-Full, which is more highly param-eterized. GWP and the different BEKK methods have mixed performance. GWP outperforms BEKK and BEKK-Full on the EQUITY dataset, which was gen-erated from an empirical time-varying estimate of the return covariances. By contrast, BEKK outperforms GWP on the real-world FX dataset. Note the positive predictive log-likelihoods result from keeping the same experimental protocol as the GWP paper, where the return data were not rescaled to have zero mean and unit standard deviation. We have introduced a novel Bayesian Multivariate Dy-namic Covariance model (BMDC) with time-varying parameters that follow a diffusion process. The pro-posed model can adapt its parameters to changing dynamics in financial markets, which results in sig-nificant improvements in prediction performance over standard econometric models such as BEKK and other more recent methods such as the generalized Wishart process. In addition to this, we have presented an in-ference method based on particle filtering that yields substantial savings in computation time, enabling scal-able inference to high-dimensional and high-frequency datasets.
 Acknolewdgements JMHL is supported by Infosys Labs, Infosys Limited. Bollerslev, T. Generalized autoregressive conditional heteroskedasticity. Journal of econometrics , 31(3): 307 X 327, 1986.
 Casarin, R. and Marin, J.M. Online data processing: comparison of Bayesian regularized particle filters. Electronic Journal of Statistics , 3:239 X 258, 2009. Chib, S., Omori, Y., and Asai, M. Multivariate stochastic volatility. Handbook of Financial Time Series , pp. 365 X 400, 2009.
 Cont, R. Empirical properties of asset returns: Styl-ized facts and statistical issues. Quantitative Fi-nance , 1(2):223 X 236, 2001.
 Dem X sar, J. Statistical comparisons of classifiers over multiple data sets. The Journal of Machine Learn-ing Research , 7:1 X 30, 2006.
 Doucet, A., De Freitas, N., and Gordon, N. Sequential
Monte Carlo methods in practice . Springer Verlag, 2001.
 Engle, R.F. Autoregressive conditional heteroscedas-ticity with estimates of the variance of United King-dom inflation. Econometrica: Journal of the Econo-metric Society , pp. 987 X 1007, 1982.
 Engle, R.F. and Kroner, K.F. Multivariate simultane-ous generalized ARCH. Econometric theory , 11(01): 122 X 150, 1995.
 Fiorentini, G., Sentana, E., and Calzolari, G. Max-imum likelihood estimation and inference in mul-tivariate conditionally heteroscedastic dynamic re-gression models with Student t innovations. Journal of Business and Economic Statistics , 21(4):532 X 546, 2003.
 Fox, E. and Dunson, D. Bayesian nonparametric co-variance regression. Arxiv preprint arXiv:1101.2017 , 2011.
 Gilks, W.R. and Berzuini, C. Following a moving target Monte Carlo inference for dynamic Bayesian models. Journal of the Royal Statistical Society:
Series B (Statistical Methodology) , 63(1):127 X 146, 2001.
 Gordon, N.J., Salmond, D.J., and Smith, A.F.M. Novel approach to nonlinear/non-Gaussian
Bayesian state estimation. In Radar and Sig-nal Processing, IEE Proceedings F , volume 140, pp. 107 X 113. IET, 1993.
 Gouri  X eroux, C., Jasiak, J., and Sufana, R. The wishart autoregressive process of multivariate stochastic volatility. Journal of Econometrics , 150(2):167 X 181, 2009.
 Harvey, A., Ruiz, E., and Sentana, E. Unobserved component time series models with ARCH distur-bances. Journal of Econometrics , 52(1-2):129 X 157, 1992.
 Harvey, A., Ruiz, E., and Shephard, N. Multivariate stochastic variance models. The Review of Economic Studies , 61(2):247 X 264, 1994.
 L  X azaro-Gredilla, Miguel and Titsias, Michalis K. Vari-ational heteroscedastic gaussian process regression. In ICML , pp. 841 X 848, 2011.
 Liu, J. and West, M. Combined parameter and state estimation in simulation-based filtering . Institute of
Statistics and Decision Sciences, Duke University, 1999.
 Musso, C., Oudjane, N., and LeGland, F. Improving regularised particle filters, 2001.
 Patton, A. J. Modelling asymmetric exchange rate dependence. International Economic Review , 47(2): 527 X 556, 2006.
 Philipov, A. and Glickman, M.E. Factor multivariate stochastic volatility via wishart processes. Econo-metric Reviews , 25(2-3):311 X 334, 2006.
 Pitt, M.K. and Shephard, N. Filtering via simulation: Auxiliary particle filters. Journal of the American Statistical Association , pp. 590 X 599, 1999.
 Wilson, Andrew and Ghahramani, Zoubin. Copula processes. In Lafferty, J., Williams, C. K. I., Shawe-
Taylor, J., Zemel, R.S., and Culotta, A. (eds.), Ad-vances in Neural Information Processing Systems 23 , pp. 2460 X 2468. 2010.
 Wilson, Andrew and Ghahramani, Zoubin. Gener-alised wishart processes. In UAI-11 , pp. 736 X 744,
