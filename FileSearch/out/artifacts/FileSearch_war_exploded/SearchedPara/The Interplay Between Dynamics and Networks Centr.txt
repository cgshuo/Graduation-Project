 We study the interplay between a dynamic process and the structure of the network on which it is defined. Specifically, we examine the impact of this interaction on the quality-measure of network clusters and node centrality. This en-ables us to effectively identify network communities and im-portant nodes participating in the dynamics. As the first step towards this objective, we introduce an umbrella frame-work for defining and characterizing an ensemble of dynamic processes on a network. This framework generalizes the traditional Laplacian framework to continuous-time biased random walks and also allows us to model some epidemic processes over a network. For each dynamic process in our framework, we can define a function that measures the qual-ity of every subset of nodes as a potential cluster (or commu-nity) with respect to this process on a given network. This subset-quality function generalizes the traditional conduc-tance measure for graph partitioning. We partially justify our choice of the quality function by showing that the clas-sic Cheeger X  X  inequality, which relates the conductance of the best cluster in a network with a spectral quantity of its Laplacian matrix, can be extended from the Laplacian-conductance setting to this more general setting.
Two fundamental problems in network analysis involve identifying central nodes and communities in a network. The goal of centrality identification is to find central or im-portant nodes, for example, those that control the flow of information on the network. The objective of community detection is to discover subsets of well-interacting nodes in a given network. Both of these graph mining approaches have tremendous applications in different areas, such as so-cial network, biological network, World Wide Web analysis. For example, the centrality measure Page Rank [20] is one of the backbones of Google X  X  search algorithm. Similarly, com-munity detection or graph clustering is useful in potential drug-target identification [29].

The first step towards finding potentially meaningful com-munities is to define a quality function that measures the degree to which a subset of network nodes tend to interact among themselves. To this end, measures such as cluster-ing coefficients, subgraph density, and conductance, were introduced to express the quality of a subset as a good clus-ter. Similarly, many measures of centrality including Page Rank and eigenvector centrality are used to discover impor-tant nodes. However, to define a useful quality or centrality function, one needs to determine how the network structure models the interaction among nodes. Unfortunately, this can be quite challenging and is often ignored. Indeed, the aforementioned measures apply different interpretations. As a result, current network analysis methods often make im-plicit assumptions about the dynamic processes (and the re-sultant interaction) among nodes and use these assumptions to define the quality of a cluster or centrality of a node.
Explicitly taking the dynamic process into account, a node X  X  centrality at any time describes its participation in the flow taking place on the network [5, 15]. Similarly, communities are groups of nodes that interact more frequently with each other (according to the rules of the dynamic process) than with nodes from other communities [16]. In fact, this view of modeling is not new. For instance, in choosing conductance as a measure of cluster quality, one may in fact implicitly assume that unbiased random walk is taking place on the network [12, 26, 8, 9]. Under this assumption, a measure of centrality is the heat kernel page rank [6].

Other dynamic processes such as the spread of informa-tion, ideas, or epidemics, induce different interactions from the unbiased random walks. An epidemic [13] is a stochastic process that, unlike a random walk, attempts to transition to (i.e., infect) every neighbor of a node. Epidemic dynam-ics may be specified by the replicator operator [16], whose stationary distribution defines eigenvector centrality [4, 10]. It is natural to think that the centrality of a node depends on the specifics of the dynamic process, which together with the network topology influence its activity level. For exam-ple, nodes that are visited most frequently by a random walk (specified by the heat kernel page rank) are different from nodes that are infected most often during an epidemic (spec-ified by eigenvector centrality). Moreover, epidemics could lead to a different community formation of a network [16].
We study the interplay between a dynamic process and the underlying network on which it unfolds. We focus on the impact of this interaction on the emergence of central nodes and the formation of communities in the network, and on the design of efficient algorithms for their identification.
General framework for dynamic processes: We pre-sent an umbrella framework for describing dynamic pro-cesses on a network that generalizes the traditional Lapla-cian framework for diffusion and random walks. Recall that a random walk on a network is a stochastic dynamic process that transitions from a node to a random neighbor of that node. It defines a Markov chain that can be specified by the normalized Laplacian of the network. Our framework (Sec-tion 2) attempts to capture the class of dynamic processes that evolve in time according to a rule that can be defined by generalizing the normalized Laplacian.

Formal analysis of interaction dynamics: Our frame-work defines a class of dynamic processes with relatively simple characterization parameters, which enables rigorous analysis of the impact of these parameters on the measures of the community quality and node centrality. Its inclu-sion of diffusion and random walks allows us to build on the insights from previous work on mathematical analysis of random walks, conductance measures for clustering, and spectral notions for centrality, in order to derive our gener-alization that reflects the interaction between the dynamic process and its underlying network. We are also able to use it to define new processes whose properties may offer useful insights into community finding and graph partition-ing. Although this particular framework cannot express ev-ery dynamic process of interest, the generalization allows us to model some epidemic processes over a network. Thus, we can use these well-established special cases (such as random walks and epidemics) to clarify the relationship between the parameters of the dynamic processes and their induced com-munity qualities and centralities.

Generalized conductance: We extend conductance to a general quality-measure for clusters that reflects the dy-namic process on the network. For each dynamic process, we use its characterization parameters to define this function. It measures the quality of every subset (of nodes) as a po-tential cluster (community) with respect to this process on the given network. This subset-quality measure generalizes traditional conductance and provides a continuous family of measures for subsets in a graph. Recall that, for each set S  X  V in a weighted graph G = ( V,E ), the conductance of S ,  X  G ( S ), is equal to the ratio of the degree of the connectiv-ities between S to V  X  S to total degree of connectivities of S (or the total degree of connectivities of V  X  S , whichever is smaller). As each subset-quality function measures different degree to which a subset of nodes in a graph tend to cluster together and its coherence as a community, a comparative study of these subset-measures could be useful in the design and evaluation of community detection algorithms.

Generalized Cheeger X  X  inequality: In both theory and practice, a basic problem in community detection is to justify why one quality function is better than another for modeling communities in a network. Unfortunately, this is a highly challenging problem for rigorous reasoning and jus-tification. The interplay of dynamics and network topology further adds to its difficulty. In this paper, we will build on the wisdoms demonstrated in the past decades in spectral graph theory. To partially justify our choice of the qual-ity function, we prove that the classical Cheeger X  X  inequality can be extended to our generalized settings. Recall (also see Section 3) that the Cheeger X  X  inequality relates a spec-tral quantity of the Laplacian matrix of the network to the conductance of the best cluster in the network. Particular, it shows that if  X  is the second smallest eigenvalue of the normalized Laplacian matrix of G and S  X  V is a subset in G with the smallest conductance, then
Centrality, quality and community: We will show that the same relation (as in Eq. 1) holds for the general-ized conductance and the extreme eigenvalue of the linear operator for each dynamic process in our framework. Each function that measures community quality can then be used to decompose the network into potential communities.
In addition, like previous work in random walks, we can also relate the convergence to stationary distribution with the quality measure in each of the dynamics in this frame-work. For example, the time taken by the random walk to reach its stationary distribution is bounded by conduc-tance [11]. The Cheeger inequality provides this connec-tion via the extreme eigenvalue of the normalized Lapla-cian. Similarly, using generalized Cheeger inequalities, we also show that the time it takes for each of the dynamic processes to reach its stationary is bounded by the corre-sponding quality function.
 Efficient spectral and local partitioning algorithms: Like previous studies in Laplacian-based spectral graph the-ory, such as Spielman-Teng [26], Andersen-Chung-Lang [2], and Andersen-Peres [3], our analysis also leads to efficient spectral and local algorithms for identifying provably good clusters based on these new quality functions.

We hope this study will help lead to better approaches for defining and understanding the general interaction between dynamics and networks. Due to lack of space we are unable to provide the proofs of many theorems in this paper, which will be available in the extended version of this paper. We represent a network as a weighted, undirected graph G = ( V,E, A ), where for i,j  X  V , A [ i,j ] = a i,j assigns an (affinity) non-negative weight to each edge. We follow the the weighted adjacency matrix. By convention we assume it is symmetric and a i,i = 0 for all i  X  V . In the discussion below, the (weighted) degree of node i  X  V is defined as the total weight of edges incident on it, that is, d i = P j a
In a dynamic process, each network node i has a dynamic variable  X  i associated with it, which can change its value based on interactions with its neighbors. The values of the variables evolve in time according to the rules of the dynamic process. We consider linear dynamic processes of the kind: where  X  is a column vector containing the  X  entries and L is a symmetric positive semi-definite matrix, the spreading operator , which defines the details of the dynamic process.
As discussed in the introduction, we focus on dynamic pro-cesses on a network that generalize the traditional normal-ized Laplacian for diffusion and random walks. Recall that the symmetric normalized Laplacian matrix of a weighted graph G = ( V,E, A ) is defined as where D is the diagonal matrix defined by ( d 1 ,...,d n ). We study the properties of a dynamic process whose spreading operator can be written as: Here T is the n  X  n diagonal matrix of node delay factors . Its i th diagonal element  X  i represents the average delay of node i . Another generalization from the traditional Lapla-cian is the use of the interaction matrix W instead of the adjacency matrix A . In theory, W can be any n  X  n sym-metric positive-definite matrix; however, here we restrict our attention to scaling transformations of the adjacency matrix A . We also assume that the spreading operator is properly scaled : specifically, we assume that  X  i  X  1, for all i  X  V . Note that the degree matrix D W is now also defined in terms of the interaction matrix, that is d W i = P j w i,j name this spreading operator the generalized Laplacian .
We study how the interplay between dynamics and topol-ogy affects clustering as T and W vary. For a better intu-ition, it helps to consider the random walk Laplacian matrix: This matrix is similar to our symmetric normalized Lapla-cian matrix, with identical spectral properties. As its name indicates, this operator defines a continuous-time unbiased random walk on the interaction graph W , which according to [15] is equivalent to biased random walks on the orig-inal adjacency matrix A . Under this interpretation,  X  the mean delay time of the random walk on node i before a transition, assuming a simple Poisson process. This intu-ition leads to two orthogonal parametrizations of a dynamic process: namely W controls the distribution of walk tra-jectories and T controls the delay time of node transitions along each trajectory. While we use symmetric operators for mathematical convenience in definitions and proofs, it is more intuitive to think from the random walk perspective.
While the generalized Laplacian does not cover all dy-namic processes of interest, this family of spreading opera-tors includes some well-known ones, such as the Laplacian or normalized Laplacian, as well as a continuous family of new operators that are not as well studied. It also contains certain operators for modeling epidemics. The consideration of this family of operators is also partially motivated by our recent experimental work in understanding network central-ity [10, 16]. We conclude this subsection with some special cases that can be described in this framework.
 If the interaction matrix is the original adjacency matrix W = A , and node delay factor is simply the identity matrix T = I , then we recover the normalized symmetric Laplacian :
When W = A , T = d max D  X  1 , the spreading operator corresponds to the (scaled) graph Laplacian This operator is often used to describe heat diffusion -like processes.

Let v be the eigenvector of A associated with its largest eigenvalue  X  max : Av =  X  max v . We can then construct a di-agonal matrix V whose elements are the components of the eigenvector V . Let us scale the adjacency matrix according to W = V AV and use it as the interaction matrix. Setting the node delay factor to identity, the spreading operator is: This operator is known as the replicator matrix R , and it models epidemic diffusion on a graph [16]. It is simply the normalized Laplacian of the interaction graph V AV [24]. Using the random walk intuition, an unbiased random walk on this interaction graph is equivalent to a maximum en-tropy random walk on the original graph given by the adja-cency matrix A [15].

Reweighing each edge by the inverse of square root of the degrees of the endpoints gives the unbiased adjacency matrix W = D  X  1 / 2 AD  X  1 / 2 . Then, the degree of node i in the scaled graph is d W i = P j  X  V W [ i,j ]. Letting T = d W max D  X  1 W gives a unbiased Laplacian matrix :
Similarly, many other operators can be expressed using this framework.
Before considering the impact of spreading operators on communities, we first examine the node centralities of each operator at any time, and their stationary distribution after convergence. The community quality functions that we use are partially inspired by the stationary distribution.
Solution of Equation 2 gives the weight distribution of the dynamic process across nodes at any time based on the ini-tial weight distribution. In the rest of the paper, for conve-nience we will refer to this instantaneous distribution  X  ( t ) as time-dependent centrality . Its stationary distribution is the conventional stationary centrality , or centrality for short. If the dynamic process converges when starting from  X  then lim t  X  X  X   X  ( t ) is proportional to  X  : For example, the stationary distribution of R is v , also known as the eigenvector centrality . Eigenvector centrality was introduced by Bonacich [4] to explain the importance of actors in a social network based on the importance of the actors to which they were connected, and it gives the stationary distribution of a simple epidemic at the epidemic threshold [27, 10].
In network clustering and community detection, one would like to identify subsets of nodes S  X  V that are more simi-lar, or behave more similarly, to each other than to nodes in other subsets. A standard approach to clustering involves defining an objective function that measures the quality of a cluster. For a subset S  X  V , let  X  S = V \ S to denote the complement of S , which consists of nodes that are not weights of all edges used by S to connect with the outside volume of all affinity weights involving vertices in S . One popular heuristic to measure the quality of a subset S as a potential good cluster (or a community) [12, 26, 8] is to use the ratio of these two quantities: For example, a subset that (approximately) minimizes this quantity  X  the conductance of S  X  is a desirable cluster, as it maximizes the fraction of affinities within the subset. If interactions among nodes are proportional to their affinity weights, then a set with small conductance also means that its members interact significantly more with each other than with members not in the subset. Other well-known quality functions are normalized cut [23] and ratio-cut, given by respectively. The smallest achievable such ratio is known as the isoperimetric number .

Algorithmically, once a quality function is selected, one can then perform a partitioning-based algorithm or mathe-matical programming-based method to find a cluster or clus-ters that optimizes the quality function.

For the Normalized Laplacian paradigm (or when the un-derlying process is a random walk), there exists a relation-ship between clustering and dynamics: in a good (i.e., low conductance cut) cluster, a random walk starting within a cluster seldom transitions outside the cluster [17, 23, 22, 26]. Therefore, the presence of a good cluster implies that it will take a random walk a long time to reach its stationary dis-tribution. We generalize this notion with a claim that every dynamic process has an associated function that measures the quality of the cluster with respect to that process. Op-timizing the quality function leads to cohesive communities, i.e., groups of nodes that the dynamic process seldom leaves.
Consider a dynamic process defined by a spreading oper-S  X  V , let vol L ( S ) = P i  X  S d W i  X  i be the generalized vol-ume under our framework. We define the quality of a set S with respect to L as: We also define,
Using the random walk perspective, the numerator mea-sures the random jumps across communities, while the de-nominator ensures a balanced bisection. The generalized volume can be interpreted as the total time a random walk stays within a community after convergence, as it is propor-tional to both node degrees and node delay factors.
Below, we summarize the induced special cases discussed in the previous subsection.

W = A and T = I , and hence h L ( S ) is the conductance.
W = A and T = d max D  X  1 , hence h L ( S ) = cut( S, This is the ratio cut scaled by 1 /d max .

W = V AV and T = I . Recall v is the eigenvector of W associated with the largest eigenvalue  X  max . The redefined Since the degree of a node in an interaction graph is d W i P cator is simply the conductance of the interaction graph [24]. ated quality function is We call this quality function unbiased cohesion .
Cheeger inequality states that where  X  1 is the second largest eigenvalue of the normalized Laplacian, L = I  X  D  X  1 / 2 WD  X  1 / 2 , and  X  G is conductance. The relationship between conductance and spectral proper-ties of the Laplacian enables the use of its eigenvectors for partitioning graphs, particularly the nearest-neighborhood graphs and finite-element meshes [25].

In this section, we generalize Cheeger X  X  inequality to any spreading operator under our framework and its associated generalized conductance (given by Eq. 8). Our generaliza-tion of Cheeger X  X  inequality comes with algorithmic conse-quences. It leads to spectral partitioning algorithms that are efficient in finding low conductance cuts for a given operator. Theorem 1. (Generalized Cheeger Inequality)
Consider the dynamic process described by a (properly scaled) Let  X  0  X   X  1  X  ...  X   X  n  X  1 be the eigenvalues of L . Then  X  0 = 0 and  X  1 satisfies the following inequalities: where  X  L ( G ) is given by Eq. 8.

Proof. We prove the theorem by following the approach for proving the classic Cheeger X  X  inequality (see [8]).
Let (  X  1 ,..., X  n ) be the diagonal entries of T . Note that v 0 = T 1 / 2 D 1 / 2 W  X  1 , where 1 denotes the vector of all 1 X  X , is an eigenvector of L associated with eigenvalue  X  0 Let vol L ( S ) = P i  X  S d i  X  i for S  X  V , where for clarity we abuse the notation d i and use it as d W i . Suppose f is the eigenvector associated with  X  1 . Then, f  X  v 0 . Consider vector g such that g [ u ] = f [ u ] / then implies X  X  L ( G ) = min
Instead of sweeping the vertices of G according to the eigenvector f itself, we sweep the vertices of the graph G according to g by ordering the vertices of G so that and consider sets S i = { v 1 ,  X  X  X  ,v i } for all 1  X  i  X  n .
Similar to [8], we will eventually only consider the first  X  X alf X  of the sets S i during the sweeping: Let r denote the largest integer such that vol L ( S r )  X  vol L ( V ) / 2. Note that where the first equation follows from P v g [ v ] d v  X  v denote the positive and negative part of g  X  g [ v r ] as g g  X  respectively: Now  X   X  min Without loss of generality, we assume the first ratio is at most the second ratio, and will mostly focus on the vertices { v 1 ,....,v r } in the first  X  X alf X  of the graph in the analysis below. Thus, which follows from the Cauchy-Schwartz inequality.

We now separately analyze the numerator and denomina-tor. To bound the denominator, we will use the following property of  X  i : Because L is properly scaled,  X  i  X  1 for all i  X  V . Therefore,
X Hence, the denominator is at most To bound the numerator, we consider subsets of nodes S = { v 1 ,  X  X  X  ,v i } for all 1  X  i  X  r and define S 0 =  X  . First note that By the definition of  X  L ( G ), we know  X  L ( G )  X  min i for all 1  X  i  X  r , where recall the function h S ( L ) is defined have
By orienting vertices according to v 1 ,...,v n , we can ex-press the numerator
Num = X
Combining the bounds for the numerator and the denom-inator, we obtain  X  1  X   X  2 L / 2 as stated in the theorem. The right hand side of the theorem follows from the same argu-ment for the standard Cheeger Inequality. Given a weighted graph G = ( V,E, A ) and a operator L , we can use the standard sweeping method in the proof of Theorem 1 to find a partition ( S,  X  S ). This procedure is described in Algorithm 1.
 Algorithm 1 Spectral Dynamics Clustering ( G, L ) Input : weighted network: G = ( V,E, A ), and spreading operator L defined by the interaction matrix W and the node delay factor T .
 Output partition: ( S,  X  S ) Algorithm
Before stating the quality guarantee of the above algo-rithm, we quickly discuss its implementation and running time. The most expensive step is the computation of the eigenvalue vector f associated with the second smallest eigen-value of L . While one can use standard numerical methods to find an approximation of this eigenvector  X  the analysis would depend on the separation of the second and the third eigenvalue of L . Since L is a diagonally scaled normalized Laplacian matrix, one can use the nearly-linear-time Lapla-cian solvers (e.g., by Spielman-Teng [26] or Koutis-Miller-Peng [14]) to solve linear systems in L .

Following [26], let us consider the following notion of spec-tral approximation of L : Suppose  X  1 ( L ) the second smallest eigenvalue of L . For  X  0,  X  f is an -approximate second eigenvector of L if  X  f  X  D 1 / 2 T 1 / 2  X  1 , and
The following proposition follows directly from the algo-rithm and Theorem 7.2 of [26] (using the solver from [14]).
Proposition 1. For any interaction graph G = ( V,E, W ) and node scaling factor T , and ,p &gt; 0 , with probability at least 1  X  p , one can compute an -approximate second eigen-vector of operator L in time
To use this spectral approximation algorithm (and in fact any numerical approximation to the second eigenvector of L ) in our spectral partitioning algorithm for the dynamics, we will need a strengthened theorem of Theorem 1.

Theorem 2. (Extended Cheeger Inequality with Respect to Rayleigh Quotient)
For any interaction graph G = ( V,E, W ) and node scaling factor T , (whose diagonals are (  X  1 ,..., X  n ) ), for any vector u such that u  X  D 1 / 2 T 1 / 2  X  1 , if we order the vertices of G into ( v 1 ,....,v n ) such that g [ v 1 ]  X  ...  X  g [ v { v 1 ,...,v i } .

The next theorem then follows directly from Proposition 1, Theorem 2 and the definition of -approximate second eigenvector of L that provide a guarantee of the quality of the algorithm of this subsection.

Theorem 3. For any interaction graph G = ( V,E, W ) and node scaling factor T , (whose diagonals are (  X  1 ,..., X  one can compute in time a partition ( S,  X  S ) such that entry of the interaction matrix W , and  X  1 ( L ) is the second smallest eigenvalue of L . Consequently, = 2(1 + )
In the analysis of massive networks, it is essential to iden-tify subsets of nodes whose induced sub-graphs have  X  X ig-nificant X  structural coherence without examining the entire network. Using clustering as an example, Spielman and Teng [26] introduced a framework of local algorithms for net-work analysis: given an input node, a local algorithm can only explore the neighbors of the nodes it has already ac-cessed. It may occasionally access some random nodes in the network. The complexity of the local algorithm is then measured by the total number of accesses it makes, as well as the computations it performs.

In spite of lacking global access, Spielman and Teng showed that local algorithms can be effective in identifying good clusters when conductance is used as quality measure. Their work was subsequently improved by Andersen-Chung-Lang [2], Andersen-Pere [3], and Chung [6, 7]. Chung [6, 7] applied the sweeping method to the heat-kernal page rank to identify a random walk-based local cluster. Similarly, we propose a dynamic-dependent sweeping procedure to discover a local cluster of provably good generalized conductance. Due to length limit, we only state relevant theorems in this paper. For details of proofs, please refer to the full version on arXiv.
For an starting vector  X  , let  X  t,  X  [ i ] denote the value of the dynamics of vertex i  X  V at time t when the initial vector is of Eq. 4 with  X  0 =  X  .

Let  X  = (  X  [1] ,..., X  [ n ]) denote If the dynamic process converges when starting from  X  , then lim t  X  X  X   X  t,  X  is proportional to  X  , i.e., for a constant z de-pending only on  X  , We will also use  X   X  to denote lim t  X  X  X   X  t,  X  .
 In this spirit, we define the fractional volume of a subset S  X  V be fvol L ( S ) = P j  X  S p d W j  X  j . Following the anal-ysis of Theorem 1, let  X  min = min i  X  i ,  X  max = max i  X   X  [ i ] = the traditional Laplacian-conductance framework, we will establish that the existence of a community S  X  V with small h L ( S ) underscores why the dynamics may not con-verge rapidly from the inital distribution.

We examine the evolution of the dynamics defined by a network G = ( V,E, A ) and a spreading operator L . Partic-ularly, we are interested in estimating the rate that the dy-namic process converges to its stationary distribution from some initial distribution, and its relation to the generalized conductance h L that we defined (Eqn. (7)). As each dy-namic process leads to its own notion of (time-dependent) centrality, we will study and compare the corresponding community structures by its generalized conductance.
Our local clustering algorithm (Algorithm 2) explores this interplay. Here we assume the starting vector  X  u is seeded u , and other entries are all zeros. Next theorem provides a performance guarantee for the local algorithm.

Theorem 4 (Local h L -Clustering). For any 0  X   X   X  1 , suppose S is a subset in a interaction graph G = ( V,E, W ) with vol L ( S )  X  1 12  X   X  min  X  h
L ( S )  X   X  2 . Then, there exists a subset S S  X  S with fvol L ( S S )  X  fvol L ( S ) / 4 such that for any u  X  S rithm 2 with s  X  2fvol L ( S ) and =  X  2  X   X  min  X  erties that (1) the conductance of S S is at most O (1 + )  X   X  q log s + log  X  max  X 
Theorem 4 follows from our proofs in the following subsec-tion 3 together with Andersen-Chung-Lang X  X  analysis [2] of the push-based approximation scheme. Similar to its global counterpart in Theorem 3, Theorem 4 uses Theorem 2 in place of Theorem 1 to address the approximation of the dy-namic process. During the approximate dynamic process with the Andersen-Chung-Lang push scheme, only O (1 / ) nodes have non-zero entries.
 Algorithm 2 Local h L -Clustering( G, L ,u, X ,s, ) Input : Network: G = ( V,E, A ), spreading operator L de-fined by the interaction matrix W and the node delay factor T . The starting node: u , quality bound:  X  , targeted frac-tional volume: s , and rounding approximation Output : subset S S Algorithm 1. Set t =  X   X  2  X   X  min  X  log 2. 2. Apply the push-based approximation scheme of 3. Order the vertices of  X  V into { v 1 ,v 2 ,  X  X  X } such that 4. Sweeping: For each S i = S t,u [ i ] = { v 1 ,...,v i 5. Output the S i with the smallest h L ( S i ). a lemma showing that while the quantity  X  t,  X  ( S ) is reduc-ing during every step of the dynamic process, the derivative depends on the generalized volume of S , and is bounded by a factor proportional to the generalized conductance h L ( S ) of S given by Eqn. (7).

Lemma 1. For S  X  V with fvol L ( S )  X  fvol L ( V ) / 2 we
Lemma 1 then provides a lower bound on the fractional volume of a subset S S  X  S from whom the dynamic process does not converge rapidly. Let  X  t,u denote  X  t,  X  u ,  X   X 
Corollary 1. For any subset S  X  V in a interaction graph G = ( V,E, W ) , let
S S = u  X  S :  X  t,u ( S )  X  1
Following the intuition of the proof of the extended Cheeger inequality (Theorem 1) and the traditional Laplacian analy-sis [17, 26, 8, 7], we consider a sweeping process based on the time-dependent centrality with starting vertex u . At time t , the sweeping is performed according to a targeted size s , we define the s -local h L -value denoted by  X  Lemma 2. For any subset S  X  V in a interaction graph G = ( V,E, W ) of fractional volume s = fvol L ( S )  X  fvol we have .
 The following lemma is a consequence of Lemma 2 and Corollary 1, which ultimately leads to Theorem 4.

Lemma 3 (Local h L -Sweeping). For any 0  X   X   X  1 , suppose S is a subset in a interaction graph G = ( V,E, W ) there exists a subset S S  X  S with fvol( S S )  X  fvol( S ) / 4 such that for any u  X  S S , the sweeping by using the vector  X  with t = O (  X   X  2  X   X  min ) will find a set S S with s -local h at most O  X   X  p log s + log(  X  max / X  min ) .
Through experiments we demonstrate the difference in the centralities and communities detected in a graph under dif-ferent dynamic processes. Interestingly, even this simple class of processes can lead to divergent views about who the central nodes are and what are the cohesive clusters for a collection of widely studied real-world networks.
We study how the dynamic processes defined in this paper affect centrality and spectral partitioning. Our framework actually offers more freedom in designing node delay factor T and the interaction graph W and is thus a much more powerful tool. We will study these possibilities in greater detail and use the proposed local clustering algorithm for real-world applications in future work.

Table 1 lists the networks we study empirically, and their properties. We treat all networks as undirected. These net-works come from different domains, and embody a variety of dynamic processes and interactions, from real world friend-ships (Zachary karate club [30]), to social network (Face-book [18]), to electrical power distribution (Power Grid [28]), to intra-text (Word Adjacency [19]) and inter-text (Political Blogs [1]) links.

The House of Representatives network is built from the 98th United States House of Representatives voting data [21]. Unlike the previously studied variants, here we use a special version taking account of all 908 votes. The resulting net-work is dense and has an unusually flat degree distribution. Originally analyzed by Smith et al. [24], this network better differentiates between the dynamics under our framework.
We first study node (stationary) centrality rankings re-sulting from different dynamic processes. By construction, centrality of a node converges to Eq. 5. Given a graph, the degree sequence is fixed, and stationary centrality depends solely on the node delay factor T . A centrality profile is a curve of stationary centrality values for each node given a spreading operator. Figure 1 shows the centrality profiles of network nodes. To improve visualization, nodes are ordered by their centrality according to the normalized Laplacian matrix, and they are rescaled to fall within the same range.
Except for  X  X ouse of Representatives X  and  X  X ower Grid X  networks, the centrality profiles on the other four data sets are very similar. They all have heavy-tailed degree distribu-tions, thus their centralities under the normalized Laplacian Figure 1: Centrality profiles for different networks Comparison of stationary centrality on all six networks. The x-axes represent node indices which has been fixed for all dy-namics on each network in descending order of the  X  X or-malized Laplacian X  centrality. On the y-axes, the convergent centrality has been normalized to the interval [0,1] for all dynamics on all networks.
 Figure 2: Optimal bisections for L (left) and R (right) on Political Blogs
Laplacian has the exact same bisection as Normalized Lapla-cian, while Unbiased Adjacency leads to similar results as Replicator. Notice the correspondence to their sweep pro-files. F igure 3: Sweep profiles for different networks Sweep profiles produced according to Algorithm 1 on all six networks. The x-axes indicate the sweep point, or commu-nity size of one of the bi-sections. On the logarithmic y-axes, the quality function has been normalized to the same range for all dynamics on each network. behave similarly. Replicator centralities follow largely the same trend. There are important differences, however. For example, in the  X  X ouse of Representatives X  network, nodes in the range [1 , 50] considered to be highly central according to the normalized Laplacian are judged not as important by the Replicator. Since centralities and communities are closely related under our framework, this would eventually lead to the differences in community detection, as we show in the next subsection. The centrality scores of nodes in the  X  X ower Grid X  network are all the same except for a few nodes. The lack of information comes from the extreme sparsity of the network.
We use the sweep profile to study differences in network partitioning using different spreading operators for the real world networks listed in Table 1. Given a spreading op-erator, a sweep profile is a curve of quality functions fol-lowing Algorithm 1. Let f be the eigenvector associated with the second smallest eigenvalue of L . The vertices are ordered ( v 1 ,....,v n ) such that g [ v 1 ]  X  ...  X  g [ v g [ u ] = f [ u ] / The y-axis plots The smallest h L ( S i ) gives a provably good cluster S cording to Theorem 3.

Figure 3 shows the sweep profile for each network un-der different dynamics. To improve visualization, we rescale community profiles to lie within the same range. Sweep pro-files provide us an interesting perspective into the differences in the communities identified according to different dynam-ics. With the exception of Zachary X  X  karate club, there are large differences both in the shape of the profile and, more importantly, in the location of its minimum, which corre-sponds to the optimal bisection of the network.

In the  X  X olitical Blogs X  network, both regular and nor-malized versions of Laplacian split a  X  X hisker X  community from the core (Left of Figure 2). However, the Replicator identifies a community of more than 500 nodes (Right of Fig-ure 2). While Replicator is less susceptible to  X  X hiskers X , on the  X  X ower Grid X  and  X  X acebook Egonets X  networks, it only identifies small communities within the  X  X ore X . Instead, un-biased Laplacian succeeds in finding more balanced cuts of the networks. In the  X  X ouse of Representatives X  network, the Replicator puts  X  X wing nodes X  into a different commu-nity from the other operators. Recall that this difference was also reflected in its centrality profiles. In future work, we plan to analyze the reasons behind these differences in more detail and in a dynamic setting.
The dynamics of a process occurring on a network can be succinctly described in terms of a spreading operator. The generalized Laplacian operator presented in this paper can describe the spreading operators associated with known pro-cesses, such as random walks and epidemics, but also new ones, such as the unbiased Laplacian. We generalize the re-lationships between the properties of random walks and nor-malized graph Laplacian, to other dynamic processes. Each operator leads to a distribution that gives centrality of nodes with respect to that process. In addition, we show that the generalized conductance measuring community quality with respect to the dynamic process is related to the eigenvalues of the spreading operator describing that process through a Cheeger-like inequality. These relationships can be used for spectral graph partitioning. Nodes within the same partition interact more with each other via the dynamic process than with nodes in other partitions. As in previous local clus-tering algorithms of Spielman-Teng, Andersen-Chung-Lang and Andersen-Peres [26, 3, 2], the mathematical structure underlying the generalized Cheeger X  X  inequality enables effi-cient local clustering algorithms for the more general com-munity qualities, whose running time is essentially linear in the size of the cluster it outputs, and does not depend on the size of the whole graph.

While our framework is flexible enough to represent sev-eral important types of dynamic processes, it does not rep-resent all possible processes, for example, those that are lo-cally non-conservative. In order to describe such dynamics, an even more general framework is needed. We conjecture, however, that the more general spreading operators will still obey the Cheeger-like inequality, and that other theorems presented in this paper can be extended to these processes. This work is partly supported by grants NSF CIF-1217605, AFOSR-MURI FA9550-10-1-0569, AFRL FA-8750-12-2-0186, DARPA W911NF-12-1-0034, NSF CCF-0964481, and NSF CCF-1111270.
