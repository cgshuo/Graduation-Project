 Users tag objects for different purposes. Regardless of the purpose, tags can save users X  effort in tracking informati on they need. Tags can also help search engines retrieve web pages more precisely and can be used to identify user intents. For example, traditional keyword-based retrieval cannot return web pages about  X  X icrosoft Office X  when a user submits  X  X icrosoft X . Tags will make search engines aware of such potential relations between  X  X ffice X  and  X  X icrosoft X .

Carman et al. [5] find that the terms people use to annotate web sites are similar to the ones they use in the corresponding web search. They show that the vocabulary contains a large amount of overlap and the term frequency dis-tributions are correlated. Usually people use search engine actively. When they submit queries to seek information they need, they often refine the queries to get more precise and accurate results. To some extent, queries have comparable ability with tags in describing a web page. Therefore, if we extract tags for a web page from queries people have posted to view that page, the extracted tags will be of high quality as they are from different queries issued by different users.
The contribution of our work is summarized as follows:  X  We extract tags from the query terms for a web page.  X  We use online encyclopedia to help to extract as much tags as possible.  X  We can rank the tags related to a web page diversely.
 2.1 Tag Generation and Tag Recommendation Basically, the tags are generated from text or from social sites. Zhou et al. [18] propose a probabilistic generative model for generation of document content as well as associated tags. The community influence on tag selection in Flickr has been studied by Marlow et al. [12]. Tags can be recommended based on their quality, co-occurrence, mutual info rmation and object features [7]. Xu et al. [17] propose a set of criteria for tag quality and present a collaborative tag suggestion algorithm with these criteria to recommend high-quality tags. In [15], authors exploit terms extracted from th e object metadata and tag co-occurrence patterns in order to suggest tags for users on Flickr. Liu et al. [11] rank the tags associated with a given image automatically according to their relevance to the image content to select tags for an image. Fabiano et al. [1] exploit not only previously assigned tags, but also terms extracted from other textual features associated with the targe t object to recommend tags. 2.2 Tag Classification We have to classify queries first and try to understand queries related to a page. Jansen et al. [9] develop a software application that can automatically classify queries using a Web search engine log. Shen et al. [14] try to enrich queries using WordNet for web-query classification. In our work, we use Baidu Baike (also known as Baidu Encyclopedia) 1 to help tag generating and query classification. Hu et al. [8] map the query into the Wikipedia representation space to capture its semantic interpretatio n. Bordino et al. [4] project the query-flow graph on a low-dimensional Euclidean space to capture a notion of semantic similarity between queries. In our work, we extract tags from related queries of a web page and finally anno-tate the web page with ranked tags diversely. The framework of our methodology is shown in Fig. 1.

Tag Generating is a basic part of our work and will be discussed in Section 3.1. The task of Tag Generating is to map queries to the corresponding tags.
As shown in the dotted box on the upper left corner in Fig.1, all queries in of Baidu Baike. Briefly, we can exploit the hierarchical structure of Baidu Baike to build a semantic tree [2,10]. With the assistance of this tree, we can classify all entries in Baidu Baike and then classify the queries.

For each web page d ,aquery q is directly related to d if and only if a user u posts the query q and in the results returned by the search engine, u clicks d . The query q is called a DR query of page d . We collect DR queries for a web page first and filter out those ambiguous ones. In order to get semantically related tags for a web page, we will expand DR queries of a web page with Coexistence-based Measurement or Graph-based Mea surement which will be both discussed in Section 3.3. 3.1 Tag Generating In order to map queries to tags, we imitate the language habit of online users. For this purpose, we want to get the frequently-used words of the tagging users. Entries of Baidu Baike can meet our demand. Besides, these entries can be considered as tags. We collect the entries and use an n-gram algorithm to segment each query q into Baidu Baike entries. As an n-gram is both an entry of Baidu Baike and a substring of q, we use formula (1) to compute the appearance probability of this n-gram. C (  X  1  X  2 ... X  n ) is the frequency of a certain n-gram in the query and N is the appearance of distinct queries of the n-gram in Baidu Baike.
 We first select the highest probability of n-gram out as a tag of q ,andthenremove this substring from q and extract new tags for q repeatedly. For example, this is a query q  X  X ho is the writer of A Mid-Summer Night X  X  Dream X . In Baidu Baike, we get entries  X  X  Mid-Summer Night X  X  Dream X  X nd  X  X riter X . So query q will be mapped into tags  X  X  Mid-Summer Night X  X  Dream X  X nd  X  X riter X . Given a query q ,weuse T q to represent the set of probability of each n-gram extracted from query q . p t represents the probability of tag t ,ann-gramof q . The possibility of tag t generated from q could be calculated by formula (2). | X | is the L 1 norm. 3.2 Tag Classification For some kinds of web pages, people often have similar viewpoints. To avoid such topic bias, we will make the tags of a web page come from as more categories as possible.

In our work, we build a tag classifier. We classify all tags into different cat-egories and refer this classification information when we rank tags for a web page, just as shown in Fig.1. In Section 3.1, we see that tag classification can be realized with query classification. A tag t may be generated from several queries which we call source queries of t . Once classification results of t X  X  source queries are abstained, the category that the majority of source queries belong to will be marked as t X  X  category.

We generate training set by Baidu Baike and consider using the k-nearest neighbor algorithm to conduct query classification. Let Q be the set of queries, D be the set of web pages and U be users that own at least one complete query process: post one query and has clicked a web page in the returned results. For information in the search log, we have existing ternary relation S ,and S  X  Q  X  D  X  U . Thus each record ( q , d , u )  X  S means that a user u has posted query q and clicked page d in the returned results. Each query has a distribution of web pages. The vector of web page occurrenc e can be used to represent the query. For the query q k , Here, n q k ,d i means the number of times that all users in U have clicked d i when submit q k .
  X  is the L formula (4), however, not every page in V q k can well reflect the meaning of q k .
Consider the following situation:  X  Spam Page. Spam page contains lots of hot keywords. It may be attached by many queries without any related information.  X  Exception Page. Exception page is such a page that a user has clicked acci-dentally. For instance, a user sends the query  X  X arry Potter and the Deathly
Hallows X  to find the book, but he clicks some pages talking about J. K. Rowl-ing, who is the author. is the number of unique queries in the search log, while | m : n q m ,d i  X  V q m | is the total number of queries that users have posted with page d i clickedinthe corresponding returned results.

To reduce the noise of exception pages, we try to measure how likely page d i can match user  X  s intent. Suppose that a user sends query q k , and then in the will probably send no more queries and click no other pages in the same session. For that reason, we segment each user  X  s query stream into sessions based on the method mentioned in [16]. We name d i and q k as a pair. The matching degree of this pair is inversely proportional to the number of web pages and the number of queries of a session in which this pair has occurred. While this pair can occur in several sessions, in formula (6), D k,session denotes the web page array in a session and Q k,session denotes the query array in a session. Pages and queries that follow the record of q k in a session will be put into the arrays. Finally, the mode values of sizes of different arrays are used to generate md q k ,d i . Thus we get a new array to represent V q k : 3.3 Tag Expanding For a page, we will extract tags from queries users send directly to target the web page which we call directly related queries of the web page, shortened as DR queries. However, many web pages have a very small amount of DR queries. These DR queries can provide limited t ags to describe a web page which force us to find out more information related to the web page.

For each web page, we build a matrix R K  X  N to denote relevance score between the search log. Each element of the matrix will be computed by (8).
 We will present two methods to compute rel ( q i ,r j ), Coexistence-based Measure-ment and Graph-base Measurement. The former focuses on the queries which have clicked same web pages or have occurred in same sessions historically with DR queries, while the latter is an extension of the former.
 Coexistence-Based Measurement. To some extent, queries that have oc-curred in same sessions or have clicked same web pages with web page d X  X  DR queries (d itself excluded) will be more relevant with page d X  X  .Wecallqueries that have occurred in same sessions or have clicked same web pages (d itself ex-cluded) with page d DR queries coexistence queries of d . In Coexistence-based Measurement, for a web page d we only use its coexistence queries to build matrix R
K  X  N . According to the Jaccard coefficient, we can normalize the coexistence of two queries as follows: The coefficient takes the number of times that both q i and r j have occurred, divided by the number of times that the two queries have occurred in total. The Jaccard coefficient is known to be useful to measure the relevance between two objects or sets. There are two kinds of co existence definitions: click same web pages or occur in same sessions. We will discuss both of them in experiments. Graph-Based Measurement. Coexistence-based Measurement discovers lim-ited queries for a page, especially when the log data is sparse. If we draw edges between coexistence queries and DR queries of web page d , we will get Fig.2.
In Fig.2, we see that Coexistence-base d Measurement only considers queries in the first level. If we expand the graph from this level, we will get a DAG, as shown in Fig.2. Although r 21 does not occur with q 01 , it is still probably related to q 01 . An approach to compute the relevance between two queries can be used to compute the maximum information flow between two points. The maximum information flow is influenced by three conditions:  X  while d o ( q i ) is the out-degree of vertex q i  X 
The ratio of | q i  X  r j | to d i ( r j ). d i ( r j ) is the in-degree of vertex r j  X 
The number of nodes on the shortest path between q i and r j , which is denoted Then we have: In Graph-based Measurement, we mark q i  X  r j as the routes between q i and r j and compute the relevance between two queries with formula (10). 3.4 Tag Ranking For a web page d i ,weuse Q d i to denote DR queries of d i . In (11), q k belongs to Q d i ,and N q k denotes the number of DR queries of d i . q represents the query related to page d i which means R [ q k ,q ] is greater than zero. R [ q k ,q ]canbe the probability of tag t with formula (2) mentioned before. The tags are ranked by p ( t | d i ,q ). D k denotes the set of web pages that query q k is directly related to. EA q k ,d i denotes the discrimination and is calculated with (13). On average, if d i has appeared in major sessions that D q k gets involved, q k is supposed to be a con-vincing query of d i . In (14), we change the method for calculating p ( d i | q )aswe think the higher EA q k ,d i is, the more relevant query q to page d i will be. Thus in (12) we can use (13) to calculate p ( d i | r j ): For each web page, we generate tags from queries in Section 3.1 and collect all related tags with the method presented in Section 3.3. Finally, we put all related tags into their categories with category information obtained in Section 3.2. For each category, we will select top three ones. All tags selected will be ranked together by their relevance with the web page. In experiments, we introduce how to gather training set and demonstrate the evaluation method. We show the performance of the two relevance measure-ments mentioned in Section 3 and compare our methods with the language-model based relevance measurements. Ranking effect of EA parameter will also be investigated. Besides applying entries of Baidu Baike to generate tags, we convert Baidu Baike into a semantic tree to help gathering training set and evaluating semantic relevance between a tag and its corresponding web page. In Fig.3, the second-layer nodes represent top categories information, and there are 12 in total. Each entry exists as a leaf node of this tree.
 4.1 Data Set We use a part of Sogou search log. The log contains 3,121,019 queries, 8,459,725 web pages and 6,415,029 sessions. We select 23990 web pages randomly. 4.2 The Training Set To get the training set, we collect relate d entries of each query with the help of Baidu Baike  X  s search engine. Each query is co nnected with some entries which are remarkably similar to it.

After getting related entries of a query, we calculate semantic similarity be-tween each query X  X  similar entries and cat egory nodes of the semantic tree with formula proposed in [13]. The most similar category of these entries will be treated as the query X  X  category. With the help of this training set and the method mentioned in Section 3, we get tags for each category. A sample of tags in some categories is shown in Table 1.
 4.3 Case Study We select web pages and illustrate their tags obtained by the two measurements. In Table 2, Cosession and Coclick are two types of coexistence relevance mea-surement. The web page in Table 2 describes a type of car of Brilliance. In Table 2, Cosession method provides tags about Nimble as users always maintain Nim-ble and Brilliance in a search task of a session. It is obvious that graph based method has supplied more related tags and give us more understanding of related concepts in the web page.
 4.4 Comparison and Ranking Evaluation We use Baidu Baike semantic tree to validate the relevance between a tag and its corresponding web page. A similarity proposed in [13] is employed. For each tag, we make the average score it receive s from the current page X  X  words as its final similarity score to the page. Specifically, we use semantic similarity scores as golden standards. To avoid noisy words in the web page, we only employ the words whose similarity scores to t ags have exceeded a threshold, which is empirically set as 0.5. As the value range of the similarity formula is between 0 and 1 (larger value means more relevant), we mark a tag as a relevant tag if its similarity score to the web page exceeds 0.8.

Tags can also be extracted from web page s content, hence, we extract keywords from a web page [6] to generate its tags. We use Latent Dirichlet Allocation (abbreviated as LDA) [3] model to generate tags for web pages. In Table 3, we will see the difference between these methods. DR method means we generate tags only from those directly related queries.

Graph-based method gets higher precision than other methods when n is smaller than 5. LDA method also gains satisfactory results, while both keyword-based method and Cosession-based method have poor performance. The reason is, content-based method relies too much on the quality of the web page contents.
In tag ranking part, we have discussed EA parameter which is calculated based on the session relation between queries and web pages. As shown in Table 4, we see that EA definitely promotes the ranking result of different measures. 4.5 Manual Evaluation To do manual evaluation, five volunteers rate each tag at five levels: 1(Poor), 2(Bad), 3(Acceptable), 4(Good), and 5(Excellent), based on their understanding of the web page. We randomly select 100 web pages. Each page has three groups of tags and every group has at most 5 tags. For every tags of each page, we make the average score as the final score. To measure precision, we mark a tag as a relevant one when its final score exceeds 4 . The results of manual evaluation are demonstrated in Table 5.

Precision results of manual evaluation and semantic tree evaluation are ba-sically consistent. NDCG results become higher when we only keep 5 tags for each page. We emphasize the category of tags, however, for a given web page, there are many improper categories which should not be used to generate tags. To reduce the sacrifice of relevance, most of the web pages only involve 2 or 3 categories. In this paper, we propose a new prospective of mining search logs for tags. We present two approaches to dig out tags related to a web page and rank them properly. In order to keep diversity, we classify web queries into different categories and then extract tags from queries to depict each category. As a future work, we will exploit the extracted tags to improve query recommendation and web search.

