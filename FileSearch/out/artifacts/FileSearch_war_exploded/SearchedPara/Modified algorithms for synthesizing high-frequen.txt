 Thirunavukkarasu Ramkumar  X  Rengaramanujam Srinivasan Abstract Because of the rapid growth in information and communication technologies, a company X  X  data may be spread over several continents. For an effective decision-making process, knowledge workers need data, which may be geographically spread in different locations. In such circumstances, multi-database mining plays a major role in the process of extracting knowledge from different data sources. In this paper, we have proposed a new methodology for synthesizing high-frequency rules from different data sources, where data source weight has been calculated on the basis of their transaction population. We have also proposed a new method for calculating global confidence. Our goal in synthesizing local patterns to obtain global patterns is that, the support and confidence of synthesized patterns done. Experiments conducted clearly establish that the proposed method of synthesizing high-frequency rules fairly meets the stipulation.
 Keywords Multi-databases  X  Data mining  X  Transaction population  X  Rule selection  X  Rule synthesis 1 Introduction Database mining has emerged as a major application area for an efficient discovery of the previously unknown and potentially useful patterns in large databases. Much of the data Local DBs Relevant Database P attern Set Data Wareho u se mining techniques developed in early 90s focused on the centralized database or data warehouse information. Rapid strides made in the communication network technology and distributed database systems have led to the development of several multi-database systems for industrial applications. A multi-database environment consists of a group of databases or datasets distributed in a wide area network. For effective decision-making, global orga-nizations are required to mine the multiple databases that are distributed through out their branches, which may be physically located even in different continents. Multi-database min-ing can be defined as the process of mining data from multiple databases, which may be heterogeneous, and finding novel and useful patterns of significance . Interesting research papers on multi-database mining have been presented by Xindong Wu, Chengqi Zhang, Shichao Zhang and others [ 7  X  15 ]. Turinsky and Grossman in their work [ 8 ] discuss two types of strategies while mining multiple databases. Since the task of moving large data sets over the Internet may be a time-consuming and costly proposition, the first strategy is to leave the data in place, building local models and combining the models at a central site. They call this scheme an in-place strategy. On the other extreme, when the amount of geographically single model there. They call this a centralized strategy. Then they describe an intermediate strategy of optimal data and model partitions (OPTDMP) to achieve a given level of accuracy at a minimum cost. Zhang et al. [ 13 ] have, deprecated moving data to a central location and then mined which they call mono-database mining (Fig. 1 ), because apart from the cost of moving huge data over a communication network, the strategy will effectively obliterate the local patterns at each site. They argue that any business organization, with multiple branches, has two levels of decisions: head quarter level (global) and branch level (local) decisions. Following this logic, they classify the patterns in a multi-database system as local patterns, high vote patterns, exceptional patterns and suggested patterns.

Wu et al. [ 10 ] discuss the classification of databases, which is a prerequirement for multi-database mining. If a large organization has different types of business with different metadata structures, the databases within the company will have to be classified before data-mining with food items, some may-deal with foot-wear, some others may deal with textile items and so on. Liu et al. in their paper [ 7 ] have attacked the problem of identifying databases relevant to a particular data-mining task in multiple databases. They argue that the first step in multi-database mining is to identify databases that are the most likely to be relevant to an application; without doing so the mining process will be unnecessarily lengthy, directionless and ineffective. They have proposed a measure of relevance and have given an algorithm for identifying relevant databases. Zhang et al. [ 11 ] describe the process of multi-database mining and patterns that exist in multi-databases. They have developed a model for identifying exceptional patterns from multiple databases, which could be considered as a postprocessing work after mining multiple, relevant databases. Blanchard et al. [ 4 ] have proposed a rule-focusing methodology for the visual post processing of association rules. It allows the user to on rule interestingness measures, on a visual representation and on interactive navigation among the rules.

Zhong et al. [ 15 ] have proposed a way of mining peculiarity patterns from multiple statis-tical and transaction databases. Wu and Zhang [ 9 ] in their paper have described the process of synthesizing high-frequency rules from different data sources based on the data source weights. An important assumption in the development of their method is that databases should be of equal size. If data sources are of different sizes, then data preprocessing has to be done to make them roughly of the same size. We propose a new methodology for synthesizing high-frequency rules, where rule weight is proportional to the sum of the weights of the data sources supporting the rule. The weight of any data source is calculated based on the population of data source X  X .e., by the number of transactions in the database. The proposed method is equally applicable to databases of varying sizes. Our goal in synthesizing local patterns to obtain global patterns is that, the support and confidence of synthesized patterns must be very nearly same if all the data sites were integrated and mono-mining has been made . We clearly establish that the Wu X  X hang method of synthesizing high-frequency rules does not meet this criterion, while our method fairly meets the stipulation. Also, we dispute their method of calculating global confidence and have proposed an alternative method. 2 Problem definition and method justification The synthesizing problem can be formulated as follows:  X  X here are n sites: S 1 , S 2 ,..., S n . to get a global set of synthesized rules, which are potentially useful for an organization in the decision-making process. It is assumed that transaction population of individual sites are known. It is further assumed data preprocessing has been already made, and data sources in all the sites are highly relevant. For evaluating the synthesized results, mono-mining results are kept as the target X  .
 Before we could consider the proposed method, let us consider the logic put forth by Wu X  X hang for their method. A local pattern is a pattern that has been identified in the local database of a branch. A pattern can be a frequent item set or an association rule. Wu X  X hang have assumed that, within a company, each branch, large or small, has equal power to vote for global decision-making. They have elucidated their strategy by using a competing model in sports. For a three-set tennis match, if a player wins two out of three sets he is declared the winner. For example if player A wins first set by 7 X 6 and the third set by 7 X 6 and player B wins second set 6 X 0, player A will be declared winner, since he has won two sets, though player B has won larger number of 18 games, as compared to the 14 games won by A. Each set result can be considered a vote by a particular site and the player who receives larger number of votes wins.

We do not agree with the formulation that, in a big company, each branch, big or small, has equal power to vote for patterns. In a pure business sense, all branches, are not equal; the branches, which have high volume of business, will have and should have a greater say in determining global policies based on global patterns. Here, we make a fair assumption that large number of transactions implies high volume of business. Hence, it is reasoned that rule weights are to be based on  X  X ffective X  vote from various sites. In other words, if there are two sites S1 and S2 and if S2 has twice the number of transactions of S1, then effective vote for S2 will be two as compared to one of S1. This approach is in tune with the practice followed in the real world applications. For example, consider the case of two presidential candidates A and B who have won a state each in US Presidential election. This information is not as significant as the information that candidate A has won California and B has won Wyoming, which, respectively, carry 55 and 3 Electoral College votes.
 There is also another argument for proposing transaction population-based site weights. Our goal in synthesizing local patterns is that we should be able to get very nearly same results as those that would be obtained by mono-mining. We go in for local pattern analysis for various reasons: (i) mono-mining could not be done as huge volumes of data are distributed at various sites and moving data to a centralized location is quite expensive; (ii) some times national laws prevent data movement; (iii) with the local pattern analysis, the peculiarities of the local sites are captured, which would have been swiped out under mono-mining technique. However, if we could get the same results as mono-mining with a synthesis, then we could get double benefits. Presently, we show that, to ensure mono-mining results with a synthesis, site weights are necessarily to be based on transaction populations.

Let us demonstrate the above proposition with an example in probability. If we imagine bag, which has four red balls and four balls of other colors. The probability of picking a red ball will be 4 / 8 = 0 . 5 . Suppose the balls in the two bags are put in a single bag, the probability of picking a red ball is ( 3 + 4 )/( 10 + 8 ) = 7 / 18 = 0 . 389 and not the average value of ( 0 . 3 + 0 . 5 )/ 2 = 0 . 4 . The formula can be put as
P probability example to multi-database mining situation. Sites correspond to bags, central store corresponds to mixed bag (mono-mining) and tuples correspond to balls. Then, the formula will be
If the expression given for P mixed bag (red) corresponds to synthesis of global support from two sites, then P = If we designate,
Thus, our method of synthesis of global support, based on transaction population, is deduced directly from the probability example. The support for a rule X  X  Y is the percentage of transactions that contain X  X  Y (i.e. both X and Y). This is taken to be the probability, P (
XUY ) . Confidence for a rule X  X  Y is defined as the ratio = support for ( X  X  Y ) /support for (X). It is nothing but the conditional probability P ( Y | X) which is the probability of Y occurrence, given the information that X has occurred. Clearly, confidence is an algebraic ratio between two support values, and to synthesize global confidence, we have to evaluate each support value separately and then calculate the ratio.

The main problem of association rule mining is that the number of possible rules to search the rule in the form of antecedent  X  consequent; local support of a rule R ij can be defined as the confidence of a rule R i in site S j . The global support of a rule R i can be defined as the support obtained for a rule R i from all the sites put together. Similarly, the global confidence of a rule R i can be defined as the confidence obtained for the rule R i from all the sites. In our proposed algorithm, we evaluate global support of antecedent for rule R i separately to find global confidence. Global support of antecedent for rule R i can be defined as the support of antecedent of R i in all the sites put together. Unnormalized site weight is a number proportional to the transaction population of a participating site in the rule synthesis. Normalized weight of a site is the ratio between transaction population in respective data source and total transaction population of all participating sites. 3 Synthesizing high frequency rules on the basis of transaction population Wu X  X hang have advocated a weighting model for synthesizing high-frequency association rules from different data sources. According to them, a rule is called a high-frequency rule if it is supported or voted by a large number of data sources and the rule weight is proportional to the number of data sources supporting the rule. The weight of any data source in turn is calculated based on the of number of high-frequency rules supported by it. Hence, if a data source supports/votes large number of high-frequency rules, its weight would also be higher. They have obtained the global support and confidence values directly by synthesizing local support and confidence values.

Our proposed method for synthesizing high-frequency rules from different data sources comprises the following steps: (1) calculating the weights of rules based on the transaction population of respective data sources where the rules are present; (2) obtaining the weights of data sources based only on the transaction population; (3) calculating the global support by using the weights of data sources and the local support values (4) calculating the global confidence by a different methodology and (5) ranking the rules whose support and confidence values satisfy minsupp, minconf limits. 3.1 Calculation of rule weights Wu X  X hang have calculated the weight of any rule based upon the vote received from each site for a particular rule. Our method of calculating rule weight is almost similar, except that each site will be casting vote for the presence of a rule proportional to its population. Let us call this vote as effective vote rate and designate the vote rate used by Wu X  X hang as nominal vote rate.
 Example 1 A company having four branches at metropolises and 16 branches located at urban areas is considered. Let the volume of transactions in the metropolitan branches be ten times the volume of transactions in the urban branches. Suppose the metropolitan branches support rule R1, while the urban branches support rule R2. By Wu X  X hang method
If minimum nominal vote rate min.  X  nominal = 0 . 30, R2 will be selected and R1 will be discarded.
 By the proposed method
If minimum effective vote rate min.  X  effective = 0 . 50, then R1 will be selected and R2 will be rejected.

Clearly, Wu X  X hang method cannot be applied to the present case, since the data sources are not of same size. However,  X  nominal has a definite role to play. We recommend representing any global pattern by a quintuple (pattern, nominal vote, effective vote, global support, global confidence), where nominal vote is the vote received by a rule on an equi-vote basis from sites, effective vote rate is the weighted vote taking population into account, global support and global confidence are synthesized support and confidence values.

Focusing our attention only to min.  X  nominal and min.  X  effective thresholds, there are four limit X  X elect the rule as a global rule; this corresponds to rule R1 supported by metropolises to rule R2 supported by the sites located at urban areas. Clearly, we cannot designate the supported by a large number of sites. The solution is to designate the rule as a sub-global rule applicable to a sub-class. The sub-class can be based upon region X  X ay West, East, North, etc., or can be based upon type X  X etropolis, suburb, or any other characteristics. The min.  X  nominal threshold can be selected on the basis of minimum number of sites required to which has several interesting features. But we do not discuss multi-level synthesis further as its scope is outside the scope of this paper. 3.2 Calculation of site weights For the Example 1 , let us consider the calculation of site weights.
 By Wu X  X hang method Weight of rule R1 = W | R1 = 4 Weight of rule R2 = W | R2 = 16 Normalized weight of rule R1 = W R1 = 4 / 20 = 0 . 20 Normalized weight of rule R2 = W R2 = 16 / 20 = 0 . 80 Weight of metropolitan sites = w | s1 ... w | s4 = 4  X  0 . 20 = 0 . 80 Weight of urban sites = w | s5 ... w | s20 = 16  X  0 . 80 = 12 . 80
Normalized weight: metropolitan sites = w s1 ... w s4 By the proposed method Weight of each metropolitan site = w | s1  X  X  X  w | s4 = 10 Weight of each urban site = w | s5  X  X  X  w | s20 = 1 Normalized weight: urban sites = w s5  X  X  X  w s20 = 1 / [ ( 4  X  10 ) + ( 1  X  16 ) ]= 0 . 017857 In the following sections, we illustrate the calculation of global support and confidence values by the two methods. 3.3 Calculation of global support by Wu X  X hang method Let us consider two examples. The first example considers two sites with equal population; the number of transactions, from which the rules have been mined, is approximately the same at the sites. The second example considers the case of widely differing populations. Firstly we will work out the rule weights, site weights and global support for synthesized rules by using the Wu X  X hang method and show that the synthesized global support does not tally with mono-mining value. Then we describe our method.
 Example 2 ( Equal Population ) Let there be two sites. Site S1 supports nine rules: R1 ... R9 (rule R1 has a support of 0.20 and rules R2 ... R9 have a support of 0.30). Site S2 supports single rule R1 with a support of 0.40.
 Total number of rules = 9 Weight of rule R1 = W | R1 = 2 Weight of rules R2 ... R9 = W | R2 ... W | R9 = 1 Normalized weight of rule R1 = W R1 = 2 / 10 = 0 . 20 Normalized weight of rules R2 ... R9 = W R2 ... R9 = 1 / 10 = 0 . 10 Weight of site S1 = w | s1 = ( 2  X  0 . 20 + 8  X  0 . 10 ) = 1 . 20 Weight of site S2 = w | s2 = 2  X  0 . 20 = 0 . 40 Normalized weight of site S1 = w s1 = 1 . 20 / 1 . 60 = 0 . 75 Normalized weight of site S2 = w s2 = 0 . 40 / 1 . 60 = 0 . 25
They have thus attempted to give weights for rules based up on the frequency of occur-rences at various sites and weights for sites based upon large number of high weighted rules. In fact, the weights of sites can be determined directly as follows:
These, when normalized, yields the same result. Thus, the site weights can be calculated directly based on square of rule occurrences. Increasing the weights this way enables us to attach a larger importance to sites supporting several high frequency rules and eliminate weaker sites from our consideration. To check the synthesized global support values, let us calculate the actual global support, if the two sites are merged together and mono-mining has been done. Let there be 1,000 records in each site, and rule R1 is supported by 1,000  X  0 . 20 = 200 transactions at site 1 and 1,000  X  0 . 40 = 400 transactions at site 2. Effective global support for rules R2...R9 will be 300/(1,000 + 1,000) = 0.15. It is seen that the synthesized values using Wu X  X hang Method do not tally with mono-mining results.
 Example 3 ( Differing Populations ) Suppose, in the Example 1 , the four metropolitan branches support rule R1, each with a support of 0.30, and the 16 branches at urban ar-eas support R2, each with a support of 0.30.
 Since the databases are of widely differing sizes, Wu X  X hang method is not applicable. Let us calculate the mono-mining values. Let the 16 urban sites have 1,000 transactions each, then four metropolitan sites will have 10,000 transactions each. Support for R1 at each metropolitan center is equal to 10,000  X  0.30 = 3,000 records and for R2 at urban centers is equal to 1,000  X  0.30 = 300 records. Therefore,
Let us rework the above two examples by using the proposed method. 3.4 Calculation of global support by the proposed method We present the working as per the proposed method for synthesizing global support for the two examples.
 Example 2 ( Equal Population ) Weight of site S1 = w | s1 = 1 Weight of site S2 = w | s2 = 1 Normalized weight of S1 = w s1 = 1 / 2 = 0 . 50 Normalized weight of S2 = w s2 = 1 / 2 = 0 . 50 Weight of rule R1 = W | R1 = ( 1  X  0 . 50 ) + ( 1  X  0 . 50 ) = 1 Weight of R2 ... R9 = W | R2 ... W | R9 = 1  X  0 . 50 = 0 . 50 Normalized weight of R1 = W R1 = 1 / [ 1 + ( 0 . 50  X  8 ) ]= 0 . 20 Normalized weight of R2 ... R 9 = W R2 ... R9 = 0 . 50 / [ 1 + ( 0 . 50  X  8 ) ]= 0 . 10 Global support for rule R1 = Supp G ( R1 ) = ( 0 . 50  X  0 . 20 ) + ( 0 . 50  X  0 . 4 ) = 0 . 30 We find out that in both the cases the global support values tally with mono-mining values. The normalized weights of rules are not used for calculation of global support. They are used only for rule selection. Rule selection algorithm is given in Appendix, while a full example is discussed in the Sect. 3.8 .
 Example 3 ( Differing Populations ) In all, there are 20 sites: four metropolitan sites, each with a population-weight of 10, and 16 urban sites, each with a population-weight of 1.
We find that the results tally. Thus, it has been shown that the proposed method yields calculation of global confidence values. 3.5 Calculation of global confidence by Wu X  X hang method Example 4 To focus only on calculation of global confidence, in the fourth example, we choose two sites with equal population and supporting the same set of three rules, but with different support and confidence levels (Table 1 ).
 Let us now calculate global confidence by Wu X  X hang Method.

For calculating mono-mining values for global confidences for these rules, let us assume 1 and since confidence = 0 . 80 , 200 / 0 . 8 = 250 transactions support  X  X  X . Therefore global confidence = ( 400 + 200 )/( 1 , 000 + 250 ) = 0 . 48 . Similarly, the actual values of global confidence can be calculated as 0.6533 and 0.6750 for rules R2 and R3. We find that actual global confidence values and the ones calculated by Wu X  X hang method do not tally. 3.6 Calculation of global confidence by the proposed method Let us now give the expression for calculating the global confidence of any rule R (antecedent  X  consequent) [ 1 , 2 ].

Since the confidence is obtained as a ratio between two algebraic quantities, it is neces-sary to calculate supp G (antecedent  X  consequent) and Supp G (antecedent) separately . Supp G (antecedent  X  consequent) is the global support for the rule and this has been already eval-uated. Therefore, we need to evaluate Supp G (antecedent) only. Let us attempt to calculate these for rules R1, R2 and R3.
 For Rule A  X  B For Rule C  X  D For Rule D  X  E
The results obtained by our method are exact values, obtainable if the two databases were to be merged together and mono-mining had been adopted. We have deliberately chosen the simple case of equipopulations sites with identical set of rules so that focus is not lost towards variations caused by other factors. Global confidence for any rule is to be synthesized by evaluating the Supp G (antecedent  X  consequent) and Supp G (antecedent) separately. In this, some problems are likely to arise. Some sites may not support a particular rule. If a rule R is not found in a site S j , it simply means that the support for the rule at the site is below minimum threshold and it can be approximated to zero. The difficulty lies in calculating Supp (antecedent) at the sites. We are proposing three ways for the calculation of support for antecedent: 0 (1) support of antecedent may be evaluated if there is any other rule at the site involving the same antecedent or (2) for mining large K item set, if data is available for (
K  X  1 ) item set, information can be collected from that; (3) calculate the average of support for antecedent (R) in other sites to obtain global antecedent values. The algorithm is given in the Appendix and this type of scenario is discussed in the following section. 3.7 Equal population and non-uniform distribution of rules in sites Example 5 There are three sites; all the sites are having equal population and rules are not distributed evenly (sites does not having identical set of rules). They are tabulated along with their support and confidence (Table 2 ). The data exactly corresponds to the data in Ref. [ 9 ]. Since all the sites are having equal population, the site weights will be 1 / 3 = 0 . 3333. For Rule A  X  B  X  C Supp G ( A  X  B  X  C ) = ( 0 . 3333  X  0 . 40 ) + ( 0 . 3333  X  0 . 50 ) = 0 . 2999 Conf G ( A  X  B  X  C ) = 0 . 2999 / 0 . 5825 = 0 . 5148 For Rule A  X  D For Rule B  X  E For Rule B  X  C
The global support and confidence values for synthesized rules are given in Table 3 .The results from the Wu X  X hang Method are also given for comparison.
Let us apply the proposed method to sites having different populations. Full example is discussed in the following section. 3.8 Rule synthesization by the proposed method: full example Example 6 There are three sites and four rules (populations and rules are different in all the three sites). Rules are tabulated along with their support and confidence in the respective rule synthesizing.
 Step(1) Rule selection: Unnormalized rule weights are calculated as follows:
The normalized rule weights of R1, R2, R3 and R4 are 0.3636, 0.2727, 0.1818 and 0.1818, R3 and R4 are eliminated. It can be noted that R3, supported by two sites, is also eliminated, since the site population is only half of site S2. Now, the selected rules are S  X  X  R1 , R2 } . Step (2) Rule synthesizing: The global support and global confidences of selected rules can be calculated as follows: For Rule R1 Supp G ( R 1 ) = ( 0 . 25  X  0 . 2 ) + ( 0 . 5  X  0 . 3 ) + ( 0 . 25  X  0 . 3 ) = 0 . 2750
Conf G ( R 1 ) = 0 . 2750 / 0 . 5625 = 0 . 4888 For Rule R2
The results of the synthesis are given in Table 5 . 4 Experiments We have evaluated the effectiveness of our synthesizing approach by conducting various experiments. The results of three of our studies are discussed further. 4.1 Study 1 We have synthesized an artificial database of 10,000 records, with 20 items A to O having average number of items per transaction = 4.02. The database is divided into four data-bases with equisized partitions of 2,500 records each. The distribution of data items X  X atterns in the four databases is uniform. For example, for patterns A, B and C the distributions at the four sites are as follow A : (1,300,1,200,1,300,1,200); B: (1,000,1,000,1,000,1,000); C : (700,600,500,600). Mono-mining of the original database and local mining for the four databases are done using standard Apriori algorithm. The local patterns, which have a sup-port  X  0.20, are synthesized into global patterns using the proposed method as well as the Wu X  X hang method. Comparison of synthesized global support and confidence values are giveninTables 6 and 7 , while Table 8 presents a comparison of error measures. 4.2 Study 2 For the second study, a database having 10,000 records, with 20 items A to O is considered. The database is partitioned into four databases with uniform population of 2,500 records each. However, the pattern distribution is not uniform for many of the data items. For example, the distribution of patterns A, B and C among various sites is as follows; A : (0,2,500,0,2,500); B : (1,250,1,667,0,1,667); C : (2,500,1,000,0,500). A comparison of synthesized support val-ues by the two methods is available in Table 9 while Table 10 presents comparison of syn-thesized confidence values. Table 11 provides a comparison of error measures. 4.3 Study 3 For the third study, the initial database is the same as for Study 1 with 10,000 records. The database was partitioned into four groups with populations of 4,000, 3,000, 2,000 and 1,000 records. Comparision of synthesized support and confidence values are given in Tables 12 and 13 and error measures are given in Table 14 . 5 Analysis of results be drawn. 5.1 Synthesized global support values From a comparison of Mean | Error | and RMS error measures presented in Tables 8 , 11 and 14 , it can be found that, for Study 1 Wu X  X hang method proves to be marginally superior, while for Study 2 the proposed method scores better and for Study 3 only the proposed method is applicable. A look at tables will bring out the fact that our method has large number of zero error entries. For example, in Table 6 , zero error entries for our method is 6, whereas for the Wu X  X hang method the value is 1. On inspection, it is found that the local supports at various sites are 0.40, 0.40, 0.40 and 0.40 for pattern  X  X  X . Since this is a special case where local be the site weights. On the other hand, the proposed method always yields correct results matching with mono-mining for patterns having support at all sites; correct results will also be obtained for sites that do not support a pattern where the actual support at those sites  X  0. We wanted to improve further the synthesized results and bring them to a closer proximity with mono-mining results. From Table 6 (referring to columns without corrections), we find that for pattern  X  X  X  mono-mining support = 0.35, while the value synthesized by our method is 0.31. The individual support values for this pattern at the four sites are (0.52, 0.36, 0.16, 0.36). Since at site 3 the support = 0.16, the pattern is rejected by that site and synthesized by our method. For Wu X  X hang method, site weights are 0.2469, 0.2775, 0.2378 and 0.2378. ( 0  X  0 . 2378 ) + ( 0 . 36  X  0 . 2378 ) ] .

The problem arises because for a pattern which is not supported at a site it is assumed that support = 0, whereas the actual support is a value between 0 and min-support value at that site. Hence, the synthesized support values are marginally lower in cases where patterns are not supported by all sites. This can be handled in two ways; The first approach is to accept the results as they are with the knowledge that the results obtained are conservative and actual supports may be higher. Otherwise, we can make a correction by assuming that when a pattern is not supported by a site, actual support = x  X  min-support ,where0  X  x &lt; 1. We can make suitable estimate of x and proceed. Typical value for x can be 0.5. Incidentally, such a procedure improves the results of both the methods. We had repeated the synthesizing procedure with a correction factor of 0.5.ie., 0.5  X  min-support = 0.1, wherever a pattern is not supported by a site. Table 6 a presents results with out corrections while Table 6 bpresents and also from Table 8 , it can be found that the corrections improve the results of both the methods. From a perusal of Tables 9 and 11 , it is found that the proposed method scores better in synthesizing global support for situations involving skewed data. From Tables 12 and 14 , for study 3 with skewed population distributions X  X here only our method is applicable X  X e find that the results are satisfactory. 5.2 Synthesizing global confidence A perusal of synthesized global confidence values from Tables 7 and 10 and error measures from Tables 8 and 11 shows that the proposed method emerges superior to the Wu X  X hang method. In fact, as discussed earlier, confidence measure is based on joint probability concept, synthesized. Confidence values by the new method are close to mono-mining values. Again, observing closely, it is found for some of the results the error is rather high. For example, in been obtained without making any corrections corresponding to the sites that do not support the pattern. When the corrections are made as detailed earlier, the resulting confidence value improves to 0.6990, reducing the error to 0.0520. From Tables 13 and 14 for study 3 X  X here only our method is applicable X  X e find that the results are satisfactory.

Based on the examples illustrated, the three studies presented and the results of other experiments, it can confidently be claimed that synthesizing global support and confidence by the proposed method yields fairly close results to the targeted mono-mining results in all the situations. However, the method has a limitation; the sizes of the participating databases must be known. In case this information is not available X  X s with Internet databases X  X ne has to adopt alternative strategies put up by Wu X  X hang [ 9 ]. 6 Conclusions and future work This paper has extended the work of Wu X  X hang, and the proposed method of synthesizing high-frequency rules in multi-databases is applicable to databases of varying sizes. A new method for calculation of global confidence measure has also been proposed. Experimental results. Thus, the benefits of both mono-mining and multi-database mining are captured. An attempt has been made to synthesize rules with site weights based on population. This is not the only way for the allocation of weights; site-weights based on turnover X  quantity or cost of items sold X  X an be explored. For this, quantitative mining has to be done, which is currently receiving attention from our end.
 Appendix 1 Algorithm: Rule selection Input: Output: (1) Let W | R = 0; (2) For each rule R i in S | , i = 1to N | do (3) W | R (4) begin (5) end; (6) For each rule R i i = 1to N | do (7) Output S; // Reduced rule set of N rules (8) End procedure. 2 Algorithm: Rule synthesizing Input:
Output: X  X  Y [Synthesized rule sets] (1) Let S | = S 1  X  S 2  X  X  X  X   X  X  X  S m (2) Call rule selection; (3) Let W | s = 0; (4) For each site j , j = 1to m do (5) For each site j , j = 1 to m do (6) For each Rule R i in S, i = 1to N do (7) begin (8) end; (9) Rank all rules in S by their support; (10) Output the high rank rules of S whose support and confidence are at least minsupp and minconf, respectively. (11) End all. 3 Algorithm: global_supp_ante (R i )
Let Supp_ante G ( R i ) =0; 1. Check whether the site s j contains rule R i 2. ELSE 3. ELSE 4. ELSE
END IF; 5. Supp_ante G ( R i ) = Supp_ante G ( R i ) + w s j  X  Supp_ante j ( R i ) ; End procedure.
 Glossary of terms Supp G ( R i ) Global support for rule R i Supp_ante G ( R i ) Global support for antecedent of rule R i Conf G ( R i ) Global confidence for rule R i Supp j ( R i ) Support at site j for rule R i Conf j ( R i ) Confidence at site j for rule R i
Supp_ante j ( R i ) Support at site j for antecedent of rule R i min.  X  effective , min.  X  nominal Minimum effective, nominal vote rates for rule selection minsupp Minimum support for rule synthesizing minconf Minimum confidence for rule synthesizing W | R Total weight of all rules
W R i Normalized weight of rule R i W | s Total of unnormalized site weights W s Total normalized weight of all sites = 1 References Author Biographies
