 1. Introduction increasing size of storage devices makes the task even more difficult. process: forensic tools: and false negatives.
 child pornography cases than computer hacking cases [13].
 developed.
 subject. Fig. 2 illustrates the overall process of our solution.
 document and the subject vector.
  X  the subject.
 computer. He might provide the following set of terms (along with their PoS tag) to define the subject: b Hacking&gt;hack:Verb,security breach:Noun,login:Noun,Nmap:Noun,permission:Noun,exploit:Verb clustering algorithm, such as bisecting k-means algorithm, to conduct further analysis on them. 1.1. Contribution summarize the major contributions of the paper as follows:  X  vector. This is reflected in our proposed similarity function Sim ( d , s d  X  D and subject s i  X  S , where D is a collection of documents and S is a set of subjects.  X  precision of our clustering algorithm by reducing the polysemy affect [10,40] .  X   X  approach is highly scalable for large data sets.
 the paper in Section 7 . 2. Related work and background knowledge the user-provided initial subjects definitions.
 document vector and subject vector in SVSM.

WordNet supports two types of relations: semantic and lexical.  X   X  Synonymy are two examples of lexical relations.

According to Leibniz, 1 synonymy can be defined as follows: other never changes the truth value of a sentence in which the substitution is made . C does not alter the truth value .  X  either homonyms 2 or polysemous . 3 3. Problem de fi nition clustering system in Section 3.4, followed by a problem statement. 3.1. Initial subject de fi nition
For each input term t  X  s i 0 , the investigator should provide its part of speech PoS problems, where more than one distinct meaning exists for the same word. Moreover, PoS 3.2. Extended Synonym List (ESL) 3.3. Preprocessing
The following preprocessing procedures are applied on the initial vectors and the document set. 3.3.1. Initial vectors preprocessing stemming algorithm [34] for this purpose. This algorithm, for example, reduces the words  X  exploitation  X  to the root word  X  exploit  X  . 3.3.2. Document set preprocessing 3.3.2.1. Stopwords removal. Words that do not convey any meaning as well as common words, such as
We compiled a static list of stopwords to be used for this purpose. by using white spaces and punctuation marks as separators. For example, the string tokens:  X  George  X  ,  X  Sam  X  ,  X  Mike  X  .
 After the preprocessing, the set of distinct terms in a given document set is denoted by their terms and compute the weight of the terms in each document: document using term frequency  X  inverse document frequency ( tf frequency of term t in the document set D : where | D | is the number of documents in the document set D , and Freq frequency of the term within the document set. 3.4. Clustering system de fi nition We can now define our clustering system as a tuple: where:  X 
D ={ d 1 , d 2 , ... , d | D | } is a set of input documents to be clustered.  X 
S ={ s 1 , s 2 , ... , s n } represents a set of n subjects, where each subject s based on the initial definition vector s i 0 .  X  them.  X 
Sim ( d , s i ) is a similarity function that measures the similarity between a document d value that ranges between 0 and 1.  X  cluster C i  X  C contains a set of retrieved documents for subject s 3.4.1. Problem statement
Given a set of subjects S , the initial definition of each subject s
C X C 1 ; C 2 ; ... ; C C jj such that each cluster C i is associated with one and only one subject s 4. Solution modeling 4.1. Subject vector generation subject s i  X  S , our clustering algorithm generates a set of expansion vectors s 1 set of weighted terms that are semantically related to the terms in the previous expansion vector s vector s i 1 is semantically generated from the initial subject definition vector s generated terms decreases as we generate more expansion vectors.
 the expansion vectors of s i : 4.2. Subject Vector Space Model (SVSM) other: where ( s i  X   X  s j  X  ) denotes the dot product between s analogous to their representation in TVSM. 4.2.1. Term representation
Terms are represented in SVSM with respect to subject dimensions in SVSM, i.e., each term t n -dimensional vector t  X  whose coordinates are the weights of the term in each dimension: where  X  t ; s i is the weight of term t in subject dimension s be a weight value assigned to t and  X  t ; s i will be equal to this value; otherwise,
The norm (positive length) of a term vector t  X  represents the global weight of that term: are positive, the cosine similarity value between any two term vectors is always between zero and 1: where  X  is the angle between term vectors t i  X  and t j  X  4.2.2. Document representation
Each document d  X  D is represented as an n -dimensional vector d the products of each term coordinate with the weight of a term in document d :  X  to normalize the document length to 1.
 coordinates differ by a constant factor. 4.3. Document-subject similarity function i.e., where  X  t ; s i ;  X  t ; d are the weight of term t in subject s 5. Semantic clustering algorithm { s objective, we apply two computational linguistics techniques tasks. 5.1. Slang words processing  X  coke  X  , the sixth noun sense we get is:  X  coke, blow, nose candy, snow, C in which the word exists.
 and each subject s i  X  S and generates a set of overlapping clusters C accordingly. steps to generate expansion vectors for each subject s i  X  Algorithm 1. Subject vector generation subject vector as long as its length (the number of terms) does not exceed the threshold
Note that the weight of each term in any initial vector s generating a set of expansion vectors, the weight of each term in any expansion vector s any term in the previous expansion vector s i r , i.e., terms as additional features may introduce noise [15].
Fig. 4 illustrates the subject s i vector generation process. 5.1.1. ESL Lookup (lines 6  X  11)
The objective of this step is to generate an expansion vector s List ( ESL ) such that r  X  1 expansion vectors have already been generated.
The input in this step is a set of weighted terms denoted by generated ( r = 1), then  X  a is the initial subject definition vector s subject s i .

For each t  X   X  a , line 6 scans the ESL. If t ESL , then any related term t weight equal to the weight of t . 5.1.2. WordNet Synonyms (lines 17  X  18) synonyms of each term.

The input for this step is a set of weighted terms denoted by step (ESL Lookup).
 technique for part-of-speech (PoS) tagging and sense determination in a context. t  X   X  expansion approach using WordNet. 5.1.2.1. Synset repository construction. Let  X  b  X  t 1 ; t WordNet: where PoS S j denotes the part of speech of all synonyms in synset dictionaries. to identify the best fit synset in the context of subject s each term t  X   X  b to solve the ambiguity problem as follows: (2) For each context term t k  X  s i 0 , list all the possible senses: (3) For the target term t l , as well as each context term t (4) Measure the relatedness between each gloss of target term t (6) Repeat this process for every term t l  X   X  b to determine the most appropriate sense for each term. and 0.239 for verbs. 5.1.2.3. Expansion using synonyms. Having assigned a synonym set be generated by assigning the synonym terms of each term t where wsd ( t l ) represents the best fit synset in the context of subject s assigned a weight that equals half the weight of the terms in s 5.1.3. Top frequent terms (lines 24  X  30)
The goal in this step is to generate an expansion vector s algorithm to determine the context dominant sense in Section 5.1.3.3 . Finally we apply the Jiang to determine the most related terms to the initial subject definition s 5.1.3.1. Compute top documents. The input for this section is a set of terms vectors for subject s i  X  S that have already been created: computing the dot-product between each pair of vectors as follows: the top of the documents with the highest score as the most related set of documents denoted by D 5.1.3.2. Compute top frequent terms. To determine the top frequent terms in D each row corresponds to a document d  X  D  X  and each column corresponds to a term t frequency  X  inverse document frequency ( tf  X  idf ) [37] of each term in each document.
Based on matrix ^ M , we then determine the set of top frequent terms using the function ( tft ). Let matrix where each entry corresponds to a term frequency  X  d  X  5.1.3.3. Word sense disambiguation. Even though we have extracted the set of frequent terms tft dominant sense , and our goal here is to determine the dominant sense for each term t e terms that appear to the left and right of the term in each of its occurrences. senses:
We first determine the most appropriate sense for a term in each context x 5.1.3.4. Relatedness distance measure. The set of terms tft t  X  tft ^ M to the initial subject definition vector s i 0 . The Jiang this sum, and then takes the inverse to convert it from a distance to a similarity measure.
Using jcn , we compute the distance between each term t  X   X   X  will be used to construct the expansion vector s i r +2 : expansion vector for the same subject, i.e., and the weight of each term t  X  s i r +2 is equal to the weight of the expansion vector itself List (ESL) in Section 5.1.1 .

Once the generation of expansion vectors for all subjects s the similarity function Sim ( d , s i ) between each document d D and each subject s Algorithm 2. Document clustering.
 6. Experimental evaluation documents. We used Apache Tika 4 and Lucene 5 to parse, preprocess, and index the documents. document and its assigned subject is maximized. a given search query and a specific subject.
 algorithm implemented in the clustering engine in terms of accuracy, efficiency, and scalability. 6.1. Data sets
Below is a brief summarization of each data set's characteristics:  X  system documents (CRAN), 1033 medical documents (MED), and 1460 information-retrieval documents (CISI).  X  sexual assault-related documents.  X  and 80 overlapping documents that belong to more than one class (contain more than one topic). 6.2. Evaluation method We use F-measure [24] to measure the accuracy of the clustering solution produced by our method. natural classes of the document set D .Wecomputethe Precision and Recall of cluster C where K i jj , C j , and K i  X  C j denote the number of documents in class K in our experiments to compute the accuracy of cluster C j where F 1 score reaches its best value at 1 and worst score at 0. 6.3. Experimental results 6.3.1. Accuracy
Our clustering algorithm allows for two user-specified thresholds cluster C i if its normalized score returned by the similarity function is larger than
Fig. 6 depicts the F-measure values (accuracy) of the clustering algorithm with respect to values relative to the average document length avg _ dl in the data set: 0.25 similarity threshold  X  increases from 0.05 to 0.5. Assigning a value between 0.1 and 0.175 to a high accuracy value when  X   X  [0.08,0.2] and  X  = avg_dl . consequently reduces the sensitivity of our clustering algorithm to the input parameter maximum length of a subject vector is equal to the average document length in the document set ( most cases provides higher F-measure values.

Having determined that higher accuracy is obtained when  X 
Fig. 7 depicts the F-measure values of the clustering algorithm with respect to values span from 0.59 to 0.75 when the minimum similarity threshold that the higher the minimum similarity threshold  X  is, the higher the drop in accuracy. That is, when correlate with the value of the minimum similarity threshold 6.3.2. Ef fi ciency and scalability complexity of our approach is dominated by the maximum subject vector length runtime under different subject vector lengths and different data set sizes. than Forensic-2 ), the gradient (slop) of each data set's runtime remains the same. a balanced duplication of the data set, we define the scaleup factor
We also define the remainder factor  X   X  as follows: is scalable. 7. Conclusions and further work subject vectors can further enhance the accuracy of our algorithm.
 Acknowledgment like to thank S X ret X  du Qu X bec (SQ) for providing us with real-life materials for experimentation.
References
