 The 2016 ACM Recommender Systems Challenge focused on the problem of job recommendations. Given a large dataset from XING that consisted of anonymized user profiles, job postings, and interactions between them, the participating teams had to predict postings that a user will interact with.
The challenge ran for four months with 366 registered teams. 119 of those teams actively participated and sub-mitted together 4,232 solutions yielding in an impressive neck-and-neck race that was decided within the last days of the challenge.

The ACM RecSys Challenge allows researchers and engi-neers around the world to jointly work on real-world rec-ommender system problems in various domains such as so-cial media [3] or product recommendations [2]. In 2016 the challenge was dedicated to the problem of job recommenda-tion 1 [1]. We released a dataset from XING 2  X  X  business-oriented social network with around 18 Million users world-wide and more than 10 Million users in Germany.

XING supports people in discovering career opportuni-ties. Job recommendations are therefore an essential part of http://2016.recsyschallenge.com http://xing.com number'of'users/items'that'performed/ Figure 1: Number of interactions per user and item. 328,618 items (24.2%) and 582,370 users (42.9%) remained without interactions during the training period. More than 80% of the interactions are clicks, followed by deletes, replies and bookmarks. The distributions for training data and test data (ground truth) follow similar characteristics. the XING platform and its mobile apps. Those recommen-dations aim to satisfy the demands of both the job seekers who have certain preferences concerning their next career step and the recruiters who aim to hire the most appropri-ate candidate for a given job. In this challenge, we focused on the demands of the job seekers by defining the following task: Given a XING user, the recommender had to predict those job postings that a user will positively interact with by clicking on it or bookmarking it.
We provided a training dataset featuring user profiles, job postings, and interactions that users performed on job posts. The dataset also incorporated user-item impressions , i.e. information about job postings that were shown to users. The training data 3 contained 1,367,057 users and 1,358,098 items. Users and items were described by several similar attributes such as job categories, career level, industry, lo-https://github.com/recsyschallenge/2016/#data cation, etc. In addition, the educational background and details about work experience were given for the users.
Around 12 weeks of interaction data between the users and the items was released for training including including (1) clicks on job postings, (2) bookmarks , (3) replies indicating that users intended to apply for the job and (4) deletes which corresponds to removing an item that the user no longer wants to see. Figure 1 describes the characteristics of the different interactions. Two weeks of interactions for a set of 150,000 target users were used as test data in order to evaluate the submitted solutions. Figure 1 also shows the distribution of that ground truth dataset.
Anonymization of the training dataset was carried out with an iterative protector/attacker procedure. We took a simple and straightforward approach to threat modeling: The attacker profile was implicit the choice of a highly expe-rienced Data Science team that attempted to de-anonymize the data. At each step the dataset was further bleached, and additional synthetic users were added. Then, tests were carried out to check if the dataset could be de-anonymized by the attacker and also if the dataset supported training a recommender system algorithm effective on a plain-text test set. This procedure ensured that enough information was left in the data to make this to be a useful data set for solving the problem on the actual plain-text data, while at the same time protecting the privacy of XING users.
The bleaching procedure involved replacing named enti-ties with IDs, removing a selection of user attribute values, and removing a selection of interactions. The relative or-dering of the interactions was maintained. Synthetic users were created by clustering real users. Further protections included the obvious measure of including only a fraction of XING X  X  users and job postings in the dataset, and also protecting the dataset legally with a user agreement that explicitly prohibits attempts to de-anonymize the dataset, share it, or use it for non-academic purposes.
We used a scoring function as evaluation measure that combines precision@k and recall@k 4 . This evaluation mea-sure was based on the key performance indicators that XING https://github.com/recsyschallenge/2016/#evaluation is using to monitor the quality of the job recommender sys-tem. Each team was allowed to submit 5 solutions per day and solution files were allowed to feature at most 30 recom-mendations per user. A public leaderboard that was based on 30% of the ground truth data immediately informed the teams about the performance of their algorithms after their submissions.

The participating teams came from more than 30 differ-ent countries such as USA (25%), Germany (11%), China (9%), France (7%) or Hungary (4%). Teams came both from academia (  X  25%) and industry (  X  75%, most common: In-ternet &amp; IT ), e.g. from larger companies such as Yandex or Amazon as well as from smaller start-up companies.

The evolution of the top full score X  X ased on the en-tire ground truth X  X s depicted in Figure 2a together with the number of submissions that were performed during that week. The top score thus increased from week to week. In fact, the highest score of the challenge was achieved just 30 minutes before the official submission deadline. Figure 2b reveals that not only the top teams very highly active in sub-mitting solutions, but also many teams that finally ended up at rank 30 and above submitted a high number of solutions.
The top solution achieved a score of 2,052,185 points that is 24.1% of the best possible score. Figure 2c also shows that the top solution managed to include items that XING X  X  sys-tem does not recommended. Hence, algorithms developed during the challenge seem to complement XING X  X  recom-mender ensemble and are likely to have a significant impact on XING X  X  future job recommendations.
 [1] F. Abel. We know where you should work next [2] D. Ben-Shimon, A. Tsikinovsky, M. Friedmann, [3] A. Said, S. Dooms, B. Loni, and D. Tikk.

