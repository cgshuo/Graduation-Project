 In this paper, we propose a novel opinion summarization problem called compact explanatory opinion summarization (CEOS) which aims to extract within-sentence explanatory text segments from in-put opinionated texts to help users better understand the detailed reasons of sentiments. We propose and study general methods for identifying candidate boundaries and scoring the explanatoriness of text segments using Hidden Markov Models. We create new data sets and use a new evaluation measure to evaluate CEOS. Exper-imental results show that the proposed methods are effective for generating an explanatory opinion summary, outperforming a stan-dard text summarization method.
 I.2.7 [ Artificial Intelligence ]: Natural Language Processing X  text analysis ; H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing X  Linguistic processing ; H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Infor-mation filtering Compact explanatory summarization, Explanatory phrase extrac-tion, Opinion Mining
Most previous studies on opinion summarization have focused on predicting sentiments of entities and aspect-based rating for the entities, but they do not provide a detailed explanation of the under-lying reasons of the opinions. For example, to understand opinions about  X  X Phone X , one can use review articles from websites to find aspects such as  X  X creen X ,  X  X attery X , and  X  X rice X , and then further predict the sentiment orientation (usually positive or negative) on each aspect. Although these existing techniques can show the gen-eral opinion distribution, they cannot provide the underlying rea-sons why people have positive or negative opinions about the prod-uct. Therefore, even if such an opinion summarization technique is available, people would still need to read through the classified opinionated text collection to find out why people expressed those opinions.
 Although general automatic summarization techniques may be used to shrink the size of text to read, they generally extract sen-tences based on  X  X opularity X . As a result, the output summary tends to cover already known information. For example, for the sum-mary request for  X  X ositive opinions about iPhone screen X , a pure popularity-based summary could be  X  X creen is good X . Such a sum-mary is obviously redundant and does not give any additional in-formation to explain the reason. In contrast, ideally, we would like the summary such as  X  X etina display is very clear X . Explanatory sentences should not only be relevant to the target topic we are in-terested in, but also include details explaining reasons of sentiments which are not redundant to the target topic itself.

Another deficiency of the existing sentence extraction methods is treating a sentence as a unit, but it is often the case that not all words in a sentence are useful for explaining an opinion, so it is also desirable to extract smaller segments within a sentence that can explain opinions. For example, a sentence may be verbose or include functional phrases such as  X  X  love the fact that ... X  and  X  X y friends said ... X . Some part of the sentence even may not be relevant to the given topic. For instance, a sentence,  X  X he pictures are beautiful, and the camera is so small you can carry it anywhere X , could be classified as an opinion sentence of  X  X amera size X  topic. However, the first half of the sentence is not related to the size of camera. It is always desirable to use minimum display space to show maximum amount of useful information, which is especially necessary when displaying summaries on the small space such as a smart phone.

In this paper, we introduce a novel summarization problem called  X  X ompact X  Explanatory Opinion Summarization (CEOS) which ex-tracts explanatory text segments from sentences. We can regard the CEOS problem as extracting text segments to answer the question about why reviewers hold a certain opinion. Thus, the main differ-ence between CEOS and a regular summarization problem is that in CEOS we emphasize on selecting texts that provide an explana-tion of why an opinion holder has a particular polarity of sentiment about an entity, whereas in regular summarization, there is no guar-antee of the explanatoriness of a selected segment.

Two main technical challenges in solving the CEOS problem are: 1) to find the boundary of an explanatory text segment and 2) to assess the explanatoriness of the segment in giving a reason for the given sentiment. We focus on studying how to solve these problems in a systematic and unsupervised way as such a method would be generally applicable to many domains without requiring manual effort. We propose general new methods for CEOS using Hidden Markov Model (HMM).

The main contributions of this paper include: 1) We introduce a novel summarization problem called compact explanatory opin-ion summarization (CEOS), where the goal is to select explanatory within-sentence text segments that can explain why a certain senti-ment polarity of opinions is held. 2) We propose general methods for solving the CEOS problem using Hidden Markov Model which require no human supervision. 3) We define a new measure and create two new data sets for evaluating this new task, which will be publicly available. 4) We evaluate all the proposed method s to understand their relative strengths and show that they are more ef-fective than a regular summarization method and term frequency based baselines. Automatic text summarization has been studied for a long time. In particular, LexRank [4], which is a representative algorithm to measure the centrality of sentences, converts sentences into a graph structure and finds central sentences. To show the difference be-tween general and explanatory summarization, LexRank will be used as our main baseline. Our problem setup is based on ex-tractive summary generation and unsupervised learning. Therefore, abstractive summarization and supervised machine learning-based approaches are not comparable.

There are several surveys that summarize the existing opinion summarization works [11, 12, 15]. Aspect-based summarization is one of the most popular types in opinion summarization, which first finds subtopics (aspects) of the target and obtains statistics of positive and negative opinions for each aspect [6, 13, 14, 16]. Most of previous works showed statistics, not focus on selecting sen-tences. The input and output of such a summarization problem are completely different from our problem setup. Indeed, our problem setup is meant to further improve the utility of an abstract sum-mary that can be generated by existing aspect-based summarization methods. Other works try to further summarize aspect-sentiment-divided opinions [5, 9]. None of these existing opinion summariza-tion methods is designed to solve the same problem as ours.
One of the sophisticated methods for passage retrieval in in-formation retrieval field uses Hidden Markov Model (HMM) [7]. Although passage retrieval has similar challenges to compact ex-planatory summarization, its focus is not on finding an  X  X xplana-tory X  phrase, but a  X  X elevant X  passage to a query. In this paper, we show how we adapt the HMM-based passage retrieval technique to address explanatory opinion summarization.

Another related work is handling why -question in question an-swering area. Researchers mainly focus on how to find and ex-tract specific causal lexical patterns or rhetorical structure [18]. In opinion summarization, explanatory opinion may appear with-out explicit causal relationships indicated by lexicons such as  X  X e-cause X . Moreover, in this paper, we more focus on an unsupervised language-independent statistical method which is possibly applica-ble to multiple languages.

Sentence compression [3] has similar problem setup in that shorter output is generated based on the input sentence. However, sentence compression has a very different goal, how to generate shorter sen-tence with good readability and grammar from the input single sen-tence regardless of explanatoriness. Sentence compression tech-niques may be potentially combined with our approach to improve readability, but the two problems are very different in nature.
Explanatory sentence extraction [8] proposes methods for scor-ing explanatoriness with sentence unit and shows the usefulness of using explanatoriness ranking in opinion summarization. However, as we discussed above, not an entire sentence may be explanatory. In this paper, we propose methods to extract within-sentence ex-planatory text segments and also compare the previous work as one of our baselines.
Our problem formulation is based on the assumption that exist-ing opinion mining techniques can be used to find subtopics (senti-ment polarity on aspect). We hope to further help users digest the opinions expressed in a set of sentences with a certain subtopic by extracting a set of explanatory within-sentence segments providing specific reasons of opinions. Thus, as a computational problem, the assumed input consists of two sets of sentences; a sentence set O = { o 1 , ..., o n } to be summarized and a background sentence set T which is a superset of O . For example, O is the set of sentences about  X  X icture quality of camera A X , and T is the set of sentences about  X  X amera A X . In real application scenarios, when we have a data set T , existing opinion mining techniques would be able to classify sentences in T into subtopic clusters by aspects or opinion orientation. Any one of the clusters can then be treated as O to obtain an explanatory summary.

Given T and O as input, the desired output is an explanatory opinion summary S , which is a subset of sentences segments of O , i.e., S = { s 1 , ..., s m } such that every s i  X  o j is an explanatory text segment. s i is any consecutive sequence of words in any sen-tences in O , that is, it can be an entire sentence or a part of one sentence in O . If an input sentence has more than one explanatory text segment, two segments may be extracted from the same input sentence. The summary, S , would fit a display with k characters, i.e., P m i =1 | s i | X  k , where | s i | is the length of segment s
Given a boundary detection method and an explanatoriness scor-ing function E ( s ) , we can generate an explanatory opinion sum-mary by recursively selecting the most explanatory phrase candi-date until the length of selected phrases reaches the summary length limit k . If the final segment that makes the output summary reaches or goes over the length limit, we can use the part of the sentence that will fill up to k character limit because even a partial text seg-ment may deliver explanatory details. By doing this, we do not give preference to methods that tend to extract shorter segments. In contrast, if we did not allow to fill up the remaining space with a partial segment, methods that prefer longer segments would have more empty space and would tend to have lower score than meth-ods that prefer short segments.

Clearly, the main challenge in making this algorithm work is to design a method for explanatory text boundary detection finding good candidate segments and a good explanatoriness scoring func-tion. Note that the recursively selecting algorithm above can be modified in a straightforward way to accommodate redundancy re-moval by using existing techniques such as Maximal Marginal Rel-evance [2] or clustering. However, we intentionally do not explore these variations in this paper in order to focus on studying the novel research challenge in extracting explanatory text segments, which has not been studied before. Figure 1: HMM structure for explanatory text extraction
A n HMM is a very useful model for sequence data [17]. We pro-pose an HMM-based explanatory text segment extraction method that can naturally model the sequence of words with different char-acteristic (explanatory/nonexplanatory) states, shown in Figure 1. The proposed HMM has five states denoted by five circled nodes in the picture. States B 1 and B 2 are background (nonexplana-tory) states, modeling the non-explanatory text segments on the left and right sides of the explanatory segment respectively. E is the explanatory state, modeling the (hidden) explanatory segment in a sentence. I is an initial state, and F is a final state. The out-put from I and F is assumed to be a special symbol indicating the beginning and end of a sentence, respectively. The output of the other states are words, and the set of output symbols is the word vocabulary of the text collection. Each word has a certain prob-ability (including zero) of being emitted from each state. Arrows between states indicate nonzero transitions probabilities from one state to another. Such an HMM thus naturally models the situation where an explanatory phrase ( E ) is surrounded by nonexplanatory phrases ( B 1 , B 2 ) . Although both B 1 and B 2 have basically the same functionality generating nonexplanatory words, we need both of them because there can exist nonexplanatory words before as well as after an explanatory phrase in a sentence. Because an entire input sentence can be explanatory, the HMM can also potentially go directly from state I to state E and from E directly to F with-out going through B 1 or B 2 (i.e., transition probabilities from I to E and E to F are nonzero). Likewise, an entire input sentence can be nonexplanatory; thus, transition probability from B 1 to B 2 is nonzero, either. Furthermore, the transition probabilities from each state (except I and F) into itself are nonzero so that they can generate a segment with more than one word.

Our main idea is to fit such an HMM to a sentence and find the sequence of state transitions that can optimally fit the sentence (i.e., best explaining the generation of the sentence). From such a se-quence of state transitions, we can then obtain an annotation of ev-ery word in the sentence with one of the three states { B 1 , E, B 2 } , and the segment of words annotated with state E would be regarded as the extracted explanatory segment for use in summarization.
The proposed HMM can naturally implement the two intuitions, popularity and discriminativeness [8]. Popular and representative information is more likely explanatory. Discriminative informa-tion that can distinguish the target subtopic from the background data set also tends to be explanatory. Specifically, we will make the output probability from state E resemble the word distribution in all the opinion sentences O , which would naturally implement the popularity and representativeness heuristic since a word that is more often seen in O would have a higher chance of being gener-ated from E . We will also set the output probability distributions of the two background states B 1 and B 2 based on the background text data discussed earlier, which would naturally implement the heuris-tic  X  X iscriminativeness relative to background X  since a word more frequent in the background text would then have a higher chance of being  X  X bsorbed X  by one of the background states rather than being generated from E .

Formally, let p ( w | x ) be the output probability of word w in state x , p ( x j | x i ) be the transition probability from state x p ( x 1 ) be the initial probability of state x 1 . X = x nite set of N states, and in our HMM design X = { B 1 , B 2 , E, I, F } . For each sentence, o = w 1 w 2 ...w n , from the input data set O , we want to find the state sequence Seq  X  which has the highest likeli-hood, p ( o | HMM ) .
 The output sequence generated by the state E would then be re-garded as the candidate explanatory text part, s , from sentence o . For example, with a sentence  X  X he retina display is very clear X , if we suppose  X  X etina display X  is an explanatory phrase, the state se-quence of Seq  X  = q 1 ...q n would be like IB 1 EEB 2 B 2 B 2 F . The explanatory segments from the sentences of O are ranked by the explanatoriness scores of their respective sentences (to be defined below), and top ones are used to generate the summary.

To obtain an explanatoriness score of a sentence, we can intu-itively use the probability of the sentence given by the  X  X xplana-tory HMM X  discussed above. That is, if a sentence is more likely generated from such an HMM, it would be more likely explana-tory. However, we cannot directly use this probability as it would naturally penalize a long sentence. To address this problem, we normalize this probability by the probability of generating the same sentence from a background HMM. The background HMM can be constructed similarly to the one above except that we would force it not to enter the explanatory state by setting all the incoming tran-sition probabilities to explanatory state to zero, i.e., set the initial probability of E state and the transition probability from B 1 to E all to zero. With this setup, we can estimate parameters of HMM in the same way and find the likelihood of the input sentence o . Fi-nally, by normalizing the likelihood of the sentence given the orig-inal HMM by that given the background HMM, we can measure how likely the text segment is explanatory without any bias due to various lengths of sentences. Formally, given text segment s ex-tracted from sentence o , its explanatoriness score would be defined basic HMM-based explanatory extraction method as HMM E .
The output distribution of state E is the explanatory language model, and is meant to capture which words are more likely to be observed in an explanatory segment. The output distribution of state B 1 and B 2 is the background language model, which mod-els word frequencies in the background text in general. We can thus use the entire input sentence set, O , to estimate the explana-tory language model, and the entire texts in topic T as the back-ground data set to estimate background language model; p ( w | B ) = c ( w, T ) / | T | , p ( w | E ) = c ( w, O ) / | O | , where T is background data set (e.g. entire opinionated sentences about one Topic T ), O is input data set, B corresponds to the background states B 1 and B 2 , E is explanatory state, and c ( w, C ) is the count of word w in text collection C . With such estimates, the words that would be tagged with state E would likely be relatively discriminative opin-ion words, i.e., those words popular in the input data set but not in the background data set.
Once the output probabilities are set, we can learn the transi-tion probabilities of the HMM from an observed sequence such as each sentence of the input data set. While we may also estimate these probabilities based on labeled training data, here we focus on learning the transition probabilities in an unsupervised way us-ing the Baum-Welch algorithm on the input sentence itself (i.e., treating it as the only observed sequence) [1]. Like other EM al-gorithms, Baum-Welch algorithm starts with some random guess of the parameter values. At each iteration, we compute the prob-ability of all possible hidden state transition paths, and then re-estimate all the parameters based on the expected counts of the corresponding events. The process is repeated until the likelihood converges. Compared with a regular EM algorithm, Baum-Welch is much more efficient due to the use of dynamic programming to avoid brute-force enumeration of all the possible paths. More de-tails about this algorithm can be found in [17].

We have seen that the explanatory model parameters for both segment likelihood ratio and HMM probabilities are estimated from input sentences. However, input opinion sentences may contain nonexplanatory segments, and this appears to be a concern as the parameters are estimated based on sentences containing noisy el-ements. However, the proposed method would work well on sen-tences containing such noisy elements because of the use of back-ground models for discrimination. A nonexplanatory element would be penalized because those words are more common in a back-ground set than an explanatory set. Our methods are designed to favor a phrase with terms frequent in the input opinion set, but not common in the background set. In the same way, in HMM, those noisy elements are more likely to be captured by background states.
The basic model above uses maximum likelihood estimator to model an explanatory language state. Because the vocabulary of input data set is not big enough compared to the one in the back-ground data set, the estimated output probabilities may be too big compared to those in the ideal explanatory language model (which would include all possible explanatory sentences). In addition, be-cause the current observing sentence used for transition probability estimation is a part of O , there is a concern that the trained HMM may overfit to the explanatory state. That is, it may stay at the explanatory state too long.
One easy way to avoid this problem is excluding the observing s entence in modeling explanatory language model ( HMM E -Rmv ). That is, when we estimate explanatory language model for o can use other sentences in O .

A more formal method for avoiding overfitting is to smooth the explanatory language model. One way to smooth is using Lapla-cian [19] smoothing that adds uniform weighting to each word ( HMM E -LP ). The smoothed model can be defined like the fol- X  is a parameter controlling the strength of Laplacian smoothing.
We can enhance the explanatory language model by adding words from the initial extraction. This is similar to pseudo feedback in in-formation retrieval. We assume the extracted text segments are ex-planatory (pseudo-explanatory), and use them to modify the initial explanatory language model ( HMM E -FB ). From the first run of HMM over all the input sentences in O , we would have initial text segment extraction results, and using the extracted words we can also produce a feedback language model E  X  . With  X  1 , the param-eter controlling strength of feedback, we can smooth the current explanatory language model with this pseudo explanatory model: p
Because there is no data set for evaluating explanatory opinion summarization, we created new data sets. We can use the output of opinion mining results as our input; thus, we assume that the sen-tences are already tagged with sentiment polarities and classified into different aspects. We use a publicly available product review data set [6] including 12 products review sets from Amazon sentiment and aspect labels. To evaluate the generality of the pro-posed method, we created another data set in a different domain, hotel. For reviews obtained from trip advisor 2 , we generated an aspect and sentiment label for each sentence using three human la-belers and filtered out the ones disagreed. For each data set, we cluster sentences based on the aspect and sentiment labels. If there is less than 10 sentences in one cluster, we discard the cluster be-cause it does not need summarization. As a preprocessing step, the input data set is first processed by a basic stemmer to relieve sparseness issues.

Our key evaluation question is whether the proposed methods can really find explanatory text segments. Therefore, for gold stan-dard, we asked two human labelers to mark explanatory parts of each sentences. We provided the topic description of each cluster (product type, aspect, and sentiment orientation), and asked them to mark any part of each sentence that explains a reason of the opin-ions in the given topic. They are asked to mark segments with explanatory information which is relevant to the given topic and is not directly inferable from the topic label. For example, one ac-tual label about  X  X egative opinion about MP3player case X  is  X  X he case is strong and stylish , but unfortunately &lt; exp &gt; lacks a win-dow ( now a big deal ) . &lt; /exp &gt;  X . The labeler did not include func-tional words such as  X  X nfortunately X  and non-topic-relevant phrase  X  X trong and stylish X  which has opposite sentiment orientation to our target topic. Labelers are allowed to mark more than one ex-planatory phrase for each sentence if each is independently useful for readers. The data sets with detailed labeling instructions, exam-ples provided to the labelers, and the generated labels are publicly available 3 . h ttp://www.amazon.com http://www.tripadvisor.com http://sifaka.cs.uiuc.edu/ir/data/expSum/
The generated test data sets include totally 89 topic clusters with 3799 sentences. Average explanatoriness is 0.335, which is the av-erage ratio of the number of characters marked as explanatory by labelers to the entire number of characters for each data set. The la-bel agreement, defined as the ratio of the number of characters hav-ing the consistent label to the total number of characters, is 0.725. In the evaluation results below, we measure performance for each label and report average value.
In our problem setup, we use the following new measure, called explanatory characters at k characters (denoted as EC @ k). The idea of EC @ k measure is to capture the perceived utility of CEOS when displayed on a screen with room for k characters. The perceived utility is defined as the percentage of characters displayed that are parts of explanatory phrases. Formally, suppose S = ( s 1 an explanatory opinion summary with n text segments from orig-inal sentence set O , and E = ( e 1 , ..., e m ) is a gold standard ex-planatory text segments of input sentences O .
 H ere, idealEC @ k(S) is the maximum possible score. This normal-ization makes EC @ k score more interpretable. That is, EC @ k = 1.0 means achieving the best possible performance. Also, the normal-ization makes this measure comparable between different data sets; thus, we can report mean EC @ k which is averaged performance over all input topics, and the averaged score would not be domi-nated by too difficult (there is no explanatory text) or easy (all parts of input sentences are explanatory) topics. In our experiments, for parameter k, we chose 150 that is a short summary similar in length to twitter, and 500 that is around 100 words.

We can think EC @ k is similar to ROUGE-1 using entire explana-tory summary as gold standard and score normalization. Although ROUGE is a popular measure for summarization, we designed a new measure because the main technical challenge in the new sum-marization problem is to extract segments and score their explana-toriness; we focused on evaluating only this component in order to answer the research question about what is the best way of model-ing explanatoriness without being affected by other factors such as redundancy. Moreover, ROUGE has a problem in matching con-tents with different expressions. For ROUGE evaluation, we would compare our outputs with the same k length of gold standard human summaries. Thus, two system summaries with the same informa-tion but extracted different expressions may be assigned different performance measurements by ROUGE depending on which ex-pression was included into the gold standard summary. We could use concatenation of all the explanatory sentences as a gold stan-dard summary. However, the ROUGE score would not be within [0 . 0 , 1 . 0] , thus scores will be neither easily interpretable nor com-parable to others with different length of model summaries.
We hypothesize that the proposed summarization method would work better than a standard text summarization method that mostly implements the popularity heuristic. We use LexRank summa-rization algorithm as a baseline to test this hypothesis. Another baseline for explanatory scoring function is TF-IDF-based scoring function BM 25 E proposed in the previous work [8].

As baseline explanatory segment boundary identification meth-ods, we use three different approaches. One simple way of defining boundary is using a maximum boundary, the entire sentence ( SenOrder ). As the opposite extreme of sentence boundary, we evaluate any subsequence of words as candidate boundaries by our scoring function and choose the best scored text segment as our ex-traction ( E xhaustive ). Otherwise, because it is likely that explana-tory phrase boundary matches with syntax boundary, we can use subtrees of parse tree as our text segment candidate ( ParseTree ). By using parse tree, we can shrink the number of candidate seg-ments to evaluate compared to the exhaustive search, and they are also more likely to have meaningful boundaries. In our experi-ments, we use Stanford Parser [10].

Our emphasis on solely unsupervised approaches is very well justified since such an approach can in principle be applicable to any domain without requiring any manual effort. Any previous work with supervised learning is not comparable to our methods. Moreover, the prediction results of our method can be easily incor-porated into a supervised learning method as an additional feature to improve performance in case there is training data.
 Table 1: Comparison of various methods for scoring explana-toriness (EC @ k score). In the bottom 4 rows, a  X  indicates that the improvement of the corresponding HMM run over the strong baseline LexRank is statistically significant with 95% confidence interval. The best performance for each measure and data set is marked as bold.

T able 1 shows performance comparison of various methods. In most cases, our proposed methods show higher EC values than baselines. We can see that the HMM methods clearly outperform the direct adaptation of TF-IDF (BM25 E ). Even compared to the strong baseline LexRank, HMM E -Rmv shows statistically signifi-cant improvement with 95% confidence level. Different candidate generation methods (SenOrder, Exhaustive, ParseTree) show simi-lar performance.
We further examine different variations of the proposed HMM-based method to understand which variation works the best. The bottom part of Table 1 shows comparison of these variations. The proposed basic HMM method has no parameter to set. The param-eters for smoothing and feedback with HMM were set heuristically to reasonable values based on their interpretations (  X  = 10000 ,  X  1 = 5 ). Although we use fixed values with unsupervised learning setup, further tuning them will possibly lead to further improve-ment of performance.

In general, HMM E -Rmv and HMM E -LP show better perfor-mance than HMM E . We performed significance test between HMM and HMM E -Rmv/HMM E -LP, and some values of HMM E -Rmv/ HMM E -LP showed significant improvement over HMM E with 95% confidence level. Sentence removal and Laplacian smoothing avoid overfitting, which may explain why they can increase performance.
HMM E -FB shows similar performance to HMM E . To under-stand the difference between HMM E -FB and HMM E , we addi-tionally check how many  X  X ntire X  explanatory phrases labeled by humans are in the generated summary. EC measure allows partial extraction of an explanatory segment and rewards it in proportion to the overlapped character length to the gold standard. However, the partial extraction may degrade the readability of the output sum-mary. We will check this issue again with an example summary later. For the full phrase extraction task, HMM E -FB shows better performance than HMM E . Feedback increases probability of ini-tially retrieved words in explanatory language model. Therefore, the modified HMM would tend to attract similar words around the initially retrieved words; thus, it is more likely to retrieve the longer phrase as an explanatory candidate. Thus, although HMM E -FB has similar explanatory information to HMM E , HMM E -FB extracts more full phrases, and the output summary possibly has better read-ability. Table 2: Example summary output comparison between ex-planatory summary (ExpSum, using HMM E -RMV) and base-line summary (Base, using LexRank) about positive opinion about the location of Hotel2 (top) and negative opinion about the facility of Hotel1 (bottom).

When generating these sample results, we applied simple redu n-dancy removal technique. We pick text segments from the top of the ranked list one by one. However, if more than 50% of the con-tent of the next candidate text segment is covered by already se-lected texts, we skip and do not include the candidate text to the summary. We add texts to the output summary until the summary reaches 500 characters.

Top of Table 2 shows example summaries about  X  X ositive opin-ion about the location of Hotel2 X  (we anonymized some names which may reveal the identity of the target hotel.) This exam-ple clearly shows the benefits of the explanatory summary over the normal summary. Explanatory summary shows good details about  X  X ocation X  of the target hotel such as  X  X onvenient location to both [Attraction A] and [Attraction B] X , and  X  X rivate entrance to the [Attraction B] theme park and within easy walking X . On the other hand, in the normal summary, we can see many repetitions of  X  X ood location X  because it is popular contents in the input data. We already know that the topic is about  X  X ositive X  opinion of the hotel location. Thus, a large portion of space in the normal sum-mary is consumed by the already known fact from the given topic. Moreover, some sentences in the normal summary include nonrel-evant information to the given topic (location) such as  X  X he rooms were fine X  and  X  X very other level of service was great X . These c on-tents are actually filtered out in explanatory summary because they would have high frequency in background data which includes all other aspects (e.g. room, service). This also shows why we need within-sentence segment extraction.

Bottom of Table 2 shows another example summary compari-son about  X  X egative opinion about the facility of Hotel1 X . In this case, the baseline summary shows some details, but all of them are about a pool. For this topic, there were many people complain-ing about the pool; thus, all the top ranked sentences of LexRank results were dominated by the opinions about a pool even after ap-plying redundancy removal. We additionally examined the entire ranking by LexRank and found out that texts about elevator and parking were ranked too low to be selected as an output summary. On the other hand, explanatory summary not only includes details opinions about a pool which the baseline summary contains ( X  X ool is small and not warm enough X ), but it also could catch other com-plaints about elevator/parking and rank them high, which were dis-criminative information in the facility topic.
 In spite of benefits, explanatory summary still has limitations. As we discussed before, a mistake in boundary detection may lead to partial extraction and result in losing the entire information. In the second example summary,  X  X ounge chairs looked like they were once X  cannot give us information because the segmentation did not include the last part of the sentence. Also, extracting within-sentence segments has risk to lose context, or we may have mean-ingless text segments such as  X  X s X  and  X  X here X . They are stop words that usually do not deliver meaningful information by them-selves. To overcome this limitation, we could introduce simple heuristics to filter out phrases containing only stop words. A more elegant way of handling this problem would be introducing an ad-ditional layer of background data set. In addition to the current comparison to the background, if we also check discriminativeness of information to general word corpus, stop words would less likely to be selected as explanatory information. Overcoming these limi-tations is remained as our future work. However, most of extracted phrases are still quite readable and informative, and the benefit of getting explanatory information is fairly clear.
In this paper, we introduced a novel opinion summarization prob-lem called compact explanatory opinion summarization (CEOS). The key challenge in solving this problem is to automatically iden-tify explanatory text segments. We proposed a unified HMM-based framework for explanatory text segment extraction. Experimen-tal results using two new test sets and a measure show that the proposed methods outperform general text summarization methods such as LexRank, and especially HMM-based methods with mod-ified explanatory language model is the most effective in selecting explanatory text segments.

Our work is the first step toward studying the new problem of explanatory opinion summarization. With the two data sets and an appropriate measure, we have paved the way for further study-ing this problem. As future work, we can further explore different ways of estimating the proposed probabilistic models. In this pa-per, we more focused on statistical methods that are applicable to large scale data without the need of training sets and that may even be generalized to multiple languages. Using more complex fea-tures such as n-grams, frequent patterns, and linguistic features can further improve the performance of our algorithm. Furthermore, we can explore abstractive explanatory summarization instead of extractive summarization.
 This material is based upon work supported in part by the National Science Foundation under Grant Number CNS-1027965 and by an HP Innovation Research Award.
