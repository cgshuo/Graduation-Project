 ORIGINAL PAPER Asif Ekbal  X  Sriparna Saha Abstract In this paper, the concept of finding an appropriate classifier ensemble for named entity recognition is posed as a multiobjective optimization (MOO) problem. Our under-lying assumption is that instead of searching for the best-fitting feature set for a particular classifier, ensembling of several classifiers those are trained using different feature representations could be a more fruitful approach, but it is crucial to determine the appropriate subset of classifiers that are most suitable for the ensemble. We use three heteroge-nous classifiers namely maximum entropy, conditional ran-dom field, and support vector machine in order to build a number of models depending upon the various representa-tions of the available features. The proposed MOO-based ensemble technique is evaluated for three resource-con-strained languages, namely Bengali, Hindi, and Telugu. Evaluation results yield the recall, precision, and F -measure values of 92.21, 92.72, and 92.46%, respectively, for Bengali; 97.07, 89.63, and 93.20%, respectively, for Hindi; and 80.79, 93.18, and 86.54%, respectively, for Telugu. We also eval-uate our proposed technique with the CoNLL-2003 shared task English data sets that yield the recall, precision, and F -measure values of 89.72, 89.84, and 89.78%, respectively. Experimental results show that the classifier ensemble iden-tified by our proposed MOO-based approach outperforms all the individual classifiers, two different conventional baseline ensembles, and the classifier ensemble identified by a single objective X  X ased approach. In a part of the paper, we formu-late the problem of feature selection in any classifier under the MOO framework and show that our proposed classifier ensemble attains superior performance to it.
 Keywords Natural language processing  X  Named entity recognition  X  Maximum entropy  X  Conditional random field  X  Support vector machine  X  Multiobjective optimization (MOO)  X  Genetic algorithm  X  Classifier ensemble  X  Weighted voting 1 Introduction Named entity recognition (NER) is an important tool in almost all natural language processing (NLP) application areas such as information extraction [ 1 ], machine translation [ 2 ], question answering [ 3 ], and automatic summarization [ 4 ] etc. The main task of NER can be thought of as a two-step procedure that involves identifying every word/term and clas-sifying them into some predetermined categories like per-son name, location name, organization name, miscellaneous name (date, time, percentage and monetary expressions etc.) and  X  X one-of-the-above X .

The existing approaches of NER can be grouped into three main categories, namely rule-based, machine learning (ML) X  based, and hybrid approach. Rule-based approaches focus on extracting names using a number of handcrafted rules. Generally, these systems [ 5  X  8 ] consist of a set of patterns using grammatical (e.g., part of speech), syntactic (e.g., word precedence), and orthographic features (e.g., capitalization) in combination with dictionaries. These kinds of systems yield results for restricted domains and are capable of detect-ing complex entities that are difficult with machine learn-ing models. However, rule-based systems lack the ability of portability and robustness, and furthermore, the high cost of the maintenance of rules increases even when the data are slightly changed. These types of systems are often domain dependent, language specific and do not necessarily adapt well to new domains and/or languages.

In contrast, ML approaches have gained more attention to the researchers for NER because these are easily train-able, adaptable to different domains and languages as well as their maintenance is also less expensive. There are three existing ML techniques, namely supervised, semi-super-vised, and unsupervised. The idea of supervised learning is to study the features of positive and negative exam-ple of NE over a large collection of annotated docu-ments and design rules that capture instances of a given type. The widely used supervised ML approaches used in NER are Hidden Markov Model (HMM) [ 9 , 10 ], maximum entropy (ME) [ 11 , 12 ], decision tree [ 13 ], and conditional random field (CRF) [ 14 , 15 ]. The main shortcoming of supervised learning is the requirement of a large anno-tated corpus to obtain the reasonable performance, but this is often a great problem for working with the resource poor languages. The creation of large amount of anno-tated data is both cost-sensitive and time-consuming. The unavailability of such resources and the prohibitive cost of creating them lead to two alternative learning methods: semi-supervised and unsupervised. The term  X  X emi-supervised X  (or,  X  X eakly supervised X ) is relatively recent and more use-ful specifically for the resource poor languages. One com-monly used technique for semi-supervised approach [ 16  X  19 ] is  X  X ootstrapping X  that involves a small degree of supervi-sion, such as a set of seeds, for starting the learning process. Clustering is a typical approach in unsupervised learning. For example, one can try to gather NEs from clustered groups based on the similarity of context. There are also some other unsupervised methods. Basically, these techniques [ 20 , 21 ] and [ 22 , 23 ] rely on lexical resources (e.g., WordNet), lexi-cal patterns, and statistics computed on a large unannotated corpus. In hybrid systems [ 23 , 24 ], the goal is to combine rule-based and ML-based methods and develop new methods using strongest points from each method. Although, hybrid approaches can get better result than some other approaches, but weakness of handcraft rule-based NER surfaces when there is a need to change the domain of data.

Besides these, there are number of other existing works in the area of NER. Most of the languages covered include English, most of the European languages, and some of the Asian languages like Chinese, Japanese, and Korean. India is a multilingual country with great linguistic and cultural diversities. People speak in 22 different official languages that are derived from almost all the dominant linguistic fam-ilies in the world, but these are only the official languages, and there are some more speaking languages too. However, the works related to NER in Indian languages have started to emerge only very recently. Named entity (NE) identifi-cation in Indian languages is more difficult and challenging compared with others due to a number of reasons such as: 1. Indian languages lack capitalization information that acts 2. Indian names are more diverse and lot of these appear in 3. Indian languages are resource-constrained, i.e., corpus, 4. Indian languages are highly inflected and provide rich As part of the Indian languages, there are some exist-ing works that cover a few languages like Bengali, Hindi, and Telugu. For Bengali, the existing works are based on unsupervised lexical pattern learning [ 25 ], HMM [ 26 ] that considers additional context information during emission probabilities, CRF [ 27 ], SVM [ 28 ], and voting [ 29 ]. The works on Hindi can be found in [ 30 ] with a CRF approach, [ 31 ] using rules and in [ 32 ] using a hybrid feature set (lin-guistic and statistical) based ME approach. Various systems on NER in Indian languages using different approaches are reported in the proceedings of the IJCNLP-08 Workshop on NER for South and South East Asian Languages (NERS-SEAL). 1 As part of this workshop, Gali et al. [ 33 ] reported a CRF-based system using some commonly used features, post-processing technique based on some rules for Bengali, Hindi, Oriya, Telugu, and Urdu. Srikanth and Murthy [ 34 ] reported a system for Telugu with person, location, and orga-nization tags. Gali et al. [ 35 ] presented a CRF-based system for English, Telugu, and Hindi, where they suggested that a character n-gram-based approach is more effective than word-based models to increase the recall of NER system.
The performance of any classification technique depends on the features of training and test data sets. Feature selec-tion, also known as variable selection, feature reduction, attri-bute selection, or variable subset selection, is the technique, commonly used in machine learning, of selecting a subset of relevant features for building robust learning models. Appro-priate feature selection plays a crucial role to improve the performance in any classification model as it does not pro-vide a method for automatic feature selection, and heuristics are usually used for this task. Rather than selecting the best-fitting feature set, ensembling several homogeneous/heter-ogeneous NER systems where each one is based on dif-ferent feature representations and/or different classification techniques can be considered as an alternative research direction. Ensembling of classifiers is done to increase the generalization accuracy that greatly depends on the diversity of each individual classifier as well as on their individual per-formance, but it is a crucial step to determine the proper sub-set of classifiers (from a superset) that can construct the final ensemble in a most efficient way. Some optimization tech-niques like genetic algorithm (GA) [ 36 ] may be used to deter-mine this appropriate subset of classifiers, but these single objective optimization techniques can only optimize a sin-gle quality measure, e.g., recall, precision, or F -measure at a time. In reality, sometimes a single measure like this cannot always capture the quality of a good ensembling reliably. But sometimes depending upon the requirement in many applica-tion domains, it may be essential for a good ensemble to have its all the parameters, e.g., recall, precision, and F -measure optimized simultaneously. In order to achieve this, in the present work, we propose a new classifier ensemble tech-nique based on multiobjective optimization (MOO) [ 37 ]. The new technique enjoys the advantages of both GA and MOO.
Multiobjective optimization (MOO) problem, typically. has a rather different perspective. While in single objective optimization, there is only one global optimum, in multiob-jective optimization, there is a set of global optimum solu-tions called Pareto optimal set [ 37 ]. All these solutions have equal importance. A single objective approximation of mul-tiple objectives, in form of a weighted sum, unfortunately often fails to capture the full Pareto front. Over the past decade, a number of multiobjective evolutionary algorithms (MOEAs) have been suggested [ 38 , 39 ]. The prime motiva-tion for using evolutionary algorithms ( EA s) to solve mul-tiobjective problems is their population-based nature and ability to find multiple optima simultaneously. A simple EA can be easily extended to maintain a diverse set of solutions.
In the literature [ 29 , 40 ], it has been shown that the com-bination of more than one classifiers could be more effective compared with any single one. In Indian languages, Ekbal and Bandyopadhyay [ 29 ] presented a voted NER system for Bengali by combining three different classifiers, namely ME, CRF, and SVM. They used word-level and contextual fea-tures, gazetteers, post-processing techniques, and unlabeled data to improve the performance in each of the classifiers as well as of the overall system. To the best performing system at CoNLL-2003 shared task [ 41 ] was presented by Florian et al. [ 40 ]. They presented a classifier-combination experimental framework for NER in which four diverse classifiers namely robust linear classifier, ME, transformation-based learning, and HMM, were combined together with some voting tech-niques.

In the present work, we use three different classifica-tion techniques, ME, CRF, and SVM as the base classifi-ers. Depending on the various combinations of the available features and/or feature templates, different versions of these classifiers are made. All the classifiers make use of the language-independent features in the form of different contextual and orthographic word-level features that are applicable for almost all the languages. The features are lan-guage independent in the sense that these do not require any domain knowledge and/or external language resources for their extraction. Thereafter, a recently developed and widely used MOO technique, NSGA-II [ 42 ], is used to search for the appropriate classifier combination. Classifiers are encoded in the chromosomes. Two conflicting quality measures, namely recall and precision, are used as the objective functions. The values of these objective functions are computed from the threefold cross-validation on the training data. The pro-posed approach is evaluated for three resource-constrained languages, namely Bengali, Hindi, and Telugu. In terms of native speakers, Bengali ranks fifth in the world, second in India, and first in Bangladesh. Hindi is the third most spoken language in the world and the national language in India. Telugu is one of the popular languages and predominantly spoken in the southern part of India. For NER in Bengali, we manually annotate a portion, containing approximately 250K wordforms, of the Bengali news corpus [ 43 ] with a coarse-grained NE tagset of four tags namely, PER ( Person name ), LOC ( Location name ), ORG ( Organization name ), and MISC ( Miscellaneous name ). The miscellaneous entities (MISC) denote date, time, number, monetary expressions, and measurement expressions. We also use the IJCNLP-08 NER on South and South East Asian Languages (NERS-SEAL) 2 Shared task data of around 100K wordforms that were originally annotated with a fine-grained tagset of twelve tags. For Hindi and Telugu, we use the data sets obtained from the NERSSEAL shared task. Evaluation results show the effectiveness of the proposed approach with the overall recall, precision, and F -measure values of 92.21, 92.72, and 92.46%, respectively, for Bengali; 97.07, 89.63, and 93.20%, respectively, for Hindi; and 80.79, 93.18 and 86.54%, respec-tively, for Telugu. Thereafter, the proposed technique is eval-uated for CoNLL-2003 shared task [ 41 ] English data sets. It yields the recall, precision, and F -measure values of 89.72, 89.84, and 89.78%, respectively. Evaluation results also show that the classifier ensemble identified by our proposed multi-objective-based approach outperforms all the individual clas-sifiers, two different conventional baseline ensembles and a single objective GA-based classifier ensemble technique [ 44 ] for all the languages.

In a part of the paper, we have also formulated the problem of feature selection in any classifier under the MOO frame-work. Thereafter, a MOO-based technique is proposed to solve this problem. We show that the proposed feature selec-tion technique is more efficient than the heuristic-based fea-ture selection of ME framework. The proposed technique is evaluated for all the three Indian languages, namely Bengali, Hindi, and Telugu.
Experimental results also suggest that the MOO-based classifier selection performs better than MOO-based feature selection.

The main contributions of our work are twofold, i.e., 1. A novel technique for classifier ensemble based on MOO 2. A MOO-based feature selection technique is proposed
The main motivations and/or advantages of our work are as follows: 1. The proposed techniques are language independent and 2. The proposed framework of classifier ensemble is appli-3. Note that our work proposes a novel way of ensembling 4. Another important motivation of MOO-based technique
The rest of the paper is organized as follows. A brief over-view of the base classifiers, namely ME, CRF, and SVM, for NER are briefly described in Sect. 2 . Sect. 3 depicts the set of NE features that we have used for NER in three leading Indian languages, namely Bengali, Hindi, and Telugu. A brief discussion on MOO is provided in Sect. 4 . The problem of classifier ensemble is formulated under MOO in Sect. 5 .We discuss our proposed MOO-based ensemble technique elab-orately in Sect. 6 . Section 7 reports the detailed evaluation results that include the description of data sets in Sect. 7.1 and the results with discussions in Sect. 7.2 . In Sect. 8 ,we present our proposed technique of MOO-based feature selec-tion. The results with the various ensemble sizes are reported in Sect. 9 . Section 10 presents the evaluation results with the original data sets of IJCNLP-08 NERSSEAL shared task. Finally, we conclude in Sect. 11 . 2 Base classifiers for NER We use Maximum Entropy (ME), Conditional Random Field (CRF) and Support Vector Machine (SVM) as the base clas-sifiers to construct the ensemble system based on weighted voting. Brief descriptions of these classifiers are presented below. 2.1 Maximum entropy framework for NER The ME framework estimates probabilities based on the prin-ciple of making as few assumptions as possible, other than the constraints imposed. Such constraints are derived from the training data, expressing some relationships between fea-tures and outcome. The probability distribution that satisfies the above property is the one with the highest entropy. It is unique, agrees with the maximum likelihood distribution, and has the exponential form P ( t | h ) = where t is the NE tag, h is the context (or history), f j are the features with associated weight  X  j , and Z normalization function.
 The problem of NER can be formally stated as follows. Given a sequence of words w 1 ,...,w n , we want to find the corresponding sequence of NE tags t 1 ,..., t n , drawn from a set of tags T , which satisfies: P ( t 1 ,..., t n | w 1 ,...,w n ) = where h i is the context for the word w i .

The features are, in general, binary valued functions, which associate a NE tag with various elements of the con-text. For example: f ( h , t ) = 1ifword ( h ) = sachIn and t = Person name
We use the OpenNLP Java-based MaxEnt package 3 for the computation of the values of the parameters  X  j . This allows to concentrate on selecting the features, which best character-ize the problem instead of worrying about assigning the rela-tive weights to the features. We use the Generalized Iterative Scaling [ 45 ] algorithm to estimate the MaxEnt parameters. 2.2 Conditional random field framework for NER Conditional Random Fields (CRFs) [ 15 ] are undirected graphical models, a special case of which corresponds to con-ditionally trained probabilistic finite state automata. Being conditionally trained, these CRFs can easily incorporate a large number of arbitrary, non-independent features while still having efficient procedures for non-greedy finite-state inference and training. CRFs have shown success in various sequence modeling tasks including noun phrase segmenta-tion [ 46 ] and table extraction [ 47 ].

CRF is used to calculate the conditional probability of values on designated output nodes given values on other des-ignated input nodes. The conditional probability of a state sequence s = s 1 , s 2 ,..., s T given an observation sequence o = o P  X  ( s | o ) = where f k ( s t  X  1 , s t , o , t ) is a feature function whose weight is to be learned via training. The values of the feature func-tions may range between  X  X  X  ,... + X  , but typically they are binary. To make all conditional probabilities sum up to 1, we must calculate the normalization factor, Z which as in HMMs, can be obtained efficiently by dynamic programming.

To train a CRF, the objective function to be maximized is the penalized log-likelihood of the state sequences given the observation sequences: L  X  = ond sum corresponds to a zero-mean,  X  2 -variance Gauss-ian prior over parameters, which facilitates optimization by making the likelihood surface strictly convex. Here, we set parameters  X  to maximize the penalized log-likelihood using limited-memory BFGS [ 46 ], a quasi-Newton method that is significantly more efficient, which results in only minor changes in accuracy due to changes in  X  .

When applying CRFs to the NER problem, an observation sequence is a token of a sentence or document of text and the state sequence is its corresponding label sequence.
A feature function f k ( s t  X  1 , s t , o , t ) has a value of 0 for most cases and is only set to be 1, when s t  X  1 , s t are certain states and the observation has certain properties. We have used the C ++ -based CRF ++ package, 4 a simple, customiz-able, and open source implementation of CRF for segmenting or labeling sequential data. 2.3 Support vector machine framework for NER In the field of NLP, support vector machines (SVMs) [ 48 ] are applied to text categorization and are reported to have achieved high accuracy without falling into over-fitting even though with a large number of words taken as the features [ 49 , 50 ]. Suppose, we have a set of training data for a two-class problem: { ( x 1 , y 1 ),...,( x N , y N ) } , where x a feature vector of the i -th sample in the training data and y  X  X + 1 ,  X  1 } is the class to which x form, a SVM learns a linear hyperplane that separates the set of positive examples from the set of negative examples with maximal margin (the margin is defined as the distance of the hyperplane to the nearest of the positive and negative examples). In basic SVMs framework, we try to separate the positive and negative examples by the hyperplane written as: ( w . x ) + b = 0 w  X  R n , b  X  R .
 SVMs find the  X  X ptimal X  hyperplane (optimal parameter w, b ) , which separates the training data into two classes pre-cisely.

The linear separator is defined by two elements: a weight vector w (with one component for each feature) and a bias b that stands for the distance of the hyperplane to the origin. The classification rule of a SVM is: sgn ( f ( x , w , b )) (3) f ( x , w , b ) = w . x + b (4) being x the example to be classified. In the linearly separa-ble case, learning the maximal margin hyperplane ( w , b ) be stated as a convex quadratic optimization problem with a unique solution: minimize || w || , subject to the constraints (one for each training example): y ( w . x
The SVM model has an equivalent dual formulation, char-acterized by a weight vector  X  andabias b . In this case, contains one weight for each training vector, indicating the importance of this vector in the solution. Vectors with non-null weights are called support vectors . The dual classifica-tion rule is: f ( x , X , b ) = The  X  vector can be calculated also as a quadratic optimi-zation problem. Given the optimal  X   X  vector of the dual quadratic optimization problem, the weight vector w  X  that realizes the maximal margin hyperplane is calculated as: w The b  X  has also a simple expression in terms of w  X  and the training examples ( x i , y i ) N i = 1 .

The advantage of the dual formulation is that efficient learning of non-linear SVM separators, by introducing ker-nel functions . Technically, a kernel function calculates a dot product between two vectors that have been (non-linearly) mapped into a high-dimensional feature space. Since there is no need to perform this mapping explicitly, the training is still feasible although the dimension of the real feature space can be very high or even infinite.

By simply substituting every dot product of x i and x in dual form with any kernel function K ( x i , x j ) , SVMs can handle non-linear hypotheses. Among the many kinds of ker-nel functions available, we will focus on the d -th polynomial kernel : K ( x Use of d -th polynomial kernel function allows us to build an optimal separating hyperplane that takes into account all combination of features up to d .

Support vector machines have advantage over conven-tional statistical learning algorithms from the following two aspects: 1. SVMs have high generalization performance indepen-2. SVMs can carry out their learning with all combinations
We develop our system using SVM [ 48 , 49 ] that performs classification by constructing an N-dimensional hyperplane that optimally separates data into two categories. We have used YamCha 5 toolkit, an SVM-based tool for detecting clas-ses in documents and formulating the NER task as a sequen-tial labeling problem. Here, the pairwise multiclass decision method and the polynomial kernel function are used. We use TinySVM-0.07 6 classifier. 3 Named entity features The main features for the NER task are identified based on the different possible combinations of available word and tag contexts. We use the following features for construct-ing the various classifiers based on the ME, CRF, and SVM frameworks. Most of these features are language indepen-dent in nature and can be easily obtained for almost all the languages. The features are language independent in the sense that these do not need any domain-dependent resources and/or language-specific rules for their generation. We also define a semantically motivated feature, based on global con-text information, that proved to be very effective to improve the overall system performance. 1. Context words : These are the preceding and suc-2. Word suffix and prefix : Fixed length (say, n )word 3. First word : This is a binary valued feature that checks 4. Length of the word : This binary valued feature checks 5. Infrequent word : This is a binary valued feature that 6. Last word of sentence : This feature checks whether the 7. Capitalization : This is a binary valued feature that 8. Part-of-speech (POS) information : POS information 9. Chunk information : This is useful for NE identi-10. Digit features : Several digit features are defined 11. Dynamic NE information : This is the output label(s) 12. Semantic feature : This feature is semantically moti-4 Multiobjective algorithms The MOO can be formally stated as follows [ 37 ]. Find the vectors x  X  =[ x  X  1 , x  X  2 ,..., x  X  n ] T of decision vari-ables that simultaneously optimize the M objective values { f if any.
 An important concept of MOO is that of domination. In the context of a maximization problem, a solution x is said to dominate x j if  X  k  X  1 , 2 ,..., M , f k ( f ( x
Among a set of solutions P , the non-dominated set of solutions P are those that are not dominated by any mem-ber of the set P . The non-dominated set of the entire search space S is the globally Pareto optimal set. In general, a MOO algorithm usually admits a set of solutions that are not dom-inated by any solution encountered by it. These notions can be explained with a two-objective optimization problem that has five different solutions, as shown in Fig. 1 .
MOO performance measures . In MOO, basically two functionalities must be achieved regarding the obtained solu-tion set [ 37 ]. It should converge as close to the true Pareto optimal front as possible, and it should maintain as diverse a solution set as possible. The first condition clearly ensures that the obtained solutions are near optimal, and the second condition ensures that solutions with a wide range of trade-off objectives are obtained. Clearly, these two tasks can-not be measured with one performance measure adequately. A number of performance measures for MOO algorithm have been suggested in the past. Here, we mainly use one such performance measure. The measure named Minimal-Spacing [ 51 ] reflects the uniformity of the solutions over the non-dominated front. Smaller values of MinimalSpacing for a particular MOO algorithm indicate better performance. Non-dominated sorting genetic algorithm-II (NSGA-II) . Genetic algorithms (GAs) are known to be more effective than classical methods such as weighted metrics, goal pro-gramming [ 37 ], for solving multiobjective problems primar-ily because of their population-based nature. NSGA-II [ 42 ] is widely used in this regard, where initially a random parent population P 0 is created and the population is sorted based on the partial order defined by the non-domination relation. This results in a sequence of non-dominated fronts. Each solution of the population is assigned a fitness value that is equal to its non-domination level in the partial order. Here, functions are minimized using the search capability of GA, i.e., the algo-rithm is trying to find those solutions that are non-dominated with respect to the minimization of the objective values. The authors have assumed the minimization of fitness. A child population Q 0 of size N is created from the parent popu-lation P 0 by using binary tournament selection, recombina-tion, and mutation operators. According to this algorithm, in the t th iteration, a combined population R t = P t + Q formed. The size of R t is 2 N ,assizeofboth P t and Q t is N . All the solutions of R t are sorted according to non-domi-nation. If the total number of solutions belonging to the best non-dominated set F 1 is smaller than N , then F 1 is totally in the order of their ranking. To choose exactly N solutions, the solutions of the last included front are sorted using the crowded comparison operator [ 42 ] and the best among them (i.e., those with lower crowding distance) are selected to fill then used for selection, crossover, and mutation to create a population Q ( t + 1 ) of size N . The pseudocode of NSGA-II is provided in Fig. 2 . 5 Formulation of classifier ensemble selection problem Suppose, the N number of available classifiers are denoted by C 1 ,..., C N .Let, A ={ C i : i = 1 ; N } . The classifier ensemble selection problem is then stated as follows: Find a set of classifiers B that will optimize a function F ( B ) such that: B  X  A . Here, F is a classification qual-ity measure of the combined classifiers. The particular type of problem like NER has mainly three different kinds of classification quality measures, namely recall, precision, and F -measure. Thus, F  X  X  recall , precision , F -measure } .The combination of classifiers is done by either majority voting or weighted voting.

Thus, the classifier ensemble problem under the single objective optimization framework looks as follows:
Find a set of classifiers B such that maximize F ( B ) ; F { recall , precision , F -measure } and B  X  A . Here, we choose F = F -measure as this is a combination of both recall and precision.

The classifier ensemble selection problem can be formu-lated under the MOO framework as below: Find a set of classifiers B such that maximize [ F 1 ( B ), F 2 ( B ) ] ,w F , F Here, B  X  A . We have chosen F 1 = recall and F 2 = precision. 6 Proposed multiobjective GA for classifier ensemble selection A multiobjective GA, along the lines of NSGA-II, is now proposed for solving the classifier ensemble selection prob-lem (CESMOO). Note that although the proposed approach has some similarity in steps with NSGA-II, any other exist-ing multiobjective techniques could have been used as the underlying MOO technique. The new technique enjoys the advantages of both GA and MOO. 6.1 Problem representation using chromosome If the total number of available classifiers is M , then the length of the chromosome is M . As an example, the encod-ing of a particular chromosome is represented in Fig. 3 . Here, M = 19, i.e., total 19 different classifiers are built. The chro-mosome represents an ensemble of 7 classifiers (first, third, fourth, seventh, tenth, eleventh, and twelfth classifiers). The entries of each chromosome are randomly initialized to either 0 or 1. Here, if the i th position of a chromosome is 0, then it represents that i th classifier does not participate in the classi-fier ensemble. Else, the value 1 designates that the i th classi-fier participates in the classifier ensemble. If the population size is P , then all the P number of chromosomes of this population are initialized in the above way. 6.2 Fitness computation Initially, the F -measure values of all the available classifiers are calculated using threefold cross-validation on the avail-able training data. We execute the following steps to compute the fitness value. 1. Suppose, there are N number of classifiers present in an 2. Here, the training data are divided into 3 parts. Each 3. The overall recall, precision, and F -measure values 4. Steps 2 and 3 are repeated 3 times to perform threefold
Motivation of using recall and precision as two objective functions . The definitions of recall and precision are given below:
From the definitions, it is clear that while recall tries to increase the number of tagged entries as much as possible, precision tries to increase the number of correctly tagged entries. These two capture two different classification quali-ties. Often, there is an inverse relationship between recall and precision, where it is possible to increase one at the cost of reducing the other. For example, an information retrieval sys-tem (such as a search engine) can often increase its recall by retrieving more documents at the cost of increasing number of irrelevant documents retrieved (i.e., decreasing precision). This is the underlying motivation of simultaneously opti-mizing these two objectives. The objective functions corre-sponding to a particular chromosome are f 1 = recall a v g f two objective functions are simultaneously optimized using the search capability of NSGA-II.

Note that F -measure is the harmonic mean (i.e., weighted average) of recall and precision. The equation of F -measure is given below: F -measure = But it has been thoroughly discussed in the initial chapters (Chap. 2) of Ref [ 37 ] that weighted sum approach cannot identify all non-dominated solutions. Only solutions located on the convex part of the Pareto front can be found. But as discussed in the last note of introduction, our another impor-tant motivation of this work is to provide the user a set of alternative solutions. Thus, MOO is indeed the best candi-date to solve this problem. Here, no weight is required to combine the objectives (i.e., recall and precision), and thus, no a priori information on the problem is needed.

Moreover optimization of F -measure does not guarantee optimization of both recall and precision. Thus, MOO is, indeed, needed to optimize simultaneously recall and preci-sion. 6.3 Other operators Thereafter, the steps of NSGA-II are executed to optimize the above-mentioned two objective functions. We use crowded binary tournament selection as in NSGA-II, followed by conventional crossover and mutation for the MOO-based classifier ensemble. The most characteristic part of NSGA-II is its elitism operation, where the non-dominated solutions [ 37 ] among the parent and child populations are propagated to the next generation. The near-Pareto-optimal strings of the last generation provide the different solutions to the ensem-ble problem. 6.4 Selection of a solution from the final Pareto optimal In MOO, the algorithms produce a large number of non-dominated solutions [ 37 ] on the final Pareto optimal front. Each of these solutions provides a classifier ensemble. All the solutions are equally important from the algorithmic point of view, but sometimes the user may want only a single solution. Consequently, in this paper, a method of selecting a single solution from the set of solutions is now developed.
For every solution on the final Pareto optimal front, the overall average F -measure value of the classifier ensemble for the threefold cross-validation is calculated on the train-ing data. The solution with the maximum F -measure value is selected as the best solution. Final results on the test data are reported using the classifier ensemble corresponding to this best solution. There can be many other different approaches of selecting a solution from the final Pareto optimal front. 7 Experimental results and discussions We define two different baseline classifier ensemble techniques as below:  X  Baseline 1 :Inthis baseline model, all the individual clas- X  Baseline 2 : All the individual classifiers are combined
We set the following parameter values for NSGA-II: pop-ulation size = 100, number of generations = 50, probability of mutation = 0.2, and probability of crossover = 0.9. 7.1 Data sets for NER Indian languages are resource constrained in nature. For NER, we use a Bengali news corpus [ 43 ], developed from the archive of a leading Bengali newspaper available in the web. We manually annotate a portion of this corpus containing approximately 250 K wordforms with a coarse-grained NE tagset of four tags namely PER ( Person name ), LOC ( Loca-tion name ), ORG ( Organization name ), and MISC ( Mis-cellaneous name ). The Miscellaneous name includes date, time, number, percentages, monetary expressions, and mea-surement expressions. The data are collected mostly from the National , States , Sports domains, and the various sub-domains of District of the newspaper. This annotation was carried out by one of the authors and verified by an expert. We also use the IJCNLP-08 NER on South and South East Asian Languages (NERSSEAL). 8 Shared task data of around 100K wordforms that were originally annotated with a fine-grained tagset of twelve tags. This data are mostly from the agriculture and scientific domains. For Hindi and Telugu, we use approximately 502,913 and 64,026 tokens obtained from the NERSSEAL shared task. The underlying reason to adopt this finer NE tagset in the shared task was to use the systems in some specific NLP applications, particularly in machine translation. The IJCNLP-08 NERSSEAL shared task tagset isshowninTable 1 . One important aspect of the shared task was to identify and classify the maximal NEs as well as the nested NEs, i.e., the constituent parts of a larger NE, but the training data were provided with the type of the maximal NE only. For example, mahatmA gAndhi roDa (Mahatma Gandhi Road) was annotated as location and assigned the tag  X  X EL X  even if mahatmA (Mahatma) and gAndhi (Gandhi) are NE title person (NETP) and person name (NEP), respectively.
The task was to identify mahatmA gAndhi roDa as a NE and classify it as NEL. In addition, mahatmA and gAndhi had to be recognized as NEs of the categories NETP (Title person) and NEP (Person name), respectively.

In the present work, we consider only the tags that denote person names (NEP), location names (NEL), organization names (NEO), number expressions (NEN), time expressions (NETI), and measurement expressions (NEM). The NEN, NETI, and NEM classes are mapped to the MISC class that denotes miscellaneous entities. Other tags of the shared task are mapped to the  X  X ther-than-NE X  category, denoted by  X  X  X . This is in line with the CoNLL-2003 shared task of NER [ 41 ], where four NE classes were considered. We already men-tioned that the primary motivation of using a fine-grained tag-set in the IJCNLP-08 NERSSEAL shared task was to design the NER systems that could be effective to improve perfor-mance in a machine translation system, but our main focus is to develop the system for use in information extraction, and thus, those few classes are not considered. Finally, the tag-set mapping now becomes as shown in Table 2 . For English NER, we use the CoNLL-2003 shared task [ 41 ] data.
In order to properly denote the boundaries of NEs, four basic NE tags are further divided into the format I-TYPE (TYPE  X  PER/LOC/ORG/MISC), which means that the word is inside a NE of type TYPE. Only if two NEs of the same type immediately follow each other, the first word of the second NE will have tag B-TYPE to show that it starts a new NE. For example, the name mahatmA gAndhi [Mahatma Gandhi] is tagged as mahatmA [Mahatma]/I-PER gAndhi [Gandhi]/I-PER, but the names mahatmA gAndhi [Mahatma Gandhi] rabIndrAnAth thAkur [Rabindranath Tagore] are to be tagged as mahatmA [Mahatma]/I-PER gAndhi [Gandhi]/I-PER rabIndrAnAth [Rabindranath]/B-PER thAkur [Tagore]/I-PER if they appear sequentially in the text. This is the standard IOB format that was followed in the CoNLL-2003 shared task [ 41 ]. The English data sets of CoNLL-2003 shared task were already provided in this particular IOB for-mat. We convert the data sets of other languages namely Bengali, Hindi, and Telugu into the IOB format [ 41 ]. Some statistics of the training and test sets are presented in Table 3 . 7.2 Results and discussions We build a number of different ME, CRF, and SVM mod-els by considering the various combinations of the available NE features and/or feature templates. In this particular work, we construct various classifiers by considering the various subsets of the following set of features: various context win-dow within the previous three and next three words, i.e.,  X  3 = w i  X  3 ...w i + 3 of w i , word suffixes and prefixes of length upto three (3+3 different features) or four (4+4 differ-ent features) characters, first word, length, infrequent word, last word in the sentence, several digit features, semantic feature, and dynamic NE information.

A feature vector consisting of the features as described above is extracted for each word in the NE-tagged cor-pus. Now, we have a training data in the form ( W where W i is the i th word and its feature vector and T its corresponding output class. For CRF, we consider various combinations from the set of feature templates as given by, F of w tor of w i ; POS tags of the current and/or the surrounding word(s); Output tag ( t i ) of the previous word(s); Semantic feature}.

For Bengali, we generate 152 different models using ME classifier by varying the available features. Some (21) of these best performing classifiers are shown in Table 4 . Varying the available features and/or feature templates, we construct many CRF-and SVM-based classifiers, out of which 9 CRF-based and 8 SVM-based classifiers are shown in Table 4 . 9 The CRF-based model exhibits best performance with the overall recall, precision, and F -measure values of 89.42, 90.55, and 89.98%, respectively. Thereafter, we apply our proposed multiobjective NSGA-II-based approach to deter-mine the appropriate classifier ensemble. Overall evaluation results of this ensemble technique along with the best indi-vidual classifier, two different baseline ensembles and the single objective optimization-based ensemble approach are reported in Table 5 .
The proposed MOO-based ensemble performs best with the recall, precision, and F -measure values of 92.21, 92.72, and 92.46%, respectively. Results show that the overall per-formance attained by the MOO-based classifier ensemble determined by the proposed algorithm performs better than (an improvement in recall, precision, and F -measure values by 2.79, 2.17, and 2.48 percentage points, respectively) the best individual classifier. The proposed MOO-based ensem-ble technique performs better than the two baseline mod-els with reasonably high margins. It shows the increments of 7.10 and 6.36 percentage points in the F -measure val-ues over Baseline 1 and Baseline 2 , respectively. Evaluation also shows the superiority of MOO-based method over sin-gle objective approach with the increments of 1.13, 1.50, and 1.31 percentage points in recall, precision, and F -measure, respectively. The single objective-based approach is based on GA and optimizes the single classification quality measure, F -measure.

Statistical analysis of variance, (ANOVA) [ 52 ], is per-formed in order to examine whether the MOO-based ensem-ble technique really outperforms the best individual classifier and two baseline ensembles. Our proposed technique is based on GA, a heuristic-based search and optimization technique. The final results provided by GAs largely depend on the seed value of the random variables and values of parameters. Here, we have executed the proposed approach 10 times, and the best among these is reported in Table 6 ,butthetwo base-lines (majority voting and weighted voting) always provide the same results in every run. This is due to the fact that all the available classifiers are ensembled in the baselines .Sofor ANOVA analysis, we consider ten different runs (in maxi-mum of the cases results are almost same) of GA, whereas the same results are used ten times for two baselines . Thereafter, ANOVA analysis is carried out on these outputs. ANOVA tests show that the differences in mean recall, precision, and F -measure values are statistically significant as p value is less than 0.05 in each of the cases. Evaluation results of the ANOVA analysis are shown in Table 6 for MOO-based tech-nique. Results also reveal that the MOO-based approach truly performs better than two baseline approaches, best individual classifier and the single objective GA-based technique.
For the purpose of illustration, the boxplots of the recall, precision, and F -measure values of the final Pareto optimal front for Bengali are shown in Figs. 5 , 6 , and 7 , respectively. The final Pareto optimal front is also shown in Fig. 4 . In order to measure the quality of the obtained Pareto optimal front, MinimalSpacing measurement [ 51 ] is used. Table 7 shows the MinimalSpacing value of the solutions on the final Pareto optimal front obtained by the proposed technique. Smaller values of MinimalSpacing for a particular MOO algorithm indicate better performance.

Thereafter, the proposed approach is evaluated on Hindi and Telugu data sets. The various classifier combinations are reported in Tables 8 and 10 for Hindi and Telugu, respec-tively. We use the same set of features as Bengali. The over-all performance of the best individual classifier, two base-line ensembles, single objective GA-based ensemble and the proposed MOO-based ensemble are presented in Tables 9 and 11 for Hindi and Telugu, respectively. For Hindi, CRF model exhibits the best performance whereas SVM model shows the highest performance for Telugu. The proposed MOO-based ensemble yields the overall recall, precision, and F -measure values as 97.07, 89.63, and 93.20%, respectively, for Hindi, and 80.79, 93.18, and 86.54%, respectively, for Telugu. Results show that the overall performance of the classifier ensemble determined by the proposed algorithm is better than all the other models. For Hindi, it shows the improvement of F -measure values by 3.80, 18.51, 9.56, and 2.66%, respectively, over the best individual classifier, two baseline approaches, and GA-based ensemble.

Results for Telugu show that the overall performance attained by the MOO-based ensemble is reasonably better (an improvement of 3.37, 15.19, and 8.84% recall, precision, and F -measure values, respectively) than the best individual classifier. We also observe the increments of 15.31 and 5.71 percentage F -measure points over Baseline 1 and Baseline 2 , respectively. The proposed algorithm also performs superior with more than 2.85 percentage F -measure value compared with its single objective version. Note that unlike Bengali, the baseline models based on majority voting do not per-form well in comparison with weighted voting for Hindi and Telugu both. This may be due to the nature of the data sets.
The MinimalSpacing measurement of the final Pareto opti-mal front is provided in Table 7 for both the languages, Hindi and Telugu. ANOVA tests for Hindi and Telugu show that the differences in mean recall, precision, and F -measure values of the proposed technique with respect to each of the other four techniques are significant as p value is less than 0.05 in each case. Figure 8 shows the final Pareto optimal front identified by the proposed technique for Hindi. The proposed MOO-based technique provides a large number of alterna-tive solutions. Depending upon the application domain or the particular requirement, any user can select one single desired solution.

It will not be fair to compare the performance of our pro-posed system with that of the previous proposals for Bengali [ 25  X  29 ], Hindi [ 30  X  32 ], and Telugu [ 34 ] as these works use (i) different data sets, (ii) different experimental setup, (iii) more complex set of features, and (iv) domain-dependent knowledge and/or resources. In contrast, our proposed algo-rithm is based on a relatively small set of features that can be easily obtained for almost all the languages, does not make use of any domain-dependent information and thus can be replicated for any resource-poor language very easily. Results on CoNLL-2003 shared task English data set. Finally, we test our proposed algorithm on the benchmark data set of CoNLL-2003 shared task English data [ 41 ]. The various classifier combinations are reported in Table 12 . Each of the classifiers is trained with the same set of features as Bengali except the position of the word and the various digit features . But for English, we use three new features, first one checks capitalization information , second contains POS information , and the third contains chunk information . Experimental results of the best individual classifier, two dif-ferent baseline models, single objective GA-based classifier ensemble, and the MOO-based ensemble method are pre-sented in Table 13 . It shows the overall recall, precision, and F -measure values as 89.72, 89.84, and 89.78%, respectively. Results also show that the proposed MOO-based ensemble outperforms the best individual classifier, two baseline mod-els as well the single objective GA-based ensemble.
For the benchmark English data set, our proposed system achieves the performance better than the best performing sys-tem [ 40 ] of CoNLL-2003 shared task. The best system [ 40 ]at CoNLL-2003 shared task demonstrated the recall, precision, and F -measure values of 88.54, 88.99, and 88.76%, respec-tively. They presented a classifier-combination experimental framework for NER in which four diverse classifiers namely robust linear classifier, ME, transformation-based learning, and HMM were combined. They made use of more complex set of features; gazetteer information, in the form of a list of 50,000 cities, 80,000 proper names, and 3,500 organizations. They also used the outputs of other two NE classifiers, trained on a richer tagset of 32 named categories for improving the system performance. However, they did not report any results on the test set without using any domain knowledge. In con-trast, our proposed algorithm (i) makes use of the features that can be derived for any language with a little effort, (ii) does not use any domain-dependent resources like the gazetteers etc., and (iii) does not make use of any additional NE taggers, but still achieves state-of-the-art performance, which is 1.02 percentage F -measure points higher in comparison with the best system of CoNLL-2003.

Until now, the best reported results for CoNLL-2003 shared task data are in Lin and Wu [ 53 ] that proposed a semi-supervised approach for NER. In addition to word clusters, they used phrase clusters as the features and achieved signifi-cant performance improvement. They proposed an algorithm for clustering tens of millions of phrases and used the result-ing clusters as features in discriminative classifiers. They col-lected 20 million unique queries from an anonymized query log that were found in a 700 billion token web corpus with a minimum frequency count of 100. Thereafter, they con-structed the feature vectors for 20 million phrases using the web data, executed the K-means clustering on the phrases that appeared in the CoNLL training data to obtain K cen-troids, and assigned each of the 20 million phrases to the nearest centroid of clusters. They used CRF as a base clas-sifier and experimented with 48 various feature templates. They obtained the F -measure value of 90.90%, which is 1.12 points higher than our proposed system. In addition to the above-mentioned two systems [ 40 , 53 ], we also present the comparative results with some other well-known exist-ing techniques in Table 14 . Suzuki and Isozaki [ 54 ]runa baseline discriminative classifier on unlabeled data to gener-ate pseudo-examples, which are then used to train a different type of classifier for the same problem. Later on, they used the automatically labeled corpus to train HMMs. Chieu and Ng [ 55 ] showed how the use of global information, in addi-tion to the local ones, can improve the model performance. It is to be noted that our system achieves 7.09 points higher F -measure value in comparison with the stacked, voted model, proposed by Wu et al. [ 56 ] in the CoNLL-2003 shared task. 8 Feature selection using multiobjective optimization The performance of any classification technique depends on the features of training and test data sets. Feature selection is the technique of selecting a subset of relevant features for building robust classifier. In a machine learning approach, feature selection is an optimization problem that involves choosing an appropriate feature subset. In ME-based mod-els, relevant feature selection is a crucial problem and also a key issue to improve the classifier X  X  performance. Maxi-mum entropy does not provide a method for automatic feature selection. Usually, heuristics are used to find the appropriate set of features in the ME model. In this section, the prob-lem of feature selection is posed as a MOO [ 37 ] problem. Generally, feature selection problems are solved using some single objective optimization techniques like GA [ 36 ], but as already described in the introduction, these single objective optimization techniques can only optimize a single quality measures, for e.g., recall, precision or F -measure at a time. Sometimes, a single measure cannot capture the quality of a good classifier reliably. A good classifier should have all its parameters optimized simultaneously in comparison with the high value of any parameter. Moreover, F -measure is a combination of both recall and precision. Thus, here, we simultaneously optimize both recall and precision in order to determine the best feature combination for NER under the ME framework. In order to achieve this, a MOO technique [ 37 ] is used. 8.1 Proposed approach A multiobjective GA, along the lines of NSGA-II, is used for solving the feature selection problem. The proposed approach selects appropriate features in ME framework for three Indian languages, namely Bengali, Hindi, and Telugu.
Chromosome representation and population initiali-zation. If the total number of features is F , then the length of the chromosome is F . As an example, the encoding of a particular chromosome is represented in Fig. 9 . Here, F = 12 (i.e., total 12 different features are available). The chro-mosome represents the use of 7 features for constructing a classifier (first, third, fourth, seventh, tenth, eleventh, and twelfth features). The entries of each chromosome are ran-domly initialized to either 0 or 1. Here, if the i th position of a chromosome is 0, then it represents that i th feature does not participate in constructing the classifier. Else, if it is 1, then the i th feature participates in constructing the classifier.
If the population size is P , then all the P number of chro-mosomes of this population are initialized in the above way.
Fitness Computation. For the fitness computation, the following steps are executed. 1. Suppose, there are N number of features present in a 2. Construct a classifier with only these N features. 3. Here, initially the training data are divided into 3 parts. 4. Now, the overall recall, precision, and F -measure values 5. Steps 2 and 3 are repeated 3 times to perform threefold Other Operators. Thereafter, the steps of NSGA-II (c.f. Fig. 2 ) are executed to optimize the above-mentioned two objective functions. 8.2 Results of feature selection approach We set the following parameter values for NSGA-II: popu-lation size = 100, number of generations = 50, probability of mutation = 0.2, and probability of crossover = 0.9. We use ME as the base classifier.

Here, the following features are considered: Context of size five (previous two, current and next two) or three (previ-ous, current, and next) words, Prefixes of length upto three or four characters (3 or 4 features), Suffixes of length upto three or four characters (3 or 4 features), First word of the sentence, Length of the word, Infrequent word, Position of the word, digitComma, digitPercentage, digitDot, digitSlash, digitHy-phen, digitFour, digitTwo, semantic feature and dynamic NE information.
 The feature selection algorithm is run for all the three Indian languages, namely Bengali, Hindi, and Telugu. The best solution of the proposed MOO-based feature selection technique finally selects the features as shown in Table 15 for these languages. In the table, meanings of the notations are as follows: C [ X  i , + j ] : context spanning from the previ-ous i th word to the next j th word with the current token at position 0; Pre i and Su f i : prefixes and suffixes of character sequences up to i of the current word, respectively; t i output class of the current token; and SeM i : semantic feature of the current token.

The recall, precision, and F -measure values of the best individual classifier trained using the feature set identified by the best solution of the proposed MOO-based technique are 86.05, 88.14, and 87.08%, respectively, for Bengali. Here, the best solution of the final Pareto optimal front is the solution with the highest F -measure value of the threefold cross-validation on the training data. We have also exe-cuted the proposed MOO-based classifier ensemble selec-tion approach on the developed 152 ME-based classifiers to determine the appropriate classifier ensemble. The pro-posed approach yields the recall, precision, and F -measure values of 87.32, 90.02, and 88.65%, respectively. Thereaf-ter, we execute the feature selection algorithm for Hindi and Telugu data sets. Evaluation results yield the recall, preci-sion, and F -measure values of 87.01, 91.92, and 89.40%, respectively, for Hindi and 74.80, 87.58 and 80.69%, respec-tively, for Telugu. Overall results of the feature selection technique and the MOO-based classifier ensemble are pre-sented in Table 16 . For each of the languages, results show that our proposed MOO-based classifier ensemble performs superior compared with the baseline model developed using the MOO-based feature selection approach, but it is also to be noted that the MOO-based feature selection yields better performance in comparison with the heuristic-based feature selection of ME model for each of the languages. The proposed MOO-based feature selection technique shows the increments of 0.56, 3.12, and 4.05 percentage F -mea-sure points (c.f. Tables 4 , 8 , 10 ) over the best individual ME-based classifiers for Bengali, Hindi, and Telugu, respec-tively.
 9 Results for Bengali by varying the ensemble size For the purpose of illustration, we experiment with the var-ious ensemble sizes for Bengali. The results are reported in Table 17 . Note that increasing the ensemble size increases the length of the chromosome and thereby increases the size of the search space. As an example, for the total number of classifiers = 140, total length of the chromosome will be 140. This, in turn, increases the size of the search space. Thus, it is very difficult to find the appropriate classifier ensemble. Results also suggest that increasing the number of classifiers may not always increase the overall performance of the sys-tem. If more good performing/complimentary classifiers will be added in the total set of classifiers, then the overall sys-tem performance may increase, but in general, after a certain size of the classifier ensemble, system performance does not improve with the increase in ensemble size. The following table shows that the system achieves the recall, precision, and F -measure values of 87.32, 90.02, and 88.65%, respectively, with the ensemble that is formed with the 80 best performing ME-based classifiers, but if we increase the number of classi-fiers to either 140 or 152, the performance does not improve, but inclusion of heterogenous classifiers improves the overall performance of the system. Though, the overall performance increases until we reach the size of the ensemble to 169. 10 Results using original data sets of IJCNLP-08 shared In this section, we report the results of our proposed MOO-based technique for Bengali, Hindi, and Telugu using the original data sets of IJCNLP-08 NERSSEAL shared task. The original data sets were annotated with a fine-grained tagset of 12 tags as shown in Table 1 . One important aspect of the shared task was to identify and classify the maximal NEs as well as the nested NEs, i.e., the constituent parts of a larger NE, but the training data were provided with the anno-tations of the maximal NE only. Other details of this tagset with appropriate examples are shown in Sect. 7.1.

We use same set of features, as described earlier in Sect. 3 , for all the three Indian languages, namely Bengali, Hindi, and Telugu. In a similar way, we construct different ME-, CRF-, and SVM-based classifiers with the same combination of features and/or feature templates as described earlier (c.f. Sect. 7.2 ).

But in order to identify the nested NEs, we use several gazetteers and derived different heuristics. We identify NEM (NE measurement), NETI (NE time expressions), NEO (NE organization names), NEP (NE person names), and NEL (NE locations) to be the potential NE tags, where nesting could occur. A NEM expression may contain NEN, an NETI may contain NEN, an NEO may contain NEP/ NEL, an NEL may contain NEP/NETP/NED, and an NEP may contain NEL expressions.
 The NE identification is treated as a two-step procedure. In the first step, only the maximal NEs are identified and classified. All these identified entities are listed and used in the second step. In the second step, i.e., for nested NE iden-tification, we check whether a NE sequence contains other NE(s) as its subsequence. If there is any such subsequence, then it denotes the presence of potential nesting. In addition, we use several gazetteers to derive various rules in order to identify the nested NEs. We built several gazetteers from the training set of the respective language. Any NE subsequence is searched in these automatically built gazetteers to retrieve its appropriate nested NE category. In addition to the gazet-teers automatically extracted from the respective training set, we also use the gazetteers as shown in Table 18 . These gazet-teers were prepared manually as well as semi-automatically from the Bengali news corpus [ 43 ], Election Commission 10 of India and other sources.
 The system is evaluated in terms of precision, recall, and F -measure. These measures are calculated in three different ways [ 58 ]: 1. Maximal matches: The largest possible NEs are matched 2. Nested matches: The largest possible as well as nested 3. Nested lexical item matches: The lexical items inside the
Overall evaluation results are reported in Table 19 .The proposed MOO-based classifier ensemble is trained and eval-uated with the IJCNLP-08 NERSEEAL shared task data sets of the respective Indian languages, namely Bengali, Hindi, and Telugu. For all the three languages, the proposed approach attains better accuracies than the best reported sys-tems of the shared task [ 58 ]. We observe the increments of 10.17, 9.47, and 11.45 percentage points in the lexical F -measure values over the corresponding best system for Bengali, Hindi, and Telugu, respectively. The system shows best results for two main classes, namely  X  X erson X  and  X  X oca-tion X . For all the languages, the system performs poorly for the high ambiguous classes such as  X  X itle-person X ,  X  X esigna-tion X . The detection of the  X  X erm X  class is very difficult. Some rules may be more useful for the classes like  X  X umber X ,  X  X ea-sure X , and  X  X ime X  classes. The system also suffers from the low accuracies for the  X  X rganization X  class. This may be due to the presence of insufficient number of organization names in the training data. 11 Conclusion and future works In this paper, we proposed a MOO-based classifier ensem-ble technique for NER. Our underlying assumption is that rather than selecting the best-fitting feature set, ensembling several classification systems where each one is based on different feature representation and/or different classifica-tion technique can be considered as an alternative research direction. We came up with sufficient experiments to support our hypothesis that optimizing more than one classification quality measures simultaneously could be a more fruitful approach. The proposed approach encodes the classifiers in its chromosome. The overall recall and precision values of threefold cross-validation on the training data attained by the classifier ensemble encoded in a particular chromosome are used as two objective functions. We used ME, CRF, and SVM classifiers as the base classifiers. Several different versions of them varying the available feature combinations and/or tem-plates have been developed. One most interesting and impor-tant characteristic of our system is that it makes use of only language-independent features that can be easily derived for almost all the languages without any knowledge of them a priori. Thus, our proposed algorithm can be easily replicated for any language. We evaluated our proposed MOO-based classifier ensemble for three resource poor Indian languages, namely Bengali, Hindi, and Telugu, as well as for English. For each of these languages, results show that the overall per-formance attained by the proposed technique outperforms the best individual classifier, two different baseline ensembles as well as the classifier ensemble identified by a single objec-tive GA-based technique. In a part of the paper, we have also developed a feature selection technique using MOO. There-after, we have compared the MOO-based classifier ensem-ble selection technique with MOO-based feature selection approach.

In future, we would like to extract language-dependent features from our various existing in-house resources and tools. Future work also includes the development of some vote-based classifier ensembles. In the proposed technique, we have assumed that each classifier is allowed to vote for all the NE classes. But sometimes it is also necessary to determine the subset of classes for which a particular clas-sifier is most suitable. Authors are currently working in this direction.
 References
