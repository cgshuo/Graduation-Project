 The problem of using topic representations for multi-document sum-marization (MDS) has received considerable attention recently. In this paper, we describe fi ve different topic representations and in-troduce a novel representation of topics based on topic themes. We present eight different methods of generating MDS and evaluate each of these methods on a large set of topics used in past DUC workshops. Our evaluation results show a signi fi cant improvement in the quality of summaries based on topic themes over MDS meth-ods that use other alternative topic representations.
 H.3 [ INFORMATION STORAGE AND RETRIEVAL ] Algorithms, Performance, Experimentation Summarization, Topic Themes
One of the problems of data overload that we are facing today is that there are many documents that cover the same topic. Multi-document summarization (MDS) techniques can address this prob-lem by condensing information found in several documents into a short, readable synopsis, or summary.

Multi-document summaries need to be both informative and co-herent. Informativeness is rendered by the methods of selecting the information from documents to incorporate it into the summary. The coherence of the summary is obtained by ordering the infor-mation originating in different documents. Much work in summa-rization dealt with these problems separately. For example, sev-eral MDS systems select information for summaries using a cut-and-paste process, whereas [10] proposes that the information that needs to be extracted can be localized through statistical approaches. Copyright 2005 ACM 1-59593-034-5/05/0008 ... $ 5.00.
 The ordering of sentences in multi-document summaries was ad-dressed by [3], where three different ordering algorithms were pro-posed.

In this paper we argue that information selection and ordering in a multi-document summary (MDS) can be based on the structure of the topic covered in the document collection. The topic structure is characterized in terms of topic themes, which are representations of events or states that are reiterated throughout the document collec-tion, and therefore represent repetitive information. The relations that are established between themes determine both the content se-lection and the ordering of the information. This determines a novel MDS procedure that obtains improved results over previous meth-ods.

Central to the MDS approach proposed in this paper is the notion of topic representation and structure. As fi rst proposed in [11], the topic of a document (or a set of documents) can be represented us-ing a set of terms  X  known as a topic signature (TS)  X  that are highly correlated to the topic itself. Under this approach, each topic sig-nature term is assigned an association weight that measures the re-latedness of the term to the topic. [6] proposed an extension to this model by considering the relations between topic signature terms. Also a new representation of a topic was proposed in terms of the themes it covers. In a different approach, [1] proposed the use of content models to capture constraints on topic selection and orga-nization for texts in a particular domain.

Our approach represents topics as a structure of themes, which can be considered either linear or graphical. A theme is de fi ned as a cluster of sentences  X  taken from several different documents  X  which convey the same semantic information. Sentences corre-sponding to each theme are extracted using a semantic parser (pre-viously described in [15]) which identi fi es sentences with common predicates and arguments. Once the themes for a particular docu-ment collection are assembled, we identify the set of relations that exist between elements in different themes. These relations are as-sumed to dictate both (a) the information content to be included in an MDS as well as (b) the order of the themes that are selected.
The remainder of the paper is organized as follows. Section 2 describes previous work on topic representation. In Section 3 we motivate the need for topic themes and propose a themes repre-sentation. Section 4 focuses on how the theme structure is used to generate multiple-document summaries, Section 5 presents the experimental results, and Section 6 summarizes the conclusions.
The representation of topics was the focus of several recent pa-pers. In our experiments we have considered fi ve different topic representations (TRs): ( TR 1 ) representing topics via topic signa-tures ( TS 1 ); ( TR 2 ) representing topics via enhanced topic sig-natures ( TS 2 ); ( TR 3 ) representing topics via thematic signatures (
TS 3 ); ( TR 4 ) representing topics by modeling the content struc-ture of documents; and ( TR 5 ) representing topics as templates im-plemented as a frame with slots and fi llers.

TR 1 . Topic Representation 1 : Topic Signatures . In [11] the topic signature is represented as TS 1 = { topic, &lt; ( t , ( t n ,w n ) &gt; } where the terms t i are highly correlated to the topic with association weight w i . The terms are considered to be either stemmed content words, bigrams or trigrams. Term selection and weight association are determined by the use of likelihood ratio With the likelihood ratio method, the con fi dence level for a speci fi c c =  X  2 log X  value is found by (a) looking up the  X  2 distribution table, (b) using the value c to select an appropriate cutoff associated weight, and (c) determining the terms selected in the topic signature based on the value c .

To fi nd the candidate topic terms, a set of documents is preclas-si fi ed into (a) topic relevant texts , and (b) topic nonrelevant texts  X  . This classi fi cation enables the assumption of two hypotheses: Hypothesis 1 ( H 1 ): P ( | T i )= p = P ( |  X  t i ) i.e. the relevancy of a document is independent of t i ; Hypothesis 2 ( H 2 ): P ( | T i )= p 1 = p 2 = P ( |  X  t ence of t i indicates strong relevancy assuming p 1 p 2 ; and the following 2-by-2 contingency table: where O 11 is the frequency of term t i occurring in , O 12 frequency of term t i occurring in  X  , O 21 is the frequency of term  X  t = t i occurring in , O 22 is the frequency of term  X  t i ring in  X  . The likelihood of both hypotheses is computed as: L ( L ( where b ( k ; n, x ) represents the binomial distribution 1 . The  X  2 value is computed as  X  2 log L ( H 1 ) topic representation for two different topics T 1 and T 2
TR 2 . Topic Representation 2 : Enhanced Topic Signatures . [6] proposed that topics can be represented by identifying the rele-vant relations that exist between topic signature terms: TS { topic, &lt; ( r 1 ,w 1 ) , ..., ( r m ,w m ) &gt; } , where between two topic concepts. Two forms of topic relations are con-sidered: (1) syntax-based relations between the VP and its Subject, tween events and entities that cannot be identi fi ed by syntactic con-straints, but belong to the same context. C-relations are motivated by: (a) frequent collocations of certain nouns with the topic verbs or topic nominalizations, and (b) an approximation of the intra-sentential centering, as introduced in [9]. The topic relations are discovered by starting with the topic terms uncovered in TS selecting a seed syntactic relation between the topic terms. Only nouns and verbs are considered from TS 1 . Figure 1(b) illustrates the seed relations, while Figure 1(c) illustrates the enhanced topic representation.
 The iterative process of discovering topic relations has four steps: Step 1: Generate candidate relations: in each document relevant to the seed relation, all syntax-based and C-relations are identi fi ed. To discover topic relations we have used a very large corpus of texts: the AQUAINT corpus (LDC Catalog # LDC2002T31) which b ( k ; n, x )= n k x k (1  X  x ) n  X  k Figure 1: Topic representations for topics T 1 = Pinochet Trial and T 2 = Leonid Meteor Shower (a) topic signature TS 1 ; (b) seed relations for T 1 and T 2 ; (c) enhanced topic signature TS topic signature TS 3 . contains 375 million words corresponding to about 3GB of data. The seed relation becomes a query q that is used by the SMART IR system [4] to generate the set of relevant documents. These documents are processed to identify Verb-Subject, Verb-Object, and Verb-Prepositional Attachment relations. Document process-ing starts with the identi fi cation of named entities. Part of speech (PoS) tags and non-recursive, or basic, noun phrases are identi fi ed using the transformation-based learning method reported in [17]. Simple verb phrases (VP) and prepositional phrases (PP) are iden-ti fi ed with fi nite state automata (FSA) grammars. Syntactic rela-tions, such as Verb-Subject, Verb-Object, and Verb-Prepositional Attachment are recognized by another FSA. The C-relations are discovered by creating a salience window for each verb in the doc-ument. The NPs of each salience window are extracted and ordered with an ordering relation introduced in [9]. Both syntax-based re-lations and C-relations are expanded by replacing names with their semantic classes or by replacing words with concepts from a large, hand-crafted ontology of over 200,000 English words.
 Step 2: The candidate topic relations are ranked following a method introduced in [18]. Each relation is ranked based on its Relevance-Rate and its Frequency . The Frequency counts the number of times a relation is identi fi ed in the set of relevant documents. Relevance-Rate = Frequency/Count , where Count measures the number of times an extracted relation is recognized in any document, relevant or not.
 Step 3: Select a new topic relation based on the ranking in Step 2. Step 4: Restart the discovery by using the latest discovered relation for classifying relevant documents. The discovery procedure stops after N=100 iterations or when no new relations are discovered. TR 3 . Topic Representation 3 : Enhanced Topic Signatures with Themes . Although topic-relevant terms or relations can be used to capture information about a topic that is repeated throughout a document collection, additional information is needed to produce accurate multi-document summaries [6]. For example, a set of doc-uments focusing on topic T 1 = Arrest of Augusto Pinochet discusses not only the arrest itself, but also other themes, e.g. the charges, the extradition request, the international reaction, as well as the re-action of Chilean citizens. Although some of these themes may be general, since they apply to other arrest events (e.g. charges), others may be speci fi c only to the current topic (e.g. reaction of Chilean citizens). A third topic representation that is based on the concept of themes was proposed in [6]: TS 3 = { topic, &lt; ( sociated with the topic and r i is its rank.

The discovery of themes is based on (1) a segmentation of docu-ments produced by the TextTiling algorithm [8], and (2) a method of (i) assigning labels to themes, and (ii) ranking them. [6] consid-ered four cases for theme labeling: Case 1: A single topic-relevant relation is identi fi ed in the seg-ment. For example, for the topic T 1 = { Arrest of Augusto Pinochet } only the relation [ charge-murder ] is discovered. The theme label is given by the nominalization of the verb, i.e. C HARGES . Case 2: Several topic relations are recognized in the segment. The label is determined by the relation ranked highest in the topic sig-nature TS 2 . for example, if both the relation [ arrest-Pinochet ] and [ charge-murder ] are recognized, only the highest weighted one de-termines the label, e.g. A RREST .
 Case 3: If multiple topics are processed simultaneously, the theme may receive multiple labels.
 Case 4: The theme contains topic-relevant terms, but no topic re-lation. In this case the most relevant noun becomes the label of the theme. For example, if within the paragraph, for TS 1 counter the nouns immunity , crime , and request , the theme label will be I MMUNITY , since it has the largest associated weight, as it was illustrated in Figure 1.
 TR 4 . Topic Representation 4 : Topics Represented as Content Models . In addition to topic representations based on TS, we also considered deriving topic themes based on models of the content structure of documents. [1] employs an iterative re-estimation pro-cedure that alternates between (1) creating clusters of text spans with similar word distributions to serve as representatives of within-document topics; and (2) computing models of word distributions and topic changes from the clusters obtained. The working assump-tion is that all texts describing a given topic are generated by a sin-gle content model. The content model is a Hidden Markov Model (HMM) wherein states correspond to topic themes and state tran-sitions capture either (1) orderings within that domain, or (2) the probability of changing from one given topic theme to another. The induction of the topic model is described as: Step 1 . Initial topic induction , in which complete-link clustering is used to crate m sentence clusters by measuring sentence similarity with the cosine metric.
 Step 2 . The model states and the emission/transition probabilities are determined. Each cluster corresponds to a state. For each state s corresponding to cluster c i the sentence emission probabilities are estimated using smoothened counts: p where f c y = ww or y = w ) occurs within the sentences in cluster c i V is the vocabulary. When estimating the state-transition probabil-ities, if two clusters c 1 and c 2 are considered, D ( c 1 the number of documents in which a sentence from c 1 immediately precedes a sentence from c 2 . D ( c i ) is the number of documents containing sentences from cluster c i . For two states s i probability of transitioning from s i to s j is estimated as: p ( where m is the number of states and  X  2 is a smoothening constant. Step 3 . Viterbi re-estimation. In this step the model parameters are re-estimated using an EM-like Viterbi approach: the sentences are re-clustered by placing each sentence in a new cluster c i responds to a state s i most likely to have generated it according to the Viterbi decoding of the training data. The new clustering is used as input to the procedure of estimating the HMM parameters. The cluster/estimate cycle is repeated until the clustering stabilizes or the iterations reach a prede fi ned number of cycles. Figure 2 illus-trates samples from a cluster corresponding to topic T 1 . The cluster represents the topic representation TR 4 .
 Figure 3: (a) Template representation of topic T 3 :  X  X atural dis-asters X ; (b) Text containing information about the topic.
TR 5 . Topic Representation 5 : Topics Represented as Extrac-tion Templates . Topics can be represented as a set of inter-related concepts, implemented as a frame having slots and fi llers. In Infor-mation Extraction, such frames are called templates and are popu-lated with information related to the salient facts reported in doc-uments and extracted by the IE systems. For example, if the topic is  X  X atural disasters X  , Figure 3(a) illustrates a template populated with information extracted from the text illustrated in Figure 3(b).
The idea of representing the topic as a frame-like object was fi rst implemented as underspeci fi ed (or  X  X ketchy X ) scripts, which were used to model a set of pre-de fi ned particular situations, e.g. demon-strations, earthquakes or labor strikes. Since the world contains millions of topics  X  each which could be described by a script  X  it is important to be able to generate scripts automatically from cor-pora. In a fi rst attempt to generate sketchy scripts automatically, [7] proposed using the I S -A and G LOSS lexical relations found in relevant terms.

The I S -A and G LOSS relations encoded in WordNet participate into lexico-semantic domains between topic-relevant concepts. [7] nouns, verbs, adjectives and adverbs. Each word in WordNet is stored with a set of synonyms known as a synset , as well as a def-inition or gloss . In addition to these lexical resources, WordNet incorporates properties of knowledge bases, as it is organized into 24 noun hierarchies and 512 verb hierarchies as well. call these lexico-semantic domains topical relations and provide four possible ways of combining the I S -A and G LOSS relations for generating the topical relations: (1) considering a path between a synset 1 and any other synset 2 in the G LOSS of synset 1 considering a path between a synset 1 and any synset 2 reached through two G LOSS relations; (3) considering a path between a synset 1 and any synset 2 reached by an I S -A followed by a G relation; (4) considering a path between a synset 1 and a if there are G LOSS relations from them to a synset 3 .
The topical relations mined from WordNet have the advantage that they bring forward semantically-connected concepts deemed relevant to the topic. An ad-hoc template generation algorithm was presented in [7]. The algorithm X  X  steps are: Step 1: Extract all sentences in which one of the concepts traversed by topical relations is present. The concepts from the topical re-lations are used as seed lexical items for the identi fi cation of the template slots.
 Step 2: Identify all Subject-Verb-Object (SVO) +Prepositional at-tachments syntactic structures in which one of the topical concepts is used. For this purpose, we used the phrasal parser implemented for the topic representation TR 2 .
 Step 3: Add all SVOs in which one referent of a pronoun existing in the SVOs discovered at Step 2 exists. Referents are discovered with the resolution method proposed in [16].
 Step 4: Combine the extraction dictionaries with WordNet to clas-sify each noun from the structures identi fi ed at Step 2 and Step 3. Step 5: Generate the semantic pro fi le of the topic. For this reason we compute three values for each semantic class derived at Step 4: (1) SFreq : the number of syntactic structures identi fi ed in the collection; (2) CFreq : the number of times elements from the same semantic class were identi fi ed; and (3) PRel the probability that the semantic class identi fi es a relevant slot of the template. Similarly to the method reported in [19], PRel = CFreq / SFreq . To select the template slots the following formula is used: (CFreq &gt; F1) or ((SFreq &gt; F2) and ( PRel &gt; P)) The fi rst test selects roles that come from the semantic categories that are identi fi ed with high frequency, under the assumption that this re fl ects a real association with the topic elaboration in the col-lection. The second text promotes slots that come from a high per-centage of the syntactic structures recognized as containing infor-mation relevant to the topic even though their frequency might be low. The values of F1 , F2 and P vary from one topic to another -we derive them from the requirement that a template should not contain more than 5 slots.
Although the documents used to generate a multi-document sum-mary may be relevant to the same general topic, they do not neces-sarily include the same information. In order to produce exhaustive summaries, MDS systems must be able to identify information that is (1) common to multiple documents in the collection, (2) unique to a single document in the collection, and (3) contradictory to in-formation presented in other documents in the collection. Extract-ing all similar sentences would produce a verbose and repetitive summary, while extracting some similar sentences could produce a summary biased towards some sources, as it was noted in [2].
Multi-document summaries based on topic representations simi-lar to the ones presented in Section 2 extract sentences relevant to the topic representations. For example, [10] used the topic repre-sentation outlined in (TR1) to extract sentences for MDS based on a topic signature score that is equal to the total of signature word scores it contains, normalized by the highest sentence score. When more elaborate topic representations are used, e.g. TR 3 ,or the extractive summarization is based on models of topic themes and shifts between these themes. Results reported in [1] and [6] in-dicate that this topic representation produces better multi-document summaries. For this reason, we revisit the notion of theme repre-sentation and propose herein a more linguistically-motivated de fi -nition and representation of themes.

Themes were previously used in the context of MDS [2] to de-fi ne sets of similar sentences that are detected across a set of doc-uments describing the same topic. Figure 2 illustrates a theme de-fi ned through a collection of similar sentences for the topic  X  X he Arrest of Augusto Pinochet X  . Each of the sentences listed in Figure 2 communicates about the arrest of Pinochet, which is expressed through the presence of the same predicate, namely the verb  X  arrest  X , or one of its paraphrases, e.g. the idiom  X  place un-der arrest  X , and at least one common argument of the predicate, namely  X  Pinochet  X . This observation is at the core of our method of representing themes.

Current semantic parsers, similar to the ones described in [5] or [15], are able to recognize all verbal predicates and their arguments predicate-argument structures recognized for the sentences listed in Figure 2. The predicates that were recognized are underlined in Figure 2. The parses were obtained with the method reported in 5 www.cis.upenn.edu/  X  ace ments sequentially from Arg 0 to Arg 5 . Generally, Arg0 would LOC indicates a locative, and ArgM-TMP stands for a temporal.
Figure 4 highlights the common predicates between the sentences listed in Figure 2. It is to be noted that for sentence S icate  X  X lace X  was transformed into the idiomatic predicate  X  X lace under arrest X , which is listed as a synonym of the verb  X  X rrest X  in the web resource dictionary.com (Merriam-Webster Dictionary of Law). The transformation keeps as Arg1 for  X  X lace under arrest X  the Arg1 of  X  X lace X , but Arg2 is no longer recognized. The decision of no longer instantiating the Arg2 for the phrasal predicate  X  X lace under arrest X  is motivated by the fact that the fi ller of Arg2 con-tributed to the recognition of the new predicate. Also, both predi-cates  X  X lace X  and  X  X rrest X  share the same semantics for the Arg0, Arg1, ArgM-LOC, and ArgM-TMP.

We generate the theme representation through the following six steps: Step 1: For every sentence in each document from the collection, the predicate-argument structures are identi fi ed. This step also in-volves the recognition of paraphrases as synonyms or idioms. The resources for synonymy detection are WordNet and dictionary.com . Step 2: All sentences having at least one common predicate with a common argument (e.g.  X  arrest  X  with argument  X  Pinochet  X ) are clustered together. In this step, the semantic consistency of the other arguments is also checked. For every argument, the consis-tency is accepted when: (a) the head of the phrase is the same, synonymous, or a name alias; or (b) the argument is a pronoun or a noun phrase that refers to the same entity (e.g. in Figure 4,  X  they  X  from Arg0 of predicate  X  arrest  X  in both S 1 and  X  British police  X  X n S 3 ); or (c) the arguments are mapped to the same ontological node, when using the ontology employed in TR 2 (d) the arguments contain the same predicate, having at least one stand for agent , Arg1 for direct object or theme , whereas Arg2 rep-resents indirect object , benefactive ,or instrument , but mnemonics tend to be very speci fi c. For example, when retrieving the argu-ment structure for the verb-predicate  X  X rrest X , we fi nd Arg0: police , Arg1: criminal , Arg2: crime . 7 www.cis.upenn.edu/  X  treebank consistent argument. Consistency is sought only between several instantiations of the same argument in the theme. In Figure 4, se-mantic consistency is sought only for Arg0, Arg1, and Arg2. To fi nd semantic consistency between Arg2 of predicate A RREST S 1 and Arg2 of the same predicate in S 2 the frame semantics of the noun  X  X llegation X  are used. This noun is associated with the frame S TATEMENT , for which a FE of  X  X essage X  is recognized. The message is semantically consistent: in both cases the predicate M
URDER is used, for which we have two associated thematic roles: the agent:  X  X e X  referring to  X  X inochet X , and the patient:  X  X panish citizens X , consistent with  X  X paniards X , due to mappings to the same concept of the ontology employed in TR 2 .
 Step 3: Conceptual representations for each cluster are generated. These conceptual representations are similar to the dependency-based representation employed by [2]. The representation consists of (1) the predicate, (2) the semantically consistent argument, and (3) arguments that anchor the predicate in time and location, or de-scribe the cause, manner or effect of the predicate. For example, for the theme illustrated in Figures 2 and 4, the cluster centered around the predicate A RREST would consider arguments Arg0, Arg1, Arg2 (semantically consistent), as well as ArgM-LOC, ArgM-TMP, and ArgM-ADV, as illustrated in Figure 5. Two statistics modeling the coverage of the predicate-argument representation are collected: the number of times the lexeme  X  X rrest X  is used as a predicate in the cluster, and the total number of times the same lexeme is rec-ognized throughout the entire collection. For each argument, a list of triplets is recorded as well as a text snippet. The format of the triplets is: (a) the sentence position and document number where the argument was recognized, followed by (b) the word number within the sentence where the argument starts, and (c) the word number where the argument ends.
 Step 4: Selection of the candidate themes is made by consider-ing the mappings of the clusters into (1) the topic representation TR 3 and (2) the topic representation TR 4 . Both these topic rep-resentations correspond to the notions of theme and theme change . The selection is cast as a binary classi fi cation problem that can be solved through inductive methods. We have implemented the clas-si fi cation with binary trees, considering for each candidate theme the features represented in Table 1. For this supervised learning paradigm, the abstracts created by humans are also considered. For training purposes, only themes that are manifested in the human-created abstracts are considered as positive examples. For example, for topic T 1 , the themes that were selected were: A RREST Step 5: In a topic, there are meaningful relations between the themes. We have considered two forms of such relations: (1) Cohesion relations . Often themes co-occur (1) in the same sen-tence, (2) in successive sentences, or (3) in the same text segment. Themes co-occur in the same sentence because their representative predicates share an argument or one of the predicates belongs to an argument of the other. For example, in Figure 4, both predi-cates A RREST and M URDER co-occur both in S 1 and S 2 . Themes co-occurring in successive sentences are recognized when pairs of theme-relevant predicates are recognized each in one of the sen-tences. Cohesive relations between themes belonging to the same segment are identi fi ed similarly to the cohesive relations between succeeding sentences. Cohesive relations in the same sentence re-ceive a weight a =10 , in successive sentences a weight b in the same segment a weight c =1 . (2) Discourse relations . [13] argues that for some summaries, the structure of discourse helps in selecting better textual units. To study the interaction of discourse relations on our theme repre-sentation, we have considered only the C ONTRAST and C AUSE E
XPLANATION relations. These two relations were recognized by the same naive Bayes classi fi ers as the one reported in [13]. When-ever we recognized any of these two discourse relations between a text unit containing one of our selected themes and any other text unit, we would select the relation for inclusion in the theme rep-resentation, and later in the summary. The discourse relations are modeled by a three-valued feature. The weights are given by the method presented in [13].
 Step 6: The themes are structured into a graph. The nodes are mapped into the conceptual representation of each theme. Fig-ure 5 illustrates such a representation of a theme. The links of the graph correspond to a combination of cohesion and coherence rela-tions. When between two themes we have both a cohesive relation R 1 with weight w 1 , and also a coherence relation R 2 with weight w , the weight assigned to the link between the themes is equal to w 1 + w 2 . If only one type of relation exists the link receives the wight of that relation. Unlinked themes are removed from the theme representation.
Multi-document summarization is performed by (1) extracting sentences that contain the most salient information; (2) compress-ing the sentences for retaining the most important pieces of in-formation; and (3) ordering the extracted sentences into the fi nal summary. When comparing several MDS methods that use topics or theme representations we have found that most of them con-tributed mainly to the extraction phase of the MDS process. In total, we have implemented four extraction methods, two ordering methods, and a separate MDS method, based on the theme rep-resentations, that performed extraction, compression and ordering simultaneously. Thus we could compare eight MDS methods, as listed in Table 2.

EM 1 . Extraction Method 1 . Similar to [11], sentence extrac-tion is based on topic identi fi cation and interpretation, provided by TR 1 in the form of topic signatures TD 1 . Each sentence from the collection receives a topic signature score equal to the total of the signature word scores it contains, normalized by the highest sen-tence score.

EM 2 . Extraction Method 2 . The same procedure can be used when the enhanced topic signature TS 2 , pertaining to TR to score sentences according to the weights of the topic-relevant relations.

EM 3 . Extraction Method 3 . When TR 3 is employed, we have fi rst selected the segments labeled by the highest scoring theme. To extract sentences, we computed in each segment a sentence topic score based on TS 2 and extracted the sentence with the highest score for each theme.

EM 4 . Extraction Method 4 . Topic representation TR 5 was used in [7] to generate multi-document summaries. In [7], sen-tences are extracted based on the importance of the template par-tially matching it. For each slot S j of a template T i we count the frequency with which a text snippet fi lled that slot and any other slot of another template. The importance of T i equals the sum of all frequencies for each slot S j .

Each Extraction method was used in combination with one of the following two ordering methods for generating MDS:
OM 1 . Ordering Method 1 : Topic representation TR 5 was used in [1] for single-document summarization. Given the content model represented in TR 5 , we can learn which themes (represented by the content model X  X  states) should appear in the MDS. As in [1], all the extracted sentences can be tagged by the Viterbi algorithm with a Viterbi topic label ,orV-topic  X  the name of the state most likely to have generated them. The selection of themes and their order is determined by the probability of generating a summary sentence. This probability is learned by training on abstracts generated by humans. For each document-abstract pair we (1) count the number of sentences that are assigned the same V-topic S , and (2) normal-ize this count by the number of documents containing sentences with V-topic S .

OM 2 . Ordering Method 2 : This ordering method, introduced in [3], aims to remove dis fl uencies from the summary by group-ing together topically related themes. It applies only to extraction method EM 3 , which has knowledge of themes, since it is based on
TR 3 . This ordering method de fi nes pairwise relations between themes. Given two themes T 1 and T 2 where T 1 contains sentences ( s 1 ,s 2 , ..., s n ) and T 2 contains sentences ( t 1 ,t 2 note by # T 1 T 2 the number of pairs of sentences ( s i ,t appear in the same text, and # T 1 T + 2 to be the number of sentence pairs that appear in the same text and are in the same segment. The measure of relatedness between themes T 1 and T 2 is given by the ratio # T 1 T + 2 / # T 1 T 2 When the ratio is higher that a predi fi ned sure of the pairwise relation between themes produces groups of related themes (GRTs). The GRTs are ordered by a chronological ordering (CO) algorithm presented in [3]. In this algorithm, each GRT is assigned a date corresponding to its fi rst publication 9 . The date assignment establishes a partial ordering over the GRTs. When two GRTs have the same date (that is, they are reported for the fi rst time in the same article) we sort them accordingly to the order of presentation in this article. This generates a complete order over the GRTs. Within the GRT, the themes are ordered by applying the CO algorithm to them.

As illustrated in Table 2, fi ve different combinations of extraction methods and ordering methods lead us to as many MDS methods. Furthermore, the theme representation presented in Section 3 can be used in three more MDS methods. Step 4 of the theme represen-tation selects the themes that need to be extracted. Since the con-ceptual representation of a theme includes information about the sentences where the themes were described, both ordering methods OM 1 and OM 2 can be used for implementing two additional MDS methods, namely MDS 6 and MDS 7 from Table 2. We considered date MDS 1 through MDS 8 an eighth MDS method by using the graph representation produced at Step 6 in Section 3. The order between the themes that are pro-duced is obtained by applying the well-known Traveling Salesman Problem on the graph. The Hamiltonian path that is generated is used to select the order of the themes, but the sentences that con-tain information in the conceptual representation of a theme need to be ordered as well. We do not consider a complete order, but rather select only one sentence that has the highest coverage among the arguments of the theme. When a tie exists, we give priority to the sentence that covers most of the core arguments (Arg0-5) as op-posed to the locative or temporal arguments. For example, given the theme illustrated in Figure 5, sentence S 2 is selected, since it covers four arguments (Arg0, Arg1, Arg2, and ArgM-ADV). Sen-tence S 3 also covers four arguments (Arg0, Arg1, ArgM-LOC and ArgM-TMP), but only two core arguments.
Automatic text summarization has drawn a lot of interest in the natural language processing and information retrieval communities in recent years. Recently, a series of government-sponsored eval-uation efforts in text summarization have taken place in both the United States and Japan. These evaluations, known as the Doc-ument Understanding Conferences (DUC), have organized yearly evaluations of automatically-produced summaries by comparing the summaries created by by systems against those created by humans. In 2004 multi-document summaries were produced for 50 different topics.

Following the recent adoption of automatic evaluation techniques (such as BLEU/NIST) by the machine translation community, a troduced for both single and multi-document summarization [12]. ROUGE includes four automatic evaluation methods that measure the similarity between summaries: ROUGE-N, ROUGE-L, ROUGE -W, and ROUGE-S. Formally, ROUGE-N measures the n -gram recall between a candidate summary and a set of reference sum-maries. ROUGE-N is computed as follows: ROUGE-L uses the longest common subsequence (LCS) metric in order to evaluate summaries. In this technique, a sequence [ r ,r 2 , ...r n ] is considered to be a subsequence of another sequence S =[ s 1 ,s 2 , ...s n ] if there can be de fi ned a strictly-increasing se-quence of indices for S (i.e. I =[ i 1 ,i 2 , ...i k ] such that for all j =1 , 2 , ...k , s ij = z j . The longest common subsequence for uation; http://www.isi.edu/  X  cyl/ROUGE/ R and S can be de fi ned as the sequence common to both R and S with the greatest length. ROUGE-L is based on the assump-tion that pairs of summaries with longer LCS scores will be more similar than those summaries with shorter LCS scores. To cap-ture this generalization, if we assume that summary sentences and Y can be represented as a sequence of words, an LCS-based F-measure can be calculated to estimate the similarity between a reference summary X (of length m ) and a candidate summary of length n as follows:
Here, LCS ( X, Y ) is equal to the length of the LCS of X and  X  = P lcs /R lcs . LCS can be also used to compute an F-measure for an entire summary, not just a single sentence. The summary-based LCS F-measure can be computed as follows: R F where u represents a reference summary of m words, C represents a candidate summary of n words, and LCS  X  ( r i ,C ) is the LCS score of the union LCS between r i and the candidate summary Figure 6 illustrates ROUGE scores for the 50 topics evaluated in DUC-2004 for each of the eight summarization methods we pro-pose in this paper. Results from three different ROUGE scores are depicted: ROUGE-1 (Figure 6(a) and 6(b)), ROUGE-2 (Figure 6(c) and 6(d)) and ROUGE-L (Figure 6(e) and 6(f)). Although perfor-mance does vary from topic to topic regardless of the summariza-tion system employed, the graphs above show that the best results were obtained when MDS were generated using method MDS 8 , followed closely by MDS 7 , and MDS 6 , as shown in Figure 7.
In this paper we investigated fi ve topic representations that were used before in MDS and proposed a new representation based on topic themes. We have presented a total of six new MDS methods that use different information extraction and information ordering methods. We have shown how both extraction and ordering for MDS can be improved when topic themes are available as part of the input. Finally, we have evaluated these summarization methods using the ROUGE scoring package and the topics and document collections featured in the DUC 2004 evaluation.

The theme representations proposed in this paper are based on the shallow semantic information provided by semantic parsers, a source of linguistic information much more sophisticated than those employed by previous thematic representations. Addition-ally, we have represented themes in a graph-like structure (deter-mined by both coherence relations and cohesion relations) that im-prove the quality of ordering information for MDS. Although the idea of using cohesion and coherence for summarization is not new in of itself, it has not previously been applied to thematic represen-tations based on predicate-argument structures.

In future work, we plan to extend thematic representations in order to incorporate additional semantic information, to recognize theme paraphrases, and to represent themes using macro-predicates that correspond to natural classes of predicates. Additionally, we plan to expand the number of coherence relations that we recognize between themes. Finally, we intend to incorporate compression methods into MDS and to customize a compression method that is based on topic themes.
