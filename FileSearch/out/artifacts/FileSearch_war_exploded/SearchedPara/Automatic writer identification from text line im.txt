 ORIGINAL PAPER  X nder K X rl X   X  M. Bilginer G X lmezo  X  glu Abstract In the present article, new techniques have been introduced for revealing the individual features of a person X  X  handwriting pattern from the scanned images of handwrit-ten text lines to facilitate text-independent writer identifi-cation. These techniques are aimed at designing a dynamic model which can be formalized according to any handwritten text line. Various combinations of the extracted features are applied to three well known classifiers for evaluating the con-tribution of features to define the correct identification rate. The K-NN, GMM, and Normal Density Discriminant Func-tion Bayes classifiers are used in the present identification model. The experimental studies are conducted using two datasets obtained from the IAM database. The first dataset has already been proposed and used in the literature, whereas the second dataset is an expanded version of the first data-set and has been constituted for the first time in this study to analyze the performance of the extracted features under conditions such as an increased number of writers to dis-criminate in the database and a decreased number of text lines per writer. The remarkable identification rates obtained from the three classifiers on both datasets clearly indicate that the proposed feature extraction techniques can be effectively used in writer identification systems.
 Keywords Writer identification  X  Feature extraction  X  Handwriting analysis  X  Classification methods  X  Database 1 Introduction Handwriting is a personal biometric that has long been con-sidered to be unique to a person [ 1 ]. As the main factors affecting the constitution of a person X  X  handwriting, such as biological and cultural, differ for each person, handwriting is a distinguishing biometric like voice. Writer individuality rests on the hypothesis that each individual has a consistent handwritingwhichisdistinctfromthehandwritingofanother individual [ 2 ]. Hence, the individuality of handwriting makes the identification of the writer of a handwritten sample possi-ble. The analysis of handwritten documents with a viewpoint of determining the writer has a great impact on the criminal justice system.

Research in writer identification and verification has received significant interest in recent years due to its foren-sic applicability [ 3 ]. The problem of writer identification and verification arises frequently in the court of justice where one must come to a conclusion about the authenticity of a docu-ment. It also arises in banks for signature verification, or in some institutes which analyze texts of former authors, and are interested in the genetics of these texts as, for example, the identification of the various writers who took part in the drafting of a manuscript or who made corrections [ 4 ].
The writer identification task concerns the retrieval of handwritten samples from a database using the handwritten sample under study as a graphical query. It provides a subset of relevant candidate documents, on which complementary analysis will be developed by the experts [ 4 ]. A writer iden-tification system performs a one-to-many search in a large database with handwriting samples of known authorship and returns a likely list of candidates [ 3 ].

The writer verification task, on its own, must come to a conclusion about two samples of handwriting and determines whether they are written by the same writer or not [ 4 ]. Hence, writer verification can be regarded as a two class discrimina-tion problem. Writer verification has potential applicability in a scenario in which a specific writer must be automatically detected in a stream of handwritten documents [ 3 ].
Research in writer identification and verification has been focused on two streams: off-line and on-line recognition. Writer identification and verification can be performed on-line, if temporal and spatial information about the writing is available [ 5 , 6 ]. In on-line recognition, the writer is con-nected via an electronic pen or a mouse to the computer and the handwriting is recorded as a function of time. But, in off-line recognition, handwriting is captured by means of a scanner or camera and becomes available for processing and recognition in the form of an image. Because of the avail-ability of temporal information, on-line recognition is often considered as an easier problem [ 7 ].

From the textual content point of view, writer identifica-tion and verification tasks are separated into two categories as text-dependent and text-independent. While text-dependent methods require the samples of texts that include similar and known contents, any text can be used for text-independent methods. Text-dependent writer identification is very con-strained and inappropriate for many practical applications, e.g., the identification of the writers of archived handwritten documents.

The availability of large amounts of data for training and testing processes is a fundamental prerequisite for the devel-opment of recognition systems with high performance. Some standard databases developed for writer identification and verificationarenotusedwidelyenoughortheyareusedpartly because of their largeness or irregular arrangements. Exam-plesofsomeofthewell-knowndatabasesinthisfieldareIAM [ 8 ], Firemaker [ 9 ], UNIPEN [ 10 ] and RIMES [ 11 ] databases. IAM database 1 is the mostly used database for writer identifi-cation and verification research in the literature. The authors have usually preferred to use different datasets chosen from the IAM database and they usually did not report about the use of these datasets [ 4 , 12  X  17 ]. In recent years, a dataset containing text lines of 100 writers from IAM database is reported and used in some of the research works [ 18 , 19 ].
To represent a handwritten document, a set of features extracted from the image of the document is used. Defini-tion of a feature space is one of the main phases of a writer identification system. Extraction of features representing the between-writer variability is the main goal to determine the writer identity. The features of handwriting are divided into two classes. Those that are used by forensic experts are called document examiner features; those that are measured by computer algorithms are called computational features [ 1 ]. In recent years, a significant progress has been made in recog-nizing a person based on biometric features [ 3 , 20 , 21 ]. The identification of indispensable features provides the infor-mation about which features should be selected when faced with the problem of distinguishing writers of several hand-written samples. After several feature selection processes are applied, the frequency of appearance of the features in the determined optimal sets may also be used as an indicator of their usefulness [ 1 ].

The classification is used to make a final decision in line with the extracted features and acquired knowledge. Many techniques have been reported for handwritten-based writer identification and verification. Most of these tech-niques depend on distance measures [ 3 , 16 , 22  X  25 ]. K-Near-est Neighbor (K-NN) classifier and neural networks are other widely used methods [ 1 , 2 , 12 , 24  X  26 ]. There are also sel-dom used methods such as Bayes classifier [ 17 , 26 ], Gaussian Mixture Model (GMM) [ 19 ], Hidden Markov Model (HMM) [ 18 ] and Support Vector Machines (SVM) [ 15 ].

In this study we address the problem of off-line, text-inde-pendent, and automatic writer identification from the images of handwritten text lines. For comparison, we performed our experimental studies on the dataset with 100 writers from the IAM database, which has been used in recent research [ 18 , 19 ]. As seven of the 100 writers could not be accessed during our database research, the dataset containing the remaining 93 writers from the IAM database was used. All text lines in the database were derived from scanned handwritten pages and included different textual contents. Handwriting in the database was produced by habitual and natural script style of writers without forgery. This study does not address the issue of identifying forged or disguised handwriting. This paper proposes a new approach to extract individual features from text lines. All features were tested using various classifiers to evaluate the contribution of features, and the results were compared for each selected feature and classifier. The clas-sifiers used in our identification model were K-NN, GMM, and Normal Density Discriminant Function (NDDF) Bayes classifier. In addition, we analyzed the performance of the features under conditions such as the increased number of writers to discriminate in the database and decreased num-beroftextlinesinthetrainingset.Forthisstudy,weexpanded the dataset by increasing the number of writers to 212. New writers were selected from the IAM database according to the maximum text line number owned by each writer. The text line labels of the expanded dataset are provided on the Internet 2 for the use of research community.

The rest of this paper is organized as follows. In the next section, the related research work is given. In Sect. 3 ,the proposed approaches for extracting features are introduced. Section 4 includes experimental study covering database, identification methods and results. In Sect. 5 , a brief dis-cussion is given with a conclusion. 2 Related work In this section a detailed survey of studies about the writer identification and verification is given. In general, writer identification and verification approaches based on handwrit-ten text have received much more attention by the research community during the last decade. It is so difficult to find research works which use a common dataset as a benchmark. Since reported experimental studies have been achieved with different datasets, comparison of the approaches proposed in theliteratureissimplyimpossible.Wemakeacomprehensive review of research works including the proposed features, classification methods, database and experimental results.
Among the well-known text-dependent approaches, the extraction of macro and micro features is one of the most comprehensive [ 2 ]. Macro features can be extracted at doc-ument, paragraph, line, and word or character level and con-sist of pen pressure, writing movement, stroke information, slant, and height features. Micro features are computed at the character shape level and consist of gradient, structural, and concavity features. K-NN classifier and neural networks are used to classify features. Experiments were performed on a dataset of 1,000 writers who wrote the same group of 156 different words three times (CEDAR letter [ 27 ]). The highest identification rate was reported as 81% when the micro fea-tures were classified with K-NN, and 96% verification rate was achieved with neural networks.

In a recent text-dependent study, a set of structural micro features of handwriting was extracted from the characters  X  X , X   X  X , X   X  X , X  and  X  X h X  [ 1 ]. The proposed features are standard forensic document examiner features. A neural network was used as a classifier and a genetic algorithm was used to search for optimal feature sets. Experiments were performed on a dataset that was constructed by segmenting the related char-acters from the CEDAR letter [ 27 ], representing 165 writers, between 15 and 30 samples per writer. The highest identifi-cation rate of 58% was obtained when the selected optimal features of all four characters were used.

In the text-independent writer identification and verifica-tion area, a wide variety of features have been proposed over the past several years. B-splines have attractive properties for curve representation and have been proposed for the air-craft-type identification from image silhouettes and writer identification from single letters [ 28 , 29 ]. A written text is allocated to a writer by first isolating and identifying the let-ters and then using the characteristic shape of each writer X  X  letters. A residual-based decision rule is applied for feature matching. Experiments were performed on a dataset of 10 writers, with all alphabet letters written 10 times by each writer. When the letters were used jointly, 100% identifi-cation rate was achieved. The results indicate that classi-fication based on only single letters is neither reliable nor reasonable.

Morphological operators have been used to extract fea-tures from single words in [ 26 ]. The feature vectors are obtained by means of morphologically transforming the pro-jection functions of the thinned images. Bayesian classifier and neural networks were employed to test the efficiencies of the features. Experiments were performed on a dataset in which 50 writers wrote the word  X  X haracteristic X  45 times, both in English and in Greek. Identification rates of 92.5% with Bayes and 96.5% with neural networks were reported. In addition, verification rates of 95% with Bayes and 98% with neural networks were reported.

Gabor filtering is another technique to extract writer-specific features. The main idea is to model the pictorial information in the human visual cortex, which involves a set of parallel and quasi-independent mechanisms or corti-cal channels. Said et al. [ 24 , 25 ] used multi-channel Gabor filtering and the grey scale co-occurrence matrix (GSCM) to extract features from the entire image of a text. Features were extracted from the images of uniform text blocks independent of textual content. Two classification techniques, namely the weighted Euclidean distance (WED) and the K-NN classi-fier, were adopted. Experiments were performed on a dataset of 20 writers, with 25 text blocks per writer. The best identi-fication rate was reported as 95.3%, which was obtained by the classification of Gabor Filter features with WED. Gabor filters have also been widely used in many Chinese handwrit-ing-based writer identification studies [ 30  X  34 ].
Although SVM has been one of the popular methods used recently in many research areas, it is rarely used in writer identification and verification problems. Steered Her-mite features are calculated from the text-independent hand-writing images and applied to SVM for training and testing processes in [ 15 ]. On a dataset from the IAM database of 30 writers, 83% identification rate was reported, with five text lines per writer.

One of the most comprehensive studies in the text-independent writer identification and verification field is presented in [ 3 ], where the authors offer probability distribu-tion functions (PDFs) to extract texture and allograph (code-book-based) level features from handwriting images. At the texture level, PDFs of contour-based features are computed to encode the orientation and curvature information. At the allograph level, grapheme emission distributions are com-puted using a common shape codebook obtained by graph-eme clustering. The various combinations of the texture and allograph level features were evaluated on the IAM and Fire-maker databases. Feature vectors were matched by means of various distance measures. According to the reported results, the Hamming distance matching of the combina-tion of edge-hinge, run-length, and grapheme emission dis-tributions gave the highest identification rate of 89% on the IAM database of 650 writers, with two handwriting pages per writer. Although these features offer a text-independent and robust characterization of individual handwriting style, the extraction process of the features requires complex and time-consuming algorithms.

Codebook-based feature extraction techniques have been popular in recent years. Among the latest studies, Siddiqi and Vincent [ 23 ] generated codebooks by means of the small writing fragments. These fragments carry no semantic infor-mation and are obtained by dividing the handwriting into small windows. One of the disadvantages of the technique is that the window size is empirically determined and fixed for all writing styles. Since in real-world problems the handwrit-ing images may be scanned in different resolutions, it would be better to find a way of determining the window size auto-matically. The authors also introduced a set of features that are extracted from the contours of handwritten images in a previous study [ 22 ] and extended the same idea in [ 23 ]. To perform writer identification and verification, a dissimi-larity measure was defined using X 2 distance measure. The experimental studies were carried out on two pages of writ-ing samples from the IAM (650 writers), the RIMES (375 writers), and a combination of these databases (1,025 writ-ers). According to the results, the highest identification rate of 91% was obtained on the IAM database by combining the codebook and counter features [ 23 ]. An interesting observa-tion is that both the codebook features and the combination of the codebook and contour features have a weak performance on the RIMES database when compared to the performances obtained on the IAM database. The reason of this result could be that the databases do not exhibit the same variability. In an earlier study, the authors divided the handwriting image into small sub-images as in [ 3 ] and then grouped them accord-ing to their morphological properties [ 17 ]. They applied the Bayes classifier on a dataset from the IAM database of 50 writers, with one page per writer, and obtained a 94% iden-tification rate.

In another codebook-based study, Bensefia et al. [ 35 ]clus-tered the segmented graphemes to produce a codebook that was termed  X  X riter invariants. X  Extending the same idea in a later study [ 36 ], instead of clustering the graphemes of each writer separately, all the graphemes of the database were clustered to define a common feature space over the entire dataset. While writer identification was performed by a tex-tual-based information retrieval model, writer verification was performed by a mutual information criterion between two handwritten documents. They achieved an 86% identifi-cation rate and a 96% verification rate on a dataset from the IAM database of 150 writers, and a 95% identification rate and a 96% verification rate on the PSI database of 88 writers. Geometrical features are also a widely used feature type. Marti et al. [ 12 ] divided the handwriting text line into three zones and extracted features by using the dimensions of these zones. With the K-NN classifier on a dataset from the IAM database of 20 writers, a 90.7% identification rate was obtained. Bozekova et al. [ 16 ] also extracted features using the dimensions of three handwriting zones. They performed writer verification on a dataset from the IAM database of 40 writers, with100 pages. Three systems based on feature matching by Euclidean distance, grapheme clustering [ 3 ], and the combinations of these two systems were proposed for verification. The highest verification rate of 96.5% was obtained with the third system. In another study, Schlapbach and Bunke [ 18 , 19 ] introduced a kind of sliding window tech-nique to extract nine geometrical features from text lines. Features are extracted for each position of the window, which is pixel by pixel. The window size is determined experimen-tally and fixed to the same size for all text lines. On a data-set from the IAM database containing 100 writers, with five pages per writer, a 96% identification rate and a 97.5% veri-fication rate with HMM [ 18 ] and 97.88% identification rate with GMM [ 19 ] were obtained. It would be better to deter-mine the window size automatically depending on the writing style rather than using a fixed size for all writers. An adap-tive windowing will also not be affected by the handwriting images scanned in different resolutions, which is a real-world scenario. Therefore, in our study, we propose dynamic win-dows that are adaptive for any handwriting. We also extracted proposed features from the separate analysis of the three handwriting zones, in addition to geometrical features that are determined by using the dimensions of these zones. The earlier work discussed in this section has been summarized in Table 1 giving a comparison based on the proposed feature types, databases, classification methods and correct identifi-cation rates. 3 Feature extraction Even when a person writes the same text two times sequen-tially, the writing cannot be uniform. Writer identification and verification are only possible when the variation in hand-writing style between different writers exceeds the variations intrinsic to every writer considered in isolation [ 37 ]. Hand-writing samples of three different writers are shown in Fig. 1 [ 3 ], in order to see inter-and intra-writer variability. Contrary to handwritten recognition, the inter-writer variability is the most effective factor to determine the writer X  X  identity.
The selection of discriminative features is a crucial step in the verification and identification process, because the next step uses only these features and acts upon them [ 13 ]. The process of deriving discriminative features increases the correct identification rate of the classifier and allows higher classification accuracy. Indeed, although some features may provide useful information for the writer identification task, some features may also be analyzed in conjunction with the decision of the classifier. Hence, the features should be regarded together with the classifier type to obtain the best results.

In practice, forensic document examiners already have determined some kind of features by means of tools and visual observation. And this makes the performance of the identification system directly dependent to the performance of the person achieving this effort. It could be argued that all document examiner features could eventually be com-putational features X  X hen the correct algorithms have been defined. Although, computational algorithms allow defin-ing many features which are impossible to be measured by human, it is fact that most of the document examiner features are not yet computable [ 2 ]. The main difficulties to compute the document examiner features are that they are text depen-dent and their automatic extraction would require recogni-tion, moreover some of the features such as embellishment, legibility or writing quality is qualitative.

Inthissection,weespeciallyfocusonanewfeatureextrac-tion model proposed in this paper. We utilize some of the fea-ture extraction studies in the literature in a different manner while designing our model. 3.1 Preprocessing Some image processing steps may be required before fea-ture extraction to eliminate environmental effects like pen type, paper quality etc. or to put the text lines in a regular form depending on the model used in the extraction process. Text lines in the handwritten pages of IAM database have already been segmented and cropped. They do not include much noise as well. Therefore, we do not need any prepro-cessing such as line segmentation or noise reduction.
Text line images in the database consist of 256 gray lev-els. Hence, we only perform a binarization process just to distinguish the background and text and to make the math-ematical calculations easier. This process converts the gray-scale image to pure black and white colors. For this purpose, we determine a threshold level by using Otsu X  X  method [ 38 ] so that any value higher than the threshold is assumed to be white and any value lower than the threshold is assumed to be black. Figure 2 shows the histogram and threshold level of a handwriting text line image. In our process, black repre-sents the text and white represents the background. An exam-ple of gray-scale and binarized text line images is shown in Fig. 3 a, b, respectively.

While some preprocessing operations are applied to reduce the variations in the handwritten text, they may cause to loose information that would help extracting some of the distinguishing features. Although the features such as writ-ing X  X  height and thickness are peculiar to the writer, some authors prefer to eliminate these features by applying scaling and thinning processes with the cost of losing their discrimi-native properties. But, we avoid removing any writer-specific information and do not prefer such preprocessing.

We analyze the handwritten text lines in three zones: upper extension zone, lower extension zone and main zone (Fig. 4 ). The idea of dividing handwritten text lines into three zones are proposed in reference [ 12 ] to define basic geometric fea-tures and in reference [ 19 ] to perform vertical scaling of the text lines.

To divide a text line into three zones, first of all, the hori-zontal projection of the text line image is computed (Fig. 5 ). The minimum value of the projection P min and the maximum value of the projection P max are computed as follows: P where r is the number of rows in the text line and P i is the value of the projection at the i th row. Since most of the infor-mation is included in the main zone, it is expected that the highest value of the projection corresponds to this zone. We constitute two ghost lines on the projection with the first line (
L lower border of the main zone (Fig. 5 ). To find out the exact positions of these borders, the projection is scanned from the beginning to the end and all possible zones covered by L 2 and L 3 are detected. Then, the squared errors are summed for each possible position of these lines as follows: D ( L where D ( L 2 , L 3 ) denotes the total squared error for the selected upper border position ( L 2 ) and lower border posi-tion ( L 3 ) and P L is the value corresponding to the index L of projection (Fig. 5 ). The top line is represented by ( L 1 bottom line is represented by ( L 4 ) (Fig. 4 ).
 Finally, the values of L 2 and L 3 for which the minimum D ( L lower borders of the main zone (Figs. 4 , 5 ): L , L 3.2 Global features Slant, width, thickness, surface area, size, and density are the features that reveal individual handwriting style. These features are widely used by document examiners and can eas-ily be interpreted visually. In this section, we introduce the mathematical models that represent the visual attributes of handwriting. Since these features possess the characteristics of the entire text line, they are called global features.
The feature extraction models are based on the three hand-writing zones. Since the dimension of handwriting may vary for each writer depending on available space or other fac-tors, the ratios between the dimensions are preferred. First, the width of the handwriting and the thickness of the strokes are computed.

To compute the width, the middle row of the main zone is determined. In this row, the length w i of each run of white pixels between two black runs is measured (Fig. 4 ). To elim-inate outliers, such as inter-word spaces or very small gaps, the median of these values is computed and used as a feature representing the handwriting X  X  width [ 12 ]: w = median ( w Thickness of strokes is computed in the similar way. At this point, the length t i of each run of black pixels between two white runs is measured (Fig. 4 ): t = median ( t Before introducing the global features, the following defini-tions are given to help expressing the global features mathe-matically: p main zone is the number of black pixels in the main zone: p where the c is the number of the columns on the text line and p , j indicates the value of the pixel on the text line image. S main zone is the area of the main zone: S where d line is the length of the text line and h 2 is the height of the main zone. w t denotes the number of black-to-white transitions.  X  denotes the slant angle of a text line and computed by means of the vertical projection approach. The central idea is that the projection of a text line which is written straight up will have larger and more distinct peaks [ 39 ]. Therefore, we shear the text line image at different angles in both directions by means of affine transforms. For each angle, we compute the vertical projection. The angle at which the projection gives the highest peaks is taken as the slant. Figure 6 shows the original and slant corrected text line images and vertical pro-jections belonging to these images.

The global features are indicated by the letter  X  X  X  and defined as follows: g1 = w, g2 = t /w, g3 = h 2 / t , g5 = d line /w t , g6 =  X .
 These features represent especially the tightness, intensity, surface area and slant information of the handwriting. The most important visual attribute of handwriting that reveals individual writing style is the slant. The handwriting slant is also a very stable personal characteristic [ 3 ]. 3.3 Local features In this section, we design a new feature extraction model based on dynamic windows. We also propose the separate analysis of each of three handwriting zones at a local level, because each zone has different handwriting characteristics peculiar to the writer. We especially avoid the preprocess-ing steps that tend to remove writer-specific information such as scaling and thinning. Instead of standardizing the dimensions, processing each handwriting zone separately minimizes the effect of within-writer variability in our fea-ture extraction method.

The width of the dynamic window is not fixed and not determined experimentally. The window width is equal to the handwriting width (the feature g1), and the height of the window is equal to the height of the text line to be scanned. Thus, the width and height of the window are varied with respect to the text line. The text line is scanned horizontally from left to right based on the middle row pixels of the main zone and following steps are applied (Fig. 7 ): 1. Detect the start and end points of first white run. 2. Slide the dynamic window to the detected start point. 3. If the dynamic window vertical borders intersect the 4. Segment the image covered by the dynamic window. 5. Turn the dynamic window width to its original size. 6. Detect the start and end points of the next white run. 7. Repeat steps 2 X 6 until there are no more white runs. 8. Concatenate all segmented images (Fig. 8 ).
 Thedynamicwindowscapturethecrucialpartsofthetextline image while removing what is unnecessary. Consequently, the final image constructed by the dynamic windows consists of the concatenated regions obtained from text line image. The following definitions help to express the local features mathematically: x top i = vertical position of the highest black pixels, i = 1 , 2 ,..., c x bottom i = vertical position of the lowest black pixels, i = 1 , 2 ,..., c .

Six features extracted from the final image are indicated by the letter  X  X  X  and defined as follows: l1 = l2 = l3 = l4 = l5 = the mean of the number of black pixels on columns , l6 = the mean of the number of white transitions Envelopes of the highest and lowest pixels obtained from a text line image are shown in Fig. 9 . Local features reveal some individual characteristics of a writer: l1 and l2 represent both the dimension and regularity properties, l3 and l4 rep-resent both the movement and slope properties, l5 represents the density property, and l6 represents both the sparseness and tightness properties. Since the features are generated by means of a specific local region of the text lines, these fea-tures are called local.

Local features are extracted from the main zone of the text lines and the complete text lines by means of dynamic win-dows. Since a complete text line contains upper, main, and lower zones together, features extracted from a complete text line will provide the relative information among the hand-writing zones when combined with the features extracted from the main zone.

For the upper and lower zones, which include the upper and lower extensions of the handwriting, we removed the gaps and concatenated the textual particles. Then we extracted the same six local features for each of both zones.
In total, four sets of six local features were obtained from upper, main, and lower zones and the complete image of the text line. Each set contained six local features, which are indicated by the capital letters  X  X FS X  (Local Features Set) and defined as follows: LFS1 = 6 local features (l1, l2, l3, l4, l5, l6) from main zone, LFS2 = 6 local features (l1, l2, l3, l4, l5, l6) from complete text line, LFS3 = 6 local features (l1, l2, l3, l4, l5, l6) from upper zone, LFS4 = 6 local features (l1, l2, l3, l4, l5, l6) from lower zone. 4 Experimental study 4.1 Database The handwritten text line images used in our experiments are derived from the IAM (Institute of Computer Science and Applied Math) handwriting database [ 8 ]. The database contains 1,539 pages of handwritten English texts taken from 657 different writers. The pages were scanned at 300 dpi, 8 bits/pixel, gray-scale. The number of pages is varied from one to five for each writer. The relations between the number of the writers, pages and text lines are given in Table 2 . Each page has variable textual contents which are selected from Lancaster Oslo Corpus [ 40 ]. Handwritings in the database are produced by habitual and natural script style of writers without any forgery.

The database also includes words and text lines segmented from the pages. In our study, the features were extracted from text lines. Length of the text lines varies between 112 and 2,260 pixels. The average text line length is 1,702 pix-els. However either the short text lines or noisy text lines would cause loss of information, we didn X  X  eliminate any lines. Figure 10 shows an example of short and noisy text line in the database.

We conducted our experimental studies using two data-sets obtained from the IAM database. The first dataset has been proposed in recent years and used by some researchers [ 18 , 19 ]. To constitute this dataset, writers who have at least five pages were selected. The number of text lines per writer varied between 27 and 54 and the total number of text lines was 4,307. Although the labels of these text lines were avail-able, we could not access the text lines belonging to the last seven of the 100 writers. Thus, 4,075 handwritten text lines of 93 writers were used in this study. The number of text lines belonging to 93 writers varied between 29 and 54.

The second dataset is an expanded version of the first and firstly constituted in this study to evaluate the effect of the number of writers inawriter identificationproblem. Thus, we increased the number of writers to 212 by selecting those who had at least 18 text lines. The minimum number of text lines belonging to writers of IAM database is given in Table 3 .The second dataset completely covered the first, and contained a total of 7,117 text lines. The number of text lines belonging to 212 writers varied between 18 and 54. 4.2 Writer identification In the preprocessing step, the text line images were bina-rized and divided into three handwriting zones, as described in Sect. 3.1 . Then, the global g1 to g6 and the local feature sets LFS1 to LFS 4 were extracted, as described in Sects. 3.2 and 3.3 .

Two sets of experiments were conducted to test the extracted features. In the first set, the features obtained from the first dataset were tested with different types of classifiers for evaluating the contribution of the features to improve identification rates. The classifiers used in the identification phase were K-NN, GMM, and NDDF Ba-yes classifier, which are well known and can be cited from any pattern recognition book. The second set of experi-ments aimed to analyze the performance of the features under conditions such as the increased number of writers to discriminate in the database and decreased number of text lines in a training set. The second set of experiments was conducted with the same classifiers on the second data-set.

The datasets were split into four disjoint sets for each writer to perform a four-fold cross-validation technique. Iter-atively, three out of the four sets were used for training and the remaining set used for testing. The cross-validation tech-nique guaranteed that the training and test sets were dis-joint and that the maximum possible amount of test data was used [ 18 ]. This technique was repeated four times and the final recognition rate was obtained by averaging the four results obtained from the four test sets. As the num-bers of text lines per writer varied between 18 and 54, the numbers of text lines per writer for each of the four sets varied as well. For example, if a writer has 38 text lines, the numbers of text lines for each of the four sets of that writer are 10, 10, 9, and 9, respectively. The total num-bers of text lines per writer and the numbers of text lines for each of the four groups of writers are provided on the Internet. 3
The classification systems were implemented in accor-dance with the Pattern Classification book [ 41 ] and the Pattern Classification Tools of Matlab [ 42 , 43 ], which pro-vide fast and flexible implementation for pattern recognition studies.

The parameter K in the K-NN method and the num-ber of the Gaussian Mixture Components were optimized experimentally with respect to the leave-one-out error on the training sets. The combination of local feature sets (LFS1 to LFS4) and global features was used to achieve parameter optimization experiments. The value of K and the number of mixtures were systematically varied from 1 to 10. According to the experiments, for the K-NN classifier, K = 1 nearest neighbors, and for the GMM classifier, three mixtures gave the maximum correct iden-tification.

To give the mathematical definitions of the classifi-ers, we let  X  =[  X  1 , X  2 ,..., X  C ] denote C classes and [
X vectors, each of which belongs to class  X  j , where j = 1 , 2 ,..., C .
For the K-NN classifier [ 43 ], the Euclidean distance was used as distance criterion. For K = 1 nearest neighbor, to determine the class  X  j of the unknown writer, we measured the similarity with each class by computing the Euclidean distance between the feature vectors of each class and fea-ture vector X U of the unknown writer. The unknown writer was then assigned to the class  X  j for which the minimum distance is obtained: j = arg min For the GMM classifier [ 43 ], the distribution of the feature vectors of a writer is modeled by a Gaussian mixture density. For a d-dimensional feature vector X, the mixture density for a specific writer is defined as: p ( X |  X  j ) = where M is the number of Gaussian mixtures and the mix-ture weights w sum up to one. p m ( X ) denotes the multivariate Gaussian density function: p where  X  m is d-by-1 mean vector, m is d-by-d covari-ance matrix, m and  X  1 m are its determinant and inverse, respectively, and ( X  X   X  m ) t is the transpose of the ( The parameters of a writer X  X  Gaussian densities; mean vec-tor  X  m , covariance matrix m , and mixture weights w m for all m = 1 , 2 ,..., M were initialized randomly. Next, GMMs were trained using the Expectation and Maximiza-tion (EM) algorithm. The parameters of the Gaussian den-sities were re-estimated until the likelihood score of the entire dataset did not change substantially or a limit on the number of iterations was reached. For each writer, a GMM was built and trained with data taken from this writer only. The feature vector X U of the unknown writer was applied to the trained models of each writer and then the class posterior probabilities corresponding to each train-ing model were calculated. The unknown writer was then assigned to the class for which maximum probability is obtained.

For NDDF Bayes classifier [ 42 ], normal density discrim-inant functions g j ( X ) for each of the classes are defined as follows; g ( X ) = X  1 where p ( X  j ) is the prior probability of the class  X  j .The mean  X  j and covariance matrix j of the feature vectors in the training set of each class were computed to construct Normal Density Discriminant Functions. The feature vector X
U of the unknown writer was applied to discriminant func-tions of each class and then the outputs were calculated. The classifier is said to assign feature vector X U of the unknown writer to class  X  j if: g j ( X U )&gt; g i ( X U ) for all i 4.3 Results In the first set of experiments, features were tested using the three different classifiers on the first dataset. The aver-age correct identification rates obtained from four-fold cross-validation for each feature group and their combinations are given in Table 4 . As Table 4 shows, local features gave much better results than global. In addition to high performance of individual local groups of features, the combination of them had a significant positive effect on identification rates. All classifiers indicated similar effects on these combina-tions as well. Satisfactory results, which were higher than the 96% identification rate, indicated that the proposed features were easily used in writer identification with any classifier. Combining the global features with local groups of features increased the identification rate about 0.5%. When the per-formances of the classifiers were compared, the NDDF Bayes classifier was found to be superior. The identification rates of either 98.76 or 98.25% are the best scores among results given in the literature [ 18 , 19 ] on the similar dataset. A com-parison of the performances obtained in our study and earlier studies with similar data is given in Table 5 .
In the first set of experiments, contributions of each indi-vidual features were evaluated as well. To determine the contribution of each individual feature to the correct iden-tification rate, several tests were conducted with NDDF Bayes classifier on the first dataset. Global features and local features were evaluated independently. The local features extracted from the complete text line (LFS2) were used to evaluate the local features. The correct identification rates of the global features (g1 X  X 6) and the local features (l1 X  X 6) of LFS2 on the first dataset were given as 57.06, and 86.89%, respectively (Table 4 ). The contributions of each individual features were determined as follows: 1. Removethefeaturetobeevaluatedandtesttheremaining. 2. Subtract the obtained correct identification rate from the 3. Repeat Steps 1 and 2 for each individual feature. The graphics indicating the contribution of individual fea-tures to the correct identification rate are shown in Figs. 11 and 12 for global and local features, respectively. The results indicated that each individual feature positively affected the correct identification rate. While local features seem to have almost equal contributions, the individual global features g3 and g6 had better contributions among the other global fea-tures.

In the second set of experiments, performances of the fea-tures were evaluated on the second dataset with the same clas-sifiers. In this experiment, although the number of writers to discriminate in the database was increased, the possible num-ber of text lines in the training sets was decreased for the rest of the first dataset in the second dataset. From the point of text line numbers in the training set, the worst possible case to have occurred with the four-fold cross-validation was 21 text lines for the first dataset and 13 text lines for the second. The average correct identification rates obtained from four-fold cross-validation for the same feature groups are given in Table 6 . Although similar results were obtained as in the first set of experiments, the correct identification rates were reduced with only about 1% decrement for the best scores. Although there were an increased number of writers to dis-criminate in the database and a decreased number of text lines in the training sets, the perfect results obtained from the sec-ond dataset again prove the robustness of the features. The identification rate of 97.78% was still the best score among the results given in the literature (Table 1 ).

Additional experiments were conducted to analyze the evolution of the scores when the number of text lines avail-able for training was decreased. First, we made the avail-able number of text lines equal for each writer to fit all 212 writers in the experiments. This allowed us to measure the effect of the decreasing number of text lines in train-ing more definitely. Since each of the 212 writers in the second dataset had at least 18 text lines, we kept only the first 18 text lines for the writers with more than 18. Then the number of available text lines per writer was decreased from 18 to four one-by-one and each case was tested. Con-sequently, 15 cases were constructed and tested. For each case, the text lines were split into four sets to perform four-fold cross-validation. Table 7 indicates the number of text lines per writer in the four sets for each case. Each case was tested by combining the local feature sets LFS1 to LFS4 and the NDDF Bayes classifier. The average correct identification rates obtained from the fourfold cross vali-dation are shown in Fig. 13 as a function of the number of text lines. While the 91.62% correct identification rate was obtained for four text lines per writer, the 95.9% cor-rect identification rate was obtained for 18 text lines per writer.

As Fig. 13 shows, there was not a sharp decrease in the identification rate as the number of text lines decreased. It can also be seen that the correct identification rate of 97.09%, which was obtained with all available text lines for the same conditions (Table 6 ), decreased to 95.9% when only 18 text lines per writer were used.

Similar experiments were also conducted for evolution of the scores when the number of writers in a query was increased. We again fit all 212 writers to have 18 text lines, and text lines were split into four sets for fourfold cross-val-idation. Therefore, each of the four sets per writer had 5, 5, 4, and 4 text lines, respectively. Twenty-one cases were constructed by increasing the number of writers ten by ten from 12 to 212. Each case was tested by combining local feature sets LFS1 to LFS4 and the NDDF Bayes classifier. The average correct identification rates obtained from four-fold cross-validation are shown in Fig. 14 as a function of the number of writers. While a 97.77% correct identification rate was obtained for 12 writers, a 95.9% correct identifica-tion rate was obtained for 212 writers. It can be seen from Fig. 14 that the increasing number of writers did not sharply decrease performance. 5 Conclusion In this paper, the problem of identifying a writer using a text-independent, off-line method is addressed. A comprehen-sive review of the research including the proposed features, classification methods, database, and experimental results is also given. Since reported experimental studies have been achieved with different datasets, comparing the approaches proposed in the literature is impossible. Therefore, we used images of 93 writers in the IAM database, which is used in the literature with 100 writers. However, since the remaining seven writers could not be accessed, the results obtained from 93 of the 100 writers can still be used to compare the per-formances of writer identification systems. The experimen-tal studies were conducted using two datasets obtained from the IAM database. While the first dataset is used by some researchers in the literature, the second dataset is constituted as an expanded version of the first in this paper. The second dataset was used to analyze the performance of our features under conditions such as an increased number of writers to discriminate in the database and a decreased number of text lines in the training set. We broadcast the labels of the text lines used in the second dataset to provide a benchmark for the research community.

New methods are proposed to extract the individual fea-turesfromhandwrittentextlines.Whenanyhandwritingdoc-ument is given, the document must be segmented into text lines as a preprocessing step before the proposed methods are applied. The proposed features are easily computed and give remarkably high, results. The proposed feature extrac-tion method aims to design a dynamic model that can be formalized according to a given text line. By analyzing the text lines in three writing zones at a local level, charac-teristics that are specific to each writer embedded in these zones can be expressed. Features are divided into two groups: global and local. Global features represent the visual attri-butes of handwriting and possess the characteristics of the entire text line. Local features reveal some individual charac-teristics of a writer such as dimension, regularity, movement, slope, sparseness, tightness, and density. These features are generated from specific local regions of text lines that are determined automatically and vary according to the writer X  X  handwriting width.

Local groups of features and their combinations were tested with the K-NN, GMM, and NDDF classifiers to eval-uate the contribution of features to the correct identification rate. The results were compared for each selected feature groups and classifiers. The local features gave much better results than global features. In addition to the high perfor-mance of each local group of features, combining them had a significant positive effect on identification rates. Satisfac-tory results for all classifiers indicate that the proposed fea-tures can be effectively used in writer identification with any classifier. The identification rates obtained in this study are appreciably high, such as 98.76%, when compared with the results in the literature on the same dataset.

We also evaluated individual feature performances. The results indicate that each individual feature positively affects the correct identification rate. While the individual local fea-tures have almost equal performance, the individual global features g3 and g6 had better performances among the other global features. The proposed features can also be adapted to a writer verification process.

The second dataset derived from the IAM database was also used in the experimental studies. While similar results were obtained as in the first dataset, the correct identification rates were saved with only about 1% decrement. The remark-able results obtained from the second dataset again prove the robustness of the features. We set up various experiments for analyzing the evolution of the scores as a function of both the number of text lines and the number of writers. It can be seen that neither the decreases in number of text lines nor the increases in the number of writers caused a dramatic loss of performance for the features. The results again demonstrate the stability of the proposed features.

Although, this study focused on analyzing the perfor-mances of the proposed features in different aspects; more than analyzing the classifier efficiencies, one can conclude from the results that the NDDF Bayes classifier outperforms the others with our features. The NDDF Bayes classifier has a simple and less-time consuming training phase as well. Since the harmony of the selected feature type and the selected clas-sifier significantly affected performance, it may be difficult to say absolutely which classifier is best. The classifier effi-ciencies could be compared in a further study for both their advantages and disadvantages.
 References
