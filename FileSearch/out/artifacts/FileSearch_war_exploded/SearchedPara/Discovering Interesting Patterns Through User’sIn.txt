 In this paper, we study the problem of discovering interest-ing patterns through user X  X  interactive feedback. We assume a set of candidate patterns ( i.e. , frequent patterns) has al-ready been mined. Our goal is to help a particular user effec-tively discover interesting patterns according to his specific interest. Without requiring a user to explicitly construct a prior knowledge to measure the interestingness of patterns, we learn the user X  X  prior knowledge from his interactive feed-back. We propose two models to represent a user X  X  prior: the log-linear model and biased belief model .Theformer is designed for item-set patterns, whereas the latter is also applicable to sequential and structural patterns. To learn these models, we present a two-stage approach, progressive shrinking and clustering , to select sample patterns for feed-back. The experimental results on real and synthetic data sets demonstrate the effectiveness of our approach. Categories and Subject Descriptors: H.2.8 [Database Management]: Database Applications -Data Mining General Terms: Algorithms Keywords: Pattern Discovery, Interactive Feedback
Discovering interesting patterns is an important task in data mining. However, a common problem in most pattern discovery algorithms is that there are too many patterns in the output while only a few of them is really interesting to a user. Moreover, the measure of interestingness is of-ten subjective, and there is no consistent objective measure to represent user X  X  interest. A pattern could be interest-ing to one user but not to another. Consider a scenario in
The work was supported in part by the U.S. National Sci-ence Foundation NSF IIS -03-08215/05-13678 an d NSF BDI-05-15813. Any opinions, findings, and concl usions or recom-mendations expressed in this paper are those of the authors and do not necessarily reflect the views of the funding agen-cies.
 Copyright 2006 ACM 1-59593-339-5/06/0008 ... $ 5.00. the literature domain. There are often hundreds of papers published annually in a research area. To understand the research topics in the literature, one can mine frequently occurred terms, called theme patterns , from those papers. One such pattern from KDD conference papers is  X  X ssociate pattern mining X . A novice who wants to know the main re-search topics of KDD area will be interested in this pattern. However, an experienced researcher who would like to dis-cover new emerging topics will probably not think it is an intriguing pattern at all.

Most existing pattern mining methods focus on efficiently computing patterns which satisfy a pre-specified criterion. The criterion can be simply a minimum support constraint or as complex as the unexpectedness with respect to a user-specified model, e.g. , the Bayesian Network [8]. In many cases, however, none of these pre-specified criteria can model the user X  X  interestingness measure really well: the minimum support constraint is often too general to catch a user X  X  prior knowledge and consequently too many common patterns are often generated in the results; the Bayesian network crite-rion requires users to constru ct a reasonably precise back-ground knowledge explicitly, which is found to be difficult in many real applications.

In this paper, we propose to discover interesting patterns through user X  X  interactive feedback . We assume a set of can-didate patterns ( i.e. , frequent patterns) has already been mined. Our goal is to help a particular user effectively dis-cover interesting patterns acco rding to his real interest. In-stead of requiring the user to explicitly construct the prior knowledge precisely beforehand, we alleviate the user X  X  bur-den by only asking him to rank a small set of sample patterns according to his interest.
 Figure 1: Discovering Interesting Patterns from In-teractive Feedback
A framework of discovering interesting patterns is shown in Figure 1. Our system takes a set of candidate patterns as input. A model is created to represent a user X  X  prior knowledge, and the entire procedure is to learn the model parameters. At each round, a small collection ( e.g. , 10) of sample patterns are selected from the pattern collection and are asked for the user X  X  pre ference. The user ranks the sample patterns, and the feedback information will be used to refine the model parameters. The system then re-ranks the patterns according to the intermediate learning result and decides which patterns to be selected for next feedback. The interaction continues for several rounds. Finally, the top-ranked patterns are output as interesting patterns.
There are two basic research questions in discovering in-teresting patterns through interactive feedback. First, how does the system model a user X  X  prior knowledge? Second, how does the system select sample patterns to maximize the learning benefits? In this paper, we propose two mod-els, the log-linear model and biased belief model ,torep-resent user priors. The former is designed only for item-set patterns whereas the latter can also be applied to sequential and structural patterns. For e ffective learning from user X  X  interactive feedback, we develop a two-stage approach, pro-gressive shrinking and clustering , to select interesting and novel patterns for feedback. Our experimental results show that the proposed approaches are effective in discovering user-specified interesting patterns.

The rest of the paper is organized as follows. Section 2 introduces our problem formulation. The models for prior knowledge are discussed in Section 3, followed by learning procedure from the user X  X  interactive feedback in Section 4. We present the experimental results in Section 5. Section 6 concludes our work.
We first discuss the formulations of interestingness and user feedback and then present the problem statement.
We assume that a set of frequent patterns P has been mined and forms the input of our system. Each pattern P  X  X  consists of the composition of P ( i.e. , the item-set, sequential items or graphical structure of P )andasetof transaction IDs which contain P .

The interestingness of a pattern P is evaluated by a subjec-tive measure [11] that computes the difference between the observed frequency f o ( P ) and the expected frequency f Here frequency is the proportion of transactions which con-tain the pattern. We model the subjective interestingness measure using two components: a model of prior knowledge and a ranking function. The model of prior knowledge M is used to compute the expected frequency of P as follows: i.e. , M takes a pattern P  X  X  and a model parameter  X   X   X  as inputs and returns f e ( P ) as the expected frequency of The ranking function R is of the form: which returns the degree of interestingness of the pattern according to two frequencies.
In order to learn to rank patte rns according to the subjec-tive measure of user interestingness, we ask for user feedback interactively. A user feedback is formulated as a constraint on the model to be learned. We iteratively present the user asetof k sample patterns { P 1 ,P 2 ,...,P k } and ask for the user X  X  preferences. P i is ranked above P j ( i.e. , P i &gt; the user judges P i is more interesting. A user can provide a fully ordered or partially ordered feedback. Every pair of relative order P i &gt; f P j is formulated as a constraint as follows:
The problem of discovering interesting patterns through interactive feedback can be stated as follows: Given a set of patterns, the system ranks patterns according to a user-specific interestingness measure, and at the same time min-imizes the user X  X  efforts in providing feedback.

The user-specific interestingness measure consists of a rank-ing function and a model of prior knowledge. Generally, it is relatively simple to determine the ranking function R :A user can either select a system-default function or define one by his own. However, it is difficult to determine the model of prior knowledge M and its parameters  X  .Inthispaper, we mainly focus on the models and the methods of learning parameters from user feedback. Without loss of generality, we use the following log-linear ranking function: The above function measures the degree of how f o ( P )is larger than f e ( P ). Our framework can accept other types of ranking functions such as linear ( e.g. , f o ( P )  X  f details in Section 3.3.

Given the ranking function, the problem of discovering user-specific interesting patterns is equivalent to learning the model of the user X  X  prior knowledge.
We discuss two models to represent user X  X  prior knowl-edge. One is log-linear model which works for item-set pat-terns only, and the other is biased belief model which can also be applied to structural patterns.
We introduce the fully independent log-linear model and its constrained formulation using ranking SVM[9].
Statisticians have been using log-linear model [2] to study the frequency of an item-set comprising n -items: f ( x 1 ...,x n ). More formally, the saturated log-linear model for f is expressed as: where the u summands capture the interactions between the items, and x j is chosen from { i j , i j } . For example, denotes the interaction between i 1 and i 2 .

The saturated log-linear model depicted above is the most general model for n items. Simpler log-linear model reduces the number of parameters by specifying certain interaction effects to be zero, which can typically be interpreted as aformof independence between the corresponding dimen-sions. The fully independent model assumes the values of u over two or more items vanish. Furthermore, since we are not interested in the generalized patterns, we do not need the value of u ( i j ). As a result, there are only n +1 variables: u and u ( i j )( j =1 ,...,n ). We simplify the notation u ( u . Given an item-set pattern P =( i 1 ,...,i s ), its expected frequency by a fully independent log-linear model is:
The relative ordering P 1 &gt; f P 2 provided by the user feed-back gives the constraint: Here, log f o ( P 1 )andlog f o ( P 2 )areconstants. log f log f e ( P 2 ) are both linear combination of variables u ( j =1 ,...,n ). Basically, we want to learn these variables so that the number of violated constraints is minimized. This problem is known as NP-hard [3] and a practical approach is to use ranking SVM formulations [9].

We introduce a weighting vector as learning variables: where u, u 1 ,...,u n are log-linear model parameters and a scale variable associated to log f o ( P ). Each pattern be represented by a vector: where x j =1ifandonlyif i j  X  P . The feedback constraint canberewrittenas: The ranking SVM formulates the problem as the following constrained optimization problem: By minimizing w 2 , the formulation tries to maximize the generalizability of the model. C is the parameter which controls the trade-off betw een the learning error and the generalizability. Algorithms have been developed to solve the problem efficiently. Detailed introductions can be found in [9].
The log-linear model is an item-set based model which cannot be applied to more complicated patterns ( e.g. ,se-quential patterns or structural patterns). Here we introduce a more general biased belief model .
Instead of modelling user prior on patterns directly, we model user prior on data. The intuition is that the expec-tation of a pattern is determined by user X  X  belief in the un-derlining data. If a user has high belief in the subset of the data that supports the pattern, the user will have high ex-pectation of this pattern; on the other hand, if a user knows little about the data, the expectation will be low.
The biased belief model derives the expected frequency of a pattern from the belief in transactions containing the pat-tern. To measure user X  X  belief in the data, we assign a belief probability to each transaction. A higher probability means the user is more familiar with this transaction, whereas a lower one indicates that this transaction is novel to the user. Let us assume that each transaction is independent. The set of transaction data forms a multiple-Bernoulli distribution , where each binary trial corresponds to the event whether the user knows the transaction or not. Therefore, the user X  X  prior knowledge can be represented by a vector [ p 1 ,...,p where p k is the belief probability for transaction k ,and is the total number of transactions. Given a pattern P ,the value of f e ( P ) is proportional to the expected number of occurrences of P : where x k ( P ) = 1 if transaction k contains pattern P ,other-wise, it is 0.

The learning task is to determine the parameters p k .Given a user feedback P i &gt; f P j ,wehave: that is, Similar to our formulation in log-linear model , we introduce a weighting vector: and each pattern P is represented by a vector: We again use the ranking SVM method and formulate the optimization problem as follows: The additional constraints w k  X  0 indicate that the belief probability for each transaction cannot be less than 0. We do not apply the constraint w k  X  1 here because all w k  X  X  can be scaled to no larger than 1.
Unfortunately, the constrained formulation presented above does not give satisfactory results in experiments. One im-portant reason is that we assume the transactions in user X  X  prior are similar to the observed transactions, which is not always true. Consider an extreme situation where an ob-served data set contains a set of transactions supporting both patterns P 1 and P 2 , and also contains another set of transactions supporting P 2 only. But there is no transaction containing P 1 only. A user may have high expectation of pattern P 1 but not P 2 . The constraints w k  X  0 are too rigid so that the expectation of P 2 cannot be less than P 1 .This violates the user X  X  belief. To improve the learning power of themodel,weremovetheconstraints w k  X  0toallowsome transactions to be assigned to negative weights. In this ex-ample, the transactions containing pattern P 2 only will have negative weights so that they can downgrade the high belief (of P 2 ) brought by the transactions containing both P 1 P . Hence the model is more amenable to fit in the user X  X  prior knowledge.
With respect to the ranking function, we have demon-strated both models using a log-linear formulation. The bi-ased belief model can also take the linear ranking functions ( e.g. , f o ( P )  X  f e ( P )). Assigning v ( P )=[ f o ...,  X  x m ( P )] and w =[ u, p 1 ,p 2 ,...,p m ]( u is a scale vari-able) leads to a linear ranking SVM formulation. Extend-ing to nonlinear constraint formulations, both models can use arbitrary rank ing functions. Let R ( f o ( P ) ,f K ( v ( P ) ,w ), if K satisfies Mercer X  X  condition [4], it can be used as SVM kernel; otherwise, the formulated nonlinear problem can be solved by existing mathematical program-ming package ( e.g. , SNOPT [5]). Recent progress on nonlin-ear programming [5] shows that problems up to 40 , 000 vari-ables and constraints are solvable within reasonable time.
In this section, we discuss the strategy to select sample patterns for effective learning. The importance of selecting best samples for user feedback has been recognized by some previous work [13, 10]. Ideally, the system should collabo-rate with the user in the whole interactive process to improve the ranking accuracy and reduce the number of interactions. In this section, we first discuss the selection criteria and then propose our sample selection method. Finally, we present the complete algorithm as a summary. We first propose two criteria to select sample patterns. The first is that the selected sample patterns should not be redundant to each other. We say there is redundancy between two patterns if they are close in both pattern com-position ( i.e. , the set of items) and frequency. Since redun-dant patterns naturally rank close to each other, present-ing redundant patterns for feedback does not maximize the learning benefit and increases user overhead. The second criterion is that the selected patterns should help to learn a user X  X  knowledge about the ranking of interesting patterns since a user generally has preference over higher ranked pat-terns, and the relative ranking among uninteresting patterns is not important.
Our two criteria are also discussed in active feedback with information retrieval [10], where the authors proposed to first cluster top-N documents, and then select the k cen-troids from each cluster as feedback samples. This method was shown to be effective in document query. However, the method cannot be directly applied here. This is because in information retrieval, the documents ranking is query guided. Interesting results are generally congregated around the query, and the initial top-N results are good enough to guarantee that most interesting documents are included. While in pattern ranking, the interesting patterns scatter over the whole pattern collections. At the beginning, the system has no idea which parts of patterns are interesting. Concentrating the initial top-N results will delay the dis-covery of interesting patterns.

We extend the method as follows. Instead of fixing the number of N for clustering, we adopt a two-stage approach, progressive shrinking and clustering , to select sample pat-terns at each iteration. We define a shrinking ratio  X  (0  X &lt; 1). At the beginning, the candidate set size N is equal to the size of the complete pattern collection. It gradually decreases to focus more on the highly ranked patterns. At each iteration, we update N =  X N , and the pattern set for clustering is the top-N patterns w.r.t. the current ranking.
Suppose a user agrees to examine k patterns at each iter-ation, we then cluster these top-N patterns into k clusters. We use the Jaccard distance [7] for clustering: given a pat-tern P 1 and P 2 , the distance between P 1 and P 2 is defined as: where T ( P ) is the set of transactions which contain pattern P . This measure is applicable to all kinds of patterns mined from transaction database, and also a valid distance metric [12].

We adopt a clustering criterion of minimizing the maxi-mum distance of each pattern to the nearest sample pattern. This is a typical k -center problem in graph algorithms and approximatable within 2 using a greedy algorithm. The al-gorithm first picks an arbitrary pattern. While the number of picked patterns is less than k , the algorithm continues to pick a pattern which has the maximal distance to the nearest picked patterns. The complexity of this algorithm is
O ( kn ). Due to the limited space, we do not introduce the details here, interested readers can refer to [6].
We call this clustering procedure online-clustering .Toim-prove the scalability of this step, we perform micro-clustering on the input pattern set at the beginning and only keep the representative patterns in each micro-cluster. Basically, a pattern P is absorbed by a representative pattern P r if P is a subpattern of P r and D ( P, P r ) &lt; .Here is a small value ( e.g. , 0.1). We start with a subset of maximal patterns (a pattern is maximal if its super pattern is not in the col-lection), and remove all the patterns that can be absorbed by one of those maximal patterns. Since maximal patterns contain more information about the pattern content, they are kept as representative patterns. This procedure repeats on the remaining patterns until there is no pattern left.
We have discussed the user prior models and the sample selection method. As a summary, we outline the complete algorithm for pattern ranking with user X  X  interactive feed-back in Algorithm 1.

The algorithm takes the entire collection of patterns as input. User can also specify the number of iterations he/she would like to provide feedback and how many patterns he/she would like to judge at each round. The algorithm works as follows. First, a micro-clustering is conducted on the input patterns set P , and only the representative patterns in P are used thereafter. Variable N indicates the number of top Algorithm 1 Discover Interesting Pattern Input: A set of n patterns, P Output: Ranked Pattern List 1:
P r = Micro-Clustering( P , ); 2:
N = |P r | ; 3: for ( i =0; i&lt;iter ; i ++) 4: C =top-N patterns in P r ; 5: Online-Clustering of C ; 6: Present k sample patterns to user for feedback; 7: Formulate constraints according to the user feedback; 8: Refining the model parameters by Ranking SVM; 9: Re-Rank Patterns in P r with the refined model; 10: Remove the k selected patterns from P r ; 11: N =  X N ; 12: Rank Patterns in P with the learned model; 13: return patterns (with the current ranking) to be considered for sam-ple selection (line 4). This value is progressively reduced by afactor  X  (line 11). Line 5 conducts the online-clustering to find k sample patterns for user feedback (see previous subsection). Line 6 asks user to provide feedback on the sample patterns. Lines 7 and 8 formulate the feedback as constrained problem, which is further solved by the ranking SVM. Note the constraints from the previous feedback are accumulated in the formulation. The model parameters are updated by the solutions of the ranking SVM and the pat-terns are re-ranked according t o the updated model. Line 10 removes the selected sample patterns so that they will not be selected again for user judgment. After the algorithm repeats iter times, the ranking results are output.
We set up an experiment environment to simulate user feedback. The intuition is that a user may consider a pattern interesting because he was previously exposed to data that has different flavor. Thus the user X  X  prior knowledge can be approximated by a background data set, and the expected frequency of a pattern is the frequency computed from this background data.

Using this methodology, we partition each data set in our experiments into two subsets: one for observed data and the other for background data. The background data is used to simulate a user X  X  prior knowledge. For each pat-tern P , f e ( P ) is the smoothed frequency in the background data. The background data provides a target pattern rank-ing which is used to simulate user feedback. Since our goal is to discover interesting patterns, our accuracy measure favors higher ranked patterns. Let top l ( k ) be the top-k %results reported by the ranking learned from the interactive feed-back and top t ( k ) be the top-k % results in the target ranking constructed by our simulation. The accuracy measure is defined as follows.
 We assume that the user provides fully ordered feedback. To minimize the user X  X  effort, at m ost 10 patterns are presented to the user at each iteration and at most 10 iterations are allowed. Since the number of constraints is upper bounded by 450, the scalability is not an important issue here because most constrained problems can be solved by ranking SVM within seconds. In all experiments, we use closed item-set (or sequential) patterns as input and set =0 . 1 for micro-clustering and  X  =0 . 1 for shrinking ratio. The ranking SVM [9] is called with its default parameter setting.
We conduct a series of experiments to examine the ranking accuracy w.r.t. different criter ia: item-set patterns, sequen-tial patterns and different sample selection strategies.
Using the simulation environment discussed above, our first task is to examine the ranking accuracy on the item-set patterns. The first experiment is run on a real data set pumsb [1], which consists of 49 , 046 transactions with 2 distinct items. The average length of transactions is 74. We extract the first 1 , 000 transactions from the original data set as observed data and the rest transactions are used as background data. By setting minimum support as 88%, we mined 8 , 234 closed frequent item-set s. The micro-clustering with =0 . 1 reduces them to 769 representative patterns. The accuracy of top 10% results of the log-linear model and biased belief model with different feedback size ( i.e. ,5and 10) is shown in Figure 2. We observed that both models achieve higher than 80% (70%) accuracy with feedback size 10 (5).
In this subsection, we examine the ranking performance on sequential patterns . We use the 2001-2002 KDD paper abstracts as the observed data and the 1999-2000 KDD pa-per abstracts as the background data. All abstracts are decomposed into sentences. There are 1 , 609 sentences in 2001-2002 data set. Using minimum support 0 . 8%, we mine 967 closed sequential patterns. The log-linear model is used by treating the sequential patterns as item-set patterns. The accuracy of the top k percent ( k =1 ,..., 10) ranking after 10 iterations is shown in Figure 3.

Not surprisingly, the biased belief model works better than the log-linear model . We further compute the limiting be-havior of both models by assuming that the fully ordered feedback on all 967 patterns is available for constraint for-mulation. This can be seen as the upper bound case of the ranking accuracy. An interesti ng observation is the ranking accuracy of log-linear model with the fully ordered feedback is even worse than that with 10 iterations. This indicates that treating sequential patterns as item-set patterns actu-ally introduces noise information to the log-linear model . For example, sequential patterns ab and ba are considered same as item-set patterns. However, they might have totally different frequencies. Hence, the fully ordered feedback does not help to learn a finer log-linear model . On the other hand, the biased belief model gets 80% for top 10 percent rankings with fully ordered feedback.
 Figure 2: Top-10% ranking accu-racy: k iterations.
Finally, we test the learning effectiveness by various strate-gies to select sample patterns for feedback. We compare our proposed strategy with the selective sampling approach [13] and the top-N clustering approach [10]. We use the same KDD abstract data set in the previous experiment and set the feedback size as 10. Since selective sampling does not consider pattern redundancy, it is very likely that the method will pick 10 very similar patterns. To make a fair comparison, we first cluster representative patterns into 100 groups and select 10 representative patterns using selective sampling criteria. For top-N clustering approach, the value of
N is set as 100, which is 10% of the total patterns. The shrink ratio of our method is set as 0 . 1. As shown in Figure 4, the selective sampling approach is comparatively worse because it does not favor higher ranked patterns. The ac-curacy of the top-N clustering approach is worse than that of the shrinking and clustering method until the 5-th iter-ation. This confirms that our proposed approach is more effective to locate interesting patterns, and the top-N clus-tering approach may miss some interesting patterns in the early iterations.
In many data mining approaches, the algorithm or the measure is pre-designed and the user accepts the results pas-sively. This paper introduces a new problem setting where the mining system interacts with the user. To discover inter-esting patterns for a particular user, we propose a framework to learn user X  X  prior knowledge from interactive feedback. We study two model formulations, the log-linear model and the biased belief model , and discuss the strategy to select sample patterns for user feedback. The performance of pro-posed approaches are tested on various data sets. Experi-ment results show that both models are able to learn user X  X  background knowledge. Moreover, the biased belief model also works for sequential and structural patterns.
The current work can be extended in several ways. First, we will study new models for sparse data set. As seen from the experiments, data sparsity may cause learning difficulty. Second, we will further exploit active feedback strategies to maximize the learning benefit. Finally, we will explore the interactive feedback on other personalized data mining applications such as user-specific summarization and clus-tering. [1] R. Bayardo, B. Goethals, and M. Zaki. Fimi 2004 [2] Y. M. M. Bishop, S. E. Fienberg, and P. W. Holland. [3] W. W. Cohen, R. R. Schapire, and Y. Singer. Learning [4] N. Cristianini and J. Shawe-Taylor. An introduction to [5] P. E. Gill, W. Murray, and M. A. Saunders. Snopt: An [6] T. F. Gonzalez. Clustering to minimize the maximum [7] A. Jain and R. Dubes. Algorithms for Clustering Data. [8] S. Jaroszewicz and T. Scheffer. Fast discovery of [9] T. Joachims. Optimizing search engines using [10] X. Shen and C. Zhai. Active feedback in ad hoc [11] A. Silberschatz and A. Tuzhilin. What makes patterns [12] D. Xin, J. Han, X. Yan, and H. Cheng. Mining [13] H. Yu. Svm selective sampling for ranking with
