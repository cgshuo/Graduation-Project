 The Digital Revolution on information storage and transmission increases the amount of information that we deal with in our daily lives. Although we enjoy the entertainment and convenience brou ght to us by such a variety of sources, the volume of information is increasing far more quickly than our ability to digest it. For instance, the Internet has become the most significant media source and is growing at an exponential speed. But the user ability of obtaining useful information in the Internet grows slowly. Tools that support for the effective retrieval of relevant information are still primitive  X  most information retrieval systems heavily rely on textual queries of users to identify their information needs [13]. Queries constructed by keywords only are, however, not powerful enough to express the needs of a particular user both semantically and contextually. To see this, consider the following common search scenario:  X  X ind movies showing this weekend in nearby cinemas that I most lik ely to like. X  Such a user information need requires the retriev al system at least to be able to capture user interest ( X  X ost likely to like X ). Unfortunately, most existing retrieval models and search technologies are incapable of achieving such a realistic retrieval goal, because they only focus on building the correspondence between textual queries and documents and lack mechanisms to model individual users who issue queries. Hence, it is essential to accurately mode l various user information needs beyond queries. With the recent advances in Huma n-Computer Interfacing and sensor technologies that make use of cameras, motion detectors, voice captures, GPSs etc., we have witnessed a research transition from information (document) centric computing into user centric computing; consider for example user profiling, that attempts to broadly understand users X  various interests, intentions etc. on the basis of the recorded human-computer interactions.

Also, large amounts of information exist in a dynamic form. To process streams of incoming data, we need an information system that can play a more active role during the information seeking process. Therefore, information filtering sys-tems arise [2]. In contrast to most retrieval systems that passively wait for user queries to respond accordingly, they ai m to actively filter out, refine and sys-tematically represent the relevant information and intuitively ignore superfluous computations on redundant data.

Combination of these two demands has created increasing interests in build-ing a recommender system that can steer us ers towards their p ersonal interests and actively filter relevant information items on the users X  behalf. As one of the dominant techniques, collaborative filtering has appeared in the domain of Information Retrieval (IR) and Human-Computer Interaction (HCI) [8]. They attempt to filter information items such as books, CDs, DVDs, movies, TV pro-grams, and electronics, based on a history of the user X  X  likes and dislikes. Exam-ples include the Amazon X  X  book recommendation engine ( amazon.com )andthe Netflix DVD recommendation engine ( netflix.com ). We believe recommender systems will eventually support companies to realize a shift from offering mass products and services to off ering customized goods and services that efficiently satisfy desires and needs of individual users.

In this paper, we would like to emphasize the following two crucial observations: 1. Although collaborative filtering exists in various forms in practice, its pur-poses can be generally regarded as  X  X tem ranking X  and  X  X ating prediction X . They are illustrated in Fig 1. The rating prediction (see Fig 1 (a) and (b)) aims at pre-dicting an unknown rating of an item for the user, with the requirement that the user has to explicitly rate a certain amount of items. This type of recommenda-tion has been widely conceived and well st udied in the research literature, since the pioneering work on t he MovieLens systems ( http://movielens.umn.edu ); from the early work on filtering netnews [15] and the movie recommender sys-tems ([9]) to the latest Netflix competition ( http://www.netflixprize.com/ ), most approaches accept by default that the rating prediction is the underly-ing task for recommender systems. Howev er, in many practical systems such as Amazon ( http://amazon.com )and Last.Fm ( http://last.fm ), it is sometimes more favorable to formulate collaborative filtering as an item ranking problem, because we often face the situation where our ultimate task is to generate the top-N list of the end user X  X  most favorite items (see Fig 1 (c) and (d)). 2. User profiles can be explicitly obtained by asking users to rate items that they know. However these explicit rating s are hard to gather in a real system [5]. It is highly desirable to infer user preferences from implicit observations of user interactions with a system. These implicit interest functions usually generate frequency-counted profiles, like  X  X layback times of a music file X , or  X  X isiting frequency of a web-site X  etc. So far, academic research into frequency-counted user profiles for collaborative filtering has been limited. A large body of research work for collaborative filtering by default focuses on rating-based user profiles [1,9,10,16,21].

This motivated us to conduct a formal study on probabilistic item ranking for collaborative filtering. The remainder of the paper is organized as follows. We first describe related work, and then establish the generative language model for collaborative filtering. After that, we extend the model by considering the uncertainty of the estimation. Finally, we provide an empirical evaluation of the recommendation performance, and conclude our work.
 In the memory-based approaches, all rating examples are stored as-is into mem-ory (in contrast to learning an abstraction), forming a heuristic implementation of the  X  X ord of Mouth X  phenomenon. In the rating prediction phase, similar users or (and) items are sorted based on the memorized ratings. Relying on the ratings of these similar users or (and) items, a prediction of an item rating for a test user can be generated. Examples of memory-based collaborative filter-ing include user-based methods [3,9,15], item-based methods [7,16] and unified methods [19]. The advantage of the memory-based methods over their model-based alternatives is that less parameters have to be tuned; however, the data sparsity problem is not handled in a principled manner.

In the model-based approaches, training examples are used to generate an  X  X bstraction X  (model) that is able to predict the ratings for items that a test user has not rated before. In this regard, many probabilistic models have been proposed. For example, to consider us er correlation, [14] proposed a method called personality diagnosis (PD), treating each user as a separate cluster and assuming a Gaussian noise applied to all ratings. It computes the probability that a test user is of the same  X  X ersonality type X  as other users and, in turn, the probability of his or her rating to a test item can be predicted. On the other hand, to model item correlation, [3] utilizes a Bayesian Network model, in which the conditional probabilities between items are maintained. Some researchers have tried mixture models, explicitly assuming some hidden variables embedded in the rating data. Examples include the aspect models [10,12], the cluster model [3] and the latent factor model [4]. These methods require some assumptions about the underlying data structures and the resulting  X  X ompact X  models solve the data sparsity problem to a certain extent. How ever, the need to tune an often signif-icant number of parameters has prevented these methods from practical usage. For instance, in the aspect models [10,12], an EM iteration (called  X  X old-in X ) is usually required to find both the hidden user clusters or/and hidden item clusters for any new user.

Memory-based approaches are commonly used for rating prediction, but they can be easily extended for the purpose of item ranking. For instance, a rank-ing score for a target item can be calculated by a summation over its similar-ity towards other items that the target u ser liked (i.e. in the user preference list). Taking this item-based view, we formally have the following basic ranking score: where u and i denote the target user and item respectively, and i  X  L u de-notes any item in the preference list of user u . S I is the similarity measure between two items, and in practice cosi ne similarity and Pearson X  X  correla-tion are generally employed. To specific ally target the item ranking problem, researchers in [7] proposed an alternative, TFxIDF-like similarity measure, which is shown as follows: where Freq denotes the frequency counts of an item Freq ( i ) or co-occurrence counts for two items Freq ( i ,i ).  X  is a free parameter, taking a value between 0 and 1. On the basis of empirical observations, they also introduced two nor-malization methods to further improve the ranking. In our previous work, we have introduced the concept of relevance into collaborative filtering [17]. Items can be then ranked by estimating the probability of the relevance between users (preferences) and items [18,20]. In this p aper, we take another angle, considering a generative process between items and users. Collaborative filtering aims at finding information items that a user is most likely to like, given his or her preference. To achieve this, we could formally measure how probable an item (denoted as i ) is to be suggested to a given user (denoted as u ): p ( i | u ), and then rank items accordingly: where log p ( u ) can be removed since it is independent of the target item i .The item ranking has two parts: its like lihood towards the user preference p ( u | i )and its popularity p ( i ). The probability p ( i ) can be easily estimated by counting the frequency from the collection.

To estimate the likelihood p ( u | i ), we follow the argument of the language model of information retrieval. In the language modelling approach of informa-tion retrieval [6], one needs to assess how probable a query q would be generated from a document language model  X  d , and then rank each of the documents d in the collection on the basis of the generative probability p ( q |  X  d ). Similarly, in collaborative filtering, we first choose an optimal generative model  X  i for each candidate item i ; it captures the underlying distribution of users (or user pref-erences) who liked the item. Probability p ( u |  X  i )isthenusedtoestimatehow probable a user preference (as a query) is to be generated by that model. Re-placingitintoEq.(3)gives By doing this, we relate the language modelling of text retrieval and the collaborative filtering modelling at a probabilistic level. Yet, at the feature repre-sentation level they are quite apart from each other, as their input data and pur-poses are completely different. Consequen tly, applying the text retrieval model to collaborative filtering is not trivial. The difficulty lies in the fact that in text retrieval both queries and documents ar e represented by texts, which provide an important information channel to link queries (user needs) and documents. Due to the lack of relevance observations, the language models in text retrieval shift their focus from directly estimating the c orrespondence (relevance) between user needs (queries) and documents to estimating word statistics in the documents and/or queries and then building up the link through these statistics. Conversely, in collaborative filtering, in most cases, we do not have such extra information to relate user preferences an d information items. Instea d, recorded in the system are only user preferences, which are thought of as indirect observations of the relevance between a user interest and an information item. Thus, the central question in modelling collaborative filtering is how to relate users and items through this usually very sparse user-ite m matrix, where its elements record the frequency counts, like  X  X layback times of a music file X , or  X  X isiting frequency of a web-site X  etc.

The estimation of the likelihood p ( u |  X  i ) depends on the representation of the user preference. From the data stored i n the user-item matrix, if we use a set of items i  X  L u to present user u , and assume that each item i in the user preference L u is independently generated, we have straightforward as both queries and documents are represented by the same set of features, i.e., words. Subsequently,  X  d is estimated conveniently by looking at the words occur in document d . By contrast, the interpretation of the likelihood p ( i |  X  i ) in Eq. (5), which links the target item i to another item i in the target user X  X  preference, is slig htly different; it measures how probable an item i would be generated from a user pr eference where an item i occurs. It is estimated by considering the following two steps: 1) aggregating the user preferences in which item i occurs, and 2) from them, calculating how frequent item i is also present -c ( i ,i ) denotes the number of user preferences where both items i and i occur, and c ( i ) denotes the number of user preferences where item i occurs. The hat on  X   X  i indicates that it is an estimated value.

Like text retrieval, due to the sparsity of the data, only considering the co-occurrence statistics is unreliable. One can smooth the estimate from the col-lection statistics; using the linear smoothing method [22], we have the following ranking formula: where the ranking score of a target item i is essentially a combination of its popularity (expressed by the prior probability P ( i )) and its co-occurrence with the items i  X  L u in the preference list of the target user (expressed by the conditional probability P ( i | i ).  X   X  [0 , 1] is used as a linear smoothing parameter to further smooth the conditional probability from a background model ( P ( i )). i c ( i )= i c ( i ) denotes the number of user preferences in the collection.
Alternatively, one can apply the Bayes-smoothing technique [22] to smooth the estimation. More formally, we have: where  X  is the smoothing parameter and p ( i )  X  c ( i ) Eq. (5) results in the following Bayes-smoothing-based ranking formula: In summary, we have derived two ranking formulae in Eq. (6) and Eq. (8), respec-tively, by following the school of thinking in the language modelling approaches of text retrieval. The two scoring functions are item-based as the scoring relies on the co-occurrence statistics between items. It is worth noticing that a paral-lel user-based method can similarly be d erived by considering the co-occurrence between users. As described, the classic language modelling approaches, thus including Eq. (6) and Eq. (8), consider the model parameters as unknown fixed constants, and apply point estimate such as the MLE, the linear-smoothing, or the Bayes-smoothing technique. The main drawback of this approach is that exact measures of the uncertainty associated with the estimation are not handled in a princi-pled manner. As a result, unreliably-estimated items may be ranked highly in the ranked list, reducing the retrieval performance of the top-N returned items.
To model the uncertainty of the estimate, we follow the Bayesian viewpoint, considering parameter  X  i itself has a probability distribution associated with it. We propose to use variance Var (  X  i ) to summarize the uncertainty, inspired by the risk-aware language models introduced in [23]. A large variance indicates that the estimate is unreliable and its rank score should be penalized accordingly. Based on this, we have the following formula: where Mean (  X  i ) is the mean of  X  i while Var (  X  i ) denotes its variance. b&gt; 1, and it is a parameter that adjusts the risk preference and can be tuned from data.
Here the user preference data is assumed to follow Multinomial distribution, and the conjugate prior is Dirichlet distribution. Thus, the mean and variance are obtained as follows: 5.1 Data Sets and Experiment Protocols The standard data sets used in the evaluation of collaborative filtering algorithms (i.e. MovieLens and Netflix) are rating-based, which are not suitable for testing our method using implicit, frequency-counted user profiles. This paper adopts two implicit user profile data sets.
 The first data set comes from a well known social music web site: Last.FM . It was collected from the play-lists of the users in the community by using a plug-in in the users X  media players (for instance, Winamp, iTunes, XMMS etc). Plug-ins send the title (song name and artist name) of every song users play to the Last.FM server, which updates the user X  X  musical profile with the new song. For our experiments, the triple { userID, artistID, Freq } is used.
 The second data set was collected from one well-known collaborative tagging Web site, del.icio.us . Unlike other studies focusing on directly recommending contents (Web sites), here we intend to find relevance tags on the basis of user profiles as this is a crucial step in such systems. For instance, the tag suggestion is needed in helping users assigning tags to new contents, and it is also useful when constructing a personalized  X  X ag cloud X  for the purpose of exploratory search . The Web site has been crawled between May and October 2006. We collected a number of the most popular tags, found which users were using these tags, and then downloaded the whole profiles of these users. We extracted the triples { userID, tagID, Freq } from each of the user profiles. User IDs are randomly generated to keep the users anonymous.

For 5-fold cross-validation, we randomly divided this data set into a training set (80% of the users) and a test set (20% of the users). Results are obtains by averaging 5 different runs (sampling of training/test set). The training set was used to estimate the model. The test se t was used for evaluating the accuracy of the recommendations on the new users, whose user profiles are not in the training set. For each test user, 5, 10, or 15 items of a test user were put into the user profile list. The remaining items w ere used to test the recommendations. Our experiments here consider the recommendation precision , which measures the proportion of recommended items that are ground truth items. 5.2 Performance The Language Models. We choose a state-of-the-art item ranking algorithm [7] discussed in Section 2 as our strong baseline. We adopt their implementation, the top-N suggest recommendation library 1 , which is denoted as SuggestLib .The proposed language modelling approach of collaborative filtering in Eq. (6) is de-noted as LM-LS while its variant using the Bayes X  smoothing given in Eq. (8) is de-noted as LM-BS . The optimal parameters are tuned by applying cross-validation.
The results are shown in Table 1 and 2. From the tables, we can see that our ranking methods, derived from the language models of text retrieval, performs consistently better than the heuristic ranking method, SuggestLib ,overallthe configurations. A Wilcoxon signed-rank test [11] is done to verify the significance. We believe that the effectiveness of our methods is due to the fact that the models naturally integrate frequency counts and probability estimation into the ranking formula. For the two smoothing methods, we have obtained a mixed result -in the Last.FM data, the Bayes smoothing method outperforms the linear smoothing, while in the del.icio.us data, the linear smoothing is better than the Bayes smoothing method.
 TheRisk-awareRanking. We continue our experiment with the risk-aware model given in Eq. (9). As we intend to investigate whether the added variance bit could improve the recommendation accuracy, the linear smoothing approach (denoted as Model 1) is now regarded as a baseline, Two different risk-aware models are evaluated: Model 2, using the linear smoothing to estimate the mean ( Mean (  X  i )), and Model 3, using the maximum likelihood to estimate the mean ( Mean (  X  i )). The results, under the three configurations top-1, top-10, and top-15, are shown in Fig. 2 and Table 3. We can see that Model 2 and Model 3 significantly outperform Model 1 in all configurations. Model 2 is slightly better than Model 3, implying that, the variance plays a more critical role than the smoothing from the collection. And, even without smoothing from the collection, the risk-model that considers the variance only provides a robust scoring function. In this paper, we have presented a novel statistic model for item ranking in col-laborative filtering. It is inspired by the widely-adopted language models of text retrieval. To consider the uncertainty of the parameter esti mation and reflect it during the ranking, we then presented a risk-averse ranking model by consider-ing the variance of the parameters. The e xperiments on two real data sets have shown that the significance of our approaches.

One of the assumptions in our model is that the items in users X  profiles are independent of each other. This is unrealistic in practice. In the future, we intend to explore this dependence. It is also of great interest to study the method of combing content descriptions under the proposed framework.
 The experiment of the risk-aware model was conducted by Mofei Han when he was working on his MSc thesis under the supervision of the author.

