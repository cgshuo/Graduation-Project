 Information networks are widely used to characterize the relationships between data items such as text documents. Many important retrieval and mining tasks rely on ranking the data items based on their centrality or prestige in the network. Beyond prestige, diversity has been recognized as a crucial objective in ranking, aiming at providing a non-redundant and high coverage piece of information in the top ranked results. Nevertheless, existing network-based ran k-ing approaches either disregard the concern of diversity, o r handle it with non-optimized heuristics, usually based on greedy vertex selection.

We propose a novel ranking algorithm, DivRank, based on a reinforced random walk in an information network. This model automatically balances the prestige and the diversit y of the top ranked vertices in a principled way. DivRank not only has a clear optimization explanation, but also well connects to classical models in mathematics and network science. We evaluate DivRank using empirical experiments on three different networks as well as a text summarization task. DivRank outperforms existing network-based ranking methods in terms of enhancing diversity in prestige. Categories and Subject Descriptors: H.2.8 [Database Applications]: Data Mining General Terms: Algorithms Keywords: Diversity, ranking, information networks, rein-forced random walk
Consider the task of recommending three restaurants to a visitor. Without any prior information, a natural strategy is to recommend the three most famous ones, all of which hap-pen to be seafood restaurants. However, the visitor could be a vegetarian, could prefer Chinese food, or could be allergi c to seafood. A better strategy is thus to include something different in the recommendation, even though it is not as famous as the seafood restaurant it has replaced. A similar situation can be found in setting up the program committee of a conference, where an ideal committee should consist of prestigious researchers who cover all the related areas.
Many retrieval and mining tasks are concerned with find-ing the most important and/or relevant items from a large collection of data. Top ranked web pages are presented to the users of a search engine; top ranked job applicants are invited to on-site interviews; top ranked researchers are s e-lected as the recipients of prestigious awards. Many rank-ing approaches have been proposed, ranging from pointwise weighting methods that use simple properties of each data item to network-based methods that utilize the relations among items, and to learning-to-rank methods that balance a lot of factors. Information networks, which characterize the relationships between the data items, have been playing an important role in these tasks. For instance, a search en-gine ranks web pages based on their prestige in a web hyper-link graph [14, 9]; researchers and scientific publications are ranked based on how well they are cited by other researchers. It is natural to assign a higher weight to data items that are referred to by many items, connected to many items, or on the paths between many items. These measures are known as centrality (or prestige) measures in general, with vario us instantiations like degree, closeness, betweenness [13], and more complicated measures such as the PageRank score [14] and the authority score [9]. These measures can be also com-bined with other features such as the relevance to a query.
However, the information need of a user usually goes be-yond prestige or centrality. The diversity in top ranked re-sults has been recognized as another crucial criteria in ran k-ing. The top ranked items are expected to contain as little redundant information as possible, cover as many aspects as possible, or be as independent as possible. The need of diversity in ranking is even more urgent when the space of output is limited, for example in a mobile application.
Consider a toy example (illustrated in Figure 1(a)) which presents a network with 20 vertices. Vertex 1, 2, 3 and their neighbors are closely connected, while the ego-networks of vertex 4 and vertex 5 are loosely connected to the major community. Suppose the task is to find top-3 vertices to present the information of the whole network. If we rank the vertices using a prestige measure like degree or the PageR-ank (presented in Figure 1(b)), we can see that the top 3 ranked vertices are 1, 2, 3 respectively. All the three ver-tices are from the largest community and even form a clique by themselves. They are therefore likely to carry redundant information. Information of the two smaller communities centered at vertex 4 and vertex 5, however, does not present. A more desirable selection of the top-3 nodes should contain diverse information, like in Figure 1(c). Vertex 1, 5, and 4 receive the majority weight, representing the three commu-nities. Vertex 1, which represents the largest community, i s ranked to the top. Although vertex 2 and 3 has a higher degree than vertex 5, they are ranked lower because vertex 1 has already partially covered their information.
A greedy vertex selection algorithm may achieve diver-sity by iteratively selecting the most prestigious vertex a nd then penalizing the vertices X  X overed X  X y the already selec ted ones. An example is the Maximum Marginal Relevance [3]. One may also consider first clustering the nodes (e.g., [17]) and then selecting centroids of clusters. However, it X  X  diffi -cult to predefine the number of clusters in this task. There lacks a principled objective and a unified process that auto-matically balances centrality and diversity.

In this paper, we propose a novel and unified process that balances prestige and diversity in ranking, based on a time-variant random walk in the network. The proposed model, called DivRank (abbreviation for Diverse Rank ), intro-duces the rich-gets-richer mechanism to PageRank style ran-dom walks with reinforcements on transition probabilities . In contrast to the greedy vertex selection methods, DivRank provides a unified and intuitive stochastic process, as well as a principled optimization explanation. The process is well connected to a number of classical models in mathematics and network science, such as the vertex-reinforced random walk , the Polya X  X  Urn , and the preferential attachment .
DivRank not only has a solid theoretical foundation, but also presents a strong empirical performance. The result presented in Figure 1(c) is actually generated using DivRan k. We compare DivRank with a number of representative meth-ods in literature using real world datasets and tasks. In all these tasks, DivRank outperforms the state-of-the-art met h-ods in generating diverse top ranked results.

There are many potential applications of DivRank. The tasks presented in our experiments (i.e., ranking actors in social networks, ranking authors and publications, and tex t summarization) are by no means the only possible tasks. One may expect DivRank be applied in diversifying search results, snippet generation, keyword selection, mobile se arch, expert finding, and in various recommender systems.
The rest of the paper is organized as follows. In Section 2, we briefly introduce the task of ranking in information net-works. In section 3, we formally introduce DivRank, includ-ing the general form and two practical approximations. We then provide an analytical discussion of DivRank in Sec-tion 4, followed by a comprehensive empirical analysis in Section 5. We discuss the related work in Section 6 and present our conclusions in Section 7.
In this section, we introduce the basic concepts and task of ranking vertices in networks, followed by the commonly used random walk processes for prestige measurement.
Let G = ( V, E ) be a graph (or a network) where V is a finite set of vertices and E is a finite set of edges. We define an ordered pair ( u, v ) as an edge from vertex u to vertex v . When G is an undirected graph, we have ( u, v ) = ( v, u ); when G is a directed graph, we have ( u, v ) 6 = ( v, u ). In a so-cial network, V refers to a set of social actors (people) and E refers to the social ties between actors. In an information network, V and E broadly correspond to any type of infor-mation objects and the relationships between objects. We define the weight of an edge using w ( u, v ). Note that when the edge corresponds to a citation between two documents or a hyperlink between two web pages, w ( u, v ) takes a bi-nary value. w ( u, v ) could take any non-negative real value in other scenarios, e.g., when the edge corresponds to the similarity or cooccurrence of two objects, etc.

We then cast the task of ranking the vertices based on their prestige (or centrality in different contexts, which we will use interchangeably with prestige) in a network as find-ing a prestige function f : V  X  R + . Beyond simple mea-sures such as degree, recent research focuses on a family of centrality measures based on the stationary distribution o f a random walk in the network, such as the well-known PageR-ank [14] and its counterpart in text networks, LexRank [5].
A family of prestige measures in networks leverages the stationary distribution of a random walk in the network. A random walk defines a Markov chain in the given (either directed or undirected) network, where each vertex repre-sents a state and a walk transits from one state to another based on a transition probability, denoted as p ( u, v ). In other words, a random walk on G is defined by a transition probability function p : V  X  V  X  [0 , 1]. Let us use p T ( u ) to denote the probability that the walk is at state u at time T . A standard random walk can be defined as
If the Markov chain is ergodic, p T ( v ) converges to a sta-tionary distribution  X  ( v ) which is commonly used to mea-sure the importance of vertices.

Most existing random walk models assume that the tran-sition probability p ( u, v ) doesn X  X  change over time, and in-stead can be estimated based on the topological structure of the network and/or the prior knowledge about the process. In a Web hyperlink graph, p ( u, v ) can be estimated by where d is a damping factor and deg ( u ) is the out-degree of the web page u (the number of hyperlinks from u to other web pages). The Markov chain defined by p ( u, v ) is ergodic. The stationary distribution of this random walk,  X  ( u ), yields to the well known PageRank score for ranking web pages.
There are different ways to estimate p ( u, v ). For example, in a general weighted graph, such as a document similarity graph, one can estimate p ( u, v ) using w ( u, v ) / P v  X  V to substitute I [( u, v )  X  E ] /deg ( u ) 1 in Equation 2, where w ( u, v ) is the weight of the edge ( u, v ). In another scenario where we have a prior distribution p  X  ( v ) ( s.t. P v p 1), we can substitute 1 /N in Equation 2 with p  X  ( v ). The stationary distribution of such a random walk then yields to personalized PageRank , or topic-sensitive PageRank .
In all these cases, we notice that the transition probabil-ities do not change throughout the random walk process. In other words, the corresponding Markov chain is time-homogenous.  X  assigns higher weights to vertices that are more prestigious. If one vertex is visited very frequently b y the walk, all its neighbors are also more likely to be visited , thus inherit a prestige score from that vertex. This is known as a regularization process [23, 22], or a smoothing process [12] of scores in the network. In the scenario that vertices with high degrees are well connected, the top ranked vertice s are likely to contain redundant information. In other words , the top ranked results is not diverse.

How to achieve diversity in a random walk? We may expect that there is not only a smoothing process between neighbors, but also a competing process. By doing this, we expect that rich nodes get richer over time and  X  X bsorb X  the scores of its neighbors. In next section, we propose a principled way to facilitate this mechanism. We propose a new ranking algorithm in a network, called DivRank, which automatically balances centrality and di-versity in the top ranked items. DivRank is motivated from a general time-variant random walk process known as the vertex-reinforced random walk in mathematics literature [15].
Time-homogenous random walks (e.g., PageRank) assume that the transition probabilities remain constant over tim e. In a real world random walk process, it is reasonable to con-sider the change of transition probabilities over time. In-deed, a visitor is more likely to walk to a museum that have already been visited by many visitors; people tend to join larger groups in a banquet; an actor accumulates prestige when acting in various movies, and the prestige in turn help her get even more opportunities. These can all be considered
I ( X ) is an indicator function which returns 1 if the state-ment X is true and zero otherwise. as random walk processes with time-variant transition prob -abilities. One particular family of time-variant random wa lk processes is known as the vertex-reinforced random walks (VRRW) in mathematics literature. The basic assumption is that the transition probability to one state from others i s reinforced by the number of previous visits to that state.
Formally, let p 0 ( u, v ) be the transition probability prior to any reinforcement and let N T ( v ) be the number of times the walk has visited v up to time T . Then a VRRW can be de-fined sequentially as follows. First, we initialize N 0 ( v ) = 1 for v = 1 , . . . , n . Suppose we know the random walk stays at state u at time T , then at time T + 1, the ran-dom walk moves to state v ( v = 1 , . . . , n ) with probability p ( u, v )  X  p 0 ( u, v ) N T ( v ) for any state u . In other words, p ( u, v ) is reinforced by N T ( v ). The discussion of proper-ties of vertex-reinforced random walks can be found in [15], which shows that, under some well-defined conditions, the score in VRRW converges to some stationary distribution almost surely.
We then introduce the general form of DivRank based on a similar reinforced random walk. Let p T ( u, v ) be the transition probability from any state u to any state v at time T . We can then define a family of time-variant random walk processes in which p T ( u, v ) satisfies where
Here, p  X  ( v ) is a distribution which represents the prior preference of visiting vertex v . When p  X  ( v ) is uniform, the left component is similar to the random jumping probabil-ities in PageRank. p  X  ( v ) could also be realized as a topic-sensitive distribution, similar to the personalized jumpi ng probability in personalized PageRank. p  X  ( v ) could even be realized as the stationary distribution of a time-homogene ous random walk (e.g., PageRank). When  X  = 1, Equation 3 yields to a standard vector-reinforced random walk. p 0 ( u, v ) is the  X  X rganic X  transition probability prior to any reinforcement, which can be estimated as in a regular time-homogenous random walk. After each step, the transition probabilities will be reinforced by the expected number of visits to each vertex. It is reasonable to assume that at any time, there is a probability that the walk stays at the curren t state, and this probability is reinforced by the number of visits at the current state. In other words, we assume there is always an  X  X rganic X  link from a vertex to itself. We have
If the network is ergodic, after a sufficiently large T , the reinforced random walk defined by Equation 3 also converges to a stationary distribution  X  ( v ). That is  X  ( v ) is then used to rank the vertices in the information network, denoted as DivRank . Apparently, P v  X  V  X  ( v ) = 1.
In Section 3.2, we introduced the general form of DivRank based on a general reinforced random walk. Note that the expectation of N T ( v ) follows the recurrent formula where p T +1 ( v )= P u p T ( u, v ) p T ( u ). It is easy to show that if  X  ( v ) exists, we have E [ N T ( v )]  X   X  ( v ) when T is suf-ficiently large. However, in DivRank p T ( u, v ) depends on N
T ( v ) and tracking N T ( v ) is non-trivial. Efficient approxi-mation is needed for practical applications.
 In the original study of vertex-reinforced random walk, Pemantle proposed an approximation as follows [15]: Let 1  X  L  X  T , we can assume that the random walk process from time T to T + L behaves as if N T + L ( v ) doesn X  X  change over N T ( v ) since L  X  T . Therefore, the random walk in this period approximates a time-homogenous Markov chain with a fixed transition probability p T ( u, v ). Since L  X  1, we may also assume that N T + L ( v )  X  N T ( v ) is proportional to the stationary distribution of such a Markov chain,  X  T ( v ). We can thus approximate N T + L ( v ) using N T ( v )+ L  X 
This approximation, however, is still computationally in-efficient. To find  X  ( v ), one needs to compute the stationary distribution,  X  T ( v ), of many different Markovian random walks. In this section we propose two more practical ap-proximations of DivRank.
 One way to simplify the computation is to approximate N
T ( v ) using E [ N T ( v )]. In other words, we let p T ( u, v )  X  p ( u, v ) E [ N T ( v )]. From Equation 7, we have This is more efficient than the Pemantle approximation, since there is no need to compute the stationary distribu-tion for every Markovian random walk. The underlining assumption is that the random walk approximately stays with every p t ( v ) for an equal period of time. We denote this approximation of DivRank as cumulative DivRank .
 An even simpler approximation is to use p t ( v ) directly to ap-proximate E [ N t ( v )]. Indeed, when the random walk reaches the stationary status (at time T ), p t ( v ) converges to  X  ( v ). When the walk continues running for a sufficiently long time ( t  X  T ), E [ N t ( v )] is proportional to  X  ( v ), or p this simple approximation, we have
We denote this simple approximation as pointwise Di-vRank . Equation 3 can then be simplified as where D T ( u ) = P v  X  V p 0 ( u, v ) p T ( v ). Below we use DivRank to refer to this pointwise DivRank unless specially noted.
We have now introduced the general form of DivRank and its two practical approximations. In this section, we prese nt an analytical discussion of DivRank, including an optimiza -tion explanation and the connections to existing models.
What is the intuition behind DivRank, and what principle enhances diversity in ranking? Embedding Equation 3 into Equation 1, it is not hard to get
What does this process end up optimizing? Let us con-sider the scenario where the network is undirected (e.g., w ( u, v ) = w ( v, u )) and p 0 ( u, v ) is estimated through (1  X   X  ) I ( u = v ) +  X  w ( u, v ) /deg ( u ). Let D  X  T ( u ) = w ( u, v ) N T ( u ) N T ( v ). Consider the following objective:
By taking the partial derivative of f v , it is not hard to show show that we can get Equation 11 from setting  X  X  T ( G )  X  X  This is to say, at every time T , the random walk defined in Equation 11 is attempting to improve the objective function in Equation 12. Let us analyze Equation 12. We can see that by minimizing the right component in the summation, f v keeps close to the predefined value, f  X  v . By applying different f  X  v , one can incorporate various assumptions about f . For instance, one can assume that a reasonable f should rank nodes with a larger degree higher, and thus set f  X  v proportional to the degree of v .

The left component is more interesting. By minimizing the left component, the system regularizes the weights of vertices by dragging f u /f v towards D  X  T ( u ) /D  X  T ( v ). In other words, this component in the objective function reflects the consistence of f v /D  X  T ( v ) over the network, which is related to the consistency regularizer in machine learning literat ure [21, 22] but varies over time.

We know D  X  T ( v ) = P u  X  V w ( u, v ) N T ( u ) N T ( v ) and N N ( v ). When the random walk starts, the optimization pro-cess is dragging f towards the degree distribution, which is exactly a Markovian random walk in the undirected graph. Nodes with a higher degree will get a higher weight, which in turn results in a larger accumulative N T . When the ran-dom walk proceeds, the nodes which already have a high N T tend to get an even higher weight. The self-link to a vertex guarantees that even if all the neighbors of v shrink, D  X  could still be large as long as N T ( v ) is large.
In other words, at time 0, the objective function in Equa-tion 12 favors nodes with a higher centrality. As time goes by there emerges a rich-gets-richer phenomenon.

Indeed, the ratio of two adjacent nodes f u /f v is propor-tional to D  X  T ( u ) /D  X  T ( v ) when the left component of Equa-tion 12 is optimized. Originally, this ratio is proportiona l to the ratio of their degrees. As the random walk proceeds, this ratio tends to become more and more skewed. The self-links guarantee that adjacent nodes will  X  compete  X  for DivRank scores. Nodes already having high weights (thus higher D  X  T ( v )) are likely to  X  X bsorb X  the weights of its neigh-bors directly, and the weights of neighbors X  neighbors indi -rectly. As a result, the connectivity among the top ranked vertices tend to be low, thus enhances the diversity of infor -mation.

This provides an optimization explanation of DivRank on an undirected network. If the network is directed and there one could find a corresponding optimization explanation sim -ilar to the regularization framework on directed graphs in [22], but time-variant. However, it is generally hard to sho w an optimization explanation on an arbitrary directed graph , even for time-homogenous random walks like PageRank.
Although DivRank is a novel model, it is well connected to a number of classical models in other contexts. First, when there is no jumping behavior (i.e.,  X  = 1), DivRank yields to a vertex-reinforced random walk with self-links.
If the graph is fully connected with uniform edge weight, the VRRW yields to a Polya X  X  Urn .  X  converges to a Dirich-let compound multinomial distribution. Such a process has been used to model the word burstiness in text [11]. Indeed, the word sampling process in [11] can be viewed as a special case of a reinforced random walk on a network of words.
Furthermore, the process of DivRank is also related to preferential attachment models in network evolution, e.g., the Barab  X asi-Albert model [2]. In a preferential attachme nt model, new nodes are more likely to attach to existing nodes that have already got a larger number of attachments, thus generates networks with a power-law degree distribution. Although DivRank does not model the evolution of networks (instead assumes that the topological structure is stable o ver time), we do see a related principle underneath, as well as a similar rich-gets-richer phenomenon. DivRank models the evolution of node weights and transition probabilities in t he random walk in a  X  X referential transition X  flavor. Indeed, one may call it a  X  X referential ranking X  model.

There is another random walk based model in literature which improves the diversity in ranking. The Grasshopper model in [24] leverages an absorbing random walk. The model starts with a regular time-homogenous random walk. Every step the vertex with the largest weight is selected into the top ranked set, which is then set as an absorbing state. The model then reruns the random walk with absorb-ing states, and select the next vertex based on the expected number of visits to each node before absorption. In this way, Grasshopper also achieves diversity in the top ranked results. Comparing to DivRank, we can see Grasshopper takes a greedy approach of selecting vertices one by one. Such a process is similar to other greedy vertex selection methods like MMR, but with a  X  X oft X  penalization. In contrast, Di-vRank generates the ranking of vertices in a unified process, which balances prestige and diversity automatically. In th e following section, we will compare DivRank with Grasshop-per using real world datasets and tasks.
In this section, we evaluate the effectiveness of DivRank empirically. We select ranking tasks on three real world networks as well as a document summarization task.
A natural competitor of DivRank is PageRank , the ran-dom walk based centrality measure without diversity. We also compare with its two variations, namely the person-alized PageRank and LexRank in the context of text sum-marization. We also compare DivRank with two diversity-aware methods, namely the Maximum Marginal Relevance ( MMR ) and Grasshopper . We believe that these baseline methods (except MMR) well represent the random walk based ranking methods in literature.

Note that MMR is originally proposed in a query-dependent context, thus it is not directly comparable to DivRank. In MMR, there is an explicit notion of relevance to the query. Although our setup is query-independent, we make a small variation to MMR so that it is comparable to PageRank, DivRank, and Grasshopper. The idea is to use PageRank score as the initial  X  X elevance X  score of MMR.
 What is a reasonable general measurement of diversity? The recent X  X edundancy, Diversity, and Interdependent Doc -ument Relevance X  workshop at SIGIR 2009 concluded that  X  there is no evaluation metric that seems to be universally accepted as the best for measuring the performance of algo-rithms that aim to obtain diverse rankings  X  (quoted from [16]). Without a query, it is not feasible to apply the uni-fied measures in retrieval that are related to  X  X elevance X  an d  X  X ubtopics X  [18, 4]. In our experiments, we thus present sep -arate measures for prestige and diversity in the top-ranked results. [24] applies an ad hoc diversity measure in a par-ticular context of ranking movie stars, i.e., the coverage o f countries in the top ranked actors. Such a measure only as-sesses diversity indirectly and cannot be generalized to ot her datasets/tasks where such metadata is not available. In gen -eral, we need a measure that accounts for the redundancy of information in the top ranked vertices, even if we do not have any information other than the network itself.
In our experiments, we propose to leverage the density measure in network science. The density of a graph is de-fined as the number of edges (excluding self-links) presenti ng in the network divided by the maximal possible number of edges in the network. Formally, we can define where | V | is the number of vertices in G. Note that this general definition applies to both undirected graphs and di-rected graphs. Specifically, given the top-K ranked vertice s, we can construct a subgraph of G , G K , consisting of the top-K vertices and the edges among them. We then use the density of the subgraph, d ( G K ), as an inverse measure of diversity in top-K ranked vertices. Our assumption is that the smaller d ( G K ) is, the more independent the top-K ver-tices are, thus the less redundancy and higher diversity is contained by the top-ranked results (and vice versa).
For each task, we also define task-specific measure(s) to evaluate the quality (e.g., prestige) of the top-K vertices . Note that although it is difficult to develop a general mea-sure that combines quality and diversity, in some tasks like document retrieval and text summarization, we can leverage the standard and unified measures in those contexts.
Our first experiment considers a movie star social network extracted from the Internet Movie Database (IMDb 2 ). It is exactly the same dataset used in Zhu et al. 2007 ([24]). The dataset covers 3452 unique actors/actresses from 1027 com-edy movies produced between 2000 to 2006. We construct an actor social network by using all movie stars as vertices and weighting an edge between a pair of stars with the num-ber of movies they co-starred in. Following [24], we also add a self-link to each actor with weight 1.

The task is to find the top-K actors that represent this social network. Ideally, the selected actors/actresses sh ould be prestigious (appear at central positions in this network ), and the top-K actors should also cover diverse groups of movie stars. Besides the density measure, we also include the  X  X ountry coverage X  measure which is used in [24]. To measure the X  X uality, X  X e follow [24] and compute the unique number of movies covered by the top-K stars (called  X  X ovie coverage X ). The basic assumption is that the ideal top-K stars should cover as many unique movies as possible, and also cover comedians from different countries (which are as-sumed to represent different communities). Note that a pres-tigious actor is supposed to be starring in many movies, not necessarily co-starring with many actors. One could notice that the movie coverage measure is not a pure prestige mea-sure, where there is also an implicit notion of diversity.
Following [24], we set the prior distribution p  X  ( v ) to be proportional to the number of movies that the actor has starred in. The same information is provided to Grasshopper and personalized PageRank.

We compare the performance of the random walk based ranking methods, including two approximations of DivRank, PageRank, personalized PageRank, and Grasshopper in Fig-ure 2 using density, country coverage, and movie coverage. We set the jumping probability in all these methods to 0.1. Since there are separate measures for prestige and diversit y, we didn X  X  tune the parameter  X  and simply set it 0.25. From Figure 2(a), we can clearly see that (pointwise) DivRank achieves the largest diversity in the top ranked results ( K &lt; 500), followed by cumulative DivRank, then Grasshopper. When K is large enough (e.g., K  X  500), these diversity generated by those three methods becomes similar. Density in top-K vertices generated by PageRank or personalized PageRank is clearly and consistently higher than those thre e methods, suggesting that PageRank-style random walks are not effective in enhancing diversity. Similar patterns can b e observed in Figure 2(b), plotted with country coverage. The three diversity enhancing methods cover much more coun-tries than PageRank and personalized PageRank, where cu-mulative DivRank provides the best coverage when K is smaller than 150, and pointwise DivRank provides the best coverage when K is between 200 and 400. One would ask whether the enhancement of diversity is at the expense of quality. From Figure 2(c), we see that the three diversity en -hancing methods also generate higher movie coverage. The three methods perform comparably in terms of movie cov-erage, with Grasshopper slightly higher. All three methods present significantly larger movie coverage than PageRank and personalized PageRank. We also explored MMR, which generates similar results as Grasshopper 3 . It is interest-ing that personalized PageRank results in both the lowest diversity and the lowest movie coverage. This is because the movie coverage measure also partially accounts for di-versity, and personalized PageRank works ineffectively wit h diversity.

Does the benefit of DivRank really come from the rich-gets-richer mechanism? To test this, we plot the score dis-tribution of the top-K results by PageRank (left) and Di-vRank (right). From Figure 3, we can clearly see that the score distribution in top 100 results is much skewer in Di-vRank than in PageRank. Indeed, the riches (e.g., the top ranked vertices) have accumulated a significantly larger pr o-portion of wealth (e.g., DivRank score 4 ), which enhances the diversity.
Although it is not meaningful to tune the parameters with multiple evaluation measures, we plot the performance of pointwise DivRank over different values of the parameter  X  , which controls the strength of self-links.
Figure 4 plots the performance of pointwise DivRank us-ing different values of  X  (K = 100). From Figure 4(a, b, c), we can see that density in top-K results is lower than PageRank and Grasshopper as long as the value of  X  is not extreme (i.e., close to 0 or 1). In the  X  X omfort zone, X  a smaller  X  generates a higher movie coverage and a larger  X  generates a higher country coverage. The density measure is optimized when  X  is in the middle range of (0 , 1). In gen-eral, the performance is not sensitive when  X  in the middle range of (0 , 1). Figure 4(d) shows the number of iterations needed before DivRank converges. We can see that the con-vergence rate of DivRank is not sensitive to  X  . In general, the converging time presents the pattern that P ageRank &lt; DivRank &lt; Cumulated DivRank &lt; Grasshopper 5 . Figure 4: Effect of parameter  X  on the performance of DivRank (K = 100)
In summary, DivRank generates promising results in rank-ing movie stars, consistently outperforming PageRank and personalized PageRank in terms of diversity, country cov-erage, and movie coverage. It also provides top-K actors ( K &lt; 500) with comparable movie coverage but higher di-versity, comparing to other diversity enhancing algorithm s.
The results in ranking IMDb actors are promising. It is interesting to test whether the good performance of DivRank can be generalized to other datasets, especially to directe d networks. To test this, we include a larger dataset with two directed networks extracted from an academic community.
The dataset is known as the ACL Anthology Network 6 (AAN), which contains an author citation network as well as a paper citation network constructed from 14912 papers col-lected in the ACL Anthology 7 . The author citation network covers 9641 authors, with each edge weighted by the number of times an author cited the work of the other. The paper citation network covers 11609 papers, with unit-weighted edges from each paper to the papers it cited.
These two networks are good representatives of directed networks. The task is to rank the most prestigious re-searchers (authors) and papers in the corresponding net-work, of course with diversity into consideration.
Like in the experiment with the actor social network, we use density to measure the inverse of diversity in the top-K results. To measure the quality, in this context the prestig e of the top ranked authors, we leverage the well known h-index measure. By definition, if an author has published at most x papers which are cited for at least x times, the h-index of that author is x [8]. H-index provides a reasonable estimation of the author X  X  impact in the community, which is widely used in ranking scholars in reality. We use the average h-index of the top-K authors as the prestige mea-sure of ranking authors. For the paper citation network, we use the average number of citations of top-K papers as the prestige measure.

Please note that unlike movie coverage, both h-index and average citation purely measures prestige without any noti on of diversity. For ranking papers in the paper citation net-work, we also include a measure that is similar to movie cov-erage, impact coverage , which counts the number of unique papers citing the top-K papers. This may be a better quality measure than the average number of citations.

The results are summarized in Figure 5. To simplify the illustration, we only plot three most representative meth-ods: PageRank, DivRank, and Grasshopper. From Figure 5 (a) and (d), we can see that DivRank again effectively en-hanced the diversity in top ranked results, which generates clearly and consistently sparser subgraph (i.e., higher di ver-sity) with top-K items than PageRank and Grasshopper.
From Figure 5(b) and (e), we can see that in DivRank, the enhancement of diversity results in a lower average prestig e when K is large, if the prestige measure considers every ver-tex independently. This is reasonable, since centrality-b ased methods (e.g., PageRank) always rank the most prestigious vertices to the top, which easily yields to the maximum in-dependent prestige if the prestige measure correlates with the centrality. By enhancing diversity, one is optimizing the marginal prestige instead of the independent indepen-dent prestige . Like the movie coverage measure in ranking actors, the impact coverage in ranking papers (Figure 5(f) ) confirms this intuition: both DivRank and Grasshopper pro-duce a consistently higher impact coverage than PageRank, where DivRank is better for the top results ( K  X  40) and Grasshopper is better when K &gt; 40. We X  X e also tried MMR and it generates comparable results with Grasshopper.
It is worth mentioning that even with the independent prestige measure, the top-ranked results by DivRank outper -form PageRank and Grasshopper. Indeed, when K  X  30, we can clearly see from Figure 5 (b, e) that DivRank generates the highest average prestige among the three. This is de-sirable since for the user, the most useful (and preservable ) information in a ranked list is always at the very top.
We also plot the score distribution of the top 100 papers in the paper citation network, presented in Figure 5(c). Again , we can see that the DivRank score distribution (in the right plot) presents a much skewer pattern than the PageRank score distribution (in the left plot) and the top ranked ver-tices have absorbed a much larger wealth. The pattern also appears in the author citation network.

This experiment proves that the effectiveness of DivRank generalizes to larger and directed networks.
In both the actor social network and the AAN academic networks, DivRank is evaluated using the task of prestige ranking directly. The good thing is that it gives us straight -forward assessment of the performance of the ranking algo-rithms; the limitation, however, is that there isn X  X  a unifie d metric that reasonably combines prestige and diversity.
This motivates us to evaluate DivRank by applying it to a task which has a well defined evaluation measure. Such a task should be able to be cast as a ranking problem, should be easy to evaluate, and should benefit from diversifying the top ranked results. We select document summarization as it does not depend on the input of queries. Document sum-marization is also chosen in [24] to evaluate Grasshopper.
We compare DivRank and its competitors using the Task 2 of the 2004 Document Understanding Conference (DUC) 8 . The goal is to generate a summary with no more than 100 words for a set of documents about each of the 50 included topics. We cast multi-document summarization as the prob-lem of extracting the top-K sentences from the documents, and further as ranking the sentences based on a cosine sim-ilarity network. Because of the size limit of the summary, an ideal system should not only select the sentences most relevant to the topic, but also avoid redundant information in the selected sentences. We present each sentence in a topic with a TF-IDF vector space model. Then we create the graph of sentences by adding an unit-weighted edge be-tween every two sentences if their cosine similarity is high er than 0.1. This is exactly the same setting in [5] and [24].
We evaluate the algorithms using ROUGE, the standard metric for text summarization [10]. ROUGE is a recall-based measure which compares the overlap between the system generated summary and the gold standard (human gener-ated summary). Following [24], we also report ROUGE-1 score (unigram matching). The 50 topics were randomly split into a training set (with 30 topics) and a test set (with http://www-nlpir.nist.gov/projects/duc/guidelines/2 004.html 20 topics). The former is used to select the optimal param-eters in the models and the latter is used for evaluation.
The averaged ROUGE-1 results on both training set and test set were listed in Table 1. Note that the MMR method uses LexRank [5], the counterpart of PageRank in summa-rization, as the  X  X elevance X  score. Consistent with [24], w e provide the position information to personalized PageRank , Grasshopper, DivRank, and cumulative DivRank, by setting p ( v ) according to the position of the sentence in a docu-ment. If the sentence v is the l th sentence in a document, we set p  X  ( v )  X  l  X   X  , where  X  is a parameter.
From Table 1, we see that when tuning the parameters on the training data, DivRank performs the best, followed by cumulative DivRank and Grasshopper. Personalized PageR-ank performs reasonably well (better than LexRank), show-ing the importance of sentence position in document sum-marization. The good performance of DivRank generalizes well on the test data. The improvement over LexRank and Grasshopper is significant. This experiment shows that Di-vRank is effective when applied to text summarization.
The importance of enhancing diversity in ranking has been recognized in various contexts, including novelty detecti on [20], subtopic retrieval [18], diversifying search result s [1, 6], recommender systems [25], and so on. [16] provides a sum-mary of research problems and existing work on diversity in information retrieval. Our paper studies the diversity pro b-lem in the context of ranking in information networks.
Centrality/Prestige ranking is a classic topic in network science. Many measures have been proposed, including de-gree, closeness, betweenness, impact domain, etc [13]. In the context of computer science, there have also been many well-accepted models and algorithms such as PageRank [14], HITS [9], LexRank [5], personalized PageRank [7], manifold regularization (e.g., [23]), etc. Most of these models are based on random walks or regularization on the network structure. However, none of them takes the diversity of in-formation in the ranking into consideration.

The most related model to DivRank is Grasshopper, which is a vertex selection algorithm based on absorbing random walk [24]. Like MMR [3], Grasshopper takes a greedy ap-proach to select one vertex at each step. Indeed, Grasshop-per can be interpreted as a  X  X oft X  version of MMR. Instead of greedy vertex selection [3, 19, 24], DivRank generates th e entire ranked list with one unified process, which automat-ically balances prestige and diversity based on a reinforce d random walk model. To the best of our knowledge, DivRank is the first model which achieves this.

The theoretical framework of DivRank is related to quite a few classical models in mathematics literature, includin g the vertex-reinforced random walk [15] and the Polya X  X  Urn. The rich-gets-richer mechanism of DivRank is also related t o the preferential attachment (e.g., the Barab  X asi-Albert m odel [2]) in network evolution which lays the foundation of scale -free networks, and word burstiness [11] in text mining.
We present DivRank, a novel ranking method in informa-tion networks that balances prestige and diversity. Unlike PageRank, DivRank employs a time-variant random walk process, which facilitates the rich-gets-richer mechanis m in ranking. Diversity is achieved through the  X  X ompetition X  process between adjacent vertices. We show that DivRank has nice theoretical connections to a number of classical models in various contexts, such as vertex-reinforced ran-dom walk, the Polya X  X  urn, and the preferential attachment. We also present a principled optimization explanation of Di -vRank.

Empirical experiments show that DivRank effectively en-hances diversity in the top ranked results without the sac-rifice of quality, which outperforms traditional greedy sel ec-tion methods. The good performance generalizes well to di-rected graphs as well as real tasks that network-based rank-ing can be applied to.

There are many potential applications of DivRank. Given its good performance on paper citation networks, one can expect that DivRank facilitate ranking web pages in a web hyperlink graph. The results in text summarization also sug -gest potential applications in snippet generation and opin -ion extraction. One may imagine other applications such as keyword extraction and enhancing diversity in recommender systems.

An interesting future direction is to combine DivRank with other features in a learning-to-rank framework. Like PageRank, DivRank is proposed in a query-independent setup . It is interesting to extend DivRank to a query-dependent scenario, which leads to applications like subtopic retrie val, search result diversification, and expert finding. We thank Prof. Xiaojin Zhu and Andrew Goldberg for shar-ing the code and data of Grasshopper. We thank Dr. Dengy-ong Zhou for his useful comments. [1] R. Agrawal, S. Gollapudi, A. Halverson, and S. Ieong. [2] A.-L. Barabasi and R. Albert. Emergence of scaling in [3] J. Carbonell and J. Goldstein. The use of mmr, [4] C. L. Clarke, M. Kolla, G. V. Cormack, [5] G. Erkan and D. R. Radev. Lexrank: graph-based [6] S. Gollapudi and A. Sharma. An axiomatic approach [7] T. H. Haveliwala. Topic-sensitive pagerank. In WWW [8] J. Hirsch. An index to quantify an individual X  X  [9] J. M. Kleinberg. Authoritative sources in a [10] C.-Y. Lin and E. Hovy. Automatic evaluation of [11] R. E. Madsen, D. Kauchak, and C. Elkan. Modeling [12] Q. Mei, D. Zhang, and C. Zhai. A general [13] M. E. J. Newman. The structure and function of [14] L. Page, S. Brin, RajeevMotwani, and TerryWinograd. [15] R. Pemantle. Vertex reinforced random walk. Prob. [16] F. Radlinski, P. N. Bennett, B. Carterette, and [17] J. Shi and J. Malik. Normalized cuts and image [18] C. X. Zhai, W. W. Cohen, and J. Lafferty. Beyond [19] B. Zhang, H. Li, Y. Liu, L. Ji, W. Xi, W. Fan, [20] Y. Zhang, J. Callan, and T. Minka. Novelty and [21] D. Zhou, O. Bousquet, T. N. Lal, J. Weston, and [22] D. Zhou, J. Huang, and B. Sch  X  olkopf. Learning from [23] D. Zhou, J. Weston, A. Gretton, O. Bousquet, and [24] X. Zhu, A. Goldberg, J. Van Gael, and [25] C.-N. Ziegler, S. M. McNee, J. A. Konstan, and
