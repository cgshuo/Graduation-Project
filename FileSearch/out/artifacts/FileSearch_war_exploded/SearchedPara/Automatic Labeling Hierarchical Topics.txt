 Recently, statistical topic modeling has been widely applied in text mining and knowledge management due to its power-ful ability. A topic, as a probability distribution over words, is usually difficult to be understood. A common, major chal-lenge in applying such topic models to other knowledge man-agement problem is to accurately interpret the meaning of each topic. Topic labeling, as a major interpreting method, has attracted significant attention recently. However, previ-ous works simply treat topics individually without consider-ing the hierarchical relation among topics, and less attention has been paid to creating a good hierarchical topic descrip-tors for a hierarchy of topics. In this paper, we propose two effective algorithms that automatically assign concise labels to each topic in a hierarchy by exploiting sibling and parent-child relations among topics. The experimental results show that the inter-topic relation is effective in boosting topic la-beling accuracy and the proposed algorithms can generate meaningful topic labels that are useful for interpreting the hierarchical topics.
 H.3.3 [ Information Search and Retrieval ]: Text Mining Statistical topic models, topic model labeling
Statistical topic modeling has been widely applied in text mining and knowledge management due to its broad appli-cations, such as word sense disambiguation [2, 3], temporal analysis [17] and opinion mining [10, 7] etc.

A wealth of topic models have been proposed to extract interesting topics in the form of multinomial distributions
This work was done in National University of Singapore. Corresponding author.
 proach, which improves the labeling accuracy by exploiting the sibling and parent-child relations among topics.
Formally, we define D as the set of all documents. The hierarchical structure between topics is formalized as is-a relationship t j  X  t i , defining that t j is the parent (direct parent) of t i . For specifying the set of topics with direct par-ent t j ,weuse T t j  X  X  X  to denote all the documents contained in this sub-hierarchy as D t j  X  X  X  . For a topic t j ,weuse T t j  X  X  X  to denote the set of all its direct children and grand-children and so forth. D t j  X  X  X  denotes all the documents contained in hierarchy T t j  X  X  X  . Semantically, the is-a relationship assumes that if a document is assigned to a topic, it is also assigned to its parent topic.
After assigning each document to its top topic according to the topic distribution on this document, two steps are ex-ecuted to generate meaningful labels for topics: (1) extract candidate labels; (2) rank candidate labels for each topic.
As discussed in Mei et al. (2007) [11], compared with single terms and sentences, phrases appear to be more ap-propriate for labeling a topic. In general, to obtain phrases in documents, there are two basic approaches: Chunking Parsing and Ngram Testing [11, 4]. The Ngram Testing usually performs better than Chunking Parsing in labeling topics [11]. Therefore, we first generate meaningful phrases as candidate labels using Ngram Testing [4]. In addition, it is also possible to label a topic better using its own topic terms, as demonstrated by [6]. Thus we also add the top-n topic terms into the set of candidate labels, based on the term probabilities on the corresponding topic.
We rank the candidate labels, by exploiting the structural relation among the topics. To incorporate structural rela-tion, we have the following four intuitive assumptions: (A1) the label of a topic should be representative and important terms in this topic. (A2) given a topic, terms that are more common among its child topics are more likely to be suitable labels; For example, assume that the term  X  X lassi-fication X  occurs in documents of the topics about  X  X upport vector machine X  and  X  X aive bayes X ; Whereas terms  X  X upport vector machine X  and  X  X aive bayes X  only occur in their re-spective documents of each topic. It X  X  reasonable to label term  X  X lassification X  to the parent topic of the topics about SVM and NB. (A3) the labels near the top of the hierarchy should be more general than those at the bottom; For exam-ple, the terms  X  X upport vector machine X  is more specialized than  X  X achine learning X . (A4) if one label occurs often in one sibling topic only, then this label should be preferred over labels that occurr in all sibling topics. The assump-tions A2 and A3 are about parent-child relations; and A4 is about sibling relations. However, it is difficult to weight the structual relation. Based on these four assumations, we will describe the structual relation by the term weight scor-ing and statistic scoring approaches. Figure 2: Labeling performance on the Wikipedia dataset by different approaches with various hierar-chy depth. and we refer to this method as JSD .
We first crawled question-answer pairs (QA pairs) from two top categories in Yahoo! Answers: Computers &amp; Inter-net and Health . This gives rise to an archive of 6,345,786 QA documents. We refer to the dataset as Y!A .Moreover,we crawled documents from the Wikipedia, and filtered out cat-egories that do not carry any semantic information. In order to create a tree structure, we chose four topics as starting point, i.e. arts, computing, health, and sports , and then tra-versed the graph in a breath-first manner with a maximum depth of 10. For each node, we randomly chose only 5 outgo-ing links and 80 documents. Thus, we obtained about 1,640 categories and about 20,572 documents as the test dataset. We refer to the dataset as Wiki .

To obtain groundtruth, i.e. a hierarchy of topics and cor-responding labels, we conducted the following steps: (1) cre-ate preliminary topic hierarchies and labels by using a super-vised hierarchical topic model, i.e. hierarchical Labeled LDA (hLLDA) [13], over our document collections. (2) judge the resultant hierarchies manually, and correct inaccurate labels.
For evaluating the correctness of the generated topic la-bels, we used the following two definitions to judge what is a correct label: exact match and partial match [16]. For a given topic with correct-label C and its parent-label P , alabel L is an exact match of the correct label C if there exists a synonym SL of L such that SL is one of  X  C  X ,  X  CP  X  and  X  PC . X  On the other hand, a label L is a partial match of the correct label C if there exists a synonym CL of L such that CL has at least one term same as that in  X  C  X ,  X  CP  X  and  X  PC . X 
For each of the two definitions of a correct label, we com-pute the following performance metric: (1) Match at top Nresults( Match@N ) , which indicates whether the top N
To explore the influence of the hierarchical depth on la-beling performance, we executed the labeling methods with the utilization of varying hierarchy depth from level 1 to 8. Figure 2 shows the labeling accuracies with respect to dif-ferent hierarchy depth on the Wikipedia dataset. We can see that the labeling accuracy varies dramatically with the increase of hierarchy depth; and our proposed methods sig-nicantly outperform the other methods that do not exploit hierarchical relation at most cases.
We have proposed some factors to measure our assump-tions in Section 3.2, such as S i and R i . It is necessary to evaluate the influence of each factor on the labeling per-formance. Figure 3 shows the labeling accuracies by the TWL and JSD methods with different factor combination over the Wikipedia dataset. The labelling performance in-creases with the incorporation of more hierarchical relation, i.e., the utilization of more factors. Specifically, the perfor-mance increases when one more factor comes in. For ex-ample, the performance of the combination of S 1 and S 2 is better than that of S 1 . These results demonstrate the reasonability of our assumptions in Section 3.2.
In this paper, we have proposed two automatic methods for labeling topics in a hierarchy. Experiments over two real-word document corpus shown that exploiting the hier-archical relation among topics yield a statistically significant performance improvements as compared to the state-of-the-arts that simply treat the topics individually.

The future work is to incorporate domain ontologies or existing taxonomies, such as Wordnet and Wikipedia, into the topic labeling process.
 [1] D. Blei, A. Ng, and M. Jordan. Latent dirichlet [2] J. Boyd-Graber and D. Blei. Syntactic topic models. [3] J. Boyd-Graber, D. Blei, and X. Zhu. A topic model [4] J. Chen, J. Yan, B. Zhang, Q. Yang, and Z. Chen.
