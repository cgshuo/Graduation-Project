 This paper describes an adapted information bottleneck approach for construction of domain-oriented sentiment lexicon. The basic idea is to use three kinds of relationships (WW inter WD intra ) to infer the semantic orientation of the out-of-domain words. The experimental results demonstrate that proposed method could dramatically improve the accuracy of the baseline approach on the construction of out-of-domain sentiment lexicon. I.2.7 [ Artificial Intelligence ]: Natural Language Processing Algorithms, Performance, Experimentation Sentiment Analysis; Opinion Mining; Information Retrieval In recent years, we have seen a rapid growth in non-topical text analysis, in which characteriza tions are sought of the opinions, feelings, and attitudes expressed in a text, rather than just the subjects. A key problem in this area is sentiment classification [11-evaluation of a target object (film, book, product, etc.). one of the commonly-used methods is to build a general sentiment lexicon. A particular challenge for construction of general sentiment lexicon is that the se ntiment expression often behaves with strong domain-specific natu re, and this so-called domain-specific nature makes it an importa nt job to design an automated approach that could build a sentiment lexicon for each new domain. So far, two kinds of approaches have been proposed to deal with this problem. One is based on a thesaurus. This method utilizes synonyms or glosses of a thesaurus to determine polarity of words [2][5][6][8]. The second approach e xploits raw corpus. Polarity is decided by using co-occurrence in a corpus. This approach is based on a hypothesis that polar terms conveying the same polarity paradigm polar terms are prepared, and new polar terms are detected based on the strength of co-occurrence with the seeds [4][7][10]. Most of existing approaches ta ke the homogeneous relationship between words (i.e., relationship between out-of-domain words and in-domain words (WW inter -Relationship)) into account, while ignore the other two kinds of he terogeneous relationships (i.e., relationship between out-of-dom ain words and out-of-domain documents (WD intra -Relationship), relationship between out-of-domain words and in-domain documents (WD inter -Relationship)). Consequently, there is a lot of r oom for improvement and it is still a challenge to find more benefici al guidance from in-domain data for the construction of out-of-domain sentiment lexicon. In this study, we take the construction of domain-oriented sentiment lexicon as clustering of sentiment words and extend the information-bottleneck clustering algorithm [9] by integrating more restriction for building an appropriate knowledge context of every sentiment word. First, some corpus-based techniques are employed to build three graphs (i.e., WW inter -Graph, WD sentiment words and documents. S econd, an improved information bottleneck based clustering process is imposed on the three graphs, the polarity of out-of-domain sentiment words are identified simultaneously by the polar labels of in-domain data. The dramatically improve the performance of the baseline approach on the construction of out-of-domain sentiment lexicon. The proposed domain-oriented se ntiment lexicon construction the semantic relationship between words and documents, either in-domain or out-of-domain; (2) based on the three graphs, an information bottleneck based clustering process is imposed to obtain the semantic orientation of every out-of-domain word. Given the in-domain word collection {|1 } of-domain word collection {|1 } semantic similarity between any two words computed using approaches that are either knowledge-based or corpus-based. In this study, we simply choose th e mutual information to compute the semantic similarity between word which indicates the degree of statistical dependence between and pt and () occurrences of where () t . (, ) count t t N , where (, ) and We use an adjacency matrix A =[ A ij ] m X 2 to describe WW in which A i1 denotes the total similarity between out-of-domain word denotes the total similarity between out-of-domain word in-domain words with negative polar label. Then A is normalized to Given the in-domain document collection {|1 } i Dd im = X  X  X  the out-of-domain word collection {|1 } j Tt jn = X  X  X  domain document, we can build a weighted bipartite graph G from D and T in the following way: if word t j appears in document d , we then create an edge between d i and t j . A nonnegative weight importance of word t j in document d i , computed as follows: where t represents a unique term in d i and tf the term frequency in the docum ent and the inverse document frequency. We use an adjacency matrix B =[ B ij ] m X n Similarly, B is normalized to equal to 1. Similar to the WW inter -Graph, we can build an undirected graph WD inter -Graph to reflect the heterogeneous relationship between out-of-domain words and in-dom ain documents. We use an adjacency matrix C =[ C ij ] m X 2 to describe WD inter C denotes the total similarity between out-of-domain word t and all in-domain documents with positive polar label; C denotes the total similarity between out-of-domain word normalized to The information bottleneck algorithm (IB) is proposed by Slonim and Tishby [9], which is a clustering algorithm. 
Input : normalized matrix 
Output : the semantic orientation of every out-of-domain 
Initialization : 
Loop : 
Figure 1: Pseudo-code of the adapted information bottleneck The IB principle determines the distortion measure between the conditional distributions p ( y | x ) and p ( y | c ), and use the Jensen-Shannon divergen ce to measure the merge cost. Where the functional D JS is the Jensen-Shannon divergence defined as where in our case We extend the traditional IB algorithm for more in-domain knowledge (sentiment polarity label) , and the pseudo-code of the adapted information bottleneck algorithm is shown in Figure 1. This algorithm iteratively searches a clustering for the out-of-domain words, and assigns sentimen t polarity labels to the word clusters to complete the se ntiment-lexicon building task. In order to evaluate the properties of the proposed algorithm, in this section, we describe our e xperiments and the data used in these experiments. Aimed at Chin ese applications, we conduct the experiments based on the specia lty of Chinese language, and verify the performance on Chinese web reviews. However, the main proposed approach in this paper is language independent in essence. We download texts from the Inte rnet, which including comments http://blog.sohu.com/stock/). The de tailed information is illustrated in Table 1, We use ICTCLAS (http://ictclas.org/), a Chinese word segmentation software, to extract sentiment words from these texts. In the usage of the part-of-speech tagging function provided by this software, we take all adj ectives, adverbs and adjective-noun phrases as candidate sentiment words. 
Table 2 the detail information of labeled sentiment lexicon of Extracted Sentiment Words Electronics 58967 298 124 242 90 After removing the repeated words and words with ambiguity, we get a list of words in each domain. Then, we manually label the semantic orientation of every word, and use these labeled word lists as the sentiment lexicons in the following experiments. In order to highlight the nature of domain sentiment lexicon, we distinguish the domain-dependent sentiment words from the domain-independent sentiment word s in the process of labeling. We take the words only occur in one domain or the ones show reverse orientation among different domains as domain-dependent sentiment words. To justify the re liability of this labeling process, we ask three annotators to label one domain data, respectively. Three annotators had pair-wise agreement scores[1] of 80.10%, 83.87% and 85.96%, which is high enough to be considered consistent. Table 2 presents the detailed information of labeled sentiment lexicon of each domain. Since proposed method aims to construct domain-specific semantic orientation inferring met hods. Most of these approaches infer word semantic orientati on by measuring the relationship between words, which can be either corpus-based or knowledge-based, Since the proposed appro ach is also corpus-based, for justness, we take the PMI me thod[10], improved PMI (SM+SO) method[3] and lexicon extension (LE) method[7] as the baseline methods, and compare the perfo rmance between these methods and our method. The PMI method takes some labele d sentiment words as paradigm words to infer the semantic orientation of unlabelled words. In the implementation, we use the common part (sentiment words) of in-domain data and out-of-domain data as the paradigm words of the PMI method. For SM+SO method and LE method, we set up the experimental environment as the default confi gurations as Gamon and Aue [3] and Kanayama and Nasukawa [7]. We use accuracy to evaluate the performance of proposed method. Let C be the clustering function which maps from word (or document) to its true sentiment label, and F be the function which maps from word to its prediction sentiment label that given by the sentiment inferring methods. The accuracy is defined as: Table 3 and Table 4 report the performance comparison between proposed method and the three baselines on six tasks for domain-independent words and dom ain-dependent words. By the comparison between the two tables, we can find that nearly all approaches show better pe rformance on domain-independent tasks than on domain-dependent tasks, which indicates the difficulty of domain sentiment lexicon construction. From Table 4, we can find th at proposed method shows better performance on nearly all of the data sets. In consideration of that the baseline methods take only the relationship between out-of-domain words and in-domain words (WW inter -Relationship) into account, while neglect the other two kinds of relationship (WD Relationship and WD intra -Relationship), the full use of the three proposed method. Seen from these experimental results, a question may arise: why does the PMI method perform so poorly that it seems to disaccord the conclusion drawn by Turney and Littman[10]. A reasonable explanation is that the PMI method is corpus-based, and the corpus size influences its performance very much. The experimental results provided by Turney and Littman [10] is obtained by making use of search engine, and taking the whole Internet as the corpus. While th e corpus in our experiment is relatively small, which may brings much noise and makes the co-occurrence information sparse. Thes e factors may lead to the poor performance of the PMI method. Fr om another perspective, this also shows the robustness of proposed method on relatively small-scaled corpus. 
Table 3 Accuracy of domain-independent sentiment word There is only one parameter in proposed method, which is the trade-off parameter  X  in Equation 11. We conduct experimental to-hotel, hotel-to-electronics and stock-to-hotel. Figure 2 presents this experimental result. The parameter  X  reflects the influence of in-domain knowledge on the guide of clustering on out-of-domain data. From this figure, we can find that when  X  is small, by introducing in-domain knowledge, the accuracy increase; while when  X  is larger than a threshold, the algorithm gradually degenerates into the clustering based fully on in-domain knowledge, which excludes the contextual knowledge about out-of-domain data (i.e., WD According to this figure, we set  X  to 0.25 in our experiments. In this paper, we propose an adapted information bottleneck method for the automatic construction of domain-oriented sentiment lexicon by fusing the cross-domain knowledge and within-domain knowledge in a uni fied information-theoretic framework, and solve this problem using an iterative proposed method greatly outperforms the baseline methods in the task of building out-of-domain sentiment lexicon. This work was mainly supported by two funds, i.e., 0704021000 and 60803085. [1] J. Cohen. A coefficient of agreement for nominal scales. In [2] A. Esuli and F. Sebastia ni. Determining the semantic [3] M. Gamon and A. Aue. Automatic identification of sentiment [4] V. Hatzivassiloglous and K. McKeown. Predicting the [5] M. Hu and B. Liu. Mi ning and summarizing customer [6] J. Kamps, M. Marx, R. M okken, etc. Using WordNet to [7] H. Kanayama and T. Nas ukawa. Fully Automatic Lexicon [8] S. Kim and E. Hovy. Determ ining the sentiment of opinions. [9] N. Slonim and N. Tishby . Agglomerative information [10] P. Turney and M. Littman. Measuring Praise and Criticism: [11] H. Tang, S. Tan and X. Cheng. A Survey on Sentiment [12] S. Tan, G. Wu, H. Tang a nd X. Cheng. A novel scheme for [13] S. Tan, X. Cheng, Y. Wang, H. Xu. Adapting Naive Bayes to [14] Q. Wu, S. Tan, H. Zhai, G. Zhang, M. Duan and X. Cheng. 
