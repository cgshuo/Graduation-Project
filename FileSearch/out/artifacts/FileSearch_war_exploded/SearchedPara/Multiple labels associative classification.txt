 REGULAR PAPER Fadi Abdeljaber Thabtah  X  Peter Cowling  X  Yonghong Peng Abstract Building fast and accurate classifiers for large-scale databases is an important task in data mining. There is growing evidence that integrating classification and association rule mining can produce more efficient and accurate classifiers than traditional techniques. In this paper, the problem of producing label associative classification approach (MMAC). In addition, four measures are presented in this paper for evaluating the accuracy of classification approaches to a wide range of traditional and multi-label classification problems. Results for 19 different data sets from the UCI data collection and nine hyperheuristic scheduling runs show that the proposed approach is an accurate and effective classification technique, highly competitive and scalable if compared with other traditional and associative classification approaches.
 Keywords Data mining  X  Association rule  X  Classification  X  Multi-label classification  X  Frequent itemset  X  Hyperheuristic  X  Scheduling 1 Introduction Data mining is applicable to a wide variety of areas, such as finance, marketing and retail, and it has attracted much attention in the knowledge discovery and machine learning research communities [ 32 ]. Classification is a well-known task in data possible. Whilst single-label classification, which assigns each rule in the classifier the most obvious class label, has been widely studied [ 13 , 20 , 25 , 26 , 34 ], little work has been conducted on multi-label classification. Furthermore, the majority of the research carried out to date on multi-label classification relates mainly to text categorisation [ 15 , 28 ].
 one versus the rest (OvR) [ 33 ], which constructs a set of binary classifiers obtained by training on each possible class versus all the rest. The OvR approach performs a winner-takes-all strategy that assigns a real value for each class to indicate the class membership.
 which constructs a classifier that has been trained on each possible pair of classes. For K classes, this results in ( K  X  1 ) K / 2 binary classifiers, which may be prob-lematic if K is large. On the other hand, the OvR approach has been criticised for training on several separate classification problems, since each class can easily be separated from the rest, giving contradictory decisions (whenever two or more rules predict a test instance), and no decision (whenever none of the resulting rules can predict a test instance) [ 9 ].
 strategies for building a classification system. During the construction of each classifier, the heuristics look for single-label rules with high accuracy. In cases where the rule is associated with more than one class label, they usually select the rule associated with the label that leads to a lower error rate and simply ignore all other possibilities. However, one or more of the ignored rules may also produce competitive error rates, if compared with the selected rule. Moreover, in some possibly making them very useful in decision making. The majority of current traditional classification approaches, such as decision trees [ 11 , 25 ] and covering algorithms [ 20 ], do not take the creation of possibly useful rules with multiple labels into consideration.
 sively studied [ 2 , 13 , 21 , 24 ], and is still one of the most active research areas in data mining [ 14 ]. The association rule approach aims to investigate the shop-ping behaviour of customers, with the hope of finding regularities. Classification aims to predict single class label, while association rule mining can discover the relationship among any attributes in the data.
 cation, named associative classification, has been proposed [ 17 , 22 , 30 ]. A few ac-curate classifiers that use associative classification previously presented are CBA [ 22 ], CMAR [ 17 ], CPAR [ 34 ]andMCAR[ 30 ]. As in the majority of traditional classification techniques, most existing associative classification techniques create the most obvious class label correlated to a rule and simply ignore all other labels. However, multi-label classification rules may often be useful in practice. For the growing quantity of data in fields such as bioinformatics, scene classification and text categorisation, multi-label classification is more appropriate. It allows human refinement of classes, or allows further information (such as dictionaries in recog-nition) to be used in classification, hence there is great potential to develop and construct new algorithms to treat such problems.
 blocked sinus and coughing could relate to three potential class labels of illness  X  X old X ,  X  X lu X  or  X  X uberculosis X , which are stored in a database. Assume that these symptoms are associated 40, 34 and 26 times with the  X  X old X ,  X  X lu X  and  X  X uber-culoses X  labels, respectively. Furthermore, assume that the number of times the symptoms emerge in the database is 100 times. A traditional associative classifi-cation algorithm extracts only the rule associated with the most obvious label, i.e.  X  X old X , since it has the largest occurrence, and ignores the other potential rules. However, in this case it is useful to extract the other rules, since they bring up useful information that has a large representation in the database, which means that the two ignored rules may take a role in prediction and may be very useful to the decision maker. There are also many more application areas similar to medi-cal diagnosis where multi-label rules are more appropriate than single-label rules, such as text categorisation and scene classification.
 multi-class multi-label associative classification (MMAC). The presented tech-nique assumes that for each training instance that passes certain thresholds, there is a rule associated with not only the most obvious class label, but with the sec-ond, third, ..., k th possible class labels. In order to evaluate classifiers derived by MMAC on different application themes, and compare them to other approaches, four evaluation methods are presented.
 Sect. 2 . The multi-label classification problem is introduced in Sect. 3 . Basic con-cepts of association rule and associative classification are discussed in Sect. 4 . The MMAC approach and our methods for evaluation of traditional and multi-label classifiers are presented in Sects. 5 and 6 , respectively. Experimental results are given in Sect. 7 and finally the conclusions are presented in Sect. 8 . 2 Related work on associative classification Ali et al. [ 3 ] used association rule mining to calculate the correlations between the attributes and the class labels for two applications, e.g. telecommunication and medical diagnoses, using the a priori approach of Agrawal and Srikant [ 2 ]. Their aim was to extract overlapping rules that are individually accurate, and they did not consider prediction of future class labels. The results of the two case studies indicate that association rule can be used to generate many useful rules for medical practitioners. The authors speculated on whether association rule mining could be used for prediction.
 rule mining with classification. CBA operates in three main steps. First, it discre-tises real/integer attributes and second, it uses the a priori approach of Agrawal and Srikant [ 2 ] to discover frequent itemsets and generate the rules. Finally, a subset of the rules produced is selected to represent the classification system. The discovery of frequent itemsets is the most resource-and time-consuming step in CBA, since it requires multiple passes over the training data. In each pass, the seed of the rule items found in the previous pass are used to generate potential rule items in the current pass. The experimental results show that CBA scales well with regard to error rate if compared with decision trees [ 25 ]. [ 13 ] to find frequent itemsets. CMAR differs from other associative methods since it uses more than one rule to assign a class to a test object and stores the classi-fication rules in a prefix tree data structure, know as a CR-tree. When classifying a new object, CMAR accumulates the subset of classification rules matching the new object and looks at their class labels. In the case where all rules have a com-mon class, CMAR simply assigns that class to the test object. In cases where the classes of the accumulated rules are not identical, CMAR divides the rules into separate groups based on their class values and compares the effects of every group to identify the strongest one. The strength of the groups is measured by the weighted  X  2 adopted from [ 16 ].
 ing values has been studied by Li et al. [ 19 ]. The authors introduced two simple methods, one extends decision trees [ 25 ] and the other extends optimal class as-sociation rules [ 18 ]. They compare the predictive power of the two methods with popular classification methods, like CBA and decision trees, on test data that con-tain missing values. They claim that their association rule method generally de-rives a smaller set of rules that is able to predict test data objects with missing values. The k -optimal rules set has been introduced to obtain further minimal ef-fective rule-based classifiers. The results reported on four data sets [ 23 ]showed that the optimal association rule method is competitive with traditional classifica-tion methods based on decision trees.
 FOIL strategy [ 26 ] to generate rules, was proposed by Yin and Han [ 34 ]. CPAR seeks the best rule condition that brings most FOILgain among the available ones in the data set. FOILgain is used to measure the information gained from adding a condition to the current rule. Once the condition is identified, the weights of the positive examples associated with it are reduced by a multiplying factor, and the process repeats until all positive examples in the training data set are covered. The search for the best rule condition is the most time-consuming process of CPAR, since the gain for every possible item needs to be calculated to determine the best overall gain. In the rule-generation process, CPAR derives not only the tribute item with similar gain. It is claimed that CPAR improves the efficiency of the rule-generation process when compared with popular associative classification methods such as CBA.
 both positive and negative rules has been introduced by Antonie and Zaiane [ 4 ]. The  X  X nterestingness X  of the rules for the proposed algorithm is based on the cor-relation coefficient that measures the strength of the linear relationship between pairs of variables [ 29 ]. In addition to confidence and support thresholds, the cor-relation coefficient has been used to prune the final rules in the classifier, giving a much reduced rules set. The way in which the algorithm generates the rules is similar to an a priori method where multiple scans are required to discover the rules. Ranking occurs in a similar way as the CBA rules ranking method, e.g. con-fidence, support. Experimental tests on six data sets from the UCI data collection [ 23 ] showed that negative association rules are useful when used with positive rules for producing competitive classification systems.
 technique since it uses the core concepts of association rule mining (support and confidence), in a classification framework. However, MMAC presents the idea of extracting rules with multiple labels and has many distinguishing features over current associative classification algorithms, which we will discuss in more detail in Sect. 5.3 . 3 Multi-label classification problems Most of the research conducted on classification in data mining has been devoted to single-label problems. A traditional classification problem can be defined as follows: let D denote the domain of possible training instances and Y be a list of class labels, let H : D  X  Y denote the set of classifiers. Each instance d  X  D is assigned a single class y that belongs to Y . The goal is to find a classifier h  X  H that maximises the probability that h ( d ) = y for each test case ( d , y ). In multi-label problems, however, each instance d  X  D can be assigned multiple labels y , y ( y d in the training data. 4 Classification based on association rules 4.1 Frequent items, support and confidence Classification is a special case of association rule mining in which the consequent of the rule is the class label attribute. We aim to derive a complete set of class association rules of the form X  X  C ,where X is an itemset and C is a ranked list of labels. Let us define the classification problem in an association rule framework. class labels. A particular value for attribute A i will be denoted a i , and the class labels of C are denoted c j .
 Definition 1 An item is defined by the association of an attribute and its value ( A i , a ), or a combination of between 1 and n different attributes values, ( A 1 , a 1 ) , ( A 1 , a 1 ), ( A 2 , a 2 ) ,..., ( A 1 , a 1 ), ( A 2 , a 2 ),...,( A n , a n ) . Definition 2 Arule r for multi-label classification is represented in the form (
A tecedent of the rule is an item and the consequent is a list of ranked class labels, i.e. c il has higher ranked order than c i 2 and c i 3 .
 Definition 3 The actual occurrence ( Act Occ ) of a rule r in T is the number of cases in T that match r  X  X  antecedent.
 Definition 4 The support count ( SuppCount ) of r is the number of cases in T that match r  X  X  condition and belong to a class c i for r . When the item is associated with multiple labels, there should be a different ( SuppCount ) for each label. Definition 5 Arule r passes the minimum support threshold ( MinSupp ) if for r , the SuppCount ( r )/ | T | X  MinSupp ,where | T | is the number of instances in T . Definition 6 Arule r passes the minimum confidence threshold ( MinConf ) if SuppCount ( r )/ Act Occ ( r )  X  MinConf .
 Definition 7 Any item in T that passes the minimum support threshold is said to be a frequent item. 4.2 Associative classification The majority of current associative techniques use the step-wise a priori approach of Agrawal and Srikant [ 2 ] to find frequent items in a data set. If a frequent item consists of only a single value, it is said to be a frequent single item. Assume that the integer MinSupp is set to 3, the frequent single items in Table 1 are ( A 1 , x 1 ) , ( A 1 , x 2 ) and ( A 2 , y 1 ) .
 pairs of items, the frequent pairs of items are input to discover frequent triples of items, and so on. Associative classification techniques generate frequent items by making multiple passes over the training data. In the first pass, they count the support of single items and determine whether they are frequent, and then in each subsequent pass, they start with items found to be frequent in the previous pass in order to produce new possible frequent items.
 derive a complete set of class-association rules (CARs) for those frequent items that pass MinConf . These kinds of techniques are often called confidence-based methods since they generate only the class with the highest confidence for each frequent item. 5 MMAC Our proposed method consists of three phases: rule generation, recursive learning and classification. In the first phase, the method scans the training data to discover and generate a complete sort of CARs. In the second phase, MMAC proceeds to discover more rules that pass the MinSupp and MinConf thresholds from the remaining unclassified instances, until no further frequent items can be found. In the third phase, the rules sets derived during each iteration will be merged to form a global multi-label classifier that will then be tested against test data. Algorithm 1 represents a general description of our proposed method, which we will explain in more detail below.
 ues, or continuous, i.e. real and integer attributes. For categorical attributes, we assume that all possible values are mapped to a set of positive integers. In order to classify continuous attributes, we must first use a discretisation approach such as that described in [ 10 ].
  X  Phase 1:  X  Phase 2:  X  Phase 3: 5.1 Building the classifier 5.1.1 Frequent items discovery and rules generation To increase the efficiency of frequent-items discovery and rule generation, MMAC employs an efficient technique based on an intersection method [ 31 ]. The method scans the training data once to count the occurrences of single items, from which it determines those that pass the MinSupp and MinConf thresholds. Frequent sin-gle items and their occurrences in the training data (rowIds) are stored in arrays. Then, by intersecting the rowIds of the frequent single items discovered so far, it is easy to obtain the possible remaining frequent items that involve more than one attribute. The rowIds for frequent single items can be used to locate items quickly in the training data in order to obtain support and confidence values for rules involving more than one item.
 the rowIds of A and B , then the resulting set will represent the tuples where A and B happen to be together in the training data. Therefore, the classes associated with AB can be easily located, so that the support and confidence can be calculated, to decide whether AB is a frequent item and a candidate rule in the classifier. Since the training data has been scanned only once to discover and generate the rules, this approach is highly effective in terms of runtime and storage because it does which requires multiple scans.
 the MinConf threshold. If the item confidence is larger than MinConf ,thenit will be generated as a candidate rule in the classifier. Otherwise, the item will be discarded. Thus, all items that survive MinConf are generated as candidate rules in the classifier. 5.1.2 Ranking of rules and pruning Most of the current associative classification techniques rank the rules mainly in terms of the confidence level. When several rules have identical confidences or supports, CBA and CMAR randomly choose one of the rules, which may degrade accuracy. In order to ensure a subset of effective rules form the classifier, a detailed ranking technique, shown in Definition 8 , is presented. The presented ranking method is different from CBA and CMAR ranking techniques since it looks for detailed rules by adding a more detailed condition for breaking ties. Pruning takes place by discarding any item that has a support value less than the MinSupp and a confidence value less than the MinConf threshold. Another pruning of the rules occurs in the rule evaluation, which we discuss in Sect. 5.1.4 .
 Definition 8 Given two rules, r a and r b , r a precedes r b if: 1. The confidence of r a is greater than that of r b . 2. The confidence values of r a and r b are the same, but the support of r a is greater than that of r b . 3. Both confidence and support and ActOcc values of r a and r b are the same, but r a has fewer conditions in its left-hand side (LHS) than that of r b . 5.1.3 Recursive learning For given training instances D , associative classification algorithms such as CBA and CPAR derive a single-label rules set and form a default class for the remain-ing unclassified instances in D . On the other hand, MMAC derives more than one rules set and merges them to form a multi-label classifier. For D , the proposed method produces a first-pass rules set in which each rule is associated with the most obvious class label. Once this initial set is generated, all training instances associated with it are discarded and the remaining unclassified instances become a new training data, D . The MMAC algorithm checks whether there are still more frequent items remaining undiscovered in D (rules derived from D which may be associated with more than one class label). If so, a new set of rules will be generated from D , and the remaining unclassified instances in D will form new training data, and so on. The algorithm proceeds with learning until no more fre-quent items are discovered in a pass. At that stage, any remaining unclassified instances will form a default class.
 data and generating few rules sets. Consider for example the training data shown in Ta b l e 1 . Assume that the integer MinSupp and MinConf have been set to 2 and 0.40, respectively. At the first iteration, MMAC derives a set of rules: [ ( A 1 , x 2 )  X  c ,( A remaining unclassified instances, which are in bold, will represent the new training data for iteration two, in which one more rule will be learned, e.g. [ ( A 1 , x 1 )  X  c ] , and produced to form the second rules set.
 been produced at iterations 1 and 2 will be performed to obtain a global multi-label classifier. In many cases, a rule will be presented in more than one rules set and is associated with different class labels like item ( A 1 , x 1 ) , which has two representations in Table 1 , one with class label  X  c 1 1  X  in rules set 1, and one with class label  X  c 1 2  X  in rules set 2. A good question will be how one can rank the class labels in a rule to represent this item. 5.1.4 Rules evaluation evaluation step takes place to test each rule in order to remove redundant ones. If a rule correctly classifies at least a single instance it will be marked as a survivor and good candidate rule. In addition, all instances correctly classified by it will be deleted from the training data. In the case that a rule has not classified any training instances, it will be removed from the rules set. This process of pruning redundant and noisy rules from the set of produced rules minimises the chance that low-confidence rules will take any role in the later classification process. Furthermore, rules that have large frequencies and high confidences are preferred by the MMAC rule-ranking method. 5.1.5 Ranking of class labels A class label l 1  X  l 2 , also known as l 1 precedes l 2 in a multi-label rule r ,ifit has a larger representation in the training data. Consider, for example, an item ( that it has 100 representation in the training data in which it is associated with labels  X  c 1  X ,  X  c 2  X  X nd X  c 3  X , 50, 30, and 20 times. Moreover, assume that this item has passed the MinSupp and MinConf thresholds when associated with  X  c 1  X ,  X  c 2  X  X nd X  c 3  X . MMAC ranks these labels based on their number of occurrences ( ing form: ( A , a ), ( B , b )  X  c 1  X  c 2  X  c 3 . 5.2 Classification In classification, let R be the set of generated rules and T the training data. The basic idea of the proposed method is to choose a set of high-confidence rules in R to cover T . In classifying a test object, the first rule in the set of rules that matches the test object condition classifies it. This process ensures that only the highest ranked rules classify test objects. 5.3 Comparison of MMAC and CBA CBA and MMAC were applied on the training data shown in Table 1 by using a MinSupp integer of 2 and MinConf of 0.40 to illustrate the effectiveness of the rule sets derived by both algorithms. Table 2 represents the classifier generated by CBA, which consists of one rule and covers five training instances, which are 1, 4, 6, 8 and 9. The remaining four instances, that cover 0.36 of the entire training data, are left unclassified. The columns  X  X upp X  and  X  X onf X  in Tables 2 and 3 stand for support and confidence values.
 in which more rules have been discovered, i.e. three more rules than the CBA clas-sifier. In this particular example, there is only one rule derived by our proposed algorithm from Table 1 that has multiple labels, which is ( A 1 , x 1 )  X  c 1  X  c 2 . The MMAC classifier covers all training instances, and leaves no unclassified in-stances. Unlike the CBA algorithm that was unable to produce rules with multiple labels, our proposed method generates rules that can predict multiple labels. More-over, the CBA classifier contains only a default rule, and therefore it has large im-pact on the classification of unseen data that may significantly affect the accuracy in the classification, and could lead to deterioration in the overall classification accuracy.
 algorithms are the following:  X  MMAC presents not only a single class classifier but also a multi-label one, where each instance is associated with its ranked list of classes.  X  Other associative classification techniques often use multiple passes to discover frequent items. MMAC uses an efficient technique for discovering the rules, which requires only one scan of the data.
  X  MMAC introduces a detailed rule ranking technique that minimises randomisation when a choice point among two or more rules occurs in the rule-ranking process.  X  The proposed method presents a recursive learning phase that discovers more rules, aiming to minimise the role of the default class in classifying test objects. 6 Evaluation measures Multi-label classification has been investigated mostly in text categorisation [ 15 , 28 ], and there has been very little work conducted on developing evaluation measures for its classifiers. There are no standard evaluation techniques applica-ble to the multi-label classification problems. Moreover, the right measure is often problematic and depends heavily on the features of the considered problem, such as those used in [ 5 ].
 majority of single-and multi-label classification problems. First we define the mathematical notation we will use in our definitions. Let D denote the test data set with m rows d 1 , d 2 ,..., d m ,andlet C denote the set of classes. Row d has class c ( d ) in the test data set. A (possibly multi-label) classifier is a multifunction h : D  X  2 C , where for d  X  D , h ( d ) = h 1 ( d ), h 2 ( d ),..., h k ( d ) ( d ) .The f 1 ( d ), f 2 ( d ) ,..., f k ( d ) ( d ) respectively. 6.1 Top-label This evaluation measure takes into consideration only the top-ranked class label and ignores any other labels associated with an instance. For traditional classifi-cation tasks where there is only one class label to assign to the test object, and given an instance and its associated class, the top-label method estimates how many times the top-ranked class label is the correct class label. The top-label is |{ d  X  D : h 1 ( d ) = c ( d ) }| / m . 6.2 Any-label This evaluation technique measures how many times any of the predicted labels of an instance match the actual class label in all cases of that instance in the test label y , then the classification is correct. The any-label is | d  X  D : X  i such that h i ( d ) = c ( d ) | / m . 6.3 Label-weight This technique enables each predicted label for an instance to play a role in classifying a test case based on its ranking, and therefore it could be considered as a multi-label evaluation measure. An instance may belong to several class labels, each one associated with it by a number of occurrences in the train-ing data. Each class label can be assigned a weight according to how many times that label has been associated with the instance. The label-weight is respectively, in the training data. Each class label will be assigned a weight, i.e. 7/15, 5/15, and 3/15, respectively, for labels  X  c 1  X ,  X  c 2  X  X nd X  c 3  X . This technique matches the case class label. For instance if label  X  c 2  X  of item ( A , a ) matches a case in the test data that has  X  c 2  X  as its class, then the case will be considered a hit, and 5/15 will be assigned to the case. 6.4 Support-weight This evaluation technique gives the top-ranked label the maximum weight, and each of the rest a weight equal to the number of times that the label is associated with the instance divided by the number of times it is associated with the top-ranked labels. This means that the top-ranked label is considered the fittest, and each of the rest are assigned a weight that is less than the top-raked class weight. the example presented in the last section, the support-weight technique assigns 7/7, 5/7, and 3/7, respectively, to  X  c 1  X ,  X  c 2  X  X nd X  c 3  X . 7 Experimental results We evaluated our approach on 19 different data sets from the UCI data collection [ 23 ] as well as different data sets for forecasting the behaviour of an optimisation heuristic within a hyperheuristic framework [ 8 , 31 ]. Tenfold cross-validation was used to derive the classifiers and error rates in the experiments [ 32 ]. Cross-validation is a standard evaluation measure for calculating the error rate on data in machine learning.
 terms of classification accuracy (PART [ 11 ], RIPPER [ 7 ], CBA [ 22 ]) in order to evaluate the predictive power of the proposed method. The choice of such learning methods is based on the different strategies they use to generate the rules. Since CBA, PART and RIPPER are suitable for traditional classification problems, the classification accuracy derived by only the top-label evaluation measure has been used for a fair comparison.
 XP. The experiments for PART and RIPPER were conducted using the Weka software system [ 36 ]. Weka stands for Waikato Environment for Knowledge Analysis, which is an open java source code for the machine-teaching community that includes implementations of several data-mining tasks such as classification, clustering, association rule mining and regression. CBA experiments were conducted using a VC ++ implementation version provided in CBA [ 35 ], and finally MMAC was implemented using Java.
 overall classification accuracy of the set of rules produced by existing associa-tive classification techniques [ 17 , 21 , 22 ]. Moreover, the support value has a large impact on the number of rules produced in the classifier as well as the processing time and storage needed during rules discovery. From our experiments, we noticed that support rates ranging between 0.02 to 0.05 usually achieve the best balance between accuracy rates and the size of the resultant classifiers. Moreover, the clas-sifiers derived when the support was set to 2 and 3 achieved high accuracy and are often better than that of decision trees rule (PART), RIPPER and CBA. Due to this, the MinSupp value was set to 0.03 in the experiments. The confidence threshold, on the other hand, is less complex and unlike the support value does not have a large effect on the behaviour of associative classification methods, and therefore it was set to 0.30. 7.1 Binary and traditional data results We have evaluated 19 selected data sets from [ 23 ], six of which were reduced by ignoring their integer and/or real attributes. Several tests using tenfold cross-validation have been performed to ensure that the removal of any real/integer attributes from these data sets does not significantly affect the classification accuracy. As a result, we only considered data sets where the error rate was not more than six times worse than the error rate obtained on the same data set before the removal of any real/integer attributes.
 PART, RIPPER, CBA and MMAC on the 19 benchmark problems. The accuracy of MMAC has been derived using the top-label evaluation measure. Our algo-rithm outperforms the rule-learning methods in terms of accuracy rate, and the won X  X oss X  X ied records of MMAC against PART, RIPPER and CBA are 13 X 6 X 0, 15 X 4 X 0 and 15 X 4 X 0, respectively. The results shown in Table 4 indicate that our proposed algorithm outperforms CBA in terms of error rate. One of the principle reasons for this appears to be that MMAC often generates a few more rules than CBA. The increase in accuracy suggests that this is not simply overfitting and would likely justify the small increase in classification rate for MMAC over CBA in applications. However, in some cases, such as the  X  X RX X  data set, the number of rules is large, even though every rule represents at least one training object. Thus, a post-pruning method, such as pessimistic error pruning, [ 27 ]maybe useful in such cases.
 data sets. It indicates that the associative-based techniques MMAC and CBA are slower than the traditional techniques PART and RIPPER. Particularly, since CBA adapts the a priori approach, which is a resource-and time-consuming approach, making it the slowest algorithm for building classifiers. Furthermore, PART is the fastest algorithm to construct a classification system due to its simple strategy to discover rules. The figures also suggest that our proposed algorithm is typically slower than traditional classification techniques such as RIPPER and PART. How-ever, they also indicate that MMAC compares well in term of processing time with the CBA algorithm. 7.2 Multi-label scheduling data results Details of several solution runs generated by a hybrid hyperheuristic, named Peck-ish, for solving a complex scheduling problem are provided by Thabtah et al. [ 8 ], Cowling and Chakhlevitch [ 31 ]. The hyperheuristic is a robust, general approach plex scheduling and optimisation problems. One can consider a hyperheuristic approach as a supervisor that manages the choice of which low-level heuristic to select from the available ones for the problem during the process of building a schedule.
 the maximum improvement to the objective function (if one exists). If none of the existing low-level heuristic improves the objective function, the Peckish hyper-heuristic selects one randomly. A low-level heuristic is a simple rule or method that yields a small change in the schedule. Often these low-level heuristics are based on human methods of constructing the schedule, such as adding an event, deleting an event or swapping two events.
 tions of applied low-level heuristics. In addition, ten different low-level heuristics (LLH 1, LLH 2, LLH 20, LLH 27, LLH 37, LLH 43, LLH 47, LLH 58, LLH 68 and LLH 74) have been used to generate each solution. Each solution consists of six different attributes and a number of instances that maximise the objective function of the optimisation problem. Table 5 indicates the features of the data sets used in the experiments.
 heuristic where columns LLH2 and LLH1 represent the low-level heuristics ap-plied at the previous two iterations. Column LLH represents the current low-level heuristic that improved the objective function and column Imp represents the im-provement on the objective function value. Finally, the column Apply represents whether or not the selected low-level heuristic has been applied by the hyper-heuristic. The data generated by the hyperheuristic is multi-label, since at each iteration there could be more than one low-level heuristic that improves the objec-tive function. For example, at the first iteration in Table 6 , there are three low-level heuristics (LLH 2, LLH 43 and LLH 4) that improve the objective function. Thus, there are three class labels associated with the instance (1, 1). Generally, each training instance in the scheduling solutions may associate with at least; one class label.
 the nine solution runs produced by the Peckish hyperheuristic, with regard to accuracy, and rules features. Figures 2 and 3 represent the relative prediction accuracy and indicate the difference in the classification accuracy of the MMAC evaluation measures with respect to those derived by CBA and PART. The relative prediction accuracy numbers shown are calculated using the formula top-label and label-weight measures, since in most cases both of them consider only one class in the prediction. The top-label takes into account the top-ranked class, and the label-weight considers only the weight for the predicted class that matches the test case. Thus, both of these evaluation measures are applicable to traditional single-class classification problems. On the other hand, the any-label measure considers any class in the set of the predicted classes as a hit whenever it matches the predicted class, regardless of its weight or rank. Furthermore, the support-weight measure balance between any-label and top-label measures be-cause it considers the top class the fittest on one hand and assigns each of the rest of classes a weight on the other hand. It should be noted that the relative accuracy of MMAC evaluation methods against data set number 8 in Figs. 2 and 3 ,isneg-ative since CBA and PART achieved a higher classification rate on this particular data set.
 has been carried out. Figure 4 shows the number of rules extracted from each data set, categorised by the number of class labels. Unlike most associative techniques, four labels. This is one of the principle reasons for improving the classification accuracy within applications. Figure 4 also demonstrates that the majority of the rules created from each scheduling run are associated with one or two labels. It turns out that this is due to the fact that, during each iteration, often only one or two low-level heuristics improve upon the objective function in the scheduling problem. Thus, each training instance often corresponds to just one or two class labels. Figure 5 shows the distribution of the training instance association, with class labels for one scheduling data set where instances that are correlated with one class label dominate the rest.
 than PART and CBA for the majority of the data sets. One principle reason for extracting more rules is due to the recursive learning phase that MMAC employs. This discovers hidden information that most of the associative classification techniques discard, as they only extract the highest confidence rule for each frequent item. 8 Conclusions A new approach for multi-class multi-label classification rules has been proposed that has many distinguishing features over traditional and associative classification methods: (1) It produces classifiers that contain rules with multiple labels, (2) It presents four evaluation measures for determining accuracy that are applicable to a wide range of applications, (3) It employs an efficient method for discovering rules that requires only one scan over the training data, (4) It employs a detailed ranking method, which prunes redundant rules, and ensures only effective ones are used for classification. Performance studies on 19 data sets from UCI data collection and nine hyperheuristic scheduling runs indicate that our proposed ap-proach is effective, consistent and has a higher classification rate than PART, CBA and RIPPER algorithms. In addition, the proposed algorithm is able to extract rules with up to four multiple labels from the scheduling data sets, which results in a higher classification accuracy for test instances. In further work, we anticipate extending the method to treat continuous data and create a hyperheuristic approach that learns  X  X n-the-fly X  which low-level heuristic method is the most effective. References
