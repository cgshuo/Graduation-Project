 Recent technologies supporting continuous connectivity enable sustained awareness within soci al networks, which eventually boosts interaction and therefore the need of individuals to manage their interpersonal privacy. This paper introduces the Privacy Grounding Model that describes how people develop and use mechanisms to establis h a shared understanding of their intentions to interact with others. The main design implication of this model is the need for lightweight interactive mechanisms by which individuals can collaboratively ground needs for interaction. To illustrate how the model supports the design of grounding mechanisms, we present examples and discuss a case study that informs about their use during several weeks. H.5.3 [ Information Interfaces and Presentation ]: Group and Organization interfaces  X  asynchronous interaction, synchronous interaction, theory and models. Design, Human Factors, Theory. Interpersonal privacy, coordination, social communication, mediated communication, ambiguity. The contemporary trend towards increasing connectivity means that people render themselves accessible for communication and social interaction in a larger proportion of their day and in an ever increasing range of social and physical contexts. In the context of non-mediated social interactions an individual can easily avoid social contact and accountability to react to others by means of physical separation, e.g., closi ng doors, managing interpersonal distance, gaze orientation, body posture, etc. In contrast disembodiment of remote partners [3] means that the initiation of communication, social interaction and the interruption of another circumvent these traditional m echanisms to manage one X  X  privacy. Particularly in the context of computer mediated communication competing inten tions for connectedness and privacy need to be managed at once, which causes individuals to experience distress over their interpersonal space [10]. Personal reachability management studies try to address this problem by developing automatic control of accessibility to others [12, 18]. However, such solutions seem unable to address the subjective and dynamic aspect s of coordinating people X  X  interaction needs. Automated solutions for protecting privacy seem elusive and even undesirabl e. Bellotti and Sellen [3] discuss the limitations of automated mechanisms for privacy protection, arguing that users need control and feedback over system behaviour so they can be better informed and capable to prevent misuse of personal information they disclose. They stress that while awareness can be perceived as intrusive, too little awareness can also cause unintentional invasions to privacy. An example in mediated communica tion is when people cannot tell the availability of others which could lead them to initiate conversation at undesired times. Na rdi, Whittaker and Bradner [8] introduced the notion of outeraction to describe relevant social practices that people use to coordinate availability in their mediated communication activities. In the context of instant messaging they discuss initiations, delays, omissions, and use of plausible deniability. At the other extreme, an exclusively manual control over one X  X  accessibility to different parts of one X  X  social network can represent an excessive workload for users, making it difficult to manage interpersonal interactions effectively. Wu [20] reports a short-term deployment of a loca tion-based application for mobile phones in which users could reque st location based information and accept or reject incoming requests about own location. They could also create privacy rules letting the system manage specified incoming requests. Study participants reported the need for both interactive and automatic privacy control, as the criteria to assess such requests depe nded on who was requesting the information but also on how often they received communication requests. experimentally. A study of inte rruption behaviours in mediated settings [16] shows how communica ting individuals who need to interrupt each other in order to progress with their own tasks, prefer interactive mechanisms to coordinate interruptions as opposed to automated solutions. T hus they observe that when given automated filtering of interruptions, their study participants developed workarounds allowing them to coordinate interruptions  X  X anually X  with the other party. Palen and Dourish [10] argue that users of mediated communication systems are primarily concerned about interaction issues(reachability and interruptions) than issues regarding disclosure of information (surveillance, identity theft, etc.). We refer to this privacy concern as the coordination of interpersonal privacy . Representations of how systems and their users manage their interpersonal privacy can help users predict each others X  behaviours to interact. Palen and Dourish [10] point out how users rely on representations of their presence and actions to understand each others X  degree of availability and accessibility, concluding that automation and low fidelity mediation can affect adversely this process of mutual understanding if what the system conveys is not what the users intended to communicate. An important aspect when ma naging self-presentations is ambiguity . Aoki and Woodruff [2] discuss the importance of individuals to control their own face and respect for others while allowing for ambiguity over the explanations they used to reach successful face-work. They argue that representations of one-self do not need to reflect the truth pe r se as soon as they are accepted by the parties involved. Failure to represent intended availability can result in interpersonal privacy breakdowns, described as an undesired state of interaction cause by the disclosure of too much or too little information [6]. Such undesired states can be associated with affective costs such as feelings of being obliged to react to a message, or feelings of uncerta inty and disappointment towards unresponsive interaction. Aoki and Woodruff [2] identify the social implications of accoun ting for unresponsiveness. They discuss the need to provide explanations even when no reaction is planned. As mentioned earlier such explanations when considered acceptable by others, seem useful for individuals to  X  X ave face X  for themselves and for others, even if they are ambiguous In [19] the communication behaviours of a group of teenagers when using a Push-to-Talk (PTT) system are examined. PTT X  X  lightweight protocol of esta blishing a communication allowed their study participants to coordinate effortlessly their availability for interaction. Nevertheless, participants reported feeling apprehensive about using such a system with others than very close friends, as the lightweight pr otocol to initiate conversations renders one vulnerable to be cont acted at all times. Considering the arguments by [2] and [3], PTT provides a clear example of a lightweight mechanism for managing privacy borders, but supports no shared representati ons that allow communicating parties to build a common understanding of their availability and coordinate interactions when conflicting needs arise. This paper describes the design of interactive solutions over availability representations to support the coordination of interpersonal privacy over differe nt media. We argue that to manage interpersonal privacy designers of communication applications need to strike a balance between (i) lightweight collaborative practices for es tablishing communication and communicating intentions to interact; (ii) allowing communicators reach a shared understanding of the representations of their interaction needs and (iii) to respond to individuals X  needs for equivocation and ambiguity. This so cial perspective on privacy is founded on the Privacy Grounding Model (PGM) a theoretical model that describes how privacy borders are collaboratively coordinated. It was de veloped as an application of Clark X  X  theory of Common Ground [5] in the specific context of coordinating interpersonal privacy. The remainder of this paper outlin es PGM that characterizes the elements of interpersonal privacy as a collaborative coordination process. This perspective recognizes the dialectic and dynamic nature of interpersonal privacy [1], and aims at informing solutions that support the social capabilities of communicators to coordinate collaboratively their interpersonal privacy needs [1, 10, 11]. We show how the model in forms the design of interactive tools for coordinating interpersona l privacy. We conclude with a discussion regarding the lessons learnt from the design of such mechanisms and directi ons for future work. Privacy is considered from a social interaction perspective as introduced by Altman [1] and app lied to the context of mediated communication by Palen and Dourish [10]. Individuals continuously regulate th eir social interactions to and from the environment adapting the representations of their privacy borders to reflect their moment-to-moment availability to interact [1]. In doing so, they may evaluate the current situation as ranging from  X  X rowded X  when more interaction than desired takes place through to  X  X olitude X , when little social interaction than desired is achieved. Petronio [11] extends Altman X  X  definition of privacy emphasizing collaboration as an active element in the disclosure of private information, where both the owne r and the recipient of this information share responsibility for its disclosure. We endorse Petronio X  X  conception of privacy as a collaborative coordination process, though her theory does not account for the mechanisms by which collaboration is orchestrated. However, such an explicit account is instrumental for informing the design of interactive mechanisms to suppor t privacy control. The Privacy Grounding Model (PGM) addresses this gap, providing a generic characterization of the social practices surrounding interpersonal privacy coordination. PGM is an application and refinement of the theory of Common Ground by Clark [5], a theory that provides a rich description of how communicating individuals coor dinate the process and the meanings of their communication (mostly applied to verbal face-to-face communication). Below we summarize PGM; a detailed account of the links to Common Ground theory and empirical validation of the model are outside the scope of this paper and can be found elsewhere [13, 14, 15]. Here we focus on the implications of this model for design. Given its basis upon Common Ground theory, PGM assumes the presence of collaboration at least to the extent in which communicators establish a shared understanding of their privacy borders. The scope of PGM does not include antagonistic privacy invasion as, for example, using deceit to gain access to an individual. The model does though account for differing and competing needs of individuals to engage in communication and describes how these needs are coordinated. PGM distinguishes three levels of abstraction that connect theoretical aspects of privacy coordination ( component level ) with descriptions of related behaviours ( mechanisms level and characterizations level ). At the component level we distinguish between collaboration, representations of privacy borders turn from individual intentions into a shared understanding. This occurs in a process where individuals develop the necessary common ground for their coordination purposes. Figure 1 illustrates the process in which members of a networked community regulate privacy borders by collaborating in the development of common ground for coordination by signalling the intentions and grounding the understanding of their privacy borders. Regulation amounts to opening and closing of privacy borders. The model describes three types of privacy regulation, as these were classified by [4]. Solitude control concerns the regulation of borders related to availability, for example when setting an  X  X way X  status. The control of confidentiality concerns borders indicating information flow, fo r example blurring one X  X  video presence image (e.g., as in [9]). Finally, the control of autonomy concerns the regulation of the dependence or independence of an individual X  X  behaviour, e.g., feeling obliged to call back, or feeling social pressure to engage in a particular behaviour. The collaboration component pertains to the need of communicators to develop conjointly the representation of their privacy borders through the range of communication channels available to them. For example, borders can be represented by information shared through video br oadcast, chat messages, or by one X  X  online status. Collaboration is achieved using contribution pairs as mechanisms in which communicators contribute through presentations of privacy borders and reactions to such presentations. These contributions are characterized by the use of proposals as presentations of inten tions to initiate interaction (e.g.,  X  X re you there? X ,  X  X  X  X  back X ), and acceptances or repairs as reactions to communicate agreement or to fix a previously produced presentation, respectively (e.g.,  X  X es, I X  X  here X ,  X  X  X  X  busy now X ). The effort of collaboration indicates the shared motivation of participants to contribute in th eir communication process. Clark X  X  principle of least collaborative effort is manifested in how communicators adapt their strategy to coordinate their contributions. Communicators enga ge in an assessment process where they estimate the effort required to (develop the common ground needed to) achieve understanding in the exchange of contribution pairs [5]. For exampl e, sometimes an  X  X way X  status would be sufficient to convey one X  X  availability while in other cases additional effort is require d to facilitate the understanding of such representation by adding some elaboration or explanation. The signalling component relates to the communication of intentions to interact. Indivi duals communicate their privacy intentions using two tracks of communication: track-I signals to communicate the main content of the communication, and track-II signals to provide the means to coordinate the process of communication in track-I [5]. For example, a message  X  X i, can we talk now? X  is an explicit messa ge that indicates intentions for communication (track-II signal) wh ile, a message  X  X ow did your meeting go? X  is explicitly communicating a content signal (a track-I signal). Note that the second signal also indicates, but implicitly, the availability to communicate. Other ways to indicate availability can be purpos e specific representations, such as online status, changing the pres ence name in the buddy list, etc. To guarantee that intentions are signalled effectively and with a minimum collaborative effort, track-II signals should be distinctive , brief , in the background and simultaneous to the signals in the content track (track-I) [5]. Therefore, we think that to support successful track-II signals, designers need to provide explicit as well as lightweight mechanisms for representing privacy borders. Typically for mediated settings, the more explicit a signal for coordination, the le ss brief, less in the background, less simultaneous, but more distinctive it will be. For example, an  X  X way X  status in an instant messaging application, is more lightweight but less distinctive than a text message  X  X  am away X . The grounding component pertains to the process of establishing common ground, i.e., a shared understanding of the privacy borders and respective intentions to interact. To ensure that grounding is achieved, communicator s assess whether they need to commit in collaborative effort to develop common ground, or whether they can use extant common ground and in doing so minimize the effort needed for grounding. We distinguish three representations that are used to develop common ground: conventions referring to group custom or practices related to the use of a communication protocol; shared events referring to any information related to previous ev ents that have been shared by all communicators and external representations referring to any external demonstration of track-I signals, which all communicators can see [5]. Conventions and previously shared events although crucial in the development of common ground turn out to be less relevant with respect to the scope of designing interactive coordination mechanisms. Their development and use is a social process that may be only indirectly influenced by the design of the medium used. For example, if someone uses previous experiences to decide not to talk to a friend later than 10 p.m., that decision does not require interactive mechanisms to coordinate it. In the context of mediated communication, almost any information presented in the syst em could be seen by users as representing privacy borders. Fo r example, video snapshots, online status, chat messages, etc ., could represent intentions to interact and thus represent in terpersonal privacy borders. A direct implication of PGM is that interactive solutions must support the development of shared representations of privacy borders to coordinate interpers onal privacy without compromising the degree of ambiguity that communicators need. More specifically, designers need to support (a) signalling and grounding mechanisms to inte ntionally link (b) existing representations with (c) privacy intentions, so they become (d) shared basis for coordination of interpersonal privacy (see Figure 2). Below we describe our e xperience from the design and examination of two interactive mechanisms for the collaborative grounding of interpersonal privacy: the one-click mechanism and the drag-and-drop mechanism. We discuss the motivation of these solutions, their implementa tion and lessons learnt from a case study. In line with PGM X  X  desi gn implications as depicted in Figure 2, such interactive mechanisms were designed to be lightweight (a) signalling and gr ounding mechanisms that link (b) existing messages in content channe ls (e.g., the main text window in a chat application) with (c) inte ntions to interact by (at least) indicating that an (d) existing message has been attended to. The two interactive grounding mech anisms mentioned have been implemented as extens ions of an existing groupware application, the Community Bar [7]. Community Bar (CB) is a groupware system that supports awareness and casual interaction of small communities. While the implementations are tied to CB, these mechanisms and the issues surrounding their design are quite generic; CB combines several tools for enabling groups to communicate, which appear in di fferent social networking and groupware applications, so the de sign issues discussed below are relevant for a very broad range of systems. CB runs on desktop computers and offers a bar positioned at the side of the screen, always visible, even if other applications are set to  X  X aximized X  view. The sidebar of CB (see Figure 3) provides a shared space where users can post and see media items , which provide awareness informati on that can take the form of video, chat, text notes, web page s, activity indicators, digital photos, etc. CB implem ents the notion of places representing small virtual social worlds where members of a community can dynamically create places or join existing places according to their needs to interact in sub groups within a community [7]. People could belong to multiple places at the same time and in 
Figure 4. Tooltip (right) and maximized (left) chat view. 
Figure 5. One-click grounding representation of a message each place they can create as many media items as necessary to support their social activities. Privacy border regulation in CB concerns largely with unresponsiveness in chat convers ations as a result of their asynchronous nature. In an evaluation study of Community Bar [17] it was observed how users needed to disambiguate whether their messages are delayed or omitted, and they often needed to know whether the message has at least been read. Similarly, participants delaying or omitting to respond often felt the need to acknowledge that they have read the message but they could not react immediately. In terms of PGM we observe that, in both cases, the lack of track-II signals impedes the acknowledge ment of unresponsiveness in a way that does not require to actually interact. Communicators limited to a chat channel for example, experience a lack of communicate track-II signals as te xt is characterized as an effective but not lightweight signal for grounding privacy. The Privacy Grounding Model gives rise to two requirements for the design of signalling and grounding mechanisms in the context of existing chat representations: minimize the effort of signalling and grounding existing chat representations, and maximize the effectiveness of the coordinati on process, whilst allowing for ambiguity. The grounding mechanisms are im plemented as part of the maximized view of the chat application in CB (see left window in Figure 4). This view provides a window that displays the text messages of a conversation to the le ft and the participants of that conversation to the right. For the implementation of these mechanisms this view was sligh tly modified by adding a colour scheme to identify the owner of each message (see Figure 5 where messages by User 6 and User 3 are distinguished by different colours). The interactive mechanisms implemented are designed as lightweight alternatives to te xt-based messages that support intentional but low effort signalling for grounding existing privacy border representations. They offer variations of lightweight and ambiguous track-II si gnals to minimize the effort of signalling and grounding existing chat messages as representations of interp ersonal privacy borders. The one-click grounding is an interactive m echanism that allows chat participants to click on someone else X  X  existing message in the chat application as a lightweight reaction. Figure 5 shows the chat view of User 6, and the one-click representation of User 3 (see black circle, and the mouse over notification) who clicked on a User 6 X  X  message. The one-click mechanism offers a low-effort signalling and grounding that aims to help communicators understand that their message has been read. A user, who does not intend to engage in a requested interaction, can click on a message to acknowledge that he has attended it but cannot react immediately. This mechanism supports autonomy on the basis of ambiguity:  X  X  saw your message but I X  X  not re plying, maybe later X  (without having to say when or why). This representation grounds unresponsive interaction as a collaborative mechanism that minimizes initiator X  X  uncertainty of whether the message has been noticed or not, without compromising the recipient X  X  need to postpone answering. The ability of the user to avoid interaction by not acknowledging a message at all is also not compromised. The drag-and-drop mechanism allows participants of a conversation to add pre-fabricated text to existing messages in the chat application. It provides a  X  X rounding palette X  that allows users to create a collection of personalized texts which can be dragged and dropped into an exis ting chat message to signal and ground their intentions to react or expectations for reactions. The dragged information is designed as a track-II signal which is displayed below the existing message providing the following data: grounder X  X  name, timestamp , the grounding message, and a symbol (  X  ) to make it distinctive from the typed messages in the chat (see Figure 6). Initiators and recipients of a ch at-exchange can use the drag and drop mechanism to build common ground regarding their interpersonal privacy borders. Initiators can provide extra information to ensure a good understanding of the intentions of their chat messages and expectations of reactions. Recipients can provide more information about their understanding and how to handle requested interaction. For example, to acknowledge a delay U6 adds the  X  X anned X  messa ge  X  X hone me later X  to User 3 X  X  intentions to initiate a conversation (see Figure 6). The drag-and-drop mechanism offers a light way to map a grounding instance with an existing message, assuming that the effort of drag-and-drop to ground an existing message would be less than writing a full text in the chat item. The  X  X rounding palette X  allows members of a community to develop a collection of intentional signal to support grounding, which can be used and reused in different context to c oordinate intentions. Ambiguity is preserved by giving users the flexibility to define the content (precision) of the dragged-and-dr opped messages. It is expected that drag-and-drop grounding should be useful in situations where 
Figure 6. Drag-and-drop grounding representation of a more information needs to be provided for grounding privacy needs compared to what is possible with the one-click mechanism, e.g., to offer apologies, explanations or even to repeat the same response to several initiators, etc. A case study is presented to in form how the one-click and the drag-and-drop mechanisms influe nce the development of common ground to coordinate initiations and unresponsive interaction (whether delays or omissions). Our expectations regarding the impact of the two grounding m echanisms were twofold: (1) The lightweight (low effort) nature of the mechanisms (2) The distinctive aspect (effectiv e) of the mechanisms should The study design consisted of a within subject setting with two weeks of intervention (grounding weeks) and two weeks without intervention (control weeks) of the grounding mechanisms. In the control weeks an original version of Community Bar (CB) was used, and in the grounding weeks a grounding-version was used that included the implemented mechanisms (CB g ). For the purpose of the study we focused on the interaction that occurred in three media items of CB: presence, chat and alert item. The presence item represents the presence of people connected to the system by broadcasting a picture or video snapshot, a status, and a name (text); the chat item represents a space for public conversations; and the alert item is implemented in the presence item and represents a visual way to attract others X  attention. Study participants are a small co mmunity of twelve PhD students, all members of the same research group. Only five members of the group were familiar with CB though none were regular users; the rest of the group was new to the system. The group was partially distributed between two consecutive floors. Half of the participants shared a big open offi ce together with other students. The other half was spread over smaller rooms shared with non participants except for two par ticipants who shared the same room. Most participants work individually on their own projects. Daily interaction between participants is mostly face-to-face, via email and instant messaging (mainly MSN). Most of their casual interaction is social, and their work related activities are mostly based on planned meetings. For example, once every two weeks they gather with members of their research group to attend presentations about each other X  X  wo rk. Besides, they coordinate periodic meetings to discuss partic ular aspects of their projects. The social interaction of the group is mostly limited to lunch and coffee breaks, though subgroups engage in more frequent interactions. The observer is a member of this group involved in both social and work activities, thus she was well aware of the characteristics of the group and its members. To minimize the influence of her observations in pa rticipants X  interaction, she did not use CB (or CB g ) to communicate with the participants during the study period. Participants were asked to use CB (or CB g ) for four weeks as their primary communication media. For each study period they were given a user manual that br iefly describe the functionalities offered by the current CB version in used (without and with grounding mechanisms). They were not aware of the purpose of both the study and the grounding mechanisms. Their only instruction was to use CB to interact with the other participants checking the new functionalities in the grounding weeks. They had the freedom to use other media only in the case where CB could not be appropriate for the communication purpose, for example to engage in a private conversation or to contact someone who was not in the system. The use of a camera was obligatory, but participants were free to choose what to broadcast at any time. Often they chose to point the camera away from their face, e.g., the ceiling, their keyboard, and the room they were in, etc. Logs were analyzed looking fo r confirming and disconfirming evidence regarding the use of the grounding mechanisms as low effort and sufficient track-II signals to coordinate interaction. The unit of analysis was defined as a coordination unit formed by one initiation and its related reactions. Initiations were identified as the indi viduals X  actions to establish interaction with others. Coordi nation units in the data logs corresponded to initiations in either the chat or the alert items. They were characterized as incidental or intentional signals in the chat item, and intentional signals when coming from the alert item. Reactions were defined as the actions of an individual that were triggered by an existing initiation. In addition, non-chat signals relating to the identified initiation and reaction such as online status, video, connection time, etc., were also included in the coordination unit to provide the necessary context for the communication process. An inte ntional reaction signal could come from chat, alert or the grounding mechanisms. Reactions that occurred more than ten minutes after the initiation was presented were considered as delayed reactions. Criteria for confirming evidence pertain to the use of the mechanisms as grounding intentions to react to existing chat messages. For example, a r ecipient using the one-click mechanism to ground that an existing message had been read but not dealt with yet. This occurren ce was considered as evidence of lightweight signalling and grounding of existing representations, as well as evidence of using ambiguity to develop common ground, without explicit grounding. Criteria for disconfirming evidence relate to the use of extra text-based track-II signals to reach a shared understanding of an existing chat representation. For example, the use of the one-click mechanism followed by a text as an explicit repair such as  X  X usy now, I will react later X  indicated that the one-click was insufficient. This occurrence was considered as evidence of lack of support of (1) low effort si gnalling as more signals were required and (2) sufficient gr ounding as more explicit grounding was needed. A quantitative comparison between grounding and control weeks aimed to assess the effect of the grounding mechanisms in supporting privacy coordination. The comparison concerned the signalling and grounding of unresponsive reactions (whether delays or omissions), which present a major challenge in the coordination of interpersonal priv acy. Considering the use of one-click and drag-and-drop as track-II signals to support low-effort coordination of reactions (1), it was expected that their use in the grounding weeks would be for a first reaction after an initiation by other or for joining an existi ng conversation. We measured the occurrences of these two events ( first-reaction and join-conversation ) and the time elapsed between the initiation and the respective event. The lightweight aspect of the mechanisms was expected to encourage more of su ch events with the mechanisms as coordination signals (track-II) than in the control weeks, therefore minimizing the uncertainty of omissions or long delays. We also expected to provide confirming evidence regarding sufficient grounding and ambiguity (2), if the use of the grounding mechanisms is found suffi cient to coordinate privacy without the need of extra text-bas ed intentional signals to make the privacy representations more explicit. Data was collected over a period of four weeks, with five consecutive working days each. A total of 59098 lines were recorded, in which 85% were classified as system notifications including video snapshots, and auto matic status changes; 2% as u ser interaction including connection to the system, chats, alerts, manual status change, presence message, and the use of the one-click mechanism; and the remaining 13% events were rejected because of inaccuracy, repetition, or irrelevance to this study. A total of 243 questions were prompted by the diary item with a response rate of 37%. There was no recorded use of the drag-and-drop mechanism (see discussion section). Chat instances were the most pr ominent actions during the four weeks with a peak in week 2, seconded by alerts, which were used mostly as initiations. The one-click mechanism registered a total of 27 instances. The maximum number of online participants per week varied between ten to tw elve participants. In average, four participants were actively interacting every day with the community. A total of 52 coordination units were counted, 25 during the control weeks, and 27 during the intervention weeks. Leaving out the initiations without reactions ( 11) 41 units were analyzed, 21 in the control weeks and 20 in the grounding weeks. Table 1 shows the distribution of the analyzed coordination units during control and grounding weeks. It also shows the frequency of the total number of first-reaction and join -conversation occurrences during both periods. For the analysis we classified the coordination units in open and closed initiations to distinguish between initiations that are addressed to anyone (e.g.  X  X unch? X ) and initiations that are targeted to one or more persons in particular (e.g.,  X  X nna are you coming? X ). For open initiations we considered first-reactions as the first reaction used by the participan ts who responded to an initiation (therefore one initiation could have as many first-reactions as people involved in such coordination unit). In the case of one-click first-reactions we only counted the instances where one-click was used instead of text as a first-reaction. Alternatively, for the closed initiations we consid ered join-conversations as the reactions of participants that were not addressed in the initiation but contributed anyway to the conversation. 
Table 1. Number of analyzed c oordination units (initiations) and the reaction patterns observed during the control weeks Coordination units 11 16 4 10 Analyzing the use of the one-click mechanism the following results were observed: 10 coordina tion units presented the use of the one-click mechanism with a tota l of 27 instances recorded; in 4 units the one-click mechanism was used as a first-reaction, twice with delay (longer than 10 minutes). Out of the remaining 23 instances, 8 corresponded to jo in-conversation (3 of them delays), and the remaining 15 co rresponded to other-reactions (11 of them delays). The other-reactions instances were of less interest as they represented one-click reactions accompanied by other text-based occurrences. Therefore in this analysis we focused on first-reactions and join-conversations. Table 2 shows the total distribu tion of one-click reactions during week 2 and week 3 (the grounding weeks) and the frequency regarding both first-reaction and join-conversation patterns, and everything else (other-reactions). Table 2. Frequency of total one-click reactions and its relevant One-click total reactions -16 11 -One-click first-reactions -3 1 -One-click join-conversation -5 3 -One-click other-reactions -8 7 -Regarding first-reactions , Figure 7 describes the use of one-click mechanisms as the first and only reactions to an open initiation. The figure shows two consecutive initiating messages sent by Participant 7 (lines 1 and 2) that only have reactions consisting of one-clicks by other participants . Lines 3 and 4 show one-click reactions by Participants 10 and Participant 6 of the message in line 1 (within five minutes afte r it was sent). Line 5 shows Participant 12 X  X  one-click reaction to the same message but about two hours later; and in line 6, same participant one-clicked the message in line 2, about seve n hours after it was sent. Regarding join-conversations , most instances observed in the grounding weeks were supported by the one-click mechanism (8 out of 10). Figure 8 shows an example where P3 used one-click to be part of an existing convers ation. The figure describes a sequence of closed initiating messages sent by P12 to P1 (lines 1, 2, and 3) to which Participant 1 reacted within five minutes (line 4); later on some of the initiati ng messages were one-clicked by Participant 3 as his only reaction to this initiation sequence (line 5, 6). In line 7, we can see one example of a one-click other-reaction, as P12 used it to acknow ledge the text reaction of P1. Regarding delays, two of the delays of the one-click first-reactions were surprisingly long (i n the order of 50 minutes). As it turned out, the one-click mechanism was used as a sufficient signal (no similar signals presen ted) to ground very long delays. Similarly all delays of one-clic k join-conversation represented unexpectedly prolonged delays (in the order of 100 minutes) compared to the control weeks. It seems that participants used the one-click mechanism to signal a nd ground a  X  X assive X  or delayed engagement in conversations, which was not possible before. A similar phenomenon was also observed when looking at the slight increase of the average number of participants reacting to a coordination unit in the grounding weeks. In the control weeks there were only two cases in which a maximum of four participants reacted to the same coordination unit. In the grounding weeks, five coordination units recorded a maximum of four participants, with at leas t two participants grounding their passive participation using th e one-click mechanism in the discussion. As it was expected the one-click mechanism did encourage collaborative practices by offeri ng lightweight mechanisms to make the existing messages common ground representations. The use of the one-click mechanism as a replacement of text-based signalling and grounding practices represented 52% of the total one-click instances analyzed. The remaining instances, which were followed by text-based signal by the same participant, were not considered as disconfirming evidence, since such text messages represented actual exch ange of content information (track-I signals). In all cases, the one-click mechanism was used for grounding privacy borders regarding different levels of participation. From the gathered evidence, an interesting behaviour was observed that exemplified the us e of the one-click mechanism to support lightweight coordination of participation. The one-click mechanism provided the possibility for participants to ground their passive involvement in an existing conversation. When analyzing the activity of participants using the one-click mechanism to ground existing messages, it was observed that about half of the cases were ma de by members that were not actively involved in the conversa tion. They used the mechanism to join an existing conversa tion through establishing a limited participation. Grounding existi ng messages using the one-click mechanism as the only reaction, provided participants with the opportunity to acknowledge passive participation in situations where a  X  X eavier X  contribution (writing a message) was not worthwhile. This supports the ra tionale behind the design of the grounding mechanisms: signalling and grounding should provide a link between existing representati ons and privacy intentions to develop coordination mechanis ms (Figure 2). The one-click supported the development of common ground by linking existing representations to indicate intentions to interact. Another implication of the use of the one-click as a grounding mechanism was the support of autonomy (e.g., desired level of ambiguity). The evidence that individuals could ground participation without having to commit themselves to an undesired level of interaction suggested that the one-click mechanism can support effective signalling and grounding practices without compromising ambiguity . Participants could collaborate in representing their pr ivacy intentions by keeping a passive interaction without having to explicitly explain it. As a result, the number of participants engaging in a conversation was higher in the grounding weeks as passive participants found a way to express their level of involve ment in a conversation, without having to explicitly explain their lack of willingness to actively participate. In hindsight it seems obvious that the gain in efficiency provided by one-click versus typing a text message, is only relevant under high pressure and where the  X  X ocial costs X  of unresponsive interaction are high. As this group used CB only for informal social communication, the efficiency of the one-click mechanism lowered the threshold to participat e in discussions and resulted in a higher participation by the group. While the design solutions were implemented in the context of Community Bar, the need for grounding and the applicability of such mechanisms is much broader. For example, email messages need much more lightweight signals for grounding privacy: issuing an acknowledgement request could be an option offered directly on every email message as a button (e.g. check box) instead of a dialogue box issued on request by a sender. A contact list on a mobile phone decorated with availability information of one X  X  contacts could be made in teractive allowing one to notify (and correspondingly acknowledge such notifications) their wishes to communicate directly rather than by leaving messages on voice mails or sending a text message. These examples are just indicative; illustrating that the need is quite generic for shared representations where signalling and grounding intentions can be coordinated. Considering the different uses of the one-click mechanism and the non use of the drag-and-drop mechanism, we discuss the influence that the community X  X  interaction needs had upon their coordination behaviours. The co mmunity under study reflected little need for interaction, which was also confirmed by their appreciation of Community Bar as a social awareness rather than as a channel for direct communication. In the interview most participants confirmed the benefits of video as probably the only functionality of the CB they were interested to keep using:  X  X  think that CB gives me a nice feeling of who is around even if we don X  X  communicate. Seeing on the camera that other colleagues are on their places make me feel more part of the group X  . This explains their preference to use the one-click mechanism as grounding for passive participation rather than for quick reactions. The use of the one-click mechanism to ground passive participation showed that partic ipants had the need for track-II signals to ground interaction  X  X he n appropriate for them X . This again reflected the community needs for low interaction and how the one-click mechanism responded to such needs. The non-use of the drag-and-drop mechanism could be explained by the low need of participants to justify unresponsiveness, as interaction in CB was not used for their primary activities or for urgent tasks so explanati ons of unresponsiveness was unnecessary. Participants mentioned that the effort to choose a sentence from the grounding palette together with the consequence of explicitly grounding intentions seemed too demanding for their needs. Some speculated the benefits of both mechanisms in other settings where a clear need to communicate remotely was presented:  X  X  believe it [one-click and drag-and-drop] was a great idea .To report that you have read someone else X  X  message with a one click could be very useful in a community with more needs for mediated interaction X  . Clearly, a strong relation exists between community interaction needs and the explicitness that communicators wish to achieve by signalling and grounding privacy intentions. The option of track-II signals to ground existing re presentations encourages communicators to contribute to the understanding of their interaction needs, even when their interaction needs are low. Track-II signals guarantee minimal collaborative effort and ambiguity of signalling and grounding, which are crucial requirements in the coordination of interaction. It is likely that a different pattern of communication will emerge in contexts where privacy breakdowns carry more social and affective costs for individuals. Beyond showing that privacy border coordination is facilita ted, future studies should demonstrate that interpersona l privacy breakdowns will be reduced. As in the case of the presented study, actual privacy regulation practices supported by grounding m echanisms are expected to transcend the interactions and purposes of a specific communication application (e.g. CB). It is therefore advantageous to tie such grounding mechanisms to a larger set of communication applications including face to face, especially the ones already used by the groups or individual participating in the study. Our current and future work explore a variety of interactive mechanisms (e.g. tangible, mob ile controls) to explore the concept of grounding privacy in a wider set of applications that support mediated communication. We plan follow up evaluations for longer periods as well as cons idering other social contexts. Interpersonal privacy was discussed as a collaborative process where communicating individuals construct a shared understanding regarding their privacy borders. Applying Clark X  X  theory of Common Ground we have developed the Privacy Grounding Model (PGM) to describe the mechanisms by which this shared understanding of privacy borders is achieved. Whereas earlier works have alluded to the use of such mechanisms by individuals, they have not descri bed their nature or considered how they can inform the desi gn of related applications. The main implication of this m odel for the design of networked applications is that we need to equip users with signalling and grounding mechanisms in communi cation channels that can enable privacy border regulation to unfold interactive track-II signals. Privacy coordination signals need to stay in the background, be more brief, dis tinctive and simultaneous than primary (track-I) communication. Two design instantiations of PGM were studied in the context of a groupware application called Community Bar (CB). Lightweight interactive grounding mechanisms we re designed as alternatives to typing text in CB: the one-click and the drag-and-drop as interfaces for grounding interpersonal privacy in chat messages. While our expectations from the field test regarding drag-and-drop were not confirmed, the results of the one-click were promising. The study provided evidence of how lightweight interactivity can support collaborative privacy coordination through the development of common ground. The effectiveness of grounding was explored by using distinctive visualizations that represented th e intentionality of existing chat representations. The distinctiveness of such visualizations guarantees a clear link to ground existing representations with representations and sufficiently distinctive to communicate intentions. Ambiguity was preser ved in these mechanisms by supporting little or imprecise information (e.g., just an acknowledgement). The contribution of PGM is that is has provided a generic description of interactive mechanisms that can be used to coordinate interpersonal privacy in any application supporting mediated communication. The main implication of the model, and one that is currently not explicitly designed into existing communication applications, is th e need for providing users with lightweight mechanisms for gr ounding privacy representations interactively. Interactivity is of paramount importance in the context of mediated communicati on, as it allows users to add intentionality to system representations regarding availability, delay or explanations. The work presented here has been supported by the European Commission through the FP6 FET ASTRA STREP (IST-2004-29266). [1] Altman, I. (1975). The Environment and Social Behaviour -[2] Aoki, P. M. and Woodruff, A. (2005). Making space for [3] Bellotti, V. and Sellen, A. (1993). Design for privacy in [4] Boyle, M., and Greenberg, S. (2005). The Language of [5] Clark, H. (1996). Using language . New York, Cambridge [6] Markopoulos, P., Romero, N., van Baren, J., IJsselsteijn, W., [7] McEwan, G. and Greenberg, S. (2005). Supporting social [8] Nardi, B., Whittaker, S., and Bradner, E. (2000). Interaction [9] Neustaedter, C., Greenberg, S., and Boyle, M. (2006). Blur [10] Palen, L., and Dourish, P. (2003). Unpacking  X  X rivacy X  for a [11] Petronio, S. (2002). Boundaries of privacy: dialectics of [12] Reichenbach, M., Damker, H., Federrath, H., and [13] Romero, N. (2008). Coordination of Interpersonal Privacy in [14] Romero, N., Markopoulos, P. (2005). Common ground to [15] Romero, N., Markopoulos, P. (2009). Grounding Privacy [16] Romero, N., Matysiak, A., Kaptein, M., and Markopoulos, P. [17] Romero, N. McEwan, G., and Greenberg, S. (2007). A field [18] Roussopoulos, M., Maniatis, P., Swierk, E., Lai, K., [19] Woodruff, A. and Aoki, P. M. (2003). How push-to-talk [20] Wu, M. (2007). Adaptive privacy management for 
