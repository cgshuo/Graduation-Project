 Digital storage of personal music collections and cloud-based music services (e.g. Pandora, Spotify) have fundamentally changed how music is consumed. In particular, automati-cally generated playlists have become an important mode of accessing large music collections. The key goal of automated playlist generation is to provide the user with a coherent lis-tening experience. In this paper, we present Latent Markov Embedding (LME), a machine learning algorithm for gen-erating such playlists. In analogy to matrix factorization methods for collaborative filtering, the algorithm does not require songs to be described by features a priori, but it learns a representation from example playlists. We formu-late this problem as a regularized maximum-likelihood em-bedding of Markov chains in Euclidian space, and show how the resulting optimization problem can be solved efficiently. An empirical evaluation shows that the LME is substantially more accurate than adaptations of smoothed n-gram models commonly used in natural language processing.
 I.2.6 [ Artificial Intelligence ]: Learning; I.5.1 [ Pattern Recognition ]: Models Algorithms, Experimentation, Human Factors Music Playlists, Recommendation, User Modeling, Sequences
A music consumer can store thousands of songs on his or her computer, portable music player, or smart phone. In addition, when using a cloud-based service like Rhapsody or Spotify, the consumer has instant on-demand access to millions of songs. This has created substantial interest in automatic playlist algorithms that can help consumers ex-plore large collections of music. Companies like Apple and Pandora have developed successful commercial playlist algo-rithms, but relatively little is known about how these algo-rithms work and how well they perform in rigorous evalua-tions.

Despite the large commercial demand, comparably little scholarly work has been done on automated methods for playlist generation (e.g., [13, 4, 9, 11]), and the results to date indicate that it is far from trivial to operationally de-fine what makes a playlist coherent. The most comprehen-sive study was done by [11]. Working under a model where a coherent playlist is defined by a Markov chain with transi-tion probabilities reflecting similarity of songs, they find that neither audio-signal similarity nor social-tag-based similar-ity naturally reflect manually constructed playlists.
In this paper, we therefore take an approach to playlist prediction that does not rely on content-based features, and that is analogous to matrix decomposition methods in col-laborative filtering [7]. Playlists are treated as Markov chains in some latent space, and our algorithm  X  called Logistic Markov Embedding (LME)  X  learns to represent each song as one (or multiple) points in this space. Training data for the algorithm consists of existing playlists, which are widely available on the web. Unlike other collaborative filtering ap-proaches to music recommendation like [13, 4, 19], ours is among the first (also see [1]) to directly model the sequential and directed nature of playlists, and that includes the ability to sample playlists in a well-founded and efficient way.
In empirical evaluations, the LME algorithm substantially outperforms traditional n-gram sequence modeling methods from natural language processing. Unlike such methods, the LME algorithm does not treat sequence elements as atomic units without metric properties, but instead provides a gen-eralizing representation of songs in Euclidean space. Techni-cally, it can be viewed as a multi-dimensional scaling prob-lem [3], where the algorithm infers the metric from a stochas-tic sequence model. While we focus exclusively on playlist prediction in this paper, the LME algorithm also provides interesting opportunities for other sequence prediction prob-lems (e.g. language modeling).
Personalized Internet radio has become a popular way of listening to music. A user seeds a new stream of music by specifying a favorite artist, a specific song, or a semantic tag (e.g., genre, emotion, instrument.) A backend playlist algorithm then generates a sequence of songs that is related to the seed concept. While the exact implementation details of various commercial systems are trade secrets, different companies use different forms of music metadata to identify relevant songs. For example, Pandora relies on the content-based music analysis by human experts [17] while Apple iTunes Genius relies on preference ratings and collaborative filtering [2]. What is not known is the mechanism by which the playlist algorithms are used to order the set of relevant songs, nor is it known how well these playlist algorithms perform in rigorous evaluations.

In the scholarly literature, two recent papers address the topic of playlist prediction. First, Maillet et al. [9] formu-late the playlist ordering problem as a supervised binary classification problem that is trained discriminatively. Posi-tive examples are pairs of songs that appeared in this order in the training playlists, and negative examples are pairs of songs selected at random which do not appear together in order in historical data. Second, McFee and Lanckriet [11] take a generative approach by modeling historical playlists as a Markov chain. That is, the probability of the next song in a playlist is determined only by acoustic and/or social-tag similarly to the current song. We take a similar Markov chain approach, but do not require any acoustic or semantic information about the songs.

While relatively little work has been done on explicitly modeling playlists, considerably more research has focused on embedding songs (or artists) into a similarity-based music space (e.g., [8, 13, 4, 19].) Our work is most closely related to research that involves automatically learning the music embedding. For example, Platt et al. use semantic tags to learn a Gaussian process kernel function between pairs of songs [13]. More recently, Weston et al. learn an embed-ding over a joint semantic space of audio features, tags and artists by optimizing an evaluation metric (Precision at k ) for various music retrieval tasks [19]. Our approach, how-ever, is substantially different from these existing methods, since it explicitly models the sequential nature of playlists.
Modeling playlists as a Markov chain connects to a large body of work on sequence modeling in natural language processing and speech recognition. In those applications, a language model of the target language is used to disam-biguate uncertainty in the acoustic signal or the translation model. Smoothed n-gram models (see e.g. [6]) are the most commonly used method in language modeling, and we will compare against such models in our experiments. However, in natural language processing and speech recognition n-grams are typically used as part of a Hidden Markov Model (HMM)[14], not in a plain Markov Model as in our paper. In the HMM model, each observation in sequence is gov-erned by an hidden state that evolves in Markovian fashion. The goal for learning to estimate the transition probability between hidden states as well as the probability of the ob-servations conditioned on the hidden states. Using singular value decomposition, recent works on embedding the HMM distribution into a reproducing kernel Hilbert space [16, 5] circumvent the inference of the hidden states and make the model usable as long as kernel can be defined on the domain of observation. While both this work and our work make use of embeddings in the context of Markov chains, the two approaches solve very different problems.

Sequenced prediction also has important applications and related work in other domains. For example, Rendle et al. [15] consider the problem of predicting what a customer would have in his next basket of online purchasing. They model the transition probabilities between items in two con-secutive baskets, and the tensor decomposition technique they use can be viewed as embedding in a way. While both are sequence prediction problems, the precise modeling problems are different.

Independent of and concurrent with our work, Aizenberg et al. [1] developed a model related to ours. The major dif-ference lies in two aspects. First, they focus less on the se-quential aspect of playlists, but more on using radio playlists as proxies for user preference data. Second, their model is based on inner products, while we embed using Euclidean distance. Euclidian distance seems a more natural choice for rendering an easy-to-understand visualization from the embeddings. Related is also work by Zheleva et al. [21]. Their model, however, is different from ours. They use a Latent Dirichlet Allocation-like graphical model to capture the hidden taste and mood of songs, which is different from our focus.
Our goal is to estimate a generative model of coher-ent playlists which will enable us to efficiently sample new playlists. More formally, given a collection S = { s 1 ,...,s of songs s i , we would like to estimate the distribution Pr( p ) of coherent playlists p = ( p [1] ,...,p [ k p ] ). Each element p a playlist refers to one song from S .

A natural approach is to model playlists as a Markov chain, where the probability of a playlist p = ( p [1] ,...,p is decomposed into the product of transition probabilities For ease of notation, we assume that p [0] is a dedicated start symbol. Such bigram (or n-gram models more gener-ally) have been widely used in language modeling for speech recognition and machine translation with great success [6]. In these applications, the O ( |S| n ) transition probabilities Pr( p [ i ] | p [ i  X  1] ) are estimated from a large corpus of text us-ing sophisticated smoothing methods.

While such n-gram approaches can be applied to playlist prediction in principle, there are fundamental difference be-tween playlists and language. First, playlists are less con-strained than language, so that transition probabilities be-tween songs are closer to uniform. This means that we need a substantially larger training corpus to observe all of the (relatively) high-probability transitions even once. Second, and in contrast to this, we have orders of magnitude less playlist data to train from than we have written text.
To overcome these problems, we propose a Markov-chain sequence model that produces a generalizing representation of songs and song sequences. Unlike n-gram models that treat words as atomic units without metric relationships between each other, our approach seeks to model coherent Figure 1: Illustration of the Single-Point Model. The probability of some other song following s de-pends on its Euclidean distance to s . playlists as paths through a latent space. In particular, songs are embedded as points (or multiple points) in this space so that Euclidean distance between songs reflects the transi-tion probabilities. The key learning problem is to determine the location of each song using existing playlists as training data. Once each song is embedded, our model can assign meaningful transition probabilities even to those transitions that were not seen in the training data.

Note that our approach does not rely on explicit features describing songs. However, explicit song features can easily be added to our transition model as outlined below. We will now introduce two approaches to modeling Pr( p ) that both create an embedding of playlists in Euclidean space.
In the simplest model as illustrated in Figure 1, we rep-resent each song s as a single vector X ( s ) in d -dimensional Euclidean space M . The key assumption of our model is that the transition probabilities Pr( p [ i ] | p [ i  X  1] the Euclidean distance || X ( p [ i ] )  X  X ( p [ i  X  1] ) || and p [ i ] in M through the following logistic model: We will typically abbreviate the partition function in the denominator as Z ( p [ i  X  1] ) and the distance || X ( s )  X  X ( s as  X ( s,s 0 ) for brevity. Using a Markov model with this transition distribution, we can now define the probability the of an entire playlist of a given length k p as Our method seeks to discover an embedding of the songs into this latent space which causes  X  X ood X  playlists to have high probability of being generated by this process. This is inspired by collaborative filtering methods such as [7, 18], which similarly embed users and items into a latent space to predict users X  ratings of items. However, our approach differs from these methods in that we wish to predict paths through the space, as opposed to independent item ratings. In order to learn the embedding of songs, we use a sample D = ( p 1 ,...,p n ) of existing playlists as training data and take a maximum likelihood approach. Denoting with X the matrix of feature vectors describing all songs in the collection Figure 2: Illustration of the Dual-Point Model. The probability of some other song following s depends on the Euclidean distance from the exit vector V ( s ) of s to the target song X  X  entry vector U (  X  ) .
 S , this leads to the following training problem: Equivalently, we can maximize the log-likelihood
L ( D | X ) = X In Section 5, we describe how to solve this optimization problem efficiently, and we explore various methods for avoid-ing overfitting through regularization in Section 3.3. First, however, we extend the basic single-point model to a model that represents each song through a pair of points.
Representing each song using a single point X ( s ) as in the previous section has at least two limitations. First, the Euclidean metric || X ( s )  X  X ( s 0 ) || 2 that determines the tran-sition distribution is symmetric, even though the end of a song may be drastically different from its beginning. In this case, the beginning of song s may be incompatible with song s altogether, and a transition in the opposite direction  X  from s 0 to s  X  should be avoided. Second, some songs may be good transitions between genres, taking a playlist on a trajectory away from the current location in latent space.
To address these limitations, we now propose to model each song s using a pair ( U ( s ) ,V ( s )) of points. We call U ( s ) the  X  X ntry vector X  of song s , and V ( s ) the  X  X xit vector X . An illustration of this model is shown in Figure 2. Each song s is depicted as an arrow connecting U ( s ) to V ( s ). The  X  X ntry vector X  U ( s ) models the interface to the previous song in the playlist, while the  X  X xit vector X  V ( s ) models the interface to the next song. The transition from song s to s is then described by a logistic model relating the exit vector V ( s ) of song s to the entry vector U ( s 0 ) of song s Adapting our notation for this setting by representing the asymmetric song divergence || V ( s )  X  U ( s 0 ) || 2 as  X  the corresponding dual-point partition function as Z 2 ( s ), we obtain the following probabilistic model of a playlist. Similar to Eq. (4), computing the embedding vectors ( U ( s ) , V ( s )) for each song can be phrased as a maximum-likelihood problem for a given training sample of playlists D = ( p 1 where V and U are the matrices containing the respective entry and exit vectors for all songs. As in the single-point case, it is again equivalent to maximize the log-likelihood: L ( D | V,U ) = X While the choice of dimensionality d of the latent space M provides some control of overfitting, it is desirable to have more fine-grained control. We therefore introduce the following norm-based regularizers that get added to the log-likelihood objective.

The first regularizer penalizes the Frobenius norm of the matrix of feature vectors, leading to for the single point model, and ( V,U ) = argmax for the dual point model.  X  is the regularization parameter which we will set by cross-validation. For increasing values of  X  , this regularizer encourages vectors to stay closer to the origin. This leads to transition distributions Pr( p [ i ] that are closer to uniform.

For the dual-point model, it also makes sense to regularize by the distance between the entry and exit vector of each song. For most songs, these two vectors should be close. This leads to the following formulation, ( V,U ) = argmax where  X  is a second regularization parameter.
The basic LME model can be extended in a variety of ways. We have already seen how the dual-point model can account for the directionality of playlists. To further demon-strate its modeling flexibility, consider the following exten-sions to the single-point model. These extension can also be added to the dual-point model in a straightforward way.
Popularity. The basic LME models have only limited means of expressing the popularity of a song. By adding a separate  X  X opularity boost X  b i to each song s i , the resulting transition model can separate the effect of a song X  X  popularity from the effect of its similarity in content to other songs. This can normal-ize the resulting embedding space with respect to popularity, and it is easy to see that training the popularity scores b part of Eq. (12) does not substantially change the optimiza-tion problem.

User Model. The popularity score is a simple version of a preference model. In the same way, more complex models of song quality and user preference can be included as well. For example, one can add a matrix factorization model to explain user preferences independent of the sequence con-text, leading to the following transition model.
 Analogous to models like in [7], A ( s ) is a vector describing song s and B ( u ) is a vector describing the preferences of user u .

Semantic Tags. Many songs have semantic tags that describe genre and other qualitative attributes of the music. However, not all songs are tagged, and tags do not follow a standardized vocabulary. It would therefore be desirable to embed semantic tags in the same Euclidean space as the songs, enabling the computation of (semantic) distances be-tween tags, as well as between tags and (untagged) songs. This can be achieved by modeling the prior distribution of the location of song s based on its tags T ( s ) in the following way.
 Note that this definition of Pr( X ( s ) | T ( s )) nicely generalizes the regularizer in (4), which corresponds to an  X  X ninformed X  Normal prior Pr( X ( s )) = N (0 , 1 2  X  I d ) centered at the origin of the embedding space. Again, simultaneously optimizing song embeddings X ( s ) and tag embeddings M ( t ) does not substantially change the optimization problem during train-ing. This extended embedding model for songs and tags is described in more detail in [12].

Observable Features. Some features may be univer-sally available for all songs, in particular features derived from the audio signal via automated classification. Denote these observable features of song s as O ( s ). We can then learn a positive-semidefinite matrix W similar to [10], lead-ing to the following transition model.

Long-Range Dependencies. A more fundamental prob-lem is the modeling of long-range dependencies in playlists. While it is straightforward to add extensions for modeling closeness to some seed song  X  either during training, or at the time of playlist generation as discussed in Section 4  X  modeling dependencies beyond n-th order Markov models is an open question. However, submodular diversification models from information retrieval (e.g. [20]) may provide interesting starting points.
From a computational perspective, generating new playlists is very straightforward. Given a seed location in the embedding space, a playlist is generated through repeated sampling from the transition distribution. From a usability perspective, however, there are two problems.
First, how can the user determine a seed location for a playlist? Fortunately, the metric nature of our models gives many opportunities for letting the user specify the seed lo-cation. It can be either a single song, the centroid of a set of songs (e.g. by a single artist), or a user may graphically select a location through a map similar to the one in Fig-ure 3. Furthermore, we have shown in other work [12] how songs and social tags can be jointly embedded in the metric space, making it possible to specify seed locations through keyword queries for semantic tags.

Second, the playlist model that is learned represents an average model of what constitutes a good playlists. Each particular user, however, may have preferences that are dif-ferent from this average model at any particular point in time. It is therefore important to give the user some control over the playlist generation process. Fortunately, our model allows a straightforward parameterization of the transition distribution. For example, through the parameters  X  ,  X  and  X  in the following transition distribution the user can influence meaningful and identifiable properties of the playlists that get generated. For example, by setting  X  to a value that is less than 1, the model will take larger steps. By increasing  X  to be greater than 1, the model will focus on popular songs. And by setting  X  to a positive value, the playlists will tend to stay close to the seed location. It is easy to imagine other terms and parameters in the transition distribution as well.

To give an impression of the generated playlists and the effects of the parameters, we provide an online demo at http://lme.joachims.org .
In the previous section, the training problems were for-mulated as the optimization problems in Eq. (5) and (8). While both have a non-convex objective, we find that the stochastic gradient algorithm described in the following ro-bustly finds a good solution. Furthermore, we propose a heuristic for accelerating gradient computations that sub-stantially improves runtime.
We propose to solve optimization problems (5) and (8) using the following stochastic gradient method. We only describe the algorithm for the dual-point model, since the algorithm for the single-point model is easily derived from it.

We start with random initializations for U and V . We also calculate a matrix T whose elements T ab are the number of transitions from the s a to s b in the training set. Note that this matrix is sparse and always requires less storage than the original playlists. Recall that we have defined  X  2 ( s as the song divergence || U ( s a )  X  V ( s b ) || 2 and Z equivalently write the objective in Eq. (8) as where  X ( V,U ) is the regularizer and l ( s a ,s b ) is the  X  X ocal X  log-likelihood term that is concerned with the transition from s a to s b . Denoting with 1 [ x = y ] the indicator function that returns 1 if the equality is true and 0 otherwise, we can write the deriva-tives of the local log-likelihood terms and the regularizer as  X  X  ( s a ,s b )  X  X  ( s p )  X  X  ( s a ,s b )  X  X  ( s q )  X   X ( V,U )  X  X  ( s p )  X   X ( V,U )  X  X  ( s p ) where we used
We can now describe the actual stochastic gradient algo-rithm. The algorithm iterates through all songs s p in turn and updates the exit vectors for each s p by U ( s p )  X  U ( s p ) +  X  For each s p , it also updates the entry vector for each possible transition ( s p ,s q ) via V ( s q )  X  V ( s q ) +  X   X  is a predefined learning rate and N is the number of tran-sitions in training set. Note that grouping the stochastic gradient updates by exit songs s p as implemented above is advantageous, since we can save computation by reusing the partition function in the denominator of the local gradients of both U ( s p ) and V ( s q ). More generally, by storing in-termediate results of the gradient computation, a complete iteration of the stochastic gradient algorithm through the full training set can be done in time O ( |S| 2 ). We typically run the algorithm for T = 100 or 200 iterations, which we find is sufficient for convergence.
The O ( |S| 2 ) runtime of the algorithm makes it too slow for practical applications when the size of S is sufficiently large. The root of the problem lies in the gradient compu-tation, since for every local gradient one needs to consider the transition from the exit song to all the songs in S . This leads to O ( |S| ) complexity for each update steps. However, considering all songs is not really necessary, since most songs are not likely targets for a transition anyway. These songs contribute very little mass to the partition function and ex-cluding them will only marginally change the training ob-jective.

We therefore formulate the following modified training problem, where we only consider a subset C i as possible successors for s i .
 This reduces the complexity of a gradient step to O ( | C The key problem lies in identifying a suitable candidate set C i for each s i . Clearly, each C i should include at least most of the likely successors of s i , which lead us to the following landmark heuristic.

We randomly pick a certain number (typically 50) of songs and call them landmarks, and assign each song to the near-est landmark. We also need to specify a threshold r  X  [0 , 1]. Then for each s i , its direct successors observed in the train-ing set are first added to the subset C r i , because these songs are always needed to compute the local log-likelihood. We keep adding songs from nearby landmarks to the subset, un-til ratio r of the total songs has been included. This defines the final subset C r i . By adopting this heuristic, the gradients of the local log-likelihood become  X  X  ( s a ,s b )  X  X  ( s p )  X  X  ( s a ,s b )  X  X  ( s q ) where Z r ( s a ) is the partition function restricted to C P every 10 iterations 1 , and fix them after 100 iterations to ensure convergence.
We implemented our methods in C. The code is available online at http://lme.joachims.org .
In the following experiments we will analyze the LME in comparison to n-gram baselines, explore the effect of the popularity term and regularization, and assess the compu-tational efficiency of the method.

To collect a dataset of playlists for our empirical eval-uation, we crawled Yes.com during the period from Dec. 2010 to May 2011. Yes.com is a website that provides radio playlists of hundreds of stations in the United States. By using the web based API 2 , one can retrieve the playlists of the last 7 days for any station specified by its genre. With-out taking any preference, we collect as much data as we can by specifying all the possible genres. We then generated two datasets, which we refer to as yes small and yes big . In the small dataset, we removed the songs with less than 20, in the large dataset we only removed songs with less than 5 appear-ances. The smaller one is composed of 3 , 168 unique songs. It is then divided into into a training set with 134 , 431 tran-sitions and a test set with 1 , 191 , 279 transitions. The larger one contains 9 , 775 songs, a training set with 172 , 510 transi-tions and a test set with 1 , 602 , 079 transitions. The datasets are available for download at http://lme.joachims.org .
Unless noted otherwise, experiments use the following setup. Any model (either the LME or the baseline model) is first trained on the training set and then tested on the test set. We evaluate test performance using the average log-likelihood as our metric. It is defined as log(Pr( D test )) /N test , where N test is the number of transi-tions in test set. One should note that the division of train-
A iteration means a full pass on the training dataset. http://api.yes.com Figure 3: Visual representation of an embedding in two dimensions with songs from selected artists highlighted ing and test set is done so that each song appears at least once in the training set. This was done to exclude the case of encountering a new song when doing testing, which any method would need to treat as a special case and impute some probability estimate.
We start with giving a qualitative impression of the em-beddings that our method produces. Figure 3 shows the two-dimensional single-point embedding of the yes small dataset. Songs from a few well-known artists are highlighted to pro-vide reference points in the embedding space.

First, it is interesting to note that songs by the same artist cluster tightly, even though our model has no direct knowl-edge of which artist performed a song. Second, logical con-nections among different genres are well-represented in the space. For example, consider the positions of songs from Michael Jackson, T.I., and Lady Gaga. Pop songs from Michael Jackson could easily transition to the more elec-tronic and dance pop style of Lady Gaga. Lady Gaga X  X  songs, in turn, could make good transitions to some of the more dance-oriented songs (mainly collaborations with other artists) of the rap artist T.I., which could easily form a gate-way to other hip hop artists.

While the visualization provides interesting qualitative in-sights, we now provide a quantitative evaluation of model quality based on predictive power.
We first compare our models against baseline methods from Natural Language Processing. We consider the follow-ing models.

Uniform Model. The choices of any song are equally likely, with the same probability of 1 / |S| . Figure 4: Single/Dual-point LME against baseline on yes small (left) and yes big (right). d is the di-mensionality of the embedded space.

Unigram Model. Each song s i is sampled with proba-bility p ( s i ) = n i P of s i in the training set. p ( s i ) can be considered as the pop-ularity of s i . Since each song appears at least once in the training set, we do not need to worry about the possibility of p ( s i ) being zero in the testing phase.

Bigram Model. Similar to our models, the bigram model is also a first-order Markov model. However, transition of songs. Note that not every transition from s i the test set also appears in the training set, and the corre-sponding p ( s i | s j ) will just give us minus infinity log likeli-hood contribution when testing. We adopt the Witten-Bell smoothing [6] technique to solve this problem. The main idea is to use the transition we have seen in the training set to estimate the counts of the transitions we have not seen, and then assign them nonzero probabilities.

We train our LME models without heuristic on both yes small and yes big . The resulting log-likelihood on the test set is reported in Figure 4, where d is the dimensionality of the embedding space. Over the full range of d the single-point LME outperforms the baselines by at least one order of magnitude in terms of likelihood. While the likelihoods on the big dataset are lower as expected (i.e. there are more songs to choose from), the relative gain of the single-point LME over the baselines is even larger for yes big .
The dual-point model performs equally well for models with low dimension, but shows signs of overfitting for higher dimensionality. We will see in Section 6.4 that regularization can mitigate this problem.

Among the conventional sequence models, the bigram model performs best on yes small . However, it fails to beat the unigram model on yes big (which contains roughly 3 times the number of songs), since it cannot reliably estimate the huge number of parameters it entails. Note that the number of parameters in the bigram model scales quadrati-cally with the number of songs, while it scales only linearly in the LME models. The following section analyzes in more detail where the conventional bigram model fails, while the single-point LME shows no signs of overfitting.
We now explore in more detail why the LME model out-Figure 5: Log likelihood on testing transitions with respect to their frequencies in the training set on yes small performs the conventional bigram model. In particular, we explore the extent to which the generalization performance of the methods depends on whether (and how often) a test transition was observed in the training set. The ability to produce reasonable probability estimates even for transi-tions that were never observed is important, since about 64 percent of the test transitions were not at all observed in our training set.

For both the single-point LME and the bigram model on the small dataset, Figure 5 shows the log-likelihood of the test transitions conditioned on how often that transition was observed in the training set. The bar graph illustrates what percentage of test transitions had that given number of oc-currences in the training set (i.e. 64% for zero). It can be seen that the LME performs comparably to the bigram model for transitions that were seen in the training set at least once, but it performs substantially better on previously unseen transitions. This is a key advantage of the general-izing representation that the LME provides.
We now explore whether additional regularization as pro-posed in Section 3.3 can further improve performance.
For the single-point model on yes small , Figure 6 shows a comparison between the norm-based regularizer (R1) and the unregularized models across dimensions 2, 5, 10, 25, 50 and 100. For each dimension, the optimal value of  X  was 50, 100, 500, 1000 } . It can be seen that the regularized models offer no substantial benefit over the unregularized model. We conjecture that the amount of training data is already sufficient to estimate the (relatively small) number of parameters of the single-point model.

Figure 7 shows the results for dual-point models using three modes of regularization. R1 denotes models with  X  = 0, R2 denotes models with  X  = 0, and R3 denotes models trained with  X  =  X  . Here, the regularized models consis-tently outperform the unregularized ones. Starting from di-mensionality 25, the improvement of adding regularization is drastic, which saves the dual-point model from being un-usable for high dimensionality. It is interesting to note the effect of R2, which constrains the exit and entry points for each song to be near each other. Effectively, this squeezes Figure 6: Effect of regularization for single-point model on yes small Figure 7: Effect of regularization for dual-point model on yes small the distance between the two points, bringing the dual-point model closer to the single-point model.
Since the single-point model appears to perform better than the dual-point model, it raises the question of how im-portant directionality is in playlists. We therefore conducted the following experiment. We train the dual-point model as usual for d = 5 on yes small , but then reverse all test tran-sitions. The average log-likelihood (over 10 training runs) on the reversed test transition is  X  5 . 960  X  0 . 003, while the log-likelihood of the test transitions in the normal order is  X  5 . 921  X  0 . 003. While this difference is significant according to a binomial sign test (i.e. the reversed likelihood was in-deed worse on all 10 runs), the difference is very small. This provides evidence that radio playlists appear to not have many directional constraints. However, playlists for other settings (e.g. club, tango) may be more directional.
As discussed in Section 3.4, an added term for each song can be used to separate popularity from the geometry of the resulting embedding. In Figure 8, a comparison of the popularity-augmented model to the standard model (both with single-point) on the two datasets is shown. Adding the popularity terms substantially improves the models for low-dimensional embeddings. Even though the term adds only one parameter for each song, it can be viewed as adding Figure 8: Effect of popularity term on model likeli-hood in yes small (left) and yes big (right) as much expressive power as dozens of additional spatial parameters per song.
We take the single-point model with d = 5 without regu-larization as an example in this part. We list the CPU time per iteration and log-likelihood on both datasets in Table 1 and Table 2. The landmark heuristic significantly reduces the training iteration time to what is almost proportional to r . However, for low r we see some overhead introduced by building the landmark data structure. The heuristic yields results comparable in quality to models trained without the heuristic when r reaches 0 . 3 on both datasets. It even gets slightly better than the no-heuristic method for higher r . This may be because we excluded songs that are very un-likely to be transitioned to, resulting in some additional reg-ularization. Table 1: CPU time and log-likelihood on yes small
Table 2: CPU time and log-likelihood on yes big
We designed the following experiment to see whether our method captures the coherency of playlists. We train our model on the 1-hop transitions in training dataset, which is the same as what we did before. However, the test is done on the n -hop transitions (consider the current song and the n th song after it as a transition pair) in the test dataset. The experiments was run on yes small for various values of d without regularization. Results are reported in Figure 9.
One can observe that for all values of d , the log-likelihood consistently decreases as n increases. As n goes up to 6 and above, the curves flatten out. This is evidence that our method does capture the coherency of the playlists, since songs that are sequentially close to each other in the playlists are more likely to form a transition pair.
We presented a new family of methods for learning a gen-erative model of music playlists using existing playlists as training data. The methods do not require content features about songs, but automatically embed songs in Euclidean space similar to a collaborative filtering method. Our ap-proach offers substantial modeling flexibility, including the ability to represent song as multiple points, to make use of regularization for improved robustness in high-dimensional embeddings, and to incorporate popularity of songs, giving users more freedom to steer their playlists. Empirically, the LME outperforms smoothed bigram models from natural language processing and leads to embeddings that qualita-tively reflect our intuition of music similarity. This work was funded in part by NSF Awards IIS-0812091, IIS-0905467, and IIS-1217686. [1] N. Aizenberg, Y. Koren, and O. Somekh. Build your [2] L. Barrington, R. Oda, and G. Lanckriet. Smarter [3] T. F. Cox and M. A. Cox. Multidimensional scaling . [4] D. F. Gleich, L. Zhukov, M. Rasmussen, and K. Lang. [5] D. Hsu, S. Kakade, and T. Zhang. A spectral [6] D. Jurafsky and J. Martin. Speech and language [7] Y. Koren, R. M. Bell, and C. Volinsky. Matrix [8] B. Logan. Content-based playlist generation: [9] F. Maillet, D. Eck, G. Desjardins, and P. Lamere. [10] B. McFee and G. R. G. Lanckriet. Metric learning to [11] B. McFee and G. R. G. Lanckriet. The natural [12] J. L. Moore, S. Chen, T. Joachims, and D. Turnbull. [13] J. C. Platt. Fast embedding of sparse music similarity [14] L. Rabiner. A tutorial on hidden markov models and [15] S. Rendle, C. Freudenthaler, and L. Schmidt-Thieme. [16] L. Song, B. Boots, S. Siddiqi, G. Gordon, and [17] D. Tingle, Y. Kim, and D.Turnbull. Exploring [18] C. Wang and D. Blei. Collaborative topic modeling for [19] J. Weston, S. Bengio, and P. Hamel. Multi-tasking [20] Y. Yue and T. Joachims. Predicting diverse subsets [21] E. Zheleva, J. Guiver, E. Mendes Rodrigues, and
