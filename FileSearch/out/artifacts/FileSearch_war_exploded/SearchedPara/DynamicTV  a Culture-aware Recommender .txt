 A geographically homogeneous group of citizens shares much common knowledge, characteristics of their culture and history. This knowledge is captured for the use in an item-based recommender system that uses text ual information, by introducing bias corpora: newspaper articles that represent the shared knowledge. We present a technique for incorporating and quickly replacing bias corpora in a case study of recommendation of TV contents on our IPTV platform. With this recommender, users watched more items and expressed satisfaction with the service . H.3.3 [ Information Storage And Retrieval ]: Information Search and Retrieval  X  Information filtering Algorithms, Experimentation. Recommender systems, biased LSA. Whenever the items in a collec tion are supplied with textual descriptions, it is possible to perform item-item content-based recommendation, even in the absence of sales data or ratings. In such cases, Latent Semantic Analysis (LSA) is a useful tool for discovering similarities be tween items and producing recommendations [8]. In [5], Rose nstein and Lochbaum studied a content based recommender system using LSA on item description texts for an e-comme rce platform, demonstrating high acceptability and increased revenue. Some authors have taken into account the context in which the recommender operates. In [6], Rocha and Bollen propose to compute item similarity using relations learned from an external knowledge corpus. Adomavicius et al . [7] introduce context as defined by data associated with the place and time of usage. In this paper we present a recommender developed within the DynamicTV research project [1]. We consider the knowledge shared by users that live in the same geographical area, as for example a country. Users that have lived in the same area for years are likely to recall the same events (political and other) and to place great importance on what has happened in their own area. Such local knowledge implies seman tic relations that can not be discovered by analysing only the textual descriptions of the recommendable items in a collection. As the local knowledge changes over time, we also track its evolution. We represent this common knowle dge by adding a bias to the computation of recommendations. A bias corpus , i.e. a large number (the order of a million) of newspaper articles is added to the recommendation set , i.e. the textual descriptions of recommendable items. Our algorith m permits fast updates in order to add recent knowledge, on-the-spot replacement of the bias corpus, representing a diffe rent knowledge domain and fast blending of several bias corpora. The paper is organized as follows . In section 2 the algorithm is introduced with attention to the de tails of bLSA (biased LSA). In section 3 we study how the technique performs in the context of interactive television with respect to number of watched items and viewer satisfaction. In this paper we propose an item-item content-based culture-aware recommender based on the text ual descriptors (such as the synopsis) associated to TV conten ts using a variant of the well known Latent Semantic Analysis approach. The recommender exploits a corpus of documents re presentative of a cultural context for automatically learning the re lations among terms to be used while recommending TV contents. Latent Semantic Analysis takes as input a matrix M containing weighted word frequencies. Each row in M represents a document (in our case, a content description) and each column represents a keyword. The main idea is to perform a dimension reduction of the matrix M using the Truncated Singular Value Decomposition (TSVD) and then using the similarities among items calculated in the new reduced space for creating the recommendations given an item [8][9]. Our approach is motivated by some experiments with LSA for recommendation. We applied LSA to two different corpora, one containing short (avg. 17 words) te xtual descriptions of 1,300 TV contents (feature films and TV series), and one containing 407,000 longer (avg. 90 words) ne wspaper articles. The TV program guide will be called the recommendation set , as our goal is to produce recommendations for the items in this set. The set of RSS feeds (http://notizie.virgilio.it/) will be called the bias corpus . When applying LSA to the recommendation set, we noted that recommendations are generally good for genres that are well represented in the recommendation set, like Science fiction and war movies. The problems arise when dealing with items that treat rare topics or having short descriptions. For example,  X  X ot X  e Cleopatra X  is a comical history movie, a rare genre in the recommendation set. The recommenda tions obtained for this film are not very relevant as shown in the left column of Table 1. Adding the bias improves the recommendations (right column). The reason for the improvement is found in the words that the new corpus brings to the approximating bag-of-words. For example, to the film  X  X ot X  e Cleopatra X  words are added that represent the comedy style of Tot X  (the main character): Irriverente (irreverent) , pasti ccione (bungler/messer), sketch In order to produce relevant recommendations for any given topic, we believe that two conditi ons must be fulfilled. Firstly and obviously, other items with relevant content must be present in the recommendable set. If there is only one document that treats topic A (e.g. mountains) in a recommendable set that otherwise only treats topic B (e.g. the sea), clearly no good recommendation can be made. The second condition, on the other hand, regards a fundamental feature of Latent Se mantic Analysis: the texts used must enable the discovery of the latent semantics. Two documents that carry similar meaning but are written with different words can only be linked if the corpus contains other documents where the relevant words co-occur. For documents that treat rare topics, this second condition is often not me t. This is more evident in a small corpus, where documents th at provide the semantic links will be lacking. The main hypothesis in this paper is that an additional corpus can improve recommendations. The additional corpus must provide enough knowledge so that good sema ntic links emerge between the items in the recommendation set. In our experiments we used articles of Italian newspapers, since they represent and influence the common culture of people living in the country. We note that newspaper articles also reflect how common knowledge changes over time. To this end we introduce the biased Latent Semantic Analysis (bLSA) as a variant of the original recommendation algorithm based on LSA. The bLSA is based on the idea of using a large cultural-context corpus, called the bias corpus in addition to the recommendation set. The bLSA is composed of 5 main steps described in detail in the following sections: bias corpus selection, content-keyword matrices creati on, superset matrix creation, incremental SVD computation and superset matrix on-the-spot update. In the case we studied, the recommendation set is made of short texts that describe films and TV series as they come from content providers to the IPTV platform. These texts contain few instances of common  X  X ultural X  knowledge like politics, history, economy and everyday life. In order to discover a corpus that improves recommendations, it seems necessary to try out differe nt ones and choose the best  X  or the best combination of severa l corpora. A method for quickly replacing and merging bias corpora is therefore called for. Paragraphs 2.2.3 -2.2.5 present such a method. Each text of the recommendation set and the bias corpus is converted to a keyword vector and put in a row of the corresponding content-keyword matrix. The goal of this step is the creation of two content-keyword matrices, the recommendation matrix , associated to the recommendation set, and the bias matrix , associated to the bias corpus. Both matrices have columns that correspond to the words found in the corresponding corpora. Keywords selection in a text fo llows four main steps: stopword filtering, identification of com pound words, lemmatization, Part Of Speech tagging. The matrix elements are tf (term frequency)  X  idf (inverse document frequency) weights [2]. Each keyword vector of a recommendable TV content will fill a row in the recommendation matrix , while each keyword vector bias matrix. The number of columns (each representing a keyword) equals the number of keywords identified in the respective set. The set of keywords used in the recommendation matrix is called the recommendation vocabulary , the one used in the bias matrix, the bias vocabulary . In order to analyze jointly the two corpora a new content-keywords matrix, called superset matrix , must be created by merging the recommendation matrix and the bias matrix. The merge process must take into account that the vocabularies of the two matrices differ and that the original tf-idf values in the merged matrices are no longer valid. The superset matrix uses a shared vocabulary. The three possible strategies are: the union of the two source vocabularies, the intersection or the choice of one of the two. The construction strategy will affect the latent relations extracted from the recommendation matrix: in our experience the union seemed to be the best choice . The conversion of the vocabularies is done by two matrices, called conversion matrices , F R and F B that permute, eliminate, and add empty columns. If M R is the recommendation matrix and i s the bias matrix, the superset matrix M S Finally, the tf-idf values in the superset matrix are re-calculated according to the new keyword frequencies Paragraph 2.2.5 describes a fast method for updating the tf-idf values. The final step of bLSA is the computation of the truncated SVD of the superset matrix S M  X  : Since the bias corpus must be large (in our experiments the number of bias documents is on the order of a million), the computation of the SVD on the en tire matrix is unfeasible. The SVD was therefore computed using the incremental truncated SVD described in [3][4]. As described above, the superset ma trix that will be used for the generation of recommendations can be updated to incorporate new bias or recommendable contents, by an incremental approach. We use a technique called superset matrix on-the-spot update for changing or adding a bias corpus on the spot avoiding an (often very time-consuming) re-factorization of the whole superset matrix. This is very useful for a fast adaptation to changes in the bias corpus or for setting up experiments. The technique merges the LSA products of chosen bias matrices with the LSA product of the recommendation matrix. The merger process is composed of a tf-idf update and a merger of updated LSA products. The process can be iterated for merging more than two matrices. 1. tf-idf update . Each element in the content-keyword matrix M is a product with factors tf  X  and idf  X  : ) ( ) , ( j j i M in the i-th content, and on S i , the sum of occurrences of all The idf factor depends on N, the total number of contents in the M matrix, and on d j , the number of contents in which the j-th keywords appear at least once: Update of the tf factor . Because of the merger, the total number of contents changes and so does the shared vocabulary. Hence the corresponding tf-idf values change as well. If S i of occurrences of the keywords in a given content with the original vocabulary, and S i  X  is the sum of occurrences of the keywords in the same content with the shared vocabulary, then the updated tf factor is: In the LSA product of M, the multiplication of the i,j-th element by a factor dependent on the row can be expressed as Update of the idf factor . Let N denote the number of total contents in M and N X  denote the number of contents after a merger, d j is the number of contents in M where the j-th the merge. The updated idf is: We update the LSA product of M by post-multiplication may be done simultaneously: We must make sure that the new product is a valid SVD. The factors DU and V C T do not have orthonormal columns, so we begin by orthogonalizing using QR factorization. We thus Equation (2) can now be rewritten: Here we factorize T T V U R R The LSA product is now a valid SVD with factors The proposed tf-idf update does not require that the correction have low rank in order to be e fficient, while the term weight correction of Zha and Simon does [3]. The tf-idf update procedure described is applied to both of the LSA products that are to be merged. The output will be two new 2. Merger of updated LSA products. The two updated LSA products are stacked as follow: The factor on the right hand side can again be factorized using QR The matrix T R is factorized with SVD, as in T T V U R The stack of two LSA products is now This is a valid SVD where the three factors are: obtained by by merging two LSA products. The merger technique may be applied to any pair of LSA products. The factor V discarded in the computation as well as those rows in U X  X  X  associated to the bias. The recommender system described is currently adopted by the IPTV platform of Telecom Italia, called Alice Home TV. It hosts about 10,000 TV programs. The bias corpus used by the recommender is composed of more than 1M news articles of a national newspaper. From an indus trial perspective, the benefits of a recommendation service on the IPTV are measured in terms of an increased number of watched items and in terms of customer satisfaction while using the system. The impact of using the recommendation service, in terms of watched items, has been measured tracking the watching behaviour of two chosen samples of users. One sample is called composed of 2000 frequent watchers : these are the customers with a high TV watch rate per m onth. The users belonging to the active sample had access to the recommender, while the users of the control sample had not. The study has been conducted tracking the watching behaviour of the two samples in a chosen time interval for comparing the average number of watched items while using or not the recommendation service. The users monitoring. The three months trial period goes from November 2008 to January 2009. Since the wa tching rate classification is made monthly, the number of user s in the sample changes due to the fact that some of them are no more classified as frequent watchers in the chosen month. As stated in 2.2.1, unbiased recommendations are quite poor. We recommendations since it could harm consumer trust. 
Table 2. Average and total number of items watched by the As from Table 2, the gap between the active sample users and the control sample increases over the time, as people use and follow the provided recommendations. The customer satisfaction has been measured using a survey by telephone run over a subset of 123 users belonging to the active sample after a 3 months period of usage of the recommendation service. Around 70% of the watched the recommended items at least once. The users have been asked to give a 1 to 10 mark on some features of the service. As shown in Table 3, most of the users find the recommender satisfying. The paper introduced a culture-aware recommender system, based on the biased LSA (bLSA), a variant of the content to content recommender systems based on LSA, and adopted by the IPTV platform of Telecom Italia. As de monstrated by the experiments, it has brought good results from the beginning in terms of increase of watched items a nd customer satisfaction. [1] Etzler, L., Guercio, E., Montanari, R., Perrero, M., Rapp, A., [2] Sparck Jones, K.,  X  X  statistical interpretation of term [3] H. Zha and H. Simon, On updating problems in latent [4] M. Brand, Fast low-rank modifi cations of the thin singular [5] Mark Rosenstein, Carol Lochbaum -Recommending from [6] Rocha Luis M., Johan Bollen -Biologically Motivated [7] G. Adomavicius, R. Sankarana rayanan, S. Sen, and A. [8] Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. [9] M. W. Berry, S.T. Dumais , G.W. O'Brien, Using Linear 
