 LIP6  X  CNRS and Universit X  Pierre et Marie Curie, Paris, France 1. Introduction
Many real-world complex networks have a natural bipartite structure and may therefore be modeled as bipartite graphs, i.e. two sets of nodes with links only between nodes in different sets. Typical exam-ples include actor-movie networks [40] where actors are linked to the movies they played in; authoring networks [30] where authors are linked to the papers they co-signed; peer-to-peer exchange graphs [17] where peers are linked to the fi les they provided/searched; and on-line shopping networks where clients are linked to the products they bought [28].

Studying such networks has received recently much attention, see [25] for a survey. The main approach consists in transforming bipartite graphs into classical (non-bipar tite) graphs through a process called therefore is very appealing, but there is a lack of established methods for doing so.

In addition most of these networks are dynamic: they evolve over time, with node and link additions and removals. Studying such dynamics is extremely important for our understanding of these objects, but here again very limited knowledge and basic met hods is available, even for classical (non-bipartite) dynamic graphs.

One of the main approaches developed for studying graph dynamics is link prediction [6,18,27], which graph at a given time.
We address here the problem of link prediction i n dynamic bipartite graphs. To do so, we introduce a on these links and compare it to a basic classical approach. We study the performance of our method on real-world datasets using wide ranges of parameters and present the results for a fi le-provider graph. This shows that this method reaches very good performances and that internal links play a key role in the dynamics of real-wor ld bipartite graphs.

The paper is organized as follows. We review related work in Section 2 and present the bipartite frame-work, including the notion of internal links, in Section 3. We then formally state the considered problem and its assessment in Section 4. We present in Section 5 our prediction method and a basic method which we consider for comparison purpose. We fi nally present our experimental setup in Section 6 and the results of experiments in Section 7. We discuss our conclusions and perspectives in Section 8. 2. Related work
Link prediction is a key research problem in network dynamic analysis. Several works study this problem on classical (non-bipartite) graphs. Most of them are based on measures of similarity between nodes. For instance, in [27] the authors examine several topological measures (such as Jaccard coef fi -cient, Adamic/Adar coef fi cient, SimRank, etc.) based on node neighborhoods and the set of all paths between nodes. They use these measures for ranking possible future co-authors collaborations. In [20] 31] the authors add several non-topological measures based on node attributes (such as keyword match, number of papers, geographic proximity, KL-divergence of two nodes X  topic distribution, etc.) and they use a supervised learning algorithm to perform link prediction. In a similar way, the authors of [7] pre-dict co-authoring of publications by using topological measures computed in the co-authoring graph and indirect topological measures computed using the co-author graph (where two papers are linked if they are signed by a same author). The authors of [39] add another measure (local probabilistic model) to available temporal information. Finally, the authors of [11] use a hierarchical decomposition of a social network and use it for predicting missing links. They generate a set of hierarchical random graphs, and they compute average probability of connection between two nodes within these hierarchical random graphs.

Works presented above deal with classical (non-bipa rtite) graphs, and are not directly applicable to bipartite graphs. In [21], the aut hors adapt some t opological measures used in classical graphs for pre-the bipartite graph and neighbors of neighbors of v . They also study the set of all paths between nodes, in the bipartite graph. Going further, the authors of [6] consider two transformations of the bipartite and they study the topological measures between u and the neighbors of v in the bipartite graph, and conversely.

The authors of [13] study two prediction problems in bipartite graphs in which links appear and dis-appear over time: predicting new links aims at predicting links that will appear and were never observed ing links that were previously observed. They use matrix-and tensor based methods to do so. In [23, 24], the authors study link prediction in growing (bipartite) graphs. They argue that, in practice, the growth changes the eigenvalues but leaves the eigenvectors largely unchanged. Studying the eigenvalues evolution allows to propose a growth model for a given network, and use it for link prediction.
Another research problem is closely related to link prediction in bipartite graphs: the recommendation problem [34]. Recommendation systems are used to suggest items to users, such as products to customers for instance. Notice however that the two problems are quite different: recommendation aims typically at fi nding a small number of products of interest for each customer; prediction aims at fi nding links that will appear in the future. Predicting that a given node will have a huge number of new links while many others will not have any is o f little interest re garding recommendation b ut may be a great success regarding prediction.

Various approaches have been developed for recommendation [3,5,22], with collaborative fi ltering being the most successful and widely used approach [22]. Two main approaches of collaborative fi ltering have been proposed, both based on the idea that similar users will purchase similar items and that users will purchase items similar to the ones they already purchased. The fi rst approach consists in predicting a given user in order of decreasing interest, and then in recommending the top N items to this user [12, 28]. This approach does not require explicit ratings but only the information of which users adopted which items, and is the most similar to link prediction. We will use such an approach in this paper for the purpose of comparison with our method, see Section 5.2. 3. The bipartite framework
We present here bipartite graphs and their transformations into (weighted) classical graphs, called links are at the core of our work. 3.1. Bipartite graphs, projections, and internal links
A bipartite graph G =(  X  , ,E ) is de fi ned by a set  X  of bottom nodes, a set of top nodes and a set E  X  X  X  X  of links. The key point is that links exist only between a node in  X  and one in .We denote by N ( u )= { v  X  (  X  X  X  ) , ( u, v )  X  E } the neighborhood of a node u in G .If u  X  X  X  then N ( u )  X  , and conversely. More generally, given any set of nodes S  X  (  X  X  X  ) , we denote by N ( S ) its neighborhood: N ( S )= u  X  S N ( u ) .

The  X  -projection of G is the graph G  X  =(  X  ,E  X  ) in which ( u, v )  X  E  X  if u and v have at least one u and v are linked to a same top node in G . As a consequence, each top node induces in G  X  a clique between its neighbors in G . See Fig. 1 for an example. We denote by N  X  ( u ) the neighborhood of a node u in G  X  : N  X  ( u )= { v  X  X  X  , ( u, v )  X  E  X  } = N ( N ( u )) .The -projection of G , denoted by G ,is de fi ned dually.

We now introduce a special class of links, called internal links , which play a key role in the whole paper.
 De fi nition 1 (internal links) . Let us consider a bipartite graph G =(  X  , ,E ) and the bipartite graph G =(  X  , ,E  X  X  ( u, v ) } ) obtained by adding the link ( u, v )  X  X  X  X  to G , with ( u, v ) /  X  E . The link ( u, v ) is internal if G  X  = G  X  .
In other words, an internal link in a bipartite graph G is a pair of nodes ( u, v ) such that adding the nodes ( B,C ) , ( B,D ) and ( B,E ) already have a neighbor in common in G , respectively, i , j and k . Adding link ( B,l ) to G increases their number of common neighbors to 2 and thus does not change  X  -projection.

As this example indicates, internal links have a characterization in terms of neighborhood which we give now.
 Lemma 1. Given a bipartite graph G =(  X  , ,E ) , a pair of nodes ( u, v ) in (  X  X  ) \ E is an internal link for G if and only if N ( v )  X  N ( N ( u )) .
 Proof. Let us consider a pair of nodes ( u, v ) in (  X  X  ) \ E and let G =(  X  , ,E = E  X  = E  X   X  X  ( u, x ) ,x  X  N ( v ) } .

Suppose now that ( u, v ) is an internal link, i.e. E  X  = E  X  . Then all links ( u, x ) in the expression N and so E  X  = E  X  and the link ( u, v ) is internal.
 We fi nally introduce the notion of induced links, which will be useful in the following. De fi nition 2 (induced links) . Given a bipartite graph G =(  X  , ,E ) , the set of links induced by any pair of nodes ( u, v ) in (  X  X  ) is:  X  ( u, v )= { u } X  N ( v )= { ( u, w ) ,w  X  N ( v ) } .
In Fig. 1, for instance,  X  ( A, j )= { A } X  N ( j )= { ( A, B ) , ( A, D ) } . Notice that E  X  = (
B,l ) is an internal link. 3.2. Weighted projections
As explained for instance in [25], G  X  contains much less information than G . In particular, the fact that u and v are linked in G  X  means that they have at least one neighbor in common in G but says nothing on their number of common neighbors. Several approaches are used for weighting the links of the  X  -projection in order to capture such information. We present the main ones in this section (examples are displayed in Fig. 2).

First, the weight of link ( u, v ) may be de fi ned as the number of (top) neighbors that u and v have in common in the bipartite graph, called sum : The  X  weight function has been used for instance to estimate the probability of collaboration between authors [29].

Notice that if u and v both have many neighbors, then  X  ( u, v ) will naturally tend to be high. Con-This quantity has been used for instance in the context of peer-to-peer exchange analysis to capture similarity between peers [26].

The value of  X  ( u, v ) may however be strongly biased if one of the two nodes has many neighbors and the other one only few: the value would then be very low, even if all neighbors of one node are neighbors in the literature [35,36]:
From this point of view, though, nodes play an unbalanced role: a -node x has an in fl uence on the if a -node only has two neighbors then it probably indicates a signi fi cant similarity between them. To capture this, one may consider that each -node votes for the similarity between its neighbors and that the sum of its votes is only one (it has only one voice to distribute). This leads to the delta function: similar quantity has been used in [1] to capture the similarity between two home pages as a function of the features they share.
All weight functions above intuitively capture similarity between nodes. One may also use weight functions to capture other features, like the activity of nodes in the network. This leads for instance attachment : which re fl ects the expectation that u and v may have neighbors in common: if links were placed at random then the probability that ( u, v ) is a link would be proportional to  X  ( u, v ) .
All weighting functions presented above are natural and capture relevant informations about a bipartite graph. Each has its own strengths and weaknesses, and up to our knowledge there has been only limited comparison between them until now. By comparing their performance in the context of link prediction below, we expect to give some insight on their respective relevance in this context, see in particular Section 7.3. 4. The bipartite link prediction problem 1 ...n } .Let G =(  X  , ,E ) be the graph observed from a given instant a to another instant b&gt;a :  X  = { D s.t. a t&lt;b } . We call G the reference graph and [ a, b [ the reference period .
 that we consider only the links between nodes of G (we ignore new nodes appearing in the period [ b, c [ ) which are not present in G (we consider links in  X  X  X  E only).

In this framework, the goal of a link prediction method is to fi nd a set P of predicted links which contains many of the links in E but only few which are not in E . Notice that in the extreme case where one predicts all possible links, i.e. P =  X  X  X  E , then one succeeds in predicting all links of E but does not predicting links not in E but fails in predicting any link in E .

Evaluating the performances of a prediction method therefore consists in evaluating its success in reaching a tradeoff regarding these two objectives, which is non-trivial. We present below a classical method to do so [10,36], which we use in this paper.
 Let us denote by P the set of links that the method predicts and will not appear: P =(  X  X  X  E ) \ P . Figure 3 illustrates the four possible cases which may occur during link prediction: the set P  X  E of true positives is the set of appearing links that the method successfully predicts; the set P \ E of true negatives is the set of unpredicted links which indeed do not appear; conversely, the false positives are the links in P \ E , i.e. the links which we predicted but do not appear, and the false negatives are the links in P  X  E .

The aim of a link prediction method is to maximize the number of true positives and negatives while minimizing the number of false positives and negatives. This is captured by two quantities, called preci-sion and recall .
 a measure of correctness.
 is the probability that an appearin g link will indeed be predicted by the method, and so is a measure of completeness.

As explained above, there is a tradeoff between precision and recall, as, in general, improving one degrades the other and conversely. In order to capture this in a single value, which often is more con-recall [38]. The goal of a prediction method then is to maximize the F-measure. 5. Bipartite prediction methods
In this section, we introduce our link predic tion method for bipartite graphs, which we call internal link prediction . We also present a typical collaborative fi ltering method which we use for comparison in the next sections. 5.1. Internal link prediction
The key feature of our prediction method is that it focuses on internal links: it predicts internal links only. The intuition behind this is that two bo ttom nodes which already have a common neighbor in G (i.e. they are linked in G  X  ) will probably acquire more in the future. Instead, if two nodes have no common neighbor in G , then they will probably still have none in th e future. The links that can be added to G links which appear are indeed internal.

Going further, two bottom nodes with many common neighbors in G will probably have more in the future. More generally, all the weight functions presented in Section 3.2 are measures (from different points of view) of our expectation that two nodes having neighbors in common probably will have more with high weights.

This leads to the following prediction method, which we call internal links prediction . Let us consider a weight function  X  like the ones described in Section 3.2, and a given weight threshold  X  . We denote or equal to  X  . We then predict all the internal links which induce at least one link in E  X   X  .
Figure 4 shows an example of internal link prediction using the Jaccard weight function,  X  .Thesetof (
B,C ) , ( B,D ) ,and ( B,E ) . Given a threshold  X  we predict ( B,l ) if one of these links has weight at least  X  . For instance:  X  if  X  = 1 4 , all links in the projection have a weight larger than or equal to  X  , and so we predict all  X  if  X  = 1 3 , only 5 links in the projection have weight larger than or equal to  X  , including ( B,C ) , Algorithm 1 provides the details of the method useful for implementation, and Theorem 1 shows its complexity.
 Theorem 1. Algorithm 1 performs internal link prediction on a bipartite graph G =(  X  , ,E ) in time addition to the space needed for storing G .
 Proof. We fi rst show the termination and correctness of our algorithm. The algorithm consists of imbri-cations of for loops over fi nite and static sets, so it necessarily terminates.

To show its correctness, we must show that it predicts all the internal links that induce links in E  X   X  , i.e. links with weight larger than or equal to  X  , and only those links.

The algorithm consists in a loop over all nodes u in  X  , with three main parts, each consisting in a for loop.

The fi rst part computes N  X  ( u ) , denoted by Nbot in the algorithm to emphasize that it is not precom-puted nor stored, and the weights of the corresponding links. The nodes w added to Nbot are exactly fi rst part of the loop. We do not detail the weight computation here, because it depends on the weight function considered. We assume that it can be computed with the same time complexity overhead as N  X  , which is true for all the weight functions presented in Section 3.2.

The second part does two things. First it stores in a set m the nodes v such that ( u, v ) induces a link ( soon as it has a neighbor w  X  X  X  such that ( u, w )  X  E  X   X  .

This loop also stores in d [ v ] the number of neighbors of v which are neighbors of u in G  X  .Atthe Algorithm 1: Internal link prediction internal link, from Lemma 1.

The third part of the loop then computes the intersection between the nodes v which correspond to one link ( u, w )  X  E  X   X  (the nodes in m ).

Before entering in the details of the complexity analysis, let us discuss how sets may be ef fi ciently managed in our algorithm. A set s of nodes in (resp.  X  ) may be represented by an array indexed by nodes in (or  X  ), such that s [ v ]=1 if and only if v  X  s , together with an array i s containing the indexes of nodes in s , and an integer n s representing the number of nodes in s . Therefore listing all the time needed to populate the set, and therefore does not create any time complexity overhead. In our algorithm, the array d may be managed in a similar way: an additional array stores the indexes of nodes for which d [ v ] =0 , which allows to reset d to 0 without iterating over all nodes in .
This leads to the space complexity of our algorithm. With the encoding above, a set of nodes in in general compared to | E | , our algorithm only requires  X ( || + | X | ) space in addition to the space needed for storing its input G and its output P (which we may choose not to store).

Let us now study the time complexity of the algorithm. The main loop runs over all nodes in  X  and performs three sets of operations. We will study the complexity of these parts independently. number of operations for the fi rst part of the main loop is of the order:
We h ave th a t | N ( v ) |  X  ,where  X  =max v  X  | N ( v ) | . Therefore the above quantity can be bounded:
The second part of the loop performs  X ( | N ( w ) | ) operations for each node w  X  N  X  ( u ) . The total number of operations in this part of the loop is therefore performed in time: This expression can be bounded in two ways, by considering that | N  X  ( w ) |  X   X  (where  X   X  = In the fi rst case we obtain In the second case we obtain
Finally, the third part of the loop iterates over all nodes in m .Since m was computed in the second part of the loop, the number of operations in the third part of the loop is bounded by the one for the second part of the loop, therefore we do not need to evaluate it further.
 The overall complexity of the algorithm is therefore in the order of because  X   X  X  ( X   X  ) since each node in with degree d induces a clique of d nodes, each of them having a degree at least d  X  1 in G  X  .
 5.2. Collaborative fi ltering prediction
As explained in Section 2, typical collaborative fi ltering approaches consist in predicting that  X  -nodes tend to create links to the -neighbors of  X  -nodes which are similar to themselves (clients will buy products that similar clients already bought). More precisely, such methods fi rst select for each  X  -node u the set of k  X  -nodes which are the most similar to u and then the N -nodes the most strongly linked to these nodes, for given parameters k and N . Here, natural notions of similarity between  X  -nodes are provided by the weighted  X  -projection.

We will therefore use the following collaborative fi ltering method [8]: given a weight function  X  ,we consider for each  X  -node u the set U k  X  N  X  ( u ) of its k neighbors with largest weight. Then for each v for each w  X  N ( v )  X  U k : There are other possible ways to compute the score [9,14,15,19,41], however in this paper we restrict ourselves to the formula above which is typical. Finally, the collaborative fi ltering method predicts for each node the N links with highest scores.
 Figure 5 presents an example of collaborative fi ltering using the Jaccard weight function  X  , k =2 and N =1 . For instance, node E has three neighbors in the  X  -projection: N  X  ( E )= { B,C,D } . The method then considers the k =2 most similar ones, i.e. the ones linked to E with the largest weight in G  X  .As ( E,B )and( E,C ) have the same weight, the method chooses at random between B and C . Suppose that U leading to s ( E,j )=  X  ( E,B )+  X  ( E,D )= 7 12 ,and s ( E,i )=  X  ( E,B )= 1 4 . Finally, as N =1 ,it predicts the link with highest score, ( E,j ) .

We present details in Algorithm 2. The fi rst part of the loop computes N  X  ( u ) . The corresponding time (notations are de fi ned there). The complexity of the second part of the loops depends on parameters Algorithm 2: Collaborative fi ltering k and N .The sort and head instructions are used to compute the k and N largest values in N  X  (according to weight function  X  )and s , respectively. This can be done in constant time if k and N are constant, but we kept this notation to make the algorithm easier to read.

The loop iterating over all nodes w  X  U k performs | N ( w ) | operations at each step. This loop is repeated for all nodes u  X  X  X  . The total number of operations performed is bounded by O (
The total time complexity is therefore in the order of O ( X   X  | E | ) , as Algorithm 1. The space complex-Nbot,U,U k ,and s . This is the same as Algorithm 1. 6. Experimental setup
Evaluating our method in practice requires the availability of large scale bipartite data with their dy-namics . One natural source for such data might be benchmarks for recommendation systems. However, such datasets often do not contain temporal information or have been fi ltered to fi t recommendation needs (for instance, nodes with a small degree have been removed, as well as large degree ones). This makes them unusable in our context.

We fi nally conducted experiments on various datasets, in particular user-tag graphs from deli-obtained with a fi le-provider dataset [2] which are representative of all obtained results.
We fi rst describe this real-world dataset. We show that its amount of internal links is high, which ensures the relevance of predicting internal links. We then discuss appropriate parameters for our ex-perimentation for both our method and the collaborative fi ltering one. We present the results of our experimentations in Section 7. 6.1. File-provider dataset
We use for our experiments a measurement of a peer-to-peer fi le exchange network [2]. It consists of a recording of messages received and sent by a large eDonkey server during almost 10 weeks, with queries from users for fi les, and answers from the server indicating which users provide which fi les. We server pointed peer u i as a provider for fi le v i at time t i .

Using the formalism described in Section 4, each triplet corresponds to a link between a  X  -node (a peer) and a -node (a fi le) at time t i . For two given timestamps x and y we consider:  X  the reference period [0 ,x [ and the corresponding reference graph G =(  X  , ,E ) induced by links  X  the prediction period [ x, y [ and the corresponding set of links E  X  (  X  X  ) \ E added to G between The  X  -projection G  X  of G is the graph in which two peers are linked if they provide one or more fi les in common.

Basic features of the reference graph G and its projection G  X  are presented in Table 1, for different reference period durations x . Notice that the number of -nodes ( fi les) is much larger than the number of  X  -nodes (peers), which is mostly due to the fact that we consider only peers which provide at least one fi le (most only download fi les). Notice also that the number of links in the  X  -projections is huge. for a discussion of this. To this regard, it is crucial that the methods considered in this paper need not store G  X  , unlike most other approaches. 6.2. Amount of internal links
In order to gain more insight on the dynamics of the considered data, let us consider the number | E | of new links appearing during the prediction period [1 ,y [ ,for y =2 ,..., 55 days, for a reference graph G obtained with a reference period [0 , 1 day [ , presented in Fig. 6 (left). The number of new links grows rapidly with the size of the prediction period, showing that many new links appear between nodes of the reference period, even after a long time. As one may expect, though, the number of new links grows faster during the fi rst few days.
 35% , for prediction periods of up to 10 days, with a maximal at almost 45% . The fraction of internal links decreases as the length of the prediction period grows, but it remains above 25% for prediction periods of up to 50 days.
Let us now observe how the number of new links | E | and the fraction of internal links among them evolves as the duration of the reference period grows. We consider reference periods [0 ,x [ ,for x = 1 , 2 ,..., 48 hours, and for each x we consider the 15 day prediction period [ x, x +15 days [ ; and present duration x .

The fraction of internal links among these new links is presented in Fig. 7(right). It increases from 35% to 45% for reference periods from 1 to 6 hours. After this it decreases slowly but remains above 28% for reference periods of up to 48 hours.

These statistics show that the fraction of internal links is very high in the considered dataset, even for long reference and prediction periods, which is also true for other datasets we tested. This motivates our approach of focusing on this special class of links.
 6.3. Parameters for prediction methods
The performances of link prediction methods depend on various parameters. We explore in depth in the next section (Section 7) the impact of the reference and prediction periods durations, as well as the impact of the weight functions. Even when these parameters are given, though, other parameters play a in practice, and would actually have limited interest here as we are mostly concerned with qualitative results. We explain in this section how we choose values for these parameters for our experiments while avoiding extensive exploration of all possible values.
 Internal link prediction prediction periods and a given weight function depend on the weight threshold  X  .If  X  =0 then all possible internal links are predicted, which corresponds in this example to 33% of all appearing links. However, many of these links do not actually appear, and so the corresponding precision is almost zero. Instead, if a very high threshold is used then only few internal links are predicted, and so the obtained recall is almost zero. However, most of these few links do appear, which corresponds to a precision of almost 100% . More generally, the precision increases with the threshold value, and the recall decreases. The F-measure which captures a tradeoff between the two reaches its maximal value of 0 . 28 for  X  =0 . 4 in this example.

To avoid taking into account the impact of the threshold  X  on the internal link prediction method, we will select in the experiments of Section 7 the value of  X  which maximizes the F-measure. For instance, when studying the impact of the prediction period duration x for a given reference period (Section 7.1) we will plot the maximal value of the F-measure as a function of x Fig. 9(left).
 Collaborative fi ltering
As explained in Section 5.2, the collaborative fi ltering method depends on a parameter k which is the number of similar neighbors considered for each node. We have experimented the performances of the was obtained for k =50 , therefore we will use this value in all our experiments in the following.
The other parameter, N , is the number of links predicted for each node. It also has a strong impact on the performance of the collaborative fi ltering method. Figure 8(right) shows that the precision decreases and the recall increases when N increases.

Again, to avoid taking into account the impact of N on the performances of the collaborative fi ltering method, we will select in the following the value of N which maximizes the F-measure. 7. Experimental results
In this section, we study the performances of our approach for link prediction and compare it to the collaborative fi ltering approach in the experimental framework described above. We fi rst explore the impact of the prediction period duration, which allows us to choose a relevant value for this parameter for the rest of our comparisons. We then study the impact of the reference period duration, and again select a relevant value for this parameter. Finally, we compare the performances of the different weight functions for these parameters. 7.1. Impact of the prediction period duration
In order to study the impact of the prediction period duration we consider several reference periods [0 ,x [ (from x =1 hour to x =7 days), and several prediction periods [ x, y [ ( y = x +1 day ,y = x +2 days ,...,y = x +49 days). We then compute, for each considered reference period duration, the maximal value of the F-measure observed over all values of the threshold  X  (for internal link prediction ) as explained in Section 6.3.

Results are presented in Fig. 9. The following key facts appear clearly:  X  All plots have the same global shape (a fast increase followed by a slow decrease or steady regime),  X  Different weight functions give different results, which we deepen in Section 7.3;  X  In most cases, and for all weight functions which perform well, internal link prediction surpasses prediction period durations for all reference period durations and weight functions. We will therefore use this prediction period duration in all the following. 7.2. Impact of the reference period duration
In order to investigate the impact of the reference period duration [0 ,x [ , we vary its duration x for x =1 , 2 ,..., 48 hours, and we use the prediction period [0 ,x +15 days [ of 15 days, as explained in the previous section. We do not consider reference periods longer than 48 hours days, because, as we can see in Fig. 9, longer reference periods lead to poorer performances. We compute for all cases the maximal value of the F-measure observed over all values of the threshold  X  (for internal link prediction ) as explained in Section 6.3.

Results are presented in Fig. 10. The following key facts appear clearly:  X  Overall, the maximal F-measure decreases with the size of the reference period (except for very  X  Different weight functions give different results, which we deepen in next section;  X  In most cases, and for all weight functions which perform well, internal link prediction surpasses period durations. We will therefore use this reference period duration in all the following. 7.3. Impact of the weight function In this section, we observe the impact of the weight function on both considered prediction methods. which are representative of wide ranges of values for these parameters. We then compute the precision and recall for all possible values of the threshold  X  for internal link prediction and all possible values of N for collaborative fi ltering; we plot the obtained precision as a function of the obtained recall in Fig. 11.

A fi rst important observation is that the weight functions considered clearly split into two classes regarding the performances of internal link prediction Fig. 11(left): sum, Jaccard and cosine reach very Fig. 11(right): all weight functions lead to very similar results except attachment which performs worse than the others.
 8. Conclusion
In this paper, we introduce a new class of links in bipartite graphs, which we call internal links ,and propose a method which uses them for solving the link prediction problem. We evaluate the relevance of this method by comparing it to a classical collaborative fi ltering approach and perform experiments on various datasets, which show that our method performs very well. We present in details the results ob-which weight function is used for projection.

Our link prediction method has the following advantages. First, it performs very well, much better than a collaborative fi ltering approach, where no other method was previously available. Moreover, our appear in the future; this gives much insight on the properties of the underlying dynamics. Finally, the prediction: one may use small thresholds to have excellent precision at the cost of a poorer recall, and conversely.

Our work may be extended in several ways. In particular, other (maybe more speci fi c) weight functions may be introduced and tested. One may also predict internal links that induce only links with weight above the threshold (inducing one such link is suf fi cient in our current algorithm), or use both -and  X  -projections (our current algorithm only uses the  X  -one). There is therefore room for improving the method and its results.

Likewise, it would be interesting to conduct more experimentations and compare results on different datasets. Comparing our method with others, in particular machine learning approaches like the one methods for external links (those links which are not internal), which may be done with such methods or by modifying ours.
 Another interesting direction would be to modify our approach in order to perform recommendation. As already explained, link prediction and recommendation are quite different problems, but they are may adapt our method and evaluate its relevance for recommendation.
Finally, we think that the notion of internal links introduced in this paper is fundamental and may be used as a building block in a much wider scope, i n particular analysis of bipartite graphs. Although different, it is close to the notion of redundancy proposed in [25], which is one of the main statistics currently used for comparing real-world bipartite gr aphs and random ones. The fraction of internal links in any bipartite graph and similar statistics based on internal links may be used for this same purpose, to the graph dynamics). We consider this as one of the main perspectives of our work.
 Acknowledgements
We warmly thank Nasserine Benchettara, C X cile Bothorel, Ludovic Denoyer, and Rushed Kanawati Research Agency under contracts MAPE ANR-07-TLCOM-24 and DynGraph ANR-10-JCJC-0202.
 References
