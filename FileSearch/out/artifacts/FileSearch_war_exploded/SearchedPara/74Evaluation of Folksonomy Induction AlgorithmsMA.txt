 In recent years, social tagging systems have emerged as an alternative to traditional forms of organizing information. Instead of enforcing rigid taxonomies with controlled vocabulary, social tagging systems allow users to freely choose so-called tags to anno-tate resources [Koerner et al. 2010; Strohmaier et al. 2010]. In related research, it has been suggested that social tagging systems can be used to acquire latent hierar-chical structures that are rooted in the language and dynamics of the underlying user population [Benz et al. 2010; Cattuto et al. 2008; Heymann and Garcia-Molina 2006; Hotho et al. 2006b]. The notion of  X  X olksonomies X  X  X rom folk-generated taxonomies X  emerged to characterize this idea. 1 While a number of algorithms have been pro-posed to obtain folksonomies from social tagging data [Benz et al. 2010; Heymann and Garcia-Molina 2006; Plangprasopchok et al. 2010a], we know little about the na-ture of these algorithms, their properties and characteristics. Although measures for evaluating folksonomies exist (such as [Dellschaft and Staab 2006]), their scope is of-ten narrow (i.e., focusing on certain properties only), and they have not been applied widely to state-of-the art folksonomy algorithms. This article aims to address some of these shortcomings. In this work, we report results from (i) implementing 3 different classes of folksonomy induction algorithms (ii) applying them to 5 different tagging datasets and (iii) comparing them in a study by adopting an array of evaluation tech-niques. The main contribution of this article is a broad evaluation of state-of-the-art folksonomy algorithms across different datasets using existing semantic evaluation techniques. An additional contribution of our work is the introduction and application of a new, pragmatic technique for folksonomy evaluation that allows to assess the use-fulness of folksonomies for navigation. The results presented in this article highlight some challenges of choosing among different folksonomy algorithms, but also lead to new insights about the properties and characteristics of existing folksonomy induction algorithms, and help to illuminate a path towards future, more effective, folksonomy induction algorithm designs and evaluations. To the best of our knowledge, this work represents the largest and most comprehensive comparative evaluation study of state-of-the-art folksonomy induction algorithms to date.

The article is structured as follows: In Section 2, we give a description of three classes of state-of-the art algorithms for folksonomy induction. Section 3 provides an introduction to semantic evaluation of folksonomies. We present a novel pragmatic (i.e., navigation-focused) approach to evaluating folksonomies in Section 4. In Section 5, we describe our experimental setup and in Section 6 the results of conducting se-mantic and pragmatic evaluations are presented. Finally, we discuss implications and conclusions of our work. While different aspects of emergent semantics have been studied by the tagging re-search community (see, for example, [Angeletou 2010; Au Yeung et al. 2009; Yeung et al. 2008]), the common objective of folksonomy induction algorithms is to produce hierarchical structures ( X  X olksonomies X ) from the flat-structured tagging data. Such algorithms analyze various evidence such as tag-to-resource networks [Mika 2007], tag-to-tag networks [Heymann and Garcia-Molina 2006], or tag cooccurrence [Schmitz et al. 2006] to learn hierarchical relations between tags. While further algorithms exist (such as [Li et al. 2007]), we have selected the following three classes of algo-rithms because (i) they were well documented and (ii) for their ease of implementation. Figures 1 and 2 illustrate exemplary folksonomies and folksonomy excerpts induced by these algorithms. In the following, we briefly describe each considered class of algo-rithms and how we have applied them in this article. Frey and Dueck [2007] introduced Affinity Propagation (AP) as a new clustering method. A set of similarities between data samples provided in a matrix represents the input for this method. The diagonal entries (self-similarities) of the similarity ma-trix are called preferences and are set according to the suitability of the corresponding data sample to serve as a cluster center (called  X  X xemplar X  in Frey and Dueck [2007]). Although it is not required to set a cluster number explicitly, the preference values cor-relate with the number of resulting clusters (lower preference values result in fewer clusters and vice versa).

In several iterations, AP exchanges messages between data samples to update their  X  X esponsibility X  and  X  X vailability X  values. Responsibility values reflect how well data samples serve as exemplars for other data, and the availability values show the suitability of other data samples to be the exemplars for specific data samples. Responsibility and availability are refined iteratively with a parameter  X  as an up-date factor. A full description of AP is beyond the scope of this article; we point the interested reader to Frey and Dueck [2007] for further information.

Based on Frey and Dueck [2007], the Plangprasopchok et al. [2010a] have intro-duced an adaption of affinity propagation to infer folksonomies from social tagging data. The authors incorporated structural constraints directly into the global objective function of affinity propagation, so that a tree evolves naturally from execution. In this article, we follow a simpler approach by applying the original AP recursively in a bottom-up manner. In a first step, the top 10 Cosine similarities (pruned for memory reasons) between the tags in a given dataset serve as the input matrix, and the min-imum of those serves as preference for all data samples. Then, AP produces clusters by selecting examples with associated data samples. If the ratio between the number of clusters and the data samples is between 3 and 15 (which we use as an adjustable parameter), then the result will be retained, otherwise another run with lower (too many clusters have been selected) or higher preference values (too few clusters have been selected) will be executed. Finally, the centroids of the clusters are calculated by using the sum of the connected data samples normalized to unit length. Now the Cosine similarities between the centroids serve as the input matrix for the next run of affinity propagation. This approach is executed until the top-level is reached.
Since our objective is to construct a tag hierarchy where each node represents a unique tag, a tag in each cluster is used as a label. The label is selected by choosing the nearest tag to the centroid. Furthermore, this tag is removed from the actual tags contained in the leaf cluster and is not used as a representative in lower hierarchy levels. We set the AP parameter  X  0 to 0.6 with increasing values depending on the imum of 5000 iterations ( i max ) or if the exemplars of clusters are stable for at least 10 iterations. Dhillon et al. [2001] introduce an adaption to the k-means algorithm for textual data by optimizing the Cosine similarity instead of Euclidean distance, while Zhong [2005] introduced an efficient version of an online spherical k-means. Without going into de-tail, these adaptations allow an online version to be at least as fast as a batch spherical k-means with better results. We utilize k-means iteratively in a top-down manner to build a tag hierarchy. Basically, in the first step, the whole input data set is used for clustering the data into 10 clusters. Our decision to use k = 10 was motivated by a desire to capture cognitive limitations of users who are interacting with folksonomies (e.g., to capture the limited ability of users to navigate hierarchies with 100s of children nodes). Clusters containing more than 10 connected samples are further partitioned while ones with less than 10 samples are considered as leaf clusters. However, since a cluster set of 11 samples would also be partitioned into 10 clusters we introduced a special case to give some freedom to the clustering process for these border cases by setting the cluster number to the maximum of 10 or number of data samples divided by 3 what would result in 3 clusters in case of 11 samples. The tag representing a node is selected by taking the nearest tag to the centroid. Furthermore, this tag is removed from the actual tags contained in a cluster and which are further clustered in the next step, if there are more than 10 samples left. Heymann and Garcia-Molina [2006] introduce an algorithm as an alternative to pro-ducing hierarchical structures from tagging data by means of hierarchical clustering approaches. The input for the algorithm is a so-called tag similarity network , an un-weighted network where each tag is a node in the network and two nodes are linked to each other if their similarity is above a predefined similarity threshold. In the simplest case, the threshold is defined through tag overlap: if the tags do not overlap in at least one resource then they are not linked to each other in the tag similarity network. The second prerequisite for the algorithm is the ranking of nodes in a descending order according to how central the tags are in the tag similarity network. In particular, this ranking produces a generality order where the most general tags from a dataset are in the top positions. The algorithm starts by a single node tree with the most general tag as the root node. The algorithm then proceeds by iterating through the generality list and adding each tag to the tree: the algorithm calculates the similarities between the current tag and each tag currently present in the tree and adds the current tag as a child to its most similar tag. The authors describe their algorithm as extensible as they leave the possibility to apply different similarity, as well as different centrality measures. The presented algorithm adopts cosine similarity and closeness centrality, and we denote this algorithm henceforth CloCen/Cos.
 Benz et al. [2010] describe an extension of the algorithm presented in Heymann and Garcia-Molina [2006]. Generally, this new algorithm is based on principles similar to Heymann X  X  algorithm; but the new algorithm applies tag cooccurrence as the similarity measure and the degree centrality as the generality measure (DegCen/Cooc). In par-ticular, the algorithm executes an extensive preprocessing of the dataset for instance, to remove synonym tags or to resolve ambiguous tags. For this article, we study both published variations of these algorithms: CloCen/Cos and DegCen/Cooc. For reasons of simplicity, we skipped preprocessing of the dataset and only applied the alternative similarity and centrality measures. Table I summarizes some statistical properties of all resulting folksonomies.

In the following, we briefly discuss and present state-of-the art evaluation tech-niques for folksonomy algorithms. Specifically, we review current semantic evaluation techniques in Section 3 and present a new pragmatic approach to folksonomy evalua-tion in Section 4. A universal measure for evaluating the overall semantic quality of a taxonomy is dif-ficult to envision or design for several reasons. First, taxonomies are usually con-structed not only for the mere purpose of representing knowledge, but they are often targeted towards a particular application. Depending on the application type and the anticipated user population, different aspects of the taxonomy will be more or less important, which should be reflected in any evaluation approach. If, for example, there exists a direct interface where humans work with the taxonomy, the quality of the lex-ical labels to describe concepts will be more important than in a case where the taxo-nomically captured knowledge serves only as an input for an automatic process. Hence there exist different evaluation paradigms focusing on assessing different aspects of a learned taxonomy. In general, we can broadly distinguish between three evaluation paradigms [Brank et al. 2006; Dellschaft and Staab 2006]:  X  Application-centered . When taxonomies are engineered towards a certain applica-tion, a natural measure of taxonomy quality would be the performance improvement achieved by using different taxonomies as input. A requirement hereby is the exis-tence of measures to compare the achieved results. Though this paradigm reflects clearly the actual  X  X tility X  of a taxonomy, a problematic issue is how to disentangle the influence of the input taxonomy from other application parameters.  X  Human Assessment . This paradigm relies on the judgement of human experts how well an taxonomy meets a set of predefined criteria. Hereby it is obviously an impor-tant question on which criteria to agree. This paradigm can be expected to provide valuable assessments of taxonomy quality at a high cost due to the heavy involve-ment of human interaction.  X  Reference-based . The prerequisite of this methodology is the existence of a  X  X old-standard X , to which the learned taxonomy can be compared. The gold stan-dard can be an taxonomy itself, but also, for instance, a set of documents covering the domain in question. The key issues hereby are how to assess the quality of the gold-standard itself, and the establishment of valid comparison measures.

Comparing the paradigms, Dellschaft [2005] concludes that only reference-based methods are practically feasible for large-scale and frequent evaluation. We will adopt this approach as an initial semantic evaluation methodology in the scope of our work. As an additional check for the validity of this methodology in the context of our work, we also performed a human subject experiment where we asked human subjects to judge the quality of a subset of learned hierarchical relationships. We will now first provide details on the reference-based evaluation, and then explain the setup of our human subject experiment. When adopting a reference-based evaluation paradigm, it is a nontrivial task to judge the similarity between a learned concept hierarchy and a reference hierarchy, espe-cially regarding the absence of well-established and universally accepted evaluation measures. This typically requires researchers to find answers to at least two cru-cial questions: (i) Which reference (gold-standard) ontology to choose, and (ii) which measure to use to compute the similarity between the learned and the gold-standard ontology. In order to support a comparative evaluation of all the folksonomy induc-tion algorithms presented earlier, we have chosen a set of rather general reference datasets; that is, taxonomies derived from WordNet, Yago and Wikipedia (see below). The reason for that lies in the significant vocabulary overlap that we found between the folksonomies and these reference datasets. Other reference datasets, such as Music-Moz 2 or the ACM Classification Schema, 3 did not produce sufficient vocabulary overlap for comprehensive evaluation. Particular vocabulary matching scores are presented in Table IV. In the following, we briefly describe each of the gold standard taxonomies used in our work, and then proceed with the presentation of the evaluation measures adopted by this article.  X  WordNet [Miller 1995] is a structured lexical database of the English language. It contains roughly 203.000 terms grouped into 115.400 synsets. Among the synsets, several relations are defined; one of the most important ones is the taxonomic rela-tion. As a first gold standard, we extracted the taxonomic hierarchy among synsets in WordNet.  X  Ya g o [Suchanek et al. 2007] is a large ontology which was derived automatically from Wikipedia and WordNet. Manual evaluation studies have shown that its pre-cision (i.e., the percentage of  X  X orrect X  facts) lies around 95%. It has a much higher coverage than WordNet (see Table II), because it also contains named entities like people, books or products. The complete ontology contains 1.7 million entities and 15 million relations; as our main interest lies in the taxonomy hierarchy, we restricted ourselves to the contained is-a relation 4 among concepts.  X  The  X  X ikitaxonomy X  [Ponzetto and Strube 2007] is the third dataset used for eval-uation. This large scale domain independent taxonomy 5 was derived by evaluat-ing the semantic network between Wikipedia concepts and labeling the relations as isa and notisa , using methods based on the connectivity of the network and on lexico-syntactic patterns. It contains by far the largest number of lexical items (see Table II), but this comes at the cost of a lower level of manual control.

Starting from several gold-standard taxonomies, the next task is to judge the sim-ilarity between a learned taxonomy F and a reference taxonomy T . Finding a uni-versally applicable, valid similarity score for two (possibly very large) hierarchical structures is nontrivial. Yet, a number of useful measures have been proposed by past research. Dellschaft and Staab [2006], for example, propose two measures, that is, taxonomic precision and taxonomic recall for this purpose. The basic idea is hereby to find a concept c present in both taxonomies, and then to extract a characteristic ex-cerpt (consisting for instance, from the sub-and super-concepts) from both taxonomies, that is, ce ( c , F )and ce ( c , T ). If both excerpts are very similar, then the location of the concept c in both taxonomies is similar. Hence, taxonomic precision and recall have a local part tp and tr , respectively, according to:
Then all local values are summed up over the concept overlap between both struc-tures according to:
Whereby C F denotes the set of concepts in the learned folksonomy and C T the set of concepts of the reference taxonomy. TR is computed analogously. Finally the taxo-nomic F-measure is computed as the harmonic mean of taxonomic precision and recall
The same idea underlies the measure of taxonomic overlap proposed by Maedche [2002]; its local and global part are computed according to: In all cases, an important aspect is the composition of the characteristic excerpt ce . A common approach is to choose the semantic cotopy [Maedche 2002], which consists of all sub-and superconcepts of a given concept c and the concept itself. Because all local measures tp , tr and to are based on the intersection of excerpts, adding the concept c has an especially strong effect when the average size of the excerpts is small, which happens, for instance, in rather shallow hierarchies. We first used the semantic cotopy as characteristic excerpt, but with limited success; 1 because especially the randomly generated folksonomies were strongly favored by this method due to their inherent shallow structure. For this reason, we used another excerpt, that is, the common semantic cotopy (as defined in Dellschaft and Staab [2006]). It basically contains the sub-and superconcepts of c which are present in both taxonomies, but excluding the concept c itself. This choice eliminates the problematic  X  X rivial hit, X  leading to much more useful results.

While these measures have not been applied widely, they are theoretically sound and interesting. This makes them promising candidates for the folksonomy evaluation study at hand. We will adopt all measures for our evaluation, that is, taxonomic pre-cision, recall, F1-measure and overlap. As an additional check for the validity of these measures, we performed a small human subject experiment, which will be introduced next. Although the human ability to interpret and integrate information in a meaningful way can surely be seen as superior to current automatic approaches, the task of eval-uating the  X  X uality X  of a learned hierarchical structure remains challenging even for skilled subjects. Especially the manual comparison of two (potentially very large and complex) taxonomies will probably not lead to consistent and reproducable evaluation results. For this reason, we have chosen a simpler approach targeted towards the as-sessment of the consistency of each learned taxonomy. Our basic idea hereby was to sample a subset of all direct taxonomic subsumption pairs from a learned hierarchy, and then to let humans judge if (and if yes, how) the two contained terms are related. We used a web interface to present each human subject one term pair ( A , B )atatime, asking  X  X hat X  X  the relation between the two terms A and B? X  As an answer, the subject could choose between selecting one of the following options: (1) A is the same as B. (2) AisakindofB. (3) A is a part of B. (4) A is somehow related to B.
 (5) A is not related to B. (6) I don X  X  know the meaning of A or B.

In order to allow as many meaningful answers as possible from a broad audience, we performed an a-priori filtering of the term pairs by a list of  X  X ommon X  words, namely, the 5.000 nouns which were used most often in the Brown corpus. 6 We only kept those pairs ( A , B ) as candidates for the study where both terms A and B were present in this list of popular nouns.

The intuition behind this approach is that a  X  X etter X  taxonomy will yield a lower percentage of pairs being judged as unrelated. The reason why we allowed for a further distinction of relations (i.e.,  X  X ame as, X   X  X ind of, X   X  X art of, X  and  X  X omehow related X ) is that we do not expect our analyzed algorithms to produce exclusively semantically sharp taxonomic (i.e.,  X  X ind of X ) relations. Our semantic evaluation methodology will be complemented by pragmatic evaluation measures, which are introduced next. While semantic evaluation of hierarchical structures in social tagging systems has re-ceived some attention in the literature, pragmatic (i.e., task-oriented) evaluation rep-resents a new aspect [Helic and Strohmaier 2011; Helic et al. 2011]. In the following, we introduce a novel way to evaluate the usefulness of folksonomies for user tasks in social tagging systems.

One way of assessing the suitability of folksonomies in supporting user tasks is to assess their usefulness for searching or navigating social tagging systems. Follow-ing this line of thought, we can measure the extent to which a folksonomy aids a user in navigating the system. This is the approach employed in this article. Instead of observing real user behavior, our method of choice is simulation, mainly because current tagging systems do not adopt folksonomy-based navigational support yet and simulation provides us with better experimental control and thus makes it possible to evaluate different folksonomy constructing algorithms across multiple datasets. In the following, we shortly introduce our simulation model and its theoretical background. One of the research questions attracting a lot of interest in the field of networks is the relation between network structure and function, such as the relation between the structure and routing function of a network. Ever since the  X  X mall world X  experiment [Milgram 1967] conducted by Stanley Milgram, researchers have been intrigued by the routing efficiency or navigability question in social networks: how people are able to find unknown people who are, potentially, geographically and socially distant to them-selves. The key aspect of this question is the absence of the global knowledge of the network: people know only their friends and therefore posses only the local knowledge of the network but are still able to find unknown people. Similar navigability has been observed in other real networks such as metabolic or neural networks, or has been an important design goal for engineers of communicational networks such as the In-ternet or different peer-to-peer networks [Adamic et al. 2001]. Researchers identified the concept of similarity between nodes [Leicht et al. 2006; Menczer 2002; Watts et al. 2002] or more generally the concept of distance between nodes [Adamic and Adar 2005; Kleinberg 2000a, 2000b, 2001; Watts et al. 2002] as an important aspect of establish-ing networking navigability. Combining the notion of distance between nodes with the algorithmic term of greedy routing [Kleinberg 2000b], Kleinberg [2000a, 2001] theoret-ically explained network navigability in the following way: nodes use distance to select the next node in a routing session and the greedy algorithm selects the adjacent node closest (with the smallest distance) to the current destination node. The algorithm and its applications have been studied in the recent literature [Kleinberg 2006].
Serrano et al. [2008] abstract the notion of distance as introduced by Kleinberg to a hidden distance between nodes. Hidden distances define a hidden metric spaces which governs not only routing in the network but also the network formation and emer-gence of network structural properties such as power-law degree distributions and high node clustering. The authors connect observable emergent structural properties of a network with its navigability by defining a region of navigable networks in two di-mensional space with clustering-coefficient [Watts and Strogatz 1998] and power-law exponent as dimensions. On the other hand, a hidden metric space is also a geometric entity in which nodes are identified by their coordinates in it; distance between nodes is their geometric distance in that particular metric space. An interesting research question is the structure of such hidden metric spaces that underlie observable net-works. Bogu  X  n  X  a et al. [2009] introduce a model with the circle as a hidden metric space and show its effects on routing in the global airport network. Krioukov et al. [2010] discuss hyperbolic geometry as a hidden metric space whereas Bogu  X  n  X  a et al. [2010] apply hyperbolic geometry as a model of the hidden metric space of the Internet and design a novel greedy Internet routing algorithm.

The relation between Kleinberg X  X  node distance and the recent work on hidden met-ric spaces can easily be established. In Kleinberg X  X  model, the nodes are organized into a hierarchy according to their similarity: the distance between two nodes corresponds then to the height of their least common ancestor in that hierarchy [Kleinberg 2001] (Adamic and Adar [2005] and Watts et al. [2002] have similar distance definitions that are also based on the node distance in one or more hierarchies). Hyperbolic geometry, as well as a hierarchy, distribute distances exponentially; it is, therefore, possible to approximate a hyperbolic metric space by a tree [Krioukov et al. 2010]. In the first step of our folksonomy evaluation, we generate tag-to-tag networks from different tagging datasets. We adopt a model of a tagging dataset as a tripartite hypernetwork with V = R  X  U  X  T , where R is the resource set, U is the user set, and T is the tag set [Cattuto et al. 2007; Ramezani et al. 2009; Schmitz et al. 2006]. An annotation of a particular resource with a particular tag produced by a particular user is a hyperedge ( r , t , u ), connecting three nodes from these three disjoint sets. Such a tripartite hypernetwork can be mapped onto three different bipartite networks connecting users and resources, users and tags, and tags and resources, or onto, for instance, tag-to-tag networks. For different purposes it is often more practical to analyze one or more of these networks. For example, in the context of ontology learning, the bipartite networks of users and tags has been shown to be an effective projection [Mika 2007]. In this article, we focus on navigating the tag-to-tag network (based on a tag-to-resource network), to mimic a tag-based user navigation task.
In the second step, we construct different folksonomies from a number of tagging datasets, where we apply the algorithms that we have introduced in Section 2.
In the final step, we adopt a folksonomy as a particular incarnation of a hidden metric space. We simulate greedy routing through the observable tag-to-tag network querying the folksonomy for node distances; the idea is that greedy routing will be more successful if the coordinates imposed by a folksonomy are closer to the real hid-den metric space of the network in question. We quantify the quality of a folksonomy by measuring the success rate of the greedy algorithm (the number of successfully reached destination nodes divided by the total number of routing sessions), and by the stretch, which is the ratio of the average greedy hops to average shortest paths (this measure tells us how longer are greedy paths as compared to global shortest paths). The measures are similar to those introduced in Bogu  X  n  X  a et al. [2010]. In addition to the global values calculated in Bogu  X  n  X  a et al. [2010], we calculate the measures for each observable shortest path in the networks. The folksonomies that perform better, that is, folksonomies where the success rate is higher better reflect the underlying hidden metric space and therefore are more suitable for instructing greedy routing. Stretch value is a control value: achieving values close to 1 means that folksonomies are good at finding shortest paths quickly, that is, in an almost optimal way. On the other side, high strecth values, for instance, 2 or more would mean that greedy search takes often suboptimal paths and that the folksonomy in question does not represent the hidden metric space optimally. Without making assumptions about actual user behavior, we can conclude theoretically that better performing folksonomies would provide a better navigation support for users. We leave the task of testing whether this conclusion also holds in practice, for instance, with actual user behavior, to future work. In our experiments, we apply 4 folksonomy induction algorithms (from 3 distinct classes) to five different social tagging systems yielding 20 different folksonomies. We evaluate these 20 folksonomies on a semantic level against 3 reference datasets, and on a pragmatic level against the task of navigation on the underlying tag network structure. The detailed experimental setup is presented next. Data from the following social tagging systems was used as an empirical basis (see Table III for an overview).  X  Dataset BibSonomy . This dataset 7 contains nearly all 916,495 annotations and 235,340 unique resources (scientific articles) from a dump of BibSonomy [Hotho et al. 2006a] until 2009-01-01. The tag-tag network comprises 56,424 nodes and 2,003,986 links.  X  Dataset CiteULike . This dataset contains 6,328,021 annotations and 1,697,365 unique resources (scientific articles) and is available online. 8 The tag-tag network consists of 347,835 tags and 27,536,381 links.  X  Dataset Delicious . This dataset is an excerpt from the PINTS experimental dataset 9 containing a systematic crawl of Delicious and Flickr in 2006 and 2007. We ex-tracted all data from November 2006. The resources in this dataset are Web ad-dresses. The tag-tag network consists of 380,979 tags and 39,808,439 links.  X  Dataset Flickr . This dataset is also an excerpt from the PINTS Flickr crawls. It contains the data from December 2005. The resources in Flickr are user-generated photos. The tag-tag network consists of 395,329 tags and 17,524,927 links.  X  Dataset LastFm . This dataset is from Schifanella et al. [2010]. It contains annota-tions that were crawled from the last.fm website in the first half of 2009. The re-sources in this dataset are songs, artists and albums. The tag-tag network consists of 281,818 tags and 84,787,780 links. While our reference-based semantic evaluation adopts the measures presented in Section 3.1, for the human subject experiment we first extracted all subsumption pairs containing  X  X ommon X  terms (as described also in Section 3) present in each folksonomy induced from the Flickr dataset. We focussed on this dataset because its scores in the reference-based evaluation were comparatively high, and data from this system was used in related work on folksonomy induction before [Plangprasopchok et al. 2010a]. From the resulting sets of candidate pairs, we randomly selected 25 pairs for each folksonomy induction algorithm under consideration, leading to 125 term pairs. As a control condition, we also added 25 term pairs randomly sampled from one of our ref-erence hierarchies (namely the WordNet noun taxonomy), leading to a total number of 150 term pairs to be judged for each of our subjects. We then sent a link 10 pointing to the online study to students and staff from our two IT departments. In summary, 27 persons took part in the evaluation. Because some of them did not completely finish the rating of all pairs, we received 3,381 votes, including 249  X  X on X  X  know X  choices, lead-ing to a total of 3,132 useful answers for our study. In order to consider only pairs for which we have a sufficient amount of votes, we only included those tag pairs for which at least 18 subjects had provided useful answers. This left us with a final set of 128 term pairs. For each term pair, we computed the fraction of each possible judgement, and averaged these values subsequently over each folksonomy induction algorithm. Figure 4 shows the results. Apart from this, pragmatic evaluation was adopted in the following way: With greedy search we model and then simulate navigation in tagging systems. We se-lect 100,000 resource nodes uniformly at random from the bipartite tag-to-resource tagging network. Each of these nodes represents a starting node for decentralized search, modeling an arbitrary user entry page into the system (e.g., a landing page from a search engine, the latest resource from a news feed, homepage, or similar). We assume that users who come to the tagging system would explore the system to find one or more related topics or resources of current interest. To model this, we select an-other resource node from the tagging network uniformly at random. Tags associated with the second resource are both related to each other (they overlap at least at the second resource) and represent a collection of related resources that a user might be interested in. We define the set of resources connected by those tags as target nodes for the greedy search. The goal of the agent is to find a short path from the starting node to one of the target nodes in the search pair.

We use length of the shortest path as the reference point in the evaluation. This reflects a typical scenario of navigation in tagging systems: the user will explore the tagging system by navigating to find relevant topics and resources as quickly as pos-sible, that is, with as few clicks as possible. We calculate the global shortest path between nodes from each search pair using breadth first search. If there is no global path between nodes from a pair (i.e., when one of the target nodes does not belong to the giant component) then this node is removed from future calculations.

The folksonomy is applied as a hidden metric space to provide the distance between nodes. Although search starts at a resource node, as soon as the first tag is selected, the search becomes a search in the tag-to-tag network. Search is considered successful if the algorithm finds at least one of the target tags. To model users behavior during navigation we apply the following strategy: if the agent arrives at a certain node for the second time, the search stops and is counted as a failure (no backtracking); this mimics the situation where a user arrives at a tag that he has already visited, and then decides to, for instance, switch to the search field or to leave the system. The success rate s of the greedy search thereby provides an answer to the question of the pragmatic suitability of a folksonomy to support navigation. In addition to the success rate we calculate so-called stretch  X  [Krioukov et al. 2010] with h (average greedy hop length) and l (average shortest path length) as:
To obtain a baseline (a lower bound) for the performance of a particular folksonomy, we also apply a random folksonomy as a hidden metric space. The results of applying semantic and pragmatic evaluation are introduced next. As a first result, we present the vocabulary overlap between concepts present in the folksonomies and those in selectedreference datasets (see Table IV). While the overlap is significant for WordNet, Yago, and Wikitaxonomy, it is extremelysmall for ACM and MusicMoz. Due to the small overlap, we discarded ACM and MusicMoz from all subsequent investigations,and focused our evaluations on WordNet, Yago, and Wikitaxonomy.

Figure 3 displays the results of the reference-based semantic evaluation. On the y-axis of each figure, the similarity between each folksonomy and a reference gold-standard taxonomy is depicted. We measure similarity using different measures, in-cluding taxonomic precision (TP), taxonomic recall (TR), taxonomic F1-measure (TF) and taxonomic overlap (TO). As explained in Section 3.1, all these measures are based on the comparison of  X  X haracteristic excerpts X  from both hierarchical structures. The local values are then summed up and averaged into a global value.
 At a first glance, the results from our experiments convey a consistent picture: Taking the taxonomic F1-measure (black bars) as an example, one can observe that across almost all experimental conditions the folksonomies induced by generality-based methods (Clo/Cos and Deg/Cooc in the figures) outperform the clustering-based ones (Affprop and Kmeans). A similar distribution is found for the other measures (TP, TR and TO). In all cases, the folksonomy induced by the random algorithm performs worst and yields a similarity score of close to zero.
 A slight exception to these first observations are the folksonomies induced from the LastFM dataset (lowermost row), for which, for instance, affinity propagation slightly outperforms the generality-based Clo/Cos algorithm. However, the general level of similarity is much lower for all folksonomies based on this dataset. We attribute this to the fact that the LastFM dataset has a relatively strong topical focus, that is, the tag-ging of music-related items like songs, artists or albums. Our choice of gold-standard taxonomies, however, was targeted towards topically more general hierarchies in order to enable a comparison across diffferent datasets. Our results suggest that this choice makes sense for thematically  X  X eneral-purpose X  tagging systems like BibSonomy, Ci-teULike, Delicious or Flickr, but is less well-suited for more specific ones like LastFM. We also experimented with domain-specific taxonomies like the ACM Computing clas-sification system 11 which might be better suitable for BibSonomy and CiteULike, as well as with a music genre taxonomy derived from MusicMoz 12 fitting obviously to LastFM; but due to the relatively small lexical overlap, we also had limited success to this end. Hence we will focus in the remaining discussion of the results on our more general datasets (topmost four rows).

A conclusion that can be drawn from these empirical results is that the cluster-ing techniques we investigated seem to produce folksonomies which exhibit a smaller degree of similarity to gold-standard taxonomies than techniques based on term gen-erality. Especially the folksonomies produced by taking degree centrality as general-ity measure and cooccurrence as similarity measure seem to resemble most closely to the reference taxonomies. This is an interesting observation, especially regarding that these measures are computationally much more lightweight compared to, for instance, closeness centrality, cosine similarity or elaborate clustering mechanisms. We have also tried other parameter settings for K-means (different k X  X ) and did not observe a substantial difference.

When comparing the clustering techniques, it seems that affinity propagation has a slight advantage over k-means, however, to a much lesser extent than the difference to the generality-based methods. An open question which remains is how to interpret the absolute similarity values, or in other words: Is, for instance, a score of 0.02 cap-tured by the taxonomic F1-measure an indication of a  X  X trong X  similarity between the learned and the reference taxonomy? Due to the complexity and the size of the involved structures, it is difficult to make a clear decision to this end. Because the values are averaged over the complete concept overlap, it is possible that some branches are very similar, while others are not. In order to facilitate a better understanding of the  X  X rue X  quality of the learned folksonomies, we also performed a small-scale human subject experiment, whose results will be discussed next.

Figure 4 summarizes the results of this experiment involving the human assess-ment of folksonomies induced on the Flickr dataset. The topmost five rows corre-spond to the algorithms used, while the lowermost row is a control condition based on the WordNet noun taxonomy. The values on the y-axis depict the average fraction of choices for each possible answer; as an example, among all judgements on subsump-tion pairs produced by affinity propagation, the average fraction of  X  X art o X  answers was roughly 5,8% (0.058, black part of the uppermost bar). Please note that only  X  X osi-tive X  answers are included in this plot (i.e., answers stating that there is a meaningful relation among two terms). However, the percentage of  X  X egativ X  answers (i.e., explicit statements by the users that two terms are not related) can be deduced from the figure by subtracting the sum of positive votes from 1. As an example, for affinity propaga-tion we received a fraction of roughly 59% (0.59, topmost row, average) of  X  X ot relate X  answers for each pair. So as a short statement, one can say that the  X  X onger X  the bars are, the higher is the quality of the corresponding folksonomy.

To start with the lower and upper bounds, the folksonomy produced by the random algorithm performs worst; all  X  X ositive X  relation judgements are adding up to roughly 0.2. On the contrary, the control judgements on the WordNet noun taxonomy sum up to  X  0.82, including a large portion (  X  0.42) of  X  X ind of X  answers. So as a first observation, we can say that the random folksonomy was judged to be the worst and the WordNet noun taxonomy was judged to be the best hierarchy, which confirms our intuition and validates our experimental methodology. In between these bounds, the sum of positive votes seems to confirm the impression from the reference-based evaluation: Again, the two generality-based methods yield a higher percentage of positive votes compared to the two clustering approaches. Despite this fact, taking a more detailed look one can also see that the percentage of  X  X ind of X  and  X  X art o X  votes (which are semantically more precise compared to  X  X omehow related X ) is highest for the KMeans clustering al-gorithm. This could of course be an artifact of sampling, but could also point towards a greater semantic precision of the folksonomy induced by KMeans clustering. However, taking a closer look at the  X  X omehow relate X  pairs, it turns out that despite their lesser degree of semantic preciseness, the obtained relations can still be useful especially for organizational purposes of a category hierarchy (e.g.,  X  X ot/stove X ). In light of these ob-servations, the results of the human subject experiment can be seen as a confirmation of the validity of the measures we used in our reference-based evaluation setting.
So in summary, the results of our semantic evaluation suggest that the generality-based algorithms we analysed lead to folksonomies which capture a higher amount of meaningful semantics compared to the ones obtained by clustering algorithms. This insight will now be complemented by the results of the pragmatic evaluation. The results of pragmatic evaluation are depicted in Table V and Figure 5. As a base-line, we perform exploratory navigation with a randomly generated folksonomy to obtain a lower bound. We can assert that the cause why an agent using a random folk-sonomy as hidden metric space finds considerable short paths is because tagging net-works are highly connected and have a low effective diameter ( &lt; 3 . 5) [Helic et al. 2010]. Due to high link density, the majority of tags are connected by multiple short paths. That means that even if the agent takes a single nonoptimal or wrong link towards the destination tag, with high probability there exists an alternative link which also leads to the destination tag. In particular for the (global) shortest path of 2, an agent using a random folksonomy is considerably successful in finding short path, regardless of the first tag selected, that tag is in the majority of cases linked to the destination tag. How-ever, as the path towards the destination becomes longer (  X  3) the ability of an agent using a random folksonomy as hidden metric space deteriorates. The LastFM dataset exhibits even more extreme behavior in this respect; since tags in this dataset are mu-sic genres, the overlap in certain resources seems to be extremely high. However, for agents it is possible to find the shortest paths or alternative short paths with the given folksonomies. Across all datasets, we see that agents using folksonomies produced by the introduced algorithms find significantly shorter paths than when using a random folksonomy.
 Structurally, the hierarchies generated with K-Means are typically unbalanced. We performed additional experiments to introduce a balancing factor to resolve these structural issues to obtain more balanced clusters. However, preliminary results show that this approach improves the success rate of greedy search only marginally (the success rate could be improved by 1% for the BibSonomy dataset), and thereby does not seem to have a significant impact on the validity of our results.

A problem with Aff. Prop. seems to be the choice of the cluster representative. In the current implementation, the cluster representative is chosen by taking the nearest sample to the centroid. As the similarities in tagging datasets are often small and sparse, the similarities between cluster members are equal, and thus the selection of the cluster representative is completely arbitrary. The same issues seem to influence the construction of the hierarchy that is based on the similarity between the centroids of the previous execution steps. One possible remedy for this could be to use an average similarity of connected data samples. An advantage of Aff. Prop. is that on the upper hierarchical levels, the algorithm produces broader structures than, for example, K-Means, which seems to make them more suitable for navigation.

Summarizing, hierarchical clustering methods seem to lack additional information about the dataset as given by the tag similarity network and centrality ranking. Note that while Heymann and Garcia-Molina [2006] came to a similar conclusion based on intuition, our article provides an empirical justification for this.

There are no significant differences in performance of DegCen/Cooc and CloCen/Cos combinations of the centrality and similarity measures. We have performed addi-tional experiments and produced folksonomies by combining betweenness central-ity and cooccurrence as well as closeness centrality and cooccurrence. The choice of centrality or similarity measure does not significantly influence performance. Any combination of these two measures perform similar. 6.2.1. K-Means Variations. To further investigate the reasons for a bad performance of hierarchical clustering algorithms we produced folksonomies with another variation of the K-Means algorithm. The results presented so far have been produced by the K-Means algorithm operating in batch mode. We also produced K-Means folksonomies operating in online mode (i.e., incremental additions). Figure 6 shows the simulation results with the BibSonomy dataset. There are no significant differences in the perfor-mance of those two algorithm variations. The simulations with other datasets produce comparable results; across all datasets there are no significant differences in perfor-mance between the batch and online K-Means algorithm variations. 6.2.2. Cluster Size. We also investigated the effects of cluster size (the choice of k) on the performance of K-Means folksonomies. To that end, we produced further folk-sonomies using online K-Means with k =20and k =30astheclustersize. Figure7 shows the results of pragmatic evaluation for our BibSonomy dataset with varying k. The plot shows that there is little or no influence on the performance of folksonomies generated with different k X  X . Comparable results have been obtained on our other datasets, which suggests that the choice of k X  X ithin the limits of our experiments X  X s not a confounding factor for evaluation. 6.2.3. Alternative Pragmatic Metrics. In addition to success rate and stretch, the useful-ness of folksonomies can be evaluated with other pragmatic evaluation metrics as well. For example: When a user navigates to a target tag, we can calculate how hard it is for the user to identify the target resources among the tags presented to her in the last step of navigation. The last step of navigation represents a situation where the user is just one-click away from her set of target resources. A useful metric to capture this problem is precision, which we define as the number of relevant resources divided by the number of total resources presented to the user for a given tag. We define relevant resources as all resources tagged by all of the target tags. We can simulate this by letting a greedy agent navigate the tagging system, and then calculate the fraction of greedy paths which go trough the best precision tag for all algorithms and datasets at step n-1 (the last step before the agent reaches his target). The outcome of this exper-iment is presented in Figure 8. Our results are consistent with the results obtained from applying our other pragmatic evaluation metrics (stretch, success rate): The folk-sonomies obtained from tag similarity networks outperform the other approaches. To the best of our knowledge, this article represents the most comprehensive attempt at evaluating state-of-the-art folksonomy induction algorithms both empirically and via simulation to date. Based on a review of existing measures for semantic folkson-omy evaluation, we have selected a subset and applied it to 20 folksonomies created from 5 social tagging system datasets. The results of our semantic evaluation show that folksonomy induction algorithms specifically developed for social tagging systems outperform algorithms based on traditional hierarchical clustering mechanisms con-sistently across most datasets. However, the results of the reference-based evaluation have shown to be somewhat sensitive towards the composition of the characteristic excerpts used by existing taxonomy similarity measures. Our particular composition of excerpts however painted a clearer picture of the usefulness of different folksonomy induction algorithms. An assessment of the induced folksonomies by human subject confirmed the validity of our reference-based evaluation. In addition, we have pre-sented a new pragmatic evaluation method that compared the 20 folksonomies from a navigation-oriented perspective. The results obtained from pragmatic evaluation are consistent with the semantic evaluation: Again, generality-based approaches tailored towards the characteristics of social tagging systems show a superior performance compared to clustering algorithms. In summary, our work sheds new light on the properties and characteristics of state-of-the-art folksonomy induction algorithms and introduced a new pragmatic approach to folksonomy evaluation, while at the same time identifying some important limitations and challenges of evaluating hierarchical structures in information systems in general.

