 Social media such as blogs, Facebook, Flickr, etc., presents data in a network format rather than classical IID distri-bution. To address the interdependency among data in-stances, relational learning has been proposed, and collec-tive inference based on network connectivity is adopted for prediction. However, connections in social media are often multi-dimensional. An actor can connect to another actor for different reasons, e.g., alumni, colleagues, living in the same city, sharing similar interests, etc. Collective inference normally does not differentiate these connections. In this work, we propose to extract latent social dimensions based on network information, and then utilize them as features for discriminative learning. These social dimensions describe diverse affiliations of actors hidden in the network, and the discriminative learning can automatically determine which affiliations are better aligned with the class labels. Such a scheme is preferred when multiple diverse relations are as-sociated with the same network. We conduct extensive ex-periments on social media data (one from a real-world blog site and the other from a popular content sharing site). Our model outperforms representative relational learning meth-ods based on collective inference, especially when few labeled data are available. The sensitivity of this model and its con-nection to existing methods are also examined.
 H.2.8 [ Database Management ]: Database applications X  Data Mining ;J.4[ Social and Behavioral Sciences ]: So-ciology Algorithm, Experimentation Social Dimensions, Behavior Prediction, Social Media, Re-lational Learning, Modularity
Social media, in forms of Web 2.0 and popular social net-working sites like Facebook, Flickr, Youtube, Digg, Blog, etc., is reshaping various fields including online business, marketing, epidemics and intelligence analysis. Concomi-tant with the opportunities indicated by the rocketing online traffic in social media 1 are the challenges for user/customer profiling, accurate user matching at different domains, rec-ommendation as well as effective advertising and marketing. Take blogsphere as an example. Bloggers can upload tags for their own blog sites. The tags of a blog site provide the description of the blogger, facilitating blog search, retrieval and other tasks. Unfortunately, not all the bloggers provide tags; even if some do, they may just choose some for conve-nience. Thus, it becomes a challenge to infer the likely tags of those bloggers with partial information.

Another problem is social networking advertising. Cur-rently, advertising in social media has encountered many challenges 2 . A recent study 3 from the research firm IDC sug-gested that  X  X ust 57% of all users of social networks clicked on an ad in the last year, and only 11% of those clicks lead to a purchase X . Note that some social networking sites can only collect very limited user profile information, either due to the privacy issue or because the user declines to share information. On the contrary, the friendship network is nor-mally available. If one can leverage a small portion of user information and the network data wisely, the situation might improve significantly.

Both aforementioned two problems can be considered as a classification problem. Consider the tags in blogosphere and user interests as labels, the key task boils down to classify-ing users into relevant categories. Note that in both cases, some labeled data are readily available: a) In blogosphere, some bloggers do provide accurate and descriptive tags; b) For social networking advertising, online activities of users such as clicking on an ad or purchasing a product reflect the users X  potential interests. In reality, this kind of label information is very limited compared with the whole user population. Different from conventional data mining where data are assumed to be independently identically distributed (IID), the data here (specifically, the actors) are connected in a network. So the key problem is how we can leverage the http://www.techcrunch.com/2008/12/31/top-social-media-sites-of-2008-facebook-still-rising/ http://www.nytimes.com/2008/12/14/business/media/ 14digi.html http://www.nytimes.com/2008/12/01/technology/internet/ 01facebook.html
Figure 2: A Snapshot of Node 1 X  X  local Network social network information for accurate classification when limited label information is available.

Social networks do provide some valuable information thr-ough homophily [22].  X  X irds of a feather flock together. X  It is observed that similarity breeds connections in real-world social networks. In terms of social media, actors sharing some interests tend to interact with each other, thus leading to autocorrelations between the labels of connected actors. Relational learning (within-network classification) [21, 10] has been proposed to capture the correlations between con-nected objects. Specifically, if there is only one network among data objects, one basic Markov assumption [21] is that the label of one node is dependent on that of its neigh-bors. For prediction, collective inference is required to find an equilibrium status such that the inconsistency between neighboring nodes is minimized. This is normally done by iteratively updating labels or class membership of one node while fixing the other nodes in the network. Relational learn-ing with collective inference has been shown to outperform models that do not consider the connectivity information [4, 33, 24].

One limitation of collective inference models is that they treat the connections in the network homogeneously. In the real world, various reasons lead to heterogeneous con-nections. People connect to each other because they are colleagues, classmates, friends, or share similar interest or political views. Currently, most collective inference models do not differentiate the connections between actors and this might blur the class membership of actors in the network. To give a palpable understanding, let us look at a toy example in Figure 1. Actor 1 connects to Actor 2 because they work in the same IT company, and connects to Actor 3 because they often meet in the same sports club. Given the label in-formation that Actor 1 is interested in both Biking and IT Gadgets, can we infer Actor 2 and 3 X  X  labels? Treating these two connections homogeneously, we guess that both Actors 2 and 3 are also interested in biking and IT gadgets. But if we know how Actor 1 connects to other actors, it is more reasonable to conjecture that Actor 2 is more interested in IT gadgets and Actor 3 likes biking.

The above example is ideal since the cause of connections is explicitly known. But this kind of information is rare in real-world applications, though some social networking sites, like Facebook, do ask how two get to know each other when user adds a friend. Most of the time, only the net-work connectivity (as in Figure 2) is available. If we can somehow differentiate the connections into different affilia-tions as shown in Figure 3, then we can possibly infer the class membership of each actor more precisely. Notice that Actor 1 is presented in multiple different affiliations. This is consistent with the multi-facet property of human nature.
Given limited information and the network connectivity, differentiating the connections into different affiliations is by no means an easy task as the same actor is involved in multiple affiliations. Moreover, the same connection can be associated with multiple affiliations. For instance, one can connect to another as they are colleagues and also go to the same sports club frequently. Instead of capturing affili-ations among actors via differentiating connections directly, we resort to latent social dimensions, with each dimension representing a plausible affiliation among actors.
In this work, we present a rel ational learning framework based on latent social dimensions. Each dimension can be considered as the description of a likely affiliation between social actors. With these social dimensions, we can harness the power of discriminative learning such as SVM or logistic regression to automatically select the relevant social dimen-sions for classification. In the prediction phase, different from existing relational learning methods, collective infer-ence becomes unnecessary as the selected social dimensions have already included the relevant network connectivity in-formation. This proposed framework is flexible and allows for the combination of other features such as user profiles or social content information.

Different from existing relational learning works, which often concentrate on entity resolution, web page or publi-cation classification, we specifically focus on classification associated with social media where the network is noisy and typically has a composite of multiple relations among actors. We also study a more complicated situation that each actor can have multiple class labels instead of just one single la-bel [21]. Extensive experiments were conducted on two data sets: one is collected from a real-world blog site and the other from a popular content sharing site. It is demonstrated that network classification with latent social dimensions outper-forms alternative relational learning methods. In addition, we show that latent social dimensions, in conjunction with other features like content or tags extracted from social me-dia, can improve the performance significantly.
In social media, individuals are highly idiosyncratic. Each actor X  X  interest cannot be captured by mere one class. Take Flickr 4 as an example. One user in Flickr subscribes to as many as 4344 interest groups 5 . Rather than concentrating http://www.flickr.com/ http://www.flickr.com/people/8551473@N08/ on univariate cases for classification in network data [21] (each node has only one class label), here we examine more challenging tasks that each node in a network can have mul-tiple labels. The problem we study can be formally described below:
For convenience, we use y i  X  X  0 , 1 } K to denote the class labels associated with node v i . Typically, relational learning makes the following Markov assumption: where N i is a set of  X  X eighbors X  of vertex v i . The neighbors are normally defined as vertices that are 1-hop or 2-hop away from v i in the network [14, 8]. A relational classifier based upon the labels of neighbors can be learned via the labeled vertices V L . For prediction, the constructed relational clas-sifier assigns class labels or update class membership for each node while fixing labels of the other nodes. This process is repeated until convergence. Relaxation labeling [4], iterative classification [19] and Gibbs sampling [9] are the commonly used techniques. Please refer to [21] for details.
The assumption in Eq. (1) is essentially of local depen-dency. It does not capture the weak dependencies between nodes that are not close or directly connected. Expanding the neighbor set can possibly increase the capacity of model-ing complicated dependency if over-fitting is not a concern, but it requires much more computation for the convergence of subsequent collective inference, as the small-world phe-nomenon [34] is almost universally observed in social net-works. Expanding the neighbor set to include nodes that are several hops away would include a large portion of the whole network.
 A social network is often a composite of various relations. One user can connect to his/her friends, alumni, colleagues or family members. He can also connect to other virtual friends if they share some interesting topics. The diversity of connections does not necessarily indicate that two connected users would share certain class label. Relying on network information alone for collective inference cannot distinguish these connections. It becomes a challenge to detect which connections are informative for one class label. This is anal-ogous to the feature selection problem [17] in classical data mining if we were lucky enough to have these connection types. But in reality, this kind of information is rare or not refined enough to be informative. Hence, we aim to identify latent social dimensions which are informative of affiliations among actors. In these dimensions, the weak dependency among  X  X istant X  actors can also be captured. Next, we shall illustrate some principles to extract latent social dimensions and present an algorithm of discriminative relational learn-ing .
The social dimensions extracted from the network should satisfy the following properties:
As introduced above, we aim to extract the social dimen-sions that are indicative of affiliations between actors. Based on homophily[22], similar actors interact at higher rates than dissimilar ones. Thus, actors sharing certain properties tend to form groups with more frequent within-group interac-tions. This naturally connects to one basic task in social network analysis  X  community detection, which aims to find communities that have more frequent within-group in-teraction than between-group interactions. While most com-munity detection algorithms partition the actors into several disjoint clusters, we allow an actor to be involved in different affiliations. Hence, a soft clustering method is adopted.
Many approaches have been developed for clustering on graphs that serve the purpose of social dimension extraction, including graph partitioning [15], latent space model [12, 29], block model [28, 1], spectral clustering [37], etc. In large scale social networks, scale free property [3] is commonly ob-served. In other words, the degree of nodes in a network fol-lows a power law distribution. Modularity [26] is a recently proposed community measure that explicitly takes the de-gree distribution into consideration and has been shown to be an effective quantity to measure community structure in many complex networks [6].

Here, we briefly review the concept of modularity. Con-sider dividing the interaction matrix A of n vertices and m edges into k non-overlapping communities. Let s i denote the community membership of vertex v i , d i represents the degree of vertex i . Modularity is like a statistical test that the null model is a uniform random graph model, in which one actor connects to others with uniform probability. For two nodes with degree d i and d j respectively, the expected number of edges between the two in a uniform random graph model is d i d j / 2 m . Modularity measures how far the inter-action deviates from a uniform random graph wth the same degree distribution. It is defined as: where  X  ( s i ,s j )=1if s i = s j , and 0 otherwise. A larger modularity indicates denser within-group interaction. Note that Q could be negative if the vertices are split into bad clusters. Q&gt; 0 indicates the clustering captures some de-gree of community structure. In general, one aims to find a community structure such that Q is maximized.

While maximizing the modularity over hard clustering is proved to be NP hard [2], a relaxation of the problem can be solved efficiently [25]. Let d  X  Z n + bethedegreeofeach node, S  X  X  0 , 1 } n  X  k be a community indicator matrix de-fined below: and the modularity matrix defined as The modularity can be reformulated as Relaxing S to be continuous, it can be shown that the opti-mal S is the top-k eigenvectors of the modularity matrix [25].
While the interactions matrix A is normally very sparse, the modularity matrix B is dense and cannot be computed andheldinmemoryif n is large (which is typically true for real-world social networks). We could use the power method or Lanzcos method to calculate the top eigenvectors, as it relies only on the basic operation of matrix-vector multi-plication. As the modularity matrix B is the difference of a sparse matrix A and rank-one matrix dd T / 2 m ,wecan calculate the multiplication of B and a vector x as With a simplified matrix vector multiplication without ex-plicitly representing the whole modularity matrix, we are able to calculate the top eigenvectors efficiently for large scale networks using existing numerical software packages.
In this section, we illustrate the detailed procedure of social-dimension-based (SocDim) method for discriminative relational learning. The overall process is shown in Figure 4, which consists of two steps: 1. Extract latent social dimensions based on network con-2. Construct a discriminative classifier . After we extract
One concern with modularity maximization is that the obtained features are not unique. Let S be the extracted features based on Eq (4), and P be an orthonormal matrix such that P  X  R k  X  k ,P T P = PP T = I k .Itcanbeverified that S = SP also maximizes the modularity as: But this does not affect the discriminative learning if a linear SVM is employed. Linear SVM with social dimensions S can be considered as a kernel machine with a linear kernel K = SS T . With an orthogonal transformation P , the new kernel K does not change since: Hence the classifier and the prediction is not affected by the non-uniqueness of Step 1.
In this section, we describe the data we collected for ex-periments and the baseline methods for comparison.
We shall examine how relational learning behaves on real-world social networks. Two data sets are collected: one from BlogCatalog 6 and the other from a popular photo sharing site Flickr 7 .

BlogCatalog A blog in BlogCatalog is associated with various information pieces like the categories the blog is listed under, blog level tags, snippets of 5 most recent blog posts, and blog post level tags. Bloggers submit their blogs to BlogCatalog and specify the metadata mentioned above for improved access to their blogs. This way the blog sites http://www.blogcatalog.com/ http://www.flickr.com/ are organized unde r pre-specified categories. A blogger also specifies his social network of other bloggers. A blogger X  X  interests could be gauged by the categories he publishes his blogs in. Each blogger could list his bl og under m ore than one categories. We pick 39 categories with a reasonably large blogger pool for evaluation purpose. On average each blogger lists their blo g under 1.6 ca tegories.

Flickr It is a popular website to host personal photos uploaded by users and also an online community platform. Users in Flickr can tag photos and add contacts. Users can also subscribe to different interest groups ranging from black and white photos 8 to a specific subject (say bacon 9 ). In our experiments, we randomly pick 195 interest groups as the class labels and crawl the contact network among the users subscribed to these groups. The users with only one single connection are removed from the data set.

Table 1 lists some statistics of the network data. As seen in the table, the connection among the social actors are extremely sparse. The degree distribution is highly imbal-anced, a typical phenomenon in scale-free networks. Both data sets are available from the first author X  X  homepage.
We apply SocDim to both data sets. The number of latent social dimensions is set to 500 and one-vs-rest linear SVM is used for discriminative learning. We also compare SocDim to some representative relational learning methods. http://www.flickr.com/groups/blackandwhite/ http://www.flickr.com/groups/everythingsbetterwithbacon/ In our experiments, actors might have more than one label. Since most methods yield a ranking of labels rather than an exact assignment, a thresholding process is normally re-quired. It has been shown that different thresholding strate-gies lead to quite different performance [7, 32]. To avoid the effect of thresholding, we assume the number of labels on the test data is already known, and check how the top-ranking predictions match with the true labels. Two commonly used measures Micro-F1 and Macro-F1 are adopted to evaluate the classification performance.
In this section, we examine the performance of different relational learning methods. We also investigate whether collective inference is necessary for SocDim and its sensitiv-ity to the latent dimensionality.
Table 2 presents the performance of various approaches for the BlogCatalog data. We gradually increase the number of labeled nodes from 10% to 90%. For each setting, we randomly sample a portion of nodes as labeled. This process is repeated 10 times and the ave rage results are reported. Bold face in the table denotes the highest performance in each column. Clearly, our proposed SocDim outperforms all the other methods. wvRN, as shown in the table, is the runner-up most of the time. MAJORITY performs even worse than RANDOM in terms of Macro-F1 as it always picks the majority class for prediction.

The performance differences between SocDim and other relational learning methods with collective inference, are plotted in Figure 5. As shown in the figure, the link based classifier (LBC) performs poorly with few labeled data. This is because LBC requires to learn a relational classifier on la-beled data before the inference. When samples are few, the learned classifier is not stable and robust enough. This is indicated by the large deviation of LBC in the figure when labeled samples are less than 50%. wvRN is more stable, but its performance is not comparable to SocDim. Even with 90% of nodes being labeled, a significant difference be-tween these two models is still observed.

Meanwhile, the latent group classifier (LGC) performs not so well on BlogCatalog. To make a fair comparison, we also include the case (LGC500) such that the number of clusters is the same as the latent dimensionality (500) in SocDim. But increasing the number of clusters does not affect performance much. SocDim allows the same actor to appear at different latent dimensions, whereas LGC forces each actor to be assigned to only one group. So even with the same discriminative learning procedure, SocDim performs much better than LGC.
Compared with BlogCatalog, Flickr data is in a larger scale with close to 100,000 nodes. In practice, the label information in large scale networks is often very limited. Here we examine some similar cases with few labeled data. We change the training ratio from 1% to 10%. Roughly, the number of labeled actors increases from around 1000 to 10 , 000. The results are reported in Table 3.

It is evident that our SocDim outperforms the other meth-ods almost all the time. Different from BlogCatalog data, LGC is a close runner-up this time. This is because the network is very noisy, as indicated by the poor performance
Figure 8: Collective Inference X  X  Effect on SocDim of most methods. Clustering essentially helps remove such noise and keeps prominent patterns. Due to its discrete property, the performance is inferior to SocDim. Other re-lational learning methods such as wvRN and LBC perform poorly. The LBC fails most of the time (almost like ran-dom) and is highly unstable. This can be verified by the fluctuation of Micro-F1 of LBC. Here, we want to reempha-size that the interactions in real-world networks are highly diverse. Detecting the relevant labels from 195 labels is not an easy task. While alternative relational learning methods fail, SocDim works significantly better than those  X  X traw man X  methods like RANDOM and MAJORITY.
In previous sections, SocDim predicts the labels without collective inference. One natural question is whether collec-tive inference can boost the performance of SocDim? Since wvRN does not build a relational classifier, it becomes tricky to combine social dimensions. Hence, we implement a vari-ant of link-based classifier with relaxation labeling. The dif-ference is that a relational classifier is learned based on the combination of the labeled nodes X  social features and their relational features aggregated from their neighbors.
Figure 8 shows the performance after we combine SocDim with collective inference. Clearly, the social features do help for inference, but collective inference degenerates the per-formance of SocDim instead of improving it. This is consis-tent with our conjecture that latent social dimensions have already encoded the necessary network information. Col-lective inference enforces local dependency, while extracted social dimensions alone are capable of capturing the local and weak distant dependency. Therefore, collective infer-ence becomes unnecessary and we can directly use social dimensions as features for prediction.
In previous experiments, we fix the latent dimensionality to 500 for SocDim. In this section, we examine how the per-formance is affected by the selected number of latent social dimensions. On both data sets, we vary the dimensionality from 100 to 1000 and observe its performance variation. The performance changes on BlogCatalog and Flickr are plotted in Figures 6 and 7, respectively. To make the figures legible, we only plot the cases when 10%, 50% or 90% of nodes in the network are labeled on BlogCatalog and 1%, 5% or 9% of labeled nodes on Flickr.

As seen in the figures, Macro-F1 stabilizes on BlogCatalog after 500 dimensions but increases steadily on Flickr Data. If fewer ( &lt; 300) latent social dimensions are selected, then it might miss some discriminative dimensions thus the perfor-mance deteriorates. A surprising pattern observed on both data sets is that Micro-F1 decreases with increasing latent dimensions. It seems that the dimensionality is a trade-off between Micro-F1 and Macro-F1. We suggest 400  X  600 dimensions as a proper range to use SocDim. One nice property of SocDim is that it is feature-based. Thus, if information is available about the nodes in the net-work (e.g., user profile, social content, or tag information), it is easy to couple the network information and user informa-tion: simply combine the extracted social dimensions with other features, and let the discriminative learning procedure determine which features are more informative of a class la-bel. The combination of network and actors X  features is ex-pected to lead to more accurate classification performance. Here we take BlogCatalog as an example to show the effect.
BlogCatalog provides the snippets of 5 recent posts of bloggers. We use the snippets as content information about the bloggers. The performances of using content or network alone, or the combination of the two are plotted in Figure 9. As the snippets are short and noisy, it is not surprising that the performance based on content alone is even worse than network-based approach. If we combine the social features and the content features, the performance is increased by 2-3%. This is most observable when the labeled data are few.
Relational Learning (network classification) [10, 21] refers to the classification when objects or entities are presented in multiple relations or network format. The data instances in the network are not independently identically distributed (IID) as in conventional data mining. In order to capture the autocorrelation between labels of neighboring data ob-jects, a Markov dependency assumption is forced. That is, the labels of one node depend on the labels (or attributes) of its neighbors. Collective inference [14] is proposed for prediction. Normally, a relational classifier is constructed based on the relational features of labeled data, and then an iterative process is required to determine the class labels for the unlabeled data. It is shown that a simple weighted vote relational neighborhood classifier [20] works reasonably well on some benchmark relational data and is recommended as a baseline for comparison [21]. It turns out that this method is closely related to Gaussian field for semi-supervised learning on graphs [39].

Most relational classifiers only captures the local depen-dency based on the Markov assumption. To capture the long-distance autocorrelation, latent group model [23], and nonparametric infinite hidden relational model [38] assume generative models such that the link (and actor attributes) are generated based on the actors X  latent cluster member-ship. But the complexity and high computational cost for inference hinders its direct application to large networks. So Neville and Jensen in [23] propose to use clustering al-gorithm to find the hard cluster membership of each actor first, and then fix the latent group variables for later infer-ence. In social media, a network is often very noisy. Some nodes do not show a strong community membership and hard clustering might assign them randomly [13]. The resul-tant community structure can change drastically even with the removal of one single edge in the network. Our latent social dimensions are represented as continuous values and allow each node to involve at different dimensions in a flex-ible manner. Conjunction with the discriminative power of SVM, this yields a more accurate and stable performance as verified in the experiments.

Another related field is semi-supervised learning. Some works [18, 5] attempt to address semi-supervised learning with multiple labels by utilizing the relationship between different labels. The relationship can be obtained either from external experts or computed based on the labeled data. But its computational cost is prohibitive. We tried the method presented in [5], which constructs a graph be-tween different labels and then find out an label assignment such that it is smooth on both the instance and the label graph. It requires to solve a Sylvester equation and direct implementation takes extremely long time to find a solution, preventing us from reporting any comparative results.
On the other hand, some papers try to construct kernels based on graphs for SVM. Diffusion kernel[16] is a commonly used one. Unfortunately, it requires full SVD of the graph Laplacian, which is not applicable for large-scale networks. Empirically, the classification performance is sensitive to the diffusion parameter. Cross validation or some variants of kernel learning procedure is required to select a proper dif-fusion kernel [36].

Community detection has been an active field in social network analysis and various methods have been proposed including stochastic block model [28, 1], latent space model [12, 11], spectral clustering [37], hierarchical clustering based on various measures such as shortest-path betweenness [27] or modularity [26, 25]. In our proposed model, community detection could be used as a procedure to extract latent so-cial dimensions. In this work, we adopt modularity as it is specifically designed for social networks. But any other soft clustering methods serve the purpose as well.
Social media provides a virtual social networking envi-ronment. The classical IID assumption of data instances is not applicable. Relational learning based on collective in-ference has been proposed to capture the local dependency of labels between neighboring nodes. However, it treats the connections within the network homogeneously. In reality, the connections within the same network are often multi-dimensional. To capture different affiliations among actors in a network, we propose to extract latent social dimensions via modularity maximization. Based on the extracted social features, a discriminative classifier like SVM can be con-structed to determine which dimensions are informative for classification. Extensive experiments on social media data demonstrated that our proposed social dimension approach outperforms alternative relational learning methods, espe-cially when the labeled data are few. It is noticed that some relational learning models perform poorly in social media data. This is partly due to the multi-dimensionality of con-nections and high irregularity of human interactions in so-cial media. Our approach, by differentiating the connections among social actors, achieves effective learning.
In our current model, the obtained social dimensions are orthogonal to each other. We feel that this orthogonality is not a strictly required component. We are currently inves-tigating fast sparse approximation of social dimensions to avoid the large-scale eigenvalue problem. Sometimes, group profiles [30] are available like the group size, connection den-sity, and shared topics and attributes. How to utilize this group-level information with social dimensions needs more exploration. Another challenge arising in social media re-search is that the network is highly dynamic and might con-sist of multiple entities [31]. Each day, new members join the social network, and new connections are established among existing members. How to efficiently update the relational model in this large scale remains a challenge.
This research is sponsored by the Air Force Office of Scien-tific Research grant FA95500810132. We thank BlogCatalog and Flickr for providing APIs. We also acknowledge Xufei Wang for crawling the data in BlogCatalog and Munmun De Choudhury for her help on Flickr crawling. [1] E. Airodi, D. Blei, S. Fienberg, and E. P. Xing. Mixed [2] U. Brandes, D. Delling, M. Gaertler, R. Gorke, [3] D. Chakrabarti and C. Faloutsos. Graph mining: [4] S. Chakrabarti, B. Dom, and P. Indyk. Enhanced [5] G. Chen, F. Wang, and C. Zhang. Semi-supervised [6] L. Danon, J. Duch, A. Arenas, and A. D  X   X az-guilera. [7] R.-E. Fan and C.-J. Lin. A study on threshold [8] B. Gallagher, H. Tong, T. Eliassi-Rad, and [9] S. Geman and D. Geman. Stochastic relaxation, gibbs [10] L. Getoor and B. Taskar, editors. Introduction to [11] M. S. Handcock, A. E. Raftery, and J. M. Tantrum. [12] P. D. Hoff and M. S. H. Adrian E. Raftery. Latent [13] J. Hopcroft, O. Khan, B. Kulis, and B. Selman. [14] D. Jensen, J. Neville, and B. Gallagher. Why [15] G. Karypis and V. Kumar. A fast and high quality [16] R. I. Kondor and J. Lafferty. Diffusion kernels on [17] H. Liu and H. Motoda.Computational Methods of [18] Y. Liu, R. Jin, and L. Yang. Semi-supervised [19] Q. Lu and L. Getoor. Link-based classification. In [20] S. A. Macskassy and F. Provost. A simple relational [21] S. A. Macskassy and F. Provost. Classification in [22] M. McPherson, L. Smith-Lovin, and J. M. Cook. [23] J. Neville and D. Jensen. Leveraging relational [24] J. Neville, D. Jensen, L. Friedland, and M. Hay. [25] M. Newman. Finding community structure in [26] M. Newman. Modularity and community structure in [27] M. Newman and M. Girvan. Finding and evaluating [28] K. Nowicki and T. A. B. Snijders. Estimation and [29] P. Sarkar and A. W. Moore. Dynamic social network [30] L.Tang,H.Liu,J.Zhang,N.Agarwal,andJ.J.
 [31] L. Tang, H. Liu, J. Zhang, and Z. Nazeri. Community [32] L. Tang, S. Rajan, and V. K. Narayanan. Large scale [33] B. Taskar, P. Abbeel, and D. Koller. Discriminative [34] J. Travers and S. Milgram. An experimental study of [35] I. Tsochantaridis, T. Hofmann, T. Joachims, and [36] K. Tsuda and W. S. Noble. Learning kernels from [37] U. von Luxburg. A tutorial on spectral clustering. [38] Z. Xu, V. Tresp, S. Yu, and K. Yu. Nonparametric [39] X. Zhu, Z. Ghahramani, and J. Lafferty.

