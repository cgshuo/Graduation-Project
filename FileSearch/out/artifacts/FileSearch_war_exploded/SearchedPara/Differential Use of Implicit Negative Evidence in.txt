 Languages have a complex structure, full of general rules wi th idiosyncratic exceptions. For ex-ample, the causative alternation in English allows a class o f verbs to take both the transitive form,  X  X  opened the door X , and the intransitive form,  X  X he door ope ned X . With other verbs, alternations are restricted, and they are grammatical in only one form. Fo r example,  X  X he rabbit disappeared X  is grammatical whereas  X  X  disappeared the rabbit X  is ungram matical. There is a great debate over how children learn language, related to the infamous  X  X over ty of the stimulus X  argument [1, 2, 3, 4]. A central part of the debate arises from the fact that a child m ostly learns language only by hear-ing adults speak grammatical sentences, known as positive evidence . Children are believed to learn language mostly from positive evidence because research ha s found that children rarely receive in-dications from parents that a sentence is not grammatical, a nd they ignore these indications when they do recieve them. An explicit indication that a sentence is not grammatical is known as nega-tive evidence [5, 6, 7]. Yet, speaking a language speaking involves the gen eralization of linguistic patterns into novel combinations of phrases that have never been heard before. This presents the following puzzle: How do children eventually learn that cer tain novel linguistic generalizations are not allowed if they are not explicitly told? There have been t wo main lines of analyses addressing this question. These analyses have taken two different pers pectives on the basic task involved in language learning, and have yielded quite different result s.
 ceptable and unacceptable sentences in a way that is robust t o the actual distribution of observed sentences. From this perspective, Gold X  X  theorem [8] asser ts that languages with infinite recursion, such as most human languages, are impossible to learn from po sitive evidence alone. In particu-lar, linguistic exceptions, such as the restrictions on ver b alternations mentioned above, are cited as being impossible to learn empirically. More recent analy ses yield similar results, while making weaker assumptions about the desired outcome of learning (f or a review, see [9]). In light of this, it has been argued that child language learning abilities ca n only be explained by the presence of innate knowledge specific to language [3, 4, 10].
 On the other side of the debate, results indicating that rela tively sophisticated linguistic representa-tions such as probabilistic context-free grammars can be le arned from positive evidence have been obtained by viewing language acquisition as a process of for ming a probabilistic model of the lin-guistic input, under the assumption that the observed data a re sampled from this model [11, 12, 13]. In addition to these general theoretical results, statisti cal learning models have been shown to be capable of learning exceptions in language from positive ex amples only in a variety of domains, including verb alternations [14, 15, 16, 17, 18, 19]. Furthe rmore, previous experimental work has shown that humans are capable of learning linguistic except ions in an artificial language without negative evidence [20], bearing out the predictions of some of these models.
 One key difference between these two perspectives on learni ng is in the assumptions that they make about how observed sentences are generated. In the former ap proach, the goal is to learn to iden-tify grammatical sentences without making assumptions abo ut the distribution from which they are drawn. In the latter approach, the goal is to learn a probabil ity distribution over sentences, and the observed sentences are assumed to be drawn from that distrib ution. This difference is analogous to the distinction between discriminative and generative mod els in machine learning (e.g., [21]). The stronger distributional assumptions made in the generativ e approach result in a less robust learner, but make it possible to learn linguistic exceptions without negative evidence. In particular, gener-ative models can exploit the  X  X mplicit negative evidence X  p rovided by the absence of a sentence: the assumption that sentences are generated from the target probability distribution means that not observing a sentence provides weak evidence that it does not belong to the language. In contrast, discriminative models that seek to learn a function for labe lling sentences as grammatical or un-grammatical are more robust to the distribution from which t he sentences are drawn, but their weaker assumptions about this distribution mean that they are unab le to exploit implicit negative evidence. In this paper, we explore how these two different views of lea rning are related to human language acquisition. Here we focus on the task of learning an artifica l language containing both alternating and non-alternating verbs. Our goal is to use modeling and hu man experiments to demonstrate that the opposing conclusions from the two sides of the language a cquisition debate can be explained by a difference in learning approach. We compare the learning p erformance of a hierarchical Bayesian model [15], which takes a generative approach, with a logist ic regression model, which takes a dis-criminative approach. We show that without negative eviden ce, the generative model will judge a verb structure that is absent in the input to be ungrammatica l, while the discriminative model will judge it to be grammatical. We then conduct an experiment des igned to encourage human partici-pants to adopt either a generative or discriminative langua ge learning perspective. The experimental results indicate that human learners behave in accordance w ith model predictions: absent verb struc-tures are rejected as ungrammatical under a generative lear ning perspective and accepted as gram-matical under a discriminative one. Our modeling compariso ns and experimental results contribute to the language acquisition debate in the following ways: Fi rst, our results lend credence to conclu-sions from both sides of the debate by showing that linguisti c exceptions appear either unlearnable or learnable, depending on the learning perspective. Secon d, our results indicate that the opposing conclusions about learnability can indeed be attributed to whether one assumes a discriminative or a generative learning perspective. Finally, because our ge nerative learning condition is much more similar to actual child language learning, our results lend weight to the argument that children can learn language empirically from positive input. Generative approaches seek to infer the probability distri bution over sentences that characterizes the language, while discriminative models seek to identify a fu nction that indicates whether a sentence is grammatical. General results exist that characterize th e learnability of languages from these two
Figure 1: A hierarchical Bayesian model for learning verb al ternations. Figure adapted from [15]. perspectives, but there are few direct comparisons of gener ative and discriminative approaches to the same specific language learning situation. Here, we compare a simple generative and discriminative model X  X  predictions of how implicit negative evidence is us ed to learn verb alternations. 2.1 Generative model: Hierarchical Bayes In the generative model, the problem of learning verb altern ations is formulated as follows. Assume we have a set of m verbs, which can occur in up to k different sentence structures. Restricting ourself to positive examples for the moment, we observe a tot al of n sentences x sentences containing verb i can be summarized in a k -dimensional vector y i containing the verb occurrence frequency in each of the k sentence structures. For example if we had three possible sentence structure types and verb i occurred in the first type two times, the second type four time s and the third type zero times, y i would be [2 , 4 , 0] and n i would be 6 .
 We model these data using a hierarchical Bayesian model (HBM ) originally introduced in [15], also known to statisticians as a Dirichlet-Multinomial model [2 2]. In statistical notation the HBM is where y i is the data (i.e. the observed frequency of different gramma tical sentence structures for verb i ) given n i occurrences of that verb, as summarized above.  X  i captures the distribution over sentence structures associated with verb i , assuming that sentences are generated independently and structure k is generated with probability  X  i about the kinds of sentence structures that typically occur . More precisely,  X  represents the distribu-tion of sentence structures across all verbs, with  X  k , while  X  represents the extent to which verbs tends to appear in only o ne sentence structure type. In this model, the number of verbs and the number of possible s entence structures are both fixed. The hyperparameters  X  and  X  are learned, and the prior on these hyperparameters is fixed b y setting  X  = 1 and  X  = 1 for all i . This prior asserts a weak expectation that the range of  X  and  X  do not contain extreme values. The model is fit to the data by comp uting the posterior distribution p (  X  i | y i ) = R Chain Monte Carlo (MCMC) algorithm. Following [15], we use G aussian proposals on log(  X  ) , and draw proposals for  X  from a Dirichlet distribution with the current  X  as its mean. 2.2 Discriminative model: Logistic regression For our discriminative model we use logistic regression. A l ogistic regression model can be used to learn a function that classifies observations into two cla sses. In the context of language learning, the observations are sentences and the classification probl em is deciding whether each sentence is grammatical. As above, we observe n sentences, x with a variable c ( c j =  X  1) encode the verb, the sentence structure, and the interactio n of the two (ie. each sentence X  X  particular verb and sentence structure combination). With m verbs and k sentence structures, this results in m verb features, k sentence structure features, and mk interaction features, each of which take the value 1 when they match the sentence and 0 when they do not. For example, a sentence containing the second of four verbs in the first of three sentence structu res would be encoded with the binary feature vector 0100100000100000000 .
 The logistic regression model learns which features of sent ences are predictive of grammaticality. This is done by defining the probability of grammaticality to be where w and b are the parameters of the model. w and b are estimated by maximizing the log likelihood P n that are not observed) have weights that are set to zero. To examine the predictions that these two models make about t he use of implicit negative evidence in learning verb alternations, we applied them to a simple ar tificial language based on that used in [20]. This language has four transitive verbs and three poss ible sentence structures. Three of the verbs only appear in one sentence structure (non-alternati ng), while one verb appears in two possible sentence structures (alternating). The language consiste d of three-word sentences, each containing a subject (N1), object (N2) and verb (V), with the order depend ing on the particular sentence structure. 3.1 Vocabulary The vocabulary was a subset of that used in [20]. There were th ree two-syllable nouns, each begin-ning with a different consonant, referring to three cartoon animals: blergen (lion), nagid (elephant), tombat (giraffe). Noun referents are fixed across participants. Th e four one-syllable verbs were: plode and jump on . While the identity of the nouns and verbs is irrelevant to the models, we de-veloped this language with the intent of also examining huma n learning, as described below. With human learners, the mapping of verbs to actions was randomly selected for each participant. 3.2 Syntax and grammar In our language of three-word sentences, a verb could appear in 3 different positions (as the 1st, 2nd or 3rd word). We constrained the possible sentences such that the subject, N1, always appeared before the object, N2. This leaves us with three possible sen tence structures, S1,S2, and S3, each of which corresponded to one of the following word orders: N1-N 2-V, N1-V-N2 and V-N1-N2. In our experiment, the mapping from sentence structure to word ord er was randomized among participants. For example, S1 might correspond to N1-N2-V for one particip ant or it might correspond to V-N1-N2 for another participant. There was always one sentence st ructure, which we denote S3, that was never grammatical for any of the verbs. For S1 and S2, grammat icality varied depending on the verb. We designed our language to have 1 alternating verb and 3 non-alternating verbs. One of the three non-alternating verbs was only grammatical in S1. The other two non-alternating verbs were only grammatical in S2. For example, let X  X  consider the situatio n where S1 is N1-V-N2, S2 is N1-N2-V and S3 is V-N1-N2. If flern was an alternating verb, both nagid flern tombat and nagid tombat flern would be allowed. If semz was non-alternating, and only allowed in S2, nagid tombat semz would be grammatical and nagid tombat semz would be ungrammatical. In this example, flern nagid tombat and semz nagid tombat are both ungrammatical. The language is summarized in Table 1. 3.3 Modeling results The generative hierarchical Bayesian model and the discrim inative logistic regression model out-lined in the previous section were applied to a corpus of sent ences generated from this language. Table 1: Grammaticality of verbs. + and -indicate grammatic al and ungrammatical respectively, while ? indicates that grammaticality is underdetermined b y the data. The number in parentheses is the frequency with which each sentence was presented to mode l and human learners in our experi-ment. Verb V4 was never shown in sentence structure S2. Gramm aticality predictions for sentences containing this verb were used to explore the interpretatio n of implicit negative evidence. Figure 2: Predicted grammaticality judgments from generat ive and discriminative models. In paren-theses next to the verb index in the title of each plot is the se ntence structure(s) that were shown to be grammatical for that verb in the training corpus.
 The frequencies of each verb and sentence structure combina tion are also shown in Table 1. We were particularly interested in the predictions that the tw o models made about the grammaticality of verb V4 in sentence structure S2, since this combination of v erb and sentence structure never occurs in the data. As a consequence, a generative learner receives implicit negative evidence that S2 is not grammatical for V4, while a discriminative learner receive s no information.
 MCMC. The results indicate that V1 is expected to occur in bot h S1 and S2 50% of the time, while all other verbs are expected to occur 100% of the time in the on e sentence structure for which they are grammatical, accurately reflecting the distribution in our language input. Predictions for gram-maticality are extracted from the HBM model as follows: The i th verb is grammatical in sentence structure k if the probability of sentence structure k ,  X  i matical otherwise, where  X  is a small number. Theoretically,  X  should be set so that any sentence observed once will be considered grammatical. Here, poster ior values of  X  i about 0.5 for V1 in S1 and S2, and either 0 or 1 for other verb and sentence structure combinations, resulting in clear grammaticality predictions. These are s hown in Figure 2. Critically, the model predicts that V4 in S2 is not grammatical.
 Logistic regression was performed using all sentences in ou r corpus, both grammatical and ungram-matical. Predictions for grammaticality from the logistic regression model were read out directly from p ( c in S2, and has consequently not estimated a weight for the fea ture that uniquely identifies this sen-tence, it has seen 27 grammatical and 3 ungrammatical instan ces of S2, and 18 grammatical and 6 ungrammatical instances of V4, so it has learned positive w eights for both of these features of sentences. As a consequence, it predicts that V4 in S2 is gram matical. The simulations above illustrate how generative and discri minative approaches to language learning differ in their treatment of implicit negative evidence. Th is raises the question of whether a similar difference can be produced in human learners by changing the nature of the language learning task. We conducted an experiment to explore whether this is the cas e.
 In our experiment, participants learned the artificial lang uage used to generate the model predictions in the previous section by watching computer animated scene s accompanied by spoken and written sentences describing each scene. Participants were also pr ovided with information about whether the sentence was grammatical or ungrammatical. Participants w ere assigned to one of two conditions, which prompted either generative or discriminative learni ng. Participants in both conditions were exposed to exactly the same sentences and grammaticality in formation. The two conditions differed only in how grammaticality information presented. 4.1 Participants A total of 22 participants were recruited from the community at the University of California, Berke-ley. 4.2 Stimuli As summarized in Table 1, participants viewed each of the 4 ve rbs 24 times, 18 grammatical sen-tences and 6 ungrammatical sentences. The alternating verb was shown 9 times each in S1 and S2 and 6 times in S3. The non-alternating verbs were shown 18 t imes each in their respectively grammatical sentence structures and 3 times each in the 2 ung rammatical structures. Presentation of sentences was ordered as follows: Two chains of sentences were constructed, one grammatical and one ungrammatical. The grammatical chain consisted of 7 2 sentences (18 for each verb) and the ungrammatical chain consisted of 24 sentences (6 for eac h verb). For each sentence chain, verbs were presented cyclically and randomized within cycles. Fo r the grammatical chain, V1 occurrences of S1 and S2 were cycled through in semi-random order (verbs V 2-V4 appeared grammatically in only one sentence construction). Similarly, for the ungram matical chain, V2 and V3 cycled semi-randomly through occurrences of S1 and S3 and S2 and S3 respec tively (verbs V1 and V4 only appeared ungrammatically in S3). While participants were be ing trained on the language, presen-tation of one sentence from the ungrammatical chain was rand omly interleaved within every three presentations of sentences from the grammatical chain. Sub ject-object noun pairs were randomized for each verb across presentations. There were a total of 96 t raining sentences. 4.3 Procedure Participants in both conditions underwent pre-training tr ials to acquaint them with the vocabulary. During pre-training they heard and saw each word along with p ictures of each noun and scenes corresponding to each verb along with spoken audio of each no un/verb. All words were cycled through three times during pre-training. During the main ex periment, all participants were told they were to learn an artificial language. They all saw a series of s entences describing animated scenes where a subject noun performed an action on an object noun. Al l sentences were presented in both spoken and written form. 4.3.1 Generative learning condition In the generative learning condition, participants were to ld that they would listen to an adult speaker who was always spoke grammatical sentences and a child speak er who always spoke ungrammat-ically. Cartoon pictures of either the adult or child speake r accompanied each scene. The child speaker X  X  voice was low-pass filtered to create a believably child-like sound. We hypothesized that probabilistic representation of the language from the gram matical sentences produced by the adult speaker. 4.3.2 Discriminative learning condition In the discriminative learning condition, participants we re presented with spoken and written sen-tences describing each scene and asked to choose whether eac h of the presented sentences were grammatical or not. They were assured that only relevant wor ds were used and they only had to fig-ure out if the verb occurred in a grammatical location. Parti cipants then received feedback on their choice. For example, if a participant answered that the sent ence was grammatical, they would see either  X  X es, you were correct. This sentence is grammatical ! X  or  X  X orry, you were incorrect. This Figure 3: Human grammar judgments, showing proportion gram matical for each sentence structure. sentence is ungrammatical! X  The main difference from the ge nerative condition is that in the dis-criminative condition, the presented sentences are assume d to be chosen at random, whereas in the generative learning condition, sentences from the adult sp eaker are assumed to have been sampled from the language distribution. We hypothesized that parti cipants in the discriminative condition would behave similarly to a discriminative model: they woul d use feedback about both grammatical and ungrammatical sentences to formulate rules about what m ade sentences grammatical. 4.3.3 Testing After the language learning phase, participants in both con ditions were subjected to a grammar test. In this testing phase, participants were shown a series of wr itten sentences and asked to rate the sentence as either grammatical or ungrammatical. Here, all sentences had blergen as the subject and nagid as the object. All verb-sentence structure combinations we re shown twice. Additionally the verb V4 was shown an extra two times in S2 as this was the cru cial generalization that we were testing.
 Participants also underwent a production test in which they were shown a scene and asked to type in a sentence describing that scene. Because we did not want t his to be a memory test, we displayed the relevant verb on the top of the screen. Pictures of all the nouns, with their respective names below, were also available on the bottom of the screen for ref erence. Four scenes were presented for each verb, using subject-object noun pairs that were cycled through random. Verbs were also cycled through at random. 4.4 Results Our results show that participants in both conditions were l argely able to learn much of the grammar structure. Hoewever, there were significant differences be tween the generative and discriminative conditions (see Figure 3). Most notably, the generative lea rners overwhelmingly judged verb V4 to be ungrammatical in S2, while the majority of discriminativ e learners deemed V4 in to be grammat-ical in S2 (see Figure 3d). This difference between conditio ns was highly statistically significant the predictions of the HBM (generative) model and the logist ic regression (discriminative) model discussed earlier. Our results strongly suggest participa nts in the generative condition were learning language with a probabilistic perspective that allowed the m to learn restrictions on verb alterna-tions by using implicit negative evidence whereas particip ants in the discriminative condition made sampling assumptions that did not allow them to learn the alt ernation restriction.
 Another difference we found between the two conditions was t hat discriminative learners were more willing to consider verbs to be alternating (i.e. allow thos e verbs to be grammatical in two sentence structures.) This is evidenced by the fact that participant s in the generative condition rated occur-rences of V1 (the alternating verb) in S1 and S2 as grammatica l only 68% and 72% of the time. This is because many participants judged V1 to be grammatical in e ither S1 or S2 and not both. On the other hand, participants in the discriminative condition r ated occurrences of V1 in S1 and S2 gram-matical 100% of the time (see Figure 3a). Pearson X  X   X  2 tests for the difference between conditions for grammaticality of V1 in S1 and S2 were marginally signific ant, with  X  2 (1) = 4 . 16 , p = . 04 and  X  2 (1) = 3 . 47 , p = 0 . 06 respectively. From post-experiment questioning, we learn ed that many participants in the generative condition did not think verb s would occur in two possible sentence
Figure 4: Human production data, showing proportion of prod uctions in each sentence structure. structures. None of the participants in the discriminative condition were constrained by this as-sumption. Why the two conditions prompted significantly diff erent prior assumptions about the prevalence of verb alternations will be a question for futur e research, but is particularly interesting in the context of the HBM, which can learn a prior expressing s imilar constraints.
 Production test results showed that participants tended to use verbs in the sentences structure that they heard them in (see Figure 4). Notably, even though the ma jority of the learners in the discrim-inative condition rated verb V4 in S2 as grammatical, only 20 % of the productions of V4 were in S2. This is in line with previous results that show that how of ten a sentence structure is produced is proportional to how often that structure is heard, and rar ely heard structures are rarely produced, even if they are believed to be grammatical [20]. We have shown that artificial language learners may or may not learn restrictions on verb alterna-tions, depending on the learning context. Our simulations o f generative and discriminative learners made predictions about how these approaches deal with impli cit negative evidence, and these pre-dictions were borne out in an experiment with human learners . Participants in both experimental conditions viewed exactly the same sentences and were told w hether each sentence was grammatical or ungrammatical. What varied between conditions was the way the the grammaticality information was presented. In the discriminative condition, participa nts were given yes/no grammaticality feed-back on sentences presumed to be sampled at random. Because o f the random sampling assumption, the absence of a verb in a given sentence structure did not pro vide implicit negative evidence against the grammaticality of that construction. In contrast, part icipants in the generative condition judged the unseen verb-sentence structure to be ungrammatical. Th is is in line with the idea that they had sought to estimate a probability distribution over sentenc es, under the assumption that the sentences they observed were drawn from that distribution.
 Our simulations and behavioral results begin to clarify the connection between theoretical analyses of language learnability and human behavior. In showing tha t people learn differently under differ-ent construals of the learning problem, we are able to examin e how well normal language learning corresponds to the learning behavior we see in these two case s. Participants in our generative condi-tion heard sentences spoken by a grammatical speaker, simil ar to the way children learn by listening to adult speech. In post-experiment questioning, generati ve learners also stated that they ignored all negative evidence from the ungrmamatical child speaker, si milar to the way children ignore negative evidence in real language acquisition. These observations support the idea that human language learning is better characterized by the generative approac h. Establishing this connection to the gen-erative approach helps to identify the strengths and limita tions of human language learning, leading to the expectation that human learners can use implicit nega tive evidence to identify their language, but will not be as robust to variation in the distribution of o bserved sentences as a discriminative learner might be.

