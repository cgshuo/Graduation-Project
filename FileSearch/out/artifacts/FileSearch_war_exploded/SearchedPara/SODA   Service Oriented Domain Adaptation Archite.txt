 Online social media, such as Twitter.com, have be-come the de facto standard for sharing information, thoughts, ideas, personal feelings, daily happenings etc. which essentially led research and development in the field of social media analytics to flourish. So-cial media analytics provide actionable insights to business by analyzing huge amount of user gener-ated content (UGC) (Sriram et al., 2010; Jo and Oh, 2011; He et al., 2012; Si et al., 2013; Nakov et al., 2013). Sentiment categorization, one of the common social media analytics task, segregates a collection of UGC into different buckets with positive, neg-ative or neutral orientation (Liu and Zhang, 2012; Thelwall et al., 2011; Bollen et al., 2009). This in-formation is used to aggregate statistics and identify trends which are helpful for many applications viz. Customer Care , Product Marketing , User Studies .
Supervised machine learning (ML) techniques such as text categorization have played a key en-abler role to classify microblogs into sentiment cat-egories (Pang and Lee, 2008; Tan et al., 2009; Go et al., 2009; Fern  X  andez et al., 2014). These are trained on a fraction of annotated data as per client pro-vided label set e.g. { positive , negative , and neu-tral } for a product/service/domain 1 . One of the obstacles towards rapid adoption of such systems is requirement of labeled tweets for developing ML-based models as it requires extensive human labeling efforts. Additionally, need of manual labeling slows down the process of categorization on high velocity social media which requires fast analytic insights. From our conversations with business professionals, we derived the need of a practical solution which would help them scale up across hundreds of col-lections and domains without the overhead of anno-tating data and building models from scratch every time for a new collection.
 In this paper, we demonstrate Service Oriented Domain Adaptation (SODA) which offers social media analytics as-a-service to the users. Specif-ically, it provides sentiment categorization as-a-service that allows users to efficiently analyze com-ments from any new collection without the over-head of manual annotations or re-training models. It thus enables faster wide-scale analysis within and across different domains/industries such as telecom, healthcare, finance etc. SODA is based on an iter-ative ensemble based adaptation technique (Bhatt et al., 2015) which gradually transfers knowledge from the source to the new target collection while being cognizant of similarity between the two collections. It has been extensively evaluated by business profes-sionals in a user-trial and on a benchmark dataset. Figure 1 illustrates the architecture of SODA com-prising three primary modules, 1) similarity, 2) do-main adaptation, and 3) active learning. The first two modules use unlabeled data from the new col-lection while the optional third module helps in cre-ating labeled data for enhanced classification perfor-mance. These modules are explained below. 2.1 Similarity In social media analytics, especially for senti-ment categorization, there exist numerous collec-tions about different products or services where la-beled data is available and thus can be used to adapt to a new unlabeled collection. Given a target col-lection, the key question is to identify the best pos-sible source collection to adapt from. The similar-ity module in SODA identifies the best adaptable source collection based on the similarity between the source and target collections. This is based on the observations from existing literature (Bhatt et al., 2015; Blitzer et al., 2007) which suggest that if the source and target collections are similar, the adapta-tion performance tends to be better than if the two collections are dissimilar. The similarity module in SODA is capable of computing different kinds of lexical, syntactic, and semantic similarities between unlabeled target and labeled source collections. For this demonstration on sentiment categorization from social media data, it measures cosine similarity be-tween the comments in each collection and com-putes sim as the similarity score. 2.2 Domain Adaptation The heart of SODA is the adaptation module that works on two principles, generalization and adapta-tion . During generalization, it learns shared com-mon representation (Blitzer et al., 2007; Ji et al., 2011; Pan et al., 2010) which minimizes the diver-gence between two collections. We leverage one of the widely used structural correspondence learn-ing (SCL) approach (Blitzer et al., 2007) to com-pute shared representations. The idea adhered here is that a model learned on the shared feature rep-resentation using labeled data from the source col-lection will also generalize well on the target col-lection. Towards this, we learn a model ( C S ) on the shared feature representation from the source collec-tion, referred to as  X  X ource classifier X . C S is then used to predict labels for the pool of unlabeled in-stances from the target collection, referred to as P u , using the shared representations. All instances in P u which are predicted with a confidence (  X  1 ) higher than a predefined threshold (  X  1 ) are moved to the pool of pseudo-labeled target instances, referred to as P s . We now learn a target domain model C T on P s using the target specific representation, referred to as  X  X arget classifier X .

C T captures a separate view of the target in-stances than the shared representation and hence brings in discriminating target specific information which is useful for categorization in target collec-tion. For further adaptation, the source ( C S ) and target ( C T ) classifiers are combined in a weighted ensemble ( E ) with w s and w t as the corresponding weights and iterate over the remaining unlabeled in-stances in P u . In each iteration, the ensemble pro-cesses the remaining instances and iteratively adds confidently predicted instances to P s which are used to re-train/update C T . This iterative process contin-ues till all instances in P u are confidently labeled or a maximum number of iterations is reached. Trans-fer occurs within the ensemble where the source classifier progressively facilitates the learning of tar-Algorithm 1 Adaptation Algorithm get classifier by providing pseudo labeled instances. The weights of the individual classifiers are updated, as a function of error ( I (  X  ) ) and the similarity ( sim ) between the collections, which gradually shift the emphasis from source to the target classifier. Finally, the ensemble is used to predict labels for future un-seen instances in the target collection. Algorithm 1 summarizes our approach (refer (Bhatt et al., 2015) for more details). 2.3 Active Learning SODA also implements an active learning module to allow users to annotate a few selected informative comments from the target collection. These com-ments are selected using cross entropy difference (CED) (Axelrod et al., 2011) such that the difference with source collection and the similarity with target collection is maximized. It selects comment(s) from target collection that have low CED score i.e. com-ments that have high entropy with respect to source H
S (  X  ) and low entropy with respect to target collec-tion H T (  X  ) as in Equation (1).
 Note, this active learning module is optional and should be used when the adaptation performance with unlabeled instances is not satisfactory. More and more instances can be annotated in multiple rounds till a satisfactory performance is achieved. These annotated instances are used to build a stronger target classifier for the ensemble based adaptation algorithm.
 Figure 2: Interactive GUI of service oriented domain adaptation (SODA) (best viewed in color). Figure 2(a) illustrates the interactive user interface (UI) of SODA where one can select a new target collection for the analysis task (i.e. sentiment cat-egorization). For a new target collection, it identi-fies relevant adaptable source collections based on their similarity. One can select any of the candidate source collections (selected collection highlighted in Figure 2(a)) and adapt. Figure 2(b) shows the performance report along with the predicted com-ments from the target collection. User evaluates the adaptation performance in unlabeled target collec-tion by analyzing the predicted comments and de-cides whether to annotate additional comments in Figure 3: The effect of labeled comments on the per-formance while adapting from Coll-1  X  Coll-6. target collection? If yes, Figure 2(c) lists a few in-formative comments selected using the active learn-ing module to seek annotations. One can mark these comments as positive, negative or neutral and subse-quently adapt using these labeled instances from the target collection. Figure 2(b) also shows the adap-tation performance with a few labeled instances in the target collection. One can continue annotating more instances in the target collection until satis-factory performance is achieved. For more detailed The interactive UI of SODA is developed using Ruby on Rails framework. All collections are man-aged in MySQL server. All three modules in SODA fetch data from the server and write the output back to the server. All modules work in real time enabling the system to be highly responsive to the user. The application is hosted on Amazon AWS as RESTful web services using Java Jersey (Tomcat server) that act as a bridge between the UI and back end. To evaluate the overall experience, a user trial was conducted where several business professionals pro-vided feedback on SODA. The objective was to eval-uate the overall usability, reduction in required ef-forts, and the performance on the new target collec-tions. The overall evaluation rated SODA 5 on us-ability and 4 for reduction in efforts ( 1 being worst &amp; 5 being the best). Table 1 reports the classifica-tion accuracy of SODA with few labeled comments from the target collection (ranging from 0 to 100 ). It also reports the performance of the in-domain clas-sifier which is trained and tested on data from the same collection. Coll-1 to Coll-8 refer to collections pertaining to marketing &amp; sales, comcast support, Table 1: User-trial results on social media data. Table 2: Results on the Amazon review dataset. DirectTV support, ASUS, Johnson &amp; Johnson CSAT, Apple iPhone6, and HUWAEI respectively. Figure 3 compares the effect of adding labeled comments in batches of 25 comments at-a-time. When there is no labeled data in the target collection, in-domain classifier can not be applied while SODA still yields good classification accuracy. Moreover, SODA con-sistently performs better than the in-domain classi-fier with same amount of labeled data.

We also evaluated the performance of domain adaptation (DA) module of SODA on the Ama-zon review dataset (Blitzer et al., 2007) which is a benchmark dataset for sentiment categorization. It has 4 domains, namely, books( B ), dvds( D ), elec-tronics( E ), and kitchen( K ) each with 2000 reviews divided equally into positive and negative reviews. Table 2 shows that DA module of SODA outper-forms 1) a widely used domain adaptation technique , namely, structural correspondence learning (SCL) (Blitzer et al., 2007; Blitzer et al., 2006), 2) the base-line ( BL ) where a classifier trained on one domain is applied on another domain, and 3) the in-domain classifier. Note that in Table 2, the performance of DA module of SODA is reported when it does not use any labeled instances from the target domain. We demonstrated SODA for efficient microblog cat-egorization on new social media collections with minimum (or sometimes no) need of manual anno-tations; thus, enabling faster and efficient analytics.
