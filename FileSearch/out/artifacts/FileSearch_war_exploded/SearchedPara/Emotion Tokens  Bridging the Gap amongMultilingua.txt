 Nowadays millions of users publish short messages on Twitter. It is widely spread all over the world and becomes a rich resource of texts in many different lan-guages. Twitter X  X  messages ( tweets ) are full of opinions and emotions, thus senti-ment analysis for tweets is important for information spreading and marketing. However, this is more difficult than traditional text analysis.

Tweets are limited with no more than 140 characters and are usually com-posed on mobile devices, hence people often use irregular expressions both for convinience and to save room for more words. Emotion tokens (including emotion symbols , irregular forms of words and combined punctuations ) are usually seen in tweets, such as  X   X  Me tienes olvidada :(  X ( -.-otra vez esta...) Disculpa es que estaba dormido.  X  AAAAH ok,  X qu  X  e har  X  as ahora?  X  Dormir mucho m  X  as.  X  (Spanish:  X   X  I have forgotten :(  X ( -.-again this...) Sorry is that he was asleep.  X  AAAAH ok, what will you do now?  X  Sleep more. X  ) Based on our observation (see section 3.2), there are about 0.47 emotion tokens per tweet; about one third tweets contain at least one emotion token. Emotion token is one of the most remarkable features of Internet text. It strongly expresses the feelings of the author and is often utilized across languages. Thus, emotion tokens are helpful for multilingual Twitter sentiment analysis, to determine if a tweet expresses a positive or a negative feeling, no matter what language the author uses.
Although the emotion tokens have been studied previously, they are usually considered as annotation of the texts and are chosen manually [6]. Different from these studies, we automatically extract d ifferent types of emotion tokens and use a propagation algorithm to label their polarities by few  X  X eed X  tokens. Therefore, many different tokens and their scores are discovered to build a sentiment lexicon which helps multilingual Twitter sentiment analysis.

The highlight of our work is: Different types of emotion tokens are extracted automatically, without considering the semantic information; their sentiment po-larities are labeled with an unsupervised propagation algorithm. The sentiment lexicon built based on the tokens works as a bridge over the gap among differ-ent languages, while most state-of-the-art Twitter sentiment analysis approaches only deal with English tweets. In addition, the corpus for building the lexicon is independent of time which is practical and feasible for real-world applications. This paper is organized as follows. Related work on sentiment analysis and Twitter is introduced in Sec. 2. Emotion t okens and their characteristics are analyzed in Sec. 3. In Sec. 4 and 5, algorithms for sentiment lexicon construction and sentiment analysis are proposed respectively. In Sec. 6, the algorithms are evaluated. In the last section, conclusions and future work are addressed. Sentiment analysis plays an important role with the growing of user-generated-content services. In traditional studies, m ost researchers build statistical models for sentiment and affect analyses, where semantic information is highly consid-ered as features [17,20]. These models r equire annotated corpus, which is often limited for online texts. Alternatively, manually built sentiment lexicons can be used as a useful resource [2,22]. Linguistic information (part-of-speech tags, syntactic information) is used for rule-based approaches [18]. Even though the feature words can be extracted with automatic algorithms [16], the semantic differences among languages limit multilingual analysis.

An intuitive idea for multilingual sentiment analysis is to translate languages into a well-studied language (e.g. English); hence traditional methods can be ap-plied. Previous studies on news and blogs work on sentence level [5] or word level [11]. Cross-language dictionaries work as bridges between different languages [9]. Obviously, without language techniques, these methods do not work. Some ma-chine learning models may be independent of languages, but training requires multilingual annotations [7,19] or is based on machine translation [3].
Emoticons and irregular words, howev er, are commonly seen in Internet texts of many languages. Emoticons are considered as annotations since they directly express the one X  X  attitude [6]. Unfortunately, they have various forms; most stud-ies manually choose some smileys (e.g.  X  :-)  X ) as labels [19]. They fail to consider many other figures such as  X  &lt; 3  X  (heart, means love ). In Twitter, we need to dis-cover more possible emoticons with different forms, since they are independent of languages and are helpful for multilingual analysis. On the other hand, the ir-regular words are usually seen when people wish to save keystrokes, or the length of message is limited. We focus on the emphasized spelling, i.e. the repeating of consecutive letters in a word (e.g.  X  nooooo WTF everyone left me  X ).
Twitter is a popular research topic nowadays. Besides its network characteris-tics [15], social impacts reflected by Twitte r sentiment are also of interests, such as word-of-mouth branding [13]. Other work follows the trends of sentiment [8]. As mentioned before, smileys are usually considered as annotations [6,19]. Most studies use linguistic rules or supervised learning to help sentiment analysis [14], which is difficult to be generalized into multiple languages.

There are websites that provide senti ment detection of Twitter. However, a study on the comparison of these results concludes that they contain much noise and lack precision [4]. The twitrratr site (http://twitrratr.com/) builds lists of positive and negative keywords and cl assifies the sentiment of tweets based on matching. The twittersentiment site (http://twittersentiment.appspot.com/) uses distant supervision to classify the sentiment of Twitter messages [12]. Al-though some smileys are used to collect training data as labels, emoticons are removed in their classification. We compare our results with these two websites.
To sum up, we notice that the traditional sentiment analysis methods are in shortage on Twitter and are limited to a specific language. To achieve a better multilingual Twitter sentiment analysis, we consider the emotion tokens as a bridge over the gap among languages. 3.1 Types of Emotion Tokens The three types of emotion tokens are lis ted in Table 1. They express emotions and cover most of the emotional informal words on the Internet.
 Note that some of the repeating letters words may be relevant to language. However, based on our observation, many of them are onomatopoeic words (Ta-ble 2). Therefore, they can be simply considered as another type of emoticons . 3.2 Characteristics of Emotion Tokens in Twitter In this paper, we use Stanford X  X  SNAP data (http://snap.stanford.edu/data/) which contains more than 400 million tweets in over six months.
 For a simple classification of English and non-English tweets, we examine the Unicode of the characters in each tweet . If all the characters in one tweet are from the Basic Latin or symbols section, the tweet is called a Basic Latin tweet. We find that most of them are in English. If some characters are in the Latin extended section, it is called an Extended Latin tweet. These tweets are often in Portuguese, Spanish, German, etc. Tweet s containing characters beyond these sections (such as Chinese) are not studied in this paper.
From the SNAP dataset of more than 400 million tweets, we uniformly sam-ple five million tweets. Among them, 1,649, 503 (33.0%) tweets contain emotion tokens. Their proportions in each character set are shown in Table 3. Shown in Table 4, each tweet with emotion tokens contains about 1.4 tokens. There are about 0.47 emotion tokens (either of the three types) per tweet.

Table 5 lists how many tweets contain such types of emotion tokens. Many types of emotion tokens co-occur in tweet s. This is the basic idea of our propa-gation algorithm. For example,
The misspelled word  X  X plendid X  may lead to a missing of the emotion in semantic-based methods, but the emotion tokens help us identify its sentiment.
Since the tweets are rich of co-occurred emotion tokens, a propagation algo-rithm based on the co-occurrence can be applied to label the polarities. As mentioned in Section 2, sentiment lexi cons are commonly used for sentiment analysis. Previous studies take semantic links (WordNet relations, conjunctions, etc.) to build such lexicons [1]. The emo tion tokens, however, do not have se-mantic links between each other. Consid ering the frequent emotion tokens in tweets, the co-occurred tokens are likely to have similar sentiment. Thus the co-occurrences between words are links for con structing a graph. Then a few initial seeds are used to propagate and discover new tokens. 4.1 Co-occurrence Graph Construction of Emotion Tokens An undirected graph G =( V, E ) is constructed to represent the links of words. Each node v  X  V is a word, while each edge ( v i ,v j )  X  E represents a co-occurrence between the two words v i and v j .Theweight w ij of edge ( v i ,v j )is the count of co-occurrence between v i and v j . This co-occurrence matrix W (i.e. the adjacent matrix of G ) is symmetric. Each diagonal element w ii of the matrix is the frequency of the corresponding v i in the corpus.

A direct idea is to build such a graph with only the emotion tokens. However, the lexicon built with this graph does not contain any normal words; it could not deal with tweets without any emotion tokens. Therefore, we build the graph on both emotion tokens and normal words. Note that the semantic information of normal words is not considered. We show an example for the graph construction (with the four tweets) in Fig. 1. Only two normal words are shown in the figure for simplicity. Fig. 1(c) is the graph we propagate to build the sentiment lexicon. To illustrate a clear scale of the gra ph, 100,000 Basic Latin and Extended Latin tweets from August, 2009 are sampled from the SNAP dataset. Both emo-tion tokens and normal words are extracted from them. The built graph contains 98,924 vertices (with only 10,390 emotion tokens) and 3,353,873 edges (22,515 among emotion tokens themselves, 314,186 among normal words and the rest are bridges). This undirected graph is extremely sparse (edges take only 0.08%). 4.2 The Propagation and Smoothing Algorithm Similar to the SentiWordNet [1], we assign a positive score and a negative score to each word, which are calculated separately  X  the propagation starts with one seed for calculating the positive scores a nd one for negative scores, respectively.
A general algorithm for label propagation is used. Let x k be the vector of scores of each word after the k -th iteration. The x k +1 is calculated by a co-occurrence matrix W and a bias vector b , formally, Normalizations in each iteration are applied after the W  X  x k and W  X  x k + b .The convergence of x k has been proved [23]. This form of graph propagation is used in many algorithms such as Page-Rank and TrustRank. The bias vector b is set to the seed vector x 0 to keep the superiority of seeds. Also due to this reason, W  X  x k is normalized before adding b to make them in a same scale. Since the initial x 0 is always added in each iteration, the seed token may have a much higher score than the other thousands of tokens. To smooth the scores into a reasonable scale, we add a logarithm transformation on each word followed by a normalization to the [0 , 1] interval. The positive and negative scores are normalized separately. This method maps the scores into a natural distribution.

We choose only one seed to start the propagation (one for positive and one for negative, respectively). Since the g raph contains both emotion tokens and normal words, two types of initial seeds are proposed: (1) smileys:  X :) X  for positive scores,  X :( X  for negative. (2) good/bad:  X  X ood X  for positive,  X  X ad X  for negative. We build two SentiLexicons based on the two types of initial seeds.

With the graph built in Section 4.1, we find many of the scores (positive score minus negative score) of the emotion tokens are labeled correctly after the propagation. Many of the tokens do not have explicit emotions when judged by humans, but may contain hidden emotions brought by the context. We examine the scores by P + @100 and P  X  @100, i.e. the precision of the first 100 tokens with the largest absolute scores. Only 25% and 34% tokens have obvious emotions within the positive and negative ones, respectively. Among them, P + @100 = 0 . 92 and P  X  @100 = 0 . 53. Similarly, P + @200 = 0 . 88, P  X  @200 = 0 . 56, while P + @300 = 0 . 83 and P  X  @300 = 0 . 59. This demonstrates that the tokens are usually propagated with larger positive scores. The sentiment polarity of a tweet t is determined by both its positive score, score + ( t ) and its negative score, score  X  ( t ), shown in the equation below. Note the scores of the emotion tokens ( v e ) and normal words ( v w )of t are looked up from the built SentiLexicon .Thescore  X  ( t ) is calculated similarly as score + ( t ). polarity( t )= score + ( t )=  X  score + ( v e )+(1  X   X  ) score + ( v n )(2) This model is similar as a bag-of-words model. Though simple, it does not involve any linguistic (semantic) information of the sentence. Thus it can be used for multilingual sentiment analysis without much linguistic knowledge.
 6.1 Dataset Tweets for building the SentiLexicon and evaluating the algorithms are sampled from the Basic Latin and Extended Latin tweets in the SNAP dataset. Over 99.99% tweets are from June 11th, 2009 to December 31st, 2009, so only the tweets within this period are considered.

During this 204 days period, we pick eight tweets per day for evaluation (no overlap with the tweets building lexicons), including English, Portuguese, Spanish and German tweets (two of each language), which are among the most popular languages in Twitter [21]. Google X  X  Translation API is used to automat-ically pick out the tweets of a certain language. Each tweet is then given one of the three labels: positive, negative or neutral with two annotators. The third annotator is introduced when there is no majority. If the label is still uncertain, the tweet is discarded (it is difficult even for human judgements). We finally have 449 positive, 211 negative and 553 neutral tweets (total 1,213). 6.2 Strategies of Comparative Evaluations 1. SentiWordNet : The baseline method
The SentiWordNet provides positive and negative scores for senses, part-of-speech tags of English words. We use this lexicon with the strategy as referred to its website (http://sentiwordnet.isti.cnr.it/), summing up the scores of each POS tags of a word. With this strategy, the SentiWordNet provides 17,778 positive words (whose positive score is greater than its negative score), 20,350 negative and 1,565 neutral words (with non-zero scores) among 39,693 words. The positive and negative scores of a tweet is the sum of each word. Then a threshold  X  is used to classify its sentiment. 2. twitrratr
The twitrratr provides two lists of positive and negative keywords. We try to match them in a tweet and count their numbers. Similarly, we determine the sentiment of the tweet by the bigger count of positive and negative words. If two numbers are equal, we consider it as a neutral tweet. 3. twittersentiment
We retrieve twittersentiment  X  X  results of our data from its API. The authors test their method on their own dataset[12]. However, the API they provided makes it comparable for both their and our methods on our dataset. 6.3 Results and Discussions We examine the lexicon from several asp ects. Besides the evaluation on English and non-English tweets, we build the lex icons with different sizes of tweets to see if the size is  X  X he bigger, the better X . Moreover, the lexicons are built from different months X  tweets in SNAP data, to examine if the lexicon built from a specific month is stable for the analysis on tweets in other months. Our results are all compared with the SentiWord Net baseline and the two websites. Parameters and Seeds. The parameter  X  determines how much the emotion tokens influence the sentiment score, while  X  determines the proportion of neutral tweets. We conduct experiments with several combinations of them (both in the [0 , 1] interval), based on the SentiLexicon built with both smileys and good/bad as seeds from 10,000 tweets in August, 2009 without loss of generality. In general,  X  = 1 is better, i.e. the scores of emotion tokens are weighted with 1 while normal words are weighted with 0. This implies that it is the emotion tokens that affect the sentiment of the tweet. The  X  is somehow stable among different  X   X  X . Similarly, there are no significant di fferences between the two types of seeds. For simplicity, we fix  X  =0 . 7 and smileys as seeds in the following experiments. Comparative Evaluations on Different Languages. To show our method X  X  efficiency on multilingual tweets, we compare SentiLexicon (smileys as seeds,  X  =1,  X  =0 . 7) with the three algorithms mentioned above. The lexicons are built with tweets from June to December, respectively. Since the results are similar, we only show the results built wi th the August tweets. The performances are compared on English tweets and non-En glish tweets respectively, shown in Table 6 and Table 7. The F 1 , P and R under each class stand for F 1 -score, Precision and Recall, respect ively. The last column  X  F 1 is the average of three F -scores in the three classes. For the performance of SentiWordNet , we only list the best one with  X  =0 . 5. Since this lexicon is for English, it should not be used for non-English sentiment analysis.
 These two tables suggest that our method is efficient on multilingual tweets. Most of the F 1 -scores, precisions and recalls of the SentiLexicon are higher than the current state-of-the-art methods. In English tweets, the recall rate on neg-ative tweets of our method is rather low, which pull down the overall accuracy. We examine that these negative tweets do not contain many strong emotion to-kens; hence we classify most of them as neural ones. Another reason is that the tokens are usually have larger positive scores. Therefore, many of the negative tweets are classified as positive ones. We find that in Twitter, there are usu-ally more positive tweets than negative ones (e.g. 449 positive vs. 211 negative ones with our annotation). As a result, the construction of the co-occurrence graph links many tokens with positive words implicitly; the propagation process assigns larger positive scores for many of the tokens. This indicates that the negative tweets may be processed differently from the positive tweets. However, in non-English tweets, our method outperforms the other methods.
 Sizes of Datasets for Building Lexicons. With the tweets from August, 2009, three sizes of datasets are extracted: 1,000 (1k), 10,000 (10k) and 100,000 tweets (100k). We compare their performances on the evaluation tweets with the SentiLexicon built from them, and draw the differences between accuracies and average F 1 -scores on the same scale to compare 1k vs. 100k (Fig. 2(a)) and 10k vs. 100k (Fig. 2(b)). We see that 10k vs. 100k is less different than 1k vs. 100k. Hence we conclude that 1,000 tweets is not sufficient to build a good lexicon, since many tokens may not even appear in such small amount of tweets. On the other hand, the lexicon built with 100,000 tweets does not perform much better than just 10,000 tweets. This finding is helpful for practical use  X  we do not have to build a very big lexicon. The token s covered in 10,000 tweets are enough to build a helpful lexicon for sentiment analysis.
 Stability of the Lexicons over Time. The lexicons are built with tweets from only one month, hence we propose to examine whether or not the lexicon from one month can work on future months. One strategy is to build the lexicon with tweets in the first month in the dataset (June 2009), and evaluate it on tweets in the succeeding months in the eval uation set. The other strategy is to build with each month (except the last one) and evaluate it on tweets in just the next month (e.g. use June to evaluate July tweets). We also build a lexicon with the first week (June 11th to June 17th, 2009) and evaluate it on July to December tweets. The performances of each strategy are shown in Fig. 3.
The results show the accuracies are all around 50% to 60% in each month X  X  evaluation tweets, and the average F 1 -scores are also within 0.4 to 0.5. The performances of the lexicons do not re ly on tweets in a specific month or week. This infers that the lexicon is stable along with time. Therefore, we can build a lexicon with the current tweets and us e it for future sentiment analysis. In this paper, we propose the emotion tokens to help sentiment analysis on mul-tilingual Twitter messages. A graph pr opagation algorithm with a smoothing method is applied; hence the polarities of the tokens are labeled automatically based on their popular co-occurrences. W ith this lexicon, we perform a mul-tilingual sentiment analysis for tweets, and achieve a better performance than traditional semantic based approach as well as several Twitter sentiment analy-sis websites. The comparative evaluations indicate that the emotion tokens are helpful for both English and non-Englis h Twitter sentiment analysis, and are independent with the tweets in different time periods to build the lexicon.
There are also several technical issues we would like to address as future work, such as improving the bag-or-words model for sentiment analysis for higher accuracies, tracking Twitter X  X  sentime nt within a longer period and to discover if some tokens have opposite or weak emotions.
 Acknowledgments. We would like to thank the anonymous reviewers for their valuable comments. We are deeply grateful to our annotators: Yongfeng Zhang, Qianli Xing, Yin Wang, Kuan Liu, Junwei Miao, Tong Zhu, Qian Wang, Fei Chen, Xiaoguang Wang, Bin Liang and many other participants. The NExT Search Centre is supported by the Singapore National Research Foundation &amp; Interactive Digital Media R&amp;D Program Office, MDA under research grant (WBS:R-252-300-001-490).

