 Instagram, an online photo-sharing platform, has gained in-creasing popularity. It allows users to take photos, apply digital filters and share them with friends instantaneously by using mobile devices. Instagram provides users with the functionality to associate their photos with points of inter-est, and it thus becomes feasible to study the association between points of interest and Instagram photos. However, no previous work studies the association. In this paper, we propose to study the problem of mapping Instagram photos to points of interest. To understand the problem, we ana-lyze Instagram datasets, and report our findings, which also characterize the challenges of the problem. To address the challenges, we propose to model the mapping problem as a ranking problem, and develop a method to learn a ranking function by exploiting the textual, visual and user informa-tion of photos. To maximize the prediction effectiveness for textual and visual information, and incorporate the user-s X  visiting preferences, we propose three subobjectives for learning the parameters of the proposed ranking function. Experimental results on two sets of Instagram data show that the proposed method substantially outperforms exist-ing methods that are adapted to handle the problem. H.3.3 [ Information Storage and Retrieval ]: Information Filtering Photo Mapping; Ranking; Point of Interest
Instagram, a mobile based photo-sharing system, allows users to share their photos with friends instantaneously on various social networking platforms, e.g., Facebook, Twitter, etc. It provides users with many digital filters for creating c  X  Fi gure 1: A graph representation of the interactions in Instagram. magic visual effects on their photos, and users can express their sentiments/opinions and give comments on uploaded photos. Launched in October 2010, Instagram has gained popularity rapidly over the past several years. As of Decem-ber 2014, it had over 300 million active users who shared more than 20 billion photos. 1 The Instagram community is still growing at a rapid speed and on average more than 40 million photos are uploaded per day.

One interesting functionality of Instragram is that it al-lows users to associate photos with Points of Interest (POIs), which offers an exciting opportunity to study the association between photos and POIs. In Figure 1, we give an exam-ple to show how users, photos and POIs interplay with each other. In Instagram a user can upload photos with textual descriptions and hashtags. For example, user u 1 submit-ted a photo with the description  X  X ice swimming pool! X  and meanwhile the hashtag  X #Hilton X  was used. Users can also associate the uploaded photos with POIs, e.g., user u 1 an-notated the two pictures he uploaded to the POIs  X  2 and  X  respectively.

Knowing the association between photos and POIs has important applications. First, it provides both visual and textual annotations about POIs for users to explore. For example, when we are interested in visiting a POI, we can browse the photos associated with it to see the POI and it-h ttp://www.statista.com/statistics/253577/number-of-monthly-active-instagram-users/ s environment; meanwhile, we can read the corresponding textual information to find interesting aspects or social ac-tivities related to the POI. Second, the association is a fun-damental data preprocessing task, which is a prerequisite for other mining tasks. Third, associating photos and POIs will help to understand users X  preferences over POIs. Recently, Silva et al. have studied the Instagram data [22], compared Instagram photos with the check-ins on Foursquare [23], and shown that photos can be mimicked as check-ins at POIs.
When users upload photos, they need manually associate photos with POIs, which can be tedious. In Instagram, on-ly less than 30% pictures are annotated to POIs by users. Thus, studying how to automatically map Instagram photos to POIs is an important problem. However, to the best of our knowledge, no existing work has considered the problem.
In this paper, we propose to study the problem of map-ping the Instagram photos to POIs. Specifically, given the photos that have been associated with POIs as training set, we learn a mapping function to annotate a photo that is not associated with POI. The problem is challenging because of two reasons. First, as we will see in Section 3.2, we find that the number of photos associated with each POI follows a power law distribution. That is, a great number of POIs have very few photos and thus it is difficult to train an ef-fective mapping model for them due to the data scarcity problem. Second, we have not only visual and textual infor-mation, but also user visiting information to explore. The visiting preferences of users over POIs, as an important type of information, should be exploited, which is also a way to overcome the data scarcity problem. As we will see in Sec-tion 3.2, however, we find that users tend to take photos at POIs that are new to them, and this makes it difficult to exploit users X  visiting preferences.

Note that our problem differs from previous studies on mapping Flickr photos to the earth. Previous work on Flickr photos can be classified into two types. One type is associ-ating photos to some landmarks [5, 14, 3], and the other is dividing the world map into grids and then predicting which grid a photo belongs to [20, 18, 11, 16]. For the first type, the landmarks usually refer to popular places and thus there are enough photos in each landmark to train a model. In our case, as aforementioned we lack photos for the majority of POIs due to the power law distribution. Furthermore, in these approaches [5, 14], the number of landmarks con-sidered is limited, and it is unclear how to effectively scale these approaches coping with many POIs when the training samples are scarce. For the second type, a grid region usu-ally contains multiple POIs and mapping photos to a grid level is insufficient to annotate POIs. Another major dif-ference is these previous studies do not exploit the visiting preferences of users to POIs. However, Instagram data re-veals users X  visiting preferences over POIs [23], and thus it is important to exploit user information in our problem.
To solve the photo mapping problem, we first explore the characteristics of Instagram data. We make three interesting observations: (1) most of POIs have fewer than 10 photo-s; (2) users in general associate fewer than 50 photos with POIs in one year and the number of users who associate more than 50 photos decreases in a power law fashion; (3) users tend to take photos at POIs that are new to them. These findings are reported for the first time, and also character-ize the challenges of our problem (to be analyzed in Section 3.2). Second, we model the mapping problem as a ranking problem, and define a function to score POIs in terms of the textual context, visual content and user information for a given photo. In particular, we propose a new multi-task model to combine the textual, visual and user information for learning the scoring function. In the proposed model, we maximize prediction abilities of the combined (textual, visual and user) information as the main objective, and max-imize prediction effectiveness of textual and visual informa-tion as two subobjectives. As a result, the most informative features from textual context and visual content can be effec-tively combined into the function. Moreover, we effectively incorporate the visiting preferences of users into the scoring function by designing another weighted matrix factorization subobjective. The contributions of this paper can be sum-marized as follows.
The rest of the paper is organized as follows. In Section 2, we briefly review related work. In Section 3, we explore the Instagram data and present some interesting patterns we find. Our proposed model is introduced in Section 4 and experimental results are presented in Section 5. Finally, we conclude the paper with some future research directions in Section 6.
Previous work on geolocating images can be categorized into two types. One type is dividing the concerned region into grids and predicting the grid where an image resides, and the other type is identifying from a set of candidates the landmark that an image refers to.

Grid Prediction . Hays and Efros [6] propose a data driven approach to calibrating Flickr images to grids on the earth. In the approach, they first filter Flickr images by some specific geo-related and some obviously geo-unrelated ta gs, and then place the images onto 200 km  X  200 km grid-s by employing K -nearest neighbors algorithm with some predefined visual features. Instead of leveraging visual fea-tures, Serdyukov et al. [20] adopt textual features, i.e., user-generated tags, to map the Flickr photos to grids. They build a Language Model (LM) for each grid in terms of its associated tags, and place the photos according to the prob-ability calculated by the LMs. Liu et al. [16] propose to build LM for a user in terms of the tags he/she used, and then combine it with grid-based LM for mapping Flickr im-ages to grids. In this approach, only textual features are considered.

Our problem differs from these previous studies [6, 20, 16] mainly in two aspects. First, we aim to associate In-stagram photos with POIs, instead of grids. A grid usually contains multiple POIs and mapping photos to grid level is insufficient to annotate POIs. Nevertheless, we adapt the approach in the work [16] for our problem, and compare with it in our experiments. Second, previous studies do not consider the visiting preferences of users. However, the pho-tos uploaded in Instagram resemble check-ins [23], which are very useful to characterize users X  preferences over POIs and should not be overlooked for our problem.

Landmark Identification . Crandall et al. [5] combine both visual (Scale Invariant Feature Transform X  X IFT fea-tures [17]) and textual (tag features) information to place Flickr photos onto landmarks, which is a representative work on landmark identification. In their work, they focus on identifying which of 10 landmarks in a city an image be-longs to. Their solution is considering the problem as a multi-class classification problem. In particular, they build Support Vector Machine (SVM) and Naive Bayesian (NB) based on visual and textual features, respectively, and then combine the classification results of them to produce final prediction. Other example studies on landmark identifica-tion include [14], [3], [25] and [1].

Our work differs from these studies in two aspects. First, the landmarks often refer to popular places and thus there exit sufficient photos to train a classification model. How-ever, in our problem, we lack training photos because most of POIs have only a few photos. Moreover, the number of landmark candidates considered in previous studies is very small , e.g., 10 landmarks [5], while the number of POIs is much larger, e.g., more than one thousand. It is not very ef-fective to train a classification model for our problem where the training samples are scarce, as we will see in the ex-periments. Second, these studies do not consider the users X  preferences over POIs.
As a vast amount of tweets and online information are generated by users, several studies have been conducted for predicting locations of tweets or users [2, 4, 12, 24]. For example, based on user-supplied home address information and social friendship information in Facebook, Backstrom et al. [2] propose to predict the locations of users by measuring and using their social and spatial proximity. Cheng et al. [4] develop a probabilistic approach to estimating the city-level location of a Twitter user, which purely relies on the content of his/her tweets. In their approach, a classification model is first built to identify the geoscope word in tweets for estimat-ing users X  locations, and then a lattice-based neighborhood smoothing model is proposed to refine the estimations. Re-% of photos annotated to POIs 2 9 2 6 % of photos with textual info. 9 2 9 4 cen tly, Li et al. [12] study a similar problem to identify the cities of residence for Twitter users. They propose a unified discriminative influence model based on the assumption that Twitter users tend to follow users living close to them. How-ever, these approaches focus on a city-level granularity and cannot solve our problem because city-level accuracy is too coarse to associate photos with POIs. Moreover, users X  vis-iting preferences over POIs and visual features of photos are not explored in the approaches. Yuan et al. [24] develop a spatio-temporal topic model based on Twitter data, which can also be used for estimating users X  locations or tweets X  locations given a time.
We crawled two sets of Instagram data from 13 Nov 2013 to 13 Nov 2014, which were from users in New York City (NYC) and Singapore (SG), respectively. When crawling the data, a user was considered from NYC or SG if more than a half of his/her Instagram photos were taken in the region of NYC or SG. We refer to the two datasets as NYC and SG, respectively. NYC comprises 602,604 POIs and 21,910,375 photos taken by 126,543 users, and SG comprises 372,104 POIs and 13,168,666 photos taken by 87,281 users. 92% and 94% of NYC and SG photos are accompanied with textual information, respectively. When users upload photos, they need manually associate photos with POIs. We find that 29% and 26% photos have been already annotated to POIs by users for both data, respectively. In other words, more than 70% of photos in Instagram are not mapped to POIs. The basic statistics of both data are summarized in Table 1.
Observation 1: Number of photos per POI. We show in Figures 2(a) and 2(b) the empirical Complemen-tary Cumulative Distribution Function (CCDF) of number of photos per POI, for NYC and SG data, respectively. We observe that both CCDFs follow the power law distribution, i.e., P [ X  X  x ] = x  X  , where X is a random variable for the number of photos and  X  is a coefficient. By fitting the em-pirical distribution, we obtain the coefficient  X  =  X  0 . 96 and  X  =  X  0 . 99 for NYC and SG, respectively.

Given a power law distribution, we can compute x  X   X  ple, when P [ X  X  x ] = 10%, we have x  X  11 and x  X  10 for NYC and SG, respectively. 2 This means only 10% of POIs have at least 11 or 10 photos for NYC and SG, respectively, and the other 90% of POIs have no more than 11 or 10 pho-tos. Due to this issue, it would not be effective to train a
Th is is in accordance with the empirical distribution we computed, where P [ X  X  11] = 9 . 82% and P [ X  X  10] = 10 . 2% for NYC and SG, respectively. Figure 2: Distribution of number of photos per POI. Figure 3: Distribution of number of photos associ-ated with POIs per user. classifier for POIs as the previous methods [14, 5] for Land-mark identification do (as we will see in the experiments), because most of POIs will lack training samples.

Observation 2: Number of photos per user. We show in Figures 3(a) and 3(b) the empirical Probability Den-sity Function (PDF) of number of photos associated with POIs per user. We can see from both figures that the proba-bility first slightly increases, peaks when the number of pho-tos is around 5, and then decreases rapidly after 50, which is not a power law distribution. 3 However, the righthand part after the peak has a heavy tail, which can be modeled with a power law distribution, as shown in the figures. This ob-servation indicates that Instagram users in general associate fewer than 50 photos with POIs in one year (recall that both datasets are for one year period), and the number of users who associate more than 50 photos decreases with a power law probability. This observation suggests that we have only a few annotated training samples for each user.

Observation 3: Behaviors of users. First, we study the number of POIs where a user took photos. We plot the empirical CCDF of number of POIs per user in Figures 4(a) and 4(b) for NYC and SG data, respectively. We observe that 50.42% of users in NYC and 42.55% of users in SG have visited and taken photos at more than 20 POIs. This indicates we cannot easily determine which POI a photo is associated with based on users X  visiting information, because users take photos at many POIs.

Another interesting finding about users X  behaviors is that they incline to take photos at POIs that are new to them. To observe this, we calculate the probability that a user takes photos at newly-visited POIs by the following three steps: (i) for each user, we sort his/her photos taken at (associat-
It resembles a Double Pareto Lognormal Distribution [21]. Figure 4: Distribution of number of POIs per user. Figure 5: Histogram of the probability to take pho-tos at POIs that are new to users. ed with) POIs by time; (ii) we employ the first five POIs as initial visited set for each user, and then iterate through his/her sorting list to count whether a photo is taken at a new POI or a visited POI; meanwhile, we update the vis-ited POI set by including the POI for each checked photo; (iii) according to the counting results, we can compute the probability P u for user u to take a photo at new POIs as: where n u counts the number of new POIs for user u in step (ii) and o u counts the number of visited POIs. Finally, we depict a histogram with the probabilities of all the users. The histograms are shown in Figures 5(a) and 5(b) for NYC and SG, respectively.

We can see that a greater portion of users have high prob-ability (say 0.8 to 1.0) to take photos at newly-visited POIs (or we call previously-unvisited POIs for a user). This can be explained by the intuition that new POIs are usually more attractive for users to take photos than the visited ones; for previously visited POIs, users rarely take photos and anno-tate them again within the period of our data collection (1 year). The finding further indicates the difficulty in exploit-ing users X  visiting behaviors to associate photos with POIs. In this section, we first define the problem of associating Instagram photos with POIs, and then present our proposed approach to solving the problem.
Notations . Let U be a set of users { u 1 , u 2 ,  X  X  X  , u P denote a set of photos { p 1 , p 2 ,  X  X  X  , p |P| } and L denote sy mbols mea nings a set of POIs {  X  1 ,  X  2 ,  X  X  X  ,  X  |L| } in an Instagram database. As photos are associated with textual context, we employ the bag-of-word model to represent each photo p as an m -dimensional vector x p , where x pi denotes the frequency of word i for photo p . We note that x p is a zero vector if a photo does not have textual description. However, this does not take place usually because more than 90% photos have the textual information as aforementioned in Table 1. For visual content, we extract visual words to construct features [5]. Specifically, for each photo, we first use the standard computer vision technique Scale Invariant Feature Transfor-m (SIFT) [17] 4 to produce a set of keypoints, where each keypoint is represented as a 128-dimensional vector. Sub-sequently, the keypoints from all the photos are clustered into n -clusters to create a  X  X isual vocabulary X , where each cluster is considered as a  X  X isual word X . Finally, we assign each keypoint in a photo to its closest cluster, and then rep-resent each photo as a n -dimensional vector which indicates how many times each  X  X isual word X  appears in the photo. That is, for each photo p , we form a n -dimensional vector y , where y pi denotes the frequency of  X  X isual word X  i ap-pearing in photo p . For clarity, we summarize the notations used in this paper in Table 2.

Associating photos with POIs: Based on the set of photos that are associated with POIs by Instagram users, we aim at learning a function for mapping a photo to a POI. Formally, given a training set D  X  X  , where each p  X  X  has two attributes p.u and p. X  : p.u denoting the user who uploads photo p and p. X  denoting the POI that photo p is associated with, we learn a mapping function f : { ( u, p, x p , y p L which is used to predict the POI for a photo that is not associated with a POI .

According to Observation 1 in Section 3.2, the number of training samples for most of POIs is small. Hence, build-ing a classifier for POIs in L based on textual and visual features may not yield good accuracy for mapping. To learn the mapping function we propose a new approach that effec-tively exploits not only the visual and textual information of photos, but also the information of the users who upload them. Next, we present our proposed method.
We approach the mapping problem by treat it as a ranking problem. We develop an approach to learning a function from the training set D to score each POI for a given photo to be associated, and then rank the POIs based on their scores. The textual context, visual content, and user information
W e use the software provided by http://koen.me/research /downloads/ of a photo are taken into account in learning the ranking function. Since there are multiple types of information, we design a subtask for each type to maximize its predicting effectiveness. As a result, the most effective information of each type can be combined into the scoring function.
Next, we present how we embody this idea in details. We first embody our method by only considering textual con-text and visual content, and then introduce how our method exploits the user information.
In this subsection, we present an approach to combining textual contexts and visual contents of photos to learn a s-coring function for mapping a photo to a POI. We first intro-duce two factors w  X  and v  X  of m -dimension and n -dimension for each POI  X  , and then use them to model the interactions with textual and visual features of photos, respectively. The scoring function is defined as follows: where s p X  denotes the interaction score between photo p and POI  X  , and operator  X  represents the inner product. Clearly, the score s p X  is computed by a sum of textual interaction score w  X   X  x p and visual interaction score v  X   X  y p between POI  X  and photo p .

Next, our objective is to learn { w  X  }  X   X  X  and { v  X  }  X  that for each photo p its correct POI is expected to be ranked higher than the other POIs. In particular, we extend a pair-wise classi cation approach that is used in RankSVM [9] for this objective. That is, given each training sample p  X  D we compare pairwisely the scores of POIs p. X  and  X   X  (  X   X   X  X  and  X   X   X  = p. X  ) to check whether they are ranked correctly; if p. X  is ranked higher than  X   X  , there is no loss; otherwise a loss is produced. Specifically, we have the following objective function to minimize: where h ( z ) = max (0 , 1  X  z ) is the hinge-loss for converting the score difference between two POIs into a penalty. We note that the hinge-loss is nonzero only if z &lt; 1.
In Eq. (3) the two types of information, i.e., the textual context and the visual content, are combined directly and the objective function might not exploit the most informa-tive features from each type of information. For overcoming this issue, we design two subtasks for assistance, namely, to rank the correct POI higher than the other POIs when only a single type of information is presented. By following the idea of Eq. (3), we write another subobjective function to minimize for each subtask: and When minimizing O 1 , the factor w  X  will encode the most dis-criminative textual features for POI  X  , as O 1 aims at ranking POIs correctly by only utilizing textual features; similarly, minimizing O 2 will push v  X  exploit the most discriminative visual features.
Put ting O main , O 1 and O 2 together, we thus have a new objective function for minimizing as: J where  X  1 and  X  2 are two parameters for balancing between the main objective and two subobjectives;  X  W 2 from over-fitting;  X  W and  X  V are regularization parameter-s. We have tried  X  1 -norm as regularization terms to make the solutions of { w  X  }  X   X  X  and { v  X  }  X   X  X  sparse, but it turns out the performance is not good. The reason may be the discriminative terms for POIs are usually infrequent textu-al (or visual) words. These words are forced to be zeros in which thus deteriorates the performance.

When minimizing J , the objective O main is in charge of ranking the target POI correctly by combining textual context and visual content of photos, and the subobjectives O 1 and O 2 will push { w  X  }  X   X  X  and { v  X  }  X   X  X  to exploit the informative textual and visual features, respectively.
In this subsection, we discuss how to incorporate the user information of photos to make prediction. Intuitively, we aim at exploring users X  visiting preferences over POIs, i.e., how likely a user visits a POI, which is useful for inferring where his/her photo is taken. According to Observation 3 in Section 3.2, however, users tend to take photos at previ-ously unvisited POIs. Therefore, it is insufficient to model the visiting preference of a user based on his/her visited POIs. A good solution should be able to model the prefer-ences of users over both visited and unvisited POIs. This makes exploiting users X  visiting preferences in ranking POIs a non-trivial task.

To address the challenge, we propose a new approach based on factorization model to incorporate the user in-formation. Factorization model has been proven to be a promising tool for capturing users X  preferences, which has been applied in recommendation systems [10, 19, 15, 13]. As both users and POIs do not have explicit feature repre-sentations in our problem, we learn to embed users and POIs into a latent space for modeling their interactions. Specifi-cally, we introduce a latent factor u u of k -dimension for each user u and a latent factor l  X  of k -dimension for each POI  X  . By using them, we extend the scoring function in Eq. (2) as: where s up X  represents the interaction score among user u , photo p and POI  X  . We incorporate the user preference in the ranking function by including the term u u  X  l  X  . Different from textual and visual information, where x p and y p are predefined explicit representations in the terms w  X   X  x p v  X  y p , respectively, both u u and l  X  are unknown and require to be solved.

Replacing s p X  with s up X  in Eq. (3), the objective function can be extended as: and the objective function J in Eq. (6) can also be updated
When minimizing the objective function J , the latent fac-tors of users and POIs will be optimized to encode users X  vis-iting preferences. However, the optimization is a combined effect of textual, visual and user information, and the users X  visiting preferences might not be effectively utilized. To ad-dress this issue, we design a subobjective for solely modeling the visiting preferences of users.

Our subobjective is performing matrix factorization on user-POI interaction data. Based on the training set D , we can construct a |U| X |L| matrix A , where a u X  denote the frequency of user u takes photos at POI  X  . Note that we use a transformation by setting  X  a u X  = 1 2 (log ( a u X  implementation, because a small number of POIs may have very large frequency. Then we compute the latent factors of users and POIs, such that the user-POI interactions, mod-eled as inner product of users X  latent factors and POIs X  latent factors, are a good approximation of the matrix A . Howev-er, approximating the matrix directly will over-highlight the users X  preferences on visited POIs, because unvisited POIs have zero frequencies and directly approximating them will lead users X  preferences over unvisited POIs close to zero, which is not reasonable for our problem since users tend to take photos at unvisited POIs and thus their preferences to unvisited POIs should not be too small. On the other hand, we cannot only approximate the non-zero entries in matrix A , because the data is too sparse according to Observation 2 in Section 3.2. As a trade-off, we consider using weighted matrix factorization. In particular, we construct a |U| X |L| weighted matrix B by assigning larger weights for non-zero entries and smaller weights for zero entries as: where  X  = 0 . 001 is used in this paper. Because we give smaller weights for zero entries (corresponding to unvisited POIs), which is a relaxation for fitting zero entries, the users X  preferences over unvisited POIs thus will not be very close to zero. The subobjective function of the task is written as: The final objective function is thus changed into: J where  X  3 is a parameter for controlling the importance of the user preference subtask;  X  UL 2 is a regularization term to prevent over-fitting problem and  X 
UL is a regularization parameter. Here we use one regular-ization parameter for the latent factors of users and POIs, because only their inner product values matter to our ob-jective function.
In this subsection, we discuss how we optimize the ob-jective function J  X  to learn the prediction model. Let  X  { u u , l  X  , w  X  , v  X  } , where u  X  U and  X   X  L , denote the param-et ers of our model. We adopt the Stochastic Gradient De-scent (SGD) method for learning them. As J  X  is composed  X 
O 2 and  X  3 O 3 , we perform the SGD updates alternatively for these objectives. That is, in each iteration, we sample one training instance p  X  X  and then update parameters as follows for each objective: where  X  is the learning rate.

Next, we show how to calculate the corresponding gradi-ents used in above updating formulae. As the main objec-tive, subobjective 1 and subobjective 2 are similar, we derive the gradients for the main objective here as an example: ro and we use the above gradient calculations for updating parameters; otherwise, the hinge-loss is zero and we do not need to update parameters. Moreover, the corresponding regularization terms are incorporated into the calculations. For subobjectives 1 and 2,  X  X  1 O 1  X   X  and  X  X  2 O 2  X   X  can be com-puted in the similar way. The gradients for subobjective 3 are derived as follows:  X  , , We note that when deriving the gradients for each subob-jective, the corresponding regularization terms should be in-corporated.
 The proposed method, Rank in g with T ex tual, V isu al and U ser information for P ho tos to P OI s, called RankTVU P2P , can thus be summarized as Algorithm 1. In the algorith-m, we iteratively update the model parameters based on the main objective and three subobjectives until the per-formance on validation set is stable and does not increase. After obtaining the model parameters, the mapping score of a photo to a POI is calculated as Eq. (7). The larger the s-core is, the better the photo is mapped to the corresponding POI.
In this section, we conduct extensive experiments to eval-uate our proposed technique with the existing three state-of-the-arts, based on two Instagram datasets that we have crawled from the users in New York City (NYC) and Singa-pore (SG), respectively.

A lgorithm 1: RankTVU P2P in put : training set D , validation set V , learning rate output : model parameters  X 
Initialize  X  with Normal distribution N (0 , 0 . 01); repeat 3 fo r p  X  X  do un til the performance on validation set V does not increase ; return  X 
For NYC and SG datasets we crawled, we use the most recent three months data, i.e., from 13 Aug 2014 to 13 Nov 2014, in our experiments to evaluate the performance of dif-ferent algorithms. For data preprocessing, we remove POIs with less than 5 photos and users who visited less than 10 and 5 POIs in NYC and SG, respectively. 5 As our aim is to test the performance of photo mapping, we only use the photos that have already been associated with POIs by Instagram users. We construct the textual representation of photos by keeping the words with frequency larger than 10 into textual vocabulary. Note that we employ the word frequency in the bag-of-word model as discussed in Section 4.1. For the visual representation, we construct 1000 visual words as vocabulary by using the method introduced in Sec-tion 4.1. After preprocessing, NYC dataset comprises 2,049 POIs and 74,758 photos from 3,556 users, and SG dataset comprises 1,363 POIs and 58,072 photos from 5,717 user-s. Each photo is represented as a 1000-dimensional visual feature vector, and represented as a 8217-dimensional and a 6696-dimensional textual feature vector for NYC and SG, respectively. Then, for each user, we mark off 20% of his/her most recent photos to build the test set and mark off another 10% earlier photos as tuning/validation set. The remaining (the earliest) 70% photos are employed as training set for building the prediction models. The datasets are available at http://www.ntu.edu.sg/home/gaocong/data/Instagram.zip
We employ two standard metrics to evaluate the perfor-mance of photo associating results as in [20], namely, Mean Reciprocal Rank and Accuracy within top N , denoted by MRR and Acc@ N , respectively, where N is the number of candidate POIs produced by algorithms. MRR is the aver-age of the reciprocal ranks of the results produced for all the photos in test set. Specifically, it is computed as follows:
W e perform the preprocessing to reduce noises. We note that after the preprocessing the data is still very sparse, where 51.7% and 47.9% POIs have less than 10 photos in NYC and SG, respectively. where rank p. X  is the position of target POI p. X  in the rank-ing list produced by algorithms for the test photo p ; P test denotes the test set. Clearly, a bigger MRR indicates the target POI is highly ranked and thus a better result. Ac-c@N is computed as: where T op ( N, p ) denotes the set of top-N candidate POIs produced by algorithms for the test photo p . Acc@ N con-siders a mapping is correct as long as the target POI p. X  for photo p is ranked within top-N positions. For N , we use the values of 1, 2 and 3 ( N = 1 is the default value) in the experiments, respectively, as the accuracies of those top predicted results are definitely more important for our problem.
The following three related methods are utilized as the baselines. All the existing methods cannot leverage user information to infer users X  visiting preferences to unvisited POIs. Different from them, our approach has a weighted matrix factorization subobjective O 3 , which acts as a recommender componen-t and is capable of exploiting such information. For a fair comparison, we use our tuning set to find the optimal pa-rameters for all the baseline methods, and then use them to evaluate the performance on test set.
In the experiments, we set the regularization parameters  X 
V =  X  UL = 0 . 1 and  X  W = 0 . 001, and set the learning rate  X  as a small value 0.01 in our experiments to ensure the generalization accuracy. Next, we tune the parameters  X  1  X  2 and  X  3 used in three subobjectives, and the dimension k of latent factors of users and POIs, based on tuning set, to show how they affect the performance of the proposed method. For parameters  X  1 ,  X  2 and  X  3 , we first perform grid search to find the optimal combination of them, and then tune each parameter by fixing the other twos to demonstrate their individual impact on the performance.

Figure 6(a) shows how the performance of the proposed method changes when we tune the parameter  X  1 , which controls the weight of textual subojective O 1 . We can see from this figure the proposed method performs the best at  X  1 = 0 . 5 on both NYC and SG datasets. We show the effect of parameter  X  2 , controlling the weight of visual subobjec-tive O 2 , in the Figure 6(b). It can be seen that the best performance is delivered at  X  2 = 0 . 5 on the two datasets. Figure 6(c) shows how the parameter  X  3 , used for combin-ing user preference subobjective O 3 , affects the performance of the proposed method. We observe that the performance first increases and then decreases as  X  3 is increased, and the best performance is yielded at  X  3 = 0 . 1 for both datasets. We note that although  X  1 and  X  2 are larger than  X  3 , we can-not conclude that the textual and visual subobjectives are more important than user preference subobjective, because the subojective functions O 1 , O 2 and O 3 may be in different scales. We will analyze how the three subobjectives affect the performance in the next subsection. Finally, we show the effect of dimension k of latent factors on performance in Figure 6(d). We find that the performance increases as the dimension k is increased. After k exceeding 200, the perfor-mance does not change significantly and thus we use k =200 in our experiments.
Performance Comparison . Figure 7 presents the per-formance comparison results of different algorithms. Rank-TVP P2 P (textual + visual) denotes our approach utilizing only textual and visual content. We can see from the fig-ure that the proposed method RankTVU P2 P performs the best, in terms of two evaluation metrics, namely MRR and Acc@ N . It outperforms RankSVM, LM and NB, in terms of Acc@1, by more than 27.25% and 41.75% on NYC and SG, respectively. This is because RankTVU P2 P exploit-s the users X  visiting preferences over POIs (but RankSVM, LM and NB cannot leverage), which is an important infor-mation source for handling the sparsity problem of training data. When only utilizing the textual and visual content, we observe that our approach still delivers better perfor-mance than the baseline algorithms. In terms of Acc@1, the improvements are more than 12.5% and 11.7% on the two datasets, respectively. Moreover, we can see that RankSVM outperforms the other two baseline methods, which are all classifier based approaches. This may be attributed to that RankSVM, as a ranking based method, is more suitable to address the mapping problem when training samples are s-carce. Finally, we observe that the Acc@ N increases as N increases for all the methods. This is because the evaluation metric Acc@ N considers a mapping is correct as long as the target POI for a test photo is ranked within top-N positions. We find that the proposed RankTVU P2 P method consis-tently performs better than the baselines for different values of N .

Impact of Different Types of Information . Next, we analyze how different types of information affect our results. We incorporate the information one by one into our pro-posed RankTVU P2P to test how the performance changes. Figure 8 shows the detailed results on both datasets. We observe the performance of our model increases when textu-al, visual and user information are incorporated one by one in terms of both MRR and Acc@ N . When combing textual context with visual content, the performance improves, in terms of Acc@1, 11.0% and 14.1% on NYC and SG, respec-tively. When we further incorporate the user information, in terms of Acc@1 the performance boost 17.2% and 34.4% on both datasets, respectively. Finally, we find our model with only textual context achieves 76.9% and 65.2% of the best performance with all the three types of information in-corporated, on NYC and SG, respectively. The observations demonstrate the usefulness of each type of information. As the three types of information are from different views, they may contain complementary information to enhance each other for identifying the target POIs, which is a key reason that we obtain substantial improvements when combining them. According to the results, we also find that although visual content is important for associating photos with POIs, textual and user information have greater contributions to the final results.

Impact of Subobjectives . Finally, we study how our designed subobjectives in RankTVU P2 P help us obtain a better performance. To determine their individual effects on our proposed RankTVU P2 P performance, we take a-part the subobjective functions from RankTVU P2P one by one, and check their impacts on the performance. Figure 9 presents the results on both datasets, where we use the suffix  X   X  X  i  X  to denote the result obtained by removing subjective O i ( i =1, 2 and 3) from RankTVU P2 P.
Figure 8: Impact of different types of information.
We observe that the performance of RankTVU P2P de-creases when we remove the subojectives O 3 , O 2 and O 1 one by one. Comparing RankTVU P2 P with RankTVU P 2P -O 3 , we find that incorporating the subobjective O 3 proves the performance, in terms of Acc@1, 7.2% and 14.2% on NYC and SG, respectively. Moreover, by checking the results for RankTVU P2 P-O 3 and RankTVU P2 P-O 3 -O 2 we can see that 3.6% and 5.1% improvements, in terms of Acc@1, are obtained with the incorporation of the subojec-tive O 2 on both datasets, respectively. Finally, studying the results of RankTVU P2 P-O 3 -O 2 and RankTVU P2P -O -O 2 -O 1 , we observe that the subojective O 1 leads to 4.7% and 5.5% improvements in terms of Acc@1 on NYC and SG, respectively.

The results demonstrate these three designed subojectives play crucial roles for helping RankTVU P2 P obtain better performance. The reason is that the subojectives ( O 1 , O and O 3 ) will push the scoring function for POIs to exploit the most useful information from textual context, visual con-tent and user information of photos.
In this paper, we define and study the problem of associ-ating Instagram photos with POIs. To address the problem, we first find some interesting patterns contained in Insta-gram by data analysis, and then propose a ranking based mapping method, called RankTVU P2P . In the proposed method, a new multi-task objective function is developed, where the main objective is to score POIs with the three types of information, namely, textual context, visual con-tent, and user, and the other subobjectives are to maximize th e prediction effectiveness for each type of information. In particular, we design a weighted matrix factorization subob-jective to learn the visiting preferences of users over POIs. A stochastic gradient descent based algorithm is developed to optimize the objective function for learning parameters of our model. Extensive experiments are conducted on two sets of Instagram data, namely, NYC and SG, and the re-sults show that our model outperforms the baseline methods substantially.

Although Instagram has gained increasing popularity, lit-tle research has been conducted on it [8, 23, 7]. We propose a new research problem based on Instagram in this paper. Based on our work, several interesting problems can be in-vestigated or studied in the future. First, we only consider the Instagram photos that can be associated with POIs in our work such that we just focus on how to solve the map-ping problem. However, it would be interesting to study whether a photo from Instagram is really related to POIs or not in the future. Second, there are other types of infor-mation that could be investigated in Instagram, e.g., time stamps of photos, coordinates of photos (only available for the photos taken when GPS is enabled) and category infor-mation of POIs, etc.
This work is supported in part by a grant awarded by a Singapore MOE AcRF Tier 2 Grant (ARC30/12) and a grant awarded by Microsoft Research Asia. [1] Y. Avrithis, Y. Kalantidis, G. Tolias, and E. Spyrou. [2] L. Backstrom, E. Sun, and C. Marlow. Find me if you [3] W.-C. Chen, A. Battestini, N. Gelfand, and V. Setlur. [4] Z. Cheng, J. Caverlee, and K. Lee. You are where you [5] D. J. Crandall, L. Backstrom, D. Huttenlocher, and [6] J. Hays and A. A. Efros. Im2gps: estimating [7] N. Hochman and L. Manovich. Zooming into an [8] Y. Hu, L. Manikonda, S. Kambhampati, et al. What [9] T. Joachims. Training linear SVMs in linear time. In [10] Y. Koren, R. Bell, and C. Volinsky. Matrix [11] D. Leung and S. Newsam. Proximate sensing: [12] R. Li, S. Wang, H. Deng, R. Wang, and K. C.-C. [13] X. Li, G. Cong, X. Li, T. A. N. Pham, and [14] Y. Li, D. J. Crandall, and D. P. Huttenlocher. [15] D. Lian, C. Zhao, X. Xie, G. Sun, E. Chen, and [16] B. Liu, Q. Yuan, G. Cong, and D. Xu. Where your [17] D. G. Lowe. Distinctive image features from [18] F. O. Ostermann, M. Tomko, and R. Purves. User [19] S. Rendle. Factorization machines. In ICDM , pages [20] P. Serdyukov, V. Murdock, and R. Van Zwol. Placing [21] M. Seshadri, S. Machiraju, A. Sridharan, J. Bolot, [22] T. H. Silva, P. O. Melo, J. M. Almeida, J. Salles, and [23] T. H. Silva, P. O. Vaz de Melo, J. M. Almeida, [24] Q. Yuan, G. Cong, Z. Ma, A. Sun, and N. M.
 [25] Y.-T. Zheng, M. Zhao, Y. Song, H. Adam,
