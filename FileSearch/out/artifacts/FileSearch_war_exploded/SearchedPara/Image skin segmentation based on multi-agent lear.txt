 1. Introduction
Skin detection is one of the most important techniques in image processing and is the most distinctive and widely used approach for many applications ( Wadud et al., 2008; Mohamed et al., 2008 ), such as face detection ( Dargham et al., 2009 ), human motion analysis ( Peer et al., 2009 ), pornographic image ( Daxiang et al., 2013 ), and blocking objectionable content ( Ottinger et al., 2009 ). Correspondingly, applications such as content-aware video compression and image colour balancing can also bene from automatic skin detection in images. Skin detection is used to determine the image pixels that are related to human skin. Colour is a useful cue for extracting skin pixels, and choosing a skin colour as an element in detecting human presence is a relatively simple and straightforward task; in addition, skin colour has a processing time advantage, given that colour processing is faster compared to other processing of other features ( Taqa and Jalab, 2010b ); never-theless, using colour information for skin detection is challenging because the appearance of skin in images is affected by various factors, such as the illumination, background, camera character-istics, and re fl ections from glass or water ( Liu et al., 2011; Shoyaib et al., 2012; Khan et al., 2012; Mohair et al., 2012 ). Many techniques have been presented in the literature for skin detection using colour ( Bhoyar and Kakde, 2010 ). Skin detection is the process of fi nding skin-coloured pixels and regions in an image or a video ( Elgammal et al., 2009 ). This process is typically used as a pre-processing step to fi nding regions that potentially have human faces and limbs in the images. A skin colour detector typically transforms a given pixel into an appropriate colour space and then uses a skin classi fi er to label the pixel, whether it is a skin or a non-skin pixel ( Berbar, 2011 ). A skin classi fi er de decision boundary of the skin colour class in the colour space based on a training database of skin-coloured pixels. The main goal of a skin colour detection algorithm is to build a decision rule that will discriminate between skin and non-skin pixels ( Zolfaghari et al., 2011 ). This goal is accomplished by introducing a metric that measures the distance between pixel colours in relation to the skin tone. This metric type is de fi ned by the skin colour modelling method. Different methods for discriminating between skin and non-skin pixels are available in the literature ( Vezhnevets et al., 2003; Kakumanu et al., 2007 ). However, it was only in the last 15 years that the value of skin colour segmentation has been fully realised in various computer vision applications ( Naji et al., 2012 ). These applications can be grouped into three types of skin modelling, namely, explicitly de fi ned skin regions, non-parametric skin, and parametric skin approaches.
 The fi rst category uses explicit rules based on colour values. The explicit skin cluster classi fi er experimentally de fi boundaries of the skin cluster in a certain colour space ( Vezhnevets et al., 2003 ). These methods use explicit rules that are based on colour values, which is an approach that many studies have taken ( Kovac et al., 2003 ). These methods are very modest to implement, and the simplicity of the skin detection rules leads to a quick and inexpensive construction of a classi
However, the main dif fi culty of achieving high recognition rates with this method is the need to fi nd empirically both good colour space and adequate decision rules. Recently, a method that uses machine learning (ML) algorithms to fi nd a suitable colour space and a simple decision rule and thus achieves high recognition rates was proposed ( Sisodia and Verma, 2011 ).
 elling methods are better suited for constructing classi fi cases of limited training and expected target datasets ( Shoyaib et al., 2012 ). The generalisation and interpolation ability of these methods facilitate the construction of classi fi ers that have accep-table performance using incomplete training data ( Surendiran and
Alagarsamy, 2010; Paul et al., 2011 ). These methods are expressed with a small number of parameters and need very little storage space; however, it requires more time to compute the skin probability model in comparison to non-parametric methods.
Thus, they can be very slow; a mixture of Gaussians in both training and work, as well as in their performance, depends strongly on the skin distribution shape. Moreover, most of the parametric skin modelling methods ignores the non-skin colour statistics. This aspect, together with the dependence on the skin cluster shapes, results in higher false positive rates compared to non-parametric methods ( Vezhnevets et al., 2003 ). Neural Networks are considered to be the most suitable method to use in parametric skin modelling compared with other methods ( Bhoyar and Kakde, 2010; Doukim et al., 2010; Wylie, 2010; Zolfaghari et al. 2011 ).
 distributions. The key idea of non-parametric skin modelling methods is to estimate skin colour distributions from the training data without deriving an explicit model of the skin colour. The results of these methods are sometimes referred to as the skin probability map, which assigns a probability value to each point in a discrete colour space ( Brand and Mason, 2000; Gomez, 2002 ).
Vezhnevets et al. (2003) and Kakumanu et al. (2007) demon-strated three clear advantages of non-parametric methods: fast training, classi fi cation, and usage. Their performance depends heavily on the training set selection and is theoretically indepen-dent of the shape of the skin distribution, which is not the case for explicit skin cluster de fi nitions and parametric skin modelling.
These methods usually have high true positive and low false positive rates, which indicates that they can fi nd most of the skin regions when the number of non-skin pixels marked as skin pixels is low ( Kakumanu et al., 2007 ). The disadvantages of these methods are that they need a very large amount of storage space and cannot interpolate or generalise the training data. The storage of the (skin | RGB) table, also known as the lookup table (LUT), requires a large amount of memory ( Vezhnevets et al., 2003 ). A solution to this problem is to use a smaller colour space, such as a colour space with 32 3 colours instead of 256 3 colours ( Phung et al., 2005 ). A Na X ve Bayesian classi fi er, however, is considered to be the most suitable method to be used in non-parametric skin model-ling compared with the others ( Zhanyu and Leijon, 2010; Cao and Liu, 2011; Liu et al., 2011 ).
 bines the Bayesian method with a grouping histogram technique and the back-propagation neural network with a segment adjacent-nested technique based on YCbCr and RGB colour spaces, to improve the skin detection performance.
 covers the related research and objectives of the present study.
The proposed system design is described in Section 3 .In Section 4 , the experiments conducted for the proposed skin detector are described. An evaluation and discussion of the results are provided in Section 5 , followed by the research limitations, the research contributions, the future works and conclusions in Sections 6, 7, 8 and 9 , respectively. 2. Literature review proposed based on neural networks or Na X ve Bayesian classi ( Bhoyar and Kakde, 2010 ).
 detection that is based on a pulse-coupled neural network (PCNN). The original input image was translated from RGB colour space to YIQ colour space, and then, a channelled image is obtained.
Elgammal et al. (2009) used the Bayesian approach for skin detection based on an RGB colour space. Wylie (2010) used neural networks for skin detection to detect skin pixels based on an RGB colour space. Their system was, however, prone to picking up objects that are similar in colour, such as hair, which is skin-like.
Wylie has asserted that there is a positive relationship between the number of perceptrons in the hidden layer and the perfor-mance of the skin detector. Bhoyar and Kakde (2010) presented a pixel-based skin colour classi fi cation approach for detecting skin pixels and non-skin pixels in colour images by using a novel neural network symmetric classi fi er based on an YCbCr colour space.
Zhanyu and Leijon (2010) proposed a Bayesian estimation algo-rithm using parameters that are based on an RGB space as the features, and the posterior mean was used as the point estimate of the parameters. The proposed skin detectors are still affected by different lighting conditions. More reliable skin detectors that can work effectively under different lighting conditions are needed. were evaluated, namely combining skin features and combining skin classi fi ers. A major issue in the design of a multi-layer perceptron neural network based on an YCbCr colour space was to determine the optimal number of hidden units given a set of training patterns. The skin detection performance based on their combination strategies are not accurate, as the false is 14.90% due to the mean square error (MSE) results are consistent for few number of neurons in the hidden layer and then the variation occurs until it gives the lowest MSE value of 0.0425 and this is mean that the training error still high due to overlap between the training data.
 based on pre-de fi ned rules of skin colour tones, texture features and a combination of both colour and texture features. In their work, a back-propagation arti fi cial neural network-based RGB colour space was then used to learn the features and to classify any given input, each image the matrices R, G and B are converted into a vector, one parallel after another. This leads to the large training fi le and it cannot take the number of pixels from different images with higher training probabilities. This also prevents the establishment of training a suf fi cient number of pixels for a more credible region in the detection of skin. This shows the limitations of this approach.
 technique that employs a Bayesian decision approach with colour statistics data. The statistics of the skin colour distribution were obtained in YCbCr colour space, and more studies under different lighting conditions must be performed.
 under varying illumination using a local edge-based colour constancy algorithm based on RGB colour space. However, some non-skin pixels with colours similar to skin could be classi as skin pixels.

Zolfaghari et al. (2011) presented a novel method of human skin detection based on a hybrid neural network and genetic algorithm (GA). The back-propagation neural network has been used as a classi fi er, and its inputs were the image pixels' Hue (H), Saturation (S) and Value (V) features. This approach achieved the high detection rate of 98.825%, but pixel-based algorithm on this proposed, classi fi ed each pixel individually without taking into considered the other pixels of the image. For this, the output image from the hybrid method contains some pixels that were non-skin but were classi fi ed as skin.

Naji et al. (2012) presented a reliable colour pixel clustering model for skin segmentation under unconstrained scene conditions. However, the classi fi cation boundary is not likely to provide a good generalisation because it seems to be  X  tuned  X  to the particular training samples, rather than some underlying charac-teristics or true models of the classes that have to be separated. For example, classi fi cation boundaries with thin gulfs or holes are not practical for the task of skin segmentation because the assumption that some regions in a small neighbourhood belong to the skin, whereas the other regions that fall in between is not improbable. The adjacent entry in a colour space show is still very similar colours.

However, the methods above have been criticised for being inef fi cient because of the inability of the detector to fully differ-entiate the pixels that have similar skin tone or colour. Thus, clothing colour, materials, colour, and background are the chal-lenges that are present in detecting true skin. Moreover, the skin pixels were still affected by lighting and its variability in spite of the researchers' attempts to fi nd a solution to these problems. Water and glass re fl ection problems were similarly not addressed by most of the researchers. Hence, the Bayesian and neural network methods do not have an integrated method to address all of the problems mentioned and are, therefore, still inadequate in producing an effective skin detector ( Doukim et al., 2010 ). Thus, the design and implementation that we present in this paper of a skin detector based on multi-agent learning to detect the skin pixels accurately considers the problems of light-changing condi-tions, skin-like colour and re fl ection from glass and the water, as described in next sections. 3. Proposed system design
In developing a reliable skin detector that has a high detection rate, a number of issues pertaining to skin must be resolved. These issues include a skin-like, lighting condition and re fl ection in relation to water and glass. In attempting to resolve these issues, we proposed a system that works and that has two machine learning methods. Multi-agent learning is used to extract the skin regions from the image. The skin detector then goes through a number of processes, as described in Fig. 1 .

The skin detector uses the technique of grouping YCbCr colour histograms (GH) for the Bayesian method. It also uses the segment adjacent-nested (SAN) technique, which is based on RGB applied to a back-propagation (BP) neural network, as shown in the pre-processing phase of Fig. 1 . The images dataset X and Y are used as the training set in multi-agent mapping of the skin and non-skin as well. Next, outputs from the multi-agent training will be taken as inputs for the threshold function in the detecting process. These sets are denoted by the numbers 7 and 9 in Fig. 1 . For the purpose of detection in the skin detector, four parameters were used in the function Fun ( I , N1 , Ps , Pns ), as depicted in the skin detector block of Fig.1 . The parameter I is the original image, while the parameter N 1 is the output from a neural pre-testing process based on a skin detection function, Fun ( i , net ). The last two parameters, Ps and Pns , are the outputs of the Bayesian training process, which imply the probability for a pixel to be a skin pixel and the probability for a pixel to be a non-skin pixel, respectively. The output from the skin detection function Fun ( I , N 1, Ps , Pns ) is an image that contains skin regions with a white background, denoted as II . The study fi ndings show that the proposed multi-agent learning system for skin detection has achieved a TP rate of 98.44% and TN rate of 99.86%. In addition, it has achieved a signi fi cantly lower average rate for the FN and FP (i.e. only 1.56% and 0.14% respectively). 4. Proposed system implementation phases. These phases are the pre-processing phase, the training phase and the testing phase, as described in Sections 4.1 4.1. Pre-processing phase segment adjacent-nested technique under the back-propagation neural network and the grouping histogram technique under the
Bayesian method, as shown in Fig. 1 . These two techniques are, respectively, referred to as SAN ( X &amp; Y ) and GH ( X , Y ) for the training. For the testing, the images will be pre-processed using the segment adjacent-nested technique, as denoted by i  X  SAN ( I ). 4.1.1. The grouping histogram technique gram technique for the entire two-dimensional colour component to be under one uni fi ed container, which is referred to as the grouping histogram technique. The container is sub-divided into smaller compartments or bins that store the number of times a speci fi c colour occurs in the training skin images. In this proposed technique, the Cb and Cr component for each image is extracted from the YCbCr colour space during the image conversion. Then, the histogram of each pixel in the image is calculated. The process is repeated for all of the images. The results are saved in a matrix of 256 256. This step makes the histogram array size have a range between 0 and 255 255  X  65,025 gradients of colour. In this process, the pixels are matched in the 0  X  65,025 pixel range, and grouping is performed accordingly for all of the images, one after another, within the image gradient matrix, and the process is looped until all of the pixels in the images are categorised. The same process is performed for the non-skin images. 4.1.2. Segment adjacent-nested technique
This technique considers the mid-point pixel and the character-istics of the surroundings pixels within a segment, to determine and decide whether the midpoint is skin or otherwise. In other words, the characteristics of the surrounding pixels are signi in giving this technique a higher detection rate in terms of using the back-propagation neural network. The technique is used for both the training and testing of the data. In this process, an image is converted into three matrices ( R , G and B ) and then is made into a string format. Next, it becomes a string concatenation (i.e.,
R  X  G  X  B for each pixel), which is later changed back to a number format that ranges between 000000000 and 255255255, which is the reason why this technique is called adjacent. For example, for a pixel that has R  X  255, G  X  128 and B  X  100, this new technique will convert it into a concatenated string of (string (255)  X  string (128)  X  string (100)), which is then changed to a number (255128100) that occupies a single cell. The pixels are accordingly trained within set range between 000000000 and 255255255, then, windowing is applied for each image using a 3 3 sliding window, in this process that all image pixels can characteristics of the neighbour surroundings pixels are signi fi cant in giving this technique more reliable results comparing with other slide win-dows, such as 5 5or7 7, 9 9or11 11, because; whenever the size of the window has increased, the mid-point will be far away from the edge of the skin so, a lack of the training these pixels will occur; thus a huge number of segments for training images will not be train, and this is will affects negatively to the ef fi ciency of the training; which are leads to increase the like-lihood for false detection. To avoid that, the smaller segment that contains mid-point is used 3 3 sliding window not the others.
Next, the nine pixels in each window are arranged in a vector that has assigned values. The transition between each 3 3 sliding window is one pixel in both the x -axis and y -axis directions of an image, which is the reason why this technique is called nested. In the back-propagation neural network, each target is given a value (i.e., 1 for skin and 1 for non-skin). During the training stage, both the skin and non-skin vectors are automatically presented to the system, in sequence. 4.2. Training phase clustering histogram and segment adjacent-nested vectors for both the skin and non-skin images are computed. The training of the images must be performed only once. During the training phase, the probability density for the grouping histogram of skin and non-skin is calculated (see Fig. 1 )as Ps  X  Fun (GH( X )) and
Pns  X  Fun (GH( Y )), respectively. The trained vectors for the adjacent-nested skin and non-skin segment are calculated, and this process is depicted in Fig. 1 as net  X  Fun (SAN( X &amp; Y )). The most crucial element in this phase is the accuracy of the dataset that covers a wide range of skin colours. It should be noted that there is, so far, no standard image dataset for training the proposed skin detector ( Taqa and Jalab, 2010b ). Consequently, it prepared a dataset of 1200 skin and non-skin images were downloaded from the Internet. This dataset include 600 human images, they were divided into four groups of skin colour images dark Skin, fairly dark, fair skin and pink skin as shown in Fig. 2 . All of the pixels inside the images will be considered in the training process, either in the Bayesian or the neural method for the proposed multi-agent learning system. The skin was manually cropped using
Adobe Photoshop to remove the non-skin pixels from the human images.

Another 600 are categorised as non-skin images and not all of the pixels within the images will be accounted for in the training process. All of the white pixels are discarded during the training. 4.2.1. Description of the neural network training
The neural networks (NNs) are divided in two groups, the probabilistic neural networks (PNNs) and the multi-layer percep-trons (MLPs). The main disadvantage of the PNNs is the fact that all of the training data must be stored in the pattern layer, which requires a large amount of memory. However, in general, today's standard PCs have a suf fi ciently large main memory capacity for an ef fi cient implementation of a PNN. For applications in which large amounts of training cases are available, this argument against PNNs becomes relevant. Although the output of the PNN is probabilistic, we should keep in mind that the probabilities are estimates and are conditional on the learning set. This aspect is considered to be the main reason for choosing (MLPs) rather than other types of NNs ( Yogendra and Jain, 2012 ). Empirically, the best structure of the MLPs architecture for the proposed multi-agent learning system for skin detection comprises three layers, which includes the input layer, the hidden layer (with a speci fi of neurons) and the output layer. Fig. 3 depicts the architecture of the MLPs that we used for the segmentation task; they had nine neurons in the input layer, four neurons in the hidden layer and one neuron in the output layer.

The back-propagation learning algorithm is preferred for train-ing the feed-forward ANN (FF-ANN). Training was performed using 331,282,971 pixels for 1200 images from the skin and non-skin pixels dataset, as mentioned earlier. The fi rst step in training a feed-forward network is to create a network object. The creation function of a feed-forward network requires fi ve arguments, and the network object is then generated. The fi rst argument is an array of sample p -element input vectors, which is  X  Segment Adjacent-Nested Vectors  X  in our case. The second argument is an array of sample t -element target vectors, which are  X  Probability of Skin and Non-skin Indexes  X  . The sample inputs and outputs are used to set up network input and output dimensions and para-meters. The third argument is an array that contains the sizes of each hidden layer. The output layer size is determined from the targets for which more optional arguments can be provided. For example, the fourth argument is a cell array that contains the names of the transfer functions to be used in each layer. The argument contains the name of the training function to be used. If only three layers are supplied, then the default transfer function for the hidden layer is the hyperbolic tangent sigmoid transfer function (tansig), and the default for the output layer is the linear transfer function (purelin) ( Demuth et al., 2005 ). The default training function is the Levenberg  X  Marquardt back-propagation (trainlm) ( Demuth et al., 2005 ). The transfer from input to output inside a layer is achieved by means of an activation function and a transfer function. Typically, the activation function of a layer can be zero (deactivated), one (linear), or non-linear. In our experi-ment, for the proposed multi-agent learning system for skin detection, different activation functions are implemented and investigated to determine the functions that produce optimum results. A back-propagation feed-forward neural network is uti-lised in this paper, and previous research with this method has shown good results ( Taqa and Jalab, 2010b; Doukim et al., 2010; Wylie, 2010; Bhoyar and Kakde, 2010; Zolfaghari et al., 2011 ). Table 3 describes the fl ow and characteristics of the neural part of the skin detector.

The training stage often takes a long time because of the very large amount of calculation that is required on the data. The maximum training time is 8 hours, while 01:13:58 hours is the minimum, based on trial and error.

In this process, the weight matrices between the input and the hidden and output layers are initialised with random values. After repeatedly presenting features of the input samples and desired targets, it compare the output with the desired outcome, followed by error measurement and weight adjustment until the correct output for every input is attained. Furthermore, the hidden layer neurons are estimated using an activation function that features the hyperbolic tangent sigmoid transfer function, whereas, the output layer neuron is estimated using the activation function that features the linear transfer function. The training algorithm used is Leven-berg  X  Marquardt back propagation. To train the neural network for skin detection, a segment are extracted and entered as training input data into the ANN. The quality of the training sets that enters into the network determines how well the detector performs. The training phase of the skin detector is illustrated in Fig. 4 . the parameters given in Table 1 yielded high accuracy results. This conclusion about the design was driven by the experiment results shown in Table 2 , which are graphically depicted in Fig. 5 . This fi gure shows the identi fi cation of the aligned trained data on the target, where the imaginary diagonal represents the target of the ideal data regression. The trained data regression is 0.96574, while the ideal state is 1. In other words, the results show regression analysis for a reducible ANN between two targets, namely, 1 for skin and 1 for non-skin. The results show that the relationship between the network outputs ( Y ) and the targets ( T ) is close and almost perfect; the correlation coef fi cient R is equal to 0.96574, which is almost an ideal fi t. Moreover, from training these pixels, it can be concluded that the training pixels for both the skin and the non-skin using the segment adjacent-nested technique applied to the back-propagation neural network method do not have any overlap.
 decreases until it reaches a stable stage. The error rate is calculated using the mean square error (MSE) function, and the error decreases to 10 4 , as shown in Table 2 , over 1200 iterations. multi-agent learning system for skin detection, as mentioned in
Table 1 . Several separate training experiments and the results of their empirical tuning are given in Table 2 . In the other words,
Table 2 lists all of the trial experiments and the equivalent design for each experiment. These experiments were performed with different parameters, after which the best results were taken. This table shows the performance error minimisation, the linear regression of the targets relative to the outputs and other argu-ments that highlight the most ef fi cient combination.
 iterations but fail to notice a distinct decrease in the perfor-mance (error).

It can be observed that the three-layer architecture has excel-lent performance compared with the equivalent two-and four-layer architectures, for the same parameters. In other words, the results show that the three-layer architecture is better than the other layered architectures for the same criteria.

The training function  X  trainlm  X  gives the best results compared to the  X  trainrp  X  and  X  learngdm  X  with the same parameter selection. 4.2.2. Description of Bayesian training
During the pre-processing phase, the Bayesian clustering his-togram for 1200 images (mentioned earlier in Section 2 )is computed as a lookup table (for both skin and non-skin). The histogram counts are used in the post training, after normalisation of the lookup table, and converted to a discrete probability distribution as shown in Fig. 7 .

The probability of observing a pixel of colour (CbCr) knowing that a skin pixel is observed is denoted by P skin (CbCr) and is calculated as in the following equation: P where skin [CbCr] indicates the value in the histogram bin that corresponds to the colour vector (CbCr). The parameter Norm is the normalisation coef fi cient, which is the sum of all of the values of the grouping histogram bins. The normalised value of the search bins table is the probability that the corresponding colour matches the skin. In a more appropriate sense, skin detection would be P ( skin | CbCr), which is calculated following the Bayesian rule, which is given in the following equation ( Flach and Lachiche, 2004 ): P  X  skin j CbCr  X  X  P The probabilities P (CbCr | skin ) and P (CbCr | skin ) are calculated directly from the skin and non-skin grouping histograms. The prior probabilities P ( skin ) and P ( skin ) can be estimated easily from the total number of skin and non-skin pixels in the training set, as shown by Eqs. (3) and (4) , respectively ( Chai and Bouzerdoum, 2000; Flach and Lachiche, 2004 ): P  X  skin  X  X  T s T P  X  skin  X  X  T n where T s and T n are the numbers of skin and non-skin pixels, respectively. After completing the training of the data, we saved the probability results into two fi les. For skin, it is saved in  X 
ProSkin.mat  X  , and for non-skin, the result is in  X  ProNonSkin. mat  X  , which is denoted as Ps and Pns , as shown in Fig. 1 earlier. Fig. 8 (a and b) shows the container values that portray the distribution of the skin pixels, non-skin pixels and their corre-sponding characteristics. Furthermore, both of the fi gures, respec-tively, describe the distribution of the output of the probability for the grouping histogram technique for the skin pixels and non-skin pixels. The two container images are represented on the same range, and they are from 0 to 255 for each of the Cb and Cr colour components. These containers are divided into four quadrants. It is important to note that, in Fig. 8 (a), the distribution of the skin pixels is mostly in the fi rst quadrant of the fi gure within the range 19 o Cb o 135 when 135 o Cr o 235, where Cb, Cr  X  [0, 255] while in Fig. 8 (b), the distribution of the non-skin pixels is mostly in the other three quadrants of the fi gure. From this pixel distribution, it can be concluded that the probabilities of the training pixels for both the skin and non-skin pixels using the grouping histogram technique under the Bayesian method do not overlap. Even if they do overlap, the number of overlaps is negligible, as shown in Fig. 8 (c).

The rationale for using these datasets is that they have adequate pixel distribution characteristics between the skin and non-skin and are, therefore, considered to be ideal for training. 4.3. Detection phase
Throughout this detection phase in the proposed multi-agent learning of the skin detector, the pre-processing are processed in the same manner as in training phase, as shown in Fig. 9 .
In addition, this phase is used in the performance evaluation of the proposed skin detector.
 obtained from the previously described training of Bayesian and pre-detecting neural methods. The three sets of results, namely  X  Neural.mat  X  ,  X  ProSkin.mat  X  and  X  ProNonSkin.mat  X  . The computa-tion would progress through the process and fi nally determine or detect the skin pixels of the original image. The output is a new image in which only the skin pixels are returned, while the non-skin pixels are considered as white pixels as that shown in Fig. 9 .
The details of the procedures are described in the following: 1. Each pixel of the original image is input, and its probability is 2. The matched pixels are saved in two variables, namely, nn , .
 3. The variable  X  is de fi ned in Eq. (7) , as follows: which represents the adjustable threshold, where the costs of the false classi fi cations are manipulated by C 12 and C 21 for the false detection and false dismissal rates, respectively. The costs of the correct classi fi cations (i.e., C 11 and C 22 ) are typically set to zero, which means that the fi nal (  X  ) value can be calculated by Eq. (8) ,as follows:  X   X  C 12
The multi-agent combination uses a parallel method to arrive at a crucial and accurate decision point. A successive connection method was not used because it would not be able to address error issues. More speci fi cally, in a successive connection method, the treatment would be based on the error handler, and the result would diffuse, and hence, the error would not be resolved. A parallel connection method, on the other hand, will account for all of the expected cases of the machines learning's logic, whether it is from the Bayesian method or the back-propagation neural network, and would subsequently choose what is true for the parties on either side. It uses the  X  OR  X  connection between these methods. The results of the multi-agent system will go through all of the image pixels of I with the threshold according to Eq. (9) , which describe actions that take place under the same conditions. N 1  X  Pix x ; y  X  X  skin if N 1 Bayesian  X  Pix x ; y  X  X  8 Pix x ; y ; N 1  X  Pix x ; y  X  o 0 OR Bayesian  X  Pix x ; y where parameter N 1( Pix x , y ) is the second parameter for function second steps. The thresholds are considered based on two aspects. First, ( N 1( Pix x , y ) o 0), which represents the neural part, where 0 was chosen based on Fig. 5 . It was shown that the range of training for non-skin pixels was lower than zero, and the range of training for skin pixels was greater than zero. From these points, we considered the boundary between the skin and non-skin pixels to be 0. Second, (Bayesian  X  Pix x ; y  X  o  X  ), which represents the Baye-sian part. Here, the value of the threshold  X  was chosen to be 0.9, based on the results of multiple experiments with different thresholds during the validation dataset in the construction of the skin detector. More details on this choice will be discussed Section 5.2 . In summary, if the set condition is satis fi pixel refers to the non-skin, and [255255255] is assigned to refer from the original image I . The collected pixels from the set condition are skin pixels, which is labelled II in Fig. 1 . Using multi-agent learning will detect the skin pixels with a high detection rate while maintaining the speed of the computations because the proposed method performs a statistical calculation, which is where the unique strength of the approach lies. In this connection, it is noted that both of the machine learning processes are trained separately, which is the reason why the training speed is not affected in the multi-agent learning. The multi-agent learning system for skin detection can retrieve the skin pixels from the original image and results in a high success rate with low false positives and false negatives. The supporting results will be shown in Section 5 . 5. Evaluation and discussion of the results
An evaluation and discussion of the results of the proposed skin detector will be presented in this section; it will focus on the ability of the proposed techniques to resolve the problems men-tioned in Section 1 . This section includes a discussion of the results related to the multi-agent learning system for skin detection. Then, we provide a comparison of the test results between the proposed multi-agent system and among other existing standards in the skin detection application, followed by a receiver operating characteristic (ROC) curve for the segmentation performance. 5.1. Discussion results related to the multi-agent learning system for skin detection In this paper, the skin detection was conducted on a 3.00 GHz Intel (R) Core TM 2 Duo processor with 8 GB RAM on a Windows Vista platform using MATLAB R2012b. The proposed system can resolve the skin detection problem. The colour space for the proposed system is composed of two parts. First, the YCbCr colour space employing the grouping histogram clustering technique is used for the Bayesian method. For the skin segmentation to become more robust when the lighting has variations in lumi-nance, the Y component of the pixel is discarded ( Zaidan et al., 2010a, 2010b ), and the Cb and Cr colour components are used. Classi fi cation will, therefore, be based on only the Cb and Cr, which will limit the search and speed up the calculation in identifying regions of human skin. More speci fi cally, the colour space is quanti fi ed in a number of containers, each of which corresponds to a speci fi c set of pairs of colour component values in two dimensions. However, it faces the colour gradient range and timing issues when computing the histogram of each container. With the two-dimensional colour components, the computing time for the histogram is doubled. Furthermore, the problem that involved the colour gradient range was that the colour component range is only 0  X  255 for each colour, which affects the ability to distinguish between the skin pixels and the other pixels in relation to the lighting variations problem. When the value of the colour component is in two dimensions, such as Cb and Cr, the training location for these colour components has 512 positions. These possibilities are further divided into 0  X  255 for Cb and 0
The underlying issue here is that, currently, there is no technique to address the colour gradients of the skin pixels, which are extracted from the skin images collectively ( Vezhnevets et al., 2003 ). For the histogram, we have modi fi ed the histogram technique for the Bayesian method, as mentioned in Section 4.1.1 . Here, it uses a clustering-based grouping histogram techni-que for grouping the skin and the non-skin pixels. The results are saved using two matrices, each with 256 256 for skin and non-skin, respectively. This arrangement makes a histogram array for each, with the value range from 0 to 255 255  X  65,025 gradients of colour instead of 0  X  255 only for each of the colour components. Thus, using this range, we can determine the gradient of the pixels in each colour component accurately in terms of resolving the colour gradient range problem. Using the same technique, the entire two-dimensional colour component range will be under one uni fi ed container instead of two containers. This step is performed to resolve the timing problem. Therefore, the GH technique can solve the problems that relate to the timing and colour gradient range. As a result, this technique can solve the problem of the lighting variation. Fig. 10 shows the results of the proposed skin detector, which are robust to lighting variation.
Second, the commonly-used pure colour components RGB colour space for coloured digital images is used for the back-propagation neural network, for the skin detection to become more robust and address skin-like tones. A neural network method uses a pixel-based technique to detect the skin pixels ( Taqa and Jalab, 2010b ). For each image, the matrices R , G and B are converted into a vector, one after another or in parallel with one another. This process contributes to having a large training or testing fi le and it cannot take pixels from different images that have higher training probabilities. For example, for a pixel with R  X  255, G  X  128 and B  X  100, the pixel will take three cells, i.e., cells (255), (128) and (100). This arrangement leads to a space problem when testing or training the pixels. This arrangement also pre-vents the training of a suf fi cient number of pixels to produce a more credible region in the detection of skin. Moreover, the problem of distinguishing the edge of the skin region from a different background still exists ( Lee et al., 2007 ). These problems directly affect the ability to distinguish between the skin pixels and the skin-like pixels. Hence, we proposed a new technique called the segment adjacent-nested (SAN) technique, as men-tioned in Section 4.1.2 . The back-propagation neural network with a segment adjacent-nested technique based on RGB colour space is used. In this newly proposed technique, the R , G and B compo-nents for each pixel are taken and converted into a string. The concatenated string (RGB) is converted to a new number, based on the same pixel arrangement as in the original image. In other words, the pixels numbers are arranged between 000000000 and 255255255 in each pixel to indicate the position of the concatenation (RGB) in the image. This procedure is performed to resolve the spacing problem. In this technique, this procedure can increase the number of different colour pixels that come from different images and that are used in the training phase, and subsequently, the procedure can increase the performance of the skin detector. This technique considers the mid-point pixel and the characteristics of the surrounding pixels within a segment, to determine and decide whether the midpoint is skin or otherwise. This procedure is performed to resolve the edge of the skin region problem. Thus, the proposed SAN technique can solve problems in relation to the spacing and edge of the skin region. In other words, this technique will not produce a large amount of skin-like colour as a condition of using the second part of the multi-colour space. Fig. 11 shows sample results from the proposed skin detector that highlight the robustness to the skin-like colour problem.
After further analysis and scrutiny, we have shown that the water and glass re fl ection problem technically emerges due to a combina-tion of skin-like and lighting condition problems. This fi that if one can avoid the skin-like colour problem issues together with the elimination of the lighting changes problem, it would then together resolve the water and glass re fl ections problem; this approach is depicted in Figs. 12 and 13 , respectively. These imply that using the grouping histogram technique for the Bayesian method or the adjacent segment-n ested technique for the back-propagation neural network alone is insuf fi cient to produce results withahighreliability.Inotherwords,theskindetectorisnotreliable if only one proposed method is used. Therefore, the hybrid method remedies this problem by using a multi-decision for both methods. This approach is called multi-agent learning.

From the initial test for the multi-agent learning system for skin detection, it was found that any increase in skin-like colour would increase the rate of false positives. This increase would, in turn, reduce the true negatives, implying that the skin detector that was used is not reliable. A total of 400 skin and non-skin images were used in the fi rst training that used the multi-agent learning method. It is worth noting that the skin detector is formed by 9,244,195 hand-labelled skin pixels from 200 skin images. These images were divided into four groups of skin colour images, which include 50 dark-skin images, 50 fairly dark-skin images, 50 fair-skin images and 50 pink skin images, and 45, 450, 410 hand labelled non-skin pixels from 200 non-skin images under different levels of colour. From the testing that was performed, inaccuracy in the skin detection arose due to some pixels that were not skin but were detected as skin. In fact, the opposite is true, and this inaccuracy. What actually happened was that there was an overlap in the skin and non-skin pixels during the training. This overlap is a signi fi cant problem that concerns where there are shared pixels in the skin and non-skin cases. The effect of this problem can be minimised by training the skin and non-skin pixels in a grey colour on more images, including different tones of skin and non-skin pixels. To address the wide range of skin colours and overcome the problems that arise from the initial test of the multi-agent learning system for skin detec-tion, more images of skin and non-skin were added during the training phase of the proposed skin detector. The fi rst test is on the number of skin images that had been used in the training. Thus far, 400 skin images have been added to the system with a wide range of skin colours, to avoid the overlapping of skin-like in the skin images. These images include 100 dark-skin images, 100 fairly dark-skin images, 100 fair-skin images and 100 pink-skin images.
Second, to avoid the overlapping of skin-like in non-skin images regions, another 400 non-skin images were added to the system, comprising 200 samples for the skin-colour objects and 200 samples for the skin-colour hair, respectively. These images were used in the training phase to train the system to differentiate between different types of skin and non-skin pixels, to avoid the duplication or overlapping of skin-like colours. Altogether, the total number of images that were used is 1200 images for both skin and non-skin, and these represent 3,794,256 skin-like pixels.
For each line in the 3 3 sliding window, there are 9 pixels, which resulted in 3,794,256 9  X  34,148,304 pixels for all of the skin tones. The 33,014,963 non-skin-like pixels have resulted in 33,014,963 9  X  297,134,667 pixels for the neural network train-ing. The total number of skin and non-skin pixels under the neural network is 331,282,971 pixels. In the Bayesian method, the train-ing for the skin involves 34,148,304 pixels, with all of the skin tones, and 380,976,578 pixels for non-skin. Overall, the total number of skin and non-skin pixels under the Bayesian method is 331,282,971 pixels. Altogether, in the multi-agent learning method, the total number of skin pixels is 68,296,608 pixels (34,148,304 for neural  X  34,148,304 for the Bayesian method), and 678,111,245 pixels (297,134,667 for neural  X  380,976,578 for the Bayesian method) are non-skin. The multi-agent learning method-based skin detector is considered to be an appropriate and effective way to detect skin pixels with high precision and reliability, as shown in Figs. 10  X  13 earlier. 5.2. Comparison of the test results between the skin detectors using the proposed multi-agent learning system and the among other approaches terms of TP, FP, TN, and FN and was computed for all of the pixels in the  X  skin classi fi er testing set  X  through the skin segmentation testing ( Naji et al., 2012 ). TP is the proportion of skin pixels that are classi fi ed correctly as skin pixels while FN is the proportion of skin pixels that are classi fi ed incorrectly as non-skin pixels. On the other hand, TN is the proportion of non-skin pixels classi correctly as non-skin pixels while FP is the proportion of non-skin pixels classi fi ed incorrectly as skin pixels. The combination of TP and FN represent the skin area while the TN and FP represent the background area without skin pixels. The test and validation datasets consists of 600 images selected at random from the Compaq database; these images are consisting of 300 samples for validation and 300 samples for testing datasets.

In addition, we have used TP, FP, TN and FN to arrive at an appropriate threshold decision in the Bayesian method as part of the proposed multi-agent learning system for skin detection. Table 3 depicts the results of empirical tuning, based on several thresholds that are listed. Those thresholds were used on the validation images, after which the best threshold results were taken. The table also lists all of the trials' TP and FP rate for each threshold. This table shows that the chosen criteria are dependent on their threshold, which depends on the minimum FP and the maximum TP for highlighting the most ef fi cient combination.
As tabulated in Table 3 , the highlighted row is the average used in the proposed skin detector in relation to selecting the threshold of 0.9. In the other words, it concludes that the best Bayesian threshold in the proposed skin detector has a value of 0.9. This threshold provides the best results compared to the other thresh-olds, and attains 98.68% for the TP, 0.09% for the FP, 99.91% for the TN, and 1.32% for the FN. In order to evaluate the testing results of the proposed skin detector using the threshold 0.9 which is obtained based on the validation dataset, we will used the testing dataset. The testing sets divided into three groups. The fi contains 100 images with skin-like colour, while the second group contains 100 images under different lighting conditions. The third group contains 100 images under the re fl ective glass or water category. The outcome of using the proposed skin detector on these images was signi fi cant because it solved all of the problems faced by the skin detectors. The averages of TP, FP, TN and FN attributes in three groups for images testing were used as shown in Table 4 .
Based on Table 4 , a distinctively the averages of the three test cases for evaluation attributes that the proposed skin detector has achieved attains 98.44% for the TP, 99.86% for the TN, 0.14% for the FP and 1.56% for the FN. Table 5 shows the comparison of the experimental results of the proposed method with the other standard skin classi fi ers and de fi nitively shows that the proposed skin detector has achieved a high average rate of 98.44% with regard to the TP and again accomplished a high average rate of 99.86% with regards to TN. Similarly, at the other end, it has achieved a very low average rate of FN (i.e. only 1.56%) and a very low average rate of FP (i.e. only 0.14%). The proposed method shows a signi fi cance increase in the average rate of the TP while reducing the average rate of the FP compared with the other methods. 5.3. ROC curve for segmentation performance
We computed performances by using receiver operating char-acteristic (ROC) curve analysis. We sampled 300 images. The values of T skin (the multi-threshold system used for skin segmen-tation) were between [0, 1]. For each value of T skin , the pixels in the testing set were classi fi ed as w 1or w 2, referring to Eqs. (5) and (6) . Then, the classi fi ed pixels were compared against the ground truth to determine the total number of true positives (TPs) and false positives (FPs). The TPs and FPs were normalised by dividing by the total number of skin pixels and non-skin pixels. The coordi-nates of [normalised FP, normalised TP] were used to describe the performance on the skin detection for a given T skin . Then, the ROC curve was formed by taking the locations with the highest normalised TP for a given normalised FP and is shown in Fig. 14 . Refer to Table 4 for the rankings. 6. Research limitations
The multi-agent learning system for skin detection is a combi-nation between a Bayesian method with a grouping histogram technique based on the YCbCr colour space and the back-propagation neural network with a segment adjacent-nested technique based on RGB colour space; this system was implemen-ted. The proposed module considers skin-like colour pixels, the lighting conditions, and water and glass re fl ection problems. The simulation of a skin detector system that is discussed in this paper, however, does not include black colour images because the skin detector used is unable to detect images that are black in colour. 7. Research contributions
The contributions of the proposed skin detector are sum-marised in the following points:
Proposed a novel technique called grouping histogram based on the YCbCr colour space. This approach is the pre-processing technique used for the Bayesian method.
 8. Potential future works 9. Conclusions involving the technique of a grouping histogram for the Bayesian method and a back-propagation neural network with an adjacent segment-nested technique. These techniques are based on two colour spaces, namely, YCbCr and RGB, respectively. The results produced by this hybrid method are signi fi cant because a number of goals have been obtained; as a result, we have the following conclusions:
The grouping histogram technique with the Bayesian method can distinguish the skin and non-skin pixels more accurately. In other words, the segmentation of skin in the proposed skin detector has become more robust even under different lighting conditions. This result is a signi fi cant accomplishment because existing skin detectors were unable to resolve this sensitivity issue when the images were captured under different lighting conditions.

The adjacent segment-nested technique with the back-propagation neural network can fi lter the skin-like colour pixels. This part makes the proposed skin detector more reliable and thereby improves its performance. This step is also a signi fi cant accomplishment because existing skin detectors were not able to resolve the skin-like issue.

The above-mentioned hybrid method makes the segmentation of the skin become more robust with respect to water and glass re fl ections, which is yet another attainment that was pre-viously not accomplished by others. Furthermore, the proposed multi-agent learning system for skin detection has produced a signi fi cance TP and TN average rate, i.e., 98.44% and 99.86% respectively. In addition, it has achieved a signi fi cant low average rate for the FN and FP, i.e., only 1.56% and 0.14% respectively. Another pertinent achievement of the proposed skin detector is that only the skin pixels are traced from the image input, which means that the search spaces of the image pixels have been greatly reduced. It can be concluded that the development of the proposed skin detector is signi fi cant because it can detect skin pixels more accurately.
 References
