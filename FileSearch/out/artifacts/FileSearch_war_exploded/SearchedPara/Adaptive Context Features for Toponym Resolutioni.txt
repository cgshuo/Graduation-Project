 News sources around the world generate constant streams of information, but effective streaming news retrieval re-quires an intimate understanding of the geographic content of news. This process of understanding, known as geotag-ging , consists of first finding words in article text that corre-spond to location names ( toponyms ), and second, assigning each toponym its correct lat/long values. The latter step, called toponym resolution , can also be considered a classi-fication problem, where each of the possible interpretations for each toponym is classified as correct or incorrect. Hence, techniques from supervised machine learning can be applied to improve accuracy. New classification features to improve toponym resolution, termed adaptive context features , are introduced that consider a window of context around each toponym, and use geographic attributes of toponyms in the window to aid in their correct resolution. Adaptive pa-rameters controlling the window X  X  breadth and depth afford flexibility in managing a tradeoff between feature compu-tation speed and resolution accuracy, allowing the features to potentially apply to a variety of textual domains. Ex-tensive experiments with three large datasets of streaming news demonstrate the new features X  effectiveness over two widely-used competing methods.
 H.3.1 [ Information Storage and Retrieval ]: Content Analysis and Indexing Algorithms, Design, Performance Toponym resolution, geotagging, streaming news, adaptive context, machine learning  X  T his work was supported in part by the National Science Foundation under Grants IIS-10-18475, IIS-09-48548, IIS-08-12377, and CCF-08-30618.

Today X  X  increasingly informed and connected society de-mands ever growing volumes of news and information. Thou-sands of newspapers, and millions of bloggers and tweeters around the world generate constant streams of data, and the demand for such data is skyrocketing as people strive to stay up-to-date. Also, Internet-enabled mobile devices are increasingly common, which expands the requirement for location-based services and other highly local content X  information that is relevant to where users are, or the places in which they are interested. News itself often has a strong geographic component, and newspapers tend to character-ize their readership in terms of location, and publish news articles describing events that are relevant to geographic lo-cations of interest to their readers. We wish to collect these articles and make them available for location-based retrieval queries, which requires special techniques.

To enable news retrieval queries with a geographic com-ponent, we must first understand the geographic content present in the articles. However, currently, online news sources rarely have articles X  geographic content present in machine-readable form. As a result, we must design algo-rithms to understand and extract the geographic content from the article X  X  text. This process of extraction is called geotagging of text, which amounts to identifying locations in natural language text, and assigning lat/long values to them. Put another way, geotagging can be considered as enabling the spatial indexing of unstructured or semistruc-tured text. This spatial indexing provides a way to exe-cute both feature-based queries ( X  X here is X happening? X ) and location-based queries ( X  X hat is happening at location Y ? X ) [5] where the location argument is specified textually rather than geometrically as in our related systems such as QUILT [34] and the SAND Browser [31]. Geotagging methods have been implemented in many different textual domains, such as Web pages [3, 23, 27], blogs [28], ency-clopedia articles [14, 36], tweets [33], spreadsheets [2, 17], the hidden Web [19], and of most relevance for us, news articles [8, 11, 18, 20, 21, 29, 32, 37]. Particular domains such as blogs and tweets may pose additional challenges, such as having few or no formatting or grammatical re-quirements. The methods in this paper were applied in the NewsStand system [37], which uses a geotagger to assign ge-ographic locations to clusters of news articles based on their content, which allows users to visually explore the news in NewsStand X  X  interactive map interface. Also, several com-mercial products for geotagging text are available, such as tigate here.

Geotagging consists of two steps: finding all textual ref-erences to geographic locations, known as toponyms , and then choosing the correct location interpretation for each toponym (i.e., assigning lat/long values) from a gazetteer (database of locations). These two steps are known as to-ponym recognition and toponym resolution , the second of which we investigate here, and are difficult due to ambigu-ities present in natural language. Importantly, both these steps can be considered as classification [10] problems: To-ponym recognition amounts to classifying each word in the document X  X  text as part of a toponym or not, and toponym resolution amounts to classifying each toponym interpreta-tion as correct or incorrect. With this understanding, and with appropriately annotated datasets, we can leverage tech-niques from supervised machine learning to create an effec-tive geotagging framework. These techniques take as input sets of values known as feature vectors , along with a class la-bel for each feature vector, and learn a function that will pre-dict the class label for a new feature vector. Many such tech-niques for classification, and other machine learning prob-lems, exist and have been used for geotagging purposes, in-cluding SVM [4, 13, 24], Bayesian schemes [9, 12, 41], and expectation maximization [6].

The effectiveness of such techniques for a given problem domain depends greatly on the design of the input features that comprise each feature vector. One common feature used for geotagging is the population of each interpretation, since larger places will tend to be mentioned more frequently and are more likely to be correct. However, using population alone or overly relying on it, as many methods do, resulted in greatly reduced accuracy in our experiments, especially for toponym recall. Instead, in this paper, we consider a new class of features to improve the accuracy of toponym resolution, termed adaptive context features . These features construct a window of variable size around each toponym t , and use the other toponyms in the window to aid in resolv-ing t correctly by considering the geographic relationships between interpretations l t of t and those of other toponyms in the window. In particular, we search for interpretations that are geographically proximate to l t , or are siblings of l in terms of a geographic hierarchy (e.g., cities in the same state). The more such relationships appear in the window, the greater evidence there is that l t is the correct interpre-tation of t . These window features are a natural extension of other context-sensitive features which depend on other words nearby the toponym, such as object/container and comma group [20] evidence, as well as pairing notions such as pair strength [19].

We call these features adaptive because the window X  X  pa-rameters can be varied for different domains, or to achieve different ends. Some relatively small windows can contain a significant number of highly ambiguous toponyms, especially for toponyms at fine scales [26], and considering all possible combinations of interpretations places inhibitive penalties on feature computation speed. For example, consider Fig-ure 1, which is an excerpt from a press release [25] published in the Earth Times newspaper, with toponyms highlighted and the numbers next to each toponym indicating the num-ber of interpretations in our gazetteer for the toponym. If http://metacarta.com http://opencalais.com http://developer.yahoo.com/ge o/placemaker Figure 1: Excerpt from an Earth Times press release [25] with toponyms and their number of interpretations high-lighted, showing the extreme ambiguity of these toponyms and illustrating the need for adaptive context features. we consider all possible combinations of resolutions for these toponyms, this results in about 3 10 17 possibilities, an as-tonishingly large number for this relatively small portion of text, which is far too many to check in a reasonable time. Instead, we can set parameters which we term the window X  X  breadth and depth , named analogously to breadth-first and depth-first search, which control the number of toponyms in the window and the number of interpretations examined for each toponym in the window, respectively. The adaptive context features thus afford us flexibility since by varying these parameters, we can control a tradeoff between feature computation time and resolution accuracy. The more to-ponyms and toponym interpretations we examine, the more likely we are to find the correct interpretation, but the longer resolution will take, and vice versa. Some textual domains such as Twitter, where tweets arrive at a furious rate, de-mand faster computation times, while in other, offline do-mains, the time constraint is relaxed and we can afford to spend more time to gain higher accuracy. While window-like features and heuristics have been used in other work related to geotagging (e.g., [15, 16, 24, 30, 35, 42]), these features X  adaptive potential has not been explored.

As we pointed out, in this paper our focus is on toponym resolution, while toponym recognition makes use of our pre-vious work [18]. Our work differs from that of others in a number of ways, including our focus on streaming data, and most importantly the size of the domain of the data used in our evaluation. In particular, in our evaluation we make use of articles from a large set of news sources, many of which are from small localities, and the domain of loca-tions is very large, as evidenced by our gazetteer containing 8.1M location interpretations, in contrast to systems such as Web-a-Where [3] which contains only about 30,000 loca-tion interpretations. The rest of this paper is organized as follows: Section 2 introduces the geotagging framework that enables us to test our adaptive context features, and de-scribes our toponym recognition and resolution processes as a whole. We also introduce several other features that com-plement our adaptive context features and serve as baselines for comparison. Section 3 describes our new adaptive con-text features, as well as algorithms for their computation. Section 4 details extensive experiments showing our meth-ods X  performance benefits over OpenCalais and Placemaker, that also test various feature combinations and parameters. Finally, Section 5 offers potential avenues of future work and concludes.
In this section, we present the framework that enables testing of our geotagging methods. This framework was originally developed for and is an integral component of the NewsStand [37] and TwitterStand [33] systems. We describe our toponym recognition (Section 2.1) and resolution (Sec-tion 2.2) procedures, as well as a set of baseline features ( Section 2.3) that we use in combination with our adaptive context features, which will be presented in Section 3.
Our toponym recognition procedure is designed as a mul-tifaceted process involving many types of recognition meth-ods, both rule-based and statistics-based. After an initial to-kenization step, our method proceeds by performing lookups into various tables of entity names, including location names and abbreviations (e.g.,  X  X aryland X , X  X d. X ), business names (e.g.,  X  X pple X ,  X  X oyota X ), person names (e.g.,  X  X had X ,  X  X ic-toria X ), as well as cue words for the above types of entities (e.g.,  X  X County X ,  X  X r. X  X ,  X  X Inc. X ). We also refactor geographic names by shifting particular cue words (e.g.,  X  X Lake X  to  X  X ake X  X ).

In addition to the above rule-based methods, we leverage statistical NLP tools. We use an NER package to recognize toponyms and other entities, and perform extensive postpro-cessing on its output to ensure higher quality. We also per-form part-of-speech (POS) tagging to find phrases of proper nouns, since names of locations (and other types of entities) tend to be composed of proper nouns. The POS tagging also provides a means of recognizing additional grammatical forms that hint at entities X  types, including active verbs and noun adjuncts, which we use as signals to adjust entity types. Furthermore, we incorporate evidence from other documents in the document X  X  news cluster. After the above recognition steps, we establish groups of entities to be resolved at the same time, by grouping similar entities together.
This multifaceted recognition procedure is designed to be flexible to capture variations that appear in streaming news, and also to be as inclusive as possible when recognizing to-ponyms, to maximize toponym recall, which comes at the cost of lower precision. Our recognition procedure X  X  high recall is also corroborated by experimental results in Sec-tion 4.3. Since toponym recognition is only the first step in a two-part geotagging process, our toponym resolution methods will serve to restore precision to the entire process.
As mentioned earlier, geotagging can be understood as a classification problem, and we use methods from supervised machine learning to implement toponym resolution. Specif-ically, we cast it as a binary classification problem, in that we decide for a given toponym/interpretation pair ( t, l t whether l t is correct or incorrect. These location interpre-tations are drawn from a gazetteer , which is a database of locations and associated metadata such as population data and hierarchy information. Our gazetteer, which is based on used in geotagging methods, which both increases our meth-ods X  utility as well as geotagging X  X  difficulty. We characterize our gazetteer further in our experiments in Section 4.1.
For our classifier, we use a decision tree-based ensemble classifier method known as random forests [7], which has state-of-the-art performance for many classification tasks. Briefly, given an annotated training dataset, the random forests method constructs many decision trees based on dif-ferent random subsets of the dataset, sampled with replace-ment. In addition, each decision tree is constructed using random subsets of features from the training feature vectors. Because the features and subsets are chosen randomly, a va-riety of trees will be in the forest. Classifying a new feature http://geonames.org v ector is relatively simple: each tree in the forest votes for the vector X  X  class, and the consensus is taken as the result. Note that individual trees may be excellent or poor class predictors, but as long as some features allow better-than-random classification, the forest taken as a whole will be a strong classifier. Another useful aspect of random forests is that the number of trees that vote for a given class can be used as a confidence score for the classification, and pro-vides a means of tuning the precision/recall balance of the classifier. Assuming the score is an accurate estimate of the method X  X  predictability, accepting classifications with a lower score will result in lower precision but higher recall, and vice versa. For our implementation, we used the fast
As an alternative to classification, Martins et al. [24] con-sidered the use of SVM regression to estimate a distance function based on feature vector values that is intended to capture the distance between a given l t , and t  X  X  ground truth interpretation. They use the resulting distance values to rank the interpretations, essentially using them as confi-dence scores, and select the one with smallest distance value as the interpretation for t . However, a significant drawback of this technique is that it assumes that all toponyms in-put to the toponym resolution process are not erroneous, i.e., that the toponym recognition procedure is perfect in identifying toponyms, while in reality, no such procedure is perfect. The distance measures they compute, while use-ful for ranking, are not necessarily meaningful as confidence scores for deciding whether a given l t has strong enough evidence to consider it correct. For example, an inferred distance of  X 10 X  may indicate strong evidence for a given l , but weak evidence for another. On the other hand, our framework using random forests and their confidence scores provide consistent and meaningful scores for deciding clas-sification strength.
In addition to the adaptive context features introduced in the next section, we use several baseline toponym reso-lution features in our methods. To borrow terms from lin-guistics, these features, which will be computed for each toponym/interpretation pair ( t, l t ), can be loosely classed as what we term context-sensitive and context-free features. Put simply, context-sensitive features depend on t  X  X  posi-tion in relation to other toponyms in the document, while context-free features do not. Note that our adaptive context features subsume and generalize context-sensitive features, so we will describe them in the next section. On the other hand, the context-free features we use include the following: I: interps . Number of interpretations for t ; more interpre-P: population . The population of l t , where a larger popu-A: altnames . Number of alternate names for l t in various D: dateline . Geographic distance of l t from an interpreta-L: locallex . Geographic distance of l t from the newspa-http://code.google.com/p/fast -random-forest http://www.cs.waikato.ac.nz/ml/weka The interps , population , and altnames features are do-main independent, i.e., they can be used in any textual do-main, while the dateline and locallex features are specific to the news domain. In our experiments in Section 4.4, we consider these features alone and in various combinations to understand each feature X  X  relative utility.
In this section, we present our adaptive context features to aid in the resolution of toponyms. These features reflect two aspects of toponym coocurrence and the evidence that interpretations impart to each other, which include: 1. Proximate interpretations, which are both nearby in 2. Sibling interpretations, which are nearby in the text We capture these interpretation relationships and encode them in features. To compute these features, we examine for each toponym t a window of text around t , and com-pare interpretations of toponyms in the window with the interpretations of t . That is, a given interpretation l t is promoted if there are other interpretations of toponyms in the window that are geographically proximate to it, or are sibling interpretations. In addition, we vary two pa-rameters of the window termed window breadth and window depth , which control a tradeoff between computation speed and discriminative utility for the features by changing the number of toponyms in the window, and the number of in-terpretations per toponym, respectively.

Figure 2 is a schematic representation of the algorithm used to compute our features. Each box represents a to-ponym, and the lines under the boxes represent location interpretations for each toponym. Different toponyms have different levels of ambiguity, as measured by the number of interpretations for the toponyms. In Figure 2, we are computing adaptive context features for the highlighted to-ponym and its interpretations in the middle. We compute these features for all toponyms at a document distance of less than the window breadth w b , and we compare the first few interpretations of each toponym in the window, up to a maximum of w d interpretations, the window depth.
Note that our proximity and sibling features subsume and generalize other commonly-used features in toponym res-olution. In particular, these features generalize context-sensitive features, which compute a toponym interpreta-tion X  X  likelihood of correctness based on the other toponyms nearby to it in the document. One example of these context-sensitive features includes the object/container pair (e.g., Paris, Texas , Dallas in Texas ), consisting of two toponyms, one of which contains the other. Authors use them when their audiences are not familiar with the location in question, and use the containing toponym to provide a geographic context for the toponym. Object/container pairs are a par-ticularly common type of evidence used in many types of documents, and much research has investigated its utility (e.g., [3, 16, 21, 30, 35]). This type of evidence can be un-derstood as an extreme case of our sibling feature, in the case where the window is restricted to the immediately next or preceding toponym. More general than object/container pairs is the comma group [20], which consists of a sequence of toponyms adjacent to each other separated by connec-tor tokens (e.g.,  X  Paris , Dallas , San Antonio and Houston  X ) that share geographic characteristics (in our example, all cities in Texas), and hence provide mutual evidence for each others X  correct interpretations. These relationships can be captured using our features with a window of appropriate size to contain all the toponyms. Another difference between these sources of evidence and our adaptive context features is that we do not assume any meaning for the specific position of toponyms within the window. For example, we do not consider the grammatical structure involved, or the tokens present between toponyms in the window. This increases the flexibility of our features as compared to, e.g., comma groups, whose recognition depends on specific wording and organization of the toponyms. As noted by Lieberman et al. [20], comma groups in particular can be constructed in var-ious ways that can mislead rule-based heuristics, such as in our original example in Figure 1.

The following sections describe our proximity (Section 3.1) and sibling (Section 3.2) features, and the algorithms we use to compute them (Section 3.3). We also describe a strategy for propagating significant feature values for a toponym to its other instances in the same document (Section 3.4).
The proximity features we use are based on geographic distance. Because this distance is continuous, appropriate thresholds for what is considered  X  X ear X  and  X  X ar X  are not apparent. Thus, it behooves us to defer their definitions to learning algorithms that can learn appropriate and mean-ingful distance thresholds.

To compute our proximity features for a toponym/inter-pretation pair ( t, l t ), we find for each other toponym o in the window around t the closest interpretation l o to l t . Then, we compute the proximity feature for ( t, l t ) as the aver-age of the geographic distances to the other interpretations. Thus, a lower feature score indicates a higher level of over-all geographic proximity for toponyms within the window. This feature strategy also balances fairness with optimism, in that it allows all toponyms in the window to contribute to ( t, l t ) X  X  feature score, while each toponym in the window contributes its best (i.e., geographically nearest) interpreta-tion to the feature score. It has the additional benefit that no distance thresholds are hard-coded into the feature. In-stead, the learning procedure can learn appropriate distance thresholds from its training data.
Our second class of adaptive context features are those based on sibling relationships between interpretations in a geographic hierarchy. In other words, this feature will cap-ture the relationships between textually proximate toponyms that share the same country, state, or other administrative division. The sibling feature is intended to capture inter-pretations that are at the same level in the hierarchy (e.g., states in the same country, cities in the same state) as well as interpretations at different levels (e.g., a state and its con-taining country, a city inside its containing state). The first case captures  X  X rue X  sibling relationships, while the second case captures containment relationships, which can be con-sidered siblings at a coarse granularity (e.g., College Park and Maryland are siblings at a state level of granularity).
We compute sibling features in a similar way as the prox-imity features. For each toponym/interpretation pair ( t, l we use as our sibling feature value the number of other to-ponyms o in the window around t with an interpretation that is a sibling of l t at a given resolution. We consider three lev-els of resolution, which correspond to three sibling features for each ( t, l t ): country-level, state-level, and county-level.
Given that the sibling features are so related to the prox-imity features, at first glance, the sibling feature appears to be redundant in that some toponym interpretations that are siblings will tend to be geographically proximate as well (e.g., Paris, Texas and Dallas, Texas ). However, in some cases the sibling feature will prove helpful in distinguishing toponym relationships. For example, cities that are posi-tioned at opposite ends of a given state might be too far to be considered geographically proximate, but would still be considered siblings. Similarly, the notion of geographic dis-tance for area objects such as countries and states depends on their representation. If we represent, e.g., a country by a single point, such as its centroid or the location of its capital city, it might be considered geographically distant from many cities contained in it, while the sibling feature would correctly capture these relationships. Another differ-ence between the proximity and sibling features is that the geographic hierarchy is discrete, while geographic distances are continuous values. As a result, we do not have the same thresholding problem as for the proximity features, as our  X  X hresholds X  are effectively the same as the hierarchy levels.
As noted earlier, our adaptive context features are based on computing features within a window of context around each toponym t . We can consider two variables related to the search for a correct interpretation of t : 1. Window breadth , denoted w b , which corresponds to the 2. Window depth , denoted w d , which is the maximum
The window breadth w b controls how many toponyms around a given toponym t are to be used in aiding the res-olution of t . With a larger w b , more toponyms will be used to resolve t , thus reducing the resolution algorithm X  X  speed but hopefully increasing its accuracy. Similarly, the window depth w d controls the number of interpretations to be con-sidered for each toponym in the window. A larger w d means that more interpretations will be checked, with a resulting decrease in speed, but with more potential for finding cor-roborating evidence for a correct interpretation of t .
Because the window depth may preclude examination of all interpretations for a given toponym, the order in which the interpretations are examined is important. Ideally, inter-pretations would be ordered using context-free attributes of each interpretation. In a sense, the ordering is based on an apriori estimate of each interpretation X  X  probability of being mentioned in a given document, though we do not formal-ize this notion here. We order or rank these interpretations using various factors, which include, in order of importance: 1. Number of alternate names for the location in other 2. Population of the location, where a larger population 3. Geographic distance from a local lexicon location. These ranking factors can be considered context-free, in that the ordering of interpretations for a given toponym is in-dependent of its position in the document. We could use additional factors such as each interpretation X  X  geographic distance from a dateline toponym interpretation, but be-cause we include these factors as separate features we do not need to include them in the ranking here.

One seeming drawback with regard to the window depth is that it may not seem effective in that most toponyms in our gazetteer have only one or two possible interpretations, as our experiments in Section 4.1 show. However, toponyms that are well-known by virtue of having a well-known inter-pretation (for example, Paris , widely known as the French capital), will tend to be mentioned more frequently in doc-uments, and these will be more ambiguous. This is also reflected in measurements made on the toponyms present in our experimental datasets (Section 4.2).

In addition, rather than using all toponyms in the window around each t , we perform some pre-filtering to remove to-ponyms that detract from the usefulness of our adaptive con-text features. For example, we do not use toponyms in the window that have the same name as t , since they will have the same set of interpretations as t , which will impart no useful information. In addition, and more generally, we may not be sure which of the words in the window correspond to toponyms, due to ambiguities in toponym recognition. Our toponym recognition process (described in Section 2.1) is designed for high recall and as a result we will consider many words which are not true toponyms. In other cases, we may not be sure of the appropriate interpretation for a given toponym. For example, consider the phrase  X  X niver-sity of Maryland X , which could be interpreted as a whole, University of Maryland , referring to the school, or as Mary-land , the state. Rather than immediately deciding on one of these toponyms, our recognition process keeps both, even though they overlap. Thus, we can keep and consider all of them in toponym resolution, though they must be appropri-ately filtered when processing toponyms in the window.
Our algorithm for computing adaptive context features, called AdaptiveContext , is shown in Algorithm 1. It takes as input the toponyms T in the document being pro-cessed, as well as the window breadth w b and window depth w d under consideration. The algorithm proceeds by iterat-ing over all toponyms t  X  T (line 2). For each t , an array Algorithm 1 C ompute adaptive context features. 1: p rocedure AdaptiveContext ( T, w b , w d ) 2: for t  X  T do 3: P  X  X } 4: O  X  X  o  X  T : Name ( t ) 6 = Name ( o )  X  5: for o  X  O do 6: L o  X  Locs ( o )[1 . . . min { w d , | Locs ( o ) |} ] 7: for l t  X  Locs ( t ) do 8: d min  X  min { X  l o  X  L o , GeoDist ( l t , l o ) } 9: P [ l t ]  X  P [ l t ]  X  X  d min } 10: for lev  X  X  country, admin 1 , admin 2 } do 11: if  X  l o  X  L o : Sibling ( l t , l o , lev ) then 12: Increment SibFeature ( t, l t , lev ) 13: end if 14: end for 15: end for 16: end for 17: for l t  X  Locs ( t ) do 18: ProxFeature ( t, l t )  X  Avg ( P [ l t ]) 19: end for 20: end for 21: end procedure P i s initialized which will hold minimum distances to in-terpretations of toponyms in the window around t , which will be used in computing the proximity features for t (3). Next, other toponyms O within the window around t are col-lected by finding toponyms o  X  T whose document distance is smaller than the window breadth w b , and also have a dif-ferent name than t (4). We then loop over each toponym o  X  O to begin comparing interpretations of t and o (5). First, we collect the location interpretations associated with o , up to a limit of w d interpretations, the window depth (6). Then, we loop over each interpretation l t of t (7), and find the interpretation l o of o with minimum geographic distance from l t (8). We add the interpretation l o to the location set P [ l t ] associated with l t which will be used for computation of the proximity feature for l t (9). Next, we compute the sibling features for each level lev of our geographic hierar-chy (10) by checking whether there exists an interpretation l of o with l t as its sibling (11). If so, we increment the sib-ling feature for that level (12). Finally, after looping over all toponyms of O , the sibling features are fully computed for each interpretation l t of t , but the proximity feature remains to be completed. We do so for each l t (17) by averaging the geographic distances computed for l t , which results in the final proximity feature values (18). We use the median geo-graphic distance as our averaging measure.
Oftentimes, documents will mention the same toponyms multiple times. When considering pairs of toponyms for use in computing adaptive context features, described in the pre-vious section, these toponym repetitions are ignored because they impart no useful information, since the interpretations for each pair will be the same. However, we can still make use of toponym repetition within a single document because the toponyms appear in different contexts (i.e., at different offsets) within the document. Since our adaptive context features are context-sensitive, we can apply stronger feature values computed for the toponym in one context to the same toponym in other, weaker contexts.

To leverage these repetitions, as a final processing step, we compute additional features for each ( t, l t ) pair by propagat-ing feature values among toponyms in the document that share the same name. We propagate feature values that in-dicate strong evidence that a given toponym interpretation is correct. For the proximity feature, this corresponds to the lowest average distance values, while for the sibling fea-tures, we propagate the largest sibling counts for each level of resolution we consider.
In this section, we describe the extensive experiments per-formed on our own and competing geotagging methods. We first establish the general difficulty of geotagging using our large gazetteer, due to a large amount of toponym ambi-guity (Section 4.1), and then introduce the datasets to be used for measuring geotagging performance, and character-ize the toponyms present in them (Section 4.2). In terms of geotagging accuracy, we compare our own adaptive method, referred to as  X  X daptive X , against two existing prominent competing methods: Thomson Reuters X  X  OpenCalais, and Yahoo! X  X  Placemaker. Both OpenCalais and Placemaker are closed-source commercial products, but they do pro-vide public Web APIs which allow for automated geotag-ging of documents, and hence they have been used exten-sively in state-of-the-art geotagging and entity recognition research (e.g., [1, 24, 28, 38, 40]). In addition to not being able to make direct algorithmic comparisons due to their black box nature, neither OpenCalais nor Placemaker of-fer a means of tuning the precision/recall balance, so we could not explore this aspect of the systems. We discuss how well these systems fare against our own methods in terms of toponym recognition (Section 4.3) and toponym resolu-tion (Section 4.4). For the latter, we also consider various combinations of features and show how they affect resolu-tion accuracy, and use a feature ranking method to mea-sure the importance of each feature when used in resolving toponyms. Finally, we vary the adaptive context parame-ters of window breadth ( w b ) and depth ( w d ), and show how they affect the feature computation time and accuracy of the Adaptive method (Section 4.5).

Note that in all our accuracy experiments, we measure performance using precision and recall as measured over the correct interpretations. We also used 10-fold cross validation to avoid misleading performance numbers due to potential overfitting. Also, we used 100 trees in our random forests, with 5 attributes for each tree, and accepted classifications with at least 0.5 confidence score (i.e., at least half of the trees voted for the interpretation). All experiments were conducted on a Dell Precision 470 workstation with a dual core Intel Xeon 3GHz CPU and 8G RAM.
First, we examined our gazetteer to understand the level of ambiguity of toponyms present in it. The gazetteer con-tains a total of 8.1M location interpretations, 5.1M distinct names, and 7.0M alternate names in languages other than English. The gazetteer X  X  large size ensures a high level of am-biguity and ensuing greater difficulty in performing geotag-ging correctly, when compared to gazetteers used by other systems such as Web-a-Where [3]. For each toponym in the gazetteer, we counted the number of interpretations associ-ated with it, and plotted the results. Results are shown in Figure 3. Toponyms in the gazetteer exhibit a power-law re-lationship in terms of the number of interpretations, in that Figure 3: Toponyms and the number of interpretations they h ave exhibit a power-law relationship.
 Documents 104 621 13327 M edian doc word count 236 242 309 News sources 4 114 1607 Annotated docs 104 621 1080 Annotated topos 2359 4765 11564 Distinct topos 295 1177 2320 Median topos per doc 12 6 8
Median topo ambig per doc 3 14 7 the vast majority of toponyms a small number of interpre-t ations, while a few toponyms have a very large number of interpretations. Of course, most of these unambiguous to-ponyms will not be mentioned in a given document, and in our datasets, described in the next section, the documents X  toponyms have higher levels of ambiguity.
In choosing the datasets for our evaluation, we wanted news data from a variety of sources, and for a variety of audiences. To achieve this end, we used three datasets of news in our evaluation: ACE , LGL , and CLUST . The first, ACE [22], consists of articles from four large news sources: Agence France-Presse, Associated Press World, New York Times, and Xinhua. These articles tend to have a broad world interest and concern topics such as international diplo-macy and trade, so they tend to mention large, well-known places. Thus, ACE serves in our evaluation as a test of the geotagging methods X  capability for correctly recognizing and resolving well-known, prominent places. On the other hand, to test smaller places, we used the LGL [21] dataset, which consists of articles from about 100 smaller, more local news sources. These articles are intended for more geographically localized audiences, and concern local events that mention small places. Our third dataset, CLUST [18], contains a variety of articles from both large and small news sources.
Table 1 presents statistics that broadly illustrate charac-teristics of our three test corpora. ACE is relatively small compared to LGL and CLUST , both in terms of number of documents and news sources. However, ACE tends to have more toponyms per article, which may be due to the content consisting of generally international news involving many different countries and other locations, which would all be mentioned in the articles. In addition, we measured toponym ambiguity in the articles by checking, for each doc-ument, the median number of gazetteer interpretations for Figure 4: Breakdown of location types within each of our t est corpora. the toponyms in the document. the median number of in-terpretations present for toponyms in each document. LGL has the largest amount of toponym ambiguity, followed by CLUST and ACE . This is not overly surprising, given that LGL was constructed deliberately focusing on highly am-biguous toponyms [21]. However, the measurements show a high level of ambiguity in all three datasets.

We also classified the annotated locations present in the documents according to their types, which are shown in Fig-ure 4. We normalized the type counts for each corpus to illustrate the fractions of each type within each corpus. For cities, we further divided the locations into large cities (over 100k population) and small cities (less than 100k popula-tion). These location types clearly show the important dif-ferences between the three corpora. The vast majority of ACE  X  X  toponyms, 83%, consist of countries and large cities, indicating ACE  X  X  broad geographic scope. This is not overly surprising given that it consists of newswire, which is usually intended for a broad geographic audience. In contrast, 60% of LGL  X  X  toponyms are small cities, counties, and states, and among all three datasets, LGL contains the smallest fraction of countries and large cities, showing that LGL mainly concerns smaller, more local places, with a corre-spondingly smaller geographic audience. CLUST falls in the middle, with the largest fraction of states among the three datasets, and in between the other two in terms of countries, counties, and small cities. Bearing these observa-tions in mind, in terms of overall geographic relevance, ACE and LGL can be said to have wide and narrow relevance respectively, while CLUST falls in the middle, illustrating our three datasets X  utility in testing geotagging at coarse, middle, and fine-grained geographic scopes.
Though the main focus of this paper is improved toponym resolution, for completeness, we tested each system X  X  to-ponym recognition performance when isolated from the sub-sequent toponym resolution step. Note that OpenCalais and Placemaker also provide lat/long values with each toponym, but we disregard these when testing toponym recognition using these systems because it is more information than we need for this experiment. Table 2 shows the performance results for each method X  X  toponym recognition step. For all three datasets, the Adaptive method shows higher recall performance than either OpenCalais or Placemaker, which as we discussed earlier is the crucial measure to consider for toponym recognition used before toponym resolution, as well as a higher overall F 1 -score for LGL and CLUST . While OpenCalais and Placemaker do have higher precision, this ACE A daptive 1635/1659 = 0.986 1635/2359 = 0.693 OpenCalais 1062/1080 = 0.983 1062/2359 = 0.450 Placemaker 1161/1219 = 0.952 1161/2359 = 0.492 LGL Adaptive 2799/2970 = 0.942 2799/4765 = 0.587 OpenCalais 1260/1632 = 0.772 1260/4765 = 0.264 Placemaker 2516/3466 = 0.726 2516/4765 = 0.528 CLUST Adaptive 7143/7440 = 0.960 7143/11564 = 0.618 OpenCalais 5397/6352 = 0.850 5397/11564 = 0.467
Placemaker 7524/8642 = 0.871 7524/11564 = 0.650 is mitigated by their relative lack of recall. Also, Adaptive  X  X  precision is restored by its toponym resolution processing, which will be shown in the next section. These results are also consistent with previously-reported performance [18].
In the next experiment, we measured the accuracies of each method X  X  toponym resolution in isolation X  X hat is, if each method were given a set of toponyms, how well the method would select the correct lat/long interpretation for each toponym. Because OpenCalais and Placemaker do not allow for the specification of ground truth toponyms, it is not possible to make direct comparisons of toponym res-olution X  X  recall for these systems. Instead, we report the precision for the resolution process in isolation (P Resol the recall for the combined recognition and resolution pro-cesses (R Recog+Resol ). For P Resol , we only report accuracy for toponyms that were correctly recognized by each sys-tem. Also, for the Adaptive method, we used a window breadth w b of 80 tokens and unlimited window depth w d . To determine whether a given interpretation is correct, we check the geographic distance between the interpretation X  X  lat/long values and the ground truth lat/long values, and if it lies within a small threshold (10 miles) we consider it cor-rect. This method allows for the inevitable minor variations between the tested systems, due to their having selected in-terpretations from different gazetteers.

Table 3 shows the performance results. Of all three meth-ods, the Adaptive method has the best overall precision, es-pecially so for the LGL and CLUST datasets. Adaptive also maintains this high precision while having high toponym re-Table 4: Toponym resolution accuracy for different feature combinations.
 call. This is best seen for the L GL dataset where Adaptive has a 17% advantage over OpenCalais, and a 22% advan-tage over Placemaker, along with a recall advantage of 32% over OpenCalais and 6% advantage over Placemaker. These performance numbers indicate our method X  X  superior perfor-mance in terms of the toponym resolution task. Examining performance for all the methods across the three datasets, the methods performed best on ACE , worst on LGL , and in the middle for CLUST . These results follow our intuition that correctly geotagging documents containing smaller, less well-known locations ( LGL ) is more difficult than for larger, more well-known locations ( ACE ).

Our next set of experiments tested various combinations of features used in the Adaptive method, to illustrate each feature X  X  overall utility. We used different combinations of the features described in Section 2.3, as well as the adaptive context features described in Section 3. Table 4 contains the performance results, with feature abbreviations corre-sponding to those used in Section 2.3, and feature combi-nations indicated with commas (e.g., I,P combines interps and population ). In addition, we considered two baseline feature combinations B 1 and B 2 . B 1 tested only the domain-independent features ( I,P,A ), while B 2 also included those features tailored for the news domain ( D,L ). We again used our adaptive context feature ( W 80,  X  ) with window breadth of 80 tokens and unlimited window depth. In general, reso-lution precision was high for all feature combinations, so the main difference was resolution recall. For ACE and CLUST , the dateline and locallex features did not improve B 1 much, but locallex did make a large difference for LGL . Our adaptive context features in general improved B 1 , for LGL in particular. However, in combination with B 2 , the adaptive context features showed little improvement and in some cases lower performance, which is not overly surprising in that domain-specific features will exhibit domain-specific performance, and sometimes, adding features to a model will decrease performance. However, taken as a whole, the results illustrate our adaptive context features X  utility for general geotagging purposes, especially over more simplistic features such as population .

We also conducted an experiment to measure the impor-tance or utility of our features for classifying toponym in-terpretations. This process, also known as feature selection or dimension reduction [10], ranks the individual features in terms of their overall utility. For our feature importance measure, we used the gain ratio [10], a commonly-used, entropy-based measure for decision tree construction. We computed the gain ratio for each feature, and normalized the resulting importance values within each dataset. Results are presented in Figure 5. Interestingly, for each dataset, the interps and altnames features outranked population . Figure 5: Importance of features used in the Adaptive m ethod, as measured by the gain ratio. F igure 6: Performance results when varying window breadth, showing changes in (a) time and (b) accuracy. The locallex feature was highly important for LGL , though this is not too surprising considering the dataset X  X  content of smaller, local news articles. The windowprox and win-dowsib have lower importance values, but interestingly, the windowprox feature has almost the same feature value as population . windowsib  X  X  low importance value may be due to it being little-used in the three datasets.
In our final set of experiments, we tested how varying the adaptive parameters of our window features, namely the window breadth w b and window depth w d , would affect the speed and accuracy tradeoff for our methods. We used our adaptive context features in combination with our first baseline comparison method, B 1 , described in the previous section, which is a combination of the interps , population , and altnames features. First, we varied the window breadth between 1 X 80 tokens and measured the resulting tradeoff. Figure 6a and Figure 6b show the results in terms of com-putation time and method accuracy, respectively. As the window breadth increases, the computation time increases F igure 7: Performance results when varying window depth, showing changes in (a) time and (b) accuracy. linearly, which is to be expected. The computation time for CLUST is larger than for the other datasets due to its size. Interestingly, even with a small window breadth, precision remains high, and recall is respectable for all three datasets, giving evidence that the features are applicable even for do-mains where little time is allocated for geotagging. Also, while increasing the window breadth, recall also increases for the datasets, showing the time/accuracy tradeoff as ex-pected. Results are similar for when varying window depth, shown in Figure 7a and Figure 7b.
Our investigations of adaptive context features have shown their utility and flexibility for improving the geotagging of streaming news. In future work, we plan to test different weightings of toponyms in the window to judge their effect on resolution accuracy. For example, toponyms that are fur-ther away in the window could be given less weight, using linear or Gaussian weighting schemes, essentially leveraging Tobler X  X  law [39] which states that  X  X verything is related to everything else, but near things are more related than distant things X . In addition, we could consider clusters of news articles about the same topic, which are collected in the NewsStand system, and design other features using these clusters. For example, we might examine other documents in a cluster to get additional toponyms for consideration in geotagging the current document. This can be thought of as creating one large virtual document consisting of some or all of the documents in a cluster, and then extending the window to include toponyms in those other documents. As before, with large clusters, we may not want to consider all toponyms or all interpretations in other documents in the cluster, due to inhibitive performance penalties. In sum-mary, adaptive context features serve as a flexible, useful addition to geotagging algorithms for streaming news and other textual domains.
