 Importance weighted active learning (IWAL) introduces a weight-ing scheme to measure the importance of each instance for cor-recting the sampling bias of the probability distributions between training and test datasets. However, the weighting scheme of IWAL involves the distribution of the test data, which can be straightfor-wardly estimated in active learning by interactively querying users for labels of selected test instances, but difficult for conventional learning where there are no interactions with users, referred as pas-sive learning . In this paper, we investigate the insufficient sam-pling bias problem, i.e., bias occurs only because of insufficient samples, but the sampling process is unbiased. In doing this, we present two assumptions on the sampling bias, based on which we propose a practical weighting scheme for the empirical loss func-tion in conventional passive learning, and present IWPL, an im-portance weighted passive learning framework. Furthermore, we provide IWSVM, an importance weighted SVM for validation. Ex-tensive experiments demonstrate significant advantages of IWSVM on benchmarks and synthetic datasets.
 Categories and Subject Descriptors: H.2.8 [Database Manage-ment]: Database Applications X  Data mining ; I.2.6 [Artificial Intel-ligence]: Learning General Terms: Algorithms, Performance, Experimentation Keywords: Classification, Learning with confidence, Discounted confidence
For correcting the bias of the probability distributions between training and test datasets, importance weighted learning [2, 7] was proposed, where the importance weight of each instance can be adjusted for the empirical loss function according to the proba-bility distributions of the training and test datasets. However, the weighting scheme involves probability distribution of test dataset, which can be easily estimated in active learning by interactively querying users for labels of selected test instances, but difficult for conventional passive learning where there are no interactions with users. Besides, learning with confidence [4] can utilize another category of confidence labels for instances to generate the impor-tant weights. However, it requires much more efforts for labeling and the confidence scores might be inconsistent, for example, some users are self-confident and universally assign high confidences to instances while others are not and assign low confidences.
In this paper, we investigate the insufficient sampling bias prob-lem, i.e., the bias occurs because of insufficient samples, but the sampling process is unbiased. For many sophisticated learning tasks such as speech recognition and information extraction, it is very difficult, time-consuming, or expensive to obtain sufficient la-beled instances for training [6], and thus the training dataset may distribute differently from the test, and these datasets may be very noisy.

In doing this, we present two assumptions on the distributions of the training and test datasets for satisfying insufficient sampling bias, where the variances of the training and test instances can be different, however, their distribution categories and expectations should be the same. For example, the probability distributions of the training and test instances are two Gaussian distributions N (  X ,  X  2 train ) and N (  X ,  X  2 test ) , which share a same expectation  X  , but have different variances  X  2 train and  X  2 test . Obviously, our assumptions are weaker than i.i.d.

Based on the assumptions, we propose a practical weighting scheme for the empirical loss function in conventional passive learning, and present IWPL, an importance weighted passive learning frame-work. Furthermore, we provide IWSVM, an importance weighted SVM for validation.

Specifically, we evaluate the probability distribution of the train-ing dataset with the dissimilarity between each instance to the dis-tribution expectation of the instances. Besides, we estimate the distribution of the test dataset based on the ranks of the training instances if we order them according to their dissimilarity to the distribution expectation of the instances.

It is less precise but more robust to adopt the ranks of the ob-jectives to approximately represent their probabilities, which have been explored for many problems. For example, in evaluation sys-tems, Borda count[1] transforms the review scores of the items from different reviewers into a set of partial rankings, and assigns ascoreof 1 /r i to a given item t i that has a rank of r i that t i has a probability of 1 /r i to be ordered at the first rank. Then these items can be aggregated and ordered according to their total scores for evaluation. This method can achieve acceptable perfor-mance even when the review data is very sparse.

The effectiveness of our approach can be understood from an-other perspective. In order to reduce the sample bias, the distribu-tion of the instances should be discounted with a rank-based weight log(1+ r ) . This rank-based weighting scheme is also adopted to dis-count the relevance gain of the document at the rank i in the ac-curacy measure of NDCG [3] for document ranking in information retrieval, and has been widely used in XML retrieval, database and collaborative filtering [5]. Conventional passive learning. Let T = { ( x i ,y i ) } n Y be the training instances, where x i  X  X  is a training instance following a probability distribution P ( x ) ,and y i  X  X  is the label of x i following a conditional probability distribution P ( y
Let f ( x ;  X  ): X X  X  be a classifier for estimating the class label y for the input instance x ,where  X  represents the parameters that need to learn. Let L ( y, f ( x ;  X  )) : Y X Y X  R  X  0 be the loss function at an input instance x , which measures the discrepancy between the ground truth label value y and its estimation f ( x ;  X  ) .
Since the instance X and the label Y are two random variables following the joint probability distribution P ( X, Y ) , a learning al-gorithm learns the parameter  X  by minimizing the expectation of the loss function, formally:
In conventional passive learning, a standard empirical loss func-tion to learn the parameter  X  is shown as follows:
However, conventional passive learning fails to consider impor-tance weights for instance, resulting to deteriorated performances. Importance weighted active learning. For many problems, the distribution of the training data can be quite different from the test data. Let p train ( x ) and p test ( x ) be the probability density func-tions corresponding to the distributions of the training and test data respectively. The importance of the instance x i can be measured by the ratio of test and training densities, formally:
In active learning, the probability distribution p test ( x instance x i in the test dataset can be obtained via interactions with users. First of all, a small subset of unlabeled instances are selected from the test dataset to interactively query users for labels of se-lected test instances. Then the probability distribution of the test dataset can be estimated by responses of users.

In doing this, importance weighted active learning [2, 7] presents an unbias empirical loss function L IWAL , where the function value L IWAL ( x i ) at a given instance x i was weighted by w i , formally:
Although importance weighted learning introduces a weighting scheme w i to the empirical loss function, it involves probability distributions of test dataset, which is difficult for estimation in con-ventional passive learning. Generally this weighting scheme can be only successfully adopted in active learning, where the distribution of the test instances can be estimated by requesting to the users. Learning with confidence. Learning with confidence [4] can uti-lize confidence scores, another category of labels besides the class labels, to evaluate the important weights for instances in the em-pirical loss function. In this situation, binary classification can be represented naturally as a regression problem.
 However, first of all, it requires much more efforts for labeling. Even these confidence scores are available, they might be incon-sistent, for example, some users are self-confident and universally assign high confidences to the instances while others are not and assign low confidences.

In summary, to our best knowledge, there are no practical method to estimate importance weights of instances for conventional pas-sive learning.
 Insufficient sampling bias. In this paper, we focus on the insuffi-cient sampling bias, i.e., bias occurs only if we cannot obtain suf-ficient instances for training, but the sampling process is unbiased. In doing this, we present two assumptions on the training and test datasets for satisfying insufficient sample bias.

A SSUMEPTION 1. Category assumption. The probability dis-tributions of the training and test datasets ( p train and p to a same distribution category.

A SSUMEPTION 2. Expectation assumption. For each class, the distribution expectations of training and test datasets are the same, formally: where X train and X train be two random variables of the train-ing and test instances respectively.

We can use the average value of the instances to estimate their expectation. For each class, the difference is very small between the average values of the training and test datasets, formally:  X  y  X  X  : where is a small positive real number, ( x T i ,y ) and ( x a training and a test instance respectively, and both of them are labeled as y .

In this case, the distribution variances of the training and test datasets can be different due to different sampling rounds, how-ever, their distribution categories are the same, and their expecta-tions are so close that they can be recognized as the same as well. For example, p train  X  X  (  X ,  X  2 train ) and p test  X  X  (  X ,  X  two Gaussian distributions, are distribution density functions of the training and test datasets. They share a same expectation  X  ,but have different variances  X  2 train and  X  2 test . Such relationship guar-antees that the distribution of the test dataset can be estimated with the distribution of the training dataset.

Obviously, the category and expectation assumptions are weaker than the independent and identically distribution (i.i.d.) assump-tion. Thus the problem is: based on these two assumptions, how to practically estimate importance weights of instances for conven-tional passive learning.
In this section, we introduce IWPL, an important weighted pas-sive learning framework based on the category and expectation as-sumptions for the insufficient sampling bias problem. Probability distribution of the training dataset. Let E ( X ) be the distribution expectation of the training instances, the distribution at a given training instance x i involves two issues: the distance from x i to E ( X ) and the angle of the corresponding vectors of the instances x i and E ( X ) .

Actually these two issues can also be estimated by the similar-ity/dissimilarity measures between instances. For example, the Eu-clidean distance measures the distance between instances, the vec-tor cosine measures the angle of the corresponding vectors of the instances, or we can conceive a combined one that involves both.
Thus, it is very natural and straightforward to utilize the dissimi-larity dis ( x i , E ( X )) between a given training instance x distribution expectation E ( X ) for estimating the probability distri-bution at x i in the training dataset, formally: Probability distribution of the test dataset. Assumptions (1) and (2) guarantee that the probability distribution of the training dataset in the training data can be used to estimate that of the test dataset.
The dissimilarities of two instances x i and x j to the distribution expectation, dis ( x i , E ( X )) = 3 and dis ( x j , E ( X )) = 5 ,involves two aspects of information: (i) the scores of 3 and 5, and (ii) their preference dis ( x i , E ( X )) &lt;dis ( x j , E ( X )) . For estimating the distribution of the test dataset with the training dataset, the scores are meaningless due to different variances in these two datasets, however, the preference still works.

E XAMPLE 1. Let E ( X ) be the distribution expectation of the instances. Let x i and x j be two training instances following the probability distribution density function p train ,where dis ( x &lt;dis ( x j , E ( X )) and p train ( x i ) &lt;p train ( x x m and x n are two test instances following the distribution den-sity function p test and dis ( x m , E ( X )) &lt;dis ( x case, p test ( x m ) &lt;p test ( x n ) holds according to the category and expectation assumptions.

If we order these instances based on their average dissimilarity to the distribution expectation, each instance receives a rank value. The importance weight of the training instances x i should be pro-portionate to that of the test instance x m if they have a same rank. The distribution of the test dataset is estimated formally as follows:
It is less precise but more robust to adopt the ranking of the ob-jectives to approximately represent their probabilities, which have been explored for many problems. For example, in evaluation sys-tems, Borda count[1] transformed the review scores of the items from different reviewers into a set of partial rankings, and aggre-gated them for group recommendation. This method can achieve acceptable performance even when the review data is very sparse.
Adopting the ranking of the objectives to approximately repre-sent their probabilities has been explored for many problems. In the Borda count method [1] for ranking aggregation, the form of the 1 r has already been used to represent the rank-based gains of the votes (probabilities) for each reviewer. In  X  p test we use a loga-rithmic variant to yield a meaningful score for  X  p test ( x has a very high rank.
 The proposed loss function L IWPL . With the estimations of the probability distributions of the training and test datasets, the impor-tance weighting scheme can be estimated as follows: Thus the loss function can be represented as follows:
The effectiveness of our approach can be understood from an-other perspective. In order to reduce the sample bias, the distribu-tion of the instances should be discounted with a rank-based weight log(1+ r ) . This rank-based weighting scheme is also adopted to dis-count the relevance gain of the document at the rank i in the ac-curacy measure of NDCG [3] for document ranking in information retrieval, and has been widely used in XML retrieval, database and collaborative filtering [5].
In conventional SVM, the empirical loss function L EMP is im-plemented by maximizing the margin among support vectors. Let  X  be the function used to map the linear vector x i into a higher (maybe infinite) dimensional space. Let C&gt; 0 be the penalty pa-rameter for classification errors. Let  X  i be the slack variable. Let K ( x i ,x j )=  X  ( x T i x j ) be a kernel function. For binary classifica-tion problems, the maximum margin-based loss function for SVM is represented as follows: where C mentation of the empirical loss function L EMP ,and ||  X  || 2 the regularization of the parameters for reduction of the classifier X  X  complexity.

In our implementation of L IWPL , the penalty of the classifica-tion error  X  i is weighted by the estimation of the importance weight  X  w , formally:
We chose SVM as our comparison partner. Our implementation of IWSVM was based on SVM. A direct comparison of the two will provide valuable and irreplaceable insights.

We chose the liner kernel function in both IWSVM and SVM. In order to demonstrate the promises of IWSVM, we conducted two series of experiments on two benchmark and a synthetic datasets respectively. For each experiment, we ran each algorithm 5 times randomly and returned the average accuracy as the result for com-parison. Figure 1: Accuracy of the SVM and IWSVM with different numbers of the instances for training. Figure 2: Accuracy of the SVM and IWSVM with different numbers of the noisy instances in each category.
This experiment demonstrates that IWSVM can achieve the same or even higher learning accuracy with a smaller dataset in compar-ison with conventional passive learning.

In this experiment, we used two classic UCI benchmarks, WDBC and Statlog (Heart). We randomly selecting different numbers of the instances from the training pool for IWSVM and SVM to eval-uate their performance with small data. In particular, the propor-tions of the selected training instances varied from 10% to 100% in increments of 10%.

The experimental results are shown in Figure 1. From the figure we can see that IWSVM significantly gains in accuracy. Although the accuracy of the two methods improves with the increase of the the number of the training instances, IWSVM achieved the similar or even higher accuracy with a small volume data in comparison with SVM. In particular, for the WDBC dataset, as shown in Fig-ure 1(a), IWSVM achieved the accuracy of 97.4% with only 50% training instances, while SVM could not outperform it even with 100% training instances. For the Statlog dataset, as shown in Fig-ure 1(b), IWSVM achieved the accuracy of 80.6% with only 60% training instances, while SVM could not outperform it even with 100% training instances.
This experiment demonstrates the promises of the IWSVM with the noisy data in comparison with conventional passive learning.
We used a synthetic dataset for this experiment. For simplic-ity and easy demonstration, we employed two-dimensional features for representation of the instances. The generation process of the instances are as follows. First of all, we built two Gaussian models to generate the two categories of instances respectively. In partic-ular, the first model generated positive instances, where the expec-tation and standard deviation were (0,0) and 0.5 respectively. The second model generated negative instances, where the expectation and standard deviation were (3,3) and 2 respectively. Every Gaus-sian model generated 500 instances for training and 500 instances for test. Then we gradually added the noisy instances into the origi-nal training data to evaluate the performances of IWSVM and SVM with noisy data. The positive noisy instances were generated by the Gaussian model for generating negative ones, and vice versa.
In this experiment, the numbers of the positive and negative noisy instances varied from 10 to 100 in increments of 10. The experi-mental results are shown in Figure 2. From the figure we can see that IWSVM significantly gains significantly in accuracy. Although the accuracy of the two methods deteriorate with the increase of the number of the noisy instances in each class, the accuracy of the IWSVM deteriorates much slower than that of the SVM with the increase of the number of the noisy instances. For example, both of the two methods achieved similar accuracies (a little more than 99%) with the original data; The learning accuracy of SVM were 74.4% and 65.9% when 50 and 100 noisy instances were in-troduced in each class, while the accuracy of IWSVM were 96.1% and 88.0% respectively.
For correcting the insufficient sampling bias between the prob-ability distributions of the training and test datasets with conven-tional passive learning, we proposed a practical weighting scheme for estimating the importance of each instance, and presented IWPL, an importance weighted passive learning framework. Furthermore, we provide IWSVM, an importance weighted SVM for validation. We experimentally compared IWSVM with SVM on benchmarks and synthetic datasets, demonstrating the accuracy gain of IWSVM.
Given the novelty of the approach, for future work we plan to perform a systematic study on IWSVM, both theoretically and ex-perimentally. Besides, it is interesting to explore the effectiveness of L IWPL for other conventional passive learning algorithms such as logistic regression and neural network. Last but not least, it is essential to apply IWSVM to other application domains for valida-tion purposes.
This research was supported in part by the Natural Science Foun-dation of China (60970047, 61070097, 71171122), the Humanity and Social Science Foundation of Ministry of Education of China (12YJC630211), and the Natural Science Foundation of Shandong Province of China (BS2012DX012). [1] J. Aslam and M. Montague. Models for metasearch. In SIGIR , [2] A. Beygelzimer, S. Dasgupta, and J. Langford. Importance [3] K. J X rvelin and J. Kek X l X inen. Cumulated gain-based [4] M. Li and I. Sethi. Confidence-based classifier design. Patt. [5] N. N. Liu and Q. Yang. EigenRank: A ranking-oriented [6] B. Settles. Active learning literature survey. Computer [7] M. Sugiyama, M. Krauledat, and K. M X ller. Covariate shift
