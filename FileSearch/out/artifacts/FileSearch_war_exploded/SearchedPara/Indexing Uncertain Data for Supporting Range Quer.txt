 Recently, many emerging applications over uncertain data are attracting a wide atten-tion of researchers [3]. The causes of the uncer tainty are greatly different in various applications. For example, in a habitat monitoring system, due to the impreciseness of sensing devices [5], the data obtained are often noisy. As another example, in moving objects tracking [6], the location informatio n of objects collected by a GPS system may not be exact due to the delay on data updating. Among a large number of queries, range query is the most fundamental and important operation in managing uncertain data [1].
A probabilistic range query is to find out the objects that appear in the query region with the probability at least  X  ( the probabilistic threshold of the query). Since such a computation involves the expensive and complex integral [4] [2], the filter-refinement is preferable. In the filtering phase, the probabilistic objects, which must(or not) be the query results, are quickly filtered without proceeding the complex integral. For the objects that cannot be filtered, in the refinement phase, the integral has to be done to verify the answers. Thus, the key of optimizing a prob-range query is to provide, as tight as possible, a bound for flittering with a small cost.

Several indexes have been proposed to answer the queries on uncertain data. The key idea is pre-computing the summary [8] of each object X  X  PDF (short for probabil-ity density function), augmenting existing index techniques to organize summary, and then using the summary for filtering.[8]. One of the most popular index named U-tree employs the PCR(short for probabilistically constrained region) technique to summary the PDF of the uncertain object. However, PCR could not provide the uncertain object with a strong pruning/validating power, and the dynamic update cost of U-Tree is high (detailed in Section2).

Another two popular indexes U I-tree [7] and UD-tree [8] employ the partition tech-nique to summary the PDF of uncertain object. Using the partition technique, the sum-mary of an object could provide it with a str onger pruning/validating ability than the PCR-based [4] summary. However, it still has room for improving. The partition does not fully consider the gradient of PDF. And they both consume too much space cost (e.g., given a 62K data, the index size is 20M).

Contributions: In this paper we study the problem of answering prob-range queries on uncertain data. The contributions are as follows:
Firstly, we propose a novel summary called MRST (multi-resolution summary tree) to approximately capture the PDF of uncertain object. The MRST fully considers the gradient of PDF and more effectively captu res an object X  X  PDF. It has a more powerful filtering ability and consumes lower space co st. We propose a novel algorithm to access the MRST. Through using the key idea of greedy algorithm, this algorithm could reduce the computational cost as much as possible.

Secondly, we propose a new index called R-MRST to organize the summary of ob-jects. R-MRST augments the R-tree tec hnique. The filtering ability of R-MRST X  X  node is as strong as that of U-Tree, but it has the lower cost both in space and dynamic update.
The rest of this paper is organized as follows: Section 2 gives related work and the problem definition. Section 3 proposes the MRST. Section 4 proposes R-MRST that is used to effectively indexing uncertain data. Section 5 evaluates the proposed methods with extensive experiments. Section 6 is the conclusion and the future work. In Section 2.1, we review the existing indexing approaches. In Section 2.2 we formally define the problem of probabilistic range query on uncertain data. Table 1 summaries the mathematical notations used in the paper. 2.1 Related Work In recent years, many effective indexes have been proposed to answer prob-range query on the uncertain data. The PCR-based index named U-Tree (and U-catalog-Tree) is proposed by Tao et al [4]. The problem of U-Tree is that the filter ability of PCR is not strong, and the dynamic update cost is high. Given a set of objects O , U-Tree constructs a group of PCRs for every object, and employs the R-tree technique for organizing them. For simplicity, we introduce U-Tree in the 2-dimension space. As is depicted in is constructed as follows: 2 lines in each dime nsion are computed. In the horizontal di-mension, o has the probability  X  to occur on the left(right) side of line l 1 ( l 2 ). In the rectangle bound by these four lines. Given a prob-query q with q p  X   X  ( q p denotes the threshold of q ), o .PCR(0.2) is used for pruning/validating if q p  X   X  .Asisdepicted in Fig 1(a), q 1 , q 2 , q 3 and q 4 , we assume that their query threshold are all 0.2. Given q , o could be pruned because o.PCR (0 . 2) does not intersect with q r (short for the query region). On the other hand, given q 2 , o could be validated because q r completely contains the part of the left, upper, down border of o.MBR and l 3 . However, the prun-ing/validating ability of PCR is not powerful if q r overlaps with an objects but can not contain d-1 dimension planes of an obj ect in a d-dimension space. For example, o obeys uniform distribution. Obviously, o is the query result of q 3 . o is not the query result of q . However, they can not prune(or validate) o because no filter pruning can be used to prune/validate them. As another problem , the dynamic update cost of U-tree is high. In Fig 1(b), because every object uses a group of PCR to summary its PDF, the node of U-tree also has to use a group of MBRs for bounding these PCRs. Obviously, the cost of maintaining these boundaries is much hi gher than that of R-Tree once the dynamic update happens.

Zhang et al proposed UI-Tree(and UD-tree) for indexing uncertain objects [7]. The filtering ability of them are stronger than tha t of U-Tree. However, the space cost of them are all high. To construct the summary of each object X  X  PDF, the key idea of UI-Tree is partitioning the uncertain region of every object, pre-computing the appearance probability of the partitioned sub-region, and using R-tree technique to organize these sub-regions. Given a prob-range query, UI-tree retrieves the sub-regions that overlap with the query region, finds the corresponding objects, and then computes the lower and upper bounds of app ( o, q ) (short for the appearance probability that o lies in the query region). Specifically, given an object, if a subregion o ( i ) is contained in q r , app ( o, i ) (short for the appearance probability that o lies in o ( i ) ) contributes to both lower and contributes to the upper bound of app ( o, q ) .Then o may be validated (pruned) based on the lower (upper) bound of app ( o, q ) . Although UI-Tree has the stronger pruning ability than U-Tree, its space cost is too high. In the other hand, the partition do not reflect the PDF X  X  gradient, and the filtering algorithm does not consider the intersection area between the query region and the subregions. 2.2 Problem Definition Given a multidimensional probabilistic object o in the d -dimension space, it is described either continuously or discretely. In the continuous case, an object has two attributes: o r and o.pdf ( x ) .The o r is a d -dimension uncertainty region, where o may appear at any locations with certain probabilities. The o.pdf ( x ) is the probability of o appearing at location x . In the discrete case, o is represented by a set of sampled points x 1 , x 2 ,. . ., x m ,and o occurs at location x i with probability x i .p . Given a query region q r ,weuse calculated by two cases. In the continuous case: where o r  X  q r denotes the intersection of o r and q r ,and o is a result if p app ( o , q )  X   X  ( query probability threshold). In the discrete case: where n 1 is amount of the sampled points in o r ,and n 2 is the amount of the sampled points falling into o r  X  q r .
 Definition 1. ( Probabilistic Range Query ). Given a set of probabilistic objects O and a range query q , the probabilistic range query retrieves all probabilistic objects o  X  O with app ( o, q )  X   X  ,where  X  is the probabilistic threshold and 0  X   X   X  1. In this section, we propose a novel summary called MRST (multi-resolution summary tree) to capture the PDF of uncertain data. It provides uncertain data with strong prun-ing/valiating ability through considerin g the gradient of PDF. At the same time, MRST consumes less space cost than the state of ar t approaches. In the following part, we dis-cuss how to construct and access MRST respectively. In the last part of this section, we employ the bit-vector technique to both reduce the space cost and computational cost. 3.1 A Tight Probabilistic Bound For Filtering In this section, we introduce how to provide the object with a tight bound. It is the guide of the summary construction.

We firstly discuss how to provide each sub-region o ( i ) with a tight bound. Given an object o , a sub-region o ( i ) and a query q ,if q r overlaps with o ( i ) .MBR , Equa-tion 3 and Equation 4 show the probabilistic lower-bound and upper-bound of o lying in o r  X  q r respectively. Obviously, by fully considering the intersection area between o ( i ) .MBR and q r , even if our partition is as the same as that of UD-Tree and UI-Tree, the probabilistic bound proposed in this paper is tighter. denotes the maximal(minimal) probability density in o ( i ) . ZS ( o, i ) represents the blank bound) of the p robability o lying in q r  X  o ( i ) .
 Property 1. Given an object o and a query q ,when q r overlaps with o  X  X  subregion i =1 o ( i ) ,the lb app ( o, q )= lb app ( o, q ) ( ub app ( o, q ) ) denotes the lower-bound(uppe r-bound) of the probability o is tight enough. According to Equation 3, Equation 4 and Property 1, the following conditions should be satisfied for the tighter bound: (i) ub ( q,i )  X  lb ( q,i ) should be relatively small; (ii) the amount of subregions should be relatively small. 3.2 Effective Summary Construction Using Multi-Resolution Technique In this section, we employ the multi-resolution technique to construct the summary (called MRST). The MRST could provide the uncertain object with a more effective partition and a tighter probabilistic bound. No w, we formally define the PBD(short for probability bound difference ) which is us ed as the criterion of construction. Definition 2. ( PBD ). Given a sub-region o ( i ) of an object o , PBD ( o, i ) =( ub ( o, i )  X  lb ( o, i ) )  X  S ( o, i ) .

Given an object o , its corresponding MRST is constructed in the following two steps: they are spilt and shrink . The split is to partition the subregions where the probability density changes dramatically. The procedure is that we recursively partition the object region o r until the PBD of each sub-region is less than  X  . And then, we use a quad-tree to temporarily organize this split result. Af ter spilt, the probability density in each sub-region o ( i ) changes smoothly, and ub ( o, i )  X  lb ( o, i ) may be small enough. Obviously, the bound provided by MRST is tighter. For example, in Fig 2(a), the shadow region is the object region o r bounded by a MBR, and the blank region may be seem as the sub-region of o r with a zero-pdf. Fig 2(g) is designed to show the PBD of each subregion. According to Fig 2(g), because the PBD ( o, A ) and PBD ( o, C ) are less than  X  (=0.1 in this section), we stop splitting them. Because PBD ( o, B ) and PBD ( o, D ) are more than  X  , we subdivide them into four parts respect ively. The Fig 2(b) is the result of spilt, and Fig 2(c) shows the corresponding quad-tree.

After the spilt, the shrink is done to merge t he subregions wher e the proba bility den-sity of them are roughly the same. Given two subregions o ( i ) , o ( j ) of o ,theyaremerged if PBD( o , i + j )  X   X  . We access the quad-tree in the post-order. We firstly merge the leaf nodes within the same subtree. Then, we merge the leaf nodes among different subtrees. Specifically, in each subtree, the leaf node with the minimal app ( i , o ) is selected as the candidate node(eg,. d 1 , b 1 , A and C ). Given two candidate node u and v from differ-ent nodes, if PBD( o , u + v )  X   X  , they are merged. According to Fig 2(g), b 1 , because PBD( o , b 1 + b 2 + b 4 )  X   X  , b 1 , b 2 and b 4 can be merged. The Fig 2(d) shows the result of merging the nodes from the same subtree, where b 1 and C are merged. The Fig 2(f) is the finally MRST .

After constructing the MRST of an object, an interesting result is that if the proba-bility density of a sub-region is dramatically changing, it has a fine partition; otherwise, it has a coarse partition. By this property, it guarantees that the MRST could more effectively reflect the gradients of the PDF, and the amount of subregions is relatively small(shown in experiment). In addition, because the PBD ( o, i ) of each subregion o ( i ) is also relatively small, MRST could provide the object with a tight bound. We could build a cost model to find the optimal  X  that need to consider both the filtering ability and I/O cost. A similar method was propos ed in [8]. Due to the limitation of space, we do not discuss it. 3.3 Accessing the Summary of Uncertain Data In this section, we propose Algorithm 1 to efficiently access the summary of uncertain data. Algorithm 1 employs the key idea of greedy algorithm. The Algorithm 1 uses a field called d ( q,i ) to determine the accessing order of the nodes in MRST so as to early terminating the accessing of MRST as much as possible.
Given a query q , an object o and a subregion o ( i ) ,if q.r overlaps with o.MBR , we access the MRST of o to check whether o is a result of q .The d ( q,i ) is com-puted through Equation 5. Obviously, the larger the d ( q,i ) is, the greater it contributes to ub app ( o ) -lb app ( o ) , and the corresponding o ( i ) should be prior accessed. Compared with the traditional accessing method such as pr eorder traversal and inorder traversal, introducing this field to control the nodes acce ssing order is more efficiently to compute the bound.

As shown in Algorithm 1, we firstly access the root of MRST, compute lb app ( o ) and ub app ( o ) according to Equation 3 and Equation 4. If o can not be pruned(or vali-dated), we initialize the array L (line 2-6). After initializing L , the following things are repeatedly done to compute the probabilistic bound. Firstly, we find the node e whose corresponding d ( i, q ) is maximal in L . Secondly, based on e , we tighten the bound: (i) children of e i to compute the new bound according to by Equation 3 and Equation 4,and property 1. Thirdly, if o is not still filtered, we update L : we insert the children e ij of e into L ,when e ij satisfies the conditions that (i) e ij also has children; (ii) the corre-sponding subregion of e ij overlaps with q r .

After accessing the MRST of an object, o is validated if the lower-bound of app ( o, q ) is more than q p .Also, o is pruned if the upper-bound of app ( o, q ) is less than q p .If o can not be pruned/validated, we have to use the integral to check whether o is the result. 3.4 Efficient Summary Storage Now, we discuss how to efficiently store the MRST. The MRST stores three types of information to capture the PDF of a given object. Given an object o and a subregion information, blank area information, and the hierarchical relationship between parent and its children. Because too many informa tion has to be stored, we employ the bit vector to compress MRST as much as possible.

Firstly, we use a m -bits vector to represent the probabilistic information, and its domain is 2 m . As the tradeoff between the degree of accuracy and the space, given an object o and a sub-region o ( i ) , we use 6 bits to express app ( o, i ) , where the domain is 0to63. app ( o, i )=0 . 2 , it is expressed by 0 . 2  X  63 =12(001100). We use 4bit to express lb ( o, i ) (also ub ( o, i ) ), where the domain is 0 to 15. Secondly, we use a n -bits bit vector to express o ( i )  X  X  location information.

Specifically, given an object o ,weusea MBR to bound it. Next, we could use a  X  X ir-tual grid X  with a 2 n  X  2 n resolution to partition the MBR. Lastly, the  X  X irtual coordinate X  expressed by bit vector is used to express o ( i )  X  X  location information. For example, us-ing a 7-bits vector, the resolution of the grid is 128  X  128 . The left-bottom(right-upper) coordinates are described by the cell Id. As shown in Fig 2, the  X  X irtual coordinate X  of node d 1 is expressed by (64,111) and (80,127). The area information depends on the resolution of the  X  X irtual grid X .
 Algorithm 1. Accessing MRST
For example, as shown in Fig 2, base on t he  X  X irtual grid X , because the area of d 1 is 32  X  32 =1024 and half on d 1 is blank, the blank area of d 1 is 512(10000000). Finally, we use a static array to organize the nodes in MRST. We use k -bits vector to express  X  X ffset+len X  so as to describe the hierarchical relationship between the parent and its children. As shown in Fig 2, D is a interval node that has two children d 1 and d 3 ,where the offset is 3(11),and len=2(10).

Another advantage of data compression is that we could use the bit-operations to do the above operations shown in algorithm 1 . Due to the limitation of space, we do not discuss how to store the node in MRST, and how to access MRST using bit-operations. In this section, we propose an index called R-MRST to organize the MRST of uncertain data. Its pruning ability is roughly the same with the other indexes such as U-Tree, but cost of dynamic update and space are much lower than them.

As is discussed in Section 2.1, it is unworthy to store too much probabilistic infor-mation in each node(leaf or interval). For example, given a leaf node based on U-Tree, although using a group of MBRs to bound its children X  X  PCR could obtain a tighter boundary, as shown in Fig 1(b), the shrunken degree of the boundary is relatively small, and it causes both a high space cost and high dynamic update cost. The other indexes such as UI-Tree and UD-Tree also have the similar problem.
Based on the above analysis, we propose the R-MRST .AsshowninFig3,itisthe framework of R-MRST . It is similar with R-Tree. Due t o the limitation space, we mainly discuss how to maintain the probabilis tic information in each node of R-MRST, and how to use it for pruning according to Property 2.
 Property 2. Given a prob-range query q and a node e of R-MRST, the intersection area between e.MBR and q r is S .If S  X  ub ( e ) &lt;q p , e can be pruned.

For each node e in R-MRST, we maintain the maximal probability density called ub ( e ) among all the objects in the subtree of e . Given a query q ,if q r overlaps with the MBR of e , we employ Property 2 for pruning. Although the pruning method seems simple, as shown in Fig 1, it also could prune the node whose MBR X  X  margin overlaps with the query region. Thus, it is suitable for processing range query over uncertain data, and both the space cost and update cost are low.
 Query on R-MRST: Given a prob-range query q , the search starts from the root of R-MRST, and eliminates its en tries according to Property 2. For each remaining entry, we retrieve its child node, and perform the above process recursively until a leaf node is reached. For an object o encountered, we attempt to filter it through accessing its MRST. For the object o which can not be filtered, in the refinement phase, we use the integral to check whether o is the result of q .

Dynamic Update Algorithm: Compared with R-tree, the update method of our in-dex is roughly the same. The difference is the maintenance of ub ( e ) . Specifically, given a leaf node e , when a newly arrived object o inserts into e , the following cases cause the updating of ub ( e ) .(i) ub ( o )  X  ub ( e ) ; (ii) the number of objects in e exceeds to the if e is split into e 1 and e 2 , we compute ub ( e 1 ) and ub ( e 2 ) . When a object o leaves e , the following cases cause the ub ( e ) updating. (i) ub ( o ) is maximal probability density among all the object in e , in this case, we select the new ub ( e ) from e . (ii) if two node e we access the parent e of e to check whether the ub ( e ) need to be updated. If so, we update ub ( e ) and continuous access the upper-level node until no interval node should be updated. This section experimentally evaluates the efficiency of the proposed techniques. The R-MRST will be compared with U-Tree (a classic technique) and UD-Tree, where U-Tree is a classic index and UD-Tree is the most advanced index technology presently.
Two real spatial data sets LB and CA are employed to represent the center of prob-abilistic regions, which has been used as the test data set such as [8] [4]. They con-tain 53k and 62k two-dimension points rep resenting locations in Long Beach and Los Angeles respectively. In addition, three synthetic data sets containing 128k/256k/512k two-dimension points are employed. In our experiments, the region of probabilistic data is a rectangular with side-length varying from 100 to 500 and the default value of the side-length is 200. In this paper, we call the half of side-length as radius. Because it is unfair to select uniform distribution as the o.pdf ( x ) , we use two other common distribu-tions: poisson distribution and normal distribution. In the default case, all dimensions are normalized to domain [0,10000] and LB with constrained normal distribution is employed as the default data set. A workload contains 100 queries in our experiment. The region of the queries are a rectangular with r q varying from 500 to 1500. In our experiments, we randomly choose the probabilistic threshold  X   X  (0,1] for each query. R-MRST was implemented in C++. Experiments are run on a PC with i3-core and 4 GB memory. 5.1 Index Construction Firstly, we compare the index size among R-MRST, U-Tree and UD-Tree. Secondly, we compare the constructing time among these three indexes. Thirdly, we compare the space cost of summary based on these three indexes. The experiment is employed in different data sets. One of them is based on the CA . Another one is a synthetic data set with 200k 2-dimension data. Since UD-Tree can not work when the PDF is in the continual case, we use the sampled points to simulate the PDF of an object.

The Fig. 4(a) to Fig. 4(b) uses the synthetic data set. In the Fig. 4(a), the storage cost of R-MRST is less than that of both U-Tree and UD-Tree. Fig. 4(b) shows the space cost of MRST. As we see, ours performs best of all. 5.2 Query Performance In this section, we evaluate the query performance. In the first group of experiments, we evaluate the performance of the R-MRST, UD-Tree [8] and U-Tree against different r q . The parameters of the experiments are same as the previous one. Firstly, we evaluate the ability of pruning/validating. In the Fig. 5(a), the candidate size of UD-Tree and R-MRST are roughly the same which both perform better than U-Tree. Secondly, we evaluate the response time. In the Fig. 5(b), R-MRST performs best of all.
 In the second group of experiments, we evaluate the performance of the R-MRST, UD-Tree and U-Tree against different threshold  X  .The  X  varies from 0.1 to 0.9, and the other parameters are default. The experiment content are the same as the first group. The Fig. 6(a)-Fig. 6(a) are the results of the experiments. In the Fig. 6(a), R-MRST performs best of all.

The third group of experiments evaluate the filtering ability and the computational cost of the node in R-MRST. All of parameters are default. Firstly, we count the number of the entry nodes needed to be accessed. In Fig. 7(a), the filtered ability of R-MRST and U-Tree are are roughly the same. Secondly, we record the response time. In the Fig. 7(a), the computational cost of them are roughly the same.
 In the forth group of experiments, we study the probability filtering ability of MRST. We count the amount of probabilistic data th at should be checked and then calculate the recall ratio ( rr ) and the response time. The result are reported in the Fig. 8(a)-Fig. 8(a). As expected, MRST has a stronge r filtering ability. In the Fig. 8(a), although the computational cost based on MRST is higher than of PCR, the difference of their response time can be accepted.
 In the last experiments, we compare the performance of R-MRST, UD-Tree, and U-Tree by different data sets. Five data sets (LB,CA and three synthesize) are employed. The number of data points of each da ta set is 53k, 62k, 128k, 256k and 512k. We use default parameters in these experiments. As expected, R-MRST performs best of all. In this paper, we studied the problem of range query on probabilistic data. Through deep analysis, we proposed an effective indexing technique named R-MRST to man-age uncertain data. R-MRST could provided a very tight bound for pruning/validating the objects that overlap(or non-overlap) with the query region in a lower cost. Our ex-periments convincingly demonstrated the efficiency of our indexing techniques. In the future, we will further study other indexes which are suitable for high-dimensional un-certain data and support probabilistic data update frequently.

