 YING ZHANG, PHIL VINES, and JUSTIN ZOBEL School of Computer Science and Information Technology, RMIT University 1. INTRODUCTION
The web contains documents written in many languages and as many languages are used in queries. Although English is the most widely used language on the web, the use of Chinese continues to grow; it is now the third or fourth most commonly used query language. In addition, many Chinese speakers have some knowledge of English, making it attractive to develop effective methods for Chinese X  X nglish cross-lingual information retrieval (CLIR).

There are several approaches to implementation of CLIR. Perhaps the most popular is to use a dictionary to translate the queries into the target language and then use monolingual retrieval. As with other CLIR language pairs, in
Chinese X  X nglish CLIR the accuracy of dictionary-based query translation is limited by two factors: the presence of out-of-vocabulary (OOV) words and trans-lation ambiguity. The OOV problem arises from the fact that some Chinese query terms are not found in translation resources, such as bilingual dictionar-ies and parallel corpora. For example, the query may concern current affairs and thus contain new words or translated words that are outside the scope of the translation dictionary; or the query may contain proper nouns X  X uch as brand names, place names or personal names X  X hat are not included in the translation dictionary. Although only some queries contain OOV terms, incor-rect translation of such terms almost inevitably leads to disastrous results. In some literature, especially in relation to English-to-Chinese translation [Mend et al. 2004], a further problem, the need for phrase detection, is also discussed.
Groups of two or more words may have a special meaning when translated as a unit that differs from that obtained by translating them individually. However, when translating from Chinese, the need to correctly handle such phrases can be treated as part of the OOV problem, as there are no explicit delimiters be-tween words and the difference between a word and phrase is not well defined.
The major distinction is between individual characters and  X  X ords, X  which are strings of characters.

Existing systems tackle the OOV problem in several ways. We have observed that some systems sometimes do not translate an OOV term at all (such as
BabelFish), while others translate character by character using Pinyin, with disastrous results. Some research prototypes appear to require manual inter-vention [Chen et al. 2000] in order to correctly segment OOV terms. In our approach, we exploit juxtaposition of English text and Chinese text on the web to identify OOV terms and thus determine the appropriate segmentation. The technique is segmentation-free as we do not segment a query into words when searching for OOV terms. This has proved to be a  X  X atch-22 X  problem in the past. If the word is unknown, it can not be segmented correctly. If the word cannot be segmented correctly, it was assumed to be impossible to search for a translation.
 In this paper we examine the problem of OOV translation in the context of
Chinese X  X nglish CLIR. We circumvent segmentation difficulties in OOV trans-lation by using the entire Chinese query to search on the web. By mining the web to collect a sufficient number of Chinese X  X nglish co-occurrences and ap-plying statistical techniques, we are then able to infer the OOV term and its appropriate English translation with reasonable confidence. The idea of using the web to search for translations is not new [Chen et al. 2000; Mend et al. 2004]; however, our technique can extract translations that were previously undetected, or only detected after manual intervention to provide correct seg-mentation. For example: suppose the query is  X  x 1 x 2 x 3 segmentation is  X  x 1 x 2 x 3 | x 4 | x 5 x 6 x 7 . X  However  X  x tionary and thus it is an OOV term. If we first applied a segmenter, we might c haracters  X  x 4 x 5  X  are an OOV term, but that would be wrong. It is unwise to assume anything about the segmentation of a query when trying to identify
OOV terms. A potential drawback to our technique is that it might obtain can-didate translations for all query terms. However, our technique works because unusual Chinese terms borrowed from English tend to be accompanied by the original English terms on the web, but this is not the case for common terms. After using the entire Chinese query to fetch web documents written in
Chinese, we collect the English text that is preceded by any substring of the original Chinese query. By applying simple statistical techniques, we are then able to detect Chinese OOV terms and appropriate English translations with reasonable confidence. This OOV translation technique leads to substantial im-provement in effectiveness. We also tested several query expansion techniques, including a novel use of mutual information to select additional query terms. This technique provided a further improvement in retrieval effectiveness.
Extending our original NTCIR-4 paper [Zhang and Vines 2004a], we have used a series of additional experiments to identify the value of the individual components of our process and to explore the sensitivity to parameter settings.
T ogether, these methods show that CLIR using the web and public dictionar-ies can approach the effectiveness of monolingual information retrieval. 2. BACKGROUND 2.1 Chinese OOV Term Translation
NTCIR is a forum for evaluating information retrieval techniques for Asian lan-guages (see www.research.nii.ac.jp/ntcir/ ). The NTCIR-4 task we partici-pated in involves using Chinese queries to retrieve English documents [Kishida et al. 2004]. The English document collection from the NTCIR-4 Workshop CLIR task contains 347,376 news articles from 1998 to 1999. There are 58
Chinese topics, each containing four parts: title , description , narrative , and key words . The principal translation problem we investigated was Chinese query terms that are missing from translation dictionaries or out-of-vocabulary (OOV) terms.

The OOV problem can be divided into two classes, each requiring different approaches. By understanding the different kinds of OOV terms, we can classify the previous approaches and see which types of terms they are likely to pro-vide solutions for. In particular, it is useful to distinguish between OOV terms that have been rendered into the target language by means of transliteration and those that have been rendered by some form of semantic translation. In addition, there are terms that have been translated by a combination of these approaches, such as  X   X  (Kia Motors). 2.1.1 T ransliteration. In Chinese, each character represents a syllable.
Chinese has relatively few distinct phonemes and many sounds in English are not present in Chinese (and vice versa), so Chinese terms transliterated from English often do not closely resemble the original English pronunciation.
Since, many English phonemes often map to one Chinese phoneme, backward transliteration X  X ecovery of the English term from the Chinese X  X s difficult. An additional problem with this process is that a given English term may have more than one Chinese transliterated equivalent. For example,  X  X ichael Jordan X  is transliterated into  X   X  X  nT aiwan, but into  X   X  and  X   X  in Hong Kong. This is because different Chinese communities transliterate En-glish terms in different ways.
 Mend et al. [2004] developed a system that incorporates transliteration from
English to Chinese to deal with English OOV terms. (The results of such a system can be added to Chinese-to-English translation dictionaries, as a further enhancement to the methods discussed below.) Their system appears successful where transliteration rules have been strictly applied and little variation exists, but is not always able to pick the best transliteration when several are in use.
Lin and Chen [2002] developed a backward OOV transliteration process that attempts to recover the original English term from the transliterated Chinese term. This approach requires a candidate set of English terms. Chinese terms and the candidate English terms were converted into a common form using the
International Phonetic Alphabet and a similarity function was then applied to select the closest match. Although there are many sounds in English that have no equivalent Chinese sound and vice versa, they exploited the degree of con-sistency used in the transliteration process. Their system is trained on sample data to learn phonetic similarities, then produces a rank list of possible English name equivalents. Lin and Chen report that the average rank of correct English term was 2.04. In their experiments they usually had the correct transliteration a vailable to them. In previous work we found that by mining the web to collect
OOV terms and then using the web to search for translations, we were able to translate 61% of terms correctly and 31% of terms approximately [Zhang and
V ines 2004b]. These results are not directly comparable, but show that it is rarely necessary to have the correct translation available. 2.1.2 Semantic Equivalence. When OOV term translation is based on meaning rather than sound, transliteration techniques fail. For example,  X   X  (embryonic stem cell) and  X   X  (international space sta-tion) are semantic translations and cannot be connected using transliteration.
Also, backward transliteration of Japanese and Korean names will generally fail, such as  X   X  (Akira Kurosawa), as they have been transliterated via different rules.

In this case, schemes such as web mining [Lu et al. 2002] and approaches based on parallel corpora [McEwan et al. 2002; Yang and Li 2002; Chen and
Nie 2000] can be applied. Lu et al. [2002] exploited the existence of web pages written in different languages that had anchor text pointing to the same page.
By applying statistical techniques, the top-ranked translation proved to be cor-rect in 53% of cases. While this technique is useful, the key drawback is that it requires a web page relating to the Chinese OOV term and sufficient interest to cause linking from a foreign language site. Their technique found several company names, but did not appear to find names of individuals, place names, and other such terms that are rarely the subject of a web page.

McEwan et al. [2002] attempted to locate parallel documents on the web and used these to build bilingual dictionaries. However, such approaches suffer from lack of sufficient high-quality parallel texts. Yang and Li [2002] successfully mined parallel Chinese X  X nglish documents from the web, but, as is common with parallel mining, considered only a small domain X  X ress releases from the
Hong Kong Government. Chen and Nie [2000] also obtained good results in alignment of English X  X hinese documents, but only 427 documents from the
Hong Kong government were used in their experiments. 2.2 Resolution of Translation Ambiguity
Dictionary-based query translation is prone to errors, because of the possibility of selecting the wrong translation of a query term from among the transla-tions provided by the translation dictionary. This is the translation ambiguity problem. It is particularly severe when users enter short queries (often two or three words), a situation in which it may not be possible for even a human to determine the intended meaning from the available context.

There have been several approaches to the ambiguity problem. These have in-c luded using co-occurrence statistics in the target document collection [Balles-teros and Croft 1998; Gao et al. 2002], using mutual information [Mirna 2000;
Maeda et al. 2000], and probabilistic methods based on a language model [Federico and Bertoldi 2002; Sun et al. 2003]. 2.2.1 Co-occurrence Statistics. Ballesteros and Croft [1998] describe a technique that employs co-occurrence statistics obtained from the corpus be-ing searched to disambiguate dictionary-based translation. Their hypothesis is that the correct translations of query terms should co-occur in target language documents and incorrect translation should tend not to co-occur. They mea-sured the importance of co-occurrence of the elements in a set by the em metric, which is a variation of EMIM [van Rijsbergen 1977]. Gao et al. [2002] used a technique based on mutual information and showed that closer words tend to have stronger relationships and improved the basic co-occurrence approach by adding a distance factor. In this paper, we explore the effectiveness of using this approach in combination with a hidden Markov model. 2.2.2 Mutual Information. Mirna [2000] proposed a term-sense disam-biguation technique for selecting the best translation sense of a term from all possible senses given by a bilingual dictionary. Given a set of original query terms, they select the best translation for each of the terms such that resulting set of selected translations contains translations that are mutually related or statistically similar with one another. The degree of similarity or association re-lation between terms was calculated with a term association measure, the Dice similarity coefficient, which is also used in document or term clustering. Maeda et al. [2000], working on Japanese X  X nglish CLIR, have used a search engine to collect the cooccurrence information between terms in web documents, and applied a modified Dice coefficient to calculate the mutual information between terms. They used one document as the window of co-occurrence. 2.2.3 Language Modeling. F ederico and Bertoldi [2002] have used N-best translations provided by the translation dictionary, together with a term weighting adjustment scheme, with good results. Where the motivation for do-ing this is language mismatch X  X hat is, several words in the target language having a similar meaning to the original word in the source language X  X hen the effect is similar to query expansion and can improve recall effectiveness.
However, when trying to discover the most appropriate translation of an OOV term it is possible that some of the candidate translations are entirely wrong, thus leading to considerable loss of retrieval effectiveness if they are included in the query. 3. CHINESE OOV TERM DETECTION AND TRANSLATION
When looking for English translations of Chinese OOV terms, they need to be appropriately detected in the query. Many existing systems use a segmenter to determine Chinese word boundaries. However, if the Chinese OOV term is currently unknown, there is no information to indicate how it should be segmented. In other work [Chen et al. 2000], this problem appears to have been overcome by manual intervention to provide appropriate segmentation.
However, it is clearly desirable that the segmentation be either automatic or, as in the case of the technique we describe, unnecessary.

When a large corpus of Chinese text is available, it is possible to apply statis-tical techniques to identify named entities that are not present in translation dictionaries. Sun et al. [2003] used a trigram stochastic model to detect named entities. Their technique had a success rate of approximately 80%; however, they did not attempt translation. Such a technique is not practical in our sit-uation, as we do not have a Chinese corpus to work with, and in any case it is unlikely that a corpus would contain many of the OOV terms that occur in news and current affairs.

The basis of our approach is the observation that most translated English terms tend to accompanied by the original English terms on the web, typically immediately after the Chinese text, but general terms do not. For example, the text might contain  X  (Dioxin) X  where  X   X  X sa sequence of Chinese characters and  X  X ioxin X  is the original English term for  X   X . By mining the web to collect a sufficient number of such instances for any given word and applying statistical techniques, we hypothesize that we are then able to infer an appropriate translation with reasonable confidence.
In formulating our approach, we also considered English text that was not immediately adjacent to the Chinese query terms. However, we found that such small number of Chinese X  X nglish co-occurrences and our approach proved to be robust in such situations.

OOV translation is only the first step in the retrieval process. We add these terms into both a segmentation and a translation dictionary. We then use the standard dictionary-based query translation steps of segmentation and trans-lation disambiguation. In summary, our procedure consists of three steps: ex-traction of the web text, collection of co-occurrence statistics, and translation selection.
 3.1 Extraction of Web Text
F irst, we query the web to identify strings that contain the Chinese query terms and some English text. 1. Use a search engine to fetch the top 100 Chinese documents, using the en-2. For each returned document, the title and the query-biased summary are
Fo r example, consider a query  X   X  (Director Takeshi Kitano X  X  films) composed of four Chinese terms:  X   X ( T akeshi Kitano),  X   X  (Director),  X  and  X   X  (films). Suppose that  X   X  X  sa nO OV term,  X   X  is a structural particle, and  X   X  and  X   X  are in-vocabulary terms. We used this query to retrieve a series of titles and query-biased summaries of web text that contain English text, as shown in Figure 1, and as can be seen,  X  X akeshi
Kitano X  is the most common English text and  X   X  X  s the Chinese text most commonly observed in the context. 3.2 Collection of Co-occurrence Statistics
We then collect co-occurrence information from the data we obtained. Although is useful in OOV translation. We only consider the English text that occurs immediately after the Chinese query substrings, because, if such an English term occurs at a high frequency, it almost invariably serves as the translation of that Chinese string. 1. Where English text occurs, check the immediately preceding Chinese text to see if it is a substring of the Chinese query. 2. Collect the frequency of co-occurrence of each distinct English string and all Chinese query substrings that appear immediately prior.

Fo r each distinct English string e with the frequency f e of associated Chinese query substrings c j with the length occurrence frequency f ( e , c j ). Extending the example from in Figure 1, this information is summarized in Table I. 3.3 Translation Selection Incorrect translations can, as discussed earlier, greatly degrade effectiveness.
Fo r this reason, we select only the best translation for a Chinese OOV term from Table I as follows: 1. Select the English text e with the highest f e , since the remaining English text that occurs with the highest frequency is more likely to provide the correct translation compared to other text with the lower frequency. 2. For this English text e , select the associated Chinese query substring c the highest f ( e , c j ). In the event of a tie, we use | 3. If the selected Chinese query substring c j cannot be found in the Chinese segmentation dictionary, we treat it as OOV term and add it into the Chinese segmentation dictionary and ( c j , e ) into the translation dictionary.
In this case,  X   X  X  s identified as a Chinese OOV term and  X  X akeshi Kitano X  is extracted as its English translation.

A given Chinese term may have more than one English transliteration. For example,  X  X sama X  and  X  X sama X  are transliterated into the same Chinese term  X   X . However, this phenomenon is rare. Our methods tend to choose the most common form.
 4. TRANSLATION DISAMBIGUATION
Each set of English translations E is a sequence of words e probability model P ( E ) = P ( e 1 , e 2 , e 3 , ... e n of each sequence of words. We select English translations E with the highest P ( E ) among all possible translation sets.

Our disambiguation technique is based on hidden Markov models (HMM) [Miller et al. 1999], which have been used widely for probabilistic modeling of sequence data.

To compute the probability of a sequence of words, we need to calculate the quantities P ( e ), the probability of word e , and P ( e context of e : where f ( e )i s the collection frequency of term e , N is the number of terms in the document collection, and P w ( e , e )i s the probability of term e occurring after term e within a window of size w .

The zero-frequency problem arises in the context of probabilistic language models, when the model encounters an event in a context in which it has not been seen before. Smoothing provides a way to estimate and assign the probability to that unseen event. We use the following absolute discounting and interpolation formula, which applies the smoothing method proposed by F ederico and Bertoldi [2002]. In this method, where f w ( e , e )i s the frequency of term e occurring after term e within a window size w .

F ederico and Bertoldi [2002] successfully used this formula to compute the frequency of term e and e within a text window of fixed size through an order-free bigram language model in their work. However, they did not give detailed information about the size of the text window. The absolute discounting term  X  is equal to the estimate proposed by Ney et al. [1994]: where n k representing the number of terms with the collection frequency k .
We have observed that two words being in close proximity generally provides stronger correlation and produces more credible results for disambiguation of translation than does cooccurrence of two words in a large window. Gao et al. [2002] applied a decaying factor to the mutual information calculation; their experiments showed that the decaying factor can be used to discriminate strong and weak term correlation.
 where Dist( e , e )i s the average distance between e and e in the document collec-tion. Therefore, we have added this distance factor D ( e , e ) into the probability calculation, to give:
Gao found a value of  X  = 0 . 8g av e the best results when combined with their mutual information model. However there was not much difference for values of  X  between 0 . 2 and 1 . 0. The major difference was for is, no distance factor. We investigated the effect of this parameter on disam-biguation performance. (The full details of our experimental setup is described in Section 6.) The results are shown in Table II. It can be seen that our test collection is quite insensitive to this parameter, even for that the reason for this is that the HMM model is a superior technique where sequence data is involved, and is not significantly improved by the addition of a decaying distance factor. Note that variation in window size used to collect word association information has a small effect on the outcome, with w producing the best results. 5. POST-TRANSLATION QUERY EXPANSION
Query expansion has been widely investigated in monolingual retrieval [Robertson and Jones 1976; Xu and Croft 2000; Ruthven 2003]. It has gener-ally provided improvement in retrieval effectiveness, whereas other approaches that use document structure or thesauri expansion have been less success-ful [Mandala et al. 1999]. We aimed, first, to measure the effect of using mutual information on post-translation query-expansion and, second, to investigate the effect of parameter value variability on query-expansion retrieval effective-ness. We also compare the query-expansion techniques we used at NTCIR-4 with those of other participants. We note that query expansion involves selec-tion of parameter values that are not necessarily consistent from one collection to another [Billerbeck and Zobel 2004].

We applied an automatic feedback query-expansion approach that adds t terms from the top d retrieved documents to the translated query. We tested a two-stage process that first selects a set of candidate terms using standard term weighting metrics and then applies a mutual information procedure to select the final set of terms to be added. The motivation for this approach was that, not only should terms be  X  X mportant X  in terms of having a high weight, but they should be related to the query. Using the co-occurrence of the candidate term and all query terms in the collection is a plausible way to measure the word association. In the following sections we explain how these parameters were calculated. 5.1 Term Weighting
To provide a baseline for our query expansion experiments using mutual in-formation, we experimented with two approaches to the selection of the set of candidate terms: tf and tf.idf , without the additional mutual information step. tf is the frequency with which the term occurs in the top d retrieved docu-ments. idf is calculated as log( N / d f ), where d f is the document frequency of the term and N is the total number of documents in the document collection.
English stop words were removed from the retrieved documents prior to term selection.

We experimented with adding either 5 or 10 top ranked terms from the top-ranked 5, 10, 20, 30, 40, and 50 documents. The results of these experiments are shown in Table III. It can be seen that there is not a great difference in the results, but in all cases using tf to select the top terms was more effective than using tf.idf .I t can also be seen that using more documents provided a slight improvement up to 30 documents, but no improvement after that. 5.2 Mutual Information
As explained above, our mutual information procedure involved selecting the top t terms from the set of candidate terms that have the highest degree of mutual information with all translated query terms. In order to select the best t terms, we need to calculate the mutual information of a term and a term set.
The mutual information of a term x and a set S of terms is the sum of x with every term in the set S .

To measure the mutual information (MI) between a given term x and a term s within a window size of w ,w e used: where f w ( x , s )i s the frequency with which x and s co-occur within a window size of w in the document collection; f x is the collection frequency of x and f is the collection frequency of s . Addition of 1 to the frequency ratio means that a zero co-occurrence frequency corresponds to zero mutual information.
In addition to selecting the number of terms t and documents d that partici-pate in query expansion, using of mutual information also requires selection of a window size w used to collect mutual information statistics. Further, the fact that we are using a two-step process requires that we decide how many terms to collect in the first stage, which we call the candidate set c ,t o consider in the second stage. We express this as a proportion of the number of terms added in the final stage. For example, if we add t terms to the query, we might collect an initial candidate set of c = 2 t . Our post-translation query expansion using mutual information thus involves four parameters:
There are many possible combinations of these parameters. We investigated the interaction of these parameters, as follows. 5.2.1 Effect of Adding Documents. As neither tf nor tf.idf wa sc learly supe-rior, we experimented with using both of these to select terms for the next phase.
F rom further experiments (not presented here), we determined that choosing w = 4, 16, or 20 and t = 5o r1 0g av e slightly better results. The results are shown in Table IV. From this table we can observe slight improvements up to 20 documents and a decline after that. We also note the using 5 terms is al-wa ys superior to using 10 terms, something we explore further below. Finally, using tf together with mutual information is more effective than using tf.idf with mutual information. 5.2.2 Effect of Adding Terms. Although our previous experiments (Table IV) suggest that t = 5m ay provide the best results, we experimented with adding larger numbers of terms to see if this had any effect. As tf had proven superior to tf.idf ,w e persevered only with tf . The results of these exper-iments are shown in Table V and confirm that t = 5 produces the best results. 5.2.3 Effect of Window Size. T able VI shows the effect of window size on query expansion using mutual information. Again we have chosen other param-eter values that appear to give optimal results. From the results in Table VI, we can see that there is no consistent trend, although w = results when d = 20. Once again t = 5 performs best. 5.2.4 Effect of Candidate Set Size. A final issue is the number of terms collected in the first phase for consideration in the second phase. In the above experiments, we used a candidate set that was twice the number of terms ul-timately required, namely c = 2 t .W e wondered if collecting more terms in the first phase might improve results, so we experimented with using larger can-didate sets, namely t = 3 and t = 4. However, as can be seen in Table VII, this only led to a deterioration in performance. 5.3 Significance of Mutual Information in Query Expansion
After testing a large number of combinations, as outlined above, we selected the best results from query expansion using only tf to compare with the best results provided by query expansion using tf with mutual information . While this represents tuning, it allowed us to test whether using mutual information in query expansion is likely to provide any benefit.

We used the Wilcoxon-ranked signed to examine the statistical signifi-cance of our results. Our baseline title run T -do using disambiguation and
OOV translation achieved a MAP of 0 . 2166. As shown in Table VIII, using query expansion based on tf with t = 5 and d = 30, we achieved 0 which represents a 5% improvement; using tf and mutual information, with d = 20, t = 5, c = 2 t , and w = 16, we achieved 0 . 2386, which represents a 10% improvement. However, neither of these improvements is statistically significant. 6. QUERY TRANSLATION EXPERIMENTS We used two dictionaries in our experiments: ce3 from the Linguistic Data
Consortium (see www.ldc.upenn.edu ), and the CEDICT Chinese X  X nglish dictio-nary (see www.mandarintools.com/cedict.html )t o translate Chinese queries into English.

As described in Section 3, we detect Chinese OOV terms using a segmentation-free process and add them into a Chinese segmentation dictio-nary for later use. In the dictionary-based query translation phase, we used the updated Chinese segmentation dictionary to segment the queries and re-place each query term using a set of English translations through a bilingual translation dictionary lookup. 6.1 Preprocessing
English stop words were removed from the English document collection. We used a stop list that contains 477 entries and the Porter stemmer [Porter 1980] to reduce words to stems. The Chinese queries were processed as follows: 1. In NTCIR-4, each Chinese query was presented as a list of comma-separated
Chinese text. Our assumption is that each of these text strings is either a phrase or a word. Sixty-six of 163 Chinese strings cannot be found in the translation dictionaries. We treat all of these as potential Chinese OOV terms, although some of them could be translated word by word. 2. Using these 66 Chinese strings as queries, we applied our translation ex-traction technique and added extracted translation pairs into the translation dictionary.
 3. We compiled a segmentation dictionary using the two translation dictionar-4. The translation dictionary was used to replace each query term by all English 5. Our translation disambiguation technique was used to select the most ap-6.2 Experimental Design
Our retrieval experiments consist of 16 runs. In T -runs ,w eh av e used the titles of the Chinese topics as queries and in D-runs the description fields are used as queries to retrieve the documents from the English document collection. The relevance judgments provided by NTCIR are at two levels X  strictly relevant documents known as rigid relevance , and likely relevant documents, known as relaxed relevance .I n this paper, we used only rigid relevance to report our results. Our CLIR experiments used the Zettair search engine developed by the Search Engine Group (see www.seg.rmit.edu.au )a t RMIT University.
To provide a baseline for our CLIR results, we used BabelFish to  X  X anu-ally X  translate each Chinese query. The retrieval results are shown as runs
T -BabelFish and D-BabelFish . Kraaij [2001] showed successful use of the Ba-belFish translation service based on Systran. We established a monolingual reference ( T -mono and D-mono )b y which we can measure our CLIR results.
If the Chinese queries were translated perfectly, we would expect to achieve the same retrieval effectiveness as monolingual retrieval. We then tested dis-ambiguation and OOV translation. After each stage, we have also tested query expansion. These experiments allow us to separately gauge the improvement contributed by each of our techniques. A brief description of the runs is shown in Table IX.
 7. RESULTS AND DISCUSSION
In the previous sections we discussed the individual techniques developed as part of our dictionary-based query-translation process. In this section, we ex-plore the combinations of these techniques and investigate the improvement contributed by each component. The results of these experiments are shown in
T able X. 7.1 BabelFish and Disambiguation
In previous work [Zhang and Vines 2003] using the NTCIR-3 query set, we found that disambiguation alone was always more effective than the BabelFish baseline. This was not the case with the NTCIR-4 query set. Although the
MAP for the description runs was slightly higher using the disambiguation technique, the MAP for the title runs were lower than for use of BabelFish.
Examination of the translations gives the explanation. In the NTCIR-3 queries, many of the OOV terms were incorrectly translated syllable by syllable into completely wrong terms. This resulted in a number of incorrect terms being added to a relatively short query. The effect of this was often that many incorrect documents were retrieved. In the NTCIR-4 query set, we observed that in the majority of cases where BabelFish was unable to translate an OOV term, it wa s simply omitted from the translation. In many cases, there was still enough information in the other query terms to retrieve some relevant documents, especially at high levels of recall. 7.2 Disambiguation Combined with OOV Translation
As shown in Table IX, the OOV translation runs T -do and D-do combine trans-lation disambiguation and OOV detection techniques. The results showed that our OOV translation technique provided an improvement of 18 respectively, compared to the runs T-d and D-d that only applied disambigua-tion. This improvement was statistically significant at the 95% confidence level and emphasizes the importance of a good OOV translation technique. The rigid relevance assessment MAP values for title and description runs were 0.2166 ( T -do ) and 0.1932 ( D-do ), respectively, representing 87 gual retrieval effectiveness. 7.3 Query Expansion
W ith the addition of query expansion as described in Section 5, results were fur-ther improved in all cases. For disambiguation only (no OOV translation) com-bined with query expansion, our T -dq run result (0 . 1830) was slightly lower than those obtained by applying query expansion to the BabelFish T -BabelFish results (0 . 1906), while our D-dq run results (0 . 1678) were higher. More impor-tantly, combining components of our technique X  X isambiguation, OOV trans-lation, and query expansion X  X roduced results that were statistically signifi-cantly higher than those obtained by applying query expansion to BabelFish for both T -doq (0.2386) and D-doq (0 . 2147) runs. The title run ( T -doq )a c hieved 95 . 8% of the monolingual query expansion run ( T -mono + q ) and description run ( D-doq )a c hieved 97 . 0o f the monolingual query expansion run ( D-mono
Although query expansion only gave improvements of 0 . 8 and 1 monolingual runs, it provided improvements of 10 and 11% for cross-lingual post-translation query expansion runs. This shows that query expansion can usefully improve retrieval effectiveness for imperfectly translated queries, al-though it was not helpful for monolingual retrieval.

Kwok et al. [2004] tested pre-translation query expansion in NTCIR-4 and found that it degraded the MAP using both rigid and relaxed assessment. By contrast, our post-translation query expansion technique provided an improve-ment of 10 and 11% of title and description runs, respectively. 7.4 Translation Quality
Our CLIR results were close to our monolingual benchmark. In comparison to other participants of this task in NTCIR-4, we obtained the second high-est results at high levels of precision. The PIRCS retrieval system from City
University [Kwok et al. 2004] achieved better overall results. Interestingly, their monolingual benchmark was higher then ours: 0 . 3175 and 0 title and description runs. This suggests the underlying search engine retrieval effectiveness was superior to ours. In CLIR runs they only achieved 75 and 73% of mono-lingual retrieval effectiveness for rigid assessment [Kwok et al. 2004].
This shows that our OOV translation technique has been effective in de-tecting Chinese OOV terms and extracting English translations and, thus, sig-nificantly improves CLIR effectiveness. Table XI shows the translations ex-tracted from the web. Among 66 potential Chinese OOV terms, 38 instances can be translated word by word using the translation dictionary. Of 28 Chinese
OOV terms, we were able to successfully translate 20. The remaining eight cases failed for one of two reasons: first, our search technique did not return any English terms associated with some Chinese OOV terms; second, some personnel names that relate to events are no longer topical and could not be found on the web, such as  X   X  (Flojo). As mentioned in Section 2, a system that periodically crawls the web to discover new terms would overcome this problem.

We compared our results to those of the LiveTrans system [Cheng et al. 2004]. The LiveTrans system returns a list of up to 20 alternative transla-tions. In 21 cases, the most appropriate translation were present somewhere in the list. In only five cases was the top-ranked translation the most appro-priate. Our system only returns the most appropriate translations, and thus correct in 20 instances. In three cases, our system produced the translations that might be considered more appropriate than LiveTrans. For example, for the Chinese OOV terms  X  , X   X  , X  and  X  , X  our sys-tem extracted the English translations  X  X mbryonic Stem Cell, X   X  X enetic Treat-ment X  and  X  X ontactless Smart Cards CSC X , respectively; whereas LiveTrans extracted  X  X mbryonic stem/stem cells, X   X  X ene theraph, X  and  X  X ontactless/smart card, X  in each case. 8. CONCLUSIONS
We have developed a new segmentation-free technique to identify Chinese OOV terms and extract English translations, which has been demonstrated using the NTCIR-4 test collection [Kando 2004]. This technique can improve the re-trieval effectiveness by 18 . 4% and can be used to improve Chinese segmenta-tion accuracy. We also investigated the effects of distance factor and window size when using a hidden Markov model to provide disambiguation. Contrary to what has been noted when using mutual information techniques to provide disambiguation, we found that using a window distance factor has no benefit when combined with a hidden Markov model. We also evaluated a novel use of mutual information to select additional query terms in post-translation query expansion. Although this technique did not work for monolingual retrieval, it provided an improvement of up to 11% in cross-lingual retrieval effectiveness and allowed us to achieve up to 97% of monolingual retrieval effectiveness.
In conclusion, our OOV translation technique leads to a significant improve-ment in retrieval effectiveness. Post-translation query expansion can be used to improve effectiveness especially for imperfectly translated queries. In addition, the web proved to be a rich resource of potential translations for topic-specific terms.

