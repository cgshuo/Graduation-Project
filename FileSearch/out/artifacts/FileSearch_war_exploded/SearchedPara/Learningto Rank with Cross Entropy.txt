 Learning to rank algorithms are usually grouped into three types: the point wise approach, the pairwise approach, and the listwise approach, according to the input spaces. Much of the prior work is based on the three approaches to learn the ranking model to predict the relevance of a document to a query. In this paper, we focus on the problem of con-structing new input space based on groups of documents with the same relevance judgment. A novel approach is pro-posed based on cross entropy to improve the existing ranking method. The experimental results show that our approach leads to significant improvements in retrieval effectiveness. H.3.3 [ Information Search and Retrieval ]: Search and Retrieval X  Retrieval models Algorithms, Experimentation, Performance Learning to Rank, Groups, Relevance Judgment, Cross En-tropy
Learning to rank [3] has become an important research issue for information retrieval. The basic premise for learn-ing to rank approaches is that there are three types of input spaces: pointwise, pairwise, and listwise samples. There is nearly no approaches based on other samples. Among the three approaches, the listwise approaches have achieved the best ranking performance on Letor data set [4]. However, the existing listwsie approaches are still not effective enough to rank the documents by relevance. Some techniques [2, 5] have been devised to improve this kind of approaches for better performance. One of such novel ideas is to construct new samples to improve the ranking accuracy [2].

Although the top-k framework [5] and the group-wise ap-proaches [2] can generate some good performance for rank-ing, the loss function of the approaches are all based on likelihood loss, which does not reveal the extendibility of the approaches.

In this paper, we show that we can effectively rank the list of documents with respect to a query based on group-wise approach. By using the listwise based ListNet [1] loss func-tion, Cross Entropy Loss, our method can lead to significant improvements in retrieval effectiveness.
ListNet [1] is a robust and effective listwise approach that has achieved good performance in most data sets. It is a feature-based ranking algorithm that minimizes a probabilis-tic listwise loss function which is the cross entropy loss based on Luce model.The cross entropy loss function is calculated as: The ranking function is denoted as f w that is defined based on the neural network model. Given a feature vector x d with respect to q n , f w ( x d ) assigns a score to it. Given a query q , the ranking function f w can generate a score list z n ( f ( f document list.  X  is the set of all possible permutations of k documents, P s (  X  ) is permutation probability of  X  according to s , which is based on Luce model as follows: where s ( j ) denotes the score of object at position j of per-mutation  X  .

ListNet introduces the cross entropy loss into the listwise method for the first time.This approach almost achieves the best ranking performance on most of the measure metrics on the Letor dataset [4], so the improvement to ListNet is quite meaningful.
Top-k framework [5] aims to improve the top-k ranking performance by reforming the likelihood loss in order to ma ke top-k subgroup order sensitive. The cross entropy loss function for Top-k Framework can be defined as: where D is cross entropy loss. P (  X  | x ;  X  y ) and P (  X  are Luce model based permutation probabilities. The score vector of the ground truth permutation is produced by a mapping function  X  y () : R d  X  R , which retains the or-der in a permutation, i.e., if m &gt; n, then  X  y ( m ) &gt; X  order to optimize the top-k ranking accuracy, it lets the mapping function retain the order of documents within the top k positions of the ground truth permutation and as-signs to all the remaining positions a small value  X  (which is smaller than the score of any object ranked at the top-k po-sitions), i.e.  X  y ( x y (1) ) &gt;  X  X  X  &gt;  X  y ( x y ( k ) =  X  y ( x y ( n ) ) = 0. It can be proved that after the modifica-tion, the cosine loss becomes top-k subgroup order sensitive [5]. However there are still some problems with the frame-work. Suppose we have a hypothesis list for the ground truth of six documents, i.e. 2, 2, 2, 1, 0, 0 (2 defined as very relevant, 1 defined as relevant and 0 defined as irrelevant). If k=2, then after processing by mapping function  X  y , the new ground truth of six documents may be 2, 2, -1, -1, -1, -1. Although the loss function may be sensitive to the top-2 ranking positions, which may tend to improve the top-k ranking accuracy. it may make a mistake to the document at position 3, which is very relevant to the query, is treated as the documents at position 5 and 6, which is not relevant to the given query, and so is the document at position 4, which is the relevant document. The error caused by map-ping function to the training samples can also decrease the performance of the ranking model.

For the cross entropy loss function top-k framework just proposes the method to change the mapping function, but no experimental results for validating the effectiveness of the method. For reforming the cross entropy loss function, it makes the mapping function retain the order for the top k positions in a permutation and map all the remaining po-sitions to a small value  X  , which is smaller than the score of any object ranked at the top-k positions.

In this paper we will experiment to validate whether the method works. First, we implement the top-k ListNet. The results on Letor data set is shown in Figure 1 evaluated by NDCG@3. We tried different values of k (i.e., k=1, 3, 10, and the exact length of the ranked list). Obviously the last case corresponds to the original cross entropy loss in ListNet. From Figure 1 we can see that the top-3 ranking accuracies of ListNet cannot be significantly improved with the modifications. There is no one single method that can always achieve best performance on the three collection, and the performance is even descending on TD2004. That may be caused by the selection of the value of k, which is chosen arbitrarily as a fixed value for each query. It may result in that for the two documents with similar feature vectors and same label, which can be annotated by different values based on mapping function. It can cause the label confusion, which can affect the loss function in the process of training, and ultimately reduce the performance of the ranking function. It seems that the cross entropy loss based top-k framework can not improve the ranking performance effectively because the mapping function is easy to make the label confusion for the training documents.

In fact, the top-k ranking loss function is based on the documents on the top-k positions. As the true loss only depends on top-k documents, the selection of k is very im-portant to the final ranking results. In order to avert the label confusion it is natural to set the value of k equal to the number of relevant documents so that the top-k frame-work is sensitive to the relevant document. However, the relevance of document is not just only relevant or irrelevant. There may be multiple relevance judgments as 2 (definitely relevant), 1 (possibly relevant), 0 (irrelevant) used in the OHSUMED collection of Letor data set [4]. And the loss function can not consider the relevant documents with the different relevance judgement as the same ones. It may af-fect the performance of ranking model. In this paper, we use the idea of grouping to solve the problem.
Each query q ( i ) is associated with a list of documents D { with the same relevance judgement j . n is the number of relevance degree for the documents. Furthermore, each list of documents D ( i ) is associated with a list of judgments judgment on the group document D ( i ) j with respect to query q ( i ) . i.e. j = 2, then the relevance degree of the group of D 2 is 2. The documents with respect to a given query in training set can be divided into several groups in which the documents with same labels are gathered together. The groups are the basis of group-group samples. We make the pair of groups as the pairwise method. The pattern is con-structed of a group with higher level label and a group with lower level label, For the query q ( i ) with the relevance degree n=3 (0, 1, 2), we can construct the training sample like this: D ple. The group sample D ( i ) 2 ; 1 includes all the documents in the group D ( i ) 1 and D ( i ) 2 . Furthermore, each list of group sam-ple documents is associated with a list of judgments (scores) Y f ; for each feature vector x ( i ) (corresponding to document d ( i ) in the group sample), it outputs a score f ( x ). For the list of feature vectors x in the group sample we obtain a list of Z li st of documents in the group sample. The goal of learning is formalized as minimization of the total losses with respect to the training group-group sample. where L g is a group sample loss function. m is the number of the group samples in the training data. After defining the group-group sample, we can optimize the top-k framework for the further ranking performance.
Group ranking framework is similar to the top-k ranking framework [5]. However, the samples of the two methods are different, and the meaning of k is different. The true loss of group ranking is defined as: l ( f ( x ) ,y ) = where the r is decided by the number of documents with the higher label in the group ranking samples, and the expected risk of group ranking loss becomes where X is the input space whose elements are the group samples to be ranked, Y is the output space whose elements are permutations of groups. and the optimal ranking func-tion with respect to the group ranking true loss is: where G r ( j 1 ,j 2 ,...,j r ) = { y  X  Y | y ( t ) = j t denotes a group sample in which all the permutations have the top-r,which is decided by the number of documents with higher relevance label, true loss. In this paper, the surrogate loss function is based on cross entropy for the group-group samples, which is described as follows:
L g (  X  g ( y g ) ,z g ( f ! )) =  X  z ( f w ) is the score list for the group sample generated by ranking function f w . y x is the ground truth for the document list of the sample. G is the set of all possible permutations of the documents in the group sample, P s ( g ) is the permutation probability of g according to s . By introducing the group-group sample into the cross entropy loss, we can deal with the relevant label confusion easily for the top-k framework. For the mapping function  X  g , we set the value of the k to be the length of the list of the documents with higher relevant label in the group sample, which can still retain the order in a permutation. For the group sample we propose the mapping function  X  g as follows. Let the mapping function retain the value of the label of the group with the higher relevant label, but for the lower relevant label, the label will be set to a smaller value  X  in order to make the loss function more sensitive to the documents with the higher relevant Alg orithm1 Group ranking algorithm
In put: a set of listwise examples { ( X,Y ) | ( x (1) ,y (1)) , ( x (2) ,y (2)) ,..., ( x ( m ) ,y ( m )) Iteration T , learning rate  X 
Constructing group samples from listwise samples: { ( X g ,Y g ) | ( x 1 ,y 1 ) , ( x 2 ,y 2 ) ,..., ( x n ,y Initialize parameter  X  For t=1 to T do
Compute gradient  X   X  : Update  X  =  X   X   X   X   X   X  End For Output: parameter vector of the ranking function:  X  . T able 1: Ranking accuracies of ranking methods on OHSUMED,  X  and  X  indicate significant im-provement to ListNet and Top-10 of our approach GroupCE ( p 6 0 . 05 ) la bel in the new samples. Algorithm 1 shows the learning algorithm of group ranking, which is similar to ListNet [1]. This paper adopts the neural network framework for training and optimization.

Group sample can be taken as a ranked list with respect to a virtual given query. Therefore, the theory analysis of the top-k ranking framework [5] also works for the group ranking framework.
We evaluate our methods on the Letor3.0 data set re-leased by Microsoft Research Asia. This data set contains two collections: the OHSUMED collection and the .Gov col-lection. The collections we use to evaluate our experiment are OHSUMED, TD2003 and TD2004 which are the sub-sets from .Gov collection. We adopt NDCG@n and MAP to evaluate the performance of ranking functions.
First we compare our method with the existing methods based on cross entropy. We take Top-10 ranking method and original cross entropy loss based approach ListNet as baseline methods to make comparison with our cross entropy loss based group ranking method GroupCE. The results are listed in Table 1-3.

From Table 1-3, We can see that although Top-10 methods on the letor data sets aims to improve the ListNet, in fact Table 2: Ranking accuracies of ranking methods on TD2003 T able 3: Ranking accuracies of ranking methods on TD2004 Grou pCE 0 . 2485 y 0 . 4933 y 0 . 4024 y 0 . 3377 y T able 4: Ranking accuracies on OHSUMED collec-tion th e improvement is too marginal, and some evaluations even show Top-10 is no better than ListNet. It may be caused by relevance label confusion as we discuss in the Section 2.2. However, GroupCE achieves the best performance among all the methods on the OHSUMED and TD2004 datasets in terms of almost all of the measures. It also performs fairly well as compared to the other methods on the TD2003 dataset. Especially for MAP and NDCG@10, it outperforms all the other methods on all the datasets. The performance of GroupCE is also better than Top-10 ListNet. We also conduct the significant experiments to evaluate the improve-ment of our approach, the results reveal that our approach can indeed improve the original cross entropy based meth-ods significantly. The main reason is that the loss function method is relevant documents sensitive and also secures the label classification clarity. The group ranking framework can deal with the label confusion easily, because it annotates the document in the same group by the same value. From the above experimental results, we can come to the conclusion that it is better to use the modified group loss functions than the original surrogate loss functions.

We also examine the performance of our methods com-pared with the existing methods. We select several repre-sentative ranking algorithms compared with our cross en-tropy based group ranking method. The ranking algorithms include pointwise approach: Regression, pairwise approach: RankSVM and FRank and also Listwise approach method: SVMMAP. Especially we compare our method with group ranking method based on likelihood loss [2] (GroupMLE for short). The results are listed in Table 4-5.

We also choose OHSUMED, TD2003 and TD2004 collec-tion as the test collections. The results on the test collec-tio ns show that method of group ranking are useful in en-hancing performance of IR systems comparing with existing methods. The GroupCE method almost boosts the rank-ing accuracies in the terms of all measures. Compared with GroupMLE, our method also achieve better performance on ranking accuracies. It shows that cross entropy loss is more appropriate than likelihood loss to construct the loss func-tion based on group ranking framework.
In this paper, we have proposed a novel group ranking ap-proach based on cross entropy loss to improve the ranking performance. In the new framework, the true loss is de-fined on the relevant documents, and our experiments have shown that GroupCE can significantly outperform its orig-inal versions based on cross entropy. For future work, we will continue to study the theory basis of the group ranking framework to examine whether the ranking performance can be improved further. This work is supported by grant from the Natural Science Foundation of China (No.60673039 and 60973068), the Na-tional High Tech Research and Development Plan of China (No.2006AA01Z151), National Social Science Foundation of China (No.08BTQ025), the Project Sponsored by the Scien-tific Research Foundation for the Returned Overseas Chinese Scholars, State Education Ministry and The Research Fund for the Doctoral Program of Higher Education (No.20090041 110002), Science Foundation for Youth Scholars of Dalian University of Technology. [1] Z. Cao, T. Qin, T. Y. Liu, M. F. Tsai, and H. Li. [2] Y. Lin, H. Lin, Z. Ye, S. Jin, and X. L. Sun. Learning [3] T. Y. Liu. Learning to rank for information retrieval. [4] T. Y. Liu, J. Xu, T. Qin, W. Xiong, and H. Li. Letor: [5] F. Xia, T. Y. Liu, and H. Li. Statistical consistency of
