 In on-line reviews, authors often use a short passage to describe the overall feeling about a product or a service. A review as a whole can mention many details not in line with the overall feel-ing, so capturing this key passage is important to understand the overall sentiment of the review. This paper investigates the use of extractive summarisation in the context of sentiment classifica-tion. The aim is to find the summary sentence, or the short pas-sage, which gives the overall sentiment of the review, filtering out potential noisy information. Experiments on a movie review data-set show that subjectivity detection plays a central role in building summaries for sentiment classification. Subjective extracts carry the same polarity of the full text reviews, while statistical and posi-tional approaches are not able to capture this aspect.
 H.4.m [ Information Systems Applications ]: Miscellaneous Algorithms, Experimentation Summarisation, Sentiment Classification, Opinion Mining New interest in the area of Sentiment Analysis is pushed by the popularity of on-line resources, which allow users to review prod-ucts and services. One of the main tasks in this field is the classi-fication of documents according to the overall polarity, i.e. either positive or negative. A common behaviour among reviewers is to summarise the overall sentiment of the review in a short passage, or even in a single sentence. However, the rest of the review can express different feelings from the overall judgement. Moreover, often a review contains sentences which do not provide any infor-mation about opinions, i.e. they are not subjective. This is the case of movie reviews, where a short picture of the plot can be given to open the review, without commenting on it. Previous work has shown how the detection of subjective sentences can improve the sentiment classification [3].
 This poster investigates how summarisation techniques can be ap-plied in the context of sentiment classification of on-line reviews. More specifically, the aim is to capture the summary passage, i.e. the short passage which gives the overall sentiment of the review. From the user X  X  perspective, the advantage of having a summarised review consists in a reduced effort to understand the message of the document, given that the key information is preserved. Traditional summarisation techniques can be applied for this task, although a more opinion-oriented approach is needed, since the goal is not to better describe the topic of the review in a single sentence, but to capture its overall polarity. In order to verify whether the sum-marisation task preserves the information about the sentiment of reviews, text classification is performed on the original documents and on the produced summaries.
 The contributions of this work are two-fold: firstly, we show how the summaries based on subjectivity well represent the polarity of the full-text review; secondly, we investigate different techniques for identifying the key passage of a review with respect to polarity. Experiments on a movie review data-set show the importance of subjectivity detection for polarity classification. Different sentence selection techniques can be applied to produce various kinds of extractive summaries. This section outlines the different approaches taken into account for the experimental study. Firstly, the traditional Luhn X  X  approach [1] is used to score the sen-tences according to their significance. The top-n sentences are se-lected to create the summary. The results for this approach are labelled as Luhn-n , where n is the number of sentence used to cre-ate the summary. The significance score of a sentence is based on clustering of sentence tokens using a distance threshold (5 is the distance used in this poster). The significant words are chosen ac-cording to their frequency, i.e. the terms with higher tf , excluding stop words, are considered significant. The significance score for a sentence will be the maximum score for any of its clusters. A second family of summarisers is built on top of an empirical observation: often reviewers tend to summarise their overall feeling in a sentence or in a short paragraph, placed either at the beginning or at the end of the review. In this case, a summary can be created simply selecting the n opening, or closing, sentences. Results for these approaches are labelled as First-n and Last-n , respectively. The previous approaches do not consider the subjective nature of the reviews. To overcome this issue, a classifier can be used to iden-tify and filter subjective sentences. A specific data-set, described in Section 3, is used to train the classifier. Filtering out the objective sentences and aggregating only the subjective ones can already be seen as a summarisation approach. The average compression rate of the data under analysis is around 60%. Results for this approach are labelled as Subjective-Full . One of the first two approaches can be applied to subjective ex-tracts, in order to increase the compression rate. In the results, this family of approaches is labelled as follows: Subjective-Luhn-n for the summaries produced using Luhn X  X  approach on the sub-jective sentences, Subjective-First-n and Subjective-Last-n for the summaries based on the subjective sentence positions. The evaluation of summarisation systems is a research issue in it-self [2]. The purpose of this work is observing how summarisa-tion preserves the opinion of a document, so the evaluation is per-formed w.r.t. the polarity classification, i.e. a good summary is ide-ally able to carry the same polarity of the full document. Full text reviews and summaries are classified according to their overall po-larity. Traditional machine learning approaches can be applied for this classification task. Specifically, Naive Bayes (NB) and Support Vector Machine (SVM) classifiers are considered, using unigram-presence as features. The feature selection for NB is based on doc-ument frequency, being a commonly used selection strategy. For the subjectivity detection, a data-set of subjective and objec-tive sentences is used to train the classifiers [3]. This data-set con-tains 5000 subjective sentences, taken from RottenTomatoes pets, and 5000 objective sentences, taken from IMDb 2 plots. The classifiers can be considered reliable enough for the subjectivity detection task which leads to the generation of subjective extracts (micro-average F 1 results on this data-set, with a five-folding cross validation, are 88.85 for NB and 88.68 for SVM).
 The sentiment classification has been evaluated on a different movie review data-set firstly used in [3], containing reviews taken from IMDb and annotated as positive or negative. The data-set con-tains 2000 documents, evenly distributed between the two classes. Table 1 reports the results of the micro-averaged F 1 scores [4] on the review data-set. The macro-averaged results are very similar to the micro-averaged ones, given the data-set is well balanced. Table 1: Micro-averaged F 1 results of sentiment classification http://www.rottentomatoes.com http://www.imdb.com The first observation is that statistical and positional summarisation approaches do not provide any improvement to the sentiment clas-sification results. In fact, the performances are substantially worse for both NB and SVM. The explanation behind this behaviour is that these approaches are not explicitly opinion-oriented, so they are not able to capture the sentiment behind a review. The quality of sentiment classification for subjective extracts is instead in line with the full review classification. Subjective extracts through NB achieves a 1.5% better result compared to the classification of full text. On the SVM side, the classification of subjective extracts is performed slightly worse than the full text. In other words, the sub-jectivity detection step preserves the most important information about polarity, and this aspect is captured by both classifiers. In order to further analyse this finding, experiments on objective ex-tracts classification have been also performed. The objective sen-tences have been aggregated, building the counterparts of the sub-jective extracts. The micro-averaged F 1 values for the objective extracts classification were below 75% for both classifiers, hence significantly worse than both the full review and subjective extract classification. When further summarisation is performed on the subjective extracts, the results drop again. In Table 1, we can ob-serve a similar behaviour between summaries created from the full text and summaries created from the subjective extracts. As fur-ther analysis, we also examine the classification of the summaries with respect to the full documents. In other words, we verify if a full text and its respective summary are classified under the same label, without considering whether this is the correct answer or not. In 91% of the cases, the subjective summaries are assigned to the same label of the correspondent full text. For all the other summari-sation approaches, this value drops below 80%, and in some cases below 70%. This is further evidence of the connection between subjectivity and polarity.
 Sentence extraction techniques purely based on statistical or posi-tional approaches do not capture the subjectivity of a review, and hence are inadequate to summarise the sentiment of the document. On the contrary, subjectivity detection produces results which are comparable to the full text classification. Further summarisation on top of subjectivity detection, again fails to capture the polar-ity of documents, as more opinion-oriented approaches are needed. Showing a subjective extract instead of the full text, a potential user would need to read about 60% of a review, or even less, in order to understand its polarity. [1] H.P. Luhn. The automatic creation of literature abstracts. IBM [2] A. Nenkova and K. McKeown. Automatic summarization.
 [3] B. Pang and L. Lee. A sentimental education: Sentiment [4] Fabrizio Sebastiani. Machine learning in automated text
