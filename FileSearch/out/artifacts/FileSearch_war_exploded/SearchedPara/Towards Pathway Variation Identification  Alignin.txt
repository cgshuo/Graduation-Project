 A Care Pathway is a knowledge-centric process to guide clin-icians to provide evidence-based care to patients with specif-ic conditions. One existing problem for care pathways is that they often fail to reflect the best clinical practice as a result of not being adequately updated. A better understanding of the gaps between a care pathway and real practice requires aligning patient records with the pathway. Patient records are unlabeled in practice making it difficult to align them with a care pathway which is inherently complex due to its representation as a hierarchical and declarative process mod-el (HDPM). This paper proposes to solve this problem by developing a Hierarchical Markov Random Field (HMRF) method so that a set of patient records can best fit a given care pathway. We validate the effectiveness of the method with experiments on both synthesized data and real clinical data.
 J.3 [ Life and Medical Sciences ]: Medical information sys-tems; I.2.1 [ Arti cial Intelligence ]: Applications and Ex-pert Systems Theory, Experimentation
A care pathway is a complex intervention for the mutu-al decision-making and organization of care processes for a  X  Co rresponding Author.
 well-defined group of patients during a well-defined period [14]. Relying on a care pathway, clinicians can create care plans for individual patients with specific clinical condition-s in order to improve care quality. A care pathway usually consists of multiple phases corresponding to different disease progress conditions where each phase can have sub-phases or care activities performed by care givers. Figure 1 shows a typical care pathway for treating patients with congestive heart failure (CHF) which contains four phases of care ac-tivities [5].

As the clinical evidence that forms the basis for care path-ways has a surprisingly short shelf life, it is not unusual that a care pathway could fail to address the clinical needs of a specific patient cohort due to the absence of required clin-ical knowledge or the evidence supporting a care pathway becoming obsolete. To successfully put a care pathway into practice and better adapt it to local care settings, clinical institutions must identify the variations between the care pathway and daily care practices for a targeted patient co-hort, and revise the care pathway based on the identified best practice from patient records. For example, a varia-tion could be that the pathway does not include an activity of measuring blood pressure at the initial assessment stage for patients with chronic heart failure while in practice the measurement is taken for most patients. However, difficul-ty exists for variation identification because patient records produced from care practices are typically not labeled with explicit pathway information, and we cannot directly tell which data items belong to which phases. Therefore, in or-der to identify variations between the pathway and a given set of patient records, we must first align each patient record with the pathway.

Aligning patient records with a given care pathway so that the records best fit the pathway is challenging due to sev-eral reasons: Firstly, a care pathway has a complex struc-ture which can be represented as a hierarchical declarative process model (HDPM) where the process is composed of multi-layer phases and activities and there may be tempo-ral dependencies among phases and activities. Existing so-lutions for the sequence tagging problem, which is a close neighbor of this problem, are designed for a single layer con-dition without considering the hierarchical structure of the Fi gure 1: An example of care pathway for chronic heart failure. model, and do not address the temporal dependencies ei-ther (see Section 2). Secondly, an activity can be planned in different care phases (e.g. measuring blood pressure is a regular activity taken through every phase of hypertension care) which may result in ambiguity of assigning patient data items corresponding to the activity to the right care phase.

Figure 2 shows a simple example to illustrate the situ-ation where the care pathway is represented with a tree-like structure and comprises two phases  X  p 1  X  and  X  p 2 contain four activities  X  a 1  X ,  X  a 2  X ,  X  a 3  X , and  X  a temporal dependency  X  X here must be a phase p 1 before the phase p 2  X . A patient record is formulated as an event trace  X  a 1 , a 2 , a 3 , a 4  X  X hich means that the record is generated from problem now is to assign each event in the trace into cor-responding phases. As a result, we have two alternative mappings as shown in the table where the only difference is the label of  X  X 1 X . Between two options we prefer the first mapping because the second mapping violates the temporal dependency between p 1 and p 2 since X  a 1  X  X s labeled with X  p Furthermore, the first mapping achieves better smoothness in terms of phase changing as there is only one phase change from  X  p 1  X  to  X  p 2  X  along with the occurrence of  X  a 3 there are two phase changes in the second mapping. In re-ality, a care pathway could be much more complex and may confound us with the task of effectively and efficiently map-ping the patient records with the pathway.

Finally, there are no phase or subphase labels available in patient records. The lack of supervision information makes it hard to train a learning model for alignment and evaluate its performance.

In order to address the aforementioned issues, we propose the adoption of a Hierarchical Markov Random Field (HM-RF) based method [2] to align a group of patient records with a given care pathway by optimizing a HMRF model with the simulated field algorithm. The algorithm work-s by considering correlation relationships between pathway elements, labeling state transition smoothness as well as sat-isfying temporal constraints defined in the pathway. We also evaluate the method in terms of a few proposed performance metrics against a synthetic data set and a real clinical data set. In summary, in order to conduct variation analysis of Fi gure 2: Aligning a patient record with a care path-way care pathways, the paper mainly contributes on the follow-ing:
In addition, our method is not limited to care pathway analysis and is applicable to solve the same alignment prob-lem for all hierarchical declarative processes.
Over the last decade, process mining has emerged as a new research field, which aims to discover, monitor and improve process models by extracting knowledge from event logs [12]. Research in process mining can be categorized as follows: (1) process discovery, to discover a process model from an event log; (2) conformance checking [13, 1], to compare an existing model with an event log; and (3) model enhancement [4], to improve an existing model based on an event log. For con-formance checking or enhancement, alignment of an event log and a process model is typically required to relate the events in the log to the model elements. For example, van der Aalst et al. [13] proposed an alignment approach using A* algorithm to diagnose and quantify deviations between a process model and an event log. Fahland et al. [4] further introduced a method to repair a process model with respect to an event log based on the alignment between them.
Although alignment techniques have been successfully used in the context of procedural process models that explicitly define all allowed process behaviors, it is quite challenging to align declarative process models with event logs. This is because in a declarative model,  X  X verything is allowed unless explicitly forbidden X  X 3]. Therefore, the search space for find-ing an optimal alignment of a declarative model and a log is much larger. To address this issue, de Leoni et al. [3] im-proved the alignment approach by pruning the search-space nodes that were guaranteed to lead to non-optimal solution-s. However, their approach is limited to non-hierarchical declarative models and cannot distinguish duplicate activ-ities planned in different phases which is applicable to our problem.
On the other hand, aligning patient records with a care pathway with multiple phases is actually a labeling prob-lem. A variety of labeling problems can be optimally posed as Bayesian labeling in which the solution of a problem is defined as the maximum a posteriori (MAP) probability es-timate of the true labeling. The posterior probability is usu-ally derived from a prior model which depends on how var-ious prior constraints are expressed, and a likelihood model which relates to how data is observed and is problem do-main dependent. Markov Random Field models [7] are used to encode contextual constraints into the prior probabili-ty, and widely used in pattern recognition applications in-cluding speech recognition, image segmentation and so on because they can exploit context in a local manner by en-couraging adjacent nodes to take the same label. In specific, to encode context at different scales, Zhu et.al [16] proposed a Dynamic Hierarchical Markov Random Field method to extract web data. Hinton et.al [10] proposed multilayer gen-erative models that combine the best aspects of Markov ran-dom fields and deep directed belief nets and describe im-age patches. However, these methods cannot deal with the sequence labeling problem with hierarchical structure and temporal constraints.

One previous work [8] started to address the issue of align-ing patient records with a care pathway with multiple stages. However, the work applied a straightforward HMM method and only considered the temporal dependency between t-wo adjacent events in a trace and ignore the others in the trace. In addition, the resulted alignment may contain fre-quent phase changing which contradicts to care practice. In this paper, we design a Hierarchical Markov Random Field method which is well suited to the real scenario of a care pathway structured with multiple layers and having tempo-ral constraints between pathway elements.
In this section, we introduce notation and concepts to for-mulate our problem.

HDPM. In this paper, we use a two-layer HDPM to for-mulate a care pathway. Let an HDPM be a tuple { P, S, A, R, T where P = { p v } V v =1 , S = { sp q } Q q =1 and A = { a resent the phase label set, subphase label set and activity set respectively, and V , Q and M are the respective set sizes. R is the collection of all  X  X arent-child X  relationships over two layers, which can be represented as R = { R p , R R p  X  X  0 , 1 } Q V is a matrix where R p ( q, v ) = 1 if the q -th subphase belongs to the v -th phase, otherwise R p ( q, v ) = 0. Likewise, R s  X  X  0 , 1 } M V is a matrix where R s ( m, q ) = 1 if the m -th activity belongs to the q -th subphase, otherwise, R ( m, q ) = 0. T represents the set of temporal constraints associated with phases or activities. A temporal constraint is represented as a tuple of three elements where the first el-ement indicates the pathway layer (i.e., phase, subphase, or activity) where the constraint applies, and the latter two el-ements are the specific pathway elements against which the constraint applies. Note that in this paper we only consider the precedence constraints. E.g., {  X  X hase X , X  p 1  X , X  p 2 phase-level constraint to restrict that p 2 happens only when p 1 has already been completed. Figure 3 shows a tree-like example of HDPM with two layers.

Event Trace. A patient record is a typical event trace, i.e., a sequence of events { e 1 , ..., e n } where each event is sam-pled from the care activity set. Without loss of generality, we Fi gure 3: The Hierarchical Declarative Process Model (HDPM). introduce a mapping from the event sequence to the activity set, e.g., a i = mapping ( e j ), where j  X  [1 , n ] , i  X 
Smoothness. Patient conditions, particularly for pa-tients with a chronic disease, normally do not change drasti-cally. Thus, when labeling patient records with care phases (or subphases) in an HDPM, we anticipate a smooth phase transition. Figure 4 illustrates how a smooth labeling is achieved for an event trace given the HDPM in Figure 3. Candidate subphase labels available for assigning to each event are in the middle layer of the figure. At the bottom is our tagging result which keeps phase-transitions smooth in a local manner where the first event of a 1 in the even-t trace is labeled with sp 2 in order not to having a phase transition from sp 2 to sp 1 (if labeling a 1 with sp 1 ) because its previous adjacent event a 3 is labeled with sp 2 . We use a smooth potential function to achieve the smoothness across the two layers when developing the alignment method (See Section 4), and we also propose a metric to evaluate the labeling smoothness in Section 5.

Co-occurrence. Co-occurrence is a widely used concep-t in text classification, image annotation. In this work, it refers to the number of times that an activity is planned in the same subphase or phase with another activity. In-tuitively, we can use a matrix to record the co-occurrence for all activities given an HDPM. Likewise, we can gener-ate the co-occurrence matrices of subphases that are defined in the phases. Figure 5 shows the resulting co-occurrence matrices according to the HDPM in Figure 3. For example, C [1 , 2] = 2 specifies that a 1 and a 2 are defined in the same subphases twice (respectively in sp 1 of p 1 and sp 1 of p Larger co-occurrence leads to tighter correlations between activities or subphases. Note that diagonal values record the number of corresponding elements defined in the path-way model, e.g., C p s [1 , 1] = 2 because two sp 1 are respec-tively defined in p 1 and p 2 of the model shown in Figure 3.
Must-link and Cannot link. Given an HDPM, we say that there is a must-link between two activities if they are always planned in the same subphases, whereas there is a cannot link between them if they never co-occur in the same subphase. E.g., for the HDPM in Figure 3, ( a 1 , a 2 ) are must-link and ( a 3 , a 5 ) are cannot link. These two relationships affect our labeling method in the way that the correspond-ing events of must-link activities are labeled with the same subphase while events of cannot link are different. Figure 6 illustrates our idea where events of a 1 and a 2 are always labeled the same and events of a 3 and a 5 are labeled with different subphases sp 1 and sp 2 . Let C = { C ml , C cl resent the link relationship set where C ml = { ( a j , a C cl = { ( a i , a j ) } represent the must link set and cannot link set respectively. We use a matrix W to represent all the link relationships between pairs of activities where Fi gure 6: The illustration of must-link and cannot-link.

With the above definitions, we can formulate the problem as follows: given an event trace { e 1 , ..., e n } we aim to infer { and s i  X  S is the phase label of event e i with the goal of achieving the best label smoothness and the maximal satis-factory temporal constraints.
In this section, we describe the details of our HMRF-based approach. HMRF is a commonnly used generative model [6]. It is defined based on two assumptions:(a) Given the latent variables y (subphase labels) and s (phase labels), the observed variables e (events in a trace) are independen-t, i.e., p ( e | y, s ) = variables e , y and s constitute a hierarchical Markov net-work respectively. Figure 7 demonstrates the sketch of our method. When aligning an event trace from a patient data set against the given care pathway represented by an HDPM, our objective is that the resulted alignment should 1)max-imize the number of the right parent-children relationships for the events and phases; 2)maximize the label smoothness, i.e., have as few as possible phase transitions across the w-hole trace; 3) maximally satisfy the temporal constraints a-mong activities, subphases and phases. Therefore, we define the general formulation of joint probabilistic distribution of events and hidden subphase and phase labels as follows: where  X  u denotes the unary potential function and is used to evaluate the correlation of parent-child relationship,  X  denotes the subphase-level smoothness potential function,  X  s denotes the phase-level smoothness potential function,  X  denotes the temporal constraints function, Z denotes the partition function which is included to maintain the normal-ization condition for the distribution (please refer to [6]), n is the number of events in the given trace, N i denotes the neighborhood set of e i (In this work, N i includes the 5 events preceding and 5 events succeeding e i ) and T is the number of temporal constraints in the model. We define each function in the subsequent subsections, and describe the optimization algorithm in the end.  X  u is composed of two parts: the first part  X  1 ( e i , y beds the correlation between the observation e i and its la-tent subphase label y i ; the second part  X  2 ( y i , s i the correlation between a subphase label y i and a phase la-bel s i . Recall that the given HDPM tells the parent-child relationships across the two layers. For simplicity, we define the unary potential as  X  u ( e i , y i , s i ) =  X  1 ( e i where  X  1 ( e i , y i ) = exp (  X  1 ),  X  2 ( y i , s i ) = exp (  X  are defined as follows where 0 . 05 is an extremely small value to ensure that there is no zero probability.  X  y ( y i , y j ) embeds the correlation between two subphases y i and y j , and ensures the label smoothness in the sub-phase level. It is determined based on the two previously introduced concepts: co-occurrence and link relationships between activities in Section 3. On the first hand, relying on the co-occurrence of activities within subphases, the basic idea is to propagate these co-occurrence correlations between activities to the subphase label space. The principle of label propagation is illustrated in Figure 8 where the length of the arrows represents the degree of correlation. Since a 4 and a are closer, their labels y 4 and y 5 have a higher probability of sharing the same subphase label. The correlations between subphase labels can be represented by a knn neighborhood system of their n underlying activities, denoted as a n  X  symmetric matrix V ls y = { v ij } . This neighborhood system is constructed based on both co-occurrence and distances be-tween activities. v ij &gt; 0 means positive correlation, i.e. y and y j should be same; v ij &lt; 0 means negative correlation, i.e. y i and y j should be different; v ij = 0 means no correla-tion. According to [15] , the normalized affinity matrix V is computed as where D y is a diagonal matrix with D y ii = F y is the initial affinity matrix which is computed based on the co-occurrence matrices C s a (as in Figure 5) and the distances between events, and is computed as F y as F y ij C distance between e i and e j .

With the above formulation, the pairwise potential func-tion for subphase label smoothness is defined as where  X  is a positive trade-off parameter between unary and pairwise potential, and it is learned in Section 4.5.  X  is defined as follows: if y i = y j , then  X  ( y i , y j ) = 1, else  X  ( y i , y j ) = 0. The above equation has an intuitive inter-pretation in probability: when V ls y ij &gt; 0, if y i  X   X  this configuration will decrease; when V ls y ij &lt; 0, if y ability of this configuration will decrease; when V ls y ij  X  ( y i , y j ) = 1, i.e., the prior probability of any configuration of y i and y j is equal. In summary, when a either a positive or a negative correlation exists between y i and y j (propagated from underlying event co-occurrence correlation), configu-rations that violate the correlation (which means that we assign different two subphase labels for a positive correla-tion or the same label for a negative correlation) should be penalized in probability. The penalty degree depends on the value is the bigger penalty we get.

On the other hand, we also consider link constraint propa-gation. Following [9] and relying on Equation 1, we compute Fi gure 8: R is the original activity space, y is the subphase level label space. the link correlations between y as V cs y where  X  (0 &lt;  X  &lt; 1) is a user-defined constant to control the propagation degree. After that, combining the previ-ous definition in Equation 5 the whole pairwise potential is updated as follows:  X  y ( y i , y j ) = exp (  X   X  [  X  [ where  X  is a user-defined parameter which represents the trade-off between the two terms. (In our experiments in Section 5 we set  X  = 1 so that co-occurrence and link con-straints are equally treated).
We define the phase level smoothness over the subphase labels. This formulation is based upon the observation that phase labels for events within a neighborhood are more likely to take the same value. Because the co-occurrence matrix of subphase labels in phase labels has been obtained, we have a similar formulation with the subphase level as in Equation 7.  X  s ( y i , y j , s i , s j ) = exp (  X   X  [  X  [ + + F parameter which will be optimized in Section 4.5.
Handling temporal constraints is a challenge in many pat-tern recognition problems. Three levels of temporal con-straints are involved in our problem. As illustrated in Fig-ure 3, we have: 1) The activity-level temporal constraint, such as in phase p 2 , a 1 should be executed before a 2 . When a 1 and a 2 happen sequentially in a trace, it is more favor-able to assign the phase labels for the two events as p 2 The subphase level temporal constraint, such as in phase p , sp 1 sh ould be executed before sp 2 . (3) The phase lev-el temporal constraint, for example, p 1 should be executed before p 2 . According to Equation 2, the corresponding tem-poral constraint function for these constraints is formulated as  X  =  X  a  X   X  s  X   X  p , where  X  a = exp (  X   X   X  ( e i = a 1 , e j = a 2 , j &gt; i, y i  X  y = exp (  X   X   X  ( y j = sp 2 ,  X  X  X  y 1 j 1  X  sp 1 ))  X  s = exp (  X   X   X  ( s j = p 2 ,  X  X  X  s 1 j 1  X  p 1 )) and  X  is a positive parameter (in the experiments we set  X  = 1), and  X  ( c ) = 1 if the constraint c is satisfied, otherwise,  X  ( c ) = 0. In the examples, the constraint in  X  a represents that if two events a 1 and a 2 occur sequentially, their labels should be assigned to p 2 , and the one in  X  y means that if the j -th event is labeled as sp 2 , then at least one event before it should be labeled as sp 1 . For simplicity, given an event trace, we only identify the first occurrence of these constraints. The unified objective is to maximize the following Because y and s are not independent with one another, we use an approximate method to gain a suboptimal solution (simulated field algorithm [2]). The main idea is: when treating a particular latent variable y i , ignore the fluctua-tions of its neighbors or its top level variables by fixing their states. As a consequence, the overall computation reduces to addressing independent variables. The parameters to be optimized are  X  in Equation 7 and  X  in Equation 8. The main algorithm is summarized in Figure 9.
 Fi gure 9: HMRF-based algorithm to align event traces from patient records.

The optimization procedure iterates over the following t-wo steps: Step 1 Given  X  ( t 1) ,  X  ( t 1) , p ( y | e,  X  p ( s | e,  X  ( t 1) ,  X  ( t 1) ), update y and s . We treat the latent variables y and s equally. y ( t ) and s ( t ) are respectively simulated from p ( y i | e i , s i ( s 1 , ..., s In this step, parameter learning and inference are performed by the Expectation Maximization (EM) algorithm as fol-lows.

E step : compute the posterior probability and the expec-tation of the joint log likelihood function, for y and s
The value of p ( y i , y ( t ) N computed with Equation. 7 and Equation. 8.

M step : learn the parameters  X  ( t ) ,  X  ( t ) .
The optimization procedure stops when the convergence criterion is satisfied. (the function value does not change much or number of iterations exceeded the threshold.)
In this section we present the details of experiments on two datasets to demonstrate the effectiveness of our method.
In order to evaluate the performance of our alignment method, we proposed the following measurement metrics:
Alignment Accuracy Our goal is to align patient da-ta with phases of a given care pathway, it is natural to use the percentage of correctly tagged clinical events reflected by patient data to measure the overall performance of the method. However, measuring it is difficult because patient data normally does not include explicit tag (phases) infor-mation. Thus, we propose to use a synthetic dataset (see Section 5.2) with known tags to measure alignment accura-cy of our method. We use g i y and g i s to denote the ground tru th labels on the subphase level and phase level. n is the total number of events in the test sequences. We also mea-sure the number of correctly matched events on both layers. The measures are defined as follows: where ACC total measure the proportion of the events that are labeled right at the both levels.

Temporal Constraint Satisfaction As a declarative process model a care pathway encodes the temporal con-straints that must be followed when performing clinical ac-tivities. So we expect that the alignment result could re-sult in satisfaction of temporal constraints. For each lev-el of HDPM, if a temporal constraint is satisfied once, it is deemed as a correctly classified sequence regarding this constraint. We define the temporal constraint satisfaction (TCS) on each level as follows T CS = 1 wh ere N s is the number of total event sequences and N c the number of temporal constraints defined in the level.
Transition Smoothness As illustrated in Figure 4, label transition smoothness is another metric we are concerning about when aligning events with the model. In fact, we use the transition smoothness as a compensation for the accu-racy metric, especially when labeling is not available in real data. The smoothness metric on the subphase level and phase level are defined as follows: where C y ( j ) is the set of subphases which include the ac-tivity corresponding to e j in the given HDPM and C s ( j ) is the set of phases which include the activity corresponding to e j , and the denominator is the number of occurrences of all hidden state transitions. If the activities of two events involved with a state transition share common subphases or phases, then the transition is deemed unnecessary. The smoothness is measured based on the proportion of unneces-sary state transitions: the fewer the number of unnecessary state transitions, the higher the smoothness.
Synthetic dataset . In the first set of experiments, we randomly generate synthetic data using a Hidden Markov Model (HMM) derived from the HDPM shown in Figure 3. The phases and subphases of the HDPM are converted to hidden states of the HMM, and the activities are mapped onto observations. The probabilities of the HMM are ini-tially set according to a uniform distribution, and subse-quently the probabilities of the transitions that satisfy the Fi gure 10: Care pathway model for treating patients with CHF.
 Table 1: Experimental results on the synthetic dataset.
 co nstraints of the HDPM are increased. Based on the HMM, we generate the synthetic event traces and their correspond-ing phase (subphase) traces. In the generated traces, each event and its phase are determined according to its previous event and phase, the probabilities in the HMM and random-ly generated noise. The length (number of events) of each generated trace is 100. We randomly divide the generated traces into training and testing sets, each of which consists of 100 event traces.

Real world dataset . In the second set of experiments, we create a HDPM (as shown in Figure 10) based on a pub-licly available care pathway guideline for treating CHF [5], including 4 phases, 10 subphases, 84 activities and 4 tempo-ral constraints between the subphases. Then we align a set of patient records with this HDPM. The patient records are obtained from a real world dataset which contains 3 years X  diagnosis, lab tests and medications from 425 patients with CHF condition. In total, 22 , 431 clinical events from the records are mapped to the activities defined in the HDPM. The average length of the event traces is 53. Furthermore, we randomly split the real world dataset into equal sized training and testing sets.
We first performed an experiment using our method to align the traces in the synthetic dataset with the HDPM defined in Figure 3. We applied the algorithm in Figure 9 to learn the parameters  X  ,  X  based on the training set, and then inferred the optimal phase and subphase labels for each event trace in the testing set. With the derived results, we computed the values of evaluation metrics in Section 5.1. To understand how our method performs, we also applied the same method in [8] which employs Viterbi algorithm [11] to label each event traces in the testing dataset based on an HMM derived from the given HDPM, and compared the alignment metrics with our method.

Table 1 shows the experimental results on the syntactic dataset. We observe that our HMRF-based method out-performs the HMM-based method in alignment accuracy at both phase and subphase levels because of effective learning T able 2: Experimental results on the real dataset. o f model parameters and explicit consideration of satisfying temporal constraints as well as transition smoothness. In contrast, the HMM-based method overlooks temporal con-straints between HDPM elements (There are totally three temporal constraints in the HDPM), and does not explicitly consider transition smoothness. Therefore, our method also outperforms the HMM-based method in terms of TCS and SMO. Note that both methods achieved low SMO at the phase level. This may be resulted because the given HDPM has two phases p 1 and p 2 which share a large proportion of common activities including a 1 , a 2 and a 4 . According to Equation 19, the state transitions between these common activities within the traces are counted as unnecessary which leads to the low value of SMO.

Moreover we performed the experiments on the real dataset as well. Table 2 shows the achieved SMO and TCS val-ues when applying our method and HMM-based method to align the patient traces with the given CHF pathway (TCS is not applicable at the phase level as there is no temporal constraints among the four phases of the pathway). As no known labeling information on phase and subphase is avail-able in the real dataset, we are not able to compare the alignment accuracy of the methods. Clearly, our method outperforms the HMM-based method in both metrics, and validates the effectiveness of the method again.

With the goal of identifying variations between a care pathway and the practice based on it, we collected the aligned patient records with the given CHF pathway and identified two types of variations: 1)Missing activities that are defined in the original pathway but not (or seldom) present in the particular stages. 2)Violated constraints that are defined in the original pathway but not (or seldom) abided by clinical practice. Based on the variation analysis results, we found that: 1) A few activities are seldom performed in practice by clinicians including: Creatinine, Blood Pressure (BP), Captopril, etc. 2)The constraints that are seldom followed by clinicians. For example, In a large proportion of traces, the subphase  X  X aseline X  does not occur before  X  X reatmen-t X  in Phase I, which violates the pre-defined constraint. We found that the majority of these absent activities and violat-ed constraints are due to the non-compliance to pre-defined lab tests. These results are statistically significant and have been validated by a medical professional. Therefore, these can be used to refine the original care pathway by remov-ing unnecessary items or relaxing constraints and in turn improve care quality.
In this paper, we propose a method using hierarchical markov random field to align patient records with a giv-en care pathway that is represented with a HDPM. We inte-grate the co-occurrence and link relationships obtained from the HDPM into the HMRF model to achieve a smooth align-ment result. We employ a simulated field algorithm to au-tomatically learn and optimize the model parameters. The method lays a foundation for identifying pathway variations and is generally applicable to HDPM in other domains.
One limitation of our work is that we assume that every event in the traces can be mapped onto an activity pre-defined in the HDPM. In real patient data, however, some additional events, which are not defined in the HDPM, may occur frequently. How to tag these additional events with appropriate phases is an important issue that needs to be ad-dressed. One possible solution is to: 1) collect all additional events from the data set; 2) Identify co-occurrence patterns and link relationships between these additional events and the existing events from data sets. 3) Extend C p s and C include these additional events. 4)Follow the same method in this paper to align all events. We will validate the pro-posed approach in future.

In addition, we currently restrict our analysis to HDPM with only two phase levels. In reality, it is possible that a care pathway can have more than two phase levels. In future, we intend to extend the current method to HDPM with more layers. [1] A. Adriansyah, B. van Dongen, and W. van der Aalst. [2] G. Celeux, F. Forbes, and N. Peyrard. Em procedures [3] M. de Leoni, F. Maggi, and W. van der Aalst.
 [4] D. Fahland and W. M. van der Aalst. Repairing [5] S. A. Hunt, W. T. Abraham, M. H. Chin, A. M.
 [6] D. Koller and N. Friedman. Probabilistic Graphical [7] S. Z. Li. Markov Random Field Modeling in Image [8] X. Li, H. Liu, S. Zhang, J. Mei, G. Xie, Y. Yu, J. Li, [9] Z. Lu and H. H. S. Ip. Constrained spectral clustering [10] S. Osindero and G. Hinton. Modeling image patches [1 1] L. Rabiner. A tutorial on hidden markov models and [12] W. van der Aalst. Process mining: Overview and [13] W. van der Aalst, A. Adriansyah, and B. van Dongen. [14] K. Vanhaecht, K. De Witte, and W. Sermeus. The [15] L. Zelnik-Manor and P. Perona. Self-tuning spectral [16] J. Zhu, Z. Nie, B. Zhang, and J.-R. Wen. Dynamic
