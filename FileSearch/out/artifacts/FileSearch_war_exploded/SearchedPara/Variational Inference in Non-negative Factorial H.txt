 Gautham J. Mysore gmysore@adobe.com Maneesh Sahani maneesh@gatsby.ucl.ac.uk Spectrograms reveal a great deal of acoustic structure and are therefore often the representation of choice for modeling sounds. A spectrogram is the magnitude of the short-time Fourier transform (STFT) of a signal and is therefore a non-negative matrix. This has led to the popularity of using non-negative matrix factor-ization (NMF) (Lee &amp; Seung, 2001) to model audio (Smaragdis &amp; Brown, 2003).
 Conceptually, NMF models each time frame (column) of an audio spectrogram as a linear combination of non-negative dictionary elements. Given the spectro-gram of a sound source, we can use NMF to learn a dictionary (Figure 1) that serves as a model for the range of different short-term spectra generated by that source. While potentially a powerful spectral model, NMF provides no generative account of the temporal dynamics linking these short-term spectra, nor of any spectral non-stationaries: two essential ingredients of real audio signals.
 A recent proposal, the non-negative hidden Markov model (N-HMM) (Mysore et al., 2010), deals with this failing of NMF by modeling a sound source with mul-tiple dictionaries (Figure 2) such that each time frame of the spectrogram is modeled by a linear combination of the elements of any one of its many dictionaries, essentially allowing different sub-models for spectra at different time frames. Moreover, transitions between these component dictionaries from one time frame to the next are governed by a Markov chain, thus captur-ing the temporal dynamics of the source. The model is described more completely in Section 2.1. NMF and its probabilistic counterparts have been used extensively for audio source separation (Virtanen, 2007; Smaragdis et al., 2007). The basic idea is to first learn a dictionary for each source from isolated train-ing data. The mixture is then modeled by a dictionary formed from the concatenation the dictionaries of the two 1 sources (Figure 3). The goal is then to estimate mixture weights over all dictionary elements at each time frame. Using these mixture weights, we can re-construct the contribution of each source at each time frame, obtaining the separated spectrogram of each source. The phase of the original mixture STFT is typically then used to obtain time-domain audio sig-nals from these separated spectrograms.
 The N-HMM has been extended to the non-negative factorial hidden Markov model (N-FHMM) to model sound mixtures and has been used for source separa-tion (Mysore et al., 2010). Each time frame of the spectrogram is modeled by one of the combinatorially many concatenations of dictionaries of the two sources as illustrated in Figure 4. When used for source sep-aration, the goal is to estimate the posterior proba-bilities of using each pair of dictionaries at each time frame as well as the mixture weights for each of these dictionary pairs. Using these estimates, we can recon-struct the separated spectrograms and perform source separation in the same way as described above. The N-FHMM has been shown to achieve much better source separation accuracy than simple NMF (Mysore et al., 2010). However, the combinatorial nature of the N-FHMM makes the complexity of exact inference exponential in the number of sound sources, which is often intractable. Specifically, if each source has N states and there are S sources, then we must evaluate the posterior probabilities of N S state configurations per time frame.
 It would therefore be useful to be able to use an approximate inference technique for the N-FHMM. Structured variational inference (Ghahramani &amp; Jor-dan, 1997) is an attractive approach for factorial hid-den Markov models (FHMM) in general. However, the natural extension of this idea to the N-FHMM has cer-tain limitations, which make it a poor approximation (Section 3.1). In this paper, we propose a Bayesian variant of the N-FHMM (Section 2.2) that makes it more amenable to variational inference, and then de-velop a suitable factored approximation to the poste-rior distribution deriving the corresponding variational inference algorithm (Section 3.2).
 Experiments (Section 5) show that our algorithm achieves accuracy comparable to that of exact infer-ence, but is about 30 times faster on the configurations of the N-FHMM that achieve the the highest-quality source separation results. In this section, we first describe the probabilistic model of the N-HMM (Mysore et al., 2010) for single sources as it forms the foundation for the N-FHMM. We then describe the probabilistic model of the proposed Bayesian variant of the N-FHMM. In these models, each time frame of the spectrogram is viewed as a his-togram of  X  X ound quanta X  in the same way that a docu-ment is viewed as a histogram of words in topic models (Hofmann, 1999; Blei et al., 2003). 2.1. Non-negative Hidden Markov Model The graphical model is shown in Figure 5. The random variables D 1 ...T form a Markov chain, and the spectra in each time frame are independent given these vari-ables. Each possible value of D t identifies a spectral dictionary. Each dictionary contains a set of dictionary elements (analogous to topics), one of which is selected for each sound quantum by the random variable Z t . Each dictionary element is a normalized vector over frequencies (analogous to a distribution of words). The frequency associated with a particular quantum is se-lected by F t .
 The generative process at time frame t is thus: 1. Choose state D t | D t  X  1  X  Discr [  X  ( D t  X  1 )] 2. Repeat for each of v t quanta: Here, Discr [] represents the discrete distribution;  X  ( d ) is the column of the Markov transition matrix repre-senting transitions from state d ;  X  t ( d ) is a vector of normalized mixture weights for dictionary element d in time frame t ; and  X  ( d,z ) is the normalized dictio-nary element z of dictionary d . Given the spectrogram of a sound source, maximum X  X ikelihood (ML) values of all these parameters may be found by the EM al-gorithm. The dictionaries and the transition matrix define the model of the sound source, whereas the mix-ture weights (which depend on t ) are nuisance param-eters unique to the particular instance of the sound source used for training. A sample of the dictionaries learned from real speech data is shown in Figure 6. 2.2. Non-negative Factorial Hidden Markov The original N-FHMM introduced an independent Markov chain D ( s ) 1 ...T for each source s , and time-dependent mixing weights that selected elements from a combined state-dependent dictionary  X  t ( d (1) ,d (2) ) . Here, we extend this model in two ways. First,  X  t and Z t will range over all dictionary elements of all sources. Thus the selection of a dictionary based on the state D t becomes probabilistic, and elements from more than one dictionary may appear in principle. Second, we treat  X  t as a Dirichlet-distributed latent variable, rather than as a parameter. Separating the mixture requires estimation of  X  t : the older N-FHMM formu-lation used ML estimates; here we use a variational posterior.
 The generative process (Figure 7) at time frame t is thus: 1. Choose states for each source: 2. Choose mixture weights: 3. Repeat for each of v t quanta: The function  X  gives the Dirichlet parameters for the mixing weights, and thus specifies the dictionary el-ements available given each pair of source Markov states. It can most easily be written by introducing indicator variables  X  ( s ) t,n = 1 if D ( s ) t = n and 0 other-wise; as well as a binary mask array B , with B snk = 1 iff dictionary element k is available when the Markov chain associated with source s is in state n . Then the k th generative Dirichlet parameter for  X  t can be vided the two sources do not share dictionary elements, the sum in this expression evaluates to either 0 or 1. Thus the distribution on  X  t has parameters of 1 +  X  corresponding to the elements selected by the current Markov states, and 1 otherwise. The hyperparame-ter  X  sets the concentration of the Dirichlet; we took  X  = 1 . Thus, we can write the distribution on mixing weights: This formulation does not make exact inference any easier because the number of such distributions that we have to consider is still exponential in the number of sources. However, we will see in Section 3.2 that this is important for our variational inference derivation. The remaining parameters are much as before:  X  ( z ) is the z th normalized dictionary element;  X  (1) and  X  (2) are the transition matrices of the two sources. We also need parameters for the initial state probabilities, for which we write  X  (1) and  X  (2) . The number of quanta at each time frame v t could be modeled as a draw from (say) a Poisson distribution. However, it is inde-pendent of the other generative variables and (in our applications) is observed, so we do not model it as a random variable.
 Without the temporal dynamics, our formulation is similar to that of latent Dirichlet allocation LDA (Blei et al., 2003). The main difference is that the Dirichlet distribution in a given time frame is a function of the Markov states of the sources rather than being con-stant for all time frames. The parameters describing each source N-HMM are learned from isolated training data of that source. Thus, the goal of inference in the N-FHMM is only to resolve the mixture; specifically, to estimate the marginalized posterior distribution of the mixture weights P (  X  t | f ) at each time frame. Once this distribu-tion is found, we can reconstruct the individual sources and therefore perform source separation. The full posterior distribution is given by P ( Z ,  X , D (1) , D (2) | f ) where  X  , D (1) , and D (2) represent  X  t , D (1) t , and D at all time frames and Z represents all draws of Z t at all time frames. f represents the observed values of F t at all time frames. The computational cost of finding the posterior distribution is exponential in the num-ber of sources due to the coupling of the states of the individual N-HMMs. Exact inference in N-FHMMs is therefore intractable so we resort to approximation. Variational inference (Jordan et al., 1999) refers to a class of techniques that are used to approximate an intractable posterior distribution with a simpler (typically factorized) distribution. By minimizing the KL divergence between the two distributions, a lower bound on the log-likelihood is maximized. This is the class of approximations that we employ.
 A natural variational approximation to the N-FHMM would be to decouple from each other the sets latent variables that correspond to each component N-HMM, but to retain the structured posterior over each sepa-rate source. This scheme is analogous to the structured variational approximation for FHMMs (Ghahramani &amp; Jordan, 1997). Unfortunately, however, it performs poorly for the N-FHMM of (Mysore et al., 2010). We first briefly sketch the approach and explain why it seems to fail, before moving to the new variant of the N-FHMM to derive a more successful variational in-ference algorithm. 3.1. Difficulties with Decoupling Decoupling the variational posteriors for each sound source requires that it be possible to group latent vari-ables according to the generative source. This is easy for D ( s ) . However, the latent variables Z identify ele-ments from a combined dictionary over both sources. Thus, to proceed we introduce a new latent variable S t to indicate the proportions of quanta drawn from each source at time t , and then separately generate Z (1) and Z (2) , each ranging over the dictionary of a sin-gle source. In this parameterization, the posterior is mated by the decoupled variational distribution: In this form, the two components q ( Z (1) , D (1) ) and q ( Z (2) , D (2) ) do indeed correspond to structured pos-teriors within the two N-HMMs describing the sound sources, while the factor q ( S t ) corresponds to the mix-ing proportions of the two sources at time frame t . The variational iterations then update each individual N-HMM posterior using the forward X  X ackward algorithm (Rabiner, 1989) while keeping the contribution of the other N-HMM fixed; and then revise the mixing pro-portions of the sources. While certainly plausible, this algorithm proves to be very prone to sticking in local optima and in experiments performs more poorly than even basic NMF (implemented in a probabilistic form, see Section 5). Here we provide an intuitive sketch of what we see as the source of the difficulty. In many applications, the sound sources to be sep-arated may have some spectrally similar aspects, so that some or all of the dictionary elements in their in-dividual N-HMMs may have similar forms. This is the case when the sound sources are, for example, speech from different speakers. In such a situation, the dictio-nary elements of one source may be able to provide a reasonable fit to sounds generated by the other source. Consider an example of a single time frame in a speech mixture in which the first source contributed a har-monic spectrum (say a vowel) while the second source produced a noise-like spectrum as might be associated with a fricative. Both source models are likely to con-tain spectral dictionary elements to account for both vowels and fricatives, although these elements might belong to different dictionaries within each source model. Thus, if at an early stage the harmonic struc-ture is incorrectly assigned to source 2 and the noise-like component to source 1, the inferred Markov states for the two components will be incorrect. We find that it is then very unlikely that further iterations will re-solve the error, indeed they seem to make it worse. As the incorrect assignments reinforce each other in the two models, the posterior over Markov states becomes very sharp. Thus, the two sources are confused. This reflects a local optimum: it could very well be that the variational free energy would be larger for the correct assignment, but the hill-climbing form of the iterative algorithm makes it unable to discover that fact. In experiments, we found that this situation appeared with some frequency, despite the fact that the tempo-ral structure of the underlying Markov process biased solutions away from such confusions to an extent. 3.2. Proposed Variational Approximation In the proposed variant of the N-FHMM, the link be-tween Markov state and dictionary element is less ab-solute. Also, we estimate a full posterior over the mix-ing proportions  X  t over all dictionary elements, rather than obtaining an ML point estimate X  X his reduces the risk of zeros (or very small values) in the point esti-mate, which would have created a similar barrier to exploration. Thus both sources are able to explore the full range of possible dictionary elements and settle on the correct apportionment of the mixture spectrum, while the interaction between Markov state variables and prior on  X  t strongly favors explanations that con-centrate on a single dictionary per source.
 To develop the variational algorithm for this model, we approximate the posterior distribution P ( Z ,  X , D (1) , D (2) | f ) with the following factored form: Note that for a given time frame, the index k for  X  t is over all dictionary elements of all dictionaries of all sources. The mixture weights for a given time frame t are therefore in a single factor q (  X  t ) . Moreover, this factor is independent of D (1) t and D (2) t so we do not have the combinatorial problem.
 However, the distribution over the states of all time frames of a given sound source q ( D (1) ) and q ( D (2) ) are each a single factor. This is because we would still like to make use of the structure of the temporal dynamics in each individual source and exact inference is efficient using the forward X  X ackward algorithm. By minimizing the KL divergence between the true posterior distribution and the factorized distribution, we obtain the following variational inference solution (Jordan et al., 1999) for each of the factors: where q 1 refers to the product of all of the factors ex-cept q (  X  t ) (and similarly for the other factors). We use proportionality rather than equality to simply in-dicate that the quantities are unnormalized. Solving these equations, we find that q (  X  t ) is a Dirichlet dis-tribution, which we parameterize by q ( D (2) ) are each a set of discrete distributions, with The distribution q ( Z t,v ) is also discrete, and at any time frame the parameters for all Z t,v whose corre-sponding observed frequencies f t,v are equal, will be identical. Thus, we write these parameters as where l indexes frequency (in place of v ), and k iden-tifies a dictionary element.
 On simplification of Eq.2, we obtain following update equation for the parameters of q (  X  t ) : Note that as b d ( s ) t,n are defined to be marginal probabil-ities, they are exactly the expected values under q of  X  t,n . The index f t,v is the observed frequency of quan-tum v at time t . We can group all quanta for which f t,v is equal, to obtain: where V lt is the value of the spectrogram (i.e., the number of quanta) at frequency l and time frame t . On simplification of Eq.3, we obtain estimates of the parameters of q ( Z t,v ) : log where  X  () is the digamma function;  X  is a log normal-izer; and  X  l ( k ) is the value of dictionary element k at frequency l . The digamma terms arise from the nor-malizing  X  -functions of the Dirichlet distribution (Blei et al., 2003).
 On simplification of Eq.4 and 5, we first obtain surro-gate  X  X ikelihood X  terms, which we subsequently use in the forward X  X ackward algorithm to obtain the distri-bution parameters. This likelihood term at time frame t for state n of source s is given by: The forward X  X ackward algorithm then finds estimates of the marginals b d ( s ) t,n of q ( D ( s ) ) . We iterate over Eqs.6,7,8, and the forward X  X ackward algorithm for each source. The resulting solution pro-vides estimates of the parameters bution q (  X  t ) , indicating the distribution of mixture weights. We reconstruct the spectrograms of the individual sources by taking linear combinations of the dictionary elements of all dictionaries of each individual source according to the estimated mixture weights each time frame. This gives us estimates of the sepa-rated spectrograms of each source b V ( s ) lt . We can simply go back to the time domain with these estimates using the phase of the original mixture. However, a common source separation practice to first obtain more refined spectrogram estimates by applying the following mask-ing strategy: where V lt is the original mixture spectrogram. The final estimated spectrogram for each source is therefore V lt . We employ this strategy in our experiments. To validate our proposed variational inference algo-rithm, we performed source separation experiments on speech mixtures and compared our results to those of exact inference within the N-FHMM of (Mysore et al., 2010). As the proposed algorithm has much lower com-putational complexity, our goal was to try to achieve source separation performance that came close to that of exact inference. Additionally, we compared to the performance of the decoupled variational approxima-tion (Section 3.1), and to the performance of proba-bilistic latent component analysis (PLCA) (Smaragdis et al., 2007), this being the baseline comparison used in (Mysore et al., 2010). PLCA is a probabilistic audio interpretation of NMF (up to a column-wise normal-ization). It therefore serves as an baseline equivalent to NMF.
 We performed experiments with 50 different speech mixtures and report the mean of the results. Data were taken from TIMIT, a commonly used corpus for speech processing and speech recognition tasks. It comprises numerous sentences from multiple speakers.
 We performed each of the 50 experiments as follows. We first randomly chose one male and one female speaker. For each speaker, we assigned nine sentences as training data and one sentence as test data. We then concatenated the training data sentences and ob-tained a spectrogram with a window size of 64ms and a hop size of 16ms (the sampling rate was 16KHz). Next, we learned an N-HMM (with an ergodic Markov chain) from the training data of each speaker, yield-ing a set of dictionaries and a transition matrix for each speaker. The next step was to mix the two test sentences (one from each speaker) at 0dB and obtain the spectrogram using the above window size and hop size. We then combined the dictionaries and transition matrices of the two speakers into either a joint PLCA or an N-FHMM model, performed inference using the various methods, and separated the sources.
 We used the standard BSS-EVAL suite of metrics (Vincent et al., 2006) to evaluate the source separa-tion performance. This suite consists of three signal to noise ratio (SNR) type metrics (in dB). Source to Interference Ratio (SIR) evaluates the suppression of the unwanted source. Source to Artifacts Ratio (SAR) evaluates the amount of artifacts introduced by the separation process (with larger numbers reflecting less artifacts). Source to Distortion Ratio (SDR) gives us an overall source separation score that takes both the suppression capability as well as the introduced arti-facts into account. We computed these metrics on each of our 100 sources separated from 50 mixtures. In order to find the optimal configuration of our model (the number of dictionaries and number of elements per dictionary), we repeated these experiments in 30 Proposed Variational Opt. 7.63 12.00 10.24 different configurations. The BSS-EVAL metrics for all of these configurations are shown in Figure 8. The optimal configuration (in terms of SDR) was 20 dictio-naries with 20 elements each. It is evident, however, that the different configurations yield similar perfor-mance scores, except for a noticeable drop when using only 1 element per dictionary. This is encouraging as it implies that the algorithm is not particularly sensitive to the specific configuration for this kind of data. To make comparison to exact inference unbiased, we also searched for the optimal configuration in that case. Here, 20 dictionaries with 30 elements each yielded the best source separation performance (data not shown), although, as with the proposed variational inference algorithm, the metrics did not vary substan-tially with different configurations. Table 1 shows the results obtained with this configuration as well as the results of the proposed method and decoupled varia-tional inference when using the same configuration. As a baseline, we also experimented with PLCA with various dictionary sizes, and found that 30 dictionary elements yielded the optimal source separation per-formance. The results of using this configuration of PLCA are are also shown in Table 1.
 We see that our algorithm performs almost as well as exact inference even when using the same configura-tion (Table 1). The difference in SDR is less than 0.2 dB. There is however a large difference in computa-tion time. Based on the configuration of each source having 20 dictionaries of 30 elements each, we empir-ically found each iteration of the proposed method to be about 30 times faster than using exact inference. However, when using the optimal configuration for the proposed method (20 dictionaries of 20 elements each), we observed about a 40x speedup. The pro-posed method generally took about twenty iterations to converge (Figure 9), which is a similar number to that seen with exact inference.
 The SIR of the proposed method is lower than that of exact inference but the SAR is higher. This can be understood as follows. Exact inference returns a higher SIR because it is more constrained. Only one dictionary from each source may be active in each time frame. This restriction is relaxed in the pro-posed method, allowing some interference from ele-ments of the other dictionaries. This very property gives the proposed method a higher SAR. In order to reduce artifacts, it can be helpful to recruit some con-tribution from dictionary elements that correspond to non-active Markov states. This can help explain nu-ances in the spectral time frame that the active dic-tionary might not capture completely. This is possible in the proposed method, but not in the rigid exact N-FHMM model. The proposed method and exact in-ference therefore have a fairly even SIR/SAR trade off leading to approximately the same SDR scores. As shown in Table 1, the proposed method outper-forms PLCA in all three metrics and the decoupled variational approximation performs very poorly with a lower SDR and SIR than even PLCA. We have proposed a Bayesian variant of the N-FHMM and an efficient variational inference algorithm for the model. The computational complexity of the algo-rithm is linear in the number of sources, and it is about 30 times faster than exact inference on an empirically optimal configuration of the N-FHMM, with compara-ble source separation accuracy. Although variational inference in the N-FHMM was demonstrated on the task of source separation, it is a general model of sound mixtures and can be used for various other audio tasks such as concurrent speech recognition of multiple speakers and automatic music transcription.
 Blei, D., Ng, A., and Jordan, M. Latent dirichlet al-location. Journal of Machine Learning Research , 3: 993 X 1022, January 2003.
 Ghahramani, Z. and Jordan, M. Factorial hidden
Markov models. Machine Learning , 29:245 X 273, 1997.
 Hofmann, T. Probabilistic latent semantic indexing.
In Proceedings of the 22nd International Conference on Research and Development in Information Re-trieval , Berkeley, USA, August 1999.
 Jordan, M., Ghahramani, Z., Jaakkola, T. S., and
Saul, L. K. An introduction to variational meth-ods for graphical models. Machine Learning , 37: 183 X 233, 1999.
 Lee, D. D. and Seung, H. S. Algorithms for non-negative matrix factorization. In Advances in Neu-ral Information Processing Systems , volume 13, pp. 556 X 562, 2001.
 Mysore, G. J., Smaragdis, P., and Raj, B. Non-negative hidden markov modeling of audio with ap-plication to source separation. In Proceedings of the
International Conference on Latent Variable Analy-sis and Signal Separation , St. Malo, France, Septem-ber 2010.
 Rabiner, L. R. A tutorial on hidden Markov mod-els and selected applications in speech recognition. Proceedings of the IEEE , 77(2):257 X 286, 1989. Smaragdis, P. and Brown, J. C. Non-negative matrix factorization for polyphonic music transcription. In
Proceedings of the IEEE Workshop of Applications of Signal Processing to Audio and Acoustics , New Paltz, New York, October 2003.
 Smaragdis, P., Raj, B., and Shashanka, M. Super-vised and semi-supervised separation of sounds from single-channel mixtures. In Proceedings of the sev-enth International Conference on Independent Com-ponent Analysis and Signal Separation , London, UK, September 2007.
 Vincent, E., Fevotte, C., and Gribonval, R. Perfor-mance measurement in blind audio source separa-tion. IEEE Transactions on Audio, Speech, and Language Processing , 14(4):1462 X 1469, 2006. Virtanen, T. Monaural sound source separation by nonnegative matrix factorization with temporal con-tinuity and sparseness criteria. IEEE Transactions on Audio, Speech, and Language Processing , 15(3):
