 Azarakhsh Malekian  X  Erik Vee  X  Motivated by applications in guaranteed delivery in computational advertising, we consider the general problem of balanced alloca-tion in a bipartite supply-demand setting. Our formulation captures the notion of deviation from being balanced by a convex penalty function. While this formulation admits a convex programming so-lution, we strive for more robust and scalable algorithms.
For the case of  X  1 penalty functions we obtain a simple combina-torial algorithm based on min-cost flow in graphs and show how to precompute a linear amount of information such that the allocation along any edge can be approximated in constant time. We then ex-tend our combinatorial solution to any convex function by solving a convex cost flow. These scalable methods may have applications in other contexts stipulating balanced allocation.

We study the performance of our algorithms on large real-world graphs and show that they are efficient, scalable, and robust in prac-tice.
 Categories and Subject Descriptors. H.2.8 [ Database Manage-ment ]: Database Applications X  Data Mining General Terms. Algorithms, Experimentation, Theory Keywords. Balanced allocation, maximum flow, convex flow
In the guaranteed delivery setting, advertisers and users are me-diated by the publisher (e.g., a search engine, an online newspaper). The advertiser buys a contract for a certain number of impressions (user visits to the publisher X  X  page) and declares interest in a sub-set of user population called buckets. The goal of the publisher is to satisfy the demands by placing an ad from the advertiser on the web page visited by a user, if the user (i.e., the impression) belongs to the advertiser X  X  bucket.
 Motivation. Consider the following setting in the context of com-putational advertising and search engines. Each search engine user has three attributes (gender, age, location) and there are four ad-vertisers who have bought contracts to target various user subsets; Part of this work was done while the authors were visiting Yahoo! Research.
 each advertiser specifies its bucket of interest by specifying appro-priate user attributes. Advertiser  X   X  X  bucket is young females (gen-der=female, age=young),  X   X  X  bucket is males (gender=male),  X   X  X  bucket is senior Floridans (age=old, location=FL), and  X   X  X  bucket is all Californians (location=CA). If the search engine only needs to satisfy the contract X  X  requirement, assigning a sufficient number of users to an advertiser as long as they belong to the advertiser X  X  bucket is an apparent feasible solution.

Unfortunately, such an assignment can be unfair and unreward-ing to the advertiser for the following two main reasons. (1) While each advertiser X  X  bucket has some of the user attributes specified explicitly, the unspecified attributes are subject to inter-pretation. Most often, the advertiser is equally interested in all the users who belong to the bucket. For instance, it will be undesirable if  X  were a sports car dealer and the search engine assigns mostly middle-aged men to  X  . Likewise, it is undesirable if a dispropor-tionate number of old women from Florida were assigned to  X  , who happens to be Florida real-estate agent. Thus, there is a tacit assumption by each advertiser that the users assigned to it are as  X  X alanced and fair X  as possible from the set of available users. (2) There can be a large number of attributes and each at differ-ent levels of granularity (location=city, state, country, etc.) that it might never be fully possible for any advertiser to specify the de-sired buckets to the finest conceivable detail. For instance,  X  could be a toy store who failed to specify an explicit age group; like-wise,  X  could be an earthquake insurance agent primarily targeting young homeowners near the fault line. In either case, it is more de-sirable for the search engine to assign a balanced set of users rather than blame the advertiser for under-specifying their bucket.
In this paper we address this problem. Given a set of impres-sions (i.e., the supply) and contracts (with demands and buckets), how to find a feasible assignment of impressions to contracts that is as balanced as possible? Answering this question involves formu-lating what being balanced precisely means in this context. And, given the large number of advertisers (typically, in the hundreds of thousands) and the astronomical number of impressions (typically, in the hundreds of millions) in an online setting, we insist on an al-gorithm that is efficient , in both time and space, that is scalable, and that yields insights into the structure of the allocation problem it-self. In particular, we desire an efficient allocation algorithm whose allocation can be stored succinctly , ideally, using space linear in the number of impressions and contracts as opposed to the naive stor-age that is linear in the number of impression X  X ontract pairs, which can be quadratic. This succinct representation should let us recon-struct the allocation along every pair of contract and impression in a time-efficient manner. Thus, we trade space for time.
 Our contributions. We consider the general problem of balanced allocation in a bipartite supply-demand setting. Our formulation, inspired by [14], is combinatorial and captures the notion of devia-tion from being balanced by a natural and general form of a penalty function. While this formulation admits a convex programming so-lution (assuming the penalty function is convex), it is undesirable in practice because of efficiency considerations and therefore we seek more robust and scalable solutions.

For the case of  X  1 penalty functions we obtain a simple combina-torial algorithm for the balanced allocation problem. Our solution is based on solving a min-cost flow problem on bipartite graphs, which can be done very efficiently. By using a powerful dual for-mulation stemming from our combinatorial treatment of allocation and constraining the flow to be unique in a certain way, we also show how to precompute and store a linear amount of information such that the allocation along any edge in the bipartite graph can be approximately answered in constant time, under mild assumptions on the input instances. This space-efficient reconstruction method might be of independent interest in contexts beyond balanced allo-cation.

We also prove two additional properties of our formulation. First is robustness, where we show how to upper bound the performance loss when the supply estimates are only approximately known. Sec-ond is extensibility, where we show an even simpler greedy approx-imate algorithm when some of the demand constraints are allowed to be violated.

We perform an experimental evaluation of our algorithm on a large real-world dataset obtained from the Yahoo! X  X  display adver-tising system. Our experiments demonstrate the efficiency and the scalability of our min-cost based algorithm. In particular, our com-binatorial solution, as opposed to a black-box linear/convex pro-gramming solution, makes it feasible to solve large instances ef-fortlessly. Furthermore, our experiments also illustrate the space savings enabled by the reconstruction procedure.

Finally, we extend our combinatorial solution to any convex func-tion. This involves solving a convex cost flow, which once again is more efficient than solve a general convex program.
 Related work. The related work falls into three classes. The first is work on online allocation problems. The second is the ever-increasing body of literature in the area of computational advertis-ing. The third is network flow problems and the role of primal-dual methods in computational advertising.

Vee, Vassilvitskii, and Shanmugasundaram first studied the on-line allocation with forecast problem, where given an approxima-tion of the online supply, the goal is to create an efficiently recon-structible plan for performing some form of balanced allocation [15]. They focus on the efficiency and sampling aspect of the prob-lem and consider only the strictly convex version, which makes it amenable to using fixed point criteria such as KKT conditions for non-linear optimization. Ghosh et al. [10] studied the problem of representative allocation for display advertising when there are both spot markets and guaranteed contracts; they propose a solu-tion where guaranteed contracts are implemented by randomized bidding in spot markets. Devanur et al. [6] presented a sampling based method that computes a near-optimal allocation for online keyword matching with budget constrained advertisers and random permutation model. Their approach also computes a compact plan consisting of the dual variables of an LP which can later be used to efficiently compute the primal allocation online. None of these methods is combinatorial like ours and hence are more likely to be less scalable.

Online advertising is one of the most profitable resources for the large search engine companies and publishing sites such as cnn.com , nytimes.com . Two popular methods used for online advertising are slot ad auction and display advertisement. Most of the recent literature for online advertisement are focused on study-ing slot ad auction from the game-theoretic perspective [8]. There have been some recent work on display advertisement and guaran-teed delivery. In [9], Feige et al. studied the guaranteed delivery for display advertisement with penalties. In the guaranteed deliv-ery model, advertisers act as contractors. Each advertiser requests some number of impressions. If this request is accepted by the search engine, it would be called a contract. In this model, for each accepted contract, either the whole demand requested in the con-tract should be satisfied or the search engine will pay extra penal-ties for the non-satisfied portion of the demand. They showed that there is no constant approximation for their problem and present a bicriteria algorithm. Also they proved a structural approximation result for the adaptive greedy algorithm. The problem of advanced booking with costly cancellation also have been studied in [5] and [3] from a game-theoretic point of view.

Our solution is mainly based on the network flow problem and its dual. There is a large amount of literature on the network flow problem (e.g., [2]). The closest work to our method is the push-relabel algorithm of Goldberg and Tarjan [12]; they introduced a method for computing the maximum flow problem without using augmenting paths. The reconstruction of the min-cost flow instance is based on the dual variables of the min-cost flow solution. Primal-dual methods have been largely used as a tool to find approximation algorithms for various problems (e.g., [4, 1]). Recently, Devanur et al. [7] and Jain and Vazirani [13] used primal-dual methods and KKT conditions for solving market equilibria problems.
Suppose we are given a set  X  of impressions and a set  X  of con-tracts . Each impression  X   X   X  has a supply  X   X  &gt; 0 . Each contract  X   X   X  has (i) a weight  X   X  &gt; 0 that captures its importance, (ii) a desired bucket imp(  X  )  X   X  of impressions, and (iii) a demand  X   X  &gt; 0 , denoting the number of impressions that need to be allo-cated to this contract. For an impression  X  , let con(  X  )  X   X  denote the set of contracts that desire  X  .

As stated earlier, the goal is to find the most balanced allocation of impressions to contracts. Let  X   X   X  be the number of impressions  X  that are assigned to contract  X  in a given allocation. Let be quantity that captures the ideal balanced allocation of impression  X  to contract  X  , i.e. a perfectly balanced number of impressions from impression  X  are assigned to contract  X  . Let  X   X  =  X  The goal is to minimize where  X (  X  ,  X  ) is the penalty function that penalizes deviation from the ideal balanced allocation, subject to the supply and demand constraints. Different norm/distance functions can be used for  X (  X  ,  X  ) ; for example,  X  =  X  1 ,  X  =  X  2 ,  X  = KL , and so on [14]. If  X (  X  ,  X  ) is not restricted to be convex, then the problem becomes NP-hard to even approximate to within a constant factor (proof omitted). We define the notion of  X  -robust input.

D EFINITION 1 (  X  -ROBUST INPUT ). An input instance to our problem is  X  -robust if there is a feasible assignment of impressions to contracts when we scale up all the demands by a factor of 1 +  X  .
Henceforth, we will assume that our input instances are  X  -robust for a suitable  X  ; this is a mild technical assumption that typically holds in practice. Also, a superscript  X  will always denote a contract and a subscript  X  will always denote an impression.
The balanced allocation problem with the  X  1 penalty function can be formulated as a linear programming (LP) problem. Our main result is that we can solve this LP by instead solving a min-cost flow problem, i.e., there is a combinatorial solution to the bal-anced allocation problem with  X  1 penalty. In Section 4, we show that by preprocessing the network flow solution, we can find a suc-cinct representation that only stores  X  (  X   X   X  +  X   X   X  ) values and can re-construct the asymptotically optimal solution in  X  (1) time. Later in Section 5, we obtain an approximate solution (along with effi-cient reconstruction) when the demand constraints are  X  X oft. X 
We first consider an LP formulation of the problem: subject to To simplify the description, for a given allocation  X  , we define unfair (  X  ) = P  X   X   X  P  X   X   X   X   X   X   X   X   X   X  . The flow network, with capac-ity cap(  X , X  ) and cost cost(  X , X  ) on each edge (  X , X  ) , is constructed as a four layer graph  X  (Figure 1). Figure 1: The network construction with (capacity, cost) on the edges for  X  1 .

Note that minimizing absolute value can be converted to two lin-ear inequalities without loss of generality. The first and the last layers are the source  X  and sink  X  respectively. The second layer represents the set  X  of contracts, and the third layer stands for the set  X  of impressions. Source  X  has an edge (  X , X  ) to each contract  X   X   X  in the second layer, with cap(  X , X  ) =  X   X  and cost(  X , X  ) = 0 . Contract  X   X   X  in the second layer is connected to the impression  X   X   X  in the third layer iff  X   X  imp(  X  ) . In this case, there are two edges  X  a top edge and a bottom edge  X  between  X  and  X  . The top edge has capacity  X   X   X   X   X   X  and cost 2  X   X  and the bottom edge has capacity  X   X   X  and cost zero. Finally each impression  X   X   X  in the third layer is connected to the sink  X  by an edge (  X , X  ) with cap(  X , X  ) =  X   X  and cost(  X , X  ) = 0 . Let  X  denote the set of edges between the second and the third layers in Figure 1.
 T HEOREM 2. The min-cost  X  - X  flow on  X  is the solution to (1).
P ROOF . We need to show the following: (i) a maximum  X  - X  flow in  X  is a feasible solution to (1), provided (1) has a feasible solu-tion; (ii) any feasible solution to (1) is a feasible  X  - X  flow in  X  ; and (iii) minimizing the cost of the maximum  X  - X  flow in  X  is equiva-lent to minimizing the objective in (1). It is easy to see that if (1) has a feasible solution, then a maximum  X  - X  flow in  X  is a feasi-ble solution. Since we look for the maximum flow, if there is any feasible solution to the LP that can satisfy all the demands and the supply constraint, then that solution would be selected as the max-imum flow as well. This means if (1) has a feasible solution, then any feasible maximum flow in our network is a feasible solution to (1). Second, it is easy to see that any feasible solution to (1) is also a feasible  X  - X  flow in  X  . And last, we argue that the cost of the optimal solution to (1) is the same as the minimum cost of the maximum flow in  X  . In other words, we need to show that the costs of the flow are computed correctly in  X  . Note that the total contribution to the cost of the pairs of impressions and contracts is enough to compute twice this cost. Now consider an impression  X  and a contract  X  . If  X   X   X  &gt;  X   X   X  , then we can route at most  X  through the edge with cost 0 and route  X   X   X   X   X   X   X  through the edge with cost 2  X   X  , which is equal to 2  X   X  (  X   X   X   X   X   X   X  twice the cost of this pair.

So we showed that our min-cost flow solution has exactly the same value as (1). Next, we show that in fact, we can preprocess the min-cost flow solution so that by keeping track of just  X  (  X   X   X  +  X   X   X  ) values, we can reconstruct the complete flow.
Even though the min-cost flow formulation obtains the optimal solution, as we mentioned earlier, it is not feasible to store the entire allocation information. Naively storing the solution representation is expensive since it uses  X  (  X   X   X  ) space. (As we will see in Sec-tion 6, supply X  X emand bipartite graphs that occur in practice tend to have high average degree, i.e.,  X   X   X  is much larger compared to  X   X   X  +  X   X   X  .) Ideally, we wish to store just  X  (  X   X   X  +  X   X   X  ) informa-tion (i.e., amortized  X  (1) per node) that will let us reconstruct the flow along every edge; for practical reasons, we also require such a reconstruction to be time-efficient.

We consider the  X  1 formulation and show an approximate re-construction via dual variables for the nodes. First, we write the LP corresponding to the min-cost flow; from Theorem 2, this LP is equivalent to (1).
Here,  X   X   X  denotes the flow along the top edge and  X   X   X  flow along the bottom edge from  X  to  X  . The dual of the above LP looks as follows.
Here,  X  denotes the allocation, where  X   X   X  is the allocation amount from impression  X  to contract  X  . Since we want to maximize the dual function and the coefficient of each  X   X   X  in the objective func-tion is negative, we would like to set the  X   X   X   X  X  as small as possible. From the constraints in the dual, this means  X   X   X  = max(0 , X  and hence we do not need to keep track of  X   X   X   X  X . Next, we show how to reconstruct  X   X   X   X  X  by only keeping  X   X   X  X  and  X   X  show that in fact it is enough just to keep track of the  X 
Since we are considering an optimal solution, because of the complementary slackness, we have three cases for each edge be-tween  X  and  X  . First we consider the bottom edges. (i)  X   X   X   X   X  &lt; 0 : in this case, we have  X   X   X  = 0 . (ii)  X   X   X   X   X  &gt; 0 : in this case,  X   X   X  is fully saturated. (iii)  X   X   X   X   X  = 0 : in this case, we have  X   X  =  X   X  . This is the only case that we have an edge between (  X , X  ) , with the only constraint being the edge capacity constraint.

We have the same scenario for the top edges as well. In the third case, the dual variables do not give us any information on the value of the primal. We call the edges belonging to the third class slack edges . Next, we argue that any feasible assignment of flow to slack edges would be a solution. To see this, first notice that the cost of any slack edge (  X , X  ) is exactly to  X   X   X   X   X  any path from  X  to  X  consisting of only slack edges have the same cost. Also, any cycle consisting of slack edges has a cost of 0 . Therefore, any feasible maximum flow on the slack edges would constitute a solution. However, this means we have to be able to reconstruct a maximum flow on the slack edges. Thus, in the worst case, reconstructing an arbitrary maximum flow using the dual is no easier than finding a maximum flow from scratch! Therefore, we need to store extra information to be able to reconstruct a maximum flow on the slack edges efficiently.

Next, we provide a combinatorial solution in which we show how to compute a representation for approximate reconstruction (Section 4.1) and how to use this representation to do the actual reconstruction (Section 4.2). In Section 4.3 we discuss the generic effect of supply and/or demand scaling, which is of interest when supply forecasts, for instance, are not available precisely. Remark. At a first glance, a extreme point solution to the primal LP of the maximum flow might appear to require only linear stor-age; this is not the case, however. The primal LP of a maximum flow for a graph with  X  nodes and  X  edges has  X  variables and  X  +  X  constraints. If an extreme point solution to this LP has  X  non-zero variables, there should be  X  linearly independent tight constraints. Among those constraints, at most  X  of them could be node constraints and the remaining  X   X   X  should be edge capac-ity constraints. However, a tight edge capacity constraint uniquely identifies the flow on it respective edge so we do not need to store the flow value for these edges. So we need to store the flow ex-plicitly for at most  X  edges. This argument however requires that we already know which edges have non-zero flow. The number of edges with non-zero flow could be of  X  (  X  ) which would require more than linear space to store.

To illustrate this with an example, consider a maximum flow on a graph with three nodes  X  ,  X  , and  X  . Suppose there is one edge of capacity  X  from  X  to  X  and  X  + 1 edges from  X  to  X  , each of capacity 1 . Among the  X  + 1 edges from  X  to  X  , at most  X  edges can be tight and we need to store which  X  of them are non-zero. Note that there is no way to identify those  X  edges from the dual LP.
As described earlier, by computing the dual variables of the min-cost flow, we can decide which edges are saturated and which are empty. For the remaining (i.e., slack) edges, the problem is re-duced to computing a maximum flow in the new subgraph. Here, we present a way to find a specific maximum flow solution that is easy to reconstruct. We start by developing some definitions.
For a given node  X   X   X  and a given flow function flow :  X   X   X  + on the edges, let in (  X  ) = X
D EFINITION 3 (  X  -FEASIBLE FLOW ). A flow function flow (  X , X  ) :  X   X   X  + is called  X  -feasible if and only if for any contract  X  , 0  X  excess (  X  )  X   X   X  out (  X  ) or equivalently out (  X  )  X  in (  X  )  X  (1 +  X  ) out (  X  ) .

Suppose we have a function height :  X   X   X  + such that the flow on each edge  X  = (  X , X  ) is given by flow (  X , X  ) = min(1 , max( height (  X  )  X  height (  X  ) , 0))  X  cap(  X , X  ) . Before we show the existence of such a function, we define an-other function xheight (  X  ) as follows. For a given height (  X  ) , if by changing height (  X  ) to height (  X  ) +  X  we get excess (  X  ) = 0 , then we define xheight (  X  ) =  X  . Intuitively, xheight (  X  ) indicates how much we need to increase the height of  X  (while keeping other nodes fixed) to reduce the excess flow of  X  down to 0 . It is easy to see that xheight (  X  ) can be computed using a binary search. (To see this, first assume height (  X   X  ) is fixed for all  X   X  height (  X  1 )  X   X  X  X  X   X  height (  X   X   X   X  +  X   X   X  X  X  1 ) . If we assume that when excess (  X  ) = 0 , height (  X   X  )  X  height (  X  )  X  height (  X  computing xheight (  X  ) will be reduced to solving a linear equation. Now to find  X  , we can perform a binary search over all the nodes at the given heights.)
Next we show that there exists a function height (  X  ) for which the corresponding flow is  X  -feasible and it is greater or equal to maximum feasible flow on the slack edges. Note that for a given function height (  X  ) , computing the corresponding flow is trivial just from its definition using (4). The method we use for computing the height function is as follows. Let  X  =  X  2  X   X   X  (1+  X  ) . Algorithm 1 Computing height (  X  ) . 1: Initialize height (  X  ) = 2  X   X   X  + 2 and height (  X  ) = 0 for  X   X  =  X  2: repeat 3: For the current function height , find the node  X  with largest 4: Set height (  X  ) = height (  X  ) + xheight (  X  ) and update the 5: until xheight (  X  )  X   X  for all  X   X   X 
Note that the above algorithm might appear similar to the push-relabel algorithm of Goldberg and Tarjan [12]. However, the re-quirement that the amount of flow going through an edge is a func-tion of the height difference of its endpoints and the non-integrality of the heights makes our setting different from theirs. We now show that the corresponding flow for height (  X  ) after the termination of the algorithm is  X  -feasible and is at least as large as the maximum feasible flow. First we show some properties of the algorithm.
L EMMA 4. After the termination of the algorithm, the set of edges between  X  and contract nodes are all fully saturated or in other words for any contract node  X  , height (  X  )  X  height (  X  )  X  1 .
P ROOF . First we partition the nodes into two sets  X  and  X  based on whether they are reachable from  X  on the residual flow graph. We first claim that  X   X  =  X  and  X   X   X  . This follows since there can be no simple path from  X  to  X  in the residual graph. Any simple path from  X  to  X  is of length at most 2  X   X   X  + 1 and since height (  X  ) = 2  X   X   X  + 2 , it should be the case that for some edge (  X , X  ) on the path, height (  X  ) &gt; height (  X  ) + 1 and therefore flow (  X , X  ) = cap(  X , X  ) , which means (  X , X  ) is not in the residual graph. Thus,  X  and  X  are disconnected.

Since  X  and  X  are non-empty and disjoint, (  X , X  ) is a cut. No-tice that the size of this cut is less than or equal to the cut which consists of edges between  X  and the contract nodes, because we may have some excess flow on nodes in  X  . We can conclude that if the cut (  X , X  ) is not the same as the cut between  X  and the contract nodes then the demands of the contracts were not satis-fiable to begin with which contradicts our assumption. Therefore,  X  = {  X  } and  X  =  X   X  , so for any contract node  X  , height (  X  )  X  height (  X  )  X  1 .

L EMMA 5. For all  X   X   X  , excess (  X  ) is always non-negative during running the algorithm.

P ROOF . First, we can see that at the initialization step, excess (  X  )  X  0 . We show that after running each step, the property still holds. Suppose the algorithm selected  X  at a round and relabeled it so af-ter the relabel step excess (  X  ) = 0 . For all nodes that has an outgo-ing edge to  X  , their outgoing flow is only decreased so their excess will increase. And for all nodes with incoming edges from  X  , their incoming flows only increase so their excess will increase as well. For the rest of the nodes the excess will not change.
 T HEOREM 6. The flow computed by Algorithm 1 is  X  -feasible. P ROOF . Consider the time when the algorithm has terminated. We know that for each  X   X   X  , if we increase its heights by xheight (  X  ) &lt;  X  then excess (  X  ) becomes 0 . Consider a node  X  from the contract layer at the end of the algorithm. Since we know that all the con-tracts are satisfiable, the set of edges from  X  to the contract nodes is the minimum cut and height (  X  )  X  height (  X  )  X  2 . (Note that height (  X  ) = 2  X   X   X  + 2 and height (  X  ) = 0 and any simple path between each contract and  X  has a length less than or equal to 2  X   X   X  .) Therefore, flow (  X , X  ) = cap(  X , X  ) and raising  X  by  X  will not change its incoming flow. Suppose out max (  X  ) is the total ca-pacity of edges going out of  X  . We know that after the algorithm terminates, xheight (  X  )  X   X  . Hence, in (  X  )  X  out (  X  ) = excess (  X  )  X   X  out max (  X  ) . Also note that there can be at most 2  X   X   X  edges going out of  X  , each one with a capacity of less than the incoming capacity of  X  which was cap(  X , X  ) . This implies out max (  X  )  X  2  X   X   X  cap(  X , X  ) and therefore in (  X  )  X  out (  X  )  X  2  X   X   X   X  cap(  X , X  ) . On the other hand since in (  X  ) = flow (  X , X  ) = cap(  X , X  ) , we can conclude that in (  X  )  X  out (  X  )  X  2  X   X   X   X  in (  X  ) . By rearranging the terms, we get in (  X  )  X  (1 +  X  ) out (  X  ) .

Next, we bound the running time of the algorithm that computes the representation.

L EMMA 7. The algorithm terminates after at most  X  ((  X   X   X  +  X   X   X  )  X   X   X  X  X  X   X   X  / X  ) iterations.

P ROOF . First of all, at each iteration, we increase the height (  X  ) for some node  X  by at least  X  . Notice that no node will ever go higher than the source  X  so each node can be relabeled at most (2  X   X   X  + 2) / X  times so the total number of iterations (for all nodes)  X   X   X  / X  ) .

Note that the algorithm 1 is used in the preprocessing step which is offline. Furthermore, even at its worst-case complexity which is We now describe how to reconstruct the flow using just height (  X  ) . For now we assume that after the termination of the algorithm there is no excess flow on any node, i.e.,  X   X , excess (  X  ) = 0 . Obviously, because of the way we constructed the height function, the flow of every edge (  X , X  ) is flow (  X , X  ) = min(1 , max( height (  X  )  X  height (  X  ) , 0))  X  cap(  X , X  ) . This would work perfectly well if there was no excess flow on any node. However because of the excess flows, the solution may not be feasible. To fix that we first tweak the demands before computing the height function and show that if the input instance is (2  X  +  X  2 ) -robust, then we can reconstruct a fea-sible solution. Consider the following modification of our method. (i) Scale up all the demands by a factor of (1 +  X  ) 2 , compute the height function height (  X  ) as explained in Algorithm 1, and then set the demands back to their original values. (ii) At reconstruction time, for each contract  X  and impression  X  , reconstruct the flow on (  X , X  ) using height (  X  ) as before but then scale it down by a factor of (1 +  X  ) .

T HEOREM 8. Suppose that the given input instance is (2  X  +  X  robust. Then, the reconstructed solution according to the above modification is feasible. Furthermore, it may assign impressions to contracts up to (1 +  X  ) times their demand.

P ROOF . First, notice that since the input is (2  X  +  X  we can still satisfy all the demands which means the set of all demand edges is still a minimum cut. After Algorithm 1 termi-nates, since the solution is  X  -feasible, for any contract  X  we have out (  X  )  X  in (  X  ) / (1 +  X  ) . But notice that we scaled up all the de-mands by (1 +  X  ) 2 at the beginning out height computation algo-rithm, so in (  X  ) = (1 +  X  ) 2  X   X  where  X   X  is the original demand of the contract  X  . Therefore, out (  X  )  X  (1 +  X  )  X   X  and clearly if we scale down the flow that we reconstruct for the edges going out of  X  by (1 +  X  ) , still the outgoing flow of  X  is at least as much as  X  which means the demand constraints are satisfied. Using a similar argument for the supply side we can show that for any supply node  X  the incoming flow of  X  cannot exceed its supply  X   X  .
 A summary of the whole process is given in Algorithm 2 and Algorithm 3.
 Algorithm 2 Preprocessing. 1: Build the min-cost flow graph  X  , run the min-cost flow and 2: Remove the edges that are forced to be saturated or empty, up-3: Scale all the demands by (1 +  X  ) 2 4:  X   X   X   X   X   X   X   X  , compute the height (  X  ) using Algorithm 1
Note that note 3 is the algorithm that is used in real-time to serve the requests.
Notice in applying Theorem 8, we scale up the demands before running the height algorithm but we use the same supply. There Algorithm 3 Reconstruction (  X , X  ) . 1: { (  X , X  ) is the given edge} 2: if  X   X   X   X   X  &lt; cost(  X , X  ) , then let flow (  X , X  ) = 0 3: if  X   X   X   X   X  &gt; cost(  X , X  ) , then let flow (  X , X  ) = cap(  X , X  ) 4: if  X   X   X   X   X  = cost(  X , X  ) , then let flow (  X , X  ) = might be also other reasons for scaling up the demands. For exam-ple, suppose we do not know the exact supply of the supply nodes (i.e., the  X   X  values), but we may have an estimate of each supply node which we call  X   X   X  . For example suppose we know that with high probability,  X   X   X   X   X   X  1+  X  . Under, such a circumstance we may want to scale down all the supply estimate  X   X   X  by some factor 1 +  X  (or equivalently scale up all the demand constraints, compute the flow and then scale the flow down by the same factor) to make sure that with high probability we can always meet the the supply con-straints.

Scaling the demands (or supplies) may affect the value of our objective function. The next result gives an upper bound on the change of the objective function when we scale the demands by an arbitrary factor.

T HEOREM 9. For a given input instance which is  X  -robust, and with the optimal objective function value O PT , if we scale the de-mands by 1+  X  , then the new optimal value of the objective function O PT  X  is at most  X   X   X  2  X   X  max  X   X   X   X   X  away from O PT and that is tight.
P ROOF . Consider the flow corresponding to the optimal alloca-tion of the original input (before scaling up the demands). Now, for each contract  X  one by one, we scale cap(  X , X  ) by 1 +  X  . Since the input instance is  X  -robust, we should be able to augment the flow by  X  X  X   X  which is the amount of increase in the capacity of (  X , X  ) . By applying the augmentation we may change the flow of each of the other contract nodes by at most  X  X  X   X  which means the value of the objective function may increase at most by  X  X  X   X  . Since there are  X   X   X  augmentations and each augmentation may affect the flow of all the other contract nodes, in the worst case the total change in the ob-jective function value is upper bounded by  X   X   X  2  X  max  X   X   X  tight example is omitted in this version.
In this section we present a simple greedy approach for a slightly generalized version of the  X  1 penalty function. In this version, we assume the demand constraints are soft, meaning, it is possible to satisfy a contract partially. (The search engine, however, should pay extra amount per unsatisfied demand, similar to the model used in [9]; we will capture this by a parameter  X  .) We also show how to preprocess and then reconstruct the greedy solution using  X  (  X   X   X  +  X   X   X  ) space for storing the preprocessed information and  X  (max  X   X   X   X  con(  X  )  X  ) time to recompute the allocation.
We assume each contract has its own weight  X   X  =  X   X   X   X  and to implement the soft demand constraint, we assume an amount of  X   X   X   X  is paid for each impression that cannot be allocated to the contract  X  , where the factor  X   X  1 . We now present a greedy algorithm and prove that the total cost of its solution is at most 1+  X / 2 that of the optimal solution. The greedy algorithm proceeds as follows.

We now show that this algorithm obtains an approximation to the optimum.
 Algorithm 4 Greedy allocation 1: repeat 2: Let  X  be the next contract with the largest  X   X  3: Give the most balanced allocation possible to contract  X  4: until all contracts are considered
L EMMA 10. Algorithm 4 is a 1 +  X / 2 -approximation for the  X  1 penalty function for the soft demand case with factor  X  .
P ROOF . The proof is based on charging. We start by defin-ing some notation. As usual, for a given allocation  X  , let  X  be the number of allocations from impression  X  to contract  X  . In an allocation  X  , we call a contract  X  on impression  X  as under-represented if  X   X   X  &lt;  X   X   X  ; let under  X   X  (  X  ) = max(0 , X  Similarly, we call  X  over-represented on  X  if  X   X   X  &gt;  X  over  X   X  (  X  ) = max(0 , X   X   X   X   X   X   X  ) . X   X  . Let O PT allocation and G REEDY denote the greedy allocation. Two kinds of penalties are considered in the objective function: Unbalance part and partial contract allocation. Now we make the following claim: in any allocation  X  , we have unfair (  X  )  X  2 P  X   X   X , X   X   X  The claim holds because for any contract  X  , P  X   X   X  P  X  is completely satisfied in  X  . In addition,
This means that the unbalance of our solution is at most twice as under representativeness of our solution. Also, since the alloca-tion is greedy, the amount of under-balance on each impression in greedy is lower than any other allocation. I.e., for any allocation  X  including O PT .

Now, let us consider the total cost of under-balance on impres-sion  X  in the greedy solution, Even if we do not accommodate these contracts in any other im-pression and pay the  X  factor instead of allocating them, the total amount would be at most  X   X  under  X  ( G REEDY ) . Now the total value of the objective function for the greedy solution is at most (  X  + 2) P  X   X   X  under  X  ( G REEDY ) . From the earlier argument, we know that P  X   X   X  under  X  ( G REEDY )  X  O PT / 2 . These imply that the greedy solution is a 1 +  X / 2 approximation for the  X  with soft demand.
Next, we show how we can reconstruct the greedy solution by storing only  X  (  X   X   X  ) preprocessed information. The running time for reconstructing the allocation based on stored information is  X  (max  X   X   X   X  con(  X  )  X  ) . In the preprocessing phase, we compute the greedy allocation as described in Section 4. The stored information for each contract  X  is P  X   X  imp(  X  ) over  X   X  ( G REEDY ) . The reconstruc-tion is as follows:
As described earlier, we need to keep track of only one variable for each contract. Also at each impression arrival, in the worst case we have  X  (max  X   X   X   X  con(  X  )  X  ) processing time. With similar argu-ment given in Lemma 10, we can show that the computed solution here is also 1+  X / 2 -approximation for the balanced allocation with soft demands. Algorithm 5 Greedy reconstruction (  X  ) 1: {A new impression from bucket  X  } 2: For all contracts  X  , set over  X  = P  X   X  imp(  X  ) over 3:  X   X  = {  X   X  con(  X  )  X   X  is under-represented } 4: if  X   X   X  =  X  then 5: Assign the new impression to arg max  X   X   X   X   X   X  6: else 7:  X   X  = {  X   X  con(  X  )  X  over  X  &gt; 0 } 8: Assign the new impression to arg max  X   X   X   X   X   X  9: over  X  = over  X   X  1 .
In this section we perform an experimental evaluation of our al-gorithm on large real-world datasets. The goal of the experiment is three-fold: (i) to demonstrate the practical feasibility and the scal-ability of our min-cost based algorithm, on large instances of the problem, especially compared to using a black-box linear/convex programming solution, (ii) to compare the performance of our al-gorithm to that of baselines such as G REEDY (Section 5) and its heuristic variants, and (iii) to understand the space savings enabled by the reconstruction procedure.
 Data and implementation. The datasets consist of various sub-sets of actual impressions buckets and advertiser contracts from Yahoo! X  X  display advertising system. For simplicity of exposition, we discuss the results for the largest graph in this collection. A gist of results for other graphs is given in Table 4.
 The basic characteristics of the largest graph is shown in Table 1. We can see that the average degree of both the impression and con-tractor nodes is fairly high. The supplies and demands are integral and in our experiments, we treat all contracts equally, i.e.,  X  for all  X   X   X  . First, we ensure that this instance is in fact feasible by checking that the maximum flow in the instance is at least the sum of the demands of the contracts. In fact, the given instance is 0.0001-robust.

Next, we implement the min-cost based algorithm for minimiz-ing the  X  1 penalty. To do this, we use Goldberg X  X  algorithm [11] for min-cost flow, obtained from http://www.avglab.com/ andrew/soft.html . Since this implementation requires inte-gral capacities and costs, we round the costs and capacities when constructing the graph in Figure 1. Additionally, since parallel edges are not supported in the implementation, we split each bot-tom edge in the middle layer of Figure 1 by introducing a new node; the costs and capacities of the newly created edges are the same as the original bottom edge.

The program was run on a single CPU 1.8GHz Linux machine with 16G memory. The min-cost based algorithm took 178 seconds to run on our input instance; we believe this can be significantly im-proved by careful fine-tuning. Besides providing insights into the problem itself, this is more time-efficient than applying a black-box LP solver (an untuned version of which took over 4000 seconds on our instance). Also, the LP solver is unhelpful in efficient recon-struction.
 Performance. The performance of this algorithm is compared to that of the G REEDY algorithm. Since the contracts are unweighted in our instance, we try two additional variants of G REEDY tracts are ordered by decreasing demands (denoted G REEDY increasing demands (denoted G REEDY &gt; ). The results are shown in Table 2. The second column reports the  X  1 penalty as in (1). For comparison purposes, we also compute the  X  2 penalty as in (5) and report it in the third column. The fourth column contains the fraction of contracts that are unsatisfied by the allocation; notice that the min-cost based algorithm always satisfies all the demands, as long as the instance is feasible. As we see, the  X  1 penalty of the min-cost based algorithm is much less than the first two versions of G
REEDY . Interestingly, the third version G REEDY &gt; does better in terms of both  X  1 and  X  2 penalties, but unfortunately does not sat-isfy all the demands. If however the demands are soft, i.e., there is a cost associated with not fully satisfying a demand, we can apply Lemma 10 to comment on the performance of G REEDY .

To understand the solution produced by the min-cost algorithm better, we consider the distribution of the  X  1 penalties per contract (i.e., for a contract  X  , the penalty value  X   X  P  X   X   X   X   X  shows this distribution: the  X  -axis represents the  X  1 penalty values and the  X  -axis represents the fraction of contracts with this penalty value. As we see, the penalties of the min-cost flow-based algo-rithm is sandwiched between the greedy counterparts. This shows that in order to satisfy all the contracts, one has to incur fairly high  X  1 penalties at least for some contracts. (G REEDY and its variants do not take this into account and hence might end up not satisfying some contracts.) Efficacy of reconstruction. Finally, we look at the efficacy of the reconstruction. To study the space savings, we examine the values of the dual variables in (3). Table 3(a) shows the values. It is clear that the flow is either saturated or empty for more than 99% of the edges in the graph. Thus, the reconstruction becomes an efficient proposition since we only need to address the remaining 0.36% of the edges.

The graph  X   X  in Algorithm 2 for our instance is fairly small; Ta-ble 3(b) shows its properties. From the data, we can store (  X   X   X  +  X   X   X  +  X   X   X   X  +  X   X   X   X  ) values (instead of  X   X   X  ) and can reconstruct the solution. This is 3 . 1%  X  smaller by almost two orders of mag-Table 3: (a) Distribution of the dual variables. (b) Reconstruc-tion graph  X   X  : characteristics. nitude  X  of the space without the reconstruction! The time for reconstructing the flow for each edge is essentially negligible by applying Algorithm 3.
 Results for other graphs. We present a summary of results for nine other graphs of varying sizes and characteristics. From Table 4, we see that our min-cost based algorithm performs uniformly well over all these graphs, especially in terms of the running time and the reconstruction size.
In this section we describe the combinatorial solution for a gen-eral convex penalty function. Our solution is based on finding a convex cost flow. For simplicity of exposition, we describe the method for the  X  2 2 function; the general method, however, works for any convex distance function.

For  X  2 2 penalty function, the quadratic programming formulation of the problem is as follows.
We show how to solve (5) using a convex cost flow. The flow network, with capacity and cost on each edge, is constructed as follows. We create a node for each contract and a node for each impression. Now compute the completely balanced allocation for each contract. In this tentative allocation, some of the impressions could be overfull and some of them could have excess supply. The goal is to reallocate the contracts to impressions in the least ex-pensive way (according to the  X  2 2 penalty) such that none of the impressions is overfull. We represent the excess of impression  X  by  X   X  =  X   X   X  P  X   X  con(  X  )  X   X   X  . If  X   X   X  0 , then we consider the im-pression node as a supply node and set its supply equal to  X   X   X   X  0 , then we set the impression node as a demand node and set its demand equal to  X   X  . Also we connect each supply impression node  X  to each contract  X  that is interested in that impression, set-ting cap(  X , X  ) =  X   X   X  and cost 2  X  2  X   X  , where  X  is the flow on that edge (Figure 3). Figure 3: The network construction with (capacity, cost) on the edges for  X  2 2 .

From our construction, it is easy to see the following (proof sim-ilar to that of Theorem 2).

L EMMA 11. The solution to network described above is equiv-alent to the solution to (5).
In [15], Vee et al. showed that the solution to the  X  reconstructed using the Lagrange multipliers of the quadratic pro-gram. As part of their method, they show that, assuming that the Lagrange multiplier for supply constraint is  X   X  and the Lagrange multiplier for demand constraint is  X   X  , the best allocation that min-imizes  X  2 2 norm and is a feasible solution satisfies and store the values, we can reconstruct the allocation. They also showed that the solution to  X  2 2 is unique, which means that the returned solution by the convex cost function also fits in their argu-ment. Earlier in this section, we showed how to compute  X  Here, we give a solution sketch on how we can compute Lagrange multipliers combinatorially as well, given the primal solution. For simplicity, we denote  X  =  X   X   X   X   X  P Rewriting (6), we have  X   X   X  =  X   X   X   X  (  X   X   X   X   X  ) . Thus if we com-pute  X   X   X  , we can compute  X   X   X   X   X  as well. So, for all pairs (  X , X  ) with  X   X   X  &gt; 0 , we first compute  X   X   X  =  X   X   X   X   X  . We now construct a graph with one node for each Lagrange multiplier (in total  X   X   X  +  X   X   X  nodes) and place an edge between two of them if there is a corre-sponding  X   X   X  &gt; 0 for them; let the length of the edge be  X  all it is easy to see that in each connected component, if we know the Lagrange multiplier for one of the nodes (for example  X  Lagrange multiplier for the rest of the nodes in the same compo-nent can be computed as well. So for each connected component, we assign some variable  X  to one of the nodes and compute the distance of all the nodes from that node. This way, the value of the Lagrange multipliers in each component can be represented by  X  +  X  for which  X  is already computed and the only variable is  X  . So the only remaining question is how to choose  X  values in each com-ponent. Looking back at the Lagrangian for the quadratic program, and replacing  X   X   X   X  X  and  X   X  and  X   X  by their computed values, the ob-jective can be written as a linear function in terms of the selected representing values (  X  values) for each component. It is enough now to compute the best value for each of them assuming that we want to minimize the Lagrange objective function. We omit the details in this version.
In this paper we considered the problem of balanced allocation in a bipartite supply-demand setting. We worked with a simple formulation and circumvented the need for mathematical program-ming solutions by taking a more direct and combinatorial look at the formulation. We obtained a flow-based algorithm for the  X  penalty case, the insights from which allowed us to precompute and store a linear amount of information such that the allocation can be reconstructed in constant time per edge. We extended the flow-based algorithm to the general convex function case.
Interesting directions for future work are: Is there a non-flow based solution to the  X  1 penalty case, assuming certain structure on the contracts and/or impressions? Can sampling be used to ap-proximate the  X  1 penalty case and obtain an even more efficient solution? Is there a regular (i.e., not convex) flow solution to the  X  2 penalty case? We thank Andrei Broder, Flavio Chierichetti, Kishore Papineni, Preston McAfee, Prabhakar Raghavan, Jayavel Shanmugasundaram, and Sergei Vassilvitskii for useful discussions. [1] A. Agrawal, P. N. Klein, and R. Ravi. When trees collide: An [2] R. K. Ahuja, T. L. Magnanti, and J. B. Orlin. Network Flows: [3] M. Babaioff, J. Hartline, and R. Kleinberg. Selling banner [4] R. Bar-Yehuda and S. Even. A linear-time approximation [5] F. Constantin, J. Feldman, S. Muthukrishnan, and M. P X l. An [6] N. R. Devanur and T. P. Hayes. The adwords problem: online [7] N. R. Devanur, C. H. Papadimitriou, A. Saberi, and V. V. [8] B. Edelman, M. Ostrovsky, and M. Schwarz. Internet [9] U. Feige, N. Immorlica, V. Mirrokni, and H. Nazerzadeh. A [10] A. Ghosh, P. McAfee, K. Papineni, and S. Vassilvitskii. [11] A. V. Goldberg. An efficient implementation of a scaling [12] A. V. Goldberg and R. E. Tarjan. A new approach to the [13] K. Jain and V. V. Vazirani. Eisenberg-Gale markets: [14] P. McAfee and K. Papineni. Maximally representative [15] E. Vee, S. Vassilvitskii, and J. Shanmugasundaram. Online
