 Ulf Brefeld brefeld@informatik.hu-berlin.de Tobias Scheffer scheffer@informatik.hu-berlin.de Semi-supervised learning algorithms utilize unlabeled data to improve classification performance. The EM approach in which a classifier labels unlabeled data, and then learns from that data, is complemented by the multi-view framework. Multi-view algorithms  X  such as co-training (Blum &amp; Mitchell, 1998)  X  split the attributes into two independent subsets, each of which has to be sufficient for learning. An example of a domain that is suitable for multi-view learning is web page classification: a page can be classified based on its content as well as based on the anchor texts of its inbound hyperlinks.
 Multi-view algorithms learn two independent classi-fiers based on independent attribute subsets. These classifiers then provide each other with labels for the unlabeled data. The co-EM algorithm (Nigam &amp; Ghani, 2000) combines multi-view learning with the probabilistic EM approach. This, however, requires the learning algorithm to process probabilistically la-beled training data and the classifier to output class probabilities. Hence, the co-EM algorithm has so far only been studied with naive Bayes as underlying learner  X  even though the Support Vector Machine is known to better fit the characteristics of many inter-esting problems, such as text classification. We close this gap by developing and studying a co-EM version of the Support Vector Machine.
 The rest of our paper is organized as follows. We dis-cuss related work in Section 2. We formulate the prob-lem setting and review known multi-view and semi-supervised learning algorithms which are relevant for our empirical studies in Section 3. In Section 4, we develop the co-EM Support Vector algorithm and re-port on our experimental res ults in Section 5. Section 6 concludes. Semi-supervised learning (Cooper &amp; Freeman, 1970; for an overview, see Seeger, 2001) has a long tradition in statistics and machine learning; the Expectation Maximization (EM) algorithm (Dempster et al., 1977) is probably the most prominent approach to learning from labeled and unlabeled data (McCallum &amp; Nigam, 1998; Nigam &amp; Ghani, 2000). The EM algorithm is wrapped around learning algorithms that fit model pa-rameters to probabilistically labeled data.
 Linear separators, such as Support Vector Machines (SVMs), cannot immediately be trained from proba-bilistically labeled examples. The transductive SVM  X  TSVM  X  (Vapnik, 1998; Bennett, 1999; Joachims, 1999b) still utilizes unlabeled data by EM-like self-labeling and a modification of the optimization cri-terion (see Section 3). The TSVM is motivated by the idea that the test instances which are to be clas-sified are often available (without class labels) during training. Besides the transductive SVM, a transduc-tive version of the k-NN algorithm (the spectral graph partitioning algorithm; Joachims, 2003) has been stud-ied.
 The co-training algorithm (Blum &amp; Mitchell, 1998) learns two decision functions on independent attribute subsets but does not operate with class probabilities  X  which makes it easily applicable for support vec-tor learning. The co-EM algorithm (Nigam &amp; Ghani, 2000; Ghani, 2002) combines multi-view learning with EM. Co-EM (with naive Bayes as underlying classi-fier) has been found to outperform co-training in some cases (Nigam &amp; Ghani, 2000); in particular, when the compatibility and independence assumptions (see Sec-tion 3) are not violated (Muslea et al., 2002a). Applications of co-training that have been studied in-clude classification of web pages (Blum &amp; Mitchell, 1998), named entity recognition (Collins &amp; Singer, 1999), text classification ( e.g., Denis et al., 2003), wrapper induction (Muslea et al., 2002b), classification of emails (Kiritchenko &amp; Matwin, 2002; Kockelkorn et al., 2003), and word form normalization (Mladenic, 2002). For text classification, experiments have clearly shown that the co-trained Support Vector Machine (in fact, even the  X  X anilla X  Support Vector Machine) substantially outperforms co-trained naive Bayes (Kir-itchenko &amp; Matwin, 2002; Kockelkorn et al., 2003). Together with the observation that co-EM outper-forms co-training for problems with compatible and independent views, this raises the question whether there is a co-EM version of the Support Vector Ma-chine, and whether this is possibly the most effective classifier for text classification problems with compat-ible views.
 However, it should be noted that semi-supervised learning does not necessarily lead to better results than supervised learning. When the target distribu-tion is not in the assumed model class, then the best approximation of the unlabeled data can sometimes lie further away from the optimal classifier than the best approximation of (even few) labeled data (Coz-man et al., 2003). While additional unlabeled data have often been observed to improve classifier perfor-mance (Baluja, 1998; Collins &amp; Singer, 1999; Nigam et al., 2000; Mladenic, 2002), there are some cases in which they have been found to deteriorate performance  X  often, but not always, when the labeled sample is large (Shahshahani &amp; Landgrebe, 1994; Baluja, 1998; Nigam et al., 2000; Kockelkorn et al., 2003). We fo cus on the semi-supervised learning setting in which labeled data D l = ( x 1 ,y 1 ) ,..., ( x m l ,y m l { +1 ,  X  1 } and unlabeled data D u = x  X  1 ,...,x  X  m u are available. Our goal is to learn a decision function f ( x ) which assigns high values to positive and low values to negative examples. The ability of a decision func-tion to discriminate positives against negatives is nat-urally characterized by the receiver operating charac-teristic (ROC) analysis (Bradley, 1997; Provost et al., 1998). The ROC curve displays the number of true positives against the number of false positives for the range of decision function values. The area under the ROC curve, called the AUC performance, is equal to the probability that, when we draw one positive and one negative example at random, the decision func-tion assigns a higher value to the positive than to the negative example. Depending on the application at hand, the decision function may itself be the learning result, or it may be thresholded to yield a classifier h ( x )= sign ( f ( x )  X   X  ), where  X  is adjusted to mini-mize the application-specific cost function.
 In the multi-view setting that we discuss, the avail-able attributes V are split into disjoint sets V 1 and V 2 A labeled instance ( x, y ) is decomposed and viewed as ( x 1 ,x 2 ,y ), where x 1 and x 2 are vectors over the attributes V 1 and V 2 , respectively. These views have to satisfy the independence and compatibility assump-tions.
 Definition 1 Views V 1 and V 2 are independent when  X  x 1  X  V 1 ,x 2  X  V 2 : p ( x 1 ,x 2 | y )= p ( x 1 | y ) p ( x Definition 2 Views V 1 and V 2 are compatible with target concept t : x  X  y when there are hypotheses h 1 : V 1  X  X  X  1 , +1 } and h 2 : V 2  X  X  X  1 , +1 } such that, for all x =( x 1 ,x 2 ) , f 1 ( x 1 )= f 2 ( x 2 )= t ( x ) . Table 1 shows the semi-supervised learning algorithms in our discourse area, EM, TSVM, co-training, and co-EM. Let us briefly review these methods. In the EM algorithm , one single hypothesis iteratively labels the unlabeled data probabilistically, and then adapts its parameters to the data.
 The TSVM algorithm has a similar structure but does not operate with class probabilities. Instead, the la-beling of the unlabeled data is changed when, by switching a pair of labels, the optimization function of the current separator f i is improved. The TSVM optimization problem is defined as follows (Joachims, 1999b).
 Definition 3 Given labeled data D l , unlabeled data D u ,andparameters C and C tion problem is to minimize Equation 1 over all pos-sible values of w , b , y  X  1 ,...,y  X  m u ,  X  1 ,..., X  m l  X  ,..., X   X  m u subject to the constraints 2, 3, and 4. In order to avoid local optima, the TSVM algorithm minimizes a smooth approximation of Equation 1; the contribution of the unlabeled data is weighted with a smoothing factor C S that is doubled in each iteration until it reaches one. In order to obtain a desired ratio  X  p ( y ) of positive and negative labels for the unlabeled data, the contributions of positive and negative slack values are weighted accordingly (Equation 5). In each iteration of the co-training algorithm (Table 1, top right), each of the two decision functions commits to class labels for (at least) one positive and one nega-tive example  X  the ones that are most confidently rated positive and negative. In contrast to EM and TSVM, co-training never revises c onjectured labels for unla-beled data. The co-training algorithm has a favorable theoretical property: because of their independence, the two decision functions can provide each other with labels for the unlabeled data in a way that is essentially equivalent to drawing (slightly noisy) labeled examples at random (Blum &amp; Mitchell, 1998). A co-training step improves the classifier p erformance when one clas-sifier errs for an unlabeled instance, whereas the peer classifier is very confident and adds the correct class label to the labeled data. The independence of the views reduces the chance of both hypotheses agreeing on an erroneous label of an unlabeled instance. The co-EM algorithm (Table 1, bottom right) com-bines the two paradigms. Unlike co-training, the co-EM algorithm does not commit to the generated class labels but rather re-estimates class probabilities after each iteration. The key difference to the self-training strategy of EM is that each decision function produces labels that are used to train the independent peer hy-pothesis. In this section, we present the co-EM Support Vector Machine. We have to address two principal difficulties: The co-EM algorithm requires each classifier to yield class probability estimates for the unlabeled data. Ad-ditionally, we have to construct a learning algorithm that utilizes data which have been labeled with class probabilities for training.
 Let us first address the problem of estimating class probabilities. A linear classifier f gives us an uncal-ibrated decision function f ( x )= wx , but we need to have an estimate of the class posterior p ( y | x ). We as-sume a parametric model: the decision function values foraclass, p ( f ( x ) | y ), are assumed to be governed by a normal distribution N [  X ,  X  2 ]. We estimate the pa-rameters  X  and  X  2 during training; given labeled and unlabeled training data and a decision function f ,we proceed as follows.
 Firstly, we estimate the prior probabilities  X  p ( y )from the labeled data. We split the unlabeled data into pos-itives D + u and negatives D  X  u according to the fixed ra-tio  X  p ( y ); the unlabeled instances x  X  j with highest f ( x are selected into D + u . Secondly, we estimate the mean decision function values  X  + and  X   X  (Equation 6) and corresponding variances  X  2 + and  X  2  X  (Equation 7). From the priors  X  p ( y ) and Gaussian likelihoods with parameters  X  + ,  X   X  ,  X  2 + ,and  X  2  X  , we can now infer the desired class probabilities  X  p ( y | x  X  j ) (Equation 8).
Now we address the second problem: Given labeled data D l , and unlabeled data D u with class probability estimates  X  p ( y | x  X  j ), how can we train a support vector classifier? Intuitively, if  X  p ( y | x  X  j ) = 1 for some instance x , then that instance is essentially a labeled example and should contribute to the optimization criterion ac-cordingly. On the other hand,  X  p ( y | x  X  j )=1 / 2 indicates a lack of information about the class label of x  X  j ;the optimization criterion should not be influenced by the class label it assigns to such an x  X  j .
 We introduce an individual weight for each example into the optimization criterion analogously to Brefeld et al. (2003); we define the weight such that we achieve a smooth transition from full contribution for  X  p ( y | x  X  j )= 1tonocontributionfor X  p ( y | x  X  1 / 2. We label an unlabeled instance x  X  j with y = argmax y  X  p ( y | x  X  j ) and define its weight to be c max y  X  p ( y | x  X  j )  X  min y  X  p ( y | x  X  j ). Co-EM SVM. Input: Labeled data D l , unlabeled data D u ,slackparameter C , number of iterations T . 1. Initialize smoothing factor C S = 1 2 T 2. Train initial support vector machine f 2 0 on labeled 3. Estimate  X  p ( y ) using the labeled data D l . 4. For i =1 ...T : For v =1 ... 2: 5. Return the combined function 1 2 ( f 1 T + f 2 T ). Definition 4 Given labeled data D l and unlabeled data D u = x  X  1 ,...,x  X  m with label probabilities  X  p ( y the probabilistic SVM optimization problem is to minimize Equation 9 over all possible values of w , b ,  X  1 ,..., X  m l ,and  X   X  1 ,..., X   X  m u , subject to the con-straints 10, 11, and 12, where c x j  X  =(max y  X  p ( y | x min y  X  p ( y | x  X  j )) . In order to reduce the risk of finding local minima, we copy the smoothing strategy of the TSVM and multi-ply the contributions of the unlabeled data to Equa-tion 9 by an initially small number C S which is dou-bled in each iteration until it reaches one (Equation 13). The resulting algorithm is shown in Table 2. We can trivially extend the co-EM SVM to non-linear functions by moving from the primal to the dual rep-resentation of the optimization criterion and replac-ing the inner products by kernel functions. As a by-product, we obtain another semi-supervised single-view algorithm: the EM SVM algorithm is a self-training strategy that is just the co-EM SVM algo-rithm with V 1 = V 2 .
 How does co-EM improve the performance of a Sup-port Vector Machine? Intuitively, when x is a large margin example for f 1 ,then f 1 has a small error prob-ability for x .When V 1 and V 2 are truly independent, then the projection of x into V 2 is a randomly drawn instance in V 2 ; x may be a support vector in V 2 even though it is a large-margin example in V 1 .Theco-EM SVM labels each unlabeled example in V 2 with the class label assigned by f 1 . Co-EM assigns a weight to the example that is derived from the probability that this class label is in fact correct. This only holds for independent views; in the other extreme of equal views, co-EM training beco mes EM self-training. Our experiments are based on the course data set (Blum &amp; Mitchell, 1998; Nigam &amp; Ghani, 2000), and the well-known Reuters-21578 and 20-newsgroups data sets. In the course data set, the task is to decide whether a web page is a course home page, based on its content ( V 1 )aswellasontheanchortextsofin-bound links ( V 2 ); the split of attributes into V 1 and V is explicit for the data set.
 All curves that we present in this section are aver-ages of 20 runs of the focused algorithm, with distinct, randomly drawn samples. Our implementation of the co-EM algorithm is built into SV M light (Joachims, 1999a). We use the default parameters of SV M light and linear kernels for all experiments. We want to shed light on the following list of questions. How fast does co-EM SVM converge? The curves for the co-EM SVM in Figure 1 (for the course data set), third column, show a sharp increase in the second iteration, and anoth er increase (in few cases, a decrease) towards the end of the training process. The increase after the first iteration is caused by the unlabeled data which are first perceived in the second round. The change towards the end of the training process is caused by the smoothing factor which expo-nentially approaches one in the last round. The flat region in between indicates that the chosen 30 iter-ations are more than sufficient. In many cases, the maximal AUC value is reached for a smoothing weight C
S of less than one. This implies that we could im-prove the performance of the co-EM SVM by adjusting the maximal C S as a learning parameter. However, we refrain from adjusting any parameters and report on results for a maximal smoothing parameter of 1. How does the relative benefit of semi-supervised support vector algorithms depend on the number of available labeled data? We vary the number of labeled examples and observe ROC curves over the co-training and EM iterations. Figure 1, top row, compares the curves for co-training, co-EM SVM, and EM SVM. The right-most curve in the top row summarizes these results and compares them to the performance of the  X  X anilla X  SVM and the TSVM. For all labeled sample sizes, the co-EM SVM outper-forms all other variants.
 How does the relative benefit of semi-supervised support vector algorithms depend on the number of available unlabeled data? The second row of Figure 1 shows the results for 2 positive and 8 negative and various unlabeled sample sizes, the third row for 4 positive and 16 negative labeled ex-amples and various unlabeled sample sizes. The right-most diagrams summarize the results and present the baselines SVM and TSVM.
 The performance of all variants scales down linearly as we reduce the amount of unlabeled data. Except for 2 positive and 8 negative examples using 12.5% of the unlabeled data, co-EM SVM is most effective. The former case is dominated by EM SVM that is least affected by the amount of unl abeled data. Here, co-training behaves brittly and the performance decreases over the iterations. This d ecrease becomes stronger as we reduce the amount of unlabeled data. How does the relative benefit of semi-supervised support vector algorithms depend on the compatibility of the views? In order to add controlled amounts of incompatibility and depen-dence into the experiment, we adapt an experimental setting of Nigam and Ghani (2000) and Muslea et al. (2002a). We use four of the 20 newsgroups: rec.autos, comp.graphics, sci.space, and talk.politics.misc. After building tfidf vectors, we generate positive ex-amples by concat enating vectors x 1 from rec.auto with randomly drawn vectors x 2 from sci.space to construct multi-view examples ( x 1 ,x 2 ). We gener-ate negative examples by concatenating vectors from comp.graphics with vectors f rom talk.politics.misc. This procedure generates views which are perfectly independent (peers are selected randomly) and com-patible (either group can be discriminated from the other).
 In each run we choose 5 positive and 5 negative la-beled examples and add noise and dependencies, re-spectively, at random. Figure 2, top row, shows the re-sults for increasingly large incompatibility (percentage of labels flipped). With up to 20% noise, both co-EM and co-training learn extremely accurate separators (both achieve AUC values of 1). As we add increas-ingly much noise, the performance of co-training dete-riorates faster than the performance of co-EM SVM. How does the relative benefit of semi-supervised support vector algorithms depend on the independence of the views? In order to add dependencies into the data set we proceed as fol-lows. Each vector is a concatenation of attributes x ,...,x k (view V 1 ), and x k +1 ,...,x 2 k (view V 2 ). For each vector, each attribute k + i assumes the value of attribute i (as opposed to its original value) with probability p dep .For p dep =0,theviews V 1 and V 2 are perfectly independent. For p dep = 1, the projec-tions of each instance into either view are equal; the views are totally dependent. This procedure allows to add much stronger dependencies than the related procedure proposed by Muslea et al. (2002a) Figure 2, bottom row, shows the curves for varying levels of dependency. The performance of the co-EM SVM deteriorates faster than the performance of co-training as we add strong dependencies. As expected, the SVM shows only marginal deteriorations and out-performs all other variants for stronger dependencies. So, how does the co-EM SVM algorithm com-pare to results of co-training and co-EM with naive Bayes? We focus on the course data set for which several results are published that are based on naive Bayes (Blum &amp; Mitchell, 1998; Nigam &amp; Ghani, 2000; Muslea et al., 2002a).
 Table 3 summarizes the results. After 100 rounds, the co-trained SVM achieves an error of 4.45% while the co-EM SVM outperforms all other support vector algo-rithms significantly with an error rate of 0.99%. Since 3 positive and 9 negative examples do not reflect the true prior distribution we used the natural ratio of 2 positive and 8 negative examples for shifting the deci-sion hyperplane.
 Do the obtained results hold for larger data sets? We conduct another set of experiments in which we discriminate each of the seven most frequent classes of the Reuters-21587 data set from all other classes. In each of the seven binary cl assification problems we draw 190 labeled examples (1% of the data) at ran-dom  X  the positive/negative ratio varies due to differ-ent class sizes  X  and obtain 18853 unlabeled examples that we use as hold out set as well. In each trial we randomly split the available attributes into two sub-sets; we average over 20 distinct samples and attribute splits. The results are shown in Figure 3.
 Analogously to the course data set experiment, the multi-view algorithms outperform all other variants of supervised and semi-supervised support vector algo-rithms that we studied. Her e, co-training beats the baseline SVM significantly in four out of six cases fol-lowed by the co-EM SVM with three out of five signif-icant improvements. We developed a co-EM version of the Support Vector Machine. The co-EM SVM algorithm utilizes unla-beled data when the available attributes can be split into two independent subsets each of which has to be sufficient for learning. We observed that the co-EM SVM outperforms all other variations of semi-supervised SVM algorithms for the course problem, in most trials with the 20 newsgroups data set, and per-forms second-best for the Reuters data set. When we reduce the amount of unlabeled data, the performance of the co-EM SVM deteriora tes less severely than the performance of co-training. The single-view counter-part of the co-EM SVM behaves similar to the trans-ductive SVM. Furthermore, we found that multi-view learning improves the performance on the Reuters data set even though the views are generated by splitting the attributes at random.
 Acknowledgment This work has been supported by the German Science Foundation DFG under grant SCHE540/10-1.

