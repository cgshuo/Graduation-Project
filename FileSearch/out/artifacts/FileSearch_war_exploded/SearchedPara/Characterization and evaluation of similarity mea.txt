 Darius Pfitzner  X  Richard Leibbrandt  X  David Powers Abstract In evaluating the results of cluster analysis, it is common practice to make use of a number of fixed heuristics rather than to compare a data clustering directly against an empi-rically derived standard, such as a clustering empirically obtained from human informants. Given the dearth of research into techniques to express the similarity between clusterings, there is broad scope for fundamental research in this area. In defining the comparative pro-blem, we identify two types of worst-case matches between pairs of clusterings, characterised as independently codistributed clustering pairs and conjugate partition pairs . Desirable beha-viour for a similarity measure in either of the two worst cases is discussed, giving rise to five test scenarios in which characteristics of one of a pair of clusterings was manipulated in order to compare and contrast the behaviour of different clustering similarity measures. This comparison is carried out for previously-proposed clustering similarity measures, as well as a number of established similarity measures that have not previously been applied to clustering comparison. We introduce a paradigm apparatus for the evaluation of clustering comparison techniques and distinguish between the goodness of clusterings and the similarity of cluste-rings by clarifying the degree to which different measures confuse the two. Accompanying this is the proposal of a novel clustering similarity measure, the Measure of Concordance (MoC). We show that only MoC, Powers X  X  measure, Lopez and Rajski X  X  measure and various forms of Normalised Mutual Information exhibit the desired behaviour under each of the test scenarios.
 Keywords Clustering  X  Evaluation  X  Similarity measures  X  Cluster comparison  X  Review 1 Introduction Cluster analysis is a fundamental technique in the analysis of data across a broad spectrum of disciplines. This is evidenced by four of the top ten data mining algorithms identified at the 2006 ICDM conference being clustering or classification approaches [ 63 ]. Clustering is simply a process in which the members of a data set are divided into groups such that the members of each cluster(group) are sufficiently similar to infer they are of the same type and the members of the separate clusters are sufficiently different to infer they are of different types. The comparison of members within a data-set is normally achieved by assigning a vector of binary or numeric attributes to each member. In hard clustering, attributes are then used to compare each member to all the other members through the application of a threshold probability measure (either fixed or dynamically generated) which determines the similarity or dissimilarity between members of a cluster or between a member and the central point of a cluster. Popular clustering methods include partitioning methods, e.g. k-means [ 34 ]; hierarchical methods, e.g. Chameleon [ 27 ]; density-based methods, e.g. DENCLUE [ 22 ]; grid-based methods, e.g. CLIQUE [ 1 ]; and model-based methods, e.g. AutoClass [ 6 ].
Clustering algorithms embody the logic of forming data sets into a collection of nonempty subsets so that members in the same subset are more similar (cohesion) than members that come from different subsets (separation). The problem inherent in this process is that the maximization of cohesion and separation often causes conflict as the distance function may separate members that should be together and vice versa. When this is a likely scenario an arbitrating process such as the use of a template or gold standard may be used to help the demarcation process.

The usefulness of cluster analysis in eliciting groupings within data sets has seen extensive research and development into clustering algorithms and distance metrics (for reviews see [ 4 ], and [ 66 ]). Compared to this there is relatively little research and development into mea-suring the similarity between the sets of clusters produced by different algorithms. In many applications the idea of clustering appears to be a useful technique used to reflect human intuitions and physical, biological or social associations or laws. A particularly challenging problem is that of introducing human understanding, interpretation and biases (context) into the problem of visualizing and interacting with data arising in an information retrieval task (such as web search). In such situations human judgment is the relevant standard for the measurement of the relevance of any clustering. This raises the question of how to compare the performance of common clustering techniques and distance measures against a human generated gold standard partitioning (a partitioning of elements that is considered to be  X  X or-rect X  in some sense). There is a distinct lack of research and development into techniques for the comparison of clusterings (partitionings). However, there has been some significant work in the field such as that by [ 2 , 15 , 48 ]and[ 38 ].

More research into the comparison of clustering pairs, such as between a human-generated clustering and one automatically generated from the same set, would be timely, as techniques that optimize clustering by manipulating input parameters and/or the clustering algorithm are being employed on an increasing basis. Many of these techniques compare clusterings to other automatically generated clusterings or to a gold standard partitioning and often need to achieve this independently of the production algorithm or distance metric used. To do this, human-generated clusterings need to be compared to those generated automatically, a more complex task than the typical bipartite comparison of clusters. Bipartite comparison is a simple population to population correlation test whereas in the comparison of clusterings there is an extra dimension to account for in the comparative process. Cluster validation methods focus on defining cluster cohesion and separation via distance measures to represent the quality of groups of clusters; however, in comparing clusterings, the correlation between the total set of clusters as well as the individual cluster memberships needs to be considered without knowing a priori which should correspond or even having any constraint on the number of clusters matching.
In this paper, we characterize and evaluate a number of similarity/dissimilarity measures as applied to the context of comparing a pair of clusterings. These include measures previously proposed for this problem, and a host of other similarity/dissimilarity measures that, although they have not previously been applied to clustering comparison, are applicable.
The evaluation of these measures is performed in the context of five test case scenarios in which we systematically manipulate certain characteristics of one member of a pair of cluste-rings, in order to determine whether the measures are sensitive to these manipulations. These tests are derived from a consideration of two possible worst-case matches between a pair of clusterings, which we term Independently Codistributed Clustering Pairs and Conjugate Partition Pairs.

To help avoid confusion the authors would like to highlight the fact that the words clusters (data point groupings of a clustering) and clustering (the set of clusters that result from a clustering process) may be used in in close proximity to each other in this document.
The structure of this paper is as follows. In Sect. 2 , previous work on clustering compa-rison is reviewed. Section 3 provides a discussion of desirable characteristics of a clustering comparison similarity measure under the two identified worst cases. In Sect. 4 ,wederive and justify MoC. Section 5 contains an evaluation of the behaviour of each of the similarity measures under the five test scenarios, and Sect. 6 provides a conclusion. 2 Background We now turn to discuss the problem of comparing data groupings, specifically clustering pairs, using a pair counting technique.

Association measures have been well researched and used since the late 1800 X  X  (see Sect. 2.3 ) to measure relative association between variables. In proposing the new measure MoC this paper looks closely at a limited but key set of association measures proposed within this period. MoC is designed to represent the difference between clustering pairs (partitions) as opposed to cluster pairs (two individual divisions of two separate partitions).
Several measures have been suggested for use in the comparison of clustering pairs. These measures can be used to compare how well different data clustering algorithms perform on a set of data. Measures are commonly summarized using a generalized 2  X  2 contingency (alternatively, matching or confusion) matrix to facilitate comparisons between measures. This research combined this approach with a pair counting approach, to populate the 2  X  2 contingency matrix (see Sect. 2.1 ), a convenient way to summarize the relationships between the memberships of two subclusters. Contingency tables can also be used in both asymmetric and symmetric situations as the key relationships in the contingency table can be assessed bidirectionally (see Sect. 2.1 ). 2.1 Contingency tables and pair counting in cluster comparison Pair counting was first applied scientifically by [ 59 ] through his Law of Comparative Judg-ment and is a mathematical representation of a discrimination process. These processes see comparisons made between pairs of a collection of entities with respect to the magnitudes of attributes, traits, and the like. To apply a pair counting approach to the traditional contingency matrix, firstly all the members of one clustering are incrementally paired. These pairs are then compared to all the similarly paired members of the other clustering. Using different relationships between the two member pairs of the partitions, the values in the contingency matrix are assigned as follows:
Given the partitionings P and Q ofthedataset D we first define data set pairs Pairs D as all the pairs realizable from the complete data set. Second, clustered pairs Pairs P and Pairs Q are those pairs of members from D that cluster together in P and Q respectively. Using Pairs P , Pairs Q and Pairs D the values of the four quadrants of the contingency matrix are realised as:
We a l s o d e fi n e So for example given the set, and the partitions, then, so,
As noted earlier, contingency matrices can be used in both symmetric and asymmetric situations. In the symmetric case, there is no gold standard and so no predictive data; only the similarity of the two partitions can be measured. However, in the asymmetric case because there is a fixed target (Gold Standard) which allows for certain predictive observations to be made about the system that created the partition. In Table 1 , each column of the matrix represents the instances in a predicted class, while each row represents the instances in an actual class (Gold Standard). By comparing the actual against the predicted it is easy to see if a system is confusing two classes (i.e. commonly mislabeling one as another). For those more comfortable with confusion matrices an equivalent has be supplied (see Ta b l e 2 ) to assist in translation. 2.2 Clustering comparison criteria Clustering algorithm selection or development aside, once a set of clusters has been realized there remains the question of quality of membership assignment relative to the initial purpose criteria [ 19 ]. The relative and internal criteria approaches use Monte Carlo methods [ 58 ]to evaluate whether a clustering is significantly different from chance, whereas external features are used to compare the memberships and structures of two clusterings. In this paper external criteria are used exclusively.
 Internal criteria Are quantities that involve the vectors of the data set themselves (e.g. proximity matrix). They are used to assess either the clustering itself or its producing algorithm by measuring characteristics like cohesion, separation, distortion and likelihood.
Because these criteria are greatly affected by parameters defined apriori , such as number of clusters required or minimum density, internal criteria are thus sensitive to both the quality of the clustering and the apriori criteria used for evaluating them.
 Relative criteria Are used to rate a clustering by comparing it to other clusterings, produced by the same algorithm with different input parameter values. In this predefined criteria are selected to suit the algorithm and data set.
 External features Are used to simply measure how similar a clustering is to another clus-tering, gold standard or desirable-feature template and as such produce measures inde-pendent of the producing algorithm and apriori clustering evaluation, data set, or problem specific criteria.
 In addressing the choice and comparison of clustering approaches [ 48 ] examined clustering function characteristics and posed four questions: 1. How well does a method retrieve  X  X atural X  clusters? 2. How sensitive is a method to perturbations of the data? 3. How sensitive is a method to missing individuals? 4. Given two methods, do they produce different results on the same data?
Since clustering similarity/dissimilarity is not simply a comparison of two populations via some distance, membership or algorithm traits, the question of  X  X hat does it mean to compare clusterings? X  must be answered.

Furthermore, when comparing clustering pair similarity without the use of a gold standard or desirable feature template, comparison measures will only be quantitative. This is to say they will not determine the degree of  X  X oodness X  regarding the clustering or its member clusters which is normally introduced through gold standards or desirable feature templates. We will thus develop a desiderata for cluster comparison methods based on external features they have in common (see Sect. 3 ). 2.3 Common approaches in comparing clusterings This section discusses two approaches commonly used in the comparison of clustering pairs. As clustering is one of the key techniques used in the exploration of data it stands to reason that one might want to compare the results of different approaches applied to the same data set for optimization, quantification or qualification purposes. The principal approaches used in clustering comparison can be described through their development of criteria, of which there are two main approaches: pair counting and information theoretic . This section briefly discusses these clustering comparison approaches.

To assist in these discussions the following definitions are made:  X  P represents the Left clustering.  X  Q represents the Right clustering.  X  I is the number of clusters in P where i indexes the clusters.  X  J is the number of clusters in Q where j indexes the clusters.  X  f ij is the number of items in the ij th fragment (the intersection of the  X  p i or f i . is the number of items (cardinality) in the i th cluster in P  X  q j or f . j is the number of items (cardinality) in the j th cluster in Q  X  n = number of items in the clustered space. 2.3.1 Pair counting approaches in clustering comparison As discussed previously (see Sect. 2.1 ) pair counting has been applied in this research to represent the relationships between the memberships of subclusters to judge how many member pairs two clusterings have in common. Following are broad discussions about the key techniques that use the pair counting approach. To assist the specific discusions of the Fowlkes and Mallows, and Rand measures these three key definitions are made: Fowlkes and mallows [ 15 ] published the derivation of a measure of association proposed to describe the similarity between two hierarchical clusterings.
This measure was designed to represent the similarity of two trees at each level of a clus-tering. It ranges between 0 (maximum dissimilarity) and 1 (maximum similarity), measuring the association between two partitions of objects. Using a co-occurrence matrix to count the intersections at each level of two hierarchical trees it generates a sequence of values from which the differences are plotted. It is therefore an accumulation of the intersection counts for all relative levels of two hierarchical clusterings of the same data. Alternatively, it represents the multiple measures of similarity between the different levels of clustering and is expressed as B k such that Rand Rand [ 48 ] proposed the measure R K that in his words  X  X ssentially considers how each pair of data points is assigned in each clustering X . R K is described as the ratio of the sum of the number of pairs of members that occur in the same cluster in both clusterings and the number of pairs of members that don X  X  occur in the same cluster in either clusterings compared to the total number of pairs. From this it can be said that R K is the probability that two objects are treated alike in both clusterings.
 Despite conducting fairly rigorous Monte Carlo sampling experiments to capture the cha-racteristics of R K and test its utility in comparing clustering methods Rand did not formally derive any properties for R K . Fowlkes and Mallows [ 15 ] on the other hand did derive moments of R K for the assumptions of fixed margins, f i . and f . j , and random allocation of matching counts of objects to f ij . The Rand index has a value between 0 and 1, with 0 indicating that the two data clusters do not agree on any pair of points and 1 indicating that the data clusters are exactly the same. A problem with the Rand measure is that the expected value of two random partitions does not take a constant value (say zero).
 Wallace Wallace X  X  asymmetric criteria B I and B II [ 60 ] represent the probability that two data points in a cluster in one partitioning are also in the same cluster in another partitioning and are defined as; Precision, recall and F measure Another way of comparing partitionings is to use the well known precision and recall measures. For a gold standard P , then: Clearly in this case recall equals Wallace X  X  B I and precision equals Wallace X  X  B II .Asym-metric measure that combines precision and recall is the Fmeasure , which is equivalent to Dice X  X  measure [ 9 ] and is defined as: Other pair counting measures The use of the contingency matrix in the last three discussed association measure research. Association measures and the 2  X  2 contingency matrix are ubiquitous in experimental work in a range of scientific disciplines other than data clustering and data mining, e.g. psychology, biology, climatology, etc, and present an important body of research that may be drawn on. This suggests that any of the similarity measures that have been developed based on 2  X  2 contingency matrices in other scientific contexts are valid similarity measures for the comparison of clustering pairs. Fourty-three of these measures have been collated, several of them taken from work by Yao et al. [ 21 ] on feature comparisons between amphibian species. Many of these measures may be unfamiliar in the data mining and machine learning communities, where  X  X orrectness X  against a gold standard is routinely saw for the Rand measure (see Sect. 2.3.1 ), many of these measures have the same trait of having a non-constant expected value for two random partitions for comparison, which will be demonstrated empirically in the results Sections (see Sect. 5 ). 2.3.2 Information theoretic approaches in clustering comparison Information theory is a field of mathematics that stems from the need to improve the descrip-tion and quantification of data, endeavouring to reliably store and transmit this data using the least amount of information possible. The measure known as information entropy is used to do this and is usually expressed by the average number of bits needed to store or communicate data. Information theoretic approaches apply entropy in different manners to compare the difference in information between two partitions. Some different approaches used are the Powers Measure [ 44 ], Meila X  X  Variation of Information [ 38 ]andNMI Normalized Mutual Information [ 24 , 35 , 30 , 46 , 56 , 16 ].

Entropy can be described as the information conveyed by the uncertainty that a randomly selected point belongs to a certain cluster. In the context of clustering Entropy is defined as: sures, obtained by combining and normalizing conditional entropy and mutual information in various ways. Some of these measures are presented in Table 3 . Yao et al. [ 64 ] also point out the following relationships: 5. H ( P | Q ) + H ( Q | P ) = H ( P &lt; Q )  X  I ( P ; Q ) Conditional entropy The conditional entropy measures how much entropy a random variable Y has remaining if we have already learned completely the value of a second random variable X . In other words it expresses how much extra information you still need to supply on average to communicate Y given that the other party knows X . The higher the conditional entropy the more an observer can predict the state of a variable, knowing the state of the other variable. Joint entropy The joint entropy measures how much entropy is contained in a joint system of two random variables. In other words it is the amount of information needed on average to specify both the values and is defined as: Mutual information The Mutual Information of two random variables expresses their mutual dependence or the amount of information they have in common. In other words, it measures how much knowing one of these variables reduces the uncertainty about the other. Following is a definition for Mutual Information where p ( P ) , p ( Q ) and p ( P , Q ) are probabilities. Po w e rs Whereas conditional entropy is an asymmetric measure of the information required to specify one model given the other, the Powers measure [ 44 ] was developed to allow for the fact that we do not know which model is correct, or even better. It calculates a symmetric measure of the information required to specify the alternate model given the better model, assuming that which model is correct is unknown and the two models are equiprobable. The unnormalised measure is the average of two non-negative asymmetric measures and thus always non-negative, with 0 representing identity of the models.

Mutual Information ( I ( P , Q ) ) is complementary to this model, and is also always non-negative, with 0 representing the case where H ( P ) or H ( Q ) is vacuous  X  viz. has 0 entropy, [
H upper bound for H ( P , Q ) .Conversely2 H ( P , Q ) is an upper bound, and H ( P , Q ) alower bound, for H ( P ) + H ( Q ) . These represent relationships between the expected entropy (the expected number of bits to represent the correct distribution given these models are equipro-bably) and the joint entropy (the number of bits to represent the fragments defined by the two distributions).
 Meila X  X  variation of information This measure was proposed by [ 38 ] as an information theoretic to compare two clusterings of the same data. Presented as VI (Variation of Infor-mation) it measures the amount of information lost or gained in changing from one cluster C to another C . This measure is positive, symmetric and transitive and in Meila X  X  words  X  X urprisingly enough a metric X . However, it should be pointed out that it is not normalized, which would improve its comparability to other measures.
 Normalized mutual information There are several different approaches to the normalization of mutual information, two of these come in the form of the coefficients of constraint by [ 7 ] clear that these two coefficients are not equal or symmetric. A symmetric alternative is that of one of the variables is totally redundant to the other. Another symmetrical measure is that of weighted average of the two uncertainty coefficients. In addition to these measures, one can also consider as cluster comparison measures Joint entropy, Unnormalized Mutual Informa-tion and the two asymmetric versions of Conditional Entropy. Table 5 lists the information theoretic approaches considered in this paper along with their formulas in terms of Entropy H ( P ) and H ( Q ) .

Formula table The following Tables 4 and 5 index the different formula used in testing and comparing MoC. 3 Desirable behaviour of a clustering comparison measure son of two partitions via measures that reflect similarity in terms of features such as the number of clusters, cluster sizes and relative cluster memberships. This can be achieved through techniques such as pair counting and information theoretic approaches as discussed in Sect. 2.3 .

Notwithstanding the innate ability of humans to spot patterns and relationships it is basi-cally impossible to truly characterize what heuristics humans might use in the comparison of partitions. It was this observation that prompted the research presented in this paper to investigate what it is that makes partitions different from a human or external perspective. We are interested in this question as a result of work in a number of settings, including clus-tering in document retrieval, human-computer-interaction modelling, and in evaluating the unsupervised induction of lexical categories from real linguistic data.

To identify perfectly matching clustering pairs is a relatively simple task, however quanti-fying how different a pair of partitions are is far more difficult. Different measures will have different qualities both negative and positive depending on the partitions and the desired outcome. In prelude to describing our method of comparing pairs of partitions we define desiderata used to guide the selection and testing of measures process, and outline the worst cases of Independently Codistributed Clustering Pairs , Complete Fragmentation and Conju-gate Partition Pairs used in the comparison of pairs of partitions. Desiderata of appropriate measure characteristics 1. The comparison measure m ( P , Q ) should be independent of any concept of the  X  X ood-2. In the absence of a Gold Standard a measure should be symmetric in regard to the two 3. The comparison measure should range in value between 0 and 1, where 1 is a perfect 4. There should be no dependence of the comparison measure on the number of elements 5. Similarly, if the pattern of distribution of elements between two clusterings is the same, 6. The fall-off of the similarity measure should match the intuition of decreasing similarity, 3.1 Independently codistributed clustering pairs A clear instance of a mismatch between two clusterings P and Q occurs when every cluster in P contains elements from each of the clusters in Q in the same proportions in which they are distributed among the Q clusters. In this situation the sizes of the intersections between every cluster P i and every cluster Q j , i.e. the values in the co-occurrence matrix between P and Q , take on their expected values according to the marginal totals.
 This case corresponds to a situation where no P cluster has any particular affinity for any Q cluster, so that knowing how the elements of a particular cluster P i are distributed among the Q clusters provides no information about the value of the index i . In this case, P and Q are independently distributed.

It is desirable for a clustering comparison measure to recognise this independently -distributed worst case , and to take on its minimum value when the case occurs. 3.2 Complete fragmentation and conjugate partition pairs Another clear  X  X orst case X  is when all intersections of classes of P and Q are singletons. We introduce the concept of  X  X onjugate Partition Pairs X  to define a  X  X aximal X  case which leads to complete fragmentation .

The conjugate of a partition is simply the 90 o rotation of the partition where the clusters change from being say the rows (see Fig. 1 a) of a matrix to the columns (see Fig. 1 b). By rotating the matrix Fig. 1 a and b depict clusters with the same data points, which are the clusters has only one element in common (complete fragmentation). In the pair counting approach, therefore, there are no pairs in common, so that cell a (representing True Positive) in the contingency matrix (see Tables 1 , 2 ) is zero. Measures which are based on a (such as Precision and Recall, or Rand X  X  measure) may be expected to identify this worst case relatively well.

Partitions that maintain their original structure after rotation, as seen in Fig. 1 a and b, are described as Self Conjugate or Symmetric Conjugate Partitions while partitions that do not retain their original structure (where by  X  X etaining structure X  it is meant they have the same distribution of cluster sizes), as seen in Fig. 2 a and b, are known as non-symmetric conjugate partitions. 4 MoC derivation and justification This section introduces the Measure of Concordance (MoC) through logical development beginning with an example. Suppose that a data set D of 36 elements has been clustered using two rival clustering algorithms, so that the first algorithm clusters the elements of D into the clustering P , and the second algorithm clusters the same elements into the clustering Q as depicted in Fig. 3 . Regarding these two clusterings, the question of interest is how to express quantitatively the extent to which they agree relative to the underlying groupings present in the dataset.

Given that there are I clusters in P ,and J clusters in Q (with I and J not necessarily smaller subclusters or fragments , where a fragment consists of those elements of P i that have also been allocated to a single cluster Q j in clustering Q ,forsome j . This fragment, labeled F ij , is therefore the intersection between P i and Q j . Fragments represent instances where both clusterings agree that the elements involved  X  X elong together X , and hence represent the shared structure between the two clusterings. Clearly, if cluster P i contains the fragment F ij , then cluster Q j also contains the same fragment F ij .

The relationship between the clusterings P and Q can be expressed as a co-occurrence matrix F , with row i corresponding to cluster P i and column j corresponding to Q j ,sothat each cell of F contains the size of fragment F ij as demonstrated by Table 6 .

The rectangles on the left-hand side of Table 6 labeled P 1 , P 2 and P 3 are clusters that make up a clustering P , while the rectangles labeled Q 1 , Q 2 , Q 3 and Q 4 on the right-hand side are clusters that make up a clustering Q . The smaller squares composing the rectangles are fragments. Lines connect a fragment in a P cluster to the corresponding fragment in the Q cluster.

To illustrate the notion of fragments, consider the situation in Fig. 3 . Here, cluster P 1 shares a fragment of size 3 with cluster Q 1 , and a fragment of size 2 with cluster Q 4 .Ithas no fragments in common with clusters Q 2 or Q 3 . All 4 elements of Cluster Q 2 are grouped together in cluster P 2 , and therefore Q 2 has only one fragment of size 4. Cluster P 2 ,onthe other hand, also contains additional fragments with clusters Q 1 and Q 3 .
 is the conditional probability P ( Q j | P i ) such that any element of P i is also an element of Q in P i . Clearly, when f ij / p i = 1, the entire cluster P i is a subset of the cluster Q j ,and conversely, if f ij / q j = 1, Q j is a subset of P i .

Next, consider the product of these two terms, f ij 2 / p i q j . This term provides a symmetric measure of mutual agreement or mutual concordance between the two clusters P i and Q j . P = Q j .

Let S be the sum of mutual concordance over all fragments, i.e. S = I i = 1 J j = 1 f So S takes on its maximum value iff f 2 ij / p i q j = 1forall i and j . This occurs iff P = Q ; in this case the value of S is equal to I (which is also equal to J ), the number of clusters. The minimum value of S is 1, and is attained when there is no relationship of concordance between P and Q , i.e. when every cluster P i is broken up into fragments whose sizes reflect the overall distribution of the data set into the clusters of Q . In this case, the elements of every P i are evenly distributed among the Q clusters (and vice versa), and fragment sizes take on their expected values given the marginal totals of the P and Q clusterings.
Figure 4 a, b and c illustrate the effect on S of various kinds of fragmentation. Figure 4 a represents a perfect match (no fragmentation) between clusters P i and Q j , so that they contribute 6  X  6 6  X  6 = 1tothesum S .InFig. 4 b, Q 1 has split into two clusters, Q 1 and Q 2 , In other words, merely splitting up a cluster does not detract from S (although, of course, the total number of clusters increases). S is reduced, however, by grouping the elements of the
The phenomenon in Fig. 4 b is quite general: whenever a single cluster in P (resp. Q ) can be decomposed entirely into a set of clusters in Q (resp. P ), then S is increased by 1. This suggests that the sum S is not entirely adequate as a measure of the amount of concordance between two clusterings. Situations analogous to Fig. 4 b need to be penalised for  X  X sing more clusters X  than situations analogous to Fig. 4 a.
 An obvious solution is to normalise S by a function of the number of clusters involved. There are a number of desirable characteristics which the normalization function and resulting normalized measure should exhibit. Firstly, as stated before, the range of values of the measure should be between 0 and 1 inclusive, with those extreme values being reserved for the worst and best cases respectively. Secondly, as the maximum attainable value for S is I when both P and Q consist of I clusters (so that I = J ), it is appropriate in that case to normalise by I (equivalently, J ). An appropriate normalization function should therefore take on the value I = J in this worst case. Thirdly, even when I = J , the value of the normalization function should be of the same order of magnitude as I and J . Fourthly, the normalization function should impose a penalty in cases of relatively greater fragmentation, and should treat I and J symmetrically. Possibly the simplest normalization function that satisfies these requirements is  X  Finally, then, MoC is defined as
This provides a measure of the degree of concordance between two clusterings P and Q , and takes on the value 0 for independence between P and Q ,and1when P = Q .

Another way to understand the MoC measure is in terms of the more familiar precision and recall measures, as follows. For every pair of clusters P i and Q j the I  X  J co-occurrence matrix F can be collapsed into a 2  X  2 contingency table, with the first row corresponding to P i and the second row to all other P clusters, and likewise the first column corresponding to Q j and the second column to all other Q clusters. Then, labeling the cells a , b , c and d as in Table 1 for convenience only, it is clear that a = f ij , b = p i  X  f ij , c = q j  X  f ij , and d = N  X  p i  X  q j + f ij ,where N is the total number of elements in D . In this case, the mutual concordance term f 2 ij / p i q j in the calculation of MoC is clearly the product of precision and recall obtained from this table. So MoC can alternatively be regarded as the (normalised) sum of the products of precision and recall over every 2  X  2 table induced over the cells of F . 4.1 Relationship to Pearson X  X  Chi-squared statistic There exists a close relationship between MoC and the familiar Pearson X  X  chi-squared (  X  2 ) statistic for the independence of two variables. Chi-squared can also be used to test for inde-pendence between the two clusterings P and Q . Using the marginal totals of the co-occurrence matrix defined by clusterings P and Q , the expected value for the size of fragment f ij is the expected values derived from the marginal totals. Note that the case where the obtained and expected values are the same corresponds to the case where the allocation of elements from any cluster P i to the clusters of Q follows the same distribution as the allocation of the entire set of elements to the clusters of Q .Inotherwords,no P i cluster has any particular affinity for any of the Q -clusters which could distinguish it from any other P -cluster. So there is no information about how the elements will be allocated to Q clusters when given the index i of the P -cluster. Clearly, this constitutes the situation of minimal relationship (maximal independence) between P and Q , and in this case,  X  2 = 0.

We can write  X  2 as
Thus, MoC is a normalized form of  X  2 . This means that a  X  2 value can easily be obtained given a MoC value and vice versa. From the  X  2 value, significance can be determined; note that this gives the significance of the departure of the P and Q distributions from a purely even co-distribution based on their marginal totals, rather than the significance of the association between P and Q .

Because  X  2 can take on an arbitrarily large value, it is not directly suitable for our purpose of expressing the strength of the association between the two clusterings. It is preferable to use a measure of association derived from  X  2 which has been normalized to range from 0 to 1. This suggests that MoC is one such suitable measure.
Two other popular measures of association that are derived from  X  2 , as discussed by [ 41 ], and that perform normalization somewhat differently, are the Cram X r and Tchouproff coefficients, given by
Note firstly, however, that both Cram X r X  X  and Tchouproff X  X  coefficients are undefined when either I = 1or J = 1. This seems to be a deficiency; in the case where (say) a clustering algorithm places all data elements in one cluster, we nevertheless would want to allocate a value to its concordance with the gold standard. MoC is defined to have a value even when I = 1or J = 1 (albeit by way of exception in the case where I = J = 1).

Furthermore, in some cases, Cram X r X  X  coefficient does not recognise departures from a perfect match between P and Q . Consider the situation in Fig. 5 .Thesum S is 3, because P 2 can be cleanly divided into Q 2 and Q 3 , so that the contribution to S from P 2 , Q 2 and Q 3 is 1, as discussed above. Then  X  c = 3 clearly not identical. MoC does not suffer from this problem, but instead gives a value of
Alternative normalizations of  X  2 have also been proposed, but suffer from these and other problems; for a general review see [ 21 ]. 5 Qualitative description of measure behaviour The following section describes the behaviour of the measures listed in Tables 4 and 5 under the worst-case situations discussed in Sect. 3 . Rather than performing an exhaustive quantitative analysis of the behaviour of each measure, specific clustering scenarios have been devised representing each of these cases and qualitative descriptions of the behaviour of the measures under these scenarios were collated. These qualitative descriptions are presented as broad characterizations of the general behaviour of these measures in the evenly distributed worst case, the perfectly matching best case and the conjugate worst case. These cases are characterized in terms of range and shape . Range describes the set of values attained by a function for the given test sequence, which should fall within the set of all values attainable by that function for its possible domain as described in the  X  X ange X  column of Tables 4 and 5 . Shape describes the plot formed by the set of values attained by a function for the given test sequence. To avoid artifacts due to limited precision in our simulations, we characterise a measure as taking on its extreme value if it differs by no more than some fixed value from that value, and as being constant at a value over an entire scenario if it varies by less than some fixed value throughout. In Scenarios 1 X 4, was set at 0 . 01, and in scenarios 5, was 0 . 05 (the reason for the difference is explained in Sect. 5.2 ). For convenience the different shapes are presented in  X  X ey X  format below in Fig. 6 .

Under these conditions we list the following observations regarding a , b , c and d (as defined in Table 1 ):  X  a and d decrease proportionally to the increase in b and c as members are shifted out of  X  b and c increase as members are shifted out of common clusters resulting in an increasing Range and shape key Following is a short summary of of the different graphical shapes and descriptor labels used to characterise a measure X  X  general behaviour for each given test.  X  Constant functions are indicated by the symbol C .  X  Linear functions are indicated by the symbol L , with a subscript of either F or R to  X  Non-linear functions are described in terms of whether the absolute value of their deri- X  Sigmoid functions can be described as piecewise functions assembled from a pair of  X  Functions which are undefined over the interval are indicated by a U .  X  Other functions are indicated by an X , however there is only one such function (Forbes 5.1 Testing on independently distributed clusterings 5.1.1 Incremental independence Scenario 1 demonstrates how each function reacts when incrementally increasing the amount of a partitioning that is independently distributed, while holding the number of members, fragments and clusters constant. This is achieved by comparing pairs of clusterings that range from being perfectly correlated with each other to being perfectly independent of each other, by systematically altering the original composition of clustering P according to the marginal totals of the clustering Q , in a series of 1000 increments of 0.1% at a time.

This scenario starts with the co-occurrence matrix in Table 7 which is incrementally added to using the matrix in Table 8 . After one thousand increments, the situation of total independence depicted in Table 9 is achieved.

Under these conditions, as defined in Table 1 , we list the following observations regarding a , b , c and d :  X  a and d decrease proportionally to the increase in b and c as members are shifted out of  X  b and c increase as members are shifted out of common clusters resulting in an increasing Expected results Given each function is tested against the continuum of perfect match (best) to total mismatch (worst), an appropriate result is one where the function produces a series of values that track from one extreme value to the other e.g. 1 X 0. As noted in the desiderata (see Sect. 3 ), a measure should depart rapidly from its best case value as soon as the partitions begin to differ. For this reason the preferred shape of a measure X  X  curve should be either D F , D R ,SDA F or SDA R .
 5.1.2 Scaling of the independent case Scenarios 2, 3 and 4 test the degree to which the different measures are insensitive to scale. In the independently co-distributed case of the previous section, there is a relationship between the number of data points in the set, the size of the fragment in each cell of the co-occurrence matrix, and the number of clusters in the two clusterings. These scenarios systematically examine the effect on the measures of manipulating an independent co-distribution by holding either the number of data points, the fragment size or the number of clusters constant, while incrementing the other two parameters.

Under these conditions the following observations are made regarding the effect on a , b , c and d : Scenario 2 Constant n , Cluster count increases and Fragment size decreases. This test keeps the number of elements in the data set constant, while changing the number of clusters.
This has the effect of decreasing the size of each fragment for increasing cluster sizes as there are fewer available elements in each cluster to intersect. Under these conditions the following observations are made:  X  a decreases to zero due to decreasing fragment size and thus reduced member pairs for  X  a decreases then increases  X  b and c decrease to n ((  X  b and c decrease  X  d increases as the available pairs for intersections ( a  X  X ) or complements ( b  X  X  and c  X  X )  X  d decreases Scenario 3 Constant Fragment Size, Cluster count increases and n increases. This test keeps the fragment size constant, while changing the number of clusters (this has the effect of increasing the number of elements in the data set which results in an increase in the number of fragments/pairs available as intersections ( a  X  X ) or complements ( b  X  X  and c  X  X ).
Under these conditions the following observations are made:  X  n is increasing  X  a , b , c and d increase as the available fragments for intersections ( a  X  X ), complements  X  a = ( p 2  X  b and c = n  X  d increases as more exclusive pairs can be formed between members in different clusters  X  a , b , c and d are decreasing .
 Scenario 4 Constant Cluster Count, Fragment Size increases and n increases. This test keeps the cluster count constant, while changing the fragment size (this has the effect of increasing the number of elements in the data set). Under these conditions the following observations are made:  X  n is increasing  X  a , b , c and d increase as n is increasing.
 Expected results As these scenarios are varying characteristics of an independent co-distribution the independence between the clusterings is maintained and so the result should be constant on the function X  X  worst-case (perfect mismatch) value. 5.2 Testing conjugate partitions Test 5 is used to demonstrate how each measure represents the difference between a range of different partitions and their conjugates. In addition, this test reflects a measure X  X  ability some partitions correspond to conjugate partitions with similar structure, in that they have similar distributions of cluster sizes, and some partitions correspond to conjugate partitions with dissimilar structure where the cluster size distributions of the two partitions are highly dissimilar. In many cases the independently co-distributed worst case and the conjugate worst case are one and the same. This happens whenever the distribution of cluster sizes is even (an equal number of elements in every cluster). For this reason, distributions of equal as well as unequal cluster sizes are considered.

To do this comparison the asymmetry of the partition was manipulated to reflect variation of structure across different membership distributions by holding n constant, and decreasing the slope of the distribution histogram by increasing the number of clusters. The value of the slope is given by 2 n I ,where I is the number of clusters in the partition. To produce cluster pairs (gold standard and conjugate) a fixed set of 5050 elements was used while varying the number of clusters. Specifically, the number of clusters was increased from 2, an almost asymmetric case (see Fig. 7 ) to 92, the almost symmetric case (see Fig. 8 ), in increments of 10. This results in a decreasing slope as the number of clusters increases where d decreases in size, while b and c increase (a is constant at zero). From each clustering generated in this way, the conjugate clustering was produced. Because of the discrete nature of the operation of conjugation, it was not always possible to generate an initial clustering of 5050 elements. Instead, for a given slope, the element set contained the nearest integral number of elements that would fit the slope; element set sizes ranged between 5,043 and 5,052. For this reason one should expect slight fluctuation in the value of a measure. In practice, we applied the threshold value (see the introduction of this section) of 0 . 05 in this case.

Under these conditions the following observations are made regarding the effect on a , b , c and d :  X  n is constant  X  a is zero in all cases as there are no fragments with size larger than 1  X  b and c increase as the slope of the first partition decreases toward the symmetric case  X  d decreases for the same reason b and c increase Expected results These scenarios represent situations of complete fragmentation. Even though the two partitions change in relative structure from being approximately asymmetric to being symmetric, we would nevertheless expect this structural difference not to affect the results greatly. Measures should attain a value equal or very near to their worst case value. 5.3 Results The following subsections describe the results of applying the five tests to the measures listed in Tables 4 and 5 . For those pair counting measures in Table 4 the Contingency matrix was formed first, then the appropriate fields applied against each measure, while the information theoretic measures in Table 5 were applied directly to an intersection matrix derived from the pair of clusterings in question. 5.3.1 Incremental independence of clustering pairs This test determines whether a measure recognizes levels of independent co-distribution (see Sect. 3.1 ) across the range of total dependence to total independence (see Sect. 5.1.1 ). To present the results four tables have been generated that categorise measures against different common features. Table 10 presents measures that realise a fixed extreme in the case of total dependence between clustering pairs. Table 11 presents measures that realise a fixed extreme in the case of total independence. Table 12 presents measures that do not realise a fixed extreme in the cases of total dependence and independence. Finally, Table 13 presents measures that realise a fixed extreme in both the total dependence and independence cases. These tables provide the following key observations:  X  If a function is a dissimilarity measure it displays an upward trend(shape = X  ), conver- X  The pair counting measures in Table 10 recognize total dependence because their nume- X  Because this test never realises the situation where a = 0 the pair counting measures in  X  Mutual Information would recognises total independence if it was normalised.  X  There is no obvious reason why the measures in Table 12 do not recognize either total  X  MoC and those other measures in Table 13 appropriately attained a fixed extreme for both  X  With only a few exceptions most measures moved rapidly away from their best case value, 5.3.2 Scaling on independent co-distribution tify those measures that realise a fixed extreme for all three scenarios. The measures are also presented in groups to enable the categorisation of measures against the following criteria: 1. Identify groups of measures that realise a fixed extreme (worst case) for all three scaling 2. Identify groups of measures that realise a fixed extreme (worst case) for any one of the 3. Identify groups of measures that react in the same manner under the three scenarios. 4. Identify those measures that do not fulfill categories 1, 2 or 3.

Ta b l e 14 is divided into four groupings of measures that highlight specified combinations of criterion. Group A addresses both criteria 2 and 3 by grouping measures that both realise a fixed extreme for any one of the three scaling tests, and by grouping measures that react in the same manner for the three tests. Group C addresses criterion 3 by grouping measures that react in the same manner for the three tests. Group D addresses criterion 4 by grouping measures that do not fall into any of the other categories. Group B functions produce the appropriate result described by criterion 1 by grouping measures that realise a fixed extreme for the three tests. 5.3.3 Incremental conjugation of partition pairs The result of conjugating a partition is a partition whose clusters have no pairs in common with its original state and is thus totally independent, one of our worst cases scenarios. Some measures however recognise structure as an measurable distributional feature resulting in different outcomes for different shaped original partitions. This test is used to identify those measures that recognise the conjugate of a partition, either symmetric or non-symmetric, as a worst case scenario and realise a worst case fixed extreme.
 Ta b l e 15 lists those measures that recognize structural difference and those that do not. The division in results can generally be explained by a measure either recognizing d or not, as with the inclusion of d the total space is recognized, not just some membership differential described by differences between a , b and c . 5.3.4 Comparison based on the combination of all tests There are no formal methods to categorise these measures against the manner in which they perform other than to broadly group them along lines such as being an information theoretic or pair counting based approach, or by comparing them against subjective criteria. In an attempt to categorise, and compare and contrast MoC X  X  performance against the other measures a subjective clustering was conducted resulting in the six broad groups. The measures were grouped together if they behaved similarly across the different scenarios,  X  X imilarly X  meaning that the curves proceed in the same direction (upward or downward) and between similar points. For the purpose of comparing points, we considered a measure X  X  minimal and maximal values and marked values that fall between extremes with an asterisk (as described above). of similarity measures for example, they move from their maximal value down to a non-minimal value under the Incremental Independence scenario. The dissimilarity measures (e.g. Sokal and Sneath, Savage) in this group also exhibit the same pattern of behaviour but move in the opposite direction (e.g. rising from a minimal value under the same scenario). Ta b l e 16 is sorted into each of six groups with the behaviour of each measure under each scenario being displayed allowing the commonalities between patterns of behaviour to be discerned.
 Group I Loosely consists of measures that express ratios of good to bad; that is, the number of pairs two clusterings have in common ( a ) divided by the number of pairs the two clusterings do not have in common ( b + c ). The majority of this group of measures are similarity measures with the exception of the Savage and Sokal and Sneath mon-metric measures that are dissimilarity measures. These two measures still conform to being measures of good-to-bad in that the Savage measure is an inverted form of either Dice Asymmetric 1 or 2 measures depending on which is the larger, and the Sokal and Sneath Non-Metric is a comparison of the pairs two clusterings do not have in common ( b + c ) divided by the number of pairs the two clusterings have in common ( a ). A standout feature of this group is that it is mainly comprised of measures that for at least one test appropriately realise a fixed extreme for the worst and/or best cases. Prototypical measures in Group I include the asymmetric Dice measures ( a a + b and a a + c , also known as precision and recall) and Jaccard ( a a + b + c ).
 Group II Also consists mostly of measures expressing ratios of good to bad. However, whereas Group I measures consider only contingency matrix cell a , Group II measures also take the cell d into account and express the ratios of a and b  X  X gainst b and c .A similarity measures with the exception of the Sneath Total Difference measure, Filkov X  X  measure and Mirkin X  X  measure, which are dissimilarity measures, and which are all based on the number of pairs the two clusterings do not have in common ( b + c ).
 Group III Represent measures that react similarly across the three scaling tests (see Sect. 5.3.2 ), realise a worst case extreme or thereabouts in the Conjugate Test (see Sect. 5.3.3 ) and that track sigmoidally across their ranges in the Incremental Independence test. Group IV Is a relatively small group of Information Theoretic measures grouped in this manner because they perform very similarly across all tests and all are measures of dis-similarity. The Mutual Information, Mountford and Michael measures can be seen as intermediary cases between this group and Group V.
 Group V Can be described as (i) for the most part, recognizing increasingly independent distributions by moving between the extreme values in their range, while (ii) being invariant in the independent case under scaling. Importantly, in the conjugate case, the measures MoC, NMI 1 and NMI 4 remain constant on their worst-case values.
 Group VI Conatains all other measures that do not seem to associate significantly with any other measures.

Therefore, of all the measures only MoC, NMI 1 and NMI 4 clearly satisfied all our desired requirements (see Sect. 3 ). However, under close inspection of the results it was noted that for the conjugate case the Powers X  X  measure, Lopez and Rajski X  X  measure and NMI 5 remained constant near their worst-case value and so fundamentally also address all of our desiderata. This result clearly supports remarks by, e.g. [ 56 , 64 ]and[ 38 ] regarding the usefulness of Mutual Information for clustering comparison. 6Conclusion Given the widespread use of clustering techniques in the presentation of apparently contex-tually pertinent data to humans and the general reliance on fixed heuristics rather than dynamic human context, there is much scope for fundamental research in this area.

Toward this end, this paper has focused on comparing the relative subgroup member-ships of two clusterings. To study pair counting measures, 2  X  2 contingency matrices (see Fig. 1 ) were used as a convenient way to summarize the relationships between the mem-berships of two subclusters. Although contingency tables are traditionally used to compare two populations they have been used here to compare two partitioned spaces through the application of a pair counting approach to assign values to the individual fields of the matrix. Key relationships between clustering pairs are identified by comparing relationships between the occurrence of member pairs, member non-pairs and member pairs that do not occur in common using the 2  X  2 contingency matrix. In addition a number of information theoretic measures were also investigated.

To compare clustering pairs using external features the two types of worst case were identified as unrelated clustering pairs and opposite partitions which are described as Inde-pendently Codistributed Clustering Pairs and Conjugate Partition Pairs . These situations were applied to the development of a measure (MoC) to appropriately recognise these cases and in the search for other measures that may react similarly or the same. They were also used to identify groups of measures with similar features to allow researchers to choose between general classes of measures exhibiting similar behaviour.

MoC X  X  logical development was supported by five tests used to demonstrate the charac-teristics of MoC and a selection of other measures. The individual tests produced distinct groupings as did the combined results.

The combined results (see Sect. 5.3.4 ) demonstrated that the measures in Group V confor-med to many of our desiderata as stated in Sect. 3 . In particular, the MoC measure, Powers X  X  measure, Lopez and Rajski X  X  measure and the six Normalized Mutual Information measures complied with our requirements 1, 2, 4, 5 and 6. As for requirement 3, these measures reco-gnised the worst case of mutual independence between clusterings whereas only MoC, NMI 1 and NMI 4 strictly recognised the conjugate case (corresponding to complete fragmenta-tion) by realising their worst case value. However, for all intents and purposes the Powers X  X  measure, Lopez and Rajski X  X  measure and NMI 5 appropriatly recognise the conjugate case by remaining constant at a value near their worst-case value. By contrast, the unnormalized information theoretic measures in Group IV were all found to combine an absolute mea-sure of goodness into the comparison viz. there is an extra term that reflects the information content of the clusterings.
 References Author biographies
