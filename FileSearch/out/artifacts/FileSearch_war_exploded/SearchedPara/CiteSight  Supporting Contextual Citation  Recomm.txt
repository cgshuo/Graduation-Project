 A person often uses a single search engine for very different tasks. For example, an author editing a manuscript may use the same academic search engine to find the latest work on a particular topic or to find the correct citation for a familiar article. The au-thor X  X  tolerance for latency and accuracy may vary according to task. However, search engines ty pically employ a consistent ap-proach for processing all queries. In this paper we explore how a range of search needs and expect ations can be supported within a single search system using differential search . We introduce CiteSight , a system that provides pe rsonalized citation recommen-dations to author groups that vary based on task. CiteSight pre-sents cached recommendations instantaneously for online tasks (e.g., active paper writing), and refines these recommendations in the background for offline tasks (e.g., future literature review). We develop an active cache-warming process to enhance the sys-tem as the author works, and context-coupling, a technique for augment sparse citation networks. By evaluating the quality of the recommendations and collecting user feedback, we show that differential search can provide a high level of accuracy for differ-ent tasks on different time scales. We believe that differential search can be used in many situations where the user X  X  tolerance for latency and desired response vary dramatically based on use. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval  X  search process. Citation recommendation, personal ization, differential search. The act of citation in academic work is a critical piece of scientific production. Citations are used to assign credit, justify decisions, norm behavior, and increase awareness of one X  X  own work. Re-search on these motivations has become a  X  X ottage industry X  [3], generating a vast array of typol ogies and classification schemes. While the act of citing is ultimately the same regardless of moti-vation, the execution of citation wo rk varies dramatically and has led to a large ecosystem of workfl ows, datasets, tools, and search engines that address different aspects of the problem. While idealized citation work may involve a set of co-authors obtaining, interpreting, synthesizing, and indexing all relevant citations prior to writing a paper, in reality the process includes many different tasks done by diffe rent individuals at different times. During paper writing, for example, an author may draw from existing knowledge of related literature to reference a specif-ic paper that they know well. Or they may find themselves making an argument that requires finding and analyzing papers they have not read. They may also preform self-audits at the completion of writing to ensure appropriate citati on of the latest work [6]. Each of these citation behaviors has a different tolerance for novelty, latency, and accuracy, and is done with different competing atten-tional demands. As a result, each activity is typically supported in a different way. For example, EndNote X  X  Cite While You Write allows authors to reference speci fic citations without leaving the context of the paper. For the more ambiguous citation needs that come up during writing, authors sometimes use the text of the paper itself, leaving notes for them selves or coauthors (e.g.,  X  X al-ice: citation?] X ) that are addressed at a later time using an academ-ic search engine, general sear ch engine, or other means. We present CiteSight, a differential search system that provides contextualized citation recommenda tions using the most appropri-ate contexts and approaches to match authors various needs as they write a paper. Differential search reflects a class of search infrastructures where different use cases require different levels of service. For example, CiteSight caches highly relevant, personal-ized, content related to the paper X  X  authors, venue, and existing citations, and searches through th is content to instantaneously identify relevant citations as a person writes. Simultaneously, CiteSight performs a deeper analysis on the broader literature in the background that can be accessed when the author is ready to consider other relevant literature. CiteSight indexes metadata for over 2.3M Computer Science manuscripts provided by Microsoft Academic. While the corpus is small by Web standards, queryin g over it is computationally ex-pensive because our queries are long and complex, and many features must be dynamically ca lculated using text and network structure. Providing recommendations in near real time X  X  desira-ble feature to limit disruption of writing  X  X low X  [24] X  X ecessitates a tradeoff. Either one settles for faster features with worse per-formance, or restricts the size of the database. CiteSight achieves an effective compromise by pre-caching documents that are likely targets of inline citation: those the author is most likely to know. By mining our repository for past behavior, features such as who the authors are and what venue is being targeted can be used to personalize the cache and increase the hit rate. Additionally, dy-namic monitoring of local behavior s, such as citations in the working manuscript can enhance the cache through the identifica-tion of co-cited literature. While cached results are provided near-ly instantaneously, CiteSight continues to search the full index by responding to additional user hints and updating results to make broader recommendations for literature to read. An additional challenge of citati on recommendation is that it often requires recommending items for which there is very little infor-mation. While we would like to us e past citation behavior as a hint for the appropriateness of a particular recommendation, cita-tions are power-law distributed (w ith a cut-off) [8]. This means that most papers are rarely ci ted and have minimal citation con-text. CiteSight introduces citation-coupling as a way to enrich the citation graph by borrowing contexts from related papers. Citation recommendation is representative of a broad class of problems where search and recommender systems are integrated with user interfaces. Differential search captures the idea that, depending on the task, end-users have different criteria for evalu-ating and using the results. Differences may range from the laten-cy required for certain tasks but may also focus on other factors such as the novelty of results. By understanding that the demands of the user, in relation to the  X  X ntelligent X  component, can vary significantly given what the end-user knows, needs, and wants, it is possible to create systems that can better support this variation. The contribution of this work in cludes an architecture to support the varied citations tasks ranging from sub-10ms inline recom-mendations to  X  X eeper X  queries. To support this mechanism we introduce a dynamic, personalized cache-warming technique that makes use of a range of signals to improve performance. We addi-tionally describe context-coupling, a technique to enhance sparse network structures to support be tter recommendati ons. Finally, we describe ways in which the design of CiteSight can support a range of enhanced  X  X low search X  [39] features including collabo-rative search, summarization, and citation audits. Significant research has been devoted to identifying the papers that are the most likely to be referenced by a given manuscript. Techniques explored include colla borative filtering [24][42], topic modeling [10][19][28][37], machine learning [5][36] and machine translation [14][18][21]. CiteSight leverages these to identify relevant citations, and extends them through a novel context-coupling technique that augm ents paper descriptions. A number of citation management systems have been built using these techniques. For example, TheAdvisor [20] expands the bib-liography entered by an author to identify related papers in the citation graph, seeded by a keyw ord-based query. Scienstein [12] allows authors to submit entire papers with their associated bibli-ography to find related work. CiteSense [45] helps users make sense of literature via an interface that provides a screen with papers citing or cited by the reviewed paper along with the cita-tion contexts that serve as contextual cues. CiteSight extends this work by supporting a variety of di fferent types of citation related tasks, such as the inline identification of targeted reference. Some citation management systems act as intermediaries between the user and academic search engines (e.g., Google Scholar, CiteseerX and Microsoft Academic Search) [34][45]. For exam-ple, ActiveCite [34] provides recommendations by forwarding searches to Google Scholar and integrating the results. Because CiteSight uses its own recomme ndation engine, it can offer per-sonalized recommendations and take into account the interaction of the user with the system when ranking recommendations. Personalization is used extensively and effectively in Web search, driven by user features such as demographics [41], session context [4], and past queries [40]. As is the case for web search [38] and browsing [2], we find that citation behavior is consistent within individuals and use this to our advantage. Cite Sight leverages features unique to academic writing, such as paper structure, au-thors, venues, and citation behavior. We are only aware of one other research project that provi des personalization for scholarly search [5], in which machine learning is used to refocus queries to an academic search engine. Additionally, reference management and social bookmarking tools like Mendeley, Zotero and CiteULike exploit users X  profiles and apply collaborative filtering to enhance their search engine. Google Scholar provides a service that recommends newly published ar ticles to users based on their publication history. While the se rvice offers personalized recom-mendations, it does so based on past publications only. As such it can help users keep up to date with research that is related to their past research, but it does not suppor t interactive search for papers relevant to current interests. While personalization tailors results to an individual, multiple authors often write academic papers and the citations must reflect all of their backgrounds. Citation search is, in effect, a collaborative search problem [30][33], and CiteSight uses this to personalize (or  X  X roupize X  [41]) its results for multiple authors. Search engines are used for many different purposes, ranging from navigational queries targeted at individual webpages to ex-ploratory searches [23][44]. To address this, recent information retrieval research has explored the optimization of multiple objec-tives. For example, Bennett et al. [4] personalize search results using short-term search session behavior and long-term search behavior differently based on user behavior. Of particular rele-vance to CiteSight is the notion of slow search [39], which ex-plores how to optimize search for time constraints beyond the traditional tight constraints adhered to by commercial search en-gines. CiteSight X  X  architecture represents one approach to the slow search problem by operating on a variety of time scales, from milliseconds (when hitting the c ache), to seconds (when compu-ting global recommendations), to longer (when collaborating au-thors leave notes like  X  X lice: please insert relevant citation here X ). Almost all citation recommendation systems require the user to leave the context of a manuscript to find citations. However, sys-tem s such as the Remembrance Agent [31] are designed to facili-tate associative memory by cont inuously displaying in situ infor-mation that might be relevant to content recently typed by a user. This approach focuses on previously-seen information. We draw inspiration from this approach for the presentation of information in-line with the task but extend it to support background pro-cessing. He et al. [15] identify sentences where adding a citation might be appropriate, along w ith the corresponding citation. This paper presents a novel system for citation recommendation with a unique, integrated user experience. CiteSight builds on existing citation prediction rese arch by introducing a context-coupling technique to augment what is known about individual papers. It also identifies the appropriate context needed to provide personalized citation recommendati ons to author groups on vary-ing time scales. Th is allows CiteSight to support a greater variety of citation related tasks than previous systems, including the inline identification of targeted reference. We begin our discussion of the Cite Sight system by describing the user experience. In subsequent sections, we explain how the sys-tem is implemented, evaluate the quality and speed of the citation recommendations it produces, and discuss how the system works in practice using a small-scale qualitative user study. The CiteSight backend was designed and implemented as an API so that it could function with a variety of front-ends (e.g., Word or Emacs). For demonstration and evaluation purposes, we imple-mented a limited, but functional, Web-based prototype, shown in Figure 1. An author creates and edits a manuscript in the main text region (Figure 1(6)). Additional te xt fields allow the author to enter metadata such as their name and coauthors (1), the title (2), keywords (3), the venue for submi ssion (4), and abstract (5). Alt-hough no metadata are required, CiteSight can make use of them to provide the best possible recommendations. Author and venue names are autocompleted from our large database, in part to make this quick for the author, and in part to eliminate ambiguity in which personalized models to load. Various objects (e.g., authors, papers, and venues) are linked to the Microsoft Academic site. Once entered, the different fields provide context for the citation recommendation process. Whenever a field is changed via the CiteSight client, the new content is fed back to the backend sys-tem, and used to populate the cache and generate recommenda-tions. Once the user is satisfied w ith their work, the system allows authors to export the text with the citations embedded in LaTeX format, along with the bibliography in BibTeX format. While editing a manuscript, ci tation recommendations are provid-ed in two forms to support differ ent citation creation tasks: as local inline recommendations (Figure 1(7)), and as global recom-mendations (Figure 1(8)). CiteSight allows authors to easily search for and include the ap-propriate citation references as they enter text into the main text window shown in Figure 1 (6). Cite Sight  X  X ueries X  consist of the citation content (the entered text) and contextual information (e.g., author, venue, other selected citations, etc.) which are evaluated by the server to generate recommendations. To reduce distrac-tions to the author [7][9], CiteSight recommendations are only triggered when an author opens a citation bracket ( X  X  X ). This pro-duces a list of up to ten papers in a popup window (Figure 1 (7)). Papers are identified in this lis t with a short summary that in-cludes title, authors and publicati on date. The CiteSight user can accept one of the recommendations by selecting it. When a rec-ommendation has been accepted, a citation to the paper is added inline and the paper is added to the bibliography. Initial recommendations for the inline process rely on the CiteSight cache, and thus can be delivered nearly instantaneously. If the author leaves the reco mmendation window open, new sug-gestions are automatically delivered from the full CiteSight index. We informally experimented with mechanisms for delivering these new results, including showing an entirely new result list or appending new results to the end of the existing list. We settled on complete replacement as we found that there was often sufficient time for the author to skim and select from the list before it was changed. Sometimes, the original cache-based recommendations will reappear in this revised list but this is not required. If the displayed results are unsatisfactory or the author ignores them, they may type additional text to refine the recommenda-tions. As long as the citation br acket is open, the recommendation list is filtered using the typed terms. For example, in Figure 1 if the author were to type  X  X ruce Croft X  while the recommendation list is open, the list would be updated to show papers written by that author. Entered text that matches the paper summary is auto-matically highlighted in the filtered results. If the author accepts a recommendation, the hint text is replaced by the recommendation. If the author chooses not to accept a recommendation, they can instead leave a placeholder (e.g.,  X  X cite] X  or  X  X add citation] X ), and  X  X eave placeholder X  is an expl icit option provided in the inline recommendation drop-down box. In this way, the system naturally supports leaving citation-related notes to oneself or one X  X  collabo-rators (e.g.,  X  X Alice: please ad d reference] X ). While placeholders help remind the authors to return, they further serve as a hint to the system that it should continue to search for relevant recom-mendations within the given context, identifying content that may take significant time to find. Author can receive new citation rec-ommendations by returning to the placeholder and clicking on it. For placeholders that include a re quest for a coauthor, when that coauthor begins editing they can receive recommendations per-sonalized to their citation history. The CiteSight interface also pro vides global recommendations to support the exploration of generally relevant papers (Figure 1(8)). The motivation is to offer a service similar to e-commerce X  X   X  X us-tomers who bought this item bought these items as well X  to help the authors identify potentially unknown papers. High-level metadata, including t itle, authors, and venue, is pro-vided for each recommended paper. The CiteSight user can click on any of the globally recommended papers to see the correspond-ing entity page on the academic search site and download the paper, if available. The global recommendation list is dynamically updated as the user progresses through paper editing or the system discovers interesting citations through deeper, offline analysis. CiteSight currently restricts th e number of updates to the global recommendation list by ignoring certain changes. In particular, global recommendations are not identified based on the text used within the body paper, as the local inline recommendations are. Instead, they are based on meta-dat a and co-citation patterns, with papers boosted that were frequently co-cited with papers already cited in the manuscript. This proce ss is described in greater detail in Section 4.3.2. We believe it is worth exploring different mech-anisms for displaying new results to find an optimal solution that is non-disruptive but ensures high precision and recall. We now discuss how the CiteSight system is implemented. An illustration of the CiteSight recommendation process is shown in Figure 2. As an author enters conten t in the client (a), that infor-mation is constantly sent to th e server. For example, when an author edits their manuscript, or enters metadata (e.g., authors or title), the server receives the new content. The server then issues this content as a semi-structured query (b) to a set of indices (d+g) to generate a ranked list of reco mmended citations (c). This pro-cess consists of two procedures: candidate retrieval and ranking (as seen in the search loops in the figure). The ranking procedure is applied up to two times: once on cached papers and again after more candidate papers are retrie ved from the full index. A second piece of CiteSight (labeled as caching loop ) constantly warms (h) the cache (g) with papers a nd pre-calculated features. CiteSight uses Lucene [22] to index a corpus of academic papers provided by Microsoft Academic . Our prototype includes 2.3M Computer Science papers from 19 70-2010 (inclusive), written by 19 million disambiguated authors and published at 20,077 venues. We include only papers that were cited 3 or more times to reduce noise and improve performance. Microsoft Academic X  X  database provides citation information, including the citations from one paper to another and the specific sentences in a paper in which the reference occurs (which we refer to as the citation context). For example, a paper A may be cited by another paper B. The authors of B include a sentence such as:  X  X mith et al., described the firs t use of the ABC procedure [A]. X  This sentence is one of the citatio n contexts for paper A (clearly, a paper may have many citation cont exts). Previous research has found that using a paper X  X  citation context to identify relevant papers can lead to higher recommendation accuracy than using the paper X  X  abstract or full-text [16]. These contexts directly map to our task as it is possible that two authors X  X  previous one, and our CiteSight user X  X ill refer to the same paper in similar ways. To leverage the different text elements, we index the title, abstract, and citation contexts of each paper. In addition to these textual fe atures, CiteSight uses additional indexed paper metadata for ranking including authorship, citation count, publication venue, and re ferences (both incoming and out-going). Additionally, we store author metadata including the au-thor X  X  name, published papers, and number of times each paper was cited (e.g., to calculate H-or G-index style statistics for an author). Finally, we record venue metadata including the venue-to-venue citations and co-citatio ns and rough estimates of venue reputation (e.g., a venue-based H-index). CiteSight was designed to also include personal paper repositories (e.g., CiteULike, Endnote, or Zotero). While these would likely improve recommendation performance, a large quantity of such personal repositories was not available to us. Thus, in this paper, we focus exclusively on the academic search engine data. Citation context has been shown to be valuable for identifying relevant citations [16]. However, many papers have very limited citation data [8]. In order to enri ch citation contexts for rarely-cited papers, we introduce a novel technique, context-coupling, to impute citation contexts. Context-coupling effectively imputes citation contexts for low-citation papers by leveraging the con-texts of similar papers. For our purpos e, the similarity of papers is determined by the structure of the citation network. Consider for example the citation network illustrated in Figure 3. Document A is the paper  X  X  pr oximity language model for infor-mation retrieval X  and paper B is  X  X n exploration of proximity measures in information retr ieval. X  The two documents are deemed similar to each other as they are co-cited several times. For example, paper D,  X  X  proximi ty probabilistic model for in-formation retrieval X  mentions bot h A and B. In our hypothetical example, A has only a handful of citation contexts which we would like to expand to better de scribe paper A. To do so, we wish to propagate to A some of the contexts describing similar papers. For example, paper E  X  X nve stigation of partial query prox-imity in web search X  cites B using the following text X   X ... In addition to the traditional criteria concerning individual query terms such as tf and idf, the prox imity between query terms in a document is often believed to be a useful criterion for document ranking... X  This citation context could also adequately describe paper A and is a good candidate for coupling . The context-coupling algorithm consists of two steps. First, for each paper we find the most similar co-cited papers. We utilize the Adamic-Adar [1] similarity metric computed over the incom-ing links (as we wish to identify papers that are referenced simi-larly). In the next step, we scan all the citation contexts to each of the most similar papers identified in step one. We compare each citation context with the citation contexts already available for the target paper and copy them, treating them as if they were attribut-ed to the target paper. The similarity of each citation context is computed using cosine similarity over the TF-IDF representation of the citation context and the content originally available for the target paper (receiving equal weight in the prototype) CiteSight uses context-coupling to enrich citation context when the papers are indexed. We also experimented with a variant of forward aggregation which was proposed by Metzler et al. [26]. In this approach, content is pr opagated transitively (e.g., G  X  A in Figure 3). However, unlike Metzler et al. X  X  approach, where all contexts are copied, we propagate only the most similar contexts. The resulting index is large. In particular, it is large enough that it is impossible to pre-compute and keep updated all of the contex-tual meta-data features for each paper in the index that that system uses for ranking. Identify relevant papers in the index and compu-ting the related meta-data features in response to a query can take half a second or longer. This is too slow to support real-time in-teraction. Existing research sugg ests that for a computer X  X  re-sponse to appear instantaneous, it must respond in less than 100 milliseconds [27]. To support a fa ster response time, CiteSight uses a cache with a dynamic cache warming system (see the cache  X  X oop X  in Figure 2). By restricting the number of papers in the cache (~1000 to 2000 in a given session) and pre-calculating vari-ous features as papers are loaded into the cache, response rates can be pushed to under 10 milliseconds. As is the case for the primary index, papers in the cache are in-dexed by Lucene using their title, abstract, and citation context. However, the meta-data related features (see Section 4.3) used for ranking are pre-computed for each paper. The cache contains the subset of papers that are identified as likely to be relevant to the author and paper being written. While we may like to identify those papers that an author is fa miliar with this is not realistic. Instead, we optimistically cache those papers that are likely rele-vant, erring on the side of recall. The cache warming subsystem (Figure 2 (h)) monitors various user-driven events and dynamical ly updates the cache. For exam-ple, when an author begins usi ng CiteSight they enter their names and the names of their co-authors. For every author in the authors list, the cache warmer finds all papers that were cited at least three times in the past by that author are included. The content of the cache is updated as the paper is written. Whenever the title, ab-stract, or keywords of the curre nt manuscript change, the system issues the new content in the background as a query to the larger index of papers and collects the hundred most relevant results to add to the cache. Finally, whenever the user chooses to add a pa-per to the bibliography, all the co -citations of that paper and its references are added to the cache as well We now look at how the CiteSight index and cache are used to retrieve inline and global recommendations. When an author opens a citatio n bracket, CiteSight uses the 50 words before and after that bracket as the citation context. Words beyond the limits of a paragraph, as determined by line breaks, are ignored. The citation context is used to search the cache (line 2 in Figure 2, and, at the same time, to search the larger primary index (line 5). The cache-based recommendations offer an instant re-sponse while less familiar recommendations are being examined. Once the top 500 papers are retrieved from the primary index and the appropriate features are computed, they are ranked along with the cached candidates. As described above, there are a number of different possible strategies to integrate these results for display in the interface (e.g., replacement, interleaving, etc.). For the pur-poses of the prototype, we opted to use the replacement strategy. The initial cached candidates and, later, the full set of candidates, are ranked using ranker learned us ing gradient boosted regression trees (GBDTs) [11][46]. GBDTs produce a prediction model in the form of a collection of decision trees. The approach is widely used, adaptable, interpretable, and produces highl y accurate mod-els. Additionally, in our experience they performed better than linear regression or support vector machines. We utilized the following featur es as input to the learner: Citation context similarity : This feature measures the similarity between the text an author has just entered into CiteSight and any text that has been used in the past to cite the candidate paper using a standard cosine similarity (over a TFIDF weighted term vector). The intuition behind this feature is that new citation contexts are likely to repeat old patterns when referring to the paper. For cached recommendation, a citation context similarity score is computed for all candidates, as they typically number less than 200. However, as the candidate set may be much larger when retrieved for the full corpus, onl y the top 500 relevant candidates (identified using Lucene X  X  built-in TFIDF/vector-based, ranking scheme) are scored; all other candidates receive a score of zero. Figure 3. An illustration of the context-coupling approach. 
To enrich the citation context available for a paper, we impute citation contexts for low-citation papers by lever-aging the contexts of similar papers Title/Abstract/Keyw ords similarity : To capture the textual similar-ity of a paper to the current manuscript we measure the similarity between the title, abstract and keywords of each. Each of these three fields is held in a separate Lucene field. As before, similarity is computed as cosine similarity over their TFIDF vector. Citation count : As popular papers are likely to remain popular and be cited again, this feature count s the number of citations a paper attracted from all the papers in the corpus. Numerous citations often indicate the candidate paper is important and that authors should at least have awareness of it. Author similarity: This feature measures the similarity between all authors of the manuscript and the authors of a candidate paper. The similarity is computed as the Jaccard index between the two author sets. A different way to think of this feature is as a self-citation indicator that boosts papers written by the authors of the current paper. This function can be biased so that the current au-thor (i.e., the one editing) weighs more heavily. Author history : For each candidate paper, we count the number of times it was cited in the past by the authors of the current manu-script. We set this feature to be the mean number of times the authors (if there are more than one) cited the candidate paper. This feature naturally boosts the score of papers that were cited by the authors in the past and reflects the tendency of an author to con-sistently cite the same papers [43]. Venue relevancy : This feature measures how relevant the venue is in which a candidate paper was published to the venue to which the currently edited manuscript is targeted. The value of this fea-ture is set to be the frequency at which papers published in the targeted venue cite papers published in the venue of the candidate paper. This feature captures the tendency of authors to cater their results to specific outlets [13]. Citations from cited papers : To boost the scores given the current editing session, we measure the number of times the candidate paper was cited by papers that were already added as references to the manuscript (averaged over thes e references). This supports the chaining that sometimes happens as an author explores the refer-ences of references. Co-citations with cited papers : Similarly to chaining, we measures the number of times th e candidate paper was co-cited with previously selected referenc es. This feature boosts candidates in the spirit of  X  X uthors who cite d X also cited Y. X  We expect this feature to be superior in cases where new papers extend previous work, making the earlier work obsolete. While some features are stable (e.g., author similarity, venue rele-vancy, etc.), others change as the author modifies the paper (e.g., citation context similarity or feat ures that take into account other papers cited in the session). Practically, this means that while all features can be computed and cached, some do require recalcula-tion if the paper changes. However, because the cache is relatively small, recalculating these invalidated features is not expensive. In addition to inline recommendations, CiteSight also suggests citations that are relevant to the entire paper. There are a number of ways global recommendations can be identified, including by searching the full index. However, given the papers in the cache are intended to be broadly relevant to the edited paper, we found that we could use the cached papers to identify global recommen-dations. To do this, we simply utilize the cache without the cita-tion context similarity score feature. The remaining features are again used to rank the documents using the gradient boosted deci-sion tree described above, and th e top results are shown to the user at the bottom of the interface. Though we might lower the importance of different similarity metrics to provide more  X  X eren-dipity X  or  X  X iversity X  in these results, further work is necessary to find the balance of relevance to serendipity/diversity. In summary, CiteSight indexes a corpus of academic papers using paper meta-data and citation context, and uses this index to identi-fy citation recommendations. Alt hough the citation context avail-able for any given paper can be sparse, the system enriches what is available using context-coupling. This results in an index that contains valuable information, but that it is too large to provide the instantaneous response needed fo r a real-time text editing tool. For this reason, CiteSight maintains a cache that monitors various user-driven events and dynamically updates so that it can make the most relevant papers availa ble on a moment X  X  notice. This cache is further used to identify the most relevant global citations. Because the global citation problem is well studied in previous work, we focus on evaluating the quality of the inline recommen-dations. We show that citation c ontext coupling significantly im-proves the quality of the inline recommendations the system pro-vides, and that citation-related f eatures are particularly valuable for ranking. Personalization appears very important, with the cita-tion history of authors contributi ng significantly and performance improving with more authors. We also look at the influence of the cache on the differential search experience, finding the cache provides accurate recommendation in many cases with minimal latency. In the next section, we present feedback from users of the CiteSight system. The server used for both training and testing was a 12-core server (2 Six-Core AMD Opteron(tm) Processor 2431 2.4GHz with 48Gb of RAM). We evaluated the recommendations made by the CiteSight system by looking at how well it would have performed for existing pa-pers where the set of citations is already known. Arguably, this serves as a reasonable ground trut h as references from these pa-pers were deemed relevant to th e paper by the expert authors who chose to cite them. The reality, however, is that authors must often balance space requirements against the need of citing all relevant 
Figure 4. Recommendations accuracy vs. number of pre-viously selected papers (top) and number of authors (in-set). CiteSight performs bett er as authors and citations are added, up to a point. Having a bibliography larger than 11 papers does not lead to additional improvement papers. Because of this, many relevant and appropriate recom-mended citations would be judged as incorrect. We believe that in the absence of complete data, a fairer test is one that also includes possible  X  X eplacement X  or  X  X ugmen tation X  citations as relevant. That is, a citation to paper A might be replaced or augmented with a citation to paper B. To identify these automatically, we use the idea that both replacement and augmented citations are likely to have been co-cited in the past with the  X  X rue X  reference. We dis-tinguish between  X  X rue X  citations and  X  X econdary X  citations. True citations (reference A in the example above) are those citations that actually exist in the source paper. These receive a relevancy score of 1 (the max). Secondary citations (reference B) are those that co-cited with the true cite. They receive a relevancy score proportional to the number of times the secondary paper is co-cited with the true citation (0  X  score  X  1). We created a test dataset of 10 00 randomly selected CS papers published in 2011, the year after the last paper included in the CiteSight corpus. Only 0.1% of all citations in these papers refer-enced a paper published in 2011, and we omit these references. Papers were required to have be tween 20 and 40 references as a rough way to eliminate papers that were incorrectly parsed for citations. The median number of c itations made by papers in the test set was 25. The mean and me dian length of the citation con-texts for this dataset were 158.3 and 153 characters respectively. On average, all papers in the dataset had 4.3 citation contexts. We used a 5-fold cross validation approach in which 80% of the papers were used for training a nd the remaining were used for testing. In the training phase we used the candidate papers of all the references of the training paper to train a gradient boosted regression trees model. We then applied the model on the candi-dates of each reference of the test papers and ranked the candi-dates based on the model X  X  prediction. To measure the performance of the system, each paper X  X  refer-ences were considered independently using a normalized dis-counted cumulative gain metric . DCG and NDCG are defined as: where IDCG p is the ideal DCG p , achieved by optimally ranking the retrieved documents and p is the number of documents used for evaluation (5 or 10 in our case). In calculating the gain, only one document (the true citation t ) receives a gain of 1 (the perfect relevancy score, i.e., rel secondary ( s ) citations X  X hose co-cited with the true citation in the corpus and represent the replac ement or augmentation described above X  X eceive a relevancy score of: Table 1 shows the performance of different models compared to the baseline model. Augmenting th e paper using the three most relevant  X  X oupled X  contexts improves accuracy from 40.8% (not shown in the table) to 46.5% (the forward aggregation scheme only offers 41.8%). As past work has demonstrated the effective-ness of citation-contexts we utilize this feature (with context-coupling) as a more realistic  X  X aseline. X  We compare the perfor-mance of models that use differe nt features independently to un-derstand the contribution of each feature. We found that the single most important feature is the context similarity, particularly after applying the context-coupling technique. We also find the citation history of authors and co-citations with selected references lead to th e biggest improvement in perfor-mance over the baseline model. Th e abstract, title and keywords similarities offer negligible c ontribution beyond the context simi-larity, supporting findings of previous work [16]. Another inter-esting observation is that the contri bution of citations by selected references is notably higher than the contribution of global cita-tion count. This suggests that global visibility is not as important as visibility within the topical community of the paper. The com-bination of all features yields better results X 15.4% over baseline. Our system aims to improve its recommendation as the user inter-acts with it. Most notably, it uses the previously selected refer-ences to rank future candidates. Figure 4 (large image) shows the accuracy of the recommendations as a function of the number of previously selected papers. There is a steady increase in accuracy as more papers are being cited up to the eleventh paper (peaking at a value of 64.2%, compared with 58% at the first recommenda-tion). While the slope of the line appears small, the change is meaningful to the final result. Around that point, having larger bibliography does not lead to additional improvement. This find-ing suggests performance could be further improved if users could express the relevance of each sele cted reference (or this could be inferred given the way a citation is used or where it is placed in the paper). The number of authors also affects citation recommen-
Table 1. CitesSight performance given different features used for ranking, using ranking by citation context as a baseline. Text features tended to perform worse than features related to the author or citation structure. Each row below context signifies context + feature (e.g., Context + keywords, Context + title, etc.) Figure 5. The log latency of the cache and index. 
Searching the cache is much faster than searching the index, with a median latency of 6.2 milliseconds for the cache, compared with 452 miliseconds for the index. dations as Figure 4 (bottom) show s. Having more authors also leads to better recommendations as the most predictive feature X  citation history X  X eco mes more reliable. Next we study the effect of the cache. First we measure the time it takes to retrieve the results. Figure 5 shows the latency of the cache and the index. Not surprisingly, the cache is much faster. The median cache latency is 6.2 milliseconds whereas for query-ing the index it is about 452 milliseconds. Note that these rates were achieved where both client and server were on the same local-network, with an unloaded server. However, while the cache results are well below the desi red 100ms, additional optimization may be desirable as the system scales to more users. As expected, long queries resulted in higher latency when query-ing the full index (see Figure 6) and the correlation between the two was 0.77. However, the length of the query did not appear to affect cache response time, we found no correlation between the two. This is likely due to the fact that the cache index was loaded into memory on the server and any differences were slight relative to network time. As we discuss later, long queries are another instance where slow search [39] might be beneficial. Of course, the cache will be useless if the recommendations it generates are irrelevant. Figure 7 shows a scatterplot of the cache and corpus accuracy for each query, along with the histogram of cache and corpus accuracies. On average, the recommendations of the cache account for about 45.5% of the NDCG@10 achieved by the corpus. In about 9.4% of the cas es the cache in fact provides better recommendations that match the actual citation more close-ly than the full corpus. These may be cases where authors pre-ferred citing a familiar paper or  X  X enue-suitable X  rather than the best fit. Overall, the cache provides accurate recommendation in many cases with minimal latency. Our evaluation is focused exclus ively on Computer Science pa-pers. Other domains, with differe nt citation behaviors, may have different results. We believe th at the citation distributions and sparseness of contexts is ubiquitous in the scientific literature but additional work is needed to validate this. Our evaluation does not extensively evaluate the impact of net-work latency as we test on hig h-speed, unloaded connection or local searches. However, as the am ount of actual data transferred is often less than 2k we believe that we can stay below the 100ms requirement even on more signifi cantly loaded networks. In terms of scaling, we note that while GBRTs are complex, training on the entire corpus (not only the 1000 documents) can be achieved in well under 24 hours on our mode st hardware. Any scaling-related performance issues can likely be ha ndled without extensive infra-structure but this requires additional validation. Finally, while we believe that NDCG is an appropriate metric there are others suited for our evaluation task. Selecting the crite-ria to optimize will require more extensive real-world use that would allow us to identify desired service characteristics. In addition to evaluating CiteSi ght X  X  performance, we also asked five participants to use the sy stem and provide semi-structured feedback. All participants were PhD students in the Computer Science department at the University of Michigan. Because the students did not necessarily have a sufficient number of their own papers for effective pe rsonalization we asked each participant to choose a paper written by someone else that they were familiar with. First each participant entered in the title, abstract, venue, keywords, and authors of the pape r they selected. Next, each par-ticipant was instructed to type in a paragraph from the text that cited one or more papers they we re familiar with, soliciting rec-ommendations from the system. We asked participants to answer structured questions and provide open-ended reflection on their impressions of the system (e.g., would you be interested in a sys-tem/plugin that provides dynamic recommendations? What prop-erties/features are most important in such a system? etc.). Prior to using the system, participants expressed considerable interest in having a system that provides dynamic recommenda-tions for citations. They stated that the most important properties would be  X  accuracy of recommendations  X  (P1, P3, P4) and  X  speed of response  X  (P2), highlighting the importance of the challenging latency and accuracy trade-offs that CiteSight X  X  differential search approach is designed to support. Some participants also men-tioned  X  coverage of papers  X  (P1, P2) and  X  the capability of han-dling synonyms and higher-level semantics  X  (P2) as secondary requirements. Such functionality is likely to require additional processing, and would fit well into the differential search session. During use, CiteSight often correctly recommended the actual citation for the participant X  X  selected paper as the top result or among the top results. The other recommendations, while not the actual cited paper, also tended to be relevant (e.g.,  X  The expected paper was not returned in my case. But other recommendations were highly relevant.  X ). Participants identified these recommenda-
Figure 6. Index latency versus query length. While long queries did not affect cache response time, they resulted in higher latency when querying the full index. 
Figure 7. Recommendation accuracy of the cache and full index. The cache account for about half of the NDCG@10 achieved by the index, and in some cases the cache actual-ly provides better recommendations. tions as relevant to the topic of the paper, and, sometimes, to the specific sentence being used as context. However, it is difficult to evaluate the quality of these alternatives because the participants can only make assumptions about what the authors would have done. In some cases CiteSight fail ed to find the actual citation used in the model text due to l imited index coverage (we simply did not have the paper metadata). After being shown the system, participants were asked what addi-tional features or extensions they would like to see it support. Their replies highlight the varia tion in how people perform cita-tion work, with different access points being important. For ex-ample, one participant (P3) asked for,  X  X  LaTeX file parser X  to automatically extract metadata and another (P4) wanted to  X  X e able to use [CiteSight] with SubLime text and Latex plugin. X  Such extensions are possible using CiteSight X  X  API. One limitation to CiteSight that became apparent during use is that the system can only rely on context that has already been typed by the user. Sometimes this text was insufficient to make an accurate prediction, for example, where the author opened a bracket at the start of the sentence (e.g.,  X  X n [... X ). While the system does allow the author to leave an empty set of brackets and return to them, this may be unnecessarily disruptive. However, brackets may not be inherently necessary. One participant (P2) suggested a feature to provide recommendations for both papers and citation placement:  X  I would add suggestions on places to insert citations, so that the user does not have to find and create a bracket by himself . X  This could be done by matching global recommendations to particular citation contexts, or running a series of background queries using different subsets of the paper text. The CiteSight system demonstrates a mechanism for disentangling recommendations given different tasks and work modalities. It at-tempts to provide fast and accurate responses for in-line queries and slower, contemplative recommenda tions when those are appropri-ate, either slowly populating the auto-complete dialog, or suggesting further reading. Based on user feedback and our own experience we have begun to explore other applications within the differential search framework. Many of these can continuously run in the back-ground making unobtrusive or on-demand recommendations. For example, authors going through a self-audit before submission could benefit from background analysis that is surfaced to indicate possible missing references or updat ed results that have been found on the Web or through crowdsourcing. Alternatively, authors wish-ing to save space in their paper may benefit from an analysis that finds review articles that covers many of the cited articles or sug-gests possible cuts. From an engineering perspective, we have also begun to explore how background tasks can be used to anticipate end-user requests. While an end-user may be willing to tolerate a delay for a more complex search, they would likely not complain if the response were fast. It may be possible to achieve this without significant costs in accuracy by pre-querying. For example, the system could query the index every 5 words typed by the user. When the user asks for local recommendation, the system will automatically show the recommendations retrieved from the last background search and update the recommendations once the  X  X ive X  background search completes. This is particularly true for long queries that take a lot of time to be processed (see Figure 6). If implemented correctly, the user may not even need to type a bracket. The notion of utility as expressed through cost/benefit analysis in mixed-initiative systems [17][35] ma y be a useful model for learn-ing which search or recommende r modalities are appropriate for which tasks. However, it is not always clear how different utility models may perform in our partic ular setting. Academics may find recommendations of value even if they are not immediately useful for the given context but that value may vary greatly depending on time pressures and other competing interests. We believe that CiteSight is an ex emplar solution of a larger set of problems on how human and search (or recommendation) systems can be integrated. Search engines are often engineered to be as fast and as responsive as possible and consequently users have become accustomed to search results being show up in a fraction of a sec-ond. Seemingly negligible increases of less than half a second in response time decreased user engagement dramatically [32]. How-ever, our experience, and contin ued evidence from the IR communi-ty [39], is that  X  X ast X  is not th e only pertinent criterion. Task re-quirements may demand stability (for refinding), novelty (for rec-ommending a new movie to watch), freshness, appropriate synthesis (finding contrasting opinions or identifying consensus in search results), and context appropriateness. Notably, many of these tasks are interleaved by any single end-us er requiring an adaptiveness that is not currently observed in bulk search or recommendation engines. Exploratory searches, medical research, vacation planning and sci-entific literature review are some examples for search instances where users might be more patient and would value higher quality results over search speed. In this world, latency is no longer the most pertinent constraint. By architecting systems with defined tasks and expectations in mind, in our case by creating a dynamic cache, we believe it is pos-sible to address multiple needs differentially while respecting exist-ing work practice. Note that for the most part, we do not utilize different search systems or have over-fit each component to the task it is intended to support. Rather, we have opted for a single ranking strategy that is focused on different datasets (i.e., likely known ver-sus likely unknown) and for which results are surfaced in different ways. In this paper we presented CiteSight, a system that dynamically recommends citation to academics as they edit a manuscript. The system is designed to support both in-line, where instantaneous results are expected, and offline tasks that can be computed in the background. A critical component that enables the versatility of CiteSight is the cache, that maintains a personalized  X  X ession pro-file X  with papers ready for instant retrieval. Context-coupling fur-ther enhances our index to support better recommendations for un-common papers. In a preliminary user study we identified response time and recommendation accuracy as the two most important properties of the system. We empirically evaluate our system using a large dataset of papers, focusing on those aspects. We found that using the cache the system is able to provide personalized recom-mendations instantly (&lt;10 ms) while more diverse results are re-trieved in the background. We would like to thank Kevyn Collin s-Thompson for useful discus-sions and the Microsoft Academic team for providing us with data, advice, and suggestions. This work is supported by the Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior National Business Center contract number D11PC20155. The U.S. government is authorized to reproduce and distribute re-prints for Governmental purposes notwithstanding any copyright annotation thereon. Disclaimer: The views and conclusions con-tained herein are those of the authors and should not be interpreted as necessarily representing the official policies or e ndorsements, either expressed or implied, of IARPA, DoI/NBC, or the U.S. Government. [1] Adamic, L.A. and Adar, E., Friends and neighbors on the Web. [2] Adar, E., Teevan, J. and Dumais, S.T., Large scale analysis of [3] Baldi, S. 1998. Normative versus social constructivist process-[4] Bennett, P.N., White, R.W., Chu, W., Dumais, S.T., Bailey, P., [5] Bethard, S. and Jurafsky, D., Who should I cite: learning litera-[6] Bornmann, L. and Daniel, H. -D., What do citation counts [7] Budzik, J. and Hammond, K.J., Watson: Anticipating and [8] Clauset, A., Shalizi, C R., Newman, M.E.J., Power-law distri-[9] Dumais, S.T., Cutrell, E., Sarin, R. and Horvitz, E., Implicit [10] Erosheva, E., Fienberg, S. and Lafferty, J., Mixed-membership [11] Friedman, J.H., Greedy function approximation: A gradient [12] Gipp, B., Beel, J. and Hentschel, C., Scienstein: A research [13] Harwood, N., Publication outlets and their effect on academic [14] He, J., Nie, J., Lu, Y. and Zhao, W., Position-aligned transla-[15] He, Q., Kifer, D., Pei, J., Mitra, P. and Giles, C.L., Citation [16] He, Q., Pei, J., Kifer, D., Mitra, P. and Giles, L., Context-[17] Horvitz, E., Principles of mi xed-initiative user interfaces. [18] Huang, W., Kataria, S., Caragea, C., Mitra, P., Giles, C.L. and [19] Kataria, S., Mitra, P. and Bha tia, S., Utilizing context in gener-[20] K X  X  X ktun X , O., Saule, E., Kaya, K. and  X ataly X rek,  X . V., [21] Lu, Y., He, J., Shan, D. and Yan, H., Recommending citations [22] Lucene, https://lucene.apache.org/ [23] Marchionini, G. Exploratory search. CACM , 49(4):41 X 46, [24] McFarlane, D.C., Latorella, K.A., The scope and importance [25] McNee, S.M. et al., On the recommending of citations for [26] Metzler, D., Novak, J., Cui, H. and Reddy, S., Building en-[27] Miller, R.B., Response time in man-computer conversational [28] Nallapati, R.M., Ahmed, A., Xi ng, E.P. and Cohen, W.W., [29] Pedregosa, F. et al., Scikit-learn: Machine Learning in Python . [30] Pickens, J., Golovchinsky, G., Shah, C., Avarfordt, P and [31] Rhodes, B.J. and Starner, T., Remembrance Agent: A continu-[32] Schurman, E. and Brutlag, J., Performance related changes and [33 ] Shah, C. and Gonz X les-Ib X  X ez, R., Exploring information [34] Shaoping, Z., ActiveCite: An interactive system for automatic [35] Shilman, M., Tan, D. and Simard, P., CueTIP: a mixed-[36] Strohman, T., Croft, W.B. and Jensen, D., Recommending [37] Tang, J. and Zhang, J., A discriminative approach to Topic-[38] Teevan, J., Adar, E., Jones, R. and Potts, M.A.S., Information [39] Teevan, J., Collins-Thompson, K., White, R.W., Dumais, S.T. [40] Teevan, J., Dumais, S. and Horvitz, E., Personalizing search [41] Teevan, J., Morris, M. and Bush, S., Discovering and using [42] Torres, R., McNee, S.M., Abel, M., Konstan, J. A. and Riedl, [43] White, H., Authors as citers over time. JASIST , 52(2):87 X  [44] White, R.W., Drucker, S.M., Marchionini, G., Hearst, M. and [45] Zhang, X., Qu, Y., Giles, C.L. and Song, P., CiteSense: sup-[46] Zheng, Z., Zha, H., Zhang, T., Chapelle, O., Chen, K. and Sun, 
