 Social networking websites allow users to create and share content. Big information cascades of post resharing can form as users of these sites reshare others X  posts with their friends and followers. One of the central challenges in understanding such cascading be-haviors is in forecasting information outbreaks, where a single post becomes widely popular by being reshared by many users.

In this paper, we focus on predicting the final number of reshares of a given post. We build on the theory of self-exciting point pro-cesses to develop a statistical model that allows us to make accu-rate predictions. Our model requires no training or expensive fea-ture engineering. It results in a simple and efficiently computable formula that allows us to answer questions, in real-time, such as: Given a post X  X  resharing history so far, what is our current estimate of its final number of reshares? Is the post resharing cascade past the initial stage of explosive growth? And, which posts will be the most reshared in the future?
We validate our model using one month of complete Twitter data and demonstrate a strong improvement in predictive accuracy over existing approaches. Our model gives only 15% relative error in predicting final size of an average information cascade after ob-serving it for just one hour.
 Categories and Subject Descriptors: H.2.8 [Database Manage-ment] : Database applications X  Data mining General Terms: Algorithms; Experimentation.
 Keywords: information diffusion; cascade prediction; self-exciting point process; contagion; social media.
Online social networking services, such as Facebook, Youtube, and Twitter, allow their users to post and share content in the form of posts, images, and videos [9, 17, 21, 30]. As a user is exposed to posts of others she follows, the user may in turn reshare a post with her own followers, who may further reshare it with their re-spective sets of followers. This way large information cascades of post resharing spread through the network.
 c  X 
A fundamental question in modeling information cascades is to predict their future evolution. Arguably the most direct way to for-mulate this question is to consider predicting the final size of an information cascade. That is, to predict how many reshares a given post will ultimately receive.

Predicting the ultimate popularity of a post is important for con-tent ranking and aggregation. For instance, Twitter is overflowing with posts and users have a hard time keeping up with all of them. Thus, much of the content gets missed and eventually lost. Accu-rate prediction would allow Twitter to rank content better, discover trending posts faster, and improve its content-delivery networks. Moreover, predicting information cascades allows us to gain fun-damental insights into predictability of collective behaviors where uncoordinated actions of many individuals lead to spontaneous out-comes, for example, large information outbreaks.

Most research on predicting information cascades involves ex-tracting an exhaustive set of features describing the past evolution of a cascade and then using these features in a simple machine learning classifier to make a prediction about future growth [4, 6, 17, 20, 26, 30]. However, feature extraction can be expensive and cumbersome, and one is never sure if more effective features could be extracted. The question remains how to design a simple and principled bottom-up model of cascading behavior. The challenge lies in defining a model for an individual X  X  behavior and then ag-gregating the effects of the individuals in order to make an accurate global prediction.
 Present work. Here we focus on predicting the final size of an in-formation cascade spreading through a network. We develop a sta-tistical model based on the theory of self-exciting point processes . A point process indexed by time is called a counting process when it counts the number of instances (reshares, in our case) over time. In contrast to homogeneous Poisson processes which assume con-stant intensity over time, self-exciting processes assume that all the previous instances ( i.e. , reshares) influence the future evolution of the process. Self-exciting point processes are frequently used to model  X  X ich get richer X  phenomena [22, 23, 33, 36]. They are ideal for modeling information cascades in networks because every new reshare of a post not only increases its cumulative reshare count by one, but also exposes new followers who may further reshare the post.

We develop S EISMIC ( Self-Exciting Model of Information Cas-cades ) for predicting the total number of reshares of a given post. In our model, each post is fully characterized by its infectiousness which measures the reshare probability. We allow the infectious-ness to vary freely over time in agreement with the observation that the infectiousness can drop as the content gets stale (see Figure 1). Figure 1: First 6 hours of retweeting activity of a popular tweet [1] (top). The controversial tweet is about the fresh death of dictator Muammar Gaddafi and mentions singer Justin Bieber. Interestingly, the car manufacturer Chevrolet Twitter account inappropriately retweeted the tweet about 30 minutes after the original tweet, which possibly lead to tweet X  X  sustained popularity. Tweet infectiousness against time as estimated by S
EISMIC (middle). Predictions of the tweet X  X  final retweet count (denoted as  X  X ruth X ) as a function of time (bottom). We com-pare S EISMIC with time series linear regression (LR),  X  X b-served X  plots the cumulative number of observed retweets by a given time. Notice S EISMIC quickly finds an accurate estimate of the tweet X  X  final retweet count.
 Moreover, our model is able to identify at each time point whether the cascade is in the supercritical or subcritical state, based on whether its infectiousness is above or below a critical threshold. A cascade in the supercritical state is going through an  X  X xplosion X  period and its final size cannot be predicted accurately at the cur-rent time. On the contrary, a cascade is tractable if it is in subcriti-cal state. In this case, we are able to predict its ultimate popularity accurately by modeling the future cascading behavior by a Galton-Watson tree.

Our S EISMIC approach makes several contributions:
We evaluate S EISMIC on one month of complete Twitter data, where users post tweets which others can then reshare by retweet-ing them. We demonstrate that S EISMIC is able to predict the fi-nal retweet count of a given tweet with 30% better accuracy than the state-of-the-art approaches ( e.g. , [12]). For reasonably popu-lar tweets, our model achieves 15% relative error in predicting the final retweet count after observing the tweet for 1 hour, and 25% error after observing the tweet for just 10 minutes. Moreover, we also demonstrate how S EISMIC is able to identify tweets that will go  X  X iral X  and be among the most popular tweets in the future. By maintaining a dynamic list of 500 tweets over time, we are able to identify 78 of the 100 most reshared tweets and 281 of the 500 most reshared tweets in just 10 minutes after they are posted.
The rest of the paper is organized as follows: Section 2 sur-veys the related work. Section 3 describes S EISMIC , and Section 4 shows how the model can be used to predict the final size of an information cascade. We evaluate our method and compare its per-formance with a number of baselines as well as state-of-the-art ap-proaches in Section 5. Last, in Section 6, we conclude and discuss future research directions. The study of information cascades is a rich and active field [27]. Recent models for predicting size of information cascades are gen-erally characterized by two types of approaches, feature based meth-ods and point process based methods.

Feature based methods first extract an exhaustive list of poten-tially relevant features, including content features, original poster features, network structural features, and temporal features [6]. Then different learning algorithms are applied, such as simple regression models [2, 6], probabilistic collaborative filtering [35], regression trees [3], content-based models [24], and passive-aggressive algo-rithms [26]. There are several issues with such approaches: labori-ous feature engineering and extensive training are crucial for their success, and the performance is highly sensitive to the quality of the features [4, 30]. Such approaches also have limited applicabil-ity because they cannot be used in real-time online settings X  X iven the massive amount of posts being produced every second, it is practically impossible to extract all the necessary features for every post and then apply complicated prediction rules. In contrast, S MIC requires no feature engineering and results in an efficiently computable formula that allows it to predict the final popularity of millions of posts as they are spreading through the network.
The second type of approach is based on point processes, which directly models the formation of an information cascade in a net-work. Such models were mostly developed for the complementary problem of network inference, where one observes a number of in-formation cascades and tries to infer the structure of the underlying network over which the cascades propagated [8, 10, 13, 14, 15, 18, 33, 36]. These methods have been successfully applied to study the spread of memes on the web [10, 14, 32, 33] as well as hashtags on
Symbol Description w Post/information cascade p t Infectiousness of w at time t (Section 3.2)  X  ( s ) Memory kernel (Section 3.1) i Node that contributed i th reshare. t i Time of the i th reshare relative to the original post. n i Out-Degree of the i th node R t Cumulative popularity by time t : |{ i &gt; 0; t i  X  t }| R  X  Final popularity (final number of reshares): |{ i &gt; 0 }|
N t Cumulative degree of resharers by time t : P i : t N e t Effective cumulative degree of resharers by time t :  X  t Intensity of cumulative popularity R t  X  p t Model X  X  estimate of infectiousness p t at time t  X 
R  X  ( t ) Model X  X  estimate at time t of final popularity R Twitter [36]. In contrast, our goal is not to infer the network but to predict the ultimate size of a cascade in an observed network.
A major distinction between our model and existing methods based on Hawkes processes ( e.g. , [22, 23, 33, 34, 36]) is that we assume the process intensity  X  t depends on another stochastic pro-cess p t , the post infectiousness. In other words, we allow the in-fectiousness to change over time. Moreover, some of these meth-ods [34] rely on computationally expensive Bayesian inference, while our method has linear time complexity. Another recently proposed related work is [12], which also takes the point process approach and directly aims to predict tweet popularity. However, their method makes restrictive parametric assumptions and does not consider the network structure, which limits its predictive ability. We compare S EISMIC with [12] in Section 5 and demonstrate a 30% improvement.
In this section, we describe S EISMIC and discuss how it can be used for: 1. Estimating the spreading rate of a given information cascade, 2. Determining whether the cascade is in supercritical (explo-3. Predicting the final size of an information cascade, which is
Important quantities in our model are the total number of re-shares R t of a given post up to time t and the cascade speed of spreading  X  t . In our model,  X  t is determined by the post infec-tiousness p t and human reaction time. Our goal is to predict R the final number of reshares.

Another important quantity in our model is the memory kernel  X  ( s ) , which quantifies the delay between a post arriving to a user X  X  feed and the user resharing it. Intuitively, infectiousness defines the probability that a given user will reshare a given post, and the mem-ory kernel models user X  X  reaction time. By combining the two we can then accurately model the speed at which the post will spread through the network. Table 1 summarizes the notation.
In order to predict the cascade size, we need to know how long it takes for a person to reshare a post. Knowing the delay allows us to accurately model the speed of a cascade spreading through the network. We consider that the time s between the arrival of is distributed with density  X  ( s ) . The probability density  X  ( s ) is also called a memory kernel because it measures a physical/social system X  X  memory of stimuli [7].

The distribution of human response time  X  ( s ) has been shown to be heavy-tailed in social networks [5]. Usually the tail of  X  ( s ) is assumed to follow a power-law with exponent between 1 and 2 or a log-normal distribution [7, 34]. However, due to the rapid nature of information sharing on Twitter, it is also natural to expect many instant reaction times. In fact, our exploratory data analysis in Sec-tion 5.2 confirms that in Twitter,  X  ( s ) is approximately constant for the first 5 minutes and then followed by a power-law decay. Dif-ferent social networks may have different distributions of human reaction times. However,  X  ( s ) only needs to be estimated once per network and thus we can safely assume it is given. We describe a detailed estimation procedure of  X  ( s ) in Section 5.2. The second component of our model is the post infectiousness. We assume each post w is associated with a time dependent, intrin-sic infectiousness parameter p t ( w ) . In other words, p how likely the post w is to be reshared at time t . Infectiousness of a post may depend on a combination of factors, including but not limited to the quality of the post X  X  content, the social network structure, the current local time, and the geographical location. In-stead of assuming a parametric form of p t , we model it flexibly in a nonparametric way which implicitly accounts for all these factors.
Most existing methods studying self-exciting point processes as-sume p t to be fixed over time. Consequently, an important concept is the criticality of the process R t . In a self-exciting point process with constant infectiousness p t  X  p , there exists a phase transition phenomenon at certain critical threshold p  X  such that [11]: 1. If p &gt; p  X  , then R t  X   X  as t  X   X  almost surely and 2. If p &lt; p  X  , then sup t R t &lt;  X  almost surely. This is called
In reality, R t is always bounded due to the finite size of the net-work. Thus, no supercritical cascades can exist if p t is assumed to be a constant. This is inadequate to model highly contagious tweets and our assumption of non-constant infectiousness solve this prob-lem as well. Furthermore, as the post gets older the information becomes outdated and its spreading power (infectiousness) may de-crease. This effect may also be observed as the post spreads further away from the original poster [34]. Alternatively, resharing by a highly influential user may increase the post X  X  infectiousness. Thus, rather than assuming a common evolutionary pattern of p t the tweets, we only assume it varies smoothly over time and use non-parametric methods to estimate p t for each tweet.
We combine human reaction times and post infectiousness to de-rive S EISMIC . In order to link p t to the post resharing process R , we model R t as a doubly stochastic self-exciting point process . This is an extension to the standard self-exciting point process (also called the Hawkes process [16]) which was initially used to model earthquakes [25].

We first define the intensity  X  t of R t , which simply measures the rate of obtaining an additional reshare at time t . More formally:
In S EISMIC , the intensity  X  t at time t is determined by infec-tiousness p t , reshare times t i , node degrees n i , and human reaction time distribution  X  ( s ) . The exact relationship described in Eq. (1) is inspired by the theory of Hawkes processes [16]:
Intuitively, P t of newly exposed users at time t and its product with the resharing probability p t gives the intensity of reshares at time t .
Note that the above point process is called self-exciting because each previous observation i such that t i  X  t contributes to the in-tensity  X  t , or equivalently, each observation increases the intensity in the future. It is further doubly stochastic (or a Cox process ) be-cause the infectiousness p t is itself a stochastic process.
Additionally, we assume node degrees { n i } are independent and identically distributed with mean n  X  . Mean degree n  X  is related to the critical threshold p  X  which is already discussed in Section 3.2. The critical infectiousness threshold takes value p  X  = 1 /n give the proof of this fact in Proposition 4.1.
In this section we describe how to perform statistical inference for the self-exciting model of information cascades introduced in the previous section. Specifically, we discuss how S EISMIC mates the infectiousness parameter p t and then predicts the ultimate size of the cascade R  X  .

Throughout this section, we make a technical assumption that the followers of all the resharers are disjoint, so we can use a tree structure to describe the information diffusion (Figure 2). The con-clusions made in this section remain valid even if resharers are not disjoint. In this case, we can replace the node degree n total number of newly exposed neighbors of node i (the followers of i -th resharer who do not follow the first i  X  1 resharers).
We first define the sample-function density , which plays a central role in estimating self-exciting point processes [29]. Let X  X  denote F t =  X  { ( n i ,t i ) } R t i =0 as the  X  -algebra generated by all the in-formation available by time t : the times t i of all the reshares up to time t and the number of followers ( i.e. , node degree) n i -th user to reshare. Sample-function density is defined as the joint probability of the number of reshares in the time interval [ t the density of their occurrence times.

To motivate our estimator of p t , we first consider the case where the infectiousness parameter remains constant over time, i.e. , p p . Later we will relax this assumption and allow p t to vary over time.

In S EISMIC , the sample-function density can be expressed using the intensity  X  t as [29, Thm. 6.2.2] By taking derivative of the log of Eq. (2) and combining it with Eq. (1), we obtain the maximum likelihood estimate (MLE) of p
The above equation forms the basis of S EISMIC as it allows us to estimate the infectiousness  X  p t at any given time t . Moreover, a confidence interval of p t can also be obtained [29].

The denominator in Eq. (3), denoted as N e t hereafter, can be in-terpreted as the accumulative  X  X ffective X  number of exposed users to the post. The numerator R t is the current number of reshares of the post. To shed more light on our estimator, we take t  X   X  , which leads to: Thus, by assuming the infectiousness p t to be a constant over time, one would essentially assume that most posts have the same infec-tiousness 1 /n  X  . However, such assumption is unrealistic as it can-not explain the bursty and volatile dynamics information cascades ( e.g. , Figure 1).

This undesirable consequence of assuming constant p t is another motivation for allowing p t to vary over time. To estimate p case, we smooth the MLE in Eq. (3) by only using observations close to time t to estimate p t . In particular, we rely on a sequence of one-sided kernels K t ( s ) , s &gt; 0 , indexed by time t . We use these kernels to weight the reshares and the weighted estimate of p is given by
Notice that when K t ( s )  X  1 the estimator reduces to the MLE we derived in Eq. (3). In S EISMIC we use a triangular kernel with growing window size t/ 2 as weighting kernel K t ( s ) :
We chose the triangular kernel because it has properties impor-tant for our application. First, the kernel discards all posts that are older than t/ 2 . In particular, it quickly discards the unstable and potentially explosive period at the beginning, which if included, would introduce an upward bias to p t . Second, the kernel takes into account posts in a larger window size as time t increases. Accord-ing to our experiments, the growing window size helps to stabilize  X  p ( t ) compared to a fixed window size. Third, for reshares within the window, the kernel up-weights the most recent posts and gradu-ally down-weights older posts. This keeps our estimator  X  p ( t ) closer to the ever-changing true p t . And last, as K t ( s ) is piece-wise lin-different functions  X  ( s ) including the one we use for Twitter in our experiments, see Section 5.
Having described the procedure for inferring the post infectious-ness, we now need to account for the network structure in order to predict how far the post is going to spread across the network.
For simplicity, let us assume the post is first posted at time 0 , i.e. , t = 0 . Consider we have observed the post for t time units and our goal now is to predict the post X  X  final reshare count, R on the information we have observed so far, F t .

The following proposition shows how to compute the expected final reshare count of a post. The main idea is to model an informa-tion cascade spreading over the network with a branching process that counts the reshare number of a post, as illustrated in Figure 2. Predictor for R  X  used by S EISMIC can be stated as follows: Figure 2: An illustration of the information diffusion tree. We observe the cascade up to time t (denoted by a dashed line) and the question is how the cascade tree is going to grow in the future. We define variables Z k which denote the number of reshares caused by the k th generation descendants. Using variables Z k the final reshare count R  X  can then be simply computer as R t +
P ROPOSITION 4.1. Assume the (out-)degrees in the network are i.i.d. with expectation n  X  and the infectiousness parameter p constant p for s  X  t . Then, we have
P ROOF . First, we consider the case where p &lt; 1 /n  X  a sequence of random variables { Z 1 ,Z 2 ,Z 3 ,... } that models the future information diffusion tree, as illustrated in Figure 2. In this tree, Z k denotes the number of reshares made by the k th tion descendants (counting from generation R t onward). Thus, the 1 generation descendants Z 1 refers to the number of new reshares generated by the posts created before time t , the 2 descendants Z 2 refers to the reshares of the posts of the 1 dants, and so on. Notice that the summation over the Z k  X  X  gives the post X  X  final reshare count R  X  = R t + P  X  k =1 Z k . In the following we use descendants Z k only for deriving Eq. (7) and emphasize that our final estimator does not require explicit network structure information.
 Given Z 1 , the sequence of random variables Z k defines a Galton-Watson tree with the offspring expectation  X  = n  X  p [11]. Here,  X  denotes the expected number of reshares that the post gets. Using a standard branching process result, we have Z i / X  i is a martingale. Therefore,  X  k &gt; 1 , E [ Z k +1 | Z k ] =  X  Z k , and, Hence, we obtain which ends up being the right hand side in Eq. (7) because p ( N t  X  N e t ) by the definition of Z 1 and N e t .
 Algorithm 1 S EISMIC : Predict final cascade size Purpose: For a given post at time t , predict its final reshare count
Input: Post resharing information: t i and n i for i = 0 ,...,R Algorithm:
N t = 0, N e t = 0 for i = 0 ,...,R t do end for  X 
R  X  ( t ) = R t +  X  t  X  p t ( N t  X  N e t ) / (1  X   X  t  X  p Deliver:  X  R  X  ( t )
Next, consider the case where p =  X  p t  X  1 /n  X  . In this regime, the point process is supercritical and stays explosive. In terms of the Galton-Watson tree discussed above, the offspring expectation  X  = n  X  p  X  1 , so E [ Z k +1 ]  X  E [ Z k ]  X   X  X  X   X  E [ Z the total future reshares P  X  k =1 Z k has infinite expectation and the final reshare count cannot be reliably predicted.

Note that Prop. 4.1 assumes that the post infectiousness remains constant in the future ( p s = p t for s  X  t ), which could be unre-alistic for some information cascades. We correct this by changing the prediction formula in Eq. (7) by adding two scaling constants  X  , X  t that adjust the final prediction: We introduce these correction factors based on the following intu-ition. We expect  X  t to decrease over time t so it scales down the estimated infectiousness in the future, which accounts for the post getting stale and outdated. Similarly,  X  t accounts for the overlap in the neighborhoods of reposters X  followers. Over time as the post spreads farther in the network, we expect  X  t to increase as more nodes get exposed multiple times, which means the arrival rate of new nodes (previously unexposed nodes) decreases over time.
We use the same values of  X  t and  X  t for all posts but allow them to vary over time. The values of  X  t and  X  t are selected to mini-mized median Absolute Percentage Error (refer to Section 5.4 for definition) on a training data set. As described in Section 5.2, we find  X  t is more important than  X  t in practice.
Last, we put together all the components described so far and synthesize them in the S EISMIC algorithm. The S EISMIC algorithm for predicting  X  R  X  ( t ) is described in Algorithm 1, which uses the algorithm for computing  X  p t (Algorithm 2) as a subroutine. These algorithms are based on Eqs. (5) and (8). We assume parameters K ( s ) ,  X  t ,  X  t , n  X  are given a priori or estimated from the data. Computational complexity of S EISMIC . For any choice of  X  ( s ) and K t ( s ) , the computational cost of S EISMIC is O ( R calculating  X  p t and predicting  X  R  X  ( t ) . Of course, the actual comput-ing time depends heavily on the integration R t t and R t t S
EISMIC is linear in the observed number of reshares R t of a given post by time t .

The linear time complexity is in part also due to the shape of our memory kernel. In Section 5.2 we will estimate the memory kernel  X  ( s ) for Twitter to have the following form (for some s Algorithm 2 Compute real-time infectiousness  X  p ( t )
Purpose: For a given post w , calculate infectiousness p t information about w prior to time t
Input: Post resharing information: t i and n i for i = 0 ,...,R
Algorithm:  X 
R t = 0,  X  N e t = 0 for i = 0 ,...,R t do end for for i = 0 ,...,R t do end for Deliver: p t This means that with the memory kernel  X  ( s ) in Eq. (9) and tri-angular weighting kernel K t ( s ) in Eq. (6), both integrals can be evaluated in closed form because they are piece-wise polynomials (polynomial with possibly non-integer exponents), which greatly decreases computational cost of S EISMIC .
In this section, we describe the Twitter data set, our parameter estimation procedure, and compare the performance of S EISMIC state-of-the-art approaches.
Our data is the complete set of over 3.2 billion tweets and retweets on Twitter from October 7 to November 7, 2011. For each retweet, the dataset includes tweet id, posting time, retweet time, and the number of followers of the poster/retweeter. Note, the data set lacks Twitter network information. The only piece of network informa-tion available to us is the number of followers of a node.
We focus on a subset of reasonably popular tweets with at least 50 retweets, so that our model enables the prediction as soon as sufficient number of retweets occur. Note, that if multiple Twitter users independently post the same tweet, which then gets retweeted, each original posting creates its own independent cascade. All in all there are 166,076 tweets satisfying this criterion in the first 15 days. We form the training set using the tweets from the first 7 days and the test set using the tweets from the next 8 days. We use the remaining 14 days for the retweet cascades to unfold and evolve. For a particular retweet cascade, we obtain all the retweets posted within 14 days of the original post time, i.e. , we approxi-mate R  X  by R 14 days . We estimate parameters  X  ( s ) , X  with the training set, and evaluate the performance of the estimator  X  R  X  on the test set. For the tweets in our training set, R mean 209.8 and median 110. The temporal evolution of mean and median of R t are also shown in Figure 3. First we describe how to fit the memory kernel  X  ( s ) (Section 3.1). We carefully choose 15 tweets in the training set and use the dis-tribution of all their retweet times as our  X  ( s ) (Figure 4). The his-tograms of the 15 sequences of retweet times all display a clear shape of subcritical decay. Moreover, all the original posters have an overwhelming number of followers. Therefore, most of the retweets, if not all, should come from the immediate followers of the original poster. Consequently, the distribution of human reac-tion time can be well approximated by that of the retweet times of Figure 3: Convergence of the mean and media cumulative retweet count R t as a function of time.The horizontal lines cor-respond to mean and median final retweet count R 14 days . On average, a tweet receives 75% of its retweets in the first 6 hours. Figure 4: Reaction time distribution and the estimated memory kernel  X  ( s ) . The reaction time is plotted on logarithmic axes, hence the linear trend suggests a power law decay. these 15 tweets. The estimation of  X  ( s ) can be further improved if the network structure is available.

The observed reaction time distribution (Figure 4) suggests a form of Eq. (9) for the memory kernel: constant in the first 5 min-utes, followed by a power-law decay. After setting the constant period s 0 to 5 minutes, we estimate power law decay parameter  X  = 0.242 with the complimentary cumulative distribution func-tion (ccdf), and chose c = 6 . 27  X  10  X  4 to make R  X  0  X  ( s ) ds = 1 . The memory kernel is a network wide parameter and only needs to be estimated once. The fitted memory kernel is plotted in Figure 4.
Last, we briefly comment on the correction factors  X  t and  X  troduced in Eq. (7). We use the same values of  X  t and  X  tweets. Notice that  X  t and n  X  only affect the predictions through their product  X  t n  X  . Overall, we find the value of  X  effect on the performance of our algorithm. In our experiments we simply set  X  t n  X  = 20 for all t . We choose the value of  X  that it minimizes the training median Absolute Percentage Error (Section 5.4). We report values of  X  t in Table 2.  X  t has a par-ticularly small value at t = 5 minutes, which may be a result of the overestimation of p t , when the triangular kernel has not moved away from the unstable beginning period. After that  X  t begins a slow and consistent decay to account for the fact that information is getting increasingly stale and outdated over time.

With all the estimated parameters in S EISMIC , we are ready to apply it (Algorithms 1 and 2) to the Twitter dataset. For a given tweet w and every 5 minute interval t , we output our estimate  X  R  X  ( t,w ) of the tweet X  X  final retweet count R  X  ( w ) . We consider four different prediction methods for comparison. The first two are regression based and the next two are point process based.
For a particular tweet, suppose that the prediction for R t is denoted by  X  R  X  ( t ) . We use the following evaluation metrics in our experiment:
In this section we evaluate the performance of S EISMIC and the four competitors described in Section 5.3. All the methods start making predictions as soon as a given tweet gets retweeted 50 times.
First, we empirically validate S EISMIC . In Proposition 4.1, we obtain a formula for the expected number of final retweets in terms of the infectiousness parameter p t . Our goal here is to show that Proposition 4.1 provides an unbiased estimate of the true final retweet count. We proceed as follows. We use S EISMIC to make a predic-tion after observing each tweet for 1 hour and then plot the predic-tion against the true final number of retweets. If S EISMIC unbiased estimate, then we expect a diagonal curve y = x , that is, the expected predicted  X  R  X  matches the true expected R  X 
Figure 5 shows that the empirical average almost perfectly coin-cides with S EISMIC  X  X  prediction. This suggests that the S estimator in Eq. (7) is unbiased and we can safely use it to predict the expected final number of retweets. However, as mentioned ear-lier, in practice one often wants to shrink the prediction in order to stabilize the estimator and achieve better overall performance. Therefore, we use the calibrated prediction formula Eq. (8) for the rest of the experiments. We run our S EISMIC method for each tweet and compute the Absolute Percentage Error (APE) as a function of time. We plot the quantiles of the distribution of APE of S EISMIC in Figure 6. After observing the cascade for 10 minutes ( t = 10 min), the 95th, 75th, and 50th percentiles of APE are less than 71% , 44%, and 25%, respectively. This means that after 10 minutes, average error is less than 25% for 50% of the tweets and less than 71% for 95% of the tweets. After 1 hour the error gets even lower X  X PE for 95%, 75% and 50% of the tweets drops to 62%, 30% and 15%, respectively.

The proposed method, S EISMIC , demonstrates a clear improve-ment over the baselines and the state-of-the-art as shown in Figures 7 and 8. The left panels of Figures 7 and 8 show the median APE of different methods over time as more and more of the retweet cas-cade gets revealed. The LR and LR-D baselines have very similar performances, indicating the additional features used by LR-D are not very informative. DPM performs poorly across the entire tweet lifetime, while the other point process approach RPM is worse than LR and LR-D in the early period but becomes better after about 2 hours. All in all, in terms of median APE score S EISMIC Figure 5: Predicted final retweet counts nicely follow the ground-truth retweet counts, which suggests S EISMIC provides an unbiased estimate of the final retweet count. The dashed red curve is obtained by binning the tweets according to the pre-diction and then computing the average number of retweets in each bin. Figure 6: Absolute Percentage Error (APE) of S EISMIC on the test set. We plot the median and the middle 50th, 80th, 90th percentiles of the distribution of APE across the tweets. 30% more accurate than all the competitors across the entire twee lifetime.

Similarly, the right panels of Figures 7 and 8 show the Kendall- X  rank correlation between the predicted ranking of top most retweeted tweets and the ground-truth ranking of tweets. Again S EISMIC giving much more accurate rankings than other methods.
Can we identify a breakout tweet before it receives most of its retweets? This question arises from various applications like trend forecasting or rumor detection. The goal of this prediction task is to as early as possible identify  X  X reakout X  tweets, which have the highest final retweet count. We quantify the performances of dif-ferent models in detecting breakout tweets by using models X  pre-dictions of tweets X  final retweet counts.

First, we form a ground-truth set L  X  M of size M . The set L contains top-M tweets with the highest final retweet counts. Then with each of the prediction methods, we produce a sequence of size Figure 7: Median Absolute Percentage Error (APE) and Kendall X  X  Rank Correlation of S EISMIC and the baselines as a function of time. S EISMIC consistently gives best performance. Figure 8: Zoom-in of Figure 7: Median APE and Rank Corre-lation for the first 60 minutes after the tweet was posted. S MIC performs especially well compared to the baselines early in the tweet X  X  lifetime. tweets with the highest predicted retweet counts at time t . As described in Section 5.4, we then compare each  X  L m ( t ) with L
M , and calculate the Breakout Tweet Coverage , which is defined as the proportion of tweets in L  X  M covered by  X  L m ( t ) .
Fig. 9 shows the performance of S EISMIC in detecting top 100 most retweeted tweets ( L  X  100 ) as a function of time. S able to cover 82 tweets in the first 1 hour and 93 tweets in the first 6 hours.

The fifth most retweeted tweet in this plot is actually the tweet we showed earlier in Figure 1. We observe that S EISMIC detects this tweet 30 minutes after it has been posted, while LR and LR-D both take more than an hour. DPM fails to detect this breakout for the first 6 hours (plots not show for brevity).

To compare S EISMIC with other methods, we keep the size of the predicted lists to be m = 500, and use a larger target list L which is a more difficult task than finding L  X  100 . Figure 10 com-pares the coverage of different methods against the proportion of retweets seen. After seeing 20% of the retweets, S EISMIC 65% of the shortlist, while LR-D and LR both cover only 50%. In Figure 9: Coverage of top 100 most retweeted tweets. Each row represents a tweet. White blocks indicate that a given tweet was not covered by S EISMIC  X  X  predicted list of top-500 tweets at time t , and blue indicates successful coverage. general, the dynamic Poisson model fails to provide accurate pre-dictions and breakout identifications.
 Overall, S EISMIC allows for effective detection of breakout tweets. For instance, after seeing around 25% of the total number of retweets of a given tweet (in other words, after observing a tweet for around 5 minutes), S EISMIC can identify 60% of the top-100 tweets ac-cording to the final retweet counts.
S EISMIC demonstrates better robustness than the other two point process based methods  X  DPM and RPM. While S EISMIC is not state, DPM and RPM are unable to make predictions when the de-cay parameter is outside the feasible set (  X  &lt;  X  1 for DPM and  X  &lt; 0 or  X  &lt; 0 for RPM). For example, in Figure 1, S characterizes the tweet as supercritical for the first 70min, DPM fails to make a prediction for the first 6 hours and RPM is only able to make a prediction from 30 to 80 minute.

All in all, we find that tweets are in the supercritical regime for only a very short time and S EISMIC is able to make predictions for most of the tweets in most of the time. We find that on av-erage, S EISMIC is not able to make a prediction for 1.80% of the tweets after observing them for 15 minutes. In other words, after 15 minutes, 1.80% of the tweets are still in the supercritical regime Figure 10: Coverage of top 500 tweets ( L  X  500 ) by various meth-ods. S EISMIC exhibits clear improvement over all methods after about 10% of retweets are observed. All methods except DPM achieve perfect coverage after 65% of retweets are observed. (over all the tweets with at least 50 retweets). This number drops to 1.29% (0.67%) after 1 hour (6 hours). As a point of comparison we also note that other methods are not able to make predictions for a much larger fraction of tweets: DPM fails to make a prediction for 6.77%, 5.79% and 1.45%, and RPM fails for 3.45%, 5.69% and 15.43% of the tweets after 15min, 1h, and 6h.

Our S EISMIC method is also significantly faster than the RPM model [28], which requires to solve a nonlinear optimization prob-lem every time it predicts. In our implementation, the average run-ning time per tweet for predicting at every 5 minutes for 6 hours is 0.02s for S EISMIC and 3.6s for RPM. The reported running time includes both parameter learning and prediction.
In this paper we propose S EISMIC , a flexible framework for mod-eling information cascades and predicting the final size of an infor-mation cascade. Our contributions are as follows:
There are many interesting venues for future work and our pro-posed model can be extended in many different directions. For example, if the network structure is available, one could replace the node degree n i by the number of newly exposed followers. If content-based features or features of the original post are available, one could develop a content-based prior of p t for each post. If tem-poral features such as the users X  time zone are available, one could proposed model provides an extensible framework for predicting information cascades.

S EISMIC is a statistically sound and scalable bottom-up model of information cascades that allows for predicting final cascade size as the cascade unfolds over the network. We hope that our framework will prove useful for developing richer understanding of cascading behaviors in online networks, paving ways towards better manage-ment of shared content.
 The S EISMIC software and the dataset we use in Section 5 can be found in http://snap.stanford.edu/seismic/ . The R package of our algorithm is also available on http://cran. r-project.org/web/packages/seismic .
 The authors would like to thank David O. Siegmund for his con-structive suggestions and Austin Benson, Bhaswar B. Bhattacharya, Joshua Loftus for their helpful comments. This research has been supported in part by NSF IIS-1016909, CNS-1010921, IIS-1149837, IIS-1159679, ARO MURI, DARPA SMISC, DARPA SIMPLEX, Stanford Data Science Initiative, Boeing, Facebook, Volkswagen, and Yahoo. [1] https://twitter.com/mottbollomy/status/ [2] D. Agarwal, B.-C. Chen, and P. Elango. Spatio-temporal [3] E. Bakshy, J. M. Hofman, W. A. Mason, and D. J. Watts. [4] R. Bandari, S. Asur, and B. A. Huberman. The pulse of news [5] A.-L. Barabasi. The origin of bursts and heavy tails in human [6] J. Cheng, L. Adamic, P. A. Dow, J. M. Kleinberg, and [7] R. Crane and D. Sornette. Robust dynamic classes revealed [8] H. Daneshmand, M. Gomez-Rodriguez, L. Song, and [9] P. A. Dow, L. A. Adamic, and A. Friggeri. The anatomy of [10] N. Du, L. Song, M. Yuan, and A. J. Smola. Learning [11] R. Durrett. Probability: theory and examples . Cambridge [12] S. Gao, J. Ma, and Z. Chen. Modeling and predicting [13] M. Gomez-Rodriguez, J. Leskovec, D. Balduzzi, and [14] M. Gomez-Rodriguez, J. Leskovec, and B. Sch X lkopf. [15] M. Gomez-Rodriguez, J. Leskovec, and B. Sch X lkopf. [16] A. G. Hawkes. Spectra of some self-exciting and mutually [17] L. Hong, O. Dan, and B. D. Davison. Predicting popular [18] D. Hunter, P. Smyth, D. Q. Vu, and A. U. Asuncion. [19] M. G. Kendall. A new measure of rank correlation.
 [20] A. Kupavskii, L. Ostroumova, A. Umnov, S. Usachev, [21] D. Liben-Nowell and J. Kleinberg. Tracing the flow of [22] Y. Matsubara, Y. Sakurai, B. A. Prakash, L. Li, and [23] G. O. Mohler, M. B. Short, P. J. Brantingham, F. P. [24] N. Naveed, T. Gottron, J. Kunegis, and A. C. Alhadi. Bad [25] Y. Ogata. Statistical models for earthquake occurrences and [26] S. Petrovic, M. Osborne, and V. Lavrenko. RT to Win! [27] E. M. Rogers. Diffusion of innovations . Simon and Schuster, [28] H.-W. Shen, D. Wang, C. Song, and A.-L. Barab X si.
 [29] D. L. Snyder and M. I. Miller. Random Point Processes in [30] B. Suh, L. Hong, P. Pirolli, and E. H. Chi. Want to be [31] G. Szabo and B. A. Huberman. Predicting the popularity of [32] J. Yang and J. Leskovec. Patterns of temporal variation in [33] S.-H. Yang and H. Zha. Mixture of mutually exciting [34] T. Zaman, E. Fox, and E. Bradlow. A Bayesian approach for [35] T. R. Zaman, R. Herbrich, J. Van Gael, and D. Stern. [36] K. Zhou, H. Zha, and L. Song. Learning social infectivity in
