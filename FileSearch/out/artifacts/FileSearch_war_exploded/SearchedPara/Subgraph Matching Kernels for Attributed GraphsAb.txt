 Nils Kriege nils.kriege@cs.tu-dortmund.de Petra Mutzel petra.mutzel@cs.tu-dortmund.de Graphs are well-studied versatile representations of structured data and have become ubiquitous in many application domains like chem-and bioinformatics. Comparing graphs is a fundamental problem and com-puting meaningful similarity measures is a prerequisite to apply a variety of machine learning algorithms to the domain of graphs. Consequently related problems have been extensively studied involving essential graph theoretical questions, which are typically NP -hard, like, e.g, the maximum common subgraph problem. However, graph similarity can be defined in various ways and its computation not necessarily requires to solve these problems exactly to yield a similarity mea-sure appropriate for a wide range of applications. To become applicable to the wealth of so-called ker-nel methods , including Support Vector Machines as the most prominent example, similarity measures must satisfy the additional constraints to be symmetric and positive semidefinite (p.s.d.). While recent de-velopment of graph kernels primarily focuses on large datasets of graphs with simple labels (cf. Table 1), it has been observed on several occasions that the predic-tion accuracy can be increased by annotating vertices or edges with additional attributes (see, e.g., Borg-wardt et al., 2005; Fr  X ohlich et al., 2005; Harchaoui &amp; Bach, 2007). Since attributes in many cases in-clude continuous values, a meaningful similarity mea-sure must tolerate certain divergence. Therefore, ker-nels designed for graphs with simple labels often are not suitable for attributed graphs.
 We propose a new graph kernel which is related to the maximum common subgraph problem. Instead of de-riving a similarity measure from a maximum common subgraph our approach counts the number of match-ings between subgraphs up to a fixed size and there-fore has polynomial runtime. Attributes of mapped vertices and edges are assessed by a flexible scoring scheme and, thus, the approach can be applied to gen-eral attributed graphs. 1.1. Related Work In recent years various graph kernels have been pro-posed, see (Vishwanathan et al., 2010) and references therein. G  X artner et al. (2003) and Kashima et al. (2003) devised graph kernels based on random walks, which count the number of labeled walks two graphs have in common. Subsequently random walk ker-nels were extended to avoid repeated consecutive ver-tices and were combined with vertex label enrichment techniques by Mah  X e et al. (2004). The runtime was improved particularly for graphs with simple labels (Vishwanathan et al., 2010). Random walk kernels have been extended to take vertex and edge attributes into account and were thereby successfully applied to protein function prediction (Borgwardt et al., 2005). A drawback of random walks is that walks are struc-turally simple. However, computing kernels by count-ing common subgraphs of unbounded size is known to be NP -complete (G  X artner et al., 2003). Thus, an-other direction in the development of graph kernels focuses on small subgraphs of a fixed size k  X  X  3 , 4 , 5 } , referred to as graphlets , which primarily apply to unla-beled graphs (Shervashidze et al., 2009). Furthermore tree patters, which are allowed to contain repeated ver-tices just like random walks, were proposed by Ramon (2009). While these approaches are based on all com-mon subtree patterns of a specified height, others only take the entire neighborhood of each vertex up to given distance into account (Shervashidze et al., 2011), thus reducing the number of features and the required run-time significantly. Menchetti et al. (2005) proposed a weighted decomposition kernel, which determines matching substructures by a restrictive kernel ( selec-tor ) and weights each matching by a kernel defined on the context of the matching. A kernel based on shortest-paths was developed by Borgwardt &amp; Kriegel (2005), which first computes the length of shortest-paths between all pairs of vertices and then counts pairs with similar labels and distance. Instead of com-paring pairs of individual vertices, the kernel proposed by Costa &amp; De Grave (2010) associates a string encod-ing the neighborhood subgraph with each vertex. Several graph kernels were tailored especially to chem-ical compound. For attributed molecular graphs Fr  X ohlich et al. (2005) proposed a similarity measure based on an optimal assignment of vertices. How-ever, the proposed function was shown not be p.s.d. (Vishwanathan et al., 2010). Established techniques in cheminformatics are based on features which can be 1. directly generated from the molecular graph, e.g. all paths or subgraphs up to a certain size (Wale et al., 2008), similar to graphlets, 2. taken from a predefined dictionary or 3. generated in a preceding data-mining phase, e.g. using frequent subgraph mining.
 The proposed techniques can be classified into ap-proaches that use explicit feature mapping and those that directly compute a kernel function. If explicit rep-resentations are manageable, these approaches usually outperform other kernels regarding runtime on large datasets, since the number of vector representations scales linear with the dataset size. However, these ap-proaches do not support attributed graphs, cf. Ta-ble 1. The computation technique proposed for ran-dom walk and tree pattern kernels, in contrast, can be extended to compare vertex and edge attributes by kernels. However, compared to graphlet kernels these approaches are based on simple features including re-peated vertices.
 We propose a technique that uses small subgraphs con-tained in the two graphs under comparison, similar to graphlets, but simultaneously provide the flexibility to compare vertex and edge attributes by means of arbi-trary kernel functions. In this section basic concepts of graph theory are introduced. We refer to simple undirected graphs. Given a graph G = ( V,E ) we denote by V ( G ) = V and E ( G ) = E the set of vertices and edges , respec-tively. The set of vertices adjacent to a vertex v is denoted by N ( v ) = { u  X  V : ( u,v )  X  E } . A path of length n is a sequence of vertices ( v 0 ,...,v n ) such that ( v i ,v i +1 )  X  E for 0  X  i &lt; n . A graph is connected if at least one path between any pair of vertices exists and disconnected otherwise. A graph G 0 = ( V 0 ,E 0 ) is a subgraph of a graph G = ( V,E ), written G 0  X  G , iff V 0  X  V and E 0  X  E . If E 0 = ( V 0  X  V 0 )  X  E holds, G 0 = G [ V 0 ] is said to be induced by V 0 in G . Note that a subgraph of a connected graph may be discon-nected. In the following we will always refer to in-duced subgraphs and assume graphs to be labeled or attributed , i.e. a graph is a 3-tuple G = ( V,E,l ), where l : V  X  E  X  L is a labeling function associating the label l ( v ) to the vertex v and l ( e ) to the edge e . All labels are from the set L and may as well consist of tuples of attribute-value pairs.
 A graph isomorphism between two labeled graphs G 1 = ( V 1 ,E 1 ,l 1 ) and G 2 = ( V 2 ,E 2 ,l 2 ) is a bijec-tion  X  : V 1  X  V 2 that preserves adjacencies, i.e.  X  u,v  X  V 1 : ( u,v )  X  E 1  X  (  X  ( u ) , X  ( v ))  X  E 2 , and labels: Let  X   X  : V 1  X  V 1  X  V 2  X  V 2 be the map-ping of vertex pairs implicated by the bijection  X  such bels the conditions  X  v  X  V 1 : l 1 ( v )  X  l 2 (  X  ( v )) and  X  e  X  E 1 : l 1 ( e )  X  l 2 (  X   X  ( e )) must hold, where  X  de-notes that two labels are considered equivalent. Two graphs G 1 , G 2 are said to be isomorphic , written G 1 ' G 2 , if a graph isomorphism between G 1 and G 2 exists. An automorphism of a graph G = ( V,E ) is a graph isomorphism  X  : V  X  V . The set of automor-phisms of G is denoted by Aut( G ). Several graph kernels count the number of isomorphic subgraphs contained in two graphs. A common sub-graph isomorphism in contrast denotes a mapping be-tween such subgraphs that preserves their structure. Definition 1 (Common Subgraph Isomorphism) Let G 1 = ( V 1 ,E 1 ,l 1 ), G 2 = ( V 2 ,E 2 ,l 2 ) be two graphs and V 0 1  X  V 1 , V 0 2  X  V 2 subsets of their vertices. A common subgraph isomorphism (CSI) of G 1 and G 2 . 2 Based on this definition we define the following kernel and will see later that the function is p.s.d. Definition 2 (CSI Kernel) Let I ( G 1 ,G 2 ) denote the set of all CSIs of two graphs G 1 and G 2 and  X  : I ( G 1 ,G 2 )  X  R + a weight function. The function is called common subgraph isomorphism kernel . 2 When vertices and edges are annotated with arbitrary attributes it is inappropriate to require a mapping to preserve the structure and the labels of the two graphs exactly. To this end, we generalize Def. 2 to allow for a more flexible scoring of bijections referred to as graph matching .
 Definition 3 (Subgraph Matching Kernel) Given two graphs G 1 = ( V 1 ,E 1 ,l 1 ), G 2 = ( V 2 ,E 2 let B ( G 1 ,G 2 ) denote the set of all bijections between sets V 0 1  X  V 1 and V 0 2  X  V 2 and let  X  : B ( G 1 ,G 2 be a weight function. The subgraph matching kernel is defined as k where V 0 1 = dom(  X  ) and  X  V ,  X  E kernel function de-fined on vertices and pairs of vertices, respectively. 2 Theorem 1 The subgraph matching kernel is p.s.d. 2 Proof The structure of a graph G = ( V,E ) with n vertices can be encoded by a tuple ( ~v, e ), where ~v = ( v i ) n is a sequence of the vertices in V and e = [ e i,j ] n  X  n is a matrix of elements E  X  { } , such that e i,j = ( v i ,v j ) if ( v i ,v j )  X  E and otherwise. By extending ~v and e by additional -elements we can en-code graphs of different size into the same space. Each permutation of the vertices of a graph yields a valid encoding and a graph can be decomposed into all its encodings. This allows us to define a graph kernel by specifying an R -convolution (Haussler, 1999). Let R ( ~v, e ,G ) be a relation, where ~v and e are defined as above, G is a graph and R ( ~v, e ,G ) = 1 iff ( ~v, e ) is an be the set of encodings of G . We can now specify the R -convolution kernel k where  X  V ( ,  X  ) = 0. Combining this kernel with a con-volution kernel based on subgraph decomposition and a suitable weight function yields k ( G 1 ,G 2 ) = X This kernel is equivalent to k sm with  X  (  X  ) = 1, since there are exactly n ! pairs of encodings of two graphs with n vertices corresponding to the same bijection. We can identify Def. 2 as a special case of Def. 3, where  X 
V ( v 1 ,v 2 ) =  X 
E ( e 1 ,e 2 ) = These kernels assure that exactly the conditions of graph isomorphism are fulfilled. Therefore the CSI kernel is a special case of the subgraph matching ker-nel and we may state the following corollary.
 Corollary 1 The CSI kernel is p.s.d. 2 3.1. Relation to the Subgraph Kernel The definitions of subgraph kernels proposed slightly differs. Here we refer to induced subgraphs of un-bounded size.
 Definition 4 (Subgraph Kernel) Given two graphs G 1 ,G 2  X  X  and a weight function  X  s : G  X  R + . The subgraph kernel is defined as where k ' : G X G  X  { 0 , 1 } is the isomorphism kernel, i.e. k ' ( G 0 1 ,G 0 2 ) = 1 iff G 0 1 ' G 0 2 . 2 The subgraph kernel basically counts isomorphic sub-graphs, while the CSI kernel counts the number of iso-morphisms between subgraphs. Since there may be more than one isomorphism between a pair of isomor-phic subgraphs, both concepts differ in detail. Theorem 2 Let k s be a subgraph kernel with weight function  X  s and k csi a CSI kernel with weight func-k csi ( G 1 ,G 2 ) = k s ( G 1 ,G 2 ) for all graphs G 1 ,G Proof For each pair ( G 0 1 ,G 0 2 ) that contributes to the sum of Eq. (3), G 0 1 ' G 0 2 holds. CSIs exist for these pairs of graphs only. There are | Aut( G 0 1 ) | = | Aut( G isomorphism between G 0 1 and G 0 2 , each of which is con-tained in I ( G 1 ,G 2 ) and contributes to Eq. (1). This is compensated by the correction term | Aut( G 0 1 ) |  X  1 3.2. Relation to the Pharmacophore Kernel Mah  X e et al. (2006) proposed a kernel to compare chemical compounds based on characteristic features together with their relative spatial arrangement, so-called pharmacophores . To this end, a molecule is rep-resented by a set of pairs M = { ( x i ,l i )  X  R 3  X L} i where x i are the coordinates of a feature i in a 3-dimensional space and l i is an associated label. The set of pharmacophores of a molecule M is P ( M ) = { ( a 1 ,a 2 ,a 3 )  X  M 3 : a 1 6 = a 2 ,a 1 6 = a 3 ,a 2 pharmacophore kernel is then defined as k p ( M 1 ,M 2 ) = and measures the similarity of two molecules based on triples of similar characteristic features with a sim-ilar spatial arrangement, which is quantified by the two kernels k i and k s , respectively. These are de-fined as k i ( p,p 0 ) = Q 3 i =1 k feat ( l i ,l 0 i ) and k Q the Euclidean distance and the index i + 1 is taken modulo 3.
 From the representation M of a molecule as used by the pharmacophore kernel we can construct a graph G ( M ) = ( V M ,E M ,l M ), such that V M = { v 1 ,...,v | M | } with l M ( v i ) = l i and E M = V M  X  V with l M (( v i ,v j )) = || x i ,x j || .
 Theorem 3 Let k p be a pharmacophore kernel and k sm a subgraph matching kernel with weight func-tion  X  (  X  ) = 6 if | dom(  X  ) | = 3 and 0 otherwise and vertex and edge kernels defined as  X  V ( v 1 ,v k feat ( l ( v 1 ) ,l ( v 2 )) and  X  E ( e 1 ,e 2 ) = k dist Then k p ( M 1 ,M 2 ) = k sm ( G ( M 1 ) ,G ( M 2 )) holds. Proof The weight function  X  ensures that only sub-graphs with three vertices contribute to the value of k sm . Since G ( M ) is a complete graph by definition, each common subgraph induced by three vertices is a triangle, i.e. all triples of vertices with their pairwise distances are taken into account. For each subset with three vertices there are six different triples represent-ing all possible permutations. Comparing two subsets with three elements, 3! = 6 combinations of associ-ated triples correspond to the same mapping of three vertices. Thus, multiplying the value of 3-element sub-graph matchings by 6 compensates for this. 3.3. Kernel Computation In this section we propose an algorithm to compute the CSI and subgraph matching kernel. Our technique is inspired by a classical result of Levi (1973) who ob-served a relation between common subgraphs of two graphs and cliques in their product graph. Given two graphs G 1 = ( V 1 ,E 1 ,l 1 ) and G 2 = ( V 2 ,E 2 ,l (modular) product graph G P = ( V P ,E P ) of G 1 and G 2 is defined by V P = { ( v 1 ,v 2 )  X  V 1  X  V 2 : l 1 ( v 1 and E P containing an edge connecting two vertices ( u 1 ,u 2 ) , ( v 1 ,v 2 )  X  V P iff u 1 6 = v 1 ,u 2 6 = v 2 ther e 1 = ( u 1 ,v 1 )  X  E 1 and e 2 = ( u 2 ,v 2 )  X  E l ( e 1 )  X  l 2 ( e 2 ) ( c-edge ) or e 1 /  X  E 1 and e 2 edge ). The distinction of c-edges and d-edges is due to Koch (2001); c-edges represent common adjacency and d-edges common non-adjacency 1 . Thus, two vertices of the product graph are adjacent iff the correspond-ing vertex mappings can be part of the same CSI, see Fig. 1 for an example.
 Levi (1973) observed that each maximum clique in the product graph is associated with a maximum common subgraph of the factor graphs. Furthermore, the ver-tex set C is a clique in G P iff there is a correspond-ing CSI  X   X  I ( G 1 ,G 2 ). As a consequence we can enumerate (or count) all CSIs by enumerating (count-ing) the cliques of the product graph. To compute the subgraph matching kernel we extend the approach by means of a weighted product graph, where vertices and edges are annotated with the values of  X  V and  X 
E , respectively. Each clique is then associated with the product of the weights of all vertices and edges contained in it.
 Definition 5 (Weighted Product Graph) Given two graphs G 1 = ( V 1 ,E 1 ,l 1 ), G 2 = ( V 2 ,E 2 ,l vertex and edge kernels  X  V and  X  E , the weighted product graph (WPG) G P = ( V P ,E P ,c ) of G 1 and G 2 is defined by V P = { ( v 1 ,v 2 )  X  V 1  X  V 2 :  X  V ( v 1 ,v 2 ) &gt; 0 }
E P = { (( u 1 ,u 2 ) , ( v 1 ,v 2 ))  X  V P  X  V P : u 1 6 = v c ( v ) =  X  V ( v 1 ,v 2 )  X  v = ( v 1 ,v 2 )  X  V P c ( e ) =  X  E (( u 1 ,v 1 ) , ( u 2 ,v 2 ))  X  e  X  E P , where e = (( u 1 ,u 2 ) , ( v 1 ,v 2 )). 2 If we assume  X  E ( e 1 ,e 2 ) = 0 if e 1  X  E 1 and e 2 /  X  E or vice versa, the distinction of c-and d-edges carries over to weighted product graphs.
 Algorithm 1: SMKernel( w , C , P ) Input : WPG G P = ( V P ,E P ,c ), weight function  X  Initial : value  X  0; SMKernel( 1 ,  X  , V P ) Param. : Weight w of the clique C , candidate set P
Output : Result of the kernel function value while | P | &gt; 0 do 2 v  X  arbitrary element of P 3 C 0  X  C  X  X  v } 4 w 0  X  w  X  c ( v ) . multiply by vertex weight 5 forall the u  X  C do 6 w 0  X  w 0  X  c ( u,v ) . multiply by edge weights 7 value  X  value + w 0  X   X  ( C 0 ) 8 SMKernel( w 0 , C 0 , P  X  N ( v ) ) . extend clique 9 P  X  P \{ v } Algorithm 1 computes the subgraph matching kernel by enumeration of cliques. A current clique is extended stepwise by all vertices preserving the clique property. These vertices form the candidate set P . Whenever the current clique C is extended by a new vertex v , the weight of the vertex itself (line 4) and all the edges con-necting v to a vertex in C (line 6) are multiplied with the weight of the current clique w to obtain the weight of the new clique. The algorithm effectively avoids du-plicates by removing a vertex from the candidate set after all cliques containing it have been exhaustively explored (line 9). 3.3.1. Restriction to Subgraph Classes In this section we discuss restrictions to certain classes of subgraphs, their relation to cliques in the product graph and appropriate modifications of the enumer-ation algorithm. Since finding a maximum clique or a maximum CSI is known to be an NP -hard prob-lem, it may be required in practice to restrict the size of the subgraphs considered. Modifying Algorithm 1 to stop the recursion whenever a fixed maximum size k has been reached, effectively restricts the size of the cliques and thereby the size of the matched subgraphs, which is quantified by the number of vertices. Restricting to connected subgraphs may also signifi-cantly reduce the search space, especially when graphs are sparse. Moreover disconnected subgraphs con-vey less structural information and may therefore be considered less relevant. This constraint can be real-ized by an adaption of a technique proposed by Koch (2001). A clique that is spanned by c-edges, a so-called c-clique , corresponds to a connected CSI. Algorithm 1 can be modified to only enumerate c-cliques by mak-ing sure that only vertices are added that are adjacent to a vertex in the current clique via at least one c-edge. The restricted variants remain p.s.d., since they are equivalent to the general subgraph matching kernel with a suitably chosen weight function. 3.3.2. Runtime Analysis Complexity The runtime of Algorithm 1 depends on the number of cliques in the product graph. Since there is a one-to-one correspondence between cliques and bijections contributing to the kernel value, we can derive an upper bound for the number of cliques in G P by considering the number of possible bijections. There are n k induced subgraphs of size k in a graph with n vertices and up to k ! isomorphisms between graphs of size k . Thus, we have cliques of size up to k in G P . Therefore the worst-case runtime of Algorithm 1 (modified to stop recursion at depth k ) is O ( nC ( k )) = O ( kn k +1 ), where n = n 1 Practical considerations The analysis of the com-plexity shows that a reasonable performance in prac-tice can only be expected when the maximum size of the subgraphs considered is restricted. Therefore, the approach competes against subgraph or graphlet ker-nels. Besides the differences described in Sec. 3.1, the methods of computation exhibit substantially different characteristics: The runtime of our algorithm heavily depends on the number of allowed mappings of sub-graphs. For instances with diverse labels in combina-tion with a restrictive vertex kernel (e.g. Dirac kernel) the size of the product graph is typically substantially reduced, such that | V P || V 1 | X | V 2 | . In a similar way diverse edge labels may diminish the number of edges. Due to d-edges sparse graphs tend to have dense prod-uct graphs and contain a large number of cliques. How-ever, in this case the number of enumerated cliques can be significantly reduced by restricting to c-cliques. The computation of subgraph kernels is based on ex-plicit mapping into feature space. While this is ben-eficial for certain datasets, the number of subgraphs quickly becomes very large for graphs with diverse labels rendering explicit mapping prohibitive (Sher-vashidze et al., 2009). Furthermore, subgraph kernels are not applicable to attributed graphs. In these re-spects, our approach is complementary to subgraph kernels and shows promise for instances for which these approaches fall short. 4.1. Method &amp; Datasets We performed classification experiments using the C -SVM implementation LIBSVM 2 . We report mean pre-diction accuracies as well as standard deviations ob-tained by 10-fold cross-validation repeated 10 times with random fold assignment. Within each fold the parameter C was chosen from { 10  X  3 , 10  X  2 ,..., 10 3 } cross-validation based on the training set.
 We compared the subgraph matching kernel (SM and CSM with connection constraint) to kernels based on fixed length random walks (FLRW) and tree patterns 3 (TP), both supporting attributed graphs. Our imple-mentation is similar to the efficient dynamic program-ming approach proposed by Harchaoui &amp; Bach (2007). Furthermore, we compare to the Geometric Random Walk (GRW), Shortest Path (SP), Weisfeiler-Lehman Subtree (WL) and Weisfeiler-Lehman Shortest Path (WLSP) kernel. WLSP is similar to NSPDK recently proposed by Costa &amp; De Grave (2010).
 These graph kernels can be tuned by several param-eters. The maximum size of (C)SM was chosen from k  X  { 1 , 2 ,..., 7 } and a uniform weight function was used. FLRW was computed for walks of length l  X  { 1 , 2 ,..., 8 } and the parameter  X  for GRW was cho-sen from { 10  X  5 , 10  X  4 ,..., 10  X  2 } . For TP we used a uniform weight  X  chosen from { 10  X  5 , 10  X  4 ,..., 10  X  2 with height h  X  { 1 , 2 , 3 , 4 } . The number of itera-tions of WL/WLSP was chosen from h  X  X  0 , 1 ,..., 5 } . All parameters were selected by cross-validation on the training datasets only. As remarked before (Wale et al., 2008; Costa &amp; De Grave, 2010) kernels using features of different size are typically biased towards large features. Therefore, we also normalized kernel values separately for each feature size where applica-ble. Since the runtimes may depend on the selected parameters, we report the time required to compute a complete Gram matrix for each dataset using param-eters frequently selected by the optimization process. For a fair comparison all kernels were adapted to take vertex and edge labels into account and implemented in Java. For the pharmacophore kernel (PH) we used the implementation provided by the authors 4 . Exper-iments were conducted using Sun Java JDK v1.6.0 on an Intel Xeon E5430 machine at 2.66GHz with 8GB of RAM using a single processor only.
 Graphs with simple labels We employed bench-mark datasets containing molecules 5 and proteins: The MUTAG dataset consists of 188 chemical com-pounds divided into two classes according to their mu-tagenic effect on a bacterium. The PTC dataset con-tains compounds labeled according to carcinogenic-ity on rodents divided into male mice (MM), male rats (MR), female mice (FM) and female rats (FR). Molecules can naturally be represented by graphs, where vertices represent atoms and edges represent chemical bonds. We have removed explicit hydrogen atoms and labeled vertices by atom type and edges by bond type (single, double, triple or aromatic). We have obtained the dataset ENZYME from Borg-wardt et al. (2005), which is associated with the task of assigning 600 enzymes to one of the 6 EC top level classes. Vertices represent secondary structure ele-ments (SSE) and are annotated by their type, i.e. he-lix/sheet/turn. Two vertices are connected by an edge if they are neighbors along the amino acid sequence or one of three nearest neighbors in space. Edges are annotated with their type, i.e. structural/sequential. Attributed graphs Benchmark datasets containing attributed graphs are less wide-spread. We used the ENZYME dataset adding an attribute representing the 3d length of the SSE in  X  A to each vertex. The ver-tex kernel was defined as the product of a Dirac kernel on the type attributes and the Brownian bridge kernel with parameter c = 3 originally used on the length at-tribute, see (Borgwardt et al., 2005). The edge kernel remains a Dirac kernel on the type attribute.
 Further classification problems were derived from the chemical compound datasets BZR, COX2, DHFR and ER which come with 3D coordinates, and were used by Mah  X e et al. (2006) to study the pharmacophore kernel. We generated complete graphs from the compounds, where edges are labeled with distances 6 as described in Sect. 3.2 and vertex labels correspond to atom types. We used a triangular kernel to compare distances de-c from { 0 . 1 , 0 . 25 , 0 . 5 , 1 . 0 } by cross-validation. 4.2. Results &amp; Discussion The classification accuracies and runtimes are summa-rized in Tables 2 and 3. In terms of classification accu-racy on graphs with simple labels no general suggestion which kernel performs best can be derived. CSM per-forms best on FM, where walk-based kernels perform slightly worse. For the multiclass classification prob-lem ENZYME with simple labels CSM yields results comparable to WL and WLSP, while others perform worse. This observation also holds for ENZYME with attributes, where WL and WLSP can no longer be applied. All approaches benefit significantly from the additional vertex annotations, which indicates the im-portance of attributes, and CSM reaches the highest classification accuracy. On molecular distance graphs we observed that SM performs best in two of four cases and competitive on the other datasets. However, the differences here are rather small. Mah  X e et al. (2006) suggested to extend the pharmacophore kernel to take more than 3 points into account. At least for the in-stances we have tested, we observed that this does not lead to a significant increase in classification accuracy. Nevertheless, this might prove useful where more com-plex binding mechanism must be considered.
 The runtime results on graphs with simple labels clearly show that computation schemes based on ex-plicit mapping outperform other approaches. These all lie in the same order of magnitude and CSM is slower than FLRW and TP. For attributed graphs SP no longer allows explicit mapping. This leads to a con-siderable increase in runtime of SP on the ENZYME dataset, where it is now the slowest of the four tested approaches, while the other kernels noticeably benefit from the sparsity introduced by the vertex kernel tak-ing the length attribute into account. TP could not be employed to molecular distance graphs, since the runtime to compute a Gram matrix here exceeded 24h even for the most restrictive edge kernel with c = 0 . 1. This can be explained by the fact that this class of graphs contains vertices with large sets of matching neighbors, all subsets of which are considered by TP. The runtime of PH also is very high rendering the ap-proach infeasible for large datasets. We observed that the runtime of SM increased with the parameter c , which is as expected, since the product graph becomes more dense when the threshold parameter is raised. Therefore, we have also compared the runtime of PH and SM both using a Gaussian RBF kernel to compare distances, which leads to a very dense product graph. We found SM to be nevertheless approximately five times faster than PH, suggesting that our method of computation is superior in general. We also compared CSM to SM and observed that CSM is significantly faster on sparse graphs, while still reaching a compa-rable prediction accuracy. We have proposed a new graph kernel, which takes complex graph structures not containing repeated ver-tices into account and supports attributed graphs without restriction. The experimental evaluation shows promising results for attributed graphs from chem-and bioinformatics. Improving the runtime for large-scale datasets and large graphs remains future work. However, our approach already works well in practice for medium-sized graphs, large graphs when vertex and edge kernels are sparse, or when restricted to small or connected subgraphs. Thus, we believe subgraph matching kernels are a viable alternative to existing approaches for attributed graphs.
 We would like to thank Karsten Borgwardt and Nino Shervashidze for providing their kernel implementa-tions and datasets. Nils Kriege was supported by the German Research Foundation (DFG), priority pro-gramme  X  X lgorithm Engineering X  (SPP 1307).
 Borgwardt, K.M. and Kriegel, H.-P. Shortest-path ker-nels on graphs. In Proc. ICDM , pp. 74 X 81, 2005. Borgwardt, K.M., Ong, C.S., Schnauer, S., Vish-wanathan, S.V.N., Smola, A.J., and Kriegel, H.-P.
Protein function prediction via graph kernels. Bioin-formatics , 21 Suppl 1:i47 X  X 56, 2005.
 Costa, F. and De Grave, K. Fast neighborhood sub-graph pairwise distance kernel. In Proc. ICML , pp. 255 X 262, 2010.
 Fr  X ohlich, H., Wegner, J.K., Sieker, F., and Zell, A.
Optimal assignment kernels for attributed molecular graphs. In Proc. ICML , pp. 225 X 232, 2005.
 G  X artner, T., Flach, P., and Wrobel, S. On graph ker-nels: Hardness results and efficient alternatives. vol-ume 2777 of LNCS , pp. 129 X 143. 2003.
 Harchaoui, Z. and Bach, F. Image classification with segmentation graph kernels. In Proc. CVPR , 2007. Haussler, D. Convolution kernels on discrete struc-tures, 1999. Tech Rep UCSC-CRL-99-10.
 Kashima, H., Tsuda, K., and Inokuchi, A. Marginal-ized kernels between labeled graphs. In Proc. ICML , pp. 321 X 328, 2003.
 Koch, I. Enumerating all connected maximal common subgraphs in two graphs. Theor. Comput. Sci. , 250 (1-2):1 X 30, 2001.
 Levi, G. A note on the derivation of maximal common subgraphs of two directed or undirected graphs. Cal-colo , 1973.
 Mah  X e, P. and Vert, J.-P. Graph kernels based on tree patterns for molecules. Mach. Learn. , 75:3 X 35, 2009. Mah  X e, P., Ueda, N., Akutsu, T., Perret, J.-L., and Vert, J.-P. Extensions of marginalized graph kernels. In Proc. ICML , 2004.
 Mah  X e, P., Ralaivola, L., Stoven, V., and Vert, J.-P.
The pharmacophore kernel for virtual screening with support vector machines. J Chem Inf Model , 46(5): 2003 X 2014, 2006.
 Menchetti, S., Costa, F., and Frasconi, P. Weighted decomposition kernels. In Proc. ICML , 2005.
 Ramon, J. and G  X artner, T. Expressivity versus effi-ciency of graph kernels. In First International Work-shop on Mining Graphs, Trees and Sequences , 2003. Shervashidze, N., Vishwanathan, S.V.N., Petri, T.H.,
Mehlhorn, K., and Borgwardt, K.M. Efficient graphlet kernels for large graph comparison. In AIS-TATS , 2009.
 Shervashidze, N., Schweitzer, P., van Leeuwen, E.J.,
Mehlhorn, K., and Borgwardt, K.M. Weisfeiler-lehman graph kernels. JMLR , 12:2539 X 2561, 2011. Vishwanathan, S.V.N., Schraudolph, N.N., Kondor,
R.I., and Borgwardt, K.M. Graph kernels. JMLR , 11:1201 X 1242, 2010.
 Wale, N., Watson, I.A., and Karypis, G. Comparison of descriptor spaces for chemical compound retrieval and classification. Knowl Inf Sys , 14(3):347 X 375,
