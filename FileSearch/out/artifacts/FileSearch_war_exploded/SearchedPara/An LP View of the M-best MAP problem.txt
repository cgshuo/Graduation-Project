 A common task in probabilistic modeling is finding the assign ment with maximum proba-bility given a model. This is often referred to as the MAP (max imum a-posteriori) problem. Of particular interest is the case of MAP in graphical models , i.e., models where the prob-ability factors into a product over small subsets of variabl es. For general models, this is an NP-hard problem [11], and thus approximation algorithms ar e required. Of those, the class of LP based relaxations has recently received considerable attention [3, 5, 18]. In fact, it has been shown that some problems (e.g., fixed backbone protein d esign) can be solved exactly via sequences of increasingly tighter LP relaxations [13].
 In many applications, one is interested not only in the MAP as signment but also in the M maximum probability assignments [19]. For example, in a pro tein design problem, we might be interested in the M amino acid sequences that are most stable on a given backbone structure [2]. In cases where the MAP problem is tractable, o ne can devise tractable algo-rithms for the M best problem [8, 19]. Specifically, for low tree-width graph s, this can be done via a variant of max-product [19]. However, when finding MAPs is not tractable, it is much less clear how to approximate the M best case. One possible approach is to use loopy max-product to obtain approximate max-marginals and use th ose to approximate the M best solutions [19]. However, this is largely a heuristic an d does not provide any guarantees in terms of optimality certificates or bounds on the optimal v alues.
 LP approximations to MAP do enjoy such guarantees. Specifica lly, they provide upper bounds on the MAP value and optimality certificates. Further more, they often work for graphs with large tree-width [13]. The goal of the current wo rk is to leverage the power of LP relaxations to the M best case. We begin by focusing on the problem of finding the second best solution. We show how it can be formulated as a n LP over a polytope we call the  X  X ssignment-excluding marginal polytope X . In t he general case, this polytope may require an exponential number of inequalities, but we pr ove that when the graph is a tree it has a very compact representation. We proceed to u se this result to obtain approximations to the second best problem, and show how thes e can be tightened in various ways. Next, we show how M best assignments can be found by relying on algorithms for second best assignments, and thus our results for the second best case can be used to devise an approximation algorithm for the M best problem.
 We conclude by applying our method to several models, showin g that it often finds the exact M best assignments. Consider a function on n variables defined as: where V and E are the vertices and nodes of a graph G with n nodes. We shall be interested x (1) is the assignment that maximizes f ( x ;  X  ), x (2) is the 2 nd best assignment, etc. The MAP problem (i.e., finding x (1) ) can be formulated as an LP as follows [15]. Let  X  be over nodes. The set of  X  that arise from some joint distribution is known as the marginal polytope [15] and is denoted by M ( G ). Formally: where  X  is the set of distributions on x . The MAP problem can then be shown to be equivalent to the following LP: 2 It can be shown that this LP always has a maximizing  X  that is a vertex of M ( G ) and is integral. Furthermore, this  X  corresponds to the MAP assignment x (1) . Although the number of linear inequalities generally required to descri be the marginal polytope M ( G ). We shall find it useful to define a mapping between assignments x and integral vertices of the polytope. Given an integral vertex v  X  X  ( G ), define x ( v ) to be the assignment that corresponding to the assignment z . Thus the LP in Eq. 2 will be maximized by v ( x (1) ). One simple outer bound of the marginal polytope is the local p olytope M L ( G ), which only enforces pairwise constraints between variables:
M L ( G ) = The LP relaxation is then to maximize  X   X  where  X   X  X  L ( G ). For tree structured graphs, M L ( G ) = M ( G ) [15] and thus the LP relaxation yields the exact MAP x (1) . Assume we found the MAP assignment x (1) and are now interested in finding x (2) . Is there a simple LP whose solution yields x (2) ? We begin by focusing on the case where G is a tree so that the local LP relaxation is exact. We first treat the cas e of a connected tree. To construct an LP whose solution is x (2) , a natural approach is to use the LP for x (1) (i.e., the LP in Eq. 2) but somehow eliminate the solution x (1) using additional constraints. This, however, is somewhat trickier than it sounds. The key difficul ty is that the new constraints should not generate fractional vertices, so that the result ing LP is still exact. We begin by defining the polytope over which we need to optimiz e in order to obtain x (2) . Definition 1. The assignment-excluding marginal polytope is defined as:  X  M ( G, z ) is simply the convex hull of all (integral) vectors v ( x ) for x 6 = z . The following result shows that optimizing over  X  M ( G, x (1) ) will yield the second best solu-tion x (2) , so that we refer to  X  M ( G, x (1) ) as the second-best marginal polytope . the right is integral and corresponds to the second-best MAP assignment x (2) . The proof is similar to that of Eq. 2: instead of optimizing ov er x , we optimize over distribu-The key question which we now address is how to obtain a simple characterization of  X  M ( G, z ). Intuitively, it would seems that  X  M ( G, z ) should be  X  X imilar X  to M ( G ), such that it can be described as M ( G ) plus some constraints that  X  X lock X  the assignment z . To illustrate the difficulty in finding such  X  X locking X  constr aints, consider the following constraint, originally suggested by Santos [10]: P i  X  i ( z i )  X  n  X  1. This inequality is not satisfied by  X  = v ( z ) since v ( z ) attains the value n for the LHS of the above. Furthermore, for any x 6 = z and  X  = v ( x ), the LHS would be n  X  1 or less. Thus, this inequality separates v ( z ) from all other integral vertices. One might conclude that w e can define  X  M ( G, z ) by adding this inequality to M ( G ). The difficulty is that the resulting polytope has fractiona l vertices, 3 and maximizing over it won X  X  generally yield an integral sol ution. It turns out that there is a different inequality that does yie ld an exact characterization of  X  M ( G, z ) when G is a tree. We now define this inequality and state our main theo rem. Definition 2. Consider the functional I (  X  , z ) (which is linear in  X  ): where d i is the degree of node i in the tree graph G .
 Theorem 1. Adding the single inequality I (  X  , z )  X  0 to M ( G ) yields  X  M ( G, z ) . The theorem is proved in the appendix. Taken together with Le mma 1, it implies that x (2) may be obtained via an LP that is very similar to the MAP-LP, bu t has an additional constraint. We note the interesting similarity between I (  X  , z ) and the Bethe entropy [20]. The theorem also generalizes to the case where G is not a tree, but we have a junction tree where C and S are the junction tree cliques and their separators, respect ively, and d S is the number of cliques that intersect on separator S . In this case, the marginal polytope should enforce consistency between marginals  X  C ( z C ) and their separators  X  S ( z S ). However, such a characterization requires variables whose cardinal ity is exponential in the tree-width and is thus tractable only for graphs of low tree-width. In th e next section, we address approximations for general graphs.
 A corresponding result exists for the case when G is a forest. In this case, the inequality in Eq. 6 is modified to: I (  X  , z )  X | P | X  1, where | P | denotes the number of connected components of G . Interestingly, for a graph without edges, this gives the Sa ntos inequality. When the graph G is not a tree, the marginal polytope M ( G ) generally requires an exponen-tial number of inequalities. However, as mentioned above, i t does have an exact description in terms of marginals over cliques and separators of a juncti on tree. Given such marginals on junction tree cliques, we also have an exact characterizati on of  X  M ( G, z ) via the constraint in Eq. 7. However, in general, we cannot afford to be exponenti al in tree-width. Thus a common strategy [15] is to replace M ( G ) with an outer bound that enforces consistency be-tween marginals on overlapping sets of variables. The simpl est example is M L ( G ) in Eq. 3. In what follows, we describe an outer-bound approximation s cheme for  X  M ( G, z ). We use M
L ( G ) as the approximation for M ( G ) (more generally M L ( G ) can enforce consistency between any set of small regions, e.g., triplets). When G is not a tree, the linear constraint in Eq. 6 will no longer suffice to derive  X  M ( G, z ). Moreover, direct application of the inequality will incorrectly remove some integral vertices. An alterna tive approach is to add inequalities that separate v ( z ) from the other integral vertices. This will serve to elimin ate more and more fractional vertices, and if enough constraints are add ed, this may result in an integral solution. One obvious family of such constraints are those c orresponding to spanning trees in G and have the form of Eq. 5.
 Definition 3. Consider any T that is a spanning tree of G . Define the functional I T (  X  , z ) : where d T i is the degree of i in T . We refer to I T (  X  , z )  X  0 as a spanning tree inequality . For any sub-tree T of G , the corresponding spanning tree inequality separates the vertex v ( z ) from the other vertices. This can be shown via similar argum ents as in the proof of Theorem 1. Note, however, that the resulting polytope may st ill have fractional vertices. The above argument shows that any spanning tree provides a se parating inequality for  X  M ( G, z ). In principle, we would like to use as many such inequalitie s as possible. Definition 4. The spanning tree assignment-excluding marginal polytope is defined as: where the ST notation indicates the inclusion of all spanning tree inequ alities for G . 5 Thus, we would actually like to perform the following optimi zation problem: max as an approximation to optimization over  X  M ( G, z ); i.e., we seek the optimal  X  subject to all spanning tree inequalities for G with the ambition that this  X  be integral and thus provide the non-z MAP assignment, with a certificate of optimality.
 Although the number of spanning trees is exponential in n , it turns out that all spanning inequalities can be used in practice. One way to achieve this is via a cutting plane algorithm [12] that finds the most violated spanning tree inequality an d adds it to the LP. To implement can be decomposed into a sum over the edges in T (and a T -independent constant): The tree maximizing the above is the maximum-weight spannin g tree with edge-weights w ij =  X  ij ( z i , z j )  X   X  i ( z i )  X   X  j ( z j ). It can thus be found efficiently. The cutting plane algorithm proceeds as follows. We start by adding an arbitrary spanning tree. Then, as long as the optimal  X  is fractional, we find the spanning tree inequality that  X  most violates (where this is implemented via the maximum-we ight spanning tree). This constraint will necessarily remove  X  from the polytope. If there are no violated inequalities but  X  is still fractional, then spanning tree inequalities do not suffice to find an integral solution (but see below on hypertree constraints to add in th is case). In practice, we found that only a relatively small number of inequalities are need ed to successfully yield an integral solution, or determine that all such inequalities are alrea dy satisfied.
 An alternative approach for solving the all spanning-tree p roblem is to work via the dual. The dual variables roughly correspond to points in the spann ing tree polytope [16], opti-mization over which can be done in polynomial time, e.g., via the ellipsoid algorithm. We do not pursue this here since the cutting plane algorithm perfo rmed well in our experiments. As mentioned earlier, we can exactly characterize  X  M ( G, z ) using Eq. 7, albeit at a cost exponential in the tree-width of the graph. A practical comp romise would be to use in-equalities over clique trees of G , where the cliques are relatively small, e.g., triplets. Th e corresponding constraint (Eq. 7 with the small cliques and t heir separators) will necessarily separate v ( z ) from the other integral vertices. Finding the maximally vi olated such inequal-ity is an NP-hard problem, equivalent to a prize collecting S teiner tree problem, but recent work has found that such problems are often exactly solvable in practice [7]. It thus might be practical to include all such trees as constraints using a cutting plane algorithm. 2 nd -best formalism can be used to devise an algorithm for M best. We begin by describing an algorithm for the exact M best and then show how it can be used to approximate those we call P artitioning for E numerating S olutions (or PES) for solving the M best problem. The scheme is general and only assumes that MAP- X  X ike X  probl ems can be solved. It is inspired by several pre-existing M best solution schemes [4, 6, 8, 19] but differs from them in highlighting the role of finding a second best solution wit hin a given subspace. The modus operandi of the PES algorithm is to efficiently parti tion the search space while systematically excluding all previously determined assig nments. Significantly, any MAP Figure 2: Number of best ranks and normalized run-times for the attrac tive and mixed grids, and solver can be plugged into it, on the condition that it is capa ble of solving the arg max in the CalcNextBestSolution subroutine. The correctness of PES can be shown by observing that at the M th stage, all previous best solutions are excluded from the opt imization and no other assignment is excluded. Of note, this simple partit ioning scheme is possible due to the observation that the first-best and second-best MAP as signments must differ in the assignment of at least one variable in the graph.
 The main computational step of the PES algorithm is to maximi ze f ( x ;  X  ) subject to x 6 = x (  X  ) and x  X  CONSTRAINTS (see the CalcNextBestSolution subroutine). The CONSTRAINTS set merely enforces that some of the coordinates of x are either equal to or different from specified values. 6 Within the LP, these can be enforced by setting  X  ( x i = a ) = 1 or  X  i ( x i = a ) = 0. It can be shown that if one optimizes  X   X  with these constraints and  X   X   X  M ( G, x (  X  ) ), the solution is integral. Thus, the only element requiring approximation in the general case is the descript ion of  X  M ( G, x (  X  ) ). We choose as this approximation the polytope  X  M ST L ( G, x (  X  ) ) in Eq. 9. We call the resulting approxima-tion algorithm S panning TR ee I nequalities and P artitioning for E numerating S olutions, or STRIPES. In the next section, we evaluate this scheme experi mentally. We compared the performance of STRIPES to the BMMF algorithm [19] and the best assignment is obtained from maximizations within O ( n ) partitions, so that its run-time is O ( n ) times the cost of finding a single MAP. Here we approximated e ach MAP with its LP relaxation (as in STRIPES), so that both STRIPES a nd Nilsson come with certificates of optimality when their LP solutions are integ ral. BMMF relies on loopy BP to approximate the M best solutions. 7 We used M = 50 in all experiments. To compare the algorithms, we pooled all their solutions, noting the 50 top probabilities, and then counted the fraction of these that any particular algorithm found (i ts solution rank). For run-time comparisons, we normalized the times by the longest-runnin g algorithm for each example. We begin by considering pairwise MRFs on binary grid graphs o f size 10  X  10. In the first experiment, we used an Ising model with attractive (submodu lar) potentials, a setting in which the pairwise LP relaxation is exact [14]. For each grid edge ij , we randomly chose J ij  X  [0 , 0 . 5], and local potentials were randomized in the range  X  0 . 5. The results for 25 graphs are shown in Fig. 2. Both the STRIPES and Nilsson algor ithms obtained the 50 optimal solutions (as learned from their optimality certifi cates), while BMMF clearly fared less well for some of the graphs. While the STRIPES algorithm took &lt; 0 . 5 to 2 minutes to run, the Nilsson algorithm took around 13 minutes. On the o ther hand, BMMF was quicker, taking around 10 seconds per run, while failing to fi nd a significant portion of the top solutions. Overall, the STRIPES algorithm was required to employ up to 19 spanning tree inequalities per calculation of second-best solution . Next, we studied Ising models with mixed interaction potent ials (with J ij and the local po-were not able to successfully find the top solutions. Thus, we added regions of triplets (two for every grid face) to tighten the LP relaxation (for STRIPE S and Nilsson) and to perform GBP instead of BP (for BMMF). This resulted in STRIPES and Nil sson always provably finding the optimal solutions, and BMMF mostly finding these s olutions (Fig. 2). For these more difficult grids, however, STRIPES was the fastest of the a lgorithms, taking 0 . 5 -5 minutes. On the other hand, the Nilsson and BMMF algorithms t ook 18 minutes and 2 . 5 -7 minutes, respectively. STRIPES added up to 23 spanning tre e inequalities per iteration. The protein side-chain prediction (SCP) problem is to to pre dict the placement of amino acid side-chains given a protein backbone [2, 18]. Minimiza tion of a protein energy function corresponds to finding a MAP assignment for a pairwise MRF [19 ]. We employed the dataset of [18] (up to 45 states per variable, mean approxima te tree-width 50), running all algorithms to calculate the optimal side-chain configurati ons. For 315 of 370 problems in the dataset, the first MAP solution was obtained directly as a result of the LP relaxation having an integral solution ( X  X asy X  problems). STRIPES pro vably found the subsequent top 50 solutions within 4 . 5 hours for all but one of these cases (up to 8 spanning trees pe r calculation), and BMMF found the same 50 solutions for each c ase within 0 . 5 hours; note that only STRIPES provides a certificate of optimality for th ese solutions. On the other hand, only for 146 of the 315 problems was the Nilsson method a ble to complete within five days; thus, we do not compare its performance here. For th e remaining 55 ( X  X ard X ) problems (Fig. 2), we added problem-specific triplet region s using the MPLP algorithm [13]. We then ran the STRIPES algorithm to find the optimal sol utions. Surprisingly, it was able to exactly find the 50 top solutions for all cases, usi ng up to 4 standard spanning tree inequalities per second-best calculation. The STRIPE S run-times for these problems ranged from 6 minutes to 23 hours. On the other hand, whether r unning BMMF without these regions (BP) or with the regions (GBP), it did not perfo rm as well as STRIPES in terms of the number of high-ranking solutions or its speed . To summarize, STRIPES provably found the top 50 solutions for 369 of the 370 protein SCP problems. In this work, we present a novel combinatorial object  X  M ( G, z ) and show its utility in obtaining the M best MAP assignments. We provide a simple characterization of it for tree structured graphs, and show how it can be used for approx imations in non-tree graphs. As with the marginal polytope, many interesting questions a rise about the properties of  X  M ( G, z ). For example, in which non-tree cases can we provide a compa ct characterization (e.g., as for the cut-polytope for planar graphs [1]). Anoth er compelling question is in which problems the spanning tree inequalities are provably optim al.
 An interesting generalization of our method is to predict di verse solutions satisfying some local measure of  X  X istance X  from each other, e.g., as in [2].
 Here we studied the polytope that results from excluding one assignment. An intriguing question is to characterize the polytope that excludes M assignments. We have found that geometry is apparently more complicated than that of  X  M ( G, z ).
 Here we used LP solvers to solve for  X  . Such generic solvers could be slow for large-scale problems. However, in recent years, specialized algorithm s have been suggested for solving MAP-LP relaxations [3, 5, 9, 17]. These use the special form o f the constraints to obtain local-updates and more scalable algorithms. We intend to ap ply these schemes to our method. Finally, our empirical results show that our method indeed leverages the power of LP relaxations and yields exact M best optimal solutions for problems with large tree-width. Acknowledgements Denote p  X  ( z ) as the minimal value of p ( z ) among all p ( x ) that give  X  . We prove that p The proof is by induction on n . For n = 1, the node has degree 0, so I (  X  , z ) =  X  1 ( z 1 ). (assume that its index is n and its neighbor X  X  is n  X  1). Denote  X  G as the tree obtained by removing node n and its edge with n  X  1. For any assignment x , denote  X  x as the corresponding sub-assignment for the first n  X  1 variables. Also, any  X  can be derived by adding appropriate coordinates to a unique  X   X   X  X  (  X  G ). For an integral vertex  X  = v ( x ), any  X  and its projected  X   X  , it can be seen that: where we define  X  = P x construct a p ( x ) that has marginals  X  and the desired minimal p  X  ( z ). Consider three cases: is identical to that used in proving that M L ( G ) = M ( G ) for a tree graph G . Simple algebra shows that p ( x ) is non-negative and has  X  as marginals. We now show that p ( z ) is minimal. Based on the inductive assumption and Eq. 11, it can easily be shown Since the p ( z ) we define achieves this lower bound, it is clearly minimal.
  X  p which indeed marginalizes to  X  , and p ( z ) = 0 so that p  X  ( z ) = 0, as required.
