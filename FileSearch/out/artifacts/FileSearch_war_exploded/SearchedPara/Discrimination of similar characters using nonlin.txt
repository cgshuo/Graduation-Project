 ORIGINAL PAPER Sangjin Ryu  X  In-Jung Kim Abstract Discrimination of confusing characters is very important in recognition of character sets containing a mul-titude of similar characters. Confusing characters have very similar shapes and are separated by only a small difference. For a successful discrimination, we need to focus on that difference. However, the small difference can be reduced or even lost during the feature extraction process. In such a case, further analysis after the feature extraction rarely succeeds. This paper proposes a discriminative nonlinear normaliza-tion algorithm to improve discrimination ability. The pro-posed method emphasizes the difference between confusing characters. It measures the importance of each region in the discrimination of confusing characters. Then, it resamples the image according to the regional importance measure. As a result, it expands important regions but shrinks less impor-tant regions. Since it emphasizes important regions in the preprocessing step, it does not suffer from the information loss during the feature extraction. In experiments, the pro-posed method successfully detected and expanded impor-tant regions. In handwritten Hangul recognition, the pro-posed method outperformed other two recently developed pair-wise discrimination methods. On SERI95a data set, it improved the recognition rate from 87.69 to 90.11 %, achiev-ing a 19.66 % error reduction rate.
 Keywords Pair-wise discrimination  X  Discriminative normalization  X  Nonlinear normalization  X  Handwritten character recognition  X  Handwritten Hangul recognition 1 Introduction For the last few decades, character recognition technology has been applied in many practical applications. Most statis-tical character recognition systems include three major steps: normalization, feature extraction, and classification. The nor-malization step regulates the shape variation of the character image. The feature extraction step extracts a feature vector from the normalized image. Finally, the classification step analyzes the feature vector to decide the recognition result.
Difficulties in handwritten character recognition mainly come from writing variations and confusing characters. To regulate shape variation, researchers have developed many nonlinear normalization methods, and they were proven to be effective [ 1  X  5 ]. On the other hand, confusing characters are handled by various methods including discriminative clas-sifiers (MLP, SVM) [ 6 ], discriminative learning algorithms (LVQ, DLQDF) [ 7 , 8 ], and discriminative feature transform algorithms (FLD) [ 9 ]. It is noticeable that many methods to improve discrimination ability work on feature vectors.
AsshowninFig. 1 , confusing characters often have very similar shapes. Especially, many Hangul characters are almost identical to other characters except for only a small difference. For a successful discrimination, we need to focus on that difference. However, the small difference can be lost during the feature extraction process. In such a case, the fea-ture vector does not carry essential information to recognize the character correctly, and as a result, the following analysis of the feature vector can easily fail. Therefore, it is necessary to emphasize the difference before the feature extraction step.
In this paper, we propose a discriminative normaliza-tion method and a pair-wise discrimination method based on it. The discriminative normalization emphasizes the dif-ference between confusing characters by expanding regions important in the discrimination of the characters. First, it statistically measures the importance of each region in the discrimination of the two characters. Then, it resamples the image to evenly distribute the regional importance measure. As a result, important regions are expanded while other regions are shrunken. Since it emphasizes important regions in the preprocessing step, it is does not suffer from the infor-mation loss during the feature extraction step.
 The remaining parts of this paper are organized as follows: Sect. 2 introduces previous work on pair-wise discrimination and nonlinear normalization. Section 3 describes the discrim-inative normalization and the pair-wise discrimination meth-ods. The experiment results are presented in Sect. 4 . Finally, Sect. 5 makes the conclusions. 2 Related works 2.1 Pair-wise discrimination It is not easy to achieve high recognition performance on a character set containing a multitude of similar characters. All class recognizers are often not enough to discriminate characters with very similar shapes. Many researchers have tried to overcome this problem by pair-wise discrimination. A pair-wise discriminator is a binary recognizer specialized for a particular confusing character pair. It is usually used as a post-processor of the recognition system to check, and if necessary, correct the recognition result.

The most effective way to discriminate confusing char-acters is to focus on the difference between the characters. In the structural approach, the difference between charac-ters was focused on by emphasizing discriminative strokes, i.e., the strokes making the difference. Kim and Kim [ 10 ] proposed a pair-wise discrimination method by assigning weights to each stroke. They extracted strokes from the input character images and matched them to the strokes of each of the character models. Then, they computed character-level matching score by averaging stroke-level matching scores. In the averaging, he assigned each stroke a weight accord-ing to its importance measured by a training algorithm. Jang [ 11 ] also developed a pair-wise discriminator for structural recognizers. With the stroke matching result provided by the structural recognizer, he statistically analyzed the region con-taining discriminative strokes. Finally, he integrates the result of the statistical analysis with that of the structural recognizer to decide the final result.

In the statistical approach, the difference between charac-ters was focused on by emphasizing critical regions. A criti-cal region is the region that contains essential information for discrimination. Suzuki et al. detected critical regions by com-pound Mahalanobis function (CMF) [ 12 ]. Leung detected critical regions by Fisher X  X  linear discriminant (FLD) and showed that CMF is a special case of FLD [ 13 ]. From a 256-D feature vector, composed of 4-directional features extracted from an 8  X  8gridwitha16  X  16 Gaussian mask, he found the optimal projection axis to separate the two classes by FLD. The optimal projection axis is obtained by finding w that maximizes J (w) defined in ( 1 ), where S B is the between-class scatter matrix and S w is the within-class scatter matrix. J (w) = With the optimal projection axis w , the importance of each feature dimension can be measured by the absolute magni-tude of its component in w . Thus, he identified the critical regions of a confusing pair by choosing the components of that have large absolute magnitudes. Then, he extracted addi-tional features from the critical regions. Finally, he decided the discrimination result by MQDF on 384-D augmented feature vector composed of 256 original features and 128 addition features.

Xu et al. [ 14 ] detected critical regions using an aver-age symmetric uncertainty (ASU). From the input image, he extracted 8 directional contour gradient features with an 8 mesh. The relevance between a feature element and a class Y can be measured by the symmetric uncertainty (SU) defined as ( 2 ), where X ij denotes the j th directional feature element extracted from the i th mesh region (1  X  j  X  8 , 1  X  i  X  64). I ( X ij ; Y ) is the mutual information between X ij and Y . H ( X tively.
 SU ij = 2 The ASU of the i th mesh region is obtained by averaging SU X  X  of the feature elements extracted from that mesh region as ( 3 ).
 ASU i = In other words, Xu measured the importance of each mesh region by the relevance between the region and the class. He identified critical regions by selecting mesh regions with higher ASU than a threshold. Then, he discriminated the characters by feature elements extracted only from the criti-cal regions. Therefore, the discriminator could focus on the critical regions, and there was less interference due to shape variation.

On the other hand, Shao et al. [ 15 ] applied the boost-ing framework to improve discrimination ability. Using the AdaBoost algorithm, they iteratively updated the distribu-tion of samples to minimize classification errors. Applying the multiple instance learning (MIL) based method, they tried to alleviate the problem that the style and scale of the critical region may change. 2.2 Nonlinear normalization The primary purpose of the nonlinear normalization is to reduce shape variation. Yamashita et al. [ 1 ] proposed a non-linear normalization algorithm based on pixel density equal-ization. Yamada et al. [ 2 ] and Tsukumo and Tanaka [ 3 ]also developed similar algorithms. However, they equalized the line density instead of the pixel density. In Lee X  X  evalu-ation, Tsukumo X  X  method showed good performance with reasonable computational costs [ 4 ]. Liu and Marukawa [ 5 ] developed a density projection interpolation method that can extend 1D normalization algorithms to their pseudo 2D coun-terparts. 3 Pair-wise discrimination using discriminative normalization 3.1 System overview The structure of the whole recognition system is presented in Fig. 2 . After the baseline recognizer, the pair-wise dis-criminator checks the recognition result and corrects it if necessary. The pair-wise discriminator is composed of dis-criminative normalization, feature extraction, and classifica-tion steps. The main idea of the proposed method is on the discriminative normalization.

As shown in Fig. 3 , the discriminate normalization is composed of two phases: a training phase and a normal-ization phase. In the training phase, it preliminarily nor-malizes training samples to minimize shape variation. Any shape normalization algorithm that is effective to reduce shape variation can be used for the preliminary normaliza-tion. In our implementation, we applied the line density pro-jection interpolation (LDPI) algorithm [ 5 ]. Then, it estimates the importance of each region in the discrimination of each confusing character pair to generate a regional importance map. In the normalization phase, it applies the preliminary normalization to the input image as it did in the training phase. Then, it resamples the pre-normalized image to evenly distribute the regional importance measure. As a result, it expands the important regions but shrinks the less important regions.

However, regional importance equalization can cause an undesirable side effect. Expanding important regions strengthens discriminative information, but at the same time, it can also increase the shape variation. To suppress shape variation minimizing the loss of discriminative information, we applied a template fitting step after the regional impor-tance equalization. It transforms the image to fit its pixel density distribution to prototype templates, which were gen-erated in the training phase. 3.2 Regional importance estimation Unlike some previous work [ 13 , 14 ], the proposed method does not explicitly distinguish critical regions from noncriti-cal regions. Instead, it measures regional importance in con-tinuous values and stores them in a regional importance map. high importance measure. We estimate the regional impor-tance by analyzing the feature vectors extracted from the pre-normalized training images. First, the feature extractor categorizes each contour pixel into one of the 8 directions shown in Fig. 4 , according to the gradient direction. Then, with an 8  X  8 mesh, it counts the number of contour pixels of each direction in each mesh region. As a result, it generates a 512-D feature vector from each image.

In the discrimination of two classes, the contribution r 2 of the i th feature element to reducing error probability is computed by ( 4 ), where  X  2 i is the variance of the i th feature element, and  X  1 i and  X  2 i are the means of the two classes, respectively [ 17 ]. r = We extended ( 4 ) to compute the contribution of each mesh region to reducing error probability. The contribution of a mesh region at j th column of i th row is defined by the sum of the contributions of all feature elements extracted from that mesh region. It is computed as ( 5 ), where the three dimen-sional index ( i , j , d ) denotes the d th directional feature ele-ment of the ( i , j )th mesh region.
 R Equation ( 5 ) defines the importance of each mesh region. However, to generate a regional importance map, we need a pixel-level regional importance measure. We computed a pixel-level regional importance measure by Gaussian inter-polation on the mesh-level regional importance measure. The rightmost two columns of Fig. 5 show some examples of the mesh-level and the pixel-level regional importance estimated by the proposed method. The second and the third columns show the average of the pre-normalized character images belonging to each class. In the regional importance maps in the right-most column, the pixels in the region that make the difference between the two classes were assigned much higher values than the other pixels. 3.3 Regional importance equalization With the regional importance map, the proposed method resamples the pre-normalized image to emphasize the impor-tant regions. Inspired by nonlinear normalization algorithms based on the line density equalization [ 1 , 5 ], we applied a transformation that equalizes the regional importance mea-sure on the transformed image. As the line density equaliza-tion expands the region with a high line density, our algorithm expands the region with a high importance measure. Figure 6 shows the procedure of the regional importance equalization for discrimination of a class pair ( , ). First, the pro-posed algorithm finds a coordinate mapping to evenly dis-tribute the regional importance measure. Then, it resamples the pre-normalized image using that coordinate mapping.
In contrast to that the line density distribution is extracted from each input image, the regional importance map is gener-ated for each class pair. Thus, the coordinate mapping for the regional importance equalization is also defined for a class pair rather than an individual image. It provides an additional benefit: the coordinate mapping function can be computed in the training phase, which can save computational costs dur-ing the normalization phase.

As pointed out in [ 15 ], most pair-wise discrimination methods that focus on critical regions, including the pro-posed method, have a potential problem possibly caused by style and scale variation in the critical region. Especially, image does not match with what was trained, they can pro-duce incorrect results. However, the proposed method has two kinds of remedies to alleviate this problem. First, it reduces shape variation of the character image by applying preliminary normalization before the regional importance estimation and the regional importance equalization. Sec-ond, the Gaussian interpolation used in the regional impor-tance estimation makes the regional importance map have a smooth shape, which is helpful to tolerate discrepancy in location/scale of the critical region.

For the regional importance equalization, we applied the algorithm used in the line density projection interpolation (LDPI) [ 5 ] with a little modification. As a pseudo 2D equal-ization algorithm, LDPI is more effective than the 1D line density equalization algorithms. The primary difference is that our algorithm equalizes regional importance measures while LDPI equalizes the line density. We call this algorithm the regional importance projection interpolation (RIPI).
Denoting the input and the output images by f ( x , y ) and g ( x , y ) , respectively, the resampling algorithm is imple-mented by a coordinate mapping from the input coordinate ( x , y )on f to its counterpart ( x , y )on g as ( 6 ), where F and F y (  X  ) are functions to compute the new horizontal and vertical coordinates, respectively. x = F With the regional importance map s ( x , y ) , RIPI computes the coordinate mapping to evenly distribute the regional impor-tance measures. In this paper, we will describe only hori-zontal coordinate mapping because the vertical coordinate mapping is computed in the same way. First, it vertically divides the regional importance map into three overlapping soft strips, each of which covers [0, y c ], [0, H 1 ], and [ y respectively. H 1 is the height of the input image, and y y -coordinate of the centroid. Then, it computes the projection of regional importance in each strip as ( 7 ). s x , y ) = w i ( y ) s ( x , y ), i = 1 , 2 , 3(7) The weights for the strips w i ( y )  X  X  are piece-wise linear func-tions defined as ( 8 ). A pre-defined constant w 0 controls the weight of the upper/lower part of the regional importance map (details in [ 5 ]). w 1 ( y ) = w w 2 ( y ) = 1  X  w 1 ( y ), for y &lt; y w 2 ( y ) = 1  X  w 3 ( y ), for y  X  y w 3 ( y ) = w The regional importance projection of the three strips project onto the x axis: p i ( x ) = With ( 9 ), the coordinate mapping function x i ( x ), { 1 , 2 , 3 } , of each strip is defined by a method similar to1D density equalization [ 16 ]. x i ( x ) is computed as ( 10 ), where W 2 is the width of the output image. x h i ( x ) is the normalized regional importance projection of the i th strip. It is defined as ( 11 ), where p i ( x ) is computed as ( 9 ). h i ( x ) = p Finally, x i ( x )  X  X  are combined to define a 2D mapping func-tion by interpolation as ( 12 ). The mapping of the vertical coordinate is computed in the same way. x ( x , y ) = 3.4 Template fitting The last step of the discriminative normalization process is the template fitting to regulate the shape variation increased by the regional importance equalization. It is well known that resampling the image to equalize a characteristic feature, such as line or pixel density, reduces the shape variation sig-nificantly [ 16 ]. From the fact that the discriminative normal-ization works for a particular class pair, we further improved the line/pixel density equalization using class-specific infor-mation. The proposed method also transforms the image to modify the distribution of the line/pixel density. However, instead of equalizing line/pixel density, it fits the density dis-tribution to the prototype templates of particular classes. This algorithm regulates shape variation minimizing the loss of class-specific feature. In a preliminary experiment, the pixel density fitting showed better result than the line density fit-ting. Therefore, we will explain focusing on the pixel density fitting.

The goal of the template fitting is to transform the input image to have a pixel density distribution as close to that of the template as possible. Like the line/pixel density equal-ization algorithms [ 1 ], the proposed algorithm computes the coordinate transform with accumulated pixel densities. Let d ( x , y ) denote the local pixel density at a coordinate ( x The horizontally and vertically accumulated pixel densities at ( x , y ) are defined as D normalization factors to make them sum up to 1.
Given the horizontally/vertically accumulated pixel den-( x , y ) is mapped to a new coordinate ( x , y )as( 13 ): ( x , y ) = argmin (
For the implementation, we approximated the 2D accumu-lated pixel densities by the projection interpolation [ 5 ], as we did for the regional importance equalization. To approximate D soft strips, each of which covers [0, y c ], [0, H 1 ], and [ y respectively. Then, for i th soft strip, it computes D I , ( 14 ).
 D With the weights defined as ( 8 ), D I h ( x , y ) is approximated as ( 15 ).
 D D case, we divide the image into vertical strips.

To build the prototype template, we average the training samples to get the average pixel density distribution. Then, we apply the projection interpolation to build D I , i h ( D phase, we compute and store the horizontally and vertically accumulated pixel densities D T h ( x , y ) and D T v ( x training phase.

As the pair-wise discriminator separates a pair of confus-ing classes, each pair-wise discriminator has two prototype templates, one for each class. T T We fit the input image with both of the class templates. As a result, we have two images after the template fitting. The feature extractor produces a 512D feature vector from each image and then combines it into a 1024D feature vector, which is fed to the discriminator. 3.5 The pair-wise discriminator The pair-wise discriminator consists of three steps: charac-ter normalization, feature extraction, and classification. The discriminative normalization was applied for the normaliza-tion step. For the feature extraction, we applied two methods, each of which is similar to the methods used by Leung and Leung [ 13 ] and Xu et al. [ 14 ], respectively. Both methods are based on the contour gradient feature. After normalizing the input image into a 64  X  64 image using LDPI algorithm [ 5 ], they decompose contour pixels into 8 directions as shown in Fig. 4 according to the gradient direction. The two methods are distinguished in the way to form the feature vector from the decomposed contour pixels. The first algorithm is similar to [ 14 ]: it places an 8  X  8 mesh on the image and counts the contour pixels of each direction in each mesh region to form the feature vector. On the other hand, the second method, like [ 13 ], samples the feature with a 16  X  16 Gaussian mask and an 8  X  8 grid. For each direction, each feature elements is com-puted with the Gaussian mask located at each vertex of the grid. As the template fitting step produces two output images for each input image, the pair-wise discriminator extracts fea-ture from both images. As the result, the feature vector has 1,024 feature elements. For the classification, we applied the modified quadratic discriminant function (MQDF) [ 18 ]. 4 Experiments 4.1 Experimental environment To evaluate the proposed method, we applied it to handwrit-ten Hangul recognition. Hangul contains a multitude of sim-ilar characters. Even the best recognizers developed so far could not achieve high performance on handwritten Hangul mainly because of confusing characters. Therefore, hand-written Hangul is a good language to evaluate pair-wise dis-crimination methods. However, the proposed method does not use any feature unique to Hangul.

For the experiment, we used the SERI95a data set, also known as the KU-1 data set [ 19 ]. The SERI95a data is one of the best known handwritten Hangul data sets containing the 520 most frequently used classes, and each class has about 1,000 samples. We used 90 % for training and the remaining 10 % for the test. The large portion of the training data is due to the fact that we needed to train both baseline recogni-tion and pair-wise discriminators, and the MQDF classifier requires a sufficient number of training samples. We further divided the training set into Tr1 and Tr2 data sets. Tr1 data set covers 60 % of the training samples and was used to train the baseline recognizer. Tr2 data set covers the remaining 40 %, and was used to select confusing pairs and to train pair-wise discriminators. The test data were not used to train the base-line recognizer or the pair-wise discriminators and used only to measure their performances.

To build the baseline recognizer, we combined statistical methods known effective in handwritten Chinese character recognition. It normalizes the input image with LDPI [ 5 ], extracts feature vector using the normalization-cooperated gradient feature extraction [ 16 ], and classifies using MQDF [ 18 ].

We selected confusing pairs to apply pair-wise discrim-ination by analyzing the confusion table of the baseline recognizer. We recognized the Tr2 data set with the base-line recognizer and counted errors between each character pair. Then, we selected the 1,500 most frequently confused class pairs. They cover about 60 % of all the recognition errors.

In the evaluation, we compared the proposed method with two other pair-wise discrimination methods recently developed by Leung and Leung [ 13 ] and Xu et al. [ 14 ], respectively. We implemented their methods to detect crit-ical regions and the methods to focus on the critical regions as described in [ 13 , 14 ]. However, we replaced their normal-ization and feature extraction algorithms with the methods described in Sect. 3.5 in order to compare them under the same environment.
 For the experiment, we used a system that has a 2.93 GHz Intel i7 CPU and 8 GB memory. The CPU was a quad-core CPU, but we used a single thread to measure the speed. 4.2 Regional importance estimation First, we generated regional importance maps using the three methods, and visualized them. Some examples are presented in Table 1 . All of the three methods produced reasonable results. They successfully detected regions making the dif-ferences between the characters. Among them, the proposed method provided the results closest to our intuition, as shown in Table 1 . It produced results more focused on the regions that make up the difference than the other methods. 4.3 Overall evaluation To analyze the practical effect of the proposed method for the recognition performance, we integrated the three pair-wise discriminators with the baseline recognizer and measured their overall performances. Basically, the pair-wise discrimi-nator checks, and if necessary, corrects the result of the base-line recognizer. However, there are a couple of issues on the integration of the two modules. One is the method to combine the results of the discriminator and the baseline recognizer to decide the final result, especially when their decisions are different. The other is the method to decide character pairs to activate pair-wise discriminators given a set of candidate classes provided by the recognizer.

In regard to the first issue, we tested two approaches. One was simply to choose the class with the higher discrimination score ignoring the result of the baseline recognizer. The other approach is the one used in [ 14 ]. It combines the scores of the two modules by weighted averaging, and then, chooses the class with higher score. As [ 14 ], we assigned the same weights to the recognizer and the discriminator. We will call the former  X  X iscriminator only X  and the latter  X  X iscriminator + recognizer X .

We also tested two approaches on the second issue. One is the method used by Leung and Leung [ 13 ] and Xu et al. [ 14 ]. If the first and the second candidates make a pair from the confusing pair list, the result is checked by the correspond-ing pair-wise discriminator. Otherwise, it accepts the first candidate as the final result without any pair-wise discrimina-tion. However, this approach is not enough for character sets including many similar characters, such as Hangul. There-fore, we tried a more aggressive approach. First, it checks whether the first and the second candidates make a pair on the confusing pair list. If so, the corresponding pair-wise discriminator decides the final result. Otherwise, it checks whether the first and the third candidates make a pair on the confusing pair list. In this way, it compares the first candidate with up to the tenth candidate. We will call the former  X 1st versus 2nd X  and the latter  X 1st versus 2nd X 10th X .

We began by experimenting on the first issue, the combin-ing method. In this experiment, we applied the  X 1st versus 2nd X 10th X  method to select class pairs to discriminate. The results are shown in Table 2 . The  X  X iscriminator + recog-nizer X  method showed better results for all pair-wise discrim-ination methods. In all cases, the proposed method outper-formed the other two methods. As well, the feature extractor using the Gaussian mask provided higher performances than the mesh-based feature extractor.

There was also an interesting observation. Using the  X  X is-criminator only X  method, Leung X  X  method showed better per-formance than Xu X  X  method. However, Xu X  X  method showed better performance than Leung X  X  method when we used the  X  X iscriminator + recognizer X  method. We guess the reason is that Leung X  X  method uses augmented feature vectors that already include the original feature used by the baseline recognizer. Therefore, integrating with the recognition score did not improve the performance very much. On the other hand, Xu X  X  method discriminates the characters with features extracted only from critical regions ignoring features from other regions. Therefore, the score of the baseline recognizer could be more complementary to Xu X  X  method than Leung X  X  method. Xu X  X  method was better than Leung X  X  method in the highest performance, but the difference was not very large.
The results of the experiment on the second issue, the way to select class pairs to discriminate, are presented in Table 3 . At this time, we decided the final result with the weighted averages of the scores of the baseline recognizer and the pair-wise discriminator. For all pair-wise discriminators, the  X 1st versus 2nd X 10th X  method that uses pair-wise discriminators more aggressively showed better performance. Again, the proposed pair-wise discrimination method showed the best performances in all cases. Xu X  X  method was slightly better than Leung X  X  method.

Table 4 summarizes the overall recognition performances applying the three pair-wise discrimination methods. This time, we also measured the discrimination performance of the baseline recognition method to compare the discrimina-tion ability of the discrimination methods with that of the recognition method. For this, we simply used the feature extractor and the classification method used for the baseline recognizer. The results are presented in the 2nd and the 7th columns. The baseline discriminator showed poorer result than the three discrimination methods. Especially, with the mesh feature, it even degraded the performance of the base-line recognizer. The reason of the degradation is that the dis-criminators were trained with the Tr2 data set which contains much smaller number of samples than Tr1 data set which was used to train the baseline recognizer. The proposed method showed the best performance among the three pair-wise discrimination methods. It improved the performance from 87.69 to 90.11 % achieving 19.66 % of error reduction rate.
The average time spent by the baseline recognizer was 7.59 ms. The discrimination time per sample spent by the proposed method, Leung X  X  method, and Xu X  X  method are 2.45, 0.18, and 1.35 ms, respectively. Leung X  X  method was the fastest, and the proposed method was the slowest. How-ever, if we compare them in the overall recognition time, which were 10.04, 7.77, and 8.94 ms, the proposed method was only 29.16 % slower than Leung X  X  method. 4.4 Component evaluation The three discrimination methods evaluated in our experi-ment are distinguished from each other by their methods used in two major steps: measuring importance of each region and emphasizing the regions that were found important. Each of the three discrimination methods has its own methods for the two steps. However, the two steps are independent from each other, and therefore, each of the three methods for the first step can be combined with any of the three methods for the second step.

For a more comprehensive analysis, we separated the two steps of the three pair-wise discriminators and evaluated all possible combinations. Tables 5 and 6 show the experimen-tal results using the two feature extraction methods. In both tables, each column represents a method to estimate regional importance and each row represents a method to emphasize the important regions. For example, the rightmost cell on the first row represents the performance of the discriminator that estimates regional importance with Xu X  X  method and empha-sizes important regions with the proposed method. In most combinations, the proposed methods showed the best perfor-mance. This shows that the proposed method is better than the other two methods not only for the whole system, but also for the parts. 4.5 Qualitative analysis of correction results Finally, we checked the recognition results corrected by the proposed method by using the human eyes. Many misrecog-nized results were successfully corrected. Some examples of successful corrections are shown in Table 7 . These images belong to  X   X  and  X   X  classes, respectively. However, their shapes are very close to rival classes  X   X  and  X   X . The recognizer failed to catch the small differences. How-ever, expanding important regions, the proposed method suc-cessfully discriminated the characters.

Although the proposed method improved the overall per-formances significantly, it also made some errors. The most important error reasons were ambiguity and severe shape variation. Table 8 shows some error samples caused by the former reason. The ellipses in the second column show the most important parts to discriminate the confusing pairs. The discriminative normalization successfully located and expanded those parts. However, unfortunately, these char-acters have ambiguous shapes particularly in the important regions. Expanding the important region helped to focus on the difference between the characters, however, at the same time, it also worsened the ambiguity as shown in the fourth column of Table 8 . As a result, the pair-wise discriminator failed to discriminate these images.

Table 9 shows error samples caused by severe shape vari-ation. These characters are heavily unbalanced in the size of the upper and the lower parts. Compared with normal writing style, the upper parts are much larger than the lower parts. Even pseudo 2D preliminary normalization was not suffi-cient to regulate such imbalance. As a result, their impor-tant regions were inappropriately aligned with the regional importance map, and therefore, the proposed method pro-duced undesirable result.
 5 Conclusion In this paper, we proposed a discriminative normalization method as well as a pair-wise discrimination method based on it. The discriminative normalization is a nonlinear nor-malization to emphasize the difference between confusing characters by expanding critical regions. It measures the importance of each region by the contribution to reducing error probability. Then, it resamples the image to evenly dis-tribute the regional importance measurements. As a result, it expands the important regions and shrinks less important regions.

In experiments, the proposed method showed a higher performance than the other two recently developed pair-wise discrimination methods in both estimating regional importance and emphasizing the important regions. Accord-ingly, it improved the overall performance of the handwritten Hangul recognition system more than other methods. On SERI95a data set, it improved the recognition rate from 87.69 to 90.11 %, showing 19.66 % of error reduction rate.
 References
