 With the exponential growth in the use of mobile de-vices in recent years, the need for speech-driven in-terfaces is becoming apparent. The limited screen space and soft keyboards of mobile devices make it cumbersome to type in text input. Furthermore, by the mobile nature of these devices, users often would like to use them in hands-busy environments, ruling out the possibility of typing text.

In this paper, we focus on the problem of speech-driven search to access information repositories us-ing mobile devices. Such an application typically uses a speech recognizer (ASR) for transforming the user X  X  speech input to text and a search component that uses the resulting text as a query to retrieve the relevant documents from the information reposi-tory. For the purposes of this paper, we use the busi-ness listings containing the name, address and phone number of businesses as the information repository.
Most of the literature on speech-driven search ap-plications that are available in the consumer mar-ket (Acero et al., 2008; Bacchiani et al., 2008; VLingo FIND, 2009) have quite rightly emphasized the importance of the robustness of the ASR lan-guage model and the data needed to build such a ro-bust language model. We acknowledge that this is a significant issue for building such systems, and we provide our approach to creating a language model. However, in contrast to most of these systems that treat speech-driven search to be largely an ASR problem followed by a Search problem, in this pa-per, we show the benefits of tightly coupling ASR and Search tasks and illustrate techniques to im-prove the accuracy of both components by exploit-ing the co-constraints between the two components.
The outline of the paper is as follows. In Sec-tion 2, we discuss the set up of our speech-driven application. In Section 3, we discuss our method to integrating the speech and search components. We present the results of the experiments in Section 4 and conclude in Section 5. We describe the speech-driven search application in this section. The user of this application provides a speech utterance to a mobile device intending to search for the address and phone number of a busi-ness. The speech utterance typically contains a busi-ness name, optionally followed by a city and state to indicate the location of the business (e.g. pizza hut near urbana illinois .). User input with a busi-ness category ( laundromats in madison ) and without location information ( hospitals ) are some variants supported by this application. The result of ASR is used to search a business listing database of over 10 million entries to retrieve the entries pertinent to the user query.

The ASR used to recognize these utterances in-corporates an acoustic model adapted to speech col-lected from mobile devices and a trigram language model that is built from over 10 million text query logs obtained from the web-based text-driven ver-sion of this application. The 1-best speech recogni-tion output is used to retrieve the relevant business listing entries. As mentioned earlier, most of the speech-driven search systems use the the 1-best output from the ASR as the query for the search component. Given that ASR 1-best output is likely to be erroneous, this serialization of the ASR and search components might result in sub-optimal search accuracy. As will be shown in our experiments, the oracle word/phrase accuracy using n -best hypotheses is far greater than the 1-best output. However, using each of the n -best hypothesis as a query to the search compo-nent is computationally sub-optimal since the strings in the n -best hypotheses usually share large subse-quences with each other. A lattice representation of the ASR output, in particular, a word-confusion network (WCN) transformation of the lattice, com-pactly encodes the n -best hypothesis with the flexi-bility of pruning alternatives at each word position. An example of a WCN is shown in Figure 1. In or-der to obtain a measure of the ambiguity per word position in the WCN, we define the (average) arc density of a WCN as the ratio of the total number of arcs to the number of states in the WCN. As can be seen, with very small increase in arc density, the number of paths that are encoded in the WCN can be increased exponentially. In Figure 2, we show the improvement in oracle-path word and phrase ac-curacies as a function of the arc density for our data set. Oracle-path is a path in the WCN that has the least edit-distance (Levenshtein, 1966) to the refer-ence string. It is interesting to note that the oracle accuracies can be improved by almost 10% absolute over the 1-best accuracy with small increase in the arc density. 3.1 Representing Search Index as an FST In order to exploit WCNs for Search, we have im-plemented our own search engine instead of using an off-the-shelf search engine such as Lucene (Hatcher and Gospodnetic., 2004). We index each business listing ( d ) in our data that we intend to search using the words ( w d ) in that listing. The pair ( w d , d ) is assigned a weight ( c including the standard tf  X  idf , as explained below. This index is represented as a weighted finite-state transducer ( SearchFST ) as shown in Figure 3 where w d is the input symbol, d is the output symbol and c 3.2 Relevance Metrics In this section, we describe six different weighting metrics used to determine the relevance of a docu-ment for a given query word that we have experi-mented with in this paper. idf w : idf w refers to the inverse document fre-atf w : atf w refers to average term frequency, which cf w  X  idf w atf w  X  idf w : (Each term as described above). 3.3 Search By composing a query ( Qfst ) (either a 1-best string represented as a finite-state acceptor, or a WCN), with the SearchFST , we obtain all the arcs ( is a listing with the query word and, c weight associated with that pair. Using this informa-tion, we aggregate the weight for a listing ( d q ) across all query words and rank the retrieved listings in the descending order of this aggregated weight. We se-lect the top N listings from this ranked list. The query composition, listing weight aggregation and selection of top N listings are computed with finite-state transducer operations.

In Figure 4, we illustrate the result of reranking the WCN shown in Figure 1 using the search rele-vance weights of each word in the WCN. It must be noted that the least cost path 1 for the WCN in Fig-ure 1 is ballys automobiles while the reranked 1-best output in Figure 4 is audi automobiles . Given that the user voice query was audi automobiles , the list-ings retrieved from the 1-best output after reranking are much more relevant than those retrieved before reranking, as shown in Table 1. We took 852 speech queries collected from users us-ing a mobile device based speech search application. We ran the speech recognizer on these queries us-ing the language model described in Section 2 and created word-confusion networks such as those il-lustrated in Figure 1. These 852 utterances were divided into 300 utterances for the development set and 552 for the test set. 4.1 ASR Experiments The baseline ASR word and sentence (complete string) accuracies on the development set are 63.1% and 57.0% while those on the test set are 65.1% and 55.3% respectively.

In Table 2, we summarize the improvements ob-tained by rescoring the ASR WCNs based on the dif-ferent metrics used for computing the word scores according to the search criteria. The largest im-provement in word and sentence accuracies is ob-tained by using the rescoring metric: P f w,d The word-level accuracy improved from the baseline accuracy of 63.1% to 63.9% after rescoring while the sentence-level accuracy improved from 57.0% to 58.3%. Thus, this rescoring metric, and the cor-responding pruning AD and the scaling factor was used to rerank the 552 WCNs in the test set. After rescoring, on the test set, the word-level accuracy improved from 65.1% to 65.9% and sentence-level accuracy improved from 55.3% to 56.2%. Number of documents All Documents 4.2 Search Experiments To analyze the Search accuracy of the baseline ASR output in comparison to the ASR output, reranked each of the two sets of ASR outputs (i.e., base-line and reranked) as queries to our search engine, SearchFST (described in Section 3). For the search results produced by each set of queries, we com-puted the precision, recall, and F-score values of the listings retrieved with respect to the listings retrieved by the set of human transcribed queries ( Reference ). The precision, recall, and F-scores for the baseline ASR output and the reranked ASR output, averaged across each set, is presented in Table 3. For the pur-poses of this experiment, we assume that the set re-turned by our SearchFST for the human transcribed set of queries is the reference search set. This is however an approximation for a human annotated search set.

In Table 3, by comparing the search accuracy scores corresponding to the baseline ASR output to those corresponding to the reranked ASR output, we see that reranking the ASR output using the informa-tion repository produces a substantial improvement in the accuracy of the search results.

It is interesting to note that even though the reranking of the ASR as shown in Table 2 is of the order of 1%, the improvement in Search accuracy is substantially higher. This indicates to the fact that exploiting constraints from both components results in improving the recognition accuracy of that subset of words that are more relevant for Search. In this paper, we have presented techniques for tightly coupling ASR and Search. The central idea behind these techniques is to rerank the ASR out-put using the constraints (encoded as relevance met-rics) from the Search task. The relevance metric that best improved accuracy is P f w,d mined on our development set. Using this metric to rerank the ASR output of our test set, we im-proved ASR accuracy from 65.1% to 65.9% at the word-level and from 55.3% to 56.2% at the phrase level. This reranking also improved the F-score of the search component from 0.718 to 0.735. These results bear out our expectation that tightly coupling ASR and Search can improve the accuracy of both components.

Encouraged by the results of our experiments, we plan to explore other relevance metrics that can en-code more sophisticated constraints such as the rel-ative coherence of the terms within a query. The data used in this work is partly derived from the Speak4It voice search prototype. We wish to thank every member of that team for having deployed that voice search system.

