 In this paper, we present a ge neral framework to quantify changes in temporally evolving data. We focus on changes that materialize due to evolution and interactions of fea-tures extracted from the data. The changes are captured by the following key transformations: create, merge, split, continue, and cease . First, we identify various factors which influence the importance of each transformation. These fac-tors are then combined using a weight vector. The weight vector encapsulates domain knowledge. We evaluate our al-gorithm using the following datasets: DBLP, IMDB, Text and Scientific Dataset.
 H.2.8 [ Information Systems ]: Database Management X  Database Applications Algorithms, Experimentation Temporal Data Analysis, Knowledge Discovery Basic Notation: S =( S 1 ,S 2 ,...,S T ) denotes a time vary-ingdatawith T time steps. f t k denotes k th feature ex-tracted from t th time step. Wherever unambiguous we omit subscript. N [ t 1 ,t 2 ] ( f k ,...,f l ) captures number of times the group by features ( f k ,...,f l ) co-occurred during a given time interval [ t 1 ,t 2 ].
 Feature Properties: We capture three properties of each feature. Collectively, these properties capture information about evolution of a single feature and its interaction with others. We consider the following properties: Strength t 2 t 1 : Strength captures importance of a feature vis-a-vis the whole dataset. Informally, strength of f compares occurrence of F with the most frequent feature. Mathemat-ically, strength is defined as:-The definition of strength can be easily extended to com-pute average, maximum and minimum strength of a group of features. In some cases, the group strength is more rele-vant than individual strengths of members. For example, in case of clusters, the strength of a cluster is better defined as the average of the individual strength of its members. Coupling t 2 t 1 ( f k ,f l ) : Coupling captures the interaction of the features within a time period. The interaction we are in-terested is co-occurrence. There are multiple ways to define the coupling. One way is to calculate the fraction of time steps in which f k and f l co-occurred ,i.e, N [ t 1 ,t 2 ever, this metric is negatively biased towards less frequent features. For example, if f k and f l always co-occurred but occurred only twice in 100 time steps the coupling is 2 100 While the features always interacted the coupling is low. To handle this problem we use the following definition: With this definition we will get coupling of 1 for the above example. An interesting case to consider is if f k occurs 2 times but f l occurs 100 times in 100 time steps, the cou-pling is 2 100 . One can argue that since whenever f k has occurred it has interacted with f l , therefore the coupling (w.r.t. to f k ) should be high. However, we are interested in joint interaction between f k and f l not conditional coupling. Similar to the strength, coupling can be extended for a group of features. Coupling of two groups G 1 and G 2 is: GCoupling t 2 t 1 ( G 1 , G 2 )= 1 where N  X |G 1 | X  X G 2 | is the averaging factor, i.e., the number of pairs which have non-zero coupling. The group coupling can be used to compute coupling between two clusters. In such cases, coupling will capture the inter-cluster member interactions. Moreover, self coupling , i.e, GCoupling t 2 captures coherence of a group. For example, a cluster with very high self coupling implies that the cluster members have high interaction. Please remember that the interaction here captures cooccurences. Therefore, we can infer that the clus-ter is a stable one with few changes in its members. Size ( f k ) : Size of the feature is self explanatory. For some features like IMDB actors, size is not relevant. Whereas in other domains like CFD or clustering applications, size is extremely important. The exact calculation of size is domain Dependant. In this paper size of a group/cluster is defined as number of members in that particular group. For vortices size is calculated as area the enclosing ellipse. Please note that each of the properties above are normalized between [0 , 1]. To handle relative importance of different properties for different datasets an importance/weight vec-tor is used. Next, we present quantifying metrics for each transformation along with key rationale behind the metric. Continue f in Table 1 Row 1. The overall score is composed of three terms. The first part accounts for the size of the feature. The second terms captures the importance (frequency of oc-currence) of the feature in it s temporal neighborhood. Fi-nally, the last term measure the stability of the feature in the temporal neighborhood. The idea of using a neighborhood is motivated by the fact that in most systems the features are influenced by their immediate neighbors. Far-off neigh-bor have little or no impact. This property is extensively used in spatio-temporal application, pre-fetching in cache and markov models. One key difference is that our tem-poral neighborhood also looks ahead. This is because if a feature is not useful in the future then its current importance should reflect this. Informally, a continue is important if a frequent and stable feature of considerable size continues . in Table 1 Row 2. Informally, a creation is important if the new feature is large and will be frequent and stable in near future . The metric is very similar to that of continue transformation. The only difference is that the temporal neighborhood only considers future time steps because the feature is non-existent earlier.
 Dissipate f t k : The score of a death of a feature is demon-strated in Table 1 Row 3. The scoring mechanism very sim-ilartothatofcreationevent,exceptthatthetimeperiod considered is before the death event, for obvious reasons. A dissipation is important if a large, frequent and stable feature dissipates . The continuation, creation and the dissipation scores lie between 0 and 1.
 Merge f of a merge event shown in Table 1 Row 4. The merge event scoring is more intricate. We again explain each of term in the function. The first and second term captures the aver-age size and strength of merged features because typically merging of two large (frequent) features is more interesting than merging of smaller (infrequent) features. The third and forth term captures strength and stability of newly created feature in future to ascertain that the new feature is indeed important. The last term captures the past interaction of the merged features. High value of this term has negative impact on the overall merge s core. Thisisbecauseifthe two merged features were also interacting in the past than the new merge is not very interesting. On the other hand, if two features with no past interaction merge then it may point to an interesting underlying phenomenon which war-rants more attention and hence this merge should be rated higher than the previous one. A merge is important if two large, frequent and non-interacting features merge (interact) to form a frequent and stable feature . Please note that the size of new feature will be approximately equal to the sum of sizes of merged features. Therefore, we don X  X  explicitly consider size of the new feature.
 Split f of a split event. The metric is very similar to that of a merge because of the converse nature of these two transformations. The last term here implies that the new features should have less or no interaction for the split to be interesting. A split is important if a frequent and stable features splits to form two large, frequent and non-interacting features . The split and merge score lie between -1 and 1.
 Order Complexity : Let the size of the temporal neigh-borhood be H timestamps. The time complexity to rank one transformation is O ( H ). If F denotes the number of features at each time step then complexity for each time step is O ( H  X  F ). If there are T time stamps, the total complexity becomes O ( H  X  F  X  T )whereH &lt; T.
 Results : Please refer to our technical report [1] for detailed experimental study and discussion on weight vector.
