 With the popularity of data mining, priv acy issues have been a serious concern. Most research on privacy issues in data mining focuses on privacy preserving data mining, i.e., how to mine data while protecting the identity of data owners. Various approaches have been proposed to conduct data mining without breach-ing of privacy [1,2,3,4]. However, privacy issues studied in previous research are on time-invariant data which do not change over time.

Time series data mining becomes popular recently. The goal of time series data mining is to find pattens contained in time series data [5,6,7,8,9,10,11,12]. In time series data mining, the data to be mined is labeled with timestamps. One example is the daily stock price. For time series data, because of the special nature of the data, its privacy goes beyond the protection of data. In this paper, when the meaning of privacy is unclear from context, we call the privacy in time-invariant data mining snap-shot privacy , and the privacy in time series data mining time series privacy .

We focus on time series privacy issues in this paper. As snap-shot privacy issues arise from snap-shot based data m ining, time series privacy issues arise from time series data mining. Time serie s privacy issues concern about changes in data over time. We need to protect data , as well as its properties in time and frequency domains. For example, sales data on a car model changes over time, but the manufacturer of the car model will worry about sharing the sales data with data miners because the sales data may indicate changes in financial situation or marketing strategies of the manufact urer over time. Another example is that a store may not be willing to share its sales data because a data miner may find out promotion periods of the store by checking periodicities contained in the data provided by the store. We argue that privacy in time series data involves protection of properties in time domain such as peak, trough, and trend, and properties in frequency domain, such as periodicity. Such properties reveal lots of information, even though they do not reveal data.

Two common approaches have been proposed to preserve snap-shot privacy in data mining. One approach is data perturbation in which data to be mined is modified to protect privacy. The other approach is data partitioning in which data is split among multiple parties and each party only see its share of the data. One method in data perturbation approach is aggregation in which time series data from different sources are aggregated and given to data miners. This can prevent data miners from finding private information about individual sources. For example, auto manufacturers usually do not want to publish daily, monthly or yearly sales data of individual car model because too much sensitive infor-mation is contained in the time series data. Instead, trusted market research companies aggregate sales data of different car models made by different auto manufacturers and publish these aggregated data. These time series data can be aggregated in different ways such as according to vehicle types or vehicle features for different purposes.

In this research, we found that current techniques to protect snap-shot privacy were largely ineffective under data flow separation attack, which can separate aggregated data and separate noise from original data. The data flow separa-tion attack employs the blind source separation model [13], which was originally defined to solve cocktail party problem : blind source separation algorithms can extract one person X  X  voice given the mixtures of voices in a cocktail party. Our experiments show that data flow separation can separate independent time series data generated by different sources.

The contributions of this paper can be summarized as follows:  X  We introduce the concept of privacy in time series data mining. Because  X  We present data flow separation attack and show that aggregation is not  X  We present frequency matching attack , a further attack based on data flow  X  We discuss the pros and cons of countermeasures to data flow separation
The rest of the paper is organized as fo llows: Section 2 reviews the related work in privacy preserving data mining and time series data mining. We list time series privacy issues in Section 3. S ection 4 outlines the threat model. In Section 5, we introduce the data flow separation attack. We will also describe frequency matching that can be used as further attacks. In Section 6, we use experiments on real stock data to show th e effectiveness of the data flow separa-tion attack. Section 7 discusses countermeasures for data flow separation attack. We conclude this paper in Section 8, with remarks on extensions of this work. 2.1 Privacy Preserving Data Mining The main approaches to privacy-preserving data mining can be categorized into two categories: data perturbation and data partitioning.

In data perturbation approaches, original data is modified by data obscura-tion or by adding random noises. An example of data obscuration is replacing values of a continuous variable with ranges. Distributions of random noises are usually known, such as even distribution or normal distribution. The modified data is given to data miners. Algorithms have been developed to mine decision tree [1] and association rules [2] in dat a with noise. Techniques for improving randomization are also proposed [14].

In data partitioning approaches to privacy preserving data mining, the orig-inal data is distributed among multiple parties, either by the partitioning of centralized data or by the nature of dat a collection. The data mining process is split into local computation at individual sites and global computation. Dur-ing the process, each party does not se e other party X  X  data, but cooperates to find global patterns. In almost all cases, secure multi-party computation [15] and encryptions are employed. Secure algorithms for decision tree construction [3], association rules mining [4], k-means clustering [16], and Bayesian network learning [17] have been proposed. In these algorithms, all parties were assumed to be semi-honest. That is, every party would faithfully follow the protocol or algorithm, but tried to learn as much as possible about others.

As discussed above, past research in privacy preserving data mining focuses on privacy of raw data. Though privacy of derived data has been mentioned [14], we are not aware of any research in time series privacy. We hope to raise the awareness of time series privacy issues in this paper. 2.2 Time Series Data Mining Because time series data is usually large and noisy, direct application of data mining algorithms on raw data is time-consuming and gives unreliable results. A lot of attentions have been paid on preprocessing techniques that facilitate data mining tasks. Research in time series data mining mostly focuses on data preprocessing techniques, such as discret ization and transformation [10], feature extraction and feature reduction [12]. Work has been also been done in related techniques such as representation [11] and similarity metric [18].

The data mining tasks studied by researchers include subsequence matching [5], classification [7], clustering [8], time series modeling [9], and association rule mining [6].

It is clear that most research in time ser ies data mining does not address pri-vacy issues, let alone time series privacy issues. While current privacy preserving techniques can be applied to preserve snap-shot privacy in time series data, they are inadequate for protecting time series privacy. We identify privacy issues for time series data in addition to traditional privacy issues in data mining. Time series data from a data source can be regarded as a time-domain signal. All the characteristics of a time-domain signal can be potentially regarded as private information by the data provider. Below, we list common characteris tics in time series data that a data provider may need to keep confidential.  X  Amplitude: Amplitude indicates the strength of a signal, like the raw data  X  Average: The average signal strength over time. For example, for a series of  X  Peak and trough: Peak and trough indicate extreme situations. They are usu- X  Trend: By observing trends of time series data, an adversary may predict fu- X  Periodicity: Periodical changes in time series data indicate existence of pe-
There are other characteristics which may be regarded as confidential by some data providers. However, as an initial study on time series privacy, we focus on the common characteristics listed above. Since data flow separation attack aims to recover original signal, the attack ma y be effective to disclose these common characteristics. In this paper we assume that data providers care about the sensitive informa-tion contained in their time series data. T o protect their privacy, data providers will only supply their data to trusted res earch companies. Research companies will aggregate time series data provided by different data providers according to different criteria. An example of aggregating sales data provided by auto manu-facturers is shown in Figure 1. In Figure 1, there is only one aggregation layer. In practice there can be many layers of aggregation because some research com-panies may aggregate data provided by other research companies or aggregate data provided by both original data providers and research companies.
We assume research companies will publish aggregated data for profit or for public usage. The research companies will disclose criteria used in aggregation, but not the information of data sources, specifically identities of data providers to protect the privacy of data providers.

We assume adversaries to have capabilities summarized as follows:  X  Adversaries can obtain aggregated data from research companies free or for  X  Adversaries can not obtain data generated from original data sources because  X  Adversaries can obtain data aggregated according to different criteria.  X  Research companies have various data providers as their data sources and
The threat model M can be represented as M = &lt; F,G,O &gt; ,where F is a set of original data sources, G is a set of aggregation operations, and O is a set of observations available to adversaries. Though observations are obtained by applying aggregation operations to data sources, i.e., O = G ( F ), aggregation operations G and data sources F are unknown to adversaries.

The model assumed in our paper is realis tic. Many research companies com-pile weekly or monthly sales of large ite ms, such as cars, TVs, computers, etc, from retailers or manufacturers. Each research company has its own sources and publishes its reports with aggregated totals. Since these reports are available with a small fee, someone can collect all these reports and try to separate data to recover original data. Manufacturer swanttoprotecttheirdatafromthird parties, but would like to see the aggregated data to understand their industry. In this section, we will first define the problem in the context of blind source separation and then describe how to apply the data flow separation attack in practice. 5.1 Blind Source Separation Blind source separation is a methodology in statistical signal processing to recover unobserved  X  X ource X  signals from a set of observed mixtures of the signals. The separation is called  X  X lind X  to emphasize that the source signals are not observed and that the mixture is a black box to the observer. While no knowledge is avail-able about the mixture, in many cases it can be safely assumed that source signals are independent. In its simplest form [19], the blind source separation model as- X  X  X  ,O n ( t )where O i ( t )= n j reconstruct the source signals F j ( t ) using only the observed data O i ( t ), with the assumption of independence among the signals F j ( t ). The common methods em-ployed in blind source separation are minimization of mutual information [20], maximization of nongaussianity [21] and maximization of likelihood [22]. 5.2 Data Flow Separation as a Blind Source Separation Problem In this paper, we define an individual data flow as a series of time-stamped data generated by an original data source. An aggregate data flow is defined as the aggregate of individual data flows. Aggregate data flows are generated by research companies. If not specified, the phrase data flow in the remaining of this paper means the individual data flow for brevity.

For an attacker who is interested in sensi tive information contained in indi-vidual data flow, it will be very helpful to separate the individual data flows based on the aggregate data flows. Because the separation of the data flows can recover the pattern of data flows, they can be use for further attack such as frequency matching attack described in Section 5.3.
 In this paper, we are interested in patterns carried in the time series data. of aggregate data flow from Research Company A. We call n as the sample size in this paper. The attacker X  X  objective is to recover the time series F i = [ f
In general, with l research companies and m individual data flows, we can rewrite the problem in vector-matrix notation, where A l  X  m is called the mixing matrix in blind source separation problems.
Data flow separation can be achieved using blind source separation tech-niques. The individual data flows are independent from each other since they are from different sources . Given the observations O 1 ,O 2 ,  X  X  X  ,O l , blind source separation techniques can be used to estimate the independent individual flows F ,F 2 ,  X  X  X  ,F m by maximizing the independence among the estimated flows.
The issues about the blind source separation method are summarized as follows.  X  Basic blind source separation algorithms require the number of observations  X  The l observations may have redundancy. In other words, the row vectors of  X  The data flow estimations by blind source separation algorithms are usually 5.3 Frequency Matching Attack After the data flows have been separated, a number of data flows, each with a given time series, have been determined to be included in the aggregate.
We choose frequency spectrum matchin g to do further attack. Frequency spec-trum can be generated by applying Discrete Fourier Transform on time series data as below where f j denotes the j th data point in the time series data and N denotes the length of the time series and then calculating the magnitude of transformed data. We match frequency spectrum by correlation.

The rationale for the use of frequency matching is two-fold: First, the dynam-ics of many data flows, such as sales, stock price, and weather, are characterized by their periodicities. By matching the frequency spectrum of a known data flow with the frequency spectru m of estimated data flows obtained by blind source separation techniques, we can identify corresponding flows with high accuracy. Second, frequency matching can easily remove the ambiguities introduced by the lifting and scaling in the estimated time s eries by removing the zero-frequency component.

Frequency matching can be applied to match data flows separated from differ-ent attacks. After collecting a set of aggregate data flows according to different criteria, an attack er can select arbitrary subset s as groups and apply data flow separation techniques on the groups to recover individual data flows. If a data flow separated from one group matches a data flow separated from another group, then these two data flows should be generated from the same source. Moreover, the source generating these two data flows should satisfy at least one aggregation criteria in each group. If the attacker can match a data flow with data flows sepa-rated from several groups, the attacker can largely reduce the anonymity or possi-bly determine the identify of the source generating the data flow since the source should satisfy at least one criteria in each of these groups of aggregate flows. To better utilize the data, the attacker can try all possible combinations to group available aggregate data flows and then match the data flows separated from these groups. Of course, when the number of aggregate flows in a group is too small, the data flow separation technique can not separate all data flows because the number of observations is smaller than the number of independent sources. In this section, we will evaluate the p erformance of data flow separation. We use the blind source separation algorithm proposed in [23] to separate the data flows. The accuracy of separation will be measured using correlation with actual flows. In our experiments, real stock market data [24] is used. 6.1 Performance Metrics In the following, we will adopt two metrics to evaluate the accuracy of data flow separation. Both metrics are based on a comparison of the separated data flows with the actual data flows.

As first performance metric, we use mean square error (MSE) , a widely used f n ] represent the time series of the actual data flow and F B =[ f represent the time series estimated by the blind source separation algorithm. To match the time series F A with F B ,wefirstneedtoscaleandlift F B so that they have the same mean and variance.
 F where std ( F )and mean ( F ) denote the standard deviation and the average of time series F , respectively. The mean square error ,  X  A,B , is defined as follows: Since the times series F B can also be a flipped version of F A , we also need to match F A with  X  F B .
 As the second metric, we use correlation , R F A ,F B , between the separated flow F B and the corresponding actual flow F A defined as follows: 6.2 A Small Example In this experiment, four time series of stock price selected from [24] are mixed into four aggregates. Figure 2(a) and Figure 2(b) show the actual data flows and separated data flows from the aggregates.

We can observe for data flows 1, 2, and 3, the separated data flows are flipped, scaled and lifted versions of the corresponding actual data flows. We can also observe the resemblance between separated flow and the corresponding actual flow for data flow 4.

Figure 3 shows the performance of data flow separation in terms of metrics introduced in Section 6.1. As shown in Figure 3(a), the separated data flows are highly correlated to actual data flows. In Figure 3(b), both the separated data flow and its flipped time series are compared against the actual flows and the mean square error for each data flow shown in the figure is the smaller one. From Figure 3(b), we can observe that the reconstructed data flows are off by around 10% in comparison with the actual data flows. Both metrics indicate that the data flow separation is successful. In the following we will use correlation only to evaluate performance because the lifting and scaling in the mean square error metrics may introduce error. 6.3 Mixing Degree In this set of experiments, we would like to study the effect of mixing degree on the performance of data flow separation. We define mixing degree as follows: It is equivalent as
Ten time series selected from stock d ata [24] are mixed randomly in this experiment to create ten aggregates. Totally, 10000 randomly-generated full-rank binary mixing matrices were used in this experiment.

Figure 4(a) shows the effect of mixing degree on the performance of data flow separation. We plot statistics of both average correlation and worst case correla-tion. In this paper average correlation is defined as mean of correlation between separated data flows and actual data flows for each trial. We use worst case to refer to the most accurately separated data flow in each trial. It corresponds to worst privacy compromising in each trial.

From Figure 4(a), we can observe that data flow separation is effective since the separated flows are highly correlate d to actual flows especially for the worst case. We can also observe that the performance of data flow separation is not sensitive to mixing degree for full-rank mixing matrices. This experiment indi-cates that countermeasure to data flow separation attack by simply increasing mix degree is not effective. 6.4 Redundant Aggregate Data Flows In this set of experiments, we focus on the cases with redundant aggregate data flows. In our setting, redundant aggregat e data flows mean that some aggregate data flows are linear combinations o f other aggregate d ata flows. Redundant aggregate data flows will reduce the number of effective aggregate data flows. Redundant aggre gate data flows are caused by rank deficient mixing matrices.
To study the effect of redundant observations, we randomly generate 1000 mixing matrices for each possible ran k. Ten data flows randomly selected from the stock data are mixed using the randomly-generated mixing metrics of differ-ent ranks.

Figure 4(b) shows the performance of data flow separation with redundant observations. We can observe that the performance of data flow separation de-creases as the number of redundant observations increases. The performance degrades because the number of knowns decreases. When the number of aggre-gate data flows is larger than the number of individual data flows, the data flow separation problem becomes an over-complete base problem in blind source sep-aration literature. In general an over-complete base problem is harder to solve. 6.5 Dependence between Individual Data Flows In this set of experiments, we study the effect of dependence between individual data flows on data flow separation perform ance. We did this series of experiments because of the fact that most blind source separation algorithms assume relative independence between actual signals.

Groups of ten data flows are randomly picked from the stock data [24]. These groups have different average correlations among data flows in the same group. The time series in each group are mixed randomly and we apply data flow separation technique on the generated aggregates.

Figure 5 shows that the performance of data flow separation technique de-creases when the dependence among individual data flows increases. It is because blind source separation algorithms used in data flow separation assume indepen-dence between underlying components. Even for the blind source separation algorithm [23] which takes advantage of both independence and timing structure of underlying signals, the dependence among individual data flows can still de-grade the performance of data flow separation attack. We can also observe that worst case correlation is not sensitive to the dependence between individual data flows. 6.6 Frequency Matching In this subsection, we show the performance of frequency matching attack pro-posed in Section 5.3. In this experiment, two groups of ten data flows each are formed by selecting data flows from the stock data. Three data flows in both groups are the same. These two groups of data flows are mixed randomly to form two groups of aggregate data flows. Data flow separation is performed on the two groups of aggregate data flows. We identify common flows in both groups by matching frequency spectrum of separated data flows in two different groups.
Figure 6 shows the correlation between three identified separated data flows in one group and the ten separated data flows in the other group. As shown in Figure 6, we can easily find out the data flows common to both groups. From the experiments in Section 6, it is apparent that aggregation methods are not sufficient to effectively counter data flow separation attacks. Additional measures are needed.

One naive countermeasure is adding different noises to a data flow to be supplied to different research companies so that research companies will receive different copies of the data flow. It may not work if the noise and the original data flow are independent, and thus can be separated by blind source separation.
According to our experiments, following countermeasures will be effective against data flow separation attacks:  X  Increase the dependence among data flows by adding dependent noises to the  X  Limit the number aggregate data flows that can be obtained by an adver- X  Data sources should know from research companies about how the supplied Also, research in blind source separation shows most blind source separation algo-rithms fail when the signals mixed are Gaussian distributed. Therefore, another countermeasure against data flow separation attack is padding each aggregate data flow so that the distribution of the aggregated data is Gaussian.
As mentioned in [25], aggregation is a major technique used to preserve pri-vacy in data mining. Since data flow separation attack can separate individual data flows from aggregates, aggregation technique based privacy-preserving data mining systems are potentially vulnerable to data flow separation attacks. In this paper, we introduce the concept of privacy in time series data mining. We present a new attack against privacy in time series data mining, called data flow separation attack, which can be used either alone or in conjunctions with other attacks to significantly reduce the effectiv eness of privacy-preserving techniques in data mining. Our experiments show that the attack is effective. With the aid of further attack such as frequency matching attack, data flow separation attack can be used to determine data sources of separate data flows.

We discuss countermeasures against data flow separation attack. Our future work will focus on countermeasures to balance privacy-preserving and perfor-mance of data mining. We thank Professor Keogh for the data sets used in our experiments and anony-mous reviewers for feedbacks on the initial version of this paper.

