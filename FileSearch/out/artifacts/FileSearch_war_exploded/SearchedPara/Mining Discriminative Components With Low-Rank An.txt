 This paper introduces a novel image decomposition approach for an ensemble of correlated images, using low-rank and sparsity constraints. Each image is decomposed as a combi-nation of three components: one common component, one condition component, which is assumed to be a low-rank matrix, and a sparse residual. For a set of face images of N subjects, the decomposition finds N common components, one for each subject, K low-rank components, each cap-turing a different global condition of the set (e.g., different illumination conditions), and a sparse residual for each in-put image. Through this decomposition, the proposed ap-proach recovers a clean face image (the common component) for each subject and discovers the conditions (the condition components and the sparse residuals) of the images in the set. The set of N + K images containing only the common and the low-rank components form a compact and discrim-inative representation for the original images. We design a classifier using only these N + K images. Experiments on commonly-used face data sets demonstrate the effective-ness of the approach for face recognition through compar-ing with the leading state-of-the-art in the literature. The experiments further show good accuracy in classifying the condition of an input image, suggesting that the components from the proposed decomposition indeed capture physically meaningful features of the input.
 H.4 [ Information Systems Applications ]: Miscellaneous Feature extraction and preprocessing Subspace learning, Low-rank matrix, Sparse matrix, Face Recognition, Component Decomposition
Face recognition has been an active research field for a few decades, and its challenges and importance continue to attract efforts from many resea rchers, resulting in many new approaches in recent years. The most recent literature may be divided into roughly two groups, where methods in the first group try to model the physical processes of image for-mation under different condition s (e.g., illumination, expres-sion, pose etc.). For example, the approach of [10] models the face image under v arying illumination conditions to be a linear combination of images of the same subject captured at 9 specially designed illumination conditions; the SRC al-gorithm of [19] further assumes that face images with illu-mination and expression conditions can be represented as a sparse linear combination of the training instances (i.e., the dictionary atoms). On the other hand, the second group of approaches utilizes mathematical/statistical tools to cap-ture the latent relations among face images for classification. E.g., the SUN approach [7] uses the statistics of the human fixation of the images to recognize the face images, Volter-rafaces [9] finds a latent space for face recognition, where the ratio of intra-class distance over inter-class distance is min-imized. One major advantage of the techniques in the first class comes from their being generative in nature, which al-lows these methods to accomplish tasks like face relighting or novel pose generation in addition to recognition. The second group of methods in a sense ignores the physical property of the faces images and treats them as ordinary 2D signals.
Although the methods in the first group have the above nice property, a baseline implementation usually requires dictionaries with training images as atoms and thus may face the scalability issue in real-world applications with a huge number of subjects. Hence efforts have also been de-voted to reducing the size of the dictionary while attempting to retain the level of performance of the original dictionary. Examples include those that generate more compact dictio-naries through some learning procedure (e.g., [13]) and those that attempt to extract subject-specific features that are ef-fectively used as dictionary atoms (e.g., [15]). Our approach belongs to the second group. Since the expressive power of the original dictionary-based techniques comes from largely the number of training images for each subject, a compact dictionary may suffer from degraded performance unless the reduced dictionary properly captures the conditions of the original data that are critical for a recognition task. For example, the method of [15], while shown to be effective for expression-invariant recognition, is difficulty to generalize to handle global conditions such as illumination change, which often introduce to the data non-sparse conditions that can-not be captured by the sparsity model proposed therein.
Recognizing that non-sparse conditions such as illumina-tion change and large occlusion are critical for face recogni-tion, and that for a typical application we may assume only a finite number of such conditions (e.g., a relatively small number of illumination conditions or other conditions), in this paper, we propose a model for representing a set of face images by decomposing them into three components: a common component shared by images of the same subject, a low-rank component capturing non-sparse global changes, and a sparse residual component. Such a decomposition is partially inspired by the observation that the reconstruction of the image with the top few singular values and the corre-sponding singular vectors often capture the global informa-tion of the image, which can be represented by a low-rank matrix. To this end, a generic algorithm is proposed, with theoretic analysis on the convergence and parameter selec-tion. The learned common and low-rank components form a compact and discriminative representation of the original set of images. A classifier is then built based on comparison of subspaces spanned by these components and by a novel image to be classified. This is very compact compared with the number of atoms in an over-determined dictionary such as that in [19]. Further, by explicitly modeling non-sparse conditions, the proposed approach is able to handle both illumination changes and large occlusions, which would fail methods like [15].

To demonstrate the effectiveness of the proposed method, we first design synthetic experiments with known ground truth to verify its key capability in recovering the underlying common, low-rank and sparse components. Then we report results on three commonly-used data sets of real face im-ages: the Extended YaleB dataset [4], the CMU PIE dataset [17] and the AR dataset [14].The experiments show that, the proposed approach obtained better performance than the SRC algorithm [19], which utilizes a much larger dic-tionary, and the SUN approach [7]. The proposed approach also achieves comparable result to Volterrafaces, which is the current state-of-the-art in the literature for a few commonly-used data sets. In addition, the proposed approach can ex-plicitly model the most important feature of the subject and the conditions in the dataset. Experiments also show that the proposed method is robust to situations where a non-trivial percentage of the training images is unavailable. Fur-ther, the capability of the proposed approach for classifying the type of condition that an input image is subject to is also demonstrated by extensive experiments. This suggests that the proposed decomposition is able to obtain physically meaningful and thus potentially discriminative components.
We introduce the proposed method in Section 2, including the proposed model, the learning algorithm and the classifi-cation method. The experiments are reported and analyzed in Section 3. We conclude in Section 4 with a summary of the work and brief discussion on future work.

In the presentation, we use upper case bold font for ma-trices, e.g., X , lower case bold font for vectors, e.g., x and normal font for scalars, e.g., x . { X i,j } N,M i =1 ,j =1 of N  X  M matrices, with X i,j as its ( i, j ) th member. We assume that N is the number of the subjects, and M the number of images per subject 1 .Thus X i,j refers to j th
For simplicity, we assume that each subject has the same age of the i th subject. When there is no confusion, we also use X to denote the set { X i,j } N,M i,j =1 .
In this section, we first present the general formulation of the proposed model in Section 2.1, and then present our algorithm for obtaining the desired decomposition in Section 2.2 and analysis of its convergence in Sec. 2.3. With these, a face recognition algorithm is then designed in Section 2.4.
In many applications of image and signal processing, we often consider a set of correlated signals as an ensemble. For efficient representation, a signal in the ensemble can often be viewed as a combination of a common component, which is shared among all the signals in the ensemble, and an innova-tion component, which is unique to this signal. Many bene-fits can be drawn from this decomposition of the ensemble, such as obtaining better compression rate and being able to extract more relevant features. In face recognition, all the face images, especially the subset corresponding to a sub-ject, may be naturally viewed as forming such an ensemble of correlated signals. In a sense, a sparse-coding approach like SRC implicitly figures out the correlation of the images in the ensemble via the sparse coefficients under the dictio-nary of the training images.

In this work, we aim at developing a new representation of this ensemble so that the face recognition task can be better supported. In particular, considering the common challenges such as illumination conditions and large occlu-sions, we want to have a representation that can explicitly model such conditions. To this end, we propose the following decomposition of face images X i,j in the ensemble X as: where C i is the common part for Subject i , A j is a low-rank matrix, and E i,j is a sparse residual.
 One essential difference between the proposed method and Robust PCA (RPCA [18]), is that RPCA assumes the sig-nals are linearly dependent, with some sparsely corrupted entries in the signals. As a result, they build a big matrix with each signal as a vector. The big matrix would natu-rally be low-rank (because of the assumed inter-image corre-lation), in addition to having a sparse set of entries. On the other hand, the proposed decomposition is partially inspired by the observation that the reconstruction of the image with first few singular values and the corresponding singular vec-tors often capture the global information of the image [12], e.g., illumination conditions, structured patterns, which can be represented by a low-rank matrix. Here the low-rank con-straint arises from certain physical conditions (rather than due to inter-image correlation), and it is imposed on each individual image. Accordingly, we represent images by ma-trices rather than vectors, un like other methods like [19, 18]. With this, we can expect that: C i is a matrix representing the common information of im-number of images, which can always be achieved by using some blank images, a situation the proposed method can handle. A j is a low-rank matrix capturing the global information of E i,j is a sparse matrix pertaining to image-specific details In this modeling, we have assumed M different low-rank matrices, which are responsible for M different global con-ditions such as illumination conditions or large occlusions, and they are shared among the images of different subjects. However, images of each subject do not necessarily contain all the M conditions, as we will show in Sec. 2.2.
We can also obtain a variant of the above model by con-sidering the Retinex theory, in which image I can be repre-sented as: where R ( x, y ) is the reflectance at location ( x, y ), which de-pends on the surface property, L ( x, y ) is the illumination, and  X  is element-wise product. Converting this into the log-arithm domain, we have The above equation indicates that we can represent the in-tensity of the face image as follows: where C i = log ( R ) captures the common property of the im-ages for Subject i , A j = log ( L ) captures the lighting condi-tions, and E i,j captures the residual. This is a variant of the model in Eqn. 1, and is especially suitable for illumination-dominated datasets such as the extended YaleB dataset and the CMU-PIE dataset.

With the above decomposition, the entire dataset con-taining N  X  M images can be compactly represented by N common components and K low-rank components. If we extract the common component C i for face images of Sub-ject i under different conditions, we expect that this com-mon component C i represents the most significant feature of that subject. The set of all the learned low-rank compo-nents A = { A j } M j =1 represents all possible global conditions of the images in the set. Hence we may use A and C i to span the subspace of the face images for Subject i ,where,in the ideal case, any face images of this subject should lie in, barring a sparse residual. This suggests that we can utilize the subspaces for face recognition by identifying which sub-space a test image is more likely to lie in, which is detailed in Sec. 2.4.
Based on Eqn. 1, we formulate the decomposition task as the following constrained optimization problem, with an objective function derived from the requirement of decom-posing a set of images into some common components, some low-rank matrices and the sparse residuals: where A j  X  = i  X  i ( A j )isthenuclearnorm, E i,j 1 = p,q | E i,j ( p, q ) | is the 1 norm and E = { E i,j } that, unlike [18] where a set of images are stacked as vectors of a low-rank matrix, we do not convert the image to a vector in the decomposition stage.

To absorb the constraints into the objective function, we can reformulate Eqn. 5 with augmented Lagrange multiplier as: where Y i,j is the Lagrange multiplier,  X  i,j and  X  i,j are scalars controlling the weight of sparsity and reconstruction error accordingly. When  X  is sufficiently large, Eqn. 6 is equivalent to Eqn. 5. It is worth pointing out that, while for clarity we have written only the expression for Subject i , the optimization is actually done for the entire set of images, since the low-rank components are deemed as been shared by all images.

To solve the problem of Eqn. 6, a block coordinate de-scent algorithm may be designed, with each iterative step solving a convex optimization problem [3][18] for one of the unknowns. To this end, we first describe the following three sub-solutions that are needed in each iteration of such an algorithm, which correspond to solving only one of the un-knowns (blocks) while fixing others.

Sub-solution 1 : For finding an optimal E i,j in the t -th iteration, where the problem can be written as with X E i,j = X i,j  X  C i  X  A j . So we do the following update [6]: where S  X  ( X )= sign ( X )  X  max (0 , | X | X   X  ).
Sub-solution 2 : For finding an optimal A k in the t -th iteration, where the problem can be written as We use the singular value thresholding algorithm [2, 5]:
Sub-solution 3 : The solution to the problem of finding optimal C i argmin where X C i,j = X i,j  X  A j  X  E i,j , can be obtained directly (by taking derivatives of the objective function and setting to zero) as
As alluded earlier, the images of any given subject may not range over all possible M conditions. This may be equiv-alently viewed as a problem of some images are missing for the subject. We now show how this can be addressed in a principled way. Assume that  X  is the set of ( i, j )where X i,j is available and  X   X  is the complement of  X . To deal with those missing entries, we only need to set Y i,j ,  X  and X i,j to0for( i, j )  X   X   X  in the initialization stage. In each iteration, we do not update E i,j for ( i, j )  X   X   X . The proposed decomposition algorithm will automatically infer the missing images.

With the above preparation, we now propose the follow-ing Algorithm 1 to solve Eqn. 6: Algorithm 1: Learning the Decomposition Input: X , X , N , M ,  X  ,  X  and  X  ; % Initialization Y Y i,j =0,  X  0 i,j =0for( i, j ) /  X   X ; while not converged do Solve E i,j for ( i, j )  X   X  by Sub-solution 1: Solve A j for j =1 , 2 , ..., M with Sub-solution 2;
Solve C i for i =1 , 2 , ..., N using Sub-solution 3; %Update Y i,j and  X  i,j for ( i, j )  X   X : t = t +1; end and if it is small enough (e.g., 10  X  6 ), we terminate the al-gorithm.  X  ,  X  and  X  are three parameters specified in input, which are discussed in Sec. 3.1.
The convergence property of an iterative optimization pro-cedure like the algorithm proposed above is critical to its use-fulness. The Algorithm 1 has similar convergence property as the methods described in [11], which are also augmented Lagrange multiplier based approaches. We can draw the fol-lowing theorem: E i,j )=0  X  i, j , then Algorithm 1 will converge to the opti-mal solution for the problem of Eqn. 5.
 The proof of Theorem 1 is included in the appendix.
With the components in Eqn. 1 estimated from the previ-ous algorithm, we now discuss how to classify a test image. Recognizing that the sparse residual captures only image-specific details that have not been absorbed by the common or the global condition, we discard the sparse residuals from the decomposition (training) stage and keep only the com-mon and the low-rank components.

Ideally a face image from Subject i should lie in a sub-space spanned by its common component C i and the low-rank components A . Therefore, we propose the following classification scheme based on comparing the distance be-tween subspaces spanned by the training components and those spanned by replacing the training common by the test image y . We first build the subspace S i for subject i ,which contains all the linear combinations of the images of Subject i under all conditions, i.e., where c i and a j is the vectorized form of C i and A j respec-tively. Subspace S i can be sufficiently represented by a set subspace S y for the test image y as the follows: Then we use the principal angles [8] between these subspace to measure their similarities. In this paper, the principal angles measure the cosine distance between the subspaces, which is calculated as s ( S i , S y )= k cos 2 (  X  k ), where  X  the k th principal angle between S i and S y . The assign i as the label of f ,forwhich s ( S i , S y ) is maximal.
Experiments have been done to evaluate the proposed model and algorithms. In this section, we report several sets of results from such experiments. First, simulations (Sec. 3.1) are employed to demonstrate the convergence and pa-rameter selection of the proposed decomposition algorithm. Then, we show the decomposition of the images from ex-tended YaleB dataset and also how the learned components can be used to reconstruct new images in Sec. 3.2. Finally, we demonstrate the application of the proposed method and algorithms in classification tasks, including face recognition (Sec. 3.3) and identifying the conditions of the images (Sec. 3.4). The performance of the proposed method in face recog-nition task is compared with that of SRC [19], Volterrafaces [9] and SUN [7] on 2 commonly used datasets, i.e., extended YaleB [10] and CMU-PIE [17].
In this subsection, we use synthetic data to demonstrate the convergence of the algorithm and selection of the param-eters. The common components and condition components used in this experiment are shown in Fig. 1 (b,c), where the condition components are from [16] and both components are rescaled to range [0 , 1]. The sparse components are sam-pled from a uniform distribution in the range of [0 , 1]. We use those components to generate 25 images, which are used in this experiment, as Eqn. 1.

Algorithm 1 in Sec. 2.2 requires three parameters,  X  con-trols the convergence speed;  X  controls the sparsity of the sparse residuals; and  X  is a scalar. In [11], they suggest  X  =1 . 5,  X  =1 . 25 and  X  = 1  X  m for Robust PCA, where m is the width of X i,j . We have also found that  X  = 1  X  is optimal from the experiments, thus we adopt this selec-tion in our paper. From the experiment, we found that  X   X  [0 . 125 , 2] and  X  =1 . 25 would be an optimal choice. Fig. 1 shows an example of the recovered common components Figure 1: (a) shows the 25 images generated in the experiment, where the sparse part has 20% support of each image. (b,c) shows the ground truth of the common components and condition components ac-cordingly. We also show the common components (d) and condition components (e) decomposed from (b) when  X  =1 . 25 and  X  =2 . (d) and condition components (e) when the sparse part has 20% support of the image. 2
To demonstrate the robustness of the algorithm, when only part of data is available, we randomly remove 10 images from the 25 images (Fig. 2(a)) and run the algorithm with the same set of parameters. The results are shown in Fig. 2, where (b) is the recovered common components and (c) is the recovered condition components. These results suggest that the algorithm is still able to produce reasonable results even with 40% of the images missing.
In this subsection, we first demonstrate the decomposition of the set of images from Extended YaleB dataset[4]. All the 2432 images from 38 subjects under 64 illumination condi-tions were used. The common components and the condi-tion components are illustrated in in Fig. 3. Comparing these with the original data, it is evident that the recovered The recovered parts are subject to a linear shift and scaling. We identify the parameters for this linear shift and scaling then map them back with those parameters. Figure 2: (a) the input data with 10 image manu-ally removed, (b,c) is the common components and condition components decomposed from (a) accord-ingly. commons are largely clean pictures of the subjects, while the condition components align well with the given illumi-nation conditions. This experiment shows the capability of the proposed method with the Retinex model to discover the illumination conditions and the subject commons from a set of real images.

Next, we randomly pick 32 illumination conditions out of the decomposed 64 conditions and the common components of Subject 1 to form a subspace as described in Eqn. 14. Then we use the proposed method to identify whether an new image is in this subspace, by reconstructing this image as the linear combination of the X  X asis X  of this subspace, i.e., c + a j . Fig. 4 shows an example, where the new image is also picked from Subject 1; and Fig. 5 shows another exam-ple, where the new image is picked from Subject 2. These examples suggest that the learned components can be used for identifying which subject an new image belongs to. Sim-ilarly, the learned components can also be used for iden-tifying which conditions the new image is associated with. These two scenarios are further evaluated in the following two subsections, with real face images.
In this subsection, we demonstrate the performance of the proposed method in face recognition task, with the compar-ison to SRC, Volterraface and SUN on the extended YaleB dataset and CMU PIE dataset. As these two datasets are dominated by illumination conditions, we use the Retinex model for the proposed method, i.e., the image is converted Figure 3: The decomposition of the extended YaleB dataset. We use all the 2432 images which contain 38 subjects (b) and 64 illumination conditions (a). Figure 4: (a) the coefficient for the linear combi-nation, (b) the input image, which is not observed in the images for training the 32 illumination condi-tions, and (c) the reconstructed image. to logarithm. In the SRC method, we build the dictionary by containing all the training images as its columns. Since there is no code publicly available for SRC, we build our own implementation. For 1 optimization used by SRC, we used Orthonormal Matching Pursuit (OMP)[1] as the solver. We set the number of non-zero elements in the sparse coefficient (refer as K later) to be twice the number of conditions in the training data. In addition, each image is normalized to have zero mean and unit l 2 norm for SRC. For Volterrafaces and SUN, we use the author X  X  original implementation and the provided parameters. For all the results, we present the both mean and standard deviation of the accuracies of 3 rounds of experiments.

To examine the robustness of the approaches with respect to the amount of training data, we use the following scheme. In the experiment, we only pick  X #train per subject X  images for each subject as the training instances, according to the randomly generated sample ma trix, where some of the ele-Figure 5: (a) the coefficient for the linear combina-tion, (b) the input image and (c) the reconstructed image. ments are set to 0 and the corresponding images won X  X  be used for training.

The Extended YaleB dataset [4] contains N = 38 sub-jects with 64 images for each subject, which correspond to 64 illumination conditions in the dataset. The images are re-sized to 48  X  42. The results on the extended YaleB dataset are summarized in Tab. 1. From this table, we find that the proposed approach and Volterrafaces achieve the best results; and SUN get obviously the lowest accuracy. The performance of SRC degrade dramatically as the size of dic-tionary (i.e., number of training instances) reduced.
The CMU PIE dataset [17] contains N =68subjectswith varying poses, illuminations and expressions etc.. For all the images, we manually crop the face region, according to the eye position, then resize them to 50  X  35. The results are summarizedinTab.2.InExperiment1,all4methodsget similar results; in Experiment 2, the proposed method and Volterrafaces get the best result; and in Experiment 3, the proposed approach gets the best result. In addition, the proposed method is more robust to the missing of training images. The performance of SRC degrades obviously as the size of dictionary reduced.

To illustrate the speed performance of the proposed ap-proach, we compared the time required to classify one im-age in our approach and the SRC approach. This time was about 0 . 84 seconds in our method, and about 1 . 59 seconds in SRC. The time for the decomposition (i.e., Algorithm 1) is less than 5 minutes. The most time consuming part for the proposed approach is the singular value decomposition (SVD), which is used in computing the principle angle, so an efficient implementation of SVD can make the proposed algorithm even faster.
Finally, we use an experiment to show how the proposed method can be applied to to identifying the conditions the testing images are associated with. The AR dataset [14] contains N = 100 subjects and 26 images for each subjects. The dataset contains 2 sessions, which are taken at different times. Each session contains 13 conditions: 4 for expres-sions, 3 for illuminations, 3 for sun glasses and 3 for scarves.  X  0.04% 99.18  X  0.14% 95.15  X  1.03 %  X  0.52% 91.90  X  0.94% 78.65  X  1.81%  X  0.26 % 99.48  X  0.49 % 90.22  X  11.84%  X  2.80% 76.91  X  3.71% 60.17  X  2.09%  X  0.23 % 98.32  X  0.03 % 80.03  X  2.17%  X  0.44% 81.02  X  0.13% 58.54  X  1.26%  X  0.39% 96.27  X  4.03% 91.03  X  2.43 %  X  0.00% 68.86  X  0.00% 51.60  X  0.00% for training and the remaining for testing.
 Figure 6: The confusion matrix (in percentage) of condition recognition result from the proposed method, where both axes are the condition index.
 The axis is index of the conditions.
 In our experiments, we use one session for training and the other session for testing. The images are converted to gray scale and resized to 55  X  40. To recognized the associated condition, we slightly changes the formulation of the sub-space: where S i is the subspace for condition i and S y the subspace for the test image. The other settings were the same as those of previous face recognition experiments.

The proposed method achieves an accuracy of 91.77% in recognizing the conditions, with the confusion matrix given in Fig. 6, where we achieved over 96% accuracy for all but conditions 1, 2, 3 (3 expressions) and 12. This experiment again demonstrates the effectiveness of the proposed method in capturing the physical conditions in the form of low-rank components.
In this paper, we proposed a novel decomposition of a set of face images of multiple subjects, each with multiple images. The decomposition finds a common image and a low-rank image for each of the subjects in the set. All the low-rank images form a set that is used to capture all possi-ble global conditions existing in the set of images. This fa-cilitates explicit modeling of typical challenges in face recog-nition, such as illumination conditions and large occlusion. Based on the decomposition, a face classifier was designed, using the decomposed components for subspace reconstruc-tion and comparison. The classification performance shows that the proposed approach can achieve state-of-the-art per-formance. Experiments also showed that the proposed method is robust with missing training images, which can be an im-portant factor to consider in a practical system. We also demonstrated with experiments that the decomposition in-deed captures physically meaningful conditions, with both synthetic data and real data.

There are a few possible directions for further develop-ment of the work. In particular, the current algorithm as-sumes that the low-rank conditions of the training images are known and given for each of them. In practice, if the data do not have such image-level label (but still with a finite set of low-rank conditions), it is possible to expand the current algorithm by incorporating another step that attempts to estimate a mapping matrix for assigning a con-dition label to each image, during the optimization itera-tion. For example, we may define a mapping matrix  X  with  X  i,j = k defining that training image X i,j is associ-ated with condition A k . Eqn. 1 suggests a constraint that we may use to solve for  X : the optimal mapping matrix should result in the most sparsity for E i,j or the lowest rank for A k , given the same reconstruction error. If we use the first criterion, the problem of finding  X  can be formulated as  X  = argmin
The work was supported in part by a grant (Grant No. 0845469) from the National Scien ce Foundation. Any opin-ions, findings, and conclusions or recommendations expressed 0.00 % 99.65  X  0.37% 97.49  X  0.21%  X  0.07% 99.73  X  0.14% 97.73  X  0.54 % 0.00 % 100  X  0.00 % 95.83  X  4.16%  X  0.11% 99.45  X  0.43% 95.75  X  0.49%  X  1.74% 96.90  X  3.73% 87.18  X  1.78% 0.00 % 99.54  X  0.31 % 94.30  X  4.72%  X  0.05% 98.53  X  0.29% 88.75  X  4.72%  X  0.06 % 99.24  X  0.06 % 90.95  X  0.70 %  X  0.03% 96.79  X  0.28% 86.98  X  0.16%  X  0.47% 97.63  X  0.28% 89.72  X  1.45%  X  0.14% 97.89  X  0.30% 88.29  X  0.02% pick M =40 conditions for training and the remaining for testing.. in this material are those of the authors and do not neces-sarily reflect the views of the National Science Foundation. [1] M. Aharon, M. Elad, and A. Bruckstein. K-SVD: [2] J. F. Cai, E. J. Candes, and Z. Shen. A singular value [3] E. Candes and Y. Plan. Matrix completion with noise. [4] A. Georghiades, P. Belhumeur, and D. Kriegman. [5] D. Goldfarb and S. Ma. Convergence of fixed-point [6] E. T. Hale, W. Yin, and Y. Zhang. Fixed-point [7] C. Kanan and G. Cottrell. Robust classification of [8] A. Knyazev and M. Argentati. Principal angles [9] R. Kumar, A. Banerjee, and B. Vemuri. Volterrafaces: [10] K. Lee, J. Ho, and D. Kriegman. Acquiring linear [11] Z. Lin, M. Chen, L. Wu, and Y. Ma. The augmented [12] J. Liu, S. Chen, and X. Tan. Fractional order singular [13] J. Mairal, F. Bach, J. Ponce, G. Sapiro, and [14] A. Martinez and R. Benavente. The AR face database. [15] P. Nagesh and B. Li. A compressive sensing approach [16] J. Portilla and E. Simoncelli. A parametric texture [17] T. Sim, S. Baker, and M. Bsat. The CMU pose, [18] J. Wright, A. Ganesh, S. Rao, Y. Peng, and Y. Ma. [19] J. Wright, A. Yang, A. Ganesh, S. Sastry, and Y. Ma.
Proposition 1 The sequences of  X  Y t +1 i,j , i  X  Y t +1 and  X  Y t +1 i,j are all bounded  X  i, j ,where Proof Let X  X  write the Lagrange function in 6 as: For simplicity, we will use L ( C t , A t , E t +1 , Y t , X  L ( dient of L ( C t , A t , E , Y t , X  t )over E i,j is As E t +1 i,j is optimal for the problem argmin
Proposition 2 The sequences of ( C t +1 , A t +1 , E t +1 Proof For Algorithm 1, we can find that: L (  X  L ( C t , A t , E t +1 , Y t , X  t )  X  L ( C t , A t , E By boundedness of assumption that  X  t =1  X  t +1 i,j (  X  t Proposition 3 The accumulation point (  X  C  X  ,  X  A  X  ,  X  Eqn. 5.
  X  min We also have: whereweusetheknowledgethat  X  Y t +1 i,j is bounded  X  i, j . (  X 
Y edness of  X  Y t +1 i,j  X  i, j ,wealsohave X i,j  X   X  C  X   X  X lution. In addition, we have With the assumption  X  t =1 (  X  t i,j )  X  1 &lt;  X  , boundedness of has limit A  X  j ,then C t +1 i has limit C  X  i ,then E t +1 X
Considering the subgradients and the optimality of E t +1 According to the property of subgradients:  X  =  X  &lt;  X  problem in Eqn. 5. This completes the proof of Theorem 1.
