 Typically, data collected by a spacecraft is downlinked to Earth and pre-processed before any analysis is performed. We have developed classifiers that can be used onboard a spacecraft to identify high priority data for downlink to Earth, providing a method for maximizing the use of a potentially bandwidth limited downlink channel. Onboard analysis can also enable rapid reaction to dynamic events, such as flooding, volcanic eruptions or sea ice break-up. Four classifiers were developed to identify cryosphere events using hyperspectral images. These classifiers include a manually constructed classifier, a Suppor t Vector Machine (SVM), a Decision Tree and a classifier derived by searching over combinations of thresholded band ra tios. Each of the classifiers was designed to run in the com putationally constrained operating environment of the spacecraft. A set of scenes was hand-labeled to provide training and testing data. Performance results on the test data indicate that the SVM and manual classifiers outperformed the Decision Tree and band-ratio classifiers with the SVM yielding slightly better classifications than the manual classifier. The manual and SVM classifiers ha ve been uploaded to the EO-1 spacecraft and have been running onboard the spacecraft for over a year. Results of the onboard analysis are used by the Autonomous Sciencecraft Experi ment (ASE) of NASA X  X  New Millennium Program onboard EO-1 to automatically target the spacecraft to collect follow-on imagery. The software demonstrates the potential for future deep space missions to use onboard decision making to capture short-lived science events. I.5.2 [ Pattern Recognition ]: Design Methodology  X  Classifier design and evaluation Algorithms, Performance, Experi mentation, Human Factors Classification, Support Vector M achine, Constrained processing environment. Historically, spacecraft collect data and transmit it to Earth for analysis. In this paper, we desc ribe several algorithms that have been developed to analyze data onboard a remote sensing spacecraft to detect events of in terest. There are two primary motivations for analyzing science data on a spacecraft. The first is that onboard analysis can enable prioritization of the data by identifying the highest priority data for transmission. For many spacecraft, in particular those in deep space beyond Earth orbit, downlink bandwidth is severely limited. It is common that instruments are capable of collecting considerably more data than can be transmitted to Earth, however they are usually tasked to collect only as much data as can be downlinked. By collecting data at the capacity of the instrument and analyzing it onboard, there is significantly increased opportunity to identify rare features or events of interest. The second motivation for onboard science data analysis is to enable the detection of and reaction to dynamic events. For example, with an eight hour round trip light time, timely reaction to an eruption event on Io, a volcanically active moon of Jupiter, would be possible only if the event was detected onboard and the spacecraft equipped to react. Equipped with only ground-based analysis such reactions are not possible. There are a number of challenges to analyzing science data onboard a spacecraft. First, processing power is very limited. The radiation hardened CPU X  X  used in spacecraft lag desktop technology by several generations. Memory is also very limited. Second, onboard analysis needs to be performed in a restricted timeframe. The actual limitations depend on the application such as when downlink opportunities occur or the potential reaction time of the spacecraft based on orbit geometries. The third challenge in developing onboard sc ience data analysis algorithms is that the data available onboard the spacecraft is uncalibrated. In some cases, such as the domain desc ribed in this paper, it is only possible to access onboard a limited portion of the collected data. We have developed a successful approach to addressing these challenges and have demonstrated its effectiveness by applying it to the development of onboard algorithms to analyze hyperspectral data for events of in terest. The key is that it is not necessary to replicate ground-based analysis to accomplish the goal of reliably detecting events of interest. In this paper, we first describe , in Section 2, the background of the application domain including the spacecraft and data used. We then explain the four classi fiers that were developed for cryosphere classification in Section 3 and present performance results on a set of test images in S ection 4. Also in Section 4, we describe how the classifier results are used for event detection. Finally, we conclude in Section 5. The onboard classifiers were developed for the Autonomous Sciencecraft Experiment (ASE), a Jet Propulsion Laboraty-led, New Millennium Program mission containing new technology in the form of software that facilitates autonomous science-driven capabilities. The ASE flight software includes a set of onboard science algorithms designed for autonomous data processing to identify observed science events [2, 4, 13]. Using the output from these algorithms, ASE has the ability to autonomously modify the spacecraft observation plan, retargeting itself for a more in-depth observation of a scientific event in progress with current response times on the order of hours. Several onboard science algorithms are associated with ASE for detecting dynamic events. Phenomena detected include volcanic eruptions[5], floods[9] and cryosphere events[6]. In this paper, we discuss cl assifiers for cryosphere event detection. The cryosphere is the component on the surface of a planetary body composed of ice. Th e ice may exist in a variety of forms including snow, permafrost, fl oating ice, and glaciers. The cryosphere dynamically interacts with the atmosphere and can significantly affect the climate on a planetary body. Ices, including water ice and CO 2 , are found throughout the solar system. In addition to the water ice caps on Earth and the water and CO 2 at the Martian poles [15], ice is thought to exist in the permanently shadowed polar craters of the moon [7] and Mercury [14], and is a major component of the moons in the outer solar system and as well as comets. Cryosphere events studied include the formation and break-up of sea ice as well as the freezing and thawing of lakes. ASE has been flying on the Earth Observer-1 (EO-1) satellite since the fall of 2003 [2 4]. EO-1 is part of NASA X  X  New Millennium Program, designed to validate new technologies for remote sensing. It was la unched from Vandenberg Air Force Base on 21 November 2000 and placed in a sun-synchronous orbit with an altitude of 705 km and a 10:01 AM descending node, giving it an equatorial crossing time that is one minute behind Landsat-7 and a 16-day repeat path orbital cycle. With observations up to two paths off nadi r, EO-1 is able to image the same location as many as 5 times every 16 days in daylight. The EO-1 payload is comprised of three instruments: Hyperion, Advanced Land Imager (ALI) and the Linear Etalon Imaging Spectral Array (LEISA) Atmospheric Corrector. We analyze data from the Hyperion instrument onboard the spacecraft. The Hyperion instrument [11] consists of two imaging spectrometers, covering the visi ble/near infrared (VNIR) and short-wave infrared (SWIR), respectively, which share a common telescope, producing hyperspectral images with a 30 m/pixel spatial resolution and 10 nm/band spectral resolution. Hyperion images are 7.5 km in width, with an along track length that depends on the duration of the data collect, but typically 60 km (8 seconds) or 90 km (12 seconds). ASE analyzes a 7.5 km by 15 km subset of the captured image when detecting cryospheric events. The VNIR spectrometer has 50 calibrated bands, ranging from 0.43 to 0.93  X  m, and the SWIR spectrometer has 148 calibrated bands, ranging from 0.91 to 2.4  X  m. Onboard constraints permit access to only 12 of the bands of the Hyperion instrument, although these 12 are selectable from the full complement. There are two identical processo rs onboard the EO-1 spacecraft, one for the primary spacecraft operations and the other for the payload. ASE uses the payload processor. It is a Mongoose V CPU with a processor speed of 8 MIPS and 256 MB of RAM. With this hardware constraint, the Hyperion data cannot be fully processed from Level 0 (raw) data to Level 1 (calibrated) data [1]. Instead the data are partially processed to an onboard product designated Level 0.5, using data from a dark calibration image collected within a few minutes of the actual image. Features of Level 1 data processing [1] not performed in the onboard processing include smear and echo correction to the SWIR bands, as well as interpola tion between pre-and post-dark calibration images before dark im age subtraction. While both Level 0.5 and Level 1 data are identical in VNIR, they diverge in SWIR, where the lack of smear and echo correction in Level 0.5 gives higher values than in the fully processed data. Because Level 0.5 data are not fully calibrated, the radiance and reflectance values for SWIR bands calculated onboard the spacecraft can be considered as pseudo-radiance and pseudo-reflectance. The approach to onboard identificati on of cryosphere events is to classify pixels in the image independently based on the available spectral information. The number of pixels in each class the image is then determined and ratios of these values are used to identify events. Pixels are classified as belonging to one of five classes: water, ice, land, snow , or cloud. A sixth class of unknown or unclassified is also allowed for some of the classifiers. The challenge is to achieve sufficiently high classification accuracy under conditions of limited CPU, few available spectral bands, and incomplete calibration. Four pixel-based classifiers to identify cryosphere events onboard the spacecraft were developed. These classifiers include an expert-derived manually constructed classifier, a classifier derived by searching exhaustively over co mbinations of thresholded band ratios, a Decision Tree, and a S upport Vector Machine (SVM). A set of scenes was labeled by ha nd by a domain expert to provide training and testing data. 
The manually constructed cryosphe re classifier was developed by a domain expert [6] and will be called the expert-dervied classifier hereafter. This cla ssifier was designed to be run in sequence after a first classifier identified all the cloud pixels. 
The preliminary pass cloud classifier is described in [8]. The manual cryosphere classifier utilizes a total of seven bands. The classifier is effectively an empirically derived decision tree developed using the full compliment of spectral bands for 175 samples (pixels). Sample spectra of snow, water, ice, land and cloud pixels were selected acr oss several images, focusing on clouds not detected by the algorithm in [8]. Image regions for each of the five classes (land, water, snow, ice, cloud) were identified visually. All of the scenes from which training data was selected were processed fro m Level 0 to Level 0.5 on the ground. The spectra were converted from radiance to reflectance and then plotted in a spreadsheet. Inspection of the plots was used to determine a sequence of band ratios and thresholds that could separate the spectra into the classes defined. After selection of ratios and thresholds, the set of training images were classified and regions incorrectly classified were identified visually. The spectral plots we re studied and a new decision layer was added to the classifier to correct significant misclassifications. This procedure was iterated until a sufficiently high accuracy was achieved. The final version of the classifier employs a series of twenty steps to classify snow, water, ice and land. Full details of the expert-derived classifier are provided in [6]. 
This procedure for developing a classifier is standard for these domain experts. It required ex tensive domain expertise and was very time consuming for the domai n expert. We developed the other three classifiers using machine learning methods to determine both if we could improve accuracy over the manual approach as well as to reduce the time required by the domain expert. 
The first automated algorithm developed was to identify the best thresholds of ratios of bands us ing an exhaustive search of all possible options. This was to be used as a point of comparison for the other algorithms. The result can be considered a very simple decision tree. 
Bands that exhibited a high percen tage (&gt;1 %) of noisy pixels in the training set were not used. A noisy pixel is defined as a pixel whose value was invalid. This happens most commonly when the signal is very low and is overwhelmed by the noise in the dark image. There is a clear correlation between noisy bands and 
H 2 0 (and to a lesser degree O 2 and CO 2 ) absorption bands. Also, surfaces like water, shadow, and lava that are less bright can suffer from a low signal-to-noise ratio. 
After removing the noisy bands 150 bands remained for use in the experiment. With 150 bands, there were 11175 possible band ratios to consider. For each ratio, the optimal threshold was determined where the decision was a one-vs-all (more accurately one-vs-other) classification. Fo r example, the optimal threshold for classifying pixels as water or not water was determined for every possible ratio. This was done for each of the five classes. 
For each class, the ratio with the highest classification accuracy was selected for the classifier. The classifier was constructed by sequentially applying the individua l ratio/threshold classifiers. 
For example, the water vs. other classifier was applied. The classifier for snow vs. other was then applied to all pixels not classified as water, etc. The order was determined by applying the individual classifiers in order of accuracy. The evaluation was done with both radiance and reflectance data. The final classifier is shown in Figure 1. 
In addition to the band ratio cla ssifier, thresholding of individual bands, and thresholding of normali zed differences between bands were both considered. Threshol ding of individual bands is was more sensitive to the uncalibrated data available onboard than band ratios. The normalized ba nd differences were not used because the normalized band differences yield equivalent results to the band ratios. This can be seen as follows. If represent the spectral data at two different pixels and pixel y
It can be seen from the classifier in Figure 1, that at most four divisions for the band ratios and f our conditional statements must be evaluated for this classifier. 
While simple in its approach, this classifier does not take any time on the part of the expert to develop other than providing labeled data, which is necessary for quantified evaluation of any classifier including the expert-derived classifier. The next two algorithms also alleviate the expe rt development time but employ more advanced learning methods than brute force to achieve improved classification results. 
The second automated classifier developed was a decision tree classifier. Decision trees are effective for a number of classification tasks with the benef it that they generation rules that can be easily understood and explained. In this work, the standard C4.5 algorithm [12] was used to develop the decision tree classifier. A number of experiments with the decision trees were conducted. 
Three different sets of features were used in these experiments: -11 selected bands -55 band ratios (all ratios of the 11 bands) and -Principle Component Analysis (PCA) Eigenvectors derived from the training data Refinement with respect to feature selection was done incrementally. Upon completion of a test, additional features were added to the training set and tested. If the additional training features produced a better classifier then the original, they were kept, other wise they were not used. The selection of which features were added wa s done randomly. While it would probably not be computationally feasible to compute the PCA onboard, these features were used in the experiments to determine if increased accuracy would be po ssible using this method if more computational power were available. A number of decision trees were trained and tested using combinations of the above featur e sets. In several cases, the decision trees had particular difficulty distinguishing between two of the classes. Which two classes were confused varied across experiments and combinations of features, however common problems were distinguishi ng between land and cloud and distinguishing between cloud and snow. To address the issue, a secondary decision tree was trai ned on only the two classes in question. This second classifier was then chained to the first and applied as a discriminator only when the first classifier identified a pixel as belonging to one of the two poorly distinguished classes. We found that the best performance was achieved using the 11 selected bands in combination with a secondary cloud vs. land classifier. Additional information did not increase accuracy, and in many cases, led to reduced accuracy. For example, one of the poorest classifiers employed both the 11 individual bands and the 11 PCA bands. The maximum number of operations required is a function of the depth of the final tree. The depth of both the primary and secondary trees for the best classifier was 12. Therefore in the worst case it is necessary to take 24 branches to perform a single pixel classification. On the average, the decision tree is able to reach a decision at a much earlier branch. Since the tree did not use band ratios, only a comparison is required at every level of the tree. Thus, the worst case complexity is 24 floating point comparison operations. The final cryosphere classifier used a Support Vector Machine (SVM). SVMs [3] are a family of classifiers that identify classes in a (possibly) high dimensional space. Maximizing the margin prevents the algorithm from over fitting the training data, which can lead to poor algorithm performance on new input data sets. To construct the SVM cl assifier, the same 11 bands that were used with the expert-derived classifier were used. In this work, emphasis was not placed on band selection. A primary disadvantage of support vector machines is that the time to classify points is proportional to the number of support vectors, which for complicated problems can be as large as the number of training examples. Since we wanted to train on thousands of example pixels, th is would result in unreasonably slow classification. Instead, we decided not to use a kernel function, leaving us with a lin ear support vector machine. Although the full benefits are not r ealized in using a linear SVM, the benefit is that the decision boundary can be determined explicitly thus requiring a single dot product to be evaluated in classifying each pixel rather than a dot product for every support vector in the classifier. Since 11 bands are used, the feature vector has 11 elements. Therefore, exactly 11 multiplies and 11 additions are required for each of the five classes, plus a comparison operation to determine the correct classification after each of the five evaluations. Evaluating the SVM was thus not substantially more computationally challenging than the other methods. The SVM approach is somewhat more sensitive to bad or missing data than the other methods. While a decision tree can potentially ignore certain branches or take de fault branches when particular spectral bands are missing, the SVM approach considers all spectral bands simultaneously and gives meaningless results if any of them are missing or bad. Thus, any time a band was missing, we marked that pixel as unclassified. This typically only represented 1% of the pixels in an image. We assessed the performance of th e classifiers using a set of 100 images labelled by a domain expe rt. The image set was divided into 50 images for training and 50 images for testing. The test set contained just over 91 million pixels . The results on the test data are shown for the expert-derived classifier, the decision tree and the SVM. The results shown for the best ratio classifier are for a comparable, but slightly different test set. The results are shown in terms of precision and recall which are defined as follows. For a given classifier, we can define the true positives (TP) for each class as those pixels that were correctly classified, e.g. all pixels that are labelled as water and classified as water. The false positives (FP) are those pixels that are classified as belonging to a class, but labelled as belonging to a nother class, e.g. classified as water, but labelled as land. Fina lly, the false negatives (FN) or misses are defined as those pixels that are labelled as belonging to the class, but are otherwise classified, e.g. labelled as water, but classified as ice. With these definitions, the precision of a classifier for a given class is defined as while the recall of a classifier for a given class is defined as The precision indicates the percent of pixels classified as a belonging to a particular class th at truly do belong to the class according to the labels. In contrast, recall indicates the percent of pixels labelled as a class that we re actually classified as belonging on the test data are shown in Tables 1 and 2. Within the test set, the number of pixels belonging to each of the five classes was not evenly distri buted. The distribution of pixels over the five classes is shown in Table 3. The overall accuracy of each classifier is given in Table 4. The expert-derived, best ratio, and SVM classifiers all have an unclassified label that can be assigned to a pixel. In these te sts, water pixels were the most common class in the set of unlabeled pixels. In particular, this was a factor with the SVM as it requires valid values for all elements of the feature vector and, as explained earlier, the signal to noise ratio for water is low leading to a higher number of bad pixels for this class. It should be emphasized that these results do not necessarily indicate the full power of the learning methods due to the restrictions imposed in developi ng the classifiers for the onboard computational environment. In particular, a non-linear kernel would be used with the SVM on a desktop machine to achieve a higher level of accuracy. The overall accuracy is very similar for the four classifiers. This accuracy assumes that all classes are equally important, that is each pixel is equally weighted independent of its label. It can be seen that the simplest approach does not reach the level of performance of an expert derived or more advanced learning approaches. An example image is shown in Figure 2. In the figure, a false color image of the scene is show n along with the expert labelling expert-derived and SVM classifiers outperform the automated ratio-based classifier and that the SVM appears to perform slightly better than the expert-derived classifier on this scene. Notice also that the blue specs in the mid and lower sections of the image for all three of the classifier results are actually small bodies of water that the expert did not label. While they are correctly classified, due to inaccuracies in the labeling, they would be evaluated as incorrect dur ing testing. This highlights a challenge in acquiring accurate labels. Table 4. Overall performance accuracy of the four classifiers. To assess the performance of the classifiers and to train the automated classifiers, an extensive set of labeled data is required. It is very tedious to provide high-fidelity labels. This problem occurs over a wide span of image classification applications that need training and testing data. We developed an interactive tool to help with the labeling process [10]. Initially developed for data from the Multi-angle Imaging SpectroRadiometer (MISR) instrument, it has been adapted to a variety of data sets, including Hyperion. The tool,  X  X ixelearn X , creates an SVM classifier from a very small set of labels and classifies the image in real time. The user then identifies pixels that are classified incorrectly, provides the correct label for a set of the mis-classified pixels using an interactive drawing tool, and retrains the classifier. The tool allows rapid, accurate labeling of large volumes of image data. This classifier can provide higher accuracy than the onboard SVM because it uses the complete set of fully calibrated spectral bands and, with less computational limitations, can employ a higher dimensional kernel. Our objective is to detect events such as sea ice beak-up. As described in the previous section, due in part to the use of uncalibrated data and limited onboard processing power, the expected accuracy at the pixel level for these classifiers is just over 80%. In addition, there is un certainty in the along track error of the spacecraft. The one second timing uncertainty results in approximately a 7 km or 230 pixel uncertainty. Combined, these two factors make onboard pixel di fferencing at the spectral or label level infeasible. A robust method for identifying the change events was implemented that uses the ratio of pixels belonging to various classes to assess the presence of change. The presence of completely cloud covered). If these criteria are met, a second criterion is analyzed to determine the presence of the cryosphere event. Figure 3 shows an example of the criteria used to determine sea ice break-up. By usi ng ratios of pixels and generous thresholds, we are able to detect the events with classification rates that are feasible for the onboard classifiers. The expert-derived classifier a nd the SVM were both uploaded to the EO-1 spacecraft and are now running onboard. These classifiers are currently being used to identify cryosphere events such as lake freezing or thawing and sea ice breaking up. The first image classified onboard by the SVM was on September 22, 2004, when the classifier correctly classified the image of Lake Winnibigoshish, Wisconsin, shown in Figure 4 as cloudy. On December 1, 2004, the SVM classifier analyzed a scene of South Georgia Island near Antarctica and successfully identified open water indicating sea ice break-up (See Figure 5). As a result of the onboard analysis a reimage of the scene was triggered and collected on December 3, 2004. This was the first use of the SVM classifier being employed as an onboard science data analyzer to automatically trigger a spacecraft reaction. The SVM classifier is now in regular use as part of the ASE software onboard EO-1. Four classifiers for hyperspectral data were developed and tested. The machine learning classifiers had comparable results to the expert-derived developed classifi er, although they took an order of magnitude less of the experts X  time to derive. The classifiers are presently being used on the EO-1 spacecraft to automatically trigger the collection of follow-up imag es of scenes based on the identification of cryosphere events. One key to the success of the onboard classifiers is that they do not need to operate at the fidelity of ground-based science data analysis methods. The objective of the data analysis on a spacecraft is to detect events. Once the data has been downloaded, the full data is available for thorough scientific analysis on the ground. In situ analysis can be used to trigger the collection of additional data, as with ASE onboard EO-1, but can also be used to change the data collection rate of an instrument when a dynamic event is detected or to identify high priority data for downlink. The use of machine learning classifiers for onboard data analysis shows great potential for use in future deep space missions, where the round trip messaging times make the reaction to dynamic events difficult to impossible with the traditional ground-in-the-loop approach. 
Figure 2. Example Image with representative results. The left pane shows a false color image of a scene near Madison, 
Wisconsin taken in the summer. The next pane shows the expert labeling, where blue is water and black is land. The third pane contains the results of the expert-derived classifier. 
The fourth and fifth panes are the automated ratio and SVM results respectively. The cyan pixels that are seen in both the expert-derived and automated ratio results are pixels that have been misclassified as ice. This work was performed by the Jet Propulsion Laboratory, California Institute of Technology, under contract with the National Aeronautics and Space Administration. Funding was provided by the NASA X  X  New Millennium Program and the Interplanetary Network Direct orate Technology Development program. [1] Barry, P. EO-1 / Hyperion Science Data User X  X  Guide, Level [2] Chien, S., Sherwood, R., Tran , D., Cichy, B., Rabideau, G., [3] Cortez, C., and Vapnik, V., Support vector networks, [4] Davies, A. G., Baker, V., Castano, R., Chien, S., Cichy, B., [5] Davies, A. G., Chien, S., Baker, V., Doggett, T., Dohm, J., [6] Doggett, T., Greeley, R., Chie n, S., Castano, R., Cichy, B., [7] Feldman, W.C., Maurice, S., Binder, A.B., Barraclough, [8] Griffin, M.K., Burke, H.K ., Mandl, D., and Miller, J., Cloud [9] Ip, F., Dohm, J.M., Baker, V.R., Doggett, T., Davies, A.G., [10] Mazzoni, D., Garay, M., Davies, R., and Nelson, D. An [11] Pearlman, J.S., Barry, P.S., Segal, C.C., Shepanski, J., Beiso [12] Quinlan, J. R. C4.5: Programs for Machine Learning. San [13] Sherwood, R., Chien, S., Tr an, D., Cichy, B., Castano, R., [14] Slade, M.A., Butler B.J. and Muhleman, D.O., Mercury [15] Thomas, P., Squyres, S., Herkenhoff, K., Howard A., and 
Figure 5. Image of South Ge orgia Island near Antarctica taken December 1, 2004. The left is the false color image while the right shows the re sulting SVM classification, where blue is water, black is land, cyan is ice, purple is snow, gray is cloud, and white is unclassified. Open water was correctly identified indicating sea ice break-up and triggering another image of the scene to be taken on 
December 3, 2004. 
