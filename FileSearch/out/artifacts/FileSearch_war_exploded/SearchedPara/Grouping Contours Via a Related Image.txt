 psrin@seas.upenn.edu Researchers in biological vision have long hypothesized that image contours (ordered sets of edge pixels, or contour points) are a compact yet descriptive representation of object shape. In computer vision, there has been substantial interest in extracting contours from images as well as using object models based on contours for object recognition ([15, 5]), and 3D image interpretation [11]. We examine the problem of grouping contours in a single image aided by a related image, such as stereo pair, a frame from the same motion sequence, or a similar image. Relative motion of contours in one image to their matching contours in the other provides a cue for grouping. The contours themselves are detected bottom-up without a model, and are provided as input to our method. While contours already represent groupings of edges, they typically lack large spatial support. Region seg-ments, on the other hand, have large spatial support, but lack the structure that contours provide. Therefore, additional grouping of contours can give us both qualities. This has important applica-tions for object recognition and scene understanding, since these larger groups of contours are often large pieces of objects.
 Figure 1 shows a single image in the 1st column, with contours; in the other columns, top row, are different images related by stereo, motion and similarity to the first, shown with their contours. Below each of these images are idealized groupings of contours in the original image. Note that internal contours on cars and buildings are grouped, providing rich, structured shape information over a larger image region. Figure 1: Contours (white) in the image on the left can be further grouped using the contours of a second, related image (top row). The bottom row shows idealized groupings in the original image according to the inter-image relationship. Stereo, motion, and similar image matching have been studied largely in isolation, and often with different purposes in mind than perceptual grouping. Much of the stereo literature focuses on per-pixel depth recovery; however, as [7] noted, stereo can be used for perceptual grouping without requiring precise depth estimation. Motion is often used for estimating optical flow or dense seg-mentation of images into groups of pixels undergoing similar motion [13]. These approaches to motion and stereo are largely region-based, and therefore do not provide the same internal structure that groups of contours provide. Similar image matching has been used for object recognition [1], but is rarely applied to image segmentation.
 In work on contours, [12] matched contour points in the context of aerial imagery, but use con-straints such as ordering of matches along scanlines that are not appropriate for motion or similar images, and do not provide grouping information. [9] grouped image pixels into contours according to similar motion using optical flow as a local cue. While the result addresses the long-standing aperture problem , it does not extend to large inter-image deformations or matching similar images. [8] grouped and matched image regions across different images and unstable segmentations (as we do with contours), but the regions lack internal structure. [2, 6] used stereo pairs of images to detect depth discontinuities as potential object boundaries. However, these methods will not detect and group group contours in the interior of fronto-parallel surfaces. We present definitions and basic criteria for grouping contours. The inputs to our method are: We would like to infer groups G 1 ,.., G nGroups , each with the following attributes: We further define the following variables on contours C j 1 = [ p k 1 ,...,p k n ] : Figure 2: (left) -matching closest points cannot reject false positives; simply enlarging the feature size rejects true positives; increasing the feature size and selecting correct context fixes the prob-lem and Figure 3: (right); the realized shape context from choosing a subset of contours can be summarized as the multiplication of a shape context matrix M and a binary indicator vector. We would like the groups to possess the following criteria: We will encode these criteria in our cost function F ( T , Con , L , Match ) , which we seek to min-tions: 1) For fixed contexts [ Con and transformations b T , min Markov random field (MRF) that can be minimized exactly via graph cuts ([3]). This corresponds each image, over the contours). 2) For fixed matches \ Match , transformations, b T and labels b L , F decomposes as the sum over i = { 1 ,..., nGroups } and we can minimize independently: min related linear program (LP), allowing for an efficient approximation. This combination of the MRF standard graph matching technique with an LP for inferring context for accurate matching by shape is our main contribution.
 The layout of our paper is as follows: we explain the problem and importance of selecting contours as context for accurate matching and grouping, outline our computational solution (LP) for inferring Con given T , our technique for choosing T , followed by finding L and matches Match based on the inferred contexts (via graph cuts). Results using our method follow, and we demonstrate improvement over a baseline that lacks that benefits of our context selection procedure. We can evaluate the hypothesis of a particular contour point match by comparing the local shape around the point and around its match. Although local features such as curvature and simple prox-imity (in the case of roughly aligned contours) have been used for matching ([12]), inconsistencies in the input contours across two images make these them prone to error. Local features exhibit com-pleteness (good score for correctly matching shapes), but not soundness (bad score to not matching shapes). Figure 2 illustrates this distinction. Two aligned sets of contours are shown in a),e). In a), the contours do not match, while in e), a  X 7 X  shape is common to both. In b) and f), matching of Figure 4: The context selection process for roughly aligned sets of contours. See text for full de-scription. closest points between two roughly aligned shapes finds matches in both examples due to the small support of local features, even though there is no valid match in a).
 However, increasing the support of the feature does not solve the problem. As an example, we use the shape context, an image feature that has been widely used for shape matching ([1]). Briefly, a shape context provides a log-polar spatial histogram that records the number of points that fall into a particular bin. In Figure 2 c,g), shape contexts (darker bins mean larger bin count) with large spatial support placed according to the rough alignment exhibit high dissimilarity in both cases, failing to find a match in a). The large feature failed because contours in each image that had no match in the other image were used in computing the shape context. Inferring which contours to include and which to omit would give better features, as in Figure 2 d),h). This fixes the completeness problem, while retaining soundness: no combination of contours in the two images in a) can produce matching shapes. Therefore, with rough alignment we can cast the first step of shape matching as context selection : which subset of contours, or context, to use for feature computation. Given the correct context, matching individual contour points is much easier. 4.1 Selection Problem We can neatly summarize the effect of a particular context selection on a shape context as seen in Figure 3. a) shows two contours which we can select from. b) shows the shape contexts for each by the shape contexts and their vector representations alongside. In c), we put the vector form of these shape contexts into a matrix SC , where each column corresponds to one contour. SC has dimensions nBins by nContours, where nBins is the number of bins in the shape context (and the length of the associated vector). The entry SC ( i,j ) is the bin count for bin i and contour j . For each whether or not the contour is selected; the vector of these indicator variables is sel i . Then the shape context bin counts realized by a particular selection of contours is SC sel i , simply the multiplication of the matrix SC and the vector sel i . d) shows the effect on the shape context histogram of various context selections. 4.2 Shape context matching cost The effectiveness of selection depends significantly on the shape context matching cost. Traditional matching costs (Chi-square, L 1 , L 2 ) only measure similarity, but selecting no contours in either image gives a perfect matching cost, since in both shape contexts, all bins will be 0. While similarity is important, so is including more contours rather than fewer (maximality).
 Our shape context matching cost, SCMatchCost(s 1 , s 2 , X  ) in Figure 4, is a linear combination of the L 1 distance between shape context vectors s 1 and s 2 (similarity), and the intersection distance (max-imality, one of our original grouping criteria), the L 1 norm of min( s 1 ,s 2 ) where min is element-Figure 5: For a pair of images, SIFT matches propose different transformations of the contours in image 1 to align with contours in image 2. The selection process is run for each transformation to infer a context suitable for evaluating contour point matches via shape. wise. The intersection term encourages higher bin counts in each shape context and therefore the inclusion of more contours. The parameter  X  trades off between similarity and maximality; typically  X   X  1 . 4.3 Computational Solution Our formulation of the problem follows the construction first presented in [16], which studied the role of context selection for object recognition. Figure 4 shows the formulation of the overall selec-input images, where the contours are in rough alignment (by applying known T i to I C 1 ). Multiple shape contexts are placed in each image on a uniform grid (an approximation of Match j | l(j)=i , since we initially have no matches). Like-colored (in the figure) shape contexts will be compared across images. Our goal is to select contours in each image to minimize the sum of SCMatchCost for each pair of shape contexts. For each shape context j in each image i , we compute the corresponding for each image has been color coded to show the SC j i matrix corresponding to each shape context. I all the shape contexts in image I i under selection selc i . We seek to choose selc 1 and selc 2 such that are in correspondence, so we can score these pairs of bin counts using BinMatchCost . A compact summary of this cost function SelectionCost is shown in Figure 4; its decomposition as the sum of SCMatchCost terms, which are each in turn a sum over BinMatchCost terms is shown.
 The minimization of SelectionCost over selc 1 and selc 2 is in fact an integer linear program ( L 1 distance and min are easily encoded with additional variables and linear constraints). By relaxing each sel j i  X  { 0 , 1 }  X  [0 , 1] , we obtain a linear program (LP) which can be solved efficiently using standard solvers (e.g. SDPT3). Although other methods exist for solving integer linear programs, such as branch-and-bound, we found that directly discretizing the sel j i with a fixed threshold worked well. Then [ Con i = { selc 1 , selc 2 } . 4.4 Multiple Context Selections for Image Matching Now that we have established how to do selection in the case were are given T i , we now apply it in images where there may be multiple objects that are related across the two images by different alignments. We first need to infer the set of candidate transformations T ; for our purposes, we will restrict them to be similarity transforms, although we note that non-linear or piecewise linear (e.g., articulation) transformations could certainly be used. A simple method for proposing transforma-tions in the two images is via SIFT ([10]) feature matches. A SIFT match provides scale, orientation, and translation (a similarity transform). RANSAC with multiple matches can be used to estimate full homographies, similar to [14].
 Figure 5 depicts an idealized selection process for two images (only the contours are shown). For groups of SIFT matches that describe similar transformations, a transformation T i is extracted and warps the contours in image 1 to line up with those of image 2, in c). The selection problem is formulated separately for each set of aligned contours d). The solution vectors of the SelectionCost e). Two correct transforms align the car and person, and the selection result includes the respective contours (rows 1,2 of e). A third, wrong transform results in an empty selection (row 3 of e). We can view the context selection procedure for minimizing F i as choosing the context of contours so as to best reduce the matching cost of the hypothesized inter-image matches for contours with label i , under the transformation T i . In a sense, we are optimizing the local features via an LP, which traditional graph matching techniques do not do. The result of this optimization will appear in the unary term of the label/match MRF described next. We previously computed context selections (as solutions to the SelectionCost LP), which found groups of contours in each image that have similar shape, [ Con = { [ Con 1 ,..., \ Con nGroups } under transformations b T . Given these, we seek to compute L and Match . Some labels in 1 ,..., nGroups may not be assigned to any contours, satisfying our simplicity criterion for grouping. Note that a contour C j 1 need not be selected as context in a particular group a in order to have l j = a . Recall with respect to the original cost function, we seek to optimize: min phrase this label assignment problem as inference in a Markov network (MN). The MN encodes the where Z is a normalization constant.
 The binary potentials  X  ( l j ,l k ) encode the preference that overlapping contours C j 1 ,C k 1 have the same label: where 0  X   X   X  1 controls the penalty of having different labels. This is a simple smoothing potential to encourage continuity. Two contours overlap if they contain at least one point in common. second image with respect to the context \ { Con 1 a , Con 2 a } . The log-unary potential decomposes as the sum of matching costs of the individual points p k i to their best match in image I 2 , with respect to the context \ { Con 1 a , Con 2 a } : SC q 2 are respectively the shape context matrix computed for a shape context centered at T a ( p ) using the contours in image 1 under transformation T a , and the matrix for a shape context centered at q using the contours in image 2.
 We compute the exact MAP estimate in the MN using the  X   X   X  swap graph cut algorithm ([3]), which can maximize this type of energy. Instead of using all contours image 1 as nodes in the MN, we only allow contours were selected in at least one of the context Con 1 i ; likewise, we only permit matches to points in image 2 that appear in a contour selected in at least one Con 2 j . This better allows us to deal with contours that appear only in one image and thus cannot be reliably grouped based on relative motion. Figure 6: Baseline comparison (top) and additional results (bottom). Top: Columns 1,2: original im-ages with input contours, each colored. Columns 3,4: grouping results for our method and baseline; groups of contours are a single color. In stereo pairs, like colors indicate similar disparity. Bottom: Columns 1,2: original images with input contours, each colored. Column 3: our grouping result. Columns 4,5: matches across images indicated by like colors. Please view in color. 5.1 Baseline Comparison As a baseline comparison, we attempted grouping using an MN that involved no selection informa-tion. The binary potential remained the same, while the unary potential  X  ( l j = a ) was a function of T : The constant occlusionThresh serves a threshold in case a contour point had no nearby match in I 2 under the transformation T marked as occluded for the hypothesis l j = a . If more than half the points in the final assignment l for a contour were occluded, we marked the entire contour as occluded, and it was not displayed. Since we omitted all selection information, all contours in the 1st image were included in the MN as nodes, and their contour points were allowed to match to any contour point in I P 2 . We again optimized the MN energy with the  X   X   X  swap graph cut. Free parameters were tuned by hand to produce the best result possible. We tested our method and the baseline over stereo, motion and similar image pairs. Input contours in each image were extracted automatically using the method of [15]. SIFT matches were extracted from images, keeping only confident matches as described in [10]; matches proposing similar trans-formations were pruned to a small set, typically 10-20. Because of the high quality of the inferred contexts, we used large shape contexts (radius 90 pixels, in images of size 400 by 500), which made matching very robust. The shape contexts were augmented with edge orientation bins in addi-tion to the standard radial and angular bins. Shape contexts were placed on a uniform grid atop the registered contours (via T i ) with a spacing 50 pixels in the x and y dimensions. Image pairs were taken from the Caltech 101 dataset [4] and from a stereo rig with 1m baseline mounted on a car from our lab (providing stereo and motion images). The running time of our unoptimized MATLAB implementation was several minutes for each image pair.
 Figure 6, top block, shows the results of our method and the baseline method on stereo, motion and similar images. We can see that our method provides superior groupings that better respect object boundaries. Groups for stereo image pairs are colored according to disparity. Due to the lack of large context, the baseline method is able to find a good match for a given contour point under almost any group hypothesis l j = a , since in cluttered regions, there are always nearby matches. However, by using a much larger, optimized context, our method exploits large-scale shape information and is better able to infer about occlusion, as well as layer assignment. We present additional results on different images in Figure 6, bottom block, and also show the dense correspondences. Interesting groups found in our results include facades of buildings, people, and a car (top row). We introduced the problem of grouping of contours in an image using a related image, such as stereo, motion or similar, as an important step for object recognition and scene understanding. Grouping depends on the ability to match contours across images to determine their relative motion. Selecting a good context for shape evaluation was key to robust simultaneous and grouping of contours across images. A baseline method similar to our proposed method, but without context, produced worse groupings on stereo, motion and similar images. Future work will include trying to learn 3D object models from stereo and motion images, and a probabilistic formulation of the matching framework. Introducing learning to improve the grouping result is also an area of significant interest; some shape configurations are more reliable for matching than others.

