 Information that exists on the World Wide Web and the users that have access to it or continuingly changing condition that converts the Internet into a chaotic system. It is global information system is that it is flooded with a large amount of data and infor-mation and hence, finding useful information on the Web is often a tedious and frus-main problem is that they search every corner of the Web and often the results, even to well defined queries, are hundreds of pages. 
We focus on the needs of the Internet users who access news information from ma-jor or minor news portals. From a very brief search we found more than thirty portals that exist only in USA. This means that if one wants to find information regarding to a specific topic, he will have to search one by one, at least the major portals, and try to find the news of his preference. A better solution is to access every site and search for a specific topic if a search field exists in the portals. The problem becomes bigger for someone who would like to track a specific topic daily (or more times per day). the aforementioned issues. However, it is not possible to provide personalized results tion algorithms that have been proposed in the past, in order to achieve qualitative and chines, decision trees and others, classify a document di to a category cj regardless of the target group that will use categorized results. 
Many well-known systems try to solve this problem by creating rss feeds or per-cent and popular issues on them. The RSS feeds have become very popular and most Regarding the personalization issue, the attempts that have been made from the major search engines and portals include only the issue of viewing already categorized con-tent according to the user X  X  interests. This means that the user is not included into the classification procedure. 
MyYahoo is a very representative example [12]. Following the login the user is the user can add his special interests on news issues by selecting general topics from a are displayed. This procedure seems very helpful but it does not include the user into the classification and rating procedure. Another representative example is the service that appears is fully customizable and the user can add his own query to the appearing results but his choice is not included in the categorization mechanism but only to the rating mechanism of the entire web. 
In this paper, the proposed news portal archit ecture bases upon scalable text classi-match his profile. The user specifies the level of his expertise on different topics and the system relies on a new text analysis technique in order to achieve scalable classi-sentences vectors (instead of the document-article vectors). This procedure enables the system to capture articles that refer to several topics, while their general meaning is different. 
The rest of the paper is structured as follows. Section 2 presents the general archi-tecture of the system where the main feature is distribution of workload and modular-ity of the mechanism. Section 3 describes how personalization is implemented in our portal, in order to exploit user X  X  awareness of a topic and further enhance the catego-introduce a new scalable classification algorithm that relies on this technique in order to provide personalized classification results. Section 4 refers to the role of the user to portal is presented and section 6 introduces some concluding remarks and issues about future work on the system. The system consists of distributed sub-systems that cooperate in order to provide end-main features of the architecture are: 2.1 Modularity: Creating Autonomous Subsystems The core mechanism of the system we created can be described as a general manager and a main database. This is the module where everything starts from and concludes to. The subsystems of the mechanism can work autonomously but the general man-ager is responsible for the cooperation of them. system and seven subsystems. 
The crawler sub-system is responsible for fetching web documents that contain the fetched web documents. Preprocessing manager, Keyword Extraction manager, Keyword  X  Document matcher and Dynamic Profile manager are implementing the Scalable Classification Algorithm that we introduce in Section 3. 2.2 Distributing the Procedure The procedure of retrieving, analyzing and categorizing content from the World Wide start. This does not preserve the implementation of a distributed system for the com-can be completed in parallel with step N for the process of text Y. Presentation of the articles to the users must capture user-profile information in order to improve end-user results. Instead of treating this procedure as a standard text clas-sification problem, we also consider dynamic changes of Web users X  behavior and  X  X n-the-fly X  definition of the category topics. 
The main technique that our system exploits in order to provide personalized re-sults is the use of scalable text classifiers instead of standard text classifiers. Scalable classifiers, permit the classification of an article into many different categories (multi-tighter set of answers. 
Consider, for example, the text article of Figure 2 and Web users A and B. A is a journalism that needs information about Linux in order to write an article about open instructions on installing OpenBSD 3.6. 
A well-trained standard classification system would then provide the above docu-operating system. However, it is obvious that although user A would need such a decision, it is useless for user B to come across this article. knows a lot about Linux) would need less and more precise results, while non-expert users (such as the journalism) will be satisfied with a variety of results. 
Scalable text classification problem can be seen as a variant of the classical classi-fication where many similarity classes are introduced and permit different, multi-label classification results depending on the similarity class. Definition 1. (Scalable Text Classification) let of categories and It follows from Definition 1 that given an initial test set of k training data (text docu-ments) TrD = {trd1, trd2, ..., trdk} already classified into specific m training catego-ries from a well-defined domain TrC = {trc1, trc2, ..., trcm}, the scalable text classi-fier is a function that not only maps new text documents to a member of the TrC set using the training data information but also: document into a specific category c. Similarity classes can be shown as different ways to interpret the general meaning (concept) of a text document.  X  Permits the classification of each document into different categories depending on the similarity class that is used.  X  Permits the definition of new members and the erasure of existing ones from the defined set C with or without all the original members, as well as new ones. infinite ways into a number of components. Definition 2. (Document Decomposition into Sentences) Let the vector representation of a document i d tences is a decomposition of vector i d component k s document. Using a decomposition that Definition 2 provides us, we can therefore compute the standard cosine similarity using Equation 1. A modified version of a  X  X erm-to-document X  matrix, that we call it  X  X erm-to-sentences X  matrix can also be used to include information about the sentences decomposition. Figure 3 provides an example. The most useful characteristic of the proposed classification algorithm is its scalabil-ity feature. A text document can be classified into many different categories depend-categories. Formal definition of the Training Phase of the Scalable classification algo-rithm is shown in Figure 4: 
Main characteristics of the classification phase (Figure 5) include (a) the ability to order to classify the corresponding document to a category and (b) the feedback that the algorithm implicitly takes in order to re-compute categories vectors and therefore capture semantic changes of the meaning of a topic as time (arrival of new text docu-ments) passes. 
It is important to mention that the procedure of  X  X stimation of similarity X  involved such as (a) simple cosine computation, (b) latent semantic analysis of the matrix so as niques to approximate the SVD of the matrix [1, 2, 8, 9] or use partial SVD on cluster proximation. this information, the core mechanism of the system that implements the Scalable Classification Algorithm changes the number k of sentences (according to Table 1) that should match the threshold criterion of a category in order to be classified. Experimental evaluation involves two main steps. Firstly, we analyze the performance gathered during this procedure, we also specify different criterion thresholds and apply them to the core mechanism of the presented system. At last, experimental results of the real articles X  classification are presented. 
In order to evaluate our scalable classification technique we used the 20 newsgroup dataset [7], which is a widely used dataset in the evaluation process of many classifi-cation algorithms (both supervised and unsupervised). 
The 20 newsgroup dataset is a collection of articles of 20 newsgroups. Each cate-main text (as Subject section may contain many keywords of the corresponding cate-gory). In order to evaluate the similarity values between different category vectors we used the standard metric [12] that computes the cosine of the corresponding vectors aj and q using Formula 2. 
Below, we present evaluation of the similarity thresholds obtained for the  X  X entence vs. category X  using the 20 newsgroup dataset. All experiments were conducted using data collected using both the Rainbow tool [16] for statistical analysis and separation procedures of the datasets, as well as using the TMG [17] a recently developed MATLAB toolbox for the construction of term document matrices from text collec-tions. 
Comparing the twenty category vectors it turns up that different category vectors create a minimum angle of 19.43 degrees and a maximum angle of 53.80 degrees. It is also easily seen that semantically different categories create large enough angles (e.g. alt.atheism and comp.os.ms-windows.misc create and angle of 42.71 deggres) while gory X  threshold can be estimated to an angle 19.43 degrees with a corresponding simi-larity value of 0.94. 
Figure 6 presents the sentence vs. category vectors similarities for different catego-ries of the 20 newsgroup dataset. The basic results can be summarized as:  X  General categories (like alt.atheism or soc.religion.christian) have a dense uniform range [0.1  X  0.5]  X  Well structured categories seem to be indicated from a uniform sentence vs. cate-gory similarity chart further separation, non-well structured categories seem to reside on  X  X erm to sentence X  matrices that have a blocked structure. Figure 6 provides a visualization of the matrix elements of the  X  X erm to sentence X  matrix where large values are identified by intense color. Figures of categories that were identified as not well structured in the previous Section are shown to have a matrix with blocked structure (e.g. (c) or (d) matrices). Using the similarity threshold of 19.43 degrees that we computed using the 20 news-group dataset, we tuned the core mechanism of the system that uses the Scalable Clas-article much this criterion. Figure 7 shows how many business articles are also classi-fied to other categories for three values of k. As value of k increases, the amount of multi-labeled articles decreases. 
We also, tested the classification feedback that our Scalable Classification Algo-rithm provides. Figure 8, reports the maximum and the minimum angle between the different category vectors, as time passes and newly classified articles affect the cate-gory vectors. We run the system for a period of 15 days and we computed the angles that minimum angles vary close to 20 degrees, while maximum angles are close to 40 degrees. exploits user X  X  awareness of a topic in order to classify articles in a  X  X er-user X  manner. presented and analyzed. Unlike standard techniques for personalization, user only specifies his level of expertise on different categories. The core of the system relies on a new text analysis and classification method that decomposes text documents on their sentences in order to capture more topic concepts of every document. 
For future work, we will further explore the classification of real articles using our the amount of multi-labeled documents and try to identify the behavior and impact of major  X  X larm news X . The scalable classification algorithm is also of independent inter-est and we intend to study theoretically its performance. Ioannis Antonellis X  X  work was partially supported by a Zosima Foundation Scholar-ship under grant 1039944/ 891/ B0011 /21-04-2003 (joint decision of Ministry of Education and Ministry of Economics) 
