 set of old transactions. UWEP employs a dynamic look-on synthetic data show that UWEP outperforms the 
Apriori [2], on the updated database. However, this KDD-99 San Diego CA USA proaches of FUP2 [5] and Partition Update [7] algo-advantages of UWEP are that it scans the existing Section 3 presents the UWEP algorithm in detail. contains k items from I. The support of an itemset X in D, supporto(X), is the number of transactions in D that contain X. An itemset X is called a large itemset if supportD (X) exceeds a minimum support threshold, and a small itemset otherwise. An implication of the form X + Y, where X c I, Y c I, and X n Y = 8, is called an association rule. The problem of finding asso-1 Notation 1 Definition 
Step 1: Generate all combinations of items with fractional transaction support (i.e., T) above a certain threshold, called m&amp;sap. 
Step 2: Use the large itemsets to generate association rules. 
The second subproblem is straightforward. However, discovering large itemsets is a non-trivial issue, where the efficiency of an algorithm strongly depends on the size of the candidate set. Therefore, we will concentrate on the update of large itemsets. 2.2 Update of Large Itemsets 
Table 1 summarizes the notations used in the remain-Updating association rules was first introduced in [4]. Given DB, db, IDBI, Idbl, minsup and LDB, the prob-lem of updating large itemsets iS to find the Set of large itemsets in DB + db. 
The FUP algorithm proposed by Cheung et al. [4] works iteratively and its framework is similar to Apriori [2] and DHP [B]. FUP2 [5] is a generalization of the FUP algorithm that handles insertions to and deletions from an existing set of transactions. In [9, 111, the concept of negative border, that was introduced in [12], is used to compute the new set of large itemsets in the updated database. A recent study [7] is based on the Partition algorithm of [lo]. 3.1 Description of the Algorithm The algorithm UWEP is presented in Figure 1. Inputs to the algorithm are DB, db, LDB (along with their supports in DB), JDBI, Idbl, and minsup. The itemsets in DB + db. Algorithm UWEP has the following five steps: 1 CA, = all 1-itemsets in db with support &gt; 0 3 initial-pruning(PruneSet) % Figure 2 4k=l 5 while cj,, # 0 and L&amp;B # Q) do 6 Unchecked = L&amp;B 7 for all X c C$, do 8 if X is small in db and X is large in DB then 9 remove X from Unchecked 10 if X is small in DB + db then 11 remove all supersets of X from LDB 12 else 13 add X to LDB+db 14 else if X is large both in db and DB 15 remove X from Unchecked 16 add X to LDB+&amp; and L&amp;, 17 else if X is large in db but small in DB then 18 find sUppOrtoB(X) using tidlists 19 if X is large in DB + db then 20 add X to LnB+&amp; and Lib 21 for all X E Unchecked do 22 find suppo?t&amp;(X) using tidlists 23 if X is small in DB + db then 24 remove all Supersets of X from LDB 25 if X is large in DB + db then 26 add X to LDB+&amp; 27 k=k+l 28 Cjb = generate-candidate( Lfb  X ) Figure 1: Algorithm UWEP: Update of Large Itemsets for each item in db 2. Checking the large itemsets in DB whose items are absent in db and their supersets for largeness in DB+db 3. Checking the large itemsets in db for largeness in DB+db 4. Checking the large itemsets in DB that are not counted over db for largeness in DB + db 5. Generating the candidate set from the set of large itemsets obtained in the previous step. In the first step of the UWEP algorithm (line 1 in 
Figure l), we count the support of 1-itemsets and create for an itemset X is an ordered list of the transaction identifiers (TID) of the transactions in which the items are present. The support of an itemset X is the length of the corresponding tidlist. 
The second pa.rt of the algorithm (procedure ini-tial-pruning in Figure 2) deals with the 1-itemsets whose support is 0 in db but large in DB. In this case, for an itemset X, it is by definition true that suppOrtDfj+db(x) = suppoftDB(x). If X was previ-1 while PruneSet # 8 do 2 X = first element of PruneSet 3 if X is small in DB + db then 4 remove X and its supersets from LDB 5 remove X and its supersets from PruneSet 6 else 7 add supersets of X in LDB to PruneSet 8 add X to LDB+db and remove X from LDB 9 remove X from PruneSet ously small in DB, then it is also small in DB+db. On the other hand, if X is large in DB, we have to check whether supportDs(X) 2 minsup x ]DB + db] or not. 
In the following, we will introduce three lemmas that are useful in pruning the candidate itemsets. Their proofs can be found in [2, 4, 5, 111. Lemma 1 All supersets of a small itemset X in a database D are also small in D. Now suppose that X is small in the updated database. Then, by Lemma 1, any superset of X must also be small in the updated database. UWEP differs from the previous algorithms [4, 5] at this point, by pruning in DB as soon as it is established to be small. In the previous algorithms, a k-itemset is only checked in the kth iteration, but UWEP does not wait until the kth iteration in order to prune the supersets of an itemset in LDB that are small in LL)B+&amp;,. Definition 1 Let X be a k-itemset which contains items II, . , 4. An immediate superset of X is a (k + l)-itemset which contains the k items in X and an additional item Ik+1. Now, suppose that X is large in the updated database. Then, we add all immediate supersets of X in LDB to the PruneSet, which holds the itemsets that must be examined before checking the itemsets in Cjb. Then, for each element in the PruneSet, we check whether its support exceeds the minimum support threshold. So, all itemsets in LDB that contain a non-existing item in db are removed from LDB, and the ones that are large are added to LDB+db before advancing to the first iteration. This pre-pruning step is particularly useful when data skewness is present in the set of transactions. 
Lines 4-28 in Figure 1 are used 1) to check whether any candidate itemset in db qualifies to be large in the whole database and to adjust their supports in LDB+&amp; and 2) to check whether any of the large itemsets in DB which are small in db qualifies to be in the set of LDB+&amp;. The two for loops between lines 4-28 perform these two operations. Let us investigate the first case: checking the candidates in db in the kth iteration. Lemma 2 Let X be an itemset. If X 6 LDB, then Corollary 1 Let X be an itemset. If X is small both in DB and db, then X can not be large in DB + db. 
Let X be a candidate k-itemset in db. If X is small in db, then we have to check whether X is in LDB or not. If X @ LDB, X can not be a large itemset in DB+db by Corollary 1. Otherwise, we have to check the support of X in DB -+-db. Since we have the support of X in DB and db in hand, we can quickly determine whether minsupx ]DB + db], then X is small in DB + db. By Lemma 1, all supersets of X must also be small, thus they are eliminated from LDB. Otherwise, X is large and we add X to LDB+&amp;,. 
Now assume that a candidate k-itemset X is large in db. There are two possibilities: X is either large or small in DB. Lemma 3 Let X be an itemset. If X E LDB and x E Ldb, then X E LDB+db. Lemma 3. In this case, we put X into LDB+&amp; with the total support. If X is small in DB, we have to check whether it is large in DB + db or not. However, we do not know supportDB(X). We can obtain it by scanning DB. In this scan, for each 1-itemset in DB, we find its tidlists and supports of longer itemsets. After counting the support of X in DB, we place X into LDB+db if Sw X  X rtDB+db(X) 2 minsup x ]DB + dbl. 
An important issue here is to decide which candidates go to the set of large k-itemsets in db. FUP2 [5] algorithm places all itemsets that are large in the whole place those candidates that are large in db regardless of whether they are small or large.in DB. We choose another strategy and put only those candidates into Cib itemset X is large in db but small in DB+db, we do not place it into Lib. This is the most important advantage of UWEP since this significantly reduces the number of candidates in db. 
In UWEP, there is a possibility that alarge k-itemset in DB may not be generated in Cjb, since we include those candidates that are large both in db and DB f db. verified against db, namely Unchecked, which contains the large k-itemsets in DB that are not generated in db. The second for loop is used to verify them against db. execution of the algorithm UWEP and its performance Lemma 4 Given a set of old transactions (DB), a set of new transactions (db), and a set of itemsets LDB which are large over DB, the algorithm in Figure 1 discovers all the large itemsets over DB + db correctly. Lemma 5 The number of candidates generated and counted by the algorithm UWEP in Figure 1 is min-imum. IForder to measure the performance of UWEP, tion database of size 2 x IDBl, where the first (DB( itemset=]l]=4. We follow the notation Tx.Iy.Dm.dn used in [4] to denote databases in which lDBI = m thousands, ldbl = n thousands, ITI = z and 111 = y. gained by UWEP over rerunning Partition [lo]. We have chosen Partition since the same data structures UWEP performs better than re-running Partition, a tion times for UWEP and Partition algorithms for TlO.I4.DlOO.dn, where n varies from 10 to 100, with the incremental database, UWEP achieves a much bet-ter performance than Partition. Despite adding 100% transactions, UWEP still performs better than re-running Partition. One interesting feature of UWEP Figure 3: a) Speedup by UWEP over Partition algorithm b) Execution times of UWEP vs. Partition algorithms, Partition Update, FUP2, and UWEP. For UWEP generates between 32%-53% fewer number of candidates than those generated by FUP2 and Partition Update. The Partition Update algorithm counts more candidates than U WEP or FUP2 .counts, up to 69%. We presented an efficient algorithm, UWEP, for advantage of UWEP over the previously proposed large itemset in DB as soon as it is known to be small iteration. Moreover, UWEP generates the candidate db and in the updated database. As shown in Section 4, this methodology yields a much smaller candidate set especially when the set of new transactions does not contain some of the old large itemsets. 
We conducted experiments on synthetic data and found that UWEP achieves a better performance than re-running Partition [lOI over the whole set of transactions. Naturally, this is true for re-running other algorithms like Apriori [2] since the previous work is discarded and the entire database is scanned again. Moreover, experiments on the number of candidates generated and counted show that U W EP outperforms Partition Update and FUPZ algorithms. 
UWEP may also be used in other knowledge dis-covery techniques that compute large itemsets, such as variations of association rules [S]. We will investigate this avenue in a separate study. We also plan to incor-porate updates and deletions to UWEP. [31 PI 151 
