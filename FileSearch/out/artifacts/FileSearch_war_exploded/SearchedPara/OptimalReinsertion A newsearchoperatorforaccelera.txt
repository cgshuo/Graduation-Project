 Andr ew Moor e AW M @ CS . CMU . EDU Weng-K een Wong W KW @ CS . CMU . EDU Given a dataset of R records and m cate gorical attrib utes, how can we find a Bayesian netw ork structure that pro vides a good model of the data? Happily , the formulation of this question into a well-defined optimization problem is now fairly well understood (Heck erman et al., 1995; Cooper &amp; Hersk ovits, 1992). Ho we ver, finding the optimal solu-tion is an NP-complete problem (Chick ering, 1996a). The computational issues in performing heuristic search in this space are also severe, even taking into account the numer -ous ingenious and effecti ve inno vations in recent years (e.g. (Chick ering, 1996b; Friedman &amp; Goldszmidt, 1997; Xiang et al., 1997; Friedman et al., 1999; Elidan et al., 2002; Hul-ten &amp; Domingos, 2002)), discussed in Section 4. Pr oblem: From fully observed cate gorical data find an acyclic structur e and tab ular conditional probability tables (CPTs) that optimize a Bayesian Network scoring criterion. Assume no initial knowledg e of the node ordering . The operation we need to perform is where D is a directed acyclic graph (D AG) and Da gScor e is a comple xity-penalized measure of how well the DAG explains the data. Common versions of Da gScor e can be brok en into a sum of terms: one for each node in the DAG. where Parents i is the set of parents of attrib ute i in the DAG, and NodeScor e Parents i i scores the degree that these parents predict the conditional distrib ution of i given the parents (while penalizing for model comple xity). Examples of NodeScor e function that have been proposed are BIC (Schw artz, 1979), BD (Cooper &amp; Hersk ovits, 1992), BDE (Heck erman et al., 1995) and BDEU (Bun-tine, 1991). The algorithms of this paper can be applied irrespecti ve of the choice of NodeScor e function. 1.1. Perf orming the optimization The most common algorithm for optimizing Da gScor e D is a hill climbing algorithm which begins with an initial structure and then considers a finite set of tweaks to it. The tweaks usually include some or all of  X  X dd arc X ,  X  X elete arc X  and  X  X e verse arc X , subject to never attempting a mo ve that would introduce a cycle. Hill climbing proceeds by finding the best tweak and applying it. Then it finds the best tweak for the new DAG structure. This process continues until no more tweaks impro ve the structure. In practice it is well worth attempting to jump out of local minima. This is usually done by a combination of multiple restart hill climbing, simulated annealing and TAB U search. 1.2. Optimal Reinsertion Ov erview In this paper we introduce a new, much lar ger -scale, search operator called Optimal Reinsertion and (more impor -tantly) sho w how to compute it efficiently .
 Given a start structure D old (Figure 1), pick one node (called the Target , T ) and sever all connections in and out. Then find, subject to some constraints, the optimal set of in-arcs and out-arcs with which to reinsert it. This proce-dure continues, running through repeated cycles in which all nodes tak e turns at being the tar get, until no step changes the DAG structure. Each mo ve in this search space finds the best of (typically) billions of changes to the current DAG, and so we can hope for faster and less local-optimum-prone search. With the algorithms described in subsequent sec-tions each step finds the optimal reinsertion very quickly . 2.1. The maxP arams Parameter During each Optimal Reinsertion step we forbid certain structures. We do not allo w any of the conditional proba-bility tables to contain more than maxP arams non-zero en-tries. We mak e this restriction for its computational benefit: we can control the total number of CPTs we will ever need to look at. We can hope that the effects of this approxi-mation will be mitigated by the fact that lar ge CPTs will recei ve lar ge penalties in the scoring function and so would not be part of the optimal solution in any case. We will re-sort to empirical studies to see the actual consequences. In practice we typically set maxP arams between 10 and 100, and usually a tar get node has some where between thou-sands up to millions of possible parent sets. 2.2. Cached Node Scor es In the algorithm that follo ws, it will be necessary to quickly look up the NodeScor e PS T value for a wide variety of Parent-Sets PS and all possible tar get nodes T . Let us use the con vention that given a dataset with m attrib utes, the attrib utes (and hence the corresponding nodes in the DAG) are identified by inte gers 1 2 m respecti vely . A parent-set PS is thus a subset of the inte gers 1 through m . Similarly , a tar get node T is an inte ger between 1 and m . We create a cache of NodeScor e PS T values, so that once the cache is constructed any lookup may occur in time independent of R (the number of records) or m (the total number of attrib utes). We only cache NodeScor e PS T combinations that produce conditional probability tables with maxP arams or fewer parameters.
 Creating this cache looks expensi ve. With maxP arams 2 k and m binary-v alued attrib utes, there are m 1 k CPTs for each of the m tar get nodes, meaning m m 1 each needing O R work to construct nai vely .
 Constructing all these tables is a job suited for AD-search, introduced in (Moore &amp; Schneider , 2002) and an extension of AD-trees (Moore &amp; Lee, 1998). There is no space to revie w AD-search here, except to mention costs. Search-ing all contingenc y tables of dimension k would normally require R m k operations. In contrast, AD-search requires operations, where  X  is a dataset-specific quantity that is al-ways in the range 0 0 5 , and is smaller for datasets with lar ger degrees of inter -dependence between attrib utes. Em-pirically ,  X  is usually between 10 2 and 10 1 . 2.3. Sear ching for the Optimal Reinsertion Let D old DAG before the Optimal Reinsertion of T . Let D D old with all arcs into and out of T remo ved. Let D new D after Optimal Reinsertion (see Figure 1). We search over parent-sets of T . During search, if our current parent-set is PS , then the next sets to be in-spected will be defined as LegalSupplements PS where Supplements PS PS m with q max PS (e.g. if PS and LegalSupplements PS defined as those members of Supplements PS that produce a CPT with maxP arams or fewer parameters. Define q 0 if PS One final definition concerns the complete set of legal spe-cializations of PS . This set of legal specializations, called Specializations PS are those parent sets that are supple-ments, supplements of supplements, or supplements to the n th degree of PS . Formally , Specializations PS is the clo-sure of LegalSupplements PS : PS X  Specializations PS if and only if PS X  PS or PS X  Specializations PS X  for some PS X  LegalSupplements PS .
 Assume that 3 5 than maxP arams parameters. Note that 3 5 6 Specializations 3 5 but 3 4 5 Specializations 3 5 (because supplements of a PS involv e only nodes denoted by a higher inde x than is currently in PS ). A further exam-ple is given in part of Figure 2.
 Note that depth first tra versal through the space of all parent sets, beginning at search operator , will visit each legal parent set exactly once. The search algorithm could be of this form: In fact, Section 2.1 added the restriction Ev en with this restriction there are man y PS CS pairs to consider , sometimes trillions. Happily , we can mak e the search tractable with two steps. First, by analytically com-puting the optimal CS to associate with each PS . Second, by pruning the search tree over parent sets in cases where we can pro ve no specialization can be better . In Figure 2 we are considering parent-set 2 4 . Without introducing cycles in the presence of this parent set, the potential children of T are SafeNodes PS 3 6 7 8 . In general define that i SafeNodes PS if and only if (a) there is no directed path from i to T in D , and (b) adding T to the parents of i would not cause more than maxP arams parameters for node i .
 Each node in SafeNodes PS can independently consider whether there is benefit in adding a T i link. We can thus define the optimal Child Set to associate with Parent Set PS as i SafeNodes ps : NodeScor e P i T i NodeScor e P i i where P i are the original parents of i in DAG D . ORSear ch tak es four parameters: Define ORScor e PS to be the score obtained with PS as the parents of T and OptChildr en PS as T  X  X  children. The ORSear ch procedure outputs PS out defined as: Table 1 gives the implementation of ORSear ch . In Step 3, we compute ORScor e PS . In Step 4, we compute the best possible score of any of the legal specializations of PS . This requires us to obtain bestNodeScor e PS T , defined as: This information is computed once, with one pass over the cache immediately after the cache of NodeScor e s is created, so is a constant-time lookup during execution of ORSear ch .
 Step 5 is our opportunity to abort this portion of the recur -sive search. If the condition is satisfied we have pro ved that there is no point in looking at any specialization of PS . Note how the decision to bound the search is dependent on the structure of the rest of D : depending on the structure we may or may not abort because PS may or may not cause loops that lose us the benefit of some of our children. Step 7 is the recursi ve call. We look at the immediate legal supplements of the current parent-set, each time possibly impro ving PS . Notice that by passing PS (the best parent set so far) as the fourth argument we give as much oppor -tunity as possible for recursi ve calls to prune. At all points in the algorithm the NodeScor e value, NodeScor e values, ChildBenefit values, Da gScor e values and bestNodeScor e values can all be obtained in constant time from the cached NodeScor e tables, or by recalling val-ues computed earlier on in the search. The original dataset is neither needed nor accessed.
 We omit the elementary inducti ve proof of the correctness of the procedure. ORSear ch is initially called with pa-rameters: ORSear ch D T
ORSear ch D T PS in PS kno wn
T i NodeScor e P i i 3. Let 4. Let bestDa gScor e BaseScor e bestNodeScor e PS in T ChildBenefit 5. If bestDa gScor e ORScor e PS kno wn define PS out PS kno wn and return from this recursi ve call. 7. For each PS X  LegalSupplements PS : PS := ORSear ch D T PS X  PS available legal PS , which we then assign as the new parents of T . The new children of T are those legal, non-c ycle-inducing nodes with strictly positi ve benefit. 2.4. The outer loop We have defined a single Optimal Reinsertion operation, but the full search consists of repeated operations. One full pass of the outer loop consists of generating a random or-dering of 1 2 m then applying the operation to each node in this ordering in turn. We iterate this procedure, performing a full pass over and over again, with a newly randomized ordering on each pass. When a full pass causes no change to the current DAG, we terminate. 2.5. Multiple Restarts In case the abo ve procedure gets caught in a local mini-mum, we run it a lar ge number of times X 50 in the fol-lowing experiments. Each run begins with a randomly cor -rupted version of the best DAG to date. Empirically , the use of multiple restarts does not appear to be critical: after the first run we have never observ ed a significant impro vement from the remaining runs. 2.6. Final Stage of Hill climbing After the specified number of restarts of the Optimal Rein-sertion procedure we finally perform an iteration of con-ventional hill-climbing. This is in order to allo w the current DAG to tweak itself to introduce CPTs bigger than allo wed by the maxP arams parameter . Thus, for this final iteration, we no longer apply the restriction that all contingenc y ta-bles must have fewer than maxP arams . In some cases, if maxP arams was set to a low value, this final pass can sig-nificantly impro ve the score. 2.7. Sparse Candidate Optimal Reinsertion The sparse candidate algorithm was introduced in (Fried-man et al., 1999). It approximates standard hill climbing, but maintains a small set of candidate parents for each node instead of simply allo wing any parent for the node. Ini-tially , the candidate set for node i is chosen to be the k at-trib utes best correlated with i , but the set can be refined as the search progresses. This has the strong benefit of reduc-ing the number of NodeScor e computations needed during hill climbing. Indeed, the first pass of hill climbing requires only O mk such computations instead of O m 2 .
 We have incorporated a primiti ve version of Sparse Candi-date into the Optimal Reinsertion search. For datasets with lar ge numbers of attrib utes, we restrict the set of legal par -ents of T to be those k attrib utes most strongly correlated with T . In the experimental results section we use values of k ranging between 10 to 20, depending on the number of attrib utes in the dataset. Table 2 sho ws the datasets that were used. 3.1. Generation of synthetic datasets The synthetic datasets create local-minimum-prone search landscapes. The y were generated from the structures sho wn in Figure 3. All nodes were binary . Nodes with-out parents chose their value with 50-50 probability . For nodes with parents, P value = True parents 0 1 if Parity(parents)=0
P value = True parents 0 9 if Parity(parents)=1 where Parity(P arents)=1 if and only if an odd number of parents have value  X  X  rue X . The nodes are thus noisy exclusi ve-ors and so it is hard to learn a set of parents in-crementally .
 Synth2 Synth3 Synth4 3.2. Pr ocessing of the real datasets The empirical datasets were chosen from UCI Irvine datasets (Blak e &amp; Merz, 1998) that contained at least 10,000 records. Real valued attrib utes were automatically con verted to binary-v alued cate gorical attrib utes by thresh-olding them at their median value (treating real-v alued vari-ables in this way with Bayesian Nets is not generally a good idea but it does not favor either method in this evalu-ation). Several additional datasets of particular current in-terest within our research lab were also used.
 To our kno wledge, this is a relati vely lar ge study of a Bayesian Netw ork structure finding algorithm X  running on 11 datasets and analyzing both optimiza-tion performance and k -fold test set performance. The datasets we used, including our discretizations, are at http://www .cs.cmu.edu/ awm/optr einsert . 3.3. The Hill climbing implementation Follo wing the methodologies of (Elidan et al., 2002; Fried-man &amp; Goldszmidt, 1997; Friedman et al., 1999; Hulten &amp; Domingos, 2002), we benchmark ed Optimal Reinsertion against an optimized version of traditional hill climbing. We used the same libraries and underlying efficient data structures to implement hill climbing. We tuned the multi-restart strate gy to maximize performance and we are satis-fied that our hill climber is highly optimized. For example, an efficient hash table is used to ensure that hill climbing never redundantly recomputes a NodeScor e score from the dataset that it can obtain from the results of an earlier com-putation. 3.4. Optimizing the BDEU scor e: Experiments All experiments were performed on an unloaded 2 giga-hertz Pentium 4, with 2 gigabytes of RAM (although none of the experiments belo w used more than 1 gigabyte and most used less than 100 me gabytes). The time measured for Optimal Reinsertion includes the costs of all compo-nents of the algorithm including the AD-search and build-ing of the NodeScor e cache.
 Table 4 sho ws the performance of Optimal Reinsertion search against hill climbing. Table 3 sho ws the number of structures searched by Optimal Reinsertion for each dataset. In most (but not all) cases Optimal Reinsertion quickly finds a better solution than Hill-climbing ever finds. 3.5. Is ther e an acceleration? Table 4 compares the performance of Optimal Reinsertion when given only one thirtieth the wall-clock time of hill climbing. It confirms that Optimal Reinsertion usually per -forms at least as well as hill climbing when Optimal Rein-sertion is given only 100 seconds and hill climbing is given 3000 seconds. adult biosur v connect4 synth2 synth4 letters 3.6. Assessing Statistical Benefits The abo ve results give empirical support to the assertion that Optimal Reinsertion is faster and less local-minimum-prone at optimizing Da gScor e . But does that matter? In some applications it is the ability of the learned model to generalize to lik elihood estimation of future data dra wn from the same distrib ution that counts, and do the gains in Da gScor e translate to gains in performance on such future data? This question is not so much a test of our algorithm, but of whether the structure scoring metric (in these tests, BDEU) is doing its job adequately . Table 5 sho ws the re-sults of 20-fold cross-v alidation. On each fold the left-out data is unused until the DAG and the Bayes Net parame-ters have been constructed from the training set. Then the log-lik elihood of each held-out data point is recorded. This procedure is applied to both Optimal Reinsertion and Hill climbing, which are each allo wed 5 minutes of computa-tion. Table 5 sho ws that frequently , Optimal Reinsertion of BDEU has a significant generalization adv antage (ac-cording to a paired t-test) over hill climbing optimization of BDEU. 3.7. Wh y is Hill-climbing beaten? The synthetic cases pro vide the most obvious examples: given the XOR nodes there is no benefit in adding any one parent indi vidually without the others and so hill-climbing can mak e no meaningful progress. We hypothesize that similar effects occur in some of the real datasets. The prob-lems of single link remo vals and additions has been stud-ied carefully in (Xiang et al., 1997). This Optimal Rein-sertion implementation has an additional adv antage over hill-climbing: the use of ADSEARCH means that once the cached node scores are computed there are no subsequent operations that require time proportional to the number of records. 3.8. Effects of maxP arams and the Sparse Candidate k The graphs in Figure 4 illustrate that as maxP arams in-creases, so does both the time and quality of the solution. this is as expected. Additional results (not sho wn) illustrate a similar effect for the number of Sparse Candidates, k . As k gro ws we tak e longer and sometimes achie ve better final results. We now discuss how the algorithms of this paper in the conte xt of the most related recent work. We also discuss possible future developments to Optimal Reinsertion. The Sparse Candidate Algorithm (Friedman et al., 1999). In its original form Sparse Candidate was a method to ac-celerate Hill climbing at the risk of a slightly lower final score. Empirically , the acceleration was lar ge and the score sacrifice small. We belie ve that a combination of Sparse Candidate and Optimal Reinsertion will be superior to ei-ther alone. Our current use of a primiti ve Sparse Candidate approach (described in Section 2.7) could be generalized to a properly adapti ve approach which iterati vely updates its set of candidates.
 Data Perturbation (Elidan et al., 2002). This very in-teresting new algorithm reduces local minimum problems very impressi vely by learning an initial net and then learn-ing a second net with more weight given to records that were poorly modeled by the original. This process iterates. We belie ve this cle ver trick is orthogonal to Optimal Rein-sertion and we belie ve that promising practical future work would implement data perturbation with Optimal Reinser -tion as the inner loop search over the weighted data. Massi ve Datasets. For truly massi ve datasets, man y re-searchers have observ ed that working with a smaller sam-ple may produce almost equal results compared with work-ing with the full data. Several algorithms have been in-troduced that do this adapti vely , with the algorithm dy-namically determining from the data what sample size will be suf ficient to very probably find a good answer , e.g. (Kaelbling, 1990; Maron &amp; Moore, 1993; Hulten &amp; Domingos, 2002; Pelle g &amp; Moore, 2002). The most rele-vant recent example is (Hulten &amp; Domingos, 2002) which learns Bayesian netw ork structure from impressi vely mas-sive datasets using adapti ve sampling. For massi ve data the sampling algorithm uses only a tin y fraction of the full dataset with only moderate performance degradation in comparison to hill climbing. In methods such as this which work on small in-memory samples, it is possible that the increased speed and accurac y of Optimal Reinsertion meth-ods may help their speed and accurac y even further . Multi-link lookahead. (Xiang et al., 1997) sho w that a class of probabilistic domain models cannot be learned by algorithms that modify the netw ork structure by a single link at a time. The y propose a multi-link lookahead search for finding decomposable Mark ov Netw orks. This algo-rithm iterates over a number of levels where at level i , the current netw ork is continually modified by the best set of i links until the entrop y decrement fails to be significant. We plan to evaluate Optimal Reinsertion against an equi valent multi-link lookahead algorithm for Bayesian Netw orks. Sear ching Equi valence Classes. There are other ap-proaches to DAG learning. One which also searches the equi valent of very man y DAGs on each step is (Chick er-ing, 1996b). This searches an underlying space of a sub-class of partial DAGs. Ev aluations in this space can also be accelerated by a cache of scores obtainable from a fast enu-meration of contingenc y tables, such as AD-search, but it will require further work to disco ver whether the equi valent of an Optimal Reinsertion operation exists.
 Structural EM. A very important problem is to learn Bayesian netw ork structure in datasets where some at-trib utes of some records are missing. (Friedman, 1997) and subsequent publications have pioneered an EM approach to this problem. The EM approach requires repeated Bayesian Netw ork structure optimizations and we plan to apply Op-timal Reinsertion to this application, as one which will ben-efit greatly from the ability to do extremely fast search. We have described and empirically examined a new search operator for learning Bayesian Netw ork structure from fully observ able data. The results are promising in com-parison with hill-climbing and there is reason to belie ve that Optimal Reinsertion could be combined with the work of several other authors to eventually produce even faster search.
 Supported by DARP A award F30602-01-2-0569 and NSF Grant 0121671. Thanks to Jef f Schneider and anon ymous revie wers for helpful comments and suggestions. Beinlich, I. A., Suermondt, H. J., Cha vez, R. M., &amp; Cooper ,
G. F. (1989). The alarm monitoring system: A case study with two probabilistic inference techniques for be-lief netw orks. Proc. Second Eur opean Confer ence on AI and Medicine (pp. 247 X 256). Berlin: Springer -Verlag. Blak e, C., &amp; Merz, C. (1998). UCI Repository of machine learning databases. http://www .ics.uci.edu/ mlearn/ MLRepository .html.
 Buntine, W. (1991). Theory Refinement on Bayesian Net-works. Proceedings of the Seventh Confer ence on UAI (pp. 52 X 60).
 Chick ering, D. M. (1996a). Learning Bayesian netw orks is
NP-Complete. In D. Fisher and H. Lenz (Eds.), Learning from data: Artificial intellig ence and statistics v , 121 X  130. Springer -Verlag.
 Chick ering, D. M. (1996b). Learning equi valence classes of Bayesian netw ork structures. Proceedings of the Twelfth Confer ence on UAI, Portland, OR (pp. 150 X 157). Mor gan Kaufmann.
 Cooper , G., &amp; Hersk ovits, E. (1992). A Bayesian method for the induction of probabilistic netw orks from data. Mac hine Learning , 9 , 309 X 347.
 Elidan, G., Ninio, M., Friedman, N., &amp; Schuurmans, D. (2002). Data perturbation for escaping local maxima in learning. Proceedings of AAAI-02 (pp. 132 X 139).
 Friedman, N. (1997). Learning belief netw orks in the pres-ence of missing values and hidden variables. Proc. 14th ICML (pp. 125 X 133). Mor gan Kaufmann.
 Friedman, N., &amp; Goldszmidt, M. (1997). Sequential up-date of Bayesian netw ork structure. Proceedings of the Thirteenth Confer ence on UAI (pp. 165 X 174).
 Friedman, N., Nachman, I., &amp; Pe  X  er, D. (1999). Learning
Bayesian netw ork structure from massi ve datasets: The  X  X parse candidate X  algorithm. Proceedings of the Fif-teenth Confer ence on UAI (pp. 206 X 215).
 Heck erman, D., Geiger , D., &amp; Chick ering, D. M. (1995).
Learning Bayesian netw orks: The combination of kno wledge and statistical data. Mac hine Learning , 20 , 197 X 243.
 Hulten, G., &amp; Domingos, P. (2002). Mining comple x models from arbitrarily lar ge databases in constant time. Proc. 8th ACM SIGKDD International Confer ence on Knowledg e Disco very and Data Mining .
 Kaelbling, L. P. (1990). Learning in Embedded Systems. PhD. Thesis; Technical Report No. TR-90-04). Stanford Uni versity , Department of Computer Science.
 Maron, O., &amp; Moore, A. (1993). Hoef fding Races: Ac-celerating Model Selection Search for Classification and Function Approximation. Advances in NIPS 6 . Mor gan Kaufmann.
 Moore, A. W., &amp; Lee, M. S. (1998). Cached Suf ficient Statistics for Efficient Machine Learning with Lar ge Datasets. JAIR , 8 , 67 X 91.
 Moore, A. W., &amp; Schneider , J. (2002). Real-v alued All-
Dimensions search: Lo w-o verhead rapid searching over subsets of attrib utes. Confer ence on UAI (pp. 360 X 369). Nichol, R. C., Collins, C. A., &amp; Lumsden, S. L. (2000). The Edinb urgh/Durham Southern Galaxy Catalogue -
IX. The Galaxy Catalogue. http://xxx.lanl.go v/abs/astro-ph/0008184.
 Pelle g, D., &amp; Moore, A. W. (2002). Using Tarjan X  s Red Rule for Fast Dependenc y Tree Construction. NIPS 15 . Mor gan Kaufmann.
 Schw artz, G. (1979). Estimating the dimensions of a model. Annals of Statistics , 6 , 461 X 464.
 Xiang, Y., Wong, S., &amp; Cercone, N. (1997). A microscopic study of minimum entrop y search in learning decompos-
