 Understanding how research themes evolve over time in a research community is useful in many ways (e.g., revealing important mile-stones and discovering emerging major research trends). In this paper, we propose a novel way of anal yzing literatu re citation to explore the research topics and the theme evolution by modeling article citation relations with a probabilistic generative model. The key idea is to represent a research paper by a  X  X ag of citations X  and model such a  X  X itation document X  with a probabilistic topic model. We explore the extension of a particular topic model, i.e., Latent Dirichlet Allocation (LDA), for citation analysis, and show that such a Citation-LDA can facilitate discovering of individual re-search topics as well as the theme evolution from multiple related topics, both of which in turn lead to the construction of evolution graphs for characterizing research themes. We test the proposed citation-LDA on two datasets: the ACL Anthology Network (AAN) of natural language research literatures and PubMed Central (PMC) archive of biomedical and life sciences literatures, and demonstrate that Citation-LDA can effectively discover the evolution of research themes, with better formed topics than (conventional) Content-LDA. H.4 [ Information Systems Applications ]: Miscellaneous Experimentation theme evolution, citation analysis
How to leverage information technologies to improve the pro-ductivity of scientific research is a highly important challenge with clearly huge impact on the society. One bottleneck in research pro-ductivity is that as a research community grows, it would be in-creasingly difficult for researchers to see the complete picture of how a field has been evolving, given the fact that large volume new literatures are written based on previous works. Junior researchers can often get lost in the overwhelming amount of related papers. Researchers who seek to shift to a new topic may spend lots of time preparing a reading list on his/her own. All these clearly hinder the progress of scientific research, and it would be highly beneficial to develop mining techniques to help researchers more easily and more efficiently understand research themes in scien tific literature. In general, two aspects of analysis are needed for understanding research themes: First, we need to analyze each research topic to answer the following questions: Which papers are the milestone papers that best represent a topic and how to quantify their impact? When did the topic beco me popular and is it still a ttracting a ttention today? Can the topic be summarized accurately with a few key-words? Furthermore, when investigating topics collectively ,which are the most dominant topics extensively studied? During the evo-lution, what are the newly generated topics initiated by the old one? Can we identify the underlying evolution patterns among topics?
To answer the questions raised above, ideally, we would like to automatically construct a  X  X esearch theme evolution graph X  ,which we illustrate in Figure. 1. With such a graph, when zooming into the scope of individual topics, multiple types of information are provided to facilitate users to understand the research topic:  X 
Topic Milestone Papers :Itiscriticaltorecognizethepapersthat are best representative for a topic in the course of understanding topics. We refer to them as  X  X opic milestone papers X . Milestone papers of a topic provide a good picture how a topic is formed. In
Figure. 1, milestone papers are shown in each topic as rectangles and the  X  X ize X  reflects their importance with respect to topics.  X 
Topic Temporal Strength :Therelativepopularityoftopicsatdif-ferent times reveals the temporal nature of topics, which can help users to identify current vs. previous research topics as well as the rough topic life spans. Intuitively, when many milestone pa-pers occur, the topic draws more attention and becomes popular.  X 
Topic Keywords :Extractingkeywordsthatcanproperlysumma-rize a topic would enable users to obtain a brief idea about the topic even without reading its relevant papers, allowing users to fast navigate among topics in search of the most interesting ones.
While zooming out to see the big picture of all related topics in the theme, there is also meaningful information to explore:  X 
Topic Importance :Quantifyingtheimportanceoftopicshelps ausertodiscriminatethe major vs. minor topics in a research theme. Topic importance also reflects how well the topic is rec-ognized by the community.  X 
Topic Dependency :Manynewtopicsarebuiltontopoftheold ones. Discovering the dependency relation between topics pro-vides a good guidance for users when searching for origin/con-tinuing topics. In Figure. 1, we visualize the dependency strength between topics by the  X  X hickness X  of edges.  X 
Evolution Patterns :Connectingtopicsbytheirdependencyil-lustrates the underlying evolution patterns for research themes.
Is there any trend that different topics get merged together to form a new (interdisciplinary) topic, such as Topic 3 and Topic 4 are merged into Topic 5? Or is there a general topic branched into multiple topics that address specialized problems, such as Topic 1 has led to Topic 2 and Topic 3? To automatically construct such an evolution graph as shown in Figure. 1, the two major computational tasks are:  X 
Discovering the research topics ,whichincludesfindingmile-stone papers, computing the temporal strength, and extracting keywords for each individual topic.  X 
Discovering the theme evolution ,whichincludesidentifyingthe topic importance and learning the dependency relation between topics, as well as recognizing the underlying evolution patterns.
Existing approaches, notably those of topic modeling, can gen-erate some (not all) of these components in the evolution graph, but they are far from adequate for the following reasons: First, though there are many works that aim to construct evolution map over time, they rely on pre-segmentation of text streams into fixed time win-dows, due to either computational issue [2, 16, 24] or modeling issue [23]. Consequently, the topic evolution result would be in-evitably sensitive to the choice of temporal granularity of how time is discretized and sliced. Suboptimal granularity of time might re-sult in missing important topics or even lead to inaccurate evolu-tion analysis. Second, the edges in most of the existing evolution graphs, do not reflect the dependency relation between topics, and can only reveal the topic similarity and correlation [2, 3, 16, 23]. The fundamental limitation is that content-based topic modeling approaches are built on word co-occurrence ,whichessentiallyis undirected unlike the dependency relation. Third, it is difficult for any aforementioned models (including Pairwise Link-LDA [17]) to assess the impact of documents with respect to different topics, i.e., identifying the milestone papers. Their approaches model topics as distributions over words, and although the text similarity between document and topic can be computed, it would be a substantially different measurement from the document impact on a topic.
As hinted above, a major reason why existing topic models are insufficient is that they have not fully exploited citation relations to discover topics. In this paper, we address these limitations by do-ing joint analysis of citations and text. Indeed, we will rely more on citation links than on document content, which makes our work dif-ferent from [17] and all others. Specifically, we leverage a similar idea to topic modeling and analyze the citation graphs in a prob-abilistic manner. We directly model the generation of citations, which are direct evidence related to  X  X mpact X  of document as well as  X  X ependency X  between topics. Through citation generation, we are enabled to address the core problem of assessing milestone pa-pers based on impact, and estimating the topic dependency. More importantly, our key insight here is that  X  X o-cited papers X  are good indicators of research topics, more effective than relying on text similarity as in most existing work. Empirical study [6] has already noticed that it is a subjective yet difficult task to annotate for each word its belonging topic even manually. However, for citations in a published paper written by experienced authors, it would be much easier to determine the topic since most authors make citations pru-dently and thus citation is much less noisy than text.

To discover topics based on citations, we propose a novel proba-bilistic approach to analyze citations by viewing citation graphs as asetof X  X itationdocuments X  X hereeachisaresearchpaperrepre-sented as a  X  X ag of citations X  .Apaperthatcites k other (possibly duplicated) papers would simply be viewed as a  X  X ocument X  with k  X  X okens X  ,eachcorrespondingtotheIDofacitedpaper. With this view, we can model all these citation documents with a gen-erative topic model where we introduce latent topic variables over the citations. This is analogous to the application o faprobabilistic topic model to model topics in text documents, but with the im-portant difference that the discovered topics with our model would be characterized by a (multinomial) distribution over research pa-pers ,ratherthanoverwordsasinconventionalcontent-basedtopic models. In addition, when combined together with additional infor-mation, particularly the published time and the title of each paper, our model can address the computational tasks of discovering both the research topics and the theme evolution ,andconstructing the evolution graph as well.

In the rest of the paper, we first review some of the related work in Section. 2, which is followed by presenting our probabilistic model for literature citations in Section. 3. After the derivation about one specific model Citation-LDA, we focus our discussion on how to construct the theme evolution graph in Section. 4. Ex-periment setup and extensive evaluation results will be given in Section. 5. Finally, we conclude our work with future direction in Section. 6.
In recent years, many literature search engines as well as dig-ital libraries have come into use, including Microsoft Academic They provide knowledge about scientific literatures through rank-ing and search interface, which in turn, relies on algorithms that utilize citation-related indicators such as H-index [13] and Impact Factor [9].

In the research community, one thread of study treats scientific literature as citation graphs. To assess the importance of papers, graph ranking algorithms such as PageRank and its variants have been applied [10, 20, 21, 22]. In [10], the authors further take time into consideration in order to overcome the recency bias that fa-vors  X  X ld X  papers. Apart from this, graph clustering is investigated to identify meaningful topics, such as [5, 8, 18, 19]. In [18], it is pointed out that efficient graph clustering can be combined with temporal information to identify the trends of topics in literature. Particularly, one recent paper [15] is close to our work. It leverages both citation and text (title and abstract) to generate the evolution map in computer science community. Specifically, their method relies on the temporal order of papers and the document language model to detect the formation of new topics, and then it computes the strength between two topics with the  X  X ross citation count X  (to-tal citation numbers between the two topics), which however ig-nores the directed relation of topic dependency. Their method is difficult to be applied to address our problem because their method does not distinguish the difference in topic importance, nor does it recognize milestone papers through assessing the impact based on citations.
While on the other hand, existing probabilistic topic modeling over text [4, 11, 14] has been throughly studied, treating documents as mixtures of latent topics. Early attempt in modeling the topic evolution [16] investigates the Probabilistic Latent Semantic In-dex (PLSI) [14] to extract topics and models the evolution process as transitions between topics in Hidden Markov Model (HMM). Later, Topic Over Time (TOT) model [24] is developed based on Latent Dirichlet Allocation (LDA) [4]. The key difference between between LDA and TOT is that TOT explicitly assumes time as gen-erated from topics, which jointly models time and word, thus en-abling itself to discover time-aware topics as well as topic tempo-ral strength. Besides, Dynamic Topic Models [2, 23] address the problem of topic evolution by modeling topics (distributions over words) changing over time. In the discrete case [2], topics at the next time-stamp deviate from the current ones by a Gaussian noise; while, in the continuous case [23], the change of topics over time is generalized as Brownian motion. One limitation of these mod-els [2, 16, 23, 24] is that they all rely on the pre-segmentation of time: without appropriate time granularity selected, they could fall into difficulty in finding important topics. Ideally, the selection of correct time span should be made automatically. In addition to these studies, others consider the problem of modeling topic cor-relation [3] and document hyperlink generation [7], for which the essential difficulty is that they cannot model the  X  X ependency X  re-lation between topics. The only exception we are aware of so far is the paper [17] which jointly models text and citation generatively. One of its proposed model, named  X  X airwise Link-LDA X , explic-itly includes the topic dependency as model parameters by extend-ing the idea of mixed-membership block stochastic models [1]. In words, the chance of generating a particular citation is determined by the topics of citing and cited documents, which indeed addresses the topic dependency directly. Nevertheless, the Pairwise Link-LDA is not able to fulfill all the tasks we listed such as recognizing the milestone papers and so on.

To our best knowledge, there is no existing approach that can address all the questions as we raised before, i.e., the discovery of research topics and theme evolution .Tothisend,wedirectly model the generation of the citation links among literatures in this paper. In the same spirit of topic modeling, citations are generated stochastically according to a distribution with respect to the under-lying topic. It is worth noting that applying the topic modeling approaches to study graphs was previously investigated for discov-ertheless, our model not only discovers the topics, but also explores their dependency relationships and yields meaningful knowledge about the evolution of topics.
In contrast to most existing work on citation analysis, where ci-tations are often modeled as network or graph, we propose to rep-resent citation graph as a set of  X  X itation documents X  where each is aresearchpaperrepresentedas X  X agofcitations X ,andmodelthese citation documents with a probabilistic generative model. Such anewapproachhasseveraladvantagesoverpuregraphanalysis methods. First, by using a latent topic variable, we can naturally associate topics with papers and citations, enabling ranking the pa-per based on citation within each topic, through which milestone papers can be identified. Second, by modeling the whole set of pa-pers in a field, we can obtain a set of topics that summarize well the major research topics in the field, with (probabilistic) weights quantifying their importance. Third, by estimating the topic level citation structure, it is possible to compute the strength of depen-dency relation between topics and picturing the evolution paths of research themes. Last, distribution over papers for each topic ob-tained by such a model can be easily used to compute a distribution over time or keywords when used together with other information such as paper published time and title, allowing modeling the topic temporal strength and summarizing topics with keywords.
Compared with pure content-based topic models, our use of topic model is entirely on capturing topics through citation structures, roughly corresponding to discovering topics based on co-citation relation ,whichisintuitivelymoreaccurateinfindingresearchtop-ics: if there is a  X  X table X  set of  X  X ore papers X  that are often cited together, then it generally indicates the existence of a major re-search topic and the core papers are actually milestone papers in that topic. Specifically, we use a probabilistic model to explain how an author generates the references (citations) for a paper (which we may also refer to as a document for convenience sometimes). More specifically, given a paper, he/she would  X  X enerate X  all the refer-ences cited in the paper independently. When generating each cita-tion, the author would first sample a topic according to a document-specific topic distribution ( doc _ topic distribution), and then draw areferencedocumenttocitefromthecitationdistributionofthe sampled topic ( topic _ doc distribution). One may easily notice that such a generation process is essentially similar to the one over words for documents assumed in probabilistic topic models for text data. Indeed, our work is a novel way of using topic models for citation analysis, and just as topic models are very effective for discovering and analyzing topics in text documents ,ourmodelcan also be very useful for discovering and analyzing topics in scientific literatures where the citation graph is available. Another advan-tage over content-based topic models we may anticipate is that the computational complexity is greatly reduced because the number of citations is much less than the number of words in the corpora.
Formally, suppose each document d cites a subset of other docu-ments { c t } ( t =1 , 2 ,... ) ,where c t is a cited reference. We assume the following generation process for a citation that links to docu-ment c t in document d (i.e., document d cites document c  X  draw topic sample: z t  X  D doc _ topic ( z ; d )  X  draw citation sample: c t  X  D topic _ doc ( c ; z t )
The doc-topic distribution D doc _ topic (  X  ; d ) and topic-doc distri-bution D topic _ doc (  X  ; z ) are parameterized by the citing document d and the topic z respectively, and are the two key components in the model that would enable many interesting ways to analyze top-ics and evolution relations among topics. Indeed, D doc _ topic gives us a probability distribution over (latent) topics conditioned on document d ,andcanbeinterpretedasthe topic coverage in doc-ument d when generating citations, whereas D topic _ doc (  X  ; z ) a  X  X everse X  conditional distribution of documents given a topic, and can be interpreted as how a topic is characterized by a set of papers (documents) that are cited. Thus if a document c i higher probability than c j according to D topic _ doc (  X  ; z ) suggests that c i better characterizes topic z than c j ,or topic z better as being a more important paper with higher impact upon z than c j .Withsuchadistributionoverpapers,wecaneas-ily compute the expected time for a topic based on the time when the paper was published as well as the topic keywords based on the paper titles (or abstracts if available). Note that a substantial advan-tage of such a probabilistic model is that it can  X  X ecode X  why doc-ument d cites document c t by inferring the latent topic associated with this citation relation and quantifying with uncertainty, which enables  X  X isambiguation X  of citation relations to some extent. As will be further discussed, we can use such a model to perform the computational analysis for discovering research topics and theme evolution, which finally lead to the construction of evolution graph as proposed in Figure. 1.
Though we may have different ways to refine the general prob-abilistic model defined above, in this paper as a first step, we fo-cus on exploring the use of the basic Latent Dirichlet Allocation (LDA) [4] model, which we call  X  X itation-LDA X  and show that even with this simple model setting, we can already discover a lot of interesting knowledge that is useful for understanding research theme evolution.
 Specifically, Citation-LDA assumes that D doc _ topic and are multinomial distributions with parameters drawn from conju-gated Dirichlet prior  X  and  X  respectively 6 .Wefollowtheconven-respectively, and we have:  X  d  X  Dir(  X  ) and  X  z  X  Dir(  X  ) citation generation process for document d i  X  is:  X  sample a topic z = k  X   X  Multi(  X  i  X  )  X  sample a document to cite c = d j  X   X  Multi(  X  z )
We use the collapsed Gibbs sampling [11] to make inferences with the model. The sampling i sinitializedbyassigningrandom topic labels { z } and updates each of them iteratively. In particular, for the t -th citation that links to d j  X  in document d i  X  assignment is updated acco rding to the probability 7 :
The sampling converges to the true posterior distribution after
In addition, the empirical posterior distribution over topics can be computed as:
The results obtained from Equation. 2 -4 form the basis for ex-ploring the knowledge that leads to the construction of the evolution graph, which includes the discovery of not only individual research topics but also theme evolution. We investigate them in details in following discussion.
Zooming into individual topics identified by Citation-LDA, we are interested in finding milestone papers ,generating keywords , and computing the temporal strength for each topic.
The topic-doc distribution {  X   X  k,j } ,ascomputedinEquation.3 indicates how well a single paper d j represents the topic ranking of papers based on {  X   X  k,j } in essence provides the topic-aware impact assessment for papers with the milestone papers for topic z k ranked at the top.

There are advantages over naive ranking of papers based on the citation counts, which can be inaccurate since there are cases that in one area people tend to include more references than people from another area. Even sophisticated citation-based measurement, e.g., [10, 20, 21, 22], without taking into account of topics, can lead to bad judgement: a well recognized theoretic paper about graphic model in  X  X ayes learning X  might receive less credit in  X  X ata engi-neering X  and  X  X ery large database X  due to the computational diffi-culty that limits its application.
For topic z k ,thereisatimepointwhenitbeganattractingat-tention, a time point when it enjoyed its glory days with most im-portant milestone papers emerged, and possibly a time point when interest decreased and the topic faded out. If it is a long lasting topic, it might span over decades while if not, the active period can be as short as only a few years.

Topic temporal distribution sufficiently maintains the informa-tion. Viewing topic z k as a distribution over papers, the proportion of accumulated proba bility for published p apers until time the cumulative distribution function (CDF):
For the discrete time case, which is also our case, the probability mass function (PMF) for temporal distribution of z k is: In addition, the expectation can be computed as:
The standard deviation can also be easily computed, which, to-gether with topic expected time ,conciselyshowthemajoroccur-ring time and provide a rough estimation about the life span for a topic.
In general it would be desirable to summarize the topic with only afewwords[6].WithCitation-LDA,weaccomplishthisbylever-aging words in title (or abstract if available) as tags for each paper and summarize the topic by those words with high expected occur-rences .Specifically,tocomputethewordoccurrenceexpectation over {  X   X  k,j } for word w in topic z k :
As shown later in experiments, the topic keywords generated from titles are surprisingly indicative yet discriminative for especially seemingly similar topics.
In order to help a researcher see the big picture of all research topics, we can also easily use Citation-LDA to discover the theme evolution, which would involve the exploration of assessing the topic importance as well as the topic dependency relation ,andrec-ognizing the underlying evolution patterns .
By Equation. 4, the distribution of {  X  Pr( z = k ) } represents the chance of documents from one topic getting cited. Consequently, it can be associated as the topic importance in the research com-munity since topics with higher importance are those who receive more citations and vice versa. The top important topics reflect the major research progress and reveal the dominant research interest in one area.
In Citation-LDA, topics are represented as multinomial distri-butions over papers {  X   X  k,j } while the doc-topic distribution implies the topic mixture of document d i .Moreprecisely,  X  is the probability of topic k (2) occurring in document d (outlink) citation. Consequently, when marginalizing over papers d discounted by {  X   X 
An intuitive explanation of Equation. 9 is: whenever randomly drawing a document d j from topic k (1) ,andthenemittingacitation from that document, Pr( k (1)  X  k (2) | k (1) ) is the chance of that citation being associated with latent topic k (2) .

More importantly, Equation. 9 explains the topic level citation structure ,aswellasquantifiesthe topic dependency between any two topics precisely  X  the amount of influence of topic k another. the topic dependency. Nevertheless, it is indeed a K  X  K matrix with most entries being sparse. In our work, we propose two prun-ing criteria:  X 
Threshold cutting-off :Bysettingathreshold  X  10 empirically, all citation dependencies between topics with strength less than would be removed.  X 
Temporal regularization :Aspreviouslyinvestigatedin[15,16], the citation dependencies of the  X  X ld X  topics upon the  X  X ew X  top-ics can be roughly regarded as noise and safely discarded. After applying pruning to the topic level citation structure ,signif-icant yet meaningful influences between topics are kept. Closely dependent topics form the themes, in which different evolution pat-terns can be found: some topics may get merged into a new topic which is highly dependent on them ( merging ). Alternatively, one topic might have multiple subsequent topics that are developed on top of it ( branching ). In other cases, topics stop evolution and grad-ually fade out .Wewilldiscussevolutionpatternswithconcrete examples in the following experiment section.
In this section, we first formally describe the two datasets AAN and PMC on which we demonstrate our Citation-LDA. Further, ex-tensive evaluation results of discovery of research topics and theme evolutions are discussed. Last, we show that our Citation-LDA over-performs conventional Content-LDA baseline with two evalu-ation metrics: forward-citation and journal conditioned entropy .
Due to space limit, here we only show some representative re-sults in our paper. The complete results as well as the source code for Citation-LDA can be found at:
In our experiments, two public scientific literature datasets are investigated: AAN from natural language processing domain and PMC from biomedical and life sciences.
The ACL Anthology Network (AAN) [20] is a public dataset which includes all papers published by Association for Computa-tional Linguistics (ACL) and related organizations over the period from 1965 till now. Major conference and journal papers in the area of natural language processing (NLP) can be found in the dataset. In our experiments, there are are in total 18 , 041 papers (including citing and cited papers) from 13 venues with 82 , 944 citations. and life sciences journal literature. Compared with AAN, it is a much larger yet sparser dataset, with a coverage of much wider ar-eas than NLP. In our experiments, we includes the papers published after year 1960 and there are 145 , 317 article papers with citations from 1 , 726 journals.

Unlike AAN, the large number of journals in PMC provide a  X  X oarse topical annotation X  for papers, as in life sciences journals are commonly specialized in only a few research topics. For exam-ple, the journal  X  X ucleic Acids Research X  covers research on nu-cleic acids such as DNA and RNA, but the journal  X  X nvironmental Health Perspectives X  mainly publishes research on environmental health such as toxicology, exposure science and public health, etc. Later, we would utilize the journal information to evaluate the mod-eling performance of Citation-LDA and Content-LDA.
Before the discussion of the results, however, a nontrivial ques-tion is how to determine the number of topics to be modeled? In fol-lowing experiments, we perform the Citation-LDA with 100 topics in AAN and 500 topics in PMC, leaving the discussion of selecting the topic number in Section. 5.4.
Milestone papers for two topics:  X  X entiment analysis X  from AAN and  X  X ir pollution X  from PMC, both of which are of great impor-tance, are presented in Table. 1 -2 respectively (10 milestone pa-pers for each topic). Together, the topic-doc probability the venue/journal sources are included. Clearly, the milestone pa-pers listed are truly representative and recognized by the commu-nity based on the impact with respect to the topic.

One might notice that the top milestone papers in Table. 2, un-like those of topic  X  X entiment analysis X  from AAN, are actually all from one journal  X  X nvironmental Health Perspectives X , which is generally regarded as among the most top tier journals in the area of  X  X nvironment health X  with especially established reputation in the topic  X  X ir pollution X . In fact, the top milestone papers for topics in PMC being from the same (or only a few) journal(s) are actually quite common. Given that the journals in PMC are closely related to a variety of specialized topics, it can be taken as  X  X oisy X  topic labels of fair quality for evaluation purpose.
Figure 2: Topic Temporal Strength for  X  X SD X  and  X  X P X 
To demonstrate that our model discovers the topic over time cor-rectly, we show the topic temporal strength of two topics, namely  X  X ord sense disambiguation X  (WSD) and  X  X ependency parsing X  (DP) from AAN in Figure. 2, and the computational details can be found in Equation. 5-7.

In fact, the topic  X  X SD X  was once a popular topic around early 90s while  X  X P X  was newly popularized around year 2005. Based on our model,  X  X SD X  has the expected time 1991 . 37 ,withastandard deviation 3 . 58 .For X  X P X ,theexpectationis 2005 . 16 and standard deviation is 3 . 84 .Theseestimationsareallconsistentwiththeex-pert knowledge. will be explained in details later, the topics are the dominant 10 topics in AAN and PMC datasets. The extracted keywords are mainly about the problem, task, model and methodology of the top-ics. For Topic 73 in AAN, it shows that the topic investigates the problem of  X  X art-of-speech tagging X , models the problem as  X  X e-quential labeling X , and approaches it with  X  X iscriminative parsing X  methods. For Topic 61 in PMC, the nature of the topic can be recovered as research on the risks of  X  X hildren exposure X  against  X  X gricultural spraying X  such as  X  X esticides X  and  X  X rganophospho-rus X . In general, it is easy to conclude the research problems or de-tailed methodology for each topic through the extracted keywords along. Besides, based on the spotted keywords, Topic 92, Topic 96, Topic 80, and Topic 50 in AAN are all about the research theme  X  X tatistical machine translation X . But keywords reveal that topics differ from each other as concerning about distinct methods/mod-els (phrase-based models (92) v.s. discriminative learning problems (reordering, alignment (80) v.s. evaluation (50) evidently substantiates that the keywords are adequately discrimi-native even for quite related topics, serving as accurate yet succinct summary for topics. As earlier implied, Table. 3-4 show the dominant 10 topics for AAN and PMC, which are selected based on the topic weight k ) } as computed in Equation. 4. Identified dominant topics cover major research progress and interest in NLP and life sciences. In AAN, it is obvious that the research theme  X  X tatistical machine translation X  plays the most important role in the community, thriv-ing and diverse with multiple different topics such as Topic 92, 96, 80, and 50. In PMC, many topics related to  X  X ublic health X  are dominant such as Topic 175, 61, and 86, though the detailed re-search topics are distinguishable from the keywords.
 Taking the topic temporal strength into account, is the joint probability of topic strength and time, allowing us to compare the topic strength in different time periods with each other topics .WevisualizethisforAANandPMCinFigure.3-4,and it shows that the major research development occurred after year disambiguation X ) of AAN was dominant compared with others in early 90s while Topic 2 of  X  X east X ,  X  X accharomyces cerevisiae X  in PMC was a extensively studied around entire 90s.
After applying the pruning to the topic level citation structure the evolution graph for research themes can be plotted. We show the evolution graph of AAN with 100 topics in Figure. 5: each node represents a topic and the importance of topics are discriminated by the size of nodes. The green nodes are new topics while the red ones are relatively old. In addition, the dependency between topics are reflected by the thickness of edges .

There are three major connected component, each of which con-tains themes developing over time: Component 3 is about the theme  X  X rammar X , and corresponding topics entirely faded out during early 90s. Nevertheless, Component 2 has the theme of  X  X iscourse/di-alogue X  and  X  X ummarization X , showing mildly progress recently (e.g., Topic 72 (2003) of  X  X achine learning X  based  X  X oreference resolution X  ). Observing the Component 1, which is the largest, is interesting with discovery of various theme evolution patterns: Topic 8 (1991) about  X  X ord sense disambiguation X  was branched into many topics, with one of them (Topic 18) being about  X  X repo-sitional phrase attachment X  (1994). Soon, Topic 18 further enabled Topic 34 (1999) of  X  X tatistical parsing X , and again Topic 73 of  X  X is-criminative parsing X  was established by 2003 on top of Topic 34. Later, Topic 94 of  X  X ependency parsing X  raised and has grown as one dominant topic since 2005.
 Another key thread of theme in Component 1 was initiated by Topic 20, which was the very beginning topic of the theme  X  X ta-tistical machine translation X  (SMT). The topics along the theme evolution path are presented in Table. 5, including 4 topics (Topic 20, 29, 50, and 93), together with the milestone papers (top 3 for each). In addition, the temporal distribution over time is given in Figure. 6, where the citations among the milestone papers, and the dependency strength between consecutive topics are also depicted.
Specifically, Topic 20 began increasing its impact around early 90s, introducing basic statistical methods to machine translation; Later, around 1998, its popularity was shifted to Topic 29 which was specialized in subproblems such as  X  X ecoding X ,  X  X lignment X  and  X  X eordering X  in SMT; By 2002, however, Topic 50 emerged, and soon grew as the new dominant topic by proposing  X  X LEU X  as the standard evaluation metric and investigating  X  X iscriminative methods X  such as  X  X inimum error rate training X ; The current state of the art approach in SMT,  X  X hrase-based model X , accompanied
Topic 20
Topic 29
Topic 50
Topic 93 by the raise of Topic 93, was actually built on top of previous work, especially milestone papers of P 7 -P 9 of Topic 50.

In Figure. 6, citation links among milestone papers across topics are illustrated, which clearly sh ow the formation of topics through the  X  X table core set X  of milestone papers that get cited together (co-cited). More importantly, it is evident that the  X  X o-citation X  of  X  X ore X  papers is the direct contributing factor in the dependency relation between two consecutive topics. We now discuss how to select the topic numbers for Citation-LDA and compare the performance with Content-LDA on two met-rics, namely, Forward Citation and Jounral Conditional Entropy .
We investigate the conventional Content-LDA [4] as our base-line, using the title and abstract to represent the papers in both datasets. In order to make the output of Content-LDA aligned with that of Citation-LDA, we need to derive the missing topic-doc dis-tribution: the distribution over papers (instead of tokens) for each whereas Pr( d )  X  | d | with | d | being the document length for
We compute the topic forward citation probability based on the topic dependency (Equation. 9) and expected topic time (Equa-tion. 7). In words, the forward citation probability reflects the chance a topic cites future topics that arise after itself (though it is impossible for a paper to cite a future paper). We compute the model X  X  loss on topic k by the topic future cita tion probability , which is given by: l ( k )= # assess the total loss for Forward Citation of a model, we define it as follows: We show the evaluation based on Forward Citation for AAN in Table. 6, from which we see: 1) Citation-LDA has better perfor-mance on Forward Citation compared with Content-LDA and 2) 100 topics are a good choice for AAN dataset.
As discussed before, the journal sources are fairly good  X  X oarse X  annotation for topics in PMC. For topic k ,wecanderivethe jour-nal conditional distribution on topic k ,yieldingtheconditionalen-
The H ( J | z ) would have low value if the journal labels and topic labels are consistent ,bywhichwemeanthatforpaperswiththe same topic label (in a probabilistic sense), there is one journal label being as dominant as possible, ideally being purely the only journal label. Hence, we can compute the loss for Journal Conditional Entropy of a model as:
Based on the journal conditional entropy on topics (Table. 7), we again demonstrate the advantage of Citation-LDA over Content-LDA: the topic formed in Citation-LDA is more consistent with the  X  X ournal labels X  than Content-LDA. In addition, we verify that for PMC dataset, 500 topics might be a reasonable choice.
In this paper, we proposed a novel approach for analyzing re-search theme evolution of scientific literature data where citation links are available. Our tasks have two folds: 1) to discover re-search topics, which includes finding milestone papers, comput-ing topic temporal strength, and extracting keywords for topics; 2) to discover theme evolution, which includes identifying topic im-portance, learning topic dependency relation, and recognizing the evolution patterns. These computational components together en-able us to understand evolution of research themes by constructing the evolution graph. In experiments, we investigated two datasets, namely AAN and PMC from two domains, with extensive results showing that our proposed model, Citation-LDA, which represents article paper as  X  X ag of citations X  and model the generation of ci-tation links within a probabilistic framework, can effectively ac-complish the tasks defined above, with the performance better than Content-LDA. Our proposed Citation-LDA, together with the de-veloped mining techniques, can be very useful to help researchers digest literature quickly, thus speeding up scientific research dis-covery and delivering very broad positive impact on the society.
In general, our model can also be applied to any graph data for tasks such as network clustering and ranking, as well as modeling the evolution of network generation, which we leave as future work directions.
The authors would like to thank the anonymous reviewers for their constructive comments and suggestions, which significantly contribute to improving the manuscript and help us to notice the related works [12, 25].
 Our work is supported by the Inte lligence Advanced Research Projects Activity (IARPA) via Department of Interior National Busi-ness Center contract number D11PC20155. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon. Dis-claimer: The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily represent-ing the official policies or endorsements, either expressed or im-plied, of IARPA, DoI/NBC, or the U.S. Government. [1] E. M. Airoldi, D. M. Blei, S. E. Fienberg, E. P. Xing, and [2] D. Blei and J. Lafferty. Dynamic topic models. In [3] D. M. Blei and J. D. Lafferty. A correlated topic model of [4] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet [5] L. Bolelli, S. Ertekin, and C. Giles. Clustering scientific [6] J. Boyd-Graber, J. Chang, S. Gerrish, C. Wang, and D. Blei. [7] J. Chang and D. Blei. Relational topic models for document [8] G. W. Flake, R. E. Tarjan, and K. Tsioutsiouliklis. Graph [9] E. Garfield. The history and meaning of the journal impact [10] R. Ghosh, T.-T. Kuo, C.-N. Hsu, S.-D. Lin, and K. Lerman. [11] T. Griffiths and M. Steyvers. Finding scientific topics. [12] K. Henderson and T. Eliassi-Rad. Applying latent dirichlet [13] J. E. Hirsch. An index to quantify an individual X  X  scientific [14] T. Hofmann. Unsupervised learning by probabilistic latent [15] Y. Jo, J. E. Hopcroft, and C. Lagoze. The web of topics: [16] Q. Mei and C. Zhai. Discovering evolutionary theme patterns [17] R. M. Nallapati, A. Ahmed, E. P. Xing, and W. W. Cohen. [18] A. Popescul, G. W. Flake, S. Lawrence, L. H. Ungar, and [19] V. Qazvinian and D. Radev. Scientific paper summarization [20] D. Radev, P. Muthukrishnan, and V. Qazvinian. The acl [21] H. Sayyadi and L. Getoor. Futurerank: Ranking scientific [22] D. Walker, H. Xie, K.-K. Yan, and S. Maslov. Ranking [23] C. Wang, D. Blei, and D. Heckerman. Continuous time [24] X. Wang and A. McCallum. Topics over time: a non-markov [25] H. Zhang, B. Qiu, C. L. Giles, H. C. Foley, and J. Yen. An
