 In general, a relational DBMS provides limited capabilities to perform multidimensional statistical analysis, which re-quires manipulating vectors and matrices. In this work, we study how to extend a DBMS with basic vector and matrix operators by programming User-Defined Functions (UDFs). We carefully analyze UDF features and limitations to imple-ment vector and matrix operations commonly used in statis-tics, machine learning and data mining, paying attention to DBMS, operating system and computer architecture con-straints. UDFs represent a C programming interface that allows the definition of scalar and aggregate functions that can be used in SQL. UDFs have several advantages and lim-itations. A UDF allows fast evaluation of arithmetic expres-sions, memory manipulation, using multidimensional arrays and exploiting all C language control statements. Neverthe-less, a UDF cannot perform disk I/O, the amount of heap and stack memory that can be allocated is small and the UDF code must consider specific architecture characteristics of the DBMS. We experimentally compare UDFs and SQL with respect to performance, ease of use, flexibility and scal-ability. We profile UDFs based on call overhead, memory management and interleaved disk access. We show UDFs are faster than standard SQL aggregations and as fast as SQL arithmetic expressions.
 H.2.3 [ Database Management ]: Languages X  Query lan-guages ; H.2.8 [ Database Management ]: Database appli-cations X  Data mining Algorithms, Languages Matrix,SQL,UDF,Vector Copyright 2006 ACM 1-59593-433-2/06/0011 ... $ 5.00.
SQL is the standard language to query and analyze data in a relational DBMS [5]. Unfortunately, SQL has no vec-tor and matrix computation capabilities that are essential in multidimensional (multivariate) statistics, machine learning and data mining. There exists work that has proposed SQL constructs and SQL primitives for data mining [4, 17], but such constructs do not offer adequate and flexible matrix manipulation capabilities. There exist proposals that have used SQL queries to integrate data mining algorithms [14, 12, 17, 16]. Other proposals have integrated data mining al-gorithms internally into the DBMS. In our case, Teradata is a parallel DBMS, which makes the integration of statistical, machine learning and data mining algorithms particularly difficult. The Teradata DBMS has a shared-nothing parallel architecture, in which each processing thread is responsible for its own memory and disk management; memory and disk cannot be shared. Even further, vector functions, matrix op-erators and optimizations are more difficult to develop in a parallel DBMS than in a sequential DBMS. These are some important reasons. A SELECT statement is automatically executed with data parallelism, which is both an advantage and a constraint because the user has little or no control over parallelism. Specifically, row distribution among par-allel processing threads cannot be controlled by the UDF. The order in which rows are processed cannot be determined beforehand, which hinders incremental processing.
A UDF is a subroutine that is developed in the C lan-guage, which is compiled to object code and that can be used like any standard SQL function in a SELECT state-ment. UDFs represent an application programming inter-face (API) that allows an end-user to extend the DBMS functionality, subject to several DBMS architecture con-straints. In this work, we study the implementation of User-Defined Functions (UDFs) to extend the DBMS with vector and matrix manipulation capabilities, which are essential in statistical, machine learning and data mining analysis. We study several operating system, DBMS and computer ar-chitecture constraints which play an important role in the implementation of UDFs.
The research questions we answer in this article are the following. Can UDFs help writing common data mining, machine learning and statistical vector operations as SQL queries?, can we take advantage of the C language pro-gramming instructions and ari thmetic operators to imple-ment vector and matrix operations?, can a UDF match or even improve SQL time performance?, are there computer or DBMS architecture limitations for UDFs?, are there any performance bottlenecks to optimize UDFs?.
The article is organized as follows. Section 2 presents definitions and an overview of UDFs. Section 3 presents two sets of UDFs: basic vector operations and computing sufficient statistics matrices. Section 4 presents experiments comparing SQL and UDFs, profiling UDF execution and analyzing time complexity. Section 5 discusses related work. Section 6 concludes the article. Our discussion is based on a multidimensional data set. Let X = { x 1 ,...,x n } be a data set with nd -dimensional points. In mathematical terms, X is a d  X  n matrix, where x is a column vector and X li is the l th dimension from x i We use i =1 ...n as a subscript for points and l, a, b as dimension subscripts. Matrix transposition is denoted by T and it is used to make matrices compatible for multiplica-tion. We prefer the term  X  X imension X  instead of variable or feature. The data set X is stored as a table with an addi-tional column i that acts as primary key (e.g. a record id), which is not used for statistical purposes. Thus table X is defined as X ( i ,X 1 ,X 2 ,...,X d ) with primary key i .
UDFs are programmed in the C language, compiled to object code and called in a  X  X ELECT X  statement, like any standard SQL function. There are two fundamental classes of functions: (1) Scalar functions, that take a set of pa-rameter values and return a single value. A scalar function produces one value for each input row. (2) Aggregate func-tions, which work like standard SQL aggregate functions and return one row for each distinct combination of group-ing columns.
This section presents our main contributions. We first ex-plain the integration of data mining algorithms in a parallel DBMS like Teradata. We identify important programming considerations. We introduce a set of scalar UDFs that per-form basic vector operations and finally, we introduce an ag-gregate UDF that computes two essential matrices for data summarization.
In the case of Teradata, we have identified three alterna-tives to integrate a data mining algorithm with the DBMS: (1) Implementing the algorithm internally so that matrix operations are handled directly by C code, bypassing the DBMS storage manager; disk blocks are directly accessed and memory has to be carefully managed. Results from each processing thread need to be combined through mes-sage passing. This alternative is particularly difficult given the shared-nothing architecture of the DBMS. (2) Devel-oping the data mining algorithms with SQL queries; SQL has limited matrix computation capabilities, but it exploits available DBMS functionality [14, 12, 11, 13]. This is the alternative currently used in some data mining techniques working on Teradata. (3) Exploiting UDFs combined with SQL. UDFs have somewhat limited memory management capabilities and they cannot perform disk I/O. But they are fast, they provide the programming flexibility from the C language, they automatically execute in parallel and they exploit DBMS functionality. This is the alternative we ex-plore in depth in this article and which is used to accelerate particular data mining operations.
We have identified the following constraints to implement vector and matrix operations with UDFs in the Teradata DBMS. (1) A UDF can only accept parameters of simple types (e.g. int, float, char) and return values of simple types. Therefore, arrays are not allowed as parameters and a UDF cannot return an array as result. This is not a significant limitation because a UDF can take up to 128 parameters, which can be used as a substitute for arrays. For higher di-mensional data sets, vector entries can be packed as strings and strings can be passed as parameters to the UDF. At run-time vector entries must be packed as a string casting numbers as strings and when the UDF receives the string it has to unpack it to get vector entries for internal vector and matrix manipulation. (2) A scalar UDF cannot allocate heap memory. On the other hand, an aggregate UDF can allocate heap memory, but the amount of memory is lim-ited and it cannot be shared among threads. The maximum amount of heap memory that can be currently allocated by an aggregate UDF under the current (32 bit) UNIX operat-ing system is one 16-bit segment. That is, it is 64 kb. This limit will change when Teradata is ported to a 64 bit oper-ating system architecture. (3) All variables and parameters are local to the UDF, even the aggregation variable allo-cated in global memory. All variables are allocated in the stack with the exception of the aggregation  X  X truct X  record, to be explained below. All stack variables disappear after each call for each row. (4) The only way to write UDF re-sults to disk in the DBMS is to store the result value as a column value in a result table. A UDF is executed in main memory at all times and it cannot perform any I/O during its execution; this is done to protect internal storage and to ensure the UDF is properly managed by the parallel DBMS. (5) SQL semantics require careful handling of nulls. In gen-eral, if some value is null in an arithmetic expression then the result is null. Therefore, if some parameter for the UDF is null then the UDF returns null. In practical terms, this means that for data set X there are d values that are passed at run-time but also d null markers that are also dynam-ically computed at run-time. (6) UDFs are automatically executed in parallel in a shared-nothing database architec-ture. Data set X is horizontally partitioned and each par-tition is independently processed by one thread. Each row from X has an address that is computed when the row is inserted. The address is a hash code that is composed of one thread id (called AMP) and a physical block address. On one hand, threads cannot share memory, but on the other hand, the UDF developer does not worry about mu-tual exclusion or synchronization. In other words, a UDF called on one row cannot read the results from the same UDF called on another row. (7) A UDF can be executed in unprotected mode guaranteeing maximum performance, but risking operating system failure if unexpected memory leaks arise. Otherwise,aUDFcanbeexecutedinprotectedmode which runs in a separate UNIX process with low parallelism that can handle memory management errors, but which has bad performance. In general, we run UDFs in unprotected mode after careful testing. (8) Arrays are statically sized when the UDF is compiled; the UDF cannot allocate an ar-ray with a user-specified size at run-time. This means that several versions of the same UDF with different memory usages may be needed when memory becomes scarce (e.g. extremely large SQL queries with many terms). In the C language, unidimensional arrays with d entries are indexed from 0 to d  X  1. On the other hand, algorithms and sta-tistical techniques are typically specified with vectors and matrices starting in subscript 1. To provide a more abstract and faithful implementation we manipulate arrays starting in subscript 1, wasting just the array entry at subscript 0. Data set X has to be pivoted in order to use standard SQL aggregations. Teradata does not currently provide PIVOT and UNPIVOT operators, like other DBMSs. However, piv-oting can be easily accomplished with d SELECT state-ments. Table Xpivot is defined as Xpivot( i, l, X l ) INSERT INTO Xpivot SELECT i ,1, X 1 FROM X ; INSERT INTO Xpivot SELECT i ,2, X 2 FROM X ; . . .
 INSERT INTO Xpivot SELECT i , d , X d FROM X ; This code transforms X into a table that has dn rows. In the following discussion we assume Xpivot has already been computed in order to apply standard SQL aggrega-tions. Pivoting is an operation that is not appropriate for UDFs because it changes table structure and it is not of a mathematical nature.
We use x i as the input vector for each operation. For each vectorial operation we show three solutions: using an arith-metic expression, using an aggregation and using a scalar UDF. For UDFs we show the main fragment of C code and we omit the C code to pass parame ters, to declare variables, to initialize arrays and to handle nulls. Also, we omit the UDF definition in SQL, which specifies input parameters data types, output data type, null handling and maximum memory that can be allocated.
 The task is to get for each point x i . The SQL based on aggregations, using X in pivoted form, is as follows: SELECT i, sum ( X l ) FROM Xpivot GROUP BY i ;
The statement based on a SQL arithmetic expression dy-namically evaluates the equation at run-time: SELECT i , X 1 + X 2 + ... + X d FROM X ;
ThevectorialsumUDFCcodeandtherespectiveUDF call follow. for(l=1,sum=0;l&lt;=d;l++) sum+=X[l]; *result= &amp;sum; SELECT i ,vectsum( X 1 ,X 2 ,...,X d ) FROM X ;
This framework can be generalized to compute distance functions (Manhattan, Euclidean, Mahalanobis), which are essential in nearest neighbor classifiers and clustering. A dot product between two vectors is useful for regression and other statistical techniques like factor analysis. Given two d -dimensional vectors x and y the task is to compute
Assume  X  is a d -dimensional vector of coefficients. For linear regression, the  X  Y predicted column is determined by or equivalently for one point,  X  y i =  X  T x i . For binary logistic regression The SQL to compute dot products, assuming  X  is also in pivoted form (i.e. betapivot( l ,beta l )), using aggregations is: SELECT i ,sum(beta l * X l ) FROM Xpivot JOIN betapivot ON Xpivot.l=betapivot.l GROUP BY i ;
The SQL statement using an arithmetic expression to compute the dot product between  X  and x i is: SELECT i ,beta 1 * X 1 + ... +beta d * X d FROM X ,beta;
The dot product UDF takes vector  X  and vector x i as parameters. The C code for the UDF to compute the dot product of  X  and x i and the UDF call in SQL are included below. Each product  X  l  X  X l is evaluated in compiled C code at run-time. for(l=1,sum=0;l&lt;=d;l++) sum+=beta[l]*X[l]; *result= &amp;sum; SELECT i FROM X ;
The vectorial sum UDF can be reused to compute a dot product by passing sum terms as parameters. Each product  X   X  X l is evaluated in SQL at run-time.
 SELECT i ,vectsum(beta 1 * X 1 ,..,beta d * X d ) FROM X ; One of the most common tasks when programming a statis-tical algorithm is to determine the subscript of the minimum (maximum) element in a vector. Such task is needed in clus-tering [14] to determine the nearest centroid to a point, in a Bayesian classifier to determine the class with highest proba-bility, in decision trees to determine the dimension (feature) with highest gain or the best split point or in logistic regres-sion to determine the target value with highest probability. The SQL solution is as follows: SELECT i, l FROM Xpivot
The only way we have discovered to compute the subscript of the minimum argument without aggregate functions re-quires a long CASE statement with d  X  1 WHEN conditions, where each condition is a conjunction of l  X  1 inequalities, l =1 , 2 ,...,d : SELECT ,CASE FROM X ;
This code takes O ( d 2 ) because the total number of com-parisons is: ( d  X  1) + ( d  X  2) +  X  X  X  +1 = ( d  X  1) d/ 2. We now show the C code implementing the UDF that finds the subscript of the minimum argument and the corresponding UDF call in a SELECT statement. argmin=1; for(l=2;l&lt;=d;l++) if(X[l]&lt;X[argmin]) argmin= l; *result= &amp;argmin; SELECT i ,argmin( X 1 ,X 2 ,...,X d )AS l FROM X ; Computing distance is fundamental for clustering and near-est neighbor classifiers. Let C represent a vector with d coordinates. Let R represent a diagonal variance-covariance matrix. There are three main distance functions, widely used in the machine learning literature. (1) Manhattan [1], also known as block-based: (2) Euclidean [8], which is the length of the shortest line linking two points in space: (3) Mahalanobis [15], which is a scaled distance by vari-ance so that dimensions in different scales can be compared mainly for clustering purposes:
These equations are computed in SQL and C using the same framework above. The main difference is that we need to pass more parameters. In the SQL code below we show the UDF call for each distance implementation and three statements reusing the vectorial sum.
 SELECT i ,ManhattanDist( C 1 ,C 2 ,...,C d , X 1 ,X 2 ,...,X FROM X ; SELECT i ,EuclideanDist( C 1 ,C 2 ,...,C d , X 1 ,X 2 ,...,X FROM X ; SELECT i ,MahalanobisDist( C 1 ,C 2 ,...,C d , FROM X ; /* Manhattan */ SELECT i ,vectsum(abs( C 1  X  X 1 ),..,abs( C d  X  X d )) FROM X ; /* Euclidean */ SELECT i ,vectsum(( C 1  X  X 1 )**2,..,( C d  X  X d )**2) FROM X ; /* Mahalanobis */ SELECT i ,vectsum(( C 1  X  X 1 )**2/ R 1 ,..,( C d  X  X d )**2/ R FROM X ; We concentrate on computing vector L and matrix Q :
Vector L in Eq. 1 contains the linear sum of points and it is d  X  1. For practical purposes, L canbeconsidereda 1  X  d matrix. Matrix Q in Eq. 2 is d  X  d and contains the quadratic sum of points, where each point is squared with a cross product.

Vector L and matrix Q together with n represent suf-ficient statistics for several linear models including cluster-ing, linear regression, Principal Component Analysis (PCA), Maximum Likelihood Factor Analysis and correlation (not strictly a model). In other words, { n, L, Q } can be used instead of X in each technique internal calculations. This makes computation much faster since L and Q are much smaller than X (i.e. d&lt;&lt;n ). It is beyond the scope of this article explaining in mathematical terms why n, L, Q have such wide applicability and showing how they can sig-nificantly accelerate processing in a relational DBMS. Such aspects will be studied in future work.

There are three optimizations that can be applied to com-pute Q . First, when dimensions are assumed to be indepen-dent, cross-products can be ignored and then Q becomes a diagonal matrix. This is the case for clustering (K-means and EM) [14] and makes Q computation take O ( d )instead of O ( d 2 ). We call it the diagonal matrix optimization. Sec-ond, in all other cases only one half of Q can be computed because Q is symmetrical. This is the case for linear regres-sion, PCA, Factor Analysis and correlation. If needed, the upper (lower) half can be copied to the lower (upper) half at the end. This makes Q computation take d ( d  X  1) / 2opera-tions instead of d 2 . We call this improvement the triangular matrix optimization. Third, n , L and Q can be computed in the same table scan because they do not depend on each other; such matrix independence is a mathematical property that can be exploited to reduce disk I/O.
 n , L and Q can be obtained from Xpivot with aggregations with one value per row. We compute the lower triangular submatrix of Q (diagonal Q : X  X HERE a = b  X ). /* n */ SELECT sum(1.0) AS n FROM X ; /* L */ SELECT l ,sum( X l ) FROM Xpivot GROUP BY l ; /* Q */ SELECT A. l AS a,B. l AS b,sum(A. X l *B. X l ) FROM Xpivot A WHERE a&gt;b GROUP BY a, b ;
This solution requires reading Xpivot three times because of the linear sum and the self-join. L and Q can be more efficiently computed on a single table scan on X with one SELECT statement with 1 + d + d 2 aggregation terms, cor-responding to n, L and Q .

L and Q can be computed more efficiently using X as follows in a table with 1 + d + d 2 columns.
 SELECT sum(1.0) AS n FROM X ; Based on the same framework introduced above, n , L and Q can be computed by one UDF in a single table scan on X . The crucial difference between a scalar UDF and an aggre-gate UDF is that the aggregate UDF can allocate global memory: the aggregate UDF can store n, L, Q in mem-ory and it can perform all incremental update operations in memory as well.
 The UDF stores aggregation results in a C  X  X truct X  record. Currently, due to specific operating system and computer architecture constraints, a UDF can only allocate up to 64 kb. In practical terms, this allows computing matrices up to d = 64, which represents a good threshold for medium and low dimensional data sets. Matrices with d&gt; 64 can be com-puted in blocks of 64  X  64 sub-matrices with separate UDF calls. Since Teradata has a shared-nothing architecture each Table 1: Time in seconds to get vectorial sum for all vectors x i ; d =32 . processing thread has its own  X  X truct X  record. The aggre-gate UDF is executed in the following phases: (1) Memory is allocated in each thread and arrays for each matrix are ini-tialized. (2) Each thread updates n , L and Q independently on a portion of X . Each row from X is scanned. (3) Par-tial results from each thread are aggregated into one global result. (4) Matrices are packed as a string and returned to the user. Clearly, phase 2 is expected to be the most time-consuming and that is why we incorporate the diagonal or triangular matrix optimization here. The C code choosing the desired matrix type optimization is below. We omit C code to aggregate partial results from each thread. thread_storage-&gt;n+=1.0; for(a=1;a&lt;=d;a++) { } We present experiments on the Teradata RDBMS V2R6. Our Teradata database server had 20 parallel processing threads in a shared-nothing architecture. The server had four CPUs running in parallel at 1.2 GHz, 256 MB of mem-ory per CPU and 1 TB of disk space. The operating sys-tem was UNIX MP-RAS (a parallel OS version derived from Unix System V). Data set X was never cached and was read from disk in every run. That is, I/O cost played a crucial role in performance. Our experiments vary n and d to compare SQL and UDFs. Each run with the same parameters was repeated five times to get average execution time. Times are reported in seconds.
Data set X had d = 32 by default. Table 1 compares the three implementations to get the vectorial sum. The SQL aggregation time grows faster than their counterparts. We expected UDFs to be slightly faster than SQL since the sum arithmetic expression is interpreted at run-time and the C code is compiled. The SQL arithmetic expression and the UDF have the same performance: I/O dominates time since this vectorial operation performs only d  X  1 floating point additions in memory. Table 2: Time in seconds for dot product  X  T X ; d = 32 . Table 3: Time in seconds for the subscript of mini-mum argument UDF for all x i ; d =32 .

Table 2 compares the dot product for the three implemen-tations. There are two differences with respect to vectorial sum: There are d multiplications in addition to d  X  1 addi-tions. The  X  vector is stored in a one-row table. We can see the SQL aggregation time grows much faster than the other two implementations. In this case joining  X  (with a Carte-sian product) with X , and performing dn multiplications significantly hurts performance. Both the SQL arithmetic expression and the UDF times are slightly higher than their respective times for the dot product. In fact, the arithmetic expression time increment because of the additional d multi-plications and joining  X  is marginal. On the other hand, we can see the gap between UDF and the SQL arithmetic ex-pression remains the same. The UDF overhead comes from passing 4 d parameters on the stack ( x i and null markers twice).
 Table 3 provides another perspective comparing SQL and UDFs. First, even though we join two tables with n and dn rows, the time to compute the subscript of the mini-mum argument is better than the time to get dot product. However, the SQL aggregation is still an order of magni-tude worse than the other two implementations. Recall the CASE statement makes O ( d 2 ) comparisons, compared to O ( d ) comparisons for the UDF. That does make a differ-ence, since now the UDF is always faster.

Table 4 compares the three implementations to compute n ,vector L and matrix Q . We used the triangular matrix optimization to compute Q by default. The aggregation is much slower than the term list and the aggregate UDF; in fact, for the largest data set it is one order of magnitude Table 4: Time in seconds to get n, L, Q on X ; d =32 .
Table 5: Scalar UDF vs aggregate UDF; d =64 . slower. The UDF is the fastest in all cases. The term list creates a  X  X ide X  table with 1+ d + d 2 terms, whereas the UDF returns only one  X  X ide X  column, but the gap in performance narrows as n grows.

We compare a scalar UDF and an aggregate UDF that do exactly the same work. For the scalar UDF we use our simplest UDF which is the vectorial sum. For the aggregate UDF we simplify our aggregate UDF to compute the sum of all elements in L . The difference is that the scalar UDF returns the vectorial sum for one x i and the aggregate UDF returns the sum for all vectors x i . Both UDFs: perform O ( dn )work,receive x i as a list of d parameters, access the d entries, perform d  X  1 additions; the aggregate UDF just does an additional sum to increment the global sum. The scalar UDF execution returns a table with two columns and n rows, whereas the aggregate UDF returns a table with one row and one column. In short, they do the same work. From an execution perspective the scalar UDF works only on the stack, whereas the aggregate UDF works on the stack and the heap. There is small additional overhead to assemble the results from all threads into one result; for large n it is negligible. As we can see in Table 5 both UDFs take about the same time, but the aggregate UDF is slightly slower.
Our comparisons between scalar and aggregate UDFs sug-gest disk I/O is a bottleneck for performance. However, we are not sure how much time it takes to create the activation call for the UDF, to pass the vector x i and the correspond-ing null markers, to create local variables, to actually run the desired vector or matrix functionality and finally, return results to the user. In the following experiments we took a data set X with n = 3200k and d = 64, which represents a fairly large data, high dimensional data set where we can study the relative importance of each internal operation in the UDF. We want to emphasize again, that X is read from disk every time and it is never cached. We made a separate experiment setting for the scalar and the aggregate UDF since both have different implementations.

Table 6 shows the relative importance of each UDF inter-nal operation. We indicate if the UDF is called or not and if vector x i is passed as parameter or not. Column time indi-cates the cumulative elapsed time for each operation within the UDF. In column  X  we compute the incremental time difference between each consecutive operation. Finally, the percentage column shows the fraction of each operation run-ning time; this column highlights the relative overhead and importance of each operation.

To profile the scalar UDF we picked the simplest func-tion: vectorial sum. We ran experiments as follows. The lower bound for UDF running time is evidently disk I/O since the UDF needs to have as parameters columns from a table. Since the UDF call itself introduces overhead we first ran a straight  X  X ELECT * FROM X  X  query to scan the en-tire table and access every column. We created a UDF with only one parameter ( d ), to quantify the overhead of creating and destroying the UDF call activation record in the stack. This function does no operation on X (we call it NOP) and returns null. We created a UDF that had X (with its d coor-dinates) as parameter, but which made no operation (NOP) on X ; each vector entry had also its null marker as required by SQL. A local array X was created in the stack to store the parameter vector. The UDF returns a null value. We used the UDF that did all the work as described in Section 3 and returned a floating point number for each row. Our first surprise is that disk I/O accounts for slightly over 50% time, and we expected it to be higher. Our second surprise was that the actual vectorial sum computation took only 4% of the total time. It is interesting that the UDF call over-head is the second contributing factor to time. We expected passing x i should take some time since it requires assign-ing each coordinate to an array entry and taking care of null indicators. Our findings indicate that there is room for performance improvement by reducing UDF call overhead. On the other hand, it is not worth optimizing the desired operation itself (summing vector entries in this case).
For the aggregate UDF we had to develop a more detailed profile, given its C code and run-time execution complexity. Recall we introduced only one aggregate UDF to compute n ,vector L and matrix Q (triangular by default). There are some similarities with the scalar UDF profile described above, but there are more internal operations. We now de-scribe the setting. The output in every case is a table with one row and one column, except for the  X  X ELECT * FROM X  X  query. Our baseline comparison was again a full table scan (FTS) with the query  X  X ELECT * FROM X  X . We first created an aggregate UDF that received only one pa-rameter ( d ) and returned a floating point number instead of a string. The UDF did not perform any operation. We de-fined a similar UDF which had to allocate L ;notice L takes little (linear) memory, less than 1 kb. We created a similar UDF, but now allocating L and Q ;inthiscase Q takes a lot memory (quadratic space), relative to the UDF constraint of 64 kb. In this case d = 64 makes memory allocation take over 32 kb. This UDF did not perform any arithmetic op-eration either. Then we built a UDF which passed vector x . This UDF did not perform any arithmetic operation and returned a number. We created a UDF that passed x i , but which computed n and L and returned a number. This UDF makes a linear number of arithmetic operations. Then we defined a UDF that passed x i and also computed n, L, Q . This UDF makes a quadratic number of arithmetic opera-tions. Last, this is the UDF that does all the work. That is, it computes n, L, Q and packs n, L, Q into a long string, which can be easily returned to the desired application or client program. Findings are even more surprising that for the scalar UDF. First of all, disk I/O is very low, just 7%. Allocating arrays for L and Q and maintaining those arrays in memory takes almost 40% of time. The operating sys-tem incurs on significant overhead maintaining the arrays in memory even though they are not used. Then packing ma-trices as a string takes 22% of time; the operating system needs to allocate memory to return the long string. That is why all UDF versions, except the last one, return just one number in order to avoid this extra overhead. Therefore, 62% of time of the UDF execution is spent on memory over-head, and not on the actual arithmetic operations. In fact, computing n, L, Q takes only approximately 20% (17+4) of total time, even though Q requires a quadratic number of operations per row. Passing x i takes little time. Last, call-ing the UDF and allocating L take negligible time. In short, for our aggregate UDF memory manipulation is the bottle-neck. Optimizing disk I/O or arithmetic operations is not worth it.
Figure 1 shows time complexity as n grows. The first graph shows two scalar UDFs: vectorial sum and dot prod-uct. Both UDFs show linear scalability; dot product is slightly slower than vectorial sum and the gap in perfor-mance grows little. On one hand, this is good news because we are basically doing twice the number of arithmetic op-erations with almost the same performance. But on the other hand, disk I/O remains a bottleneck, since we can-not expect any UDF on a d -dimensional vector to be faster than vectorial sum. The second graph in Figure 1 shows time growth for the diagonal (time O ( d )) and triangular Q computation (time O ( d 2 )). The aggregate UDF has linear performance. The gap in performance is small, even though computing Q takes O ( d 2 ). The difference in performance between d =32and d = 64 for the diagonal Q computation is practically zero. Also, such performance is almost the same as the triangular Q computation at d = 32. In other words, d plays a much smaller role in the aggregate UDF, compared to the scalar UDFs. Similarly, we cannot expect any aggregate UDF on a d -dimensional vector to be signifi-cantly faster than the UDF with a diagonal Q computation since that UDF does 2 d + 1 computations. In short, both scalar and the aggregate UDF exhibit linear scalability with respect to n and time for both is dominated by disk I/O.
To conclude this section on time complexity, Figure 2 plots scalability as d grows. The first graph shows scalar UDFs behavior. Time growth for the vectorial sum UDF is sub-linear, which is consistent with the results presented for n growth. Time growth for the dot product UDF is fairly lin-ear which can be explained by the fact that we join the one row table for  X  with X and twice the number of arithmetic operations. The second graph shows time for the aggregate UDF. We can see that time remains almost constant when we compute a diagonal Q matrix. Time grows slowly for the triangular Q matrix when d = 32 and there is  X  X ump X  when d&gt; 32, indicating arithmetic operations start having more weight with respect to I/O. In any case, time growth is almost linear even for the triangular matrix computation. We can see that the aggregate UDF incurs on significant overhead since it takes an order of magnitude more time, compared to scalar UDFs, for a data set with the same d and n . Scalar UDFs are used in queries that produce one table with n rows, whereas the aggregate UDF produces one table with one big column.
Scalar UDFs and SQL arithmetic expressions have similar performance. Computing vector operations using aggrega-tions on the pivoted version of X has significantly worse performance than SQL arithmetic expressions and UDFs. Both scalar and aggregate UDFs exhibit linear time scala-bility with respect to data set size (number of rows). Dimen-sionality (number of columns) is more important for UDFs and SQL arithmetic expressions than for aggregate UDFs. Disk I/O takes a significant portion of running time for the scalar UDF. Memory overhead takes most of the time for the aggregate UDF. Disk I/O is very low for our aggregate UDF. Both types of UDFs indicate it is not worth to op-timize the number of arithmetic operations. The number of operations that can be done inside an aggregate UDF is quadratic and performance remains almost linear.
Based on our vector and matrix operations implementa-tion we summarize UDF advantages. UDFs allow the data mining programmer to extend the SQL language with pow-erful mathematical capabilities. Our set of UDFs can ex-press most vector operations needed in many statistical tech-niques, showing wide applicability. Having the possibility to implement a complex mathematical operation with a UDF avoids the need to export a data set outside the DBMS. The C language provides great flexibility to implement vec-tor and matrix operations with multidimensional arrays and all C flow control statements, such as  X  X or X , X  X f X  and  X  X hile X . A UDF runs fast because it is plugged directly as a piece of executable code inside the DBMS, like any other SQL func-tion. Important UDF disadvantages include the following. There are certain limitations that are architecture depen-dent, such as no control on parallel execution, no shared memory, no complex types as parameters and low available memory space. UDF capabilities provided by a particular DBMS will vary; in particular, aggregate UDFs character-istics are more OS and DBMS architecture dependent. A set of UDFs cannot always be a substitute for an external statistical package, when a complex statistical or data min-ing technique is needed. Nevertheless, combining SQL and UDFs can help doing pre-processing inside the DBMS, like we did for the sufficient statistics for linear models.
Although there has been a considerable amount of work in machine learning and data mining to develop efficient and accurate techniques, most data mining work has concen-trated on proposing efficient algorithms assuming the data set is in a flat file outside the DBMS. Statistics and ma-chine learning have paid little attention to large data sets, whereas that has been the primary focus of data mining. Studying purely statistical techniques in a database context has received little attention. Most research work has con-centrated on association rules [2], followed by clustering [14] and decision trees [6]. The importance of the linear sum of points and the quadratic sum of points (without cross-products) to decrease I/O in clustering is recognized in [3, 15], assuming the data set is directly accessible with some I/O interface. We have gone beyond a scalable clustering approach, by showing the linear sum and the quadratic sum of points with cross-products solves four statistical prob-lems. This is orthogonal to implementation. Our approach to profile UDFs shares similarities with other approaches where the authors use queries to figure out in what level of the memory hierarchy there are bottlenecks. Reference [9] stresses the importance of taking into account the ever-increasing speed of CPUs and the much slower growth in memory access speed; the authors propose techniques to ac-celerate join processing on memory-resident tables.
Most proposals extend SQL with data mining functional-ity, by adding syntax to SQL and optimizing queries using the proposed extensions. Data mining primitive operators are proposed in [4], including pivoting and sampling. SQL extensions to define, query and deploy data mining models are proposed in [10]. This approach is complementary to our proposal. Getting sufficient statistics for classification in SQL is studied in [7]. In [13] there is a proposal to en-rich SQL to compute percentages in vertical and horizontal layouts. In a related approach, [11] proposes special aggre-gations to preprocess and transform data sets for machine learning and statistical analysis. Developing data mining algorithms using SQL has received some attention. Some important approaches include [16] to mine association rules, [14, 12] to cluster data sets using SQL queries, [17] to de-fine primitives for decision trees. SQL syntax is extended to allow spreadsheet-like computations in [18], letting an end-user express complex equations in SQL, but such approach is not as flexible and efficient as ours to express vector and matrix computations.
We studied how to extend SQL with vector functions and matrix operations exploiting scalar and aggregate UDFs. UDFs are subroutines programmed in the C language that can be used like any SQL function, which have constraints due to the DBMS architecture and the operating system. We focused on three vector operations including the vec-torial sum, the dot product and the subscript of the mini-mum argument. We presented three solutions: using aggre-gations, writing an arithmetic expression and developing a scalar UDF. We then studied how to compute two essential matrices, called sufficient statistics, for several linear statis-tical models. We showed three solutions: using aggregations on a pivoted version of the data set, with a long list of terms with aggregations and defining an aggregate UDF. Our ex-periments were based on the Teradata DBMS, but we expect most of our findings to be similar in other relational DBMSs that offer scalar and aggregate UDF capabilities. Experi-ments compare SQL and UDFs and study time complexity. UDFs and SQL arithmetic expressions have similar perfor-mance. SQL standard aggregations are much slower than scalar UDFs. Scalar UDFs are as fast as arithmetic expres-sions in SQL. The aggregate UDF that computes sufficient statistics is faster than the two solutions using SQL stan-dard aggregations. Disk I/O is significant for scalar UDFs, whereas memory management overhead dominates time of our aggregate UDF. Scalar and aggregate UDFs have linear time scalability on data set size. Scalar UDFs have linear time scalability on dimensionality. Aggregate UDFs have almost linear time scalability when doing a quadratic num-ber of operations with respect to dimensionality. Aggregate UDFs time growth is almost zero when the number of oper-ations is linear with respect to dimensionality.
There are several issues for future work. We plan to develop mechanisms to decrease memory management and UDF call overhead. We need to identify other mathematical operations with wide applicability that can be implemented with UDFs, thereby enhancing DBMS data mining func-tionality. Scalar UDFs can benefit from allocating global memory to maintain common matrices in memory and in some cases small matrices can be stored in cache memory. We want to understand how UDFs can simplify automati-cally generated SQL code. Some operations in a UDF can exploit cache memory, register variables or specific numeric co-processor instruction s to improve performance. This research work was partially conducted by the first au-thor at Teradata, NCR, while he was working as a researcher on data mining technology. The second author was spon-sored by the UNAM information technology project  X  X acro-proyecto de Tecnolog  X   X as para la Universidad de la Infor-maci  X  on y la Computaci  X  on X . [1] C. Aggarwal and P. Yu. Finding generalized projected [2] R. Agrawal, T. Imielinski, and A. Swami. Mining [3] P.Bradley,U.Fayyad,andC.Reina.Scaling [4] J. Clear, D. Dunn, B. Harvey, M.L. Heytens, and [5] R. Elmasri and S.B. Navathe. Fundamentals of [6] J. Gehrke, Venkatesh Ganti, and R. Ramakrishnan. [7] G. Graefe, U. Fayyad, and S. Chaudhuri. On the [8] T. Hastie, R. Tibshirani, and J.H. Friedman. The [9] S. Manegold, P.A. Boncz, and M.L. Kersten.
 [10] A. Netz, S. Chaudhuri, U. Fayyad, and J. Berhardt. [11] C. Ordonez. Horizontal aggregations for building [12] C. Ordonez. Programming the K-means clustering [13] C. Ordonez. Vertical and horizontal percentage [14] C. Ordonez and P. Cereghini. SQLEM: Fast clustering [15] C. Ordonez and E. Omiecinski. FREM: Fast and [16] S. Sarawagi, S. Thomas, and R. Agrawal. Integrating [17] K. Sattler and O. Dunemann. SQL database [18] A. Witkowski, S. Bellamkonda, T. Bozkaya,
