 Online forums are becoming a popular way of finding useful information on the web. Search over forums for existing dis-cussion threads so far is limited to keyword-based search due to the minimal effort required on part of the users. However, it is often not possible to capture all the relevant context in a complex query using a small number of keywords. Example-based search that retrieves similar discussion threads given one exemplary thread is an alternate approach that can help the user provide richer context and vastly improve forum search results. In this paper, we address the problem of finding similar threads to a given thread. Towards this, we propose a novel methodology to estimate similarity between discussion threads. Our method exploits the thread struc-ture to decompose threads in to set of weighted overlapping components. It then estimates pairwise thread similarities by quantifying how well the information in the threads are mutually contained within each other using lexical similari-ties between their underlying components. We compare our proposed methods on real datasets against state-of-the-art thread retrieval mechanisms wherein we illustrate that our techniques outperform others by large margins on popular retrieval evaluation measures such as NDCG, MAP, Preci-sion@k and MRR. In particular, consistent improvements of up to 10% are observed on all evaluation measures. H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval X  Retrieval Models Forums, Threads, Retrieval, Similarity
Online forums are fast becoming a very popular data source on the web. They are an easy way to publish knowledge since composing a post in a forum is much easier than composing a web page. Further, forums are interactive spaces where many people contribute and hence are live (as against web pages that are often static); making them more attractive to contribute to. Forums are monitored by many people making spurious information easy to detect and point out; hence, it may be expected that contributors would exercise some caution to ensure that the information that they post is correct and useful. It may also be observed that forums mostly contain subjective knowledge (e.g., opinions) and hence are often complimentary to other knowledge sources such as Wikipedia 1 . Despite such uniqueness, there have been only a few forum search engines 23 and searching forum threads is still only an emerging topic [28, 10, 12].
In this paper, we consider the problem of finding simi-lar threads to a given thread . Threads in online discussion forms are collections of posts that are posted in response to a common starting post. Finding similar data objects in other popular data sources such as text collections [13], web documents [8], images [34], websites 4 , social network profiles [15], linked entities [19] and relational data [9] have been a subject of much research. However, finding similar threads in online forums, to the best of our knowledge, has not received enough attention.

Applications: Much like finding similar objects in other knowledge sources, finding similar threads has many poten-tial applications. For example, a user browsing a thread in a discussion forum could be provided links to similar threads for a more detailed reading on the same or related topic. Likewise, links to related threads (much like grouping of news articles in systems such as Google News 5 ) could be of use in thread retrieval systems [12]. A notion of similarity among threads would also help developing a clustered interface for search results (e.g., Yippy 6 ) in thread retrieval. A knowl-edge author who seeks to read through discussions forums (e.g., developer forums) and document problems and solu-tions from them would most likely prefer to read through similar threads together since that would help minimize con-text switch, by enabling her to cover one type of problems in entirety before moving to the next. Though finding similar threads has many potential applications as outlined above, we focus on the scenario of providing a functionality of find-ing similar threads to a given thread (e.g., the thread the http://en.wikipedia.org http://www.boardreader.com http://www.boardtracker.com http://www.similarsites.com/ http://news.google.com http://search.yippy.com user is reading currently) and evaluate the effectiveness of t he similarity measure that we propose, using classical In-formation Retrieval evaluation measures.
 User:0 User:1 User:2a
C hallenges vis-a-vis Document Similarity: Threads in discussion forums, despite being largely composed of tex-tual content, have various properties that distinguish them from regular text documents such as newswire articles. The latter are mostly authored by a single author, whereas dis-cussion forum threads involve many contributors. This makes them less coherent, and more vulnerable to abrupt jumps in topics. Further, discussion forum threads have an inherent structure; this could be visualized as a tree structure where posts form nodes and edges linking posts to their replies. The intuitive method of estimating similarity that considers each thread as a large document comprising of all the compo-nent posts followed by usage of traditional similarity metrics such as tf.idf cosine would obviously lead to large posts being able to influence similarity more than smaller ones; this is undesirable since the length of a post is more often related to other factors such as author X  X  style than the utility of the post. At the other end of the fragmentation spectrum, is that of considering each thread as a bag of posts , with similarity between them being quantified as an aggregate of the pairwise similarities between the posts. Consider two hypothetical threads T1 and T2 spawned out of the same first question in Table 1. Despite being very similar due to the nature of content posted, no pair of posts (one from each thread) have a high lexical similarity. This is due to the con-tent in the single post in T1 getting split across two posts in T2. Such fragmentation is common in discussion forums due to varying expertise levels of content authors and dents the effectiveness of the bag of posts approach. The third solution is that of selecting highly informative words to form summaries of each thread and using them as a keyword query in keyword search systems that operate on forums [28, 10, 12]. However, such selection of words is often hard making it difficult to capture the entire context of the query thread. We address the above challenges in developing a methodol-ogy for finding similar threads.

Our specific contributions are as follows: Consider a discussion forum thread X and a set of threads Y . We would like to develop a method that heuristically estimates the similarity between X and each thread in Y . Given such a method S ( ., . ), one can rank the threads in Y in the non-increasing order of similarity with X , such that the following condition is satisfied: where Y i denotes the i th thread when threads in Y are arranged in the non-increasing order of similarity wrt X . The above condition simply suggests that Y i has a score at least as much as any of threads not ahead of it in the ranking.
Since we will make many references to threads and posts, we hereby informally outline what we mean by them. We define a post as the smallest unit of communication in online forums that consists of content posted by a user. Each post has associated meta-data such as user ID of the user posting the post, time of posting the post etc. A thread starts off with a post (that we call as the first post , whose title is the thread title too), and comprises all posts in reply to the initial posts. There is a recursiveness in the definition in that it includes all posts in reply to posts already in the thread. A thread tree is formed by the posts in the thread as nodes, and with a directed edge from a post to all direct replies to it. In such a thread tree represented in Figure 1(b), B2 is a direct reply to B1 whereas B4 was posted in reply to B2. In most online discussion forums, the thread structure is apparent due to the restrictions imposed (a reply having to be attached a specific post); if not, the thread structures could be identified heuristically [25].
Threads being composed of posts, an intuitive way to model thread similarity would be to consider a thread as a bag of posts, wherein the scoring function could be posed as an aggregate of the pairwise similarity between posts. How-ever, such a formulation would not be robust to fragmen-tation of information across posts, as seen in Section 1. In short, we would do better by allowing for collections of posts in a one thread to be mapped to collections of posts in an-other, while performing similarity calculations. Thread sub-structures have been exploited for online community search in [28] where four substructures were considered viz., the entire thread , single posts , post-reply pairs and the dialogue (a chain of posts from root to a leaf). The results therein suggest that the dialog substructure was not very useful. Based on such conclusions, we also opt to consider single posts and post-reply pairs as the substructures for consider-ation. For this choice of substructure types, we will show in a later section, that our similarity computation is very efficient. Though we only consider the above two types of
Figure 1: Threads with Post-Reply Substructures. s ubstructures, the framework of our methodology is generic and can accommodate any kinds of substructures.

For a thread represented by nodes as posts and reply-to relations as edges, in addition to the individual posts, the set of substructures would include the pairs indicated by the ovals as shown in Figure 1. Consider the thread in Exam-ple 1(b); the component substructures would then be { B 1 , that such a modeling does not fully solve the information fragmentation issue since it does not allow a set of three posts to match to a single post, even if that happens to be the real nature of fragmentation in a specific case. However, it goes one step forward than matching posts to posts, and could allow for matching the two posts in T2 in Table 1 to map to the single post in T1. We will use post and post-reply substructures (which we refer to, as components, hereon) in estimating similarity between threads in Section 3.
We now describe the techniques that we propose for esti-mating thread similarity; we will first describe a framework and then go on to describe instantiations of the framework that we use in our empirical evaluation. The basic problem is that of estimating the similarity between two threads X and Y . Once we have a means of estimating such thread pairwise similarities, it is easy to build a retrieval engine that finds the top-k similar threads to a given query thread, as seen in Section 2.
We now outline our concerns in modeling the similarity be-tween threads, S ( X, Y ). Firstly , threads in discussion fora, due to intervention by many people, could steer away from the main topic in the course of time and digress to tangential topics; all posts are typically not equally important to the central topic of discourse. Thus, a methodology for estimat-ing thread similarity would have to weigh posts differentially, based on heuristics such as relevance to the central topic(s) or author reputation. Secondly , a thread is a collection of posts, and the number of posts in a thread could vary very widely. For example, a thread in a technical discussion fo-rum could be composed of just 2 posts (e.g., the statement of a problem, followed by a reply with the solution), or could be a long drawn discussion (involving scores of posts) between participants that culminates in finding the solution to the problem posed in the first post. In finding similar threads to a given query thread, one may have to compare threads of widely varying sizes. Due to these properties of thread posts having to be weighted differentially , and threads being composed of widely varying number of posts , we find it very intuitive to decompose the notion of thread pairwise simi-larity into two distinct components; one that measures how well the information in X is subsumed in Y (where Y could contain other extra information), and another that measures how well Y is subsumed in X . Towards this, as detailed in Section 2.2, we decompose threads into a set of potentially overlapping components with an associated weight for each, weights indicating the importance of the component to the thread in consideration.

For a pair of threads, X and Y , our estimate of similarity between them (that we denote by S ( X, Y )) would consider three factors:
X headpost denotes the document formed by collating the title and the first post of the thread X . We use several popular text similarity metrics in estimating Sim ( ., . ).
In estimating how well X is being subsumed by Y , we roughly try to find the best matching component of Y for each component in X . In particular, many of Y  X  X  compo-nents may be left unmatched; this is because while estimat-ing how well X is contained in Y , we would intuitively not want to penalize Y for the extra information that it may contain. To recollect, the components of the thread in Ex-ample 1(b) (which we refer to as X ) are { B 1 , B 2 , B 3 , B 4 , component X i w.r.t Y : where Sim ( ., . ), the similarity between components, de-notes the text similarity and X i denotes the text document formed by putting together the text from posts within X i Essentially, for each component of X , we estimate the max-imal similarity with any component in Y .

As can be seen, B 2 has its representation in 3 of these 7 components of X ; it is easy to see that a post would have representation in as many pairs as it has immediate children (if not a root, it is also represented in a pair with its par-ent). However, we would not like to allow certain posts to influence the P S ( X, Y ) score more than others by design. In particular, we want to choose a set of components of X such that each post is only represented once across the set.
Figure 2 represents a graph with the components of the thread X as nodes; we call it the component graph . We induce an edge between components that share a node. The scores (computed as described above) are shown against the nodes. Now, our problem reduces to finding the maximum weight independent set 7 (MWIS)[27] of such a graph. The non-adjacency property of the MWIS set ensures that no post is counted twice, due to the nature of inducing edges.
To be fair in comparison between components that con-tain single posts and those that contain two, we use an intu-itive weighting scheme where the score of each component is h ttp://en.wikipedia.org/wiki/Maximal independent set w eighed as much as the number of posts it contains. Thus, the MIS shown in white in Figure 2 would have a score of 0 . 5 + 0 . 6 + 0 . 7  X  2 = 2 . 5; for the graph in our example, the white nodes denote the MWIS as well.
 Theorem 3.1. For the component graph of a thread, the MWIS can be computed in polynomial time and always cov-ers each post exactly once.

P roof: In Figure 2, we used nodes as components for the sake of simplicity. Now, we illustrate a new graph where the nodes in the component graph (i.e., components of the thread) are translated to edges; this is given in Figure 3. In this graph, we use two nodes to represent each post p , one node to stand for a post (that we denote as p itself, at the risk of overloading notation), and another one that we use as a pseudo-node, p 0 to avoid self-edges (since we are about to talk about matching and most literature on matching is silent about graphs that contain self-edges). A pair com-ponent { p 1 , p 2 } is represented by the edge p 1  X  p 2 the edge p 1  X  p 0 1 represents the singleton component { p Now, the MWIS problem for component graphs corresponds to the problem of finding the Maximum Weighted Matching (MWM) in the transformed graphs like in Figure 3. This transformation is possible since we have modeled the com-ponent graph as one where each component can at most contain two posts, thanks to our choice of components that can at most span two posts. The MWM problem is known to be solvable in polynomial time [14]; this proves the first part of the theorem.

We now informally clarify as to why the maximum match-ing of the new graph would cover every post exactly once. A post is deemed to be covered in a matching if the matching contains an edge that is incident of a node or the pseudo-node of the post. Matching, by definition, would not allow for covering a node (either of p or p 0 ) multiple times. Our informal proof as to why every post is covered works by contradiction. Let us assume that an MWM does not cover post p . This implies that neither the node p , nor p 0 (the pseudo-node), is included in it. Hence, we can simply add the edge connecting p and p 0 to the matching without vio-lating the property of it being a matching (no node incident on multiple edges). Since we assume (like in most cases in literature) that edge weights are non-negative, this can only improve the weight of the matching, and also includes more nodes. This negates the initial premise that the matching that excluded p was the MWM and completes the proof. Our formulation of P S ( X , Y ) is now the following: where MW IS ( X, Y ) denotes the MWIS for the compo-nent graph constructed from thread X w.r.t thread Y and Score Y ( X i ) is computed as in Equation 1. Normalizing the sum by the number of posts in X is kosher since each post is represented exactly once in one of the terms in the numera-tor (the one corresponding to the component in MW IS ( X, Y ) that contains the post). The only term that has not yet been introduced yet is w X ( X i ); we delve deeper into this weight-ing parameter in the following subsection.

Complexity of finding MWIS(X,Y): As we have al-ready illustrated, the problem of finding MWIS(X,Y) re-duces to finding the Maximum Weighted Matching in our case. MWM is solvable in O ( m number of edges, and n denotes the number of vertices in the transformed graph. However, very fast approximations have been proposed recently [11], thus making the compu-tational expense not of much concern.
Consider a thread about a technical issue (e.g., bluetooth not connecting in symbian ) and two posts from it, one of which talks about the core issue (e.g., bluetooth fix for sym-bian ), whereas the other talks about a tangential issue (e.g., comparsion of iphone with android and symbian ); we would intuitively want to weigh the former higher since it is more central to a topic. This is all the more important for generic posts (e.g., please help me solve the problem ) that would have to be weighed lower to limit their influence. To en-able this sort of weighting, we represent post as a mixture of topics.
Now, P ( X i | topic ) can be interpreted as the likelihood of the topic model generating component X i under the  X  X ag-of-words X  assumption. Similarly, P ( topic | X ) measures the importance of the topic to the thread. We estimate these weights over a specified number of topics (that are maxi-mally represented in the thread) with the number of topics taken as a system parameter.
H aving described our formulation of P S ( X, Y ) (and thus, the analogous P S ( Y, X )), we now describe how we combine the three factors outlined in Section 3.1. Since we are inter-ested in finding similar threads, similarity being quantified by means of containing similar content, we would intuitively prefer finding such Y s (in response to a query thread X ) which have to high values of P S ( X, Y ) and P S ( Y, X ). Either of these being low is a strong indication of the asymmetry, and thus, we choose to give the lower of the two values more preference by using the lowest of the three means (harmonic, geometric and arithmetic) to aggregate these. Our measure of similarity then takes the following form:  X  balances the weight given to the subsumption term against that given to the headpost similarity. It may be noted that though we model similarities using feature sets like in [33], we stick to a symmetric notion of similarity as is popular for similarities between textual entities.
In modeling thread similarities, we have outlined how we exploit substructures and differentially weigh them using topics. To show the incremental utility of substructures and topics, we consider four different techniques:
Since the problem that we are addressing in this paper has not been subject of prior research (Ref. Section 6), we outline a series of intuitive methods to estimate thread sim-ilarities. We outline the techniques under two heads; one in which the query thread summaries or extracts are used as queries to retrieve threads harnessing state-of-the-art thread retrieval models, and another in which the threads are di-rectly compared against each other.
The title and the first post of a thread are important since they are very influential in setting the agenda of the thread; they have been found useful for thread retrieval [2]. We put together the title and the first post of the query thread as a query and employ the Pseudo Cluster Selection (PCS) model for thread retrieval (proposed in [28]) with the system parameter k set to 5.
Summarization techniques [22] process a document and produce a concise version encompassing the most important concepts in the document. We use those to summarize the query thread to a text snippet; the snippet is then passed to the PCS thread retrieval model to retrieve similar threads.
We use two popular summarization techniques. MMR [6] focusses on increased diversity (and thus, reduced redun-dancy) while choosing sentences from the document to add to the summary. Submodular [21] is a recently proposed technique that models the summarization problem as that of maximizing a submodular function under a budget con-straint. We denote these approaches as Q.MMR or Q.SM depending on what summarization technique is used ( Q in-dicates that the query thread alone is summarized).
Here, we outline intuitive techniques (based on current trends in text processing) to find similar threads.
The most widely used model for representing documents in Information Retrieval is that of considering a document as a collection (i.e., a bag) of the component words [1]. In this baseline, we consider a thread as a large document (un-der the large document model [12]) formed by putting to-gether the text from all the component posts. Now, the similarities between threads can be estimated as the simi-larities between such documents as assessed using one of the popular text similarity measures that use the bag of words (BOW) model. We will experiment with measures such as cosine similarity of term frequency vectors, cosine similarity of tf.idf vectors [16] and Jaccard similarity co-efficient[17]. where Sim ( ., . ) stands for the text similarity between the document representations of the threads.
In this method, we consider each thread as a bag of the component posts [12]. Now, to compute thread pairwise sim-ilarity, we aggregate the postwise BOW similarities (between a pair of posts, one from each thread) using the arithmetic mean to arrive at a single measure of thread pair similarity. BOP ( X, Y ) = mean { BOW ( t x , t y ) | t x  X  X, t y  X  Y } (4)
Such aggregation of pair-wise similarities using the arith-metic mean is used in methods such as UPGMA and (Average-Link) Hierarchical Agglomerative Clustering [18].
Since the first post of the thread initiates the thread, it is intuitive for the thread initiator to provide a representative title for it to attract relevant attention from the forum. In many threads like those in support forums, the first post conveys the problem and subsequent posts typically contain solutions or (requests for) more elaborate descriptions of t he problem. The contents of the first post and its title can be thought of setting the agenda of the thread, and thus being more representative of the thread than other posts [2]. Here, we estimate the similarity between threads as a function of the similarity between their titles and the first posts. formed by putting together the title and the first post of the thread X and Y respectively. This denotes a linear combination of BOP and HeadPost.
BOP + HeadP ost ( X, Y ) =  X BOP ( X, Y )+
We set  X  = 0 . 45 since that was empirically found to be the choice yielding the best performance.
The BOP method (Section 4.2.2) may not be very robust to noise. Consider comparing a long thread with a thread containing just two posts, one of which is a noisy post; the noisy post would then affect half of the values on which the arithmetic mean is computed, and thus reduce the thread pairwise similarity considerably. Such considerations lead us to the MAX method that uses the maximum BOW similarity between a pair of posts to estimate similarity.

This method is analogous to the similarity computation used in the popular Single-Link Hierarchical Agglomerative Clustering method [18].
Instead of considering just the max similarity (like we do in MAX above), we now consider the mean of the top-k pairwise similarities.

T op -k ( X, Y ) = mean ( top -k { BOW ( t x , t y ) | t where the top-k (.) method, when applied to a set of scores, returns the subset of top-k values.
In this method, we use a UPGMC [23] style aggregation of pairwise similarities. Unlike UPGMC that computes the similarity between centroids of collections (i.e., threads), we choose to use the similarity between the central posts of the two threads (similar to using the most central entity to rep-resent the collection in K-medoids [26]), centrality estimated by mechanisms such as those outlined in [12]. This leads to: where X central denotes the most central post in X .
Unlike Section 4.1.2 where the query thread alone was summarized, we now summarize each of the threads in the corpus to separate documents. We then retrieve similar documents using traditional IR techniques using the query thread summaries as queries. Based on the summarization technique used, we denote the technique as either All.MMR or All.SM ( All denotes that the query as well as the cor-pora are summarized). For each of the summarization tech-nique, we summarize each corpus thread to between 25 and 50 words and pick the summary size that yields best perfor-mance; it turns out that the best performance was consis-tently achieved for summaries between 30 and 40 words. Table 2: Sample queries.  X  X hreadID X  X s used to iden-t ify the thread in online apple discussion forums
We now describe the empirical evaluation where we com-pare our techniques (listed in Section 3.2) against the base-line techniques detailed in Section 4. We use several stan-dard measures (NDCG, MAP, MRR, Precision) in evalu-ation. We measure NDCG and Precision at various rank cut-offs of the search results (5, 10 and 15 results). We first describe the dataset used followed by describing an exhaus-tive set of results across techniques and performance mea-sures, with all techniques using the tf.idf cosine similarity measure to model the Sim ( ., . ) function. We then analyze the techniques across other popular similarity measures and varying values of algorithm parameters.
 Total number of Threads 147,000 38 3412 A vg #posts per Thread 6 11 12 Avg #words per posts 76 81 91 Avg #words in title 7 6 8 Avg #words in first post 79 78 84 We crawled a dataset consisting of  X  147K threads from Apple Discussion Forums ( https://discussions.apple.com/ ), Apple X  X  official discussion forum for sharing tips and solu-t ions with other users. All the crawled web-pages were pre-processed and posts present in different webpages but be-longing to the same thread were identified. For each thread, the crawl contained information such as title, firstpost, other posts, author information, reply-to link and time stamp.
The queries (threads) for this dataset were generated by identifying threads related to popular issues 8 in iPhone. In total, we generated 38 queries 9 . Some of the sample query threads are listed in Table 2. For each query thread, we query the collection using the keywords in the query thread to identify candidate threads. For a given query thread, we sought the help of human labelers to assign ternary rele-vance judgments to each candidate thread; 2 for high rele-vance , 1 for partial relevance and 0 for irrelevant . We had  X  85 candidate threads per query for the final evaluation and the labeling effort was roughly 60-80 minutes per query thread, leading to a total of 45 hours of human effort spent in labeling. It was often difficult to distinguish between high relevance and partial relevance threads; hence we com-bined these two relevance levels to give a binary labelling ( relevant / irrelevant ), used to evaluate our system. Inter-annotator agreement of 89% and 61% with Kappa coeffi-cient of 0.68 &amp; 0.42 was observed for the binary and ternary relevance judgements respectively.
Table 4 presents the performance of the various tech-niques considered, when the tf.idf cosine similarity is used for estimating text similarity within each of them. Under each measure, we highlight the best performing technique. All the approaches that use thread retrieval techniques are seen to be competitive to each other, with minor varia-tions among performance trends. The better approaches among the ones that compare threads (i.e. BOP, HeadPost and BOP+HeadPost) significantly outperform the thread retrieval baselines. This is expected since thread retrieval techniques work with thread summaries (or excerpts such as first posts) whereas the thread comparison techniques such as BOP, HeadPost and BOP+HeadPost have the entire query thread at their disposal. MAX, Top-K and Central, techniques that use only a few pairwise post similarities are seen to not perform as well as BOP; this is likely to be be-cause of certain generic posts (e.g., help me please ) in the query thread that could spuriously boost the thread similar-ity estimates with those threads that also contain such posts. More significantly, the subsumption based approaches that we propose significantly outperform all the other techniques. Among them, the SUB-STR-TOP that uses both substruc-tures and topics is found to perform the best in seven out of the eight evaluation measures considered.
We considered two other similarity measures in our evalu-ation; the cosine similarity between normalized term-frequency vectors, and the Jaccard similarity co-efficient[17]. The per-formance trends on these similarity measures are largely similar to those observed in Table 4; hence, we plot only the NDCG@10, MAP and MRR values. The performance on the Cosine Similarity and Jaccard measures are given in h ttp://www.iphonefaq.org/faq
Please contact the first or second author to obtain a copy of the dataset with queries and relevance judgements. F igure 4 and 5 respectively. BOW is seen to consistently beat BOP in these charts unlike in Table 4; this is expected since the lack of idf while comparing small text documents (BOP compares posts) could spuriously enhance similarities of dissimilar posts that contain common words. Our tech-niques are seen to be outperforming the others on all the evaluation measures with SUB-STR-TOP being consistently the best among on all the three evaluation measures.
Our technique incorporates the HeadPost-style similarity and the subsumption based assessment to arrive at an overall measure of similarity between threads. Usage of weighted post and post-reply pairs as components in subsumption-based similarity assessment is at the core of the technique that we propose. In this section, we isolate and analyze the benefit of using components in subsumption based similarity assessment independent of other factors such as HeadPost-style similarity and topic-based weighting.

Table 5 compares ranking of some selected candidate threads without the HeadPost i.e., the setting  X  = 1) systems; the starred ones were judged as relevant by human labelers. For these chosen threads, title is indicative of their first post content; hence we have only shown title of the candidate threads. As evident for threads 1 and 2, highly similar ti-tle (and first posts) could mean that the threads are very similar; thus, the top few threads based on HeadPost sim-ilarity end up being relevant to the query thread. It is, hence, natural to expect that HeadPost would perform very well when the top few results alone are considered, such as indicated by NDCG@5 and MAP@5 measures. The effec-tiveness of HeadPost, however, deteriorates when threads with very similar titles and first posts are exhausted. This can be seen for candidates 5, 6 and 7 (that are all relevant) that have minimum title overlap with the query thread, thus falling behind in the ranking. Thus, HeadPost is less effec-tive when more results are considered. This is indicative of the complementary nature of the thread content based similarity assessment and the HeadPost based similarities. Table 5: Ranking of candidate threads for a sample q uery thread with title  X  X im card not installed X . * indicates that the candidate was adjudged relevant by the annotators.
 HeadPost (i.e., SUB-STR with  X  = 0), BOP+HeadPost and SUB-STR. BOP+HeadPost and SUB-STR are able to lever-age the complementarity of the HeadPost and content based similarity aspects to beat approaches that consider only ei-ther of them. While SUB-STR outperforms BOP+HeadPost thereby indicating effectiveness of component based approach. ing the HeadPost similarity, for e.g., it fails for cases when there is high lexical similarity between the candidate thread and the query thread but different aspects are discussed. This is evident from candidate 4 and 8 that are ranked high is discussed. This confirms the complementarity of Head-Post and content based similarities, and underlines that our notion of components is able to achieve significant gains over just considering threads as Bag Of Posts.
Table 6 presents results of randomization tests [29], con-ducted for the most competitive baselines (i.e., BOP, BOP + HeadPost) and the various configurations of our techniques. While our techniques provide results that are statistically significant at a p-value &lt; 0.05 over the baselines, it is in-teresting to note that SUB-STR-TOP X  X  performance is sta-tistically significant on each of MRR, NDCG@10, MAP wrt all the other techniques.

To further verify the utility of the post-reply pair sub-structure, we conducted another statistical significance test where in, apart from single posts, random post pairs were fed to SUB-STR as post-reply pairs; we call it SUB-STR Random The null-hypothesis that SUB-STR and SUB-STR Random are equivalent was rejected easily with a two-sided p-value &lt; 0.015, thus empirically establishing the utility of real post-reply pairs over random post-pairs.
Our approaches have two parameters,  X  , the relative weight-ing between subsumption based similarity and HeadPost similarity and then, the number of topics being considered. In this section, we analyze the sensitivity of our approaches to variations in these parameters and illustrate that our tech-niques are insensitive to variations on these parameters over a large range of their values.
T o enable analyze the effect of  X  independent of the num-ber of topics and usage of post-pairs as components, we plot the performance of SUB across varying values of  X  in Fig-ure 8. When  X  = 0, the approach degenerates to the Head-Post technique, whereas at the other extreme, it discards the title and first post based similarity altogether. More inter-estingly, it fairs better than HeadPost (the left-most point of the curves) for any non-zero value of  X  and is rather in-sensitive to  X  values between 0 . 3 and 0 . 8.

Selecting the right number of topics is an important prob-lem in topic modeling [30]. Nonparametric models like the Chinese Restaurant Process [3] are not scalable to large datasets as can be expected in thread retrieval scenarios. Due to the popularity of generative approaches in topic modeling, we used LDA [4] for representing a component (and hence the entire thread) as mixture of topics. One could potentially use any other method for doing the same. To estimate the topic distribution for each component, we built our LDA model over a collection of 20000 threads with # topics = 100. This is an offline process. Since we use topics to weigh the components, the number of topics in a component is another important parameter for our system. We plot the performance of the SUB-TOP on varying num-ber of topics (restricting the component to belong to at most k topics). Similar to the observations for  X  , the approach is largely insensitive to variations between 2 and 5.
The problem of finding threads similar to a given thread, to the best of our knowledge, has not been considered be-fore, in literature. In this section, we provide a brief review of related literature. Firstly, we describe literature dealing with processing of discussion threads. Secondly, we review prior works focussing on finding similarities between semi-structured content such as XML (we will see shortly that dis-cussion threads may be considered as semi-structured data).
Work on Discussion Threads: A forum thread, unlike text documents, are authored by multiple people and contain discussions on a particular topic. Upto 75% of the links from forums are found to link to noise pages like user pro-files and login pages [35]; this makes traditional web page ranking techniques like PageRank [5] and HITS [20] inap-plicable since such links are not indicative of recommenda-tions. Thread/forum retrieval, the task of identifying rel-evant threads or posts within them in response to a user query (e.g., a phrase or 3-4 words), has been of much in-terest in recent years. One of the early works on forum retrieval attempted to adapt the random surfer model to in-duce links with content information (to content-wise similar pages) to rank forum pages better [35]. An extension to this model that utilizes information about common posters for link induction was presented in [7]. Subsequent works on thread retrieval moved away from the considering threads as collections of pages to considering them as collections of posts. [12] shows that thread retrieval improves by consid-ering only some relevant posts, instead of all the posts in a thread. [28] illustrates that considering the post-reply pair (a post along with a reply to it) substructure in threads im-proves accuracy in thread retrieval. Though the problem that we address is significantly different in that we attempt to rank threads based on similarity to a given thread (which, unlike a user query, is typically larger and has a well-formed structure), we have evaluated our technique against adapta-tions of thread retrieval methods (in Section 5).
Work on XML Similarity: A forum thread may be repre-sented as a tree with posts as nodes where a parent-child re-lationship exists between a post and it X  X  reply. Additionally, siblings (multiple replies to the same post) may be ordered based on the temporal ordering. Each of these nodes (posts) could have attributes like time and poster id. It is intuitive to think of an XML schema to represent such threads due to the hierarchical nature (i.e., the tree). This leads to the question whether we can use XML similarity measures to estimate similarities between threads. However, traditional XML similarity measures make heavy use of the structural similarity [24] whereas we may not want to rely too much on structural similarity in estimating thread similarities. This is so since the content is likely to be more important than structure; the example in Table 1 shows two threads that are very similar despite the structural dissimilarity. Though macro-level structural similarity clearly cannot be used off-the-shelf to estimate thread similarities, certain types of sub-structures (e.g., post-reply pair) have been found to be use-ful in thread processing [28]. In this context, it is useful to note that research on XML similarity has gone beyond plain structural similarity [24] to hybrid methods that make use of semantic similarity of content [31]. A survey of XML sim-ilarity methods appears in [32]. In short, we argue that esti-mating thread similarities is different from estimating simi-larities between XML data since the notion of thread similar-ity relies more on content and certain sub-structures (unlike XML similarity where the similarities between macro-level structures is seen to be useful).
In this paper, we considered the problem of finding sim-ilar discussion forum threads to a query thread. Similar-ity Search on threads has numerous applications such as an enabler to providing links to similar threads in discus-@ 10) and map evaluation measures. sion forums and providing a clustered interface to present results in thread retrieval systems. Our similarity measure revolves around the notion of how well the threads being compared are mutually contained within each other. To es-timate pairwise thread similarities, we model threads as a set of weighted overlapping components, whereby containment is quantified by the lexical similarity between components from the threads under consideration. Specifically, we use the post-reply component that has been found to be useful in discussion forum search, in addition to using individual posts as components; we proved that our similarity compu-tation can run in polynomial time for this choice of com-ponent types. We outlined several intuitive methods that use thread retrieval techniques and direct thread compari-son and evaluated our approaches against them. Through an extensive series of experiments on real world data, we es-tablished the effectiveness of our technique on popular sim-ilarity measures such as NDCG, MAP, Precision and MRR. Specifically, our techniques are seen to outperform the base-lines by approximately 10% on an average on each of the measures.

We have considered two kinds of sub-structures, individual posts and post-pairs, in our technique. Incorporating more sophisticated structural components may enable better qual-ity retrieval possible at the expense of increased similarity computation costs. Devising indexing techniques that could enable looking at just a subset of threads in response to a query thread could enhance performance. We are currently exploring ways to build a parameterized thread similarity measure that could be continuously tuned in response to user feedback. In email discussion groups, a single post may involve replies to multiple previous posts. Identifying such relationships and utilizing them in similarity modeling could potentially improve the retrieval quality.
 We thank Srujana Merugu for discussions that helped us improve the final presentation.
