 Modern information networks, such as social networks, are often characterized with large sizes and dynamic changing structures. To analyze these networks, existing solutions commonly rely on graph sampling techniques to reduce net-work sizes, and then carry out succeeding mining processes. Such a sampling-then-labeling paradigm assumes that the whole network is available for sampling and the sampled net-work is useful for all subsequent tasks (such as network clas-sification). Yet real-world networks are rarely immediately available unless the sampling process progressively crawls every single node and its connections. Meanwhile, without knowing the underlying analytic objective, the sampled net-work can hardly produce quality results. In this paper, we propose an Active Exploration framework for large graphs where the goal is to carry out network sampling and node labeling at the same time. To achieve this goal, we consider a network as a Markov chain and compute its stationary dis-tribution by using supervised random walks. The stationary distribution of the sampled network help identify important nodes to be explored in the next step, and the labeling pro-cess labels the most informative node which in turn strength-ens the sampling process. The mutually and simultaneously enhanced sampling and labeling processes ensure that the final network contains a maximum number of nodes directly related to the underlying mining tasks.
 H.2.8 [ Database Management ]: Database applications  X  Data mining; I.5.1 [ Pattern Recognition ]: Models Active exploration; Supervised sampling; Random walks
Social networks have recently received significant atten-tions because of their increasingly important role in real-life applications. Examples include the friendship network in Facebook , co-author and bibliography networks in DBLP , and the World Wide Web. In a narrow sense, all these net-works can be generalized as large graphs, consisting of mil-lions of nodes and edges. The sheer number of nodes and edges makes analyzing the entire network computationally infeasible. Therefore, graph sampling becomes an important approach that generates a small but representative subgraph to approximate the original large graph. Afterwards, more expensive and complicated analyses can be performed on the sampled graph for various data mining tasks.

Despite the fact that many algorithms exist for graph sam-pling [4, 5], they have focused on generating a uniform ran-dom sample of nodes in the original graph and operating on the entire static graph. In practice, it is often the case that one aims to identify significant nodes ( i.e. , positive in-stances) that may comprise only a small portion of the over-all network. For example, in security surveillance, agents are more interested in suspects and their relationships to other individuals. In disease monitoring, health analysts want to discover affected individuals in a population. Ascertaining the information about individuals, such as their affiliations or infection status, would incur a prohibitive cost in terms of both time and resources. Therefore, it is highly desir-able to minimize the cost of exploring the network which in-cludes important nodes with particular labels. Furthermore, a full network may be too large for its global structure to be accessible at once. Thus, it would be beneficial to de-sign algorithms that start from some specific nodes, explore their neighborhood and acquire information about the net-work when necessary, such as labeling a particular subset of nodes. Such labeling information can be further fed to improve information collection while exploring the network.
Motivated by the above observations, in this paper, we for-mulate a new active exploration problem where the goal is to iteratively sample a representative subgraph, from a large graph with unknown sizes and internal structures, and label a number of important nodes in the subgraph. To tackle this problem, we model a graph as a Markov chain, where nodes are considered as interior states and links are chains between states, and design a supervised random walk to compute the stationary distributions of nodes, which indicate the proba-bility of nodes being positive. Based on this, we utilize two interleaved processes  X  sampling and labeling  X  that closely collaborate towards the common goal of active exploration. At each iteration, the sampling process is guided by a su-pervised random walk that is more likely to visit positive nodes in the neighborhood. The labeling process is there-a fter utilized to query a node X  X  label only when necessary. Only by querying, the true label of a node can be observed, and along with its node features, the labeled node is used to update the stationary distributions of network nodes to benefit supervised sampling at the next iteration. The tight coupling between the two processes allows them to interplay with each other and improve the exploration and retrieval of important nodes on large graphs.

The main contributions of this paper are three-fold: (1) we formulate a new active exploration problem for large graphs; (2) we propose a supervised random walk based so-lution with an optimization objective; (3) we present a novel unified algorithm to perform sampling and labeling at the same time for active exploration. Experiments on real-world networks show that our proposed algorithm achieves higher recall of sampling positive nodes than baseline methods, es-pecially in networks with imbalanced class distributions.
Our active exploration problem is related to network sam-pling and active learning. Graph sampling techniques can be roughly classified into two categories: graph traversals and random walks [4]. Graph traversal methods include Breadth-First Search (BFS), Depth-First Search (DFS), for-est fire, and snowball sampling. Due to the inherent bias of random walks, towards high degree nodes in the graph, approaches have been proposed to correct the bias. For ex-ample, Gjoka et al. [4] proposed a Metropolis-Hastings al-gorithm to collect an unbiased sample of Facebook users. Likewise, H  X  ubler et al. [5] presented a Metropolis algorithm for sampling a representative subgraph, requiring that the sampled graph preserves crucial graph properties of the orig-inal graph. Pfeiffer III et al. [7] tried to acquire instances X  labels and edges through an iterative process to update the classifier and assumed that a node has no other known at-tributes aside from its label. In comparisons, we aim to supervise the sampling process to explore the network by visiting more important nodes belonging to a desired class through the information of nodes X  attributes.

Active learning aims to minimize the required labeled data by selectively choosing the most informative instances to query for their labels. One line of research has focused on using graph-based metrics to define the informativeness of instances and then selecting the instances with the high-est informative scores [2]. Other research has attempted to improve the accuracy of collective classification by combin-ing link information with node-specific features [3, 6]. Prior work in active learning for network data has focused on ac-quiring only the labels of nodes to improve the accuracy of a classifier, with the assumption that the entire network structure is observed. This differs from our problem of ac-tive exploration, in which we only have part of the network observable and we investigate how to actively sample the network and query the labels on a small subset of nodes to retrieve a subgraph that comprise nodes having a particular label as representative as possible.
Let G = ( V ; E ) be an undirected graph where V denotes a set of nodes (or instances) and E denotes a set of edges between nodes. Each node v i  X  V is described by a feature vector x i and a class label y i  X  Y , where Y denotes a set of class labels. Each edge ( v i ; v j )  X  E has a corresponding feature vector r v i ;v j describing relationships between nodes v and v j . In this work, we focus on binary class problems, in which each node v i belongs to a positive class ( y i = +1) or a negative class ( y i =  X  1), and positive nodes comprise a small portion of the overall network. In our problem, we assume that a full graph is too large for its global network structure to be known as a whole. Therefore, only a partial network can be observed.

Given a very small set of labeled nodes, also called seed problem aims to: (1) sample a representative, connected subgraph G  X  from the original large graph G , and (2) dis-cover a number of positive nodes by making as few queries as possible. The generated subgraph G  X  consists of both un-labeled nodes and labeled nodes, that is, G  X  = ( V l  X  X  u
In this setting, there are two iterative processes: one is a sampling process, which is, given a partially observed sub-graph G t = ( E t ; V t ), to decide which node v is sampled next in the neighborhood, and to expand the subgraph to include a new node v , its neighbors N ( v ) and new edges between them. The other is a labeling process, which is, given a set of explored nodes V t , to select a best node v t from V t make a query for its label y t only when necessary. The set of labeled nodes is expanded to include the newly labeled data V l = V l  X  ( v t ; y t ).
One important aim of active exploration is to discover nodes belonging to a desired class. Traditional graph sam-pling techniques cannot be directly applied to achieve this objective, because they assume that the nodes are equally important in the sampling process. Therefore, we propose a novel algorithm to solve the active exploration problem.
Figure 1 illustrates key concepts behind our proposed al-gorithm. Given a partially observed subgraph G t , which is a sampled network at time t , we define two types of nodes: Intra-acquired nodes I intra and Bolder-acquired nodes I bolder Intra-acquired nodes are the nodes that have been explored up to time t , and Bolder-acquired are those directly con-nected to Intra-acquired nodes. In the subgraph, there also exist labeled nodes v  X  L and unlabeled nodes v =  X  L . Intra-acquired and Bolder-acquired nodes can both have labeled and unlabeled nodes.

Our proposed algorithm consists of two interleaved pro-cesses  X  sampling and labeling  X  that iteratively collabo-rate towards the objective of active exploration. At each iteration, the sampling process determines which node from Border-acquired nodes I bolder should be sampled next. The labeling process selects a best node from unlabeled nodes in the current subgraph, and queries its label only when neces-sary. For example, in Figure 1, star node A is selected from Border-acquired nodes to be explored next, and star node B is selected as the best node to be labeled next.

Below, we first formulate supervised random walks as an optimization problem and derive its solution. Based on this, we then discuss selection criteria used for sampling and la-beling. Finally, we present our proposed algorithm for the active exploration problem.
Given an observed subgraph G t , we propose a supervised random walk that combines information from the network Fi gure 1: A partially observed subgraph G t =( V t ; E structure with node and edge features. Motivated by [1], we consider biasing the random walk by assigning each edge with a random walk transition probability (i.e., strength). Therefore, we aim to learn a strength function f w ( v; u ) for each edge ( u; v ), based on the features of nodes u and v , as well as the features of edge ( u; v ). Intuitively, a random walk is more likely to traverse an edge of high strength, and thus the connected node via the path of the strong edge would be more likely visited by the random walk.

Now the task is to learn parameters w of function f w ( v; u ) that assign each edge with a transition probability. To achieve this, we formulate an optimization problem: min where L + and L  X  is a set of labeled nodes with positive la-bel, and negative label, respectively. The stationary distri-bution p of the random walk assigns each node a probability score, which depends on f w ( v; u ) that is parameterized by w . Parameter controls the trade-off between model complex-ity, i.e. , norm of parameter vector w , and two constraints. h (  X  ) is a loss function that assigns a non-negative penalty ac-cording to the difference of the scores p j  X  p i . If p j then h (  X  ) = 0. If p j  X  p i &gt; 0, then h (  X  ) &gt; 0. Thus, the first term indicates that we want the probability scores of nodes in L + to be greater than the scores of nodes in L  X  The second term indicates that nodes having the same class labels should have close probability scores. In the following, we discuss how to solve this optimization problem.
As discussed before, each edge ( u; v ) in a graph has a cor-responding feature vector r u;v that describes nodes u and v (e.g., words in paper titles) and the interaction attributes (e.g., when an edge exists, or how many words in their titles are shared). Thus, for edge ( u; v ) we define the strength function as R u;v = f w ( r u;v ). Function f w parameterized by w takes the edge feature vector r u;v as input and computes the corresponding edge strength R u;v that models the ran-dom walk transition probability. We then build the random walk stochastic transition matrix T r : Here, we assume that there are two virtual absorbing states: one virtual positive node that are connected to all positive nodes, and one virtual negative node that are connected to all negative nodes. Since two virtual absorbing states are only connected with labeled nodes having the same label, we can define the edge strength for virtual absorbing states  X  R s;v . Let f w be a linear function,  X  R s;v can be computed as: where  X  R s;v has the same linear form of f w . Intuitively, be considered as the sum of the information flow originating from the virtual absorbing states to node v  X  X  neighbors via node v on the Markov chain.

The vector p is the stationary distribution of the random walk (also known as Personalized PageRank), and it is the solution to the following eigenvector equation: The above equation establishes relationships between the node probability scores p v  X  p and the parameter w of func-tion f w ( r u;v ) via the random walk transition matrix T r .
Now we can minimize Eq. (1) with respect to parameter vector w . The optimization problem can be solved by deriv-ing the gradient of F ( w ) with respect to w , and then using a gradient based method to find w that minimizes F ( w ). First, we have derivative of F ( w ) with respect to w as ferentiable loss function for h ( : ), for example squared loss. However, it is difficult to compute @p v @ w because we do not have the exact function form of p ( w ). Therefore, we com-pute the derivative of p with respect to the vector w based on Eq. (4). Since T r is a symmetric matrix, we have Therefore, the derivative of p v is given as: We can calculate this equation by iteratively computing p and @p v @ w . Firstly, we compute p v . S econdly, we compute @p v @ w . For each w c  X  w; c = 1 ; : : : ;
To solve Eq. (1), we need to further calculate @T r i;v @ w @ w where f w ( r v;u ) is the edge strength function. We define f to be differentiable, so @f w ( r v;u ) @ w can be easily computed.
We now have an iterative way to compute the derivation @ w . Then we compute the updated parameters using a gradient descent based method to solve the optimization problem and obtain optimal p and w values.
Sampling of our active exploration is to bias towards dis-covering positive nodes. We select a node which is most likely to be positive and then gain its neighbors, including the nodes and edges. Based on supervised random walks, we can construct a Markov chain with probabilities, in which p is the optimal stationary distribution of the network. Each node v i in the network G t is assigned with a probability score p i . Since p i represents the probability of a node v reaching the virtual positive node, which indicates node v probability of being positive, we use it to guide the sampling process in favoring positive nodes. Intuitively, if a node has a higher value of p i , it is more likely to be a positive node be-cause it is closer to the virtual positive node. Therefore, we choose a node v  X  from Border-acquired nodes to be sampled next such that it has the highest value of p v .
Labeling is another important process of active explo-ration, with the aim to identify the label information of im-portant nodes. Given a Markov chain with probabilities, we select the most influential node in the subgraph G t and make a query for its label only when necessary. That is, when an influential node is labeled, the stationary probability p of nodes in the network would be largely affected.

We measure a node X  X  potential informativeness in terms of its ability to influence the network after being labeled. When we select a node for querying, its actual label is unknown. After labeling, we have a newly labeled node, which means that we change a node X  X  state for our Markov chain. Thus we define this difference as the informativeness of a node. Before labeling, we have After labeling, we recompute the Markov chain as Intuitively, we assume that a node X  X  label is more impor-tant when there is a significant difference in the stationary distribution before and after this node is labeled. We use the KL-divergence to measure the difference between two stationary distributions. Thus we have
Before making the query, we do not know the true label of x . However, we can use the estimation of the distribution from which x  X   X  X  true label would be chosen, p v , given by the current Markov chain. Since we have two virtual states +1 and  X  1, we compute the expectation by calculating the estimated KL-divergence for the two classes and take an average weighted by the current stationary distribution p Then we select a node v  X  with the maximum expectation E
KL v and query v
Our active exploration algorithm consists of two inter-leaved processes, as given in Algorithm 1. At time t , we construct a Markov chain based on the subgraph obtained so far, and compute the stationary distribution p of the Markov chain. The sampling process determines which node is sam-pled next using Eq. (11). The labeling process selects the most informative node using Eq. (16) and queries its label when necessary. Only by querying, the true label of a se-lected node can be observed. If no query is issued at time t , the label of the selected node thus remains unknown. Be-cause querying a node X  X  true label incurs a cost, we design a threshold T hr determining whether or not to issue a query at time t . Specifically, our algorithm issues a query when the expectation E KL v is larger than a given threshold T hr . Since E KL v indicates the influence of a selected node on the graph when its actual label is observed, we progressively select to label a node which has a large value of E KL v . Al gorithm 1 Active Exploration on Large Graph 2: while t  X  Budget do 3: Construct the Markov chain for G t by using our opti-4: Select a node i for sampling by using Eq. (11), then 5: Select a node j for labeling by using Eq. (16) under 6: Update G : G ( t +1)  X  G t ; 7: t = t + 1. 8: end while
In this section, we evaluate the performance of our pro-posed algorithm on real-world data. To the best of our knowledge, there is no existing method which addresses ac-tive exploration on graphs. To study the empirical per-formance of our proposed algorithm, called AEGraph, we use three baseline methods for comparison: Random: This method carries out network sampling and labeling in a com-pletely random manner. At each iteration, it randomly se-lects a node to sample, and then randomly selects an unla-beled node to label; Degree: This method uses node degree as the measure to guide the sampling and labeling process. At each iteration, it samples the node with the maximum node degree and determines neighbors of the selected node. The node with the maximum degree is labeled during the labeling process; Unweighted: This is a variant of our pro-posed AEGraph algorithm by removing the weight optimiza-tion module. In other words, we do not consider nodes X  features and there is no strength function for each edge.
Performance Metrics: We use two performance met-rics. One is recall, which is the number of explored positive nodes divided by the number of genuine positive nodes, and the other is network centrality which is to evaluate the qual-ity of the explored network. We focus on network structure, and compare the explored network and the original network with respect to two popular measures: betweenness central-ity and closeness centrality.

Betweenness measures the degree of brokerage for the nodes in a network. It shows how much information is propagated through each node, which is defined as where ( s; t ) is the number of shortest paths between nodes s and t in the graph, and ( s; t | v ) is the number of ( s; t )-paths that go through node v .

Closeness is another popular measure of centrality. It measures how close a node is to all other nodes in the net-work as defined by the shortest path from the source node to the destination node, defined as where d ( v; t ) is the shortest-path distance from node v to node t in the graph.

Parameter Settings: For active exploration, we need to set up several initial nodes to start the exploration process. In our experiments, we randomly choose three connected nodes as an initial network, which contains both positive and negative nodes, e.g. we start with two positive nodes and one negative node that are connected. After that, the AEGraph algorithm iteratively explores the network by car-rying out sampling and labeling simultaneously. The edge strength function Eq. (3) is defined as: f w ( r u;v ) = w the loss function, we use a common squared loss with mar-gin b as: h ( x ) = max { x + b; 0 } 2 . Empirically, we set = 1 and T hr = 0 : 001 and they give good performance.
Results: We use an existing PubMed citation network, which includes 19,717 scientific publications ( i.e. nodes) from the PubMed database pertaining to diabetes, and clas-sifies each of them into one of three classes. We use the three labels to construct three exploration problems: Problem 1: we define  X  X iabetes Mellitus, Experimental X  as positive and others as negative, and explore a network for  X  X iabetes Mellitus, Experimental X ; Problem 2: we define  X  X iabetes Mellitus Type 1 X  as positive and others as negative; and Problem 3: we define  X  X iabetes Mellitus Type 2 X  as posi-tive and others as negative.

In our experiments, we use nodes to construct edge fea-tures. For each edge between two nodes, each representing a paper, the first edge feature is the number of shared words between two papers, defined as: where W denotes the words contained a paper. The second edge feature is defined as the cosine similarity between two papers, where w is the bag-of-word vector to represent each paper using the occurrence of the words in the paper.

Figure 2 reports the recall of positive nodes with respect to different sizes of explored networks. It shows that AE-Graph and Unweighted work better than Degree and Ran-dom, which do not have active sampling strategy for iden-tifying positive nodes. AEGraph outperforms Unweighted in the three figures, because papers in the same class often share common keywords, which are captured by the edge strength function defined in AEGraph. In contrast, Un-weighted discards edge strength and therefore ignores the correlations between papers in the sampling process.
The results in Figures 2(a) and 2(b) show that AEGraph has a larger slope of improvement at the beginning of the sampling process. After 4,000 exploration iterations, the recall values become relatively stable. This demonstrates that AEGraph has good performance when the exploration process starts. It can thus potentially find useful positive nodes with very little cost. The decrease of the slope of improvement, at the later state of the sampling process, is mainly because, in our experiments, the number of positive nodes in the whole networks is fixed. As positive nodes are continuously discovered during the exploration process, the number of remaining undiscovered positive nodes decreases, which makes it more difficult to identify them.

In Figure 3, we also report the recall of positive nodes with respect to different numbers of labeled nodes, which shows the recall values of AEGraph increase quickly during the beginning and middle stage. This is mainly because there are many positive nodes with high clustering coefficients ( i.e. many positive nodes are connected to each other). The dense network structures allow each labeled positive node to help discover more positive nodes in the next iterations. There-fore, our algorithm shows high recall improvement slope.
Figure 4 reports the quality of the sampled network in preserving major structure of the original network. The x -axis in the figure denotes the ratio of the sampled network and the y -axis shows that out of the Top-k ( k =10) nodes with the largest betweenness centrality and closeness cen-trality scores in the original network, how many of them (the percentage) actually appear in the sampled networks. The results clearly show that AEGraph works very well in preserving important network structures.
In this paper, we formulated a new active exploration problem which combines network sampling and active label-ing to generate a small sampled network from a large graph. The proposed active exploration framework combines net-work sampling and node labeling as a mutual beneficial process to explore a network best suitable for the under-lying mining tasks. To achieve this goal, we considered the network structures and node features to guide a supervised sampling and labeling process. Experiments on real-world networks confirmed that our active exploration algorithm significantly outperforms baseline approaches, especially for networks containing very few positive nodes.
 This research is sponsored by an Australian Research Coun-cil (ARC) Future Fellowship under grant No. FT100100971 and an ARC Discovery Project under grant No. DP130102748, as well as a supplementary postgraduate scholarship from CSIRO.
 [1] L. Backstrom and J. Leskovec. Supervised random [2] M. Bilgic and L. Getoor. Effective label acquisition for [3] M. Bilgic, L. Mihalkova, and L. Getoor. Active learning [4] M. Gjoka, M. Kurant, C. Butts, and A. Markopoulou. [5] C. H  X  ubler, H.-P. Kriegel, K. Borgwardt, and [6] A. Kuwadekar and J. Neville. Relational active learning [7] J. Pfeiffer III, J. Neville, and P. Bennett. Active
