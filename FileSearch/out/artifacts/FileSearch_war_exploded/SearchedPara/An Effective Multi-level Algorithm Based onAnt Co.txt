 An important application of graph partitioning is data clustering using a graph model [1], [2]. Given the attributes of the data points in a dataset and the similarity or affinity metric between any two points, the symmetric matrix con-taining similarities between all pairs of points forms a weighted adjacency ma-trix of an undirected graph. Thus the data clustering problem becomes a graph partitioning problem [2]. The min-cut bipartitioning problem is a fundamental partitioning problem and is NP-Complete [3]. It is also NP-Hard to find good approximate solutions for this problem [4]. Because of its importance, the prob-lem has attracted a considerable amount of research interest and a variety of algorithms have been developed over the last thirty years [5],[6]. The survey by Alpert and Kahng [7] provides a detailed description and comparison of vari-ous such schemes which can be classified as move-based approaches, geometric representations , combinatorial formulations, and clustering approaches.
Most existing partitioning algorithms are heuristics in nature and they seek to obtain reasonably good solutions in a reasonable amount of time. Kernighan and Lin (KL) [5] proposed a heuristic algorithm for partitioning graphs. The KL algorithm is an iterative improvement algorithm that consists of making several improvement passes. It starts with an initial bipartitioning and tries to improve it by every pass. A pass consists of the identification of two subsets of vertices, one from each part such that can lead to an improved partition if the vertices in the two subsets switch s ides. Fiduccia and Mattheyses (FM) [6] proposed a fast heuristic algorithm for bisecting a weighted graph by introducing the concept of cell gain into the KL algorithm. These algorithms belong to the class of move-based approaches in which the solution is built iteratively from an initial solution by applying a move or transformation to the current solution. Move-based approaches are the most frequently combined with stochastic hill-descending algorithms such as those based on Simulated Annealing [8], Tabu Search [8],[9], Genetic Algorithms [10], Neural Networks [11], etc., which allow movements towards solutions worse than the current one in order to escape from local minima. For example, Leng and Yu [12],[13] proposed a boundary Tabu Search refinement algorithm that combines an effective Tabu Search strategy with a boundary refinement policy for refining the initial partitioning.
As the problem sizes reach new levels of complexity recently, it is difficult to compute the partitioning directly in the original graph and a new class of graph partitioning algorithms have been developed that are based on the multi-level paradigm. The multi-level graph partitioning schemes consist of three phases [14],[15],[16]. During the coarsening phase , a sequence of successively coarser graph is constructed by colla psing vertex and edge until its size is smaller than a given threshold. The goal of the initial partitioning phase is to compute initial partitioning of the coarsest graph such that the balancing constraint is satis-fied and the partitioning objective is optimized. During the uncoarsening phase , the partitioning of the coarser graph is successively projected back to the next level finer graph and an iterative refinement algorithm is used to optimize the objective function without violating the balancing constraint.

In this paper, we present a multi-level algorithm which integrates an effec-tive matching-based coarsening scheme and a new ACO-based refinement ap-proach. Our work is motivated by the multi-level ant colony algorithm(MACA) of Koro  X  sec who runs basic ant colony algorithm on every level graph in [17] and Karypis who introduces the concept of the graph core for coarsening the graph in [16] and supplies MeTiS [14], distributed as open source software package for partitioning unstructured graphs. We test our algorithm on 18 graphs that are converted from the hypergraphs of the ISPD98 benchmark suite [18]. Our comparative experiments show that our algorithm produces excellent partitions that are better than those produced by MeTiS in a reasonable time.

The rest of the paper is organized as follows. Section 2 provides some defi-nitions and describes the notation that is used throughout the paper. Section 3 briefly describes the motivation beh ind our algorithm. Section 4 presents an effective multi-level ACO refinement algor ithm. Section 5 experimentally eval-uates our algorithm and compares it with MeTiS . Finally, Section 6 provides some concluding remarks and indicates the directions for further research. Agraph G =( V , E ) consists of a set of vertices V and a set of edges E such that each edge is a subset of two vertices in V . Throughout this paper, n and m denote the number of vertices and edges respect ively. The vertices are numbered from 1 to n and each vertex v  X  V has an integer weight S ( v ). The edges are numbered from 1 to m and each edge e  X  E has an integer weight W ( e ). A decomposition of a graph V into two disjoint subsets V 1 and V 2 , such that V 1  X  V 2 = V and V 1  X  V 2 =  X  , is called a bipartitioning of V .Let S ( A )= of a subset A  X  V .Let ID v be denoted as v  X  X  internal degree and is equal to the sum of the edge-weights of the adjacent vertices of v that are in the same side of the partition as v ,and v  X  X  external degree denoted by ED v is equal to the sum of edge-weights of the adjacent vertices of v that are in different sides. The cut of a bipartitioning P = { V 1 , V 2 } is the sum of weights of edges which contain two vertices in V 1 and V 2 respectively. Naturally, vertex v belongs at the boundary if and only if ED v &gt; 0andthe cut of P is also equal to 0.5 Given a balance constraint r ,the min-cut bipartitioning problem seeks a solution ( 1 + r ) S ( V )/2. A bipartitioning is bisection if r is as small as possible. The task of minimizing cut(P) can be considered as the objective and the requirement that solution P will be of the same size can be considered as the constraint . ACO is a novel population-based meta-heuristic framework for solving discrete optimization problems [19],[20]. It is based on the indirect communication among the individuals of a colony of agents, called ants , mediated by trails of a chem-ical substance, called pheromone ,whichreal ants use for communication. It is inspired by the behavior of real ant colonies, in particu lar, by their foraging behavior and their communication through pheromone trails. The pheromone trails are a kind of distributed numeric information which is modified by the ants to reflect their experience accumulated while solving a particular problem. Typically, solution components which are part of better solutions or are used by many ants will receive a higher amount of pheromone and, hence, will more likely be used by the ants in future iterations of the algorithm. The collective behavior that emerges is a form of autocatalytic behavior. The process is thus characterized by a positive feedback loop, where the probability with which ant chooses a solution component increases with the number of ants that previously chose the same solution component.

The main idea of ACO is as follows. Each ant constructs candidate solutions by starting with an empty solution and then iteratively adding solution com-ponents until a complete candidate solution is generated. At every point each ant has to decide which solution component to be added to its current partial solution according to a state transition rule . After the solution construction is completed, the ants give feedback on the solutions they have constructed by depositing pheromone on solution components which they have used in their solution according to a pheromone updating rule .

In [21], Langham and Grant proposed the Ant Foraging Strategy (AFS) for k -way partitioning. The basic idea of the AFS algorithm is very simple: We have k colonies of ants that are competing for food, which in this case represents the vertices of the graph. At the end the ants gather food to their nests, i.e. they partition the graph into k subgraphs. In [17], Koro  X  sec presents the MACA ap-proach that is enhancement of the AFS algorithm with the multi-level paradigm. However, since Koro  X  sec simply runs the AFS algorithm on every level graph G ( V l , E l ), most of computation on the coarser graphs is wasted. Furthermore, MACA comes into collision with the key idea behind the multi-level approach. The multi-level graph partitioning schemes needn X  X  the direct partitioning algo-rithm on G l ( V l , E l )inthe uncoarsening and refinement phase , but the refinement algorithm that improves the quality of the finer graph G l ( V l , E l ) partitioning P the coarser graph G l +1 ( V l +1 , E l +1 ).

In this paper, we present a new multi-level ant colony optimization refinement algorithm(MACOR) that combines the ACO method with a boundary refine-ment policy. It employs ACO in order to select two subsets of vertices V 1 l  X  V 1 l a smaller edge-cut. It has distinguishing features which are different from the MACA algorithm. First, MACA exploits two or more colonies of ants to compete for the vertices of the graph, while MACOR employs one colony of ants to find V l and V partitioning. Second, MACA is a partitioning algorithm while MACOR is a re-finement algorithm. Finally, MACOR is a boundary refinement algorithm whose runtime is significantly smaller than that of a non-boundary refinement algo-rithm, since the vertices moved by MACOR are boundary vertices that straddle two sides of the partition and only the gains of boundary vertices are computed.
In [14], Karypis presents the sorted heavy-edge matching (SHEM) algorithm that identifies and collapses together gro ups of vertices that ar e highly connected. Firstly, SHEM sorts the vertices of the graph ascendingly based on the degree of the vertices. Next, the ver tices are visited in this order and SHEM matches the vertex v with unmatched vertex u such that the weight of the edge W ( v,u )is maximum over all incident edges. In [22] , Sediman introduces the concept of the graph core firstly that the core number of a vertex v is the maximum order of a core that contains that vertex. Vladimir gives an O ( m )-time algorithm for cores decomposition of networks and O ( m  X  log( n ))-time algorithm to compute the core numbering in the context of sum-of-the-ed ge-weights in [23],[24] respectively. In [16], Amine and Karypis introduce the concept of the graph core for coarsening the power-law graphs. In [13], Leng present the core-sorted heavy-edge matching (CSHEM) algorithm that combines the concept of the graph core with the SHEM scheme. Firstly, CSHEM sorts the vertices of the graph descendingly based on the core number of the vertices by the algorit hm in [24]. Next, the vertices are visited in this order and CSHEM matches the vertex v with its unmatched neighboring vertex whose edge-weight is maximum. In case of a tie according to edge-weights, we will prefer the vertex that has the highest core number.
In our multi-level algorithm, we adopt the MACOR algorithm during the re-finement phase , the greedy graph growing partition (GGGP) algorithm [14] dur-ing the initial partitioning phase , an effective matching-based coarsening scheme during the coarsening phase that uses the CSHEM algorithm on the original graph and the SHEM algorithm on the coarser graphs. The pseudocode of our multi-level algorithm is shown in Algorithm 1.
 Algorithm 1 (Our multi-level algorithm) Informally, the MACOR algorithm works as follows: At time zero, an initial-ization phase takes place during which the internal and external degrees of all vertices are computed and initial values for pheromone trail are set on the ver-tices of graph G . In the main loop of MACOR, each ant  X  X  tabu list is emptied and each ant chooses ( V 1 , V 2 ) by repeatedly selecting boundary vertices of each part according to a state transition rule given by Equation(1)(2), moving them into the other part, updating the gains of the remaining vertices and etc. After constructing its solution, each ant also modifies the amount of pheromone on the moved vertices by applying the local updating rule of Equation(3). Once all ants have terminated their solutions, the amount of pheromone on vertices is mod-ified again by applying the global updating rule of Equation(4). The process is iterated until the cycles counter r eaches the maximum number of cycles NC max , or the MACOR algorithm stagnates.

The pseudocode of the MACOR algorithm is shown in Algorithm 2. The cycles counter is denoted by t and Best represents the best partitioning seen so far. The initial values for pheromone trail is denoted by  X  0 =1 / X  ,where  X  is total number of ants .Atcycle t ,let  X  v ( t )bethe pheromone trail on the vertex v and tabu k ( t ) be the tabu list of ant k , Best k ( t ) represents the best partitioning found by ant k and the current partitioning of ant k is denoted by P k ( t ), the ant k also stores the internal and external degrees of all vertices and boundary vertices independently which be denoted as ID k ( t ), ED k ( t )and boundary k ( t ) respectively. Let allowed k ( t ) be denoted as the candidate list which is a list of preferred vertices to be moved by ant k at cycle t and is equal to { V  X  tabu k ( t ) } boundary k ( t ). Algorithm 2 (MACOR)
In the MACOR algorithm, a state transition rule given by Equation(1)(2) is called pseudo-random-proportional rule ,where q is a random number uniformly distributed in [0...1] and q 0 is parameter (0  X  q 0  X  1) which determines the relative importance of exploitation versus exploration. If q  X  q 0 then the best vertex, according to Equation(1), is chosen(exploitation), otherwise a vertex is chosen according to Equation(2)(exploration). To avoid trapping into stagnation behavior , MACOR adjusts dynamically the parameter q 0 based on the solutions similarity between ( V 1 , V 2 ) k and ( V 1 , V 2 ) ( k-1 ) found by ant k and k-1 .In Equation(1)(2),  X  and  X  denote the relative importance of the pheromone trail  X  the vertex v at cycle t and is given by: In Equation(3),  X  is a coefficient and represents the local evaporation of pheromone trail between cycle t and t+1 and the term  X  k v ( t )isgivenby: In Equation(4),  X  is a parameter and represents the global evaporation of pheromone trail between cycle t and t+1 and the term  X  gb v is given by: We use the 18 graphs in our experiments that are converted from the hypergraphs of the ISPD98 benchmark suite [18] and range from 12,752 to 210,613 vertices. Each hyperedge is a subset of two or mor e vertices in hypergraph. We convert hyperedges into edges by the rule that ev ery subset of two vertices in hyperedge can be seemed as edge. We create the ed ge with unit weight if the edge that connects two vertices doesn X  X  exist, else add unit weight to the weight of the edge. Next, we get the weights of vertices from the ISPD98 benchmark. Finally, we store 18 edge-weighted and vertex-weighted graphs in format of MeTiS [14]. The characteristics of these graphs are shown in Table 1.

We implement the MACOR algorithm in ANSI C and integrate it with the leading edge partitioner MeTiS . In the evaluation of our multi-level algorithm, we must make sure that the results produced by our algorithm can be easily com-pared against those produced by MeTiS . We use the same balance constraint r and random seed in every com parison. In the scheme choices of three phases of-fered by MeTiS , we use the SHEM algorithm during the coarsening phase ,the GGGP algorithm during the initial partitioning phase that consistently finds smaller edge-cuts than other algorithms, the boundary KL (BKL) refinement algorithm during the uncoarsening and refinement phase because BKL can pro-duce smaller edge-cuts when coupled with the SHEM algorithm. These measures are sufficient to guarantee that our experimental evaluations are not biased in any way.
 The quality of partitions produced by our algorithm and those produced by MeTiS are evaluated by looking at two different quality measures, which are the minimum cut (MinCut) and the average cut (AveCut). To ensure the sta-tistical significance of our experiment al results, two measures are obtained in twenty runs whose random seed is different to each other. For all experiments, we allow the balance constraint up to 2% deviation from exact bisection by set-ting r to 0.02, i.e., each partition must have between 49% and 51% of the total vertices size. We also set the number of ve rtices of the current level graph as the value of parameter s max . Furthermore, we adopt the experimentally determined optimal set of parameters values for MACOR,  X  =2.0,  X  =1.0,  X  =0.1,  X  =0.1, q =0.9,  X  =0.9, NC max =80,  X  =10.

Table 2 presents min-cut bipartitioning results allowing up to 2% deviation from exact bisection and Fig. 1 illustrates the MinCut and AveCut comparisons of two algorithms on 18 graphs. As expected, our algorithm reduces the AveCut by 5.3% to 63.8% and reaches 41.1% average AveCut improvement. Although our algorithm produces partition whose MinCut is up to 3.6% worse than that of MeTiS on two benchmarks, we still obtain 27.9% average MinCut improvement and between -3.6% and 71.5% improvement in MinCut. All evaluations that twenty runs of two algorithms on 18 graphs are run on an 1800MHz AMD Athlon2200 with 512M memory and can be done in two hours.
 In this paper, we have presented an effective multi-level algorithm based on ACO. The success of our algorithm relie s on exploiting both the ACO method and the concept of the graph core. We obtain excellent bipartitioning results compared with those produced by MeTiS . Although it has the ability to find cuts that are lower than the result of MeTiS in a reasonable time, there are several ways in which this algorithm can be improved. For example, we note that adopting the CSHEM algorithm alone leads to poorer experimental results than the combination of CSHEM with SHEM. We need to find the reason behind it and develop a better matching-based coarsening scheme coupled with MACOR. In the MinCut evaluation of benchmark ibm14 and ibm18, our algorithm is 3.6% worse than MeTiS . Therefore, the second question is to guarantee find good approximate solutions by setting optimal set of parameters values for MACOR. This work was supported by the international cooperation project of Ministry of Science and Technology of PR China, grant No. CB 7-2-01, and by  X  X EC E-Institute: Shanghai High Institutions Grid X  project. Meanwhile, the authors would like to thank professor Karypis of University of Minnesota for supplying source code of MeTiS . The authors also would like to thank Alpert of IBM Austin Research Laboratory for supplying the ISPD98 benchmark suite.
