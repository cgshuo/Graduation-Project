 Deducing trip related information from web-scale datasets has received very large amounts of attention recently. Iden-tifying points of interest (POIs) in geo-tagged photos is one of these problems. The problem can be viewed as a standard clustering problem of partitioning two dimensional objects. In this work, we study spectral clustering which is the first attempt for the POIs identification. However, there is no unified approach to assign the clustering parameters; espe-cially the features of POIs are immensely varying in different metropolitans and locations. To address this, we are intent to study a self-tuning technique which can properly assign the parameters for the clustering needed.

Besides geographical information, web photos inherently store rich information. These information are mutually in-fluenced each others and should be taken into trip related mining tasks. To address this, we study reinforcement which constructs the relationship over multiple sources by iterative learning. At last, we thoroughly demonstrate our findings by web scale datasets collected from Flickr.
 H.3.3 [ Information Search and Retrieval ]: Clustering; H.2.8 [ Database Applications ]: Data Mining, Image Data-bases, Spatial Databases and GIS Algorithms, Experimentation Web Images, Spectral Clustering
In Web 2.0, people are easily to share diverse types of re-sources with other people. Web album is one example that people can share their photos with others. In many web album services, people not only share the photos, but also provide relevant information, such as tags, titles, descrip-tion, taken time, and taken location. Such a large amount of user-contributed data constitutes spatial, temporal, tex-tual, and visual information that can be used for different mining tasks. Deducing trip related information from web photos [3, 5, 7, 12, 13, 14, 19, 20, 21, 22] has been an active topic recently. These works include mapping the photos, identifying places of interest, predicting user travel behav-ior, and itineraries planning.

In this work, we consider the collection of geo-and time-tagged photos on Flickr. The geographical location was automatically captured by location aware camera, mobile phone, or manually input by some tool in Flickr. Also, the taken time was automatically recorded into the photo meta-data. There are currently over 121 million geo-tagged photos on Flickr while there were only 40 million as reported by [13] in 2008. With the advent of more location aware devices, there is no doubt that the number of geo-tagged photos on Flickr and other sites grows rapidly. These involve in sub-stantial research work for web scale mining process.
Our goal in this work is to identify high quality points of interest (POIs) using collections of geo-and time-tagged photos. In particular, point of interest is characterized by activities of photos based on the meta data, such as taken time and geographical location. Some results are recently reported in the community. Kennedy and Naaman [13] iden-tify POIs in a city by applying k -means clustering on geo-tagged photos. The identified POIs are subsequently ranked by textual and visual features. Crandall et al. [7] study a similar problem on finding POIs in web scale datasets. The authors replace k -means with mean shift [6] that is a popu-lar clustering approach in image segmentation. Mean shift clustering requires a density radius for clustering process in-stead of specifying the number of clusters in advance. In [7], the authors set the density radius to 100 meters by sub-jective observation . Nevertheless, we argue that such radius setting should not be set subjectively since the sizes of POIs could be immensely varying in different metropolitans and locations. For instance, the sizes of famous POIs, such as Eiffel Tower , Mus  X  ee du Louvre ,and Arc de Triomphe ,in Paris are immensely varying as plotted in Figure 1. Besides k -means and mean shift clustering, Density-Based Spatial Clustering of Applications with Noise (DBSCAN) [8] is re-cently studied for POIs identification in [14]. However, the parameters in DBSCAN are not nature either. The detail of these clustering approaches are discussed in Section 2.
Our first mission in this work is to remove subjective clus-tering parameters. Given a set of geo-and time-tagged pho-tos, we propose a self-tuning clustering approach that can identify POIs neither knowing (1) the number of POIs, (2) the size of POIs, nor (3) the shape of POIs in advance. Our self-tuning clustering approach is based on spectral clustering [1, 23] which can be viewed as a grouping problem in graph theory. The set of objects in the features space are repre-sented as a weighted undirected graph G ,wherethenodes are the objects and the edges are the relation between pairs of objects. In general, the weight on each edge is represented by the closeness in the features space. Spectral clustering then makes use of the spectrum of the graph similarity. It recursively seeks a bipartition of the dataset (i.e., done by various cut algorithms [1, 2, 4, 23, 24]) until all subsets fulfill the termination criteria (i.e., closeness of a dataset).
However, as discussed in the example (Figure 1), the sizes and densities of POIs are not necessarily identical in a city. There is no unified termination criteria for various POIs in different metropolitans or locations. We observe that the geo-tagged pho tos are Gaussian dist ributed in surrounding areas of an POI; and most likely the bi-partitions of the POI X  X  photos follow the same distribution. Furthermore, we find that the costs to decompose a set of Gaussian dis-tributed photos and its sub-sets are resembling. Therefore, if a cluster and its sub-clusters being created by spectral clus-tering have resembling costs, then the cluster is more likely an POI and should be preserved in the clustering result. The detail of our finding is introduced in Section 3.2.
Besides the parameters issues, the information being taken into the clustering process should be considered thought-fully. Intuitively, web photos inherently have spatial and temporal information, such as taken location and time. Such information should be thoroughly participated in the clus-tering process. In this work, we attempt to integrate these information by reinforcement [15, 9] which is a well accepted method for analyzing richly structured data. In our rein-forcement model, every pair of photos is appraised based on their distance ( spatial ), visit sequence ( temporal ), and re-gion density ( spatial ). The detail of the model is discussed in Section 4.

We summarize our contributions as the following: 1. We attempt to identify POIs using non-subjective pa-2. We connect spatial and temporal information by re-3. We give a complete survey on POIs identification and
The rest of this paper is organized as follows. We first overview and compare the state of the art POIs identifica-tion in Section 2. Next, we discuss spectral clustering and our features similarity measurement in Section 3. Our re-inforcement model is introduced in Section 4. It calculates the pairwise relationship of the photos based on their spatial and temporal features. Our approaches are thoroughly eval-uated in Section 6 using web scale datasets collected from Flickr. Before we conclude our work and discuss possible fu-ture work in Section 8, we also introduce some related work in deducing trip related information in Section 7.
Finding POIs from a collection of geo-tagged photos can be viewed as a clustering problem of identifying highly pho-tographed locations. Kennedy and Naaman [13] use k -means clustering to identify famous locations using collections of geo-tagged photos. k -means clustering aims to partition n objects into k clusters such that each object belongs to the cluster with the nearest mean. The objective function can be formulated in the following equation. where C i is one of the k clusters and  X  i is the centroid of C . Finding the exact solution of k -means is a NP-hard problem. The most common heuristic algorithm uses an interactive refinement technique. First the algorithm ran-domly selects k objects as initial means (i.e., the centroids of k clusters). Then the clustering proceeds by alternating between the following steps. (1) Every object is assigned to the closest mean. (2) Update the mean of each cluster to the centroid of the objects. The clustering process is termi-nated when the means no longer change. However, k -means clustering is a fixed-clustering approach which is problem-atic for POIs identification since the number and sizes of POIs are not known in advance. There is no appropriate rule to decide the value of k for different metropolitans and locations.
 To address the problem of fixed-clustering approaches, Crandall et al. [7] study mean shift clustering [6] that sup-ports arbitrary size and arbitrary number of clusters. Given a kernel function, mean shift locates the maxima by sam-pling discrete data from the function. It is a non-parametric feature-space technique since the clustering result depends on a kernel function other than some parameters. Broadly speaking, the mean shift clustering is an iterative process. At each iteration, every object o moves towards to a mean location where the mean is computed by a kernel function f and the nearby objects o N . The kernel function f K could be a typical Uniform kernel (i.e., f U ( o N  X  o ) = 1) or Gaussian undirected graph with edge weight w ij for edges e ij .For V ,  X  V s  X  V ,let C ( V s ,  X  V s ) be the weight sum of edges be-complexity of the cut techniques are summarized in Table 1.
The cut problem is known to be equivalent to a quadratic discrete optimization problem, Rayleigh problem, where the optimization objective is shown in Equation 3. where y is a vector having n variables, L = W D  X  W is referred as the Laplacian of the graph, W is referred as the weight matrix of the graph, W D is a diagonal matrix with W trix which is set differently according to the cut technique. For example, Q is set to I in ratio cut and is set to W D normalized cut.

In general, Rayleigh X  X  optimization is an NP-hard prob-lem. A common approach to solve such optimization is to relax the integral constraints, such as replacing y i  X  X  X  by y i  X  [  X  b, 1]. In spectral clustering, the relaxation is done by solving an eigenvector problem which is a looser relax-ation than relaxing the integrality requirement. For each cut technique, there is a corresponding eigenvector problem for the relaxation. Due to the page limitation, we only intro-duce the normalized cut in the paper.

Algorithm 1 is a general normalized cut clustering frame-work. After we construct all necessary matrices in the first two steps, the second smallest eigenvalue  X  and the corre-sponding eigenvector V can be computed by Lanczos algo-rithm [10] in step 3. Note that this is the only step to be re-placed if we change the cut technique. Based on the previous study [23], the second smallest eigenvalue  X  can be viewed as the minimum cost to decompose the graph subject to the corresponding objective function. The graph is decomposed into two if the cost  X  is smaller than the threshold  X  .The decomposition is done by picking a value v (e.g., medium) in the corresponding eigenvector V . The elements in the eigenvector are accordingly split into two groups where the first group contains all elements having better value than v and the second group contains the remaining elements. Note that the selection of v is substantial to the decomposi-tion. Thereby, we try multiple v and pick the best one (i.e., maximize the objective function) such that the decomposi-tion is optimized. Even though spectral clustering is widely used and shown good result in many applications, it does not fulfill the requirement of POIs identification due to the subjective threshold  X  .

The input of spectral clustering is a weight matrix W .In general, we can construct W by Euclidean distances of pho-tos. However, we observe that the photos are not uniformly distributed especially inside an POI. Figure 4(a) and 4(b) plot the photos distribution for Eiffel Tower and Mus  X  ee du Algorithm 1 Spectral Clustering by Normalized Cut 1: compute diagonal matrix W D 2: compute Laplacian matrix L by W and W D 3: compute the second smallest eigenvalue  X  and the 4: if the eigenvalue  X  is smaller than threshold  X  then Louvre . In these examples, the photos are more likely in Gaussian distribution.
We denote the distance relationship as D =[ D ij ] n  X  n , where i and j are two different photos. According to above discussion, D ij is defined by a Gaussian equation as shown in Equation 4.
 where  X  2 is the variance of the Gaussian function.
In this section, we demonstrate the parametric issues us-ing a real dataset collected by Flickr API. 1 The dataset is a Paris photos collection having 216,092 geo-tagged photos in total. The detail of our data preparation can be found in Section 6. All figures are generated by our modified ver-sion of Java OpenStreetMap Editor 2 whichisamapeditor for OpenStreetMap 3 writteninJava. Fortheeaseofpre-sentation, we highlight the clusters by different colors such that the size and shape of the clusters are clearly illustrated in the figures. Besides, we also plot the minimum bound-ing rectangles (MBRs) of tourist attractions for reference, where the tourist attractions are collected from the meta-data of OpenStreetMap.

The parameters of k -means, mean shift, and P-DBSCAN are set to their default values as reported in the state-of-the-art [13, 7, 14]. For k -means, we set k to 100. For mean shift, we use Gaussian kernel with  X  2 =0 . 2andset  X  (influential area) to 100 m . Regarding P-DBSCAN, we set  X  (density ratio),  X  (minimum number of objects), and  X  (density ra-dius) to 0.1, 50, and 100 m , respectively. Also, we carefully study the effect of threshold  X  for spectral clustering and set  X  to the best value 0.6. http://www.flickr.com/services/api/ http://josm.openstreetmap.de/ http://www.openstreetmap.org/
The results are shown in Figure 5. Some attraction areas are precisely identified by these clustering approaches. For instance, the world famous POIs Eiffel Tower and Mus  X  ee du Louvre are identified very well by P-DBSCAN in Fig-ure 5(c) and spectral clustering in Figure 5(d), respectively. By carefully tuning these par ameters, the clustering ap-proaches could provide better identification. However, the tuning time might take very long and it is immensely varying in different metropolitans and locations. Besides the default values, we also illustrate other settings in Appendix. In summary, the parameters k (the number of clusters),  X  (in-fluential area),  X  (density radius), and  X  (cut cost threshold) are quite significant and sensitive to the clustering quality of k -means, mean shift, DBSCAN, and spectral clustering, respectively.
To address the parameters issue, we develop a self-tuning technique that can eliminate the effect of threshold  X  from spectral clustering. We attempt to refine spectral clustering since 1) the framework in Algorithm 1 is a hierarchical clus-tering so that each iteration is trackable and 2) the second smallest eigenvalue  X  in each iteration can be viewed as the minimum cost to decompose the cluster. We do not have these properties in other clustering methods.

Consider the examples in Figure 4, the photos are Gaus-sian distributed in the POIs. Based on this observation, we create two sets of POI photos that are Gaussian distributed as shown in Figure 6(a). The photos are partitioned into 4 groups by spectral clustering and the cuts are shown by the solid and dash lines. We also show the hierarchical view of spectral clustering procedures in Figure 6(b).

Roughly speaking, the cut in spectral clustering seeks a balance decomposition subject to an objective function. Sup-pose that the solid line is the 1 st cut in spectral clustering and the cut cost  X  is 0.55 and  X  is set to 0.5, the clustering procedure is terminated and perfectly identifies two POIs A and B . However, if  X  is set to 0.85, then spectral clustering will execute two more cuts such that the photos are decom-posed into 4 small clusters, A 1 , A 2 , B 1 ,and B 2 .Itisobvious that  X  is substantial to spectral clustering. Besides, the cost to decompose A (  X  =0.8) is similar to the cost to decom-pose A 1 (  X  =0.85), but different from the cost to decompose A  X  B (  X  =0.55). It is because A and A 1 share resembling distribution. We summarize this finding in Observation 1.
Observation 1. The cut costs of a cluster and its sub-clusters are resembling if the cluster is dense and Gaussian distributed.

We verify the observation using our Paris photos collec-tion. Figure 7(a) shows the cut cost  X  at different levels of spectral clustering. The cut cost  X  becomes very high ( &gt; 1.8) and resembling after level 21. Also the costs drop a little bit after the peak due to the fluctuation of the cut costs of small clusters.
According to Observation 1, a cluster should be preserved in the result if the sub-clusters have resembling cut costs. Therefore, we propose a method to measure the costs sim-ilarity such that we can preserve the high quality clusters in the result. We first define a new concept, cut path p ,in Definition 1.

Definition 1 (Cut Path). Given the hierarchical struc-ture of a spectral clustering, a cut path of a cluster C is the path from C toaleafcluster.

The cost of a cut path cost ( p ) is the average cut cost among all nodes in the path which is denoted by Equation 5.
In Figure 6, the cost of cut path ( A, A 1 ) is 0.825. Based on the cost of cut path, we define cut costs similarity in Definition 2.

Definition 2 (Cut Costs Similarity). Given the hi-erarchical structure of a spectral clustering, the similarity of acluster C is defined in where P is the set of cut paths of cluster C and  X  C is the mean cost of all cut paths in P .
 In Figure 6, there are two paths from cluster A to the leave clusters which include p 1 (= A  X  A 1 )and p 2 (= A  X  A 2 0 . 8375. According to the equation in Definition 2, the cut cost similarity sim ( A ) is 0.9875.

The value of the cut cost similarity sim ( C ) can be viewed as the robustness of all sub-clusters under cluster C .Our strategy is to group the sub-clusters if sim ( C ) is strong. We plot the average value of sim at different levels in Figure 7(b) as a reference. We observe that the similarity value drops after a local peak and the end levels are not stable due to the fluctuation of the cut costs of small clusters. Therefore, we identify the clusters using a top-down execution paradigm. Given a spectral clustering execution tree, a node is chosen
The level is counted from top to bottom. as a cluster result C if sim ( C ) reaches to a good local peak. In this work, we simply set the local peak to the maximum value of the largest decreasing path. In other words, we group highly resembling sub-clusters into a larger cluster based on the similarity of their cut costs. The effectiveness of the self-tuning approach is shown in Section 6.
So far, the clustering approaches only take distance infor-mation into account. Apparently, there is room for improve-ment as web photos constitute rich information in spatial, temporal, textual, and visual aspects. However, there is no explicit guideline to connect these aspects. For POIs iden-tification, the most common method is to perform cluster-ing based on distance and subsequently refine the result by the information from other aspects [7, 13]. In other word, therearequitealotaffluentinformationnotinvolvedin the clustering process. This may affect the clustering qual-ity as some trip related information (i.e., density and visit sequence are inherently recorded in web photos) are not in-volved in the clustering process. To be motivated by the discussion, we intend to study reinforcement which is a well accepted method for analyzing richly structured data [9, 25].
Consider the example in Figure 8, where we have 16 pho-tos in the system. In Figure 8(a), we might form 2 clusters where the left cluster (in gray color) contains 12 photos and the right cluster (in white color) contains 4 photos if we only take pairwise distances information into account. If the temporal information are taken into account, we might have better result as demonstrated in Figure 8(b). The la-bels of the photos are represented the movement sequence of the photographers. For instance, the movement sequence of the photograph a is represented by four objects a 1 , a 2 and a 4 . By considering both pairwise distances and move-ment sequences, we might group left 8 photos into one clus-ter and group the remaining photos into another cluster as illustrated in Figure 8(b).
In this work, we only attempt to connect spatial and tem-poral information by reinforcement. This can be viewed as a study to demonstrate the effectiveness of reinforcement for POIs identification. We add a note that other information (e.g., textual and visual) can be integrated well by rein-forcement after specific study. In the following, we study the pairwise relationship construction for density (spatial) and visit sequence (temporal). The reinforcement algorithm will be discussed in next section.
 Density Relationship Construction. As a crucial part in the density based clustering approaches (e.g., DBSCAN), density relationship should be thoughtfully considered in the reinforcement. Similar to DBSCAN, the density of a photo is counted by the number of surrounding photos within a range, which is indicated by e i . We denote the density re-lationship as E =[ E ij ] n  X  n .Thevalueof E ij represents the density similarity of two photos i and j .Theformal definition is shown in Equation 7.
 we multiply it by the sum of their densities due to Observa-tion 2 which is well accepted in density based clustering.
Observation 2. Highly dense regions are more substan-tial to POIs identification.
 Visit Sequence Relationship Construction. Besides spa-tial aspect, the movement sequences of photographers are also substantial to POIs identification as discussed in the previous example in Figure 8. We denote the visit sequence relationship as S =[ S ij ] n  X  n . In general, two consecutive photos are probably taken at the same POI. According to this, we define the visit sequence relationship between two photosinEquation8.
 where seq ( i, j ) is the number of hops between photos i and j in the movement sequence of a photographer. seq ( i, j ) is set to zero if the photos i and j are not taken by the same photographer. For instance, consider the example in Figure 8, seq ( c 1 ,c 3 )and seq ( a 1 ,b 1 ) are set to 2 and zero, respectively.
Heretofore, we obtain three feature matrices, D (distance based), E (density based), and S (visit sequence based), from both spatial and temporal aspects. In this section, we describe our iterative reinforcement model that constructs a robust structure between these information. Intuitively, these features mutually affect each others in the POIs iden-tification. Updating the values of one feature will surely influence the values of other features. Consequently, we ap-ply an iterative strategy for obtaining the robust features relationship. More importantly, clustering photos using the robust features potentially provides us better results.
Our reinforcement model is shown in Equation 9. It is a simple iterative model and can easily bias to a feature by tuning  X  ,  X  ,and  X  accordingly. Initially, we set D (0) , E and S (0) to the original feature matrices respectively. D E ( n ) ,and S ( n ) indicate the D , E ,and S matrices at n iteration.  X 
By iteratively executing Equation 9, the mutual influence of the features which include distance, density, and visit se-quence is explored by the reinforcement model. Also, we normalize D ( n ) , E ( n ) ,and S ( n ) at the end of each iteration to ensure reasonable reinforcements between them. After D ( n ) is convergent to D ( n  X  1) , we terminate the iterative process and normalize the values of D ( n ) by a Gaussian function as suggested in [25]. The effect of  X  ,  X  ,and  X  will be evaluated in the experiments section.
In this section, we discuss the implementation detail for our approach. Obviously, constructing a complete feature matrix for web scale datasets is too expensive. For instance, we have 216,092 geo-tagged photos in our Paris collection. For the distance matrix D , it will consume approximate 173.96 GB space if all photo pairs are stored into D .It is definitely too large for present computer systems. To address the space issues, we first group the photos by Hilbert curve grouping [16] based on their distances, where the Hilbert curve grouping is a popular multi-dimensional indexing techniques and well accepted by spatial databases. The grouping is shown to preserve very good quality to the original datasets, especially in low dimensionality. In this work, we carefully tune Hilbert curve parameters (e.g., max-imum number of objects and grouping size) such that the photos collections are reduced to  X  10% of their original size.

After grouping, the group feature relationship X G IJ is set to the average feature relationship of the photos across the groups. This is shown in Equation 10.
 where I and J are indicated two Hilbert curve groups of photos, respectively.

Furthermore, we should keep only substantial relations in the feature matrices. There are two reasons: 1) photos are generally grouped together into the cluster with strongest features similarity and 2) the weak features do not involve into the reinforcement process too much after normalization. One of the methods is to remove a distance relationship D from D G if D G IJ is larger than 200m. The computational cost can be further reduced without much information loss.
In this section, we present several experiments to demon-strate the superiority of our findings. We first introduce our data preparation and evaluation measure in Section 6.1 and Section 6.2, respectively. We compare our self-tuning spec-tral clustering to other clustering approaches in Section 6.3. At last, we investigate the effect of parameters  X  ,  X  ,and  X  for our reinforcement model.
We collect three photos collections using Flickr API. 5 .For each photo collection, we fetch all geo-tagged photos using the city name as the search key by the Flickr API. We filter out the photos that are not located in the city (by latitude and longitude boundary as shown in Table 2) or have identi-cal geo-location. The statistics of our photos collections are summarized in Table 2. We extract a set of tourist attractions in the metadata of OpenStreetMap. The total number of attractions for each city is shown in Table 2. The tourist attractions are repre-sented by MBRs as shown in Figure 5. In the evaluation, http://www.flickr.com/services/api/ the MBRs are enlarged to 150% of their original size since photos might be taken in the surrounding area as well. An POI is perfectly identified by a cluster if and only if all pho-tos in the MBR are grouped into the cluster and their sizes are identical. In the evaluation, we filter out the clusters not intersect to any MBRs.

In IR community, a common way to interpretation of clus-tering is to view it as a series of decisions, one for each of the N ( N  X  1) / 2 pairs of photos in the collection. We clas-sify these decisions by a simple binary classification. For instance, a true positive decision assigns two photos in the same MBR to the same cluster C and TP is indicated the total number of true positive decisions. We summarize other types of decisions in Table 3.

In [17], the precision P ,recall R ,and F  X  measure are defined by Equation 11. In this paper, we use F 1 measure as our evaluation measure. A large value of F 1 measure indicates a better clustering.
 P = TP Self-tuning Spectral Clustering. In this sub-section, we demonstrate the superiority of our self-tuning technique by Flickr photos collections. Figure 9 shows the effect of the parameter values to the corresponding clustering approach. For each experiment, we vary a single parameter for a clus-tering approach, while setting the others to their default values as listed in Table 4.

We first compare our self-tuning technique to k -means, mean-shift, P-DBSCAN, and spectral clustering using Paris photo collection. According to results in Figure 9, it is obvi-ous that our self-tuning technique is superior. Without any parameters tuning, its F 1 measure is only worse than one case in mean shift (  X  = 100 m ) and one case in P-DBSCAN (  X  =50 m ). Surprisingly, our self-tuning method is better than spectral clustering for all tested parameters. It is be-cause our approach can self-identify the dense region by the cut costs similarity instead of using a global threshold  X  .
Note that our self-tuning approach might be worse than k -means, mean shift, P-DBSCAN, or spectral clustering in other parameter settings. However, as demonstrated by Fig-ure 9, the self-tuning approach provides an acceptable qual-ity without manual tuning. As a reference, we illustrate the snapshot of the self-tuning approach in Figure 10. This is not only valuable to the clustering problem (i.e., POIs iden-tification) but also to other trip related mining problems. (c) varying  X  , P-DBSCAN
Figure 11 compares the F 1 measures between spectral clustering and self-tuning approach for Hong Kong and New York photos collections. Again, our self-tuning technique outperforms spectral clustering for all tested  X  values. The F 1 measures of Hong Kong collection are very small since the tourist attractions provided by OpenStreetMap are very limited and the sizes of attractions are also very small. Reinforcement Model. In Equation 9, we can see that  X  ,  X  ,  X  are three important parameters in the reinforcement model which control the degree of propagation. In this sub-section, we evaluate their influences to the self-tuning per-formance. Due to space limitations, we fix  X  to 0.9 as the distance information involve the most in the clustering pro-cess. The effect of other parameters (  X  and  X  )isshownin Figure 12. While setting  X  =0 . 9,  X  =0 . 9, and  X  =0 . 7, the reinforcement model is 27% better than the distance based (a) spectral clustering, HK Figure 11: Comparison between spectral clustering and self-tuning for Hong Kong and New York photos collections model. Besides, our self-tuning technique is only 4 . 3% (in average) worse than the corresponding best spectral cluster-ing result (by tuning  X  ) among all testings 6 .Itshowsthe robustness of our self-tuning technique. Figure 12: F 1 vs.  X  and  X  (setting  X  =0 . 9 )onParis photo collection
Rattenbury et al. [21] is a prior work to discover the names of events and landmarks using geo-tagged and tex-tual data of photos from Flickr. Kennedy and Naaman [13] and Crandall et al. [7] study a problem which can identify landmarks by applying clustering algorithms on geo-tagged photos. The result in [7] is used in many subsequent works being discussed shortly. The authors also propose a clas-sification method to identify the taken location of a photo based on both visual and textual features. However, these works do not consider temporal information to improve the clustering quality.

Besides identifying POIs, there are many recent works that deduce trip information from web photos. Clements et al. [5] study a work that predicts travel interests for a user who had rich travel data in the past. Popescu and Grefen-stette [19] attempt to deduce the typical visit duration for tourist attractions. The authors first study a heuristic fil-tering procedures to clean the photo collection. Then, an
The details are omitted due to the space limitations. external coverage geographical gazetteer is used to map be-tween the photos and POIs based on their textual and geo-tagged information. Other trip related information are ex-tracted based on their result, such as maximum, minimum, and average duration time of the POIs. A similar work [20] is proposed by the same authors that extracts some day-tour information, such as people visit interests, visit time, and duration time. Their solution first identifies POIs by an external knowledge base, Wikipedia and then extracts the day-tour information based on the identified POIs.
Automatic tour planning from geo-tagged photos has been recently studied in [3, 12]. Choudhury et al. [3] constructs intra-city travel itineraries using spatio-temporal data from Flickr. Their solution first identifies a set of time paths and each time path is a sequence of POIs traversed by a user. The duration time and the transit time of POIs are subsequently extracted by the time paths. Antourage [12] automatically constructs tourist trip from the geo-tagged photos, by specifying a start location and maximum distance covered by the trip. A hexagonal grid overlay is used to map landmarks of a city. Each hexagonal cell is weighted by the number of photos taken inside. Therefore, the tour planning problem in their work becomes an optimization problem that maximizes the total weight of the selected cells where the total distance cannot exceed the given constraint.
Regarding self-tuning clustering, there are some results reported in machine learning [18, 26]. These methods aim at finding the best k in k -means by statistical test or eigen-vectors analysis. These algorithms typically determine all clusters at once which is different from our hierarchical clus-tering technique.
In this paper, we study spectral clustering which is the first attempt for POIs identification. In addition, we deeply compare the state of the art approaches and figure out the parametric issues. Therefore, we analyze spectral cluster-ing procedures and propose a self-tuning approach based on the cut cost similarity so that the effect of the parame-ters is eliminated from spectral clustering. Furthermore, we study reinforcement that connects information from diverse aspects by iterative learning.

In the future works, we are intent to study the POIs rank-ing problems. In general, the POIs are ranked by simple ob-servation (i.e., number of photos, number of users, or size). There is so much room for improvement. In addition, iden-tifying POIs can be viewed as a module of other trip related mining tasks. We will investigate how these related tasks can get improved by our clustering framework. Moreover, we are highly interested in comparing different self-tuning clustering techniques for web scale photos collections. This work was partially sponsored by Grant RG066/09-10S/11R/ GZG/FST from University of Macau Research Committee. [1] T. B  X  uhler and M. Hein. Spectral clustering based on [2] J. Cheeger. A lower bound for the smallest eigenvalue [3] M. D. Choudhury, M. Feldman, S. Amer-Yahia, [4] F.R.K.Chung.Spectralgraphtheory. Regional [5] M. Clements, P. Serdyukov, A. P. de Vries, and [6] D. Comaniciu and P. Meer. Mean shift: A robust [7] D. J. Crandall, L. Backstrom, D. P. Huttenlocher, and [8] M. Ester, H.-P. Kriegel, J. Sander, and X. Xu. A [9] L. Getoor. Link mining: a new data mining challenge. [10] G. H. Golub and C. F. Van Loan. Matrix [11] D. S. Hochbaum. Polynomial time algorithms for ratio [12] S. Jain, S. Seufert, and S. J. Bedathur. Antourage: [13] L. S. Kennedy and M. Naaman. Generating diverse [14] S. Kisilevich, F. Mansmann, and D. A. Keim.
 [15] J. M. Kleinberg. Authoritative sources in a [16] J. K. Lawder and P. J. H. King. Querying [17] C. D. Manning, P. Raghavan, and H. Schtze.
 [18] D. Pelleg and A. W. Moore. X-means: Extending [19] A. Popescu and G. Grefenstette. Deducing trip related [20] A. Popescu, G. Grefenstette, and P.-A. Mo  X  ellic. [21] T. Rattenbury, N. Good, and M. Naaman. Towards [22] P. Serdyukov, V. Murdock, and R. van Zwol. Placing [23] J. Shi and J. Malik. Normalized cuts and image [24] S. Wang and J. M. Siskind. Image segmentation with [25] X.-J. Wang, W.-Y. Ma, L. Z. 0001, and X. Li. [26] L. Zelnik-Manor and P. Perona. Self-tuning spectral (e)  X  =10 m ,P-DBSCAN (f)  X  = 200 m ,P-DBSCAN (g)  X  =1 . 0, normalized cut (h)  X  =0 . 5, normalized cut Figure 13: Effect of other parameters in k -means, mean shift, P-DBSCAN, and normalized cut clus-tering
