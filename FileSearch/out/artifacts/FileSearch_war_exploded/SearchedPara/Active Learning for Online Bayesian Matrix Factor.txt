 The problem of large-scale online matrix completion is ad-dressed via a Bayesian approach. The proposed method learns a factor analysis (FA) model for large matrices, based on a small number of observed matrix elements, and lever-ages the statistical model to actively select which new matrix entries/observations would be most informative if they could be acquired, to improve the model; the model inference and active learning are performed in an online setting. In the context of online learning, a greedy, fast and provably near-optimal algorithm is employed to sequentially maximize the mutual information between past and future observations, taking advantage of submodularity properties. Addition-ally, a simpler procedure, which directly uses the posterior parameters learned by the Bayesian approach, is shown to achieve slightly lower estimation quality, with far less com-putational effort. Inference is performed using a computa-tionally efficient online variational Bayes (VB) procedure. Competitive results are obtained in a very large collabo-rative filtering problem, namely the Yahoo! Music ratings dataset.
 H.2.8 [ Database management ]: Database applications-Data mining Online learning, matrix factorization
There has been growing interest in the problem of matrix completion, i.e. , estimating unknown elements in matrices based on a subset of observed entries (with the observed entries usually assumed observed at random). Concretely, only the values of the elements x ij at locations given by the set  X  = { ( i, j ): x ij is observed } . In a collaborative filter-ing/recommender system setting, N u is often the number of users, while N v is the number of items.

The matrix X can be very large; also, the number of ob-servations can be very small relative to N u  X  N v ,butlarge in absolute terms, which poses computational and statistical challenges. For example, in the Netflix challenge [2] there are N u = 480189 users, N v = 17770 movies and the number of observed ratings is |  X  | = 100480507, which corresponds to less than 1.18 percent of X . More recently, the even larger Yahoo! Music dataset [4] has been released. It con-tains |  X  | = 262810175 ratings (integers between 0 and 100) pertaining to N u = 1000990 users and N v = 624961 items (music tracks, albums, artists and genres).

For many such real problems, the matrices of interest can be assumed to be approximately low-rank, in which case it is appropriate to consider a matrix factorization model of the form advances in matrix completion theory [3] provide bounds on the number of observations needed for successfully re-covering low-rank matrices using convex optimization (and assuming the observed entries are selected at random). How-ever, existing convex optimization algorithms are incapable of handling the very large matrix sizes typical of real collab-orative filtering problems.

Hence, the most popular approaches for large-scale prob-lems are based on solving (1), or some variant thereof, for U , V through minimization of the 2 norm of the residual computed for the known locations  X  (see, e.g. , [7]). Reg-ularization is often employed, typically using the 2 or  X  norm [9] of the parameters (these regularizers are imposed on the columns of U and V ;the 1 or 0 sparseness regular-izers characteristic of convex optimization solutions [3] are not used here, because we explicitly set the rank to K ,with K N u ,N v ). Due to memory and speed considerations, the minimization is often performed through stochastic gra-dient descent. Stochastic gradient descent is an online learn-ing method, in which the training examples are presented sequentially, obviating the need to store the entire dataset in memory. Typically, the order of presentation is random. Stochastic gradient descent has also been used successfully in other large-scale problems such as image inpainting [11] and topic modeling [5]. It enjoys local convergence guaran-tees, as shown in [17].

Alternative methods for solving (1) include Bayesian prob-abilistic matrix factorization [16], which achieves state-of-the-art performance on the Netflix dataset. However, since this is a batch method, scalability to even larger problems such as the Yahoo! Music dataset is less straightforward than with stochastic gradient descent. Additionally, [16] uses Markov chain Monte Carlo inference, for which it is harder to assess convergence.

In our work, we propose a statistical factor analysis (FA) model that extends the basic low-rank factorization shown in (1), and we develop an associated variational Bayesian (VB) [1] online inference algorithm, which incorporates the scala-bility of stochastic gradient descent while providing approxi-mate posterior estimates of all model parameters. Other VB methods that have been applied to collaborative filtering, such as [10, 14], are based on batch learning. Our method is an online extension of the batch VB principal component analysis (PCA) approach proposed in [14, 15, 12].
Another contribution of our paper is that we leverage the statistical model to actively select the best subset of obser-vations at each step of the online learning process, instead of assuming that the training examples follow a random order of presentation as in stochastic gradient descent. This active learning procedure is motivated by the fact that each mea-surement x ij is often obtained sequentially and requires user interaction, which may be expensive and time-consuming. Therefore, by prioritizing the most informative users and items, we can potentially guide the data acquisition process in a more efficient way. In general, the problem of finding the m best locations of X to measure is NP-complete. We avoid this difficulty by developing two types of greedy algorithms: (i) a near-optimal method based on [8], relying on the sub-modularity properties of mutual information; (ii) a simpler algorithm based on the estimated variance of the user and item factors returned by the VB inference. A non-Bayesian active algorithm is also used for comparison.

The remainder of the paper is organized as follows. Sec-tion 2 describes our proposed factor analysis model, as well as the associated VB inference. This section also briefly dis-cusses how to incorporate time information in the model. The active learning algorithms are presented in Section 3, which also contains an explanation of the submodularity property. Experimental results with online VB and active learning on the Yahoo! Music dataset are shown in Section 4. Concluding remarks are presented in Section 5.
The matrix factorization problem expressed in (1) can be cast as factor analysis (FA) with x ij = u T i v j + ij ,where is a residual term, assumed small, u i  X  R K is the i th col-umn of U ,and v j  X  R K is the j th column of V . Previous work on collaborative filtering [7, 6] shows that it is advan-tageous to also incorporate user and item biases, leading to the complete FA model The scalars  X  i and  X  j allow the model to adapt to phenom-ena such as anomalous user behavior or different item popu-larities. A particular item j may be popular among all users, and therefore this item does not provide as much informa-tion about individual preferences, which are captured in the feature vectors u i ; if this is the case for item j , the model should infer the associated  X  j as being large. Likewise, a given individual i may rate all items as being poor/good, and this individual therefore does not provide as useful in-formation about the features of the items v j ;inthiscase  X  i would be correspondingly small/large. In the statisti-cal literature, these inferred biases are often called random effects.

Defining the independent priors completes the model specification. In the above expressions, InvGamma denotes the inverse gamma distribution, and the U and V , respectively. For simplicity, we set the value of  X  , although it would also be possible to define a corresponding inverse gamma prior. Note that we choose a unit-variance prior for u i ; otherwise, the product of the variances of and v j would not be identifiable.

Our goal is to estimate posteriors for the model parame-ters  X  = {  X  ,  X  , U , V ,  X  } given the observed data D = ( i, j )  X   X  } at locations  X .
The posterior distribution of the model parameters satis-fies while the negative logarithm of the posterior is, up to con-stant terms, given by where u k and v k are the k th rows of U and V ,respec-tively. Hence, the statistical model is closely related to optimization-based approaches with 2 regularization on the model components [7]. An important advantage of the sta-tistical model is that it does not require cross-validation for regularization terms (Lagrange multipliers in optimization-based methods). Moreover, it yields an approximate poste-rior on all model parameters, instead of maximum aposte-riori (MAP) point estimates.

As the true posterior p (  X  ,  X  , U , V ,  X  | D ) is not tractable, we employ a variational approximation [1]. In general, as-sume that  X  denotes parameters to be inferred, and D rep-resents observed data. The likelihood of the data is p ( D and the prior on the parameters is p (  X  ). It follows that the posterior on the model parameters is
Let q (  X  ;  X  ) be a parametric distribution with parameters  X  , and consider the variational expression Minimization of F (  X  ) in (13) with respect to  X  corresponds to minimization of the Kullback-Leibler divergence between q (  X  ;  X  ) and the true posterior p (  X  | D ).

For the parametric distribution, we use a fully factorized  X  are selected in the conjugate-exponential family, then we obtain closed-form expressions for the  X  i , based on gradient descent of F (  X  i ) [1]. This procedure is guaranteed to con-verge to a local optimum, and it extends MAP estimation of  X  , yielding an approximate posterior.

The term variational comes from calculus of variations; we choose a class Q such that q (  X  ;  X  )  X  X  andthenmini-mize a functional over Q . As discussed above, minimization of the functional F (  X  ) is equivalent to minimization of the Kullback-Leibler (KL) divergence between q and the true p (  X  | D ). We choose Q to be fully factorized distributions; for the problem at hand, we write q (  X  ,  X  , U , V ,  X  ;  X  )= where
The posterior parameters are  X  = {{  X   X  i } , {  X   X  j } , {  X 
Defining the cost function C KL F (  X  ), we build on [14], where the gradients w.r.t. the components of  X  are derived. We depart from [14] in the following way: the dataset D is partitioned into smaller subsets S ( t ) , called mini-batches , which change for each iteration t . The standard stochastic gradient approach [9] is to draw each mini-batch S ( t ) uni-formly at random from the (fixed) training set D . Then, in the sums over i and j below, only the indices in the cur-rent S ( t ) are considered. All mini-batches have the same size m , which is chosen to yield the best trade-off between computational speed and robustness to local minima.
Example components of the gradient so computed are
Once we have the gradients, it is then possible to sequen-tially update  X  u ki , X  v kj , X   X  i and  X   X  j according to where  X  ( t ) is the learning step for the gradient descent proce-dure. The learning step follows the schedule  X  ( t ) =  X  X  where  X   X  (0 . 5 , 1] controls the rate of decay of the contribu-tion of old mini-batches.

The variances can be updated according to  X  Finally, the parameters of q (  X  2 k )obey
Each rating in the Yahoo! Music dataset includes a time stamp. This is the case both for the training set and for each ( i, j ) pair in the test set, which means that it is possible to improve the predictions by incorporating temporal informa-tion into the factor model. The following approach is based on [6], who obtained one of the best single-model results on the Yahoo! dataset. The FA model in (2) is changed to x where t m ,t h and t d are indices over the total number of minutes, hours and days in the dataset, respectively. The large number of user/time factors (particularly u it m ) vectors poses computational challenges; however, each user only has ratings for very few minutes on average, which makes the storage requirements feasible.

The priors for the new factors that depend on t d are and similarly for those factors that depend on t h and t m We apply the VB algorithm to (34) in much the same way as in the original formulation, with new variational posteri-Writing out (34) as a sum of cross-products, we have x which means that the gradient updates for  X  i , X  j , u i and are changed only slightly from Section 2.1. For example, defining e we now have
The gradients for the new time-related factors are com-puted similarly to those for u i and v j .
In the following, we address the problem of finding the best mini-batch S ( t ) = { ( i, j ): x ij is observed at step t size m , thereby extending standard gradient descent. In-stead of having a fixed training set D as before, the goal is now to incrementally construct a set of observed loca-tions A by starting with A =  X  and sequentially appending A X  X  X  X  ( t ) . Define V = { ( i, j ) ,  X  i,j } to be the set of all entries of X , whether observed or not. Hence, V\A is the set of missing locations. It is known [8] that finding the best S ( t ) among V\A is, in general, an NP-hard problem.
The active selection of mini-batches S ( t ) may be consti-tuted in at least two forms. In one case, all of the (sparsely sampled) data may be available apriori , and rather than selecting S ( t ) from that data in a random manner, one may use active learning to select the most-informative samples. In a second case, we may actually seek entries (acquire the database) actively and sequentially, based on the results of active learning. This may be done by asking selected cus-tomers to rate selected items. There may be other settings that are a combination of the above two cases.

We wish to leverage the current posterior estimate of  X  for selecting the m most informative observations in V\A . One possible strategy is to select the observations x ij for which the posterior implies the greatest variance, and thus uncertainty. This method, while simple, does not account for correlations between similar samples, i.e. ,thefactthat many high variance users/items may be very similar to each other, and therefore redundant. Moreover, selecting high variance users/items tends to unduly emphasize outliers.
A better alternative is to select the observations that are most informative about V\A . Toward this end, we build on [8], where near-optimal, polynomial-time greedy algorithms are proposed. These algorithms exploit submodularity prop-erties of mutual information, under a Gaussian process for-mulation.
In general, assume that each observation x s  X  R ,where s is an index over elements of V , has an associated covariate r s  X  R d .Wewishtoimposethat,when r s and r s are similar, then x s and x s are correlated. If we have a vector x =( x 1 ,...,x N ) drawn from a Gaussian process (GP), with covariance function given by a Mercer kernel K (  X  ,  X  ), then x  X  X  (  X  ,  X  ), with Afrequentchoicefor K (  X  ,  X  ) is the radial basis function (RBF) kernel A key property of GPs is that, given a vector x =( x 1 ,...,x with associated covariates ( r 1 ,..., r N ), one may readily draw x +1 for any new covariate r N +1 . This property facilitates active learning in the following way. Assume that the set V defines a set of covariates and the associated data vector is x  X  GP(  X  ,  X  VV ). The active learning problem now be-comes one of choosing a subset A X  X  of covariates at which to sample data.

To connect the GP formulation with our matrix factor-ization problem, it is appropriate to consider the user and item factors, u i and v j , as covariates. The ratings x ij considered to be drawn from a GP where the covariance ma-trix is related to the u i and v j covariates, which are latent , i.e. , non-observed. The online VB procedure is employed to provide approximate posteriors for these latent covariates.
Accordingly, we wish to define kernels which make use of the estimated posterior distributions q ( u i )and q ( natural choice consists of the symmetrized KL divergence kernel, which for user factors u i is defined as K ( D
KL ( q ( u i ) || q ( u i )) =  X  where  X  i diag(  X  2 u 1 i ,..., X  2 u Ki ). Item factors v similarly, substituting v j for u i and  X  j diag(  X  2 v 1 for  X  i . Note that the matrices  X  i and  X  j are diagonal, which simplifies inversions and determinants. An attractive feature of the symmetrized KL divergence kernel is the ab-sence of tuning parameters such as kernel bandwidths.
An appropriate criterion for choosing A is to seek to maxi-mize the mutual information MI( A ) I( A ; V\A )= h ( x A h ( x A | x V\A ), with h (  X  ) denoting the differential entropy. Given A , it is straightforward to compute MI( A ) within the GP model. However, when |A| &gt; 1 the computation to select the set A that maximizes this mutual information is NP-complete. This difficulty can be overcome by using the fact that MI( A )is submodular .
 Definition of submodularity [13]: A set function F : A X  F ( A ) is submodular if, for all A X  X  X  X  ,and y  X  V\ B , it holds that F ( A X  y )  X  F ( A )  X  F ( B X  y )  X  F (
Intuitively, F is submodular if it has a  X  X iminishing re-turns X  property, i.e. , a new datum y has more impact when the set A is smaller. The following theorem ensures that choosing A to maximize F ( A ) can be done in a near-optimal manner by a greedy algorithm.

Theorem [13]: Let F be a monotone submodular set function over a finite ground set V with F (  X  )=0. Let A be the set of the first m elements chosen to maximize F ( by a greedy algorithm, and let OPT= max A X  X  ; |A| = m F ( Then
Importantly, the mutual information MI( A ) I( A ; V\A ) is submodular [8], and MI(  X  )=0. There are conditions of practical relevance for which the mutual information metric is a monotone function, namely when |A| is small relative to the total number of entries that may searched over, which is certainly the case for the massive matrices of interest here; see [8] for a related discussion, although that work did not consider the matrix-completion problem. Therefore, there exist polynomial-time greedy algorithms for finding A such that for some small . The mutual information metric discourages acquisition of samples that are anticipated to be correlated to each other based upon the GP covariance K (  X  ,  X  ).
Specifically, Algorithm 1 in [8] finds candidate y  X  X \A to maximize the increase in mutual information where  X  A denotes V\ ( A X  y ). The conditional distributions needed to compute the conditional differential entropies in (46) are readily manifested by leveraging the ability of GP to compute such densities, as discussed above. This prop-erty is a key reason for imposing the GP representation for matrix values, with associated covariates defined by the in-ferred feature vectors u i and v j . In the GP model, the maximization is done by computing Equation (47) is a ratio of conditional covariances of the properties can be computed without first measuring x at location y .

Unfortunately, the aforementioned algorithm requires O ( |V\A| 4 operations, which is indeed polynomial-time but infeasible in many situations of interest. For instance, in the case of the Yahoo! dataset, we have N u  X  10 6 and N v  X  6  X  10 5 leading to |V\A|  X  6  X  10 11 . This problem can be mitigated by employing Algorithm 3 in [8] which uses local kernels , i.e. , only a small neighborhood around each y is consid-ered. More specifically, in expression (46) the approximation but the k -nearest neighbors of y from A . This approxima-to a maximum of k  X  k , at a small cost in the objective func-tion [8]. The overall complexity is thus reduced to O ( |V\A| which nevertheless remains impractical for our purposes.
Our proposed approach circumvents these limitations by exploiting the structure of the matrix factorization prob-lem. Instead of exploring all possible pairs ( i, j ), of which there are approximately N u N v , our main idea is to choose the best row and the best column separately . The resulting computations are now O ( N u )+ O ( N v ), which is feasible.
The objective function for rows of X is, therefore, where  X  A u denotes { 1 ,...,N u }\ ( A u  X  y ), with y the candi-date i th row. An identical objective function is defined for the columns of X , substituting j for i and v for u .
The goal is now to find optimum sets S u = { i 1 ,...,i m S v = { j 1 ,...,j m } sorted by  X  i and  X  j , respectively. Then, we form S based on S u and S v . There are multiple possi-bilities for combining S u and S v . We choose to construct S = { ( i 1 ,j 1 ) ,..., ( i m ,j m ) } . We then sequentially build A X  X  X  X  , as prescribed initially. The entire procedure is summarized in Algorithm 1, which we call VB-MI. Algorithm 1 Active learning for matrix factorization with VB-MI 1: Initialize q ( U ):  X ,  X  ,and q ( V ):  X ,  X  2: Initialize active set A X  X  X  3: while Stopping criterion is not met do 4: for i  X  X  1 ,...,N u }\{ i : i  X  X } do 5: Compute  X  i based on  X ,  X , A and kernel K 6: end for 7: Repeat steps 4 X 6 for j  X  X  1 ,...,N v }\{ j : j  X  X } , 8: S u = { i 1 ,...,i m } sorted in descending order of  X  9: S v = { j 1 ,...,j m } sorted in descending order of  X  10: S = { ( i 1 ,j 1 ) ,..., ( i m ,j m ) } 11: Collect observations x ij ,  X  ( i, j )  X  X  12: A X  X  X  X  13: Update  X ,  X  and  X ,  X  via online VB 14: end while
A simpler alternative to the aforementioned submodular-ity approach consists of finding S u and S v by sorting the user and item factors in decreasing order of the posterior trace-covariance, given by tr(  X  i )andtr(  X  j ), respectively. The mini-batch S is then constructed as in VB-MI and ap-pended to A . The resulting algorithm makes direct use of q ( u i )and q ( v j ) without necessitating any GP formulation or kernel, and the only overhead over online VB consists of two sorting steps per mini-batch, which is negligible.
As discussed above, a limitation of this approach is that it does not account for correlations, and therefore many high-variance items may also have high correlation, and conse-quently it is redundant to sample all of them. Neverthe-less, as discussed below, this has been found to work well in practice, at low computational expense, for the large-scale examples considered. This approach explicitly exploits the products (parameter variance) from the VB analysis, and it is referred to below as VB-Variance.
For the purpose of comparison, and also to isolate the con-tribution of the active learning method towards performance from that of the VB algorithm, we have implemented an active learning method capable of utilizing products from a non-Bayesian matrix analysis; in that analysis, the RMSE is dient descent (we learn a  X  X oint X  estimate for these parame-ters, rather than estimating a full posterior). This is distinct from the VB method, which minimizes the KL divergence between q (  X  ,  X  , U , V ,  X  ;  X  ) and the posterior p ( w.r.t. the posterior parameters  X  .

We follow an approach similar to [9] and estimate the pa-rameters  X  i , X  j , u i , v j by solving the optimization problem where the constraint on the norms of the factors u i , v j equivalent to max-norm regularization of U T V , controlled by the parameter B . The max-norm of a matrix Z is defined as Z max =max {| z ij |} . The bias vectors  X  and  X  are regularized in the same way.

Problem (49) can be solved by slightly modifying the sim-ple projected gradient method proposed in [9] to take  X  i and  X  j into account. Given one training example x ij ,the following updates are computed for u i and v j : with P B (  X  ) a projection operator defined by
Note how the gradient term  X  ( x ij  X   X  i  X   X  j  X  u T i v is also present in the VB update equation (20), where it is weighted by the noise level 1 / X  2 and combined with other terms that depend on the model variances. The updates for  X  i and  X  j are given by which also resemble the corresponding VB updates.
To perform active learning with this model, the user and item submodular objective functions  X  i and  X  j are computed as before, with the difference that we can no longer use the KL divergence kernel. Instead, we define standard RBF ker-nels where  X  2 is the bandwidth parameter. Typically,  X  2 is set via cross-validation (which we emphasize is avoided with the VB inference).
We first present results for the online VB algorithm ap-plied to the dataset of Yahoo! Music ratings provided for the KDD Cup 2011 challenge [4]. The purpose of this analysis is to examine the performance of the online VB solution on such large-scale data. In that analysis the mini-batches in the online analysis are selected randomly, as done in most previous related research (although virtually none of that work was done with a VB analysis). We then compare re-sults in which the mini-batches for the online method are selected randomly versus actively, via the method discussed in Section 3. We consider the FA model and online VB inference from Section 2.1 on the Yahoo! Music dataset. We set the num-ber of factors to K = 20 and choose the learning step size to follow the rule  X  ( t ) =  X  X  ( t  X  1) ,with  X  (0) =2 . 5  X  =0 . 9. The mini-batch size was set to m = |S ( t ) | = 100000. Hyperparameter values were set to  X  2 =10  X  6 ,  X  2  X  =  X  1,  X  1 =  X  2 =10  X  6 , which yield standard  X  X lat X  (nearly non-informative) priors. The variational posterior parameters were initialized at random, and the algorithm was executed for 40 epochs. Each epoch consists of a full pass through the training set, i.e. , approximately 252 million ratings. A further 6 million ratings is used for validation (these val-idation ratings were supplied to the users), while the test set consists of 4 million ratings whose scores were withheld at the time of the KDD Cup 2011 challenge. These scores Figure 1: RMSE on the validation set for 40 epochs. Each epoch is a full pass over approximately 252M ratings. The total running time is slightly less than 10 hours. have been released after the competition. The performance measure is the root mean square error (RMSE) over the test dataset, defined as RMSE = 1 | where the posterior means of  X  are used to provide point estimates.

We show the RMSE and computation time per epoch on both the validation and test sets for our VB method in Table 4.1. For comparison, we also show the RMSE and time achieved by the baseline model supplied by Yahoo!, which models the ratings as with a i , b j and c learned by standard stochastic gradient de-scent. The performance gain over the baseline is over 10%, which is considered quite significant and places the method near the top 100 in the competition. Note that the initial-ization is random and that there are no separate learning steps for the various parameters. Moreover, this is a single model (the best competitors employed a blend of dozens of different models) and it has relatively few parameters.
The convergence behavior is illustrated in Figure 4.1. While it takes slightly less than 10 hours to execute 40 epochs (we have used MATLAB code, non-optimized, on a 2.4 GHz CPU), it is apparent that the algorithm has essentially con-verged after approximately 25 epochs.
 Additionally, we have implemented the time-dependent FA model described in Section 2.2, and achieved a further RMSE drop from 25.94 to 24.8. The most demanding as-pect of the time-dependent model is the large number of user/minute factors u t m ,since t m  X  X  0 ,... 5726101 } ,al-though the fact that, on average, each user only has ratings for104 minutes in the dataset makes the storage require-ments feasible. Currently, we are pursuing the implementa-tion of active learning methods with this model (with time dependence), which will likely require extensive paralleliza-tion in order to overcome the large computational require-ments.
We have applied the three active learning procedures de-scribed in Section 3 (VB-MI, VB-Variance and Non-Bayesian) to the Yahoo! Music problem, and compared to online VB with random sampling. In this analysis we consider the model in (2), without time dependence. These experiments differ from using online VB as in Section 4.1. Here we syn-thesize all ratings, in order to be able to measure any desired x , and not limit ourselves to the fixed training dataset D supplied by Yahoo!. We first use online VB to learn a factor model of the form (2) using all available data from D ,as in Section 4.1. The resulting posterior parameters  X   X  are withheld. Then, we discard the data supplied by Yahoo! and use the posterior mean components of  X   X  to synthesize any observation x ij on demand, by computing We report the RMSE on a test set of size 4 million, sepa-rately drawn at random from the factor model and withheld from the algorithms.

In all cases, the algorithms were initialized with one single mini-batch of online VB and then executed for 40 epochs. The mini-batch size is m = 100000. In this setting, since there no longer exists a dataset D over which to perform a full pass, we define an epoch as the number of steps necessary for the set A tohavethesamesizeas D . Once this happens, we reset A X  X  X  and begin a new epoch. The factor model parameters carry over between successive epochs.

As seen in Figure 2, all active methods outperform random sampling by a significant margin. The differences in RMSE between the three active methods are less pronounced, with the mutual-information-based VB-MI algorithm slightly out-performing the others. It is particularly notable that the simpler VB-Variance method is competitive with the sub-modularity based approaches, at a fraction of the compu-tational cost. The running times, per epoch, of VB-MI, Non-Bayesian and VB-Variance are 5100 seconds, 4700 sec-onds and 1100 seconds, respectively. Thus, the VB-Variance method is only slightly more demanding than online VB.
Figure 3 shows histograms of the (scalar) components of the user and item factors, respectively u i and v j . The model assigns low variance to most components, which can be seen as an indicator of good model fit.

The plot in Figure 3 depicts the trace-covariance of the item factors v j , as returned by the online VB algorithm. There exists a clear relationship with the number of item ratings. As anticipated, rarely rated items tend to have higher variance, although a few spikes in the variance for relatively highly rated items may warrant further investiga-tion. We do not show an equivalent plot for user factors due to the fact that the relationship with the number of ratings is much less evident.
We have presented an online variational Bayesian approach to the problem of large-scale matrix completion, with ap-plications in collaborative filtering. Unlike standard matrix factorization approaches, the developed statistical model en-ables sequential selection of near-optimal subsets of users Figure 2: RMSE over 40 epochs. The VB-MI al-gorithm is based on mutual information with the KL divergence kernel, VB-Variance is based on sam-pling the users and items with highest variance and the Non-Bayesian method uses mutual information with the RBF kernel. and items through active learning. This can be done using efficient greedy algorithms which rely on submodularity.
We have also described an alternative method based di-rectly on the inferred variance of the factors, which relaxes the near-optimality guarantees and requires much lower com-putational effort, at the cost of a small performance penalty. The aforementioned methods have been compared with ran-dom sampling and with a non-Bayesian submodularity-based algorithm.

We have demonstrated the proposed framework using the challenging Yahoo! Music dataset, with promising results. Notably, all proposed active learning algorithms outperform random sampling. Comparison with the non-Bayesian method shows comparable performance. However, the RBF ker-nel in non-Bayesian method requires tuning of the band-width parameter, while the KL divergence kernel used in the Bayesian approaches is parameter-free. Moreover, the computational overhead of the submodular methods far out-weighs the difference in computations between the Bayesian and non-Bayesian algorithms. Importantly, neither the KL divergence kernel nor the fast variance-based active learn-ing algorithm would be possible without the (approximate) posterior estimate provided by the Bayesian method.
Future research will focus on incorporating temporal in-formation into the active learning algorithms. This should be possible via developments in parallel computation. Figure 3: Histograms of the variance of u ki (top) and v kj (bottom), where i, j, k are indices over users, items and factors, respectively. Shown in logarith-mic scale. The majority of the components have low variance.
 The research reported here was supported by ARO, NGA, ONR and DARPA (MSEE program). [1] H. Attias. A variational bayesian framework for [2] R. Bell and Y. Koren. Lessons from the Netflix prize [3] E. Cand` es and T. Tao. The power of convex [4] G. Dror, N. Koenigstein, Y. Koren, and M. Weimer. Figure 4: Trace of covariance of v j (item factors) as a function of number of ratings. Rarely rated items tend to have higher variance.
 [5] M. Hoffman, D. Blei, and F. Bach. Online learning for [6] M. Jahrer and A. T  X  oscher. Collaborative filtering [7] Y. Koren. Factorization meets the neighborhood: a [8] A. Krause, A. Singh, and C. Guestrin. Near-optimal [9] J. Lee, B. Recht, R. Salakhutdinov, N. Srebro, and [10] Y. Lim and Y. Teh. Variational bayesian approach to [11] J. Mairal, F. Bach, J. Ponce, and G. Sapiro. Online [12] S. Nakajima and M. Sugiyama. Implicit regularization [13] G. Nemhauser, L. Wolsey, and M. Fisher. An analysis [14] T. Raiko, A. Ilin, and J. Karhunen. Principal [15] T. Raiko, H. Valpola, M. Harva, and J. Karhunen. [16] R. Salakhutdinov and A. Mnih. Bayesian probabilistic [17] M. Sato. Online model selection based on the
