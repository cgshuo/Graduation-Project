 The exponential growth of spam emails in recent years is a fact of life. Internet subscrib-ers world-wide are unwittingly paying an estimated  X   X  10 billion a year in connection costs just to receive "junk" emails, according to a study undertaken for the European Commis-sion [1]. Though there is no universal definition of spam, unwanted and unsolicited and the cost in human time and attention of dismissing unwanted messages [2]. 
Combating spam is a difficult job contrast to the spamming. The simplest and most common approaches are to use filters that screen messages based upon the presence of common words or phrases common to junk e-mail. Other simplistic approaches include blacklisting (automatic rejection of messages received from the addresses of known spammers) and whitelisting (automatic acceptance of message received from known and trusted correspondents). The major flaw in the first two approaches is that it relies upon complacence by the spammers by assuming that they are not likely to change (or forge) their identities or to alter the style and vocabulary of their sales pitches. Whitel-or expected correspondent with a heretofore unknown address, such as correspondence from a long-lost friend, or a purchase confirmation pertaining to a transaction with an online retailer. A detail explanation of these techniques is given in [3]. 
Machine learning algorithms namely Na X ve Bayesian classifier, Decision Tree in-duction and Support Vector Machines based on keywords or tokens extracted from the email X  X  Subject , Content-Type Header and Message Body have been used success-the spammer changing themselves in the ways that are very difficult to model by simple keywords or tokens [6]. The tactics the spammer uses follows patterns and these behavioral patterns can be modeled to combat spam. Actually the more they try modeling spammer behavioral patterns instead of vocabulary as features for spam email categorization. The three well-kno wn machine learning algorithms Na X ve Bayes, DTI and SVMs are experimented to model common spammer patterns, as these classifiers has already shown great performance in different research in spam classifier [3], [4], [5]. Among the classifiers, Na X ve Bayes shows its best suitability. 
The paper is organized as follows: section 2 discusses the three machine learning algorithms (MLAs); section 3 presents common spammer patterns, email corpus, feature construction and evaluation measures; section 4 discusses the experimental results; and finally section 5 concludes the paper. The success of machine learning algorithms in text categorization (TC) has led re-searchers to investigate learning algorithms for filtering spam emails [3], [4], [5]. This paper studies the following three machine learning algorithms to model spammer tricks and techniques. 2.1 Na X ve Bayesian Classifier Bayesian classifiers are based on Bayes X  theorem. For a training e-mail E, the classifier 
Assuming class conditional independence, that is, the probability of each word in an e-mail is independent of the word X  X  context and its position in the e-mail, appearing in the category 
The category maximizing () E C P 2.2 Decision Tree Induction the tree and a path will be traced starting the r oot to a leaf node that identifies the class prediction for that sample. The commonly used rule learning algorithms J48, ID3 and C4.5 are based on decision trees [5]. The advantage offered by the decision trees is that it can easily be converted to decision rules and comprehended even by a na X ve user [7]. 2.3 Support Vector Machines Support vector machines (SVM) are a collection of supervised learning methods that can be applied to classification or regression [4], [7], [8]. Viewing input data as two sets of vectors in a d -dimensional space, an SVM constructs a separating hyperplane in that space, one which maximizes the margin between the two data sets. 
Suppose we are given some training data, a set of points of the form: x is a d -dimensional real vector. We want to find the maximum-margin hyperplane which divides the points having 1 = i c from those having 1  X  = i c . Any hyperplane can be written as the set of points X satisfying where  X  denotes the dot product. The vector W is a normal vector: it is perpendicular to the hyperplane. The parameter W b / determines the offset of the hyperplane from the origin along the normal vector W . 
We want to choose the W and b to maximize the margin, or distance between the These hyperplanes can be described by the equations: 
Note that if the training data are linearly separable, we can select the two hyper-maximize their instance. By using geometry, we find the distance between these two hyperplanes is W / 2 , so we want to minimize W . 
As we also have to prevent data points falling into the margin, we add the follow-ing constraint: for each i either We can put this together to get the optimization problem: 
Minimize (in b W , ) W subject to (for any n i ,..., 1 = ) () 1  X   X   X  b x W c People who create spams are called spammers. Electronic mails (emails) are the most common playground of many spammers in the Internet. A tremendous effort has al-ready been invested by the researchers on anti-spamming techniques [4], [5], [12], [13]. 3.1 Spammer Behavioral Patterns The keyword-based statistical analyzers mostly depend on tokenization of the email content and extracting feature from tokenized keywords to model spammer behavior. Tokenization can be misguided in many several ways as today X  X  email supports char-acter sets other than ASCII, non-text att achments and bodies with multiple parts. For example, the following HTML tricks can be used to do this: &gt;R&lt;!--free --&gt;A 
Thus above nonsense HTML tags only split the special word  X  X iagra X  and disguise the tokenizer though it would be shown as  X  X ET VIAGRA X  to email client. 
Even a word can be replaced with characters of other languages or like same charac-ter. For example,  X  X 1DEO X  can be send instead of  X  X IDEO X  and  X  X  X nt X st X  X  X  instead of  X  X antastic X . A combination of special characters can used to produce alphabetical characters. For example, char  X  X  X  can be represented as the combination of right grouping or clustering of these techniques is given Table 1 for quick review. 
Table 1 has 30 different tricks and one can easily verify that HTML based tactics cover most of them (70%). It can also be shown that 75% of Cascading Style Sheet (CSS) and 50% of Image-based tricks are also covered by HTML-based tactics. It is overlap with HTML/CSS based tactics. 
In this study, a model has been developed exploiting machine learning algorithms to capture common spammer patterns instead of keyword analysis. The 21 handy content-type headers and body shown in Table 2 simulate all possible common spammer tricks. These features have also been optimized in their capability of classi-both in spam and non-spam emails. For example, whether a content-type header ap-peared within the message headers or wh ether the content type had been set to  X  X ext/html X  is a common feature of spam, as our investigation revealed. The corpus that has been used in our experimentation, we observed that 98% spam emails include this feature. Similarly, color element (both CSS and HTML format) is also a frequent feature of spam emails. Colorful images those are generally included in the email for X-rated and unwanted internet marketing groups send to catch users X  attention. The use of color elements in non-spam mails is very low. We found that that 56% spam emails contain color elements whereas it exists only for 10% non-spam emails. The inclusion of this feature in our classification has improved performance considerably, significant features of recent spams. 3.2 Email Corpus Classification based spam filtering systems have two major drawbacks. Firstly, building email is textually misleading due to obfuscation as we explained earlier. This remains a continuous challenge for spam filtering techniques. Secondly, most training models of the classifier have limitations on their operations [12]. Classifiers often produce uncor-related training errors due to the dimension of feature space; a dissimilar output space is generated for changing feature space from small dimension to complex high dimension. 
In this work a corpus of 1,000 emails received over a period of several months is used for experimentation. The distribution of both spam and non-spam emails in this collection is equal. The equal distribution is preferred to make the classifier to elimi-spam and 500 is non-spam. The collection of this corpus is selected over a time and latest trend in spamming is kept in mind. Also the author X  X  experience with spam research and statistical selection methodology is applied to the selection, which made this email bank very much representative of current spamming. 3.3 Feature Construction Each email is parsed as text file to identify each header element to distinguish them from the body of the message. Every substring within the subject header and the message body characters (A-Z, a-z)or apostrophes. The toke ns were evaluated to create a set of 21 hand-crafted features from each e-mail message (Table 2) of which features 1-17 are proposed in [6]. In addition of these 17 features this study proposes other four features 18-21. The study investigates the suitability of these 21 features in classifying spam emails. 3.4 Evaluation Metrics Estimating classifier accuracy is important since it allows one to evaluate how accu-rately a given classifier will classify unknown samples on which the classifier has not racy, precision and recall [5], [7]. These measures are calculated using the confusion matrix given below: 
Accuracy of a classifier is calculated by dividing the number of correctly classified samples by the total number of test samples and is defined as: 
Precision measures the system X  X  ability to present only relevant items while recall measures system X  X  ability to present all relevant items. These two measures are widely used in TREC evaluation of document retrieval [10]. Precision is calculated by dividing the number of samples that are true positives by the total number of samples classified as positives and is defined as: 
Analogously, recall is calculated by dividing the number of samples that are true and is defined as: both of them. The block diagram of the proposed model of spam email classification process exploiting spammer behavioral patterns given in Fig 3. Table 4 summarizes the comparative results of the three well-known machine learning algorithms namely Na X ve Bayesian classifier, decision tree induction and SVM. These algorithms are tested on Weka 3.6.0 suite of machine learning software written in Java, developed at the University of Waikato [11]. It is observed that Na X ve Bayesian classi-level of accuracy that can be achieved by Na X ve Bayesian classifier is 92.2% (shown in yellow color in Table 4) using features from category 2 and 3. The accuracy that can be achieved by any learning algorithms using features from category 1 is negligible. Fea-tures from category 2 and 3 contribute mostly in classifying spam emails from non-spam emails for all machine learning algorithm experimented in this study. 
Highest number of features is always desira ble only if their inclusion increase clas-sifier X  X  accuracy significantly. Growing number of features not only hinders multidi-mensional indexing but also increases overall execution time. So, this study starves to without degrading the level of accuracy. 
Applying best first forward attribute selection method the study gets only 10 fea-tures from category 2 and category 3 useful for classifying the spam and non-spam emails without sacrificing the accuracy as shown in Table 5. The set includes features 8, 9, 10, 12, 13, 14, 15, 16, 17, and 18 of which feature 18 is identified in this study. The Na X ve Bayesian classifier again outperforms other two learning algorithms. The optimal feature set obtained by applying best first forward attribute selection method for the features proposed in [6] includes only features 8, 9, 10, 12, 13, 14, 15, 16 and machine learning algorithms (shown in light blue in Table 5). 
The study presented in [6] uses neural network for modeling spammer common patterns and achieved similar performance, but the limitation of neural network is its longer training time and inherent complexity of explaining its derivation, degraded the approach. On the contrary, Bayesian Classifier has the advantage of incremental inclusion of features and beforehand calculation. The decision tree based classifica-tion offers the best expressive power and allow better understanding about the classi-fication process and knowledge adoption. Therefore, the proposed modeling approach will have added advantage in this regard. This paper studies the modeling of spammer behavior by the well-known machine learning algorithms for spam email classification. Based on examining different features and different learning algorithms, the following conclusions can be drawn from the study presented in this paper: (1) Spammer behavior can be modeled using features extracted from Content-Type header and message Body only, (2) The contri-bution of features extracted from subject head er in spam email detection is negligible or insignificant, (3) Na X ve Bayesian classifier best models the spammer behavior than other two machine learning techniques namely Decision Tree Induction and SVMs, and (4) It is possible to get an optimal numbe r of features that can be effectively ap-plied to learning algorithms to classify spam emails without sacrificing accuracy. 
The preliminary result presented in this study seems promising in modeling spam-mer common behavioral patterns compared to similar research. As Na X ve Bayes and DTI both offers cost effective framework in classifying spam emails [3], a natural progression will be combining these two ML algorithms in multi-core architecture [13], running both classifier simultaneously in different cores to minimize time and applying voting mechanism to increase positivity, which will give best opportunity to model spammer common patterns. We are also working on developing multi-classifier based spam filters [12] exploiting spammer behavioral patterns with estab-lished spam data and benchmarks. 
The contribution of this paper is threefold: it shows why keyword based spam email classifier may fail to model spammers X  altering tricks, common patterns adopted by spammers and the rationale of using these patterns against them to combat spam; suitability of modeling spammer common patterns using machine learning algorithms and finally, establishment of the four concluding remarks. 
