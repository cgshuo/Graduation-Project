 Abstract DialogDesigner is an integrated design and development environment that supports dialogue designers in creating an electronic dialogue model, writing dialogue snippets, running and analysing simulation sessions, getting graphical views of the model, making automatic evaluation regarding dialogue model well-formedness, compiling the model into run-time code, and extracting different presentations. Dia-logDesigner has been used for research purposes as well as in commercial projects. Its primary focus is on providing support for the development process. We explain underlying ideas, illustrate the functionality of DialogDesigner and discuss its strengths. Keywords Spoken dialogue systems  X  Dialogue model  X  Development and evaluation process  X  Tools support 1 Introduction Prolog Development Center A/S is a company that produces spoken dialogue systems (SDSs). This has led to a need for tools in support of SDS design and development beyond the mostly coding-oriented development tools commonly available for VoiceXML or as part of commercial telephony platforms. To meet this need we have created an integrated design and development environment (IDE), DialogDesigner , centred around a generic dialogue model and incorporating a set of tools operating on that model.

The primary motivation has been to achieve (i) a more cost-efficient system development process with user-involvement by supporting rapid dialogue model Hans Dybkj X r  X  Laila Dybkj X r design and evaluation, while at the same time (ii) ensuring efficient and easy-to-use SDSs.

The work on a dialogue model does not start where one already has a precise idea of what the model is going to look like. Often the point of departure is snippets of concrete dialogue that illustrate use cases, scenarios or parts of scenarios, and the dialogue model emerges on the background of these. DialogDesigner supports the design process from the very beginning by enabling this approach to dialogue model design. Alternatively, it is also possible to start using DialogDesigner by entering an early version of the dialogue model. In either case, as soon as a first electronic dialogue model has been created, support may be provided for its further development and evaluation by enabling access to a suite of tools, as also pointed out by (Harris, 2005 ). The target user group for DialogDesigner includes SDS designers and developers. Programming expertise is not required by designers though they should have a solid understanding of formalisation of dialogue modelling and understand the related terminology.

The first version of DialogDesigner was built in early 2005 while a second and extended version was implemented in 2006, adding, among other things, support for automatic analyses of dialogue models, snippet design, as well as compilation of the model into runtime code. The tool is continuously being improved and expanded. It is implemented in C# and runs on a Windows platform. So far the first version has been used during development of a commercial traffic information system and in a commercial auto-attendant system. The second version is new but has been used in a commercial project that extends the traffic information system and in an update of the auto-attendant system. Furthermore, two demos have been designed for testing and exploration purposes. A pizza ordering demo was designed using version one while a calendar application allowing students to book a time slot in the teacher X  X  calendar for discussion of their project was designed with version two.

In the following we present DialogDesigner in more detail. Section 2 presents the goals of DialogDesigner, how it supports the development process, and how the outcome relates to a general SDS architecture. Section 3 deals with approaches to dialogue models and describes how it is done in DialogDesigner. Section 4 describes the tools included in DialogDesigner in support of the development process, including a dialogue snippet design tool, a simulation tool, a visualisation tool, two analysis tools and a code generation tool. Section 5 presents the possibility for generation of various presentations of the dialogue model. Section 6 describes DialogDesigner in relation to its goals and discusses its strengths. Section 7 discusses and concludes on the presented work and outlines future work. 2 Goals and the development process The primary aim of DialogDesigner is to support an efficient, iterative development process with customer and user involvement. In (Dybkj X r &amp; Dybkj X r, 2004b )we identified three main problems for SDS development, i.e. complex systems, com-municating the dialogue model to stakeholders, and efficient code development. The following list of goals for DialogDesigner has its origin in these identified problems.  X  Contemporary dialogue complexity . The IDE should support universal modelling  X   X  Task oriented dialogues using limited natural language within specific delim- X   X  Heterogeneous tasks , i.e. several tasks that the user may choose from or  X  Communicate with developers, customers, and users about SDS design. This  X   X  Presentation of the dialogue flow in a way that is intuitively easy to understand.  X   X  Simulating dialogues with a tool that builds on the electronic dialogue model.  X   X  Lists of prompts and phrases for validation by customers and for recording by  X  Efficient development of code . This includes:  X   X  Work separation . People with different expertise should be able to work on  X   X  Reusing flow in different parts of the system.  X   X  Code generation , making implementation, dialogue model, and presentations  X   X  Automatic analyses of the model for consistency, well-formedness, etc. 2.1 Development process support DialogDesigner is intended to form part of concrete system development processes and provides support for a highly iterative approach to dialogue design which is known to be an efficient approach to building systems of high quality and which is in line with modern life cycle models such as the Unified Process (UP) model (Jac-obson, Boosch, &amp; Rumbaugh, 1999 ), cf. Table 1 , and various agile methods, e.g. (Beck, 1999 ). The use case driven development approach of UP is supported in DialogDesigner via the dialogue snippet tool, Sect. 4.1. 2.2 DialogDesigner and the SDS architecture DialogDesigner is an off-line tool, i.e. it is not part of a runtime dialogue system, cf. Fig. 1 . The designer edits a dialogue model which is then compiled into the control structure of the dialogue manager. As part of the dialogue model the designer specifies the focus in terms of grammar names, and the prompt phrases are extracted for use in the runtime system, and mapped to the sound files to be played (if speech synthesis is not used).

DialogDesigner is independent of the runtime system. Currently we use HotVoice from Dolphin, but support for other systems could be added. For instance, we plan to add compilation into VoiceXML. When a new dialogue system is being built, the semantics and the domain model (application data and business logic) must be hand coded. Predicates, variables, and framelike structures used in actions and conditions in the dialogue model within DialogDesigner must be defined in the domain model. 3 Dialogue models We shall now take a closer look at what kind of dialogue model is suitable. Many approaches today aim at supporting conversational dialogue, e.g. Collagen (Rich, Sidner, &amp; Lesh, 2001 ) which employs a discourse structure approach to dialogue modelling, based on the attention/intention/linguistics theory of discourse structure (Grosz &amp; Sidner, 1986 ), supplemented by a partial planning module.

However, we find that our goal of making it easy to convey the main structures and prompts to stakeholders, and our delimitation to task-oriented dialogues, makes it necessary and sufficient to take the more explicit approach of using dialogue graphs as a basis for dialogue modelling. In the next two subsections we first describe three different graph-based approaches and their advantages and disadvantages, and then briefly present the synthesized approach taken in DialogDesigner. 3.1 Approaches to dialogue modelling While human X  X uman dialogue may be seen as a joint effort containing lots of overlaps and interweaving utterances that together constitute the overall discourse (Steensig, 2001 ), this complex interpretation needs to be simplified when it comes to spoken human-computer dialogue. This is not least due to the current state-of-the-art in input/output technology (speech recognition and generation) which is needed for spoken human X  X omputer interaction and which is unable to handle the com-plexity often found in human X  X uman dialogue. Therefore we only consider dia-logues that consist of a number of alternating system and user turns, with the possible addition of barge-in handling. Since our focus is on computational dialogue models, we may view a dialogue model as a program and the set of all possible dialogues enabled by the dialogue model as the set of all paths through the program. Specifically, we shall view these paths as graphs consisting of states connected by transitions .

Let us consider three different  X  X  X ure X  X  ways of composing dialogue models as graphs, cf. Fig. 2 . While all of them are graphs, there are crucial differences in the design and computational options:  X  State production systems : The dialogue is a set of states. Each state is guarded by  X  Transition production systems : The dialogue is a set of conditional transitions  X  Flow charts : The dialogue is a set of states connected by conditional transitions.
While the production system type of model provides a dynamic and flexible computation, it provides no structural hints. This is in contrast with the flow chart many details are modelled, the structure tends to become cluttered. 3.2 The DialogDesigner model In DialogDesigner we combine the presented models. A dialogue model has a set of states connected via conditional transitions. The states are hierarchically grouped which improves the overview of the model. Moreover, the groups may function as targets of transitions such that each group of (conditional) states may function as a state production system.

Each state in a dialogue model has a set of zero or more conditional prompts (system utterances) attached, as has each transition. However, a state may or may not accept user input which means that a system turn may continue across more than one state and may include several system utterances. A user turn, on the contrary, is restricted to one utterance only (at least in the present version of DialogDesigner) and is only possible in those states which accept user input.

Figure 3 illustrates a partial dialogue model depicted as a graph. The basic pro-cessing loop is the following: 1. Enter the first state. 2. Play the prompt, if any. 3. If the state accepts user input, wait for it, resolve it and update the discourse and domain representations. 4. Select a transition with satisfied condition. Play the prompt, if any. 5. Resolve the target of the transition:  X  If target is a state, enter it.  X  If target is a group, select a state with satisfied condition in the group. 6. Go to 2.

Figure 4 is a screen shot of the DialogDesigner design window that is used for entering a dialogue model. The figure shows the state hierarchy (D1), the state information including name and condition (D2), the state prompt set (D3), the transitions (D4) including name, condition, and target, and the transition prompt set (D5) of the selected transition.

DialogDesigner enables a static inclusion mechanism as well as a dynamic continue primitive both of which support reuse via sub-structuring of the dialogue model. Transitions may include the transitions of another state. In Fig. 4 , the curly brackets enclosing the transition {Commands} indicate that all transitions listed in the Commands state will be included here. Dynamic excursions to sub-dialogues are modelled via the Continue column which may indicate where to proceed when Target column. This may be used e.g. for modelling a generic help functionality. 3.2.1 Act-topic annotation Act-topic annotation represents yet another way in which to impose structure on the dialogue model and provides a basis for testing certain properties of the model, cf. Sects. 4.4 and 4.5. Our approach builds on ideas presented in (Dybj X r &amp; Dybkj X r, 2004a ). See also (Dybkj X r &amp; Dybkj X r, 2006 ) concerning speech acts and the use of act-topic annotation.

When a dialogue model is entered in DialogDesigner, it is possible to annotate each prompt and each transition (where user input is expected) with speech acts and topics, cf. Fig. 4 . Only one speech act can be assigned per prompt and one per user input, while more topics may be assigned in both cases. This is a simplification which may not be entirely correct since a prompt or a user utterance may indeed include more than one speech act.

Speech acts and topics are an abstraction that tells something about what happens when we select a particular entry in the dialogue model. They must be assigned manually. No automatic support is available for proposing an act or one or more topics for a prompt or an expected user utterance.

DialogDesigner comes with a set of 14 default speech acts, but may be configured correct), clarify (something ambiguous), feedback, hangup, inform, offer, other (i.e. believe in the possibility of a standard set of speech acts because what is an appropriate set of speech acts is highly dependent on the sort of analysis one wants to perform. However, we do believe that some reuse of speech acts is possible across highly domain and task dependent. Therefore the user of DialogDesigner always has to define his own set of topics for a dialogue model.

The speech act annotation is not used at runtime. It is used for analysis of dia-logue model well-formedness, see Sects. 4.4 and 4.5. However, the annotation may influence the implementation. The annotation may be understood as a signal to the implementor. For example, a feedback act might require a shorter subsequent pause before timeout than a request for information. 4 Tools While the dialogue model is the central object of the development process, the tools offered by DialogDesigner are key to ensuring an efficient process, cf. the goals include support for dialogue snippet design (Sub-sect. 4.1), use of walkthrough and WOZ simulation (Sub-sect. 4.2), graphical visualisation of the dialogue model (Sub-sect. 4.3), analysis of aspects of well-formedness of the dialogue model in terms of a number of health analyses (Sub-sect. 4.4) and in terms of an analysis based on act-topic patterns (Sub-sect. 4.5), and code generation (Sub-sect. 4.6). 4.1 Snippet design Often dialogue modelling takes its point of departure in scenarios or in subparts of scenarios. We design the dialogue model based on knowledge of concrete situations that the SDS must be able to deal with, and we have concrete ideas of formulation, style, and flow of exchanges. When during development we want to evaluate the emerging dialogue model, e.g. via walkthroughs or WOZ simulation, scenarios are again important. Later in the development process scenarios are still important to evaluate also the implemented dialogue model.

In DialogDesigner we use the term  X  X  X ialogue snippet X  X  to denote (part of) a concrete dialogue. Often the snippet will be equivalent to an entire scenario cor-responding to a specific use case variation, e.g. booking a one-way ticket from Copenhagen to Aalborg for a particular time and date. However, if certain parts of the system-user dialogue is expected to have many important variations, it is prac-tical to focus on these parts rather than having to create full scenarios all the time. Thus snippets may cover as little as a single utterance or a single exchange between the user and the system, e.g. eliciting a date from the user.

It is possible in DialogDesigner to start designing dialogue snippets even before any dialogue model has been defined. Figure 5 shows an example of a dialogue snippet. This is likely to be the way many dialogue model designers would prefer to work with the snippet tool in the requirements writing and early design sketching phases. Focus is on formulations and dialogue design, and snippets are often entered and/or verified in cooperation with user representatives. One could call this ap-proach  X  X  X esign by example X  X .

Once a dialogue model has been entered, the designer may begin to map the snippets into the model by assigning states and transitions to each turn in the snippet.
A snippet that has been mapped into a dialogue model can be verified auto-compatible with the model. Therefore such snippets form the basis for regression test of the dialogue model whenever it changes.

Figure 6 shows the result of a mapping between a snippet and the dialogue model where the error message (top right) concerning turn 5 implicitly reveals that the dialogue model does not take into account that the teacher X  X  calendar may be fully booked on a particular date. Having fixed this error, we would still get warnings about the difference between snippet and model prompts in turns 4 and 5. 4.2 Simulation The snippet tool provides support for simulation techniques such as scenario-based walkthroughs or WOZ. Snippets may be generated from the dialogue model X  X is-played to the right in Fig. 6  X  X y selecting states and transitions which are then inserted into the active snippet. Since conditions are not evaluated during simula-tion, the designer is asked to choose states, prompts, and transitions whenever ambiguity arises.

Walkthroughs of dialogue models can profitably be done by designers or devel-opers with the purpose of discovering missing or flawed functionality and inappro-priate interaction which is likely to cause problems for users. Walkthroughs may be based on scenarios which are made at the beginning of the design process or gen-erated on the fly.

WOZ sessions are typically scenario-based. Preferably representative users should be involved to collect reliable data. However, for early and rough tests colleagues, customer employees, or other persons at hand are very useful to get an overall impression of the extent to which the system seems to work and where major pitfalls may be.

Walkthrough and WOZ sessions are saved in the same way as snippets. Saved sessions may always be opened as any other snippets for inspection, editing and commenting which may be useful for analysis. It is also possible to generate a report showing one or all sessions in HTML format, cf. Fig. 7 .

The simulation feature can be used normatively to generate snippets as test scripts . These may then be used in a systematic functionality test of the implemented SDS.

The snippet tool may be used during presentation and discussion sessions with customers and end-users to demonstrate e.g. dialogues for typical scenarios. It is also possible to use the tool and create (partial) scenarios during discussion with stake-holders. 4.3 Graphical visualisation Since DialogDesigner is based on a kind of conditional graphs, it seems natural to display the dialogue model graphically. Thus DialogDesigner has a graph tool for dialogue model before one can benefit from the graphical view. Actually we rec-ommend to run rapid, possibly incremental, cycles using much of the tool func-tionality in DialogDesigner iteratively X  X ncluding the graphical view X  X n parallel with dialogue model design.

Showing all states of the entire model in a graph is not useful, since graphs at even a modest level of complexity become cluttered. But visualisation of the groups together with selected transitions (often domain and maybe command transitions) provides a nice overview. Another useful view is to fully expand a node with all the ingoing and outgoing transitions: This provides a nice overview of the connectivity of the state in focus and whether some transitions are missing. 4.4 Health analyses DialogDesigner supports four kinds of automatic analysis of the dialogue model regarding its well-formedness. We call these analyses  X  X  X ealth analyses X  X . Two of these are based on act-topic annotation of the dialogue model, while the other two analyses are not. We recommend to use the health analyses iteratively from early on. They check simple aspects of well-formedness and help discover design flaws which should preferably be corrected prior to a simulation session.

The two analyses not based on act-topic annotation check all states for  X  re-entrance, i.e. whether one can get back to each state in a finite number of reachable or not re-entrant, or it is information on how many steps it as a minimum takes to reach or get back to the state in question, cf. Fig. 9 .

The two act-topic based health analyses check each prompt and each transition to see  X  if topics are used that are not in the list defined by the designer, cf. the bottom of
The analyses issue a warning whenever they detect a missing or undefined act or topic.
 4.5 Using act-topic patterns in analysis There is a second kind of automatic analysis which also exploits the act-topic annotation. This analysis requires the specification of act-topic patterns (also called rule patterns) and then allows for subsequent automatic analysis of whether the dialogue model conforms to the specified patterns.
 Rule patterns are act-topic sequences written on the following form in BNF:
Two examples are testRequest.Inform: s(request{}) ; ? u(inform{}) ; testRequest.InformTopic: s(request{month}) ; ? u(inform{month}) ; The  X  X  X  X  X  (system) and  X  X  X  X  X  (user) are used to indicate who performs which act. Request and inform are speech acts. The  X  X  X } X  X  indicates any topic(s), i.e. in the first example we don X  X  care which topic(s) the system and the user are addressing whereas in the second example the topics must include  X  X  X onth X  X . The condition part is that the system has requested information. If this is the case and X  X n example two only X  X he topic is month, the analysis checks if the turn following the question mark is possible, i.e. if the user may provide information. In example two the information must specifically concern the topic month.

A third example is testPause: s(_{}) ; ? u(pause{}) ; s(repair{}) ;
Repair, pause and _ are speech acts where _ means any speech act. The condition part is that the system has said something. If this is the case, the analysis checks if the silence by initiating repair. The analysis is performed in the same window as the health analyses, cf. Fig. 9 where rule patterns are grouped and listed to the left.
For each selected rule pattern the automatic analysis runs through the dialogue model looking for the condition part of the rule pattern in prompts and transitions. specified in the sequent in the rule pattern are also allowed for where the condition was found in the dialogue model.

The rules check for existence. This means that the analysis will succeed for a given state if just one match with the rule pattern is found. The analysis does not check if there are several matches for the same rule pattern in a particular state. Also, the without computing the condition fields of the dialogue model. In principle the act-topic annotation must be consistent with the conditions specified in the dialogue model. However, in practice the actual runtime conditions may turn out to not allow the path although the analysis shows that a path is possible.

An act-topic pattern may be fairly general and if this is the case, it may very well be reused across different dialogue models. We have so far specified act-topic pat-should be noted that some of the rule patterns have been used across all the dialogue models developed so far using DialogDesigner, while others have only been used in one or some of the dialogue models.  X  Universals: In any input state universals, such as repetition, help, and goodbye,  X  Events: In any input state events, such as nothing understood (noMatch in  X  Feedback: Whenever the system provides feedback, the user should have the  X  Common act sequences: There are several, e.g.:  X   X  If the system makes an offer, it must be possible for the user to reject the offer  X   X  If the user has selected an offer, it must be possible for the system to provide  X   X  If the system requests information, it must be possible for the system to receive  X  Topic reactions: Requests concerning a topic T must have the possibility to be
Since the act-topic-based analysis checks more formal aspects of well-formedness, dialogue model has been established. 4.6 Code generation DialogDesigner supports code generation. Once the dialogue model is reasonably formalised code can be generated automatically. For the moment the model can only be compiled into HotVoice code but it is planned to also enable compilation to VoiceXML. The generated code may include warning and error messages. For example, there may be a warning that a particular condition is always true and that subsequent transitions therefore have been skipped. Or there may be an error message indicating that there is a transition to an empty state (null state). 5 Reports Five different reports or presentations of the dialogue model may be extracted in DialogDesigner. Report generation may be considered a special kind of develop-ment process support tool. Two of the enabled presentations are meant for com-munication with and use by phrase speakers. One of these presentations is a phrase list while a second is a prompt list, both in HTML. If a phrase is used more than once in the dialogue model the second or later occurrences are struck through to clearly mark repetitions. The advantage of presenting the phrase list as a prompt list is that this makes it clearer to the phrase speaker what the context is.

A third option is to extract the prompt list as a comma separated (CSV) file. This studio. The set of features extracted is configurable.

The fourth kind of presentation contains the dialogue model in terms of all states with their prompts and possible transitions. Transitions are links which means that the HTML model can be used for navigating the dialogue model, cf. Fig. 10 , without having access to DialogDesigner. We have found this HTML presentation very helpful for communicating with customers.

The fifth kind of presentation is much like the fourth one but includes more details for each state, such as grammar information and notes. Thus this presentation is meant for internal communication in the development group where such details are of relevance. As the IDE becomes easier to use, the importance of this report decreases. 6 DialogDesigner goals reviewed There exists a wealth of tools and IDEs that one way or another support SDS development and evaluation. Some are free while others are not. There are, e.g., plenty of tools and IDEs available for developing and testing VoiceXML applica-tions, see e.g. http://www.w3.org/Voice, and speech development kits (SDKs) from voice companies, such as Nuance and Loquendo, normally come with a suite of tools some of which support dialogue development.

In the following we shall briefly review the goals of DialogDesigner and relate to other, existing tools. Table 2 summarises the achievements in constructing DialogDesigner. 6.1 Contemporary dialogue complexity The first goal is support for modelling of contemporary dialogue complexity , i.e. DialogDesigner must support modelling of today X  X  state-of-the-art dialogues that are heterogeneous and task-oriented. However, having a goal addressing  X  X  X ontempo-rary X  X  dialogue complexity is equivalent to having a moving target. To illustrate this, let us look at a few examples.

In (Dybkj X r &amp; Dybkj X r, 2004b ) we described how X  X n a system from 2001 X  X e explicitly modelled barge-in by measuring the time the user spent listening to a prompt. If the time in milliseconds was less than the time needed to speak the prompt, we knew the user had used barge-in. We made this explicit modelling because we needed the feature and the implementation language HDDL (Aust, Oerder, Seide, &amp; Steinbiss, 1995 ) provided in the SpeechMania platform did not support event handling of barge-in detection. However, in the specification of VoiceXML 2.1 from June 2005, which is now supported by VoiceXML platform markname and marktime, described exactly under the heading  X  X  X sing to Detect Barge-in During Prompt Playback X  X .

At least it was possible in HDDL to implement barge-in detection via more primitive timing predicates. For other features implementation may be infeasible if not supported by the platform. For example, Ko  X  lzer ( 2002 , p. 133) notes that VoiceXML 1.0 does not support N-best recognition results. This feature is supported in VoiceXML 2.0 via the variable application.lastresult (March 2004).

A third example is anaphora resolution which, as noted by (Ko  X  lzer, 2002 ), is not supported in VoiceXML. However, to the extent that one has a recipe for resolving references, one may implement anaphora resolution on a VoiceXML platform since VoiceXML 2.0 provides access to the recognised string. So anaphora resolution is something that is not directly supported by the contemporary platform, but which may be encoded on that platform although with some difficulty.

There are also features that theoretically can be used, but for which there is no platform support. An example is that certain prosodic features have been shown to be good indicators of aware sites of system errors which might be useful in deciding on the dialogue strategy (Hirschberg, Swerts, &amp; Litman, 2001 ). However, no com-mercial recognisers support that yet, so dialogue models that depend on that feature are not a present target for DialogDesigner.

These examples serve to show that while DialogDesigner must support modelling of state-of-the-art tasks and dialogues, it should also be flexible and extensible. 6.2 Communication The second goal is communication with stakeholders about dialogue model design. This includes presentation of dialogue flow, simulation of dialogues, and extraction of prompts and phrases for validation and recording purposes. This goal is where DialogDesigner really distinguishes itself from other tools. There are several tools which enable e.g. WOZ simulation or visualisation of the dialogue model in terms of a graph structure. However their focus is not in particular on communication with stakeholders. 6.2.1 Presentation of dialogue flow Many tools try to provide intuitive scripting tools, e.g. IBM WebSphere (http:// www.ibm.com/websphere), the Edify editor (http://www.edify.com), or HotVoice (http://www.dolphin.no). These tools often make it easy for non-dialogue expert technicians with some programming expertise to script small, straightforward dia-logues. However, they do not solve the problem of communicating with stakeholders. In fact, dialogue flow and prompts are deeply entangled in the (scripted) programs. The drafting of dialogue snippets in DialogDesigner is somewhat comparable to Suede (Klemmer et al., 2000 ). But snippets are more detached from the formal model: Snippets are mapped into the model whereas the graphs in Suede become the dialogue flow directly. Moreover, snippets are allowed to be only part of a concrete dialogue, whereas Suede makes complete dialogues from the start to the end.
That being said, the graphical presentation of Suede with prompts directly in the nodes seems quite intuitive, and the ability to manipulate and edit the model via directly editing the graph, is nice. However, graphs tend to quickly become cluttered and difficult to lay out readably. 6.2.2 Simulating dialogues Other tools than DialogDesigner exist which are meant to support the design and evaluation of SDSs and which support WOZ simulation. Two such tools are Suede, and the WOZ tool developed by (Breuer, 2006 ) as a by-product of his work at Nuance. Basically the WOZ facility in both cases enables the designer to select a prompt from a list of available prompts given the present state. The selected prompt is played or spoken to the user. Based on the user X  X  answer the designer selects again one among the now available prompts, etc. In Suede simulation of recognition errors is supported. 6.2.3 Lists of prompts and phrases SpeechMania all text constants in the HDDL program may be extracted to a phrase list. This is fine except that also non-phrase strings are extracted, and that there is no relationship between the phrases in the list and the prompts in which they occur. As shown in (Dybkj X r &amp; Dybkj X r, 2004b ) the ability to present prompts, e.g. to domain experts, may be crucial for the system X  X  correctness. Also, some customers wish to have their management review and approve all prompts since they become an important part of the company X  X  external image. 6.3 Efficient development of code The third goal concerns efficient development of code . This goal includes work separation, reuse, code generation, and automatic analyses of the dialogue model.
As we have seen, DialogDesigner has some support for code development, e.g. in terms of code generation to HotVoice and automatic analyses of aspects of well-formedness. Efficient code development is core to many tools although they may have different ways in which to support it. VoiceXML tools, e.g., don X  X  do code generation since you script your dialogues in VoiceXML. However, they may include libraries of small frequently used dialogue parts, such as obtaining a date, which makes code writing efficient. Such libraries may be seen as support for reuse. There are also tools which support you in building your own libraries. The GEMINI platform (Hamerich et al., 2004 ), e.g., supports reuse by allowing all developed models to be saved as libraries for reuse in future applications. SDKs normally come with a suite of tools which may be used by different people from the development team (work separation) and which include support for automatic analyses of various kinds. Of course the code developed using an SDK may also be reused later, if relevant, even if there is no support for building a library. 7 Discussion and future work We have described DialogDesigner which is a tool in support of a rapid and iterative SDS dialogue model development process. In the following we briefly discuss its strengths, our experience so far, and future work. More information on DialogDesigner, including colour pictures, can be found at http://www.Spoken Dialogue.dk. 7.1 Software development process support We have presented the three main goals of DialogDesigner and how it supports a modern iterative software development process (Sect. 2). To achieve the goals we have enabled electronic dialogue modelling (Sect. 3) and constructed a suite of tools which support the development process (Sects. 4 and 5). In Sect. 6 we discussed the goals and achievements of DialogDesigner in relation to other work on SDS dia-logue model development support.

DialogDesigner clearly has its strengths in process support, in particular with respect to stakeholder communication whereas it provides state-of-the-art support regarding the two goals of contemporary dialogue complexity and efficient code development (Sect. 6). The communication support includes presentation, simula-tion and report facilities. HTML reports, graphical visualisation and concrete dia-logue snippets may be used for presentation of the dialogue model. Walkthroughs and WOZ sessions may be used to simulate dialogues prior to dialogue model implementation and thus allow for early error correction. Lists of prompts and phrases may be extracted for validation and recording purposes. 7.2 Experience Since DialogDesigner is quite new, we have very limited experience from using it and we have made no formal, empirical investigations of the extent to which it helps improve the development process. Possible issues to look for in order to evaluate improvements would be  X  better product quality;  X  more satisfied customers and customer representatives;  X  faster development process for designers and developers;  X  sales argument used by marketing people.

Each of these issues may be quite difficult to evaluate. In fact experience from a large number of development projects with and without DialogDesigner would be the best source for a fairly reliable evaluation. This is data we don X  X  have.
Product quality is influenced by process quality although the connection is complex and not entirely understood. To test which difference DialogDesigner makes to product quality one would in principle need two identical development teams devel-oping the same application under the same conditions and using roughly the same process, but with one team using DialogDesigner while the other does not. A com-parative evaluation of the two resulting systems could then be performed. In practice this does not work e.g. because you will never have two identical development teams. A further complication would be that the comparative evaluation could not be entirely objective since  X  X  X he quality models for the overall interaction with the SDS can cover only a part of the factors influencing perceived quality X  X  (Mo  X  ller, 2004 , preface).
Improved customer satisfaction is also difficult to measure without two almost identical development processes as described above. Customer satisfaction per se can of course be measured but it would be difficult to tell if an improvement (or the opposite) is due to the use of DialogDesigner since there are so many other parameters that may influence customer satisfaction.

Whether the development process becomes faster when DialogDesigner is used would again require the comparison of identical processes with and without the use of DialogDesigner or experience from many projects with and without the appli-cation of DialogDesigner. We don X  X  have much data so all we can say is that we have a feeling that the development process with DialogDesigner involved is faster than without. One reason may be that DialogDesigner ensures a larger degree of con-sistence between specification, design and the actual system than we would other-DialogDesigner encourages a systematic development process. Moreover, Dialog Designer ensures better possibilities for testing the dialogue model from early on. For example, the test-first concept from Extreme Programming (XP) where tests are prepared before the system is implemented (see e.g. (Beck, 1999 ) and http:// www.testdriven.com) also forms part of DialogDesigner in the sense that the dia-logue model is tested before it is implemented and scenarios for tests of the implemented system may be prepared in advance.

Thus it is our impression that DialogDesigner helps saving time because the basis for implementation is better and contains fewer errors than would be the case with a less thorough design process.

The last point on the list above may be evaluated by looking at whether the marketing people use results from DialogDesigner as part of their sales arguments because it is fairly easy to generate something which looks good. This is also a point we cannot evaluate yet. 7.3 Future work DialogDesigner is being extended and improved when time allows and need arises. Extensions are dictated by practical needs or driven by theoretical interests. There are many improvements and additions we can think of and which perhaps will be realised at some point of time in the future. Our current primary goals encompass the following extensions, in prioritised order:  X  VoiceXML generation, so that DialogDesigner conforms to the mainstream  X  Better modelling facilities. This includes the following points with the first one  X   X  creation of catalogues of dialogue patterns, including tools support for specific  X   X  support for domain modelling, cf. (Ko  X  lzer, 2002 );  X   X  more powerful generation of prompt specifications;  X   X  support for semantics/grammar modelling.  X  Further act-topic exploitation. In particular we need more experience on the  X   X  more experience on the relative strength of act-topic patterns and of snippets  X   X  a more expressive act-topic rule notation. This may for instance be done by  X   X  the possibility to view the actual sequence of prompts and transitions that  X   X  multiple acts in prompts. This will add to the complexity, but we need it since References
