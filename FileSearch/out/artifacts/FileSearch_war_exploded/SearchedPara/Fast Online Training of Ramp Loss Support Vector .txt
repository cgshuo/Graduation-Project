 which a potentially unlimited stream of training data is presented one example at a time, and can only be seen in a single pass. This is opposed to offline learning where the whole collection of training examples is at hand. The predicts target variable y given an M -dimensional input vector X x  X  . For online learning there is the anytime requirement that implies the ability to update the prediction model f ( x ) after each new example and allows its instant use for prediction. Considering the potentially high stream rates, it becomes very important to update the model in a computationally efficient manner. Typically, online algorithms attempt to update the existing f without retraining it from scratch. developed for optimization on a regularized hinge loss cost function. IDSVM [2] is one of the earliest successful solutions. It maintains the optimal Support Vector Machine (SVM) [16] solution after a new example is added. LASVM [1] and its improved version [8] have been proposed to speed-up online SVM training for large scale data by dropping the requirement of optimality. Similarly to their offline counterparts that use hinge-loss, their drawback is sensitivity to noise and outliers. This comes from the nature examples become the Support Vectors (SVs) during training. Moreover, since the SVM training and prediction time grows with the number of SVs, the scalability of hinge-loss SVM is poor on noisy data. offline algorithm [4] based on ConCave Convex Procedure (CCCP) [17] has been proposed for SVMs by using a regularized ramp loss cost function. In this new Ramp-Loss SVM (SVM R ) optimization problem, the noisy examples (i.e. SVM R for large-scale online learning tasks, called the online Ramp-Loss SVM (OnlineSVM R ). OnlineSVM R produces the optimal solution for SVM R on t+ 1 training data using the existing optimal solution on t previous examples and efficiently updating it given the new ( t +1)-th example. The algorithm retains the Karush X  X uhn X  X ucker (KKT) conditions on all previously observed examples using an SMO-style incremental learning and decremental unlearning approach under the CCCP framework. By only maintaining a fixed number of non-SVs closest to the decision boundary, the training time of OnlineSVM R could be further improved while retaining competitive accuracy. been combined with other machine learning scenarios (e.g. active learning and budget learning) in many practical applications. Coupled with the higher accuracy and robustness to noise, faster training time, and sparser model, OnlineSVM R could be used as an efficient alternative to these algorithms. To demonstrate the applicability of OnlineSVM R , OnlineSVM R with active learning is also proposed. Moreover, it could be shown that a greedy variant of OnlineSVM R for active learning could be viewed as an approximate optimization process over a regularized ramp-loss cost function. A. Zero-bias hinge loss SVM and Karush-Kuhn-Tucker bias threshold b fixed at 0, where w is the weight vector and  X  is a nonlinear mapping of the attribute space. Zero bias simplification of training [6, 11, 13]. From this point on we assume that form f ( x ) = w T  X  ( x ) is used. D = {( x i , y i ) , i = 1 ...N }, x i  X  R , y i the primal problem (see Figure 1) and C is a user specified parameter to balance the model structure and training loss. 
In the dual formulation of the optimization, the primal problem is transformed to associated with the primal problem, Q ij = y i y j element of the Gram kernel matrix Q , and k is the positive definite kernel function satisfying ). ( ) ( ) , ( j T i j i Note that, unlike the standard SVM dual form, the linear constraint 0 =  X  y T vanished in (2) because of b = 0. 
The Karush X  X uhn X  X ucker (KKT) conditions are necessary and sufficient for the optimal solution of (2), We call the examples not satisfying (3) the KKT violators . The resulting SVM classifier can be conveniently represented in the dual form as The training examples with 0  X  i  X  are called Support Vectors (SVs). B. Ramp loss SVM 
One practical issue with SVM is its scalability. Recent results [15] show that the number of SVs scales linearly with the number of training examples. The SV scaling could be shown through differentiating (1) (and assuming the hinge loss is differentiable at 1 with a smooth approximation) [4] that the optimal solution w must satisfy Thus, all examples with 1 ) (  X  i i x f y become SVs as their hinge-loss derivative is nonzero (i.e. 1 )) ( , ( ' = This includes all noisy examples with 1 ) (  X  &lt; i i x f y . 
To address this drawback of hinge loss, the non-convex ramp loss (see Figure 1) was introduced in [4]. Replacing H by R in (1), it could be seen that the examples with 1 ) (  X  &lt; not become SVs. The new ramp loss SVM (SVM formulation then reads as C. ConCave-Convex Procedure (CCCP) 
To solve the non-convex objective function (7), CCCP [17] is used. CCCP optimizes the non-convex problem by solving a sequence of approximate convex problems and has no additional parameters to tune. 
To optimize (7) using CCCP, the non-convex objective function is decomposed into convex ) ( w vex J and concave 
J parts, which can be rewritten as 
Algorithm 1: OnlineSVM R 0. f ( x )=0,  X  = I ,  X  = V 1. repeat 2. receive the next example ( x t+1 ,y t+1 ); 4. if g t+1 ] 2 , 0 [  X  5. } 1 { +  X  = t V V ; 6. calculate new t 1 +  X  using Eq. (14); 8. , I i  X   X  update g i using Eq. (15); 9. repeat 10. while ( V i  X   X  violates Eq. (3) or 11. find a KKT violator i* in V using Eq. (13); 12. calculate new i *  X  using Eq. (14); 14. I i  X   X  , update g i using Eq. (15); 15. endwhile 16. for I i  X   X  17. if g i V i  X   X  X  X   X  &amp; ] 2 , ( 18. } { i V V  X  = ; 19. elseif g i V i  X  + X   X  &amp; ) , 2 ( 20. } { i V V  X  = ; 21. endif 22. endfor 23. for i  X  , just being removed from V 24. set 0 = new i  X  and old i i  X   X   X  =  X  25. , I k  X   X  update g k using Eq. (15); 26. endfor 27. until V is not changed 28. endif 29. until the end of the stream CCCP runs in iterations. First, the procedure sets w approximates J cave ( w ) by its tangent w T J cave w old indicates w in the previous iteration, and then optimizes where V is the active subset of training examples with margin larger than  X  1, formally, There is the convergence guarantee [17] that the procedure would decrease the non-convex objective function in each iteration. The resulting optimization problem (9) is convex and can be reformulated by its dual form: where  X  V and Q VV correspond to the active set examples and  X   X  X  of examples in V D V  X  = is set to zero. It is worth noting that the optimization problem (11) is equivalent to training a standard SVM on V . 
Using the CCCP algorithm, the procedure iteratively retrains SVMs on the dynamically updated V until V remains unchanged, and eventually has all the SVs within the ramp region (i.e. 1 | ) ( | 0 ,  X   X   X   X  i i i x f y i  X  ). reallocating V is computationally expensive even for offline training of SVM R . Directly applying the offline SVM algorithm [4] to online learning by retraining each time a new example is observed is impractical. This drawback leads us to the proposed efficient online algorithm that formulates the optimal solution for t+ 1 examples in terms of the existing solution for t previous examples and efficiently accounting for the new ( t +1)-th example. algorithm for ramp loss SVM, called OnlineSVM OnlineSVM R guarantees the optimal solution of (7) after every new training example is received. core of OnlineSVM R . The key of this modification is to retain the KKT conditions on all previously seen examples, while iteratively adding or deleting an example from the active set V (see (10)). To achieve this, an SMO-style incremental learning and decemental unlearning method is proposed to guarantee the KKT conditions are maintained during the update. An efficient working set selection strategy computations and achieves faster convergence. A. Outline of OnlineSVM R ( Algorithm 1 ) this section. The details are given in the following sections. observed examples and V is a subset of I as defined in (10). g t+1 (defined in (3)), the algorithm checks the KKT conditions for this initial assignment of t+ 1: the observed examples (set I ) are updated with respect to the obtained  X  t+1 . The above step (and, similarly, Steps 14 and 25) is important. The updating of KKT conditions for V guarantees the progress of optimization at this step, while the updating for the examples outside V is for a fast relocation of the new V in future steps. Following this, the algorithm updates the solution through online CCCP iterations (Steps 9 process, (11) is iteratively optimized on V until the stopping examples removed from the previous V are decrementally unlearned from the current solution and all KKT conditions are updated accordingly (Steps 19 to 22). This process (Steps 9 to 27) iterates until V stops changing. Thus, the optimal solution of (7) is maintained upon addition of a new example. B. Online updating optimization used in Algorithm 1. As we already pointed out, the optimization of (11) is equivalent to training an SVM on V and setting  X  values of the examples outside V to zero. For the online updating, the goal is to maintain KKT conditions on all the previously seen examples. To achieve this, we propose an SMO-style online updating. SMO [14] is an iterative process where in each iteration the smallest set of examples is selected, and the dual problem is optimized with respect to them. This smallest set is called the working set. example because the fixed threshold b removes the need for the linear constraint in the dual. Hence, the smallest sub-optimization problem when the example i is used as the working set reads as where U = V  X  { i } denotes set of all the examples excluding the i -th example. selection is closely related to the optimization progress and the cost of kernel computation. From a greedy view, the most efficient working set in each iteration should be the one that achieves the largest improvement of the dual objective function (12). Formally, the optimal selection is obtained as the number of KKT violators in V . An appealing part of this procedure over the other popular working set selection methods [7, 8] is that it is free of kernel computation and all the values can be directly read from memory if some specific kernels are applied (e.g. if RBF kernel is used, then Q becomes constant).  X  (14) examples are updated as well, with respect to the new Specifically, where . old i new i i  X   X   X   X  =  X  current V and a newly added example, iterative execution of Steps 11~14 in Algorithm 1 resolves one KKT violation at a guaranteeing convergence. from V can be implemented naturally using the same approach as above. For i to be unlearned, we first set We repeat this procedure for every example being removed from V (Steps 23~26 in Algorithm 1). for the model optimization (the condition in Step 10 in Algorithm 1). The first one checks the KKT conditions (3). If all g i are less than 10  X  3 from the desired value the procedure stops. This method is standard, and is also used in SMO [14]. The second criterion considers the optimization progress; if the dual objective function could not significantly improve (e.g. less than 10 -5 ), as measured by (13), then the iterations stop. Using (13) to estimate progress could significantly reduce the computation cost. These two criteria (with 10 algorithms. C. Improving scalability accuracy for quicker update time and lower memory consumption. This can be achieved by only maintaining in I only a fixed number of the non-SVs that are closest to the Algorithm 3: OnlineSVM R with active learning (OnlineASVM R ) 0. f ( x )=0,  X  = I ,  X  = V 1. repeat 2. receive the next unlabeled example x t+1 ; 3. if 1 | ) ( | 1  X  + t x f 4. query label y t+1 ; 5. } 1 { +  X  = t I I , } 1 { +  X  = t V V ; 7. Steps 6 to 27 from Algorithm 1; 8. endif 9 . until the end of the stream decision boundary (this can be directly measured by | 1  X  g and discarding the remaining ones. The non-SVs that are far from the decision boundary are not very likely to become SVs in the future. In practice, this removal step could be executed right after Step 28 in Algorithm 1 as described in Algorithm 2. There, removal criterion is triggered (when a predefined maximal number of non-SVs is reached). Algorithm 2: The removal step 2. remove ( |X|  X  m ) non-SVs with the largest | 1  X  g| 3. endif where labels are queried only for some of the training examples from the stream. Instead of querying labels from all the observed examples, OnlineASVM R (Algorithm 3) The justification comes from the fact that an example outside of the ramp region is not placed in V (it is placed in I unchanged. Only if such an example finds itself within the ramp region during the training procedure, it is placed in V and its  X  value becomes nonzero, and thus the solution is improved. The farther away the new example is from the ramp region the smaller the chance that it will ever be used to update the solution. convex optimization problem was suggested [9]. There, the perceptron algorithm with such label filtering step is viewed function. Following this view, we argue that OnlineASVM could be considered as a greedy optimization approach that approximately optimizes the regularized ramp loss cost function (7) . A. Experimental setting binary classification data sets summarized in the first column of Table 1. The multi-class data sets were converted to two-converted the original 10-class problems to binary by representing digits 1, 2, 4, 5, 7 (non-round digits) as negative For 3-class DNA data set class 3 was separated from the other 2 classes. Class 1 in the 3-class Waveform was treated as negative and the remaining two as positive. For Covertype data the class 2 was treated as positive and the remaining 6 classes as negative. Adult , Banana , Checkerboard and Gauss were originally 2-class data sets. NCheckerboard is a noisy version of Checkerboard where class assignment was switched for 15% of the randomly selected examples. For both data sets, we used the noise-free Checkerboard as the test set. Attributes in all data sets were scaled to mean 0 and standard deviation 1. algorithm with hinge loss to compare with OnlineSVM R and OnlineASVM R : x selected the best hyper-parameters C and  X  2 using cross-validation for all combinations of algorithm and data set. The considered values were C = {0.1, 1, 5, 10, 50, 100, 500} and = { M /2  X  1 , M /2 0 , M /2 1 , M /2 2 , M /2 4 , M /2 dimensionality. B. Illustration on a 2-D dataset proposed and the previous algorithms on Gauss data set. Gauss is a noisy benchmark dataset [10] which consists of two overlapping 2-D Gaussian distributions (see Figure 2.a). 2.b-d the IDSVM, OnlineSVM R , and OnlineASVM solutions are compared. It can be observed that OnlineSVM and OnlineASVM R solutions are much sparser than that of IDSVM. As expected, their SVs are all inside the margins, while the SVs of the IDSVM solution are widely distributed and also include the noisy examples outside the margin. In Figure 3.a we show the accuracy as a function of the data stream size for the three algorithms (IDSVM was terminated after 5,000 seconds of training because it reached the resource limits of our PC). It can be seen that OnlineSVM consistently achieved higher accuracy than IDSVM, especially in the initial stages of training (see the initial points of two curves). The accuracy curve of OnlineASVM R closely follows that of OnlineSVM R and reaches it after 10,000 observed examples. This is expected because, as the accuracy of OnlineASVM R increases, there is less of a risk that an unlabeled point will end up within the ramp region. Figure 3.b illustrates that OnlineSVM R and OnlineASVM learn sparser models than IDSVM. computational cost for (1) OnlineSVM R , (2) offline SVM [4] trained on demand, and (3) the naive online algorithm that repeatedly retrains offline SVM R from scratch in an implementation, the computational cost is expressed as total number of kernel computations. For offline SVM R training, speed-up computation, as suggested in [4]. From Figure 4.a, we can observe that the computational cost of OnlineSVM is significantly less than the naive approach of retraining SVM R . Interestingly, total cost of OnlineSVM R training is comparable to training a single offline SVM R . This result clearly demonstrates the success of the proposed online solution. In Figure 4.b, we compare the training time of OnlineSVM R and OnlineASVM R with IDSVM. As can be seen, the proposed two algorithms lead to a large reduction in training time over IDSVM due to the sparser models. C. Results on benchmark datasets Table 1. Mean and standard deviation of 10 repeated experiments for accuracy and number of SVs are reported. If needed, we terminated IDSVM after 5,000 seconds of training. OnlineSVM R is significantly more accurate than LibSVM on 5 out of 9 data sets and IDSVM on 4 out of 9 data sets. The largest accuracy improvement (up to 2%) happens on two noisy data sets NCheckerboard and Covertype . The accuracy of OnlineASVM R is very competitive to both IDSVM, LibSVM and OnlineSVM R and is usually within 1% of their accuracy. Finally, perceptron-based PA algorithm is less competitive and it is significantly less accurate than the others on 7 out of 9 data sets.
 OnlineSVM R is as sparse as OnlineASVM R in most cases, and it obtains the sparsest model on 2 data sets. Both SVM based algorithms are much sparser than the hinge-loss based IDSVM, LibSVM and PA. In Gauss data set, OnlineSVM and OnlineASVM R are about 10 times sparser than LibSVM. PA results in the densest models. In the extreme case, for Cover data set, PA includes all the training data as SVs. D. Scalability with the removal step (Algorithm 3). We explored how the parameter m trades off accuracy and scalability. From Figures 5.a and c, it can be seen that the computational cost of OnlineSVM R decreases with m . For aggressive removal with m = 0, the accuracy loss is significant and should not be recommended (see Figures 5.b and d). Choice of m = 100 is more appropriate, as it results in only a small accuracy loss that decreases with data stream size and still allows significant savings in computational time. If achieving the best accuracy is a critical requirement, m = 1000 seems to be a good choice because accuracy loss in negligible and computational savings are still significant. E. Online active learning experiments OnlineASVM R achieves comparable accuracy and number of SVs to OnlineSVM R and that it is somewhat faster. In this section, we give detailed results about growth in accuracy of OnlineASVM R as a function of the labeling effort. To gain better insight, we compared its performance with 2 competing active learning approaches implemented on top of OnlineSVM R and IDSVM algorithms: maximal number of labels in each plot is obtained when one of the 5 competing algorithms reaches the end of the data stream. algorithms based on OnlineSVM R . The QueryAll strategy is consistently and significantly less accurate than Greedy and OnlineASVM R . OnlineASVM R and Greedy appear to have strengths on different data sets. While Greedy is superior on DNA , USPS , and Waveform data sets, OnlineASVM R superior on Gauss , Cover , Checkerboard , and NCheckerboard . Their performance on the remaining 2 data set is similar. These results are interesting because Greedy focuses on examples near the decision boundary, while OnlineASVM R is gentler and labels all examples within the margin. It would be interesting to explore in future work if the size of labeling region can be optimized to each individual data set. IDSVM, it is evident that OnlineSVMR is superior on the ramp-loss measure. We presented a fast online algorithm for ramp loss SVM training. The proposed algorithm OnlineSVM R significantly outperforms its competing algorithm IDSVM in terms of accuracy, model sparsity and training time. A variant of OnlineSVM R for active learning could be viewed as an approximate optimization process over a regularized ramp loss cost function. The applicability of OnlineSVM R active learning scenario has been demonstrated, as it showed the advantages over the competing algorithm. The application of OnlineSVM R to other machine learning scenarios (e.g. budget learning) could be further studied. This work was supported by the U.S. National Science Foundation under Grant IIS-0546155. 
