 DANIEL ANDRADE and TAKUYA MATSUZAKI, University of Tokyo Even for resource-rich languages such as Japanese and English, for which compre-hensive dictionaries are already available, it is necessary to constantly update these dictionaries to include translations of n ew words. As such, it is helpful to assist human translators by automatically extracting plausible translation candidates from bi-lingual corpora. The necessity of finding translations of words that are not yet listed in a dictionary is also exemplified in cross-lingual information retrieval [Peters and Sheridan 2001], where the out-of-vocabulary problem places constraints on the usefulness of such systems.

As a solution, it was proposed in Fung [1998] and Rapp [1999] to use comparable corpora to extract new translations. The t erm comparable corpora refers to a pair of non-parallel corpora written in different languages, which are roughly related to a similar topic. The advantages of using comparable corpora is that they are abundant, can be automatically extracted from the internet [Utsuro et al. 2003] and cover recent topics.

As a consequence, research in automatic bilingual dictionary creation using com-parable corpora has become increasingly widespread [Garera et al. 2009; Ismail and Manandhar 2010; Laws et al. 2010]. However, the languages considered are often quite similar, for example, from the Indo-European language family, or use a simple bag-of-words model to cover the context of a word. In the present article, we focus on a new method that effectively extracts relevant context information, which is com-parable across Japanese and English, and which also includes valuable dependency information from parse-trees.

The basic assumption is that words with similar meaning have similar contexts across languages. The context of a word is s ummarized by calculating the degree of association between the word in question and all pivot words. Pivot words are words for which a translation is already available in the bilingual dictionary. Furthermore, the degree of association is defined as a measurement for finding words that co-occur, or which do not co-occur, more often tha n we would expect by pure chance. 1 For example, a commonly used measure for degree of association is the Log-Likelihood-Ratio.
However, we argue that the degree of association can not be directly compared when using comparable corpora in Japanese and English. As an alternative, we suggest to use the statistical significance of a positive association . That means, we are only con-cerned about whether a positive association between two words such as  X  X ar X  and  X  X ire X  holds with statistical significance or not. A formal definition of positive association will be given in Section 3.2.1.

Our proposed approach can be summarize d as follows: First, we extract salient pivot words from the context of an unknown word (query word). For the extraction of relevant pivot words, we use a Bayesian estimation of Point-wise Mutual Information which measures the statistical significance of a (positive) association. We then match these salient pivots across languages in order to identify translation candidates for the query word. Next, we calculate a sim ilarity score between the query word and a translation candidate using the probability that the same pivot is extracted for both the query word and the translation candidate. The pivots are extracted from several different context positions. We use a simple bag-of-word context and additionally use successors, predecessors, and siblings from the dependency parse tree. Since the struc-ture of the dependency parse tree is generally quite different between Japanese and English, we suggest a systematic adjustment of both structures. Experiments involv-ing two different pairs of comparable corpora confirm that the proposed method im-proves the translation accuracy as compared to previous approaches. We demonstrate that the improvement provided by the proposed method is due to the selection of only statistically relevant pivots as well as the combination of the bag-of-words context and dependency parse tree information.

In the next section, we review previous research that used comparable corpora to find translations of single words. In Section 3, we explain the proposed method. In Section 4, we explain in detail the baseline systems used in the subsequent section. In Section 5, we run several word translati on experiments on two different pairs of comparable corpora and evaluate the proposed method with respect to the baselines. In Section 6, we analyze the proposed methods in detail. Finally, we summarize the contributions of the present study in Section 7. In the following, we review the major studies that use comparable corpora to find a new translation for a word q . The basic idea behind this research, as well as the present study, is to measure the context of q and to then compare that context with each possible translation candidate X  X  context using an existing dictionary. First, we explain previous research which uses a context vector approach and which will form the baselines for our method. In the second half, Subsection 2.2, we review other research which propose variations or extensions of the context vector approach. The context vector approach creates context vectors for the query word and all pos-sible translation candidates, and then co mpares the vectors using a standard vector similarity measure. First, the degree of a ssociation between the query word and all the pivot words is measured with respect to the corpus at hand. This is also done for every possible translation candidate in the target corpus. In this manner, we create a context vector for the query and all of its possible translation candidates. Recall that the pivot words, are the words for which a translation is available in a general dictionary. This enables us to compare the vectors across languages. The query and its translation candidates are then compared using their context vectors, where each dimension in the context vector contains the degree of association with one pivot word.

Fung [1998] suggested using the tf-idf measure to calculate the (positive) degree of association between q and a pivot word x . The tf-idf measure is calculated based on the number of co-occurrences in a sentence, assuming a bag-of-words model. Afterward, the context vectors were compared using the cosine similarity. This method is often referred to as the standard approach. We use the standard approach, as well as some previously proposed variations, as baselines for the proposed system. Several variations of the standard approach have been proposed [Chiao and Zweigenbaum 2002; Koehn and Knight 2002; Laroche and Langlais 2010; Morin et al. 2007; Peters and Picchi 1997; Rapp 1999; Saralegi et al. 2008; Utsuro et al. 2003]. These variations use the tf-idf measure, the Log-Likelihood-Ratio (LLR) [Rapp 1999], the Spearmans-correlation [Koehn and Knight 2002], Point-wise Mutual Information (PMI) [Peters and Picchi 1997], Log-Odds-Ratio [Laroche and Langlais 2010], and conditional probability [Pekar et al. 2006]. Depending on the method selected for calculating the degree of association, an appropriate method for comparing the context vectors is selected, for example, Manhattan-Distance, for LLR [Rapp 1999], or cosine-similarity, for Log-Odds-Ratio [Laroche and Langlais 2010].

All previous studies assumed a simple bag-of-words model. Rapp [1999] assumed the word-order to be the same in both languages. Although this might be the case for closely related languages, such as German and English, it is not the case for Japanese and English. As an alternative, Garera et al. [2009] attempted to improve the latter model, by creating a context vector using the predecessors and successors in the dependency graph. They do not consider to use additionally a bag-of-words model and neither take into account differences in the dependency structure between the two languages in question. Spanish and English, which are closely related languages, were used in their experiments. As far as we know, this is the only previous study that has used dependency parsing information. Therefore, we use that method as an additional baseline for the proposed system. Although Pekar et al. [2006] also used dependency information, they considered only verb-noun dependency. This is more restrictive since other relevant context information, such as adjectival modification, is ignored.
In Section 5, we explain in detail the implementation of the baselines. A method that also uses PMI is described in Peters and Picchi [1997]. First, as a query, they extracted the pivot words associated with the highest PMI scores. Then they calculated the similarity between the query word and text snippets from the tar-get corpus by counting how many of the extracted pivot words occurred in the text snippet. In contrast to the proposed approach, they used a simple maximum likeli-hood estimate of PMI and some threshold on the PMI-score to restrict the number of associated pivots. They did not provide an evaluation of their approach in terms of aligning translation pairs. However, our experiments described in Section 6.3 suggest that a Bayesian estimate of PMI outperforms the maximum likelihood estimate for the present task.

In a previous study [Gaussier et al. 2004], the standard approach was extended by considering the similarity to words that are not in the dictionary. The motivation of the previous study is that, ideally, we would like to translate all of the content words that co-occur with a query word q . However, only a subset of these words is in the dictionary, and thus only this subset of th e context vector can be compared across lan-guages. In order to overcome this bottleneck, Gaussier et al. [2004] suggested that the information about words that often co-occur with a query word but are not pivot words be used. Let us denote the degree of association between the query q and a pivot word p In contrast, they created a vector that contains in dimension i the similarity between the context vector of q and the context vector of a pivot word p i , whereas theses context vectors contain the degree of association with each content word (including non-pivot words). Although they reported a small improvement over the standard approach, they also reported that their approach introduces additional noise by using association to pivot words only indirectly.
 Another idea for handling the bottleneck of the existing dictionary is presented in D  X  ejean et al. [2002]. They showed how to extend the standard approach if additional domain-specific multi-lingual thesauri are available. They use a bio-medical multi-thesaurus in order to improve the translation betwenn German and English terms.
Most previous studies, including the present study, make the simplifying assump-tion that a word has only one translation, or that all translations correspond to only one sense. In a previous study [Ismail and Manandhar 2010], a method that can be used to find translations for a query conditional on a certain sense was introduced. Here, different senses of one query are ind icated by different words, which are highly associated with the query. For example, if the query is  X  X ank X , then one highly as-sociated word might be  X  X inance X , which suggests the sense of  X  X inancial institution X . Another word that is highly associated with  X  X ank X  might be  X  X iver X , which suggests the sense of  X  X and accumulated next to a river X . When creating the context vector of bank, we consider only the occurrences of bank where, in its surrounding, finance oc-curs. Using that context vector, we can find the translation of  X  X ank X  with the specific sense of  X  X inancial institution X .

Another approach was proposed by Haghighi et al. [2008], which uses the proba-bilistic interpretation of Canonical Correlation Analysis [Bach and Jordan 2005]. In this interpretation, the source and target w ords can be considered as being generated from a common latent subspace. The goal of finding the best matching translation pairs is then formulated as maximizing the likelihood in the corresponding probabilis-tic graphical model. The idea is to find the mutual exclusive matching of the source nouns and target nouns, that is, a bipartite graph, which achieves the highest proba-bility in the probabilistic model. Their method is theoretically interesting. However, this method suffers from high computational costs 2 , which makes it difficult to scale to larger sets of nouns. In their experiments, they therefore pre-selected 1,000 source words and 1,000 target words, which were then matched with their algorithm. They did not compare the performance of their method directly to that of the standard con-text vector approaches, which makes it difficult to estimate the possible gains from their method.

Recently, in Laws et al. [2010], a graph-based approach was suggested. They created two graphs, one for the source language and one for the target language. A graph consists of three types of nodes corresponding to adjectives, verbs, and nouns and three types of edges corresponding to adjectival modification, verb-object relation, and noun coordination. Edge weights represent the strength of correlation measured by the logarithm of the log likelihood ratio. The translation pairs, which are listed in the existing dictionary, are used to create edges between the two graphs. Finally, in order to find new translation pairs, a modification of SimRank is used, which recursively calculates the similarities of two nodes by measuring the similarity of the neighbors of these nodes. They evaluated their method using German and English, which are similar languages, and report an improvement over Rapp [1999]. However, note that it is necessary for that method to extract verb-object relations which is a non-trivial task for Japanese.

In Otero and Campos [2008], it was suggested that lexico-syntactic patterns, which were manually created, be used. They first POS-tagged the corpus and then extracted instances of lexico-syntactic patterns with regular expressions. Using their approach for English, we would, for example, extract the pattern instance &lt; see, subj ,man &gt; from  X  X  man sees a dog. X  using an appropriate regular expression. The pattern &lt; see, subj , * &gt; is then translated into the target language and used to score possible translation candidates for  X  X an X . In the experiments, the researchers used the related languages Spanish and Galician, which allowed them to use cognates in addition to the bilingual dictionary. In contrast to previous research, we focus on a method that can effectively describe and compare the context of two unrelated languages and use a richer model than the bag-of-words model. In particular, we show that, using the proposed method, it is possible to effectively use dependency-parser information for Japanese and English. The pro-posed method consists of three major steps. In the first step, described in Section 3.1, we adjust the dependency structures for Japanese and English to make them compa-rable. In the second step, described in Section 3.2, we extract the relevant pivot words from different context positions of the query word. We consider the occurrence of pivots in the same sentence (bag-of-words) as well as the occurrence of pivots in several syn-tactic dependency positions. For this task, we introduce a new Bayesian estimation of Point-wise Mutual Information (PMI). In the same way, we extract the relevant pivot words for each translation candidate. Finally, using an appropriate scoring function described in Section 3.3, we compare the pivots extracted for the query word with the pivots extracted for each translation candidate. Assuming we have a similar sentence in two closely related languages, such as Spanish and English [Garera et al. 2009], the dependency structures are often very similar. However, the dependency structures in Japanese and English cannot be compared directly. For example, Figure 1 shows the dependency structures of two similar Japanese and English sentences:  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  (The door opens with the card key.), and  X  X ide door does not open with key. X . The two primary reasons for the difference in dependency structure are as follows.  X  Traditionally, in Japanese, dependencies are defined between chunks of words, re-ferred to as bunsetsu , and not between words. A bunsetsu usually contains one or more content words, and ends with a function word. For example, for the above bunsetsu :  X  X  X  X  (card)  X  X  (key)  X  ( case-marking particle ).SeealsoFigure1.  X  Function words are difficult to compare between Japanese and English. For ex-ample, the case-marking particle  X  ( ga ), which indicates the subject in Japanese, cannot be related to an English word. Auxiliary verbs in English, such as  X  X an X  are realized in a different position in the dependency tree in Japanese.
 In order to make the dependency structures of English and Japanese more similar, we transform both structures appropriately, as we suggested in Andrade et al. [2011].
Looking at the example in Figure 1, we find that for the two similar sentences the relation  X  X oor X   X   X  X pen X  holds in Japanese as well as in English. In the following we describe the heuristics used to transfo rm the Japanese and English dependency structures. 3.1.1. Ignoring non-content words. In English, as well as in Japanese, we ignore function words. In order to remove function words we apply two heuristics. The first heuristic addresses particles and prepositions, and can be simply thought of as jumping over non-content words. For example from  X  X e play soccer in the garden X , we obtain the dependencies X  X occer X   X   X  X n X   X   X  X arden X , which is transformed to  X  X occer X   X   X  X arden X . More generally, the rule ca n be described as follows: where z 1 ,..., z n are words that modify the non-content word x ,and x modifies a word y .

Exceptions are modal and auxiliary verbs in English, which are treated in a unique manner. 3.1.2. Modal and Auxiliary Verbs in English. For English, we apply a second heuristic, which removes auxiliary verbs. For example in  X  X he steering is shaking X , we obtain the dependencies  X  X teering X   X   X  X s X   X   X  X haking X , which is normalized to  X  X teering X   X   X  X haking X . More generally, this rule can be described as follows: where x is an auxiliary verb, and v is a verb that modifies x . Note that if the sentence contains subordinate clauses, two verbs may modify an auxiliary verb x ,inwhichcase, we set the verb that is closest to x as the verb v . We apply the rules iteratively in order to also normalize sentences such as  X  X he steering has been shaking X . 3 These two heuristics are not sufficient to cover all of the differences in English and Japanese dependency structures involving f unction words. However, if the corpora are sufficiently large, we can extract most of the relevant word dependencies. For example in the sentence,  X  X inally, the steering stopped shaking. X , we see that  X  X teering X  is a semantic argument of  X  X hake X . But the proposed rules cannot extract the necessary direct dependency relation. Nevertheless, it is expected that  X  X he steering is shaking. X  will also appear in the corpus, which allows us to extract the relevant dependency relation that  X  X teering X  modifies  X  X hake X . 3.1.3. Dependencies within Bunsetsus. In general, bunsetsus contains several words (or morphemes), among which no dependency relationship is defined. Since this is in con-trast to English, we also define dependencies between the words within one bunsetsu. Bunsetsus can contain several consecutive nouns, such as  X  X  X  X  (card) and  X  X  (key), which is a compound noun. In this case, the problem of solving dependencies within a bunsetsu is closely related to the noun-bracketing problem in English. Since Japanese base noun phrases, like English, are head-final, we apply, right bracketing to bunset-sus including more than one noun, as a heuristic.

However, sometimes a bunsetsu contains not only nouns, but also the combination of a prefix + a noun or a noun + a post-fix. Often these combinations correspond to a single noun in English. For example,  X  X  X  (specialty, subject of study) +  X  (post-fix for indicating a person), becomes  X  X  X  X  , which is best translated as expert, or specialist. In this case, in order to improve the comparability between English and Japanese, we use the following heuristic. We look up whether a translation for such a suffix-noun pair is listed in the dictionary and whether this translation also appears in the English corpus. If so, we merge the suffix-noun combination into one noun; otherwise we ignore the suffix, that is, we treat the suffix as a non-content word.
 Usually the final bunsetsu is a predicate and often contains a noun +  X  X  (to do). Since  X  X  (to do) acts in a sentence as a verbalizer, we delete  X  X  ,andmarkthenoun as a verb. For example,  X  X  X  (explanation) +  X  X  (to do) is appropriately translated as  X  X o explain X . One reason for changing the part-of-speech of such a noun into a verb is that, ideally, we want each remaining noun in Japanese to correspond to a noun in English. This is necessary in order to guarantee that a Japanese noun which is in the gold standard has an English translation which is also a noun. For a query word q , we extract a set of relevant pi vots, which tend to co-occur in the same sentence and in several dependency positions. We first explain in detail the proposed method for extracting relevant pivots that tend to co-occur with q in the same sentence. Afterward, we show how to apply the same method for extracting relevant pivot words in several dependency positions. 3.2.1. Bayesian Estimation of PMI. The concept of (positive) association considered herein is based on the PMI. Let X be a binary random variable which is true for a certain sentence, if word x occurs in that sentence. Analogously, we define the binary random variable Q for a word q . The PMI for two words, x and q ,isdefinedasfollows: where p ( Q = true ) is the probability that word q occurs in a sentence, and, analogously, p (
X = true ) is the probability that pivot x occurs in a sentence. Furthermore, p ( X = true , Q = true ) is the probability that both words occur in the same sentence.
We say that there is a positive association between X and Q ,iff or equivalently, In related studies that use the PMI [Morin et al. 2007; Peters and Picchi 1997], these probabilities are simply estimated using relative frequencies, as follows: is the co-occurrence frequency, and n is the number of sentences. However, using rela-tive frequencies to estimate these probabilities can, for low-frequency words, produce unreliable estimates for PMI [Manning and Sch  X  utze 2002]. One possibility is to try to correct the PMI estimate by, for example, using a conservative estimate similar to as suggested in Johnson [2001]. 4 Instead of using a, possibly corrected, point-estimate of PMI, we suggested in Andrade et al. [2010] to directly use the probability of PMI &gt; 0.

We define a beta distribution over each probability of the binary events in which in Ross [2003] that a Bayesian estimate for Bernoulli trials using the beta distribution yields good credibility intervals 6 , importantly, when sample sizes are small, or when occurrence probabilities are close to 0. Therefore, we assume that where the parameters for the two beta distributions are set to Prior information related to p ( X = true ) and the conditional probability p ( X = true | Q = true ) can be incorporated by setting the hyper-parameters of the beta-distributions. 7 These can, for example, be learned from another unrelated corpora pair and then weighted appropriately by setting  X  +  X  . In the present experiments, we use no in-formation beyond the given corpora pair. The refore, the conditional priors are set to be equal to the prior for p ( X = true ). Even if we do not know which word x is, we can form some notion about p ( X = true ) because Zipf X  X  law indicates that p ( X = true ) should be small. A crude estimation is therefore the mean word occurrence probability in the corpus: We assign this estimate a total weight of one observation. That is, we set From a practical perspective, this can be interpreted as smoothing when sample sizes aresmall. Sinceweassumethat p ( X = true | Q = true )and p ( X = true ) are random variables, PMI is a random variable that is distributed according to a beta distribution ratio. 8 In the present experiments, we apply a general sampling strategy. We sample p (
X = true | Q = true )and p ( X = true ) independently and then calculate the ratio of times that PMI &gt; 0 in order to determine p ( PMI &gt; 0). 9 We refer to this method as Bayesian PMI.
Finally we calculate the set of pivot words that most likely have a positive associ-ation with word q .Suchaset  X  is required to be statistically relevant, that is, the probability that one or more words do not have a positive association is smaller than 0 . 5. Formally, this requires the following: We determine the largest set of pivots  X  that satisfies inequality (3), in the follow-ing manner: We sort the pivots x in descending order of p ( PMI ( x , q ) &gt; 0) and then incorporate the first pivots into the set  X  until inequality (3) is no longer satisfied. 3.2.2. Extraction of Relevant Pivots in Several Dependency Positions. In the following, we describe how to apply the method described above for extracting relevant pivots in several dependency positions. In particular, we explain how to extract pivots that occur as a predecessor, a successor, or a sibling of the query word q .

Relevant Pivots that are Predecessors/Successors of q . The first model for capturing dependency information is used to find the pivot words x that are positively associated with q , under the situation in which x occurs as a predecessor of q . For a formal de-scription of the model, we use the following definitions. First, we denote a dependency word pair as { w,v } , if there is an edge in the dependency graph such that either w  X  v or v  X  w holds. For the pivot word x we define the random variable X pred , such that Furthermore, for query word q we define Q succ , such that We have the desired property, that if and only if X pred and Q succ aretrueforacertain dependency word pair, then the pivot word x is the predecessor of q . Therefore, we can define the positive association between q and x that occurs as the predecessor of q ,as follows: In contrast to the bag-of-words model, we he rein consider each dependency word pair { w, v } in a corpus as a random experiment. This means that the total number of ran-dom experiments, n , is equal to the sum of the number of edges in the dependency trees of all sentences in the corpus. Let s represent a sentence, and w ords s be the set of words which occur in s . Then, formally, we can express n in the following way 10 Another stochastic model that is used to extract pivot words x , which are positively associated with q such that x occurs as a successor of q , is defined analogously.
Relevant Pivots that are Siblings of q . Finally, we extract positive associations between siblings in the dependency tree. Thus, we consider each subtree of depth one in the dependency trees as a random experiment when the subtree has more than one children. In other words, each set of children having the same parent is considered to be in a bag-of-words, where each bag-of-words is considered to be the result of one random experiment. This modeling decision is similar to the bag-of-words modeling for a sentence, in which each sentence represents a random experiment. We first divide the set of words w ords s in a sentence into a set of subsets T s such that each subset T is the largest set of words that have the same parent: 11 For each element T in T s , we define the random variable X sib :  X  x  X  T and Q set of siblings T . Analogously, we define Q sib . Therefore, X sib and Q sib are true, if and only if they both occur in T . As before, we now define the positive association between x and q , such that both X sib and Q sib are siblings, as follows: In order to calculate the number of random experiments for this statistical model, we have to count the number of sets T to obtain | T s | for each sentence s .
Having extracted the relevant pivots for a query word q , we extract, in the same manner, the pivot words for each possible translation candidate. In the previous section, we showed how to extract pivot words from the sentence (bag-of-words model) and from three different posi tions, namely, predecessor, successor, and sibling, in the dependency tree. In this section, we propose a similarity measure that compares the pivot words extracted for the query q (in the source language) with the pivot words extracted for a translation candidate c (in the target language). Therefore, using the existing dictionary, we translate each pivot word x in the source language into the corresponding set of pivot words t ( x ) in the target language. In the following, we denote by X the set of all pivot words in the source language and by Y the set of all pivot words in the target language, which is Y = t ( X ). 12
The basic concept behind the proposed similarity measure is to use the degree of surprise 13 that, by pure chance, the pivots of the query and the pivots of the candidate overlap. The similarity score between q and c consists of two parts. The first part accumulates the degree of surprise of having individual pivot words in common, which we denote as surprise I . The second part calculates the degree of surprise that q and c have a certain number of pivot words in common, which we denote as surprise N .
Calculation of surprise I (q, c) . First, for simplicity, we consider only the pivots ex-tracted from the sentence. As a similarity score, we use the degree of surprise that pivots extracted for query q in the sentence, denoted as Q s , overlap with the set of pivots extracted for translation candidate c , denoted as C s . For simplicity, we assume stochastic independence between any two pivot words associated with a translation candidate c . Let us denote the event that one or more translations of a pivot word x  X  Q as follows: 14 Note that 1 Q t ( x )  X  C s =  X  . The probability p ( s c ) is set as follows: that means the number of pivots extracted from the sentence for the candidate, divided by all pivots in the target language.

Next, we consider the pivots extracted from the query and from the candidate in a certain dependency position d . We include into the similarity measure the additional degree of surprise that these pivots overlap. As mentioned earlier, with respect to the dependency position d , we consider the successor, the predecessor, and the sib-ling. Analogously to the definitions for the sentence, we denote by Q d and C d the sets of pivots that were extracted in the dependency position d for the query and for the candidate, respectively. In the following, for simplicity, we assume that if a pivot is ex-tracted in any dependency position d , then that pivot is also extracted in the sentence. Explicitly, this means x  X  Q d  X  x  X  Q s and y  X  C d  X  y  X  C s . Analogous to event s c ,we define d c as the event whereby the translation of a pivot word x  X  Q d is also in C d ,that is, d c :  X  t ( x )  X  C d =  X  . In order to include the additional information of pivot words thermore, for simplicity, we assume stochastic independence between the same word that occurs in any two dependency positions. As a result, the extended formula for surprise I ( q , c ), which considers dependency information, is that means the number of pivots extracted from dependency position d for the candi-date, divided by the number of the pivots extracted from the sentence.

Thus far, we added up the degree of surprise for each pivot which is associated with both, the query, and the candidate. Thereby, each such pivot contributed the same amount to surprise I ( q , c ). However, not all pivots are equally informative. For example, the case in which the query and the candidate are associated with the pivot  X  X  X  X  (casualty) is more informative than the case in which the query and the candidate are associated with the pivot  X  (man). Therefore, we weight the contribution of each pivot x individually by defining the weight w x .Let C be the set of all translation candidates. Then, the number of times a pivot word is associated with any translation candidate is given by where for each candidate c ,theset C s , as defined before, is the set of pivots which are extracted from the sentence for c . The weight of a pivot is then defined as: This means that a pivot x that is associated with several candidates receives a lower weight w x . On the other hand, pivot words that are associated with only one candidate receive the maximum weight 1.

The final formula for surprise I ( q , c ), which considers the weight of each individual pivot, is
Calculation of surprise N (q, c) . Thus far, we have weighted each overlapping pivot word individually. This has allowed us to also consider the informativeness of each pivot word. However, the scoring function surprise I ( q , c ) has a bias towards candidates that have many associated pivot words. The reason for this is that such candidates are more likely to have more overlapping pivots in common with the query. Consequently, we also consider the degree of surprise that a candidate with | C s | number of extracted pivots, has | t ( Q s )  X  C s | number of pivots in common with the query. Setting m s := | t ( Q s )  X  C s | , we express this surprise as where c s := | C s | . Using combinatorics, we obtain the following solution: 15 where q s := | t ( Q s ) | and a := | Y | .
 Finally, we take into account the dependency information. Let m d := | t ( Q d )  X  C d | . Then, the formula for surprise N ( q , c )isextendedto where c d := | C d  X  t ( Q s ) | . In the same manner as before, we calculate the probability p ( m d | m s , c d ): where q d := | t ( Q d )  X  C s | .

Note, however, that we set the surprise  X  log p ( m s | c s ) and the conditional surprise  X  log p ( m d | m s , c d ) to zero if fewer pivots than expected are overlapping. If a certain number of pivots overlap, between the query and a candidate, even though this is un-likely, we assume that the number of overlaps is meaningful. The number of overlaps can have either of the following two meanings. The first meaning is that the query and the candidate have similar meanings because there are (several) pivots in common, even though having no (or fewer) pivots in common would be more likely. The second meaning is that the query and the candidate have diverging meanings because they have few pivots in common, even though the candidate has many associated pivots. Since we are not interested in the latter case, we detect the latter case by examining the same manner. We will use four baseline methods that correspond to methods proposed previously. Most of the previous methods assume that one pivot word in the source language has one translation. For example, in Rapp [1999], a German-English dictionary was used that contains a ranking of the translations that reflects their common usage. The translation with the first rank was always chosen. However, since the dictionary used in the present study does not contain such a ranking, we select the translation for which the relative frequency in the target corpus is closest to the pivot in the source corpus. This one-to-one correspondence is used for all baselines. It was first suggested by Fung [1998] that the tf-idf measure be used to create a context vector for the query and each candidate. The association between a word q and a pivot word x is measured using the tf-idf measure in the following manner: where f ( x , y ) is the number of times that x and q occur together in a sentence, and f ( x ) is the number of times that x occurs in a sentence. The resulting context vectors are then compared using the cosine similarity. We herein refer to this method as Tf-idf-COS . The method proposed in Garera et al. [2009] is identical to Tf-idf-COS except that, instead of a bag-of-words model on the sentence level, Garera et al. [2009] use the predecessor and successor information. We denote the baseline method which uses the predecessor and the successor as Tf-idf-Dep-COS . Note that the original method of Garera et al. [2009] also includes the predecessors of predecessors and successors of successors. However, since we  X  X op over X  function words, we expect that the results will be similar, because a majority of semantic relations can be reached this manner. For example, verb  X  preposition  X  noun. In Rapp [1999], the use of the Log-Likelihood-Ratio (LLR) as a measure of association is suggested. Here, we follow the original definition of LLR, as described in Dunning [1993]. In order to measure the degree of positive association between two words, x and q , we model their occurrences in a sentence as two binary random variables X and Q . We use the Log-Likelihood-Ratio to test the null hypotheses that X and Q are stochastically independent. The Log-Likelihood-Ratio is defined as follows [Dunning 1993]: with a sentence in which q does not occur, and f (  X  q ) denotes the total number of sentences in which q does not occur. The total number of sentences is N . The higher LLR( x , q ), the more likely that the null hypotheses is false, that is, the more likely that X and Q are stochastically dependent. An aspect that is not discussed in Dunning [1993] or Rapp [1999] is that stochastic dependence can indicate high negative association. This is because, if a word x tends not to occur if the word q occurs, then X and Q are also likely to be stochastically dependent. Since a negative association decreases accuracy, at least in the condition of the present study, we disregard this case. We set LLR( x , q ) to 0, if Rapp [1999], we use the Manhattan distance to compare the resulting context vectors. We herein refer to this method as LLR-MAN . In Laroche and Langlais [2010] it is suggested that the Log-Odds-Ratio (LOR), accord-ing to Evert [2004], be used as a measure of association: The +0 . 5 can be considered as a smoothing term, which prevents the argument of the logarithm from becoming 0. Again, we found that in the experimental setting of the present study, it is necessary to use Equation (13) to filter the negative association. In Laroche and Langlais [2010], LOR was reported to work best in combination with the cosine similarity. We denote the baseline method LOR in combination with cosine-similarity as LOR-COS .

Finally, as we reported in Andrade et al. [2010], a translation candidate c can also be a pivot word y in the target language. If this special case is not considered, the accuracy may deteriorate. 18 This is because the association of c with itself is high, and therefore the context vector in the position of c contains a high association value which makes the context vector dissimilar to the context vector of the query. Therefore, in order to further improve the accuracy of the baselines, we treat this case by setting f ( c , y )tozero,if c = y . In the experiments of the present study, we consider a collection of complaints concern-ing automobiles compiled by the Japanese Ministry of Land, Infrastructure, Transport and Tourism (MLIT) 19 and another collection of complaints concerning automobiles compiled by the USA National Highway Traffic Safety Administration (NHTSA) 20 . Both corpora are publicly available. The corpora are non-parallel, but are compara-ble in terms of content. In addition, we extracted another pair of comparable corpora with similar statistics (see Table I). We used articles of Mainichi Shinbun, a Japanese newspaper, in 1995, and English articles from Reuters in 1997. The main difference between the Mainichi/Reuters corpora and the MLIT/NHTSA corpora is in content similarity. The MLIT/NHTSA corpora are more comparable in content because both are related to the restricted domain of automobile complaints. On the other hand, the Mainichi/Reuters corpora are only loosely comparable because they tend to report different events. 21 The Japanese corpus was morphologically analyzed and dependency parsed using Juman and KNP 22 . The English corpus is POS-tagged and stemmed with Stepp Tagger [Okazaki et al. 2008; Tsuruoka et al. 2005] and dependency parsed using the MST parser [McDonald et al. 2005]. For all corpora, we consider each content w ord that occurs more than three times. The content words listed in the Japanese-English dictionary JMDic 23 are used as pivot words. In this way, we automatically determine 1,796 Japanese pivot words with their corresponding English translation for MLIT/NHTSA, and 1,114 Japanese pivot words with their translations for Mainichi/Reuters. The gold standard is extracted from the dictionary using Japanese and English nou n pairs that actually occur in the corpora. We then removed general nouns such as  X  X  X  X  (possibility) and ambiguous words such as  X  (rice, America). In this way, we obtain a final list of 443 domain-specific Japanese nouns for MLIT/NHTSA and 218 Japanese nouns for Mainichi/Reuters. We refer to these gold standards collectively as FULL. Each Japanese noun in the gold standard corresponds to one pair of the form &lt; Japanese noun (query), English translations (answers) &gt; . Note that evaluation with respect to a gold standard provides a conserva-tive approximation of the real performance b ecause several correct or plausible trans-lations, which are not listed in the dictionary, are count ed as incorrect translations. For the evaluation, the corresponding &lt; query, answers &gt; pair of the gold standard is removed from the pivot word list. The gold standard contains pairs in wide frequency ranges from 3 to 6,679 for MLIT/NHTSA and from 20 to 1,263 for Mainichi/Reuters. Since the difficulty of finding a correct translation depends on the frequency of the word [Pekar et al. 2006], we performed two additional experiments using only high-and low-frequency pairs from the gold standard. Based on a suggestion by Pekar et al. [2006], we set the frequency of a &lt; query, answers &gt; pair as the minimum of the Japanese word X  X  frequency and its English translation frequency. If there is more than one English translation, the maximum of the frequencies of these English translations is compared with the Japanese word X  X  frequency, and the minimum of the two is used as the entry X  X  frequency. We then use the 100 most frequent pairs (HIGH gold stan-dard) and the 100 least frequent pairs (LOW gold standard). Since most queries have only one translation, we evaluated the output of each method based solely upon accu-racy. In order to obtain a more complete picture of the performance of each method, we determine the accuracy at diffe rent ranks. The accuracy at rank r is determined by counting how often at least one correct answer is listed in the top r translation candi-dates suggested for a query divided by the number of all queries in the gold standard. In this section, we discuss the performance of the proposed method (PROPOSED), and several baselines, which were explained in Section 4. The results for the comparable MLIT/NHTSA corpora are shown in Figure 2, and those for the Mainichi/Reuters cor-pora are shown in Figure 3. A sample output of our method and the four baselines is show in Table II.

In average, the best baseline with respect to the FULL gold standard is obtained for LLR-MAN, which finds the correct translation within the Top-10 ranking can-didates in 45% and 24% of all cases for the MLIT/NHTSA and Mainichi/Reuters corpora, respectively. The proposed method outperforms this baseline by 10% and 3%, respectively. A pair-wise comparison reveals that the proposed method provides better performance than LLR-MAN for MLIT/NHTSA and Mainichi/Reuters (p &lt; 0 . 01 and p &lt; 0 . 03, respectively). 24 Note that all of the methods perform better for MLIT/NHTSA than for Mainichi/Reuters. This is to be expected, because the MLIT and NHTSA corpora are much more similar in content than the loosely comparable Mainichi and Reuters news corpora. Note that the proposed method is especially effective in MLIT/NHTSA for high-frequency words, where 55% and 93% accuracy are achieved at TOP-1 and TOP-20 accuracy, respectively.
If we compare the baselines LOR-COS and LLR-MAN for high-frequency words, we see that, interestingly, the accuracy of LO R-COS is clearly better than LLR-MAN. For example, the accuracy for TOP-1 of LOR-COS is 44%, in contrast to LLR-MAN, which has an accuracy of 33%. Note that the condition under which LOR-COS outperforms LLR-MAN is similar to the experimental condition reported in [Laroche and Langlais 2010], in which they report that LOR-COS outperforms LLR-MAN.

In contrast, in the experiments using the Mainichi/Reuters corpora, LLR-MAN has a clear advantage over LOR-COS. The reason for this is likely to be that the newspa-per corpora are only loosely comparable, in contrast to the Wikipedia corpus used in Laroche and Langlais [2010] which proposed LOR-COS. Furthermore, the LLR-MAN method was proposed in Rapp [1999], in which newspaper corpora were also used. In the present experiments, we found that, in most cases, the accuracy of Tf-idf-COS is lower than the that of LLR-MAN. Furthermore, we found that the overall performance of Tf-idf-Dep-COS is worse than that of Tf-idf-COS. Recall that the difference between Tf-idf-Dep-COS and Tf-idf-COS is that the former defines the context as words that are close in the dependency tree of a sentence, whereas the latter uses the entire sentence (bag-of-words). Such a local context appears to be too restrictive and misses words from the larger context, which are also important. This is also supported by the analysis of the proposed method in the next section. We will show that also the accuracy of the proposed method decreases when sentence bag-of-words information is removed.

Finally, note that there is another difference form the experiments in Laroche and Langlais [2010], Rapp [1999], and Garera et al. [2009] in that all three of these previous studies use Indo-European language pairs, which are more closer related than Japanese and English with respect to vocabulary and syntax. In this section, we evaluate the impact of using dependency structure information (Section 6.1), weighting of the pivot words (Section 6.2), and the use of a Bayesian estimate of PMI (Section 6.3). The results of the present analysis are shown in Figure 4 for the MLIT/NHTSA corpora and in Figure 5 for the Mainichi/Reuters corpora. 6.1.1. Does Dependency Information Help? First, we consider the impact of using de-pendency information in addition to the sentence (bag-of-words) model. Therefore, we remove all dependency information (successor, predecessor, sibling) from the scoring function, and the resulting method is referred to as SENTENCE. In Figures 4 and 5, the accuracy clearly drops when all dependency information is excluded. Notably, ac-curacy at rank 1 for the FULL gold standard drops by 4% for Mainichi/Reuters and by 3% for MLIT/NHTSA.

In order to explain the reason for the increase in accuracy of word translation, we consider a concrete example from MLIT/NH TSA given in Table III. If the query word is  X  X  X  X  X  X  X  X  (computer), the SENTENCE method returns  X  X ire X  at rank 1 and the correct translation at rank 25. However, the proposed method returns the correct translation,  X  X omputer X , at rank 1. Recall that the similarity score is based on how many overlapping pivot words are obtained for each context. If the context is set to a sentence, then the query word and  X  X ire X  have 13 pivot words in common, and so  X  X ire X  is therefore preferred to  X  X omputer X , which has only six in common with the query word. However, when considering the dependency contexts,  X  X omputer X  has a total of 12 pivot words in common with the query, whereas the incorrect translation,  X  X ire X , has only five. Since the probability that by pure chance pivots overlap in a dependency position is smaller than the probability that they overlap in the sentence (a larger context), the degree of surprise is higher, see Equations (6) and (11). As a consequence the similarity, defined in Equation (4), is higher for  X  X omputer X  than for  X  X ire X . For example,  X  X rror X  is a common sibling of the query and  X  X omputer X , but is not sibling of  X  X ire X . In addition,  X  X ailu re X  is a common successor of the query and  X  X omputer X , but not successor of  X  X ire X .

Furthermore, we analyzed the impact of the sibling information. Therefore, we ex-clude only the sibling information from the proposed scoring function, which yields the NO-SIBLING method. For MLIT/NHTSA, Figure 4 indicates a decrease in accuracy at several ranks. For example, the accura cy using the TOP-1 and Top-10 candidates decreases by 1% and 2%, respectively. This suggests that, in MLIT/NHTSA, sibling information can be helpful. However, in the case of Mainichi/Reuters, the accuracy increases slightly when excluding sibling information. In Figure 5, we see that, for example, the accuracy for the Top-10 candidates increases by 2%. We suspect that the usefulness of sibling information is limited if the sentence structure becomes more complex, as in the case of the newspaper articles of the Mainichi/Reuters corpora. Note also that the probability that, due to a parsing error, we obtain the incorrect sibling of acertainword w is higher than in the case of obtaining the successor or predecessor of w . This is because, in order to find the correct sibling of w , we must find the correct successor of w and the correct predecessors of that successor. 6.1.2. Is Additional Sentence (Bag-of -words) Information Necessary? One characteristic of the proposed method is that it combines the dependency information with the sen-tence (bag-of-words) information. In order to test whether dependency information alone is sufficient, we removed the sentence information from the proposed method and adjusted the scoring function described in Section 3.3 appropriately. For exam-probability that candidate c is associated with a pivot in dependency position d .We refer to the resulting method as NO-SENTENCE. If we compare the NO-SENTENCE method and the proposed method, using the full gold standard, Figures 4 and 5 reveal that the TOP-10 accuracy decreases by 7% for MLIT/NHTSA and decreases by 5% for Mainichi/Reuters.

One reason for the usefulness of sentence information is that some pivot words mark a topic, and are not necessarily in a (direct) dependency relation with the query. For example, in MLIT/NHTSA , we found that  X  X  X  X  X  X  X  (sunroof) in Japanese, as well as in English, has the pivot word  X  (rain) in common on the sentence level. However,  X  (rain) is not in a dependency relation. The following sentence is from the Japanese car complaints corpus MLIT, with translation in brackets: and the following from the English car complaints corpus NHTSA: As we can see, in Japanese, as well as in English  X  (rain), is used to describe the circumstances in which a problem with the  X  X  X  X  X  X  X  (sunroof) occurs. 6.1.3. Is a Word-Window an Alternative? For example, Haghighi et al. [2008] suggested using a word-window of four words instead of the entire sentence. In order to test our choice of using a sentence instead of a word-window, in the SENTENCE method, we replace the sentence bag-of-words by a four window bag-of-words. The resulting method is referred to as WINDOW. For both corpora pairs, we observe that WINDOW has an accuracy at TOP-10 that is approximately 2% lower than that of SENTENCE (see Figures 4 and 5). We suspect that a window of four words is too small to cover more topic information from the entire sentence.

Finally, we examine whether the window context, covering local information, can replace dependency information. Therefore, we use the proposed method and replace the dependency information by the local information from the word-window. The re-sulting method is referred to as SENTENCE-WINDOW. Compared to SENTENCE, the accuracy increases, for example, the TOP-10 accuracy is 2% and 4% higher for MLIT/NHTSA (Figure 4) and Mainichi/Reuters (Figure 5), respectively. However, as shown in these figures, the accuracy of SENTENCE-WINDOW is clearly lower than that of the proposed method, indicating that dependency information is more valuable than the local information from a word-window. Our proposed method not only extracts statistically relevant pivot words, but also weights each extracted pivot word individually using Equation (7). Here in this sub-section we investigate the impact of this weighting. We modified our proposed method PROPOSED such that all pivot words are weighted constantly 1. 25 We call the re-sulting method CONST-WEIGHT. As we can see in Figure 4 and 5, a constant weight reduces accuracy by aro und 1 to 2 percent points.

The advantage of weighting each pivot individually with our method, can be explained as follows. The proposed weighting, using Equation (7), tries to take two factors into account: (1) the ambiguity of a pivot word, and (2) whether it is used only in a few specific domains (sub-topics) or whether it is used more generally. The first factor is approximated by considering how many translations the pivot word has. It roughly holds that, the more translations a pivot has the more likely it is that it is ambiguous. The second factor is approximated by considering how many words the pivot is associated to. In Table IV, we show the four pivots with the highest weights, and also the four pivots with the lowest weights. We can see that both factors seem to be reasonably accounted by our suggested weighting. For example, the highly ambiguous pivot word  X   X  X  with many possible translations is the least useful, and gets a weight of 0. On the other hand the pivot word  X  X  X  X  X  X  X  (carburetor), is very specific and unambiguous, and therefore very helpful for our task. In the final part of our analysis, we estimate the contribution of Bayesian PMI to the accuracy of the proposed method. Normally, PMI is estimated using a maximum likelihood (ML) estimate of the probabilities p ( X = true | Q = true )and p ( X = true ), as in Equation (2). Next, we replace the Bayesian estimate of PMI, and use Equation (2) to determine if PMI ( x , q ) &gt; 0. The resulting method is referred to as ML-PMI. In contrast to the results of our proposed method using Bayesian PMI, the method ML-PMI has a lower accuracy (see Figures 4 and 5).

A maximum likelihood estimate of PMI is unreliable for low-frequency words, and therefore the poor performance for the ML-PMI method is not surprising (see the re-sults for the LOW gold standard in Figures 4 and 5). On the other hand, the suggested Bayesian estimate extracts only the pivot words x for which we are confident that PMI ( x , q ) &gt; 0, and this estimate can overcome the problems of ML-estimated PMI. We obtain a significant increase in accura cy for the LOW gold standard, for example the TOP-10 accuracy increases by 8% and 9% for MLIT/NHTSA and Mainichi/Reuters, respectively. Note that, on the other hand , there is little difference in accuracy for high-frequency words between ML-PMI and the proposed method (see the results for the HIGH gold standard in Figures 4 and 5). This is due to more reliable ML-estimates of PMI for these high-frequency words.

Finally, we present an example of the quality of the pivots extracted by the ML-estimated PMI and the Bayesian PMI. Using Bayesian PMI, we extract the following pivots for  X  X ylinder X  in NHTSA: However, using the ML-estimated PMI we extract: We can see that the latter list contains more pivot words that appear to be unrelated, such as  X  X ue X ,  X  X ake X , or  X  X ery X . 6.3.1. Approximating Bayesian PMI In Case of No Prior Information . As the analysis of ML-PMI shows, it is crucial to take into account the uncertainty that a pivot word x is positively associated with a word q . We denoted this uncertainty as This uncertainty is used in Equation (3) to extract a set of statistically relevant pivot words. We suggested here to use a Bayesian estimation of this uncertainty, which is theoretically sound and allows us in the future to incorporate prior information about p ( x , q ) in a principled way. 26 However, in cases where we us enopriorinformation,we can also use other non-Bayesian statistical methods to estimate p ( PMI ( x , q ) &gt; 0). We introduce here two alternative methods, the first is based on the log-likelihood-ratio (LLR), and the second is based on Fisher X  X  exact test.

One alternative, as we noted in Andrade et al. [2010], is to use the log-likelihood-ratio(LLR)toestimate p ( PMI ( x , q ) &gt; 0). The idea is described as follows: Let Z be a continuous random variable distributed according to a  X  2 distribution with one degree of freedom, then the probability, that x and y are stochastically dependent is approximately p ( Z  X  LLR( x , y )) [Dunning 1993], where LLR( x , y ) is defined as in Equation (12). Therefore the quantity p ( Z  X  LLR( x , y )) can be considered as the probability that there is (a positive or negative) association between the words x and y . where PMI ( x , q ) is calculated using Equation (2). Note that this estimation of to LLR. Furthermore, LLR is a two-sided test (see also the comment in Johnson [2001]), and hence, the value p ( Z  X  LLR( x , y )) should be more appropriately consid-ered as the likelihood that x and y are positively associated or negatively associated, not allow us to distinguish this case, we have to use PMI ( x , q ) to distinguish between those two cases. Nevertheless, the experime ntal results show that in practice there is little difference in accuracy when compared to Bayesian PMI, see Table V.
 Another method for setting an approximate value for p ( PMI ( x , q ) &gt; 0) is to use Fisher X  X  exact test for 2  X  2 contingency tables. This approximation is theoretically more sound, since Fisher X  X  exact test can be related to PMI ( x , q ) &gt; 0, as we will show in the following. First let us denote the odds ratio  X  for words x and q , in the following way: We can show (see appendix) that hypotheses H 1 . Then Fisher X  X  exact test allows us to test H 0 against H 1 . The resulting p -value is Agresti [1992]: 28 If we reject H 0 with p -value( x , y ), we can loosely say we support H 1 with probability 1  X  p-value( x , y ). Using Equation (16), this means we support PMI ( x , q ) &gt; 0with we can use The experimental results show that this approximation also delivers very similar results, see Table V. We proposed a method for finding new translations using an existing Japanese-English bilingual dictionary and a pair of comparable corpora. Given a word in Japanese for which we are searching for a translation (query word), the proposed methods attempts to find an appropriate translation by considering the context in which the query word and a translation candidate tend to occur.

The proposed method consists primarily of two steps. In the first step, we extract positively associated pivots for a query and its translation candidates from the depen-dency tree and from the bag-of-words in a sentence. We define four stochastic models for successors, predecessors, siblings, and for modeling the co-occurrence on the sen-tence level. Since each model is a Bernoulli trial, we can use the beta distribution to extract only the pivot words, which are positively associated with statistical signifi-cance. The resulting measure of positive association can be considered as a Bayesian estimate of the uncertainty of the point-wise mutual information. We also proved (see Section 6.3.1 and Appendix) that Fisher X  X  exa ct test for odds ratios can also be theoret-ically justified for estimating the uncertainty of this point-wise mutual information, andshowedthata  X  2 approximation works in practice equally well. In the second step, we estimate the probability that the query and a translation candidate have such pivot words in common in either any dependency position or on the sentence level. This probability is then used to calculate a similarity score between the query and a translation candidate.

In order to evaluate the proposed method, we implemented various previously pro-posed methods, and showed that the proposed method performs statistically signifi-cantly better that the best baseline on two different pairs of comparable corpora. Our analysis showed that the increase in trans lation accuracy can be attributed to the proposed uncertainty estimate of point-wise mutual information and the combination of dependency tree information with sentence (bag-of-words) context. The proposed method is especially promising for the situation in which we have good comparable cor-pora in which the query, as well as a correct translation, occu rs sufficiently frequently.
One strength of our method is that it successfully combines the local context from the dependency-parse tree with the broader context of the whole sentence. Though the sentence (bag-of-words) overlaps with the dependency-parse tree information, our analysis showed that clearly both context information helps to improve accuracy. This suggests that we might be able to increase a ccuracy even further by incorporating, additionally, other context information. For example, on the one hand, we might want to include more restricted local context using a word-window as in Section 6.1.3. 29 Or, on the other hand, we might want to consider to incorporate broader, global, context like a bag-of-words of several sentences, or the paragraph.

Finally, we note that the proposed method, as well as the baselines, use distribu-tional similarity as the only clue for finding a translation. However, we can comple-ment our research with other methods in order to find new translations. For example, we can generate a limited number of translation candidates using the transliteration of words in Katakana 30 and then score the translation candidates with the proposed method.
 Here we prove Equation (16), that is 31 Recall that PMI is the point-wise mutual information as defined in Equation (1), and  X  is the odds ratio as defined in Equation (15).
 P ROOF . First let us note that by definition of PMI ( x , q )itholdsthat Next, we transform the expression on the right-hand side: And therefore we have Similar to before, it also holds that And therefore we have Using Equation (17) and Equation (18), we conclude that
