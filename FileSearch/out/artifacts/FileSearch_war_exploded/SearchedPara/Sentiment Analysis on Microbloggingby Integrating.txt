 Microblogging has been acknowledged as a source of subjective opinions on a wide range of topics since 2006. Users can post mini messages using various software tools on different electronic devices, such as laptops, mobile phones and tablets without time or space limitation. Because of free format of messages and an easy accessibility of microblogging plateforms, Internet users tend to shift from traditional communication tools (such as traditional blogs or mailing lists) to microblogging services, and share opinions on varieties of topics or discuss current issues.
 Mining valuable information from microblogging has drawn many researchers X  attention in recent years and sentiment analysis on microblogging has been applied in many real applications [ 33 ]. For example, political parties may be interested in knowing whether people support their program or not. The U.S. State Department knew about the importance of this communication tool and asked Twitter to delay a scheduled upgrade which took place 3 days after the election on June 15th, 2009. Social organizations may ask people X  X  opinion on current debates. Jansen et al. [ 6 ] showed that 19% of Tweets mention a certain brand, of which 20% contained a sentiment. While reading news about politi-cal election [ 8 ], it was expected to obtain an overview about the support and opposition about presidential candidates. Analysing broader social and economic trends are also getting popular, such as the relationship between Twitter moods and both stock market fluctuations [ 10 ] or the relationship between consumer confidence and political opinion [ 12 ].
  X  X entiStrength is designed for web text using lexicon [ 25 ], in [ 38 ] a method explores feature definition and selection methods for sentiment polarity analysis. Zagibalov et al. [ 24 ] uses a unsupervised knowledge-poor method for domain-independent sentiment analysis.
 sed on the features mining from the texts. Popular social microblogging plat-forms, such as Twitter and Sina contain massive amounts of visual information in the form of photographs, which are commonly posted with texts. Researchers tend to make advantage of multi resources to mining microblogging. The role of pictures in conveying emotional messages and opinions is recognized as more important than the text. Indeed, a promising research direction is represented by the retrieval of images based on emotional semantics. Some systems based on social tagging such as ALIPR 1 allow users to annotate images using emotional labels. However, emotional mining for only images will ignore the context and background. Taking only one factor (text or image) into account is not enough to classify user X  X  sentiments. sponding image for sentiment analysis. Our work is inspired by the fusion of text sentiment analysis and image sentiment analysis. We aim to use both text and image information to help improve the result of sentiment analysis. The key issue is how to find a appropriate method to fuse text and image features. and image features satisfactorily. A new neighborhood classifier is proposed to fuse text data and image data properly. The results of the experiments on the Sina microblogging data show that combining text features and image features can improves the average performance of sentiment classification. 2.1 Sentiment Analysis With the development of Microblogging and text mining, opinion mining and sentiment analysis has been a field of interest for many researchers. A very broad and excellent overview of the existing work was done by Pang et al. [ 17 ]. sentiment reactions to various issues in political debate. They have found that sentiment was useful as a measure for identifying controversy. Jansen et al. [ 6 ] studied the Word-Of-Mouth effect on Twitter using an adjective based sentiment classifier, and it was helpful to improve the accuracy of classifying brands on Twitter.
 J.Read [ 23 ] considered emoticons such as  X :-) X  and  X :-( X  to form a train-ing set for the sentiment classification. For this purpose, the author collected texts containing emoticons from Usenet newsgroups. J.Read divided the dataset into  X  X ositive X  (texts with happy emoticons) and  X  X egative X  (texts with sad and angry emotions) samples. Classifiers (SVM and Naive Bayes) trained using emoticons were able to obtain of 70% accuracy on the test set. Go et al. [ 32 ] adopted Twitter to collect training data and then performed a sentiment search. The authors have used emoticons to construct corpora and obtained  X  X ositive X  and  X  X egative X  samples, and then various classifiers were tested. The best result was obtained by the Naive Bayes classifier with mutual information measure for feature selection. The author obtained the accuracy of 81% on their test set. Since emoticons can help analysis sentiment, there is reason to believe that investigating how to combine text features with image features to improve the performance of sentiment analysis is necessary. 2.2 Affective Image People X  X  understanding and feeling of images is subjective based on the semantic level [ 36 ]. As we have no clear definition to give evaluation of fitness other than the one in his mind, most conventional applications are lack of the capability to utilize human intuition and sentiment appropriately in creative applications such as architecture, art, music, and design.
 In order to analyse pictures X  emotion, we need to extract the effective infor-mation from visual signals. In [ 36 ], analysis and retrieval of images at the emo-tional level is studied. Early studies suggested that different semantic classes may need different specific features [ 34 ]. Obviously, the key problem is how to choose appropriate features which have close relation with image sentiment or emotion that express the image X  X  semantic.
 Colombo et al.[ 16 ] designed an image retrieval system which retrieve art paintings through mapping expressive and perceptual features to four emotions. The image was segmented into homogeneous regions, and some features including color, hue, saturation, position, and size from each region was extracted. At last, they used each region X  X  contrasting and harmonious relationships with other regions to capture emotions. Kuroda et al. [ 21 ] applied the feature of image regions to extract sky, earth and water which was used in the middle level of the system to derivative impression words and objects in landscape images. K-DIME [ 1 ] built an individual model for each user by using a neural net-work to judge pictures X  sentiment. Wang et al. [ 5 ] used specific features of images for affective image classification. Hayashi et al. [ 26 ] and Wu et al. [ 28 ] applied generic image processing features such as color histograms. In paper of [ 22 ], the authors applied Gabor and Wiccest features with SVM to perform emotional valence categorization. Hanjalic [ 27 ] and Wang [ 14 ] did some work on the affec-tive content analysis in movies.
 In this section, we will introduce the new sentiment classification method by considering data fusion. Fig. 1 is the flow chart of our microblogging sentiment analysis method. This method tends to make advantage of text features and image features to help better analyse sentiment.
 3.1 Text and Image Features In order to improve the efficiency of sentiment analysis, we considered two groups of features including text features and image features. is adopted for its good performance in Chinese document [ 37 ]. Some feature measurement method such as MI(Mutual Information), IG(Information Gain) and CHI are choosed to select features. emotional effects which comes from art theory and color combinations. We will use color and texture features to conduct our image feature selection. different cultures or backgrounds may have totally different feelings about the and color combinations from different views. For the color features, we adopted several measures which are shown in the follows:
Saturation and Brightness Statistics : According to Osgood dimensional approach [ 18 ], saturation and brightness can have direct influence on our pleasure, arousal and dominance. We use the method of Valdez et al. [ 30 ]to compute Pleasure, Arousal and Dominance with saturation and brightness.
The result obtained from the analysis gave us a significant relation between brightness, saturation and their emotional impact, which are expressed in the following equation: , where Br is Brightness and S is Saturation.

Hue statistics : Hue expresses the tone of a image. Mardia [ 7 ] measured Hue by vector-based circular statistics. We compute hue measurements like mean, hue spread, etc as our features.

Colorfulness : Datta [ 11 ] conducted experiments about image emotion and col-orfulness and he measured colorfulness using Earth Mover X  X  Distance (EMD) between the histogram of an image and the histogram having a uniform color distribution.
 Textures are also important to help us analyse the emotional expression of an image. Some artists and photographers usually create pictures which are sharp, or the main object they want to highlight is sharp with a vague background. Blurred images are often used in the category of art photograph images to express fear. Many features are developed to describe texture. We choose some normal features to help us analysis emotion of images.

Tamura textures :Tamura[ 3 ] used the Tamura texture features to analy-sis the emotion of a image. This method is popular among affective image retrieval [ 28 ]. We use the first three of the Tamura texture features: coarse-ness, contrast and directionality .

Gray Level Cooccurrence Matrix (GLCM) : Haralock [ 9 ] use GLCM method to analyse the emotion of a image. It is a classic method of mea-suring textures. We use GLCM to comput contrast, correlation, energy and homegeneity . 3.2 A Similarity Based Neighborhood Classifier Consider a common pattern recognition operation based on the K-nearest neighbors algorithm, which is a non-parametric method for classification and regression [ 29 ]. It assigns objects  X  X alue X  or  X  X lass X  based on K closest training examples in feature space . It inspires us to classify sentiment combining texts with images in text-image space .
 alized by introducing the L p vector norm defined for an n-dimensional vector (  X  instance into a class. The principle also makes sense in image sentiment field. Thus, we apply cosine similarity as the measure for both text and image features. The cosine similarity can be computed as equation (3) where vector These two kinds of similarities are represented in an coordinate plane, while the X axis represents image similarity and the Y axis represents text similarity in Fig.2.
 example. We take the distance between the test point and point (1,1) as our matching criteria. The best case is the test instance, which perfectly matches training instance both in text and image axis, that means (1,1) point. Usually, we just obtain a point in yellow area in Fig.2, and the closer to the point (1,1), the higher similarity achieved. We take the distance between the test point and point (1,1) as our matching criteria. The closer, the more similar to our labeled instance. The equation (4) deals with text feature and image feature. However, the two kinds of features many have different influences on the classification in some cases. Equation (4) is a special case of equation (5) when means text and image have the same weight. Whenp=1,wecanachieveasequ ation(6) presented: That means, when p = 1, the similarity is measured by the inner product between document elements(text and image) and the normalized weight repre-When p = 2, we obtain the equation(8) It becomes a normalized Euclidian distance between corresponding points in the text-image space.
 When p =  X  , we obtain sim ( doc  X  i, doc  X  j ) = lim The algorithm 1 shows how our proposed classifier works. In this section, we will show how our proposed method works by several experi-ments and analysis. 4.1 Data Collection As benchmark data of Sina microblogging with text and image are seldom col-lected, we collect Sina data by ourselves. 1620 documents with corresponding images are extracted from Sina platform 2 . We assigned a rating score to each microblogging. The microblogging with rating &gt; 3 were labeled positive, and those with rating &lt; 3 were labeled negative. The rest(rating = 3) are discarded for their ambiguous polarity and 1000 documents left. There are 575 positive instances and 425 negative instances. Fig.3 shows two examples of the data. Algorithm 1. A similarity based neighborhood classifier 4.2 Experiments Setup Documents have to be transformed into a suitable representation for classifica-tion tasks. We employ vector space model which is widely used in text classifi-cation as our feature vector weighting method.
 sion, the better solution is to adopt the weighted p-normal form. It turns out that the solution is useful, and there are two ways for text and image weight assignment. The first weight method is based on an intuitive idea. Nearly every Microblogging platform allow users to publish short messages with a limit of 140 characters. Actually, we assign the number of characters to text weight a =# characters and b = 140  X  a for image weight. We call it Text Proportion weighting method. The second way is taking the dimensions of each feature as weight according to the feature fusion method [ 13 ]and a features , b =# dimension of image f eatuers . We call this method Feature dimension weighting method. 4.3 Comparison and Analysis In this subsection, we conduct experiments to show the effect of the classifier with the combined text and image through comparing to the common classifers. All experiments are implemented based on WEKA 3 with version 3.6, with all parameters set to their default values.
 Tan et al. [ 19 ] reported that 5000 to 6000 numbers of Chinese text features would lead to a reasonable performance for almost every common classifier. As SVM and NaiveBayes are commonly used in sentiment analysis, we apply them to our sentiment classifiers. F value is adopted as the measure. Sample values of p = 1,2,5,9 and  X  were tested experimentally. Table 1 shows the perfor-mance of common classifiers considering onlyt text features and text combined images features. Fig.4 is the performances of our proposed classifier considering different p values with different feature selection method. Table 2 are average performance of our experiments based on common classifiers comparing to our proposed method.
  X  The results of Table 1 show that simply putting text features and image fea-tures together will not improve the performance of sentiment analysis greatyly.
Such as taken SVM considered, the F value improves only in CHI mode.  X  From Fig.4, we can see that Euclidian distance(p = 2) is not always appropri-ate for all feature extraction methods. For p-normal model the optimum values appear to occur for p values somewhere between 1 and 9; as the p-values grow larger, the amount of improvement over the common text sentiment analysis cases decreases.  X  From the experiments results of Table 2 we can see that weighted p-normal performs better than no-weight p-normal form. Feature dimension is 2.0% higher than no-weight model, and Text Proportion is 0.5% higher than no-weight model. What X  X  more, Feature dimension performs best from the experiment tables.  X  The average F value of Table 2 prove that our proposed method of data fusion performs better than common sentiment classifiers. For example, the average
F values of NaiveBayes for text features and text features with image features are 73.2% and 71.2%, and SVM X  X  F values are 73.5% and 70.6%. None of them are better than anyone of our proposed classifier X  X  performance(The worst average F value is 75.9%). In this paper, we proposed a new data fusion method combining text and image to improve the performance of sentiment analysis. We set up a dataset based on microblogging to validate our proposed method. Valued features are selected and sentiment polarity classification (positive or negative) on those messages is addressed. In text feature extraction, we use four typical feature extraction method (CHI, MI, IG) to select the features. In image feature extraction, we extract color features and texture features. Based on the fusion of text and image features, we proposed a new similarity based neighborhood classifier. Several comparison experiments show the efficiency of our proposed method. In the future we will extract more useful text features and image features to analyse microblogging sentiment.
