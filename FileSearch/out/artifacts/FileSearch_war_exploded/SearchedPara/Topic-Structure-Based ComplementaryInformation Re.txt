 QIANG MA
National Institute of Information and Communications Technology and KATSUMI TANAKA National Institute of Information and Communications Technology Graduate School of Informatics, Kyoto University 1. INTRODUCTION
Advances in information technology have changed our daily lives. Increasing amounts of information are available and our information needs and means of gathering information are becoming more diverse and differentiated than in the past. We can acquire information from different viewpoints or detailed in-formation by integrating information derived from different types of media. For instance, although a TV program may be of excellent quality and extremely re-alistic, time restrictions (e.g., on-air time) and the obligation to serve the public interest limit the depth and breadth of the information that can be presented.
However, information published on the Internet (Web) is diverse and has few restrictions, enabling us to search for Web pages that provide information to supplement the content of a TV program.

To find information similar to a given example, query by example (QBE) [Zloof 1977] and its variants are well-known and effective methods. Unlike a conventional QBE method, which requires the user to specify an example in explicit detail, [Henzinger et al. 2003] proposed a method for finding informa-tion similar to the content of a TV program by dividing closed-caption data into segments according to a fixed duration, and using each segment as an example to form a query. These methods provide an efficient way of search-ing for information that is similar to the given example. However, in many cases, we may want additional information or information from a different viewpoint. Although similar information retrieved by conventional methods may also contain additional information, the goal of these methods i.e., search-ing for similar information, limits their effectiveness in finding complementary information.

The issue of using information complementation to provide or acquire bal-anced and more detailed information is becoming increasingly important. To use an analogy, we need information from different viewpoints to provide a bal-anced diet, but we also want to enjoy a delicious banquet of detailed information on topics that we find especially interesting. As an approach to information com-plementation, we propose a novel method of searching for complementary Web pages based on using a topic-structure model to augment the content of a TV program.

We call an event or activity a  X  X opic. X  To represent the  X  X opics X  described in a video or Web page, this study uses the concept of topic structure, which is defined in Section 3. Intuitively, a topic structure consists of a pair of subject and content terms. A subject term is the dominant term on a Web page or in a text stream (a keyword sequence; e.g., closed captions of videos). A content term is a term that has a strong co-occurrence relationship with the subject term.
Naturally, the subject and content terms should both appear on the Web page (or in the text stream). Using the topic-structure model for content representation makes it possible to distinguish the roles of various keywords in a news item: subject terms play a title role and content terms play a supporting or content-structures from television news programs and Web pages. This method enables us to find interesting information by comparing topic structures.

Based on the topic-structure concept, we propose a content-join operation for information integration. In this paper, a topic structure is represented by a connected directed acyclic graph (DAG) and a join between two topic structures is represented by the union of their graphs.

We extract the topic structure of a given Web page or video and then find other Web pages or videos that provide complementary information. Based on the content join, we generate queries to find candidate Web pages or videos that may provide additional information for a given Web page or video. To select the most appropriate one from the search results, we use a concept called the complementarity degree, which is based on ranking the search results by computing the difference between the join results and the given example. Below, we present some of the results of an evaluation of our mechanism for retrieving complementary information.

We also propose an application system that enables users to view a television program and related Web pages at the same time. In our current work, the primary source of information is the content of a television program; Web pages that complement the program are secondary sources of information. The system enables users to watch a program on television, while complementary Web pages are presented simultaneously. We call this system WebTelop because it enables Web pages to be shown as captions for TV programs.

In Section 2 of this paper, we discuss related work. The topic structure model is described in Section 3. In Section 4, we describe the complementary informa-tion retrieval mechanism. In Section 5, we discuss some experimental results for our complementary information retrieval method. In Section 6, we describe the application system, WebTelop, and further experimental results. We con-clude with a brief summary in Section 7. 2. RELATED WORK
QBE [Zloof 1977] is a method of query creation that enables a user to search for similar documents, based on an example, in the form of a selected text string, document name, or list of documents. The mechanism we use for complemen-tary information retrieval is similar to that used in conventional QBE systems because it also formulates queries based on a given Web page or video clip.
However, in contrast to conventional systems, we generate queries based on the topic structure of a given item with the aim of finding complementary Web pages. Rather than simply being similar to the given item, the retrieved Web pages provide additional information.

Henzinger et al. proposed a method for automatically generating queries from closed captions to find Web pages that are similar to television programs [Henzinger et al. 2003]. Unlike their approach, our mechanism does not search for Web pages that are merely similar to the given example (television program). Our methods go beyond the retrieval of similar information.

TopicMap [XML Topic Maps 2005] is a new ISO standard for organizing, re-trieving, and navigating information resources. It provides powerful new ways of navigating large and interconnected corpora. In TopicMap, names, resources, and relationships are said to be characteristics of abstract subjects called top-ics. In contrast to TopicMap, we use the concept of topic structure, which is proposed in this paper, to describe the subject and content of an information resource through the use of structured keywords. We also extract the topic structure automatically rather than manually through user specifications.
Topic detection and tracking (TDT) research has led to algorithms for dis-covering and weaving together topically related material in data streams such as newswires and broadcast news [Allan et al. 1998; Spitters and Kraaij 2002;
TDT site 2005; Wayne 2000; Yang et al. 1998]. In TDT, the notion of  X  X opic X  is defined as a seminal event or activity, along with all directly related events and activities. Therefore, in TDT, a topic is constructed from multisequential stories that include a variety of events and activities. The  X  X tory X  concept in TDT is similar to our  X  X opic X  concept. However, in our work, each event (or activity) is considered a separate  X  X opic, X  although it may relate to other events. We use a topic-structure model to represent the content of a  X  X opic. X 
The join is a fundamental query operation in a relational database for in-formation retrieval. It is obtained from two different relations based on the
Cartesian product of these two relations [Mishra and Eich 1992]. [Guha et al. 2002] proposed approximate matching of structure and content to integrate
XML data sources. In this paper, a content-join operation based on the concept of topic structure is used to formalize the process of information augmentation.
In addition, based on the proposed join operation, we search for information that expands on the original information and broadens its coverage.
Some approaches to information integration extract the relationship between keywords that appear in the title and body of a news article [Maeda et al. 1997;
Muragami and Hirata 2001]. The focus of these approaches is on how to or-ganize information in the same type of media. Like our work, they consider the relationship between keywords appearing in the title and body. However, we propose using the topic structure to represent the different roles of these keywords. We also propose a mechanism for retrieving complementary infor-mation to enable information from different media, such as TV and the Web, to be integrated. 3. TOPIC STRUCTURE 3.1 Topic Structure
As previously mentioned, a topic structure is a pair of subject and content terms; subject terms are the dominant terms on a Web page or in a video, while content terms have strong co-occurrence relationships with the subject terms.
Both subject and content terms appear on a Web page or in a video. A primitive topic structure is defined as follows [Matsukura et al. 2001]: where S and C are a set of subject terms 1 and content terms, respectively.
As an extension to this, we assume that a topic structure is hierarchical, i.e., one topic may consist of several subtopics. Each subtopic describes a part of the main topic. In other words, S (named set of subject elements) or C (named set of content elements) may include several topic structures. Our concept of an extended topic structure is defined as follows: where  X  |  X  stands for  X  X r X  and  X  +  X  means that the element(s) may appear more than once. In addition, a keyword should not occur more than once in a topic structure. That is to say, in a topic structure, the same keyword cannot become both a subject term and a content term.

By distinguishing the subject and describing the roles of keywords, we can use the topic-structure model to search for similar or dissimilar information from the perspectives of subject and content. For example, we can retrieve in-formation that contains the same subject terms as the original one, but different content terms, or the same content terms, but different subject terms. 3.2 Topic Graph
A topic structure is represented as a connected DAG having at least two vertices: one standing for a subject term and the other for a content term. We call this a topic graph. In a topic graph, a vertex represents a keyword. A directed edge represents the subject X  X ontent relationship between two keywords; the source vertex denotes a subject term and the destination vertex denotes a content term.

Definition 3.1 ( Topic Graph ). A given topic structure t can be represented as a connected DAG, G(t).
 where V is a vertex set that represents the keywords within t . E ( a directed-edge set. The directed edge e = ( u , v ) represents the subject X  X ontent relationship between the keywords u and v . V  X  2, E = X  .
 Figure 1 shows an example of a topic graph. In this example,
This topic graph represents the topic structure 3.3 Topic-Structure-Based Join
The integration of information derived from multimedia is regarded as a join, which combines related content from different media such as TV and the Web.
This perspective, based on the topic structure, enables us to define the join of two topic structures, thus establishing a formal process for information integration (An example of joining is shown in Figure 2).

Definition 3.2 ( Topic-Structure-Based Join ). The join of two topic struc-tures, t and t ; means that their topic graphs are combined to form a connected
DAG. where G ( t ) and G ( t ) stand for the respective topic graphs of t and t ; for empty.

In this definition, we have restricted the join result to a connected DAG, i.e., the join of two topic structures should result in a single topic structure. In addition, t  X  =  X  .

If the join of two topic structures is not  X  , we say that the two topic struc-tures are joinable. Two Web pages that have some joinable topic structures complement each other.

A Web page may consist of several topics, and these topics can be represented as a set of topic structures. For example, Web page p with two topic structures, t and t 2 , may be represented as t p ={ t 1 , t 2 } . Therefore, a group of Web pages can be considered a set of sets of topic structures. In this paper, for simplicity, we use a set of topic structures to represent the topics of Web pages. where T P stands for the topic structures of Web page set P and t the topic structures of Web page p i , which is a member of P .
 We can also represent the topics of a text stream as a set of topic structures: where T S stands for the topic structures of the text stream S ( stands for the topic structure of the sub-stream s i .

Therefore, the process of integrating text streams and Web pages can be formally expressed as the join of two topic-structure sets.

Definition 3.3 ( Join of Topic Structure Sets ). Given two sets of topic struc-tures, T and T , the join of T and T is defined as follows: 3.4 Complementarity Degree
In our current work, we use the depth and width of a topic graph to represent, respectively, the level of detail and breadth of the information. That is, if the is very wide, it may describe the topic from several perspectives with high coverage of the content. Therefore, basically, the complementarity degree can be computed by comparing the topic graphs of the given example and the join result.

Definition 3.4 ( Complementarity Degree ). The degree of complementarity of the topic structure t to a given topic structure t is defined as the difference in area between the topic graphs of the join results ( t t ) and t . where D ( G ( x )) and W ( G ( x )) are the depth and width, respectively, of the topic graph of topic structure x .

We compute the shortest path from each root node to each leaf node by count-ing the number of edges. Then we define the longest one as the depth of the topic graph. Here, the root node and leaf node, respectively, denote nodes that have no parent and no child nodes. The width of a topic graph is computed as the minimum number of root and leaf nodes.

Actually, the complementarity degree is heuristically computed as the area difference between two topic graphs. Other computing methods can also be considered. For example, we can also compute the complementarity degree as the sum of differences in the depth and width. We will compare these methods in our future work. 3.5 Topic-Structure Extraction 3.5.1 Co-Occurrence Relationship. To extract the topic structure from a given example, we define two kinds of co-occurrence relationship: (1) the undirected term co-occurrence ratio and (2) the directed term co-occurrence ratio.

Definition 3.5 ( Undirected Term Co-Occurrence Ratio ). The undirected term co-occurrence ratio is used to estimate the co-occurrence relationship between two words. When the words w 1 and w 2 co-occur frequently within a topic corpus, we say that the two words have a strong co-occurrence relationship and their co-occurrence ratio will be high. We compute the undirected term co-occurrence ratio cooc ( w i , w j ) between words w i and w j using the following function: where df ( { w i } ) is the number of topics containing the word w ified topic corpus and df ( { w i , w j } ) is the number of topics containing both w and w j .

Definition 3.6 ( Directed Term Co-Occurrence Ratio ). Within a topic corpus, the directed term co-occurrence ratio currence of topics containing the keyword w j in topics containing the keyword w . We formulated this definition as follows: where df ( { w i , w j } ) is the number of topics containing both w df ( { w
Although cooc ( w i , w j ) = cooc ( w j , w i ), often than not. 3.5.2 Subject and Content Degrees. We define the notion of  X  X ubject de-gree X  to determine whether a keyword has a high probability of being a sub-co-occurrence ratio with other keywords, and (2) its term frequency. That is, if a keyword has high ratios of directed co-occurrence with other keywords words, it is considered the subject term. We also defined the  X  X ontent degree X  to determine the content terms of a topic based on the undirected co-occurrence relationship.

Definition 3.7 ( Subject Degree ). The subject degree sub ( w within a topic is defined as follows: where tf ( w i ) is the term frequency of w i , occurrence ratio of w i and w j , and n is the number of keywords within that topic.

Definition 3.8 ( Content Degree ). The content degree con ( w w within a topic is defined as the sum of its undirected term co-occurrence with the subject terms of w i . where S is the subject-term set.

Based on the subject degree, we determine the subject terms for a topic. The keywords, which have higher subject degrees (top M , etc.), are considered the subject terms. We then extract the content terms based on the content degree.
That is, when we rank (in descending order) the keywords of the topic (excluding the subject terms) by their content degrees, the top N keywords are chosen as the content terms. In the example shown in Figure 3, k undirected term co-occurrence ratio (0.5) with the subject term k 1. Hence, k 2 is selected as the content term (in this example, M = N =
If a given Web page or video (with closed captions) contains only one topic, we use the notions of subject and content degrees to extract its topic structure without further work. In this paper, we assume that each given example (Web page, video, etc.) used for query generation has only one topic. If a user gives an example with multiple topics, we simply generate queries for each individual topic or require the user to explicitly specify the topic of interest. 3.5.3 Extraction of Topic Structure from a Web Page. Since a Web page may contain more than one topic, it can be represented as a topic-structure set. To extract the topic-structure set of a Web page, we first assume each paragraph of a Web page has only one topic and extract its topic structure. Then we merge the joinable topic structures within these topic structures by using the reduction function defined below to construct the topic-structure set of the Web page.
Definition 3.9 ( Reduction of Topic-Structure Set ). For a given topic-its members: where G ( t i ) is the topic graph of topic structure t i a DAG. 3.5.4 Extraction of Topic Structure from a Text Stream. Since a text stream (closed captions of a video) may consist of multiple topics, we first need to detect the topics it contains, i.e., we should segment the text stream into semantic units. Figure 4 illustrates the flow for the topic-detection procedure. Here, we use closed captions as the text stream. The basic idea is that a high proportion of keyword pairs with high undirected co-occurrence ratios (precomputed in a topic corpus) from among all keyword pairs within various closed captions suggests that these captions describe one topic.

The details of the procedure are as follows (see also Figure 4). Here, CT the keyword set used to detect a topic at time point t i . We extract only nouns as keywords from the received closed captions 2 for further processing with Chasen [ChaSen 2005], a Japanese morphological analysis tool. ST and ET , respec-tively, are the initial and terminal time points of a segmented topic. 1. Let CT 0 = X  , ST = 0, i = 1. 2. Receive the closed captions. If there are no other closed captions, stop. 3. After receiving the closed captions at time point t i word set K from the closed captions. 4. Let CT i = CT i  X  1  X  K . 5. Compute the rate (proportion) cwf ( t i ) of keyword pairs with high co-occurrence ratios from among all keyword pairs within CT i co-occurrence ratio means that the undirected co-occurrence ratio of the two keywords is greater than a pre-specified threshold  X  . m is the number of keywords included in CT i . 6. If cwf ( t i ) &gt; ,goto9. is a prespecified threshold. 7. Let ET = t i . The initial and terminal time points of the output topic topic are ST and ET , respectively. The keywords of such a topic are also output for further processing. 8. Let CT i = X  , ST = t i , i = i + 1. 9. Receive the closed captions. If there are no other closed captions and CT
Intuitively, we can also compute the co-occurrence relationships of keywords belonging to adjoining closed captions. If these co-occurrence relationships are weak, we can say that the adjoining closed captions describe different topics. However, in this method, the next closed caption would have to be prereceived.
Moreover, each closed caption would have to be one semantic unit, or at least one whole sentence. In many cases these requirements cannot be satisfied, e.g., sometimes we only receive a portion of a sentence.

When a topic is detected, we can extract its topic structure based on the subject and content degree. If necessary, we can also use a reduction function example of a topic structure extracted from a segmented TV news report.
Video segmentation based on signal recognition has been extensively inves-tigated, but most methods are very time consuming [Maybury 1997]. Infomedia [Wactlar 2000] and [Mani et al. 1997] introduced various methods for video seg-mentation based on analysis of closed captions. However, because these meth-ods require the whole body of data to be scanned, they cannot be applied to continuously received data streams. 4. RETRIEVAL OF COMPLEMENTARY INFORMATION
The retrieval of complementary information consists of three phases: (1) ex-traction of the topic structure from a given example (Web page, video, etc.), (2) query generation using the extracted topic structure, and (3) Web searching and ranking of the retrieved Web pages. Figure 6 illustrates the processing flow for our method of retrieving complementary information. 4.1 Query Generation
Here, we assume that the subject-element and content-element sets of the given topic structure do not include other topic structures. The generated query is used to find Web pages that contain a topic structure, which is joinable with that of the given example. Because the join result of two joinable topic structures provides more detailed information than the original ones, we say that each topic structure complements the other.
A previous report [Oyama and Tanaka 2003] showed the feasibility of ex-tracting the topic structures of a Web page by using the  X  X itle X  and  X  X ody X  tags.
Based on this work, we assume that the keywords appearing in the title and body of a Web page are its subject and content terms, respectively.
We defined four kinds of queries for finding Web pages related to a given ex-ample: (1) CD (content-deepening), (2) SD (subject-deepening), (3) SB (subject-broadening), and (4) CB (content-broadening) queries.

CD and SD queries are based on a join such that subject terms in one topic structure appear as content terms in the other. Such joins add more details to the original information.

SB and CB queries are based on a join such that two topic structures have the same subject or content terms. Such joins provide broader coverage of the information.

Hereafter, let the topic structure t of a given example be ( { c term, respectively. In addition,  X  X nsubject X  and  X  X ncontent X  indicate that the fol-lowing terms are the respective subject and content terms of a topic structure contained in the retrieved Web page.  X   X   X  and  X   X   X  stand for  X  X ogical AND X  and  X  X ogical OR X , respectively.  X   X   X  means  X  X ogical NOT X . For example, the query ( insubject : k 1  X  k 2 )  X  (  X  ( incontent : k 3  X  k 4 )) means that k terms of a topic structure contained in a retrieved Web page and k not appear as its content terms. 1. Content-deepening query: For the topic structure t , using a content-deepening query, we find Web pages in which the subject terms of the topic structures appear as the content terms of t . To avoid the joining result exclude Web pages in which the content terms of the topic structures appear 2. Subject-deepening query: For the topic structure t , using a subject-deepening 3. Subject-broadening query: Using a subject-broadening query enables us to 4. Content-broadening query: The topic structure of a Web page searched for
Figure 7 shows examples of these queries and the join between a retrieved page and the given topic structure.

To distinguish this method from the retrieval of similar information, we have not defined queries for searching for information similar to a given example.
Moreover, we exclude similar Web pages that include the same topic structure as the given one by using a negative condition part. Here, the negative condition part is the sub-query starting from  X   X   X  in the latter half of each query. The first one-half is called the positive condition part. Using the negative condition part may mean that we miss some valuable information, but it reduces the number of search results, enabling us to acquire the target results more quickly. We discuss this issue below in our evaluation of the method.
 In our current work, we generally use  X   X   X  to form the positive condition part.
When this is too restrictive to acquire sufficient candidate Web pages, we use  X   X   X  instead of  X   X   X  to form queries. 4.2 Ranking by Complementarity Degree
For a given topic structure, we can generate the four kinds of query described above. For each query, we may acquire more than one Web page. To select the most complementary one, we use the complementarity degree to rank the retrieved pages.

Let the reduced topic-structure set of a searched Web page p be
Let the topic structure of the given example be t . The complementarity degree of p can be computed as where com ( p ) stands for the complementarity degree of page p to the given example.

The Web page p with the highest complementarity degree ( com ( p ))is selected as the complementary Web page for the given example (Web page, video, etc.).
In addition, we also consider the rankings returned by Google. For instance, if two Web pages have the same complementarity degree, we select the one ranked higher by Google as the complementary Web page. 5. EVALUATION
Our method differs significantly from conventional information retrieval meth-ods, so there is no formalized way to evaluate it. Hence, we first tried to compute precision ratios obtained with our method based on human judgment. After that, we tried to evaluate our method by comparing the search results and through failure analysis.

In this section, we describe four evaluations of our mechanism for retrieving complementary information. In these evaluations, we implemented the queries using Google API [Google Web APIs 2005]. In evaluation I, we evaluated the methods for topic detection and topic-structure extraction. In evaluation II, we evaluated the method for complementary information retrieval. In evaluation
III, we compared methods for retrieving complementary and similar informa-tion. We also examined the differences between the four kinds of query defined in Section 4.1. In addition, we examined the effects of the negative condition part on the discovery of complementary information.

We used closed captions (in Japanese) from NHK News 7 (a well-known TV news program in Japan) during a 9-month period (from September, 2002 to May, 2003) to build a co-occurrence relationship dictionary. The average size of received closed captions was 26.53 KB per day. First, we manually segmented the closed captions for a 1-month period (September, 2002) and generated a pre-liminary collection of topics to build a preliminary co-occurrence relationship dictionary. We then used this preliminary dictionary to process the remaining closed captions to update the collection of topics and the co-occurrence relation-ship dictionary. We used ChaSen [ChaSen 2005] for Japanese morphological analysis and only nouns as keywords for further processing. To exclude stop words, we built a stop-word dictionary, which contains 593 terms in English and 347 terms in Japanese. Based on the results of a preliminary experiment in which we used a preliminary co-occurrence relationship dictionary gener-ated from closed captions for a 1-month period (September, 2002), we set the thresholds  X  and at 0 . 15 and 0 . 28, respectively.  X  and are used for topic detection as described above. The closed captions for a 1-month period (October, 2002) were used as the training data. 5.1 Evaluation I: Evaluation of Topic Extraction from Closed Captions
We used the closed captions of NHK News 7 programs obtained over 85 days (from May to July, 2003) as the evaluation data. In total, we detected 3068 topics (segments) from these closed captions. We extracted two subject terms and three content terms for each topic as its topic structure.

If the proportion of words describing one event to all the words of the seg-mented closed captions was greater than 0.8, we considered the topic to have been well detected. In addition, if the topic structure extracted by our method included more than four terms that accurately represented the topic, we con-sidered the topic structure to have been well extracted. Based on these criteria, 2460 topics and 2129 topic structures were well detected and extracted, re-spectively. The precision ratios [the ratio of well-detected topics (well-extracted topic structures) to the total number of topics (topic structures)] were 0.802 and 0.694, respectively. Moreover, 1893 topics were well segmented and their topic structures were well extracted. We manually analyzed the closed captions and detected 3506 topics. For this process, the recall ratio for topic detection (the rate of successfully detected topics to the number of topics that should be detected) was 0 . 702.

There were 608 failures in topic detection. Depending on the failure pattern, we classified these as follows.

In 349 cases, the system failed to detect topics describing new events. Here, a new event meant that there were few similar events in the prebuilt topic col-lections. We could not satisfactorily compute the co-occurrence relationships between terms contained in the closed captions describing such events.
The 201 detected topics described more than two events. The parameters used for topic detection and the co-occurrence relationship dictionary were considered the main reasons for this.

The closed captions of the detected topics were too short in that they contained less than two sentences, or the time interval between the first and last receipt of data was less than 10 s. We think that this was insufficient to describe an event. In NHK News 7, only the words spoken by the news announcer are available on the closed-captions service. This limitation caused this kind of failure; there were 43 such failures.
 Fifteen failures were caused by  X  X ypos X  in the closed captions.

There were 939 failures in topic-structure extraction. We classified these according to their probable causes: There were 503 failures in topic detection.

Segmented closed captions that are considered to describe one topic may include  X  X oisy X  sentences describing another event or activity unrelated to the main event. We extracted the keywords from these noisy sentences as subject or content terms. There were 158 such failures.

Words that were more suitable as subject terms had a low-term frequency and we were unable to extract them as keywords of the topic structure from the closed caption data. There were 113 such failures. For example, proper nouns, such as the name of a region, organization, or person often appeared only once, although they were sometimes suitable for use as subject or content terms.

Eighty-seven failures were caused by the division of words such as the name of a person or organization. For example,  X  X ed Socks X  (in Japanese, meaning the Boston Red Sox baseball team) might be divided into  X  X ed X  (in Japanese) and  X  X ocks X  (in Japanese) by ChaSen and be extracted as subject or content terms at the same time.

We distinguished a word from its synonyms, but sometimes simultaneously extracted both a word and its synonym as subject or content terms. This was inappropriate and resulted in 78 failures.

We found that our topic-detection and topic-structure extraction methods were unsuitable for closed captions describing new events because they de-pend on co-occurrence relationships between words. In our evaluation, we used 28 days X  worth of closed captions to build the co-occurrence relationship dic-tionary. For these data, the precision ratio (for both successful topic detection and topic-structure extraction) was 0.735 (Table I). In contrast, the precision ratio for the rest of the data was 0.526. These results clearly show that the co-occurrence relationship plays an important role in our methods.
The following approaches can be used to improve the quality of the co-occurrence relationship dictionary: We can update the dictionary more frequently.
 We can use Web searches to discover the co-occurrence relationship of words.
For example, we could search the Web and use the number of results for topics containing the word(s) used in the search query to build the co-occurrence relationship dictionary.

In addition, to improve our topic-detection and topic-structure extraction methods, we could use the idf (inverse document frequency) value, not just the co-occurrence relationship and tf (term frequency) value. Using this strategy might prevent the failures that occur when a candidate subject term has a low-term frequency or when segmented closed captions describe more than two events. 5.2 Evaluation II: Evaluation of Complementary Information Retrieval 5.2.1 ( a ) Complementary Retrieval Without Ranking by Complementarity
Degree. We used topic structures extracted from videos of NHK News 7 and their closed captions for 3 days (May 28, June 20, and July 20, 2003) as the given examples in this evaluation. We detected 88 topics and extracted two subject terms and three content terms for each topic.

In the evaluation, based on the query definitions described in Section 4.1, we generated four kinds of query for each topic structure and submitted them to
Google via the Google API service [Google Web APIs 2005]. For each query, we first generated a query (called a 5-key query) using a topic structure contain-ing two subject terms and three content terms. If no results were returned by
Google, we then generated a query (called a 3-key query) using a simpler topic structure containing one subject term and two content terms.
 Google are shown in Table II. We implemented these queries using the following
Google API terms:  X  X llintext, X   X  X lltitle, X   X  X ntitle, X   X  X llintitle, X  and  X   X  X llintext X  restricts the results to Web pages whose text contains all of the query terms following it.  X  X llintitle: X  restricts the results to those pages whose titles contain all of the query terms following it. If we prepend  X  X ntitle: X  to a query term, the Google search restricts the results to documents containing that word in the title. On the other hand, if we prepend  X  X ntext: X  to a query term, the Google search restricts the results to Web pages containing that word in the text.
We limited our search domain to news Web sites. Because many news articles describe only one topic, this limitation also meant that each retrieved Web page generally had only one topic. There is no need to extract multiple topic structures from such Web pages. Thus, the complementarity degree of these retrieved Web pages to the given example should have been the same. Therefore, in this evaluation, we did not compute the complementarity degree of each retrieved Web page. For each valid query that produced more than one result from Google, we used the top result as ranked by Google as the complementary Web page.

Two graduate students separately selected relevant complementary Web pages by considering the relationship between those pages and the video (the given example): if the page was related to the video and provided supplementary information, it was considered a relevant result. Here, provided supplementary information means that the information provided a broader (or deeper) perspec-tive on the subject (or content) of the video. The students assessed different results for 8, 7, 14, and 15 pages of CD, SD, CB, and SB queries, respectively.
In these cases, we let them discuss the final assessments. Table III shows the evaluation results. Although there were some limitations, the evaluation re-sults indicate that our retrieval mechanism was effective for finding Web pages that provide supplementary information. Figure 8 shows two examples of re-trieved complementary Web pages for a TV news report. The TV news report described a Diet debate on a political scandal. The Web page on the right de-scribes the scandal in more detail and the one on the left describes a Diet debate on postal privatization to broaden the perspective.

We noticed that if a query was based on a topic structure containing proper nouns, the search results were better. This suggests that proper nouns play an important role in topic-structure-based Web retrieval. We will investigate this feature in our future work.

In our evaluation environment, after the corresponding closed captions were received, the average time delay before a Web page related to the video was displayed was 2.85 s. This shows that it is possible to develop a system that synchronizes a TV program and related Web pages online, as we have demon-strated with our WebTelop system described below.

We also considered the following approaches to improve the precision ratio of the complementary information retrieval mechanism:
Improving the topic detection and topic-structure extraction methods. Better results were achieved when a query was generated from a well-extracted topic structure. In particular, if the topic structure included proper nouns, the search results were better.

Ranking the search results based on the complementarity degree. We show evaluation results realized through this approach below. 5.2.2 ( b ) Reranking Based on the Complementarity Degree. In evaluation
II(b), we built a filter based on the complementarity degree to select complemen-tary Web pages for a given example from the search results. The given examples and the search results of evaluation II(a) were used. First, we extracted the topic structure of the given example and generated four kinds of query, the same as in evaluation II(a). We then submitted these queries to Google through the Google
Web API service. Finally, we ranked the retrieved Web pages by using the com-plementarity degree to select the ones that provided additional information on the given example. In this evaluation, we used the top 10 Web pages that were returned by Google and were available on the Web for each query.

We computed the complementarity degree of these Web pages using the method described in Section 4.2 (  X  =  X  = 0 . 5). Our filter selected the Web pages with a higher complementarity degree than the threshold ( plementary Web pages. The evaluation results are shown in Table IV. The recall ratio is the proportion of relevant Web pages selected using the complementar-ity degree from all relevant Web pages as judged by the users. The precision ratio is the proportion of relevant Web pages selected using the complemen-tarity degree from all the selected Web pages. We found that many Web pages contained more images and videos than pure text and that this resulted in failures when we attempted to compute their complementarity degree.
Furthermore, if we selected Web pages with the highest complementarity degree as the complementary Web page for a given example, the precision ratios for the SB, SD, CB, and CD queries improved to 0.807, 0.693, 0.613, and 0.688, respectively, compared to those of evaluation II(a). This shows that the proposed complementarity degree is useful for selecting the most complementary Web pages from the search results.
 5.3 Evaluation III: Comparison Evaluations
In evaluation III, we compared methods for retrieving complementary and sim-ilar information. We also carried out an evaluation to examine the differences between the four kinds of query defined in our complementary information retrieval mechanism.

In evaluation III, the topic structures used to generate queries were the same as in evaluation II(a). For each query, we used the pages (a maximum of 10) returned by Google as the search results. In comparing the search results for different queries, we used the following criteria: (1) average similarity between sets of results, (2) average number of common results, and (3) average number of results.

Average similarity between sets of results: S ( A , B ), the average similarity of the sets of results for queries A and B was computed based on a vector-space model as follows: where N is the number of queries generated from the given topic structures.
In our evaluation, N = 88. m k (  X  10) and n k (  X  10) are the number of results (retrieved Web pages) for query a k (an A query) and b k (a B query) generated from topic structure k , respectively. p i and p j are Web pages retrieved by queries a k and b k , respectively. V ( p i ) and V ( p j and p j , respectively.

Average number of common results: CR ( A , B ), the average number of com-mon results for queries A and B was computed as follows: where r a
Average number of results of retrieved Web pages: Num ( A ), the average num-ber of retrieved Web pages for query A was computed as follows: 5.3.1 ( a ) Comparison between Methods for Retrieving Complementary and
Similar Information. In this evaluation, we compared methods for retrieving similar and complementary information. Based on the topic-structure model, we defined a similar Web page as one that contained the same topic structure as the given example. We called a query used to find a similar Web page a SIM query. For a given topic structure t = ( { s 1 , s 2 , ... query is defined as follows.
A 5-key SIM query was implemented using the Google API as follows.
A 3-key SIM query was implemented as follows.
We compared the search results of each complementary query (CD, CB, SB, and SD) with the SIM query. The evaluation results are shown in Table V. In addition, the number of valid (more than one Web page retrieved) 5-and 3-key SIM queries were 29 and 45, respectively.

The negative condition part of the CD query ensured that it did not produce any search results in common with a SIM query. Usually, the keywords appear-ing in the title of a Web page also appear in the body. Thus, as a result of its negative condition part, CD queries excluded pages that might be retrieved by SIM queries.

It is very likely that a keyword appearing in the title of a page will appear in the body. However, keywords that appear in the body do not always appear in the page title. Therefore, in contrast to CD queries, SD queries, produced some search results in common with SIM queries.

According to the query definitions, Web pages that include the given topic structure should be excluded from the search results for CB and SB queries.
However, the results of the evaluation showed that CB and SIM queries, as well as SB and SIM queries, produced some common search results. This was caused by the way in which these queries were implemented. For example, let the given topic structure be ( { a , b } , { c , d , e exclude Web pages that include the topic structure ( { a , b retrieved by a 3-key SIM query. Similarly, a 5-key SB query would not exclude
Web pages that include a topic structure such as ( { a } , pages might also be retrieved by a 3-key SIM query.

The evaluation results show that CB, CD, SB, and SD queries are different from SIM queries. In other words, our mechanism for retrieving complemen-tary information produces different results from similar information retrieval methods.
 5.3.2 ( b ) Comparison of CB, CD, SB, and SD Queries. We also compared the search results for CB, CD, SB, and SD queries. Table VI shows the evaluation results. As these results show, the different queries obviously produced different search results, with all of them differing from each other. However, in some cases, although the query type was different, there were a few common search results. Moreover, there was a large difference between  X  X ntitle X  and  X  X ntext X  searches. Possible reasons for this are as follows:
A Web page may include multiple topics. Therefore, it may provide answers to different types of queries.
 Many Web pages do not use the title tag as well as we had supposed. Some
Web pages do not use a title tag and some pages include descriptions of the site name, for example, in their title tags, rather their subjects. This tendency makes it difficult to use only title and body tags to extract a Web page X  X  topic structure. Moreover,  X  X ntitle X  and  X  X ntext X  Google searches did not always work well.

The query implementation depends on the Google API and a 5-key differs from a 3-key query. 5.4 Evaluation IV: Effects of the Negative Condition Part
In evaluation IV, we evaluated the effects of the negative condition part on the retrieval of complementary information. We compared the respective search results of queries with and without a negative condition part. The evaluation environment was the same as in experiment II(a). Queries that did not include a negative condition part are shown in Table VII. As in evaluation II(a), we used the top results returned by Google as complementary pages. We also computed the precision ratio of queries without a negative condition part. If the retrieved complementary page was related to, and provided additional information re-garding the given example, we considered it to be a relevant Web page. The evaluation results are shown in Table VIII. In addition, Figure 9 shows the dis-tribution of relevant pages retrieved for each kind of query. The ovals stand for the relevant page set for each query. The intersection of two ovals represents the common relevant pages for the same given topic structures. The evaluation results clearly show that the negative condition part improved the precision ratio of complementary information retrieval.

We assumed that the subject and content terms of a Web page X  X  topic struc-ture would appear in its title and body, respectively. However, the actual topic structures of Web pages are more complex and in many cases do not satisfy our assumption. For example, a keyword appearing in the title or body may not always be a subject or content term of a Web page. Thus, we could miss valuable
Web pages that could provide additional information on a given example. One way of avoiding this would be to search the Web using all the queries and then ranking the search results based on their complementarity degree.
 6. APPLICATION SYSTEM: WEBTELOP 6.1 WebTelop Concept
Huge advances in information technologies and their widespread availability have created great changes in our lives. Among these technologies is digital broadcasting. Digital television combines broadcasting and computer technolo-gies into a powerful new medium, changing the way consumers watch TV [Digi-tal Video Broadcasting Project 2003]. In addition, with the spread of broadband services that provide high-speed connection to the Internet, rich content (video, music, etc.) can be viewed in real time.

We propose a system for integrating and presenting TV-program and Web-page content online. In our current work, the primary source of information is TV-program content. Web pages, which are retrieved in real time using our mechanism for complementary information retrieval, are a secondary source of information. With our system, these Web pages appear concurrently with the
TV program. We call this system WebTelop because it enables Web pages to appear as captions to a TV program. The Web pages are not just  X  X imilar X  to the TV program, but provide additional information on the program topic or describe the topic from different perspectives. 6.2 Prototype System
WebTelop analyzes the closed captions of a TV program and searches for com-plementary Web pages. Therefore, a user can watch TV program and browse a complementary Web page at the same time. Figure 10 shows the system con-figuration of WebTelop.
 A user is asked to specify the query type in advance. As described above,
CD, SD, CB, and SB queries can be used together or separately to search for complementary Web page. Users can specify more than one type of query. them.
 Figure 11 shows the WebTelop user interface. The top left window is the
TV viewer in which the TV program and its closed captions are displayed. The bottom left window is a bookmark viewer. A user who is interested in a TV program and its complementary Web page can click on the icon at the top right to record them for viewing later. The subject terms of each recorded TV program are presented in the bookmark viewer as an index. The user uses the buttons in the bookmarker viewer to select and view a stored TV program and related Web pages. The top right window presents the topic structure of the TV program.
The bottom right window is a browser for complementary Web pages. When a topic is detected from the closed captions, the two windows on the right change automatically, i.e., the topic structure and complementary Web page change according to changes in the TV program. 6.3 User Interface Evaluation
Intuitively, many would expect watching TV and browsing Web pages at the same time to be difficult. We carried out an experiment to test the WebTelop user interface using six groups consisting of a total of 124 human evaluators working online. Details of the characteristics of the experimental subjects are shown in
Table IX and Figure 12. Each evaluator was supplied with the WebTelop system through a personal computer.

In this evaluation, WebTelop used the four different queries to search for related Web pages and only presented the Web page with the highest comple-mentarity degree. We provided face-to-face instructions to all evaluators in ad-vance. Each evaluator was first asked to watch two videos (NHK 7 and Today X  X 
Health) and view the related Web pages (four pages/video) using the WebTelop system. Afterwards, the evaluators were asked to complete a questionnaire that included the following items:
Use the following scoring system to assess the frequency at which Web pages appeared:
Use the following scoring system to assess how many Web pages you browsed.
We also asked them to describe the video content using some keywords to check whether they watched TV while also browsing the Web pages.

If an evaluator gave a score of 0 or 1 (indicating  X  X ood frequency X  or  X  X ood browsing X ), we considered this as indicating they found the interface satisfac-tory. The frequency at which Web pages appeared was satisfactory for 57 of the evaluators and 57 . 6% of them browsed more than one-half of the related Web pages. Details of the results of the evaluation are shown in Table X.
In our evaluation, more male than female evaluators considered the user interface to be satisfactory. Many of the older women (group F3) thought the
Web pages appeared too frequently to enable browsing and were unable to browse more than one-half the pages. This may have been because these women were unfamiliar with using the Internet. We also noticed that although the younger men (group M1) were happy with the frequency of the Web pages, many of them were unable to browse more than one-half the pages. This may have been because they were not usually interested in news and were unfamiliar with the news reported in the NHK News 7 video. Therefore, they took longer to watch TV and browse the Web pages.

The results show that it is possible to watch TV and view related Web pages at the same time, although we need to further investigate the most suitable user interface for presenting cross-media news content. We plan to further evaluate the WebTelop user interface. For instance, we plan to compare the questionnaire results at different times X  X nce at the very beginning of each trial and then again after the subject has had a chance to gain experience using the system. We also plan to study the effects of content type. 7. CONCLUSION
To augment the information available to users, we propose a novel information retrieval mechanism based on the joining of topic structures. Using this mecha-nism, we find complementary information for a given Web page or video. First, we extract the topic structure of the given example (Web page, video, etc.). We then generate queries based on the topic-structure join and acquire candidate
Web pages using Google X  X  API service. Finally, we rank these Web pages on the basis on their degree of complementarity to select the most complementary Web page.

We have discussed the experimental results of our proposed mechanism for retrieving complementary information. These results indicated that the proposed mechanism was effective in searching for complementary Web pages that were not just similar to the given example, but that also provided addi-tional information.
 We also proposed an application system called WebTelop, which integrates
TV programs and related Web pages in real time to augment the content of the TV program. Using this system, a user can view a TV program and related
Web pages concurrently to acquire more detailed information or a different perspective on the topic.

Further study on information complementation is necessary. Especially, the core technologies, such as the topic structure model and complementary in-formation retrieval, need to be refined and extended. For instance, [Hutchins 1977] studied the linguistic structures of text with the goal of helping read-ers understand text items. We would like to discuss using his concepts, such as  X  X heme X  and  X  X heme, X  to extend our topic-structure model and improve the topic-structure extraction method.

