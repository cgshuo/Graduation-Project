 Institute for NLP, University of Stuttgart Institute for NLP, University of Stuttgart Institute for NLP, University of Stuttgart Institute for NLP, University of Stuttgart Institute for NLP, University of Stuttgart
We study constituent parsing of German, a morphologically rich and less-configurational language. We use a probabilistic context-free grammar treebank grammar that has been adapted to the morphologically rich properties of German by markovization and special features added to its productions. We evaluate the impact of adding lexical knowledge. Then we examine both monolingual and bilingual approaches to parse reranking. Our reranking parser is the new state of the art in constituency parsing of the TIGER Treebank. We perform an analysis, concluding withlessonslearned,whichapply toparsingothermorphologically richandless-configurational languages. 1 .Introduction
A large part of the methodology for parsing in natural language processing has been developed for English and a majority of publications on parsing are about parsing of English. English is a strongly configurational language. Nearly all of the syntactic information needed by any NLP application can be obtained by configurational analysis (e.g., by having a correct constituent parse).
 respect. At the other end of the configurational X  X onconfigurational spectrum we find a language like Hungarian that has very little fixed structure on the level of the sentence.
Leaving aside the issue of the internal structure of NPs, most sentence-level syntactic information in Hungarian is conveyed by morphology, not by configuration.
 between English and Hungarian. German has strong configurational constraints (e.g., main clauses are verb-second) as well as rich derivational and inflectional morphology, all of which must be modeled for high-quality parsing. German X  X  intermediate status raises a number of interesting issues in parsing that are of particular prominence for a mixed configurational/morphological language, but are X  X s we will argue X  X f general relevance for morphologically rich languages. Partly this is the case because there are few (if any) languages archetypical of being purely configurational and purely noncon-figurational (e.g., morphology is also important for English and even Hungarian has configurational constraints). For lac kof a better term we refer to intermediate languages as typified by German as MR&amp;LC for morphologically rich and less-configurational . has been done on English, a morphologically simple language. As computational lin-guistics broadens its focus beyond English it becomes important to take a more general approach to parsing that can handle languages that are typologically very different from
English. Rich morphology (RM) is one very salient characteristic of a language that affects the design of parsing methods. We argue that there are two other properties of languages that are relevant in a discussion of parsing RM languages: syncretism and configurationality. These two properties are correlated typologically with RM and should therefore be taken into account when we address parsing RM languages. large number of languages for which this correlation holds can be ordered along a single dimension that can be interpreted as degree of morphological complexity. We give examples for a number of languages that are positioned at different points on this scale. Finally, we argue that just as languages that are at the opposite end of the spectrum from English (prototypical examples of morphological richness like Hungarian) require parsing methods that can be quite different from those optimal for English, the same is true for a language like German that is in the middle of the spectrum X  X nd what is required is in some respects different from what is optimal for one extreme (English) or the other (Hungarian).
 tionality. Morphological richness can be roughly measured by the number of different morphological forms a word of a particular syntactic category can have; for example, 58 a typical English noun has two forms (singular and plural), a typical German noun has eight forms (singular and plural in four different cases), and a typical Hungarian noun has several hundreds of forms. Syncretism refers to the fact that different mor-phological forms have identical surface realization; for example, the form Mann ( X  X an X  in German) can be the nominative, dative, or accusative singular of Mann depending on context. Configurationality refers to the degree to which the arrangement of words and phrases of a particular syntactic function in a sentence is fixed. English is highly configurational: it has limited flexibility in how the major phrases in a sentence (subject, verb, direct object, indirect object, etc.) can be ordered. Hungarian and Latin are highly flexible: Even though there are pragmatic constraints, in principle a large number of possible orderings are grammatical. German is less configurational. It has some strict constraints (verb second in main clauses, verb final in subordinate clauses), but also some properties of a nonconfigurational language; for example, ordering of phrases in the mittelfeld (the part of the main clause enclosed by the two parts of the verbal complex) is very flexible.
 atively) correlated. Rich morphology specifies the syntactic role of a phrase in the sentence, so fixing a position is not required, and many morphologically rich languages therefore do not fix the position. Conversely, simple morphology gives little specific information about the role of words and phrases in the sentence. One device often used by morphologically simple languages to address this problem and reduce widespread ambiguity is to fix the order of words and phrases in the sentence.

Simple morphology is unspecific about grammatical function because it uses a small number of morphological categories. Syncretism is unspecific about grammatical func-tion because it suffers from a high degree of ambiguity. Even though the number of different morphological categories is potentially large, syncretic forms conflate many of these categories, so that these forms are much less helpful in determining grammatical function than forms in a nonsyncretic language with the same number of categories.
Again, to counteract the communicative difficulties that lac kof morphological speci-ficity would create, stricter constraints on ordering and configuration are often used by syncretic languages.
 for the middle of the spectrum. We now give examples of other languages and their positions on the scale. Dutch is similar to German in that it also is verb second in main clauses and verb final in subordinate clauses. The order of arguments in the mittelfeld is much more restricted than in German, however. At the same time, Dutch morphology has been much more simplified in the last centuries than German morphology. This nicely confirms the correlation between RM and configurationality. Thus, Dutch is positioned between English and German on the scale.
 logical forms is roughly comparable to German and it allows a number of different word orders. Modern Standard Arabic speakers rarely mark case, however, at least not in spontaneous speech. At the same time, Modern Standard Arabic speakers use SVO order much more frequently and consistently than is the case in Classical Arabic. Thus, Classical Arabic is roughly at the same position as German on the scale whereas spoken Modern Standard Arabic may be more comparable to Dutch.

Hungarian. It has richer morphology than German, but it has a fair amount of syn-cretism and therefore more morphological ambiguity than Hungarian. SVO is the predominant word order in modern Greek, but other word orders can be used. The order within the noun phrase is more flexible than in German: Adjectives can precede or follow the noun.
 phological form is negatively correlated with the amount of information conveyed by configuration. If morphology conveys a lot of information (due to a large number of distinctions and the lac kof syncretism), then word order is freer and conveys less information. If morphology conveys less information (due to fewer distinctions or more syncretism), then configuration is fixed and provides more information to the speaker.
This suggests that RM and configuration are important variables that should be taken into account in the design of parsing methods. In addition to looking at the extremes of the spectrum that are exemplified by English and Hungarian, we should also investigate the middle: morphologically (somewhat) rich languages that are less configurational. In this article, we loo kat the example of German.
 constituency or dependency. It is a widely held belief that dependency structures are better suited to represent syntactic analyses for morphologically rich languages because they allow non-projective structures (the equivalent of discontinuous constituents in constituency parsing). As Tsarfaty et al. (2010) point out, however, this is not the same as proving that dependency parsers function better than constituency parsers for pars-ing morphologically rich languages. In fact, most state-of-the-art dependency parsers (McDonald and Pereira 2006; Hall and Nivre 2008; Seeker et al. 2010a) generate purely projective dependency structures that are optionally transformed into non-projective structures in a post-processing step. Comparable post-processing techniques have been used in English constituency parsing (Gabbard, Marcus, and Kulic k2006; Schmid 2006;
Cai, Chiang, and Goldberg 2011) to identify discontinuous constituents and might work for other languages, as well.
 higher accuracies for detecting grammatical functions with dependency parsers than with constituent parsers, but the direct comparison is not fair as it required phrase boundaries to be correct on the constituent side while the tokens were the unit of evaluation on the dependency side. 2 How to carry out an absolutely fair comparison of the two representations is still an open research question. example is the coordination ambiguity in old men and women versus old men and children .
The correct constituent parse for the first expression contains a coordination at the noun level whereas the parse for the second expression coordinates at the level of
NPs. The dependency structures of both expressions, on the other hand, are usually identical and thus unable to reflect the fact that old modifies women but not children .Itis possible, in principle, to encode the difference in dependency trees (cf. Rambow 2010), 60 for example, by enriching the edge labels, but the constituent representation is simpler for this phenomenon.
 dency parses. For instance, many hierarchical statistical machine translation systems use constituency parses, requiring the output of a dependency parser to be transformed into a constituent parse. 4 We conclude that there is no clear evidence for preferring dependency parsing over constituency parsing in analyzing languages with RM and instead argue that research in both frameworks is important.
 phologically rich language, a system that addresses the major problems that arise in constituency parsing for MR&amp;LC, as one of our main contributions in this paper.
MR&amp;LC languages. For example, there are a large number of possible orderings of the phrases in the German mittelfeld, and many orderings are exceedingly rare. A standard constituency parser cannot estimate probabilities for the corresponding rules reliably. into small unidirectional rules that can be modeled and estimated more reliably than complex rules. Although markovization in itself is not new, we stress its importance for
MR&amp;LC languages here and present a detailed, reproducible account of how we use it for German. Markovization combines the best of both worlds for MR&amp;LC languages:
Preferential configurational information can be formalized and exploited by the parser without incurring too large of a performance penalty due to sparse data problems. is widespread syncretism. We mainly address syncretism by using a high performance finite-state automata-based morphological analyzer. Such an analyzer is of obvious importance for any morphologically rich language because the productivity of mor-phologically rich languages significantly increases the unknown-word rate in new text versus morphologically poor languages. So the parser cannot simply memorize the grammatical properties of words in the Treeban kused for training. Instead we incorpo-rate a complex guesser into our parser that, based on the input from the morphological analyzer, predicts the grammatical properties of new words and (equally important) unobserved grammatical properties of known words. With prevailing syncretism, this tas kis much more complex than in a language where case, gender, number, and so forth, can be deterministically deduced from morphology.
 morphology and (ii) a large lexicon of morphologically analyzed German words. We refer to these two components together as lexical knowledge . We show that lexical knowledge is beneficial for parsing performance for an MR&amp;LC language like German. that needs to be addressed in MR&amp;LC languages. Syntactic disambiguation in these languages must always involve both systems of grammatical encoding, morphology and configuration, acting together. The most natural way of doing this in a language like German is to perform this integration of the two knowledge sources directly as part of parsing. We do this by annotating constituent labels with grammatical function where appropriate. In contrast with syntactic parses of strongly configurational languages like English, syntactic parses of German are not useful for most tasks without having grammatical functions indicated. It is not even possible to access the basic subcatego-rization of the verb (such as determining the subject) without grammatical functions.
We argue that MR&amp;LC languages like German should always be evaluated on labels-cum-grammatical-function.

MR&amp;LC languages give rise to more ambiguity than languages that are predominantly configurational or morphological. As an example consider the German sentence  X  X ie [the] Katze [cat] jagt [hunts] die [the] Schlange [snake]. X  In German either the cat or the snake can be the hunter. This type of ambiguity neither occurs in a strongly configu-rational language like English (where configuration determines grammatical function) nor in a morphologically rich language like Hungarian that has no or little syncretism (where morphology determines grammatical function). Although morphology and configuration in MR&amp;LC languages often wor khand in hand for complete disambigua-tion, there are also many sentences where neither of the two provides the necessary information for disambiguation. We believe that this distinguishing characteristic of
MR&amp;LC languages makes it necessary to tap additional knowledge sources. In this paper, we look at two such knowledge sources: monolingual reranking (which captures global properties of well-formed parses for additional disambiguation) and bilingual reranking (which exploits parallel text in a different language for disambiguation). categorization frames. We compare our compact feature set with a sparse feature set designed for German previously by Versley and Rehbein (2009). We show that the richer subcategorization-based framewor kfor monolingual reran king is effective; it has comparable performance to the sparse feature set X  X oreover, they complement each other.
 parse is found that minimizes syntactic divergence with an automatically generated parse of its English translation. We pursue this approach for a number of reasons. First, one limiting factor for syntactic approaches to statistical machine translation is parse quality (Quir kand Corston-Oliver 2006). Improved parses of bitext should result in improved machine translation. Second, as more and more texts are available in several languages, it will be increasingly the case that a text to be parsed is itself part of a bitext. Third, we hope that the improved parses of bitext can serve as higher quality training data for improving monolingual parsing using a process similar to self-training (McClosky, Charniak, and Johnson 2006a).
 knowledge, monolingual features, and bilingual features) are valuable separately. We also show that the gain of the two sets of reranking features (monolingual and bilingual) is additive, suggesting that they capture different types of information.
 without bilingual features). In particular, we show that the baseline parser without reranking is competitive with the previous state of the art (the Berkeley parser) and that the re-ranking can add an important gain. 2 .Previous Work
Constituent parsing for English is well studied. The best generative constituent parsers are currently the Brown reranking parser (Charniak and Johnson 2005), the exten-sion of this parser with self training by McClosky, Charniak, and Johnson (2006b), and the parser of Petrov and Klein (2007), which is an unlexicalized probabilistic 62 context-free grammar (PCFG) parser with latent feature annotations. Charnia kand
Johnson (2005) and Huang (2008) have introduced a significant improvement by feature-rich discriminative reranking as well.
 Keller (2003) adapted Collins X  X  (1997) lexicalized parser to German. An unlexicalized
PCFG parser similar to our generative parser was presented by Schiehlen (2004). The best constituent parser participating in the ACL-08 Workshop on Parsing German (K  X  ubler 2008) was the Berkeley parser (Petrov and Klein 2008). The Stanford parser was also adapted to German (Rafferty and Manning 2008). German dependency parsers have been developed by Menzel and Schr  X  oder (1998), Duchier and Debusmann (2001),
Hall and Nivre (2008), Henderson et al. (2008), and Seeker et al. (2010a), to name afew.
 sented a reranker for German LFG parsing, and Dreyer, Smith, and Smith (2006) applied reranking to German dependency parsing. Versley and Rehbein (2009) developed a reranking method for German constituent parsers. The work by Versley and Rehbein and by Schiehlen (2004) is closest to ours. Like them, we rerank the unlexicalized BitPar parser. We also refine treeban klabels to increase parsing performance, but add more information and achieve a larger improvement. We use the monolingual feature set of
Versley and Rehbein in our reranker, but add further monolingual features as well as bilingual features. 3 .Generative Parsing Framework
Our generative parser is an unlexicalized PCFG parser which is based on the BitPar parser (Schmid 2004). BitPar uses a fast bitvector-based implementation of the well-known Cocke-Younger-Kasami algorithm and stores the chart as a large bit vector.
This representation is memory efficient and allows full parsing (without search space pruning) with large treeban kgrammars. BitPar is also quite fast because the basic parsing operations are parallelized by means of (single-instruction) and -operations on bitvectors. BitPar can either be used to compute the most likely parse (Viterbi parse), or the full set of parses in the form of a parse forest, or the n -best parse trees. 3.1 Grammar The grammar and lexicon used by our generative parser are extracted from the Tiger2
Treeban k(Brants et al. 2002). Similar to Johnson (1998) and Klein and Manning (2003) we improve the accuracy of the unlexicalized parser by refining the non-terminal symbols of the grammar to encode relevant contextual information. This refinement weakens the strong independence assumptions of PCFGs and improves parsing accuracy. The extraction of the grammar and lexicon involves the following steps: 1. Discontinuous constituents are eliminated (Section 3.2). 2. Treeban kannotations are transformed (Section 3.4) and augmented 3. Grammar rules, lexical rules, and their frequencies are extracted from the 4. The grammar is markovized (Section 3.6). 3.2 Raising for Non-Projectivity
The Tiger2 Treeban kthat we used in our experiments contains discontinuous con-stituents. As in other wor kon German parsing using the Tiger2 Treeban k(Dubey and Keller 2003; Schiehlen 2004; K  X  ubler, Hinrichs, and Maier 2006), we eliminated discontinuous constituents by raising those parts of the discontinuous constituent that do not contain the head to the child position of an ancestor node of the discontinuous constituent. Hsu (2010) compared three different Tiger2 conversion schemes and found raising to be the most effective. The projective parse tree in Figure 1, for instance, is obtained from a Tiger parse tree where the pronominal adverb Daraus was a dis-continuous child of the lower VP-OC node.
 the Penn Treeban kannotation style for discontinuous constituents). If slash features are added to the nodes on the path between the PROAV node and its trace within the
VP, it is possible to restore discontinuous constituents (Schmid 2006). Due to sparse data problems caused by the added slash features, however, the parsing accuracy drops by 1.5% compared with the version without slash features (when evaluated on projectivized parse trees). Traces are recognized with a precision of 53% and a recall of 33%. The correct antecedents are identified with a precision of 48% and a recall of 30%.
These figures indicate that the identification of discontinuous constituents in Tiger parse trees is a harder tas kthan in English Penn Treeban kparses, considering the 84% F-score for the recognition of empty constituents and the 77% F-score for the identification of antecedents reported in Schmid (2006) for an analogous approach.
 is often not required: We can simply assume that all constituents appearing at the S level are dependents of the main verb of the clause. Only for modifiers with scope ambiguities (e.g., negation particles) is it relevant whether they are attached at the S or VP level. These considerations suggest that it is better to recognize discontinuous constituents in a post-processing step as in Johnson (2001), Campbell (2004), and Levy and Manning (2004). In the rest of the paper, we will only wor kwith parse trees from which coreference indices and trace nodes have been removed. 3.3 Morphological Features and Grammatical Functions
The Tiger2 Treeban kannotates non-terminals not only with syntactic categories but also with grammatical function labels such as SB (subject), OA (accusative object), or 64
MO (modifier). These labels provide important information that is necessary in order to derive a semantic representation from a parse. It is not possible to infer the grammatical role of a constituent from its position in the parse tree alone (as can be done in English, for instance). Case information is needed in addition in order to help determine the correct grammatical role. The Tiger2 Treeban kprovides case, number, degree (positive, comparative, superlative), and gender information at the part-of-speech (POS) level. mation of the POS tags to the base labels similarly to Dubey (2004) and Versley (2005).
Our earlier experiments showed that adding case information increases F-score by 2.1% absolute. Further enriching the grammar with morphological features, however, hurts performance. Adding number features decreased F-score by 0.5%. Adding number, gender, and degree decreased F-score by 1.6%. When grammatical functions are taken into account in the evaluation, the performance drops by 1.5% when number, gender, and degree features are incorporated. It seems that the additional information supplied by the agreement features is not useful enough to outweigh sparse data problems caused by the more fine-grained label set. Therefore we only use case, but designing a smoothing procedure allowing us to use number, gender, and degree is interesting future work. 3.4 Tree Transformations
Similarly to Schiehlen (2004), we automatically augment the Tiger2 annotation with ad-ditional feature annotations. Our feature annotation set is larger than that of Schiehlen.
In addition to making feature annotations, we also perform some tree transformations that reduce the complexity of the grammar. In all evaluations, we use the original (projectivized) Tiger parse trees as gold standard and convert the parse trees generated by our parser to the same format by undoing the transformations and removing the additional features. In the rest of this section, we explain the tree transformations that we used. The following section describes the feature annotations. and other phrasal categories which dominate just a single node are usually omitted. The sentence Sie z  X  ogern [They hesitate], for instance, is analyzed as (S-TOP (PPER-SB
Sie) (VVFIN-HD z  X  ogern)) without an explicit NP or VP. The lac kof unary branching nodes increases the number of rules because now a rule S-TOP is needed in addition to the rule S-TOP  X  NP-SB VVFIN-HD, for instance.
 transform this parse to (S-TOP (NP-SB (PPER-HD Sie)) (VVFIN-HD z  X  ogern)) by adding an NP node with the grammatical function (GF) of the pronoun. The GF of the pronoun, in turn, is replaced by HD (head). Such unary branching NPs are added on top of nouns (NN), pronouns (PPER, PDS, PIS, PRELS), cardinals (CARD), and complex proper names (PN) that are dominated by S, VP, TOP, or DL 6 nodes. reversible, which allows the original annotation to be restored. independence assumption, namely, we assume that the expansion of the subject NP is independent of the other arguments and adjuncts of the verb (a plausible assumption that is confirmed by a performance improvement).
 head of a phrase. In case of NPs and PPs, however, the GF of the head is NK (noun kernel). The same GF is also assigned to the adjectives and determiners of the noun phrase. We replace NK by HD in order to reduce the set of symbols. cial grammatical function label CJ. We replace CJ by the grammatical function of the coordinated phrase. This transformation is also reversible. 3.5 Additional Feature Annotations
Selective lexicalization. We mar kthe POS tags of the frequent prepositions in [in], von [from, of], auf [on], durch [through, by means of], unter [under], um [around, at] and their variants regarding capitalization (e.g., Unter ) and incorporation of articles (e.g., unters , unterm ) with a feature which identifies the preposition. This can be seen as a restricted form of lexicalization. In the same way, we also  X  X exicalize X  the coordinating conjunctions (KON-CD) sowohl [as well], als [as], weder [neither], noch [nor], entweder [either], and oder [or] if preceded by entweder . Figure 2 shows an example.  X $. X  that dominates a question mar kor exclamation mar k, then the clause node and the
POS tag are annotated with quest or excl , so the grammar models different clause types. 66 ment sites. Therefore, we annotate PPs and adverbials (AVP, ADV, ADJD) with one of the features N, V, or 0 which indicate a nominal parent (NP or PP), a verbal parent (VP, S), or anything else, respectively. In case of adverbial phrases (AVP), the label is propagated to the head child.
 (PRELS, PRELAT, PWAV, PWS) is embedded inside of another constituent. In this case, all nodes on the path between the pronoun and the clause node are marked with the feature rel . Furthermore, we add a feature norel to relative clauses if no relative pronoun is found. Figure 3 shows an example.
 pronoun, we use a feature wh which is assigned to all NPs and PPs which immediately dominate a wh-pronoun (PWAT, PWS, PWAV). This feature better restricts the positions where such NPs and PPs can occur.

Liter Milch [three liters (of) milk] or Ende Januar [end (of) January]), then the first noun is usually a kind of measure noun. We mark it with the feature seq .
 Union , Die Zeit are used as proper names. In this case, the grammatical function of the
NP is PNC. In order to restrict the nouns and adjectives that can occur inside of such proper name chunks, we mark their POS tags with the feature name .
 noun modifiers inside of an NP or PP, or predicatively elsewhere. In order to better model the two types of APs, we mar kAPs that dominate a predicative adjective (ADJD) with the feature pred . 9
Millionen) Mark [three million Marks] or ein (AP politisch Verfolgter) [a politically persecuted-person]. We mar kthese APs with the feature nom .

Therefore POS tags of numbers between 1900 and 2019 are marked with year . subordinating conjunction are highly correlated. German object clauses (S-OC) usually start with dass [that] or ob [whether]; modifier clauses (S-MO) often start with wenn [if], weil [because], or als [when]. We mar ksubordinating conjunctions of argument clauses (S-OC), modifier clauses (S-MO), subject clauses (S-SB), and dislocated clauses (S-RE) with a feature ( OC , MO , SB ,or RE ) identifying clause type. Without this feature, argument clauses of nouns, for instance, are often misanalyzed as modifiers of the main clause.
 atives, and zu infinitives are all used in different contexts. Therefore we mar kobject VPs (VP-OC) with a corresponding feature. When parsing the sentence Alle R  X  aume m  X  ussen mehrfach ges  X  aubert und desinfiziert werden [all rooms must multiply cleaned and disin-fected be; all rooms must be ...], this feature allows the parser to correctly coordinate the two past participle VPs mehrfach ges  X  aubert and desinfiziert instead of the past participle VP mehrfach ges  X  aubert and the infinitival VP desinfiziert werden .
 frequent in coordinations. All phrases that do not have a child node with one of the grammatical functions HD, PNC, AC, AVC, NMC, PH, PD, ADC, UC, or DH are marked with the feature nohead .
 if they are neither headed by an imperative nor contain a child node with the gram-matical function SB (subject) or EP (expletive). This is useful in order to correctly parse coordinations where the subject is dropped in the second conjunct. 3.6 Markovization The Tiger Treeban kuses rather flat structures where nodes have up to 25 child nodes.
This causes sparse data problems because only some of the possible rules of that length actually appear in the training corpus. The sparse data problem is solved by markoviza-tion (Collins 1997; Klein and Manning 2003), which splits long rules into a set of shorter rules. The shorter rules generate the child nodes of the original rule one by one. First, the left siblings of the head child of the rule are generated from left to right, then the right siblings are generated from right to left. Finally, the head is generated. Figure 4 shows the markovization of the rule NP  X  NM NN PP PP.
 egory, the head child, and previously generated children. Because all auxiliary symbols encode the head category, the head is already selected by the first rule, but only later actually generated by the last rule. 68 where direction is either L, M, or R, parent is the symbol on the left hand side of the rule, head is the head on the right hand side of the rule, next is the symbol which will be generated next, and previous is the symbol that was generated before. Auxiliaries starting with L generate the children to the left of the head. Auxiliaries starting with
R similarly generate the children to the right of the head and the head itself. The auxiliary starting with M is used to switch from generating left children to generating right children. Each rule contains information about the parent, the head, and (usually) three child symbols (which may include an imaginary boundary symbol). The first rule encodes the trigram left-boundary NM NN . The second rule is an exception which only encodes the bigram NM NN . The third rule encodes the trigram PP PP right-boundary .
The last rule is an exception, again, and only encodes NN PP . There is no rule which covers the trigram consisting of the head and its two immediate neighbors. the training data. If one of the auxiliary symbols introduced by the markovization (such as L:NP[NN]NN X  X M ) is used less than 20 times (the values of the two thresholds were optimized on part of the development data) overall, it is replaced by a simpler symbol L:NP[NN]NN that encodes less context. In this way, we switch from a trigram model (where the next child depends on the two preceding children) to a bigram model (where it only depends on the preceding child) in order to avoid sparse data problems.
The method is similar to the markovization strategy of Klein and Manning (2003) except that they markovize all rules. We simulated their strategy by raising the rule frequency threshold to a larger value, but obtained worse results. We also tried an alternative markovization strategy that generates all children left to right (the auxiliary symbols now lac kthe direction flag, and the rules cover all possible trigrams), but again obtained worse results. A disadvantage of our markovization method are spurious ambiguities.
They arise because some of the rules which are not markovized are also covered by markovization rules. 3.7 Dealing with Unknown Words and Unseen POS Tags
BitPar includes a sophisticated POS guesser that uses several strategies to deal with unknown words and unseen POS tags of known words. Unknown words are divided into eight classes 11 based on regular expressions that are manually defined. These classes distinguish between lower-case words, capitalized words, all upper-case words, hyphenated words, numbers, and so forth. For each word class, BitPar builds a suffix tree (Weischedel et al. 1993; Schmid 1995; Brants 2000) from the suffixes of all words in the lexicon up to a length of 7. At each node of the suffix tree, it sums up the conditional POS probabilities (given the word) over all known words with that suffix. By summing
POS probabilities rather than frequencies, all words have the same weight, which is appropriate here because we need to model the POS probabilities of infrequent words.
BitPar computes POS probability estimates for each node using the sum of probabilities as a pseudo-frequency for each tag. The estimates are recursively smoothed with the
Witten-Bell method using the smoothed POS probabilities of the parent node as a backoff probability distribution. 12 The suffix trees are pruned by recursively removing leaf nodes whose pseudo-frequency is below 5 or whose weighted information gain is below a threshold of 1.
 word class and obtains the tag probability distribution from the corresponding suffix tree. BitPar assumes that function words are completely covered by the lexicon and never guesses function word POS classes for unknown words.
 information from an external lexicon (generated by a computational morphology, for instance, as we will discuss in Section 5.1) in order to predict unobserved POS tags for known words. First the external lexicon and the lexicon extracted from the training corpus are merged. Then smoothed probabilities are estimated using Witten-Bell smoothing with a backoff distribution. The backoff distribution is the average of: (1) the probability distribution returned by the unknown word POS guesser if at least one possible POS tag of the word according to the lexicon is an open-class POS tag, (2) the average POS probability distribution of all words with exactly the same set of possible POS tags as the given word 14 if at least one of the possible tags is unseen, and (3) the prior POS probability distribution if no other word in the lexicon has the same set of possible POS tags and at least one of the word X  X  possible
POS tags is unseen. 4 .Evaluation of the Generative Parser
As we present each knowledge source, we would like to evaluate it against manually annotated Treebanks. Our first evaluation shows that our generative parser introduced in the previous section is comparable with the Berkeley generative parser. Before we present this comparison in Section 4.1 we discuss evaluating parse accuracy. Europarl Treeban k(Pad  X  o and Lapata 2009). We take the first 40,474 sentences of the
Tiger Treeban kas training data (Tiger train), the next 5,000 sentences as development data (Tiger dev), and the last 5,000 sentences as test data (Tiger test). The Europarl data consists of 662 sentences 15 and are either completely used as test data and not di-vided up or we carried out seven-fold cross-validation experiments with our reranking models.
 step 1 of the grammar extraction process described in Section 3.1 to the test parses and use the result as the gold standard (except for the Pad  X  o set, which is already projectivized). The test sentences are parsed and the resulting parse trees are converted 70 to the same format as the gold standard trees by undoing Steps 2, 3, and 4 of Section 3.1.
This conversion involves four steps: 1. Demarkovization removes all the auxiliary nodes introduced by 2. The added unary-branching nodes are eliminated. 3. The original grammatical function labels NK inside of NPs and PPs, 4. All feature annotations are deleted.

We use PARSEVAL scores (Blac ket al. 1991) and the standard evaluation tool evalb to compare the converted parse trees with the gold standard parse trees using labeled
F-score. We report accuracies for all test sentences and not just sentences of length up to 40. We do not evaluate parsers with gold standard POS tags, but instead automatically infer them. These considerations make our evaluation setting as close to the real-world setting as possible.
 report PARSEVAL scores with grammatical functions inside parentheses after the results using only basic constituent categories. We believe that grammatical functions are an important part of the syntactic analysis for any downstream applications in less-configurational languages such as German because crucial distinctions (e.g., the distinc-tion between subject and object) are not feasible without them. We should mention that our results are not directly comparable to previously published results on the Tiger2 corpus (K  X  ubler 2008; Versley and Rehbein 2009; Seeker et al. 2010b), because each of the previous studies used different portions of the corpus and there are differences in the evaluation metric as well. The transformed corpus (in our train, development, and test split format) and the evaluation scripts we used are available, enable direct comparison with our results. 4.1 Comparison of BitPar and Berkeley
The best constituent parser participating in the Parsing German Shared Tas k(K  X  ubler 2008) was the Berkeley parser (Petrov and Klein 2008) and to the best of our knowledge it has achieved the best published accuracy for German constituency parsing so far.
The Berkeley parser takes an automated approach, in which each constituent symbol is split into subsymbols applying an expectation-maximization method. We compare our manually enriched grammar to this automatic approach.
 concatenated to the grammatical function labels as starting symbols. We found that it achieved the best PARSEVAL scores on Tiger dev after the fourth iteration. This model was used for parsing Tiger dev, Tiger test, and the Europarl corpus.
 parser achieved 82.76 (73.20), 76.37 (65.66), and 75.51 (63.3) on the three corpora, respectively. In general, these results indicate that these two parsers are competitive.
On the other hand, the fact that the results of the Berkeley parser are much worse than
BitPar on the out-of-domain Europarl corpus indicates that it overfits to the domain of the training corpus (Tiger2). Following a reviewer suggestion, we looked at the sentences containing many words not occurring in the training data, and observed that our lexical resource is strongly helpful for these sentences. Another disadvantage of the automatic approach of the Berkeley parser is that the resulting subsymbols are not easily interpretable, which can hinder defining features for parse reranking using them. Based on these considerations, we decided to use BitPar in our reranking experiments.
The combination of the two radically different approaches (linguistically motivated grammar extensions and automatic symbol splitting) is a rather promising area of research for improving parsing accuracy, which we plan to address in future work. 5 .Impact of Our Lexical Resource 5.1 Integration of SMOR with BitPar
There are a large number of inflected word forms for many German lemmas. This causes sparse data problems if some forms are not observed in the training data. BitPar applies the heuristics described in Section 3.7 to obtain POS probabilities for unseen words.
Although these heuristics seem to wor kquite well, we expect better results if the parser has access to information from a morphological analyzer.
 2004) to provide sets of possible POS tags for all words. SMOR covers inflection, deriva-tion, and compounding and achieves good coverage in combination with the stem lexicon IMSLex (Lezius, Dipper, and Fitschen 2000). SMOR is integrated into the parser in the following way. We create a combined word list from the training and testing data 18 and analyze it with SMOR. The SMOR analyses are then mapped to the POS tag set used by the parser, and supplied to BitPar as an external lexicon (see Section 3.7). ing corpus. SMOR produces the analysis erl  X  oschen.V.3.Sg.Pres.Ind , which is mapped to VVFIN-HD and added to the lexicon. Using this entry, BitPar correctly parsed the sentence Die Anzeige erlischt [The display goes out]. Without using SMOR, the parser analysed erlischt as a past participle because scht is a frequent past participle ending. 5.2 Effect on In-Domain and Out-of-Domain Parsing
In order to measure the effect of the integration of a German morphology on parsing accuracy (see Section 5.1), we tested the BitPar parser on the Tiger data and on Europarl data. The results are summarized in Table 1. They show that the morphology helps on out-of-domain data (Europarl), but not so much on in-domain data (Tiger). The POS tagging accuracy, however, also increases on Tiger data by 0.13%. When grammatical functions are included in the evaluation, the performance improvement more than doubles on Europarl data. As a result, we decided to use the finite-state morphology in the rest of the experiments we conducted.
 examined the two subcorpora and found that the test data contains longer sentences 72 (18.4 vs. 15.3 words on average) and that the ratio of unknown words is higher (10.0% vs. 7.6%). 6 .Parse Reranking
The most successful supervised phrase-structure parsers are feature-rich discriminative parsers that heavily depend on an underlying PCFG grammar (Charnia kand Johnson 2005; Huang 2008). These approaches consist of two stages. At the first stage they apply a PCFG grammar to extract possible parses. The full set of possible parses cannot be iterated through in practice, and is usually pruned as a consequence. The n-best list parser s keep just the 50 X 100 best parses according to the PCFG. Other methods remove nodes and edges from the packed parse forest whose posterior probability is under a pre-defined threshold (Charnia kand Johnson 2005).
 parses (i.e., reran kthis set). These methods use a large feature set (usually a few million features) (Collins 2000; Charnia kand Johnson 2005). The n -best list approaches can straightforwardly use local and non-local features as well because they decide at the sentence-level (Charnia kand Johnson 2005). Involving non-local features is more complicated in the forest-based approaches. The conditional random field methods usually use only local features (Yusuke and Jun X  X chi 2002; Finkel, Kleeman, and
Manning 2008). Huang (2008) introduced a beam-search and average perceptron-based procedure incorporating non-local features in a forest-based approach. His empirical results show only a minor improvement from incorporating non-local features, however.
 machine learning model for (re)ranking along with local and non-local features. Our reranking framework follows Charniak and Johnson (2005). At the first-stage of parsing, we extract the 100 best parses for a sentence according to BitPar X  X  probability model.
At parsing time, a weight vector w is given for the feature vectors (which numerically represent one possible parse) and we select the parse with the highest inner product of these two vectors. The goal of training is to adjust w . In the maximum entropy framework, this is achieved by solving the optimization problem of maximizing the posterior probability of the oracle parse  X  X he parse with the highest F-score. method aims to select the oracle, as the gold standard parse is often not present in the 100-best parses. 20 Our preliminary experiments showed that parse candidates close to the oracle confuse training. Hence during training, we removed all parses whose F-score is closer than 1.0 to the score of the oracle. 21 is useful only when it is additionally annotated with grammatical functions. The oracle parses often change if the grammatical function labels are also taken into consideration at the PARSEVAL score calculation. Hence slightly different objective functions are used in the two cases. We will report results achieved by reranking models where the oracle selection for training agrees with the evaluation metric utilized X  X hat is, we trained different models (which differ in the oracle selection) for the basic constituent label evaluation and for the evaluation on grammatical functions.
 extraction (Collins 2000). Here, one-eighth of the training corpus was parsed with a
PCFG extracted from seven-eighths of the data set. This provides realistic training examples for the reranker as these parses were not seen during grammar extraction. We used the ranking MaxEnt implementation of MALLET (McCallum 2002) with default parameters. 7 .Monolingual Reranking 7.1 Subcategorization-Based Monolingual Reranking Features
We introduce here several novel subcategorization-based features for monolingual reranking. For this, we first describe our algorithm for extracting subcategorization (subcat) information. We use our enriched version of the Tiger2 training set. In order to extract verbal subcat frames we find all nodes labeled with the category S (clause) or VP-MO (modifying VP) and extract their arguments. Arguments categories shown in Table 2. The arguments of nouns are obtained by looking for NN nodes which are either dominated by an NP or a PP , and which take a following node of category PP , VP-OC ,or S-OC as argument.
 to the head words of the arguments. The argument heads are extracted as follows: As
NP head we take the last node whose function label is either HD , NK ,or PH .Ifthisnode is of category NP or PN , we recursively select the head of that constituent. Similarly, the head of an AP is the last node with functional label HD .Ifitisan AP , the head is searched inside of it. In the case of PP s, we extract two heads, namely, the preposition (or postposition) as well as the nominal head of the PP , which is found using similar rulesasfor NP s. We also extract the case of the nominal head.
 the correct verbal head of a clause irrespective of the verb position (verb-first, verb-second, verb-final), we extract all verbs that are dominated by the clause and a possibly empty sequence of VP-OC or VP-PD (statal passive) nodes and an optional VZ-HD node. Then we take the first non-finite verb, or alternatively the first finite verb if all verbs were finite. In order to avoid sparse data problems caused by the many different inflections of German verbs, we lemmatize the verbs. 74 are sorted to put them in a well-defined order. An example is that given the correct parse of the sentence Statt [instead of] Details [details] zu [to] nennen [name], hat [has] er [he] unverdrossen [assiduously] die [the]  X  X rfolgsformel X  [formula of success] wiederholt [repeated] , meaning  X  X nstead of naming the details, he assiduously repeated the formula of success, X  we extract the two subcat frames: VP-MO OBJ:Details VZ-HD:zu:nennen S-TOP VP-MO SUBJ:er OBJ:Erfolgsformel VVPP-HD:wiederholt
S nodes (VP-MO is treated as S), and on attachment of prepositions and conjunctions to nouns. We define conditional probability and mutual information (MI) features.
Attach , which calculate the probability for each preposition or adverb to be attached to its governor, given the label of the governor. We estimate this from the training data as follows, for the example of the PP feature. In the feature scoring, we give each preposition attachment a score which is the negative log10 of the probabil-ity p (lex prep | label governor) = f (lex prep,label governor) / f (label governor) (with a cutoff of 5).
 information:  X  log 10 ( p ( a , b ) / p ( a ) p ( b ))(hereweusecutoffsof5and being attached to a noun (given the lexicalized preposition and the lexicalized noun). b the head verb. p ( a ) is estimated as the relative frequency of this frame over all frames extracted from Tiger2 train. MI VSimpleSubcat is a simpler version of MI VSubcat . PP is excluded from frames because PP is often an adjunct rather than an argument. of the argument (e.g., OBJ:Buch, which is  X  book  X  X sedasanobject).As b we again use the head verb. The estimate of p ( a ) is frequency(OBJ:Buch) / (total number of extracted frames). 23 In addition, this feature is refined into individual features for different kinds of arguments: MI VSubj , MI VObj , MI VIobj , MI VPP , MI VPRF ,
MI VS OC , MI VVP ,and MI VerbPROAV . As an example, the MI of  X  lesen,OBJ:Buch  X  (reading, object:Book) would be used for the MI VArg features and for the MI VObj feature. For functions such as MI VPP which are headed by both a function word (here, a preposition) and a content word, only the function word is used (and no case). cle, which can also be analyzed as an adverb but will then have a different meaning. For the sentence  X  Und [and] Frau [Mrs.] K  X  unast [(proper name)] bringt [brings] das [that] auch carry/take/bring over [to another physical location], but if it is viewed as a particle, the sentence means Frau K  X  unast is not able to explain this. The feature MI VParticle helps with this kind of disambiguation. 7.2 The Versley and Rehbein Feature Set
We also carried out experiments with the feature set of Versley and Rehbein (2009), which is specially designed for German. It consists of features constructed from the lexicalized parse tree along with features based on external statistical information. constituent in question, its daughters, and its spanning words. All features except the external statistical information are binary and indicate that a lexicalized pattern is present in the parse. They were originally designed for forest-based reranking (Versley and Rehbein 2009). Following Charnia kand Johnson (2005) we sum up these local feature values in the parse tree. Thus our versions count the number of times that a particular pattern occurs in the entire parse tree.
 based patterns are token X  X OS (e.g., one pattern is  X  lesen-VVINF  X ) and the word class of the token in question (word class comes from an automatic clustering of words based on contextual features). The constituent-based patterns are the size of the constituent, the constituent label, and the right-hand side of the derivational rule applied at the node in question. The last and biggest group of the pattern features is formed by the bilexical dependencies . They are based on the head word of the constituent node in question and its daughters. Versley and Rehbein (2009) have also introduced features that exploit statistical information gathered from an external data set and aim to resolve PP attach-ment ambiguity. Mutual information values were gathered on the association between nouns and immediately following prepositions, as well as between prepositions and closely following verbs on the DE-WaC corpus (Baroni and Kilgarriff 2006). These feature values were then used at NP  X  PP and VP  X  PP daughter attachments. in less than five sentences for computational efficiency, resulting in 117,000 extremely sparse features. 7.3 Monolingual Reranking Experiments
We reran k100-best lists from BitPar (Schmid 2004), which uses the grammar extraction procedure and lexical resources introduced in Section 3. In each of the experiments we extracted the grammar from the Tiger train and used it to obtain the 100-best parses for the sentences of the evaluation corpus.
 subcategorization-based features, the Versley09 feature set, and the union of these two 76 sets. We evaluated the models on Tiger dev, Tiger test, and Europarl. As the domains of Tiger and Europarl are quite different, besides this cross-domain parser evaluation (CROSS) we carried out an in-domain (IN) evaluation as well. In the latter we followed the seven-fold cross-validation approach, that is, the reranking models were trained on six-sevenths of Europarl. The results are presented in Table 3.
 provement over the baseline parser using both our and the Versley09 feature sets. The
Versley09 feature set achieved better results than our monolingual features when a training dataset with sufficient size is given (Tiger). On the other hand using our 16 rich features (compared with 117,000 sparse features) is more suitable for the settings where only a limited amount of training instances are available (the training sets consist of 567 sentences of Europarl in seven-fold cross-validation). The reranking models using the union of the feature sets obtain close to the sum of the improvements of the two in-dividual feature sets. The subcategorization features model rich non-local information, and the fine-grained features capture local distinctions well and the features based on the Web corpus access additional knowledge.
 most effective features were ProbAdverbAttach , MI VPP , MI VPRF , MI VSubj ,and
MI VA r g . After this the variation caused by numeric instability was too high to see a consistent incremental gain from the rest of the features. We conclude that these features can be robustly estimated and have more discriminative power than the others, but we emphasize that we used all features in our experiments.
 diese Finanzierung is incorrectly classified as an accusative object. The monolingual subcategorization features MI VSubcat , MI VSimpleSubcat ,and MI VA r g enable the reranker to correctly analyze the noun phrase as a subject and to move it from the VP level to the S level. 8 .Bilingual Reranking
We now present our bilingual reranking framework. This follows our previous work (Fraser, Wang, and Sch  X  utze 2009), which defined feature functions for reranking
English parses, but now we will use these same feature functions (and three additional feature functions introduced to capture phenomena higher in the syntactic tree) to reran kGerman parses. The intuition for using this type of bitext projection feature is that ambiguous structures in one language often correspond to unambiguous structures in another. Our feature functions are functions on the hypothesized English parse e , the German parse g , and the word alignment a , and they assign a score (varying between 0 and infinity) that measures syntactic divergence . The alignment of a sentence pair is a function that, for each English word, returns a set of German words with which the English word is aligned. Feature function values are calculated either by taking the negative log of a probability, or by using a heuristic function which scales similarly. 24 ent types of syntactic divergence between an English parse and a German parse.
Charnia kand Johnson (2005) defined the state of the art in discriminative n -best constituency parsing of English syntax (without the use of self-training). The n -best output of their generative parser is reranked discriminatively by a reranker. We call this CJRERANK. We will use an array of feature functions measuring the syntactic divergence of candidate German parses with the projection of the English parse obtained from CJRERANK.
 the Europarl corpus and annotated by Pad  X  o and Lapata (2009). There are 662 German sentences that are aligned to single English sentences; this is the set that we use. Due to the limited number of trees, we perform cross-validation to measure performance. should play approximately the same syntactic role and have a similar span as the corre-sponding constituent in a translation. If there is an obvious disagreement, it is probably caused by wrong attachment or other syntactic mistakes in parsing. Sometimes in translation the syntactic role of a given semantic constituent changes; we assume that our model penalizes all hypothesized parses equally in this case.
 tion experiment (adding one feature at a time), on top of our best monolingual system (combining both subcat and Versley09 feature sets). All bilingual experiments use all of the features (not just the features we describe here). Definitions are available. ment) is the negative log probability assigned by BitPar to the German parse. 8.1 Count Feature Functions Count feature functions count projection constraint violations.
 we have a coordination where the English CC is aligned only with a German KON, and 78 both have two siblings, then the value contributed to CrdBin is 1 (indicating a constraint violation) unless the head of the English left conjunct is aligned with the head of the German left conjunct and likewise the right conjuncts are aligned.

German sentence is parsed as a question but the parallel English sentence is not, or vice versa, the feature value is 1; otherwise the value is 0.
 projected to a simple declarative clause in English. This feature counts violations. same (projected) constituent in German. If an English PP follows immediately a VP or a single verb, and the whole constituent is labeled  X  X  X  or  X  X P, X  then the PP should be identified as governed by the VP. In this case the corresponding German PP should attach as well to the German VP to which the English VP is projected (attachment in
German can be to the left or to the right). If the governor in German does not turn out to be a VP or have a tag starting with  X  X , X  a value of 1 will be added to the feature for this German parse.
 same (projected) constituent in German (where attachment can be left or right). This feature counts violations.

Span Projection Feature Functions. Span projection features calculate an absolute or percentage difference between a constituent X  X  span and the span of its projection. Span size is measured in characters or words. To project a constituent in a parse, we use the word alignment to project all word positions covered by the constituent and then look for the smallest covering constituent in the parse of the parallel sentence. of PP constituents in an English parse to German, and sums all the span differences. It is measured in words. In addition to PPParentPrjWord we implement two bonus features,
NonPPWord and NonPPPer . The former simply calculates the number of words that do not belong to PP phrases in the sentence, and the latter computes the non-PP proportion in a character-based fashion. These can be thought of as tunable parameters which adjust PPParentPrjWord to not disfavor large PPs. The other selected projection features are described in Table 4.

Probabilistic Feature Functions. We use Europarl (Koehn 2005), from which we extract a parallel corpus of approximately 1.22 million sentence pairs, to estimate the probabilistic feature functions described in this section.
 analysis, because several variations (described next) were selected. PTag measures tagging inconsistency based on estimating the probability for each English word that it has a particular POS tag, given the aligned German word X  X  POS tag. To avoid noisy feature values due to outliers and parse errors, we bound the value of PTag at 5. use relative frequency to estimate this feature. When an English word is aligned with two words, estimation is more complex. We heuristically give each English and German pair one count. The value calculated by the feature function is the geometric mean the pairwise probabilities.
 probability that the parent of the English word at position i has a particular tag, given the aligned German word X  X  POS label. PTagBiGLeft measures tagging inconsistency based on estimating the probability for each English word that it has a particular POS tag, given the aligned German word X  X  label and the word to the left of the aligned
German word X  X  label. PTagBiGParent measures tagging inconsistency based on esti-mating the probability for each English word that it has a particular POS tag, given the aligned German word X  X  label and the German word X  X  parent X  X  label. 8.2 Bilingual Reranking Experiments
We performed experiments looking at bilingual reranking performance. To train the parameters of the probabilistic feature functions, we use 1-best parses of the large
Europarl parallel corpus (from CJRERANK and BitPar). We wor kon the same 100-best list (of the German sentences in the small Pad  X  o set) as was used in the previous section.
We parse the English sentences of the small Europarl set with CJRERANK; this parse is used as our bilingual knowledge source. Finally we rerank using the bilingual features (results in the first row of Table 5).
 using both the monolingual and the bilingual features together, and the results are presented in Table 5. The bilingual feature-based reranker achieved 1 percentage point improvement over the baseline. This advantage was just slightly decreased when mono-lingual features are also present. This indicates again that the monolingual and bilingual features can capture different linguistic phenomena and their information content is rather different. As in the Europarl IN setting, using the large sparse Versley09 feature set the reranker could not learn a meaningful model from a moderate-sized training data set. 80 produced by the monolingual reranker and it incorrectly combines the two adverbs aber and ebenso into an adverbial phrase and places this under the VP. The bilingual reranker instead attaches the two adverbs separately at the S level. The attachment to the S node indicates that the two adverbs modify the modal verb kann and not the full verb sagen .
This is triggered by the feature POSPar2Prj . 8.3 Previous Work on Bitext Parsing
Bitext parsing was also addressed by Burkett and Klein (2008). In that work, they use feature functions defined on triples of (English parse tree, Chinese parse tree, alignment) which are combined in a log-linear model, much as we do. In later wor k(Bur kett,
Blitzer, and Klein 2010), they developed a unified joint model for solving the same problem using a weakly synchronized grammar. To train these models they use a small parallel Treeban kthat contains gold standard trees for parallel sentences in Chinese and English, whereas we only require gold standard trees for the language we are reranking. Another important difference is that Burkett and Klein (2008) use a large number of automatically generated features (defined in terms of feature generation templates) whereas we use a small number of carefully designed features that we found by linguistic analysis of parallel corpora. Burkett, Blitzer, and Klein (2010) use a subset of the features of Burkett and Klein (2008) for synchronization, along with monolin-gual parsing and alignment based features. Finally, self-training (McClosky, Charniak, and Johnson 2006b) is another differentiator of our work. We use probabilities esti-mated from aligned English CJRERANK parses and German BitPar parses of the large
Europarl corpus in our bilingual feature functions. These feature functions are used to improve ranking of German BitPar parses in the held-out test sets, which is a form of self-training.
 and of Huang, Jiang, and Liu (2009). They improve English prepositional phrase at-tachment using features from a Chinese sentence. Unlike our approach, however, they do not require a Chinese syntactic parse as the word order in Chinese is sufficient to unambiguously determine the correct attachment point of the prepositional phrase in the English sentence without using a Chinese syntactic parse.
 bilingual features in parse reranking are complementary. In particular, the work on bi-text parsing by Burkett and Klein (2008) does not address the question as to whether the effect of monolingual and bilingual features in parse reranking is (partially) additive. we showed bilingual improvement for parsing English with an unlexicalized parser (Fraser, Wang, and Sch  X  utze 2009), using 34 of the 37 bilingual feature functions we use in this work. 9 .Conclusion
In this paper, we have focused on MR&amp;LC languages like German X  X anguages that are morphologically rich, but also have a strong configurational component. We have argued that constituency parsing is, perhaps contrary to conventional wisdom, an ap-propriate parsing formalism for MR&amp;LC because constituents capture configurational constraints in a transparent way and because for many applications constituency pars-ing is preferable to dependency parsing. Our detailed description of a constituency parsing system for a morphologically rich language, a system that addresses the major problems that arise in constituency parsing for MR&amp;LC, is one main contribution of this paper. Two of these problems are rule proliferation and syncretism. We have addressed rule proliferation by markovization and syncretism by (i) deploying a high performance finite-state-based morphological analyzer that is based on rich lexical knowledge and (ii) encoding grammatical functions directly as part of the phrase labels. This direct encoding allows us to directly combine morphological and configurational informa-tion in parsing and arrive at a maximally disambiguated parse. We argued that this is the right setup for MR&amp;LC languages because applications must have access to grammatical functions.
 additional knowledge sources for improved parsing of the MR&amp;LC language German.
Our motivation was that (as we argued) MR&amp;LC languages have in general higher am-biguity than purely configurational and purely morphological languages, in particular with respect to grammatical functions. Apart from the lexical knowledge embedded in the morphological analyzer, we presented wor kon two other knowledge sources to address this type of additional ambiguity: monolingual reranking (which looks at global sentence-wide constraints for disambiguation) and bitext reranking (which exploits parallel text for disambiguation). We were able to improve the performance of a strong baseline parser using these three knowledge sources and we showed that they are largely complementary: Performance improvements were additive when we used them together. The resulting parser is currently the best constituent parser for German (with or without bilingual features).
 a treeban kfor a MR&amp;LC language, we would first annotate a small number of gold 82 standard trees, using parallel text with English or another language if such text is available. Next, we would consider how to quickly differentiate constituents of the same type using constituent labels plus grammatical functions, as we outlined in Section 3.
Following this, we would use BitPar to build a parser in the same way as we presented here, and to determine the optimal level of markovization, which we assume would be very high with a small number of gold standard training trees. Next, as more trees are annotated in an active learning framework, we would begin to develop morphological analysis. We would implement the bilingual framewor kfollowing this (if we have access to bitext). Then we would implement basic subcategorization extraction and add monolingual features. Finally, as more gold standard trees are annotated, the reranking framewor kshould be constantly retrained. In particular, we expect that the effect of the knowledge sources we have presented will be much stronger when starting with less training data.
 as we have state-of-the-art performance using linguistically motivated features that are easy to understand. We also hope that our wor kcan serve as a coo kboo kof ideas to try for others working on parsers for other morphologically rich languages.
 Acknowledgments References 84
