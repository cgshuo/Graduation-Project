 Recently, several research efforts have addressed answerin g skyline queries efficiently over large datasets. However, th is research lacks methods to compute these queries over un-certain data, where uncertain values are represented as a range. In this paper, we define skyline queries over continu-ous uncertain data, and propose a novel, efficient framework to answer these queries. Query answers are probabilistic, where each object is associated with a probability value of being a query answer. Typically, users specify a probabil-ity threshold, that each returned object must exceed, and a tolerance value that defines the allowed error margin in probability calculation to reduce the computational over-head. Our framework employs an efficient two-phase query processing algorithm.
 Categories and Subject Descriptors: H.2.4 Database ManagementSystems General Terms: Algorithms, Design.
Since its introduction in databases [2], skyline query pro-cessing has received formidable interest in the literature (e.g., see [6, 7, 11, 15, 16]). This interest is mainly due to the skyline X  X  importance in realizing useful, non-trivial ap-plications ranging from multi-criteria decision-making t ools to personalized databases [9, 12]. Given a set of multi-dimensional objects, skyline queries find the set of interes t-ing (i.e., non-dominated) objects. An n -dimensional object P dominates another object Q if P is better than or equal to Q in n  X  1 dimensions, and strictly better than Q in at least one dimension. An example of skyline queries is  X  X ind my best restaurants based on minimal price and mini-mal distance X  , which returns those restaurants that are not dominated by other restaurants based on price and distance.  X  This work is supported in part by the National Science Foundation under Grants IIS-0811998, IIS-0811935, CNS-0708604, IIS-0952977 (NSF CAREER) and by a Microsoft Research Gift.
 Figure 1: Skyline example over data with uncertain ranges Throughout the paper, we are using our running example consisting of seven uncertain objects presented in Figure 1 a where the x dimension of each object is presented as a con-tinuous range while the y dimension is a single certain point. We assume lower is better for all dimensions. Figure 1b gives the probability that each uncertain object is a sky-line, assuming the probability density function within the uncertainty range is uniform, and lower is better for all di-mensions.

With the growing number of applications that include un-certainty, e.g., sensor readings, human reading errors, an d data imperfection, it became essential to support skyline queries over uncertain data. Existing work in this scope is limited only to the case where uncertain data is represented as a set of discrete values [16], i.e., a finite set of instance s a , a 2 ,  X  X  X  , a n . The exact probability of object P (in Fig-ure 1a) to be a skyline is the probability that point p in the uncertainty range of P , i.e., 0 to 4, is less than all other objects in the dataset, formally, this can be represented as R density function of object A .

In this paper, we propose an efficient framework that sup-ports skyline queries for uncertain data represented as a co n-tinuous range. The answer of the skyline query is presented, similar to Figure 1, as the probability of each object to be a skyline. Two user parameters are introduced in our frame-work, namely a user-defined threshold H where the user is only interested in those objects that have a probability mor e than H to be a skyline, and a tolerance parameter  X  that represents a trade-off between the accuracy in probability calculation, and the computational overhead. We mainly propose three bounding methods, namely, uncertainty re-duction , pairwise comparison , and bound tightening . The first two methods give an upper bound probability of each object to be in the skyline, while the last method gives an upper and lower bound probability.

We present a general two-phase framework that employs our proposed three bounding methods and follows a filter-refine approach, where the first phase (filtering) prunes a set of objects from consideration before reaching a more ex-pensive second phase (refinement). In particular, Phase I is responsible on applying uncertainty reduction and pairwise comparison to derive an initial upper-bound probability of each object along with preparing a data structure that will be used in the second phase. Given this initial upper-bound value, Phase I may determine that an object can never be a skyline where it is immediately discarded (i.e., filtered) . In Phase II, we continue pruning objects using the bound tightening which is iteratively applied to each object O until we either confirm that O is not in the skyline (i.e., O  X  X  prob-ability is below the threshold H ) or we have O as a skyline with the required probabilistic accuracy  X  . Thus, we avoid expensive exact probability calculations until a final answ er is found.
Table 1 divides existing work on preference queries for un-certain data with respect to: (a) the query type, (b) the un-certainty model, (c) utilizing a threshold value, and (d) ut i-lizing a tolerance value in probability calculation.
In contrary to our work in this paper (represented in the last line of Table 1), there is no previous work that addresse s the case of skyline for continuous uncertainty model. The two closest work to ours are [3] and [16]. The first one [3] supports continuous uncertainty model, threshold, and tol -erance values, yet it is limited only to the simpler case of nearest-neighbor queries while our work supports skyline queries. Moreover, it is limited to one uncertain dimension . The second one [16] supports skyline queries with thresh-old value, however, it is limited only to the case of discrete uncertainty model while our work supports the case of con-tinuous uncertainty model with a tolerance value in additio n to the threshold value.
As computing the exact probability for each object to be in the skyline set S is prohibitively expensive [10], we present three methods that gradually bound the probability of each object to be in S . These bounds are used to early prune objects that are not of interest, i.e., those objects that ha ve a probability less than H . The main objective is to calculate the exact probability, within tolerance  X  , to only those ob-jects that will have a probability more than H . These three methods are: (1) Uncertainty reduction (Section 3.1) aims to place an upper bound on the object probability to be in S while reducing the object uncertainty region, (2) Pair-wise comparison (Section 3.2) gives a tighter upper bound probability, and (3) Adaptive Bound tightening (Section 3.3) iteratively tightens the lower and upper bound probabiliti es of an object to be within the required tolerance  X  . Affected Objects. Uncertainty reduction is computed in a pairwise fashion. An ordered pair of objects ( Q , P ) qualifies to uncertainty reduction only if the endpoint of Q domi-nates the endpoint of P . The endpoint e P of an object P is formulated by substituting P  X  X  uncertainty range by the upper value on each uncertain dimension, formally e P = ( d ward to determine the dominance relation between e P and e
Q because both of them are exact points. As the dominance relation is not reflexive, if ( Q , P ) qualifies for uncertainty re-duction , then ( P , Q ) does not qualify.
 Main Idea. The main idea of uncertainty reduction is to reduce the upper bound probability for an object P by re-moving a portion of its uncertainty range in which if P exists in, it would have a zero probability being a skyline object. In other words, uncertainty reduction is applied to the domi-nated object where we: (a) limit its upper bound probability , and (b) reduce the uncertainty range [ d l 1 -d u 1 ]  X  [ d  X  [ d l i -d u i ] to a smaller range.
 Example. As an example, we apply the uncertainty re-duction over all the uncertain objects in Figure 2a starting from V with the lowest certain value. For object V , as the endpoint of the uncertainty range e V does not dominate any other endpoint, V does not result in any uncertainly reduc-tion for any other object. For object R , e R dominates e e , and e S , so, the pairs ( R , U ), ( R , T ), and ( R , S ) qualify for uncertainty reduction . This results in reducing the un-certainty range of U to be [2-5] instead of [2-6]. Since the reduced range is one quarter of the original range, the up-per bound probability of U is set to 75%. Similarly, the uncertainty ranges of T and S are reduced to [4-5] and [3-5] with an upper bound probability of 50% and 66%, re-spectively. Figure 2b gives the result of all points after th e uncertaintyreduction with their upper probability bounds, pruning objects S , and T from any further processing for 50% threshold. Affected Objects. Similar to the case of uncertainty reduc-tion , pairwise comparison is computed in a pairwise fashion. However, the condition that two objects qualify for pair-wise comparison is different from that of the uncertainty reduction where an ordered pair of objects ( Q , P ) qualifies to pairwise comparison only if: (a) the uncertainty ranges of P and Q overlap, and (b) the certain part of Q either is equal to or dominates the certain part of P . The certain part of object P , C ( P ), is formulated by removing P  X  X  un-certain dimensions, formally, C ( P )= { d i +1 , . . . , d the upper bound probability of object P can be bounded. As the qualifying condition includes equality, it could be the case that both ordered pairs ( P , Q ) and ( Q , P ) qualify for pairwise comparison . This case takes place if C ( P ) = C ( Q ).
 Main Idea. The main idea of pairwise comparison is that for a qualified ordered pair of objects ( Q , P ), since Q already dominates or equal to P in the certain dimensions, if Q would also dominate P in the uncertain dimension, then P would have no chance to be in the answer set, and it will be discarded using the uncertainty reduction. This means that the only chance for P to still be a skyline object is to be not dominated by Q in the uncertain dimension. Thus, we can have an upper bound probability for object P to be in the answer set as the probability that the uncertain range of P is not dominated by the uncertain range of Q . if the certain dimensions of Q is equal to those of P , we compute an upper bound probability of Q .
 To compute a tighter upper bound probability for object P for a qualified pair ( Q , P ), we compose uncertain object QP to be from the start point of object Q , Q s , to the start point of object P , P s . let Q dom be the portion of Q that fully dominates P , i.e., Q dom = QP  X  Q . The upper bound of P can be computed that the probability that object Q is in Q dom multiplied by the upper bound of P . If this computed upper bound is lower than the user-given threshold, H , we discard P . Otherwise, we proceed by iterating over all un-certain dimensions and finding the minimum upper bound of object P .
 Example. Continuing the example shown in Figure 2b. Object V does not qualify for pairwise comparison with any other object as its uncertainty range does not over-lap with others. For object R , the ordered pairs ( R , Q ), ( R , U ), ( R , P ), and ( R , S ) qualify for pairwise comparison . For ( R , Q ), the upper bound probability of Q is reduced to 1-1 2 * 1 3 * 1 2 =91%. Similarly, U upper bound is reduced to 31%, P upper bound is reduced to 87%, and S upper bound is reduced to 25%. Figure 2c gives the result of all points after the pairwisecomparisons with their upper probability bounds, where object U is discarded. Affected Objects. In contrast to uncertainty reduction and pairwise comparison that are applied for a pair of ob-jects, Adaptive bound tightening is applied for a given object P and a list of objects DL P , termed the dependency list of P . An object Q belongs to DL P if and only if the pair ( Q , P ) qualifies for pairwise comparison . In other words, DL P in-cludes all objects in the data set that affect the probability of P being a skyline object. For example, in Figure 2a, DL P = { R, Q, U } .
 Main Idea. We divide the uncertain object P into segments adaptively to get better accuracy bounds. Initially, we set the segment to be the whole uncertainty range. To do so in a simple and efficient way, we choose the segment that is causing the largest difference between the upper and lower bounds for uncertain object P . And then we split it into halves along the dimension that is causing the largest dif-ference in probability. This will increase the number of seg -ments by one more segment, it will also tighten the current probability bounds [ P lower  X  P upper ]. We keep doing so, iter-atively, till we reach to the stopping condition, ( P upper OR ( P lower &gt; H AND P upper  X  P lower &lt;  X  ). The faster we approach to the stopping condition, the more efficient our scheme will be. So, bound tightening always selects the seg-ment to split, G s , as the one that has the largest weighted difference in its upper and lower bound probabilities, i.e., G ing so, bound tightening will reach to its stopping conditions in less iterations. It is important to note that splitting G into two halves G s 1 and G s 2 results in calculating only the uncertain dimension, choosing the dimension that reduce th e weighted difference for G s 1 and G s 2 . The other bounds are G tally to reflect the new probability bounds.
 Example. Consider object P in Figure 3, the last column in the table of Figure 3b gives the difference between the upper and lower bound probability for each segment of ob-ject P multiplied with the probability of the segment af-ter splitting P at 2 then at 3. We divide P at 2. Then, of all segments, G 2 has the largest calculation error (i.e., (0 . 67  X  0 . 0)  X  1 2 = 0 . 335). Thus, G 2 is chosen to be split into two halves G 21 and G 22 . Then, only one probability value secutively, P lower and P upper are updated to be 39.8% and 73%, respectively. Phase I: Skyline and Dependency Lists Phase I scans the input data set and applies the uncertainty reduction over each object Q against existing objects that are candidate to be skylines, i.e., not yet pruned by our algorithm. We keep tracks of objects with upper bound less than given threshold , denoted as T hresholdDominated set. Based on the result of the uncertainty reduction, if Q  X  X  upper bound probability becomes less than H , we immediately prune Q , otherwise, we apply pairwise comparison on Q against each candidate object P . As pairwise comparison may affect the probability of both Q and P , we check if the probability of any of them becomes less than H . If this is the case, we prune such object. Finally, we compute the dependency list ( P DL ) for each object P , and add it to the candidate skyline set. Example. Table 2 gives the result of applying Phase I to (a) One uncert. dimension Figure 4: Scalability of USky : One &amp; Three uncertain dimensions our running example in Figure 2a when H = 50% and the data is read in the order of U , R , S , V , Q , T , and P . Phase II: Final Probability Calculation Phase II starts after the completion of Phase I and scans each object Q in the candidate skyline set. If the dependency list of Q is empty, we immediately add Q to the final answer set with a probability 100%, otherwise, we proceed with computing a lower and upper bound probability for Q . If the difference between the upper and lower bound probabilities of Q is within the accepted tolerance  X  , we report Q as an answer along with its probabilities. If we still did not achieve the required accuracy, we iteratively apply the bound tightening method until we conclude that either Q is not an answer (i.e., its upper bound probability is less than H ), or it is an answer with an accepted accurate probability calculation within  X  . Example. Continuing on bound tightening for P , we will need 10 iterations to have P lower = 57% and P upper = 61%. Object Q needs 6 iterations to have Q lower = 89 . 5% and Q
Figure 4 gives the effect of the various threshold values (0%, 50%, and 100%) on our proposed algortihm denoted as USky as dataset sizes increase. Even for the case of H = 0%, USky performance is three times better without adaptive bound tightening. When H = 100%, for two uncertain di-mensions, USky runtime is 1.3 seconds in comparsions to 8 and 2.8 seconds for H = 0% and 50%, respectively, as it immediately prunes objects that are dependent on other ob-jects found using pairwise comparison . For 50% threshold, the performance is close to 100% as the number of points with thresholds between 50% and 100% are close.

We compare our proposed algorithm USky without adap-tive bound tightening, we denote this variant as Prob . Fig-ure 5a gives the effect of increasing the threshold H for our synthetic. The speed up of USky over Prob reaches up to 28 for a 100% threshold and three uncertain dimensions. Figure 5b studies the effect of increasing the number of un-certain dimensions from one to five, while having one certain dimension, on the total runtime (presented in log scale) for the USky and Prob algorithms. For all number of uncertain dimensions, USky has about an order of magnitude better performance than Prob . (a) Uncertain Dimensions
Figure 5: Effect of dimensionality and threshold
We have defined skyline queries over continuous uncertain data, and proposed a novel, efficient framework to answer these queries. Query answers are probabilistic, where each object is associated with a probability value of being in sky -line objects. Users can specify a probability threshold, th at each object in the answer set must exceed, and a tolerance that defines the allowed error margin in probability calcu-lation. We have described our framework in the context of skyline in which we have proposed three methods to bound each object probability for being a preferred object, namel y, we have proposed uncertainty reduction , pairwise compari-son , and bound tightening . Then, we presented a two-phase framework that encapsulates our three proposed methods together using a filter-refine approach.
