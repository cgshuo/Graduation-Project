 Onomatopoeia is a word or a grouping of words that expresses sounds, action or status directly, such as  X  X lick X  and  X  X owbow. X  Japanese is filled with ono-matopoeic phrases and has more than other languages; and the phrases are widely used in news headlines, in conversation or in Manga (Japanese comic books), because they succinctly describ e things perfectly. There are two cate-gories:  X  X iongo X  and  X  X itaigo. X  Giongo are words that express voice or sounds. Gitaigo are words that express actions, states or human emotions.
 Learners of Japanese language must master onomatopoeia to make their Japanese more descriptive and expressive. However, it is hard to master ono-matopoeia use, even for advanced-level Japanese language learners. There are several reasons.

One is that Japanese has many  X  X itaigo, X  which express status or human emotions more than other languages. For instance, Japanese  X  X arabara X  is used to reflect an object X  X  state of disarray or separation, and  X  X hiiin X  is the ono-matopoeia form of absolute silence. Another reason is that most onomatopoeia are rich in meaning, depending on the context in which the phrase is used.
An effective way to master onomatop oeia is to read many sentences that contain onomatopoeia.

We are, therefore, developing an online o nomatopoeia examp le-based dictio-nary named ONOMATOPEDIA , which has extensive example sentences col-lected from the Web. This system targe ts advanced-level learners who can already communicate in Japanese, so the example sentences are written only in Japanese. Example sentences are coll ected by a search engine API using ono-matopoeic phrases as the search keyword.

In this paper, we describe two important techniques for generating a good-quality onomatopoeia example-based dictionary: they are collecting appropriate sentences from the Web, and organizing them by onomatopoeic meaning.
Inappropriate sentences tend to be collected from search engines using ono-matopoeic phrases. We introduce a model to collect and extract appropriate sentences as examples efficiently, using o nomatopoeia X  X  gramma tical character-istics. That is, onomatopoeia X  X  role is determined by an addition to the end of an onomatopoeic phrase.

Onomatopoeia have different meanings depending on the context in which they are used. We investigate a cluste ring method for collected sentences by meaning, based on a document vector mo del. Because sentences are collected on the Web, sentences exhibit varying qu alities. To overcome this problem, we propose an incremental approach to clustering sentences. We are developing an online-onomatopoeia example-based dictionary named ONOMATOPEDIA , which presents many examples of onomatopoeia for learn-ers of Japanese. Because this system tar gets only advanced-level learners, the sentences are written only in Japanese; they are not translated into other languages.

Sentences are collected from the Web using a web search engine, so we can expect them to contain practical and/or living Japanese sentences. Fig.1 shows example sentences for  X  X okapoka, X  which means  X  X eing nice and warm X  or the  X  X ound made by patting someone X  X  head. X  In the current version, sentences are sorted by verb or noun, which is qualified by the onomatopoeia. A user can view many sentence examples, and if the user wants to see how the sentences are used on the web site, the user can also see th e peripheral sentences by clicking on  X  X how peripheral sentences, X  or the user can follow a link to the web page in which the sentence is included.
 Fig.2 shows a workflow for collectin g example sentences from the Web[2]. In advance, we prepare onomatopoeic phrases in the onomatopoeia database (Fig.2(1)). The process comprises the following three steps:  X  Collection: the system collects sentences by searching Yahoo API. It ex- X  Filtering: Sentences collected in the previou s step contain inappropriate  X  Organization: As already stated, an onomatopoeic phrase has several mean-Sentences are collected from the search engine using onomatopoeic phrases as the keyword, but not all sentences are good examples for learners. An onomatopoeic phrase is generally used as an adverb, which qualifies a verb. Sometimes, however, onomatopoeic phrases are used as a product name or nickname of a person or pet, which means onomatopoeia can express impressions and intuition without a long description. As a preparatory experiment, we first collect sentences by search engine using 10 onomatopoeic phrases as keywords. We then analyze whether these sentences are appropriate, for example. We suppose that the following sentences are inappropriate.  X  pattern 1: sentences that include only the onomatopoeic phrase and omit  X  pattern 2: sentences that use onomatopoei c phrases as a proper noun such
Fig.3 shows the results. Only a few approp riate sentences ar e collected. Many of the sentences use onomatopoeic phrases as proper nouns (pattern 2). For example,  X  X ichi-pichi X  means young, fresh and cheerful. In this experiment, most collected sentences using  X  X ichi-pichi X  describe an animation character named  X  X ichi-pichi picchi, X  who is a young, cheerful and cute girl character. In this kind of case, onomatopoeic phrases are used as part of a compound noun.
Many sentences grouped in pattern 1 are also found. These sentences use onomatopoeic phrases as headlines for blogs or columns. For example, a diary that describes a warm and peaceful holiday is entitled  X  X oka-poka. X  3.1 Extracting Appropriate Sentences for Examples From the preparatory experiments, we found that inappropriate sentences have the following two features: (1) Nouns or verbs that are qualified by an ono-matopoeic phrase are omitted in the sentence (2) onomatopoeic phrases are used as part of a compound noun.

To collect appropriate sentences, we int roduced the following rules, according to grammatical cha racteristics fo ronomatopoeia.  X  rule I : a rule for search keyword  X  rule II: a rule for removing sentences
We experimented to verify effectiveness of the two rules introduced. Fig.4 shows the result. With the introduction of rule I, appropriate sentences for ex-amples can be collected effectively. Be yond that, sentences that use an ono-matopoeia phrase as part of a compound noun are rarely co llected, because compound nouns don X  X  include additional particles between the onomatopoeic phrase and the noun.

Beyond that, with the introduction of rule II, sentences in which important words are omitted are almost always removed. However, some inappropriate sen-tences remain. This happens because we a utomatically extract sentences from web pages, followed by applying automatic dependency structure analysis. In general, elimination and dependency analysis of Japanese sentences is very dif-ficult. Erroneous tasks take place and results are not always reliable. 3.2 CaboCha CaboCha is a Japanese dependency analysis machine based on Support Vector Machines. If it receives a sentences , it shows the part of speech and qualifing of each word in the sentences. Fig.5 shows the result that CaboCha receives the sen-tences  X  X me ga shitoshito hutteiru, X  which means  X  X t X  X  been drizzling. X  For each word , there are imformation of part of speech and qualifing. For instance,  X  X hi-toshito X  whicih is onomatopoeia word are used as part of a adverb and it X  X  qualifing is showed by  X 2D X ,  X 2D X  means that  X  X hitoshito X  qualifies second word  X  X utteiru X . As described above, an onomatopoeia X  X  part of speech is decided by that of the following word. In addition, the meaning of onomatopoeia may vary depending on the context. The order of example sentences is important for understanding how to use onomatopoeia.

In the current version, we classified sentences into three groups according to onomatopoeias X  part of speech: adverb, adjective, and adjective verb. It is important to notice that there is an order among the groups because examples in the adverb group are most important in the sense that they are frequently used. In each group, sentences are also classified according to the word the onomatopoeia qualifies. These groups are sorted in the order of the number of sentences. Consequently, sent ences are ordered by popularity.

Fig.6 shows part of a sentence list of onomatopoeia  X  X arigari. X  In Fig.6(a), the first group shows usage examples as an adverb, and the second group shows usage as an adjective.

This section proposes an additional classification method, taking into account that onomatopoeia usually has several meanings, depending on the context.
For example, onomatopoeia  X  X arigari X  has the following four meanings ac-cording to an onomatopo eia-dictionary[7] .
 A) Sound that originates the repetition of something stiff scratching, cutting B) Appearance of stiffness where sound of A) originates when scratching, cut-C) It seems to be awfully thin.
 D) It seems to be driven to single-minded desires.
 Fig.6(b) shows the group classified manually according to the above-mentioned meanings. These classification methods make the onomatopoeia X  X  meaning un-derstandable.

In the following section, we investigate a clustering method based on the meaning of the onomatopoeia. 4.1 Weight Specification for Making a Sentence Vector To classify sentences, we use the vect or space model, which is a well known concept in the area of info rmation retrieval and each weight is specified by the TF/IDF weight model.
 The weight vector V s for a sentence s is defined where tf t is term frequency of term t in sentence s , log ( quency. | D | is the total number of sentences in the example sentence list for an onomatopoeia set. Document frequency df t is the number of documents in which the term t appears.

We next customize the multi-dimensional vector for each sentence according to the following considerations.  X  Adjusting weight values  X  Adding peripheral sentences  X  Compression of sentence vector 4.2 Clustering Methods for Sentence Vector To cluster sentences according to an ono matopoeia-dictionary as described in section 4, we should consider sentence q uality. Because we collect sentences from the web, every sentence is not necessarily grammatical and sema ntically correct. The quality of some sentences is not particu larly high, especially if sentences are collected from blogs or from pages containing many pictures.

We propose an incremental approach to clustering sentences. The clustering method consists of four steps: sentence sel ection, clustering, wei ght re-calculation and sentence re-selection. The re-select ion process continues the clustering step again and the process flow is repeated until all sentences are clustered. 1. sentence selection: We select sentences that meet the following conditions 2. clustering: Sentences selected in the previous step are clustered. We apply 3. weight re-calculation: It calculates the degree of importance of the term 4. sentence re-selection: Based on the weight w t and importance imp t ,itre-We investigate our proposed clustering method. We cluster 1342 sentences for an onomatopoeic phrases  X  X ari-gari X . In these sentences, 814 sentences are examples as adverb, the others are the one as adjective. Vectors of sentences are 2056 dimensions.
 We use k-means algorithm for clustering, and a number of cluster K is 10. Although in the session 4 we argue that there are four meanings according to a dictionary, but a meaning group can be subtilized. Then we subtilize first, and then merge them.

We divide meaning groups of  X  X ari-gari X  into 7 types as follows manually. (A) Sound of originate when scratching, cutting down or crunching. (A-1) The sound made by rasping and scratching with blemish. (A-2) The sound made by scratching softly their body by themselves. (A-3) The sound made by eating hard food. (A-4) The sound made by doing something but it isn X  X  categorized to neither (B) Appearance of stiffness where sound of originate when scratching, cutting (C) It seems to awfully thin. (D) It seems to driven to single-minded desires.

First we cluster all sentences by k-me ans at once. The results that only 4 small clusters (80 sentences ) can collect similar sentences. Remains of cluster has different types of sentences, that is, this clustering method doesn X  X  success.
Next, we choose sentences as described in the previous section. Fig.7(a) shows the result of clustering using only good-quality sentences by sentence selection in the clustering flow. Almost all cluste r except the cluster No.13 successfully collects similar sentences.
 Based on the result, we calculate the degree of importance imp t for term t . Fig.7(b) shows the top 10 terms of total number, and Fig.7(c) show the 10 terms of imp t . From these tables, we can understand that  X  X uru X (do something) is used in most number of sentences, but this term is general, and it is used in most cluster. And, the terms listed in Fig.7(c) such as  X  X ito X (person),  X  X uki X (snow) are characteristic for a particular cluster. Fig.7(d) show the re-clustering result. While 4 clusters can collect similar sente nces by applying k-means clustering at once, almost cluster can gather similar sentences by clustering after weight re-calculation.
 The information extraction from the huge Web space focuses attention in re-cent years. Fujii, et al. are developing a cyclopedia named  X  X yclone X  X 1] which is providing a huge content of encycloped ia by extracting sentences from the Web that are considered appropriate to use as explanations of a term. And, there are also several researches about extraction of famous people X  X  information[4] and person X  X  nickname[6]. These researches use heuristics to extract appropriate sentences. Like them, we also apply heuristics to the example sentences using onomatopoeia. However, in the case of using heuristics, we may hope getting data with some level of accuracy, but th ere is no guarantee for the credibil-ity. In our case, we may get some inappropriate sentences, so we also consider combining user participatory model lik e  X  X ikipedia X  to edit the sentences.
Talking about e-learning for Japanese education, there is  X  X sunaro X  X 3] which is provided by International Student Center of Tokyo Institute of Technology. Asunaro displays the polyglot translation of sentences with scientific and tech-nical terms, grammar of Japanese sen tences and explanation of a term.
And about onomatopoeia online dictionary or cyclopedia, Koubayashi, et al. made an onomatopoeia dictionary[5] whose onomatopoeia X  X  example sentences are extracted by hands from a book and shown in three languages. Also there are some Web pages, for instance,  X  X lc X  X 8] developed by space arc or page[10] devel-oped by The National Institute for Japanese Language. But these pages X  example sentences are collected by hands by those s ervice providers, so the number of sen-tences is limited. Therefore, if we are ab le to extract appropriate sentences from Web in huge number, that will help those system X  X  construction or management. We are developing an onomatopoeia dictionary, Onomatopedia, which automat-ically extracts examples of onomatopoeia from the Web, and presents them to learners online. This paper describes effici ent techniques of extracting appropri-ate examples and clustering examples based on the onomatopoeia X  X  meaning. Because it is very difficult to collect an d organize good-quality sentences for learning automatically, after we apply the collection and organization program, we currently must check and modify sentences manually.

As future work, we need to improve the precision of filtering and organization of this system. We are planning to make a portal site for Japanese onomatopoeia based on  X  X nomatopedia, X  and will introduce a mechanism for users of the portal site to improve sentences using folksonomy techniques.

