 Department of Computer Engineering, Sharif University of Technology, Tehran, Iran 1. Introduction
In recent decades, many researches have been done in visual object recognition. Due to the high volume of videos and attempts to index them based on their content, the idea of content-based categorization has been developed from static images to videos. In these methods, the machine should learn the models of human motions to be able to classify human actions. Human action categorization has many applications; that includes detecting similar motions in surveillance videos, summarizing and indexing videos, organizing video archives based on their contents, intelligent fast-forwarding/rewinding based on a desired action, and the forth. It is considered as a challenging problem due to occlusion, camera movements, clutters, as well as changes in viewpoint, illumination, and geometry.

An action can be considered as an object that contains time. In general, motions can be considered as static or dynamic. In [18], dynamic motions are divided into three main categories of: i) a moving the motions of types ii and iii.
Our motivation, in general, is to propose a solution to better classify human actions. This work cases. Considering that feature-weighting methods have been successfully applied on the discriminate weighting methods are introduced to obtain discriminative features. It is shown that these methods exhibit superior performance compared to the state-of-the-art methods.
 results are given. Finally, Section 5 concludes the paper. 2. Related work 2.1. Human action categorization
Research in the fi eld of human action categorization and motion analysis can be divided into several main approaches. One approach is based on computing the correlation between volumes of video data. the similarity of actions is measured by the correlation function. However, they have assumed humans as  X  X he 30 pixel mans X  and therefore their method is not scalable. In [15], global histograms of image of each category are estimated and compared by a speci fi c distance measure.

Another approach is based on tracking the body parts. In that method, motion trajectories of moving body parts are used as action descriptors. The robustness of that algorithm is highly dependent on the using the corresponding 4D trajectories. The drawback of that approach is the signi fi cant amount of human annotations.

The third approach is based on representing action as local spatial-temporal interest points [2 X 4,8,9, a high rate of detections. The method responds to local regions that exhibit complex motion patterns. In [4], the idea of saliency regions in spatial images [21] is extended to the spatiotemporal case. motivated by [13], has proposed a generative graphical model approach to learn and recognize human actions. They have used the latent topic models (an unsupervised generative approach) for estimating latent variable distributions. Their algorithm can recognize and localize multiple actions in long and complex video sequences. In [2], the concept of motion context is introduced to capture both spatial features, a 3D shape called spin is used as the global feature for action recognition purposes. 2.2. Feature weighting schemes
Numerous feature weighting methods have been used to assign some scores to rank the used features terestingly, even a simple weighting approach has been found to perform well in conjunction with the k-nearest neighbor method. Here, we consider a selection of four weighting schemes. the two-way contingency table of a word t and a category c , the word-goodness measure is de fi ned to be [25] C is the number of times that c occurs without t , D is the number of times that neither c nor t occurs, and N is the total number of documents. 2.2.2. Mutual information
Mutual information (MI) is an information theoretic measure of association between two words. Point-c . Using two-way contingency table of a word t and a category c , the mutual information between t and c is de fi ned by [25] 2.2.3. Information gain
Information gain measures the number of bits of information obtained for category prediction by be [25] 2.2.4. Weighting based on support vectors
In this method, the linear support vector machine (SVM) is used to classify the training data by a hyper-plane (using linear kernel) and therefore for a test data, the SVM decides based on where K ( . ) is a kernel function. The linear kernel is chosen to decrease the computational cost and therefore K ( x test ,x test sample x test is classi fi ed based on whether x 1 test s not.

The absolute value | s classi fi cation if its coef fi cient has a large absolute value. 3. Proposed human action categorization methods
We use the spatio-temporal features as our main building block of the proposed method. Spatial-temporal features are local interest points in space-time domain. There are a number of methods to shows the main structure of our proposed human action categorization method. The schema is based on spatial-temporal features and is robustness against occlusion, noise, and geometry deformation. We assume that the videos can contain some camera motions ( e.g., in cases for which the videos have been captured by hand held cameras). In addition, actors perform actions in up to 30-degree difference in function is de fi ned as h The response function R has two parameters  X ,  X  that indicate spatial and temporal scales of features, not induce a strong response.
 Such descriptor does not provide scale invariance neither in the space nor in the time domain. In our implementation, we rely on the codebook to handle scale changes and camera motions.

In the action representation step, the bag of spatio-temporal words (BoSTW) model is used to create a codebook. This is commonly implemented as a histogram of the number of occurrences of a particular and the Euclidean distance is used as the measurement metric. In the BoSTW model ( i.e., some sort of feature quantization), the geometric arrangement between visual features is ignored which leads our method to be robust against occlusion and geometry deformation. While other approaches simultaneously fi nal codebook. In Section 4, we show that our category-based clustering method surprisingly improves The action descriptor is then formed by the histogram of codewords. At this stage, we are looking for the most discriminative inter-class codewords. In general, more discriminative representation of methods are proposed to discriminate action descriptors.

Suppose the training set D = { ( x where each x categories. The diagonal matrix W have more inter-category discriminative power. 3.1. Weighting based on probabilistic latent semantic analysis
Probabilistic latent semantic analysis (pLSA) was proposed by [20] for text analysis and was brought an unsupervised learning framework that permits to automatically discover the semantic clusters in the is, the order of words in a text document can be neglected. This probabilistic method contains three variables d, w and z which indicate action, codeword, and action category, respectively, in the vision context. Parameter z is called latent topic and should be learned.
 to be generated independently, we can marginalize over topics z to obtain the conditional probability P ( w | d ) spatial-temporal word w occurring in a particular action category z .

The goal of this algorithm is maximizing the following objective function using an expectation-maximization (EM) algorithm where n ( w, d ) is the number of codewords w in action d and P ( w, d ) is obtained from Eq. (9) by each topic in a particular action.

By maximizing the above mentioned objection function, action category distributions P ( w | z ) (which obtained. This algorithm can be considered as a clustering algorithm while it works in an unsupervised manner and proba bilistically assigns each action to a topic.
 explains the observation, that is fi nd the distribution of codewords over actions, i.e., P ( w | d test ) ,using Therefore, the distribution of codewords over each category can be obtained by in each category. Our desired weight matrix is constructed by 3.2. Weighting based on discriminative power
In this method, most speci fi c codewords in each category are selected. To this end, those codewords that exist in category i and not exist in category j = i get more weights. Therefore where f the codeword k in category j = i ,and f as similar categories (actions) and avoid confusing among them. 4. Experimental results 4.1. Used datasets
The mentioned algorithms were tested on two well-known datasets whose details are given below.
II. KTH human motion dataset [6] contains 6 types of human actions performed several times by 4.2. Results on weizmann dataset
Detection and description of spatio-temporal interest points are performed by using the procedure detailed in previous section. The detector parameters are set to  X  =2 , X  =2 and  X  =1 . 95 .Table1 parameters on the accuracy measure. Each spatial-temporal patch is described with the concatenated vector of its space-time gradients. Then, the descriptors are projected on a lower dimensional space of 80 dimensions according to Fig. 5(b). In order to construct the BoSTW, the features are clustered. Since the total number of features from all training examples is very large, we use only a subset of sequences to learn the BoSTW; in order to accommodate the memory requirements. Thus, we build the spatial-temporal codewords using a subset of our features. In addition, we have tested some well-known and hamming. The results of all these measures were almost the same. This test shows that our sample points are distributed in the feature space in a manner that above-mentioned measures does not have
Regarding the cluster quality measure, our measure is the within-cluster sums of point to cluster the clusters with the lowest values of our quality measure.

We have also tested the effect of the number of v ideo codewords on the r ecognitio n accuracy, as illustrated in Fig. 5 (a). It shows some depende ncies of the rec ognition accuracy on the number of for each run, we have learned a model from 80 videos and have tested the model on the 10 remaining videos.
Figure 6 shows the elapse time of detection and description processes by increasing the number of (i.e., detection is not dependent on the number of features). That is because we have applied linear fi lters on the whole video, which is not dependent on the number of features. At last, non-maximal description time is linearly dependent on the number of features. Table 2 shows the comparison of our proposed methods against some well-known feature weighting methods. All experiments reported results in Table 2 have been executed in the same benchmark (i.e., the leave-one-out schema and the k-fold cross validation method).

We have also compared our results with the best results from [11], which are obtained using the LDA with the same experimental settings. Figure 7 compares the best results obtained by weighting based on the discriminative features versus them. Each row in the confusion matrix corresponds to the ground similar actions (such as  X  X kip X  with  X  X un X  and  X  X ump X ) but our proposed model can distinguish among shows how the number of latent topics in the pLSA algorithm can affect the categorization accuracy. 4.3. Results on KTH dataset
As described in Section 3, the detector has two parameters  X ,  X  that are tuned to achieve the best results for  X  =2 and  X  =2 on the KTH dataset. In addition, in the procedure of applying non-maximal other. We selected  X  =1 . 95 in our experiments.

The description procedure is explained in Section 3. The descriptors are then projected on a lower dimensional space of 80 dimensions. In order to build the codebook, the k-means algorithm is used to randomly selected 30 features per training video to learn the codebook.

Actions based on their actors are divided into 25 sets. In order to test the algorithm the leave-one-out (LOO) testing paradigm is used and the reported results are the average of 25 iteration of LOO. Figure 9 shows the obtained confusion matrix of proposed methods where the k-nearest neighbors 120 frames with resolution 160  X  95, on an Intel Core 2 Duo 2 GHz machine with 2 GB ram. The results are reported in Table 3.

Table 4 shows the performance of some state-of-the-art methods. Please note that our experimental proposed methods obtain superior performance. In this table, the category-based clustering is used in order to form the codebook. 5. Conclusion
The main goal of this paper was to develop new human action categorization techniques to improve the performance of the current state-of-the-art methods. To this end, two weighting methods were proposed we reached to accuracy of 92% on KTH dataset and 96.6% on Weizmann dataset. In the second method, of accuracy on KTH dataset that is more accuracy compared to other available methods. In the case of similar actions, it was demonstrated that while other algorithms were confused among similar actions, our proposed method achieved more accurate results in relatively high rates.
 References
