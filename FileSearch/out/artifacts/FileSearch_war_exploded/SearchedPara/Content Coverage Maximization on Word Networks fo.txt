 This paper studies text summarization by extracting hierarchical topics from a given collection of documents. We propose a new approach of text modeling via network analysis. We convert doc-uments into a word influence network, and find the words sum-marizing the major topics with an efficient influence maximization algorithm. Besides, the influence capability of the topic words on other words in the network reveal the relations among the topic words. Then we cluster the words and build hierarchies for the top-ics. Experiments on large collections of Web documents show that a simple method based on the influence analysis is effective, com-pared with existing generative topic modeling and random walk based ranking.
 I.7 [ Computing Methodologies ]: Document and Text Processing; H.2.8 [ Database Applications ]: Data Mining Algorithms, Experimentation Information Coverage, Topic Hierarchy, Keyword Extraction, Text Summarization
Text summarization encompasses an important category of text mining problems. It refers to the automatic creation of a com-pressed version of a given text that provides useful information for the user. Most work in this area focuses on creating summary for a single document or a set of documents with the same topic. We study the summarization task for a collection of documents with arbitrary topics. On contrary to the sentence-level summarization on single document or multiple related documents, we summarize the collection with keywords, and further study their relatedness to discover the hierarchical topics of the given text.

Topic modeling is another important category of text mining problems. Most of existing topic modeling techniques, originat-ing from Probabilistic Latent Semantic Indexing [10] and Latent Dirichlet Allocation [1], are based on the probabilistic generative process of text. They associate a document with soft clusters ac-cording to their topics, and find topic words that best represent each topic. In our work, we propose an alternative framework of discov-ering topics from text. We first extract keywords towards the goal of text summarization, and then construct hierarchical topics from these keywords based on their role and relation in the summary. While traditional topic modeling does not have the explicit goal of optimizing the conciseness and content coverage, we target using a small number of words to cover the major topics  X  as required by the summarization task.

Motivated by the interestingness of topic modeling and the need of concise summarization, this paper explores a new problem ly-ing in the intersection of text summarization and topic modeling  X  we try to summarize a collection of documents with hierarchical topics, which comprise a small number of keywords covering the major content of the collection. Solving this problem allows us to have a general idea of the major topics and minor topics in this col-lection, summarize them in a taxonomy, and further categorize the documents and index them. This also benefits a lot of applications such as automatic construction of concept hierarchy for domain knowledge, with huge available text collections on the Web such as scientific papers and news reports. For documents with mixed topics, this allows hierarchical browsing of the major topics; for documents with a relatively pure topic, we can find the most rep-resentative words and explore their semantic relations within this topic.

Recently, robust information network analysis techniques have been shown appealing to research in text summarization, e.g. , in multi-document extractive generic text summarization [7], single document summarization and keyphrase extraction [28]. Words and sentences can be modeled as nodes linked by their co-occurrence or content similarity. And then a variety of network analysis ap-proaches can be applied. For text summarization, representative words and sentences can be found with certain assumptions about their properties in the network. In our case, by compressing text in-formation into the word network, we do not need to scan every orig-inal single document. The complexity of mining the word network only depends on the scale of the vocabulary which can be small with the help of term filtering. That enables handling larger scale of document collections than mining directly from the documents, and provides a practical motivation for doing the summarization-oriented topic modeling. However, most network-based studies employ the idea of random walk to do prestige ranking as PageR-ank [2] does. Though such a ranking model captures some depen-dency between the nodes, it does not model the objective of maxi-mizing the coverage on the content with a small number of words or sentences. Some issues such as redundancy removal are not in-herently captured by importance ranking. That motivates us to find better methods.

We adopt the idea of network-based analysis, but propose a new summarization framework for extracting keywords from a docu-ment collection and organizing them in meaningful topic hierar-chies. Rather than heuristically assessing word centrality, we ex-plicitly model the information coverage with an influence propa-gation model. The text collection is modeled as a network with nodes representing words and links representing relatedness be-tween two words. Influence is propagated in the network according to a stochastic cascade model. Under the influence cascade model, the expected number of nodes influenced by a set of k nodes (re-ferred to as seeds ) indicates the content coverage of the k seeds. We want to find a small set of seeds that maximize the content cov-erage, and build the relationship among the seeds by analyzing the words influenced by them.

The research questions we would like to study are: 1) Can we use the coverage maximization model to find summary words; 2) What is a good influence propagation model and how does it compare to other network analysis model such as random walk and 3) How to discover hierarchical topics from the extracted summary words, and how is it compared to a generative topic modeling method.
Our contribution. We first propose the idea of using an influ-ence propagation model to model the content coverage. Then we define a meaningful word network where the relation of word A influencing word B corresponds to meaningful semantic relations of A and B. Based on an approximation algorithm with theoreti-cal error bound, we develop a new algorithm that can efficiently discover the summary words and build topic hierarchy through in-fluence analysis. The input and output are illustrated in Figure 1. We compare our approach with both the PageRank-alike approach and statistical topic modeling. The experiment results show that the algorithm is not only scalable but also achieved higher accuracy in both summary words selection and topic hierarchy construction.
The rest of this paper is organized as follows: We first give a review of the related literature in Section 2, followed by some background introduction of our techniques in Section 3. Then we present our framework and methodology in Section 4 and Sec-tion 5, about influence network modeling of text and the topic orga-nization respectively. Section 6 demonstrates our performance on two collections of documents, and Section 7 concludes.
Erkan and Radev [7] propose LexRank, a variation of RageR-ank [2], to solve extractive generic multiple document summariza-tion, and show it achieves better performance than centroid-based method [21]. Mihalcea and Tarau [16] and Wan et al. [29] also use PageRank to do single document summarization and keyword ex-traction. Their work shows how to choose the nodes and links, and assign transition probability along each link. Different choices are adopted for different applications. A common strategy is to rank the nodes, either sentences or words, and select them greedily with some reranking technique such as Maximal Marginal Relevance (MMR) [3], or Cross-Sentence Information Subsumption [20].
In these graph-based ranking methods, the ranking and the re-dundancy removal are done separately, and the objective is not maximizing the information coverage. Influence maximization, while having not been applied as widely as PageRank, captures both the centrality and the coverage and better fits the text summarization need. Domingos and Richardson [6, 22] are the first to study influ-ence maximization as an algorithmic problem. Their methods are probabilistic. Kempe, Kleinberg, and Tardos [11] are the first to formulate the problem as a discrete optimization problem, and they present a greedy approximation algorithm with theoretical guar-antee. A major drawback of their work is the scalability of their greedy algorithm. Several recent studies aim at addressing this is-sue[12, 13, 4, 30]. It is not quite clear what is a good assumption on the influence probability as well as the network structure, though there is some work trying to infer those from observations [9, 24], and some other work trying to analyze it by inducting from intu-itive features and constraints [25]. To the best of our knowledge, it is not explored how to apply influence maximization in other data mining problems, and how it is different with Random Walk model in such applications.

There are some studies using existing taxonomy to classify doc-uments, or organize information into an existing taxonomy such as Open Directory Project (ODP, www.dmoz.org), WordNet and Wikipedia [8, 23, 19]. Our methodology is different as we do not refer to any existing, manually edited taxonomies. We attempt to automatically find the specific topic hierarchy for given document collections instead.

To find relations among summary words from a set of documents and form them in a topic hierarchy, stochastic topic modeling can be applied. Latent Dirichlet allocation (LDA) [1] is a widely-used topic model, and the basis for many variants. Teh et al. [26] pro-poses hierarchical Dirichlet processes (HDP) to model topics that have a hierarchical structure. Pachinko allocation models [14, 17] improve it by allowing children topics shared by different parent topics. However, the summarization need of finding a small set of keywords in these studies is not considered.
Recently, Wang et al. [31] propose to construct topic hierarchy from titles, not generic documents. Chuang and Chien [5] and Liu et al. [15] generate taxonomy of given keyword phrases by hier-archical clustering techniques, with the help of knowledge bases and search engine. These studies do not consider the summariza-tion need. We are the first to study the topical structure discovery towards the summarization goal, i.e. , take a set of documents as in-put, summarize them with a small number of words, find relations among summary words and organize them in a topic hierarchy.
Our summarization framework has two stages. The first stage extracts keywords from the document collection, and the second stage studies the relation among the keywords and organize them in hierarchical topics. We propose to use network analysis techniques for these two stages. Therefore, we briefly introduce two relevant network analysis techniques in this section.
Graph-based ranking methods have been proposed for document summarization and keyword extraction tasks [7, 16, 29]. These methods are inspired by PageRank [2], originally used for web page ranking based on their link structure. The assumption is that an important page is linked to many other important pages. In analogy, researchers construct word network (sentence network, resp.) for text data and assume the more important words (sen-tences, resp.) are linked to many other important words (sentences, resp.). The common abstract model for these studies is random Walk on weighted graphs: an imaginary walker starts from a ran-dom node, chooses a neighbor with a probability proportional to the link weight, and then walks from that neighbor. This random process eventually produces the probability of arriving at each node on the graph. The probability of arriving at each node is then used as an indication of the popularity, centrality, or importance of that node. This is the spirit of most graph-based ranking methods for text data. The difference is whether they use a node to represent a word or a sentence, and how they define the transition probability from one node to another, according to various text features like similarity and cooccurrences.

After computing the ranking score, one can retrieve the top ranked words or sentences as the output. However, many researchers have found that this naive strategy may result in redundant information because the top ranked words or sentences can be similar and have overlapped meaning. They applied reranking techniques such as maximal marginal relevance (MMR) principle to ameliorate that problem [3]. For example, suppose the ranking score is r node i , one can perform the following reranking strategy: the top ranked node is retrieved one by one, and once a node r trieved, the ranking score of all the other nodes is discounted to be r = r i  X  w ij r j , where w ij is the transition probability from node i to j . The reranked result may contain less redundancy than orig-inal results. Although the reranking technique provides a compro-mise between the random walk-based ranking and the information redundancy, it is not a principled solution to the content coverage maximization X  the content coverage is not modeled in the random walk process, and the reranking does not guarantee the coverage is maximized either.
Due the discussed issue above, we resort to another network analysis technique in social network study, namely influence maxi-mization, as we find its objective is more analogous to ours. In this section, we briefly introduce the influence maximization problem in social network analysis. In next section we propose our model for the text summarization.

A social network is modeled as a graph G = ( V,E ) with node sets V representing individuals and edge sets E representing con-nections or relationship between two individuals. Influence is prop-agated in the network according to a stochastic cascade model. One popular model is independent cascade (IC) model: Each edge ( u,v ) in the graph is associated with a propagation probability pp ( u,v ) , which is the probability that node u independently ac-tivates (a.k.a. influences) node v at step t + 1 if u is activated at step t . Given a seed set S  X  V , the independent cascade (IC) model works as follows. Let S t  X  V be the set of nodes that are activated at step t  X  0 , with S 0 = S . At step t + 1 , every node u  X  S t may activate its out-neighbors v  X  V \ X  0  X  i  X  t independent probability of pp ( u,v ) . The process ends at a step t with S t =  X  . Note that each activated node only has one chance to activate its out-neighbors at the step right after itself is activated, and each node stays as an activated node after it is activated. The influence spread of S , which is the expected number of activated nodes given seed set S , is denoted as  X  I ( S ) .

Given an input k , the influence maximization problem under an influence propagation model is to find a subset S  X   X  V such that | S  X  | = k and  X  I ( S  X  ) = max {  X  I ( S ) | | S | = k,S  X  V } . It is shown in [11] that for IC model, this problem is NP-hard, but a constant-ratio approximation algorithm is available. One im-portant issue, however, is that there is no efficient way to compute  X  ( S ) given a set S . Wang et al. [30] proves that the computa-tion is actually #P-hard. It follows that an efficient approximation algorithm is open to question, according to [27].
We choose to adopt the idea of influence maximization in our task because its principle suits our need of summarizing text with good coverage better than the random walk idea. The goal of so-cial influence maximization is analogous to content coverage max-imization, as we show in the following model.

Given a set of documents, after removing stopwords, we con-struct a network for the whole collection, where each node repre-sents one word, and each link connects two words that ever cooc-cur in some document. The propagation probability from word x to word y can be explained as if we see word x , how likely we re-ceive the meaning of y without seeing y . In this sense once a word is  X  X ctivated X , its meaning is regarded to be covered by the initial set of seeds which correspond to the summary words we select. To obtain a good summary, we want to find a small set of words that cover the largest number of words in expectation.
One important question is how to define the influence probabil-ity to capture the meaningful semantic relations of two cooccured words x and y . In this paper we consider three alternative defini-tions for the influence probability from y to x : i) the conditional probability of x  X  d given y  X  d in an arbitrary document d , ii) the conditional probability of y  X  d given x  X  d , iii) the mutual information between x  X  d and y  X  d ,
The first two definitions are natural candidates according to our influence propagation model. However, they have obvious biases: definition i) favors highly frequent words, or stopwords as seeds because these words cooccur with other words a lot. Likewise, def-inition 2) favors rare words. Mutual information is a better measure to characterize the mutual dependence of two words. However, our formulation requires that the influence probability in the range of [0,1]. Also, a node should have probability 1 of activating itself according the definition. Therefore, we normalize the mutual in-formation as follows. This normalization ensures that a node activates itself with proba-bility 1. We use Eq. (4.1) as our influence probablity definition to construct the influence network.
The scale of the word network can exceed what algorithms for IC model can efficiently handle. We resort to alternative models that approximate IC model. The basic maximum influence arborescence (MIA) model, and its variance prefix excluding MIA (PMIA) model in [30] are both shown to have scalable approximation algorithms and achieve a near-optimal solution for IC model as well. Here we take the basic MIA model as an example to illustrate.

The basic idea is to restrict the range and path of influence propa-gation to reduce the computation for the neglectable influence. For a path P =  X  u = p 1 ,p 2 ,...,p m = v  X  , we define the propagation probability of the path, pp ( P ) , as Intuitively the probability that u activates v through path P is pp ( P ) , because it needs to activate all nodes along the path. To approxi-mate the actual expected coverage within the word network, we can use the maximum influence path ( MIP ) to estimate the influ-ence from one node to another. Let P ( G,u,v ) denote the set of all paths from u to v in a graph G . We define the maximum influence path MIP G ( u,v ) from u to v in G as
Note that for each edge ( u,v ) in the graph, if we translate the propagation probability pp ( u,v ) to a distance weight  X  log pp ( u,v ) on the edge, then MIP G ( u,v ) is simply the shortest path from u to v in the weighted graph G . Therefore, the maximum influence paths directly correspond to shortest paths, and thus they permit efficient algorithms to compute them. For a given node v in the graph, the union of the maximum influence paths to v , form the maximum influence in-arborescence.

Algorithm 1: ap ( u,S, X  )
To further prune the neglectable influence, we use an influence threshold  X  to eliminate MIPs that have too small propagation prob-abilities. The activation probability of any node v , denoted as ap ( v,S, X  ) , is defined to be the probability that v is activated by seed set S via MIPs with propagation probabilities larger  X  . ap ( u,S, X  ) can be computed efficiently when S and  X  are given. First, we use Dijkstra algorithm to compute the maximum influence in-arborescence ( MIIA ) which is the union of all the maximum influence paths to v . Intuitively, MIIA ( v, X  ) give the local influence regions of words that can cover the meaning of v , and different values of  X  con-trol the size of these local influence regions. Second, we recur-sively traverse the arborescence MIIA ( v, X  ) to compute the re-strictive activation probability ap ( u,S, X  ) for every node u in it: ap ( u,S, X  ) = 1 if u  X  S , and ap ( u,S, X  ) = 1  X   X  w  X  N in ( u ) ap ( w,S, X  )  X  pp ( w,u )) if u /  X  S , where N in ( u ) is the set of in-neighbors of u in MIIA ( v, X  ) . The algorithm is outlined in Algo-rithm 1.

Let  X   X  ( S ) denote the coverage of S in MIA model with influence threshold  X  , then we have: due to the linearity of the expectation over the sum of random vari-ables.

We are interested in finding a set of seeds S of size k such that  X  ( S ) is maximized. It is not surprising that this optimization prob-lem is NP-hard [30]. Furthermore, it is NP-hard to approximate within a factor of 1  X  1 /e + for any &gt; 0 . However, function  X   X  is submodular and monotone and  X   X  (  X  ) = 0 . We say that a non-negative real valued function f on subsets of V is submodu-lar if f ( S  X  X  v } )  X  f ( S )  X  f ( T  X  X  v } )  X  f ( T ) , for all v  X  V and all pairs of subsets S and T with S  X  T  X  V . Intuitively, this means that f has diminishing marginal return. Moreover, we say that f is monotone if f ( S )  X  f ( T ) for all S  X  T . By a the-orem in [18], for any submodular and monotone function f with f (  X  ) = 0 , the problem of finding a set S of size k that maximizes f ( S ) can be approximated by a simple greedy algorithm shown as Algorithm 2. The greedy strategy is iteratively selecting new seed u that maximizes the incremental change of f into the seed set S until k seeds are selected. It achieves 1  X  1 /e approximation ratio for the coverage maximization problem in the MIA model.

Computing  X   X  ( S ) using Eq. (4.2) and Algorithm 1 is polynomial-time. Together with Algorithm 2, we already have a polynomial-time approximation algorithm. It can be optimized to near-linear. Consider the maximum influence in-arborescence MIIA ( v, X  ) of size s and a given seed set S . To select the next seed u , we need to compute the activation probability ap ( v,S  X  X  w } , MIIA ( v, X  )) for every w  X  MIIA ( v, X  ) , which takes O ( s 2 ) time if we sim-ply use Algorithm 1 to compute every ap ( v,S  X  X  w } , X  ) . We now
Algorithm 2: Greedy ( k,f ) show a batch update scheme such that we could compute ap ( v,S  X  { w } , X  )  X  X  for all w  X  MIIA ( v, X  ) in O ( s ) time.

To do so, we utilize the linear relationship between ap ( u,S, X  ) and ap ( v,S, X  ) in MIIA ( v, X  ) , as shown by the following lemma, which is not difficult to derive from line 6 of Algorithm 1.
L EMMA 1 (I NFLUENCE L INEARITY ). Consider MIIA ( v, X  ) and a node u in it. If we treat the activation probability ap ( u,S, X  ) as an independent variable, ap ( v,S, X  ) as a dependent variable, and other ap ( w,S, X  )  X  X  as constants for all w  X  X  not on the path from u to v in MIIA ( v, X  ) , then ap ( v,S, X  ) =  X  ( v,u )  X  ap ( u,S, X  )+
Algorithm 3: Compute  X  ( v,u ) given MIIA ( v, X  ) and S , after ap ( u,S, X  ) for all u in MIIA ( v, X  ) are known. 10: end if 11: end if
Based on the recursive computation of ap ( u,S, X  ) as shown in line 6 of Algorithm 1, it is straightforward to derive a recursive computation of  X  ( v,u ) , as shown in Algorithm 3. To see the intu-ition behind the equations, we remind that  X  ( v,u ) is the increment of the activation probability of v caused by unit increment of u  X  X  ac-tivation probability. Therefore, the boundary of the recursive com-putation is natural: when u = v , unit increment of u  X  X  activation probability results in the same increment of v  X  X  activation probabil-ity; when u  X  X  out-neighbor w is a seed node, the increment of its activation probability does not induce any change of v  X  X  activation probability because w is already activated. In other cases, the effect of u on v is determined by the effect of its out-neighbor w on v and the chance that w is activated by its in-neighbor u exclusively. The product over w  X  X  in-neighbors except for u in line 9 corresponds to the probability that w is not activated by other in-neighbors. Note that Algorithm 3 can be transformed into an iterative form such that all  X  ( v,u )  X  X  can be computed by one traverse of MIIA ( v, X  ) from the root to the leaves.

Computing the linear coefficients  X  ( v,u ) as defined in Lemma 1 is crucial in computing the incremental coverage of a node u . Let us consider again the maximum influence in-arborescence MIIA ( v, X  ) of size s and a given seed set S . For any w  X  MIIA ( v, X  ) , if we se-lect w as the next seed, its ap ( w ) increases from the current value
Algorithm 4: MIA ( G,k, X  ) 10: end for 11: end for 12: /* main loop */ 13: for i = 1 to k do 14: pick u = arg max v  X  V \ S { IncCov ( v ) } 15: /* update incremental content coverage*/ 16: for v /  X  S such that u  X  MIIA ( v, X  ) do 17: /* subtract previous incremental coverage */ 18: for w  X  MIIA ( v, X  ) \ S do 19: IncCov ( w )  X  =  X  ( v,w )  X  (1  X  ap ( w,S, X  )) 20: end for 21: end for 22: S = S  X  X  u } 23: for v  X  MIOA ( u, X  ) \ S do 24: compute ap ( w,S, X  ) ,  X  w  X  MIIA ( v, X  ) (Algo. 1) 25: compute  X  ( v,w ) ,  X  w  X  MIIA ( v, X  ) (Algo. 3) 26: /* add new incremental coverage */ 27: for w  X  MIIA ( v, X  ) \ S do 28: IncCov ( w ) +=  X  ( v,w )  X  (1  X  ap ( w,S, X  )) 29: end for 30: end for 31: end for 32: return S to 1 . Since ap ( w ) and ap ( v ) has a linear relationship with the linear coefficient  X  ( v,w ) , the incremental coverage of w on v is given by  X  ( v,w )  X  (1  X  ap ( w )) . Therefore, we only need one pass of MIIA ( v, X  ) to compute ap ( w )  X  X  for all w  X  MIIA ( v, X  ) , and a second pass of MIIA ( v, X  ) to compute  X  ( v,w )  X  X  and  X  ( v,w )  X  (1  X  ap ( w ))  X  X  for all w  X  MIIA ( v, X  ) . This reduces the running time of computing incremental coverage of all nodes in MIIA ( v, X  ) from O ( s 2 ) to O ( s ) .

The complete greedy algorithm for the basic MIA model is pre-sented in Algorithm 4. Lines (2 X 11) evaluate the incremental con-tent coverage IncCov ( u ) for any node u when the current seed set is empty. The evaluation is exactly as we described above using the linear coefficients  X  ( v,u ) . Lines (15 X 30) update the incremental coverage whenever a new seed is selected in line 14. Suppose u is selected as the new seed in an iteration. The influence of u in the MIA model only reaches nodes that contain u in their maximal influence in-arborescences. Thus the incremental influence spread IncCov ( w ) for some w needs to be updated if and only if w is in MIIA ( v, X  ) for some v containing u in its MIIA. This means that the update process is relatively local to u .
 Time and space complexity. Let s  X  = max v  X  V {| MIIA ( v, X  ) |} . The total running time of the algorithm is O ( | V | s  X  + ks For every node v  X  V , the algorithm stores MIIA ( v, X  ) , and for ev-ery u  X  MIIA ( v, X  ) , ap ( u,S, X  ) and  X  ( v,u ) are stored (note that ap ( u,S, X  ) can reuse the same entry for different seed set S ). We also need a max-heap to store and update IncCov ( v ) for all v  X  V . In total, the space complexity of the algorithm is O ( s  X 
Based on the above influence network model, we can find the words that cover the major topics in a document collection. The next question is how to find the relation among these words and or-ganize them into hierarchical topics. We still approach this problem with coverage analysis.
 We reexamine the coverage maximization algorithm in Section 4.2. The only important step in the greedy algorithm is to select the next seed that gives the largest incremental coverage spread. Suppose the current seed set is S . To select the next seed u , we need to eval-uate the incremental coverage of each w  X  MIIA ( v, X  ) for every word u . As we mentioned in Section 4.2, there is a linear relation-ship between the activation probability ap ( v,S, X  ) and ap ( w,S, X  ) when the seed set is fixed, under MIA model. Assume the linear coefficient is  X  t ( v,w ) after t seeds are selected. The incremental coverage of w on v after t seeds are selected can be computed as: where S t is the set of first t seeds selected. IncCov t ( w,v ) predicts that given the current seed set S t , if w is added as a seed, how much more coverage on node v we can gain. While the summation P v IncCov seed selection, the individual incremental coverage IncCov has not been utilized.

We believe the coverage vector IncCov t ( w,  X  ) for each indi-vidual w is an important feature for finding the word relations. The coverage vector refelects the capability of coverage from each word. Semantically related words should also have related cover-age capability on other words.

Suppose u x and u y are two seeds selected at the x -th and y -th place, and u x is selected before u y ( i.e. , x &lt; y ). We examine their coverage vectors to infer their relation.

First we define the dot product between their coverage vector: If u x and u y are about the same topic, u y should cover a similar set of words as u x does. So we define a measure: for the  X  X ame topic X  relations between the two nodes.

Second, if u y is talking about a subtopic that is covered by the topic of u x , the incremental coverage brought by u mostly covered by u x . We have:
The nodes can be grouped to form topics. To compute the two measures in group level, we first compute the individual node-level measure according to Eq. (5.3) and (5.4), then take average over the first group S 1 , and finally select median over the second group S , as follows. We tried other operators like max, min and other combinations, and this choice gives the best results among them.

We use these measures same and super to organize the words into hierarchical topics. Our algorithm has two phases: grouping and splitting. In grouping phase the groups are built by merging seed words. We initialize each group as containing only one seed word. For any group, if the largest same measure with another groups is above a threshold t 1 , we can merge them. And the merged groups can be further merged to form larger groups. In splitting phase, the relation between each group and its candidate parent are examined. If the super measure is above another threshold t assign the super-sub relationship between them; otherwise we as-sume the parent-child relation is weak and the two groups should represent independnt topics. The algorithm is outlined as follows.  X  Initialization. Each word forms a single group, and the parent pointer is set to a word selected before it and having the largest super measure with it.  X  Grouping. In grouping phase the groups are merged bottom-up iteratively. In each round two groups that are either parent-children or siblings, with largest same measure will be merged. The same and super measures are recomputed between the new group and existing groups. The parent pointer is updated according to the new super measure. This process lasts until the number of groups is small enough or the same measure of any two groups is smaller than a threshold t 1 .  X  Splitting. In splitting phase, we break the weak relation be-tween a group and its parent group. We break one weakest relation with the smallest super measure each time. We repeat this break-ing until the weakest relation has a larger super measure than a threshold t 2 , or the number of root topics has been desirable.
This algorithm is simple and heuristic. It only relies on the in-cremental coverage IncCov which can be naturally obtained from the efficient MIA algorithm. It is guaranteed to stop in finite steps because the maximum number of grouping and splitting is limited by the total number of seeds. One advantage of this algorithm is that it can generate flexible hierarchy with only two parameters. Depending on different use cases, one has the following choices of parameter specification.  X  The number of total topics N and the number of root topics N .  X  The threshold for grouping phase t 1 and the number of root topics N 0 .  X  The number of total topics N and the threshold for splitting phase t 2 .  X  The threshold for grouping phase t 1 and the threshold for split-ting phase t 2 .

Therefore, although there are 4 parameters which can control the shape of the hierarchy, one only needs to specify two of them. Larger t 1 leads to larger N , and larger t 2 leads to larger N erating hierarchies with different parameters is low-cost because in our 2-stage summarization framework, the coverage maximization, the word selection and the computation of two measures same and super are done before the topic construction. So when we change the parameters like the total number of desired topics and the num-ber of top-level topics, we only need to run the heuristic algorithm again on the same small seed word graph. The simplicity in chang-ing parameters allows fast generation of word clusters with control-lable structures.
We conduct experiments with our algorithms and other algo-rithms, based on network analysis and generative topic modeling respectively, on several text collections including TREC news and online discussions. Our experiments aim at evaluating the follow-ing aspects of our approach: a) its performance in picking up sum-mary words; b) its ability in topic discovery and organization; c) the effect of parameters. Datasets. We use two document collections. One is TREC AP news collection, the other is 20 newsgroup.
 Build Influence Network. We remove stopwords from a given list and build index with Lemur. Then we build the word influence network by counting co-occurrence of each pair of words with the help of inverted index. The mutual information can be computed based on the document frequency (df) of their occurrence and co-occurrence: where | D | is the number of total documents. For each node in these networks, we remove the neighbors with influence probability smaller than a threshold t 0 = 0 . 001 . And we only keep at most top k = 100 neighbors for each node. This reduces the density of the network.
 Algorithms. We compare our algorithm with three algorithms based on three different modeling assumptions.  X  Degree+MMC. The first algorithm is a simpler heuristic algo-rithm for the coverage maximization. It chooses the words with maximal weighted out-degree, to perform coverage maximization. The weighted degree of a node is the sum of propagation proba-bilities on all its outgoing edges. When each seed is selected, we will discount the weighted degree of each neighboring word by the influence probability from the neighbor to the seed, because the se-lected seed cannot contribute to the neighbor X  X  marginal coverage any more. This is similar to Maximal Marginal Relevance but it is maximizing the marginal coverage, so we name it Degree+MMC. We chose this algorithm to see how much the performance relies on the accuracy of coverage maximization.  X  PageRank+MMR. This second algorithm is based on random walk. It uses PageRank for word ranking, and MMR for reranking, like previous researchers [7, 28] did. We use the normalized influ-v , and restart probability is set to be 0.85. We chose this algorithm to study the difference between content coverage maximization and the random walk model.  X  PAM. The last algorithm we compare to is a stochastic topic model, Pachinko Allocation Model (PAM) [14], which is an exten-sion of latent dirichlet allocation (LDA). It generates hierarchical topics according to user-specified number of topics in each level. It does not generate keyword summarization of the entire document collection, and we only compare the performance in topic construc-tion. This algorithm is representative of the Bayesian topic model-ing approach.

For the first two algorithms Degree+MMC and PageRank+MMR, we use them to select keywords and use the same topic organization algorithm in Section 5. For the thrid algorithm PAM, we need to do post processing to output comparable results because PAM gener-ates word distribution only at the leaf level. The internal, non-leaf topics in PAM are represented as mixture of child topics. We gener-ate the word distribution for non-leaf topics by mixing the children topics according to the mixture distribution.
 Table 1: Summary words selected by different algorithms on a subset of 20 newsgroups: alt.atheism, comp.graphics, comp.os.ms-windows.misc, comp.sys.ibm.pc.hardware, comp.sys.mac.hardware
To evaluate summary words selected by different algorithms, we conduct both quantitative study and qualitative study.

For qualitative study, we intensionally use documents of known topics to feed the summarization algorithms, and examine the re-sults. We use 20 newsgroups data as the base of documents. We order the 20 groups from group 1 to group 20, and add one group each a time to our document collection to summarize. In this way we obtain 20 sets of documents with different number of known topics: set 1 with group 1, set 2 with group 1 + group 2, etc. , and set 20 with everything. We examine the top 20 words as summary for each set to see whether they cover the known topics in each set. Table 1 shows an example of the results of PageRank(PR)+MMR, Degree+MMC and our algorithm on a subset of 5 groups. PAM is not relevant for this task.

We find that with the same number of summary words, our al-gorithm covers more topics, and generate more meaningful topic words in general. In the top 20 ranked words, there are 12 of them each of which covers one of the topics discussed in the news-groups, and they in total cover 4 topics. We notice that there are some noises in the data and all these algorithms will report some non-relevant words. We also observe that Degree heuristic and our method tend to generate more similar words while the output of PageRank is quite different. This is because both Degree heuristic and our method have a goal of maximizing the content coverage while PageRank does not. And one interesting observation is that PageRank will select more entity words like ca, austin, gatech etc. , perhaps due to their broad connection with other words. These are true for other test sets too.

For quantitative study, we evaluate the correspondence between the summary words and the known categories. If the words cor-Table 2: Mutual information of summary words selected by different algorithms on the whole 20 newsgroups data respond well to the known categories, and cover all the major cat-egories, they form a good summary. We measure the correspon-dence between the words W = { w 1 ,...,w k } and m categories C = { C 1 ,...,C m } with mutual information (MI)
Table 2 shows an example of the detailed results on the complete set of 20 newsgroup documents, including the word-category mu-tual information of top k words when k varies. We can see that our method generates a summary that better corresponds to the known categories, though we do not use any supervised information. The other two baselines have different properties. When k is small, PageRank + MMR performs better than Degree + MMC, because it ranks the words not only according to how many words they can in-fluence directly but also which words they can influence. However, since it does not model the coverage, the highly ranked words do not cover different information in every category. This is implied from the slow increase of the mutual information from k = 30 to 50 . On the other hand, although Degree + MMC does not select the most influential words at the beginning, it consistently choose words with large degree so these words have a good coverage on their neighbors at least. Our algorithm also maximizes the infor-mation coverage as Degree + MMC does, while it has the ability to utilize the structure of indirect neighbors as PageRank has. That is the reason it can select words with better quality than both.
Figure 2 shows the mutual information for different subsets, each of which contains all the documents with the same first-level topic such as Computer, Talk and Science. Our algorithm constantly gen-erates good summary words, while PageRank and Degree have no clear winner between them. On the subset of topic Science and Talk, the Weighted Degree heuristic works well, but for Computer and the whole collection it is inferior to PageRank; PageRank + MMR produces similar mutual information for the three subsets. Again, the variation of their performance in different situation val-idates the premise that PageRank works well when the number of chosen words is smaller or close to the number of topics, while the coverage-based method exhibits potential when more words are al-lowed to be selected in the summary. The subtopics in Talk, politics about guns, politics about Mideast, and misc politics and religion, are easy to distinguish because they have quite different terminol-ogy. However, in Computer topic, it is not easy to separate some of them because of the commonly shared terms, and we see none of the three approaches achieve an average mutual information gain above 0.01.
We evaluate the topic hierarchy by user study and quantitative measure.

Figure 3 shows an example of the topic hierarchy constructed by different algorithms on TREC AP news data in the year 1998. Each node in the hierarchy represents a topic, and each topic can Figure 2: Word-category mutual information for the top 25 ranked words on different subsets defined by the first-level group (super topic) Figure 4: Topic-category mutual information for n topics, on 20 newsgroup data have one or more subtopics that is covered by this topic. Note that in PAM the non-leaf topic is not a word cluster but a distribution of sub topics. We post-process the results to generate the word cluster from the topic distribution. Also we need to specify the number of levels and the number of topics on each level for PAM. Tuning the parameters is time consuming in PAM model, since each time the parameters is changed, we need to rerun the inference algorithm on the whole documents. Nevertheless, in our heuristic method the parameter adjustment is much easier, as we explained in Section 5.
For evaluation, we design a user study as follows. Since PAM gives different shapes of hierarchy as ours, the two hierarchies are not easily comparable. We try to evaluate a topic hierarchy by mea-suring whether two topics close to each other in the tree path dis-tance are also regarded similar by human being. If so, the tree structure of the topics is consistent with human judgment. So we ask each evaluator two common sets of questions, each set corre-sponding to one topic hierarchy generated by either PAM or our method. The number of questions in both sets are equal. They are mixed and shuffled before presented to every evaluator, so one will not tell the source of a question. Each question requires an evalua-tor to look at a triple of topics ( T 1 ,T 2 ,T 3 ) , and answer whether T
Sum of mutual information Figure 5: Word-category mutual information by 50 summary words and running time w.r.t.  X  , for the TREC AP dataset in the MIA model. Blue line  X  mutual information; Green dashed line  X  running time is conceptually closer to T 2 , T 3 , or hard to tell. Then we compare whether the answer matches the real tree path distance d ( T and d ( T 1 ,T 3 ) . For example, if d ( T 1 ,T 2 ) &gt; d ( T swer is that T 1 is closer to T 3 than it is to T 2 , we count it a match. A match rewards the evaluator 2 points and a  X  X ard-to-tell X  answer gains 1 point. A non-match answer contributes nothing. In this way we obtain a score from each evaluator X  X  answers to each set of ques-tions. Thus the score can be used to judge which topic hierarchy has higher consistency with common sense.

We generate topic hierarchy with our algorithm and PAM for the same subset of TREC AP collection, and randomly generate ques-tions so that in each triple ( T 1 ,T 2 ,T 3 ) , T 1 is either T child or sibling, while T 3 has none of those relationships with T Thus T 2 is regarded to be the matching answer. Then we randomly shuffle some T 2 and T 3 to form our question sets. The evaluation on 6 users with different background knowledge shows that our topic hierarchy with 12 topics in total is more consistent than that of PAM with 2 levels, 2 super topics and 10 leaf topics. The aver-age score for our hierarchy is 7.5, compared to PAM hierarchy of 3.3. Moreover, each user gives higher score on our hierarchy and the t-test has a p-value of 0.008. So the test result is statistically significant.

We also use topic-category mutual information to measure how well we can predict the category label of a document given that we know whether words of a topic occur in the document. Let T = { w 1 ,...,w p } be a topic with p words, and T = { T 1 ,...,T the set of topics. We can define the mutual information between topics and categories C = { C 1 ,...,C m } as We generate different number N of topics with each algorithm, and draw a curve of the mutual information of N topics, as shown in Figure 4. Our algorithm constantly outperforms the other two baselines.
The threshold  X  in the coverage maximization algorithm con-trols the degree of approximation. The smaller  X  is, the more ac-curate the coverage maximization problem can be solved, but the running time is larger. We investigate the summary results by dif-ferent  X  . The positive correlation between the coverage maximiza-tion accuracy and the word-category mutual information confirms our presumptions. As expected, the result quality and the running time stops increasing when  X  becomes small enough, which means the influence to the whole network has been taken into considera-tion. Even in that case, the running time is only around 30 seconds, which shows the superiority of the efficiency over most generative topic models.
We propose a summarization method based on the analysis of the word network constructed from an arbitrary set of documents. The advantage is we can compress the information in the network and study the relations among the words by simple but intuitive means. We explore the analogy of the word influence network to social influence network, and explore the idea of finding topics by study-ing the influence among the words and modeling it as an coverage maximization problem. The result of word summary and topic hi-erarchy shows the potential of this approach on both traditional and novel tasks in text summarization, and suggests promising new re-search direction.

One possible way to improve the results is to consider more fine granularity when creating the word network. For example, we may only link words that co-occur in a paragraph or a sentence, instead of in a document. This also helps reducing the density of the net-work. The idea of using influence network to model text can be further explored on sentence, document or heterogeneous networks with different type of nodes and links. It is also possible to solve different tasks by changing the definition of the influence probabil-ity. Most summarization tasks concern with not only the ranking but also the coverage. So all those tasks that are previously solved by PageRank-alike approach can now be reexamined in the cover-age maximization framework.
 This material is based upon work supported in part by the U.S. National Science Foundation grants CNS X 0931975, IIS X 1017362, IIS X 132061, CNS X 1027965, and U.S. Army Research Laboratory under Cooperative Agreement No. W911NF X 09 X 2 X 0053 (NS X  X TA). Chi Wang was supported by a Microsoft Research PhD Fellowship. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Army Research Labo-ratory or the U.S. Government. The authors would like to thank Wei Chen for his helpful discussion. [1] D. Blei, A. Ng, and M. Jordan. Latent Dirichlet allocation. J. [2] S. Brin and L. Page. The anatomy of a large-scale [3] J. Carbonell and J. Goldstein. The use of mmr, [4] W. Chen, Y. Wang, and S. Yang. Efficient influence [5] S.-L. Chuang and L.-F. Chien. A practical web-based [6] P. Domingos and M. Richardson. Mining the network value [7] G. Erkan and D. R. Radev. Lexrank: graph-based lexical [8] A. Fuxman, P. Tsaparas, K. Achan, and R. Agrawal. Using [9] A. Goyal, F. Bonchi, and L. V. Lakshmanan. Learning [10] T. Hofmann. Probabilistic latent semantic indexing. In [11] D. Kempe, J. M. Kleinberg, and  X . Tardos. Maximizing the [12] M. Kimura and K. Saito. Tractable models for information [13] J. Leskovec, A. Krause, C. Guestrin, C. Faloutsos, [14] W. Li and A. McCallum. Pachinko allocation: [15] X. Liu, Y. Song, S. Liu, and H. Wang. Automatic taxonomy [16] R. Mihalcea and P. Tarau. TextRank: Bringing Order into [17] D. Mimno, W. Li, and A. McCallum. Mixtures of [18] G. Nemhauser, L. Wolsey, and M. Fisher. An analysis of the [19] S. P. Ponzetto and M. Strube. Deriving a large scale [20] D. R. Radev. A common theory of information fusion from [21] D. R. Radev, H. Jing, and M. Budzikowska. Centroid-based [22] M. Richardson and P. Domingos. Mining knowledge-sharing [23] M. d. B. Rodriguez, J. M. G. Hidalgo, and B. D. Agudo. [24] M. G. Rodriguez, J. Leskovec, and A. Krause. Inferring [25] J. Tang, J. Sun, C. Wang, and Z. Yang. Social influence [26] Y. W. Teh, M. I. Jordan, M. J. Beal, and D. M. Blei. [27] V. V. Vazirani. Approximation Algorithms . Springer, 2004. [28] X. Wan and J. Xiao. Exploiting neighborhood knowledge for [29] X. Wan, J. Yang, and J. Xiao. Towards an iterative [30] C. Wang, W. Chen, and Y. Wang. Scalable influence [31] C. Wang, M. Danilevsky, N. Desai, Y. Zhang, P. Nguyen,
