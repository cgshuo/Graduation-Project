 Complementing the Semantic Web effort, a new breed of so-called Web 2.0 applica-tions recently emerged on the Web. Indeed, social bookmarking systems, such as e.g., D
EL . ICIO . US 1 ,B IBSONOMY 2 or F LICKR 3 have become the predominant form of con-tent categorization of the Web 2.0 age. The main thrust of these Web 2.0 systems is their diverse resources with freely chosen keywords aka tags. The resulting structures are called folksonomies 4 , that is,  X  X axonomies X  created by the  X  X olks X . Considered as a tri-partite hyper-graph [9] of tags, users and resources, the new data of folksonomy systems provides a rich resource for data analysis, information retrieval, and knowledge dis-covery applications. Recently, the discover y of shared conceptualizations opens a new research field which may prove interesting also outside the folksonomy domain: closed cept Analysis did not grasp a broad attention. However, with the rise of folksonomies , formally represented as triadic contexts , many researches advocate the extraction of lossless concise representations of interesting patterns from triadic data.
In this paper, we are mainly interested in the mining of frequent triadic concepts (tri-concepts for short) from 3-dimensional data, i.e., folksonomy . These patterns are among the recent research topics in Triadic Concept A nalysis. In this respect, a determined al-gorithmic effort was furnished to get out this type of patterns. Worth of mention, the pioneering work of Stumme et al., through the T RIAS algorithm [6], for tri-concepts mining. T RIAS inputs a folksonomy , formally represented as a triadic context, and com-putes all tri-concepts. However, the main moan that can be addressed to T RIAS , stands in its need to transform the triadic context into dyadic contexts in order to extract tri-concepts. Thus, the mining task becomes very computationally expensive and could be avoided by extending the basic notions of FCA (Formal Concept Analysis) for the tri-which directly operates on the triadic context. It consists in using cubes called cutters generalizing the cutters introduced for constraint-based mining of formal concepts [1]. at least one dimension of a folksonomy is high. Besides, the C UBE M INER algorithm op-Cerf et al. , in [2], proposed the D ATA -P EELER algorithm with the challenge of beating both later algorithms in terms of performance. The D ATA -P EELER algorithm is able to extract all closed concepts from n-ary relations. D ATA -P EELER enumerates all the n-dimensional closed patterns in a depth fi rst manner using a binary tree enumeration strategy. However, similarly to C UBE M INER , the strategy of D ATA -P EELER , involving a depth-first approach implies its depth X  X  recursion, in the worst case, to the total num-ber of elements (whatever the dimension). Moreover, D ATA -P EELER is hampered by the large number of elements that may contain any of the folksonomy X  X  dimensions and its strategy becomes ineffective and leads t o a complex computation of tri-concepts.
In this respect, a compelling and thriving issue is to introduce a new scalable algo-rithm, that overcomes the flaws of the previous ones. Hence, in this work, the main contribution is to introduce a new algorithm for tri-concepts mining, called T RICONS , aiming at providing better scalabilty than do the pioneering approches of the litera-ture, by applying an appropriate closure operator. In fact, the closure operator splits the search space into equivalence classes in o rder to find the tri-minimal generators. These tri-minimal generators, representative of the different equivalence classes, make the computation of the tri-concepts less arduous than do the aforementioned ones. In-deed, the tri-minimal generat ors are the smallest elements, i.e., tri-sets, in an equiva-lence class, while their associated closure is the largest one within the corresponding equivalence class. Thus, the pairs -composed by Tri-MGs and their related closures -encompassed by an Tri-MG and the related closures and; (ii) to straightforwardly han-dle the triadic form of a folksonomy towards an efficient extraction of tri-concepts.
The remainder of the paper is organized as follows. Section 2 recalls the key notions used throughout this paper. We scrutinize the related work of mining triadic concepts in section 3. In section 4, we introduce a new closure operator to the triadic context as well as the T RI C ONS algorithm dedicated to the extraction of frequent tri-concepts. The empirical evidences about the performance of our approach are provided in Section 5. Finally, we conclude the paper with a summary and we sketch ongoing research in section 6. paper. In the following, we start by presenting a formal definition of a folksonomy [6]. Definition 1. ( FOLKSONOMY ) A folksonomy is a set of tuples F = ( U , T , R , Y ) , where Y X  X  X T X R is a triadic relation such as each y  X  X  can be represented by resource r using the tag t .
 u } , T = { t indicates a tagging operation by a user from U , a tag from T and a resource from R , u The following definition presents the frequent tri-set [6].
 Definition 2. (A ( FREQUENT ) TRI -SET ) Let F =( U , T , R , Y ) be a folksonomy. A tri-set of F is a triple ( A , B , C ) with A  X  X  , B  X  X  , C  X  X  such that A  X  B  X  C  X  X  . Atri-set( A , B , C )of F is said frequent whenever | A | X  minsupp u , | B | X  minsupp t and | C | X  minsupp r ,where minsupp u , minsupp t and minsupp r are user-defined thresholds. As the set of all frequent tri-sets is highly redundant, we will in particular consider a specific condensed representation, i.e., a subset which contains the same information, ing [6,8].
 Definition 3. ((F REQUENT ) TRIADIC CONCEPT ) A triadic concept (or a tri-concept for short) of a folksonomy F = ( U , T , R , Y ) is a triple ( U , T , R ) with U  X  X  , T  X  T , and R  X  X  with U  X  T  X  R  X  X  such that the triple ( U , T , R ) is maximal, i.e., for U 1  X  U , T 1  X  T and R 1  X  R with U 1  X  T 1  X  R 1  X  X  , the containments U  X  U 1 , T  X  T equal to TC = { TC | TC =( U , T , R )  X  X  is a tri-concept } .
 Given a tri-concept TC =( U , T , R ), the U , R and T parts are respectively called Extent , Intent ,and Modus .
 Example 2. Consider the folksonomy depicted by table 1 . We can denote that the tri-set S u } , { t resources shared by the users u 5 and u 7 . With the rise of folksonomies , formally represented as triadic contexts, many researches advocate the extraction of implicit shared con ceptualizations formally sketched by tri-concepts. Indeed, J  X  aschke et al. , in [6], introduced the T RIAS algorithm to compute frequent tri-concepts from a folksonomy . Hence, tackling a folksonomy F =( U , T , R , Y ), T RIAS first constructs a dyadic context K 1 =( U , T X R , Y 1 ) whose columns corre-spond to couples of elements from T and R and then, via a projection, according to the T and R axis, extracts formal concepts. The second step of T RIAS consists, for each of T RIAS is to exploit the subsets of tri-concepts already extracted in order to check whether they lead to new tri-concepts. Howev er, several tri-concepts are computed re-dundantly inducing a number of unnecessary co mputations. This drawback occurs be-cause of the particular order of extraction of tri-concepts which is strongly inspired by the way of doing of the N EXT C LOSURE algorithm [4], dedicated to building of a lattice in using cubes called cutters generalizing the cutters introduced for constraint-based mining of formal concepts in [1]. These cu tters are recursively processed to generate candidates at each level, thus, the number of levels of the execution equals that of cut-folksonomy , the number of cutters may be very large as far as the cardinality of at least one set of F is high. Besides, the C UBE M INER algorithm operates in a depth-first man-are performed on each candidate to ensure its closeness and its uniqueness which is very computationally expensive. Indeed, each candidate must be compared twice to the elements of the cutte rs. More recently, Cerf et al. , in [2], proposed the D ATA -P EELER algorithm with the challenge of outperforming both T RIAS and C UBE M INER algo-rithms in terms of performance. The D ATA -P EELER algorithm is able to extract closed concepts from n-ary relations by enumerating all the n-dimensional closed patterns in a depth first manner using a binary tree enumer ation strategy. At each level, the current node of the tree is split into two nodes after selecting the element to be enumerated. In addition, the D ATA -P EELER algorithm does not store the previously computed pat-terns in main memory for duplicate detection and closure checking. However, similarly to C UBE M INER , the strategy of D ATA -P EELER , involving a depth-first approach, may cause infinite trees. Aiming at palliating these hindrances in effectively extracting tri-concepts, we introduce the T RICONS algorithm dedicated to an efficient extraction of frequent triadic concepts from a folksonomy . Following the minimum description length The main thrust of the T RICONS algorithm stands in the localisation of the smallest el-ements, i.e., tri-sets, called tri-Minimal generators (Tri-MGs), in an equivalence class. Indeed, these Tri-MGs are the first reachable elements of their respective equivalence classes, thanks to a breadth-first sweepin g of the associated search space. Doing so, makes the computation of the tri-concepts less arduous than do the aforementioned ones. an extension of the notion of minimal generator. Thereafter, we describe the T RI C ONS algorithm. 4.1 Main Notions of the T RI C ONS Algorithm Lehmann and Wille have introduced in [8] two closure operators for the construction of triadic concepts. However, these operators are only of use on dyadic contexts, i.e. , the folksonomy should be split into three dyadic contexts. Hence, we introduce, in what follows, a new closure operator for a triadic context.
 Definition 4. Let S =( A , B , C ) be a tri-set of F . A mapping h is defined as follows : Roughly speaking, h ( S ) computes the largest tri-set in the folksonomy which contains maximal sets of tags and resources shared by a group of users containing A .Forexam-= {{ u Proposition 1. h is a closure operator.
 Proof. To prove that h is a closure operator, we have to prove that this closure operator fulfills the three properties of extensivity , idempotency and isotony [3]. ( 1 ) Extensivity Let T =( A , B , C ) be a tri-set of F X  h ( T )=( U , T , R ) such that :  X  u i  X  A ,  X  t i  X  B ,  X  r i  X  C ,
T = { t i  X  X  | ( u i , t i , r i )  X  X  X  u i  X  U ,  X  r i  X  C } X  B since U  X  A and R = { r i  X  X | ( u i , t i , r i )  X  X  X  u i  X  U ,  X  t i  X  T } X  C since U  X  A and T  X  B .
Then, ( A , B , C )  X  ( U , T , R )  X  T  X  h ( T ) ( 2 ) Idempotency such that : U = { u i  X  X | ( u i , t i , r i )  X  X  X  t i  X  T ,  X  r i  X  R } = U , T = { t i  X  X  | ( u i , t i , r i )  X  X  X  u i  X  U ,  X  r i  X  C } = T , and R = { r i  X  X | ( u i , t i , r i )  X  X  X  u i  X  U ,  X  t i  X  T } = R .

Then, ( U , T , R )=( U , T , R )  X  h ( h ( T )) = h ( T ) ( 3 ) Isotony Let T =( A , B , C )and T =( A , B , C ) be tri-sets of F with T  X  T  X  h ( T )=( U , T , R )and h ( T )=( U , T , R ) such that :
On the one hand, U = { u i  X  X | ( u i , t i , r i )  X  X  X  t i  X  B ,  X  r i  X  C } . and U = { u i  X  X | ( u i , t i , r i )  X  X  X  t i  X  B ,  X  r i  X  C } .  X  U  X  U since B  X  B and C  X  C [8].
 | C } and R = { r  X  T  X  T since U  X  U and R  X  R since U  X  U and T  X  T [8].
 Then, ( U , T , R )  X  ( U , T , R )  X  h ( T )  X  h ( T ) According to ( 1 ), ( 2 )and( 3 ), h is a closure operator.
 Like the dyadic case [10], the closure operator induces an equivalence relation on the called equivalence classes that we introduce in the following : two tri-sets of F and TC  X  X C . S 1 and S 2 belong to the same equivalence class represented by the tri-concept TC ,i.e., S 1  X  TC S 2 iff h( S 1 )=h( S 2 )= TC . tri-minimal generator and is defined as follows: Definition 6. (T RI -M INIMAL GENERATOR ) Let g =( A , B , C ) be a tri-set such as A  X  X  , B  X  X  and C  X  X  and TC  X  X C . The triple g is a tri-minimal generator (tri-generator for short) of TC iff h( g )= TC and g 1 =( A 1 , B 1 , C 1 )suchas: 1. A = A 1 , 2. ( B 1  X  B  X  C 1  X  C )  X  ( B 1  X  B  X  C 1  X  C ), and 3. h( g )=h( g 1 )= TC .
Figure 1 sketches a sample class of the induced equivalence relation from the folk-t } , { r { t ( g 1 . intent = 4.2 Description of the T RI C ONS Algorithm T
RI C ONS operates in three steps as follows: 1. The extraction of tri-generators; 2. The computation of the modus part of tri-concepts; 3. The computation of the intent part of tri-concepts.
 The pseudo code of the T RI C ONS algorithm is sketched by Algorithm 1. T RI C ONS takes as input a folksonomy F =( U , T , R , Y ) as well as three user-defined thresholds : minsupp u , minsupp t and minsupp r .TheT RI C ONS algorithm outputs the set of all frequent tri-concepts that fulfill these aforementioned thresholds. T RI C ONS operates as folksonomy in order to extract the tri-generators. Then, T RI C ONS calls the F IND M IN -IMAL G ENERATORS procedure (Step 1 ), which pseudo-code is given by Algorithm 2, in order to extract the tri-generators which are stored in the set MG (Line 4 ) : for each triple ( u , t , r ), F IND M INIMAL G ENERATORS computes the set U s which is the maximal set of users (including u ) sharing the tag t and the resource r (Algorithm 2, Line 4 ).
Algorithm 2 invokes both A DD T RI and N EXT T RIPLE functions. The first one al-next triple ( u , t , r )ofthe folksonomy F .

Afterwards, T RI C ONS invokes the Increase Set procedure (Step 2 ) for each tri-generator of MG (Lines 6 -8 ), which pseudo-code is given by Algorithm 3, in order to compute the modus part of the tri-concepts. The two first cases of Algorithm 3 (Lines 3 and 6 ) have to be considered by Increase Set according to the extent of each tri-generator before returning the set TS of tri-sets. The boolean indicator flag marked by T RI C ONS shows whether the tri-set processed by the Increase Set procedure is a tri-generator. Then, infrequent tri-sets, i.e. , whose the modus part cardinality does not fulfill the minimum threshold minsupp t are pruned (Line 9 ). In the third and final step, T
RI C ONS invokes a second time the Increase Set procedure for each tri-set of TS TS having a different intent part than a given tri-set s (Algorithm 3, Line 9 ). Before returning the set TC of tri-concepts, T RI C ONS prunes the infrequent ones, i.e. , whose the intent cardinality does not fulfill the minimum threshold minsupp r by invoking the P RUNE I NFREQUENT S ETS procedure (Line 14 ). T RI C ONS comes to an end after three thresholds minsupp u , minsupp t and minsupp r .
 Example 3. Considering the folksonomy depicted by Table 1 (page 4 ) with minsupp u = 3 , minsupp t = 3 and minsupp r = 2 yields the following track for the T RI C ONS algo-from the context (step 1 ) thanks to the F IND M INIMAL G ENERATORS procedure. Then, invoking firstly the Increase Set procedure, on these tri-gen erators, allows the reduc-tion of the number of candidates. Hence, only five candidates, at step 2 , are generated which directly lead to the frequent tri-concepts extracted by T RI C ONS .So,theset TS t candidates by far lower than its competitors, thanks to the generation of tri-generators. The third and final step, i.e., the second call to the Increase Set procedure, tends to increase the intent part of each tri-set belonging to TS in order to extract frequent tri-{ t M
INER and T RIAS , the tri-concepts are extracted only once. The final result set TC is then returned by T RI C ONS which comes to an end with frequent tri-concepts that fulfill the minimum thresholds mentioned above. In this section, we show through extensive carried out experiment the assessment of D at various levels of minimum thresholds values, while the second is considered to be sparse, i.e., containing a large number of tags but only a few of them frequently co-occur in tri-concepts (on average, no more than 2 tags).  X 
D EL . ICIO . US :D ENSE DATASET :TheD EL . ICIO . US dataset used for our experiments is around 10 MB in size (compressed) and it is freely downloadable 7 . The dense dataset contains 48000 triples : 6822 users, 671 tags and 13102 resources.  X  in size (compressed) and it is freely downloadable 8 . The sparse dataset contains 48000 triples : 33419 users, 18066 tags and 13397 resources. Performances of T RI C ONS vs. T RIAS and D ATA -P EELER : For mining frequent tri-sets and frequent tri-concepts, we set minimum support values of minsupp u = 2 , minsupp t = 2 and minsupp r = 1 , i.e. , in a frequent tri-concept, at least, 2 users have assigned the same tags ( 2 at least) to a same resource at least. Table 2 compares the performances (in sec) of the three algorithms above for different values of the number of triples over the mentioned datasets. With respect to the aforementioned minimum support values, the number of the extracted tri-concepts from the DEL . ICIO . US dataset is around 3877 . Whereas 1088 tri-conepts are extracted from MovieLens dataset.  X 
T RICONS vs. T RIAS : For both datasets, the different tests highlight that T RICONS al-ways shows better performances than do T RIAS . For exemple, T RICONS reaches almost 13 , 73 sec when handling 48000 triples from DEL . ICIO . US , showing a drop in execu-tion time of around 33 , 57% , compared to T RIAS . Moreover, the obtained results, on the both datasets, confirm that this discrepancy between the two algorithms stills in favor of T RICONS as far as the number of triples grows. Interestingly enough, for the sparse dataset, i.e., M OVIE L ENS , we note, for all values of the number of triples, an average reduction of T RICONS execution time reaching almost 69 , 54% compared to T RIAS . The performance differences between thes e mentioned algorithms can be explained by the fact that T RIAS starts by storing the entire folksonomy into main memory before extracting frequent tri-concepts. This memory greedy storage has the drawback to slow the algorithm and alters its execution time as far as the number of triples becomes sig-nificant. Contrarily to T RICONS that firstly invokes the F IND M INIMAL G ENERATORS specific treatment of T RI C ONS reduces the memory greediness. Indeed, the number of tri-generators are often by far below the total number of the triples in a folksonomy .  X 
T RICONS vs. D ATA -P EELER : For both datasets and for all values of the number of triples, D ATA -P EELER algorithm is far away from T RI C ONS performances. Indeed, the poor performance flagged out by D ATA -P EELER , is explained by the strategy adopted by this later which starts by storing the entire folksonomy into a binary tree structure, ture is absolutely not adequate to support a so highly sized data, which is the case of the folksonomies considered in our evaluation. Furthermore, T RI C ONS is the only one algorithm that does not store the dataset in memory before proceeding the extraction of tri-concepts. In addition, T RICONS generates very few candidates thanks to the clever use of tri-generators that reduce the search space significantly. In contrast, T RIAS and D
ATA -P EELER , in addition to store in memory the whole dataset, generate an impres-sive number of candidates, most of which are stored in memory uselessly given the small number of tri-extracted concepts.  X 
T RIAS vs. D ATA -P EELER : Contrariwise to experimental results shown in [2], T RIAS outperforms D ATA -P EELER since the considered datasets are far away larger. We used real-world datasets similar to those used in [6] which explains why T RIAS is better in terms of performance than its competitor. Based on these notions, we introduced the T RICONS algorithm, for a scalable min-generators. In nearly all experiments we performed, the obtained results showed that T
RICONS outperforms the pioneering algorithms of the literature; that is owe to the non-injectivity property of the closure operator. Other avenues for future work mainly address the extraction of other concise representations of frequent tri-sets. In this re-spect, we will try to expand the steady effort carried within the diadic case towards defining concise representations, e.g., disjunction-free sets (closed) non-derivable sets, representation have already shown interesting compactness rates [5].

