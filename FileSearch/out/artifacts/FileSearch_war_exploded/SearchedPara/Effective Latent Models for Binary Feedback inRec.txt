 In many collaborative filtering (CF) applications, latent ap-proaches are the preferred model choice due to their ability to generate real-time recommendations efficiently. However, the majority of existing latent models are not designed for implicit binary feedback (views, clicks, plays etc.) and per-form poorly on data of this type. Developing accurate mod-els from implicit feedback is becoming increasingly impor-tant in CF since implicit feedback can often be collected at lower cost and in much larger quantities than explicit prefer-ences. The need for accurate latent models for implicit data was further emphasized by the recently conducted Million Song Dataset Challenge organized by Kaggle [18]. In this challenge, the results for the best latent model were orders of magnitude worse than neighbor-based approaches, and all the top performing teams exclusively used neighbor-based models. We address this problem and propose a new latent approach for binary feedback in CF. In our model, neighbor-hood similarity information is used to guide latent factor-ization and derive accurate latent representations. We show that even with simple factorization methods like SVD, our approach outperforms existing models and produces state-of-the-art results.
 H.4.m [ Information Systems Applications ]: Miscella-neous Collaborative Filtering; Binary Feedback; Latent Models
Emerging popularity of e-commerce and social web has highlighted an important challenge of surfacing relevant con-tent to consumers. Recommender systems have proven to be effective tools for this task receiving a lot of attention recently [2, 5, 14]. One approach that is commonly used to build accurate recommender models is collaborative filter-ing (CF). CF is a method of making predictions about an individual X  X  preferences based on the preference information from many users. CF has been shown to work well across various domains [2], and many successful web-services such as Netflix, Amazon, YouTube and Yahoo! use CF to deliver personalized recommendations to their users.

The majority of the existing approaches in CF can be di-vided into two categories: neighbor-based approaches and model-based approaches (we review both types in detail in Section 3). Neighbor-based approaches estimate the item preferences for a target user using the similarities from neighboring users and/or items [23, 12]. In contrast, model-based approaches use the observed preferences to create a compact model of the data which is then used to predict the unobserved preferences.

While neighbor-based models can generate accurate and interpretable recommendations when sufficient data is avail-able, they are very inefficient at test time. Most neighbor models require loading large portions of data to estimate user and/or item similarities, and involve several complex operations most of which are difficult to do efficiently in real-time. In many applications where recommendations need to be generated in real-time, model-based approaches are the preferred choice. These methods build compact memory-efficient representations of the data and can be easily scaled to handle millions of users and items. For this reason we pri-marily concentrate on model-based approaches in this work.
Preference data that is used to learn CF models can be partitioned into two types: explicit feedback and implicit feedback . Explicit feedback includes all explicit preference actions from users. Data of this type typically comes in the form of ratings (Netflix, Amazon etc.) or thumbs-up/down selection (Youtube, TiVo etc.). While explicit feedback gen-erally provides high quality signal that accurately describes users X  preferences, collecting large amounts of this data re-quired to develop accurate recommender models is notori-ously difficult and time consuming. For this reason, much of the recent attention have been devoted to implicit feedback where preferences are inferred indirectly by observing user behavior. Implicit feedback can come in many forms that include plays, purchases, browse histories and even mouse clicks and scrolls. Since no additional action is required from users beyond the normal use of the service, large amounts of implicit feedback can often be cheaply collected in a short amount of time. This advantage however, comes at the ex-pense of increased signal noise.
Most of the available implicit data is binary where user ei-ther conducts the action (purchase, browse, click etc.) on a given item or no data is available. 1 Binary feedback makes the recommendation problem particularly challenging since it is impossible to gauge the degree of preference from such data. Furthermore, the majority of existing model-based approaches are developed for non-binary data and employ objective functions that rely on graded relevance to distin-guish positive preferences from negative ones. Such mod-els tend to perform very poorly on binary data. Recently, several model-based approaches have been developed specif-ically for binary feedback [13, 20], however results on CF challenges have shown that these models don X  X  perform as well as neighbor-based approaches.

The difference in performance between neighbor-and model-based methods on binary data became especially ev-ident during the Million Song Dataset Challenge (MSD) which was recently conducted by Kaggle [18]. In this chal-lenge, song listening histories were made available for 1.2M users and 380K songs, and the goal was to predict the next 500 songs for a subset of 110K users. Full song listening counts were made available but the organizers found these to correlate poorly with user preferences and binarized the data (1 if user listened to a song and 0 otherwise), using Mean Average Precision to evaluate submissions.

From the winners X  reports [3] and the challenge forum 2 , it became evident that all of the top scoring teams used vari-ations of neighbor-based methods. Moreover, results for the best performing model-based approach were orders of mag-nitude worse than the best neighbor-based methods. Simi-lar findings were reported by the challenge organizers who found that recommending songs from the same artist out-performed a complex model-based approach by a significant margin [18]. It was also reported that most model-based methods had run-time and/or memory problems on data of this size, and were either too slow to converge or used too much RAM. Given that 150 teams participated in this challenge and its recency, it can be concluded that there currently is no readily-available model-based approach that can perform well on binary data of this size.

Since the majority of implicit feedback is binary, it is highly desirable to develop accurate model-based methods that scale well to large datasets. In this paper we propose one such approach. The main idea behind our approach is to use neighbor similarities to enrich binary preferences and guide latent factor learning for both users and items. We empirically demonstrate that this approach produces la-tent representations that outperform neighbor-based meth-ods while being considerably more efficient during inference time.
In a typical binary collaborative filtering problem we have a set of N users U = { u 1 ,...,u N } and a set of M items V = { v 1 ,...,v M } . The users X  binary feedback for the items can be represented by an N  X  M matrix R where R ( u n ,v m ) = 1 if user u n expressed preference (played, pur-
Note that some explicit data can also come in binary format e.g., Facebook X  X   X  X ikes X . www.kaggle.com/c/msdchallenge/forums/t/2365/ challenge-retrospective-methods-difficulties chased, clicked etc.) for item v m and R ( u n ,v m ) = 0 other-wise. We use U ( v m ) to denote the set of all users that pre-ferred v m and V ( u n ) to denote the set of items that u expressed preference for. We use vector notation: R ( u n denotes the n  X  X h row of R (1  X  M vector), and R (: ,v denotes the m  X  X h column ( N  X  1 vector).

Unlike the traditional CF where the goal is to accurately predict ratings for every user-item pair, in binary domain the aim is to produce a top-T ranking of the items that the user is most likely to prefer next. A ranking of the items V can be represented as a permutation  X  : { 1 ,...,M } X  X  1 ,...,M } where  X  ( m ) = l denotes the rank of the item v m and m =  X   X  1 ( l ). A number of evaluation metrics have been proposed in information retrieval to evaluate the perfor-mance of the ranker. Here we concentrate on two of the more commonly used metrics, Normalized Discounted Cu-mulative Gain (NDCG) [15] and Mean Average Precision (MAP) [4]. For a given user u and ranking  X  the NDCG is given by: NDCG( u, X , R )@ T = 1 where T is a truncation constant, v  X   X  1 ( m ) is the item in position m in  X  and G T ( u, R ) is a normalizing term which ensures that NDCG  X  [0 , 1] for all rankings. T is typically set to a small value to emphasize that the user will only be shown the top-T ranked items and the items below the top-T are not evaluated.
 MAP is defined in terms of average precision (AP): AP( u, X , R )@ T = where P@ m is the precision at m : MAP is then computed by averaging AP over all users. Both NDCG and MAP have similar characteristics and discount relevance of each item by its position in the ranking and are maximized when all relevant items are ranked at the top. In binary CF, all items v with R ( u,v ) = 0 are assumed to be not relevant to u . This relevance assignment is not entirely accurate since u might not have seen v , however, in the absence of graded relevance most frameworks follow this evaluation scheme.
In this section we describe existing neighbor-and model-based approaches developed for binary data.
In a binary setting, neighborhood-based CF approaches estimate item scores for a target user using the similarity from neighboring users and/or items. Formally, given an item v and target user u , the user-user approach estimates the score for v by comparing u with other users that ex-pressed preference for v : The main idea behind this approach is based on the assump-tion that if users similar to u prefer v then S ( u,v ) should be high and v should be recommended to u . Similarly, in the item-item approach v is compared to all items that u has expressed preference for: This method follows a similar idea and aims to recommend items that are similar to items that u has expressed prefer-ence for.

After estimating scores for all items either via user-user or item-item method the resulting score vector S ( u, :) is sorted and top-T items are presented to u . In practice it is often found that the accuracy of each method can be significantly improved if dot product is replaced with a more complex metric like cosine similarity. We found this to be especially true for binary domain, where row and column L 2 normal-izations tend to work particularly well 3 : We found that for most datasets applying both normaliza-tions before computing similarities produced gains of up to 30%; further justification for using normalization can be found in [12]. We also found that the order in which these normalizations are applied is very important and should be validated separately for each dataset. Note that when only row-norm or col-norm normalization is applied, item-item (user-user) scores become the sums of cosine similarities.
In contrast to neighbor-based approaches, model-based approaches use the observed preferences to create a com-pact model of the data which is then used to predict the unobserved preferences. The most popular methods in this category are latent models that derive compact latent fac-tors for both users and items and then use these factors to predict preference. Latent models are often the default choice for many CF problems due to their accuracy and ef-ficiency. Once the factors are estimated, recommendations can be generated very efficiently by computing simple dot products between latent factors, allowing these models to be applied in real-time.

Several model-based approaches have been recently pro-posed for binary setting, here we review two of the more popular approaches WRMF [13] and BPR-MF [20]. WRMF is a regression method and learns user-item factors by min-imizing the weighted reconstruction error:
X
To avoid introducing extra notation we use self assignment of the form x = f(x) where possible. where U r is an N  X  r user factor matrix, V r is an M  X  r item factor matrix, and c nm is a weight that is set separately for every user-item pair. For binary data c nm is set to: This formulation adds an extra  X  weight to every pair with R ( u n ,v m ) = 1 forcing optimization to concentrate on those pairs. Authors of WRMF propose to use alternating least squares to optimize this model with an overall complexity of O ( N r 2 + ( N + M ) r 3 ) [13] where N is the total number of non-zero entries in R . Both N r 2 and ( N + M ) r 3 grow very quickly with r and several teams in the MSD challenge ( N  X  50 million and N + M  X  1 . 6 million) reported that WRMF took prohibitively long to train even for moderate r sizes.

BPR-MF is a ranking approach and optimizes pairwise objective that attempts to place pairs with observed prefer-ence above the unobserved ones: where triplets ( u n ,v m ,v l ) are sampled with a condition that R ( u n ,v m ) = 1 and R ( u n ,v l ) = 0. Similarly to WRMF, this implies an assumption that all items v l with R ( u n ,v l are not relevant and should be ranked below the relevant items v m with R ( u n ,v m ) = 1. Moreover, all relevant (ir-relevant) items are assumed to be equally relevant (irrele-vant). These assumptions often don X  X  hold in real-life sce-narios where noisy implicit signals tend to produce incor-rect/outlier preferences that should be discounted.
Due to its pairwise nature BPR-MF is also expensive to optimize with runtime complexity of O ( N M ). While au-thors claim that satisfactory convergence can be achieved significantly faster through sampling, no theoretical guaran-tees are provided. Another disadvantage of BPR-MF is that when the number of items is large, gradient updates are dis-tributed very unevenly (even with sampling). Popular items with many non-zero entries receive the bulk of updates while the tail-region items receive almost none. This can poten-tially explain the poor performance of this approach on the MSD dataset where challenge organizers found that it was unable to outperform the simple songs by the same artist baseline [18].
We discussed earlier that treating all observed (unob-served) items as equally relevant (irrelevant) is not opti-mal in the binary CF setting. In this section we further build on this idea and propose a model-based approach that applies neighbor similarities to further distinguish relevant items from irrelevant ones. This information is then used to infer accurate user and item factors.

Before we delve into model description, consider the fol-lowing simplified example: a fantasy fan purchases  X  X he Lord Of The Rings X  trilogy, both  X  X obbit X  releases and  X  X he Devil Wears Prada X  (a present for a friend). If we could re-quest explicit preference data from this user we would im-mediately know that (s)he does not enjoy movies like  X  X he Devil Wears Prada X . However, given that we only have ac-cess to purchase history, objectives in WRMF and BPR-MF would treat all purchases as equally relevant. During opti-mization for this user, both methods would aim to derive latent representations that rank fantasy movies and movies like  X  X he Devil Wears Prada X  at the top, which is clearly sub-optimal. One way of dealing with this problem is through model regularization and both methods apply strict regular-ization to penalize user and item factors. However, as the number of outliers increases the problem becomes more se-vere and might no longer be fixable by heavy regularization.
In contrast, by applying neighbor methods like item-item, we immediately get a lower score for  X  X he Devil Wears Prada X  since it X  X  not similar to any other purchase by this user. From this example it is evident that the neighbor ap-proach provides an effective way to resolve ties in the binary preference matrix, and neighbor score matrix S reflects user preferences more accurately than the raw binary matrix R . Neighbor methods, however, are also not immune to noise. Users/items with very few ratings can heavily skew simi-larities and result in incorrect rankings. Row and column normalizations can partially alleviate this problem but don X  X  eliminate it completely.

In our model we propose to utilize these advantages of neighbor approaches and factorize the neighbor score matrix S instead of the original binary matrix R . In addition to pro-ducing models that support very efficient inference, apply-ing low-rank factorization to S can significantly reduce the noise that is often present when similarities are computed on highly sparse data. One method that readily lends itself for the factorization task is truncated Singular Value Decom-position (SVD). A number of techniques that use truncated SVD such as the Principal Component Analysis and the La-tent Semantic Analysis have been found to be very robust to noise and generalize well. Moreover, SVD factorization is a well studied problem and efficient distributed implemen-tations exist that can factorize matrices with hundreds of millions of rows (e.g., Mahout X  X  stochastic SVD [17]), mak-ing it applicable to virtually any CF problem.

Encouraged by these results we apply truncated SVD to the neighbor score matrix S . We begin by normalizing all rows of S to have unit norms: The L 2 normalization rescales scores to have comparable ranges across users making factorization more stable. This is especially useful when some users/items have considerably more data than others (common in many CF applications) resulting in highly variable score ranges across users. After row normalization we approximate S with a product of three low rank matrices via SVD: Here r is SVD rank, U r is an N  X  r matrix,  X  r is an r  X  r diagonal matrix and V r is an M  X  r matrix.
 Once the factorization is completed  X  r is absorbed into U r , U r = U r  X  r , and the scores for every user-item pair are calculated by computing dot product between the cor-responding user and item factors: Sorting these scores gives top-T item recommendations for u . Note that for most r this operation is considerably more efficient than computing and summing neighbor similarities (Equations 1 and 2), especially when the number of users or items is large.

While SVD provides an effective way to derive latent rep-resentations, current formulation requires computing and storing the full score matrix S which is not practical for most large-scale applications. In the following sections we describe several ways of dealing with this problem. The naive SVD model has runtime complexity of O ( NM log( r ) + ( N + M ) r 2 ) 4 using the stochastic SVD al-gorithm [11], and requires O ( NM ) space. Recently, a num-ber of advances have been made on incremental SVD [7, 1] where factorization is built in stages, allowing to process large amounts of data without explicitly storing it. One of the more efficient algorithms developed by Brand [7] takes as input  X  X urrent X  factorization U X V T  X  X and matrix A , and produces updated SVD factorization U new  X  new V T new [ X , A ]. Note that in this formulation V T gets expanded to have the same number of columns as [ X , A ] whereas U and  X  only get updated but don X  X  change in size. Analogous algorithm can be used to update U : using the fact that
We can readily apply these ideas to CF and factorize users incrementally achieving considerable savings in space requirements. Formally, we partition users into blocks of size N b and for each block we iteratively (1) calculate N b  X  M neighbor score matrix and (2) update SVD factorization to include latent factors for users in the block. The run-time complexity of this block-factorization algorithm is still O ( NM log( r ) + ( N + M ) r 2 ) for r &lt; p min( N,M ) [11, 7], but the space requirement reduces to O ( N b M + ( N + M ) r )) where O ( N b M ) is the block size and O (( N + M ) r ) is the space required to store the final U r and V r factors. This is a very significant reduction from the original O ( NM ) and makes the algorithm practical for most CF applications. Moreover, block update provides an effective way to update the SVD model when new users and/or items are added to the system. Finally, note that we concentrated on incre-mentally processing users here but the same algorithm can be straightforwardly modified to incrementally process items instead. Thus depending on whether N M or N M we can either choose user oriented or item oriented approach (or alternate between the two).
In the previous section we demonstrated that by using incremental block updates we can significantly reduce the space complexity to O ( N b M ) where N b is the block size. However, for large scale applications the number of items can reach millions or hundreds of millions so even O ( N b can become too large. To deal with this problem we propose to selectively use only a small subset of similarity scores for each user. This is achieved by storing only the largest  X  scores for each user and zeroing out the rest.

The motivation behind using only the largest scores comes from the fact that we want to concentrate all model effort on maximizing the accuracy at the top of the ranking. Items with large scores are thus particularly important since they would appear at the top for each user. Furthermore, it is well
This excludes the cost of computing S . Algorithm 1 SVD block-factorization Input: R
Parameters: rank r , block size N b , sparsity factor  X  for i = 1 to N/N b do end for
Output: U r , S r , V r known that SVD produces factorizations that are closest to the target matrix in Frobenius norm (i.e., root squared er-ror). By zeroing out low scores we force SVD to concentrate on ordering items at the top correctly and put less emphasis on relative orderings at the bottom.

This approach allows us to further reduce the space re-quirement for each block to O ( N b  X  ) since sparse format can now be used and zeros don X  X  need to be explicitly stored. Sparse representation also allows for more efficient matrix multiplication and the complete block-factorization can now be computed in O ( T mult r + ( N + M ) r 2 ) where T mult cost of matrix-vector multiplication with sparse score ma-trix [11]. Given that the entire score matrix now has at most N X  non-zero entries, the matrix-vector product can be computed in time proportional to N X  , and for  X  M we get that T mult NM [25]. Note that O ( T mult r + ( N + M ) r is an order of magnitude more efficient than WRMF with complexity O ( r 2 N + ( N + M ) r 3 ). The full SVD algorithm with all the enhancements is outlined in Algorithm 1.
An important problem in CF is to efficiently provide accu-rate recommendations to new users that were not available during model optimization. This problem is often referred to as strong generalization and must be addressed by any suc-cessful recommender system. Neighbor-based models can generally be applied to new users without any difficulties since similarities can be straightforwardly re-calculated to incorporate new data. Model-based approaches on the other hand, often use complicated non-convex objectives and thus require expensive gradient updates to be conducted for every new user. In this section we address the strong generaliza-tion problem in our SVD model and derive a simple update equation to efficiently produce latent factors for new users.
One way of dealing with new users/items is to run a full block SVD update to generate new latent factors and also update the rest of the model. While in a real-world appli-cation we would want run such an update after enough new users/items have been added, it is infeasible to run it for every new user. To deal with this problem we propose a simple approach to approximate latent factors by utilizing the properties of SVD factorization. First, note that the score vector for every user u is approximated by the user-item factor product: where  X  r is absorbed into U r . From this it follows that: but since V r is approximately orthogonal we get that V  X  1 V r and: Similar approach can be used to derive an equation for item factors: V r ( v, :)  X  S (: ,v ) T U r . Equation 9 gives us a simple and effective way to approximate user factors for a new user u by (1) calculating top- X  neighbor scores S ( u, :) and (2) multiplying S ( u, :) with V r to get U r ( u, :).
In production-level systems we can use Equation 9 to quickly generate recommendations for each new user, then run full block update once enough new users/items have been added. Note that unlike gradient-based models, block update doesn X  X  require any iterative optimization or param-eter tuning (initialization, learning rate, weight penalty etc.) and can efficiently update the entire model.

In summary, our SVD-based model provides the following advantages: The idea of using SVD in CF is not new and a number of SVD-based methods have been proposed. One of the first uses of SVD for CF can be traced back to [6]. A number of extensions have since been proposed that incorporate ad-ditional information and control for user privacy [22, 19]. Incremental SVD updates in the context of CF have been investigated by Sarwar et al., [24], their approach however only produced latent factors for new users and did not up-date the existing model. This method is thus unsuitable for incrementally learning/updating the full model.

To the best of our knowledge all existing SVD methods apply factorization to the raw preference matrix R and are thus not suitable for binary feedback. Moreover, since SVD can X  X  handle missing data, applying it directly to R is equiv-alent to setting all missing values to 0. The factorization then minimizes the Frobenius norm between this  X  X illed in X  matrix and the SVD approximation. Setting missing values to 0 is not ideal in most CF applications since it assumes that all unobserved items should have a low score. For this reason SVD has now largely been replaced by other matrix factor-ization approaches such as PMF [21] that only optimize the reconstruction error on observed data. Our approach avoids this problem by applying SVD to the sparse neighbor simi-larity score matrix instead of R . In our model setting small Figure 1: Fraction overlap between training data for the target 110K MSD users and popular songs sorted in the order of popularity. scores to 0 is valid since these items are to be ranked at the bottom of the list and should have low reconstruction scores from SVD. To the best of our knowledge this approach is the first successful application of SVD to the binary CF setting.
The idea of using neighbor similarity information to train factor models is not limited to the SVD model. By replac-ing the original binary matrix R with S (Equations 1 and 2) we can apply most existing model-based approaches. Below we give some examples of the objective functions that can be used to learn U and V . We begin with the more com-monly used regression objectives such as the squared error and weighted squared error (used in WRMF): Note that in both cases S is a sparse matrix containing only the top- X  scores for each user. Unlike the traditional CF where most effort is concentrated on rating prediction, for binary preference CF the goal is to optimize the ranking accuracy. Ranking-based objectives might thus be better suited for this problem. Since S provides rich ordering in-formation over the items, we can apply virtually any objec-tive from learning-to-rank [16] to this domain. Here we give examples of two such objectives RankNet [8] (also used in BPR-MF) and ListNet [9]: All of the above objectives require gradient optimization and thus lack the advantages of the SVD approach outlined in Section 4.3. In this work we thus chose to concentrate on the SVD model and leave gradient optimization for future work.
 Table 1: MSD MAP@500 private leaderboard re-sults. SVD results are reported for four different rank sizes 1K, 5K, 10K, and 20K; all models were trained on top 50,000 and 100,000 of the most pop-ular songs. The winning team achieved a score of 0.1791 [3] using an optimized blend of user-user and item-item approaches. The best model-based ap-proach was reported to get 0.1095.
To validate the proposed approach we conducted extensive experiments on three large publicly available datasets: song dataset from the Kaggle X  X  MSD challenge and two movie datasets MovieLens and Netflix. We implemented Algo-rithm 1 in Matlab, employing stochastic SVD library by Mark Tygert 5 and block SVD library by David Wingate 6 . For block SVD we modified the provided code by replac-ing the call to Matlab X  X  svds routine with a much faster stochastic SVD call. This implementation was then used in all experiments. We used MyMediaLite [10] library to run the WRMF and BPR-MF baselines and extensively tuned both models on each dataset.

Across all datasets we consistently found that the accu-racy of user-user and item-item approaches can be signifi-cantly improved by applying both row and column normal-izations (Equations 3 and 4). We also found that the or-der in which these normalizations are applied is important and used validation set to determine the best combination for each dataset. Generally, we observed that applying row followed by column normalization worked best across most datasets and folds. For all SVD experiments we first val-idated normalization for each neighbor approach and then applied SVD to the best performing combination. The MSD dataset was used in the Kaggle Million Song Dataset Challenge [18] and consists of listening histories for 1.2M users and 380K songs. The goal of the challenge was to use these listening histories to recommend 500 songs for a subset of 110K test users. The data for the 110K test users was partitioned into training and test sets, and only training portion was made available to the challenge par-ticipants (in addition to full listening history for the other 1.1M users). The test set was further split into two sub-sets with 10K and 100K users respectively. The results on the smaller 10K subset were made visible throughout the challenge ( X  X ublic leaderboard X ), while results on the 100K pca.m from cims.nyu.edu/~tygert/software.html addblock_svd_update.m from www.mit.edu/~wingated/ resources.html and ii-SVD-full uses all M scores.
 subset were only revealed at the end of the challenge ( X  X ri-vate leaderboard X ). All submissions had to provide rankings of top-500 songs for each of the 110K test users and were evaluated using MAP@500. At the end of the challenge or-ganizers released all the challenge data (including test data) into public domain.

Note that the MSD dataset has more than 20 times more items than both MovieLens and Netflix, and is over 100 times more sparse. This makes the problem very challenging since many user/items have very little data to build accu-rate representations. The sparsity problem is further illus-trated in Figure 4.4, which shows fraction overlap between the training data for the 110K target users and most popular songs sorted in the order of popularity. From the figure we see that more that 93% of all the training data is contained within the first 100K most popular songs, leaving less than 7% of data for the remaining 280K songs.

We mentioned above that model-based approaches were found to perform poorly in this challenge. The best model-based submission was reported to get MAP@500 of 0.1095, while the winning solution achieved 0.1791 using a blend of user-user and item-item approaches [3]. These results indicate that neighbor methods produce over 60% relative improvement in accuracy on this data compared to model-based approaches. In the following section we show that our approach eliminates this performance gap achieving results that are comparable to neighbor methods.

In all MSD experiments we follow the same set-up that was used during the competition and tune models on the 10K public leaderboard set, then evaluate on the 100K pri-vate leaderboard set.
MAP@500 private leaderboard results are shown in Ta-ble 1. For this dataset we found that using larger rank generally improved performance, and we report results for four different rank sizes: 1K, 5K, 10K and 20K. To reduce experiment complexity we downsampled the item space to only include most popular songs and experimented with top 50,000 and 100,000 songs. From Figure 4.4 we see that 100,000 (50,000) most popular songs contain over 93% (80%) of all training data. Consequently, selecting only the popu-lar songs allows us to reduce the item space by a factor of 4 while keeping most of the training data.
 Table 3: MSD training runtimes in hours for the SVD model with four different rank sizes 1K, 5K, 10K and 20K. For comparison, on the same hard-ware WRMF took 10.9 hours to complete for rank 250 and would take over a month for rank 10K.
From results in Table 1 we see that the SVD model with large enough rank is able to match the performance of the corresponding item-item approach. The results for the best SVD model place it in top-3 (out of 150 teams) on Kag-gle X  X  leaderboard with a score of 0.1623. To the best of our knowledge this is by far the highest score for model-based approach in this competition. All of the top-10 teams used combinations of user-user and/or item-item approaches, and the best model-based approach was reported to only get 0.1095. We also see that SVD-1K performs comparably to SVD-full on both 50,000 and 100,000 songs suggesting that scores for only 1,000 songs per user are required to produce accurate factorizations.
MSD is the largest of the three datasets that we se-lected with, and we use it to benchmark the runtimes for the SVD approach and the best existing model-based ap-proach WRMF. To ensure accurate comparison all experi-ments were conducted on the same server with 32 Intel Xeon E5-2690 2.90GHz cores and 64GB of RAM. Runtimes in hours for the SVD model are shown in Table 3. From this table we see that full factorization with 100,000 songs can be completed in under 3 hours with rank 5,000 and under 6 hours with rank 10,000. For comparison, WRMF took over 10 hours to complete with rank 250, and using complexity bounds we estimate that for rank 10,000 it would take over a month. These results demonstrate that our approach is considerably more efficient than the existing state-of-the-art and scales well to large datasets. training data and excluded for item similarity calculation.
For MovieLens experiments we use the largest of the avail-able datasets MovieLens-10M with 10 million ratings from 72,000 users on 10,000 movies. This dataset contains rat-ings on the scale of 1 to 5 with half point increments, and each users has rated at least 20 movies. To simulate binary feedback we binarized the data setting all ratings to 1. Bina-rization simulates implicit feedback that we would get from actions like movie purchases, plays or clicks.

To get an estimate of how each model X  X  performance is af-fected by training set size we repeat all experiments 4 times with different percentages of training ratings: 10%, 30%, 50%, 70%. For each percentage  X  ,  X  percent of ratings for each user are randomly selected for training and the rest are kept for testing. Partitioning data in this way allows us to gradually increase the training set size from 10% to 70% while keeping distributions of ratings across users con-sistent. All parameter selection was done using 5-fold cross validation and the best models were re-trained on the full training set and evaluated on the test set. Rank size was validated in the range 5 to 250 for each model.

We evaluate both weak and strong generalization. For weak generalization training data from all users is used to learn the models, and average NDCG is computed on the withheld test data from same users (see Section 2 for details on NDCG calculation). On the other hand, for strong gen-eralization a subset of users is removed from training data and all model estimation is done on the remaining users. Once the models are estimated, the goal is to use the train-ing data from withheld users to incorporate them into the model (without full re-training) and produce accurate rec-ommendations. In SVD model we proposed two ways of dealing with new users: block update and approximate in-ference (see Section 4.3). We evaluate both approaches and compare their performance.

Taking advantage of the fact that we have access to ex-plicit preferences in the form of ratings we conduct two types of evaluation. After training each model using only binary data, we evaluate the recommended rankings on both binary relevance and full ratings. For binary relevance we use the procedure outlined in Section 2 and compute NDCG using full rankings of all the items that are not in the training set for each user. For rating evaluation we only rank the rated test set items for each user and calculate NDCG using rating values (1-5) as relevance for those items. Assuming that ratings provide the ground truth preference informa-tion, rating NDCG estimates the degree to which models trained on weaker binary data generalize to ground truth. While this assumption might not be completely valid due to inherent noise in ratings, rating NDCG still gives us a more accurate metric to compare the models.
Table 2 shows MovieLens weak generalization results for four training set sizes 10%, 30%, 50% and 70%. For each training set size, Table 2 shows binary and rating NDCG@10 results. We apply our SVD method to both user-user (uu-SVD- X  ) and item-item (ii-SVD- X  ) scores and vary the spar-sity factor  X  of the similarity score matrix. In addition to SVD, we also evaluate WRMF and BPR-MF approaches, all models were learned and tuned using binary data only.
We can observe several patterns from Table 2. First, item-item approach significantly outperforms user-user on binary NDCG for all training set sizes except 10%, while user-user significantly outperforms item-item on rating NDCG. The difference in performance is somewhat puzzling and implies that improvement on binary feedback doesn X  X  necessarily translate to improvement on explicit preferences. This sug-gests an optimization approach where explicit feedback is first solicited from a subset of users and the best binary model is then chosen based on the accuracy on this explicit data.

Second, SVD model always performs at least as well as the underlying similarity approach (user-user or item-item) and in many cases beats it. This leads to the conclusion that applying low-rank compression to similarity scores is beneficial and can improve accuracy by removing/shrinking noisy dimensions. The gains from SVD model are especially significant on very sparse training sets with 10% and 30% of data where it outperforms neighbor approaches on both binary and rating NDCG. We also see that SVD-500 per-form almost as well as SVD-full indicating that only 500 top scores (out of nearly 10,000 items) are required for each user to produce accurate factorizations. This reduces stor-age requirement for each block update by a factor of 20 and significantly speeds up runtime. Consistent performance on both binary and rating NDCG suggests that the SVD model can readily be used if explicit data approach to model se-lection is chosen. In this setting, explicit preferences from a subset of users would first be used to select the best neighbor method. SVD model would then be applied to the chosen neighbor method to generate latent factors for all users and items.

Third, similarly to neighbor approaches, WRMF outper-forms BPR-MF on binary NDCG while BPR-MF signifi-cantly outperforms WRMF on rating NDCG. We also see that best SVD model consistently outperforms both ap-proaches on binary and rating NDCG. and SVD-full uses all M scores.

Strong generalization results are shown in Table 4. For strong generalization 1000 randomly chosen users were with-held during model optimization and then added into the model either by doing a full model block update (SVD-block) or via inference procedure outlined in Section 4.3 (SVD-infer). For all SVD experiments  X  was set to 500 so top-500 scores were used for each user. We only show results for item-item similarity, results with user-user similarity were similar and are omitted from this table.

From the table we see that SVD-infer generalizes well and suffers only a small drop in performance relative to block-SVD which updates the entire model. Both SVD-block and SVD-infer significantly outperform the item-item ap-proach on binary and rating NDCG. These results support the conclusion that the approximate inference procedure can be used to quickly generate recommendations for new users with acceptable accuracy.
For Netflix experiments we used the full Netflix dataset with 100M ratings from 480K users on 17.7K movies. Sim-ilar to the MovieLens experiments, we binarized all ratings and evaluated performance using both binary and rating NDCG@10. We partitioned the dataset using 10%, 30%, 50% and 70% of ratings from each user for training and the rest for testing. All parameter selection was done using 5-fold cross validation and the best models were re-trained on the full training set and evaluated on the test set. Rank size was validated in the range 5 to 250 for each model.
Weak generalization results are shown in Table 5. From this table we see that, unlike the results for the MovieLens data, item-item approach significantly outperforms user-user on both binary and rating NDCG. This could be attributed to the fact that Netflix dataset is considerably larger and more sparse. A number of previous studies have shown that item-item similarity tends to work better than user-user in sparse settings [12].

From the table we also see that, first, our SVD approach either performs comparably or outperforms both user-user and item-item methods on binary and rating NDCG. Sec-ond, WRMF achieves very strong performance on binary NDCG beating our approach on all splits except 10% but under-performs on rating NDCG losing by as much as 2 points. This difference in performance could be attributed to overfitting. We discussed in Section 4 that WRMF and BPR-MF treat all items with observed preferences ( R ( u,v ) = 1) as equally relevant. Both methods are thus susceptible to outliers that are often present in noisy CF data and can produce suboptimal user representations. In this experiment outliers correspond to items with low rat-ings (  X  2). Placing such items at the top of the ranking improves binary NDCG while significantly hurting rating NDCG. Neighbor methods are able to detect such outliers and thus tend to do better on rating NDCG.

Lastly, both SVD-500 and SVD-1000 fully match the per-formance SVD-full leading to a conclusion that only 500 items (out of over 17,000) are needed to build accurate mod-els for each user.
Strong generalization results for the Netflix dataset are shown in Table 6. Similarly to MovieLens, we withheld a subset of 1000 randomly chosen users during main model optimization, and then added these users to the model via block update and approximate inference procedures. Binary and rating NDCG results for both procedures are shown in Table 6.

From the table we see that SVD-infer suffers only a minor drop in performance relative to SVD-block on rating NDCG. Also, surprisingly, SVD-infer outperforms SVD-block on bi-nary NDCG for 50% and 70% training splits. These results further validate the approximate inference procedure as a useful way to quickly generate recommendations for new users.
We presented a general approach to deal with binary pref-erences in CF. In our approach, observed binary matrix is first transformed into a score matrix by applying neighbor-hood similarity rescaling. The score matrix is then factor-ized to produce accurate user and item representations. We demonstrated that with this approach even simple factoriza-tion techniques like SVD produce accurate representations using only a small subset of the highest scores for each user. training data and exclude for item similarity calculation.
In the future work we plan to explore more complex fac-torization procedures that can potentially lead to better la-tent representations. We also plan to investigate ways to deal with discrepancy between model performance on im-plicit/binary and explicit data. We have shown that im-provement on implicit/binary data doesn X  X  always lead to improvement on explicit preferences. We believe that this discrepancy must be considered in every approach designed for binary data. Finally, we plan to extend our approach be-yond the binary setting and apply it to graded preferences (ratings).
 We would like to thank Richard Zemel and Tomi Poutanen for many useful ideas and discussions. We also thank the anonymous reviewers for their comments and suggestions. [1] P.-A. Absil, C. G. Baker, and K. A. Gallivan. [2] G. Adomavicius and A. Tuzhilin. Toward the next [3] F. Aiolli. Efficient top-n recommendation for very [4] R. Baeza-Yates and B. Ribeiro-Neto. Information [5] J. Bennet and S. Lanning. The Netflix prize. [6] D. Billsus and M. J. Pazzani. Learning collaborative [7] M. Brand. Fast low-rank modifications of the thin [8] C. J. C. Burges, T. Shaked, E. Renshaw, A. Lazier, [9] Z. Cao, T. Qin, T.-Y. Liu, M.-F. Tsai, and H. Li. [10] Z. Gantner, S. Rendle, C. Freudenthaler, and [11] N. Halko, P. G. Martinsson, and J. A. Tropp. Finding [12] J. Herlocker, J. A. Konstan, and J. Riedl. An [13] Y. Hu, Y. Koren, and C. Volinsky. Collaborative [14] Z. Huang, D. Zeng, and H. Chen. A comparison of [15] K. Jarvelin and J. Kekalainen. IR evaluation methods [16] T.-Y. Liu. Learning to rank for information retrieval . [17] Apache Software Foundation. Mahout stochastic [18] B. McFee, T. Bertin-Mahieux, D. P. Ellis, and G. R. [19] H. Polat and W. Du. SVD-based collaborative filtering [20] S. Rendle, C. Freudenthaler, Z. Gantner, and [21] R. Salakhutdinov and A. Mnih. Probabilistic matrix [22] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl. [23] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl. [24] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl. [25] R. Yuster and U. Zwick. Fast sparse matrix
