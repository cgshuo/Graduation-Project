 Word alignment is a natural language process-ing task that aims to specify the correspondence between words in two languages (Brown et al., 1993). It plays an important role in statistical machine translation (SMT) as word-aligned bi-lingual corpora serve as the input of translation rule extraction (Koehn et al., 2003; Chiang, 2007; Galley et al., 2006; Liu et al., 2006).

Although state-of-the-art generative alignment models (Brown et al., 1993; Vogel et al., 1996) have been widely used in practical SMT systems, they fail to model the symmetry of word align-ment. While word alignments in real-world bi-lingual data usually exhibit complicated mappings (i.e., mixed with one-to-one, one-to-many, many-to-one, and many-to-many links), these models as-sume that each target word is aligned to exactly one source word. To alleviate this problem, heuris-tic methods (e.g., grow-diag-final) have been pro-posed to combine two asymmetric alignments (source-to-target and target-to-source) to generate symmetric bidirectional alignments (Och and Ney, 2003; Koehn and Hoang, 2007).
 Instead of using heuristic symmetrization, Liang et al. (2006) introduce a principled approach that encourages the agreement between asymmetric alignments in two directions. The basic idea is to favor links on which both uni-directional models agree. They associate two models via the agreement constraint and show that agreement-based joint training improves align-ment accuracy significantly.

However, enforcing agreement in joint training faces a major problem: the two models are restrict-ed to one-to-one alignments (Liang et al., 2006). This significantly limits the translation accuracy, especially for distantly-related language pairs such as Chinese-English (see Section 5). Although pos-terior decoding can potentially address this prob-lem, Liang et al. (2006) find that many-to-many alignments occur infrequently because posteriors are sharply peaked around the Viterbi alignments. We believe that this happens because their model imposes a hard constraint on agreement: the two models must share the same alignment when esti-mating the parameters by calculating the products of alignment posteriors (see Section 2).

In this work, we propose a general framework for imposing agreement constraints in joint train-ing of unidirectional models. The central idea is to use the expectation of a loss function, which mea-sures the disagreement between two models, to replace the original probability of agreement. This allows for many possible ways to quantify agree-ment. Experiments on Chinese-English translation show that our approach outperforms two state-of-the-art baselines significantly. 2.1 Asymmetric Alignment Models Given a source-language sentence e  X  e I 1 = e ,...,e I and a target-language sentence f  X  1 = f 1 ,...,f J , a source-to-target translation model (Brown et al., 1993; Vogel et al., 1996) can be defined as where a 1 denotes the source-to-target alignment and  X  1 is the set of source-to-target translation model parameters.

Likewise, the target-to-source translation model is given by where a 2 denotes the target-to-source alignment and  X  2 is the set of target-to-source translation model parameters.
 two models are trained independently to maximize the log-likelihood of the training data for each direction, respectively:
One key limitation of these generative models is that they are asymmetric : each target word is restricted to be aligned to exactly one source word (including the empty cept) in the source-to-target direction and vice versa. This is un-desirable because most real-world word align-ments are symmetric , in which one-to-one, one-to-many, many-to-one, and many-to-many links are usually mixed. See Figure 1(a) for example. Therefore, a number of heuristic symmetrization methods such as intersection, union, and grow-diag-final have been proposed to combine asym-metric alignments (Och and Ney, 2003; Koehn and Hoang, 2007). 2.2 Alignment by Agreement Rather than using heuristic symmetrization meth-ods, Liang et al. (2006) propose a principled approach to jointly training of the two models via enforcing agreement :
Note that the last term in Eq. (5) encourages the two models to agree on asymmetric alignments. While this strategy significantly improves align-ment accuracy, the joint model is prone to generate one-to-one alignments because it imposes a hard constraint on agreement: the two models must share the same alignment when estimating the parameters by calculating the products of align-ment posteriors. In Figure 1(b), the two one-to-one alignments are almost identical except for one link. This makes the posteriors to be sharply peaked around the Viterbi alignments (Liang et al., 2006). As a result, the lack of many-to-many alignments limits the benefits of joint training to end-to-end machine translation. Our intuition is that the agreement between two alignments can be defined as a loss function, which enables us to consider various ways of quantification (Section 3.1) and even to incorpo-rate the dependency between alignments and oth-er latent structures such as phrase segmentations (Section 3.2). 3.1 Agreement between Word Alignments The key idea of generalizing agreement is to lever-age loss functions that measure the difference be-tween two unidirectional alignments. For exam-ple, the last term in Eq. (5) can be re-written as
Note that the last term in Eq. (6) is actually the expected value of agreement:
E
Our idea is to replace  X  ( a 1 , a 2 ) in Eq. (6) with an arbitrary loss function  X ( a 1 , a 2 ) that measures the difference between a 1 and a 2 . This gives the new joint training objective with generalized agreement: =
Obviously, Liang et al. (2006) X  X  training objec-tive is a special case of our framework. We refer to its loss function as hard matching :
We are interested in developing a soft version of the hard matching loss function because this will help to produce many-to-many symmetric align-ments. For example, in Figure 1(c), the two align-ments share most links but still allow for dis-agreed links to capture one-to-many and many-to-one links. Note that the union of the two asymmet-ric alignments is almost the same with the gold-standard alignment in this example.

While there are many possible ways to define a soft matching loss function, we choose the dif-ference between disagreed and agreed link counts because it is easy and efficient to calculate during search: alignment are labeled with  X + X . See Section 3.2 for details. 3.2 Agreement between Word Alignments Our framework is very general and can be extended to include the agreement between word alignment and other latent structures such as phrase segmentations.

The words in a Chinese sentence often con-stitute phrases that are translated as units in English and vice versa. Inspired by the alignment consistency constraint widely used in translation rule extraction (Koehn et al., 2003), we make the following assumption to impose a structural agreement constraint between word alignment and phrase segmentation: source words in one source phrase should be aligned to target words belong-ing to the same target phrase and vice versa. For example, consider the C  X  E alignment in Figure 2. We segment Chinese and English sen-tences into phrases, which are sequences of con-secutive words. Since  X 2002 X  and  X  X PEC X  belong to the same English phrase, their counterparts on the Chinese side should also belong to one phrase.
While this assumption can potentially improve the correlation between word alignment and phrase-based translation, a question naturally a-rises: how to segment sentences into phrases? Instead of leveraging chunking, we treat phrase segmentation as a latent variable and train the joint alignment and segmentation model from unlabeled data in an unsupervised way.

Formally, given a target-language sentence f  X  1 = f 1 ,...,f J , we introduce a latent variable b  X  b J 1 = b 1 ,...,b J to denote a phrase segmen-tation . Each label b j  X  { B,I,E,S } , where B denotes the beginning word of a phrase, I denotes the internal word, E denotes the ending word, and S denotes the one-word phrase. Figure 2 shows the label sequences for the sentence pair.

We use a first-order HMM to model phrase seg-mentation of a target sentence:
Similarly, the hidden Markov model for the phrase segmentation of the source sentence can be defined as
Then, we can combine word alignment and phrase segmentation and define the joint training objective as 1: procedure V ITERBI EM( D ) 3: for all k = 1 ,...,K do 6: end for 8: end procedure Algorithm 1: A Viterbi EM algorithm for learning the joint word alignment and phrase segmentation model from bilingual corpus. D is a bilingual cor-at the k -th iteration. where the expected loss is given by =
We define a new loss function segmentation violation to measure the degree that an alignment violates phrase segmentations. where  X  ( a 1 ,j, b 1 , b 2 ) evaluates whether two links l 1 = ( j,a j ) and l 2 = ( j + 1 ,a j +1 ) violate the phrase segmentation: 1. f j and f j +1 belong to one phrase but e a 2. f j and f j +1 belong to two phrases but e a
The  X  function returns 1 if there is violation and 0 otherwise. 1: procedure S EARCH ( D ,  X  ) 2:  X  H  X  X  X  3: for all s  X  X  1 ,...,S } do 8: h 0  X  X   X  a 1 ,  X  a 2 ,  X  b 1 ,  X  b 2  X  10:  X  H  X   X  H  X  X   X  h } 11: end for 12: return  X  H 13: end procedure Algorithm 2: A search algorithm for finding the Viterbi latent variables.  X  a 1 and  X  a 2 denote Viter-bi alignments,  X  b 1 and  X  b 2 denote Viterbi seg-mentations. They form a starting point h 0 for the hill climbing algorithm, which keeps chang-ing alignments and segmentations until the model score does not increase.  X  h is the final set of Viterbi latent variables for one sentence.

In Figure 2, we use  X + X  to label words that do not violate the phrase segmentations and  X - X  to label violations.

In practice, we combine the two loss functions to enable word alignment and phrase segmentation to benefit each other in a joint search space: Liang et al. (2006) indicate that it is intractable to train the joint model. For simplicity and efficien-cy, they exploit a simple heuristic procedure that leverages the product of posterior marginal prob-abilities. The intuition behind the heuristic is that links on which two models disagree should be dis-counted because the products of the marginals are small (Liang et al., 2006).

Unfortunately, it is hard to develop a similar heuristic for our model that allows for arbitrary loss functions. Alternatively, we resort to a Viterbi EM algorithm, as shown in Algorithm 1. The algorithm takes the training data D =  X   X  parameters at the k -th iteration. After initializing the model parameters (line 2), the algorithm alter-nates between searching for the Viterbi alignments Figure 3: Operators used in the H ILL C LIMB pro-cedure. dure (line 4) and updating model parameters using the U PDATE procedure (line 5). The algorithm ter-minates after running for K iterations.

It is challenging to search for the Viterbi align-ments and segmentations because of complicat-ed structural dependencies. As shown in Al-gorithm 2, our strategy is first to find Viter-bi alignments and segmentations independently using the A LIGN and S EGMENT procedures (lines 4-7), which then serve as a starting point for the H ILL C LIMB procedure (lines 8-9).
 Figure 3 shows three operators we use in the H
ILL C LIMB procedure. The M OVE operator moves a link in an alignment, the M ERGE oper-ator merges two phrases into one phrase, and the S
PLIT operator splits one phrase into two small-er phrases. Note that each operator can be further divided into two variants: one for the source side and another for the target side. 5.1 Setup We evaluate our approach on Chinese-English alignment and translation tasks.

The training corpus consists of 1.2M sentence pairs with 32M Chinese words and 35.4M English words. We used the SRILM toolkit (Stolcke, 2002) to train a 4-gram language model on the Xinhua portion of the English GIGAWORD cor-pus, which contains 398.6M words. For alignment evaluation, we used the Tsinghua Chinese-English ation metric is alignment error rate (AER) (Och and Ney, 2003). For translation evaluation, we used the NIST 2006 dataset as the development set and the NIST 2002, 2003, 2004, 2005, and 2008 datasets as the test sets. The evaluation metric is case-insensitive BLEU (Papineni et al., 2002).
We used both phrase-based (Koehn et al., 2003) and hierarchical phrase-based (Chiang, 2007) translation systems to evaluate whether our approach improves translation performance. For the phrase-based model, we used the open-source toolkit Moses (Koehn and Hoang, 2007). For the hierarchical phrase-based model, we used an in-house re-implementation on par with state-of-the-art open-source decoders.

We compared our approach with two state-of-the-art generative alignment models: 1. G IZA ++ (Och and Ney, 2003): unsupervised 2. B ERKELEY (Liang et al., 2006): unsuper-
For G IZA ++, we trained IBM Model 4 in two directions with the default setting and used the grow-diag-final heuristic to generate symmetric alignments. For B ERKELEY , we trained joint HMMs using the default setting. The hyper-parameter of posterior decoding was optimized on the development set.

We used first-order HMMs for both word alignment and phrase segmentation. Our joint alignment and segmentation model were trained using the Viterbi EM algorithm for five iterations. Note that the Chinese-to-English and English-to-Chinese alignments are generally non-identical but share many links (see Figure 1(c)). Then, we used the grow-diag-final heuristic to generate symmetric alignments. 5.2 Comparison with G IZA ++ and Table 1 shows the comparison of our approach with G IZA ++ and B ERKELEY in terms of AER and BLEU. G IZA ++ trains two asymmetric models independently and uses the grow-diag-final (i.e., GDF) for symmetrization. B ERKELEY Table 1: Comparison with G IZA ++ and B ERKELEY .  X  X ord-word X  denotes the agreement between segmentation violation.  X * X : significantly better than G IZA ++ ( p &lt; 0 . 05 ).  X ** X : significantly better than G IZA ++ ( p &lt; 0 . 01 ).  X + X : significantly better than B
ERKELEY ( p &lt; 0 . 05 ).  X ++ X : significantly better than B ERKELEY ( p &lt; 0 . 01 ). trains two models jointly with the hard-matching (i.e., HM) loss function and uses posterior decod-ing for symmetrization.

For our approach, we distinguish between two variants: 1. Imposing agreement between word align-2. Imposing agreement between word align-We used the grow-diag-final heuristic for symmetrization.

For the alignment evaluation, we find that our approach achieves higher AER scores than the two baseline systems. One possible reason is that links in the intersection of two symmetric alignments or two symmetric models agree usually correspond to sure links in the gold-standard annotation. Our approach loosens the hard constraint on agreement and makes the posteriors less peaked around the Viterbi alignments.

For the translation evaluation, we used the phrase-based system Moses to report BLEU s-cores on the NIST 2008 test set. We find that both the two variants of our approach significantly out-performs the two baselines ( p &lt; 0 . 01 ). 5.3 Results on (Hierarchical) Phrase-based Table 2 shows the results on phrase-based and hierarchical phrase-based translation systems. We find that our approach systematically outperforms G IZA ++ and B ERKELEY on all NIST datasets.

In particular, generalizing the agreement to model the discrepancy between word alignment and phrase segmentation is consistently beneficial for improving translation quality, suggesting that it is important to introduce structural constraints into word alignment to increase the correlation between alignment and translation.

While  X  X M+SV X  improves over  X  X M X  signifi-cantly on phrase-based translation, the margins on the hierarchical phrase-based system are relative-ly smaller. One possible reason is that the  X  X V X  well two asymmetric alignments agree with each other. loss function can better account for phrase-based rather than hierarchical phrase-based translation. It is possible to design new loss functions tailored to hierarchical phrase-based translation.
 We also find that the BLEU scores of B ERKE -LEY on hierarchical phrase-based translation are much lower than those on phrase-based transla-tion. This might result from the fact that B ERKE -LEY is prone to produce one-to-one alignments, which are not optimal for hierarchical phrase-based translation. 5.4 Agreement Evaluation Table 3 compares how well two asymmetric models agree with each other among G IZA ++, B
ERKELEY and our approach. We use F1 score to measure the degree of agreement: where A C  X  E is the set of Chinese-to-English alignments on the training data and A E  X  C is the set of English-to-Chinese alignments.

It is clear that independent training leads to low agreement and joint training results in high agree-ment. B ERKELEY achieves the highest value of agreement because of the hard constraint. This work is inspired by two lines of research: (1) agreement-based learning and (2) joint modeling of multiple NLP tasks. 6.1 Agreement-based Learning The key idea of agreement-based learning is to train a set of models jointly by encouraging them to agree on the hidden variables (Liang et al., 2006; Liang et al., 2008). This can also be seen as a particular form of posterior constraint or poste-rior regularization (Grac  X a et al., 2007; Ganchev et al., 2010). The agreement is prior knowledge and indirect supervision, which helps to train a more reasonable model with biased guidance.

While agreement-based learning provides a principled approach to training a generative mod-el, it constrains that the sub-models must share the same output space. Our work extends (Liang et al., 2006) to introduce arbitrary loss functions that can encode prior knowledge. As a result, Liang et al. (2006) X  X  model is a special case of our frame-work. Another difference is that our framework allows for including the agreement between word alignment and other structures such as phrase seg-mentations and parse trees. 6.2 Joint Modeling of Multiple NLP Tasks It is well accepted that different NLP tasks can help each other by providing additional informa-tion for resolving ambiguities. As a result, joint modeling of multiple NLP tasks has received in-tensive attention in recent years, including phrase segmentation and alignment (Zhang et al., 2003), alignment and parsing (Burkett et al., 2010), tok-enization and translation (Xiao et al., 2010), pars-ing and translation (Liu and Liu, 2010), alignment and named entity recognition (Chen et al., 2010; Wang et al., 2013).

Among them, Zhang et al. (2003) X  X  integrat-ed search algorithm for phrase segmentation and alignment is most close to our work. They use Point-wise Mutual Information to identify possi-ble phrase pairs. The major difference is we train models jointly instead of integrated decoding. We have presented generalized agreement for bidi-rectional word alignment. The loss functions can be defined both between asymmetric alignments and between alignments and other latent structures such as phrase segmentations. We develop a Viter-bi EM algorithm to train the joint model. Exper-iments on Chinese-English translation show that joint training with generalized agreement achieves significant improvements over two baselines for (hierarchical) phrase-based MT systems. In the fu-ture, we plan to investigate more loss functions to account for syntactic constraints.
 Yang Liu and Maosong Sun are supported by the 863 Program (2015AA011808), the National Nat-ural Science Foundation of China (No. 61331013 and No. 61432013), and Samsung R&amp;D Institute of China. Huanbo Luan is supported by the Na-tional Natural Science Foundation of China (No. 61303075). This research is also supported by the Singapore National Research Foundation un-der its International Research Centre@Singapore Funding Initiative and administered by the IDM Programme. We sincerely thank the reviewers for their valuable suggestions. We also thank Yue Zhang, Meng Zhang and Shiqi Shen for their in-sightful discussions.

