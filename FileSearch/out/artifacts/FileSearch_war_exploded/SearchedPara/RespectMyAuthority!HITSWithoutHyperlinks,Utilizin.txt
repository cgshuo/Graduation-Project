 We presen t an approac h to impro ving the precision of an ini-tial documen t ranking wherein we utilize cluster information within a graph-based framew ork. The main idea is to per-form re-ranking based on centr ality within bipartite graphs of documen ts (on one side) and clusters (on the other side), on the premise that these are mutually reinforcing entities. Links between entities are created via consideration of lan-guage mo dels induced from them.

We nd that our cluster-do cumen t graphs give rise to much better retriev al performance than previously prop osed documen t-only graphs do. For example, authorit y-based re-ranking of documen ts via a HITS-st yle cluster-based ap-proac h outp erforms a previously-prop osed PageRank-inspired algorithm applied to solely-do cumen t graphs. Moreo ver, we also sho w that computing authorit y scores for clusters con-stitutes an e ectiv e metho d for iden tifying clusters con tain-ing a large percen tage of relev ant documen ts.

To impro ve the precision of retriev al output, esp ecially within the very few (e.g, 5 or 10) highest-rank ed documen ts that are returned, a num ber of researc hers [36, 13, 16, 7, 22, 34, 25, 1, 18, 9] have considered a structur al re-rank ing strat-egy . The idea is to re-rank the top N documen ts that some initial searc h engine pro duces, where the re-ordering uti-lizes information about inter-do cumen t relationships within that set. Promising results have been previously obtained by using documen t centr ality within the initially retriev ed list to perform structural re-rank ing, on the premise that if the qualit y of this list is reasonable to begin with, then the documen ts that are most related to most of the docu-men ts on the list are likely to be the most relev ant ones. In particular, in our prior work [18] we adapted PageR ank [3] | whic h, due to the success of Google, is surely the most well-established algorithm for de ning and computing cen-tralit y within a directed graph | to the task of re-ranking non-h yperlink ed documen t sets.

The arguably most well-kno wn alternativ e to PageRank is Klein berg's HITS algorithm [16]. The ma jor conceptual way in whic h HITS di ers from PageRank is that it de nes two di eren t types of cen tral items: eac h node is assigned both a hub and an authority score as opp osed to a single PageRank score. In the Web setting, in whic h HITS was originally prop osed, good hubs corresp ond roughly to high-qualit y resource lists or collections of pointers, whereas good authorities corresp ond to the high-qualit y resources them-selv es; thus, distinguishing between two di ering but inter-dep enden t types of Webpages is quite appropriate. Our pre-vious study [18] applied HITS to non-W eb documen ts. We found that its performance was comparable to or better than that of algorithms that do not involve structural re-ranking; however, HITS was not as e ectiv e as PageRank [18].
Do these results imply that PageRank is better than HITS for structural re-rank ing of non-W eb documen ts? Not neces-sarily , because there may exist graph-construction metho ds that are more suitable for HITS. Note that the only enti-ties considered in our previous study were documen ts. If we could introduce entities distinct from documen ts but enjo y-ing a mutually reinforcing relationship with them, then we migh t better satisfy the spirit of the hubs-v ersus-authorities distinction, and thus deriv e stronger results utilizing HITS.
A crucial insigh t of the presen t pap er is that documen t clusters app ear extremely well-suited to play this comple-men tary role. The intuition is that: (a) given those clus-ters that are \most represen tativ e" of the user's information need, the documen ts within those clusters are likely to be relev ant; and (b) the \most represen tativ e" clusters should be those that con tain man y relev ant documen ts. This appar-ently circular reasoning is strongly reminiscen t of the inter-related hubs and authorities concepts underlying HITS.
Also, clusters have long been considered a promising source of information. The well-kno wn cluster hyp othesis [35] en-capsulates the intuition that clusters can rev eal groups of relev ant documen ts; in practice, the poten tial utilit y of clus-tering for this purp ose has been demonstrated for both the case wherein clusters were created in a query-indep enden t fashion [14, 4] and the re-ranking setting [13, 22, 34].
In this pap er, we sho w through an arra y of exp erimen ts that consideration of the mutual reinforcemen t of clusters and documen ts in determining cen tralit y can lead to highly e ectiv e algorithms for re-ranking an initially retriev ed list. Speci cally , our exp erimen tal results sho w that the cen tralit y-induction metho ds that we previously studied solely in the con text of documen t-only graphs [18] result in much better re-ranking performance if implemen ted over bipartite graphs of documen ts (on one side) and clusters (on the other side). For example, ranking documents by their \authoritativ e-ness" as computed by HITS upon these cluster-do cumen t graphs yields better performance than that of a previously prop osed PageRank implemen tation applied to documen t-only graphs. Interestingly , we also nd that cluster author-ity scores can be used to iden tify clusters con taining a large percen tage of relev ant documen ts.
Since we are focused on the structural re-ranking paradigm, our algorithms are applied not to the entire corpus, but to a subset D N;q init (henceforth D init ), de ned as the top N docu-men ts retriev ed in resp onse to the query q by a given initial retriev al engine. Some of our algorithms also tak e into ac-coun t a set C l ( D init ) of clusters of the documen ts in D We use S init to refer generically to whic hev er set of entities | either D init or D init [ C l ( D init ) | is used by a given algorithm.

The basic idea behind the algorithms we consider is to determine cen tralit y within a relevanc e-ow graph , de ned as a directed graph with non-negativ e weigh ts on the edges in whic h By construction, then, any measure of the cen tralit y of s 2 S init should measure the accum ulation of evidence for its rel-evance according to the set of interconnections among the entities in S init . Suc h information can then optionally be sub jected to additional pro cessing, suc h as integration with information on eac h item's similarit y to the query , to pro-duce a nal re-ranking of D init .
 ow graphs we consider can all be represen ted as weigh ted directed graphs of the form ( V; w t ), where V is a nite non-empt y set of nodes and w t : V V ! [0 ; 1 ) is a non-negativ e edge-w eigh t function. Note that thus our graphs technically have edges between all ordered pairs of nodes (self-lo ops included); however, edges with zero edge-w eigh t are conceptually equiv alen t to missing edges. For clarit y, we write w t ( u ! v ) instead of w t ( u; v ).
The HITS algorithm for computing cen tralit y can be mo-tivated as follo ws. Let G = ( V; w t ) be the input graph, and let v be a node in V . First, supp ose we someho w knew the hub score hub ( u ) of eac h node u 2 V , where \hubness" is the exten t to whic h the nodes that u points to are \go od" in some sense. Then, v 's authority score would be a natural measure of how \go od" v is, since a node that is \strongly" pointed to by high-qualit y hubs (whic h, by de nition, tend to point to \go od" nodes) receiv es a high score. But where do we get the hub score for a given node u ? A natural choice is to use the exten t to whic h u \strongly" points to highly authoritativ e nodes: Clearly , Equations 1 and 2 are mutually recursiv e. However, the iterativ e HITS algorithm 1 pro vably con verges to (non-iden tically-zero, non-negativ e) score functions hub and auth that satisfy the above pair of equations.
 Figure 1 depicts the \iconic" case in whic h the input graph G is one-way bipartite , that is, V can be partitioned into non-empt y sets V Left and V Righ t suc h that only edges in V Left V Righ t can receiv e positiv e weigh t, and 8 u 2 V P v 2 V Righ t w t ( u ! v ) &gt; 0. It is the case that auth ( u ) = 0 for every u 2 V Left and hub ( v ) = 0 for every v 2 V Righ t in this sense, the left-hand nodes are \pure" hubs and the righ t-hand nodes are \pure" authorities.
 Figure 1: A one-w ay bipartite graph. We only sho w positiv e-w eigh t edges (omitting weigh t values). Ac-cording to HITS, the left-hand nodes are (pure) hubs; the righ t-hand ones are (pure) authorities.

Note that in the end, we need to pro duce a single cen-tralit y score for eac h node n 2 V . For exp erimen tal sim-plicit y, we consider only two possibilities in this pap er | using auth ( n ) as the nal cen tralit y score, or using hub ( n ) instead| although com bining the hub and authorit y scores is also an interesting possibilit y.
Recall that the fundamen tal operation in our structural re-ranking paradigm is to compute the cen tralit y of entities (with)in a set S init . One possibilit y is to de ne S D init , the documen ts in the initially retriev ed set; we refer generically to any relev ance-o w graph induced under this choice as a document-to-do cument graph. But note that for non-W eb documen ts, it may not be obvious a priori what kinds of documen ts are hubs and what kinds are authorities.
Alternativ ely, we can de ne S init as D init [ C l ( D init C l ( D init ) consists of clusters of the documen ts in D a purely formal level, doing so allo ws us to map the hubs/au-thorities dualit y discussed above onto the documen ts/clusters dualit y, as follo ws. Recalling our discussion of the \iconic" case of one-w ay bipartite graphs G = (( V Left ; V Righ t we can create document-as-authority graphs simply by
Strictly speaking, the algorithm and pro of of con vergence as originally presen ted [16] need (trivial) mo di cation to ap-ply to edge-w eigh ted graphs. choosing V Left = C l ( D init ) and V Righ t = D init , so that neces-sarily clusters serv e the role of (pure) hubs and documen ts serv e the role of (pure) authorities. Con trariwise, 2 we can create document-as-hub graphs by setting V Left = D init
But the adv antages of incorp orating cluster-based infor-mation are not just formal. The well-kno wn cluster hyp oth-esis [35] encapsulates the intuition that clusters can rev eal groups of relev ant documen ts; in practice, the poten tial util-ity of clustering for this purp ose has been demonstrated a num ber of times, whether the clusters were created in a query-indep enden t fashion [14, 4], or from the initially most-highly-rank ed documen ts for some query [13, 22, 34] (i.e., in the re-ranking setting). Since cen tral clusters are, sup-posedly , those that accrue the most evidence for relev ance, documen ts that are strongly iden ti ed with suc h clusters should themselv es be judged highly relev ant. 3 4 But iden ti-fying suc h clusters is facilitated by kno wledge of whic h doc-umen ts are most likely to be relev ant | exactly the mutual reinforcemen t prop erty that HITS was designed to leverage.
We will compare the results of using the HITS algorithm against those deriv ed using PageRank instead. This is a nat-ural comparison because PageRank is the most well-kno wn cen tralit y-induction algorithm utilized for ranking documen ts, and because in earlier work [18], PageRank performed quite well as a tool for structural re-rank ing of non-W eb doc-umen ts, at least when applied to documen t-to-do cumen t graphs.

One can think of PageRank as a version of HITS in whic h the hub/authorit y distinction has been collapsed. Thus, writing \ PR " for both auth and hub , we conc eptual ly have the (single) equation However, in practice, we incorp orate Brin and Page's smo oth-ing scheme [3] together with a correction for nodes with no positiv e-w eigh t edges emanating from them [27, 21]:
PR ( v ) = X where out ( u ) def = P v 0 2 V w t ( u ! v 0 ), and 2 (0 ; 1) is the damping factor. 5 In practice, one can sim ultaneously compute the output of HITS for a given documen t-as-authorit y and documen t-as-hub graph pair by \overla ying" the two into a single graph and suitably mo difying HITS's normalization scheme.
We say \are strongly iden ti ed with", as opp osed to \be-long to" to allo w for overlapping or probabilistic clusters. Indeed, the one-w ay bipartite graphs we construct are ill-suited to the HITS algorithm if documen t-to-cluster links are based on mem bership in disjoin t clusters.
This is, in some sense, a type of smo othing: a documen t migh t be missing some of the query terms (perhaps due to synon ym y), but if it lies within a sector of \do cumen t space" con taining man y relev ant documen ts, it could still be deemed highly relev ant. Recen t researc h pursues this smo othing idea at a deep er level [25, 17]. Under the original \random surfer" mo del, the sum of the
Equation 4 is recursiv e, but there are iterativ e algorithms that pro vably con verge to the unique positiv e solution PR satisfying the sum-normalization constrain t P v 2 V PR ( v ) = 1 [21]. Moreo ver, a (non-trivial) close d-form | and quite easily computed | solution exists for one-w ay bipartite graphs: Theorem 1. If G = ( V; w t ) is one-way bipartite, then is an ane transformation (with respect to positive con-stants) of, and ther efor e equivalent for ranking purp oses to, the unique positive sum-normalize d solution to Equation 4. (Pro of omitted due to space constrain ts.) Interestingly , this result sho ws that while one migh t have though t that clusters and documen ts would \comp ete" for PageRank score when placed within the same graph, in our documen t-as-authorit y and documen t-as-h ub graphs this is not the case.

Earlier work [18] also considered scoring a node v by its in ux , P u 2 V w t ( u ! v ). This can be view ed as either a non-recursiv e version of Equation 3, or as an un-normalized analog of Equation 5.
Clearly , we can rank documen ts by their scores as com-puted by any of the functions introduced above. But when we operate on documen t-as-authorit y or documen t-as-h ub graphs, cen tralit y scores for the clusters are also pro duced. These can be used to deriv e alternativ e means for ranking documen ts. We follo w Liu and Croft's approac h [25]: rst, rank the documen ts within (or most strongly asso ciated to) eac h cluster according to the initial retriev al engine's scores; then, deriv e the nal list by concatenating the within-cluster lists in order of decreasing cluster score, discarding rep eats. Suc h an approac h would be successful if cluster cen tralit y is strongly correlated with the prop erty of con taining a large percen tage of relev ant documen ts.
 Ranking algorithms. Since we have two possible rank-ing paradigms, we adopt the follo wing algorithm naming con ventions . Names consist of a hyphen-separated pre x and sux. The pre x (\do c" or \clust") indicates whether documen ts were rank ed directly by their cen tralit y scores, or indirectly through the concatenation pro cess outlined above in whic h it is the clusters' cen tralit y scores that were em-ployed. The sux (\Auth", \Hub", \ PR ", or \In ux") indi-cates whic h score function ( auth , hub , PR (or PR b ip in ux) was used to measure cen tralit y. For a given re-rank-ing algorithm, we indicate the graph upon whic h it was run in brac kets, e.g., \do c-Auth[ G ]".
The poten tial merits of query-dep endent clustering , that is, clustering the documen ts retriev ed in resp onse to a query , have long been recognized [30, 36, 23, 34, 25], esp ecially in interactiv e retriev al settings [13, 22, 32]. However, automat-ically detecting clusters that con tain man y relev ant docu-men ts remains a very hard task [36]. Section 5.2 presen ts re-transition probabilities out of \no out o w" nodes | whic h are abundan t in one-w ay bipartite graphs | would be (1 ), not 1. Conceptually , the role of the second summation in Equation 4 is to set = 0 for these no-out o w nodes. sults for detecting suc h clusters using cen tralit y-based clus-ter ranking.

Recen tly, there has been a gro wing body of work on graph-based mo deling for di eren t language-pro cessing tasks where-in links are induced by inter-en tity textual similarities. Ex-amples include documen t (re-)ranking [7, 24, 9, 18, 39], text summarization [11, 26], sen tence retriev al [28], and docu-men t represen tation [10]. In con trast to our metho ds, links connect entities of the same type, and clusters of entities are not mo deled within the graphs.

While ideas similar to ours by virtue of leveraging the mutual reinforcemen t of entities of di eren t types, or using bipartite graphs of suc h entities for clustering (rather than using clusters), are abundan t (e.g., [15, 8, 2]), we focus here on exploiting mutual reinforcemen t in ad hoc retriev al.
Mark ov chains (with early stopping) over bipartite graphs of terms and documen ts were used for query expansion [20], but in con trast to our work, no stationary solution was sough t. A similar \short chain" approac h utilizing bipar-tite graphs of clusters and documen ts for ranking an entire corpus was recen tly prop osed [19], thereb y constituting the work most resem bling ours. However, in addition to not seeking a stationary solution, query drift prev ention mec h-anisms were required to obtain good performance; in our re-ranking setting, we need not emplo y suc h mec hanisms.
Most asp ects of the evaluation framew ork describ ed be-low are adopted from our previous exp erimen ts with non-cluster-based structural re-rank ing [18] so as to facilitate direct comparison. Section 4.1 of [18] pro vides a more de-tailed justi cation of the exp erimen tal design. The main conceptual changes 6 here are: a sligh tly larger parameter searc h-space for the \out-degree" parameter (called the \ancestry" parameter in [18]); and, of course, the incor-poration of clusters. estimate the degree to whic h one item, if considered rele-vant, can vouc h for the relev ance of another, we follo w our previous work on documen t-based graphs [18] and utilize p d ( ), the unigram Diric hlet-smo othed language mo del in-duced from a given documen t d ( is the smo othing pa-rameter) [38]. To adapt this estimation scheme to settings involving clusters, we deriv e the language mo del p [ ] c a cluster c by treating c as the (large) documen t formed by concatenating 7 its constituen t (or most strongly asso ciated) documen ts [17, 25, 19].

The relev ance-o w measure we use is essen tially a directed similarit y in language-mo del space: where D is the Kullbac k-Leibler div ergence. The asymme-try of this measure corresp onds nicely to the intuition that
Some of the PageRank results app earing in our previous pap er [18] acciden tally re ect exp erimen ts utilizing a sub-optimal choice of D init . For citation purp oses, the num bers rep orted in the curren t pap er should be used.
Concatenation order is irrelev ant for unigram LMs. relev ance ow is not symmetric [18]. Moreo ver, this function is somewhat insensitiv e to large length di erences between the items in question [18], whic h is adv antageous when both documen ts and clusters (whic h we treat as very long docu-men ts) are considered.

Previous work [18, 33] mak es hea vy use of the idea of near-est neigh bors in language-mo del space. It is therefore con ve-nien t to introduce the notation N bhd ( x j m; R ), pronounced \neigh borho od", to denote the m items y within the \re-striction set" R that have the highest values of r ow ( x; y ) (we break ties by item ID, assuming that these have been assigned to documen ts and clusters). Note that the neigh-borho od of x corresp onds to what we previously termed the \top generators" of x [18].
 tially retriev ed documen ts and positiv e integer (an \out-degree" parameter), we consider the follo wing three graphs. Eac h connects nodes u to the other nodes, dra wn from some speci ed set, that u has the highest relev ance ow to. The documen t-to-do cumen t graph d $ d has vertex set D init and weigh t function w t d $ d ( u; v ) = ( r ow ( u; v ) if v 2 N bhd ( u j ; D init
The documen t-as-authorit y graph c ! d has vertex set D init C l ( D init ) and a weigh t function suc h that positiv e-w eigh t edges go only from clusters to documen ts: w t c ! d ( u; v ) = The documen t-as-h ub graph d ! c has vertex set D init [ C l ( D init ) and a weigh t function suc h that positiv e-w eigh t edges go only from documen ts to clusters: w t d ! c ( u; v ) =
Since the latter two graphs are one-w ay bipartite, Theo-rem 1 applies to them.
 Clustering Method. Clearly , our cluster-based graphs re-quire the construction of clusters of the documen ts in D Since this set is query-dep enden t, at least some of the clus-tering pro cess must occur at retriev al time, mandating the use of extremely ecien t algorithms [6, 37]. The approac h we adopt is to use overlapping nearest-neigh bor clusters, whic h have formed the basis of e ectiv e retriev al algorithms in other work [12, 17, 19, 33]: for eac h documen t d 2D init we have the cluster f d g[ N bhd ( d j k 1 ; D init f d g ), where k is the cluster-size parameter.
We conducted our exp erimen ts on three TREC datasets: that of doc-P ageRank[d $ d] or doc-Auth[d $ d], resp ectiv ely. We applied basic tok enization and Porter stemming via the Lem ur toolkit (www.lem urpro ject.org), whic h we also used for language-mo del induction. Topic titles serv ed as queries.
In man y retriev al situations of interest, ensuring that the top few documen ts retriev ed (a.k.a., \the rst page of re-sults") tend to be relev ant is much more imp ortan t than en-suring that we assign relativ ely high ranks to the entire set of relev ant documen ts in aggregate [31]. Hence, rather than use mean average precision (MAP) as an evaluation metric, we apply metrics more appropriate to the structural re-rank ing task: precision at the top 5 and 10 documen ts (henceforth prec@5 and prec@10, resp ectiv ely) and the mean recipro cal rank (MRR) of the rst relev ant documen t [31]. All perfor-mance num bers are averaged over the set of queries for a given corpus.

The natural baseline for the work describ ed here is the standard language-mo del-based retriev al approac h [29, 5], since it is an e ectiv e paradigm that mak es no explicit use of inter-do cumen t relationships. Speci cally , for a given eval-uation metric e , the corresp onding optimize d baseline is the ranking on documen ts pro duced by p [ ( e )] d ( q ), where ( e ) is the value of the Diric hlet smo othing parameter that results in the best retriev al performance as measured by e .
A ranking metho d migh t assign di eren t items the same score; we break suc h ties by item ID. Alternativ ely, the scores used to determine D init can be utilized, if available. are two motiv ations underlying our approac h to choosing values for our algorithms' parameters [18].

First, we hop e to sho w that structural re-rank ing can pro vide better results than the optimized baselines even when initialized with a sub-optimal (yet reasonable) rank-ing. Hence, let the initial ranking be the documen t ordering induced on the entire corpus by p [ 1000 ] d ( q ), where the smo othing-parameter value optimizing the average non-interp olated precision of the top 1000 documen ts. We set D init to the top 50 documen ts in the initial ranking.
Second, we wish to sho w that good results can be achiev ed without a great deal of parameter tuning. Therefore, we did not tune the smo othing parameter for any of the language mo dels used to determine graph edge-w eigh ts, but rather simply set = 2000 when smo othing was required, follo wing a prior suggestion [38]. Also, the other free parameters' val-ues wer e chosen so as to optimize prec@5, regardless of the evaluation metric under consider ation. 8 As a consequence, our prec@10 and MRR results are presumably not as high
If two di eren t parameter settings yield the same prec@5, we choose the setting minimizing prec@10 so as to pro vide a conserv ativ e estimate of exp ected performance. Similarly , if we have ties for both prec@5 and prec@10, we choose the setting minimizing MRR. as possible; but the adv antage of our policy is that we can see whether optimization with resp ect to a xed criterion yields good results no matter how \go odness" is measured. Parameter values were selected from the follo wing sets. The graph \out-degree" : f 2 ; 4 ; 9 ; 19 ; 29 ; 39 ; 49 g . The clus-ter size k : f 2 ; 5 ; 10 ; 20 ; 30 g . The PageRank damping factor : f 0 : 05 ; 0 : 1 : : : 0 : 9 ; 0 : 95 g .
In what follo ws, when we say that results or the di erence between results are \signi can t", we mean according to the two-sided Wilco xon test at a con dence level of 95%. Main result. We rst consider our main question: can we substan tially boost the e ectiv eness of HITS by applying it to cluster-to-do cumen t graphs, whic h we have argued are more suitable for it than the documen t-to-do cumen t graphs we constructed in our previous work [18]? The answ er, as sho wn in Table 1, is clearly \yes": we see that moving to cluster-to-do cument graphs results in substantial impr ove-ment for HITS, and inde ed boosts its results over those for PageR ank on document-to-do cument graphs.
 whic h gives the results for the re-ranking algorithms doc-In ux, doc-P ageRank and doc-Auth as applied to either the documen t-based graph d $ d (as in [18]) or the cluster-documen t graph c ! d. (Discussion of doc-Hub is deferred to Section 5.3.)
To focus our discussion, it is useful to rst point out that in almost all of our nine evaluation settings (3 corp ora 3 evaluation measures), all three of the re-ranking algorithms perform better when applied to c ! d graphs than to d $ d graphs, as the num ber of dark bars in Figure 2 indicates. Since it is thus clearly useful to incorp orate cluster-based information, we will now mainly concen trate on c ! d-based algorithms.

The results for prec@5, the metric for whic h the re-ranking algorithms' parameters were optimized, sho w that all c ! d-based algorithms outp erform the prec@5-optimized baseline | signi can tly so for the AP corpus | even though applied to a sub-optimally-rank ed initial set. (W e hasten to point out that while the initial ranking is alw ays inferior to the corresp onding optimized baseline, the di erences are nev er signi can t.) In con trast, the use of d $ d graphs nev er leads to signi can tly sup erior prec@5 results.

We also observ e in Figure 2 that the doc-Auth[c ! d] al-gorithm is alw ays either the best of the c ! d-based algo-rithms or clearly comp etitiv e with the best. Furthermore, pairwise comparison of it to eac h of the doc-In ux[c ! d] Figure 2: All re-ranking algorithms, as applied to either d $ d graphs or c ! d graphs. and doc-P ageRank[c ! d] algorithms favors the HITS-st yle doc-Auth[c ! d] algorithm in a ma jorit y of the evaluation settings.

We also exp erimen ted with a few alternate graph-construction metho ds, suc h as sum-normalizing the weigh ts of edges out of nodes, and found that the doc-Auth[c ! d] algorithm re-mained sup erior to doc-In ux[c ! d] and doc-P ageRank[c ! d]. We omit these results due to space constrain ts.

All in all, these ndings lead us to believ e that not only is it useful to incorp orate information from clusters, but it can be more e ectiv e to do so in a way re ecting the mutually-reinforcing nature of clusters and documen ts, as the HITS algorithm does.
We now consider the alternativ e, men tioned in Section 2.4, of using the cen tralit y scores for clusters as an indir ect means of ranking documen ts, in the sense of iden tifying clusters that con tain a high percen tage of relev ant documen ts. Note that the problem of automatically iden tifying suc h clusters in the re-ranking setting has been ackno wledged to be a hard task for some time [36]. Nev ertheless, as stated in Section 2.4, we exp erimen ted with Liu and Croft's general clusters-for-selection approac h [25]: rank the clusters, then rank the documen ts within eac h cluster by p [ ] d ( q ). Our baseline algo-rithm, clust-p [ ] c ( q ), adopts Liu and Croft's speci c prop osal of the CQL algorithm | except that we emplo y overlapping rather than hard clusters | wherein clusters are rank ed by the query likeliho od p [ ] c ( q ) instead of one of our cen tralit y scores.

Table 2 (whic h may app ear on the next page) presen ts the performance results. Our rst observ ation is that the clust-In ux[d ! c] and clust-Auth[d ! c] algorithms are sup erior in a ma jorit y of the relev ant comparisons to the initial rank-ing, the optimized baselines, and the clust-p [ ] c ( q ) algorithm, where the performance di erences with the latter sometimes achiev e signi cance.

However, the performance of the documen t-cen tralit y-based algorithm doc-Auth[c ! d] is better in a ma jorit y of the eval-uation settings than that of any of the cluster-cen tralit y-based algorithms. On the other hand, it is possible that the latter metho ds could be impro ved by a better technique for within-cluster ranking.
 To compare the e ectiv eness of clust-In ux[d ! c] and clust-Auth[d ! c] to that of clust-p [ ] c ( q ) in detecting clusters with a high percen tage of relev ant documen ts | thereb y neutral-izing within-cluster ranking e ects | we presen t in Table 3 the percen t of documen ts in the highest rank ed cluster that are relev ant. (Cluster size ( k ) was xed to either 5 or 10 and out-degree ( ) was chosen to optimize the above per-cen tage.) Indeed, these results clearly sho w that our best cluster-based algorithms are much better than clust-p [ ] in detecting clusters con taining a high percen tage of relev ant documen ts, in most cases to a signi can t degree.
 Table 3: Average relev ant-do cumen t percen tage within the top-rank ed cluster. k : cluster size. Bold: best results per column. c : result di ers signi -can tly from that of clust-p [ ] c ( q ) , used in [25]. Authorities ver sus hubs. So far, we have only considered utilizing the authorit y scores that the HITS algorithm pro-duces. The chart below sho ws the e ect of ranking enti-ties by hub scores instead. Speci cally , the \do cumen ts?" column compares doc-Auth[c ! d] (i.e., ranking documen ts by authoritativ eness) to doc-Hub[d ! c] (i.e., ranking docu-men ts by hubness); similarly , the \clusters?" column com-pares clust-Auth[d ! c] to clust-Hub[c ! d]. Eac h entry de-picts, in descending order of performance (except for the one indicated tie) as one moves left to righ t, those cen tral-init. ranking : 457 : 432 : 596 : 500 : 456 : 691 : 536 : 484 : 748 opt. baselines : 465 : 439 : 635 : 512 : 464 : 696 : 560 : 494 clust-p [ ] c ( q ) : 448 : 418 : 549 io : 500 : 432 : 723 : 504 clust-In ux[d ! c] : 511 c : 479 c : 619 : 524 : 478 : 681 : 568 clust-P ageRank[d ! c] : 493 : 475 c : 595 : 496 : 444 : 683 : 528 : 490 ity scoring functions that lead to an impro vemen t over the initial ranking: A stands for \authorit y" and H for \hub". Cases in whic h the impro vemen t is signi can t are mark ed with a `*'.

We see that in man y cases, hub-based re-ranking does yield better performance than the initial ranking. But authorit y-based re-ranking app ears to be an even better choice overall. son of doc-Auth[d $ d] against doc-P ageRank[d $ d]. As the notation suggests, this corresp onds to running HITS and PageRank on the same graph, d $ d. But an alternativ e in-terpretation [18] is that non-smo othed (or no-random-jump) PageRank, as expressed by Equation (3), is applied to a di er ent version of d $ d wherein the original edge weigh ts w t ( u ! v ) have been smo othed as follo ws: (we ignore nodes with no positiv e-w eigh t out-edges to sim-plify discussion, and omit the d $ d sup erscripts for clarit y).
How does HITS perform on documen t-to-do cumen t graphs that are \truly equiv alen t", in the sense of emplo ying the above edge-w eigh ting regime, to those that PageRank is applied to? One reason this is an interesting question is that HITS assigns scores of zero to nodes that are not in the graph's largest connected comp onen t (with resp ect to positiv e-w eigh t edges, considered to be bi-directional). No-tice that the original graph may have sev eral connected com-ponen ts, whereas utilizing w t [ ] ensures that eac h node has a positiv e-w eigh t directed edge to every other node. Addition-ally , the re-w eigh ted version of HITS has pro vable stabilit y prop erties [27].

We found that in nearly all of our evaluation settings for documen t-to-do cumen t graphs (three corp ora three eval-uation metrics), doc-Auth[d $ d] achiev ed better results us-ing w t [ ] edge weigh ts. However, we cannot discoun t the possibilit y that the performance di erences migh t be due simply to the inclusion of the extra interp olation-parameter . Moreo ver, in all but one case, the impro ved results were still below those for doc-P ageRank[d $ d] (and alw ays lagged behind those of doc-Auth[c ! d]).

Interestingly , the situation is qualitativ ely di eren t if we consider c ! d graphs instead. In brief, we applied a smo oth-ing scheme analogous to that describ ed above, but only to edges leading from a left-hand node (cluster) to a righ t-hand node (do cumen t) 9 ; we thus preserv ed the one-w ay bipar-tite structure. Only in two of the nine evaluation settings did this change cause an increase in performance of doc-Auth[c ! d] over the results attained under the original edge-weigh ting scheme, despite the fact that the re-w eigh ting in-volves an extra free parameter. Thus, while we have al-ready demonstrated in previous sections of this pap er that information about documen t-cluster similarit y relationships is very valuable, the results just men tioned suggest that suc h information is more useful in \ra w" form.
 that PageRank cen tralit y scores induced over documen t-based graphs can be used as a multiplicativ e weigh t on documen t query-lik eliho od terms, the inten t being to cop e with cases in whic h cen tralit y in D init and relev ance are not strongly correlated [18]. Indeed, emplo ying this technique on the AP , TREC8, and WSJ corp ora, prec@5 increases from : 519, : 524 and : 536, to : 531, : 56 and : 572 resp ectiv ely.
The same mo di cation could be applied to the c ! d-based algorithms, although it is not particularly well-motiv ated in the HITS case. While PageRank scores corresp ond to a stationary distribution that could be loosely interpreted as a prior [18], in whic h case multiplicativ e com bination with query likeliho od is sensible, it is not usual to assign a prob-abilistic interpretation to hub or authorit y scores.
Nonetheless, for the sak e of comparison completeness, we applied this idea to the doc-Auth[c ! d] algorithm, yield-ing the follo wing performance changes: from : 541, : 544, and : 564 to : 537, : 572 and : 572 resp ectiv ely. These results are still as good as | and for two corp ora better than | those for PageRank as a multiplicativ e weigh t on query likeliho od. Thus, it may be the case that cen tralit y scores induced over a documen t-based graph are more e ectiv e as a multiplicativ e bias on query-lik eliho od than as direct represen tations of rel-
In the one-w ay bipartite case, the \ j V j " in Equation (7) must be changed to the num ber of righ t-hand nodes. evance in D init (see also [18]); but, mo dulo the caveat above, it seems that when cen tralit y is induced over cluster-based one-w ay bipartite graphs, the correlation with relev ance is much stronger, and hence this kind of cen tralit y serv es as a better \bias" on query-lik eliho od.
We have sho wn that leveraging the mutually reinforcing relationship between clusters and documen ts to determine cen tralit y is very bene cial not only for directly nding rel-evant documen ts in an initially retriev ed list, but also for nding clusters of documen ts from this list that con tain a high num ber of relev ant documen ts.

Speci cally , we demonstrated the sup eriorit y of cluster-documen t bipartite graphs to documen t-only graphs as the input to cen tralit y-induction algorithms. Our metho d for nding \authoritativ e" documen ts (or clusters) using HITS over these bipartite graphs results in state-of-the-art perfor-mance for documen t (and cluster) re-ranking.
 Ackno wledgmen ts We thank Eric Brec k, Claire Cardie, Oren Etzioni, Jon Klein berg, Art Munson, Filip Radlinski, Ves Sto yano v, Justin Wic k and the anon ymous review ers for valuable commen ts. This pap er is based upon work sup-ported in part by the National Science Foundation under gran t no. IIS-0329064 and an Alfred P. Sloan Researc h Fel-lowship. Any opinions, ndings, and conclusions or recom-mendations expressed are those of the authors and do not necessarily re ect the views or ocial policies, either ex-pressed or implied, of any sponsoring institutions, the U.S. governmen t, or any other entity.
