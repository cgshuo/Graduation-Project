 XML is rapidly emerging as the de facto standard for data representation and ex-change on Web applications, such as Digital Library, Web service, and Electronic business. XML  X  fashioned data has become one popular data type. Fig. 1(a) is one instance. Along with the promising future of XML data, the management research around this kind of data also becomes one popular issue for database community. How to retrieve interesting information from XML data is one impor-tant part of this issue. The properties of semi  X  structured and self  X  description make this problem challenging, because the processing not only should consider the structural information, but also must not ignore the semantic implied in the labels.

Generally there are two kinds of directions focusing on this issue. The first one inherits the DBMS X  X  habit. It first defines elaborate query languages (Always in regular expression style). Then users should learn their syntaxes and use them to describe their query patterns. The system receives the query, does pattern matching and finally returns the matched results. We mark this as XML Query type. Examples are Lorel, XML  X  QL, XML  X  GL, Quilt, XPath [2], XQuery [3]. XPath and XQuery are recommended by W3C organization and are the delegates of this kind of query languages. Regretfully they are inconvenient for common users. In order to use them to describe the query patterns, users not only should learn new mechanism but also should know the data organization information beforehand, such as labels and label relationships. We can see this from Fig. 2 and Fig. 3. Users should understand the meaning of  X // X ,  X  X ext() X  and  X  X position X . More inconveniently, they should also know the labels of the target XML data, such as  X  X rticle X ,  X  X itle X , even the relationships of labels.

Seeing the disadvantage of elaborate XML query languages, more and more researchers resort to the advantages from Information Retrieval (IR), and try to adapt IR properties into XML data processing. This is the other direction. There are also two kinds of directions during this procedure. The first one is to extend the query languages mentioned above so as to absorb IR properties, marked as XML IR/query type. Regretfully this kind of endeavors cannot cast off the disad-vantages from the carriers, and still is inconvenient for common users. The other direction is to integrate keyword search into XML data processing [4,5,6,7,8,9].
When we investigate the researches following XML keyword search, we found there are two deficiencies. The first one is that there is no good method to ex-press structural information in keyword search, however it is known that the structural information means a lot for XML data. The common improvement for keyword expression is to append label or label path information with key-words,such as  X  X uthor:Botnich title:Bibliography X  [6,4]. We can see that this skill still requires users know label information. Further more, the appended labels or label paths also cause one limitation, that is we cannot retrieve the XML fragments which are intimate with  X  X otnich Bibliography X  but labeled in other labels. The second deficiency is that most similarity measuring meth-ods for XML ranking either are dependent on labels and relative positions of nodes [10,11,12,13,14,15,16], or are not sensitive enough for structural discrim-ination of retrieved XML fragments [6,17,5,7,8]. For example the TF*IDF (TF means Term Frequency; while IDF means Inverse Document Frequency) like sim-ilarity measuring methods introduced in [18,5,7] only use node level distribution to sort the retrieved fragments, they do not capture the correlation relationship between keyword nodes which is one important hint for illustrating structural information. As for the methods in [16,14], their computation heavily depends on the label information and relative positions of nodes. So they are not suitable for XML keyword ranking from different XML schemas. More details about the deficiencies can be found in Section 2.3.

In this paper we reconsider the keyword searching on XML data. We first im-port nesting mechanism so as to endow keywords with some structural hints. For example we use  X ((Cohen) (Face Recognition)) X  to illustrate that the two words belong to two different nodes and they together act as one unit in higher level. Consequently we need not care the string like  X  X ohen Face Recognition X  in XML data at all. The other benefit of this nesting keywords is that we can still retrieve fragments satisfying its structural hints from different XML schemas. This is not easy for the extended keywords in [4] and [6]. By the way, this nesting keyword mechanism itself can also include label information. Since the retrieved XML fragments can be from different XML schemas, XML keyword search process-ing need new ranking scheme, which should not only be independent of labels, but also be more sensitive to structural difference between the fragments. Most similarity measures are deficient for this kind of situations because of their sensi-tivity for labels. Triggered from the SLCA (Smallest Lowest Common Ancestor) concept [4,9], we introduce a new structure to capture the structural features in fragments. Its name is KCAM (from Keyword Common Ancestor Matrix), in which each element stores the SLCA node level information corresponding to the keyword nodes. Since every XML fragment can be mapped into its corre-sponding KCAM, the similarity between two fragments can be measured by the matrix distance between their KCAMs.

The contributions of this paper can be concluded as follows: 1. We reconsider the nesting mechanism for keyword searching on XML data. 2. Though nesting mechanism can fetch more interesting fragments, the fact, 3. We design and implement related al gorithms. The extensive experiments
Section 2 reviews the related work, including three aspects  X  XML IR query languages, Dewey encoding and XML similarity measures. Section 3 illustrates the nesting keywords. Section 4 discusses the KCAM structure and proposes the computation of KCAM distance. Experiments are illustrated in Section 5. Finally, Section 6 concludes this paper. There are mainly three parts of related work associated with this paper. The first is about the IR like query descriptors used to XML data. We briefly retrospect XML query languages in Section 2.1. SLCA problem is illustrated in Section 2.2. The third Section 2.3 shows the researches of similarity measuring techniques for XML fragments. 2.1 XML IR Query Languages There are two kinds of strategies when adapting IR properties into XML data processing. The first one is to extend XML query languages so as to absorb IR properties [19,20,21,22,23,24,25,26,27,28]. Among them, the extension on XPath and XQuery is the delegate, and W3C recommends one specification, namely XQuery FullText. Just as mentioned in Section 1, this kind of extensions is hard to use for common users. Real XQuery/FT sentence in Fig. 4 illustrates this point. From it we can see that XQueryFT also requires users to learn the syntaxes and data organization information.
The other strategy is to use keyword search on XML data. Besides pure key-words only, other consideration is to append labels or label paths with key-words [4,6]. For example, a query in [6] is a list of query terms, where a query term can be a keyword (  X  X ecognition X ), a tag (  X  X rticle: X ), or tag  X  keyword combination (  X  X uthor:Cohen X ). One concrete example is  X  X ace + Recognition article: author:Cohen X . While [4] just replaces tag with label path. For exam-ple it uses  X (//article/title, Recognition) X  to confine the target nodes. We can see the essence of this kind of appending is just to help filter the leaf nodes. It is helpless to capture the structural hints the user need indeed. Other direct keyword query extenders [19,29,30] have similar limitations. 2.2 SLCA Problem Different from the keyword search in traditional Information Retrieval, the tar-gets of XML keyword search always are the XML fragments satisfying given keywords. [4,6,9] transform it as the SLCA problem, defined as Definition 1. Definition 1 (SLCA problem). Given one labeled directed tree, G = ( V G , E G , r , A ), and a sequence of keywords W = { k 1 , k 2 , ... , k k } ,theSLCA problem is to find all nodes which are the roots of all tightest XML fragments S = { S S 1. Each S i must include W ; 2. There is no any subtree in S i which includes W ; The circled part in Fig. 1(b) is the tightest fragment for keywords  X  X ohen Face Recognition X . The  X  X rticle X  node with Dewey code  X 0.0.0.1 X  is the SLCA node. The Dewey code for this SLCA node is just the common longest prefix of Dewey codes corresponding to  X  X ohen X  and  X  X ace Recognition X  nodes, whose Dewey codes are  X 0.0.0.1.0 X  and  X 0. 0.0.1.1.0 X  respectively. Th is obviously benefits from that Dewey encoding adopts the node path information into the codes [1].
By the way, we can see from Fig. 1(b) that the SLCA node for keywords has fixed structural relationship with the keyword nodes. We observe that the relative level information of SLCA nodes with the keyword nodes still keeps fixed even after we exchange the positions of keyword nodes. This simple observation triggers us to incorporate SLCA information in similarity measuring technique. More details are illustrated in Section 4. 2.3 Similarity Measures for XML Fragments After retrieving XML fragments for given keywords, the next important task is to rank them so as to return top targets to users. There are two kinds of techniques for this problem. The first is to use tree edit distance concept [31,32,33]. After proposing three edit operations (Relabel, Delete and Insert) and their operation cost, the distance between two unordered label trees, T 1 and T 2 , is defined as the smallest cost of transforming tree T 1 into T 2 just using the three operations mentioned above. We mark it as EDist ( T 1 ,T 2 ). Since the computation compli-cation of this kind of techniques, more researchers propose many approximate techniques for this problem.
 The related approximate similarity measures for this problem always inherit VSM (Vector Space Model) model [34] and TF  X  IDF concept [35], and can be categorized into four classes. Before the review of approximate similarity mea-in Fig. 5 here. The intention is to help readers intuitively understand the dif-ference of our KCAM and other methods at later discussion by real instances. The three fragments have same label domain,  X  { a, b, c, d }  X . The fragment in Fig. 5(a) is the source one. We achieve fragment in Fig. 5(b) by exchanging the position of  X  X 1 X  and  X  X 4 X  of Fig. 5(a). We can directly infer that two fragments of Fig. 5(a) and Fig. 5(b) are different in structure while having same text distrib-ution similarity. When we exchange the position of  X  X 2 X  and  X  X 3 X  in Fig. 5(a), we get the Fig. 5(c). The two fragments of Fig. 5(a) and Fig. 5(c) in fact are same in structure and text distribution similarity.

The four kinds of approximate techniques are:  X  Extended TF*IDF [29,12,36,5,18,7]. This kind of methods model XML frag- X  MLP model [13]. It has two parts to simulate the similarity between frag- X  Path bag model [17]. This kind of methods uses node label path distribution  X  Structural TF*IDF [37,11,14,15,16]. This kind of methods also absorb the
We can see that the prominent limitation of current work is their sensitivity with labels and relative node position. The essence of this limitation is induced by the structural simulation using label strings. To sum up, it is necessary to develop new similarity method mainly concentrating on structural feature of XML fragments. The new method should be independent of the labels and node position. It should also be easy to combine with other skills so as to satisfy users when they are interested in fragments with special labels. Our KCAM here is one example, we will discuss it in detail at Section 4.

Before that, we follow the tree edit distance concept and introduce ID edit distance of tree structure as the standard to illustrate the structural similarity between XML fragments, which is independent of node labels.
 Definition 2 (ID edit distance). The edit distance between two XML frag-ments, T 1 and T 2 , satisfying given keywords W , is denoted as EDist I,D ( T 1 , T ). It is the minimum cost of all ID edit sequences that transform T 1 to T 2 or vice versa. An ID edit sequence consists only of insertions or deletions of nodes: the popular edit distance with additional Relabeling. We can see that ED I,D ( T , T 2 ) mainly concentrates on the structure information. According to [35], the structural data processing has long been noticed. Regret-fully the languages developed for it are not satisfactory. For instance, since the concentrated data type at that time is mainly the Web data, Baeza  X  Yates, R. investigates the query languages developed for Web data, and concludes at page 392 that they are  X  X eant to be used by programs, not final users X . We can see from Section 2.1 that the XML Query (including XML IR/query) processing has similar suspicion. Though keyword search has not this kind of limitation, there is no structural hints in keywords either. This is a pity after all when adapting keywordsearchforsemi  X  structured XML data, in which structure plays a signif-icant role. During the reading of the book [35], one interesting idea come to my head, that is how about peeling off the labels from the XPath like queries, while at the same time keeping the keywords? This is the inchoation of the nesting keywords here.

In fact the concept of nesting keywords is simple. Its kernel is to organize the keywords also in nested form. For example we can use parentheses to bracket the interested keywords together. The artifice here is that the parentheses can be nested. Obviously this skill has the ability to endow the keywords with structural hints, since the XML specification uses this mechanism in same way. Besides this skill also is easy for common users to use. The most interesting thing about this skill is that it has great potential to describe query pattern, from pure keywords to part of XPath. 1. The simplest form of nesting keywords is that all keywords are bracketed 2. It is also easy to attach nesting keywords with labels or label paths.  X  X u-3. From the two skills mentioned above, we can see that though they have 4. When we add more complicated auxiliary information, nesting keywords
Though we can attach more additional information to expand the description power of nesting keywords, the interesting thing from above illustration is the endowed structural hints proposed in the third item (3) which is meaningful for XML keyword search. Since it implies structural hints in it and need not to know the labels, it not only can help common users to organize their queries in more accurate way, but also can conduct the subsequent processing in more affirmatory style. The latter advantage can be found from the KCAM X  X  usage in Section 4 when measuring the similarity between query keywords and the retrieved XML fragments. The kernel structure of our new similarity measure is the Keyword Common An-cestor Matrix (KCAM in short). It adopts the position independence of SLCA node with its leaf nodes. By transforming each XML fragment into its corre-sponding KCAM, the structural difference between XML fragments can be re-flected by the matrix distance of their corresponding KCAMs. The KCAM for one XML fragment satisfying given keywords is defined as follows.
 Definition 3 (KCAM). Given one keyword sequence W = k 1 ,k 2 ,  X  X  X  ,k k , T is one tightest XML fragment satisfying the keywords W .TheKCAM A for s is one k  X  k upper triangle matrix whose element a i,j ( 1  X  i  X  k, 1  X  j  X  k )is determined by following equation: According to the KCAM definition above, we can see that one KCAM cap-tures correlation relationship between keyword nodes, which is ignored in most approximate techniques mentioned in Section 2.3. After we get the KCAMs cor-responding to retrieved XML fragments, the structural difference between two arbitrary XML fragments can be deter mined by the matrix distance between their KCAMs. This distance is named as KDist(  X  ,  X  ), defined as follows. Definition 4 (KCAM Distance). Given one keyword sequence W = k 1 ,k 2 ,  X  X  X  ,k cording to KCAM definition above, we can construct two corresponding KCAMs, A T 1 and A T 2 . Then the KDist between A T 1 and A T 2 is defined as follows. Where the matrix norm used in Equation (1) is the Frobenius norm. Its calcu-lation is defined as follows. ( k  X  1) is one experiential factor so as to guarantee that KDist here is the lower bound of EDist I,D , that is KDist  X  EDist I,D . Its proof is omitted for room reason.
 Based on the two definitions above, we can easily discriminate the XML frag-ments proposed in Fig. 5. Their KCAMs are illustrated in Fig. 6. Based on the definition of KDist ( T 1 ,T 2 ), we can see the distance between Fig. 5(a) and Fig. 5(b) is Clearly we can use KCAM method to distinguish Fig. 5(a) and Fig. 5(b), and at the same time we will not classify Fig. 5(a) and Fig. 5(c) as same. KCAM mechanism has similar properties with MLP scheme proposed in [13]. MLP also has the ability to simulate the structural similarity, but is different from other methods in Extended TF  X  IDF , which essentially care the weight of keywords in retrieved fragments.Different from level information of our SLCA nodes, it uses the maximum length among all pathes from the node to its leaves. So MLP cannot distinguish the difference of fragments in Fig. 5(a) and Fig-ure 5(b). MLP is also independent of labels and node position. Finally, MLP can also be combined with other label filtering skill when users are interested more at specific domain. 5.1 System Architecture Finally the system architecture is illustrated in Fig. 7. Our experimental sys-tem mainly has two modules. One is the query processing module, which has two blocks, Query processor and Ranker. The other is the data management module, which is comprised of Dewey Index Management block and Indexer block. The former parses the nesting keywords, calculates SLCA nodes based on the retrieved Dewey codes from data management module, and uses KCAM in Ranker to measure the structural similarity of fragments. The latter is in charge with parsing the XML data in Indexer, and managing the indexed XML data in Dewey Index Management block.

We do not illustrate the computation details in each function block, for minded readers can find them when following the mathematical illustrations of this paper and the related references. The only thing reminded here is that we suggest that it is simpler to compute KDist using its matrix vector. We have following transformation from matrix to its vector according to matrix theory. So the matrix distance becomes the vector distance now. Since the algorithm design is quite straightforward following above mathematical equations, we omit the KCAM construction algorithm from this paper. 5.2 Experimental Environment Synthesized Dataset. Even though there are many ways to get experimental XML data, such as synthesized data from several tools (XMark, XMLGenerator), or some ready benchmark XML datasets (DBLP, Shakespeare, Sigmod, INEX), they are not adequate when to judge the performance of XML keyword searching methods. The reason is that they are difficult to control the node number for specific keyword, such as we need 20,0000 nodes for  X  X ibliography X . So in this paper we verify the efficiency of our KCAM method on synthesized XML data made as follows. 1. We first choose one XML fragment with k leaf nodes, G =( V G , E G , r , 2. We construct the first fragment template by inserting one Dummy node as 3. Randomly select one template from TS , and run one step of following three
We explain the procedure using Figure 8. Fig. 8(a) is the initial template fragment. The Dewey codes of n 1 , n 2 , n 3 , n 4 , n 5 are  X 0.0.0.0.0 X ,  X 0.0.0.0.1.0 X ,  X 0.0.0.0.1.1 X , X 0.0.1.0 X  and  X 0.0.1.1.0 X  respectively. Figure 8(b) illustrates the fragment after one Copying action on Fig. 8(b). Since the current value of the counter is 1, the integers of all Dewey codes at 2 nd level is changed to  X 1 X . Figure 8(c) shows the fragment after one Shuffling action of n 1 and n 3 on Fig-ure 8(a). Figure 8(d) and Figure 8(e) correspond to two new fragments after inserting new nodes respectively. The former is to insert node at 1 st position on Dewey code  X 0.0.0.0 X . Since all Dewey codes are descendant of Dewey code  X 0 X , they are all refreshed. The latter is to insert new node at 5 th position on Dewey code  X 0.1.0.0.1.0 X . We can see that only  X 0.0.0.0.1.0 X  and  X 0.0.0.0.1.1 X  are refreshed because only the y are the descendant of  X 0.0.0.0.1 X .
From the Fig. 8 we can see that the synthesized fragments are random not only on structure, but also on level distribution of SLCA nodes.
 Configurations for Experiments. Since the description capability of nesting keywords is clear, the goal of experiments here is to verify the effectiveness of KCAM mechanism by comparing it with other methods. Regretfully as we inferred from Section 2.3, only extended TF  X  IDF methods and MLP are not sensitive to label or node position. Since MLP has similar computation with methods in extended TF  X  IDF , and it is independent of labels and node position, we choose MLP as the comparison object with our KCAM.

The experimental dataset is constructed by following instructions mentioned above. We first build several template fragments like Fig. 8(a), and then in-crease the number of fragments by randomly shuffling the keyword position and inserting new node. There are four parameters to control the fragments. One is keyword number (10 in our experiment). The second is the number of template fragments. The third is the times of randomly insertion. We set it as 20. The last one is the exchange times among keywords for each template fragments and their variants after insertion.

After getting synthesized dataset, we do two kinds of experiments. The first one is for structural sensitivity. We randomly select 10 groups, each of which has 30 fragments. We carry out KCAM and MLP on them, record the ratio of the precision values between KCAM and MLP, and illustrate the average statistic. The second kind is for the performance scalability. We separate the dataset into 9 groups, from 5000 to 45000. We run both methods on each group, and illustrate the running time of each method.

All experiments are run on a Dell Dimension 8100 computer with 1.4GHz Pen-tium IV processor and 256MB of physical main memory. The Operating System is Windows 2000 Professional. We use JAVA as the programming language. The JDK is Java 2 SDK Standard Edition Version 1.4.1. We execute each test 6 times with the performance result of the first run discarded. 5.3 Experimental Result Fig. 9 is the result for precision comparison of KCAM and MLP. When the number of keywords is specified, we run MLP and KCAM on the sampled XML fragments. After we obtain the precision of KCAM and MLP, we get the ratio of the two precision values corresponding to the two methods. From Figure 9 we can see that the KCAM/MLP precision ratio is adjacent when the keyword number is small. While the ratio become larg er when the keyword number increases. This evolution verifies that KCAM method is more sensitive with the structural differences than MLP method.

Fig. 10 illustrates the runtime performance result of the two methods. We first construct two kinds of synthesized data corresponding to 5 and 10 keywords with different number of fragments from 5000 to 45000. Then we run KCAM and MLP respectively on the datasets.  X  X CAM5Key X  and  X  X CAM10Key X  mean that there are 5 and 10 keywords in all fragments when running KCAM.  X  X LP5Key X  and  X  X LP10Key X  mean that there are 5 and 10 keywords in all fragments when run-ning MLP. From Figure 10 we can see that when the number of keywords is small, KCAM has comparatively performance with MLP even there are 45000 frag-ments. When there is many keywords, the performance of KCAM becomes lower than MLP, and the gap becomes larger and larger as fragment number increases. Though the performance of KCAM is lower than MLP from Figure 10, KCAM X  X  merit is still obvious according to Figure 9, that is KCAM has more power to distinguish the structural difference. Besides, we notice that the largest cost of KCAM performance is lower than 12,000 millisecond. This shows that the computation of KCAM is still efficient and has pragmatic value for real application. In this paper we reconsider the keyword processing on XML data. Seeing that the current XML keyword extensions lack structural information, we propose nest-ing keywords mechanism so as to endow keywords with structural hints. Though this mechanism has simple concept, it is significant not only for common users but also for similarity measures of retrieved XML fragments. When using nesting keywords to retrieve information from XML database, the retrieved XML frag-ments can be from different schemas (Pure keywords has same property). But current similarity measures are incapable for this situation: they are either insen-sitive for subtle structural differences between fragments, or too sensitive with labels and node positions. Aiming at this problem, this paper proposes KCAM distance method. Its kernel is keyword common ancestor matrix, in which each element stores the level information of SLCA node corresponding to keyword nodes in XML fragments. Since the level information of SLCA node implies the relative position information between keyword nodes, KCAM can capture struc-tural information of XML fragment. Therefore the matrix distance between two KCAMs can be used to reflect the structural difference of the two corresponding XML fragments.

Our future work will concentrate on the data redundancy problem in cur-rent XML data processing systems. During the realization of our experimental system, we investigate the developed XML systems. We find there is data redun-dancy in current XML data processing scheme. That is the XML Query type processing (including XML IR/query) and XML IR/keyword type processing have their own particular XML data representation in their realization. Conse-quently when querying one XML data in different query schemes, there must be two copies of this XML data in the two processing types. Part of our future work attempts to cope with this redundancy.

