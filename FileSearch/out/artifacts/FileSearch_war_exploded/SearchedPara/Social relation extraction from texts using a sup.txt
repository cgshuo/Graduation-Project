 1. Introduction
The rapid evolution of social networking services such as Twitter ( http://www.twitter.com ) and Facebook ( http:// www.facebook.com ) has led to many studies on social network analysis (SNA) in various areas such as business economics, Etzioni et al., 2005; Wasserman &amp; Faust, 1994 ). These studies have focused on link analysis in pre-constructed social net-works. However, in natural-language documents, a huge number of social relations are not constructed into a network form. Automatic extraction of social relations from such documents would be highly beneficial to SNA studies. Fig. 1 shows our proposed system that automatically extracts social relations between people from natural-language documents using sup-port vector machines (SVMs).

The proposed system first selects those sentences that describe social relations between two people from the many sen-tences found in documents. We refer to this step as the sentence selection module. The system then extracts relation names from the selected sentences, i.e., keywords associated with social relations. We refer to this step as the relation-name extrac-tion module. Next, the system stores triple sets that comprise one person X  X  name, a relation name, and the other person X  X  name into a relations database. Finally, the system visualizes the stored triple set as a network form using commercial soft-son-relation-person) to SNA systems. Therefore, the completeness of a generated social network depends on the accuracy of a key person, the load balancing of a key person, and the degree of relatedness between two people. To alleviate this prob-lem, we enhanced the performance of sentence selection and relation name extraction using two newly designed SVM  X  kernels that reflect the syntactic structure between words in a sentence, because the names of two people sharing a social relation in a sentence are syntactically associated with each other. The current version of the proposed system operates in
Korean, but we believe that any language can be used because the system uses conventional natural language processing (NLP) techniques.
 our social relation extraction system. In Section 4 , we analyze the results of our experiments. Finally, we present conclusions in Section 5 . 2. Previous works are representative rule-based models. These rule-based models use numerous lexico-syntactic patterns for relation extrac-tion. This makes it difficult to scale the coverage of relation types and change the domains of application in these models. To overcome this problem, Etzioni et al. (2005) and Matsuo et al. (2006) proposed semi-supervised models, KnowItAll and
POLYPHONET, which label training examples using only a small set of domain-independent extraction patterns in a Web-scale corpus, respectively. DIPRE, Snowball, and KnowItAll have limitations in that they are all relation-specific models in which the set of relations has to be named by the human user in advance. Banko et al. (2007) proposed a relation-nonspecific model, TextRunner, which learns and extracts relation names from texts. Based on Banko et al. (2007)  X  X  proposals, we pro-pose a relation-nonspecific model that automatically selects keywords associated with relation names from input sentences because our goal is to find non-predefined social relations hidden in news articles. Feature-based models use various linguis-tic features such as lexical information, syntactic relations, and semantic knowledge for this purpose. These models can ex-hibit good performances, but they require considerable manual effort for calibrating diverse features. Furthermore, they cannot fully explore the structural syntactic information, which is significantly important in relation extraction requiring a linear consideration of the various linguistic feature levels. Recently, kernel-based models were proposed to overcome the problems of feature-based models. Kernel-based models use tree kernels to determine whether two entities are struc-turally associated with each other. Zelenko, Aone, and Richardella (2003) developed a relation kernel for the shallow parse representations of text. This kernel recursively matches all nodes from roots to leaves between two parse trees and computes similarities on the basis of the agreement rate for the path information from the roots to the current nodes. Culotta and Sorensen (2004) developed a relation kernel on the basis of the dependency trees of sentences. Zelenko et al. (2003) and Culotta and Sorensen (2004) outperformed the previous feature-based models, but they are computationally burdensome with respect to the complete estimation of the similarities between the trees of sentences. To overcome this problem, Bune-scu and Mooney (2005) developed a shortest path kernel that compares all the nodes in the shortest paths between two enti-ties in dependency trees. The shortest path kernel model showed the best results in terms of both computational complexity and performance ( Bach &amp; Badaskar, 2007 ). The previous kernel-based models suggested the possibility of using structural syntactic information, but they exhibited low recall rates owing to hard-matching constraints between the comparisons of two target sub-trees. Previous tree kernels required that two sub-trees share the same depth or length. To resolve this problem, we propose two types of dependency trigram kernels to efficiently compute the structural similarity between pairs of dependency trees. We then implement a social relation extraction system using the proposed kernels. 3. Social relation extraction using dependency trigram kernels 3.1. Dependency trigram kernel for selecting sentences containing social relations
Although the shortest path kernel model ( Bunescu &amp; Mooney, 2005 ) among the previous kernel-based models has stood out as the best in terms of computational complexity and performance, the shortest path kernel model can lead to low recall rates because it requires two of the shortest dependency paths sharing the same length. For example, the two sentences,  X  X  X im gave Lee money X  X  and  X  X  X ee received Kim X  X  money X  X  share the same meaning. However, their dependency trees are dif-ferent, as shown in Fig. 2 .

The shortest dependency paths between the two entities  X  X  X im X  X  and  X  X  X ee X  X  have different lengths:  X  X  Kim ? gave Lee  X  X  in the first sentence has a length of three, whereas  X  X  Lee ? received money Kim  X  s  X  X  has a length of four. To relax this con-straint, we propose a dependency trigram kernel where the comparison targets always share the same path length.
Given n words w 1, n in a sentence S , let w i denote the i th word in the sentence. The dependency relations between the n words can be represented as shown in Fig. 3 .
 dent word and the head word, respectively. If w i and w j are both entity words with a relation and if w k is the first common head word of w i and w j , we can define a dependency trigram set for the sentence S , S T , by selecting sentences with social relations, as shown in following equation where S T 1  X f w i ! w k w j j i &lt; j g , S T 2  X f w l ! w k w r j l &lt; r and 8 w l ; w r  X  child  X  w k  X g .
In Eq. (1) , w l and w r are child nodes that are both directly dependent on w k . For example, if we represent the two sen-tences in Fig. 1 using Eq. (1) , the dependency trigram sets are as follows: { Kim ? gave Lee , Kim ? gave money , Lee ? -gave money } and { Lee ? received Kim , Lee ? received money }. Thus, we can design a dependency kernel function that uses the defined dependency trigrams as function inputs, as shown in following equation In Eq. (2) , A and B are input sentences of the kernel function K that consist of n and m dependency trigrams, respectively. A i score between A i T and B j T . Briefly, Eq. (2) provides the mean score of maximum similarity values among all combinations of A and B j T , as shown in following equation
In Eq. (3) , a q is a weight value for the q th of the r attributes. A i T dependency trigram A i T , respectively. N q  X  A i T bute of A i T matical role X  X  can be obtained with a dependency parser. In the case of Korean language, this can be particularly easy to de-cide by using case markers because this language has well-developed morphemic markers. In the previous shortest path kernel ( Bunescu &amp; Mooney, 2005 ), a q was always 1. However, we consider that each attribute should have different impor-tance because their contributions differ from each other when selecting sentences with social relations. For example, when determining whether the sentence  X  X  X  gave the money to him X  X  contains a social relation, the lexical information  X  X  X ave X  X  pro-vides a more important indication than the part-of-speech (POS) information  X  X  X erb. X  X  Information theory states that more specific values for a random variable equates to more information. Based on information theory ( Gray, 2000 ), we can assign each a q with weighting values (so-called attribute weights) using the following equation: attribute. MaxE and MinE are normalizing factors denoting the maximum and the minimum of all the entropies of attributes (i.e., among r entropies). Using this normalization, a q is estimated to have a value ranging from 1.0 to 2.0. 3.2. Dependency trigram kernel for extracting names of social relations 2007 ). ACE07 (the 2007 release version of ACE) contains documents in English (approximately 70,000 words), Arabic, and
Chinese, assembled from various sources selected from newswires, broadcast news, weblogs, conversational telephone speech transcripts, and so on. Information extraction tasks in the ACE program are grouped into three objectives: entity detection and recognition (EDR), relation detection and recognition (RDR), and event detection and recognition (VDR). This paper is tightly associated with the second task, RDR. In the ACE corpus of RDR, relation names are classified into five types: tion is slightly different in the case of SOCIAL in the ACE corpus. SOCIAL in the ACE corpus represents simple personal and professional affiliation between two people, but one of the goals of the proposed system is to find more complicated and meaningful connections between two people. Table 2 shows some categories of relation names that the proposed system aims to extract from news articles.
 extracts only those relation names that are included in the abovementioned five categories. The proposed system extracts relation names without any category restrictions because it is a relation-nonspecific model.
After selecting the sentences containing social relations, the proposed system extracts relation names from the selected sentences using the dependency kernel function, Eq. (2) . The proposed system uses the same dependency kernel, but the inputs for the kernel function are quite different from those used for selecting sentences with social relations. The role of the SVM kernel during sentence selection is to determine whether two entity words are associated. Therefore, combinations of two entity words and their common head word will be important indicators for solving the sentence selection problem. However, the role of the SVM kernel during relation name extraction is to extract keywords (i.e., relation names) that indi-cate social relations in a sentence. To overcome this keyword extraction problem, we assume that a relation name has a short-distance dependency relation with the common head word of two entity words. In other words, a relation name is lo-cated close to the common head word of two entity words in a dependency tree. On the basis of this assumption, we define a dependency trigram set for the sentence S , S N , to extract relation names, as shown in following equation parentw p  X g S N 3  X f w c 0 ! w c w k j c  X  i  X  j and 8 w c  X  child  X  w k  X  and 8 w c 0  X  child  X  w c  X g .
 trigram sets are given as follows: { Kim ? gave NULL , Lee ? gave NULL , money ? gave NULL , NULL ? money gave } and { Lee ? received NULL , money ? received NULL , Kim ? money received }. In this example, NULL indicates that a node does not exist. We then design a dependency kernel function using the defined dependency trigrams as function inputs, as shown in following equation are different. A kernel function must map a whole sentence into a single point in the vector space for the sentence selection problem, as shown in Eq. (2) . However, a kernel function simply needs to map each trigram into a single point in the vector are selected using Eq. (3) . If two or more keywords are classified into a positive group (i.e., relation-name candidates) using the proposed kernel function, the proposed system selects the relation name as the one with the most positive SVM output from the keywords. 4. Evaluation 4.1. Data sets and experimental settings
To evaluate the proposed system experimentally, we used two types of test collections: the well-known ACE corpus, spe-cifically version 1.0 of the ACE 2 corpus, with English sources ( NIST, 2007 ); and a Korean news corpus that contains 1540 sentences. In the case of the Korean news corpus, we collected 8000 Korean news articles from a website (NAVER news; http://news.naver.com ). We randomly selected 770 sentences (about 17.86 words per sentence) describing the social rela-tions between two people. We referred to these selected sentences as the person-person relation (PPR) corpus. We also ran-domly selected 770 sentences (about 16.20 words per sentence) containing two people X  X  names, but with no social relations describing them. We refer to these selected sentences as the non-PPR corpus. Finally, we manually marked words associated with social relation names in each sentence of the PPR corpus. Manual marking was performed by a graduate student major-ing in NLP. Table 3 shows the category distribution of relation names in the PPR corpus.

To test the sentence selection model, we merged the PPR corpus with the non-PPR corpus. We then performed a 10-fold cross validation on the merged corpus (1540 sentences). We also performed a 10-fold cross validation on the PPR corpus to = 1.14, and a 3 = 1.43 X  X  for the sentence selection module and  X  X  a 1 = 2.00, a 2 = 1.08, and a 3 = 1.53 X  X  for the relation-name extraction module. We implemented our system by replacing the default kernels of LibSVM ( Chang &amp; Lin., 2001 ) with the proposed dependency trigram kernels. In order to conduct the experiment with the ACE corpus, we used a Stanford depen-dency parser ( Marneffe, MacCartney, &amp; Manning, 2006 ). Further, we modified the sentence selection module to handle mul-tiple categories. In other words, the modified sentence selection module could return category names (if a sentence did not have any relations, it returned  X  X  X ut-of-category X  X ) in the ACE corpus as well as binary results regarding whether the input sentences described social relations or not. For the experiment with the Korean news corpus, we conducted a linguistic anal-ysis using a Korean POS tagger (precision = 95%) based on a hidden Markov model, and we used a Korean dependency parser (precision = 85%) based on a cascaded chunking method ( Abney, 1991; Kudo &amp; Matsumoto, 2002 ). 4.2. Experimental results modified sentence selection module with previous relation extraction systems by using the ACE corpus. The other scenario was to measure the real performances of social relation extraction from news articles by using the Korean news corpus. The second scenario was again divided into two steps. The first step was sentence selection, wherein we determined whether the proposed system could correctly classify the input sentences into two categories, the PPR category and the non-PPR category.
The second step was the relation-name extraction, wherein we determined whether the proposed system could correctly extract words describing social relations from the sentences classified into the PPR category.
 extraction systems in the ACE corpus.
 class SVM is learned to discriminate among the top five classes (i.e., ROLE, PART, AT, NEAR, and SOCIAL) and one more class except that it first selects sentences with relations and then discriminates among the top five classes. Bunescu X  X  systems exhibited the best performances in the previous review of the relation extraction methods ( Bach &amp; Badaskar, 2007 ).
Wang-2008 indicates a relation extraction system based on a convolution dependency path kernel, which is known as well relaxing the same length constraints of the shortest path kernel ( Wang, 2008 ). Hong-2005 indicates a feature-based relation extraction system that uses lexical tokens, syntactic structures, semantic entity types, and distances between entities as in-puts of an SVM ( Hong, 2005 ). DepTri4SS once and DepTri4SS twoStep were learned by using the same methods with Bunescu-erably higher recall rate than the precious systems. Consequently, their high recall rates resulted in the best F1 scores. More-over, DepTri4SS once and DepTri4SS twoStep have an advantage that they use only low-level lexico-syntactic knowledge such as lexemes, POS tags, and grammatical roles, as compared with the previous systems that use high-level semantic knowledge such as named entity categories and WordNet synsets ( Miller, Beckwith, Fellbaum, Gross, &amp; Miller, 1990 ). This advantage is known to increase domain portability and decrease the effort related to a language change. When Bunescu X  X  system did not use such high-level semantic knowledge as the input features of the SVM kernels, it exhibited very low recall rates, as shown in the first row of Table 2 . Therefore, we conclude that the proposed trigram kernel is more suitable to accomplish relation extraction tasks in languages in which high-level knowledge resources are insufficient.
 tem that used a dependency kernel-based method in the Korean news corpus.

In Table 5 , Bunescu4SS indicates a sentence selection module implemented using the shortest path kernel where the same input features (i.e., lexeme, POS tag, and grammatical role) with the proposed system were the inputs ( Bunescu &amp; Moo-ney, 2005 ). DepTri4SS indicates the proposed sentence selection module. DepTri4SS wgt1 indicates DepTri4SS where the attri-bute weights were all set to the same value of 1. DepTri4SS gold indicated DepTri4SS where the results of perfect linguistic analysis ( i.e. , correct POS tags and correct dependency trees) were the input. Table 5 shows that the proposed system out-performed Bunescu4SS using a similar dependency kernel-based method, especially in terms of recall rates. This suggests that the proposed trigram kernel can effectively relax the same length constraints as Bunescu-2005. DepTri4SS generally delivered better performance than DepTri4SS wgt1 . To validate the performance differences statistically, we performed a Stu-dent X  X  t -test and obtained p -values. The p -values of accuracy, precision, recall rate, and F 1 measure were 0.1007, 0.0062, this suggests that the proposed attribute weights contribute to the precision improvement in kernel-based classification models. DepTri4SS gold always showed much better performances than the other systems. This suggests that an increase in the performance of the underlying linguistic analyzers leads to a similar increase in the performance of DepTri4SS.
Table 6 shows the relation name extraction performance of the proposed system in comparison with a simple baseline system in the Korean news corpus.

In Table 6 , ComHead indicates a system that extracts a common head word for two entities as a relation name. DepTri4NE indicates the proposed relation name extraction module. DepTri4NE wgt1 indicates DepTri4NE where the attribute weights were all set to the same value of 1. DepTri4NE gold indicates DepTri4NE where the results of perfect linguistic analysis were the input. Table 6 shows that the proposed system outperformed ComHead in terms of precision and recall rate. This sug-gests that expectation that common head words (usually verbs) will be relation names was incorrect. DepTri4NE showed better performances than DepTri4NE wgt1 and the performance difference was larger than that between DepTri4SS and Dep-Tri4SS wgt1 . The p -values of accuracy, precision, recall rate, and F 1 measure were 0.0040, 0.0004, 0.4925, and 0.0149, respectively. This implies that the performance differences, except that of recall rate, are statistically significant at the 0.01 level. In other words, this suggests that the proposed attribute weights made a greater contribute to performance improvement in kernel-based extraction models. Like DepTri4SS gold , DepTri4NE gold always delivered much better perfor-mance than the other systems.

Tri4SS using only  X  X  X  showed a better performance, except for recall rates, than that using  X  X  + P + G X . This result shows that lexical attributes contribute greatly to the precision improvement but the other attributes, such as POS tags and grammatical roles, are needed to improve the recall rates in DepTri4SS. DepTri4NE using  X  X  + P + G X  showed the best performances, as we expected. This result shows that all the attributes used contribute to the performance improvement in DepTri4NE. In Dep-
Tri4SS and DepTri4NE,  X  X exeme X  contributed most to improving the performances. The degree of attribute importance was as follows:  X  X exeme X  &gt;  X  X art-of-speech tag X  &gt;  X  X rammatical role X .
 ysis, NetMiner ( http://www.netminer.com ), which was developed by Cyram Co. ( http://www.cyram.com ). Fig. 4 shows that it was simple to combine the proposed system with a social network analysis tool. Using the combined system, we obtain analytical results, such as the people who played hub roles in the social network, and which people connected the sub-networks. 4.3. Failure analysis tion. We also identified the main reasons for incorrect results, which were as follows: 5. Conclusions
We propose a social relation extraction system based on dependency kernels of SVMs. The proposed system first classifies input sentences into two groups: one group with social relations and the other group without social relations. The system then extracts relation names from sentences in the group with social relations. To effectively perform these two processes, we designed new SVM kernels referred to as dependency trigram kernels. Experiments showed that the newly designed ker-nels could relax the hard-matching constraints of the shortest path kernel. On the basis of these experiments, we consider that the proposed system can be used as a tool for automatically constructing social networks from texts.

In the future, we will study a method for detecting person-to-person relations outside sentence boundaries using co-ref-erence resolution techniques ( Brown, 2011 ). In addition, we will study a threshold method for selecting the reliable outputs from among those of the proposed system in order to avoid the errors of the proposed system being propagated directly to a rear-end SNA system.
 Acknowledgments
This research was supported by Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education, Science and Technology (No. 2010-0009875).
 References
