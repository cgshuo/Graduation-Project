 Search engine switching describes the voluntarily t ransition from one Web search engine to another. In this paper we present a study of search engine switching behavior that comb ines large-scale log-based analysis and survey data. We charac terize aspects of switching behavior, and develop and evaluate pre dictive mod-els of switching behavior using features of the act ive query, the current session, and user search history. Our findi ngs provide insight into the decision-making processes of searc h engine users and demonstrate the relationship between switching and factors such as dissatisfaction with the quality of the res ults, the desire for broader topic coverage or verification of encounter ed information, and user preferences. The findings also reveal suff icient consis-tency in users X  search behavior prior to engine swi tching to afford accurate prediction of switching events. Predictive models may be useful for search engines who may want to modify th e search experience if they can accurately anticipate a swit ch. H.3.3 [ Information Search and Retrieval ]: search process . Measurement, Experimentation, Human Factors. Search engine switching. Search engines such as Google, Yahoo!, and Live Sea rch facilitate access to the vast quantities of information presen t on the World Wide Web. A user X  X  decision to select one search en gine over another can be based on factors including reputatio n, familiarity, effectiveness, and interface usability [19]. Search ers may not use the same engine for all queries; they often switch between differ-ent engines within and between sessions [14,18,21]. Previous work on switching has promoted multiple search engi ne use [22], predicted when users are going to switch [11,15], s tudied switch-ing to develop metrics for competitive analysis of engines in terms of estimated user preference and user engagement [1 4], or built conceptual and economic models of search engine cho ice [18,21]. However, despite the economic significance of engin e switching to search providers, and its prevalence among engin e users, little is known about the rationale behind switching, the behavior itself, or the features most useful in predicting switching events. In this paper, we present research on the character ization and prediction of search engine switching behavior. We focus on switches within a session rather than between-sessi on switches (that may be task-oriented) or long-term switches ( that may represent significant shifts in user preferences or settings). With-in-session switching is most common and allows us t o study the antecedents of switching in more detail. We use two complimen-tary methods  X  large-scale log analysis and user survey data provide a rich picture of switching behavior. Log d ata enables us to examine patterns of behavior for large numbers o f individuals, and the survey data enables us to understand some o f the rationale behind the observed patterns. The reasons behind th e switches, such as user frustration, a desire for topic covera ge or fact verifi-cation, prior experience, and interface usability, are challenging to reliably study in logs but can be identified in sur vey responses. In addition to characterizing switching behavior we also investi-gate the effect of different features on the accura cy of switch pre-diction models. We build models with rich sets of f eatures derived from the active query, recent interaction behavior from within the current search session, and/or the user X  X  long-term search history. Earlier work on switch prediction applied data mini ng techniques to user actions encoded as character sequences [11, 15]. However, such sequences are only one way to represent intera ction behavior and may not always be available to search engines. It is therefore important to understand what other features can yie ld accurate switch predictions. We extend previous switch predi ction research using a broad set of features derived from our log and survey analysis. Through our methodology we characterize p roperties of queries, sessions, and user histories that are pote ntially useful in prediction. A better understanding of which feature s contribute most to improving prediction accuracy can yield pow erful models that do not depend on complex representations of us er interaction history, making them more attractive for large-scal e deployment. The remainder of this paper is structured as follow s. Section 2 outlines previous work on predicting query difficul ty and charac-terizing search engine switching behavior. Section 3 provides an overview of the log-based analysis and survey metho dologies. In Section 4 we characterize switching behavior, inclu ding aspects of the pre-and post-switch interaction. In Section 5 we investigate the predictive value of query, session, and user fe atures in isola-tion and combination. We discuss our findings and t heir implica-tions in Section 6 and conclude in Section 7. Two lines of work are relevant to our research: pre dicting query difficulty and characterizing search engine switchi ng behavior. There is an established record of research in infor mation retrieval that addresses the challenge of predicting query pe rformance, and the influence of different query representations or document re-presentations on such performance. A high-level goa l of that work is to understand differences in performance across queries to de-vote additional resources or use alternative method s, as appropri-ate, to improve the overall search experience. For example, if a system knows which queries are difficult, it could devote addi-tional resources to enhancing search results for th ose queries, or if a system knows which algorithms work best for a par ticular query, it could improve performance by selecting th e most appro-priate algorithm for each query. While it is easy t o show that us-ing different query representations [2] or retrieva l models [1] can improve search performance, it is more challenging to accurately predict in advance which methods are most appropria te. Measures such as query clarity [6], Jensen-Shannon divergence [4], and weighted information gain [23] have been d eveloped to predict performance on a query (as measured by aver age preci-sion, for example). Leskovec et al. [16] used graph ical properties of the link structure of the result set to predict the quality of the result set and the likelihood of query reformulatio n. Teevan et al. [20] developed methods to predict which queries cou ld most ben-efit from personalization. In research more closely related to search engine switching, White et al. [22] develope d methods for predicting which search engine would produce the be st results for a query. For each query they represented features o f the query, the title, snippets and URLs of top-ranked documents, a nd the results set, for results from multiple search engines, and learned a model that predicted which engine produced the best resul ts for each query. The model was learned using a large number o f queries for which explicit relevance judgments were available. One way in which such results could be leveraged is to promote the use of multiple search engines on a query-by-query basis, using the pre-dictions of the quality of results from multiple en gines. A user X  X  decision to use one search engine over ano ther is depen-dent on many factors including reputation, familiar ity, retrieval effectiveness, and interface usability [19]. Simila r factors can influence a user X  X  decision to switch from one sear ch engine to another, either for a particular query, a particula r task if another engine specializes in such tasks, or more permanent ly, as a result of unsatisfactory experiences or relevance changes, for example. Some research has examined engine switching behavio r. Some of the earliest research in this area was by Mukhopadh yay et al. [18] and Telang et al. [21]. They used economic models o f choice to understand whether people developed brand loyalty t o a particular search engine, and how search engine performance (a s measured by within-session switching) affected user choice. They found that dissatisfaction with search engine results had both short-term and long-term effects on search engine choice. The data set is small by modern log analysis standards (6,321 search engine switches from 102 users), somewhat dated (data from June 1998  X  J uly 1999 including six search engines but not Google), and o nly summary-level regression results are reported. Juan and Che ng [14] de-scribed some more recent research in which they sum marize user share, user engagement and user preferences using c lick data from an Internet service provider. They identify three u ser classes (loyalists to each of the two search engines studie d and switchers), and look at the consistency of engine usage pattern s over time. Neither of these studies addressed the challenge of predicting switch behavior. Accurately predicting if a user is about to switch allows the search provider to offer additional sear ch support. Heath and White [11] and Laxman et al. [15] develop ed models for predicting switching behavior within search ses sions using sequences of user actions ( e.g. , query, result click, non-result click, switch) and characteristics of the pages vis ited (type of page and dwell time) as the input features. Heath and Wh ite [11] used a simple threshold-based approach to predict a switch action if the ratio of positive to negative examples exceeded a t hreshold. Using this approach they achieved high precision for low recall levels, but precision dropped off quickly at higher levels of recall. Work-ing with the same data, Laxman et al. [15] develope d a generative model based on mixtures of episode-generating Hidde n Markov Models and achieved much higher predicative accurac y. The re-search reported in this paper is similar to this li ne of work, but extends it in several ways. We use a richer set of features to cha-racterize properties of the query, the search sessi on, and the user. We compliment a large-scale log study with a survey to develop insights about people X  X  motivations for switching a nd characteris-tic behaviors, which we use to develop more abstrac t features such as  X  X everal related queries in quick successio n without clicks X . We also observe user behavior over a longe r period of time (six months), and study both pre-and post-swi tch behaviors. We now describe the log analysis and user survey us ed as the basis for our characterization of switching behavio r. We collected data from two complimentary methods  X  large-scale log analyses and a user survey or questionnaire. Th e log analyses provide insight into a range of user activities in situ. The survey provides insight into the reasons for the observed behaviors. [10, 13] have more on combining logs and other data capt ure methods. We analyzed six months of interaction logs from Sep tember 2008 through February 2009 inclusive, obtained from hund reds of thou-sands of consenting users through a widely-distribu ted browser toolbar. These log entries include a unique identif ier for the user, a timestamp for each page view, a unique browser wi ndow iden-tifier (to resolve ambiguities in determining which browser a page was viewed), and the URL of the Web page visited. I ntranet and secure (https) URL visits were excluded at the sour ce. In order to remove variability caused by geographic and linguis tic variation in search behavior, we only include entries generat ed in the Eng-lish speaking United States locale. Any personally identifiable information was removed from the logs prior to anal ysis. From these logs we extracted search sessions . Every session began with a query issued to Google, Yahoo!, or Live Search and could con-tain further queries or Web page visits. A session ended if the user was idle for more than 30 minutes. Similar criteria have been used in previous work to demarcate search sessions, e.g. , [7]. We compliment our log analysis with a survey of use rs X  expe-riences with search engine switching. We distribute d the survey via email to 2,500 randomly-selected employees with in Microsoft Corporation. 488 employees completed the survey, fo r a response rate of 19.5%. The survey contained a mixture of op en and closed questions. We were particularly interested in elici ting responses concerning the rationale behind engine switching si nce this is something that the log data does not provide. We al so asked ques-tions regarding the frequency with which people swi tched en-gines, characteristics of their most recent switchi ng episode, and patterns of activity that preceded switching events . Five-point scales were used where appropriate, with: Never , Rarely , Some-times , Often , Always used to elicit frequency information. We now analyze our logs and survey data with the ob jective of characterizing aspects of switching behavior. We fi rst present an overview of the log data and the survey data. We th en focus on aspects of the search behavior prior to the switch, including com-mon actions, temporal dynamics, and significant use r action se-quences. In addition, we study post-switch behavior , including post-switch activity and estimates of post-switch u ser satisfaction. From the logs described in the previous section we extracted 1.1 billion search sessions beginning with a query to G oogle, Yahoo! or Live Search in the six month duration of the stu dy. A search engine switch occurs if consecutive queries within a session are issued to different engines ( e.g. , query Google then query Live). Of the 1.1 billion search sessions, 42.9 million (4 .0%) contained at least one search engine switch between two of th e three en-gines, and 10.8 million (25.1%) of those switching sessions had multiple switches. In total, we observed 58.6 milli on instances of search engine switching behavior comprising 1.4% of all Google, Yahoo!, and Live queries in the six-month period. O f all switches, 7.4 million (12.6%) exhibited the same query on the pre-switch and post-switch engines. As noted above, search engine switches were observe d in 4% of all search sessions. However, switches are more lik ely to occur for longer search sessions. Figure 1 shows the probabil ity of switch-ing, P(Switch) , for sessions of varying length, as measured by th e number of queries in the session. As search session length increases, perhaps because of the nature of the user X  X  task or the quality of search results , the likelihood of switching also increases. For sessions that include five or more queries, switches occur approximately 10-14% of the time. Of the 14.2 million users in our log sample, 10.3 m illion (72.6%) used more than one engine in the six-month duration of the logs, 7.1 million (50.0%) switched engines within a searc h session at least once, and 9.6 million (67.6%) used different engines for different sessions ( i.e. , engaged in between-session switching). In addition, 0.6 million users (4.4%)  X  X efected X  1 from one search engine to another and never returned to the previou s engine. Although search engine switching describes the acti vity of volun-tarily shifting from one search engine to another, the switch itself can happen in at least three ways: Our definition of defection was a switch from one engine to another, issuing at least one additional query on t he post-switch engine, and never returning to the origin engine. M ore relaxed variants of these criteria would likely yield more defections. 1) Browser : Issue query directly from a browser search box or 2) Navigate : First visit search engine homepage via the browse r 3) QueryToNavigate : First query for a search engine name ( e.g. , A switching event is defined as any of these three switch types. In the 58.6 million examples of switching behavior these switch types were distributed as follows: Browser is 69.2%, Navigate is 18.3%, and QueryToNavigate is 12.5%. It appears that browser search boxes and optional browser toolbars facilita te search en-gine switching behavior. Navigate and QueryToNavigate both rely on the explicit recall of the destination engine na me or URL by the user before the switch can occur. This presents a possible bar-rier to switching in this way. In contrast, Browser requires only user recognition of an engine in a list of search p roviders or switching cues provided to users when searching on other engines. 70.5% of survey respondents reported that they had switched be-tween different search engines either within or bet ween sessions. This percentage is remarkably similar to the percen tage (72.6%) observed in the log-based analysis reported in the previous sec-tion. This increased our confidence about the consi stency of the two data sources used for this study. The responden ts who did not switch did so because they were satisfied with the engine they used (57.8%), they believed that no other engine wo uld perform better (24.0%), or felt that it was too much effort to switch en-gines (6.8%). Other reasons provided included loyal ty derived from features such as long-term histories or privac y protection, consistency, and distrust or dislike of other searc h engine brands. 66.8% of those who reported that they switched engi nes did so within a session at least Sometimes and 24.4% of subjects switch-ed within a session Often or Always . As part of our survey we asked those respondents who switched with a session to provide the rationale for their switching behavior. They di d so by selecting at least one explanation from a list of possible re asons provided to them. In Figure 1 we present the breakdown of respo nses, grouped by the response options offered to respondents. There are three general types of reasons: dissatisf action with the quality of results in the original engine (dissatis faction, frustra-tion, expected better results), the desire to verif y or find additional information (coverage/verification, curiosity), and user prefe-rences (destination preferred, destination typicall y better). These same three motivations were also seen in free-form survey feed-back. Respondents who answered Other listed reasons such as loyalty, hope, and search applications that let the m view the re-sults from more than one search engine simultaneous ly. Although we focus on within-session switching in th is paper, we also asked survey respondents to describe and ratio nalize any between-session switching behavior ( i.e. , attempt one session on one engine and another session on a different engin e) or long-term switching (or defection). 46.5% of those who switch ed did so between search sessions at least Sometimes and 14.2% of switch-ing respondents did so between sessions Often or Always . The reasons that respondents gave for between session s witching were that the destination engine typically performs bett er for the task they were attempting (55.2%), any engine would have sufficed (18.6%), or unintentional ( e.g. , different entry point or different computer) (12.8%). Other reasons included trust and differences in engine performance for different markets. 40.4% of subjects reported having defected from one search en-gine to another and never or very rarely returning to the pre-switch (origin) engine. 82.7% of subjects reported that they were happy with their decision to defect. This is substa ntially higher than the 4.4% observed in our log analysis, and lik ely reflects the fact that we used only three popular engines in tha t analysis (but our survey respondents may try new engines for shor t periods of time), and our strict definition of defection. The main reasons for defection were many dissatisfactory experiences wit h the origin engine (43.9%), one particularly dissatisfactory ex perience with the origin engine (7.9%), more relevant results on other engine (20.1%), or a new entry point such as a browser sea rch box or optional browser toolbar (28.1%). Since the effect of dissatisfac-tion appears cumulative, search providers should pr omptly ad-dress all forms of dissatisfaction in order to reta in their users. We now describe aspects of pre-switch behavior. A better understanding of the antecedents of switch ing can help explain switching behavior and facilitate the accur ate prediction of switching events. We used all 58.6 million switc hing events in our logs and analyzed important pre-switch interact ions. We began our analysis of pre-switch behavior by cal culating the frequency of actions immediately preceding a switch ing event, defined earlier as one of Browser , Navigate , or QueryToNavigate . There are five actions that we consider: Query, Pag ination ( i.e. , requesting the next page of search results for the current query), Clicking on a search engine result page (SERP), Cli cking on another (non-SERP) page, and Navigation to another page not associated with a click ( e.g. , through browser address bar). We also identify cases in which the switch occurs imme diately at the start of the session and the preceding event is Sta rt session. Figure 3 shows the breakdown of actions immediately before a switch. The most common pre-switch actions are queries, fol lowed by non-SERP clicks, SERP clicks, and navigation to oth er pages. We also studied in the extent to which this distrib ution of activi-ties held across the search process. Figure 4 (over leaf) shows the temporal dynamics across all 58.6 million switches in more detail. In particular, we show the probability of an action , P(Action) , occurring at different time points leading up to a switch. We con-sider the five actions described above: Query, Pagi nation to the next SERP, Click SERP result, Click non-SERP link, or Navigate to page. The top panel of the figure shows the prop ortion of each action as a function of time in the session before the switch. The 
Figure 3. Observed actions immediately preceding a switch. time scale is normalized to show proportions of the total pre-switch session time. Visible oscillations in P(Action) can be attri-buted to bucketing noise during normalization. Acti ons that occur shortly after the first query in the session are sh own at the left, and those that occur just before the switch are shown a t the right. A query occurs 100% of the time at the beginning of a session by definition. The proportion of total actions that th e query represents decreases as other actions become important. SERP c licks are common early in the process, accounting for 50% of the actions immediately following the query, but fall off after that. This is similar to a result reported by Downey et al. [7] i n which SERP clicks were more frequent than another query for th e 25 seconds after a query, but another query was more common su bsequently. It is also interesting to consider which actions in crease just before a switch. Looking at the far right of Figure 4 we s ee that clicks (on either the SERP or non-SERP) decrease, and that pagination, queries and navigation actions increase. The reason for the small drop in navigation behaviors is unclear, but may re flect users abandoning alternative resources they have navigate d to in favor of trying another engine. Immediately before a swit ch, users are less likely to click URLs relative to other points during the session and more likely to try another query or to page to see more results. We have also investigated the types of URLs that pe ople click on. The bottom panel of the figure shows the proportion of clicks that are to pages that the user has previously viewed in the session, represented as the probability of revisitation, P(Revisit) . The pro-portion of revisits increases as the session progre sses as users return to previous SERPs or other pages. P(Revisit) rises sharply immediately before a switch, perhaps confirming the frustration or dissatisfaction suggested in our survey responses. To obtain further insight into what users do before a switch that may be useful for both characterizing and predictin g switching we asked survey respondents the following question:  X  X  s there any-thing about your search behavior immediately preced ing a switch that may indicate to an observer that you are about to switch en-gines? X  We analyzed subject responses to this quest ion and identi-fied the following five most common answers: A1 : Try several small changes to the query (word orde r, phrases, A2 : Go to more than the first page of results, again often in quick A3 : Go back and forth from SERP to individual results , without A4 : Click on lots of links, then go to another engine for additional A5 : Do not immediately click on something. To verify whether these five behaviors also appeare d in our logs and to use them as features in a predictive model w e needed to first encode them in some way. Earlier work ( e.g. , [7,9,11]) has already introduced formal models and languages that encode search behavior as character sequences, with a view to comparing search behavior in different scenarios. We formulat ed our own alphabet with the goal of maximum simplicity. We en code the pre-switch interaction behaviors as a sequence of c haracters, where each character corresponds to either: (i) a u ser action such as a query or click, or (ii) attribute(s) of the pa ge visited such as SERP or non-SERP. We encoded page visits in two way s: basic and advanced . In the basic representation we only differentiate between SERP and non-SERP pages. However, in a simi lar way to [7], we felt that page dwell times could be usef ul and we en-coded these also. Dwell times were bucketed into  X  X  hort X ,  X  X e-dium X , and  X  X ong X  based on a tripartite division of the dwell times across all users and all pages viewed. The advanced representa-tion uses this more detailed characterization of pa ge visits that includes information about dwell time. Table 1 show s the alphabet used in our study. We automatically encode all acti ons by step-ping through the action series in chronological ord er, and at each point categorizing the page and the action taken to get there. For example, a user issuing a series of queries, each t ime viewing the resultant SERP for a short duration but not clickin g on any search results and then navigating to a non-SERP page thro ugh the browser address bar, and viewing that page for a lo ng time, would be represented in basic form as qRqRqRqRnP (or in abbreviated form qR*nP ), or in advanced form as qAqAqAqAnH (or in abbre-viated form qA*nH ). Table 1. Characters assigned to actions and pages v isited. We encoded all pre-switch interaction activity in t he 58.6 million switching events (including all substrings) in this format and computed the frequency with which they appeared bef ore a search engine switch. We also encoded all 1.1 billion sear ch sessions in this format (creating tens of billions of action se quences) and calculated how frequently each of the pre-switch st rings was ob-served in all sessions independent of switching. Fr om these fre-quency counts we identified significant pre-switch patterns called sequence motifs by calculating the point-wise mutual information (PMI) for each sequence. PMI is a measure of associ ation based on information theory that compares the probability of observing two items together with the probabilities of observ ing two items independently (c.f. [5]). We apply it in our contex t to estimate which sequences had a genuine association with pre-switch beha-vior and which were observed by chance. Table 2 pre sents the five basic and advanced sequence motifs with the highest PMI values. To generate these motifs we required that each appe ar at least 10,000 times in all search sessions over the six mo nths. This thre-shold allowed us to filter infrequent sequences tha t also co-occurred with switching events, giving them a high PMI value. The sequence motifs reveal some interesting behavio ral patterns. For example, it appears that repeat submission of q ueries followed by no SERP clicks ( i.e. , qR* ) commonly precede engine switches, and that revisitation and pagination also seem impo rtant. Such features were also mentioned in common survey respo nses. Three of the responses ( A1 , A2 , and A3 ) suggest that pre-switching users view SERPs for short time durations, often without clicking on search results. Repeat queries with no SERP clicks is mentioned in common survey response A1 , and pagination and revisitation are mentioned in responses A2 and A3 respectively. Note that the suffix of the fifth-ranked advanced sequence motif in Table 2 ( i.e. , [sFbA]* ) means that the same action  X  click search result, view page for short time, and return to SERP for short t ime  X  appeared repeatedly in sequence, and often before a switch. Such behavior was also highlighted in A3 . We do not see any strong evidence for A4 , clicking on lots of links before going to another engine for verification, and this may indicate that this behav ior is less com-mon than switching because of dissatisfaction or th at the beha-vioral antecedents are difficult to encode. We also did not see any strong evidence for A5 , perhaps because SERP views with me-dium-long dwell times and no clicks occurred freque ntly in many sequences, independent of engine switching. We have investigated aspects of the pre-switch beha vior of search engine users. In Section 5 we will evaluate the eff ectiveness of features derived from this analysis for predicting engine switch-ing. We now focus on the behavior following a switc hing event. Once again we use the 58.6 million switch examples from toolbar logs and study user behavior following a switch. We also include a log-based analysis that estimates whether users w ere satisfied with the results they encountered following the dec ision to switch. We begin our analysis by focusing on user actions a fter a switch. In Figure 5 we present a summary of the actions tha t immediately follow a switching event. We consider six actions i n total: Click on a SERP result, Re-query the destination engine, Query on other engine ( i.e. , switch again to a third engine), Re-query origin en-gine ( i.e. , switch back to pre-switch engine), Navigate to an other page without clicking on a link, or End session. Figure 5. Actions immediately following an engine s witch. As can be seen from Figure 5, around half of switch es were fol-lowed by a search engine result click. This suggest s that around half of switches were successful in getting users t o information that appeared relevant. For the remaining switches users engaged in a range of activities including ending the searc h session and navigating to another page through the browser addr ess bar or favorites list. Around one third of all switches le d to another query as the immediate follow-on action; suggesting dissa tisfaction with the immediate search results. Most of those queries are on the destination engine, however around 15% of those que ries involve immediately switching back to the origin engine ( e.g. , query Live Search then Google then return to Live Search) or q uerying a third engine ( e.g. , query Google then Yahoo! then Live Search). Extending the analysis beyond actions immediately f ollowing the switch allowed us to look further at returns to the origin engine and the utilization of multiple engines. If we exam ine the next query, ignoring events in-between if required, we f ind that around 20% of all switches lead to a return to the origin engine on the next query and around 6% of all switches lead to th e use of a third engine. These behaviors may be attributable to the destination engine not meeting users X  information needs or to u sers seeking to verify encountered information or obtain more infor mation (as we saw in the survey responses). Further analysis of t he queries for which this behavior was observed revealed that many were infor-mational in nature ( e.g. , computer error messages, medical diag-nosis, legal advice, or term-paper questions). For such queries search engines may be ineffective or users may wish to verify encountered information or explore topics in greate r detail. One interesting question is the extent to which swi tching to a new engine improves the user X  X  task success. It is diff icult to know for sure whether an information need was satisfied usin g only log data, but we explore several possible measures. We report two measures of overall user effort and activity (numbe r of queries and number of actions), and two measures that summa rize the quality of the interaction. The first measure is th e fraction of que-ries that result in no SERP clicks (% NoClicks ). The intuition is that no clicks are a likely indicator of poor quali ty results. We realize that some queries are satisfied by the sear ch results them-selves and do not require any additional actions. B ut others, e.g. , [8], have found that SERP clicks are less likely fo r low frequency queries and goals, so we include that measure in ou r analysis here. The other measure we use is based on work by Fox et al. [9] in which they showed that clicks which are followed by a dwell time of more than 30 seconds on the destination page are more likely to be rated as  X  X atisfied X  by users than those that re sult in a quick return to the SERP. Thus we define a SatAction as the first SERP click that a user dwells on for more than 30 second s. In Table 3, we summarize these measures for actions that occur before a switch (origin engine) and after a switch (destination engine). We show this separately for all switches a nd for switches involving the same query on the origin and destinat ion engine. Table 3. Measures of effort / activity / quality of interaction. The results are very similar for both types of swit ches. Note that given the large sample sizes all differences are si gnificant with independent measures t -tests at p &lt; .001. Users issue more queries and perform more actions on the destination engine than on the origin engine. They also seem less satisfied by our two measures  X  there are more queries with no clicks on the destin ation engine, and there are more actions before the first SatAction . Thus, on average, switches to not appear to lead to a quick resolution of the users X  information needs. An area for future research would be to examine dif ferent classes of queries in more detail to see if we can identify consistent classes of queries for which there are advantages t o switching and those for which there are no such benefits. In this section we have focused on characterizing a spects of search engine switching behavior. As well as charac terizing the behavior, it is important to understand the role th at features de-rived from this behavior can play in a predictive m odel of switch-ing. An ability to accurately predict when a user i s going to switch allows the origin and destination search engines to act according-ly. The origin engine could offer users a new inter face affordance ( e.g. , additional query suggestions, or richer support f or sorting or filtering using metadata about the search results), or search para-digm ( e.g. , engage in an instant messaging conversation with a domain expert) to encourage them to stay. In contra st, the destina-tion engine could pre-fetch search results in antic ipation of the incoming query. In the next section we describe an investigation of the predictive value of query, session, and user features. The prediction task is to estimate whether a user X  X  next action will be an engine switch given the interaction observed in a session so far and possibly knowledge about the user X  X  long-te rm interaction history. For this task we developed a learning mode l that uses logistic regression (cf. [12]), a technique that ha s been shown to have good performance in many domains and can effec tively handle numerical and categorical predictor variable s. The aim of this experiment is not to optimize the model but ra ther to deter-mine the predictive value of the query/session/user feature classes for the switch prediction challenge. The model is h eld constant throughout the experiment and only the features use d change per the experimental design. We now describe the featur es we use, the evaluation of models that use them, and the experim ental findings. 
Query class 
Session class 
User class Table 4 summarizes the features that comprise the t hree feature classes. This list is not exhaustive, but does cove r important as-pects of search interaction that may have value in this context, including many that emerged from the analysis in Se ction 4. Query features are assigned to the most recent quer y in the session within which the prediction is being made. They are derived from the query itself ( e.g. , number of tokens) and from the search logs of one of the engines in our study. The logs were g athered over the same six-month time span as the toolbar logs us ed to charac-terize switching ( i.e. , September 2008 to February 2009 inclu-sive). Unlike toolbar logs, search logs contain rec ords of the SERP contents shown to users at query time ( e.g. , the number of advertisements shown or the total number of query r esults). Session features are computed based on the observed interaction in the session up until the point that the switch p rediction is made. Session features include information about the dist ance into the session ( e.g. , the number of queries issued or pages visited so far), result inspection behavior ( e.g. , the number of revisits or pagina-tions), search success ( e.g. , the ratio of queries with no result clicks), and patterns of interaction ( e.g. , basic and advanced string sequences, currentSequenceBasic / currentSequenceAdvanced ). Also included were binary variables hasMotifBasic and hasMoti-fAdvanced . These were set to true if any of the top-100 sequ ence motifs emerging from our Section 4.3.2 analysis app eared in cur-rentSequenceBasic or currentSequenceAdvanced respectively. User features are computed at all points in the ses sion based on the current user X  X  search history gathered over the six-month pe-riod from September 2008 to February 2009. From eac h user X  X  history we extracted features of their queries, the ir frequency of searching, their average session length (in terms o f queries, time, and URLs), and the proportion of queries that they issue to their preferred engine. We would expect users who switche d frequently to issue a smaller fraction of queries to their pre ferred engine than those who switch infrequently or never switch. As stated earlier, the prediction task was to predi ct given features of the query, session, and user whether an engine s witch was about to occur as the next user action. The goal of this experiment was to assess predictive value of each of the featu re classes and highlight the individual features that performed we ll. We learned seven models, representing the three individual fea ture classes and combinations of them. We also include a baseline wh ich always predicts the most common action, no-switch. Switching immediately follows around 1% of all sear ch-related interactions. This makes the switch prediction task extremely challenging. Since the task was to predict whether the next action was a switch and not whether a full session contain ed a switch we used session states rather than complete sessions in our evalua-tion. A session state contains the observed interac tion in a session to a given point, as well as the most recent query and a unique user identifier used to locate user history if requ ired. We used a sample of 100,000 session states randomly chosen from the six months of logs from September 2008 to February 2009 inclusive to train a version of our learning m odel for each of the seven feature combinations. To mirror the distr ibution of real switches, the sample contained 1,000 randomly-chose n switching states and 99,000 randomly-chosen non-switching sta tes. Howev-er, the class imbalance caused by the small number of switching events may hurt the performance of the learning mod el. A common way of addressing class imbalance is to ar tificially re-balance the training data. To do this we down-sampl e the majority class (non-switches) using a technique similar to [ 17]. In our case, this involved holding the 1,000 positive examples c onstant, ran-domly selecting without replacement 1,000 non-switc hing exam-ples, and training a logistic regression model on t he 50/50 split. We repeat this process until all non-switching exam ples were used in training exactly one time. This yielded a total of 99 different sub-models that each make a prediction about whethe r a switch is about to occur. The majority vote among the predict ions is then used to determine the overall prediction via a form of bagging [3]. To test our models we created a separate test set t hat succeeded the training set. We extracted approximately 300 mi llion search sessions from toolbar logs for March 2009 and April 2009 using the method described in Section 3. From these sessi ons we ran-domly-selected a subset of 10,000 session states en suring that the ratio of switching to non-switching in each subset was 1:99 to match the global likelihood of the switching event. To reduce sampling bias we constructed 100 subsets using this approach. Evaluation proceeds as follows. At each of the 10,0 00 session states in the current subset, the model predicts wh ether a switch will occur as the next action given the features of the most recent query, the session so far, and/or the user search h istory. To do so, the model obtains a binary (switch/no-switch) predi ction from each of the 99 sub-models, counts the number of swi tch and non-switch predictions, and makes the final prediction based on which outcome has the most votes. The performance of the model with the assigned feature classes is then determined usi ng precision and recall averaged across all 100 subsets. We now describe the findings of our analysis. We evaluated the performance of each of the seven f eature classes plus the no-switch baseline using precision and rec all. Different levels of recall are achieved by setting different confidence thre-sholds for our model ranging from extremely low con fidence to extremely high confidence. In this context, precisi on is defined as the number of true switches ( i.e. , predicted switches that actually were switches) divided by the total number of sessi on states in the test set labeled with the switching event. Recall i s defined as the number of true switches divided by the total number of switches in the test set. Figure 6 shows precision-recall cu rves for our pre-dictions of whether a switch will occur at the next action. Separate curves are shown for models using query features, u ser features, and session features (for actions preceding the act ion we are pre-dicting), feature combinations, and a baseline that always predicts no-switch since this is by far the most likely outc ome. Error bars are too small to be visible on Figures 6 or 7 (fort hcoming). First, we consider performance using just a single class of features (query, user, or session). The best performance is obtained for the session features, followed by query features, and u ser features. Even user features, which perform the most poorly, still provide considerable lift over the baseline model. Users di ffer along many dimensions and the simple measures we have encoded ( e.g. , the average length of queries they have issued, the pro portion of que-ries for which they have previously switched search engines), provide some improvements prediction accuracy. Know ing cha-racteristics of the query, such as its length and p revious click pat-terns, can improve predictive accuracy even more. A nd, knowing characteristics of the session to date, such as the time in the ses-sion or previous clicks, are the most useful for im proving accura-cy. Second, we examined combinations of these featu res. Com-bining the different types of features results in m arked improve-ments in accuracy, suggesting that they provide com plimentary evidence about the task. At low levels of recall, a dding the session features typically improves accuracy by 50% or more . For exam-ple, at recall level 0.10, precision for the query model is 0.057 (shown in the curve with open red circles), and add ing the session features increases precision to 0.091 (shown in the curve with the filled red circles). The best performance is obtain ed when all three classes of variables are used, resulting in precisi on of 0.104 at recall 0.10. For this model, the most predictive fe atures in the logistic regression include query features ( queryLength , avgTo-kenLength ), session features ( timeInSession , actionsInSession ), and user features ( avgSessionLengthURLs ). Figure 7 shows the precision-recall curves for sess ions with three or more observed queries, since such sessions provi de additional context about the user X  X  progress on their task. Th e overall pattern of results is very similar. When considered individ ually session features are better than query features which are b etter than user features, and the best performance is obtained usin g all three types of features. There are also some interesting differ ences compared with the overall performance seen in the previous f igure. First, prediction accuracy is much higher  X  e.g. , at 0.10 recall, the preci-sion for the full model is now 0.235 compared with 0.104 in the previous figure. This is a result of longer session s providing more context to identify sequence motifs and due to task differences. More difficult tasks result in longer sessions and more switching. Second, the session variable provides more of a lif t when added to the user and query variables than it did previously . At low levels of recall, adding the session features typically im proves accuracy by 200-300% or more. For example, at recall level 0 .10, precision for the query model is 0.059 (shown in the curve wi th open red circles), and adding the session features increases precision to 0.172 (shown in the curve with the filled red circl es). The best performance is obtained when all three classes of v ariables are used, resulting in precision of 0.235 at recall 0.1 0. For this model, the most predictive features in the logistic regres sion include ses-sion features ( timeInSession , actionsInSession , numPaginations ), query features ( queryLength ), and user features ( avgSessionLeng-thURLs ). In addition, the two sequence motif features ( hasMoti-fAdvanced , hasMotifBasic ) are also strongly predictive indicating that the abstract patterns of behavior, such as qR*sPbR ( i.e. , mul-tiple queries with no clicks, then a single SERP cl ick and a SERP revisit), can improve prediction accuracy. The currentSequence-Basic or currentSequenceAdvanced features were not strongly predictive because they required an exact match bet ween a learned sequence appearing in the training data and the sequence generated from recent session interaction. More exp erimentation with sequences is required, especially with sequenc e suffixes that target recent session interaction over all session interaction. Predicting which (if any) actions during the course of a session will involve a switch to another search engine is a challenging task, in part because of the low frequency of such events. Using features of the query, user and search session (pri or to the switch), we can predict switches with much higher accuracy t han a simple baseline model. Although the absolute level of perf ormance is not too high, we believe that it is sufficient to suppo rt some kinds of user support ( e.g. , additional query suggestions or other search aids), especially in the case of longer sessions. A primary focus of this research has been the chara cterization of search engine switching behavior. Through our analy sis we have shown that approximately 4% of search sessions invo lve one or more switches between search engines. We have also shown that this percentage increases to over 10% for longer se arch sessions. The reasons for switching are varied and include: p erceived poor quality of results on original engine, desire for v erification or additional coverage, and user preferences. Approxim ately half of all users in our log sample and around two-thirds o f survey res-pondents engage in within-session switching. It is clear that the utilization of multiple search engines is an import ant aspect of users X  Web search behavior. Since switching is main ly associated with dissatisfaction with the search results on the origin engine, that engine could tailor the search experience for queries with a high observed switching rate. Given that search engine switching may also be attr ibuted to a desire for additional information, a search engine may wish to discourage switching away from their engine by offe ring topic coverage or redundancy (for verification purposes) as optional ranking criteria in addition to relevance. Tools to proactively noti-fy users when other engines may have different resu lts or results that support or refute a line of argument could als o help users. Though studying the pre-switch activities of search engine users we identified important patterns through temporal a nalysis and sequence motifs. Our findings revealed that some ac tions, such as SERP clicks and non-SERP clicks, decreased before a switch, whereas queries and navigation to other pages incre ased. Influen-tial interaction sequences also emerged as importan t from the survey data and log-based analysis. For example, re peat submis-sions of queries followed by no SERP clicks, was th e most dis-criminating sequence motif. By better understanding pre-switch behavior we can personalize switch predictions to t he current user and their search context. In addition, we can use g lobal switching rates for different queries or search patterns, ind ependent of user. We analyzed the post-switch activities of users wit h a particular focus on search success. Overall, switching to anot her search engine does not provide a quick resolution to a use r X  X  information need. In fact, we found that users perform more que ries and ac-tions on the destination engine, and do not appear to be more suc-cessful (as measured by NoClick and SatAction ). One reason may be that the queries that users switch on are diffic ult, making it likely that neither engine will be provide relevant search results, or that the other engines do not provide any additi onal information over the origin engine. Further exploration is need ed in the identi-fication of different motives for switching and div iding the analy-sis to determine their effect on search satisfactio n. We examined the use of several types of features fo r the difficult task of predicting switching during the course of a session. The findings showed that models trained using query, se ssion, and user features performed best for all sessions and f or sessions with three or more search queries. We achieved levels of performance that we believe will be useful in supporting some k inds of user assistance. For example, additional query suggestions, or richer support for sorting or filtering using metadata cou ld be provided. We also showed that some level of prediction accura cy could be obtained by using simple features of the query ( e.g. , query length and average number of search results). These could be used to construct a query-only switch prediction model that is not depen-dent on session or user history information. One limitation of this work is the focus on the thr ee most popular search engines: Google, Yahoo!, and Live Search. Mo re examples of switching behavior would be observed if addition al engines were considered in the analysis. There may be notew orthy beha-viors and rationale in the switches from popular en gines to less popular search providers, such as vertical search e ngines. We have presented a characterization of search engi ne switching behavior and an examination of several types of fea tures for the challenging task of predicting switch search engine s. We have drawn from findings from a large scale log-based an alysis and a large user survey to improve our understanding of h ow, when, and why users switch engines. Survey findings revealed that switching is not only a result of dissatisfaction with the or igin engine; it is also frequently related to user preferences and a d esire to verify or find additional information. Survey respondents ide ntified com-mon behaviors preceding a switch that were also ide ntified as significant in log analysis. These findings plus ad ditional insights gleaned from the logs were used to inform feature s election for logistic regression models that let us examine pred ictive value of query, session, and user features. Predictive model s may be useful for search engines who may want to modify the searc h experience if they can accurately anticipate a switch. Our fin dings suggest that the predictive models provide sufficient signa l to provide some additional user support, especially at low rec all. More im-portantly, we demonstrated the relative value of ea ch feature class and highlighted individual features that may be use ful predictors. In future work, we will develop improved predictive models using new features and alternative learning algorithms. I n addition, we would like to further distinguish different motivat ions for switch-ing ( e.g. , dissatisfaction with original engine, desire to v erify or diversify results) and develop models and the appro priate end-user support for each. Better understanding how to help users identify the vertical search engines or other general search engines that could provide diversity of focus, also presents an important inves-tigative opportunity. Finally, to better understand longitudinal behaviors, we will study between-session and long-t erm switches. [1] Bartell, B.T., Cottrell, G.W., and Belew, R.K. (199 4). Auto-[2] Belkin, N., Cool, C., Croft, W., and Callan, J. (19 93). The [3] Breiman, L. (1996). Bagging predictors. Machine Learning , [4] Carmel, D., Yom-Tov, E., Darlow, A., and Pelleg, D. (2006). [5] Cover, T.M. and Thomas, J.A. (1991). Elements of Informa-[6] Cronen-Townsend, S., Zhou, Y. and Croft, W. B. (200 2). [7] Downey, D., Dumais, S.T., and Horvitz, E. (2007). M odels [8] Downey, D., Dumais, S.T., Liebling, D., and Horvitz , E. [9] Fox, S., Karnawat, K., Mydland, M., Dumais, S.T., a nd [10] Grimes, C., Tang, D., and Russell, D. (2007). Query logs are [11] Heath, A.P. and White, R.W. (2008). Defection detec tion: [12] Hosmer, D.W. and Lemeshow, S. (2004). Applied Logistic [13] Huntington P, Nicholas D, Jamali, H.R , and Watkins on A. [14] Juan, Y.F. and Chang, C.C. (2005). An analysis of s earch [15] Laxman, S., Tankasali, V., and White, R.W. (2008). Stream [16] Leskovec, J., Dumais, S., and Horvitz, E. (2007). W eb pro-[17] Ling, C. and Li, C. (1998). Data mining for direct marketing: [18] Mukhopadhyay, T., Rajan, U., and Telang, R. (2004). Com-[19] Pew Internet and American Life Project. (2005). Search [20] Teevan, J., Dumais, S., and Liebling, D. (2008). To personal-[21] Telang, R., Mukhopadhyay, T., and Wilcox, R. (1999) . An [22] White, R.W., Richardson, M., Bilenko, M., and Heath , A.P. [23] Zhou, Y. and Croft, W.B. (2007). Query performance predic-
