 REGULAR PAPER Zhiguo Gong  X  Leong Hou U  X  Chan Wa Cheang Abstract In order to index Web images, the whole associated texts are partitioned into a sequence of text blocks, then the local relevance of a term to the correspond-ing image is calculated with respect to both its local occurrence in the block and the distance of the block to the image. Thus, the overall relevance of a term is de-termined as the sum of all its local weight values multiplied by the corresponding distance factors of the text blocks. In the present approach, the associated text of a Web image is firstly partitioned into three parts, including a page-oriented text ( TM ), a link-oriented text ( LT ), and a caption-oriented text ( BT ). Since the big size and semantic divergence, the caption-oriented text is further partitioned into finer blocks based on the tree structure of the tag elements within the BT text. During the processing, all heading nodes are pulled up in order to correlate with their semantic scopes, and a collapse algorithm is also exploited to remove the empty blocks. In our system, the relevant factors of the text blocks are determined by using a greedy Two-Way-Merging algorithm.
 Keywords We b i m a g e s  X  Text-based  X  Indexing  X  Segmentation  X  Retrieval 1 Introduction Millions of images, on almost every conceivable topic, are available from the Web. How to effectively reuse those valuable images attracts many research efforts over the past few years. Similar to the text-dedicated Web page search engines, a Web image search engine should also consist of three principal modules such as a crawler, an indexer, and a query engine. In general, crawlers start their work with some given URLs called seeds, then, recursively traverse Web pages with newly found URLs in the downloaded pages. Crawlers can be categorized into two types, trols. In the former model, such as www.google.com , www.altavista.com ,and www.hotbot.com , crawlers try to traverse all the URLs which are found. And the latter, such as www.campsearch.com , www.netpart.com ,and www.cora.com , can only need to select the URLs which may lead to pages specified to some given topics. Universal crawlers schedule URL traversing in either breadth first or deep first algorithms. Their crawling works can only be controlled by the physical fac-tors such as available storages, memories, time, and system administrators. On the other hand, topic-specific crawlers schedule URLs according to their possibilities to the corresponding topics. To predict the contents of the target page of a link, source page information and link structure are parsed and analyzed in general [ 2 , 5 , 6 , 8 , 19 ]. For image-dedicated search engines, crawlers are trying to know which target pages contain images semantically related to the given topics. pages (or images) should be extracted and indexed in order to be accessed by the internet users. For text-dedicated search engines, Web pages are often represented in TFIDF models [ 2 , 16 ]. And inverted indices are created to support fast access to the Web pages. More information can be used for semantic extractions of Web pages than traditional text documents. In a Web page, the weight of a term is not only affected by its frequency but also its HTML tag X  X  type [ 16 ]. However, this approach cannot be applied to Web images directly.
 Web documents. The contents of the images cannot be directly represented by their textual parts of the Web documents. How to extract and represent the contents of the Web images raises several challenges to the researchers. And Web image search models are closely related to the Web image representation methodologies. Currently four main approaches are found in literatures for content extractions and representations of Web images: (1) text-based, (2) visual feature-based, (3) manually annotation-based, and (4) link-based.
 content of a Web image. Typically, image file names, anchor texts, surrounding paragraphs, even the whole texts of the Web documents are considered for the ex-ditional image preprocessing techniques, using visual features of the image, such as color histogram, texture, shape, as the content descriptors [ 1 , 10 , 11 , 21 , 27 ]. In this model, the user can search images with a sample image. However, visual feature extractions are both time consuming and domain-related (shape extrac-tions are strictly constrained by domain knowledge), therefore, hard to be used in the comprehensive web environment. Manually annotation-based approaches are the most traditional solutions. In this model, all the images have to be anno-tated with some keywords in some predefined structures. Such kinds of methods are labor-intensive, thus not suitable for large image collections. The principle of link-based methods is based on the promise that images cocited by the same page are semantically similar [ 13 , 15 ]. This model is actually extended from some well-known link-based Web page schemes to the content of Web images retrieval. For most of the text-dedicated page search engines, link information already exists, only a reasonable overhead is necessary to add Web image search functions to the original Web page search engines. However, this model suffers from following weaknesses: (1) large amount of Web images are singly cited rather than cocited, thus their contents cannot be derived by the cocitation algorithms. (2) links are originally used by the authors to connect the Web pages, they may not well re-flect the semantic relationships among the images embedded in the pages. Our approach in this paper belongs to text-based schema.
 thors use images as visual descriptions for their Web pages, therefore, reversely the surrounding texts can also reflect some semantics of the corresponding images. With this consideration in minds, we can apply text-oriented webpage retrieval methodologies to our web image retrieval system. However, this is not a direct re-application. Several essential differences should be taken into account. For ex-ample, a term which is semantically important to the Web page may not be the same to the image. For a Web page, terms appearing within META tag elements have higher weights in representing the contents of Web pages. But those terms may have less or even no any semantic relationship to the images which are used as locally visual presentations in the Web pages.
 we firstly apply stopword removing algorithm to the text [ 26 ], then Porter X  X  stem-ming algorithm is applied in order to normalize the representations of terms [ 22 ]. To prevent the stem (root) of a term or word from being too short after the stem-ming algorithm, we set a threshold (two characters) for lengths of the terms to be processed. The normalized associated text is segmented into text blocks accord-ing to its structure X  X ag annotations. For each term or word in one text block, a value, called local weight, is assigned as its frequency within the block. We mea-sure semantic relevance of a term in a text block to a Web image with respect to both its local weight and the relative distance of the text block to the image. Then, the overall relevance of a term to a Web image is the sum of all local weights multiplied by corresponding distance factors.
 into three parts, which include TM (the texts from &lt; TITLE &gt; and &lt; META &gt; el-ement), LT (the text attached to the image display command), and BT (the text of &lt;
BODY &gt; element), based on their functions in the text. TM is often used as the summary of the page content, and it may provide valuable semantic implications to the images especially in an image container [ 15 ]; LT is the closest part of the associated text to the image, and often highlight the contents of the local Web im-age; BT is big in size, but can provide explanations for the contents of the image in most of the cases.
 ther partition it into a sequence of text blocks with respect to the nested structure of tag elements. We normalize our partitioning by Pulling UP heading elements and Collapsing empty layers. The local weight of a term within a block is calcu-lated in TFIDF model. In order to determine distance factors of the text blocks, we firstly discretize the multidimensional space of the factors, then exploit a greedy searching algorithm X  X wo-way-merging. Thus, combined weights of terms to a Web image can be calculated. Our experiment shows that the present method provides a satisfied solution for web image retrievals by using the associated texts.
 Sect. 3 provides the detail discussions of our term indexing methodologies for Web images. Section 4 illustrates our experiment. Finally in Sect. 5, we conclude this paper. 2 Related work There are several works in literature aiming to extract image contents from its as-sociated text. Guglielmo and Rowe [ 12 ] provided image retrieval systems with natural-language. In their work, both the query languages and image captions are translated into logic form, using detailed theory of the meaning of nominal compounds. Before performing fine-grain match between a query and a caption, coarse-grain match with index files are processed. The effectiveness of the system is limited by the length (less than 40 terms) and simple syntaxes (more nouns, less verbs, and so on) of the image captions. It cannot be well scaled up with the long and syntax-complicated associated text of the web images.
 bined keywords and visual features to refine the searches for images [ 20 ]. In this system, several image features, including color, texture, size and position, are used for indexing, and users can modify the feature weights with respect to different fo-cuses in their searches. The system has also been tested with some specific source sites (i.e., Disney). It applied general image retrieval methods into WWW environ-ment. Another prototype was completed by Guojun Lu and Ben Williams [ 18 ]. In their system, similar strategies are used for the image indexing X  X oth textual and feature indices are supported. For the textual index, they defined different weights for the indexed terms with respect to their positions and frequencies appearing in the textual part of the HTML documents.
 Web image indexing [ 9 , 25 ]. Their common weak points in processing associated text can be categorized into two types: Either only the small parts of the associated texts are selected for the index, or the large associated texts are not elaborately partitioned. The first weakness may cause lower recall and the second one may decrease the precisions of the retrievals.
 tents of Web images. In their approach, the contents of a Web image are extracted from image file name (TLC), text of ALT tag of the image (ALC), title of the Web page (PLC), and the caption (SLC, RSLC, CLC) [ 23 ]. The system allows user to query the Web images with a sentence. And the queries are evaluated against all those lexical chains with different weights. To refine the queries, the user can use feedback to add or minus the semantics of the original query. With this method, almost the whole text of the caption should be stored, therefore, it will be hard to store with the sizes of the caption text. Furthermore, no information as how to fast access the semantic chains of the Web image can be found from the work. address those challenging problems and introduce our solutions. 3 Methodology for text analysis In traditional IR systems, the TFIDF model is popularly used to capture and rep-resent semantics of the text documents. In general, a corpus of text is represented as a vector of term X  X eight pairs as follows: where t i represents terms which occur in the text, and w i is the corresponding weight assigned according to its importance in the text. Then users X  queries are evaluated as the cosine between document vectors and the query vectors. In this and idf i is the inverse document frequency [ 3 ]. When applying to Web documents, tag type of term t i can also play an important role in indicating the important levels of the terms in the documents. In [ 16 ], the traditional term weights are multiplied by tag factors which are assigned and justified by human experts. For example, a term with associated tag META or TITLE implies more important level than that which is associated with the tag BODY. In general, a term, which is important to a Web page, may not imply that it also important to an embedded image of the Web page. In other words, Web images are used for local visual presentations of Web documents. A term frequently used in the first paragraph, for instance, may have less or even no semantic relevance to an image which is embedded in the last paragraph of a Web page. That means,  X  X istance X  of a term to an embedded image must be taken into account. 3.1 Formal definition of web images Consistent with the definition by Lempel and Soffer [ 15 ], an image i is embedded in a Web page p if only in either of the following two cases: (1) p display i :When page p is loaded in a Web browser, i is displayed, or (2) p points to i  X  X  image file. We call i the embedded image of p and p the associated text of i ,andthe relationship between p and i is denoted as p i . Similarly, if page p has a link to another page p  X  , we also represent it as p p  X  .
 ciated text p . Here, semantics of image i refer to the concepts or objects presented by the image. In our work, we suppose that the contents or semantics of image i can be found from its associated text p . With this assumption, our semantic ex-tractor tries to determine the possibility of each word or concept, which appears in the associated text p , to represent the semantics of the embedded image i .Itis obvious that the possibility of semantic relevance of term t is closely related to its relative locations to the image i . In the next section we briefly discuss the text scope from p as for the indexing of image i . 3.2 Text scope for indexing There are some common points between predicting semantics of the target image i in p i and the target page p  X  in p p  X  by using the information provided by the source page p . Here we would like to investigate some past works either on semantic predictions of target pages or embedded images.
 of the source page is used for semantic analysis. In general, there are several ways to cut text from the whole associated text in literature [ 4 , 7 , 8 , 14 , 24 ]. Those works aimed to predict either Web page semantics or web image semantics of the link targets by analyzing the source pages of the links. In IBM ARB system [ 21 ], there is a crude cutoff distance measured in bytes to the left and right of the anchor in order to predict the meanings of the link targets. In [ 8 ], distance is measured in tokens (tags). In [ 4 ], they cut off the associated text with three methods X  X ASIC, SYNTACTIC, and TOPICAL. In BASIC, the cutoff window is measured by words. And SYNTACTIC cut off the local widow by syntactic de-limiters such as the separators for sentence, paragraph, table cell, and list items. TOPICAL solution bounds the local window by subject separators, such as head-ing begins, list ends, and table ends. Their experiments showed that the bigger the window size, the more correct to predict the target Web documents of the links. Smith et al. [ 24 ] combined text and visual features for Web image retrieval. For text part, only link annotations are used as for its topic classification of web im-ages. In [ 4 ], Cascia and colleagues defined the window from 20 words before and 20 words after the web image, and also combined with visual features to support web image retrieval. And works [ 9 , 23 , 25 ] only simply used one paragraph for embedded image extractions. The promise behind our method in this paper is our observation that more semantic relevance exists between the source Web page and its target web image than to a target Web page. Web images are often used as the visual presentations of a segment or even the whole of text in the Web page. That is, the semantics of web images are often parallel with the texts of its source Web page. Therefore, we need to pay attention to three points when selecting text window scopes and boundaries: (1) Big enough. Text window in the source web page should be big enough in (2) Semantic boundaries. Text segmentation should be based on semantic delim-(3) Distance sensitive. It is natural that terms appearing in different semantic frag-tion. Big text scope may benefit image containers [ 15 ], but generate noise to non-container pages while small scope may raise precisions, but decrease recalls of the retrievals. To compromise these two contradicts, we apply semantic segmentation on the whole text. With this approach, images in containers can be ranked with higher priorities while the noise caused by divergent pages can also be controlled. 3.3 Text block segmentation Initially we partition a web page p into three parts as TM , LT ,and BT. TM ,which represents the overall semantics of the Web page p ; LT , which is the text attached to image command &lt; IMG &gt; or image links, often highlighting the semantics of web images; and BT , which is the text of &lt; BODY &gt;&lt; /BODY &gt; element, that can provide some descriptions for the embedded images. We investigate each of them in detail in this section. 3.3.1 Text block of TM As a matter of the fact, TM is often used as the abstract of a Web page. It can well reflect the semantics of the Web page in most of the cases. For web page-dedicated search systems, terms appearing in TM are often assigned with higher weight than those appearing in other parts. However, we cannot make the same assumption for image-dedicated search systems. If page p is an image container for some specific topics, TM may still be important for the semantic extractions of the embedded images. However, terms in TM may be only little relevant to a local Web image especially for a big and noncontainer Web page. 3.3.2 Text blocks of LT The texts, which are attached to the image display command &lt; IMG &gt; or image URL, are called link-based associated text ( LT ) of the embedded image. With respect to their functions and purposes, we partition LT further into three parts called link-based text blocks.
 name )andWeblocation( i-loc ). Actually, concatenation of i-loc and i-name is the URL of the image. If the URL of image i is  X  X ww.umac.mo/general/ campus images/campuse main1.jpg, X  as an example, then i-loc =  X  X ww.umac .mo/general/campus images/, X  and i-name =  X  X ampus main1.jpg. X  Actually, this Web image is a picture of a university campus. In this example, both i-name and i-loc provide some implications to the topic of the Web image. So terms ap-pearing within i-loc or i-name may reflect some semantics of image i .Onthe other hand, some terms occurring in i-loc or i-name , such as  X  X eneral X  in our previous example, may not have any semantic relevance to the image. Further-more, many cases can be easily found, in which no terms from i-loc or i-name can provide any semantic implications to the image subjects. As a matter of the fact, terms in other part of the associated text can be used for further semantic analysis.
 play a Web image i : &lt; IMG &gt; (image tag) and &lt; A &gt; (anchor tag). The image X  X  URL is specified as the value of attribute SOURCE for &lt; IMG &gt; tag or the value of attribute HREF for tag &lt; A &gt; . Besides i-loc and i-name , another important text attached to image link command is the attribute ALT within tag &lt; IMG &gt; ,orthe element content of tag &lt; A &gt; . The value of ALT is often used as the textual alterna-tive for the corresponding image, and the content of tag &lt; A &gt; is the link X  X  source point to the image. This two text values are similar in contributing semantics to the embedded image i . To simplify our notations, we uniformly use i-alt for both of them.
 They are important text annotations which imply Web image subjects with higher probabilities. However, there are many cases in which no semantic relationships can be found from the terms in these three text strings. Furthermore, according to our statistics, large amount of web images are not associated with ALT values. Therefore, even if those link-based text blocks may provide higher precision for image index and retrieval, the recall of the retrieval is often quite lower for most of the queries. In fact, other associated texts (we called caption text in this paper) in Web pages also provide some important semantic contributions to the embedded images. 3.3.3 Text blocks of BT Caption is the text around the image i , which may also provide semantic implica-tions to the embedded images. To our knowledge, current works only partition the whole associated text into very limited text blocks. For instance, work [ 23 ] takes the paragraph, which contains the embedded image, as the only caption text of the image and ignores the other parts of the associated text of the image. And [ 18 ] partitioned the associated text only into two text blocks. The first work may reduce the recall rate such that large amount of relevant images may not be searched out, while the second work may reduce the precisions of retrievals in view of the weak support of terms X  semantic distances to the corresponding images.
 ing qualified images, which are embedded within topic-specific image containers, with higher privileges. As a matter of the fact, many image containers exist es-pecially in dot-com Web sites. In such kind of image containers, even though the texts of the pages may be large in size, they can still consistently concentrate on the same subject. Thus, such kinds of pages should have higher possibilities for the subject than pages with only one paragraph on this subject. As for this reason, in this paper, we select the whole text of BODY of the web page as the caption of the corresponding image.
 tic organizations of the web pages. Our objective for segmentation of the whole text is that each text block should be semantically consistent in supporting one subject. However, semantic consistency is a relative rule within a specific con-text. For instance,  X  X otebook, X   X  X rinter, X  and  X  X canner X  are semantically consistent in the context of  X  X lectronic equipment, X  but they are not consistent in the con-text of  X  X omputer X . Therefore, one extreme is to partition the text term by term text as one text block. The first method will make the problem unnecessary com-plicated and the latter will lose distance information of the words to the image. In our approach, the block segmentation is based on semantic separations as possible.
 rendering purpose only. However, the visual layout structure of a HTML document can also reveal the semantic structure of the document (Fig. 2 ). We separate all tags in the &lt; BODY &gt; element into two different types X  X emantic delimiters SD and nonsemantic delimiters NSD .A SD tag is used to organize a semantic consistent presentation of a text segment, for example, &lt; FONT &gt; . In our current work, SD ={ all other tags } .In SD , &lt; BODY &gt; element is the container (or root) of all other SD tag elements.
 &lt;
TA B L E &gt;&lt; \ TA B L E &gt; tags as to support their presentation layouts (70% for dot-com web pages, and 55% for dot-edu web pages). Therefore, &lt; TA B L E &gt; or-ganizations are important information for semantic partitioning. It is obvious that ( &lt;
TD &gt; or &lt; TR &gt; ) other than they are located in two different independent tables &lt; the web page is organized with three &lt; TA B L E &gt; elements X  X able 1 ,Table 2 ,and embedded in TD 1 ,TD 2 ,andTD 3 , respectively. In our approach, we suppose that Text 31 is most relevant to picture Pic 1 since they occur in the same tag element TD 1 . Then, Text 32 and Text 33 have the same relevant impact to Pic 1 since they are embedded in TD 2 and TD 3 , respectively which are both of TD 1  X  X  brother elements under the same parent element Table 3 . We also consider Text 1 and Text 2 are at the same semantic distance to Pic 1 ,Pic 2 ,andPic 3 for the similar reason. used as semantic separation method by web authors. It is also clear that text t and image i are more semantic relevant if they are from the same element &lt; P &gt; other than different ones. &lt; UL &gt; tag is also frequently used tag for semantic separation in web page writings. And item elements under the same &lt; UL &gt; tag keep the same semantic distance with each other. Intuitively, the semantic constrain scopes with their presentation constraint scopes. For instance, text occurring in &lt; TD &gt; &lt; /TD &gt; element is also organized as a semantic segment. However, this is not true for &lt; HEADING &gt; tags.
 tation of the element as a heading look. Semantically, it is natural to take the text starting from this heading element to the next heading element under the same par-ent node as one text block (Fig. 3 ). Given nodes H 1 , H 2 ,..., H k as the siblings of type &lt; HEADING &gt; under node N in the document tree. Suppose S 1 ,..., S n (they may be different tag types) are all the siblings occurring between H i and H + 1 ,then H i  X  X  semantic constraint covers all S 1 ,..., S n . For this reason, we re-structure the document tree by pulling up H i as the semantic parent node of S ,..., S way, we get a restructured Body tree X  RT .In RT , each node constrains its seman-tic scope over all its children nodes.
 is the sibling order under the parent node., and n indicates the level of the node from the root of the RT tree. For example, the root node is assigned sequence 0 , and it has two children with sequence 00 and 01 , respectively. The sequence of the node is used for determining the semantic distance of the text in a node to a Web image in the RT tree.
 E , E (the root node) and E 0 i . And furthermore, no other HTML element exists between E j + 1 and E j for any j . Obviously, value N (the number of the nested ele-ments) may be different for different web pages. To simplify our notations, we set N big enough. And if E j = BT ,then E n = BT for any N  X  n  X  j . Therefore, text blocks are defined as SB j = E j + 1  X  E j for N  X  1  X  j  X  0(Fig. 5 (b) and (c)). Then, we have BT = X  0  X  j  X  N  X  1 SB j with SB k  X  SB l = for any k = 1.
 be partitioned into M layers with respect to image i and the segmentation can be implemented as follows: partitions (Fig. 5 (b) and (c)).
 SB 0 is the most relevant text block to the embedded image i since it is the closest one to i . However, our initial experiment reveals that SB 1 other than SB 0 is the best one, among all the SB j  X  X  of RT , in deriving the semantics of the embedded image i . With a close study, we find the reason is due to the fact that large percent Web authors layout images and their corresponding text in different semantic tag elements. For example, image i and its corresponding text are located in two adja-i contains no text and i  X  X  closest text block is actually located in SB 1 . In fact, Web authors can wrap image i with as many empty tags as they like, but they look no different with web browser. To solve this problem, we collapse text blocks from SB 0 to SB N  X  1 if it is an empty element (without text) (Fig. 6 ).
 ment contains only one image. Suppose, in Fig. 5 ,image i 1 and i 2 coexist in the same document, and node N0101 , N01010 contain no text. In this case, according to the algorithm, SB 2 of image i 2 will collapse into SB 0 (Fig. 5 (c)). At the same time, if both node N01000 and N01001 contain text (Fig. 5 (a)), according to the algorithm, N01000 will be in SB 1 of i 1 . But it is only in the SB 0 of i 2 .Inother words, after the simple collapse algorithm, N01000 is more semantic relevant to i than to i 1 . This result is obviously unnatural. The reason is due to the fact that simple collapse algorithm does not take into account the affections to other im-ages in the same HTML document. As a matter of the fact, there are quite a lot of documents containing more than one image. Let { i 1 , i 2 ,..., i J } be J images contained in one RT tree, { SB i j , n | 0  X  n  X  N i j } be the semantic segmentation of image i j , then our multiimage collapse algorithm is as in Fig. 7 . In this algorithm, no node of SB i j , n + 1 which is in a lower semantic layer of another image. Without losing generality, we still use SB 0 , SB 1 ,..., SB N  X  1 to represent the final text blocks of image i .
 where B 0 = i-alt , B 1 = i-name , B 2 = i-loc ,and B i = SB i  X  3 for i  X  3. In our approaches, we suppose different text block B i may impact different semantic relevancetoaWebimage i. Without losing generality, we still use N to represent total number of the overall text blocks. 3.4 Term weighting Now a Web page p can be represented as the union of those text blocks: p = 0  X  j  X  N  X  1 B j . In TFIDF model, term t  X  X  semantic relevance to page p is measured by tf ( t )  X  id f ( t ) ,where tf(t) is the frequency of t occurring in p and idf(t) is the inverted document frequency of term t . In this paper, we use terms (or concepts) in p to derive semantics of the Web image i .However, the above TFIDF approach cannot be directly applied to index the embedded image. 3.4.1 Semantic relevance of terms to the embedded images In this paper, we modify the TFIDF model regarding following two arguments: (1) idf(t i ) is used to enhance significances of the terms which appear in less docu-(2) We apply tf(t) to each text block B j . However, frequencies of terms may be frequency of term t over B j ,and | B j | is the size of B j . Thus, the total term weight over the whole p is obtained as where N is the total number of the text blocks, and w j is the factor of B j in imply-ing the semantics of the embedded image i . Without loss of generality, we suppose that w j  X  s are normalized, such that embedded image i embedded in p . Thus, the important and challenging task for using this measure is how to determine the values for w j . 3.4.2 Objective function of retrieval performance In the area of information retrieval, precision/recall is well accepted evaluation method for the performance of the systems [ 3 , 25 ]. An ideal information retrieval system is trying to raise the values for both of the two objectives. Since the re-sult of a retrieval is usually long list in size, especially in the World Wide Web environment, a figure of precision versus recall changing is commonly used as a performance measurement for a retrieval algorithm. However, this metric can-not be used as an objective function in determining those weight values. Instead, in this study, we employ the single value summaries as our objective function in order to determine the values for w i [ 3 , 25 ].
 database and Q ={ q 1 , q 2 ,..., q K } be the set of sample queries. In this study, we suppose all the queries are single-concept queries. This assumption is reason-able since most of Web image users use only one concept as the queries. We use measure nt f ( q k ) | B j , such that OS jk is ordered according to its normalized term frequency over the text block B j . Obviously, it has the following properties: (1) The element set { o j 1 , o j 2 ,..., o j s } of OS jk is a subset of OS . (3) For any o j l in the result list, it is either relevant or irrelevant to q k . relevant results in the list OS jk . The total recall by only referencing B j is defined as value objectives: (1) Recall jk , which indicates the total recall which can be cov-relevant results earlier. Here AP jk is defined as in [ 3 , 25 ] N k is the number of results up to the k th relevant result in the result list OS jk .Asa matter of the fact, AP jk is the single value metric which indicates the performance of querying q k by only referencing text block B j . 3.4.3 Combining text blocks A combined retrieval will use the equation as the ranking function, where w j is the weight for the text block B j . The total as w j &gt; 0. That means, let query q i in Q , for any given values of w = (w fore, factor values can only affect the ranking of the result and the recall cover remains constant when we change the values of the factors. The optimal value for w is determined by the overall average precision objective defined as where AP i ( w ) is the average precision with respect to the combined similarity measure ttf of query q i .
 ever,itisobviousthat AP ( w ) is not a continuous function of w . And it is rather tricky to write down a mathematical expression for this function. There-fore, we cannot use gradient method, which is popularly used for differenti-ate functions, to find the maximum solution. In our approach, we simply dis-cretize the multidimensional space of w with fixed amount  X  = 1 / L in each dimension, where L is a natural number. The value for L determines the reso-lution of the discretization of the space. Then the searching space become the set S = ( l to search a point w  X  S , such that the objective function AP ( w )ismaximum. Actually, w i = l i / L .And1  X  l i guarantees w i &gt; 0, and 0  X  i  X  N  X  1 l i = L guar-antees the normalization condition 0  X  i  X  N  X  1 w i = 1. In order to find the optimal points in the S , we need to traverse number of points in the order of 0( L N  X  1 ). With higher resolution (bigger L ) and delicate semantic segmentation (bigger N ), the size of the space may explosively increase. As a matter of the fact, more number in semantic segmentation may cause more resolution in order to effectively differ-entiate all of the w i  X  X . For example, if we only use two text blocks for partitioning, we can then differentiate w 1 and w 2 with resolution  X  = 1 / 4. However, if we still use this resolution for three text blocks, it may be a little bit hard to effectively differentiate those three weights w 1 ,w 2 , and w 3 . To reduce the complexity of the algorithm, we employ a two-way merge solution to try some suboptimal values for those weights.
 into N text blocks. In our two-way merging approach, we iteratively combine text blocks two-by-two with several loops until completing the merge. For the first is only one text block B N without merging in the loop, the same principle exploited in any subsequent loops in the algorithm). The procedure can finish when no more can be merged. The complexity of the algorithm is in the order of 0( L log N ) (Fig. 8 ). From the algorithm, it is easy to know the final values of w i  X  X  satisfy the condition 0  X  i  X  N  X  1 w i = 1. 4 Evaluation of the results The crawler of our system gathered about 150,000 Web pages with a given set of seeds which are randomly selected from dot-com, dot-edu, and dot-gov domains. After the noise images (icons, banners, logos, and any image with size less than 5k) removed by the image extractor, about 12,000 web images embedded in the Web pages are left. Then, five human experts are assigned to define the subjects of the Web images manually. And sometimes, more than one subject are defined for the same images. For example, concepts  X  X aptop, X   X  X otebook, X  and  X  X omputer X  may be annotated to the same Web image. We select 30 concepts from the defined set as our query training set QT , and another 15 terms as our test samples. We measure the query performances with the precision-recall objective.
 vidual text block to the queries. In our experiment, we combined text block i-loc and i-name and denote it as i-path .Thatis, i-path = i-loc  X  i-name . And we only partition &lt; BODY &gt; element into five layers by combining all SB j ,where j &gt; 3 into one text block, SB 4 = X  j  X  4 SB j .Table 1 shows the recalls and relevance factors of different text blocks.
 In other words, about 54% of relevant Web images can be searched out with referencing to their owner pages. From Table 1 , it is clear that the recall covered by SB j decreases with the increase of the semantic distance for BT text blocks. i-Alt, TM, and especially i-path can only provide quite lower recalls for the retrieval. However, their precisions for retrieval are much better.
 gether with the combined retrieval performance. Even i-path provides the lowest recall of 0.007978723 in our experiment and it demonstrate the highest precision curve for retrieval. And i-ALT also shows much better performance for the re-trieval. In general, link-based text blocks can always be the best for precisions of the results. Besides, page-oriented block TM is also good in contributing semantic of the images. And this fact indicates that large percent of qualified web images are embedded in the image containers. For BT blocks, SB 0 is much better than all the others. And it is also clear that SB 3 and SB 4 can only provide uniformly lower retrieval performances for web image retrieval.
 Two-Way-Merging algorithm. Among all textic blocks of BT , SB 0 gets the maxi-mum and quite bigger value compared to others. On the first view, factors of text block i-Alt , i-path ,and TM are not as large as we expected since they can provide good retrieval performances for the web images. This phenomenon is due to the following two reasons: (1) i-Alt , i-Path ,and TM are much small in size in comparison with blocks of BT . (2) Average precision ( AP ) is used as the objective function of the Two-Way-sides its keeping the original recall percentage provided by p , it also provides good performances for retrievals. Even though its precision curve is a little bit lower than text block i-Alt , i-Path, and TM , the combined ranking model demonstrates much better than any text blocks of BT does.
 Multi-Image-Collapse (Combined), with Single-Image-Collapse (SICollapse), and without any collapse algorithm (NoCollapse). It is much clear that the Multi-Image-Collapse algorithm makes a significant improvement in the retrieval performance over the Single-Image-Collapse algorithm. And the curves also demonstrate that the lower the recall, the better the improvement of the retrieval precision. That means that relevant images are ranked earlier when we employ our Collapse algorithms (especially the Multi-Image-Collapse algorithm) in text block partitioning.
 tag elements; SB 0 : The first block of Body tag element), and p (whole Text of the Web page) as different text scopes from Web pages for semantic extractions of the embedded images. In the experiments, we try to compare their contributions in finding qualified relevant images. We define the images that are contained in a Web image container have higher qualities. Here, five ranks are used as the image qualities based on the total numbers of same topic images on the same Web pages. For example, if the owner page of image i contains over three images on the same topic, i  X  X  quality is defined as 3. Table 2 gives the precisions in finding the first images for different qualities.
 ing images with quality 1. However, its performance dramatically drops down than that of other two approaches when finding the images with qualities over 1. LT + TM + SB quality 1. But the whole text approach makes a great improvement for searching qualified images (0.55 over 0.33 for finding image containers with at least five same topic images). Furthermore, the recall covered by whole text p approach is much better than other two 5 Conclusions and future work This paper provides a novel solution for Web image indexing by using associ-ated texts. We use the whole associated texts as the source for the semantic ex-associated texts into a sequence of text blocks both based on the functions and nested structure of HTML tags within the texts. Within each block, terms X  lo-cal weights are defined as the normalized TFIDF model. To get the relevant fac-tors of the text blocks, a greedy algorithm called Two-Way-Merging is used in local term weight multiplied by the corresponding block factor. Our experiment shows our combined approach is a good balance between retrieval recall and preci-sion. However, the work also shows limitations which need to be addressed in the future: (1) Static sample space. Our derivations of the factors are based on the fixed sam-(2) Greedy inherence. Our Two-Way-Merging algorithm is a greedy searching of (3) Our current system can only support queries by using simple terms with logic (4) Current semantic extractions are only based on the texts. Ideal solutions should References Author Biographies
