 arising from an u nbounded number of latent features. One of the main moti v ations for the IBP modeling paradigms such as mixture models. Consider music tag data collected through the internet R the band.
 tag indie than those associated with tag classical .
 Gibbs sampling procedure and compare performan ce o f our hier archical method with the standard IBP construction on both a dig it modeling task, and a music genre-tagging task. (where  X  k  X  H in dep .  X  k ) and feature v ariables z n, 1: K = [ z nk ] K z z z x characterization of the IBP: the IBP stick-breaking construction [10]. As with the stick-breaking characterization of the random latent feature probabilities via an unbounded sequence. Consider once ag ain the finit e latent f actor model described abo v e. Letting K  X   X  , Z no w possesses an unbounded number of c olumns with a correspond ing unbounded set of random probabilities [  X  y defined as Bernoulli distrib ut ed random quantities: k P ( where J  X   X  and K  X   X  , the prior o v er V will require some addition al structure. J  X   X  and K  X   X  .
 Finally , we augment the model with an additional random matrix A with multinomial elements A { V j z probabilities for e ach of the J trials: P ( z nk = 0 | y n, : , V : ,k ) = # J P ( it is conjug ate to multinomi al sampling.
 the weights V gi v en the assign ment matrix A and the latent feature matrix Y . Let M j k = % times y nj caused the acti v ation of z nk ) and let N j k = % N number of ti mes y : ,j is acti v e: N j = % N for the model parameters  X  j and V j k are gi v en by: as important as we let J  X   X  .
 Ha ving defined the finite model, it remains to tak e the limit as both K  X   X  and J  X   X  . T aking weights V j k remain simple beta distri b utions gi v en the corresponding  X  k (as in Eq. (4)). tions [7] and on the IBP semi-ordered slice sam pler [10], which we emplo y at each layer of the sampler o v er the entire model without approximation.
  X  f actors Y + (those that appear at least once in the dataset, i.e.  X  i : y + Similarly , we separate  X  1:  X  into  X  + Z o where K + is the number of acti v e lo we r -layer f actors. 4.1 Semi-order ed slice sam pling of the upper -lay er IBP The IBP semi-ordered slic e sampler maintains an unordered set of acti v e y + ing  X  + an auxiliary slice v ariable s y .
 feature:  X  non-truncated distrib ution p ( Y ,  X  1:  X  ) without approximation.
 Sample  X  o tially dra w an ordered set of J o posterior feature probabilit ies from the distrib ution: p (  X  o until  X  o corresponding features y o V
T = [ ( V + binary feature v alues z nk , we update each y nj as follo ws: binary v ariables is gi v en by: p ( z nk | y n, : , V : ,k ) = (1  X  # Sample  X  + abilities  X  + acti v e set of  X  + responding  X  + 4.2 Semi-order ed slice sam pling of the lo wer -lay er factor model as the smallest probability corresponding to an acti v e feature: Sample  X  o features,  X  o The samples are dra wn accord ing to the distrib ution: Eq. (8) arises from the stick-breaking construction of the IBP and from the e xpression for P ( w  X  K weight matrix V = [ V + on this prior , the data X and parameters  X  , we sample sequentially for ea ch z nk : where f ( x n | z n, : ,  X  ) is the lik elihood function for th e n th data object. Sample A . Gi v en z nk , y + ity , in the e v ent z ik = 1 , to one of the upper -layer feat ures y + and if y + normalization of the distrib u tion. If z nk = 0 , then P ( A nk =  X  ) = 1 . Sample V and  X  +  X  once ag ain use ARS to dra w sam ples of the posterior of  X  + were held constant o v er all e xp eriments, in particular c = 1 and  X   X  = 1 . 5.1 Experiment I: Digits In this e xperiment we took e xamples of images of hand-w ritten digits from the MNIST dataset. MNIST di gits, we augment both the IBP and the hierarchical model with a matrix G of the same as: x n | Z , G,  X  ,  X  2 a de-noising task. Random noise (std=0.5) w as added to a post-processed test set and the models V  X  captured more compactly . 5.2 Experiment II: Music T ags an artist that people are di vi ded whether the y are rock or country . form of binomial probabilities, i.e. to the model defined in Sect. 3, we add the random weights W # B emer ge at the upper layer are associated with the tags (in order of probability):  X   X  and the noisy-or model  X  dram atically out performed the generalized latent linear mo del. via an noisy -or mechanism, the IBP-IBP model models correlations via an AND construct through the interaction of binary f act ors.
 Ackno wledgments The authors ackno wledge the support of NSERC and the Canada Research Chai rs program. W e also the tag data. [1] Robert J. Connor and James E. Mosimann. Concepts of independ ence for proportions with a [3] Finale Doshi-V elez and Zoubin Ghahramni. Correlated nonparametric latent feature models. [5] T om Grif fiths and Zoubin Ghahramani. Infinite latent feature models and the indian b uf fet [7] Hemant Ishw aran and Lancelot F . James. Gibbs sampling methods for stick-breaking priors. [8] Michael K earns and Y ishay Mansour . Exact inference of hidden structure from sample data
