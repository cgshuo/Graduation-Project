 REGULAR PAPER S. Mandal  X  S. P. Chowdhury  X  A. K. Das  X  Bhabatosh Chanda Abstract The requirement of detection and identification of tables from document images is crucial to any document image analysis and digital library system. In this paper we report a very simple but extremely powerful approach to detect tables present in document pages. The algorithm re-lies on the observation that the tables have distinct columns which implies that gaps between the fields are substantially larger than the gaps between the words in text lines. This de-ceptively simple observation has led to the design of a simple but powerful table detection system with low computation cost. Moreover, mathematical foundation of the approach is also established including formation of a regular expression for ease of implementation.
 Keywords Table detection  X  Document image segmentation  X  Digital document library 1 Introduction Millions of paper documents are being produced everyday, adding a never ending wealth of information to the human society. Practical use of these documents demand indexing, viewing, printing and extracting the intended portions in a fast and flexible way through electronic media. With the ma-turity of the document image analysis such systems are com-ing in the market. These include digital document libraries, vectorization of engineering drawings and form processing systems [ 1 , 12 , 13 , 15 , 18 ]tonameafew.
 (DIA) system starts with skew correction and identification of the constituent parts of the document image to text, graph-ics, half-tones, etc. The graphics portion may be vectorised and text portion may be put to OCR. However, any table that may be present in the document needs to be identified and requires special treatment because the fields are inter-related and individually carry a little sense. It may be noted that the table detection/segmentation step may be followed by table recognition step where the aim is to find out the logical or layout structure of the table. For such recognition systems it is usually assumed that the tables are already seg-mented out from the document or the whole document is a table [ 10 ]. In this paper our aim is limited to detection and segmentation of tables in a simple and efficient manner from the scanned document for subsequent processing. Our ap-proach depends on the observation that the tables have dis-tinct columns which implies that the gaps between fields are substantially larger than the gaps between the words in text lines. Indeed this calls for a reasonably homogeneous con-texts with clear rules for the arrangements of the headers and cells of a typical table. Our method works well for typi-cal paper document with Manhattan layout, it may not work for complex document with heterogeneous arrangement of items, which are commonly used by marketing people and magazines that have got very low archival value.
 past works. Proposed work is dealt next in Sect. 3 . Section 4 details experimental result while concluding remarks are given in Sect. 5 . 2 Past work Table detection and segmentation is done by many re-searchers [ 3 , 7 , 21 , 22 ]. Watanabe et al. [ 22 ] have proposed a tree representation to capture the structures of various kinds of tables. Table structure detection is also reported in [ 3 , 11 ]. Zuyev [ 24 ] described a table grid and defined the compound cell and simple cell of a table based on table grid. Node prop-erty matrix is used by Tanaka [ 19 ] in processing of irregu-lar rule lines and generation of HTML files. Unknown table structure analysis is proposed by Belaid [ 2 ]. Tersteegen et al. proposed a system for extraction of tabular structure with the help of predefined reference table [ 20 ] and Tsuruoka [ 21 ] proposed a segmentation method for complex tables includ-ing rule lines and omitted rule lines. A technique is described in [ 7 ] to separate out tables and headings present in docu-ment images. Ramel et al. [ 17 ] used a flexible representa-tion scheme based on clear distinction between the physical table and its logical structure. Detection and extraction of ta-bles are done by the analysis of graphics line present in the table in the context of the representation scheme. For tables without the rule lines a multilevel analysis of the layout of text component is carried out to capture the regularities of the text present in a typical table.
 the textual contents of the document, we describe two rep-resentative [ 10 , 14 ] from them. Individual words in [ 14 ] are clustered and a block segmentation graph is constructed based on the overlaps of the individual items (words) in con-secutive lines. Note that in tables the overlaps are limited to individual columns and the block segmentation graph will be distinctly different from a block of normal text. The authors claim that this approach works fine for ASCII file and may be extended for a scanned document. However, the algo-rithm contains too many heuristics and no guideline is given regarding the choice of the parameters used for segmenta-tion. A structured approach based on dynamic programming is taken [ 10 ] to find out which input line(s) can be taken as a part of a table. This is done by computing some charac-teristics like score , merit and line correlations to ascertain the gain (or loss) if the candidate line is taken ( or rejected) as a part of the table. This approach has a strong theoreti-cal foundation but the couple of empirical constants used in the characteristic measures need to be fixed without apriory knowledge. As a result, the detection rate is limited to 81% for the scanned image and only 83% for ASCII text. This reflects the difficulty in mapping the theoretical proposition to a practical implementation.
 tection and segmentation of tables in this section. However, the reader may see the survey paper by Zanibbi et al. [ 23 ]for a comprehensive and up to date information on this topic. 3Proposedwork The objective of the present work is to find out tables that are present in a scanned document using simple tests on the structural properties of the document. This work is contin-uation of our earlier work on segmentation where the doc-ument image containing text, graphics, half-tones are seg-mented.
 page. Half-tones are removed first [ 6 ]. The image is then binarised [ 16 ] and skew corrected [ 8 ]. Further processing is done column wise; so multicolumn document is stripped into separate columns. Text containing displayed-math zone; particularly matrices/determinants are structurally very sim-ilar to tables. In the next step, we segment displayed-math zones [ 4 ] from the document. Finally, extraction of graphics [ 5 ] is done leaving only text zones which is used as the input for table detection. 3.1 Observation To formulate the rules for detection of the tables from doc-ument images we have scanned 52 pages from books, jour-nals, reports, etc. containing different types of tables. The observations are listed below.  X  Tables may be bounded by boxes. Rows and columns  X  Tables without any box and rule lines are also common.  X  The gap between the fields (columns) is significantly 3.2 Steps for table detection The table detection algorithm depends primarily on (A) for-mation of word blobs in text lines and (B) finding out the set of consecutive text lines which would form a table. As a pre-processing step component labelling is done first and some statistics, namely the medians of the height and width of the components are determined. Using these medians all verti-cal and horizontal rule lines are identified and removed from the image. However, the horizontal rule lines are marked as HL r ( r = 1 , 2 ,..., S ) and stored for future use. Unlike some works on table detection which rely on the presence of the rule lines our approach is to ignore them to design an algorithm for detecting all kind of tables and to extend the gap between the fields; a characteristic which is primarily exploited in our work.
 A. Formation of word blobs in text lines This is done by coalescing the words in a line. Normally a text line would be converted to a single rectangular block while a row of a table would consists of multiple smaller blocks. Such a word coalescing depends on the accuracy in finding the normal word gap and finding out consecutive connected components in a single text line. We next mathe-matically formulate the blob formation.
 nected components C k ( k = 1 , 2 ,..., E ) , as defined in lit-erature [ 9 ] with their usual meanings. Let L ( C k T (
C k ) and B ( C k ) be the four extreme points of C k in four directions (i.e., left, right, top and bottom) respectively. components C a and C b are in the same text line. Then func-tion F may be represented as This may be obtained from the histogram H 1 of distance D between two consecutive connected components C a and C . The distance function D is defined for computing the horizontal distance between any two consecutive connected components C a and C b as follows: ing b = arg min x { L ( C x )  X  R ( C a ) } where ( F ( C AND L ( C x )&gt; R ( C a )) . The histogram H 1 registers the in-termediate character gap of two consecutive characters. It may be noted that if there is only one font in the document then we will get two distinct humps in H 1 ; first one for char-acter gap in a word and the second one for the word gap. An example page and corresponding histogram are shown in Fig. 1 aandb.
 humps however, first hump will be most prominent followed by the second hump. Our intention is to find out the word gap in the normal text in a document page so that we could com-bine the consecutive words into a single blob. For doing so, we have taken the upper boundary (  X  ) of the second hump. Morphological closing operation with a line-structuring el-ement of length v forms the blobs denoted as V w (where w = 1 , 2 ,..., Q ). The blob formation will be dictated by the following two conditions: 1. If there are two connected components C a and C b 2. V m  X  V n = X   X  m , n | ( 1  X  m , n  X  QANDm = n ) ing element is shown in Fig. 2 a.
 B. Selection of candidate text line for table(s) Blobs formed by coalescing the connected components are also connected components. Thus, we can directly apply the previously defined five functions L , R , T , B and F on these blobs. Let there are total N number of distinct text lines which are represented as TEL a ,where a = 1 , 2 ,..., N . blob is not be shared by more than one text line. Two blobs are in same text line if they overlap in horizontal projection, otherwise, they are in different text lines. By horizontal pro-jection we mean projection in the horizontal direction on a vertical line. A number index is assigned to each text line in raster scan order.
 all lines that has more than one blob (see Fig. 2 b). It may be noted that all words in a text line are coalesced to a single blob whereas we get multiple blobs for table rows. Mathe-matically where # (.) counts the number of blobs in a line. Thus, Q indicates that the candidate text line may belongs to a table. enough to detect all potential candidate lines; we may miss some of the rows of the tables. Those lines should be in-cluded to prevent splitting errors. Thus, imposing candida-ture to some of the lines which have not been selected in this step is the next task.
 on a test that whether their immediate neighbours are can-didate lines or not. This calls for the computation of verti-cal gap between any two consecutive lines and a measure of maximum gap g max that should exist between two consecu-tive rows of a table.
 rule line between two consecutive text lines, the gap width between TEL a and TEL a + 1 is computed as g ( a ) = An example histogram H 2 of g ( a ) is shown in Fig. 3 . size of sample is small. As a result we cannot obtain proper value of g max from H 2 . To convert the line spectrum into an equivalent band spectrum, we have applied Gaussian filter on g ( a ) with standard deviation  X  = 0 . 5,  X  is chosen 0.5 as the span of the hump is small. After applying Gaussian filter, the resultant histogram H 3 , is shown in Fig. 4 . In histogram H 3 , the upper boundary of the first as well as the most promi-nent hump is taken as the value of g max . Thus g max is more than the white gap between any two rows of the table but less than the gap between the (i) heading of a table and the table itself, (ii) gaps between two successive tables and (iii) atextlineandatable.
 infer that the text line TEL a belongs to a table if all of the following conditions are satisfied. 1. Q ( TEL a  X  1 ) = 1 2. g ( a  X  1 )  X  g max 3. Q ( TEL a + 1 ) = 1 4. g ( a + 1 )  X  g max where 1 &lt; a &lt; N . This marks those text lines (belong to a table) which initially have not been marked but their neigh-bouring lines were marked to be a part of a table.
 extra lines which are not actually table rows (e.g. table head-ing or paragraph heading) are also marked [see Fig 2b]. These are easily eliminated as isolated lines because no table has a single row. Similarly, if a text line is accidentally coa-lesced into a number of blobs then also it will be eliminated as an isolated text line because its immediate neighbours in the coalesced text are not candidate text lines.
 has been detected as a table to check for multiple humps and troughs. This is done as a measure against getting multiple consecutive text lines as candidate lines with multiple blobs. This can occasionally happen when the interword gaps are stretched in a couple of consecutive lines to solve the text alignment problem.
 lines is given in Fig. 5 .
 modeled by a regular expression as elaborated below. Let an initial candidate text lines be represented as P, non-candidate text line be represented by O, and intermediate gap between two consecutive text lines be represented by G. If the gap is less than or equals to ( g max ) then the string represented by the regular expression PG((PG)  X  (OGPG)) + will correspond to a table in the page. 4 Experimental results The experiments are done on the dataset using document pages from University of Washington X  X  document image database (UW1 and UW2) and our own collection.
 pages contain table(s). Our database images contain mostly text and tables, or text and math. However, some pages have text, tables and math. We have a couple of pages which have got graphics, text and tables and there is no page with all the four components i.e. text, graphics, math and table. All the programmes are written in C and the tests are carried out in a COMPAQ DS 20E server running digital UNIX. shows a few results with pages containing typical tables. The average time for detection and identification of the ta-ble(s) for a page is about 1 s including the pre-processing operations. The results we have got are highly encouraging considering the simplicity and low computation cost of our approach. As stated earlier our approach does not rely on rule lines and performance is equally well for both types of the tables. In fact, we have removed the rule lines as a pre-processing step. It may further be noted that two commonly present items; namely displayed math and graphics which are likely to be confused with tables have been segmented [ 4 , 5 ] in the pre-processing steps. This leads to a clean in-put to the table detection algorithm minimising the chance of errors.
 the results given in Fig. 6 . We see that the algorithm has suc-cessfully singled out different types of tables from the doc-ument pages. There may be multiple tables in a page where text lines are present between the tables [see Fig. 6 a and b] and there may not be any text lines between two successive tables [see Fig. 6 c and d]. Full page table is also segmented as shown in Fig. 6 e and f. In Fig. 6 gandhtwotablesareseg-mented from a page properly rejecting a near tabular struc-ture in between the detected tables. Next in Fig. 6 iandj, a hidden table detection from a page containing a notice is shown. In Fig 6 k and l it is notable that the table is prop-erly detected though there were a few rows with a couple of blank fields; a job which is difficult for any table detection algorithm. Finally, in the last example (Fig. 6 m and n) we see that the second line from the top, which is not a primary candidate line (as it has a single blob) is correctly included in the segmented table as its immediate neighbours are table rows.
 be noted that the chance of insertion error is practically nil implying no or extremely low merging error as reflected in the performance figures. Though the performance of the al-gorithm is very good; it has its blemishes too. It may not be able to separate two tables appearing side by side; though this is rare but in that case merging would be 100% for those tables.If a text block is horizontally adjacent to a ta-ble within a column of page layout, then the proposed al-gorithm merges the two and identifies the whole as a table. Multiline headings may also cause problem as these have bigger fonts with more gaps than the normal one. However, as a discriminating criterion vertical projection profile may help as multiline headings will not have their word gaps in column-like fashion. 5Conclusion We conclude this paper by reiterating the plus points of our approach. First and foremost it is fully automatic with no manual intervention or parameter entry. It can extract all sorts of tables that have homogeneous arrangement of cells in the table body with high segmentation performance and is not affected by the change in font and page style as the blob generation is done based on parameters computed for each page. Moreover, it is based on very simple observation lead-ing to a low-cost high-performance implementation. Finally, a mathematical treatment is presented and also a regular ex-pression is proposed using which the implementation can be done quickly through compiler tools. Work is going on to improve our algorithm:  X  To avoid merging error for multiple tables (or text block  X  Segmentation of tables with heterogeneous placement of References
