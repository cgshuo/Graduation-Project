 The task of coreference resolution involves impos-ing a partition on a set of entity mentions in a docu-ment, where each partition corresponds to some en-tity in an underlying discourse model. Most work treats coreference resolution as a binary classifica-tion task in which each decision is made in a pair-wise fashion, independently of the others (McCarthy and Lehnert, 1995; Soon et al., 2001; Ng and Cardie, 2002b; Morton, 2000; Kehler et al., 2004).

There are two major drawbacks with most sys-tems that make pairwise coreference decisions. The first is that identification of anaphora is done implic-itly as part of the coreference resolution. Two com-mon types of errors with these systems are cases where: (i) the system mistakenly identifies an an-tecedent for non-anaphoric mentions, and (ii) the system does not try to resolve an actual anaphoric mention. To reduce such errors, Ng and Cardie (2002a) and Ng (2004) use an anaphoricity classi-fier  X  X hich has the sole task of saying whether or not any antecedents should be identified for each mention X  as a filter for their coreference system. They achieve higher performance by doing so; how-ever, their setup uses the two classifiers in a cascade. This requires careful determination of an anaphoric-ity threshold in order to not remove too many men-tions from consideration (Ng, 2004). This sensi-tivity is unsurprising, given that the tasks are co-dependent.

The second problem is that most coreference sys-tems make each decision independently of previous ones in a greedy fashion (McCallum and Wellner, 2004). Clearly, the determination of membership of a particular mention into a partition should be condi-tioned on how well it matches the entity as a whole. Since independence between decisions is an unwar-ranted assumption for the task, models that consider a more global context are likely to be more appropri-ate. Recent work has examined such models; Luo et al. (2004) using Bell trees, and McCallum and Well-ner (2004) using conditional random fields, and Ng (2005) using rerankers.

In this paper, we propose to recast the task of coreference resolution as an optimization problem, namely an integer linear programming (ILP) prob-lem. This framework has several properties that make it highly suitable for addressing the two afore-mentioned problems. The first is that it can uti-lize existing classifiers; ILP performs global infer-ence based on their output rather than formulating a new inference procedure for solving the basic task. Second, the ILP approach supports inference over multiple classifiers, without having to fiddle with special parameterization. Third, it is much more efficient than conditional random fields, especially when long-distance features are utilized (Roth and Yih, 2005). Finally, it is straightforward to create categorical global constraints with ILP; this is done in a declarative manner using inequalities on the as-signments to indicator variables.

This paper focuses on the first problem, and proposes to model anaphoricity determination and coreference resolution as a joint task, wherein the decisions made by each locally trained model are mutually constrained. The presentation of the ILP model proceeds in two steps. In the first, interme-diary step, we simply use ILP to find a global as-signment based on decisions made by the corefer-ence classifier alone. The resulting assignment is one that maximally agrees with the decisions of the classifier, that is, where all and only the links pre-dicted to be coreferential are used for constructing the chains. This is in contrast with the usual clus-tering algorithms, in which a unique antecedent is typically picked for each anaphor (e.g., the most probable or the most recent). The second step pro-vides the joint formulation: the coreference classi-fier is now combined with an anaphoricity classifier and constraints are added to ensure that the ultimate coreference and anaphoricity decisions are mutually consistent. Both of these formulations achieve sig-nificant performance gains over the base classifier. Specifically, the joint model achieves f -score im-provements of 3.7-5.3% on three datasets.

We begin by presenting the basic coreference classifier and anaphoricity classifier and their per-formance, including an upperbound that shows the limitation of using them in a cascade. We then give the details of our ILP formulations and evaluate their performance with respect to each other and the base classifier. The classification approach tackles coreference in two steps by: (i) estimating the probability, P
C ( COREF | X  i, j  X  ) come given a pair of mentions  X  i, j  X  , and (ii) apply-ing a selection algorithm that will single out a unique candidate out of the subset of candidates i for which the probability P lar value (typically .5).

We use a maximum entropy model for the coref-erence classifier. Such models are well-suited for coreference, because they are able to handle many different, potentially overlapping learning features without making independence assumptions. Previ-ous work on coreference using maximum entropy includes (Kehler, 1997; Morton, 1999; Morton, 2000). The model is defined in a standard fashion as follows: P
C ( COREF | X  i, j  X  ) = Z (  X  i, j  X  ) is a normalization factor over both out-comes ( COREF and  X  COREF ). Model parameters are estimated using maximum entropy (Berger et al., 1996). Specifically, we estimate parameters with the limited memory variable metric algorithm imple-mented in the Toolkit for Advanced Discriminative with a variance of 1000  X  no attempt was made to optimize this value.

Training instances for the coreference classifier are constructed based on pairs of mentions of the form  X  i, j  X  , where j and i are the descriptions for an anaphor and one of its candidate antecedents, re-spectively. Each such pair is assigned either a label COREF (i.e. a positive instance) or a label  X  COREF (i.e. a negative instance) depending on whether or not the two mentions corefer. In generating the train-ing data, we followed the method of (Soon et al., 2001) creating for each anaphor: (i) a positive in-stance for the pair  X  i, j  X  where i is the closest an-tecedent for j , and (ii) a negative instance for each pair  X  i, k  X  where k intervenes between i and j .
Once trained, the classifier is used to create a set of coreferential links for each test document; these links in turn define a partition over the entire set of mentions. In the system of Soon et. al. (2001) sys-tem, this is done by pairing each mention j with each preceding mention i . Each test instance  X  i, j  X  thus formed is then evaluated by the classifier, which re-turns a probability representing the likelihood that these two mentions are coreferential. Soon et. al. (2001) use  X  X losest-First X  selection: that is, the pro-cess terminates as soon as an antecedent (i.e., a test instance with probability &gt; . 5 ) is found or the be-ginning of the text is reached. Another option is to pick the antecedent with the best overall probability (Ng and Cardie, 2002b).

Our features for the coreference classifier fall into three main categories: (i) features of the anaphor, (ii) features of antecedent mention, and (iii) relational features (i.e., features that describe properties which hold between the two mentions, e.g. distance). This feature set is similar (though not equivalent) to that used by Ng and Cardie (2002a). We omit details here for the sake of brevity  X  the ILP systems we employ here could be equally well applied to many different base classifiers using many different fea-ture sets. As mentioned in the introduction, coreference clas-sifiers such as that presented in section 2 suf-fer from errors in which (a) they assign an an-tecedent to a non-anaphor mention or (b) they as-sign no antecedents to an anaphoric mention. Ng and Cardie (2002a) suggest overcoming such fail-ings by augmenting their coreference classifier with an anaphoricity classifier which acts as a filter dur-ing model usage. Only the mentions that are deemed anaphoric are considered for coreference resolu-tion. Interestingly, they find a degredation in per-formance. In particular, they obtain significant im-provements in precision, but with larger losses in recall (especially for proper names and common nouns). To counteract this, they add ad hoc con-straints based on string matching and extended men-tion matching which force certain mentions to be resolved as anaphors regardless of the anaphoric-ity classifier. This allows them to improve overall f -scores by 1-3%. Ng (2004) obtains f -score im-provements of 2.8-4.5% by tuning the anaphoricity threshold on held-out data.

The task for the anaphoricity determination com-ponent is the following: one wants to decide for each mention i in a document whether i is anaphoric or not. That is, this task can be performed using a sim-ple binary classifier with two outcomes: ANAPH and  X  ANAPH . The classifier estimates the conditional probabilities P ( ANAPH | i ) and predicts ANAPH for i when P ( ANAPH | i ) &gt; . 5 .

We use the following model for our anaphoricity classifier:
P A ( ANAPH | i ) = This model is trained in the same manner as the coreference classifier, also with a Gaussian prior with a variance of 1000.

The features used for the anaphoricity classifier are quite simple. They include information regard-ing (1) the mention itself, such as the number of words and whether it is a pronoun, and (2) properties of the potential antecedent set, such as the number of preceding mentions and whether there is a previous mention with a matching string. This section provides the performance of the pair-wise coreference classifier, both when used alone (
COREF -PAIRWISE ) and when used in a cascade where the anaphoricity classifier acts as a filter on which mentions should be resolved ( AC -CASCADE ). In both systems, antecedents are determined in the manner described in section 2.

To demonstrate the inherent limitations of cas-cading, we also give results for an oracle sys-tem, ORACLE -LINK , which assumes perfect linkage . That is, it always picks the correct antecedent for an anaphor. Its only errors are due to being un-able to resolve mentions which were marked as non-anaphoric (by the imperfect anaphoricity classifier) when in fact they were anaphoric.

We evaluate these systems on the datasets from the ACE corpus (Phase 2). This corpus is di-vided into three parts, each corresponding to a dif-ferent genre: newspaper texts ( NPAPER ), newswire texts ( NWIRE ), and broadcasted news transcripts (
BNEWS ). Each of these is split into a train part and a devtest part. Progress during the de-velopment phase was determined by using cross-validation on only the training set for the NPAPER ( decisions. section. No human-annotated linguistic information is used in the input. The corpus text was prepro-detector, a tokenizer, a POS tagger, and a Named Entity Recognizer).
 In our experiments, we consider only the true ACE mentions. This is because our focus is on eval-uating pairwise local approaches versus the global ILP approach rather than on building a full coref-erence resolution system. It is worth noting that previous work tends to be vague in both these re-spects: details on mention filtering or providing performance figures for markable identification are rarely given.

Following common practice, results are given in terms of recall and precision according to the stan-dard model-theoretic metric (Vilain et al., 1995). This method operates by comparing the equivalence classes defined by the resolutions produced by the system with the gold standard classes: these are the two  X  X odels X . Roughly, the scores are obtained by determining the minimal perturbations brought to one model in order to map it onto the other model. Recall is computed by trying to map the predicted chains onto the true chains, while precision is com-puted the other way around. We test significant dif-ferences with paired t -tests ( p &lt; . 05 ).
The anaphoricity classifier has an average accu-racy of 80.2% on the three ACE datasets (using a threshold of . 5 ). This score is slightly lower than the scores reported by Ng and Cardie (2002a) for another data set (MUC).

Table 1 summarizes the results, in terms of recall (R), precision (P), and f -score (F) on the three ACE data sets. As can be seen, the AC -CASCADE system generally provides slightly better precision at the ex-pense of recall than the COREF -PAIRWISE system, but the performance varies across the three datasets. The source of this variance is likely due to the fact that we applied a uniform anaphoricity threshold of .5 across all datasets; Ng (2004) optimizes this threshold for each of the datasets: .3 for BNEWS and NWIRE and .35 for NPAPER . This variance re-inforces our argument for determining anaphoricity and coreference jointly.

The limitations of the cascade approach are also shown by the oracle results. Even if we had a sys-tem that can pick the correct antecedents for all truly anaphoric mentions, it would have a maximum re-call of roughly 70% for the different datasets. The results in the previous section demonstrate the limitations of a cascading approach for determin-ing anaphoricity and coreference with separate mod-els. The other thing to note is that the results in general provide a lot of room for improvement  X  this is true for other state-of-the-art systems as well. The integer programming formulation we provide here has qualities which address both of these is-sues. In particular, we define two objective func-tions for coreference resolution to be optimized with ILP. The first uses only information from the coref-erence classifier ( COREF -ILP ) and the second inte-grates both anaphoricity and coreference in a joint formulation ( JOINT -ILP ). Our problem formulation and use of ILP are based on both (Roth and Yih, 2004) and (Barzilay and Lapata, 2006).

For solving the ILP problem, we use lp solve , an open-source linear programming solver which implements the simplex and the Branch-and-Bound cessed to define a distinct ILP problem that is then submitted to the solver. 5.1 COREF -ILP : coreference-only formulation Barzilay and Lapata (2006) use ILP for the problem of aggregation in natural language generation: clus-tering sets of propositions together to create more concise texts. They cast it as a set partitioning prob-lem. This is very much like coreference, where each partition corresponds to an entity in a discourse model.

COREF -ILP uses an objective function that is based on only the coreference classifier and the probabilities it produces. Given that the classifier produces probabilities p assignment cost of commiting to a coreference link is c C  X  i,j  X  =  X  log ( p C ) . A complement assignment cost c C ing not to establish a link. In what follows, M de-notes the set of mentions in the document, and P the set of possible coreference links over these mentions (i.e., P = { X  i, j  X  X  X  i, j  X   X  M  X  M and i &lt; j } ). Fi-nally, we use indicator variables x 1 if mentions i and j are coreferent, and 0 otherwise. The objective function takes the following form: min X subject to: This is essentially identical to Barzilay and Lapata X  X  objective function, except that we consider only pairs in which the i precedes the j (due to the struc-ture of the problem). Also, we minimize rather than maximize due to the fact we transform the model probabilities with  X  log (like Roth and Yih (2004)).
This preliminary objective function merely guar-antees that ILP will find a global assignment that maximally agrees with the decisions made by the coreference classifier. Concretely, this amounts to taking all (and only) those links for which the classi-fier returns a probability above . 5 . This formulation does not yet take advantage of information from a classifier that specializes in anaphoricity; this is the subject of the next section. 5.2 JOINT -ILP : joint anaphoricity-coreference Roth and Yih (2004) use ILP to deal with the joint inference problem of named entity and relation iden-tification. This requires labeling a set of named enti-ties in a text with labels such as person and loca-tion , and identifying relations between them such as spouse of and work for . In theory, each of these tasks would likely benefit from utilizing the infor-mation produced by the other, but if done as a cas-cade will be subject to propogation of errors. Roth and Yih thus set this up as problem in which each task is performed separately; their output is used to assign costs associated with indicator variables in an objective function, which is then minimized subject to constraints that relate the two kinds of outputs. These constraints express qualities of what a global assignment of values for these tasks must respect, such as the fact that the arguments to the spouse of relation must be entities with person labels. Impor-tantly, the ILP objective function encodes not only the best label produced by each classifier for each decision; it utilizes the probabilities (or scores) as-signed to each label and attempts to find a global optimum (subject to the constraints).

The parallels to our anaphoricity/coreference sce-nario are straightforward. The anaphoricity problem is like the problem of identifying the type of entity (where the labels are now ANAPH and  X  ANAPH ), and the coreference problem is like that of determin-ing the relations between mentions (where the labels are now COREF or  X  COREF ).

Based on these parallels, the JOINT -ILP system brings the two decisions of anaphoricity and corefer-ence together by including both in a single objective function and including constraints that ensure the consistency of a solution for both tasks. Let c A c sifier costs for p the anaphoricity classifier assigns to a mention j be-ing anaphoric. Also, we have indicator variables y that are set to 1 if mention j is anaphoric and 0 oth-erwise. The objective function takes the following form: subject to: The structure of this objective function is very sim-ilar to Roth and Yih X  X , except that we do not uti-lize constraint costs in the objective function itself. Roth and Yih use these to make certain combina-tions impossible (like a location being an argument to a spouse of relation); we enforce such effects in the constraint equations instead.

The joint objective function (5) does not constrain the assignment of the x consistent with one another. To enforce consistency, we add further constraints. In what follows, M the set of all mentions preceding mention j in the document.
 Resolve only anaphors : if a pair of mentions  X  i, j  X  is coreferent ( x anaphoric ( y Resolve anaphors : if a mention is anaphoric ( y tecedent. Do not resolve non-anaphors : if a mention is non-anaphoric ( y
These constraints thus directly relate the two tasks. By formulating the problem this way, the de-cisions of the anaphoricity classifier are not taken on faith as they were with AC -CASCADE . Instead, we optimize over consideration of both possibilities in the objective function (relative to the probability output by the classifier) while ensuring that the final assignments respect the signifance of what it is to be anaphoric or non-anaphoric. Table 2 summarizes the results for these different systems. Both ILP systems are significantly better than the baseline system COREF -PAIRWISE . Despite having lower precision than COREF -PAIRWISE , the COREF -ILP system obtains very large gains in recall to end up with overall f -score gains of 4.3%, 4.2%, and 3.0% across BNEWS , NPAPER , and NWIRE , re-spectively. The fundamental reason for the increase in recall and drop in precision is that COREF -ILP can posit multiple antecedents for each mention. This is an extra degree of freedom that allows COREF -ILP to cast a wider net, with a consequent risk of capturing incorrect antecedents. Precision is not completely degraded because the optimization per-formed by ILP utilizes the pairwise probabilities of mention pairs as weights in the objective function to make its assignments. Thus, highly improbable links are still heavily penalized and are not chosen as coreferential.
 The JOINT -ILP system demonstrates the benefit ILP X  X  ability to support joint task formulations. It produces significantly better f -scores by regaining some of the ground on precision lost by COREF -ILP . The most likely source of the improved pre-cision of JOINT -ILP is that weights corresponding to the anaphoricity probabilities and constraints (8) and (10) reduce the number of occurrences of non-anaphors being assigned antecedents. There are also improvements in recall over COREF -ILP for NPAPER and NWIRE . A possible source of this difference is constraint (9), which ensures that mentions which are considered anaphoric must have at least one an-tecedent.
 matically improves recall with relatively small losses in precision, providing overall f -score gains of 5.3%, 4.9%, and 3.7% on the three datasets. As was just demonstrated, ILP provides a principled way to model dependencies between anaphoricity decisions and coreference decisions. In a simi-lar manner, this framework could also be used to capture dependencies among coreference decisions themselves. This option  X  X hich we will leave for future work X  would make such an approach akin to ( COREF -PAIRWISE ), the coreference only ILP system ( COREF -ILP ), and the joint anaphoricity-coreference a number of recent global approaches.

Luo et al. (2004) use Bell trees to represent the search space of the coreference resolution problem (where each leaf is possible partition). The prob-lem is thus recast as that of finding the  X  X est X  path through the tree. Given the rapidly growing size of Bell trees, Luo et al. resort to a beam search al-gorithm and various pruning strategies, potentially resulting in picking a non-optimal solution. The re-sults provided by Luo et al. are difficult to compare with ours, since they use a different evaluation met-ric.

Another global approach to coreference is the application of Conditional Random Fields (CRFs) (McCallum and Wellner, 2004). Although both are global approaches, CRFs and ILP have important differences. ILP uses separate local classifiers which are learned without knowledge of the output con-straints and are then integrated into a larger infer-ence task. CRFs estimate a global model that di-rectly uses the constraints of the domain. This in-volves heavy computations which cause CRFs to generally be slow and inefficient (even using dy-namic programming). Again, the results presented in McCallum and Wellner (2004) are hard to com-pare with our own results. They only consider proper names, and they only tackled the task of identifying the correct antecedent only for mentions which have a true antecedent.

A third global approach is offered by Ng (2005), who proposes a global reranking over partitions gen-erated by different coreference systems. This ap-proach proceeds by first generating 54 candidate partitions, which are each generated by a differ-ent system. These different coreference systems are obtained as combinations over three different learners (C4.5, Ripper, and Maxent), three sam-pling methods, two feature sets (Soon et al., 2001; Ng and Cardie, 2002b), and three clustering al-gorithms (Best-First, Closest-First, and aggressive-merge). The features used by the reranker are of two types: (i) partition-based features which are here simple functions of the local features, and (ii) method-based features which simply identify the coreference system used for generating the given partition. Although this approach leads to significant gains on the both the MUC and the ACE datasets, it has some weaknesses. Most importantly, the dif-ferent systems employed for generating the different partitions are all instances of the local classification approach, and they all use very similar features. This renders them likely to make the same types of errors.
The ILP approach could in fact be integrated with these other approaches, potentially realizing the ad-vantages of multiple global systems, with ILP con-ducting their interactions. We have provided two ILP formulations for resolv-ing coreference and demonstrated their superiority to a pairwise classifier that makes its coreference as-signments greedily.

In particular, we have also shown that ILP pro-vides a natural means to express the use of both anaphoricity classification and coreference classifi-cation in a single system, and that doing so provides even further performance improvements, specifi-cally f -score improvements of 5.3%, 4.9%, and 3.7% over the base coreference classifier on the ACE datasets.

With ILP, it is not necessary to carefully control the anaphoricity threshold. This is in stark contrast to systems which use the anaphoricity classifier as a filter for the coreference classifier in a cascade setup. The ILP objective function incorporates the proba-bilities produced by both classifiers as weights on variables that indicate the ILP assignments for those tasks. The indicator variables associated with those assignments allow several constraints between the tasks to be straightforwardly stated to ensure consis-tency to the assignments. We thus achieve large im-provements with a simple formulation and no fuss. ILP solutions are also obtained very quickly for the objective functions and constraints we use.

In future work, we will explore the use of global constraints, similar to those used by (Barzilay and Lapata, 2006) to improve both precision and recall. For example, we expect transitivity constraints over coreference pairs, as well as constraints on the en-tire partition (e.g., the number of entities in the doc-ument), to help considerably. We will also consider linguistic constraints (e.g., restrictions on pronouns) in order to improve precision.
 We would like to thank Ray Mooney, Rohit Kate, and the three anonymous reviewers for their com-ments. This work was supported by NSF grant IIS-0535154.

