 Various workspace awareness widgets and supporting techniques have been developed for collaborative 2D systems, but little has been done in supporting these widgets in collaborative 3D systems. In this paper, we c ontribute a novel awareness widget  X  televiewpointer , which provides integrated and flexible televiewing and telepointing capabilities in real-time collaborative 3D design systems that allow re laxed WYSIWIS and concurrent work. Distinctive features of the televiewpoint er include: (1) extension of telepointers from 2D to 3D representation with a distant telepointing capability; (2) integration with view frustums to represent users X  view scope and workspace contextual information for telepointing; (3) incorporation of mirror views to provide complementary views to the shared 3D workspace and a distributed radar view; and (4) co mbination with 2D telepointers to provide a flexible telepointing service in multiple working/viewing spaces without requiring users to synchronize their working perspectives. Suppor ting televiewpointers in real-time collaborative 3D designs systems is challenging because the free and concurrent work and te leviewpoint raises a potential problem of inconsistent and incorrect workspace awareness information. This paper discusse s the design rationales behind the proposed televiewpointer features, presents technical solutions in supporting these features and mainta ining their consistencies, and formulates usability hypotheses in relation to these features for future evaluation. All features and techniques reported in this paper have been implemented in the CoMaya collaborative 3D design system. The dem onstration video of the televiewpointer is available at http://cooffice.ntu.edu.sg/comaya/videoTVP.php . D.2.2 [ Software Engineering ]: Design Tools and Techniques  X  User Interfaces; H.5.3 [ Information Interfaces and Presentation ]: Group and Organizational Interfaces  X  Computer-Supported Cooperative Work. Design, Human Factors. Workspace awareness, telepointer, radar view, televiewpointer, real-time collaborative 3D design system, CoMaya. Real-time collaborative editing systems provide shared computational workspaces for multiple users to edit the same text/graphic/image/multimedia documents at the same time over communication networks [1,11,19,20]. Workspace awareness  X  the up-to-the-moment understanding of other persons' interaction with a shared workspace  X  is crucial to achieve fluid and natural collaboration in geographically di stributed environments [11,12]. Supporting workspace awareness has been recognized as one of main technical challenges in building real-time distributed collaborative systems [3,11,20]. As collaborative systems evolve from supporting strict WYSIWIS ( X  X h at You See Is What I See X ) and sequential work to relaxed WYSIWIS and concurrent work, and from supporting two dimensional (2D) workspaces to three dimensional (3D) workspaces, new workspace awareness supporting issues emerge, which motivate new researches and technical innovations. The need for supporting relaxed WYSIWIS and concurrent work has created challenges and inspir ations to prior researches on workspace awareness supporting techniques. In relaxed WYSIWIS environments, users may customize a shared workspace in different ways, including different viewports (i.e. visible portions) of the shared space, different representations of shared objects, and different disp lay formats [16,18]. Such diverse and dynamic viewing options necessitate the radar view awareness widget  X  a miniature overview of the global shared workspace which can help users keep track of where others are and what they are doing in the shared workspace. Relaxed WYSIWIS also complicates the implementation of telepointers  X  a workspace awareness widget that represents remote users' mouse cursor positions. Smart telepointers were invented to achieve correct and consistent pointing in environments where shared objects may have different placements [16]; semantic telepointers were motivated to improve and enrich the meaning of telepointing in environments wh ere users may have different viewports and shared objects may have different representations and locations [10]. The need for supporting free and concurrent work in the shared workspace has caused inconsistency problems for both shared data objects and awareness widgets (telepointers and radar views). Object-associated telepointers were invented to achieve meaningful and consistent pointing in the face of concurrent work in complex document structures [22]. The evolution of collaborative editing systems from 2D to 3D workspaces, combined with the need for supporting relaxed WYSIWIS and concurrent work, has created new challenges and opportunities for workspace awareness supporting technique research. Most workspace awareness widgets and supporting techniques were invented in the context of 2D workspaces; but little has been done in supporting and extending these widgets in collaborative 3D systems [5,8,9, 14,15,21]. The availability of one additional dimension in 3D work spaces creates the need for new representations and functional ex tensions of existing workspace awareness widgets, and requires new techniques for supporting them. In this paper, we report our research findings in supporting workspace awareness in real-time collaborative 3D design systems, which allow multiple designers to view and create shared 3D contents freely and concurrently in real-time over the Internet. The rest of the paper is organize d as follows. First, we briefly describe the collaborative 3D de sign system prototype that has been used as a vehicle for conducting the research reported in this paper. Second, we discuss th e issues and techniques of representing and supporting radar views and telepointers as 2D awareness objects in the 3D system prototype, and examine the limitations of the 2D object repr esentation of awareness widgets in 3D workspaces. Third, we extend the representation and functionality of telepointers from 2D to 3D awareness objects with a distant telepointing capability, and integrate the telepointing function with the televiewing function into a single 3D awareness widget called televiewpointer . Forth, we study the special issues and techniques fo r supporting televiewpointers in unconstrained collaboration environm ents. Fifth, we augment 3D televiewpointers with mirror views to provide a distributed radar view and with 2D telepointe rs to support telepointing in complementary 3D viewing perspectives. Sixth, we compare the televiewpointer work with prior work. Finally, we summarize main contributions of this work and future work. Our research is based on a real-time collaborative 3D design system, CoMaya, which is transparently adapted (TA) from a commercial single-user 3D design system, Autodesk Maya, without changing the source code of the original system [1,19,20]. CoMaya has been used as a research vehicle for studying a range of technical and user interface issues in 3D collaborative systems, including workspace awareness support, conflict resolution, and consistency maintenance. Workspace awareness support is part icularly needed in TA-based systems because the original single-user applications were designed without considering the support for multi-user work. There is a major gap between the single-user interface and the new multi-user collaborative working environment: single-user interfaces are designed to support an individual user in interacting with the computer, but a collaborative environment requires multi-user interfaces that are cap able of supporting users in interacting with people as well as computers. Workspace awareness support can help bridge this gap by providing information about the presence, location, and activities of remote collaborators to facilitate co mmunication and coordination among collaborators. Prior research has shown the effects and importance of workspace awareness support in improving the usability of collaborative systems [3,11,20]. TA-based collaborative systems have the advantages of combining rich functionalities and user interface features of the original commercial single-user applications with advanced multi-user collaboration capabilities, such as relaxed WYSIWIS and concurrent work [20]. However, these advantages also bring special challenges to supporting workspace awareness in TA-based systems, due to the comple xities in relaxed WYSIWIS and concurrent working environments and the transparency constraint (no access to the source codes of original applications) in TA-based collaborative systems. The 3D nature of CoMaya brin gs one additional dimension of complexity to workspace awareness support: how to represent, extend, and support common workspace awareness widgets, such as telepointers and radar views, th at were originally invented for collaborative 2D working envir onments, in collaborative 3D workspaces? The following sections report our research findings and experiences so far in this direction. Most of today X  X  computers use 2D screens for graphical displays. In collaborative applications, a telepointer represents a remote user X  X  mouse cursor position in side the shared workspace displayed on the 2D computer screen. In collaborative 2D workspaces, a telepointer is naturally represented as a 2D object on top of the 2D application window which covers both the data and control areas of the shared workspace [10,11,16,22]. Telepointers become visible to collaborators in the shared 2D workspace as long as their viewports overlap. Collaborators may use telepointers to refer to shared objects of common interest, make gestures [12,13], or merely show their presences in the overlapped 2D workspace. In collaborative 3D applications, users interact with the 3D workspace still via a 2D computer screen, which corresponds to the 2D projection plane inside the 3D workspace (see Figure 1). Therefore, a telepointer can also be represented as a 2D object on Figure 1. A view frustum represent s the view scope of a user. It is bounded by the near and far planes. 3D objects within the frustum are projected onto a 2D projection plane for viewing top of the projection plane. Due to the 3D nature of the shared workspace and the need for relaxed WYSIWIS, collaborators may view different regions of the shared 3D workspace from different perspectives and 2D telepointers may not be visible under those circumstances. For 2D telepointers to be visible in 3D workspaces, it is necessary for users to view the shared workspace from the same perspective. In collaborative 2D workspaces, a radar view can be represented as a single miniature overview of the entire workspace, on which multiple viewports of different users can be superimposed. In the CoWord system [20], for example, a miniature radar view of the whole document is shown on the right side of the main view of each user, with multiple users X  viewports being represented by different transparent colors and labels on top of the single miniature overview. In collaborative 3D workspaces, however, it is impossible to represent multiple users X  viewports with different perspectives on top of a single 3D workspace miniature overview. We proposed one solution, called multi-perspective radar view , to represent the radar view with multiple miniature 3D views, one for each remote user in the collaborative se ssion. This solution can be conveniently supported by TA-bas ed collaborative 3D systems converted from main-stream single-user 3D systems, such as Maya and 3DS Max [1], as these single-user 3D systems are capable of supporting multiple views of the same 3D workspace at the same time. Such multi-viewing capability can be adapted to support the multi-perspective radar view, with each miniature 3D view equipped with a distinctiv e virtual camera for reflecting a remote user X  X  viewing perspective of the shared 3D workspace. The 2D telepointer and multi-pers pective radar view have been implemented in CoMaya. As show n by Item-D of Figure 2, the radar view is displayed on the right side of the main workspace view of the local user. In this ex ample, there are three users in the session, so the radar view consists of two miniature 3D views that reflect the view perspectives of the two remote collaborators (Item-F of Figure 2). In ad dition, one common reference miniature view is provided to represent a common view of the shared 3D workspace for quick reference in group discussions (Item-E of Figure 2). Users can control their view privacy by allowing/disallowing their views to show as miniatures on remote users X  radar views, and the displa y of a remote user X  X  miniature viewport in the radar view is optional and can be switched on or off by the local user. The user can also switch her/his main view of the workspace to/from any remote view or the reference view, and invite/accept to synchronize her/his main view with a remote view, thus getting into the synchronized-view mode. Under the synchronized-view mode, the same region of the shared workspace is displayed in the same perspective. The synchronized-view can be controlled by a single user (the original owner of the view) or multiple users if permitted by the owner. In the case that multiple users concurrently change the synchronized-view, a consistent synchronized-view is achieved by using a distributed synchronization protocol with the help of the underlying Generic Collaboration Engine (GCE) [20]. The synchronized-view mode is a necessary condition for collaborators to view and use 2D telepointers in CoMaya. As an example, Item-C of Figure 2 shows the 2D telepointer of a remote user Alice , who is in the synchronized-view mode with the local user, pointing at the music sheet object on the data area. 2D telepointers are implemented as 2D graphic objects on top of the 3D workspace using the application programming interface (API) of Windows and the target application, Autodesk Maya. Telepointers for different users are distinguished through unique colors and name labels. In the synchronized-view mode, the same region of the shared workspace is shown in the same perspective, but may be shown in different sizes and locations on the screen at different sites. Correct and co nsistent telepointing under such relaxed WYSIWIS environment is achieved by representing and mapping the ( x, y ) coordinate of the mous e cursor location relative to the size and location of the shared workspace window on the screen. 2D telepointers can be used to refer to objects on control panels (Item-A of Figure 2) as well as on data areas (Item-B of implementation of 2D telepoin ters in CoMaya requires an identical application user interface (UI) layout among synchronized collaborating sites to achieve correct and consistent pointing at objects in control pa nels. This restriction can be removed by adopting the smart te lepointing technique in [16], which allows users to customize the style and layout of the application UI according to their personal preferences. As a 2D telepointer is a 2D graphic object mapped onto the 2D projection plane within the 3D workspace, its pointing effect is meaningful only when objects in the shared 3D workspace are viewed from the same projection plane [17]. That is why 2D telepointers are supported only in the synchronized-view mode in CoMaya. Such synchronized pointi ng capability is too restrictive for users because they have to explicitly switch to a synchronized mode to use telepointers, which discourages instant and informal interactions that are often needed in collaborative work. For example, in real-world collaboration scenarios like face-to-face meetings, people often sit at different locations and view common objects (e.g. a screen on the wall or a device on the table) in the meeting room from di fferent angles (perspectives) of the real 3D space. To suppor t communication, people may use their fingers or remote pointing de vices (such as laser pointers) to point at objects within their comm on sights, but they rarely need to move away from their sitting positions (thus changing their view perspectives) to achieve a pointing purpose. This is because it is often adequate for people to know what is the target object of a pointing action in informal di scussions; viewing the target object from exactly the same perspective may add little additional value for many communications. In advanced collaborative 3D applications, such as CoMaya , that support relaxed WYSIWIS and concurrent work, users are a llowed to freely and concurrently work from any perspective of the 3D workspace, why not allow them to freely use and view telepointers from any perspectives in the 3D workspace as well? We believe that such free telepointing capability can facilitate effortless initiation of communication and promote instant and ad hoc interaction among collaborators ( Usability Hypothesis 1 to be tested in future study ). In the multi-perspective radar vi ew, each user X  X  viewport is displayed in a separate miniature view outside the 3D workspace. Such isolated representation of a viewport does not capture the relative positions among different viewports within the shared 3D workspace. A user can switch to any remote user X  X  viewport for details, but s/he cannot easily j udge the remote user's relative viewing location, orientation and scope, which is often needed in the real-world collaborative work. In face-to-face meetings, for example, people can see each others and hence know their relative location and orientation in the same real 3D space. When someone points at a shared object for communication, s/he can judge whether or not the referred object is within the common sight (so other people can see it ) based on her/his awareness of other people X  X  location and orient ation. Other people may also adjust their location and/or orientation if necessary according to the relative relationship between the pointing direction, target object location, and their own locations. Based on these observations, we believe that it coul d be beneficial to integrate the information of another person X  X  vi ewing location, orientation and cope with the telepointer inside the shared 3D workspace to support and effectively use telepointing in 3D workspaces ( Usability Hypothesis 2 to be tested in future study ). The limitations of 2D telepoint ers and multi-perspective radar views have motivated the extension of telepointers from 2D to 3D representation and from local to distant pointing capability, and the integration of the telepointing function with the televiewing function (expressing remote users X  viewing orientation and scope) in the 3D workspace, which are discussed in the next section. To support flexible use and viewing of telepointers in 3D workspaces, we propose to represent telepointers as 3D awareness objects inside the 3D workspace. The location of a 3D telepointer inside the 3D workspace is determined by: (1) the mapping of the native mouse cursor position on the mouse user X  X  projection plane of the 3D workspace; and (2) the position of this projection plane inside the 3D workspace (see Figure 1). Therefore, a 3D telepointer changes its position when the mouse user moves the mouse cursor on the 2D screen (thus changes its position on the projection plane), or changes th e projection plane (by zooming in/out, rotating the viewport, or changing the viewing perspective). With this 3D repr esentation and embedment, users can see a 3D telepointer object through their normal 3D workspaces and from different perspectives, without the need to switch to the synchronized-view mode. A pointing action establishes a pointer-target association relationship between the pointing de vice and the pointed target. In single-user interactive (2D or 3D) applications, users use the mouse cursor to point at objects , and a pointer-target association can be established by placing the mouse cursor on top of the target object. Collaborative applicat ions should not change this experience of pointing using a m ouse. With the 3D telepointer representation and embedment, however, a subtle difference arises between the local and remote pointer-target association visual effects. From the local mouse use r X  X  point of view , an object is pointed if the mouse cursor overl aps with this target object from the local user X  X  viewing perspective. For example, if the mouse cursor X  X  position and the user X  X  vi ewing perspective are as shown in Figure 3-(a), the target object is the music sheet that is directly under the cursor. However, this local pointer-target association effect may not be visible fr om a remote user X  X  viewing perspective. This is because there may be a gap between the telepointer and the target object in the 3D workspace (see Figure 3-(b)), and the remote user may not be able to establish the telepointer-target associ ation unless: (1) the space gap is zero (i.e. the telepointer object touches the target object), or (2) the remote viewer of the telepointer has the same viewing perspective as the local mouse user (typically in the synchronized-view mode). As discussed in Section 3.4, forcin g users to synchronize their views is not an option for supporting flexible telepointing in 3D workspaces, and requiring a user to place the telepointer adjacent to the target object in the 3D workspace is undesirable as this would change the way users use a mouse for pointing. To solve the remote telepointer-target association problem, we propose to use a virtual light beam from the telepointer to the target object for establishing an explicit visual association between a telepointer and its target (as shown in Figure 3-(c)). The length of the telepointer light beam equals to the distance between the telepointer and the target object in the pointing direction in the 3D workspace. The length of the light beam reduces to zero when the telepointer is adjacent to the target object; the light beam extends towards the far end of the 3D workspace when there exists no object along the pointing direction. A telepointer with a virtual light beam is similar to a remote pointer like a laser pointer, which people often use to point at distant objects in the real-world 3D space. Therefore, the telepointer light beam not only solves the remote telepointer-target association problem, but also provides a new distant telepointing capability, which is particularly useful in the 3D workspace with infinite space and different viewing perspectives. Distant telepointing allows a mous e user to point and other users to view the pointed object w ithout changing their viewing positions or perspectives. Even when only the telepointer light beam is visible without the target object in the viewing scope, users can use the light beam as the visual clue to locate the target. Distant telepointing also has a uni que capability of pointing at the 3D space, such as for indicating directions or locations (e.g. through interactions of multiple li ght beams) in the space, which is otherwise impossible. As discussed in Section 3.3, eff ective use of telepointers in 3D workspaces requires users to have the awareness knowledge of remote users X  viewing directions and scope, embedded in the 3D workspace as well. The technical issue is how to capture and represent such awareness knowledge in the 3D workspace. We found that the 3D telepointer is a good vehicle to host and display the mouse user X  X  view orientation and scope. A 3D telepointer has a direction, which can be used to represent the mouse user X  X  view direction as well. Instead of be ing mapped to the actual projection plane, telepointers can also be ma pped onto a virtual plane on the closest visible point of the mouse user in parallel to the projection plane (i.e. the near plane in Figure 1), which indicates the starting plane of mouse user X  X  view scope . Therefore, the user X  X  view scope can be displayed using the telepointer as a reference point in the 3D workspace. The view scope takes the form of a frustum (i.e. a truncated pyramid as shown in Figure 1) and shares the same color as the telepointer but with customizable transparency level for controlling the visibility level of objects within it. A view frustum changes whenever the mouse user changes the view by shifting the visible region, rotating the view, or zooming in/out the 3D space. The view frustum thus gives information on what objects are visible to the mouse user at that moment, and hence gives knowledge on whether a pointed 3D object is within the visual scope of other users. As an ex ample in Figure 1, the piano and cushion of the stool are within th e view frustum, thus pointing at these objects can be seen by the view owner. But the legs of the stool are not within the viewing frustum, thus neither the legs of the stool nor the pointing at them is viewable to the view owner. With these extensions, a 3D telepointer becomes a 3D awareness object with integrated capabilities of telepointing and televiewing, which is called 3D televiewpointer . The awareness features of a televiewpointer are controllable by users. A televiewpointer may be shown as a simple 3D telepoi nter (Figure 3-(b)), a distant telepointer with a li ght beam (Figure 3-(c )), or a full-fledged televiewpointer with a light beam and view frustum starting from a webcam-like object (Figure 4). The control is bidirectional: the local user can control the level of working privacy (to show/hide the mouse movements and/or view changes on remote televiewpointers); and remote users can control the level of awareness (what, how, and whos e awareness information to display) based on their collaborati on needs. The control by remote 
Figure 3. Pointer-target association. (a) the mouse cursor overlaps with the target object (the music sheet) at the local site (with a user name Alice) ; (b) a simple 3D telepointer oriented towards the target at a remote site; and (c) a 3D telepointer with a virtual light be am terminated at the target at users is also beneficial to avoi d occlusion of data objects and cluttering of the display [10,18]. Unconstrained collaboration environments allow multiple users to view, point, and edit shared objects freely and concurrently. As televiewpointers are represented as awareness objects inside the 3D workspace and have pointer-target association relationships with data objects, they are subject to concurrency control and consistency maintenance. A televiewpointer should reflect the corresponding mouse X  X  current cursor position on the projecti on plane and the view scope and direction of the mouse user. We need to detect local mouse cursor movements and view cha nges, and propagate them as televiewpointer update operations to remote sites to adjust televiewpointers accordingly. Temporary inconsistency of televiewpointers may occur in the period after the local mouse/view change and before the televiewpointer update operation is executed at a remote site. The impact of such inconsistency on users depends on the frequency of propagating the mouse movements and view changes, and the communication latency among collaborating sites. Th ese issues are not special to 3D televiewpointers and also occur to 2D telepointers [12,22]. There is one issue special to televiewpointers: consistency maintenance of pointer-target asso ciation relationships. A pointer-target association relationship involves two objects in the 3D workspace: the televiewpointer awareness object and the target data object. A pointer-target association relationship is represented by the virtual light beam between the televiewpointer and the target. This representation is correct if the associated target object is the one that is the closest to the televiewpointer object in the pointing direction. For example, as shown in Figure 5-(b), the associated target object is the keyboard of the piano , which is the closest object to the televiewpointer in the pointing direction. This rela tionship is dynamic in nature and can be changed by: (1) mouse move or vi ew change operations (by the local mouse user), or (2) editing operations that updates the target object or other data objects (by remote users). In unconstrained collaborative working envir onments, multiple users can concurrently generate these po inter-target changing operations. Televiewpointers representations and pointer-target association relationships are consistent if after executing the same set of mouse/view changing and editing operations, they are identical across all collaborating sites. To maintain consistent pointer-tar get association relationships, we need to detect and propagate all actions that may change pointer-target association relationships. When the change of a pointer-target association relationship is triggered through a mouse cursor movement or view change by the mouse user, the local new pointer-target association is established instantly by the fact that the mouse cursor overlaps wi th a new object underneath. A televiewpointer update operation should be generated to capture this change and propagated to remote sites to adjust remote televiewpointers representations and pointer-target association relationships. One naive way of capturing and establishing the new pointer-target association coul d be: find the new target object under the mouse at the lo cal site and record the identifiers of the new target and the mouse in a televiewpointer update operation (together with other parameters); and use the recorded identifiers to find the target and televiewpointer and to establish the new 
Figure 5. (a) The local mouse points at the keyboard of the piano; (b) a correct pointer-target association at a remote site where the workspace state is the same as in (a) but viewed from another perspective; (c) an incorrect pointer-target association at a remote site where workspace state is different from (a): the televiewpointer light beam penetrates through the stool and terminates at the keyboard; and (d) a correct pointer-target association at the same remote site as in (c), where the televiewpointer light beam terminates at the stool.
Figure 4. A full-fled ged televiewpointer with the light beam pointer-target association at each destination site. This scheme works only if the destination workspace state is the same as the local workspace state from which the televiewpointer update operation was genera ted, but fails in the face of concurrent editing and televiewpointer update operations. Before the televiewpointer update operation arrives at a remote site, the remote workspace state may have been changed concurrently by other users, e.g. the original target object may have been moved to a different place in the 3D workspace or a new object may have been moved into a position in-between the televiewpointer and the original target along the pointing direction. If the pointer-target a ssociation re-establishment were based on the target identifier captured when the televiewpointer update operation was generated, then the new pointer-target association would be incorrect. For example, suppose the local mouse is moved to point at the ke yboard as shown in Figure 5-(a). This move will generate a tele viewpointer update operation that carries the identifier of the keyboard for pointer-target association re-establishment at remote site s. In Figure 5-(b), a remote workspace state is the same as that in Figure 5-(a) but from another viewing perspective, so establishing the pointer-target association based on the identifier of the keyboard will achieve a correct televiewpointing effect. Ho wever, if a remote user has concurrently moved up the stool object which is now the closest object from the televiewpointer direction, using the identifier of the keyboard to find the target would establish an incorrect pointer-target association as shown in Figure 5-(c) (where the light beam penetrates through the stool object and terminates at the keyboard object); the correct new pointer-object association should be what shown in Figure 5-(d) (where the light beam terminates at the new target, stool object). Clearly, correct establishment of a new pointer-target association cannot be achieved without taking into account the new state of the destination workspace. To solve this problem, we propose a Dynamic Target Searching (DTS) scheme to find the correct new target object in a dynamically changing workspace. The DTS scheme is invoked whenever a new pointer-target association needs to be established. televiewpointer object, search the current workspace in the televiewpointer X  X  direction to find the object that is the closest to the televiewpointer; if such an object is found, it is the target, otherwise the far plane (see Figure 1) of the 3D workspace is the target. The search for the target object is guided by the position and direction of the relevant tele viewpointer in the 3D workspace. The original target object information captured at the time of generating the televiewpointer upda te operation may also be used as a useful hint to quickly find the target without a search in common cases. When the change of a pointer-tar get association relationship is triggered by an editing operation wh ich moves/deletes the original target object or moves/creates a new object in-between the televiewpointer and the original target, the new pointer-target association should be established fi rst at the site where the editing operation was generated by a pplying the DTS scheme to televiewpointers at that site. Then, a target update operation is propagated to remote sites for maintaining the pointer-target association consistency. A target update operation can always be piggybacked on the corresponding editing operation which must also be propagated to remote sites for maintaining data consistency. After executing a re mote editing operation, the DTS scheme can be invoked to help establish new pointer-target association relationships (if any) at each site. Complex objects are common desi gn results using main-stream 3D design applications that have powerful 3D capabilities, such as Autodesk Maya. As the complexity of the shape of an object increases in a real world 3D design, it is important for a televiewpointer light beam to end at the correct spot on the target object as pointed by the mouse user. A complex object, such as a piano model, can be divided into multiple parts (such as keyboard, pedals, frame, etc). Unless the correct part is pointed by televiewpointers, the goal of co mmunication may not be achieved: telepointing at the pedals of th e piano model may cause confusion to a discussion that is intended for the keyboard part of the piano. Fine-grained telepointing at a spot on a target object can be supported by adding one additional step in the DTS scheme: after the closest object to the teleview pointer is found, the intersection point between the televiewpointer light beam and the target object is identified to be the ending point of the televiewpointer light beam. With this fine-grained DT S scheme, the establishment of a pointer-target association is essentially the determination of the orientation and the length of the light beam between the televiewpointer and the intersection point. The problem of searching the workspace for a target object and an ending point is similar to the problem of ray-cas ting, which is used in computer graphics to find objects that are intersected by a ray [7]. There exist algorithms in computer gra phics and suitable API in 3D graphics systems (like Autodesk Maya) for efficiently searching objects and determining intersection points [2,4]. The 3D televiewpointer is not a replacement but complementary to multi-perspective radar views and 2D telepointers. For example, the view frustum of a televiewpointer gives information about the view scope of a user within the 3D workspace, but does not show exactly what the othe r user sees, which is what viewports in a radar view can suppor t. In this section, we discuss how to combine the complement ary awareness support techniques together to provide powerful and integrated awareness supporting widgets in collaborative 3D workspaces. There is a need and a way to combine the complementary capabilities of the televiewponter and the radar view in one awareness widget. In a 3D workspace, multiple users often work on shared objects from different pe rspectives. With the support of televiewpointers, users can see each others' mouse cursor direction and view scope through the normal 3D workspace when their view perspectives overlap. In Figure 6, Tina's view is largely overlapping with Alice's view, so Tina and Alice can effectively use their televiewpointers for telepointing within the 3D workspace because both users can see the pointed target (with the help of the light beam, Tina can see that Alice is pointing at the music sheet) and know the other person's view scope (with the help of the view frustum). However, when users are working from perspectives with little or no overlap, e.g. in opposite perspectives, their views of the 3D workspace can be characterized as  X  X  See What You Do Not See X  (ISWYDNS). As shown in Figure 6, Tina's view perspective is opposite to Bob's, and each user s ees what the other user does not see. Through Bob's view frustum, Tina knows the orientation of Bob's view but knows nothing a bout what Bob actually sees. Under such ISWYDNS circumstances , the televiewpointer is not able to provide adequate support for televiewing or telepointing because users have no common view and do not know what the other user is seeing or pointing. Inspired by real-world mirrors which reflect the opposite perspective of a viewer and by the nature of a viewport which reflects the perspective of a remote user, we propose to augment each televiewpointer with a mirror view , which is a miniature viewport for the corresponding user. The mirror view provides a  X  X  See What You See X  (ISWYS) televiewing capability without forcing the users to synchronize their working perspectives. As shown in Figure 6, with Bob X  X  mi rror view, Tina is able to see exactly what Bob sees, so Tina and Bob can talk about the objects in their shared views (the Bob's mirror view at Tina site and the main view at Bob site) in their communications. The combination of ISWYDNS (provided by the main workspace view) and ISWYS (provided by the mirror vi ew) gives full coverage of the complementary views of two user s working in none-overlapping perspectives in 3D workspaces. A mirror view is by default positioned at the starting point of the corresponding televiewpointer to provide association and contextual information (e.g. Alice X  X  mirror view in Figure 6); but a user may re-position (and re-size) a mirror view to any convenient place on the screen (e.g. Bob X  X  mirror view in Figure 6). By augmenting each teleview pointer with a mirror view, we effectively create a distributed multi-perspective radar view situated inside the 3D workspace. In contrast to the centralized multi-perspective radar view (see Item-D in Figure 2), we believe the distributed radar view is more usable because mirror views are situated in the 3D workspace context, which can help users better understand and interpret what they see from these views ( Usability Hypothesis 3 to be tested in future study ). 3D televiewpointers and 2D tele pointers are complementary as well. For example, 2D telepointers can be used to point at objects in control panels of the application, which cannot be achieved by 3D televiewpointers. Even w ithin the 3D data area, 2D telepointers can complement 3D televiewpointers to provide additional telepointing capability, as discussed below. With mirror views, users working in none-overlapping perspectives can see what others see, but cannot point at objects in mirror views by using 3D televi ewpointers. This is because a televiewpointer can represent only a user's viewport and mouse cursor in the current main workspace view, but not in a mirror view. One option would be to switch the main workspace view to a mirror view (as discussed in Section 3.3) so that the televiewpointer can be used. However, this would require a user to change the working perspectiv e for the sake of telepointing, which contradicts to the original purpose of the televiewpointer: to provide a flexible telepointing service in 3D workspaces without forcing users to synchronize their working view perspectives. We observed that a mirror view reflects what a remote user sees, which is exactly what the synchronized-view mode can provide for using 2D telepointers. Therefore, we decided to augment mirror views with 2D telepointers to support telepointing from a mirror view to the corresponding main view. For example in Figure 6, Tina sees, from her main working space, Bob is pointing at an object which is not visibl e from Tina X  X  main working space. But from Bob X  X  mirror view, Tina can see that Bob is pointing at the rose on the back of the piano as Bob X  X  televiewpointer (a solid blue dot with a name label Bob ) is on top of the rose in Bob X  X  mirror view. To communicate with Bob via the mirror view, Tina can move her mouse cursor over B ob X  X  mirror view to point at the rose as well, and Tina X  X  mouse in the mirror view is represented as a 2D telepointer (with a name label Tina ) in Bob's main view (as shown in Bob X  X  working space in Figure 6). Generally, when a mouse cursor is within a mirror view, it is represented as a 2D telepoint er in the corresponding main working view; when a mouse curs or is within a main working view, it is always represented as a 3D televiewpointer in remote (main or mirror) views. It should be pointed out that, regardless whether a mouse cursor is represen ted as a 3D televiewpointer or as a 2D telepointer at a remote site, the user's experience of pointing at objects using the mous e cursor is exactly the same. Representing telepointers as 3D objec ts has been explored in prior work mainly in 3D virtual envi ronments [8,9,14,15,21]. In DIVE [9], the telepointing takes a form of 3D virtual pointing arrow placed adjacent to the pointed object. In cWorld [21], the 3D telepointer is drawn along the user X  X  view orientation, pointing at the object of interest. In [9,14] , a telepointing action is made explicit by raising and extending one arm of the corresponding user X  X  avatar to touch the point ed 3D object. Also, expressing users X  viewing scope inside the 3D workspace has been seen in prior work on collaborative 3D virtual environments, in different representations: view frustum in [9 ,14] and view cone in [5]. The televiewpointer work reported in this paper distinguishes itself from prior work in the following aspects: 1. The televiewpointer integrates televiewing and telepointing 2. The televiewpointer is augmented with a mirror view, which 3. The 3D televiewpointer is combined with the 2D telepointer In this paper, we have contributed a novel awareness widget  X  televiewpointer, which provides integrated televiewing and telepointing capabilities in colla borative 3D design applications that support relaxed WYSIWIS and concurrent work. Distinctive features of the televiewpoint er include: (1) extension of telepointers from 2D to 3D repres entation to provide flexible and distant pointing capabilities in 3D workspaces; (2) integration with view frustums to reflect users X  view scope and provide contextual information for telepointing in 3D workspaces; (3) integration with mirror views to provide complementary views to the 3D workspace and a distributed and context-related radar view; and (4) combination with 2D telepointers to provide flexible telepointing services in 3D main and mirror views and in 2D control panels of the applicat ion, without requiring users to synchronize their working perspectiv es or change their ways of using the mouse for pointing. In this paper, we have discusse d in detail the rationales behind the proposed televiewpointer features and the technical issues and solutions in supporting these featur es. We have also discussed a special consistency issue of te leviewpointers in unconstrained collaboration environment and presented a simple but elegant televiewpointer consistency main tenance scheme. In addition, several usability hypotheses relate d to these features have been formulated and will be tested in future usability studies. Last but not least, all televiewpoi nter features discussed in this paper have been implemented in CoMaya  X  a real-time collaborative 3D design system that is transparen tly converted from a commercial off-the-shelf digital media desi gn tool, Autodesk Maya. This work, however, is applicable to any collaborative 3D systems, whether transparently adapted or built from scratch. The demonstration video of the televiewpointer can be found at http://cooffice.ntu.edu. sg/comaya/videoTVP.php . The CoMaya system prototype provides a vehicle to test the feasibility of the proposed features and to evaluate the usability of these features (within lab-based a nd/or real-world settings) in the future. The UI design of the te leviewpointer features in the prototype system is quite primitive and for proof of concept only; they can be significantly improved in future work based on end-user feedbacks and/or lab-based usability studies. From this work, we have also learned that the transparent adaptation technology can not only leverage existing single-user applications for collaborative use, but also inspire and enable collaborative technology innovation (e.g. awareness support, consistency maintenance) based on existing functionalities and interface features in commercial single-user applications. This work is still ongoing and follow-up results will be reported in future papers. This work is supported in part by the Agency of Science, Technology and Research (A*STAR) of Singapore under SERC Grant 0621010034. The authors wish to thank Autodesk Research for donating Maya licenses for supporting this work, and anonymous reviewers for their va luable feedbacks which have helped improve the presentation of the paper. [1] Agustina, F. Liu, S. Xia, H. Shen, and C. Sun. CoMaya: [2] J. Amanatides, and A. Woo. A fast voxel traversal algorithm [3] J. Begole, M. Rosson, and C. Sh affer. Flexible collaboration [4] C. Benthin, I. Wald, and P. Slusallek. Interactive ray tracing [5] J. Dyck, and C. Gutwin. Groupspace: a 3D workspace [6] J. Dyck, C. Gutwin, S. Subr amanian, and C. Fedak. High-[7] A. S. Flassner (editor). An introduction to ray tracing. [8] M. Fraser, S. Benford, J. Hindmarsh, and C. Heath. [9] E. Frecon, and A. A. Nou. Building distributed virtual [10] S. Greenberg, C. Gutwin, and M. Roseman. Semantic [11] C. Gutwin and S. Greenberg. The effects of workspace [12] C. Gutwin and R. Penner. Improving interpretation of remote [13] S. Hayne, M. Pendergast, an d S. Greenberg. Implementing [14] J. Hindmarsh, M. Fraser, C. Health, S. Benford, and C. [15] A. Pang and C. Wittenbrink. Collaborative 3D visualization [16] K. J. Rodham and D. R. Olsen. Smart telepointers: [17] L. Shu and W. Flowers. Groupware experiences in three-[18] M. Stefik, D. G. Bobrow, G. Foster, S. Lanning, and D. [19] C. Sun, H. Shen, S. Xia, E. K. Ho, and D. Chen. [20] C. Sun, S. Xia, D. Sun, D. Chen, H. Shen, and W. Cai. [21] S. Valin, A. Francu, H. Trefftz, and I. Marsic. Sharing [22] S. Xia, D. Sun, C. Sun, a nd D. Chen. Object-associated 
