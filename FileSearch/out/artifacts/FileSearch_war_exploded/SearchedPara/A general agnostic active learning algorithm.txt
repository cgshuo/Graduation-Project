 Active learning addresses the issue that, in many applications, labeled data typically comes at a higher cost (e.g. in time, effort) than unlabeled data. An active learner is gi ven unlabeled data and must pay to view any label. The hope is that significantly fewer labeled ex amples are used than in the supervised (non-active) learning model. Active learning applies to a range of data-rich problems such as genomic sequence annotation and speech recogniti on. In this paper we formalize, extend, and provide label complexity guarantees for one of the earliest and simplest approaches to active learning X  X ne due to Cohn, Atlas, and Ladner [1]. The scheme of [1] examines data one by one in a stream and requests the label of any data point about which it is currently unsure. For example, suppose the hypothesis cla ss consists of linear separators in the plane, and assume that the data is linearly separable. L et the first six data be labeled as follows.
 The learner does not need to request the label of the seventh point (indicated by the arro w) because it is not unsure about the label: any straight line with the  X  s and  X  s on opposite sides has the seventh point with the  X  s. Put another way, the point is not in the region of uncertainty [1], the portion of the data space for which there is disagreement among hypotheses consistent with the present labeled data.
 Although very elegant and intuitive, this approach to active learning faces two problems: Our main contribution is to address these problems. We provide a simple generalizat ion of the selective sampling scheme of [1] that tolerates adversarial noise and nev er requests many more labels than a standard agnostic supervised learner would to learn a hypothesis with the same error.
 In the previous example, an agnostic active learner (one that does not assume a perfect separator exists) is actually still uncertain about the label of the seventh point, because all six of the previous labels could be inconsistent with the best separator. T herefore, it should still request the label. On the other hand, after enough points have been labeled, if an unlabeled point occurs at the position shown below, chances are its label is not needed. To extend the notion of uncertainty to the agnostic setting, we divide the sampled data into two groups, S and T : S contains the data for which we have determined the label ourselves (we explain below how to ensure that they are consistent with the best separator i n the class) and T contains the data for which we have explicitly requested a label. Now, somewhat counter-intuitively, the labels in S are completely reliable, whereas the labels in T could be inconsistent with the best separator. To decide if we are uncertain about the la bel of a new point x , we reduce to a supervised learning task: for each possible label  X  y  X  X  X  1 } , we error on T . If, say, the error of the hypothesis h +1 is much larger than that of h  X  1 , we can safely infer that the best separator must also label x with  X  1 without requesting a label; if the error difference is only modest, we explicitly request a label. Standard generali zation bounds for an i.i.d. sample let us perform this test by comparing empirical error s on S  X  T . The last claim may sound awfully suspicious, because S  X  T is not i.i.d.! Indeed, this is in a sense the core sampling problem that has always plagued active learning: the labeled sample T might not be i.i.d. (due to the filtering of examples based on an adaptive criterio n), while S only contains unlabeled examples (with made-up labels). Nevertheless, we prove that in our case, it is in fact correct to effectively pretend S  X  T is an i.i.d. sample. A direct consequence is that the label complexity of our algorithm (the number of labels requested before achieving a desired error) is never much more than the usual sample complexit y of supervised learning (and in some cases, is significantly less).
 An important algorithmic detail is the specific choice of generalization bo und we use in are too loose, e.g. we know in the zero-error case the rate should be n  X  1 . Our algorithm magnifies this small polynomial difference in the bound into an exponential difference in label complexity, so it is crucial for us to use a good bound. We use a normalized b ound that takes into account the empirical error (computed on S  X  T ) of the hypothesis in question. In this paper, we present and analyze a simple agnostic active learning algori thm for general hypothesis classes of bounded VC dimension. It extends the selective sampling scheme of Cohn et al. [1] to the agnostic setting, using normalized generalization bounds, which we apply in a simple but subtle manner. For certain hypothesis classes and distributio ns, our analysis yields improved label complexity guarantees over the standard sample complexity of supervised learning. We also demonstrate such improvements experimentall y. 1.1 Related work Our algorithm extends the selective sampling scheme of Cohn et al. [1] (described abo ve) to the agnostic setting. Most previous work on active learning either makes st rong dis-tributional assumptions (e.g. separability, uniform input distribution) [1 X 8] , or is generally computationally prohibitive [2,4,9]. See [10] for a discussion of these resul ts. A natural way to formulate active learning in the agnostic setting is to ask the learner to return a hypothesis with error at most  X  +  X  (where  X  is the error of the best hypothesis in the specified class) using as few labels as possible. A basic constraint on the la bel complexity was pointed out by K  X a  X ari  X ainen [11], who showed that for any  X   X  (0 , 1 / 2), there are data distributions that force any active learner that achieves error at most  X  +  X  to request  X ((  X / X  ) 2 ) labels. The first rigorously-analyzed agnostic active learning algorithm , called A , was developed recently by Balcan, Beygelzimer, and Langford [9]. Like Cohn-Atl as-Ladner [1], this algorithm uses a region of uncertainty, although the lack of s eparability complicates matters and A 2 ends up explicitly maintaining an  X  -net of the hypothesis space. Subsequently, Hanneke [12] characterized the label complexity of the A 2 algorithm in terms of a parameter called the disagreement coefficient .
 Our work was inspired by both [1] and [9], and we have built heavily upon their ins ights. Our algorithm overcomes their complications by employing reductions to supervised lear ning. 1 We bound the label complexity of our method in terms of the same parameter as used f or A 2 [12], and get a somewhat better dependence (linear rather than quadratic). 2.1 Learning framework and uniform convergence Let X be the input space, D a distribution over X  X { X  1 } and H a class of hypotheses h : X  X  { X  1 } with VC dimension vcdim( H ) = d &lt;  X  (the finiteness ensures the n th shatter coefficient S ( H , n ) is at most O ( n d ) by Sauer X  X  lemma). We denote by D X the marginal of D over X . In our active learning model, the learner receives unlabeled data sampled from D X ; for any sampled point x , it can optionally request the label y sampled from the conditional distribution at x . This process can be viewed as sampling ( x, y ) from D and revealing only x to the learner, keeping the label y hidden unless the learner explicitly where 1l[ ] is the 0-1 indicator function. We assume for simplicity that the minimal error  X  = inf { err D ( h ) : h  X  X } is achieved by a hypothesis h  X   X  X  .
 Our algorithm uses the following normalized uniform convergence bound [14, p. 200] . Lemma 1 (Vapnik and Chervonenkis [15]) . Let F be a family of measurable functions f : Z  X  { 0 , 1 } over a space Z . Denote by E Z f the empirical average of f over a subset distribution over Z , then, with probability at least 1  X   X  , for all f  X  X  : 2.2 Disagreement coefficient We will bound the label complexity of our algorithm in terms of (a slight v ariation of) the disagreement coefficient  X  introduced in [12] for analyzing the label complexity of A 2 . Definition 1. The disagreement metric  X  on H is defined by  X  ( h, h  X  ) = Pr x  X  X  h  X  ( x )] . The disagreement coefficient  X  =  X  ( D , H ,  X  ) &gt; 0 is The quantity  X  bounds the rate at which the disagreement mass of the ball B ( h  X  , r )  X  the probability mass of points on which hypotheses in B ( h  X  , r ) disagree with h  X   X  grows as a function of the radius r . Clearly,  X   X  1 / (  X  +  X  ); furthermore, it is a constant bounded Algorithm 1 Input: stream ( x 1 , x 2 , . . . , x m ) i.i.d. from D X Initially, S 0  X  X  X  and T 0  X  X  X  .
 For n = 1 , 2 , . . . , m : Return h f = LEARN H ( S m , T m ).
 independently of 1 / (  X  +  X  ) in several cases previously considered in the literature [12]. For example, if H is homogeneous linear separators and D X is the uniform distribution over the unit sphere in R d , then  X  =  X ( Here we state and analyze our general algorithm for agnostic active learning . The main techniques employed by the algorithm are reductions to a supervised learning task and generalization bounds applied to differences of empirical errors. 3.1 A general algorithm for agnostic active learning Figure 1 states our algorithm in full generality. The input is a stream of m unlabeled examples drawn i.i.d from D X ; for the time being, m can be thought of as  X  O (( d/ X  )(1+  X / X  )) where  X  is the accuracy parameter. 2 For S, T  X  X  X { X  1 } , let LEARN H ( S, T ) denote a supervised learner that returns a hy-pothesis h  X  H consistent with S , and with minimum error on T . Algorithm 1 maintains two sets of labeled examples, S and T , each of which is initially empty. Upon receiving x n , their empirical errors on S  X  T . If the difference is large enough 3 , it is possible to infer how h  X  labels x n (as we show in Lemma 3). In this case, the algorithm adds x n , with this Thus, S contains examples with inferred labels consistent with h  X  , and T contains examples with their requested labels. Because h  X  might err on some examples in T , we just insist that LEARN H find a hypothesis with minimal error on T . Meanwhile, by construction, h  X  is consistent with S , so we require LEARN H to only consider hypotheses consistent with S . 3.2 Bounds for error differences We still need to specify  X  n , the threshold value for error differences that determines whether the algorithm requests a label or not. Intuitively,  X  n should reflect how closely empirical errors on a sample approximate true errors on the distribution D .
 The setting of  X  n can only depend on observable quantities, so we first clarify the distinction between empirical errors on S n  X  T n and those with respect to the true (hidden) labels. Definition 2. Let S n and T n be as defined in Algorithm 1. Let S ! n be the set of labeled examples identical to those in S n , except with the true hidden labels swapped in. Thus, for example, S ! n  X  T n is an i.i.d. sample from D of size n . Finally, let we cannot use such bounds algorithmically: we do not request the true labels for po ints in S n and thus cannot reliably compute err ! n ( h ). What we can compute are error differences g h,h  X  ( x, y ) = 1l[ h ( x ) = y  X  h  X  ( x ) 6 = y ] .
 and noting that S ( G , n )  X S ( H , n ) 2 , gives the following lemma.
 Lemma 2. Let  X  n = p (4 /n ) ln(8 S ( H , 2 n ) 2 / X  ) . With probability at least 1  X   X  over an i.i.d. sample Z of size n from D , we have for all ( h, h  X  )  X  X  X H , 1  X   X  , for all n  X  1 and all ( h, h  X  )  X  X  X H consistent with S n , we have Proof. Applying Lemma 2 to each S ! n  X  T n (replacing  X  with  X / ( n 2 + n )) and a union bound implies, with probability at least 1  X   X  , the bounds in Lemma 2 hold simultaneously for all n  X  1 and all ( h, h  X  )  X  H 2 with S ! n  X  T n in place of Z . The corollary follows g h,h  X  ( x, y )  X  1l[ h  X  ( x ) 6 = y ] for ( h, h  X  ) consistent with S n , so E S ! n  X  T n [ g E Corollary 1 implies that we can effectively apply the normalized uniform convergence bounds from Lemma 1 to empirical error differences on S n  X  T n , even though S n  X  T n is not an i.i.d. sample from D . In light of this, we use the following setting of  X  n : 3.3 Correctness and fall-back analysis We now justify our setting of  X  n with a correctness proof and fall-back guarantee. Lemma 3. With probability at least 1  X   X  , the hypothesis h  X  = arg inf h  X  X  err D ( h ) is con-sistent with S n for all n  X  0 in Algorithm 1.
 Proof. Apply the bounds in Corollary 1 and proceed by induction on n . The base case is trivial since S 0 =  X  . Now assume h  X  is consistent with S n . Suppose upon receiving x n +1 , h particular, err n ( h +1 ) &gt;  X  2 n . Therefore, Now Corollary 1 implies that err D ( h  X  ) &gt; err D ( h  X  1 ), a contradiction. Theorem 1. Let  X  = inf h  X  X  err D ( h ) and d = vcdim( H ) . There exists a constant c &gt; 0 such that the following holds. If Algorithm 1 is given a strea m of m unlabeled examples, then with probability at least 1  X   X  , the algorithm returns a hypothesis with error at most  X  + c ((1 /m )( d log m + log(1 / X  )) + p (  X /m )( d log m + log(1 / X  ))) .
 Proof. Lemma 3 implies that h  X  is consistent with S m with probability at least 1  X   X  . Using the same bounds from Corollary 1 (already applied in Lemma 3) on h  X  and h f together with the fact err m ( h f )  X  err m ( h  X  ), we have err D ( h f )  X   X  +  X  2 m +  X  m which in turn implies err D ( h f )  X   X  + 3  X  2 m + 2  X  m So, Algorithm 1 returns a hypothesis with error at most  X  +  X  when m =  X  O (( d/ X  )(1 +  X / X  )); this is (asymptotically) the usual sample complexity of supervised lear ning. Since the 3.4 Label complexity analysis We can also bound the label complexity of our algorithm in terms of the disagr eement coefficient  X  . This yields tighter bounds when  X  is bounded independently of 1 / (  X  +  X  ). The key to deriving our label complexity bounds based on  X  is noting that the probability of requesting the ( n + 1)th label is intimately related to  X  and  X  n (see [10] for the complete proof).
 Lemma 4. There exists a constant c &gt; 0 such that, with probability at least 1  X  2  X  , for all probability that Algorithm 1 requests the label y n +1 is Pr x  X  ) , where  X  =  X  ( D , H , 3  X  2 m + 2  X  m  X  Now we give our main label complexity bound for agnostic active learning.
 Theorem 2. Let m be the number of unlabeled data given to Algorithm 1, d = vcdim( H ) ,  X  = inf h  X  X  err D ( h ) ,  X  m as defined in Corollary 1, and  X  =  X  ( D , H , 3  X  2 m + 2  X  m exists a constant c 1 &gt; 0 such that for any c 2  X  1 , with probability at least 1  X  2  X  : Furthermore, if L is the expected number of labels requested as per above, then with probability at least 1  X   X   X  , the algorithm requests no more than L + p 3 L log(1 / X   X  ) labels. Proof. Follows from Lemma 4 and a Chernoff bound for the Poisson trials 1l[Request y n ]. With the substitution  X  = 3  X  2 m + 2  X  m hypothesis class and data distribution for which the disagreement coefficient  X  =  X  ( D , H ,  X  ) is bounded independently of 1 / (  X  +  X  ) (see [12] for some examples), Algorithm 1 only needs  X  error  X   X   X  . The latter matches the dependence on  X / X  in the  X ((  X / X  ) 2 ) lower bound [11]. The linear dependence on  X  improves on the quadratic dependence required by A 2 [12] 4 . For an illustrative consequence of this, suppose D X is the uniform distribution on the sphere Figure 2: (a &amp; b) Labeling rate plots. The plots show the number of labels reques ted (vertical axis) versus the total number of points seen (labeled + unlabeled, hor izontal axis) using Algorithm 1. (a) H = thresholds: under random misclassification noise with  X  = 0 (solid), 0 . 1 (dashed), 0 . 2 (dot-dashed); under the boundary noise model with  X  = 0 . 1 (lower dotted), 0 . 2 (upper dotted). (b) H = intervals: under random misclassification with ( p &amp; d) Locations of label requests. (c) H = intervals, h  X  = [0 . 4 , 0 . 6]. The top histogram shows the locations of first 400 label requests (the x-axis is the unit interval ); the bottom requests occurred at the  X  s, the next 200 at the  X  s, and the final 109 at the s. in R d and H is homogeneous linear separators; in this case,  X  =  X ( complexity of A 2 depends at least quadratically on the dimension, whereas the corresponding dependence for our algorithm is d 3 / 2 . We implemented Algorithm 1 in a few simple cases to experimentally demonstrat e the label complexity improvements. In each case, the data distribution D X was uniform over [0 , 1]; the stream length was m = 10000, and each experiment was repeated 20 times with different random seeds. Our first experiment studied linear thresholds on the line. The target hypothesis was fixed to be h  X  ( x ) = sign( x  X  0 . 5). For this hypothesis class, we used specified  X   X  [0 , 1]. The first model was random misclassification: for each point x  X  D X , the second model (also used in [7]), for each point x  X  X  X , we independently labeled it +1 boundary. Our second experiment studied intervals on the line. Here, we only used random misclassification, but we varied the target interval length p + = Pr x  X  X  The results show that the number of labels requested by Algorithm 1 was exponenti ally smaller than the total number of data seen ( m ) under the first noise model, and was poly-nomially smaller under the second noise model (see Figure 2 (a &amp; b); we verified the pol yno-mial vs. exponential distinction on separate log-log scale plots). In the case of intervals, we observe an initial phase (of duration roughly  X  1 /p + ) in which every label is requested, fol-lowed by a more efficient phase, confirming the known active-learnability of this class [4,12]. These improvements show that our algorithm needed significantly fewer labels to achi eve the same error as a standard supervised algorithm that uses labels for all p oints seen. As a sanity check, we examined the locations of data for which Algorithm 1 req uested a label. We looked at two particular runs of the algorithm: the first was with H = intervals, p + = 0 . 2, m = 10000, and  X  = 0 . 1; the second was with H = boxes ( d = 2), p + = 0 . 49, m = 1000, and  X  = 0 . 01. In each case, the data distribution was uniform over [0 , 1] d , and the noise model was random misclassification. Figure 2 (c &amp; d) shows that, early on, labels were requested everywhere. But as the algorithm progressed, label requests concentrated near the boundary of the target hypothesis. We have presented a simple and natural approach to agnostic active learning. Our ex tension of the selective sampling scheme of Cohn, et al. [1] Our algorithm relies on a threshold parameter  X  n for comparing empirical errors. We prescribe a very simple and natural choice for  X  n  X  a normalized generalization bound from supervised learning  X  but one could hope for a more clever or aggressive choice, aki n to those in [6] for linear separators.
 Finding consistent hypotheses when data is separable is often a simple task. In s uch cases, reduction-based active learning algorithms can be relatively efficient (answering so me ques-tions posed in [16]). On the other hand, agnostic learning suffers from severe comput ational intractability for many hypothesis classes (e.g. [17]), and of course, a gnostic active learning is at least as hard in the worst case. Our reduction is relatively benign in that t he learning problems created are only over samples from the original distribution, so we do no t cre-ate pathologically hard instances (like those arising from hardness reductions) unless they are inherent in the data. Nevertheless, an important research direction is to dev elop algo-rithms that only require solving tractable (e.g. convex) optimization probl ems. A similar reduction-based scheme may be possible.

