 Soum ya Ray sra y@cs.wisc.edu consin, Madison, WI 53706 David Page page@biost at.wisc.edu consin, Madison, WI 53706 In mac hine learning, greedy algorithms are often em-ployed to learn concepts. These algorithms mak e a se-quence of choices, suc h as choosing a feature to split on when building a Decision Tree, or choosing an edge to add to a Bayesian Net work. Greedy algorithms com-mit to choices that are locally optimal according to functions suc h as Information Gain (Quinlan, 1997), in the case of decision trees, or the Bayesian Information Criterion, in the case of Bayesian Net works. Greedy learning strategies have sev eral adv antages. They are computationally e X cien t, simple to implemen t and of-ten work well in practice.
 While greedy learning strategies have man y adv an-tages, they are kno wn to su X er from myopia . This refers to the fact that these algorithms are easily mis-led when the locally optimal choice may not be globally optimal. For example, consider a dataset describ ed by a hundred Boolean features, where the target is a par-ity function over two of those features. A greedy deci-sion tree learner suc h as ID3 using Information Gain will be very unlik ely to choose the correct pair of fea-tures, because every feature at the  X rst choice point is equally likely to be locally optimal, even though only two of them are globally optimal choices.
 The myopia of greedy learning strategies suc h as top-down decision tree learners has traditionally been al-leviated with the use of Lookahe ad (Norton, 1989). k -step Lookahead performs an exhaustiv e searc h over the next k choices that can be made by the learning algo-rithm, and mak es the best choice over this sequence. This approac h has the disadv antage that the size of the searc h space is exp onen tial in k , and the searc h has to be rep eated at eac h choice point. Therefore, k -step Lookahead is computationally exp ensiv e and only fea-sible for very small values of k . However, if the value of a choice is apparen t only after more than k steps, it is possible that the choice will not be considered by the learning algorithm. Therefore, we would actually like k to be large.
 Our previous work introduced an approac h called Skewing (Page &amp; Ray, 2003), whic h attempts to al-leviate the myopia of greedy tree learners by changing the split selection function. We investigated \hard" Boolean functions. In suc h target functions, no vari-able has gain even given a complete data set (one cop y of eac h possible example), or given an arbitrarily large sample dra wn according to the test distribution. The Skewing approac h relies on the follo wing observ ation. Hard functions are only hard for some distributions . If we are able to obtain data dra wn according to a di X er-ent distribution, or skew the data we have, hard func-tions can become easier to learn. Thus, given a large enough dataset, if the \sk ewed" distribution di X ers sig-ni X can tly from the original, it is possible to isolate the relev ant features from the irrelev ant ones, even when the target function is hard. Unlik e Lookahead, the Skewing algorithm introduced in that previous work incurs only a constan t run time penalt y over a standard tree learner, suc h as ID3 using Information Gain. This approac h was applied to learn decision trees and signif-ican t bene X ts were observ ed in accuracy compared to ID3 using Gain when learning hard Boolean functions. The approac h was able to learn hard functions of sev-eral variables given a mo dest amoun t of data. And on easier functions, skewing did not harm ID3 perfor-mance; consequen tly, on randomly generated function, skewing resulted in a mo dest but consisten t impro ve-men t in performance.
 The Skewing approac h outlined above, however, has the  X  X w that its accuracy does not scale well with the num ber of features, when the training set size is held constan t. In exp erimen ts on data sets from the UCI rep ository (Blak e &amp; Merz, 1998), Skewing pro vided only very small gains over the ID3 algorithm using In-formation Gain (Quinlan, 1983). We hypothesize that the di X cult y with large num bers of features migh t be one reason why the Skewing approac h was unable to disco ver hard targets in the UCI data sets, if in fact there were suc h hard targets. In the presen t work, we give an impro ved Skewing algorithm that scales much better with the num ber of features, when the train-ing set size is held constan t. We empirically evaluate this algorithm, comparing it the previously prop osed Skewing algorithm and to ID3 with Information Gain, on both randomly generated Boolean functions and a real-w orld data set. Our results indicate that our algorithm (i) has accuracy that scales well with the num ber of features, (ii) incurs a run time penalt y that is linear in the num ber of variables, and hence runs in time quadratic in the num ber of attributes (but is still much less computationally exp ensiv e than Looka-head), and (iii) is able to e X ectiv ely learn hard func-tions over sev eral variables with a mo dest amoun t of training data.
 In the follo wing sections, we  X rst review previous work on the Skewing Algorithm. Next, we describ e the new Sequential Skewing algorithm. Then we presen t an em-pirical evaluation of the algorithms over syn thetic and real-w orld data, and discuss the results.
 Algorithm 1 Skewing Algorithm Input: A matrix D of m data points over n Boolean Output: A variable x i to split on, or  X  1 if no variable 1: N ( Entrop y of class variable in D 2: v ( Variable with max gain in D 3: g ( Gain of v in D 4: if g &lt; G  X  N then 5: v (  X  1 6: for i = 1 to n do 7: F ( i ) ( 0 8: for t = 1 to k do 9: for i = 1 to n do 10: V ( i ) ( Randomly chosen favored value for x i 11: for e = 1 to m do 12: W ( e ) = 1 13: for i = 1 to n do 14: if t &gt; 1 then 15: if D ( e; i ) = V ( i ) then 16: W ( e ) ( W ( e )  X  s 17: else 18: W ( e ) ( W ( e )  X  (1  X  s ) 19: N ( Entrop y of class variable in D under W 20: for i = 1 to n do 21: E ( Gain of x i under distribution W 22: if E  X  G  X  N then 23: F ( i ) ( F ( i ) + 1 24: j ( arg max F ( i ) 25: if F ( j ) &gt; 0 then 26: return x j 27: else 28: return v The motiv ation for the Skewing pro cedure (Page &amp; Ray, 2003) lies in the follo wing observ ation. Consider a dataset over a hundred features, x 1 ; : : : ; x 100 , where the target function is two variable exclusiv e-or, say x 99  X  x 100 . This task is clearly very di X cult for a top-down greedy decision tree learner. Now, supp ose the data are distributed di X eren tly from uniform. For ex-ample, we migh t supp ose all variables are indep enden t as in the uniform distribution, but every variable has with a large enough sample we exp ect that the class distribution among examples with x 99 = 0 will di X er signi X can tly from the class distribution among exam-ples with x 99 = 1. On the other hand, every variable other than x 99 or x 100 is likely to have nearly zero gain. Hence unless a highly unlik ely sample is dra wn, a greedy tree learning algorithm will choose to split on either x 99 or x 100 , at whic h point the remainder of the learning task is trivial.
 The desired e X ect of the skewing pro cedure is that the skewed data set should exhibit signi X can tly di X eren t frequencies from the original data set. To achiev e this, the frequency distributions for variables are changed by attac hing various weigh ts to the existing examples in a way discussed below. Our previous work ob-serv ed that, in con trast to skewing, other metho ds of rew eigh ting (suc h as boosting) or resampling (suc h as bagging) did not mak e hard functions easier to learn (Page &amp; Ray, 2003).
 The Skewing pro cedure initializes the weigh t of ev-ery example to 1. For eac h variable x i , 1  X  i  X  n , a \favored setting" v i , either 0 or 1, is randomly , uni-formly (indep enden tly for eac h variable) selected. The weigh t of eac h example in whic h x i tak es the value v is changed by multiplying it by a constan t. At the end of this pro cess, it is likely that eac h variable has a signi X can tly di X eren t weigh ted frequency distribution than previously , as desired. But this is not guaran-teed, because an unfortunate choice of settings could lead to the new frequency distribution being iden tical to the old one. In addition to this poten tial di X cult y, a second di X cult y is that this pro cess can magnify idiosyncrasies in the original data by assigning some data point with an extremely high weigh t.
 The di X culties in the preceding paragraph occur with some data sets com bined with some choices of favored settings. Therefore, instead of using skewing to create only a second distribution, k additional distributions, for small k , are created. The k di X eren t distributions come about from randomly (without replacemen t) se-lecting k di X eren t com binations of favored settings for the n variables according to a uniform distribution. Eac h of the n variables is scored for eac h of the k + 1 weigh tings of the data (the original data set plus k rew eigh ted versions of this data set). A gain threshold is set, and the variable that exceeds the gain threshold for the greatest num ber of weigh tings is selected as the split variable. The selected variable is highly likely to be corr ect in the sense that it is actually a part of the target function. Yet, in con trast to lookahead, the run-time has been increased only by a small constan t. Pseudo code for this algorithm is sho wn in Algorithm 1. It is applicable to binary-v alued variables only , with nominal or con tinuous variables con verted to multiple binary ones. The algorithm tak es a parameter 1 s &lt; 1. The weigh t of an example is multiplied by s if x i tak es preferred value v i in the example, and is multiplied by 1  X  s otherwise. Hence, if s is 2 weigh t of every example in whic h x i tak es value v i is e X ectiv ely doubled relativ e to examples in whic h x i does not tak e value v i .
 In our previous work, Algorithm 1 was empirically evaluated using Boolean targets of 2 to 6 variables, where the examples were describ ed by 30 variables (the remaining variables were irrelev ant to the target). This algorithm was at least as accurate as ID3 over a large, randomly sampled set of Boolean functions, and sho wed signi X can tly impro ved accuracy when the sample was dra wn from the set of \hard", parit y-lik e Boolean functions. Nev ertheless, on UCI data sets skewing pro vided only insigni X can t impro vemen ts in accuracy over ID3. While the exp erimen ts with UCI datasets demonstrated that Skewing does not hurt ID3's performance, other than a small constan t cost in run-time, they raise the question of why Skewing does not help signi X can tly on these data sets. Of course, in these data sets one does not kno w if the target con-cept is \hard" or not. But in con tinued work with Algorithm 1, we have observ ed empirically that the algorithm su X ers from the shortcoming that it does not scale well with increasing num bers of irrelev ant variables. Since some of the UCI data sets have large num bers of features but only a few hundred examples, we hypothesize that this migh t be one reason why sig-ni X can t impro vemen ts in accuracy over ID3 were not observ ed in the previous work, even if hard functions were presen t. The remainder of the pap er attempts to address this issue. In this section, we describ e the mo di X cations we mak e to Algorithm 1 in order to impro ve its scaling prop er-ties. As before, we wish the skewed data set to exhibit signi X can tly di X eren t frequency distributions from the original. In Algorithm 1, we achiev ed this by selecting a preferred value for every variable and multiplying the assigned weigh ts. This pro cedure works well when the example sizes are small. However, when exam-ples are represen ted by a hundred or more variables, it leads to two problems. First, on any given itera-tion, it is possible for some data point to get a weigh t value that is much larger than the others by chance. This can lead to over X tting. Second, under X  X  w prob-lems arise when the example sizes are large. We can avoid these problems if, instead of skewing all the vari-ables sim ultaneously , we skew one variable at a time. We call this approac h \Sequen tial Skewing". In this approac h, we perform multiple iterations of skewing. In eac h iteration, we choose a single variable, x i , and choose a preferred value for it. Eac h example is now rew eigh ted according to the value tak en by x i in the example. We then calculate the gain of eac h variable under the new frequency distribution. The variable to split on is the variable that sho ws maxim um gain over all the di X eren t skewed distributions.
 In Figure 1, we pro vide empirical justi X cation for the claim that Sequen tial Skewing works as exp ected. Here, we look at complete data sets over 6-variable examples lab eled according to sev eral random, 4-variable, parit y-lik e Boolean targets (the other two variables are irrelev ant). For suc h data sets, no vari-able has gain a priori . In the  X gure, we sho w a his-togram of the fraction of relev ant variables that have a given gain when a variable relev ant to the target is skewed. We observ e that, after the sequen tial skewing pro cess, there are variables that have nonzero gain, and one among these variables would be chosen by the sequen tial skewing algorithm as the split variable. Note that given a complete data set, no variable that is irrelevant to the target will have gain when either a relev ant or an irrelev ant variable is skewed. When the function we are trying to learn is already \easy" according to the original data distribution, and we do not have a complete data set (class assignmen ts for every possible variable com bination), the Sequen-tial Skewing approac h can sometimes choose the wrong variable. This happ ens when skewing a single variable causes a variable that does not app ear in the target to sho w high gain by chance. We resolv e this issue by inserting a gain threshold . If any variable clears this threshold in the unweighte d data set, we pick that Algorithm 2 Sequen tial Skewing Algorithm Input: A matrix D of m data points over n Boolean Output: A variable x i to split on, or  X  1 if no variable 1: N ( Entrop y of class variable in D 2: v ( Variable with min entrop y split in D 3: e ( Entrop y of v in D 4: if e &lt; f  X  N then 5: return v 6: if e = N then 7: v (  X  1 8: for i = 1 to n do 9: G ( i ) ( 0 10: maxg ain ( 0 11: for t = 1 to n do 12: V ( Randomly chosen favored value for x t 13: for e = 1 to m do 14: if D ( e; t ) = V then 15: W ( e ) ( s 16: else 17: W ( e ) ( (1  X  s ) 18: N ( Entrop y of class variable in D under W 19: for i = 1 to n do 20: E ( Gain of x i under distribution W 21: if E N &gt; maxg ain then 22: maxg ain ( E N 23: maxg ainv ar ( x i 24: if E N &gt; G ( i ) then 25: G ( i ) ( E N 26: if maxg ain = 0 then 27: return v 28: return maxg ainv ar variable without entering the skewing pro cedure. Unlik e Algorithm 1, the num ber of iterations needed by Sequen tial Skewing dep ends on the num ber of vari-ables. Thus, the time tak en by this algorithm to  X nd a split variable is O ( mn 2 ), where m is the num ber of examples and n is the num ber of variables. This is less e X cien t than Algorithm 1 and Information Gain, both of whic h are O ( mn ), but much more e X cien t than k -step Lookahead, whic h is O ( mn 2 k  X  1 ). In this section, we presen t exp erimen ts comparing the performance of ID3 using the Information Gain split selection function, the Skewing Algorithm describ ed in Algorithm 1, and the Sequen tial Skewing Algorithm. We presen t exp erimen ts using syn thetic data, follo wed by results on a challenging biomedical classi X cation task, that of SH3 domain binding . For these exp eri-men ts, the parameters input to the Sequen tial Skew-ing Algorithm were s = 3 rameters input to Algorithm 1 were s = 3 and k = 30. These parameters were chosen before the exp erimen ts were performed and were held con-stan t across all exp erimen ts. Impro ved results could perhaps be obtained by tuning these parameters. Sequen tial skewing will perform n skews, where n is the num ber of variables in the examples. Because ordi-nary skewing alw ays performs k skews (with k = 30 in our exp erimen ts), it is possible that sequen tial skewing will outp erform ordinary skewing when n &gt; 30 merely because it is permitted more skews. To con trol for this di X erence in the follo wing exp erimen ts, when n &gt; 30, we also run a varian t of ordinary skewing that per-forms n skews rather than k = 30 skews. We call this varian t \Sk ewing with n trials". 4.1. Synthetic Data Experimen ts In the  X rst set of exp erimen ts with syn thetic data, ex-amples are generated according to a uniform distri-bution over 30, 100 and 200 binary variables. Target functions are dra wn by randomly generating DNF for-mulae over subsets of 6 of these variables. The num-ber of terms in eac h target is dra wn randomly , uni-formly from between 1 and 25, and eac h term is dra wn by choosing for eac h variable whether it will app ear negated, unnegated, or not at all (all with equal prob-abilities). All targets are ensured to be satis X able. Ex-amples that satisfy the target are lab eled positive , and all other examples are lab eled negative . Figures 2 to 4 sho w learning curv es for di X eren t example sizes. Eac h point on eac h curv e is the average over 100 runs, eac h with a di X eren t target and with a di X eren t sample of the speci X ed sample size. The second set of exp eri-men ts is iden tical to the  X rst, except that the target functions were dra wn from the set of functions that can be describ ed entirely by variable co-references, or equalities among variables, together with the standard logical connectiv es and , or , and not . For suc h func-tions, even given a complete data set, no variable has gain. Figures 5 to 7 sho w learning curv es for di X er-ent example sizes for this exp erimen t. In eac h  X gure, \Gain" represen ts the results for ID3 with Informa-tion Gain, \Seq. Skewing" represen ts Algorithm 2, \Sk ewing" represen ts Algorithm 1, and \Sk ewing(n)" represen ts Skewing with n trials.
 We  X nd that the  X gures  X t our exp ectations. We ob-serv e that on random Boolean functions, Sequen tial Skewing is at least as accurate as ID3 using Informa-tion Gain, over a range of example sizes. We further observ e that the accuracy of Algorithm 1 on a sample of random Boolean functions drops sharply once ex-amples with man y features are considered. This may be because of two reasons:  X rst, the gain threshold parameter, f , of Algorithm 2 was not used in Algo-rithm 1, whic h may render this algorithm more sus-ceptible to over X tting. Secondly , as was observ ed in initial Skewing work, there is a \crosso ver point" in terms of training set size below whic h Algorithm 1 performs worse than ID3 with Gain. This crosso ver point can be seen in Figure 2, at a sample size of 400 examples. We believ e that the sample size at whic h the crosso ver occurs increases not only as a function of the target size, but also the example size. These is-sues con tribute to the poor accuracy of Algorithm 1 as the example size increases. While permitting n trials does raise the performance of Algorithm 1, nev erthe-less Skewing with n trials does not perform as well as Sequen tial Skewing.
 When the sample is dra wn from problematic functions, we  X nd that the Sequen tial Skewing algorithm outp er-forms ID3 by a large margin. We further observ e that while the Skewing algorithm describ ed in Algorithm 1 sho ws good accuracy when the examples are describ ed by 30 variables, its impro vemen t disapp ears quic kly as the size of the examples increases. Even allo wing the algorithm n iterations of Skewing does not sig-ni X can tly impro ve its accuracy in these exp erimen ts. However, the Sequen tial Skewing approac h con tinues to sho w high accuracy in this situation. Sequen tial Skewing achiev es the highest accuracy overall in eac h exp erimen t, and retains high accuracy as the example size increases and the training set size is held constan t. 4.2. SH3 Domain Binding Experimen ts Here, we presen t results from a biomedical classi- X cation task, that of SH3 binding . A ma jor part of working out the \circuitry" of an organism| the metab olic, signaling and regulatory path ways| is iden tifying whic h proteins interact with one an-other. Suc h protein-protein interactions, much like drug-receptor bindings, are based primarily on smaller electrostatic interactions (opp osite charges attracting) and hydrophobic interactions (two fatt y, or \water-fearing," groups of atoms interacting to keep eac h other from their environmen t).
 Man y of the imp ortan t protein-protein interactions oc-cur when a short segmen t of one protein, 6-10 amino acid residues long , here called the \ligand," interacts with a \domain" on the other protein. A domain is a longer segmen t (30-60 residues long), variations of whic h app ear in a variet y of proteins. Therefore, one way to predict protein-protein interactions is to pre-dict what possible ligands will bind to whic h speci X c instan tiations, or variations, of a given domain. Here, we investigate the binding prop erties of SH3 domains , whic h are implicated in cancer. Ligand-domain bind-ing is a pro cess where we may exp ect hard functions to arise naturally . For instance, binding may occur if some atoms on the domain have charges of the opp o-site sign to those of some atoms on the ligand, and will not occur if the charges are of the same sign. We investigate SH3 domains from 8 proteins using data generated by an exp erimen t performed by Sparks et al (1996). From their work, we obtain, for eac h SH3 domain, a complete list of ligands that bind to that domain. We then generate a sample of non-binding ligands from peptides (short sequences of amino acid residues) of length 8. These peptides are based on the same position-dep enden t frequency distribution as the positiv es, and therefore can be considered to be \near misses". Next, we align the domains and lo-cate the positions in the domains whic h are believ ed to be imp ortan t for binding, follo wing Brannetti et al (2000). We construct eac h data point by juxtap osing these domain positions from eac h protein with a pro-posed ligand, and lab el it according to whether the ligand binds to the domain. Thus, eac h data point is a sequence of 33 amino acids of whic h the  X rst 25 rep-resen t amino acids in the domain, and the last 8 rep-resen t amino acids in the ligand. Eac h amino acid is then translated into a 7-digit binary code, where eac h digit represen ts a feature of that amino acid, suc h as charge or hydrophobicit y. The  X nal data set consists of 897 data points, 97 positiv e, eac h data point being describ ed by 231 binary-v alued features. This is thus a fairly high-dimensional data set. The added di X cult y is that the classes are substan tially imbalanced. In our exp erimen ts, we perform 8-fold cross validation as follo ws. For eac h fold, all the examples corresp ond-ing to one protein constitute the test set. The exam-ples corresp onding to the other 7 proteins form the training set. 1 Thus, on average, eac h training set has 785 examples, 85 of whic h are positiv e.
 We compare ID3 with Information Gain as the split-ting criterion against Skewing and Sequen tial Skew-ing in our exp erimen ts. We rep ort the average ac-curacy , weigh ted accuracy and the tree size for the three metho ds for eac h exp erimen t. Weigh ted accu-racy is de X ned as the average of the true positiv e and true negativ e rates (this is equiv alen t to a misclassi X -cation cost that is inversely prop ortional to the ratio of classes). Since the domain is imbalanced, it is easy to achiev e high accuracy by alw ays predicting \negativ e". Thus, weigh ted accuracy may be the most informativ e measure of performance on this data set.
 We perform three exp erimen ts on this domain. In our  X rst exp erimen t, we replicate the positiv e examples so that there are equal num bers of positiv es and neg-ativ es in the training set. Further, we hold aside a prune set of 150 examples that is used to greedily post-prune the trees generated by all algorithms. However, holding aside a prune set exacerbates the data spar-sity problem.Therefore, in our second exp erimen t, we replicate the positiv es, but do not hold out a prune set, or prune the trees pro duced. Finally , we inves-tigate the e X ect of learning the trees without either replicating the positiv es or pruning. We presen t the results of these exp erimen ts in Figure 8.
 In our exp erimen ts, Sequen tial Skewing consisten tly outp erforms Information Gain. Because of the small size of the data set and the fact that we could only carry out 8-fold cross validation (this was dictated by the num ber of proteins for whic h we had data), we ob-tained statistical signi X cance only for some of our re-sults, according to a two-tailed paired t -test. The sig-ni X can t values are sho wn in bold in Figure 8. We note that weigh ted accuracy is the most imp ortan t mea-sure on this data set, and Sequen tial Skewing achiev es the best weigh ted accuracy overall. Further, we ob-serv e that not only does Sequen tial Skewing have bet-ter accuracy and weigh ted accuracy in general, it also constructs smaller trees on average. We believ e there-fore that these trees may generalize better to other do-mains, and pro vide more insigh t about the SH3 bind-ing problem. Overall, Sequen tial Skewing with repli-cated positiv es and pruned trees pro vides the highest weigh ted accuracy on this task.
 We also ran C5.0 (www.rulequest.com) on this data, with a di X eren tial cost  X le that stipulated a false neg-ativ e misclassi X cation penalt y of 10 units. This algo-rithm achiev ed a average weigh ted accuracy of 46 : 52%, with an average tree size of 76 : 5 nodes. Comparing this to the Replicated/Pruned exp erimen t, we observ e that C5.0 is outp erformed by Sequen tial skewing. The accuracy di X erence is signi X can t at p = 0 : 02 according to a two-tailed paired t -test. Functions that are di X cult for greedy decision tree learners, including parit y-lik e functions, app ear in the real world. For example, in biomedical domains, cases exist where expression of a gene or surviv al of an organ-ism may be an exclusiv e-or function of the expression of other genes or groups of genes; a particular exam-ple was describ ed in our earlier work (Page &amp; Ray, 2003). Ligand-receptor binding, whether for protein-protein interactions as discussed in the presen t pap er or for drug-target interactions, is frequen tly con trolled by hard functions of two or more variables. Skewing is a promising approac h that e X cien tly addresses suc h hard functions. Previous work on skewing introduced an algorithm that did not scale su X cien tly well to hun-dreds of features, with only hundreds of examples, to be broadly applicable to real-w orld problems. This pap er has tak en a ma jor step forw ard in making skew-ing a practical approac h to learning hard functions in real-w orld domains. Sequen tial skewing signi X can tly impro ves the abilit y of skewing to handle large num-bers (hundreds) of features with reasonable num bers (again, hundreds) of examples, as demonstrated in the presen t pap er with both real and syn thetic data. Se-quen tial skewing increases the time complexit y by a factor of n , the num ber of features, over ordinary skew-ing, but the resulting time complexit y remains lower than that of even two-step lookahead.
 Muc h room remains for researc h into skewing. We are looking at ways to impro ve the scaling beha vior further to handle thousands of features with only hundreds of data points. This is desirable, for example, for working with gene expression data. Another interesting direc-tion is to use Skewing as a feature selection algorithm. Since the full data set is used to select features, and Skewing can capture relev ant features that are infor-mativ e in conjunction with other features, it should outp erform Gain-based selection metho ds. However, the disadv antage is that variables are evaluated in a con text whic h may be di X eren t from their con text in the target function, so their utilit y may not be appar-ent. We are curren tly evaluating this approac h. Be-sides this, we are also investigating approac hes that in-corp orate Skewing directly into greedy learners other than decision tree learners. Other imp ortan t future directions are extending this approac h to handle real-valued features, and multi-class or real-v alued predic-tion problems. Besides the algorithmic issues, much work remains to be done in exploring the biomedical application domains in whic h we exp ect functions that are hard for greedy learners to arise.
 The  X rst author was supp orted by NIH Gran t 1R01 LM07050-01 and by gran ts from the Univ ersit y of Wis-consin Graduate School. The second author was sup-ported by NSF gran t 9987841 and by gran ts from the Univ ersit y of Wisconsin Graduate School and Medi-cal School. The authors thank Brian Kay and Bev erly Sea vey for discussions on the task of SH3 binding.
