 Automatic image annotation, which enables conversion of image retrieval into text matching, has received much resea rch interest recently. These approaches can be divided into the following two types: learning based approaches and example-based approaches. The learning-based approaches such as cross-media relevance model(CMRM), generative mod el based on continuous features (CRM) learn the mapping model between visual features and semantic concepts[1]. Mod-els such as latent dirichlet allocation, probabilistic latent semantic analysis, and hierarchical dirichlet processes annotated images as samples from a specific mix of topics, where each topic is a distribution over image features and annotation words. Discriminative models such as multiple-label learning, multiple-instance learning learn classifier for labels. All of above methods showed their considerable performance on small scale image and vocabulary set, whereas the complexity of the learned model and their poor scalability make the learned model hardly generalizable and unrealistic to application on infinite semantic concepts set for large scale web image annotation. Different from the first group, example-based algorithms assume that similar image share similar label[2][3][4][5]. These example-based methods needn X  X  parameters learning and parameter estimation, and are data-driven and model-less which are more flexible and can be applicable to large scale data set. In [3], content-based image retrieval is used to retrieve a set of visually similar images from a large-scale web image set, text-based label search is used to obtain a ranked list of candidate annotations for each retrieved image, then the top ones in the ranked label lists are annotated. In [4], initial relevance scores for the labels is estimate based on probability density estima-tion, and a random walk over a label similarity graph is performed to refine the relevance scores. In [5], the author proposes a neighbor voting algorithm to learn label relevance. However, this type of approach X  X  performance is inferior relatively. Recent studies indicates tha t the correlation between the labels can improve learning quality[6][7][8]. But these methods often rely on complicated learning algorithms and are not easy to model the correlations between labels when extending to large number of labels. Intuitively, such information is helpful for us to better understand image content. The ideal label set associated with images should be relevant to the image, namely, the label set can accurately describe the content of the image; Meanwhile, the ideal label set should be in-ternal correlative,namely, labels in the set is correlative to each other. Label set X  X  relevance to image and correlation between a label and label set are quite helpful to better understand image semantic, meanwhile, large scale web image annotation require the learning method has both effectiveness and efficiency. So we formulate an optimization framework that includes both factors and solve the problem in a heuristic way. Given an image collection X , a vocabulary W , we define a candidate label set W q with q labels, the relevance of W q to image x is defined as r ( x, W q ), and the correlation between labels in W q with respect to x , namely, internal correlation of W q is defined as c ( x, W q ). The objective is to assign the most relevant and internal correlative label set to x .Weuse F ( x, W q ) to denote the objective. Thus, the optimization problem is: where  X  W q is the ideal label set to x ,  X  is a controlling parameter. It is unreal-istic to solve this problem by greedy search when the whole vocabulary size n is very large, so we propose a heuristic iterative algorithm to solve it and get an approximate optimal solution, that is, searching the label which is most rel-evant to x and correlative to W q  X  1 at q-th iteration. Given a label denoted as denotes the relevance of w to x . Similarly, the internal correlation of W q with re-relevance of label w to W q  X  1 with respect to image x . Then, we select the la-bel which maximizes F w ( x, w ) at q-th iteration and added it into W q  X  1 ,where F w ( x, w ) integrates the label w  X  X  relevant and correlated information added to W q  X  1 .Thus,wehave  X  X abel set X -to-image relevance indicates label set X  X  efficiency in describing the image visual content. There are two cases will result in label set X  X  ambiguous de-scription of image. The first case is polysemy. Considering the following scenario, label set  X  X pple X ,  X  X hoto X  can describe a fruit or a computer, while X  X pple X ,  X  X omputer X  X r  X  X pple X ,  X  X ruit X  can be more discriminant, so the latter two label sets are more relevant to the target im age. The second case is that label set is not specific. For example, a label set  X  X ar X  is not specific since there are various brand like  X  X hevrolet X  or  X  X olkswagen X . Labels  X  X ice  X  or  X  X ool X  added into will not give more relevant information to the image. Note that, from the per-spective of the whole label set, the meaning of a label X  X  relevance to one image indicates how much relevant information it added to the label set, which can be reflected from the ambiguity changes. Intuitively, adding one informative label to the label set, will result in great changes to the posterior distributions of other labels. Then, the degree of posterior distributions of other labels changed after this label joined into the label set can estimate the relevant information of a la-bel. For example,  X  X ellow X ,  X  X hevrolet X ,  X  X olkswagen X ,  X  X ermany X , and  X  X S X  are likely to occur with the label set  X  X ar X . However, labels Volkswagen and Germany are less likely to occur with the updated label set  X  X ar X ,  X  X hevrolet X  when the label Chevrolet is added into the label set  X  X ar X , thus their posterior distributions to the labels in the set will be changed. This means that the label set  X  X ar X ,  X  X hevrolet X  is more specific than the label set  X  X ar X , and has more relevant information. Thus, when a label w is added in, we can compute the K-L divergence of the posterior distributions P ( w | W q  X  1 )and P ( w | W q ), where w  X  W . The greater the divergence value is, more chance w is selected into the label set. Thus, we have where f (  X  ) should be a monotonically increasing function, and K-L divergence can be computed by: Here ,where  X  denotes W q or W q  X  1 . The label X  X  conditional probability can be eas-ily computed by labels co-occurrence. Si nce there have large differences in the frequency of different labels, estimating their prior probability directly by their frequency simply to will include bias, so we compute conditional probability and prior probability as: , where count ( a, b ) denotes the co-occurrence number of a and b . By Formula(2), We select the label by the vocabulary X  X  KL divergence of posterior distribution only. However, relevance between labels and image is not considered. For exam-ple, given a candidate label set X  X ar X ,  X  X offee X  may be selected to added into the set since it leads to the greater change of posterior distribution of labels in the vocabulary. So formula(2) is rewritten as: Assume P ( x ) is uniformly distributed, thus P ( w | x )  X  P ( w,x ) where P ( w,x ) can be estimated with the expectation over the nearest neighbors of x as follows, tance of samples. Note that, we should consider the label similarity of images in selecting neighbors, so we retrieve K ( K&gt;k ) neighbors by visual similarities, then pair wise label vector X  X  similarity is computed as where sim text ( x i ,x j ) is the similarity of corresponding label vector, which can be computed by Cosine distance, after that, top-k samples with great sim ( x i ,x ) is selected. We assumed labels are independent in the e stimating label set relevance in sec-tion 3. However, it may results in deviation because it does not consider the internal correlation of label set. Considering the following scenario, a label set  X  X ky X ,  X  X un X  has been assigned to image, then the label  X  X ain X  may be added in since it has correlation with  X  X ky X , but  X  X ain X  has little relevance with  X  X ky X ,  X  X un X  as a whole. So we claimed that the label set should be internal correlative as a whole, namely, each label should be relevant to all other labels in the label set. Meanwhile, the label which is less relevant to the image but relevant to the label set should be added in. The c ( W q  X  1 ,w ) defined in Section 2 is proposed to measure the relevance between the candidate label set W q  X  1 and label w .Thus, we have c ( W q  X  1 ,w )= sim text ( W c ,w ), here both the candidate label set W q  X  1 and label w are represented by vector, then we get the  X  X abel set vector X  W c by a label combination process that combine all the labels in the candidate label set. sim text ( W c ,w ) is the semantic similarity between W c and w . To get the  X  X abel set vector X  W c , the vector of each label need to be constructed first. Assuming that each image be a document containing the associated labels, we can use the following method to measure the semantic relevance between labels. First, each image is represented by its associated labels. Then, the label-to-image matrix that describes the relationship between labels and image is denoted as M | W | X  n , where | W | is the vocabulary size, n is the number of images in the training set. The i-th row of M denotes the occurring pattern of label w i in the training set, and the j-th column of M denotes the labeling of image x j , M i,j denotes whether w i is associated with x j . Then, the label-to-label matrix U | W | X | W | = MM T is obtained, which describes labels X  semantic correlation. We normalize the matrix bels, and U ij denotes co-occurrence information of w i and w j .Thus,the U  X  X  i-th row vector U i can be regarded as the neighborhood vector of w i , and the semantic correlation of w i and w j can be estimated by thei r neighborhood vector U i and U . Here, we construct W c by a heuristic label combination process. Given two label X  X  neighborhood vector  X   X  w |
D K nearest neighbours of the test image x , | T ( w i ) | denotes the number of images that contain label w i in the training dataset.The result combined label vector is where max(  X  i , X  j ) is an augment factor. Thus the  X  X abel set vector X  W c is a In the annotation process, we combine the concept W c and the candidate label w q which is selected to join in label set W q  X  1 by the label combination process :  X  vector X  W c and label w i can be computed by sim text ( W c ,w i )= W c  X  U i | W We conduct extensive experiments on dataset NUS-WIDE[9] which contains 269,648 images and 5,018 labels all of which exist in WorldNet. We split NUS-WIDE into a training set with 150,000 images and a test set with the remain-ing images. We use two types of global image descriptors: Gist features, and color histograms with 16 bins in each color channel for RGB and HSV repre-sentations. Local feature SIFT are extracted densely on a multiscale grid or for Harris-Laplacian interest points. Images are then represented as a bag-of-words histogram. We concatenate them to form a new global descriptor. We evaluate our models with standard performance measures. Let n s i be the number of im-ages automatically annotated with a given label, n p i be the number of images correctly anno tated with that label. n i is the number of images having that label in ground-truth. Thus ARL = precision API @ q and recall ARI @ q of image with q result labels are also used to evaluate the method: API @ q = 1 | T | is the test image set, P ( I i ) is the set of result labels correctly assigned to image I by the algorithm, G ( I i ) is the set of ground truth labels for image I i .We compare our algorithm LSLabel with the following state of the art web image annotation algorithms, i.e., SBIA(Search based Method)[3], RWLabel [4] and NVLabel [5]. Table 1 shows the API and ARI with q varied from 1 to 6. Figure 1 and Figure 2 shows the corresponding curve for comparison. According to the results, LSLabel archives encouraging improvements, and the API and ARI are greatly improved. From these figures, we can observed that, our proposed al-gorithm LSLabel outperforms other algorithm significantly. For example, when q is fixed as 6, LSLabel has an improvement about 16% over NVLabel, 24% over SBIA, 14% over RWLabel in terms of API. In terms of ARI it has an im-provement about 12% over NVLabel, 16% over SBIA, 11% over RWLabel. The reasons are that, it is difficult for SBIA to properly determine the number of clusters. NVLabel usually assign commo n labels which has larger frequency in the neighborhood. This is the same to RWLabel in which the labels has the most correlation to other labels are assigned to the test image. However, the LSLabel prefers the relevant label set a s a whole. With assigned label X  X  number q increasing the superiority is more obvious. To compare the average precision and recall in terms of label, we fix the number of labels for image as 6 and ob-tain the APL and ARL. Figure 3 shows the results. From these figures, we can observed that for the average precision, LSLabel has an improvement 17-31% over other annotation algorithms, and for the average recall of label, LSLabel has an improvement about 17-35% over the other annotation algorithms. Be-cause these algorithms prefer the labels which appear frequently in the visually similar images. However, the LSLabel prefers the relevant label set as a whole, and the label set which is correlative and has great relevance information to image is assigned. Table 2 shows some annotation results generated by differ-ent methods on NUS-WIDE dataset. It shows that label set obtained by our algorithm is more discriminant to describe corresponding image. Our algorithm selects the label  X  X errari X  for the first image, because it disambiguates the image from  X  X enz X ,  X  X MW X  and  X  X IA X . RW method and Neighbor Voting method also select label  X  X ENZ X  ,  X  X MW X  or  X  KIA  X . This also happens to the second image, our algorithm selects the relevant label  X  X ruit X , and it can disambiguate the image from computer. However, other algorithms also select the label  X  X om-puter X  because label  X  X omputer X  has high co-occurrence frequency with  X  X pple X . Meanwhile, other algorithms label the third image with labels  X  X un X  and  X  X ot X , which is ambiguous to describe the third image.

Figure 4 shows examples of F1 scores for some individual labels. We can also observed that LSLabel get best performance in comparison with other methods. In this paper, a new model for web image annotation is proposed by simultane-ously learning  X  X abel set X -to-image relevance and label set internal correlation in a joint framework. The  X  X abel set X -to-image relevance is computed based on the posterior probability computation using KL divergence and label set X  X  internal correlation is computed by label correlation analysis. We further solve the label set selection problem in a heuristic and iterative manner, thus making the frame-work more applicable to the large scale annotation environment. Experiments show that the proposed method achieve s excellent and superior performance.
