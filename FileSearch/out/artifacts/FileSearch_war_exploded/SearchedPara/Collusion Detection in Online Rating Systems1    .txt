 Today, in e-commerce systems, buyers usually rely on the feedback posted by others via online rating systems to decide on purchasing a product [13]. The higher the num-ber of positive feedback on a product, the h igher the possibility that one buys such a product. This fact motivates people to promote products of their interest or demote the products in which they are not interested by posting unfair rating scores [7, 6]. Unfair rating scores are scores which are cast regardless of the quality of a product and usu-ally are given based on personal vested interests of the users. For example, providers may try to submit supporting feedback to increase the rating of their product in order to increase their income [6]. The providers also may attack their competitors by giv-ing low scores on their competitor X  X  products. Also, sometimes sellers in eBay boost their reputations unfairly by buying or selling feedback [7]. Unfair rating scores may be given individually or collaboratively [18]. Collaborative unfair ratings which are also called collusion [17, 18] by their nature are more sophisticated and harder to detect than individual unfair ratings [17]. For that reason, in this work we focus on studying and identifying collusion.

Although collusion is widely studied in online collaborative systems [4, 8, 10, 13, 12, 9, 19], such systems still face some serious challenges. One major challenge arises when a group of raters try to completely take control of a product i.e., when the number of unfair reviewers is significantly higher than the number of honest users; the existing models usually can not detect such groups. Also, the existing models do not perform well against intelligent attacks, in which group members try to give an appearance of honest users. For example, typically they will not deviate from the majority X  X  ranking on most of the cast feedback and target only a small fraction of the products. Such attacks are hard to identify using the existing methods [19].

Moreover, there are cases in which a large group of people have rated the same group of products, and thus could be considered as a potential collusion group. Such a group might be subsequently deemed as non collusive. However, in such cases there may exist some smaller collusive sub-groups inside the large group which are collusive, but when put along with others they might be undetected. Detection of such sub-groups is not addressed in the existing collusion detection models.

In this paper we propose a framework for detecting and representing collusion in online rating systems. Besides indicators used in the already existing work, we also define two novel indicators. One indicator which we call Suspiciousness of a reviewer, which is a metric to estimate to what extent ratings posted by such reviewer correspond to majority consensus. Such indicator is calculated using two distance functions: the L p norm and the Uniform distance (see Section 4.1 for more details). The other indicator which we call spamicity estimates the likelihood that a particular rating score given to a product by a reviewer is unfair.

We also propose a graph data model for repres enting rating activ ities in online rat-ing system. This model allows representing products, reviewers and the rating scores reviewers have cast on products and identifying collusive groups. We propose a new notion and representation for collusion groups called biclique . A biclique is a group of users and a group of products such that every reviewer in such a group has rated every product in the corresponding group of products. We use bicliques to detect collusion.
Moreover, we propose an algorithm which employs two clustering algorithms built upon frequent itemset mining (FIM) technique [1] for finding bicliques and sub-bicliques. Then the algorithm uses the proposed collusion indicators to find any possible collusion in online rating systems. We have implemented our model and tested it and the evaluation results show the efficiency of our model.
 The rest of the paper is organized as follows. In section 2 we propose our data model. In Section 3 we propose our example scenario and data preprocessing details. Our collu-sion detection method is proposed in Section 4 and the corresponding algorithm appears in Section 5. In section 6 we propose implementation details and also evaluate results. We discuss related work in section 7 and conclude in section 8. We define a graph data model (i.e. ORM: Online Rating Model) for organizing a set of entities (e.g. reviewers and products) and relationships among them in an online rating system. ORM can be used to distinguish between fair and unfair ratings in an online rating system and helps to calculate a more realistic rating score for every product. In ORM, we assume that interactions between reviewers and products are represented by a directed graph G =( V,E ) where V is a set of nodes representing entities and E is a set of directed edges representing relationships between nodes. Each edge is labeled by a triplet of numbers, as explained in the followings.
An entity is an object that exists independently and has a unique identity. ORM consists of three types of entities: products , reviewers and bicliques . We use the concept of folder used in our previous work [3] to represent bicliques.
 Product. A product is an item which has been rated by system users in terms of quality or any other possible aspects. Products are described by a set of attributes such as the unique indicator (i.e. ID), title , and category (e.g. book, cd, track, etc). We assume that there are N p products P = { p j | 1  X  j  X  N p } in the system to be rated.
 Reviewer. A reviewer is a person who has rated at least one product. Reviewers are described by a set of attributes and are identified by their unique identifier (i.e. ID). We assume that there are N u reviewers U = { u i | 1  X  i  X  N u } rating products. Rating Relationship. A relationship is a directed link between a pair of entities, which is associated with a predicate defined on the attributes of entities that characterizes the relationship. We assume that no reviewer can rate a product more than once. So, in ORM, there is at most one relation between every pair of products and reviewers.
When a reviewer rates a product, a rating relationship is established between corre-sponding reviewer and product. We define R = { e ij | u i  X  U  X  p j  X  P } as the set of all rating relationships between reviewers and products i.e. e ij  X  R is the rating score which the u i has given to p j . A rating relationship is weighted with the values of the following three attributes: 1. The value is the evaluation of the the reviewer from the quality of the product and 2. The time shows the time in which the rating has been posted to the system. The 3. As we mentioned earlier we assume that every reviewer can have at most one 2.1 Biclique A biclique is a sub-graph of ORM containing a set of reviewers R , a set of products P and their corresponding relationships Rel .Allreviewersin R of a biclique have rated all products in the corresponding P , i.e., there is a rating relationship between every r  X  R and every p  X  P . A biclique is denoted by BC = { R, P, Rel } .For u ,and u 3 all have voted on p 1 , p 2 and p 3 . We will use terms  X  X iclique X  and  X  X roup X  interchangeably throughout this paper.
 Amazon is one of the well-known online markets. Providers or sellers put products on the Amazon online market. Buyers go to Amazon and buy products if they find them of an acceptable quality, price, etc. Users also can share their experiences with others as reviews or rating scores they cast on products. Rating scores are numbers in range [1 , 5] . Amazon generates an overall rating score for every product based on the rating scores cast by users. Some evidence like [6] show that the Amazon rating system has widely been subject to collusion and unfair ratings.

We use the log of Amazon online rating system 1 which was collected by Leskovec et. al. for analyzing dynamics of viral Marketing [11], referred in the following as AM-ZLog. This log contains more than 7 million ratings cast on the quality of more than 500 thousands of products collected in the summer of 2006 .

We preprocess AMZLog to fit our graph data model. We delete inactive reviewers and unpopular products and only keep reviewers who reviewed at least 10 products and the products on which at least 10 ratings are cast. We also change the date format from  X  X yyy-mm-dd X  to an integer number reflecting the the number of days between the date on which the first rating score in the system has been posted and the day in which this rating score has been cast.

We use redundant votes from one rater on same product to calculate spamicity of their relation. Let E ( j ) be the set of all ratings given to product p j and E ( i, j ) be the set of all ratings given by reviewer u i to the product p j . We calculate spamicity degree of the relationship between the reviewer r i and the product p j as follows: In the above equation allowing casting two votes instead of one accommodates for the situations where a genuine  X  X ind change X  has taken place. To find collusive bicliques, first we have to identify all collaborative rating groups as collusion biclique candidates, then check them to find real collusion groups. We em-ploys FIM technique [1] to find bicliques. Mo re details on our biclique detection algo-rithm can be found here [2]. 4.1 Collusion Indicators It is almost impossible to identify collusion bicliques just by analyzing the behavior of individual members or even only based on the posted rating scores [12]. Rather, several indicators must be checked to realize in what extent a group is a collusion group [13]. In the followings, we propose some indicators and show how they indicate to a possible collusive activity. Group Rating Value Similarity (GVS). A group of reviewers can be considered as formers of a collusive biclique (denote by g ), if they have posted similar rating scores for similar products. For example, all of them promoted a set of products and demoted another set of products by similar rating scores. To find this similarity we calculate the Pairwise Rating Value Similarity between every pair of reviewers in the group. Pair-wise rating value similarity denoted by VS ( i, j ) shows to what extent u i and u j have cast similar rating scores to every product in g.P . We use cosine similarity model, a well-known model for similarity detection [15], for finding similarities between group members. Since VS ( i, j ) is the cosine of the angle between two vectors containing rat-ings of two reviewers, it is a value in range [0 , 1] .Thevalue 1 means completely same and 0 means completely different. Suppose that u i and u j are two members of group g i.e. u i and u j  X  g.R . We calculate similarity between them as follows: We then calculate an overall degree of similarity for every group to show how all mem-bers are similar in terms of values they have posted as rating scores and call it G roup rating V alue S imilarity (GVS). GVS for every group is the minimum amount of pair-wise similarity between group members. The GVS of group g is calculated as follows. The bigger the GV S , the more similar the group members are in terms of their posted rating values.
 Group Rating Time Similarity (GTS). Another indicator for finding collusive groups is that they usually cast their ratings in a short period of time. In other words, when a group of users aim to promote or demote a product they should do it in a short period of time in order to gain benefit, get paid, etc. We use this fact as an indicator to find collusive groups and call it G roup rating T ime S imilarity (GTS) . To calculate GTS, we find the the Time Window (TW) in which the rating scores have been posted on each product p  X  g.P . The beginning of the TW is the time of casting the first rating score on the products and its end is the time of casting the last rating score on the product by members of the group. We use the size of the TW in comparison to a constant MaxTW to show how big such a TW is. The parameter MaxTW is the maximum size of a TW which might be suspected to be collusive. So, for every product in the group we have: Where MinT = min( e ij .t ) , MaxT =max( e ij .t ) , j  X  g.P for all i  X  g.R
Now, we choose the largest TW ( j ) as the degree of time similarity between the ratings posted by group members on the target products. We say The bigger the GT S , the more similar the group members are in terms of the time of posting their rating scores.
 Group Ratings Spamicity (GRS). As we described in Sections 2 and 3, the spamicity of a rating relationship shows the suspici ousness of the rating score because of high number of ratings posted by a same user to a same product. We define the Group Rating Spamicity (GRS) as follows: Group Members Suspiciousness (GMS). We identify suspicious users in four steps. Step 1: Suppose that E ( j ) is the set of all ratings posted on the product p j .Wefindthe median of the members of E ( j ) and denote it by m j . We then calculate the average dis-tance of all ratings posted on p j from the median m j and denote it by d j . We calculate the average distance using equation (6). Now, we calculate a credibility degree for every e ij  X  E ( j ) . We denote this credibility degree with  X  ij and use it to marginalize outliers. The  X  ij is calculated as follows. Equation (7) implies that only the ratings which fall in range ( m j  X  d j ) are considered as credible.
 Step 2: In this step, we calculate the averages of all credible ratings on the product p j and assume that it is a dependable guess for the real rating of the product. We show it by g j and calculate it as follows. Step 3: In the third step, using the ratings we guessed for every product (Equation (8)), we calculate two error rates for every reviewer. The first error rate is the L P error rate (here L 2 )whichis L 2  X  norm of all differences between the ratings cast by the reviewer on the quality of p j and the g j . We denote the L p error rate of reviewer u i by LP ( i ) . Suppose that J i is the set of indices of all products have been rated by u i .The LP ( i ) is calculated as follows.
 The second error rate we calculate for every reviewer is the uniform norm of differences between e ij .v and g j for all products have been rated by u i . We call this error rate uniform error rate of u i , denote it by UN ( i ) and calculate it as follows. Step 4: The suspicious reviewers are the people who have have large LP ( i ) or while they have normal LP ( i ) they have high UN ( i ) values. To identify suspicious review-ers, we identify the normal range of error rates for all reviewers. Based on the calculated range, the outliers are considered as su spicious reviewers. Suppose that LP is the me-dian of all LP ( i ) and UN is the median of all UN ( i ) . Also, we assume that LP and UN are the standard distance of all LP ( i ) and UN ( i ) respectively, calculated similar to the method being used in Equation (6). The list of suspicious reviewers is denoted by S and built using Equation (11).
 Now, we define GMS of a group as follows.
 4.2 How Destructive a Biclique Might Be (The Damaging Impact) The damaging impact of a collusion group is its ability to impact normal behavior of the system and final rating scores of products. There are two important parameters reflect-ing damaging impact of a group: (i) size of the group and (ii) the number of products have been attacked by the group. The bigger these two parameters are, the more defec-tive such a collusive group is.
 Group Size (GS). Size of a collusive group (GS) is proportional to the number of reviewers who have collaborated in the group i.e., g.R.size and is calculated as follows. GS is a parameter between (0 , 1] and showing how large is the number of members of a group in comparison with other groups.
 Group Target Products Size (GPS). The size of the target of a group (GPS) is propor-tional to the number of products which have been attacked by members of a collusion group. The bigger the GTS, the more defective the group will be. GTS is a number in range (0 , 1] and is calculated as follows.
 4.3 Finding Collusive Sub-bicliques When finding bicliques, we try to maximize size of the group, i.e. g.R.size ,tofindthe largest possible collusive bicliques. It is possible that a large group is identified as an honest group due to large and diverse number of users who have just rated same subset of products. But possibly, there might exist some smaller collusive sub-groups inside. To find such sub-groups, we use again the idea of finding candidate bicliques using FIM technique. But in this stage, we only investigate bicliques which have damaging impact greater than a threshold called  X  .  X  is the collusion threshold and is specified when collusion cliques are found using our proposed algorithm. Due to space limitation, both biclique and sub-biclique detection algorithms are available in [2]. It is quite impossible to certainly find out if a group is collusive or not [13]. There-fore, we define a metric called Probability of Collusion (POC) to show to what ex-tent a group seems to be collusive. POC is an aggregation of four collusion indicators. Since in different environments, the importance of these indicators may be different, our model enables user to assign weight to every indicator to have adequate impact on POC. Suppose that W GV S , W GTS , W GRS and W GMS are corresponding weights for GV S , GT S , GRS and GM S respectively so that W GV S + W GTS + W GRS + W GMS =1 . The POC is calculated as follows.
 POC ( g )= GV S  X  W GV S + GT S  X  W GTS + GRS  X  W GRS + GM S  X  W GMS Moreover, for every group we calculate its damaging impact (DI) as follows.
 Finally we propose Algorithm 1 for collusion detection. This Algorithm uses POC, DI and ORM graph along with constants  X  and MaxtTW to detect collusion in online rating systems. We have implemented a framework for querying and analyzing collusion in on-line rating systems. Our framework com-prises several parts which enable user to easily customize collusion detection process and query and analyze collu-sion with the simple query language pro-vided for this purpose. More details of the framework architecture and imple-mentation can be found in [2] and [3].

To evaluate our model, we randomly chose 20 groups identified within AM-ZLog. Then we asked domain experts to manually check whether these groups are collusive or not. Experts using their experience and information provided in Amazon web site such as rating scores, corresponding written reviews,etc ana-lyzed these 20 selected groups. 7 groups out of 20 were identified as collusive and 13 as honest.We used this dataset to evaluate our model.
 Statistical Evaluation. For each group in dataset, we calculate all four collusion indica-tors. Then we calculate the cumulative distribution of every indicator for both collusive and non-collusive groups. The results of these calculations are shown in Figure 1. In every section of the chart, the red/dashed line shows the cumulative distribution of the corresponding indicator of collusive groups while the blue/solid line reflects the corre-sponding value for non-collusive groups. Also, the vertical axis is the cumulative value and horizontal axis is the percentage.

For every indicator in the chart, the cumulative distribution charts of the non-collusive groups are on the left side while collusive charts are more closer to one. It simply means that in average, for every indicator, values calculated for collusive groups are larger than values calculated for non-collusive groups. Therefor, these indicators and the way they are calculated are truly reflecting the behavior of the group, and can be used as indica-tors to collusive behavior.
 Evaluating Quality of the Results. To evaluate quality of the results, we use the well-known measures of precision and recall [16]. Precision measures the quality of the results and is defined by the ratio of the relev ant results to the total number of retrieved results. Recall measures coverage of the relevant results and is defined by the ratio of relevant results retrieved to the total number of existing relevant results in database.
An effective model should achieve a high precision and a high recall; but its is not possible in real world, because these metrics are inversely related [16]. It means that cost of improvement in precision is reduction of recall and vice versa. We calculate pre-cision and recall with different thresholds to show how value of  X  impacts the quality and accuracy of the results. Figure 2 shows the results of running our algorithm with different threshold values. We do not specify particular value for precision and recall. We only say that if the user wants to achieve the highest possible values for both preci-sion and recall metrics, Figure 2 obviously sh ows that the optimal value for threshold (  X  )is 0 . 4 . In this case 71% of the bicliques are retrieved and 71% of retrieved results are really collusive. One can change  X  to change quality or coverage of data. Also, for more accuracy one can run the model with differen t groups of randomly chosen bicliques.
Our model also calculates a damaging impact (DI) factor for every group to show how damaging the group is. DI helps users to identify groups that have a high potential damaging power. These groups are mainly groups with high number of targeted products. Table 1 shows a sample set of bicliques and their DI and POC. The group 2 has high values for POC and DI, so it is a damaging group. On the other hand, group 9 has small values for POC and DI, and is not a really defective group. Looking at group 11 reveals that although the POC of the group is small ( 0 . 121 ), but it still can be damaging because its DI is 0.41. DI is also useful when comparing groups, e.g, comparing 4 and 6 . Although, the POC of group 6 is 0 . 08 higher than POC of group 4 , the DI of group 4 is 0 . 07 higher than DI of group 6 . Therefore we can classify them similar rather than deeming group 4 more damaging than group 6 . Without having DI, the damaging potential of groups like 11 or 4 may be underestimated and it can lead to incorrect calculation of rating scores. Collusion detection has been widely studied in P2P systems [4, 8, 14]. For instance, EigenTrust [8] tries to build a robust reputation score for P2P collaborators but a re-search [14] shows that it is still prone to collusion. A comprehensive survey on collusion detection in P2P systems can be found here [4]. Models proposed for detecting collud-ers in P2P systems are not directly applicab le to online rating systems, because in P2P systems models are mostly built on relations and communications between people; but in online rating systems there is no direct relation between raters. Reputation manage-ment systems are also targeted by collusion. Very similar to rating systems, colluders in reputation management systems try to mani pulate reputation scores by collusion. Many efforts are put on detecting collusion using majority rules, weight of the voter and tem-poral analysis of the behavior of the users [17] but none of these models is enough strong to detect all sorts of collusion [17, 18]. Yang et. al. [19] try to identify collusion by em-ploying both majority rule and temporal behavior analysis. Their model is not still tested thoroughly and just is applied to a specific dataset and a particular type of attack.
The most similar work to ours is [13]. In this work Mukherjee et.al. propose a model for spotting fake review groups in online ra ting systems. The model analyzes textual feedbacks cast on products in Amazon online market to find collusion groups. They use 8 indicators to identify colluders and propose an algorithm for ranking collusion groups based on their degree of spamicity. However, our model is different from this model in terms of proposed indicators, analyzing personal behavior of the raters and dealing with redundant rating scores. Also a recent survey [5] shows that buyers rely more on scores and ratings when intend to buy something rather than reading textual items. So, in contrast with this model we focus on numerical aspect of posted feedback. However, the model proposed by Mukherjee et.al. is still vulnerable to some attacks. For example, if the number of attackers is much higher than honest raters on a product the model can not identify it as a potential case of collusion.

Another major difference between our work and other related work is that, we pro-pose a graph data model and also a flexible query language [2] for better understanding, analyzing and querying collusion. This aspect is missing in almost all previous work. In this paper we proposed a novel framework for collusion detection in online rating systems. We used two algorithms designed using frequent itemset mining technique for finding candidate collusive groups and sub-groups in our dataset. We propose several indicators showing the possibility of collusion from different aspects. We used these indicators to assign every group a rank to show their probability of collusion and also damaging impact. We evaluated our model first statically and showed the adequacy of the way we define and calculate collusion i ndicators. We then used precision and recall metrics to show quality of output of our method.

As future direction, we plan to identify more possible collusion indicators. We also plan to extend the implemented query language with more features and enhanced visual query builder to assist users employing our model. Moreover, we plan to generalize our model and apply it to other possible areas which are subject to collusive activities.
