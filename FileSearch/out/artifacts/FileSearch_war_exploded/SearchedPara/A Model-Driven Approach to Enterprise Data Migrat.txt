 only documented informally, using sketchy textual descriptions. 
In this paper we describe a model driven approach to automate this process using a model mappings based infrastructure. Using this infrastructure we can create concep-blocks such as mapping composer, query translator, etc. Mapping composer can com-mapping to translate a query on a model at one end of the mapping to an equivalent query on the model at the other end. These blocks process not only the mappings but also the rules captured in the conceptual model. mapping between source and target conceptual models, a mapping between source con-tivity. It also results in a significant reduction in migration errors. 
The rest of the paper is organized as follows. Section 2 discusses the modeling in-discussing future work. 2.1 Conceptual Models sion to UML meta model is implemented using our in-house meta modeling tool [9]. 2.2 Rules We can specify rules on c o or a constraint among a set flavor to Semantic Web R u suitably to cast it in the f a comfortable with. Also w e properties in SWRL parla n and readable notation. 
A rule has the following if &lt;antecedent&gt; th e Here, antecedent specifies specifies the inferences on e of this language is outside strate the syntax. Fig. 2 sh o and parent , spouse an d The following are some of el: Rule 1: Persons who have a If Person(p1) and P e Then p1.sibling = p2 Constraint 1: Two differe n the same gender. If Person(p1) and P e p1.parent = p2 a n then p2.gender &lt;&gt; p3. g 2.3 Physical Models We use relational model f o tional meta model is sho w tables and primary-key and 2.4 Model Mappings We map two models by de f more classes or tables of t language that is a restricte d this language PQL (for p a without some of the procedural extensions such as method invocations on objects. We just take inputs and return an output without leaving any side-effect in the state. 
Fig. 4 shows an example mapping where a class in model M1 is mapped as a view over a set of classes in model M2. 2.5 Model Processing Infrastructure paper due to space constraints, but the following examples will give an idea. Example 1 PQL (mapping of M1.Employee in Fig. 4): select e.name name, e.salary salary, d.name department, c.name company from M2.Employee e, M2.Department d, M2.Company c where e.department = d and d.company = c; Internal Representation M1.Employee(name(v1), salary(v2), department(v3), company(v4)) :-M2.Employee(id(v0), name(v1), salary(v2)), M2.employee_department(id1(v0), id2(v5)), M2.Department(id(v5), name(v3)), M2.department_company(id1(v5), id2(v6)), M2.Company(id(v6), name(v4)). Example 2 Rule (on M1.Employee) If Employee(e) and e.salary &gt; 120000 Then e.department =  X  X anagement X  Internal Representation Employee(id(v0), name(_), salary(v1), department( X  X anagement X ), company(_)) :-Employee(id(v0), name(_), salary(v1), department(_)), v1 &gt; 120000. element it represents. and Department is represented by the term employee_department(id1(), id2()). mappings into two classes, the so-called global-as-view (GAV) [2], [5] and local-as-over classes of other models are classified as GAV rules; whereas rules of a mapping classes of M, are treated as LAV rules. greater than 120000. 2.6 Query Translator end of a mapping into an equivalent query on the other end of the mapping, as shown where each layer does a partial translation. 2.7 Data Flow Graph Generator and directed edges. Nodes represent operators. An edge represents flow of data from guage such as java, stored procedures, etc. 
We can translate a PQL query into an equiva lent data flow graph. We first translate this internal representation. We illustrate this with a few examples: Example 1 Datalog Query Customer(name(v1)) :-CorporateCustomer(name(v1), ..). Customer(name(v1)) :-IndividualCustomer(name(v1), ..). 
The query is used to fetch names of customers from two sources --corporate cus-tomers and individual customers by executing the corresponding sub queries Corpo-rateCustomer () and IndividualCustomer (). 
Fig. 6 shows the equivalent DFG. The boxes CorporateCustomer and Indi-CorporateCustomer and IndividualCustomer from respective sources. Example 2 Datalog Query MillionDollarCustomer(name(v1), amount(v2)) :-SQ(v1, v2), v2 &gt; 1000000. SQ(v1, SUM(v3)) :-Customer(id(v0), name(v1), ..), Customer_Contract(customer(v0), contract(v2)), Contract(id(v2), amount(v3)). This query is used to fetch names and total contract amount of customers whose total contract amount exceeds a million. Fig. 7 shows the equivalent DFG. 2.8 Mapping Composer We can derive a mapping between two unmapped models by composing other known mappings. Referring to Fig. 8 below, suppose we have three models M1, M2 and M3. Suppose we know the mappings between M1 and M2, and between M2 and M3, namely MAP1 and MAP2. We can compose MAP1 and MAP2 to derive a new map-ping MAP3 between M1 and M3. 
Composition is done by a series of query translation steps. Suppose MAP1 specifies a model M2 to model M3 gives the mapping of class C1 in terms of classes in M3. the following ways: set of canonical object-relational mapping patterns. For example, a table becomes a class, a column becomes a property, a foreign-key between tables becomes a re-lation between the corresponding classes, etc. -If a system is implemented using object-oriented technology, then we can reverse engineer the object model as the conceptual model and the object-relational map-ping as the conceptual-physical mapping. Data migration team then defines the mapping between source and target conceptual models. We can use a schema matching algorithm [15, 16] to discover initial corres-pondences. These are then refined into mappings in consultation with domain experts. From these mappings, we automatically derive a mapping between source and target mapping PP_MAPPING by composing S_CP_MAPPING, CC_MAPPING and T_CP_MAPPING. 
A point to note here is that there is no inherent limitation on the number of source databases that can be mapped to the source conceptual model. We can have more than one source database, and so more than one source physical model and corresponding grated from a number of related databases. 3.1 Generating Data Migration Program translated query we generate a data flow graph. This process is depicted in Fig. 10. translate the DFG to a program in Java and JDBC. 
We also generate a master program that invokes the individual programs in an or-the child table. 3.2 Migrating Queries gram migration. We can use the derived mapping PP_MAPPING to translate queries on the source side into equivalent queries on the target side, as shown in Fig. 11. For example, we take the following query on model M1 in Fig. 4. SELECT company, SUM(salary) FROM Employee GROUP BY company; We generate the following equivalent query on model M2. SELECT v2.name, SUM(v1.salary) FROM Employee v1, Company v2 WHERE v1.department.company = v2 GROUP BY v2.name; mapping to migrate source queries to the target. mats and our financial services product stores its data in its own data model. 
We took the case of one of our customers whose data was migrated to this financial having more than 170 master tables. The record count in the tables ranges from a few hundred to a few millions. from the database schemas of customer X  X  databases and our product database respec-tively. We also created corresponding conceptual models. Mappings were then identi-complexities, varying from simple one-to-one mappings to complex mappings involv-ing join conditions and sub-queries. 
We then generated the data migration program to migrate data from customer X  X  da-coded approach. 80% improvement in productivity. Based on the analysis of available defect logs from improvements are primarily due to automated code generation from model mappings, mappings are also much easier to verify, leading to early detection of errors. Commercial data migration tools [12, 13, 14] provide a graphical environment where data-flow graphs discussed in this paper. ETL based approaches suffer from the same an error-prone and effort-intensive process [10].
 designing ETL processes. They annotate data elements of data sources and warehouse a similar approach when we derive a conceptual model from a physical model as ex-version, which has to be refined subsequently in consultation with domain experts. 
In [7] Lilia et al propose a Model Driven Architecture (MDA) based framework for levels --a platform independent model (PIM) (they call it a conceptual model) and a processes at the PIM level and use Query/View/Transformations (QVT) specifications to transform them into platform specific ETL models. While this gives a measure of son with to support operations such as query translation. 
In [11] Dessloch et al discuss Orchid, an approach for integrating declarative map-specifications from these mappings. However, they propose an operator model as the iformly, enabling us to process them together. The abstract operator model proposed by Orchid is similar to the model we use for representing data-flow graphs. [15, 16] provide surveys of schema matching approaches. As discussed in section refined into mappings in consultation with domain experts. A mapping document that specifies relationshi ps between source and target data ele-shown that using our modeling framework we can specify these mappings formally, at automatically generate data migration programs. The automation helped us eliminate reducing the chances of errors. We have also shown how queries can be migrated. We dustry standard reference conceptual models, such as ACORD for insurance [21], can are growing in popularity and many applications are adopting them as their reference conceptual models. Lack of good conceptual models is one of the stumbling blocks in adopting model driven approaches such as the one discussed in this paper. Adopting industry reference models addresses this problem. We map application specific mod-els to the industry reference model. From these mappings we can automatically derive between the applications. 
