 Most existing query expansion approaches for ad-hoc re-trieval adopt overly simplistic textual representations that treat documents as bags of words and ignore inherent doc-ument structure. These simple representations often lead to incorrect independence assumptions in the proposed ap-proaches and result in limited retrieval effectiveness. In this paper, we propose a novel query expansion technique that models the various types of dependencies that exist between original query terms and expansion terms within a robust, unified framework. The proposed model is called Hierar-chical Markov random fields (HMRFs), based on Latent Concept Expansion (LCE). By exploiting implicit (or ex-plicit) hierarchical structure within documents, HMRFs can incorporate hierarchical interactions which are important for modeling term dependencies in an efficient manner. Our rigorous experimental evaluation carried out using several TREC data sets shows that our proposed query expansion technique consistently and significantly outperforms the cur-rent state-of-the-art query expansion approaches, including relevance-based language models and LCE.
 H.3.3 [ Information Storage and Retrieval ]: Information Search and Retrieval Algorithms, Experimentation, Theory query expansion, term dependence, Markov random fields
User queries serve as sparse, underspecified representa-tions of information needs. Poor query representations can easily contribute to undesirable retrieval effectiveness. To alleviate this problem, researchers have developed various automatic query expansion techniques, including Rocchio X  X  algorithm [24], Local Context Analysis [28], model-based feedback [30], relevance-based language models [13], and La-tent Concept Expansion [20].

Most previously proposed query expansion approaches uti-lize overly simple document representations. For example, a common assumption is that documents are represented as bags of words. This representation ignores the important re-lationships and dependencies that exist between terms within a document. It is also commonly assumed that documents are flat (i.e., have no internal structure). However, many documents, such as HTML and XML documents are in-deed structured. Even documents with no explicit structure, such as newswire articles, have some implicit structure, in the form of sentences, paragraphs, and so on. Thus, these simple representations often lead to incorrect independence assumptions in the proposed approaches, which ultimately degrades retrieval effectiveness.

There are two common independence assumptions made by most previous query expansion approaches. The first is the independence assumption between query terms . For query expansion, it is crucial to identify good feedback docu-ments from which useful expansion terms can be extracted [14, 9]. Previous research has shown that retrieval models that consider dependencies between query terms can estimate document relevance more accurately [19], and the expan-sion models that build upon these models can achieve sig-nificantly better retrieval effectiveness [20].

The other assumption is the independence assumption be-tween query terms and expansion terms. Even if a document is relevant, it might be only partially related [10]. Models that do not consider the dependencies between query terms and expansion terms assume that a query term is equally as-sociated with all the terms within a document, at least from a theoretical point of view. This assumption is unlikely to hold, especially when expansion involves long documents, which are more susceptible to topic drift [17]. We are interested in addressing the following questions: Is there a way to model the two aforementioned types of dependencies within a robust, unified framework? Are there any computational complexity issues when considering both of these term dependencies? Can the two orthogonal term dependencies be combined to help each other or do they pro-vide redundant information? To our best knowledge, these questions have never been seriously studied before. In this paper, we introduce a novel graphical model called Hierarchical Markov random fields (HMRFs) for jointly mod-eling the dependencies between query terms and the depen-dencies between query terms and expansion terms. HMRFs build upon the Latent Concept Expansion (LCE) frame-work, which makes use of the Markov random field model for information retrieval [19, 20]. LCE is the first formal-ized query expansion approach that provides a mechanism for modeling term dependencies during expansion. This pa-per attempts to address one of LCE X  X  limitations, that is, the assumption that query terms and expansion terms are conditionally independent given a document.

HMRFs represent documents using a simple tree struc-ture instead of as flat and unstructured. As an undirected model, HMRFs relax the independence assumptions made by directed models (e.g., [13]) and can incorporate arbitrary features in a principled way. By exploiting implicit (or ex-plicit) hierarchical structure within documents, HMRFs can incorporate hierarchical interactions which provide a mecha-nism for modeling term dependencies in an efficient manner. Furthermore, HMRFs can learn the importance of term de-pendencies in a way that directly optimizes an underlying re-trieval metric and avoids the issue of metric divergence [21].
Specifically, the three primary contributions of this paper are: 1. A natural generalization of LCE, called LCE GE, that 2. A novel graphical model called Hierarchical Markov 3. A novel query expansion technique by embedding HM-
The rest of this paper is organized as follows. In Sec-tion 2, we briefly review related work on query expansion. In Section 3, we present our extension of LCE that models dependencies between original query terms and expansion terms. In Section 4, we describe Hierarchical Markov ran-dom fields in details. Then, in Section 5, we show the time complexity of our proposed approaches in this work. In Sec-tion 6, we evaluate our proposed models and analyze the results. Finally, Section 7 concludes the paper and discusses some possible directions for future research.
Among all the techniques for improving query representa-tions, query expansion is arguably among the most effective and widely used. One of the first approaches, that is still often used even today, is Rocchio X  X  algorithm, proposed in 1971 for the SMART retrieval system [24]. Rocchio X  X  algo-rithm was developed within the vector space retrieval model. It reweights the original query vector by moving the weights towards the set of relevant (or pseudo-relevant) documents and away from the non-relevant documents.

There has been some work on developing formalized query expansion techniques under the language modeling frame-work, including model-based feedback [30] and the relevance-based language models [13]. Both approaches use relevant (or pseudo-relevant) documents to estimate an improved query model. These models tend to ignore important issues such as term dependence, proximity, and document struc-ture. The use of positional language models for query ex-pansion may be useful for exploring some of these factors, but has yet to be formally examined [16].

Relevance-based language models, or simply relevance mod-els , form the basis for LCE and our proposed extensions. Thus, we will now describe some of the details of the model. Given a query Q , a relevance model is a multinomial dis-tribution over terms, P ( : j Q ). The model is estimated as follows: where R Q is the set of documents that are relevant (or pseudo-relevant) to the query. In the setting of pseudo-relevance feedback, these are the top ranked documents for the query. Meanwhile, it is assumed that P ( D ) is uniformly distributed.

After the model is estimated, the k terms with the highest likelihood from P ( : j Q ) are extracted as expansion terms. These terms are then added to the original query and weight-ed according to their likelihood of being generated by the relevance model. We refer to this particular instantiation of the relevance model as RM3 [1].

The two approaches that are most related to our work ac-count for term dependencies and document structure during query expansion. The first approach is Xu and Croft X  X  Local Context Analysis (LCA) [28]. LCA combines passage-level retrieval with concept expansion, where concepts are sin-gle terms and phrases. However, the weights of concepts are estimated in a heuristic manner and it is unclear how much the phrases helped over the single terms alone. The second approach, that forms the basis of our work, is Met-zler and Croft X  X  Latent Concept Expansion [20], which is based on the Markov random field model [19]. The LCE approach provides a mechanism to model term dependen-cies and achieves superior retrieval effectiveness compared to state-of-the-art query expansion approaches, including rel-evance models. However, it has several limitations, as we described earlier.

Recently, Cao et al. attempted to improve query expan-sion effectiveness at the term level, by using term proximity features to learn a classifier for selecting useful expansion terms [5]. Meanwhile, He et al. attempted to improve the expansion effectiveness at the document level by detecting good feedback documents. They classified all feedback doc-uments using a variety of features such as the distribution of query terms in the feedback document and proximity be-tween the expansion terms and the original query terms in the feedback document [9].

In contrast to previous approaches, our proposed query ex-pansion approach robustly models term dependencies, docu-ment structure, and arbitrary features all within a formally motivated framework. As we will show, this yields a highly useful query expansion model that achieves state-of-the-art retrieval effectiveness.
In this section, we introduce a novel query expansion para-digm that generalizes LCE [20] for fully considering depen-dencies among original query terms and expansion terms. Before proposing our generalized version of LCE, we first provide an overview of the original LCE approach.
Latent concept expansion (LCE) assumes that when a user formulates her original query, she has some set of con-cepts in mind, but is only able to express a small number of them in the form of a query. The concepts that the user has in mind, but did not express in the query, are called latent concepts. LCE attempts to recover these latent concepts, based on their co-occurrences with these concepts explicitly expressed in the original query, in the relevant or pseudo-relevant documents.

Specifically, LCE first constructs a Markov random field model consisting of the original query terms, the expansion concept, and the document node [20]. Figure 1 (middle) shows an example LCE MRF model that is used to ex-pand a three word query ( Q = q 1 q 2 q 3 ) with single term concepts ( e 1 ). Throughout this paper we assume that all MRF models are based on the sequential dependence as-sumption, which assumes that dependencies exist between adjacent query terms [19]. We also only consider single term latent concepts, as multi-term concepts were not found to be useful for expansion in the original LCE study [20].
Given the graph, a joint distribution over a query ( Q ), a latent concept ( E ), and a document ( D ) can be defined. The conditional probability of a latent concept given the query can be easily computed as: where P ( Q;E;D ) is the joint probability and R Q is the set of relevant or pseudo-relevant documents for query Q . After computing the conditional probabilities, the k latent concepts E with the highest conditional probability are cho-sen as expansion concepts and an augmented MRF is con-structed and used for retrieval.
As illustrated in Figure 1 (middle), LCE assumes that query terms and latent concepts are conditionally indepen-dent given a document. We hypothesize that this indepen-dence assumption can degrade retrieval effectiveness, be-cause it is important to expand the query with concepts that are actually related to the original query terms. There-fore, we extend the model structure of LCE, by adding links between each query term node and the latent concept node. We refer to this generalized model as LCE GE. The graph-ical model representation of the model is shown in Figure 1 (right). With the newly added links, LCE GE can explic-itly model the dependencies between query terms and latent concepts.

Following the original LCE approach, we parameterize the MRF model based on clique sets to provide more flex-ibility in encoding useful features over cliques in the graph while keeping the number of features and parameters reason-able [20]. Cliques in the same clique set can share feature functions and parameters, which significantly reduce the pa-rameter space. Meanwhile, we can tune the parameters on the level of clique sets, which is more effective and efficient than tuning on the level of cliques for information retrieval. We expand upon the clique sets used by LCE and ultimately make use of seven clique sets, which are summarized in Ta-ble 1.

After tying the parameters based on the proposed clique sets, the joint distribution is defined as: P ( Q;E;D ) = 1
To utilize the model, we must define the feature functions f ( c ). One appealing property of the MRF model is its ability to use a variety of features for ranking. The correct choice of features depends largely on the retrieval task and the evaluation metric. It is unlikely there is a single, universally applicable set of features. Since it is not our goal here to and LCE GE (right) for a three term query.
 Table 2: Feature functions used in MRF model.
 Here, q is a query term, b is a query bigram, tf w;D is the number of times term w occurs in document D , tf #1( b ) ;D denotes the number of times the ex-act phrase b occurs in document D , tf # uw ( b ) ;D is the number of times the terms in b appear ordered or unordered within a window of 8 terms, and j D j is the length of document D . The cf and j C j values are analogously de ned on the collection level. Fi-nally, and are model hyperparameters that con-trol smoothing for single term and phrase features, respectively. find optimal features, we use a simple, fixed set of features that have shown to be effective in previous work [19, 20]. Table 2 lists the features used in Equation 3. These features attempt to capture various types of term occurrence and term proximity information.

It is important to note that relevance-based language mod-els, LCE, and our generalized version of LCE are all closely connected. For example, notice the striking similarity in Equations 1, 2, and 3. The core difference between the ap-proaches, as is clearly illustrated by Figure 1, is how the joint distribution P ( Q;D;E ) is defined. Relevance models make the most assumptions (directed model, conditional in-dependence between q i and e ), while generalized LCE makes the fewest (undirected model, no conditional independence between q i and e ).

Although our proposed LCE GE approach can incorpo-rate all of the dependencies essential for the query expansion task, its model structure may not be the most appropriate for the following reasons.

High computational complexity: In LCE GE, the latent concept now explicitly depends on the user query. Since a latent concept could be any term in the document collection with some probability, there are large amount of pairs of query terms and latent concepts that must be eval-uated. Moreover, evaluating term proximity features can be time consuming for most retrieval systems compared to evaluating term occurrence features, especially when the re-trieval system uses standard positional inverted indexes. As a result, it may be practically infeasible to implement the LCE GE approach in a large-scale retrieval system. We will provide a more formal analysis of the time complexity of LCE GE in Section 5.

Data sparseness: Data sparseness refers to the fact that most query terms only have a few number of occurrences distributed in a relatively long document and hence a very sparse query term-latent concept relationship matrix is gen-erated. This problem is also compounded by the fact that term proximity feature functions are often more sparse than term occurrence feature functions, since term co-occurrences must be within a window size (e.g., 8 terms in LCE GE).
In the next section, we will introduce a different, implicit way of modeling dependencies between query terms and ex-pansion concepts that can be computed more efficiently than LCE GE while maintaining strong retrieval effectiveness.
In this section, we describe our proposed Hierarchical Mar-kov random field model, which will be used in conjunction with LCE to construct a novel, highly effective query expan-sion approach.
For the query expansion task, it is important to use a rep-resentation that makes full use of the document as evidence. Most previous approaches use unstructured bag of words document representations, and therefore can only explore co-occurrence features at the document level. This type of representation is too coarse for our needs, especially for long documents which are more susceptible to topic drift [17].
Instead, we need a representation that allows us to explore co-occurrence at different spatial scales within the docu-ment, such as sentence-, paragraph-, or passage-level scales. Therefore, we represent documents using a tree structure. Each node in the tree represents a content region within the document, with the root node representing the whole document. Each node is the aggregation of all its children nodes. All leaf nodes are basic content units and form a flat segmentation of the document.

We are interested in partitioning documents into topical segments. Some learning methods have recently been pro-posed to automatically infer document structure from un-structured documents [3, 11]. However, such methods may be difficult to implement, computationally expensive, or sim-ply inappropriate for our given task. Therefore, to approx-Figure 2: Illustration of LCE HMRF structure for a three term query. imate the effect of representing a document as a tree struc-ture, we represent a document as a two-layer tree . The first layer contains a single root node representing the entire doc-ument, and the second layer contains nodes that partition the document into fixed length segments (passages). Thus, segments within the document are the basic content units now, instead of the entire document. In principle though, there is nothing preventing the model described in this sec-tion from extending beyond two layers or segmenting docu-ments in some other way.

In this work, we are interested in triplets of nodes f S j 1 ;D g from the two-layer tree. Nodes S j 1 and S j are associ-ated with neighboring sibling nodes in the second layer of the document tree (i.e., they are adjacent segments), while node D is the root node of the tree (i.e., the entire document). Here, we use the positional information to sequentialize the nodes on the tree from left to right. The triplets extracted from a single document form a set and cover all the nodes of the document tree, but are not a partition, since some nodes appear in multiple triplets. The remainder of this section describes how MRFs can be used to model a joint distribution over a query, a latent concept, and this triplet, and how the distribution can ultimately be used for query expansion.
Given the hierarchical data representation and the triplets extracted from the document tree, a Hierarchical Markov random field (HMRF) model can easily be constructed and used to generate latent concepts. When HMRFs are used in this way (i.e., within the LCE framework to generate latent concepts), we refer to the resulting approach as LCE HMRF. Figure 2 provides a high level illustration of the LCE HMRF model structure. We assume there are dependencies between nodes that are associated with parent and child nodes in the document tree. Meanwhile, we assume a dependency exists between nodes that are associated with neighboring sibling nodes at the same layer of the document tree. Query terms and the latent concept are under the same independence as-sumptions adopted by LCE, that is, neighboring query terms are linked, and both query terms and the latent concept are linked to all the nodes of the triplet. Note that there are no links between query terms and the latent concept as in LCE GE.

We parameterize LCE HMRF based on clique sets in the same way as LCE GE. Unlike LCE GE, LCE HMRF can Name Description Table 3: Two additional clique sets used with LCE HMRF.
 f
T SQ ( q;D ) log[(1 ) f
T SE ( e;D ) log[(1  X   X  ) Table 4: Document structure feature functions used with LCE HMRF. Here, D = ( S j 1 ;S j ;D ) , and , ,  X  , and  X  are model hyperparameters that control smoothing for query term and latent concept fea-tures, respectively. exploit different levels of contextual information in a doc-ument. We propose two novel clique sets, which provide a mechanism to exploit a document X  X  fine-grained evidence. Features over these cliques encode how well the terms in the clique describe a basic content unit (i.e. a segment) within the document. The two new clique sets are described in Table 3. Meanwhile, LCE HMRF can also exploit a docu-ment X  X  coarse-grained evidence, like LCE GE. That is, the clique sets T D , O D , U D , D that are proposed for LCE GE are also used here, where the original document node on the LCE GE graph is replaced by the root node at the first layer of the document tree. Putting everything together, the joint distribution of LCE HMRF can be written as: P ( Q;E;S j 1 ;S j ;D ) = 1 | {z } | {z } where F D and F S are convenience functions defined by coarse-grained evidence oriented (at the document level) and fine-grained evidence oriented (at the segment level) components of the joint distribution, respectively. Furthermore, F D and F S ( Q ) are document and query dependent, while F D and F S ( E ) are document and latent concept dependent. These will be used to simplify and clarify expressions de-rived throughout the remainder of this paper.

Table 4 shows how f T SQ and f T SE are defined. The fea-ture function f T SQ estimates the relevance of a basic content unit (i.e., a segment) within the document to the query. It is based on three hypotheses: 1) if a document is relevant to the query, then a segment within the document is more likely to be relevant, 2) if a segment X  X  neighboring segments are relevant to the query, then the segment itself is more likely to be relevant, and 3) the more query term occur-rences a segment has, more likely the segment is likely to be relevant to the query. This is similar to the smoothing used by Murdock and Croft for sentence retrieval, which was shown to be highly effective [22]. Additionally, the feature function f T SE measures how relevant the latent concept is with respect to the segment in a similar manner.
In Section 4.1 and Section 4.2, we introduced the data representation and model description of our proposed Hi-erarchical Markov random field model. In this section, we detail our method for estimating the model parameters.
The HMRF model is an extension of the Markov ran-dom field model. Although the HMRF model is an gen-erative model, it is inappropriate to train the model using traditional likelihood-based approaches, such as maximum likelihood estimation and maximum a posteriori estimation. This is because our goal in leveraging the term dependency aware model is primarily for information retrieval, and thus retrieval metrics of interest are the key metrics for us to opti-mize for. Likelihood-based approaches are unlikely to max-imize the retrieval metrics (e.g., mean average precision), due to the issue of metric divergence [21].

For this reason, we discriminatively train our model to directly optimize the parameters for the evaluation metric under consideration [26, 19, 2]. It is easy to see that the joint distribution in Equation 4 is linear with respect to the model parameters. Hence, we make use of the coordinate-level ascent algorithm that was original proposed in [18], which is easy to implement for a small number of parame-ters (as is the case here), and has good empirically verified generalization properties.

The coordinate-level ascent algorithm iteratively optimizes a multivariate object function by performing a series of one-dimensional line searches. It repeatedly cycles through each parameter in Equation 4, while holding all the other param-eters fixed. This process is performed iteratively over all parameters until the gain for a given task is below a certain threshold.

We note that there is a large and growing body of liter-ature on the learning to rank methods for information re-trieval, which have been developed for effectively optimiz-ing ranking functions with respect to ranking metrics [15]. Other more sophisticated learning to rank methods for lin-ear models can also be used in this work, such as ranking SVM[12] and SVM MAP [29]. Since our work focus on study-ing the importance of term dependencies for query expan-sion and our model parameter space is small, we employed a simple, yet effective parameter estimation method instead.
Both LCE GE and LCE HMRF attempt to relax the in-dependence assumption between query terms and latent con-cepts. LCE GE explicitly incorporates the dependencies by linking query term nodes and the latent concept node on the graph. LCE HMRF instead implicitly models these same dependencies via the segment nodes. In this way, the model can identify, and reward, expansion concepts that co-occur with one or more query terms within one or more segments. Modeling such co-occurrences on a per-segment basis, rather than at the document-level provides an implicit means for modeling dependencies between query terms and expansion concepts.

By implicitly modeling the dependencies, the latent con-cept in LCE HMRF now depends on the hierarchical struc-ture within documents rather than the user query as in LCE GE. As a result, LCE HMRF does not have to evalu-ate expensive features defined over pairs of query terms and latent concepts like LCE GE. In this way, LCE HMRF can address LCE GE X  X  high computational complexity and data sparseness problems.

To illustrate how LCE HMRF weights expansion concepts, we show the general form of the LCE conditional probabili-ties, which take on the following form: where f S j 1 ;S j ;D g is the set of triplets extracted from the set of relevant or pseudo-relevant documents R Q for query Q . As we see, the contribution for each triplet is a combi-nation of scores at the document level and scores at the seg-ment level. The document level score reflects how relevant the original query is to the document, as well as how relevant the expansion concept is. The same is true for the segment level score. As a consequence, an expansion concept that dominates segments of the document that are highly rele-vant to the original query will be assigned a high likelihood.
We note that if we drop the dependence between adjacent segments from LCE HMRF (i.e., we only consider a single segment S j as evidence at a time), the model degrades into segment-based LCE , which we refer to as LCE SB. With LCE SB, documents are split into segments first, and then LCE is applied to segments for query expansion, treating each segment as a  X  X ocument X . This is akin to the passage-based query expansion performed by LCA [28]. While LCE SB can exploit fine-grained document information, it can-not utilize valuable contextual information (e.g., information from sibling nodes). Thus, LCE HMRF provides a general-ization of passage-based query expansion approaches.
In this section, we compare the time complexity of LCE GE and LCE HMRF.

The efficiency of LCE GE X  X  joint distribution computa-tion in Equation 3 is dominated by the clique sets depen-dent on the query, since clique sets that do not depend on the query can be precomputed at index-time. Among all the seven clique sets proposed for LCE GE, the clique set U
QE is the most time-consuming one. For a query Q with j
Q j query terms, U QE has j Q j 1 cliques ( b;E;D ) within it, where b is a query bigram. Given a fixed Q , the ran-dom variable E has j V j (i.e., the size of the vocabulary) possible outcomes in total, and the random variable D has jR
Q j (i.e., the number of feedback documents) possible out-comes. Thus, the feature function f U QE ( b;E;D ) needs to be computed ( j Q j 1) j V jjR Q j times. Supposing the index contains term position information and a term occurs tf avg times within a document on average, then f U QE ( b;E;D ) must be computed O ( tf 3 avg ) times. As a result, the total complexity is O ( j Q jj V jjR Q j tf 3 avg ), where j V j
Table 5: Summary of TREC data sets and topics. ulary size, is often very large. Thus, LCE GE suffers from high computational complexity problem.

Similarly, the efficiency of LCE HMRF X  X  joint distribution computation with Equation 4 is dominated by the compu-tation of f U D ( b;D ) and f T SQ ( q;S j 1 ;S j ;D ). We see that neither of these feature functions depends on the latent con-cept node E , and thus they do not need to be computed once for every term in the vocabulary. Hence, the compu-tational complexity of the model is significantly decreased compared to LCE GE. The time complexity of computing f
D ( b;D ) is O ( f is the average number of segments per document.
In Section 3.2 and Section 4, we proposed two novel query expansion approaches called LCE GE and LCE HMRF for modeling the dependencies between query terms and expan-sion concepts. In this section, we evaluate the effectiveness of these approaches empirically. Experimental results show that these term dependencies can help improve the retrieval performance consistently and significantly during expansion.
Table 5 summarizes the data sets used in our experimental evaluation. The data sets vary by their document type (Ro-bust04 is a newswire data set, while WT10g and GOV2 are web data sets), number of documents, and number of avail-able topics, thus providing a diverse experimental setup for evaluating our proposed models.

All data sets were stopped using a standard list of 418 common terms and stemmed using a Porter stemmer. In all cases, only the title portions of the TREC topics are used in our experiments, to simulate short keyword queries. A modified version of the Indri search engine was used to index and rank documents [25].

Six different models are compared in our study, including: the unigram language modeling with Dirichlet smoothing (LM), the relevance model (RM3); latent concept expan-sion (LCE), the generalized LCE model (LCE GE), LCE using Hierarchical Markov random fields (LCE HMRF), and segment-based LCE (LCE SB).

We compare LM, RM3, LCE, and LCE HMRF to better understand how modeling term dependencies can contribute to retrieval performance during expansion. Additionally, we compare LCE GE and LCE HMRF to evaluate whether models that explicitly model dependencies between query terms and expansion terms are more effective than those that implicitly model such dependencies. Finally, we com-pare LCE SB and LCE HMRF to evaluate the usefulness of the segment-level interactions considered by LCE HMRF compared to a simpler passage-based expansion approach. We utilize cross-validation to estimate the parameters and Robust04 0 : 2532 0 : 2834 0 : 3057 0 : 3313 WT10g 0 : 1968 0 : 2118 0 : 2259 0 : 2454 Table 6: Mean average precision for language mod-eling (LM), relevance model (RM3), latent con-cept expansion (LCE), and LCE using Hierarchical Markov random elds (LCE HMRF). The super-scripts , , and indicate statistically signi cant improvements ( p&lt; 0 : 05 using Wilcoxon test) over LM, RM3, LCE, respectively. evaluate the results for each data set. Given a data set, top-ics are divided into subsets of 50 topics each. Each subset, in turn, is used as a testing set, while the rest of the topics serve as a training set. Experiments are run separately for each data set, and average results over all testing sets are reported.

For the unigram language model, the smoothing param-eter is trained. For RM3, LCE, LCE GE, we train the model parameters, model hyperparameters, the number of pseudo-relevant documents used, and the number of expan-sion terms. For LCE HMRF and LCE SB, we also train the segment length. Meanwhile, LCE HMRF adopts the same first-pass and second-pass retrieval algorithm (i.e. the MRF model for information retrieval [19]) as LCE, where the only difference between LCE HMRF and LCE is how each selects and weights expansion terms.
In this section, we empirically evaluate the following hy-pothesis:
We note that the current state-of-the-art query expan-sion approaches usually improve retrieval effectiveness on average, but can also significantly hurt performance for in-dividual queries unpredictably [8, 27, 10]. As a result, we measure our proposed approaches X  effectiveness by two main criteria: average retrieval performance (in Section 6.2.1) and retrieval robustness (in Section 6.2.2). The mean average precision for LM, RM3, LCE, and LCE HMRF are given in Table 6. As would be expected, the relevance model, LCE, and LCE HMRF always significantly outperform the unigram language model.

Furthermore, LCE significantly outperforms the relevance model across all data sets. This indicates that term depen-dencies can provide extra information to help estimate a better query model than using independent terms alone and can contribute to the retrieval performance during expan-sion. The findings agree with similar experiments that were previously carried out [20].

As the results show, by implicitly incorporating term de-pendencies between query terms and expansion terms, LCE HMRF achieves the best performance across all of the data sets. In particular, it achieves 16.9%, 15.9%, and 14.3% rel-ative improvements in mean average precision over the rele-vance model, on Robust04, WT10g, and GOV2, respectively. Moreover, LCE HMRF shows significant improvements over the original LCE approach, which demonstrates the benefits of using the document structure to implicitly model depen-dencies between query terms and expansion terms during ex-pansion and support hypothesis H1 . The relative improve-ments over LCE are 8.4% for Robust04, 8.6% for WT10g, and 5.2% for GOV2. All of the improvements, with respect to relevance models and LCE are statistically significant. As we have observed, the relevance model, LCE, and LCE HMRF can lead to significantly improvements in retrieval effectiveness on average versus a simple unigram language modeling baseline. Here, we demonstrate and compare the robustness of these query expansion techniques with respect to this baseline. We define robustness as the number of queries whose effectiveness is improved/degraded (and by how much) as the results of applying these methods. A highly robust expansion technique will significantly improve many queries and only minimally degrade very few.
Figure 3 presents an analysis of the robustness of the rele-vance model, LCE, and LCE HMRF on Robust04, WT10g, and GOV2. The histograms present, for various ranges of relative decreases/increases in mean average precision, the number of queries that are hurt/improved over the baseline unigram language model.

The models that consider term dependencies show strong robustness for each data set. For the Robust04 data set, the relevance model improves 182 queries and degrades 67, whereas LCE improves 190 and degrades 59 and LCE HMRF improves 188 and degrades 61. Although LCE improves the effectiveness of 2 more queries than LCE HMRF, the relative improvement exhibited by LCE HMRF is signifi-cantly larger. For WT10g, the relevance model improves 52 and degrades 47, while LCE improves 61 and degrades 38 and LCE HMRF improves 66 and degrades 33. Finally, for GOV2, the relevance model improves 92 and degrades 56, while LCE improves 104 and degrades 44 and LCE HMRF improves 116 and degrades 32. Therefore LCE HMRF ex-hibits good robustness characteristics. Finally, we note that our proposed HMRF model relies on Table 7: Mean average precision for LCE, LCE GE, LCE HMRF. The superscripts and indicate sta-tistically signi cant improvements ( p&lt; 0 : 05 using Wilcoxon test) over LCE and LCE GE, respectively. automatically breaking documents into segments. There-fore, we are interested in analyzing the sensitivity of the retrieval performance with respect to the size of the seg-ment. This sensitivity analysis is shown in Figure 4. For each segment length, we train all of the other model param-eters to fairly evaluate the sensitivity. The results show that the effectiveness is relatively stable across different segment lengths. However, for Robust04, the homogeneous newswire data set, segment length=200 performed the best. For the heterogeneous web data sets such as WT10g and GOV2, segment length=300 performed the best. These results sug-gest that setting the segment length in the range of 200-300 is a reasonable  X  X efault X  setting, at least for the data sets currently under consideration.
In this section, we empirically evaluate the following hy-pothesis:
We compare the effectiveness of LCE GE, which is an non-hierarchical model and explicitly models the dependencies between query terms and expansion concepts, and LCE HMRF, which models the same type of dependencies implicitly via the hierarchical document structure.
 The results of this comparison are provided in Table 7. The results show that LCE HMRF significantly outperforms LCE GE on all data sets. The GOV2 data set is not tested due to the high computational cost involved in applying LCE GE. Interestingly, LCE GE shows improvements over LCE, but the improvements are not statistically significant. Although LCE GE and LCE HMRF both model dependen-cies between query terms and expansion concepts, LCE GE is shown to not be as effective as LCE HMRF, presumably due to the data sparseness issue described earlier.
Additionally, the computational cost of LCE GE is much higher than LCE HMRF. Unlike LCE HMRF, LCE GE ex-plicitly models a large number of pairs of query terms and latent concepts. Thus, LCE GE has to compute many term proximity features over these pairs, which is very time con-suming. Therefore, LCE HMRF is a practically appealing query expansion approach, both in terms of efficiency and effectiveness. Of course, in a real, large-scale system, query expansion would likely be either done offline or done online using a hybrid strategy, such as the one described by Broder et al. [4]. However, even when such an architecture is used, LCE HMRF is still desirable to LCE GE. As a consequence, we can support hypothesis H2 . model (LM) for the Robust04, WT10g, and GOV2 data sets. Table 8: Mean average precision for LCE, LCE SB, and LCE HMRF. The superscripts and indicate statistically signi cant improvements ( p&lt; 0 : 05 using Wilcoxon test) over LCE and LCE SB, respectively.
As mentioned earlier, the dependencies between sibling nodes and the parent node considered by the HMRF model provides a mechanism for utilizing valuable contextual in-formation inside a document. To quantify the utility of these dependencies, we compare the effectiveness of LCE SB (passage-based LCE) and LCE HMRF.

As shown in Table 8, LCE HMRF always significantly outperforms LCE SB. In fact, LCE SB shows slightly lower performance than LCE on the Robust04 and WT10g data sets. Although LCE SB has the capability to exploit a doc-ument X  X  fine-grained evidence, it fails to significantly im-prove the retrieval performance over LCE, likely due to data sparseness, which stems from the fact that LCE SB only considers information from a single segment, instead of from two adjacent segments and the entire document, as is the case in LCE HMRF. The segment-level dependencies con-sidered by LCE HMRF can help alleviate this problem by leveraging the document X  X  structure information to smooth the segments and improve the retrieval performance. There-fore, LCE HMRF is more than simply a passage-based ver-sion of LCE, as these results clearly show that modeling intra-segment dependencies is highly effective.
Our proposed novel graphical model called HMRFs pro-vide a natural, formally motivated mechanism for modeling term dependencies and document structure. Thus, we are interested in exploring how effective the model is for rank-ing compared to the original MRF model [19], independent of the query expansion task. As illustrated in Figure 2, by removing the latent concept node from the model structure, the HMRF model defines a joint distribution over a query and a triplet of nodes in the document tree. Hence, the con-ditional probability of a triplet given the query can easily Table 9: Mean average precision for LM, MRF, and Ranking HMRF. The superscripts and indicate statistically signi cant improvements ( p&lt; 0 : 05 using Wilcoxon test) over LM and MRF, respectively. be computed and utilized for ranking. When HMRFs are used in this way (i.e., directly for ranking document instead of expanding queries), we refer to the resulting approach as Ranking HMRF. In this work, we simply use the best match strategy to score a document for ranking, as follows: where rank = denotes rank equivalence, f S j 1 ;S j ;D g is the set of triplets extracted from document D , and P ( Q;S j 1 ;S is the joint distribution of Ranking HMRF.

We compare the effectiveness of Ranking HMRF with the original MRF model in Table 9. Both MRF and Rank-ing HMRF employ the sequential dependency assumption, which assumes that dependencies exist between adjacent query terms. For efficiency reasons, we conduct the Rank-ing HMRF approach by reranking the top 3000 results re-turned by the baseline approach (i.e., unigram language model [23]).

As shown in the table, Ranking HMRF consistently and significantly outperforms the MRF model across all the data sets. We attribute the additional performance gain to the hierarchical document structure which is naturally captured by Ranking HMRF. Basically, the original MRF model can capture two kinds of features, namely term occurrence and term proximity features. The former features are loosely de-fined at the document level while the latter ones are strictly defined within a limited window size (e.g., 8 terms). The document structure aware Ranking HMRF approach pro-vides a way for exploring co-occurrence at different spatial scales, and can define features at segment level which are less strict than the proximity features and more focused than the term occurrence features.
In this paper, we showed that most previously proposed query expansion approaches do not properly model depen-dencies between query terms and expansion concepts and make overly simple assumptions about document structure. As a result, we proposed a novel query expansion paradigm, built upon LCE, that models the dependencies between query terms and expansion terms. We have shown that these de-pendencies can help improve the retrieval performance dur-ing expansion. To effectively and efficiently model these important term dependencies, we also introduced a model called Hierarchical Markov random fields (HMRFs). We have demonstrated, both theoretically and experimentally, that LCE using HMRFs can (partially) avoid the high com-putational complexity and the data sparseness issues that plague other models. In particular, by modeling depen-dencies between adjacent document segments and the en-tire document, HMRFs provide a mechanism to utilize a document X  X  structural information to smooth the segments within it. Experimental results showed that LCE HMRF provides state-of-the-art query expansion retrieval effective-ness across several TREC data sets.

Our work can be extended in several ways. First, only term occurrence and term proximity features are used when we design the feature functions. There is additional infor-mation that can be used, such as named entities, text style, PageRank, and readability, among others. Such informa-tion can also be considered in our models. Second, our work has focused on dealing with unstructured data only. In the Web environment, there exists large amount of structured and semi-structured data containing HTML or XML fields that often play an important role in retrieval. It would be interesting to see how LCE HMRF can be extended to deal with these kinds of data. Third, it would be interesting to incorporate some notion of risk directly into the model, as was recently proposed by Collins-Thompson [6, 7]. This work is supported by the Major State Basic Research Project of China under Grant No. 2007CB311103, the Na-tional High Technology Research and Development Program of China under Grant No. 2006AA010105, and the National Science Foundation of China under Grant No. 60776797 and 60873166.
